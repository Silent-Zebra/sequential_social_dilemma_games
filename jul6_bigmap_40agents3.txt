/h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:523: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint8 = np.dtype([("qint8", np.int8, 1)])
/h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:524: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint8 = np.dtype([("quint8", np.uint8, 1)])
/h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint16 = np.dtype([("qint16", np.int16, 1)])
/h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint16 = np.dtype([("quint16", np.uint16, 1)])
/h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint32 = np.dtype([("qint32", np.int32, 1)])
/h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:532: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  np_resource = np.dtype([("resource", np.ubyte, 1)])
Process STDOUT and STDERR is being redirected to /tmp/ray/session_2020-07-08_01-09-30_26891/logs.
Waiting for redis server at 127.0.0.1:25281 to respond...
Waiting for redis server at 127.0.0.1:30951 to respond...
Warning: Capping object memory store to 20.0GB. To increase this further, specify `object_store_memory` when calling ray.init() or ray start.
Starting the Plasma object store with 20.0 GB memory using /dev/shm.

======================================================================
View the web UI at http://localhost:8888/notebooks/ray_ui.ipynb?token=eb0a8565f7df6a58deff61a564a0af412c7749a9d84edcbb
======================================================================

== Status ==
Using FIFO scheduling algorithm.
Resources requested: 0/2 CPUs, 0/1 GPUs
Memory usage on this node: 14.0/202.5 GB

Created LogSyncer for /h/zhaostep/ray_results/harvest_A3C/A3C_harvest_env_0_2020-07-08_01-09-31hbgggro1 -> 
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 14.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING

/h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:523: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint8 = np.dtype([("qint8", np.int8, 1)])
/h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:524: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint8 = np.dtype([("quint8", np.uint8, 1)])
/h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint16 = np.dtype([("qint16", np.int16, 1)])
/h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint16 = np.dtype([("quint16", np.uint16, 1)])
/h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint32 = np.dtype([("qint32", np.int32, 1)])
/h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:532: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  np_resource = np.dtype([("resource", np.ubyte, 1)])
2020-07-08 01:09:43,302	INFO policy_evaluator.py:262 -- Creating policy evaluation worker 0 on CPU (please ignore any CUDA init errors)
2020-07-08 01:09:43.303247: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
From /h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/ray/rllib/models/lstm.py:59: BasicLSTMCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.
Instructions for updating:
This class is deprecated, please use tf.nn.rnn_cell.LSTMCell, which supports all the feature this cell currently has. Please replace the existing code with tf.nn.rnn_cell.LSTMCell(name='basic_lstm_cell').
/h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:523: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint8 = np.dtype([("qint8", np.int8, 1)])
/h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:524: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint8 = np.dtype([("quint8", np.uint8, 1)])
/h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint16 = np.dtype([("qint16", np.int16, 1)])
/h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint16 = np.dtype([("quint16", np.uint16, 1)])
/h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint32 = np.dtype([("qint32", np.int32, 1)])
/h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:532: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  np_resource = np.dtype([("resource", np.ubyte, 1)])
2020-07-08 01:09:55,079	INFO policy_evaluator.py:262 -- Creating policy evaluation worker 2 on CPU (please ignore any CUDA init errors)
2020-07-08 01:09:55.080836: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
/h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:523: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint8 = np.dtype([("qint8", np.int8, 1)])
/h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:524: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint8 = np.dtype([("quint8", np.uint8, 1)])
/h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint16 = np.dtype([("qint16", np.int16, 1)])
/h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint16 = np.dtype([("quint16", np.uint16, 1)])
/h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint32 = np.dtype([("qint32", np.int32, 1)])
/h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:532: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  np_resource = np.dtype([("resource", np.ubyte, 1)])
2020-07-08 01:09:55,086	INFO policy_evaluator.py:262 -- Creating policy evaluation worker 1 on CPU (please ignore any CUDA init errors)
2020-07-08 01:09:55.087335: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
From /h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/ray/rllib/models/lstm.py:59: BasicLSTMCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.
Instructions for updating:
This class is deprecated, please use tf.nn.rnn_cell.LSTMCell, which supports all the feature this cell currently has. Please replace the existing code with tf.nn.rnn_cell.LSTMCell(name='basic_lstm_cell').
From /h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/ray/rllib/models/lstm.py:59: BasicLSTMCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.
Instructions for updating:
This class is deprecated, please use tf.nn.rnn_cell.LSTMCell, which supports all the feature this cell currently has. Please replace the existing code with tf.nn.rnn_cell.LSTMCell(name='basic_lstm_cell').
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-08_01-10-52
  done: false
  episode_len_mean: .nan
  episode_reward_max: .nan
  episode_reward_mean: .nan
  episode_reward_min: .nan
  episodes_this_iter: 0
  episodes_total: 0
  experiment_id: 4e724eb5b3a34f42879644e84578eec0
  hostname: gpu024
  info:
    apply_time_ms: 4.094
    dispatch_time_ms: 12.444
    learner:
      cur_lr: 0.0013599999947473407
      grad_gnorm: 39.9999885559082
      policy_entropy: 607.9677734375
      policy_loss: -123.9280014038086
      var_gnorm: 18.24491310119629
      vf_explained_var: 0.015939414501190186
      vf_loss: 9132.2861328125
    num_steps_sampled: 40000
    num_steps_trained: 40000
    wait_time_ms: 550.593
  iterations_since_restore: 1
  node_ip: 172.17.8.24
  num_metric_batches_dropped: 0
  pid: 26970
  policy_reward_mean: {}
  time_since_restore: 67.77584218978882
  time_this_iter_s: 67.77584218978882
  time_total_s: 67.77584218978882
  timestamp: 1594185052
  timesteps_since_restore: 40000
  timesteps_this_iter: 40000
  timesteps_total: 40000
  training_iteration: 1
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 15.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26970], 67 s, 1 iter, 40000 ts, nan rew

[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.[0m
agent-1: -408.0
agent-2: -529.0
agent-3: -352.0
agent-4: -938.0
agent-5: -870.0
agent-6: -585.0
agent-7: -393.0
agent-8: -1175.0
agent-9: -1770.0
agent-10: -1068.0
agent-11: -709.0
agent-12: -966.0
agent-13: -813.0
agent-14: -614.0
agent-15: -492.0
agent-16: -353.0
agent-17: -491.0
agent-18: -1004.0
agent-19: -1089.0
agent-20: -752.0
agent-21: -1072.0
agent-22: -1069.0
agent-23: -323.0
agent-24: -356.0
agent-25: -759.0
agent-26: -544.0
agent-27: -231.0
agent-28: -1622.0
agent-29: -348.0
agent-30: -260.0
agent-31: -1254.0
agent-32: -522.0
agent-33: -942.0
agent-34: -510.0
agent-35: -1074.0
agent-36: -144.0
agent-37: -959.0
agent-38: -768.0
agent-39: -219.0
agent-40: -449.0
Sum Reward: -28796.0
Avg Reward: -719.9
Min Reward: -1770.0
Max Reward: -144.0
Gini Coefficient: -0.29034414502014166
20:20 Ratio: 0.22024691358024692
Max-min Ratio: 0.08135593220338982
[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.[0m
agent-1: -891.0
agent-2: -1201.0
agent-3: -293.0
agent-4: -1365.0
agent-5: -875.0
agent-6: -1210.0
agent-7: -208.0
agent-8: -601.0
agent-9: -337.0
agent-10: -232.0
agent-11: -758.0
agent-12: -965.0
agent-13: -990.0
agent-14: -448.0
agent-15: -354.0
agent-16: -656.0
agent-17: -582.0
agent-18: -1323.0
agent-19: -494.0
agent-20: -173.0
agent-21: -387.0
agent-22: -1110.0
agent-23: -1421.0
agent-24: -1096.0
agent-25: -341.0
agent-26: -969.0
agent-27: -891.0
agent-28: -1159.0
agent-29: -1059.0
agent-30: -471.0
agent-31: -807.0
agent-32: -866.0
agent-33: -561.0
agent-34: -1604.0
agent-35: -661.0
agent-36: -290.0
agent-37: -976.0
agent-38: -337.0
agent-39: -600.0
agent-40: -435.0
Sum Reward: -29997.0
Avg Reward: -749.925
Min Reward: -1604.0
Max Reward: -173.0
Gini Coefficient: -0.28656115611561156
20:20 Ratio: 0.21273934378908882
Max-min Ratio: 0.10785536159600997
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-08_01-11-49
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -28796.0
  episode_reward_mean: -29396.5
  episode_reward_min: -29997.0
  episodes_this_iter: 2
  episodes_total: 2
  experiment_id: 4e724eb5b3a34f42879644e84578eec0
  hostname: gpu024
  info:
    apply_time_ms: 4.917
    dispatch_time_ms: 9.746
    learner:
      cur_lr: 0.001357335946522653
      grad_gnorm: 39.99999237060547
      policy_entropy: 663.8001098632812
      policy_loss: 3088.5703125
      var_gnorm: 18.48554229736328
      vf_explained_var: 0.0038183927536010742
      vf_loss: 21962.84375
    num_steps_sampled: 80000
    num_steps_trained: 80000
    wait_time_ms: 557.249
  iterations_since_restore: 2
  node_ip: 172.17.8.24
  num_metric_batches_dropped: 0
  pid: 26970
  policy_reward_mean: {}
  time_since_restore: 125.26425981521606
  time_this_iter_s: 57.488417625427246
  time_total_s: 125.26425981521606
  timestamp: 1594185109
  timesteps_since_restore: 80000
  timesteps_this_iter: 40000
  timesteps_total: 80000
  training_iteration: 2
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 16.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26970], 125 s, 2 iter, 80000 ts, -2.94e+04 rew

Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-08_01-12-44
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -28796.0
  episode_reward_mean: -29396.5
  episode_reward_min: -29997.0
  episodes_this_iter: 0
  episodes_total: 2
  experiment_id: 4e724eb5b3a34f42879644e84578eec0
  hostname: gpu024
  info:
    apply_time_ms: 3.873
    dispatch_time_ms: 11.108
    learner:
      cur_lr: 0.0013546720147132874
      grad_gnorm: 40.000003814697266
      policy_entropy: 671.9053955078125
      policy_loss: -627.7778930664062
      var_gnorm: 18.67351531982422
      vf_explained_var: -3.0517578125e-05
      vf_loss: 10407.4423828125
    num_steps_sampled: 120000
    num_steps_trained: 120000
    wait_time_ms: 565.413
  iterations_since_restore: 3
  node_ip: 172.17.8.24
  num_metric_batches_dropped: 0
  pid: 26970
  policy_reward_mean: {}
  time_since_restore: 179.70108318328857
  time_this_iter_s: 54.43682336807251
  time_total_s: 179.70108318328857
  timestamp: 1594185164
  timesteps_since_restore: 120000
  timesteps_this_iter: 40000
  timesteps_total: 120000
  training_iteration: 3
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 16.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26970], 179 s, 3 iter, 120000 ts, -2.94e+04 rew

agent-1: -250.0
agent-2: -26.0
agent-3: -39.0
agent-4: -118.0
agent-5: -188.0
agent-6: -92.0
agent-7: -77.0
agent-8: -234.0
agent-9: -21.0
agent-10: -46.0
agent-11: -155.0
agent-12: -68.0
agent-13: -142.0
agent-14: -93.0
agent-15: -170.0
agent-16: -83.0
agent-17: -31.0
agent-18: -11.0
agent-19: -51.0
agent-20: -152.0
agent-21: -151.0
agent-22: -238.0
agent-23: -122.0
agent-24: -150.0
agent-25: -16.0
agent-26: -135.0
agent-27: -283.0
agent-28: 7.0
agent-29: -177.0
agent-30: -282.0
agent-31: -74.0
agent-32: -78.0
agent-33: -142.0
agent-34: 13.0
agent-35: -75.0
agent-36: -271.0
agent-37: -32.0
agent-38: -116.0
agent-39: -41.0
agent-40: 29.0
Sum Reward: -4381.0
Avg Reward: -109.525
Min Reward: -283.0
Max Reward: 29.0
Gini Coefficient: -0.43161949326637755
20:20 Ratio: 0.029121164846593862
Max-min Ratio: -0.10247349823321555
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-08_01-13-40
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -4381.0
  episode_reward_mean: -21058.0
  episode_reward_min: -29997.0
  episodes_this_iter: 1
  episodes_total: 3
  experiment_id: 4e724eb5b3a34f42879644e84578eec0
  hostname: gpu024
  info:
    apply_time_ms: 2.474
    dispatch_time_ms: 5.973
    learner:
      cur_lr: 0.0013520079664885998
      grad_gnorm: 19.401020050048828
      policy_entropy: 487.0190124511719
      policy_loss: -7.554354667663574
      var_gnorm: 18.75094223022461
      vf_explained_var: 0.8967703580856323
      vf_loss: 0.3141931891441345
    num_steps_sampled: 160000
    num_steps_trained: 160000
    wait_time_ms: 534.541
  iterations_since_restore: 4
  node_ip: 172.17.8.24
  num_metric_batches_dropped: 0
  pid: 26970
  policy_reward_mean: {}
  time_since_restore: 236.02720522880554
  time_this_iter_s: 56.32612204551697
  time_total_s: 236.02720522880554
  timestamp: 1594185220
  timesteps_since_restore: 160000
  timesteps_this_iter: 40000
  timesteps_total: 160000
  training_iteration: 4
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 17.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26970], 236 s, 4 iter, 160000 ts, -2.11e+04 rew

agent-1: -64.0
agent-2: -81.0
agent-3: -340.0
agent-4: -79.0
agent-5: 4.0
agent-6: -186.0
agent-7: -77.0
agent-8: -91.0
agent-9: -42.0
agent-10: -89.0
agent-11: -25.0
agent-12: 10.0
agent-13: -146.0
agent-14: -180.0
agent-15: -221.0
agent-16: -151.0
agent-17: -106.0
agent-18: 15.0
agent-19: -48.0
agent-20: -134.0
agent-21: 24.0
agent-22: -185.0
agent-23: 25.0
agent-24: -70.0
agent-25: -65.0
agent-26: -195.0
agent-27: -51.0
agent-28: 46.0
agent-29: -88.0
agent-30: -29.0
agent-31: -89.0
agent-32: -37.0
agent-33: -43.0
agent-34: 27.0
agent-35: -105.0
agent-36: 15.0
agent-37: -173.0
agent-38: -28.0
agent-39: -142.0
agent-40: -55.0
Sum Reward: -3249.0
Avg Reward: -81.225
Min Reward: -340.0
Max Reward: 46.0
Gini Coefficient: -0.5432671591258849
20:20 Ratio: -0.10177805027590435
Max-min Ratio: -0.13529411764705881
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-08_01-14-34
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -3249.0
  episode_reward_mean: -16605.75
  episode_reward_min: -29997.0
  episodes_this_iter: 1
  episodes_total: 4
  experiment_id: 4e724eb5b3a34f42879644e84578eec0
  hostname: gpu024
  info:
    apply_time_ms: 2.533
    dispatch_time_ms: 6.493
    learner:
      cur_lr: 0.001349344034679234
      grad_gnorm: 39.999996185302734
      policy_entropy: 372.2606506347656
      policy_loss: 3.0496950149536133
      var_gnorm: 18.783960342407227
      vf_explained_var: 0.026750028133392334
      vf_loss: 50.87078857421875
    num_steps_sampled: 200000
    num_steps_trained: 200000
    wait_time_ms: 539.769
  iterations_since_restore: 5
  node_ip: 172.17.8.24
  num_metric_batches_dropped: 0
  pid: 26970
  policy_reward_mean: {}
  time_since_restore: 290.054030418396
  time_this_iter_s: 54.026825189590454
  time_total_s: 290.054030418396
  timestamp: 1594185274
  timesteps_since_restore: 200000
  timesteps_this_iter: 40000
  timesteps_total: 200000
  training_iteration: 5
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 18.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26970], 290 s, 5 iter, 200000 ts, -1.66e+04 rew

agent-1: 27.0
agent-2: 26.0
agent-3: 33.0
agent-4: 29.0
agent-5: 39.0
agent-6: 11.0
agent-7: 31.0
agent-8: 30.0
agent-9: 12.0
agent-10: 50.0
agent-11: 17.0
agent-12: 31.0
agent-13: 37.0
agent-14: 38.0
agent-15: 23.0
agent-16: 37.0
agent-17: 49.0
agent-18: 24.0
agent-19: -22.0
agent-20: 28.0
agent-21: 1.0
agent-22: 40.0
agent-23: 33.0
agent-24: 44.0
agent-25: 32.0
agent-26: 19.0
agent-27: 39.0
agent-28: 28.0
agent-29: 30.0
agent-30: 31.0
agent-31: 59.0
agent-32: 47.0
agent-33: -48.0
agent-34: 62.0
agent-35: 55.0
agent-36: 39.0
agent-37: 29.0
agent-38: 48.0
agent-39: 24.0
agent-40: -34.0
Sum Reward: 1128.0
Avg Reward: 28.2
Min Reward: -48.0
Max Reward: 62.0
Gini Coefficient: 0.3849734042553192
20:20 Ratio: -9.409090909090908
Max-min Ratio: -1.2916666666666667
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-08_01-15-31
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1128.0
  episode_reward_mean: -13059.0
  episode_reward_min: -29997.0
  episodes_this_iter: 1
  episodes_total: 5
  experiment_id: 4e724eb5b3a34f42879644e84578eec0
  hostname: gpu024
  info:
    apply_time_ms: 2.815
    dispatch_time_ms: 6.812
    learner:
      cur_lr: 0.0013466799864545465
      grad_gnorm: 40.000003814697266
      policy_entropy: 330.48077392578125
      policy_loss: 13.250547409057617
      var_gnorm: 18.785303115844727
      vf_explained_var: 0.11488950252532959
      vf_loss: 28.950428009033203
    num_steps_sampled: 240000
    num_steps_trained: 240000
    wait_time_ms: 558.718
  iterations_since_restore: 6
  node_ip: 172.17.8.24
  num_metric_batches_dropped: 0
  pid: 26970
  policy_reward_mean: {}
  time_since_restore: 346.1832401752472
  time_this_iter_s: 56.129209756851196
  time_total_s: 346.1832401752472
  timestamp: 1594185331
  timesteps_since_restore: 240000
  timesteps_this_iter: 40000
  timesteps_total: 240000
  training_iteration: 6
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 18.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26970], 346 s, 6 iter, 240000 ts, -1.31e+04 rew

agent-1: 31.0
agent-2: 25.0
agent-3: 8.0
agent-4: 34.0
agent-5: 42.0
agent-6: 37.0
agent-7: 44.0
agent-8: 55.0
agent-9: 31.0
agent-10: 42.0
agent-11: 45.0
agent-12: 38.0
agent-13: 22.0
agent-14: 28.0
agent-15: 51.0
agent-16: 32.0
agent-17: 26.0
agent-18: 38.0
agent-19: 29.0
agent-20: 53.0
agent-21: 13.0
agent-22: 38.0
agent-23: 34.0
agent-24: 31.0
agent-25: 29.0
agent-26: 29.0
agent-27: 14.0
agent-28: 28.0
agent-29: 52.0
agent-30: 23.0
agent-31: 14.0
agent-32: 67.0
agent-33: -6.0
agent-34: 39.0
agent-35: 41.0
agent-36: 44.0
agent-37: 30.0
agent-38: -4.0
agent-39: 35.0
agent-40: 21.0
Sum Reward: 1283.0
Avg Reward: 32.075
Min Reward: -6.0
Max Reward: 67.0
Gini Coefficient: 0.25083787996882306
20:20 Ratio: 5.012195121951219
Max-min Ratio: -11.166666666666666
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-08_01-16-25
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1283.0
  episode_reward_mean: -10668.666666666666
  episode_reward_min: -29997.0
  episodes_this_iter: 1
  episodes_total: 6
  experiment_id: 4e724eb5b3a34f42879644e84578eec0
  hostname: gpu024
  info:
    apply_time_ms: 3.678
    dispatch_time_ms: 9.199
    learner:
      cur_lr: 0.0013440160546451807
      grad_gnorm: 39.999996185302734
      policy_entropy: 568.4015502929688
      policy_loss: -20.10955810546875
      var_gnorm: 18.988842010498047
      vf_explained_var: 0.42587363719940186
      vf_loss: 15.625669479370117
    num_steps_sampled: 280000
    num_steps_trained: 280000
    wait_time_ms: 560.322
  iterations_since_restore: 7
  node_ip: 172.17.8.24
  num_metric_batches_dropped: 0
  pid: 26970
  policy_reward_mean: {}
  time_since_restore: 400.8699185848236
  time_this_iter_s: 54.686678409576416
  time_total_s: 400.8699185848236
  timestamp: 1594185385
  timesteps_since_restore: 280000
  timesteps_this_iter: 40000
  timesteps_total: 280000
  training_iteration: 7
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 19.3/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26970], 400 s, 7 iter, 280000 ts, -1.07e+04 rew

agent-1: 38.0
agent-2: 3.0
agent-3: 10.0
agent-4: 19.0
agent-5: 34.0
agent-6: 10.0
agent-7: 40.0
agent-8: 37.0
agent-9: 38.0
agent-10: 20.0
agent-11: 45.0
agent-12: 36.0
agent-13: 27.0
agent-14: 55.0
agent-15: 31.0
agent-16: 24.0
agent-17: 29.0
agent-18: 32.0
agent-19: 26.0
agent-20: 36.0
agent-21: 26.0
agent-22: 31.0
agent-23: 19.0
agent-24: 10.0
agent-25: 15.0
agent-26: 46.0
agent-27: 34.0
agent-28: 23.0
agent-29: 7.0
agent-30: 12.0
agent-31: 15.0
agent-32: 35.0
agent-33: 28.0
agent-34: 15.0
agent-35: 13.0
agent-36: 13.0
agent-37: 4.0
agent-38: 22.0
agent-39: 31.0
agent-40: 41.0
Sum Reward: 1030.0
Avg Reward: 25.75
Min Reward: 3.0
Max Reward: 55.0
Gini Coefficient: 0.27514563106796114
20:20 Ratio: 4.927536231884058
Max-min Ratio: 18.333333333333332
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-08_01-17-22
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1283.0
  episode_reward_mean: -8997.42857142857
  episode_reward_min: -29997.0
  episodes_this_iter: 1
  episodes_total: 7
  experiment_id: 4e724eb5b3a34f42879644e84578eec0
  hostname: gpu024
  info:
    apply_time_ms: 2.553
    dispatch_time_ms: 8.193
    learner:
      cur_lr: 0.0013413520064204931
      grad_gnorm: 31.263832092285156
      policy_entropy: 555.479248046875
      policy_loss: 9.884794235229492
      var_gnorm: 19.4564151763916
      vf_explained_var: 0.811355710029602
      vf_loss: 6.310092926025391
    num_steps_sampled: 320000
    num_steps_trained: 320000
    wait_time_ms: 555.347
  iterations_since_restore: 8
  node_ip: 172.17.8.24
  num_metric_batches_dropped: 0
  pid: 26970
  policy_reward_mean: {}
  time_since_restore: 457.6524999141693
  time_this_iter_s: 56.7825813293457
  time_total_s: 457.6524999141693
  timestamp: 1594185442
  timesteps_since_restore: 320000
  timesteps_this_iter: 40000
  timesteps_total: 320000
  training_iteration: 8
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 19.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26970], 457 s, 8 iter, 320000 ts, -9e+03 rew

agent-1: 36.0
agent-2: -35.0
agent-3: 41.0
agent-4: 16.0
agent-5: 32.0
agent-6: 17.0
agent-7: 28.0
agent-8: 20.0
agent-9: 25.0
agent-10: 34.0
agent-11: 29.0
agent-12: 3.0
agent-13: 38.0
agent-14: 42.0
agent-15: 29.0
agent-16: -38.0
agent-17: -16.0
agent-18: 26.0
agent-19: 12.0
agent-20: 8.0
agent-21: 7.0
agent-22: 34.0
agent-23: 22.0
agent-24: 40.0
agent-25: 21.0
agent-26: -22.0
agent-27: 26.0
agent-28: 7.0
agent-29: -13.0
agent-30: 34.0
agent-31: 29.0
agent-32: 24.0
agent-33: 12.0
agent-34: 17.0
agent-35: 19.0
agent-36: 20.0
agent-37: 9.0
agent-38: 23.0
agent-39: 28.0
agent-40: 16.0
Sum Reward: 700.0
Avg Reward: 17.5
Min Reward: -38.0
Max Reward: 42.0
Gini Coefficient: 0.5670714285714286
20:20 Ratio: -2.794392523364486
Max-min Ratio: -1.105263157894737
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-08_01-18-18
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1283.0
  episode_reward_mean: -7785.25
  episode_reward_min: -29997.0
  episodes_this_iter: 1
  episodes_total: 8
  experiment_id: 4e724eb5b3a34f42879644e84578eec0
  hostname: gpu024
  info:
    apply_time_ms: 2.905
    dispatch_time_ms: 7.207
    learner:
      cur_lr: 0.0013386879581958055
      grad_gnorm: 22.042753219604492
      policy_entropy: 521.36181640625
      policy_loss: 10.668462753295898
      var_gnorm: 19.690898895263672
      vf_explained_var: 0.3911302089691162
      vf_loss: 0.07949334383010864
    num_steps_sampled: 360000
    num_steps_trained: 360000
    wait_time_ms: 560.897
  iterations_since_restore: 9
  node_ip: 172.17.8.24
  num_metric_batches_dropped: 0
  pid: 26970
  policy_reward_mean: {}
  time_since_restore: 513.1425275802612
  time_this_iter_s: 55.49002766609192
  time_total_s: 513.1425275802612
  timestamp: 1594185498
  timesteps_since_restore: 360000
  timesteps_this_iter: 40000
  timesteps_total: 360000
  training_iteration: 9
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 20.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26970], 513 s, 9 iter, 360000 ts, -7.79e+03 rew

agent-1: 8.0
agent-2: 6.0
agent-3: 0.0
agent-4: 5.0
agent-5: 17.0
agent-6: 11.0
agent-7: 2.0
agent-8: 25.0
agent-9: 10.0
agent-10: 18.0
agent-11: 5.0
agent-12: 10.0
agent-13: 11.0
agent-14: 31.0
agent-15: 36.0
agent-16: -43.0
agent-17: 2.0
agent-18: 24.0
agent-19: 17.0
agent-20: 6.0
agent-21: 8.0
agent-22: 1.0
agent-23: 8.0
agent-24: 18.0
agent-25: 37.0
agent-26: 10.0
agent-27: 16.0
agent-28: 11.0
agent-29: 16.0
agent-30: 28.0
agent-31: 31.0
agent-32: 25.0
agent-33: 26.0
agent-34: 28.0
agent-35: 32.0
agent-36: 20.0
agent-37: 4.0
agent-38: 33.0
agent-39: 3.0
agent-40: 22.0
Sum Reward: 578.0
Avg Reward: 14.45
Min Reward: -43.0
Max Reward: 37.0
Gini Coefficient: 0.5032871972318339
20:20 Ratio: -9.846153846153847
Max-min Ratio: -0.8604651162790697
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-08_01-19-14
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1283.0
  episode_reward_mean: -6856.0
  episode_reward_min: -29997.0
  episodes_this_iter: 1
  episodes_total: 9
  experiment_id: 4e724eb5b3a34f42879644e84578eec0
  hostname: gpu024
  info:
    apply_time_ms: 3.04
    dispatch_time_ms: 11.069
    learner:
      cur_lr: 0.0013360240263864398
      grad_gnorm: 3.817948341369629
      policy_entropy: 565.6295776367188
      policy_loss: -1.8512365818023682
      var_gnorm: 19.694252014160156
      vf_explained_var: 0.9955612421035767
      vf_loss: 0.007050623185932636
    num_steps_sampled: 400000
    num_steps_trained: 400000
    wait_time_ms: 549.77
  iterations_since_restore: 10
  node_ip: 172.17.8.24
  num_metric_batches_dropped: 0
  pid: 26970
  policy_reward_mean: {}
  time_since_restore: 569.9990634918213
  time_this_iter_s: 56.85653591156006
  time_total_s: 569.9990634918213
  timestamp: 1594185554
  timesteps_since_restore: 400000
  timesteps_this_iter: 40000
  timesteps_total: 400000
  training_iteration: 10
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 21.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26970], 569 s, 10 iter, 400000 ts, -6.86e+03 rew

agent-1: 0.0
agent-2: 22.0
agent-3: 16.0
agent-4: -44.0
agent-5: 10.0
agent-6: 5.0
agent-7: 2.0
agent-8: 1.0
agent-9: 8.0
agent-10: 46.0
agent-11: 9.0
agent-12: 14.0
agent-13: 5.0
agent-14: 29.0
agent-15: 3.0
agent-16: 29.0
agent-17: 3.0
agent-18: 3.0
agent-19: 7.0
agent-20: 13.0
agent-21: 39.0
agent-22: 29.0
agent-23: 4.0
agent-24: 2.0
agent-25: 22.0
agent-26: 19.0
agent-27: 7.0
agent-28: 27.0
agent-29: 5.0
agent-30: 13.0
agent-31: 10.0
agent-32: 31.0
agent-33: 23.0
agent-34: 15.0
agent-35: 8.0
agent-36: 5.0
agent-37: 15.0
agent-38: 13.0
agent-39: 36.0
agent-40: 17.0
Sum Reward: 521.0
Avg Reward: 13.025
Min Reward: -44.0
Max Reward: 46.0
Gini Coefficient: 0.571257197696737
20:20 Ratio: -8.866666666666667
Max-min Ratio: -1.0454545454545454
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-08_01-20-10
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1283.0
  episode_reward_mean: -6118.3
  episode_reward_min: -29997.0
  episodes_this_iter: 1
  episodes_total: 10
  experiment_id: 4e724eb5b3a34f42879644e84578eec0
  hostname: gpu024
  info:
    apply_time_ms: 3.035
    dispatch_time_ms: 8.034
    learner:
      cur_lr: 0.0013333599781617522
      grad_gnorm: 3.2105774879455566
      policy_entropy: 522.6888427734375
      policy_loss: -0.5351245999336243
      var_gnorm: 19.93367576599121
      vf_explained_var: 0.9953123927116394
      vf_loss: 0.003834014991298318
    num_steps_sampled: 440000
    num_steps_trained: 440000
    wait_time_ms: 551.457
  iterations_since_restore: 11
  node_ip: 172.17.8.24
  num_metric_batches_dropped: 0
  pid: 26970
  policy_reward_mean: {}
  time_since_restore: 625.7825236320496
  time_this_iter_s: 55.78346014022827
  time_total_s: 625.7825236320496
  timestamp: 1594185610
  timesteps_since_restore: 440000
  timesteps_this_iter: 40000
  timesteps_total: 440000
  training_iteration: 11
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 21.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26970], 625 s, 11 iter, 440000 ts, -6.12e+03 rew

agent-1: -23.0
agent-2: 7.0
agent-3: 30.0
agent-4: 19.0
agent-5: 17.0
agent-6: 22.0
agent-7: 8.0
agent-8: 11.0
agent-9: 10.0
agent-10: 22.0
agent-11: 18.0
agent-12: 12.0
agent-13: 7.0
agent-14: 29.0
agent-15: 30.0
agent-16: 6.0
agent-17: -32.0
agent-18: 22.0
agent-19: 22.0
agent-20: 16.0
agent-21: 11.0
agent-22: 15.0
agent-23: 12.0
agent-24: 12.0
agent-25: 7.0
agent-26: 9.0
agent-27: 2.0
agent-28: 10.0
agent-29: 3.0
agent-30: 6.0
agent-31: 20.0
agent-32: 17.0
agent-33: 20.0
agent-34: 18.0
agent-35: 3.0
agent-36: 4.0
agent-37: 14.0
agent-38: 25.0
agent-39: 23.0
agent-40: 4.0
Sum Reward: 488.0
Avg Reward: 12.2
Min Reward: -32.0
Max Reward: 30.0
Gini Coefficient: 0.49375
20:20 Ratio: -6.151515151515151
Max-min Ratio: -0.9375
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-08_01-21-07
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1283.0
  episode_reward_mean: -5517.727272727273
  episode_reward_min: -29997.0
  episodes_this_iter: 1
  episodes_total: 11
  experiment_id: 4e724eb5b3a34f42879644e84578eec0
  hostname: gpu024
  info:
    apply_time_ms: 2.715
    dispatch_time_ms: 6.98
    learner:
      cur_lr: 0.0013306960463523865
      grad_gnorm: 2.5414416790008545
      policy_entropy: 540.3846435546875
      policy_loss: -1.1508738994598389
      var_gnorm: 19.934724807739258
      vf_explained_var: 0.9955857396125793
      vf_loss: 0.0028871637769043446
    num_steps_sampled: 480000
    num_steps_trained: 480000
    wait_time_ms: 566.46
  iterations_since_restore: 12
  node_ip: 172.17.8.24
  num_metric_batches_dropped: 0
  pid: 26970
  policy_reward_mean: {}
  time_since_restore: 682.7398154735565
  time_this_iter_s: 56.95729184150696
  time_total_s: 682.7398154735565
  timestamp: 1594185667
  timesteps_since_restore: 480000
  timesteps_this_iter: 40000
  timesteps_total: 480000
  training_iteration: 12
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 22.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26970], 682 s, 12 iter, 480000 ts, -5.52e+03 rew

agent-1: 18.0
agent-2: 16.0
agent-3: 18.0
agent-4: 18.0
agent-5: 15.0
agent-6: 9.0
agent-7: 9.0
agent-8: 9.0
agent-9: 12.0
agent-10: 10.0
agent-11: 24.0
agent-12: 14.0
agent-13: 14.0
agent-14: 10.0
agent-15: 16.0
agent-16: 13.0
agent-17: 22.0
agent-18: 12.0
agent-19: 19.0
agent-20: 24.0
agent-21: 18.0
agent-22: 11.0
agent-23: 16.0
agent-24: 14.0
agent-25: 23.0
agent-26: 6.0
agent-27: 12.0
agent-28: 16.0
agent-29: -1.0
agent-30: 8.0
agent-31: 25.0
agent-32: 18.0
agent-33: 10.0
agent-34: 13.0
agent-35: 3.0
agent-36: 12.0
agent-37: 13.0
agent-38: -50.0
agent-39: 13.0
agent-40: 25.0
Sum Reward: 507.0
Avg Reward: 12.675
Min Reward: -50.0
Max Reward: 25.0
Gini Coefficient: 0.36444773175542405
20:20 Ratio: -25.714285714285715
Max-min Ratio: -0.5
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-08_01-22-03
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1283.0
  episode_reward_mean: -5015.666666666667
  episode_reward_min: -29997.0
  episodes_this_iter: 1
  episodes_total: 12
  experiment_id: 4e724eb5b3a34f42879644e84578eec0
  hostname: gpu024
  info:
    apply_time_ms: 2.58
    dispatch_time_ms: 6.546
    learner:
      cur_lr: 0.001328031998127699
      grad_gnorm: 11.396734237670898
      policy_entropy: 515.4180908203125
      policy_loss: -6.507551193237305
      var_gnorm: 20.130556106567383
      vf_explained_var: 0.9938392639160156
      vf_loss: 0.03144882991909981
    num_steps_sampled: 520000
    num_steps_trained: 520000
    wait_time_ms: 561.079
  iterations_since_restore: 13
  node_ip: 172.17.8.24
  num_metric_batches_dropped: 0
  pid: 26970
  policy_reward_mean: {}
  time_since_restore: 738.7288024425507
  time_this_iter_s: 55.98898696899414
  time_total_s: 738.7288024425507
  timestamp: 1594185723
  timesteps_since_restore: 520000
  timesteps_this_iter: 40000
  timesteps_total: 520000
  training_iteration: 13
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 23.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26970], 738 s, 13 iter, 520000 ts, -5.02e+03 rew

agent-1: 20.0
agent-2: 6.0
agent-3: 11.0
agent-4: 13.0
agent-5: 4.0
agent-6: 17.0
agent-7: 18.0
agent-8: 19.0
agent-9: 27.0
agent-10: 1.0
agent-11: 15.0
agent-12: 32.0
agent-13: 13.0
agent-14: 12.0
agent-15: 7.0
agent-16: 4.0
agent-17: 11.0
agent-18: 16.0
agent-19: 13.0
agent-20: 18.0
agent-21: 35.0
agent-22: 18.0
agent-23: 18.0
agent-24: 6.0
agent-25: 22.0
agent-26: 22.0
agent-27: 14.0
agent-28: 17.0
agent-29: 24.0
agent-30: 6.0
agent-31: 20.0
agent-32: 26.0
agent-33: 13.0
agent-34: 18.0
agent-35: 15.0
agent-36: 5.0
agent-37: 18.0
agent-38: 4.0
agent-39: 11.0
agent-40: 7.0
Sum Reward: 596.0
Avg Reward: 14.9
Min Reward: 1.0
Max Reward: 35.0
Gini Coefficient: 0.28808724832214766
20:20 Ratio: 5.777777777777778
Max-min Ratio: 35.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-08_01-23-00
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1283.0
  episode_reward_mean: -4584.0
  episode_reward_min: -29997.0
  episodes_this_iter: 1
  episodes_total: 13
  experiment_id: 4e724eb5b3a34f42879644e84578eec0
  hostname: gpu024
  info:
    apply_time_ms: 4.067
    dispatch_time_ms: 7.277
    learner:
      cur_lr: 0.0013253679499030113
      grad_gnorm: 1.121341586112976
      policy_entropy: 539.0931396484375
      policy_loss: -0.4730949401855469
      var_gnorm: 20.144041061401367
      vf_explained_var: 0.9959019422531128
      vf_loss: 0.0021916693076491356
    num_steps_sampled: 560000
    num_steps_trained: 560000
    wait_time_ms: 553.207
  iterations_since_restore: 14
  node_ip: 172.17.8.24
  num_metric_batches_dropped: 0
  pid: 26970
  policy_reward_mean: {}
  time_since_restore: 795.6045756340027
  time_this_iter_s: 56.875773191452026
  time_total_s: 795.6045756340027
  timestamp: 1594185780
  timesteps_since_restore: 560000
  timesteps_this_iter: 40000
  timesteps_total: 560000
  training_iteration: 14
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 23.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26970], 795 s, 14 iter, 560000 ts, -4.58e+03 rew

agent-1: 9.0
agent-2: 14.0
agent-3: 18.0
agent-4: 26.0
agent-5: 13.0
agent-6: 17.0
agent-7: 7.0
agent-8: 10.0
agent-9: 10.0
agent-10: 14.0
agent-11: 12.0
agent-12: 11.0
agent-13: 7.0
agent-14: 14.0
agent-15: 15.0
agent-16: 6.0
agent-17: 23.0
agent-18: 7.0
agent-19: 10.0
agent-20: 16.0
agent-21: 17.0
agent-22: 18.0
agent-23: 12.0
agent-24: 14.0
agent-25: 17.0
agent-26: 25.0
agent-27: 22.0
agent-28: 6.0
agent-29: 11.0
agent-30: 14.0
agent-31: 19.0
agent-32: 9.0
agent-33: 10.0
agent-34: 3.0
agent-35: 9.0
agent-36: 13.0
agent-37: 15.0
agent-38: 15.0
agent-39: 5.0
agent-40: 22.0
Sum Reward: 535.0
Avg Reward: 13.375
Min Reward: 3.0
Max Reward: 26.0
Gini Coefficient: 0.2299532710280374
20:20 Ratio: 3.46
Max-min Ratio: 8.666666666666666
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-08_01-23-56
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1283.0
  episode_reward_mean: -4218.357142857143
  episode_reward_min: -29997.0
  episodes_this_iter: 1
  episodes_total: 14
  experiment_id: 4e724eb5b3a34f42879644e84578eec0
  hostname: gpu024
  info:
    apply_time_ms: 2.52
    dispatch_time_ms: 6.031
    learner:
      cur_lr: 0.0013227040180936456
      grad_gnorm: 3.2895069122314453
      policy_entropy: 504.1087646484375
      policy_loss: -1.7990047931671143
      var_gnorm: 20.322391510009766
      vf_explained_var: 0.9922860860824585
      vf_loss: 0.002302112290635705
    num_steps_sampled: 600000
    num_steps_trained: 600000
    wait_time_ms: 556.586
  iterations_since_restore: 15
  node_ip: 172.17.8.24
  num_metric_batches_dropped: 0
  pid: 26970
  policy_reward_mean: {}
  time_since_restore: 851.6866397857666
  time_this_iter_s: 56.082064151763916
  time_total_s: 851.6866397857666
  timestamp: 1594185836
  timesteps_since_restore: 600000
  timesteps_this_iter: 40000
  timesteps_total: 600000
  training_iteration: 15
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 24.3/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26970], 851 s, 15 iter, 600000 ts, -4.22e+03 rew

agent-1: 11.0
agent-2: 14.0
agent-3: 1.0
agent-4: 7.0
agent-5: 16.0
agent-6: 18.0
agent-7: 35.0
agent-8: 6.0
agent-9: 10.0
agent-10: 14.0
agent-11: 11.0
agent-12: 14.0
agent-13: 9.0
agent-14: 12.0
agent-15: 19.0
agent-16: 16.0
agent-17: 17.0
agent-18: 9.0
agent-19: 16.0
agent-20: 15.0
agent-21: 10.0
agent-22: 10.0
agent-23: 21.0
agent-24: 1.0
agent-25: 18.0
agent-26: 6.0
agent-27: 8.0
agent-28: 2.0
agent-29: 12.0
agent-30: 10.0
agent-31: 18.0
agent-32: 15.0
agent-33: 12.0
agent-34: 9.0
agent-35: 11.0
agent-36: 7.0
agent-37: 14.0
agent-38: 16.0
agent-39: 20.0
agent-40: 17.0
Sum Reward: 507.0
Avg Reward: 12.675
Min Reward: 1.0
Max Reward: 35.0
Gini Coefficient: 0.25557199211045367
20:20 Ratio: 4.368421052631579
Max-min Ratio: 35.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-08_01-24-53
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1283.0
  episode_reward_mean: -3903.3333333333335
  episode_reward_min: -29997.0
  episodes_this_iter: 1
  episodes_total: 15
  experiment_id: 4e724eb5b3a34f42879644e84578eec0
  hostname: gpu024
  info:
    apply_time_ms: 2.362
    dispatch_time_ms: 9.523
    learner:
      cur_lr: 0.001320039969868958
      grad_gnorm: 1.9143892526626587
      policy_entropy: 560.2396240234375
      policy_loss: 0.25402843952178955
      var_gnorm: 20.320167541503906
      vf_explained_var: 0.9943496584892273
      vf_loss: 0.0008850519079715014
    num_steps_sampled: 640000
    num_steps_trained: 640000
    wait_time_ms: 561.289
  iterations_since_restore: 16
  node_ip: 172.17.8.24
  num_metric_batches_dropped: 0
  pid: 26970
  policy_reward_mean: {}
  time_since_restore: 908.3923966884613
  time_this_iter_s: 56.7057569026947
  time_total_s: 908.3923966884613
  timestamp: 1594185893
  timesteps_since_restore: 640000
  timesteps_this_iter: 40000
  timesteps_total: 640000
  training_iteration: 16
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 24.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26970], 908 s, 16 iter, 640000 ts, -3.9e+03 rew

agent-1: 12.0
agent-2: 13.0
agent-3: 18.0
agent-4: 0.0
agent-5: 12.0
agent-6: 22.0
agent-7: 10.0
agent-8: 20.0
agent-9: 11.0
agent-10: 13.0
agent-11: 9.0
agent-12: 17.0
agent-13: 18.0
agent-14: 14.0
agent-15: 7.0
agent-16: 23.0
agent-17: 19.0
agent-18: 15.0
agent-19: 13.0
agent-20: 7.0
agent-21: 13.0
agent-22: 19.0
agent-23: 19.0
agent-24: 6.0
agent-25: 16.0
agent-26: 11.0
agent-27: 10.0
agent-28: 10.0
agent-29: 21.0
agent-30: 19.0
agent-31: 6.0
agent-32: 25.0
agent-33: 5.0
agent-34: 7.0
agent-35: 11.0
agent-36: 31.0
agent-37: 17.0
agent-38: 7.0
agent-39: 21.0
agent-40: 5.0
Sum Reward: 552.0
Avg Reward: 13.8
Min Reward: 0.0
Max Reward: 31.0
Gini Coefficient: 0.2609601449275362
20:20 Ratio: 4.232558139534884
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-08_01-25-49
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1283.0
  episode_reward_mean: -3624.875
  episode_reward_min: -29997.0
  episodes_this_iter: 1
  episodes_total: 16
  experiment_id: 4e724eb5b3a34f42879644e84578eec0
  hostname: gpu024
  info:
    apply_time_ms: 3.319
    dispatch_time_ms: 7.563
    learner:
      cur_lr: 0.0013173760380595922
      grad_gnorm: 3.319431781768799
      policy_entropy: 422.54296875
      policy_loss: -0.9136514663696289
      var_gnorm: 20.570249557495117
      vf_explained_var: 0.9915773272514343
      vf_loss: 0.0029088957235217094
    num_steps_sampled: 680000
    num_steps_trained: 680000
    wait_time_ms: 569.783
  iterations_since_restore: 17
  node_ip: 172.17.8.24
  num_metric_batches_dropped: 0
  pid: 26970
  policy_reward_mean: {}
  time_since_restore: 964.220477104187
  time_this_iter_s: 55.82808041572571
  time_total_s: 964.220477104187
  timestamp: 1594185949
  timesteps_since_restore: 680000
  timesteps_this_iter: 40000
  timesteps_total: 680000
  training_iteration: 17
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26970], 964 s, 17 iter, 680000 ts, -3.62e+03 rew

agent-1: 9.0
agent-2: 14.0
agent-3: 0.0
agent-4: 18.0
agent-5: 27.0
agent-6: 23.0
agent-7: 3.0
agent-8: 10.0
agent-9: 7.0
agent-10: 2.0
agent-11: 25.0
agent-12: 18.0
agent-13: 18.0
agent-14: 31.0
agent-15: 19.0
agent-16: 13.0
agent-17: 8.0
agent-18: 16.0
agent-19: 26.0
agent-20: 7.0
agent-21: 23.0
agent-22: 6.0
agent-23: 15.0
agent-24: 30.0
agent-25: 8.0
agent-26: 35.0
agent-27: 8.0
agent-28: 2.0
agent-29: 23.0
agent-30: 26.0
agent-31: 29.0
agent-32: 16.0
agent-33: 21.0
agent-34: 9.0
agent-35: 2.0
agent-36: 11.0
agent-37: 9.0
agent-38: 13.0
agent-39: 19.0
agent-40: 31.0
Sum Reward: 630.0
Avg Reward: 15.75
Min Reward: 0.0
Max Reward: 35.0
Gini Coefficient: 0.33920634920634923
20:20 Ratio: 8.10344827586207
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-08_01-26-46
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1283.0
  episode_reward_mean: -3374.5882352941176
  episode_reward_min: -29997.0
  episodes_this_iter: 1
  episodes_total: 17
  experiment_id: 4e724eb5b3a34f42879644e84578eec0
  hostname: gpu024
  info:
    apply_time_ms: 2.787
    dispatch_time_ms: 6.489
    learner:
      cur_lr: 0.0013147119898349047
      grad_gnorm: 0.5261991620063782
      policy_entropy: 554.79833984375
      policy_loss: -0.052957773208618164
      var_gnorm: 20.569128036499023
      vf_explained_var: 0.996731162071228
      vf_loss: 0.0010942965745925903
    num_steps_sampled: 720000
    num_steps_trained: 720000
    wait_time_ms: 549.798
  iterations_since_restore: 18
  node_ip: 172.17.8.24
  num_metric_batches_dropped: 0
  pid: 26970
  policy_reward_mean: {}
  time_since_restore: 1021.0637555122375
  time_this_iter_s: 56.84327840805054
  time_total_s: 1021.0637555122375
  timestamp: 1594186006
  timesteps_since_restore: 720000
  timesteps_this_iter: 40000
  timesteps_total: 720000
  training_iteration: 18
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26970], 1021 s, 18 iter, 720000 ts, -3.37e+03 rew

agent-1: 11.0
agent-2: 12.0
agent-3: 12.0
agent-4: 13.0
agent-5: 17.0
agent-6: 5.0
agent-7: 2.0
agent-8: 11.0
agent-9: 21.0
agent-10: 23.0
agent-11: 9.0
agent-12: 15.0
agent-13: 18.0
agent-14: 25.0
agent-15: 26.0
agent-16: 13.0
agent-17: 16.0
agent-18: 23.0
agent-19: 22.0
agent-20: 8.0
agent-21: 15.0
agent-22: 31.0
agent-23: 15.0
agent-24: 25.0
agent-25: 10.0
agent-26: 0.0
agent-27: 14.0
agent-28: 1.0
agent-29: 11.0
agent-30: 16.0
agent-31: 9.0
agent-32: 6.0
agent-33: 11.0
agent-34: 22.0
agent-35: 20.0
agent-36: 25.0
agent-37: 18.0
agent-38: 8.0
agent-39: 12.0
agent-40: 4.0
Sum Reward: 575.0
Avg Reward: 14.375
Min Reward: 0.0
Max Reward: 31.0
Gini Coefficient: 0.29030434782608694
20:20 Ratio: 5.882352941176471
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-08_01-27-42
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1283.0
  episode_reward_mean: -3155.1666666666665
  episode_reward_min: -29997.0
  episodes_this_iter: 1
  episodes_total: 18
  experiment_id: 4e724eb5b3a34f42879644e84578eec0
  hostname: gpu024
  info:
    apply_time_ms: 2.71
    dispatch_time_ms: 9.238
    learner:
      cur_lr: 0.001312048058025539
      grad_gnorm: 3.5454792976379395
      policy_entropy: 525.0089111328125
      policy_loss: -3.2262187004089355
      var_gnorm: 20.785104751586914
      vf_explained_var: 0.2030106782913208
      vf_loss: 0.0019260726403445005
    num_steps_sampled: 760000
    num_steps_trained: 760000
    wait_time_ms: 565.989
  iterations_since_restore: 19
  node_ip: 172.17.8.24
  num_metric_batches_dropped: 0
  pid: 26970
  policy_reward_mean: {}
  time_since_restore: 1077.292483329773
  time_this_iter_s: 56.2287278175354
  time_total_s: 1077.292483329773
  timestamp: 1594186062
  timesteps_since_restore: 760000
  timesteps_this_iter: 40000
  timesteps_total: 760000
  training_iteration: 19
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26970], 1077 s, 19 iter, 760000 ts, -3.16e+03 rew

agent-1: 23.0
agent-2: 10.0
agent-3: 11.0
agent-4: 10.0
agent-5: 18.0
agent-6: 1.0
agent-7: 18.0
agent-8: 8.0
agent-9: 10.0
agent-10: 12.0
agent-11: 16.0
agent-12: 15.0
agent-13: 18.0
agent-14: 3.0
agent-15: 20.0
agent-16: 24.0
agent-17: 8.0
agent-18: 6.0
agent-19: 23.0
agent-20: 9.0
agent-21: 4.0
agent-22: 17.0
agent-23: 25.0
agent-24: 20.0
agent-25: 5.0
agent-26: 3.0
agent-27: 5.0
agent-28: 8.0
agent-29: 26.0
agent-30: 21.0
agent-31: 4.0
agent-32: 21.0
agent-33: 26.0
agent-34: 14.0
agent-35: 11.0
agent-36: 15.0
agent-37: 21.0
agent-38: 5.0
agent-39: 18.0
agent-40: 15.0
Sum Reward: 547.0
Avg Reward: 13.675
Min Reward: 1.0
Max Reward: 26.0
Gini Coefficient: 0.30388482632541136
20:20 Ratio: 6.3
Max-min Ratio: 26.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-08_01-28-39
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1283.0
  episode_reward_mean: -2960.315789473684
  episode_reward_min: -29997.0
  episodes_this_iter: 1
  episodes_total: 19
  experiment_id: 4e724eb5b3a34f42879644e84578eec0
  hostname: gpu024
  info:
    apply_time_ms: 2.66
    dispatch_time_ms: 7.95
    learner:
      cur_lr: 0.0013093840098008513
      grad_gnorm: 40.0
      policy_entropy: 512.94482421875
      policy_loss: 323.11749267578125
      var_gnorm: 20.791994094848633
      vf_explained_var: 0.43426787853240967
      vf_loss: 372.36053466796875
    num_steps_sampled: 800000
    num_steps_trained: 800000
    wait_time_ms: 540.309
  iterations_since_restore: 20
  node_ip: 172.17.8.24
  num_metric_batches_dropped: 0
  pid: 26970
  policy_reward_mean: {}
  time_since_restore: 1134.6610913276672
  time_this_iter_s: 57.36860799789429
  time_total_s: 1134.6610913276672
  timestamp: 1594186119
  timesteps_since_restore: 800000
  timesteps_this_iter: 40000
  timesteps_total: 800000
  training_iteration: 20
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 27.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26970], 1134 s, 20 iter, 800000 ts, -2.96e+03 rew

agent-1: 5.0
agent-2: 10.0
agent-3: 6.0
agent-4: 2.0
agent-5: 8.0
agent-6: 18.0
agent-7: 31.0
agent-8: 8.0
agent-9: 18.0
agent-10: 6.0
agent-11: 12.0
agent-12: 21.0
agent-13: 21.0
agent-14: 7.0
agent-15: 22.0
agent-16: 12.0
agent-17: 9.0
agent-18: 10.0
agent-19: 7.0
agent-20: 19.0
agent-21: 32.0
agent-22: 24.0
agent-23: 5.0
agent-24: 7.0
agent-25: 21.0
agent-26: 14.0
agent-27: 6.0
agent-28: 15.0
agent-29: 22.0
agent-30: 20.0
agent-31: 7.0
agent-32: 11.0
agent-33: 19.0
agent-34: 11.0
agent-35: 20.0
agent-36: 18.0
agent-37: 20.0
agent-38: 11.0
agent-39: 8.0
agent-40: 20.0
Sum Reward: 563.0
Avg Reward: 14.075
Min Reward: 2.0
Max Reward: 32.0
Gini Coefficient: 0.2895648312611012
20:20 Ratio: 4.409090909090909
Max-min Ratio: 16.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-08_01-29-35
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1283.0
  episode_reward_mean: -2784.15
  episode_reward_min: -29997.0
  episodes_this_iter: 1
  episodes_total: 20
  experiment_id: 4e724eb5b3a34f42879644e84578eec0
  hostname: gpu024
  info:
    apply_time_ms: 3.268
    dispatch_time_ms: 6.533
    learner:
      cur_lr: 0.0013067199615761638
      grad_gnorm: 0.9261603951454163
      policy_entropy: 367.43194580078125
      policy_loss: 3.214411973953247
      var_gnorm: 21.059463500976562
      vf_explained_var: 0.9959591627120972
      vf_loss: 7.523767271777615e-05
    num_steps_sampled: 840000
    num_steps_trained: 840000
    wait_time_ms: 545.22
  iterations_since_restore: 21
  node_ip: 172.17.8.24
  num_metric_batches_dropped: 0
  pid: 26970
  policy_reward_mean: {}
  time_since_restore: 1190.4742596149445
  time_this_iter_s: 55.81316828727722
  time_total_s: 1190.4742596149445
  timestamp: 1594186175
  timesteps_since_restore: 840000
  timesteps_this_iter: 40000
  timesteps_total: 840000
  training_iteration: 21
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26970], 1190 s, 21 iter, 840000 ts, -2.78e+03 rew

agent-1: 22.0
agent-2: 11.0
agent-3: 19.0
agent-4: 24.0
agent-5: 16.0
agent-6: 4.0
agent-7: 3.0
agent-8: 17.0
agent-9: 11.0
agent-10: 4.0
agent-11: 4.0
agent-12: 18.0
agent-13: 26.0
agent-14: 23.0
agent-15: 15.0
agent-16: 28.0
agent-17: 20.0
agent-18: 20.0
agent-19: 6.0
agent-20: 10.0
agent-21: 24.0
agent-22: 13.0
agent-23: 18.0
agent-24: 1.0
agent-25: 8.0
agent-26: 6.0
agent-27: 16.0
agent-28: 4.0
agent-29: 10.0
agent-30: 34.0
agent-31: 31.0
agent-32: 20.0
agent-33: 22.0
agent-34: 2.0
agent-35: 19.0
agent-36: 19.0
agent-37: 22.0
agent-38: 18.0
agent-39: 21.0
agent-40: 14.0
Sum Reward: 623.0
Avg Reward: 15.575
Min Reward: 1.0
Max Reward: 34.0
Gini Coefficient: 0.3018860353130016
20:20 Ratio: 7.571428571428571
Max-min Ratio: 34.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-08_01-30-32
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1283.0
  episode_reward_mean: -2621.904761904762
  episode_reward_min: -29997.0
  episodes_this_iter: 1
  episodes_total: 21
  experiment_id: 4e724eb5b3a34f42879644e84578eec0
  hostname: gpu024
  info:
    apply_time_ms: 2.858
    dispatch_time_ms: 6.344
    learner:
      cur_lr: 0.001304056029766798
      grad_gnorm: 40.00000762939453
      policy_entropy: 456.2933654785156
      policy_loss: 373.452392578125
      var_gnorm: 21.058271408081055
      vf_explained_var: 0.25118809938430786
      vf_loss: 586.822509765625
    num_steps_sampled: 880000
    num_steps_trained: 880000
    wait_time_ms: 543.515
  iterations_since_restore: 22
  node_ip: 172.17.8.24
  num_metric_batches_dropped: 0
  pid: 26970
  policy_reward_mean: {}
  time_since_restore: 1247.5171620845795
  time_this_iter_s: 57.04290246963501
  time_total_s: 1247.5171620845795
  timestamp: 1594186232
  timesteps_since_restore: 880000
  timesteps_this_iter: 40000
  timesteps_total: 880000
  training_iteration: 22
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26970], 1247 s, 22 iter, 880000 ts, -2.62e+03 rew

agent-1: 11.0
agent-2: 13.0
agent-3: 13.0
agent-4: 14.0
agent-5: 7.0
agent-6: 20.0
agent-7: 20.0
agent-8: 19.0
agent-9: 19.0
agent-10: 16.0
agent-11: 18.0
agent-12: 11.0
agent-13: 15.0
agent-14: 6.0
agent-15: 6.0
agent-16: 7.0
agent-17: 14.0
agent-18: 20.0
agent-19: 13.0
agent-20: 17.0
agent-21: 14.0
agent-22: 22.0
agent-23: 25.0
agent-24: 15.0
agent-25: 8.0
agent-26: 8.0
agent-27: 7.0
agent-28: 22.0
agent-29: 29.0
agent-30: 23.0
agent-31: 7.0
agent-32: 25.0
agent-33: 11.0
agent-34: 18.0
agent-35: 18.0
agent-36: 22.0
agent-37: 15.0
agent-38: 18.0
agent-39: 32.0
agent-40: 12.0
Sum Reward: 630.0
Avg Reward: 15.75
Min Reward: 6.0
Max Reward: 32.0
Gini Coefficient: 0.22722222222222221
20:20 Ratio: 3.5714285714285716
Max-min Ratio: 5.333333333333333
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-08_01-31-29
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1283.0
  episode_reward_mean: -2474.090909090909
  episode_reward_min: -29997.0
  episodes_this_iter: 1
  episodes_total: 22
  experiment_id: 4e724eb5b3a34f42879644e84578eec0
  hostname: gpu024
  info:
    apply_time_ms: 2.573
    dispatch_time_ms: 5.819
    learner:
      cur_lr: 0.0013013919815421104
      grad_gnorm: 3.70276141166687
      policy_entropy: 485.1246337890625
      policy_loss: -1.055443286895752
      var_gnorm: 21.337923049926758
      vf_explained_var: 0.9958511590957642
      vf_loss: 0.014494974166154861
    num_steps_sampled: 920000
    num_steps_trained: 920000
    wait_time_ms: 539.842
  iterations_since_restore: 23
  node_ip: 172.17.8.24
  num_metric_batches_dropped: 0
  pid: 26970
  policy_reward_mean: {}
  time_since_restore: 1303.6923282146454
  time_this_iter_s: 56.17516613006592
  time_total_s: 1303.6923282146454
  timestamp: 1594186289
  timesteps_since_restore: 920000
  timesteps_this_iter: 40000
  timesteps_total: 920000
  training_iteration: 23
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 29.3/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26970], 1303 s, 23 iter, 920000 ts, -2.47e+03 rew

agent-1: 17.0
agent-2: 10.0
agent-3: 21.0
agent-4: 11.0
agent-5: 25.0
agent-6: 19.0
agent-7: 23.0
agent-8: 17.0
agent-9: 0.0
agent-10: 14.0
agent-11: 7.0
agent-12: 2.0
agent-13: 9.0
agent-14: 12.0
agent-15: 24.0
agent-16: 12.0
agent-17: 7.0
agent-18: 26.0
agent-19: 22.0
agent-20: 11.0
agent-21: 6.0
agent-22: 9.0
agent-23: 17.0
agent-24: 11.0
agent-25: 15.0
agent-26: 17.0
agent-27: 11.0
agent-28: 14.0
agent-29: 18.0
agent-30: 13.0
agent-31: 10.0
agent-32: 16.0
agent-33: 26.0
agent-34: 16.0
agent-35: 20.0
agent-36: 17.0
agent-37: 15.0
agent-38: 8.0
agent-39: 11.0
agent-40: 22.0
Sum Reward: 581.0
Avg Reward: 14.525
Min Reward: 0.0
Max Reward: 26.0
Gini Coefficient: 0.24358864027538726
20:20 Ratio: 3.9375
Max-min Ratio: Undefined
agent-1: 24.0
agent-2: 13.0
agent-3: 17.0
agent-4: 7.0
agent-5: 15.0
agent-6: 16.0
agent-7: 13.0
agent-8: 24.0
agent-9: 9.0
agent-10: 14.0
agent-11: 14.0
agent-12: 16.0
agent-13: 15.0
agent-14: 26.0
agent-15: 30.0
agent-16: 21.0
agent-17: 9.0
agent-18: 13.0
agent-19: 28.0
agent-20: 19.0
agent-21: 13.0
agent-22: 1.0
agent-23: 11.0
agent-24: 10.0
agent-25: 11.0
agent-26: 8.0
agent-27: 6.0
agent-28: 6.0
agent-29: 6.0
agent-30: 27.0
agent-31: 12.0
agent-32: 18.0
agent-33: 15.0
agent-34: 13.0
agent-35: 18.0
agent-36: 4.0
agent-37: 25.0
agent-38: 21.0
agent-39: 3.0
agent-40: 12.0
Sum Reward: 583.0
Avg Reward: 14.575
Min Reward: 1.0
Max Reward: 30.0
Gini Coefficient: 0.2746569468267582
20:20 Ratio: 5.0
Max-min Ratio: 30.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-08_01-32-25
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1283.0
  episode_reward_mean: -2219.4166666666665
  episode_reward_min: -29997.0
  episodes_this_iter: 2
  episodes_total: 24
  experiment_id: 4e724eb5b3a34f42879644e84578eec0
  hostname: gpu024
  info:
    apply_time_ms: 3.265
    dispatch_time_ms: 7.166
    learner:
      cur_lr: 0.0012987280497327447
      grad_gnorm: 19.651819229125977
      policy_entropy: 612.653564453125
      policy_loss: 6.249490261077881
      var_gnorm: 21.343399047851562
      vf_explained_var: -1.0
      vf_loss: 2.434347152709961
    num_steps_sampled: 960000
    num_steps_trained: 960000
    wait_time_ms: 562.959
  iterations_since_restore: 24
  node_ip: 172.17.8.24
  num_metric_batches_dropped: 0
  pid: 26970
  policy_reward_mean: {}
  time_since_restore: 1360.3503212928772
  time_this_iter_s: 56.65799307823181
  time_total_s: 1360.3503212928772
  timestamp: 1594186345
  timesteps_since_restore: 960000
  timesteps_this_iter: 40000
  timesteps_total: 960000
  training_iteration: 24
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 29.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26970], 1360 s, 24 iter, 960000 ts, -2.22e+03 rew

Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-08_01-33-21
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1283.0
  episode_reward_mean: -2219.4166666666665
  episode_reward_min: -29997.0
  episodes_this_iter: 0
  episodes_total: 24
  experiment_id: 4e724eb5b3a34f42879644e84578eec0
  hostname: gpu024
  info:
    apply_time_ms: 3.042
    dispatch_time_ms: 6.211
    learner:
      cur_lr: 0.0012960640015080571
      grad_gnorm: 3.6612586975097656
      policy_entropy: 578.1182861328125
      policy_loss: -2.6921873092651367
      var_gnorm: 21.594932556152344
      vf_explained_var: 0.9414752721786499
      vf_loss: 0.0013174876803532243
    num_steps_sampled: 1000000
    num_steps_trained: 1000000
    wait_time_ms: 561.952
  iterations_since_restore: 25
  node_ip: 172.17.8.24
  num_metric_batches_dropped: 0
  pid: 26970
  policy_reward_mean: {}
  time_since_restore: 1416.3340468406677
  time_this_iter_s: 55.98372554779053
  time_total_s: 1416.3340468406677
  timestamp: 1594186401
  timesteps_since_restore: 1000000
  timesteps_this_iter: 40000
  timesteps_total: 1000000
  training_iteration: 25
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26970], 1416 s, 25 iter, 1000000 ts, -2.22e+03 rew

agent-1: 13.0
agent-2: 9.0
agent-3: 11.0
agent-4: 13.0
agent-5: 15.0
agent-6: 3.0
agent-7: 28.0
agent-8: 25.0
agent-9: 20.0
agent-10: 16.0
agent-11: 16.0
agent-12: 17.0
agent-13: 1.0
agent-14: 21.0
agent-15: 10.0
agent-16: -42.0
agent-17: 5.0
agent-18: 19.0
agent-19: 19.0
agent-20: 4.0
agent-21: 11.0
agent-22: 14.0
agent-23: 19.0
agent-24: 11.0
agent-25: 27.0
agent-26: 12.0
agent-27: 22.0
agent-28: 4.0
agent-29: 9.0
agent-30: 22.0
agent-31: 5.0
agent-32: 10.0
agent-33: 22.0
agent-34: 18.0
agent-35: 9.0
agent-36: 17.0
agent-37: 10.0
agent-38: 11.0
agent-39: 14.0
agent-40: 16.0
Sum Reward: 506.0
Avg Reward: 12.65
Min Reward: -42.0
Max Reward: 28.0
Gini Coefficient: 0.39021739130434785
20:20 Ratio: -17.0
Max-min Ratio: -0.6666666666666666
agent-1: 12.0
agent-2: 8.0
agent-3: 15.0
agent-4: 8.0
agent-5: 8.0
agent-6: 20.0
agent-7: 13.0
agent-8: 15.0
agent-9: 14.0
agent-10: 24.0
agent-11: 6.0
agent-12: 15.0
agent-13: 14.0
agent-14: 8.0
agent-15: 28.0
agent-16: 6.0
agent-17: 12.0
agent-18: 17.0
agent-19: 20.0
agent-20: 11.0
agent-21: 22.0
agent-22: 19.0
agent-23: 21.0
agent-24: 14.0
agent-25: 4.0
agent-26: 16.0
agent-27: 12.0
agent-28: 17.0
agent-29: 14.0
agent-30: 8.0
agent-31: 4.0
agent-32: 15.0
agent-33: 20.0
agent-34: 11.0
agent-35: 8.0
agent-36: 15.0
agent-37: 14.0
agent-38: 17.0
agent-39: 10.0
agent-40: 10.0
Sum Reward: 545.0
Avg Reward: 13.625
Min Reward: 4.0
Max Reward: 28.0
Gini Coefficient: 0.2238073394495413
20:20 Ratio: 3.3461538461538463
Max-min Ratio: 7.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-08_01-34-18
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1283.0
  episode_reward_mean: -2008.2692307692307
  episode_reward_min: -29997.0
  episodes_this_iter: 2
  episodes_total: 26
  experiment_id: 4e724eb5b3a34f42879644e84578eec0
  hostname: gpu024
  info:
    apply_time_ms: 2.692
    dispatch_time_ms: 6.782
    learner:
      cur_lr: 0.0012933999532833695
      grad_gnorm: 4.963066101074219
      policy_entropy: 629.2080688476562
      policy_loss: 2.742412805557251
      var_gnorm: 21.603776931762695
      vf_explained_var: -1.0
      vf_loss: 0.008533462882041931
    num_steps_sampled: 1040000
    num_steps_trained: 1040000
    wait_time_ms: 562.924
  iterations_since_restore: 26
  node_ip: 172.17.8.24
  num_metric_batches_dropped: 0
  pid: 26970
  policy_reward_mean: {}
  time_since_restore: 1473.4361157417297
  time_this_iter_s: 57.10206890106201
  time_total_s: 1473.4361157417297
  timestamp: 1594186458
  timesteps_since_restore: 1040000
  timesteps_this_iter: 40000
  timesteps_total: 1040000
  training_iteration: 26
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26970], 1473 s, 26 iter, 1040000 ts, -2.01e+03 rew

Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-08_01-35-15
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1283.0
  episode_reward_mean: -2008.2692307692307
  episode_reward_min: -29997.0
  episodes_this_iter: 0
  episodes_total: 26
  experiment_id: 4e724eb5b3a34f42879644e84578eec0
  hostname: gpu024
  info:
    apply_time_ms: 3.863
    dispatch_time_ms: 5.943
    learner:
      cur_lr: 0.0012907360214740038
      grad_gnorm: 1.6781545877456665
      policy_entropy: 625.5482177734375
      policy_loss: -0.10497227311134338
      var_gnorm: 21.728120803833008
      vf_explained_var: 0.9954203963279724
      vf_loss: 0.0011625514598563313
    num_steps_sampled: 1080000
    num_steps_trained: 1080000
    wait_time_ms: 559.844
  iterations_since_restore: 27
  node_ip: 172.17.8.24
  num_metric_batches_dropped: 0
  pid: 26970
  policy_reward_mean: {}
  time_since_restore: 1529.6709899902344
  time_this_iter_s: 56.23487424850464
  time_total_s: 1529.6709899902344
  timestamp: 1594186515
  timesteps_since_restore: 1080000
  timesteps_this_iter: 40000
  timesteps_total: 1080000
  training_iteration: 27
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26970], 1529 s, 27 iter, 1080000 ts, -2.01e+03 rew

agent-1: 13.0
agent-2: 3.0
agent-3: 12.0
agent-4: 11.0
agent-5: 15.0
agent-6: 13.0
agent-7: 14.0
agent-8: 16.0
agent-9: 5.0
agent-10: 9.0
agent-11: 15.0
agent-12: 22.0
agent-13: 22.0
agent-14: 17.0
agent-15: 13.0
agent-16: 13.0
agent-17: 15.0
agent-18: 17.0
agent-19: 8.0
agent-20: 15.0
agent-21: 22.0
agent-22: 14.0
agent-23: 9.0
agent-24: 17.0
agent-25: 19.0
agent-26: 15.0
agent-27: 12.0
agent-28: 5.0
agent-29: 20.0
agent-30: 5.0
agent-31: 27.0
agent-32: 10.0
agent-33: 16.0
agent-34: 2.0
agent-35: 8.0
agent-36: 4.0
agent-37: 4.0
agent-38: 16.0
agent-39: 9.0
agent-40: 18.0
Sum Reward: 520.0
Avg Reward: 13.0
Min Reward: 2.0
Max Reward: 27.0
Gini Coefficient: 0.2502884615384615
20:20 Ratio: 4.638888888888889
Max-min Ratio: 13.5
agent-1: 13.0
agent-2: 11.0
agent-3: 8.0
agent-4: 10.0
agent-5: 10.0
agent-6: 14.0
agent-7: 11.0
agent-8: 10.0
agent-9: 17.0
agent-10: 9.0
agent-11: 6.0
agent-12: 7.0
agent-13: 17.0
agent-14: 14.0
agent-15: 5.0
agent-16: 17.0
agent-17: 6.0
agent-18: 20.0
agent-19: 18.0
agent-20: 10.0
agent-21: 17.0
agent-22: 5.0
agent-23: 8.0
agent-24: 23.0
agent-25: 20.0
agent-26: 18.0
agent-27: 21.0
agent-28: 11.0
agent-29: 15.0
agent-30: 14.0
agent-31: 12.0
agent-32: 5.0
agent-33: 13.0
agent-34: 8.0
agent-35: 14.0
agent-36: 16.0
agent-37: 14.0
agent-38: 11.0
agent-39: 14.0
agent-40: 8.0
Sum Reward: 500.0
Avg Reward: 12.5
Min Reward: 5.0
Max Reward: 23.0
Gini Coefficient: 0.214
20:20 Ratio: 3.08
Max-min Ratio: 4.6
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-08_01-36-12
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1283.0
  episode_reward_mean: -1828.392857142857
  episode_reward_min: -29997.0
  episodes_this_iter: 2
  episodes_total: 28
  experiment_id: 4e724eb5b3a34f42879644e84578eec0
  hostname: gpu024
  info:
    apply_time_ms: 4.343
    dispatch_time_ms: 8.591
    learner:
      cur_lr: 0.0012880719732493162
      grad_gnorm: 1.624368667602539
      policy_entropy: 703.0731201171875
      policy_loss: -0.9291336536407471
      var_gnorm: 21.726428985595703
      vf_explained_var: -1.0
      vf_loss: 0.00035673496313393116
    num_steps_sampled: 1120000
    num_steps_trained: 1120000
    wait_time_ms: 560.8
  iterations_since_restore: 28
  node_ip: 172.17.8.24
  num_metric_batches_dropped: 0
  pid: 26970
  policy_reward_mean: {}
  time_since_restore: 1586.6202914714813
  time_this_iter_s: 56.94930148124695
  time_total_s: 1586.6202914714813
  timestamp: 1594186572
  timesteps_since_restore: 1120000
  timesteps_this_iter: 40000
  timesteps_total: 1120000
  training_iteration: 28
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.3/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26970], 1586 s, 28 iter, 1120000 ts, -1.83e+03 rew

Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-08_01-37-08
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1283.0
  episode_reward_mean: -1828.392857142857
  episode_reward_min: -29997.0
  episodes_this_iter: 0
  episodes_total: 28
  experiment_id: 4e724eb5b3a34f42879644e84578eec0
  hostname: gpu024
  info:
    apply_time_ms: 3.254
    dispatch_time_ms: 5.753
    learner:
      cur_lr: 0.0012854080414399505
      grad_gnorm: 4.110698223114014
      policy_entropy: 678.8245849609375
      policy_loss: -1.9397432804107666
      var_gnorm: 21.916181564331055
      vf_explained_var: 0.14646506309509277
      vf_loss: 0.002854759804904461
    num_steps_sampled: 1160000
    num_steps_trained: 1160000
    wait_time_ms: 558.973
  iterations_since_restore: 29
  node_ip: 172.17.8.24
  num_metric_batches_dropped: 0
  pid: 26970
  policy_reward_mean: {}
  time_since_restore: 1642.5315585136414
  time_this_iter_s: 55.911267042160034
  time_total_s: 1642.5315585136414
  timestamp: 1594186628
  timesteps_since_restore: 1160000
  timesteps_this_iter: 40000
  timesteps_total: 1160000
  training_iteration: 29
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.3/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26970], 1642 s, 29 iter, 1160000 ts, -1.83e+03 rew

agent-1: 13.0
agent-2: 32.0
agent-3: 14.0
agent-4: 24.0
agent-5: 11.0
agent-6: 14.0
agent-7: 12.0
agent-8: 19.0
agent-9: 14.0
agent-10: 12.0
agent-11: 3.0
agent-12: 28.0
agent-13: 12.0
agent-14: 6.0
agent-15: 21.0
agent-16: 26.0
agent-17: 5.0
agent-18: 17.0
agent-19: 3.0
agent-20: 25.0
agent-21: 16.0
agent-22: 17.0
agent-23: 9.0
agent-24: 22.0
agent-25: 13.0
agent-26: 18.0
agent-27: 16.0
agent-28: 15.0
agent-29: 21.0
agent-30: 7.0
agent-31: 15.0
agent-32: 9.0
agent-33: 28.0
agent-34: 14.0
agent-35: 4.0
agent-36: 7.0
agent-37: 16.0
agent-38: 4.0
agent-39: 4.0
agent-40: 13.0
Sum Reward: 579.0
Avg Reward: 14.475
Min Reward: 3.0
Max Reward: 32.0
Gini Coefficient: 0.28639896373056994
20:20 Ratio: 5.722222222222222
Max-min Ratio: 10.666666666666666
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-08_01-38-04
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1283.0
  episode_reward_mean: -1745.3793103448277
  episode_reward_min: -29997.0
  episodes_this_iter: 1
  episodes_total: 29
  experiment_id: 4e724eb5b3a34f42879644e84578eec0
  hostname: gpu024
  info:
    apply_time_ms: 2.679
    dispatch_time_ms: 6.837
    learner:
      cur_lr: 0.0012827439932152629
      grad_gnorm: 40.00000762939453
      policy_entropy: 521.5875244140625
      policy_loss: 219.74710083007812
      var_gnorm: 21.91797637939453
      vf_explained_var: 0.4795295000076294
      vf_loss: 302.58294677734375
    num_steps_sampled: 1200000
    num_steps_trained: 1200000
    wait_time_ms: 535.018
  iterations_since_restore: 30
  node_ip: 172.17.8.24
  num_metric_batches_dropped: 0
  pid: 26970
  policy_reward_mean: {}
  time_since_restore: 1699.259301662445
  time_this_iter_s: 56.72774314880371
  time_total_s: 1699.259301662445
  timestamp: 1594186684
  timesteps_since_restore: 1200000
  timesteps_this_iter: 40000
  timesteps_total: 1200000
  training_iteration: 30
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.3/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26970], 1699 s, 30 iter, 1200000 ts, -1.75e+03 rew

agent-1: 18.0
agent-2: 6.0
agent-3: 7.0
agent-4: 13.0
agent-5: 12.0
agent-6: 11.0
agent-7: 21.0
agent-8: 16.0
agent-9: 7.0
agent-10: 17.0
agent-11: 9.0
agent-12: 9.0
agent-13: 15.0
agent-14: 6.0
agent-15: 19.0
agent-16: 5.0
agent-17: 21.0
agent-18: 11.0
agent-19: 7.0
agent-20: 29.0
agent-21: 11.0
agent-22: 11.0
agent-23: 20.0
agent-24: 16.0
agent-25: 13.0
agent-26: 26.0
agent-27: 16.0
agent-28: 10.0
agent-29: 6.0
agent-30: 25.0
agent-31: 28.0
agent-32: 0.0
agent-33: 15.0
agent-34: 15.0
agent-35: 15.0
agent-36: 9.0
agent-37: 13.0
agent-38: 14.0
agent-39: 12.0
agent-40: 20.0
Sum Reward: 554.0
Avg Reward: 13.85
Min Reward: 0.0
Max Reward: 29.0
Gini Coefficient: 0.2611913357400722
20:20 Ratio: 4.318181818181818
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-08_01-39-00
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1283.0
  episode_reward_mean: -1668.7333333333333
  episode_reward_min: -29997.0
  episodes_this_iter: 1
  episodes_total: 30
  experiment_id: 4e724eb5b3a34f42879644e84578eec0
  hostname: gpu024
  info:
    apply_time_ms: 2.418
    dispatch_time_ms: 6.334
    learner:
      cur_lr: 0.0012800799449905753
      grad_gnorm: 8.954048156738281
      policy_entropy: 637.8344116210938
      policy_loss: -4.530034065246582
      var_gnorm: 22.120786666870117
      vf_explained_var: 0.9931889772415161
      vf_loss: 0.018188120797276497
    num_steps_sampled: 1240000
    num_steps_trained: 1240000
    wait_time_ms: 551.699
  iterations_since_restore: 31
  node_ip: 172.17.8.24
  num_metric_batches_dropped: 0
  pid: 26970
  policy_reward_mean: {}
  time_since_restore: 1754.743911743164
  time_this_iter_s: 55.484610080718994
  time_total_s: 1754.743911743164
  timestamp: 1594186740
  timesteps_since_restore: 1240000
  timesteps_this_iter: 40000
  timesteps_total: 1240000
  training_iteration: 31
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.3/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26970], 1754 s, 31 iter, 1240000 ts, -1.67e+03 rew

agent-1: 19.0
agent-2: 27.0
agent-3: 26.0
agent-4: 14.0
agent-5: 17.0
agent-6: 14.0
agent-7: 13.0
agent-8: 17.0
agent-9: 10.0
agent-10: 26.0
agent-11: 17.0
agent-12: 3.0
agent-13: 13.0
agent-14: 15.0
agent-15: 1.0
agent-16: 23.0
agent-17: 15.0
agent-18: 19.0
agent-19: 1.0
agent-20: 24.0
agent-21: 14.0
agent-22: 5.0
agent-23: 33.0
agent-24: 20.0
agent-25: 4.0
agent-26: 19.0
agent-27: 5.0
agent-28: 18.0
agent-29: 16.0
agent-30: 16.0
agent-31: 19.0
agent-32: 17.0
agent-33: 21.0
agent-34: 14.0
agent-35: 3.0
agent-36: 21.0
agent-37: 8.0
agent-38: 31.0
agent-39: 18.0
agent-40: 17.0
Sum Reward: 633.0
Avg Reward: 15.825
Min Reward: 1.0
Max Reward: 33.0
Gini Coefficient: 0.2698657187993681
20:20 Ratio: 7.033333333333333
Max-min Ratio: 33.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-08_01-39-57
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1283.0
  episode_reward_mean: -1594.483870967742
  episode_reward_min: -29997.0
  episodes_this_iter: 1
  episodes_total: 31
  experiment_id: 4e724eb5b3a34f42879644e84578eec0
  hostname: gpu024
  info:
    apply_time_ms: 2.843
    dispatch_time_ms: 7.029
    learner:
      cur_lr: 0.0012774160131812096
      grad_gnorm: 2.9880995750427246
      policy_entropy: 669.53076171875
      policy_loss: -2.2589001655578613
      var_gnorm: 22.157806396484375
      vf_explained_var: 0.9956616163253784
      vf_loss: 0.004225929733365774
    num_steps_sampled: 1280000
    num_steps_trained: 1280000
    wait_time_ms: 563.958
  iterations_since_restore: 32
  node_ip: 172.17.8.24
  num_metric_batches_dropped: 0
  pid: 26970
  policy_reward_mean: {}
  time_since_restore: 1811.5650250911713
  time_this_iter_s: 56.8211133480072
  time_total_s: 1811.5650250911713
  timestamp: 1594186797
  timesteps_since_restore: 1280000
  timesteps_this_iter: 40000
  timesteps_total: 1280000
  training_iteration: 32
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.3/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26970], 1811 s, 32 iter, 1280000 ts, -1.59e+03 rew

agent-1: -37.0
agent-2: 17.0
agent-3: 16.0
agent-4: 14.0
agent-5: 20.0
agent-6: 14.0
agent-7: 8.0
agent-8: 3.0
agent-9: 19.0
agent-10: 16.0
agent-11: 20.0
agent-12: 5.0
agent-13: 12.0
agent-14: 21.0
agent-15: 14.0
agent-16: 15.0
agent-17: 14.0
agent-18: 13.0
agent-19: 9.0
agent-20: 25.0
agent-21: 20.0
agent-22: 11.0
agent-23: 22.0
agent-24: 16.0
agent-25: 16.0
agent-26: 0.0
agent-27: 14.0
agent-28: 17.0
agent-29: 20.0
agent-30: 23.0
agent-31: 16.0
agent-32: 20.0
agent-33: 11.0
agent-34: 5.0
agent-35: 19.0
agent-36: 12.0
agent-37: 14.0
agent-38: 2.0
agent-39: 12.0
agent-40: 24.0
Sum Reward: 532.0
Avg Reward: 13.3
Min Reward: -37.0
Max Reward: 25.0
Gini Coefficient: 0.331015037593985
20:20 Ratio: -35.0
Max-min Ratio: -0.6756756756756757
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-08_01-40-53
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1283.0
  episode_reward_mean: -1528.03125
  episode_reward_min: -29997.0
  episodes_this_iter: 1
  episodes_total: 32
  experiment_id: 4e724eb5b3a34f42879644e84578eec0
  hostname: gpu024
  info:
    apply_time_ms: 2.614
    dispatch_time_ms: 5.802
    learner:
      cur_lr: 0.001274751964956522
      grad_gnorm: 5.6460065841674805
      policy_entropy: 626.8843994140625
      policy_loss: -3.6962733268737793
      var_gnorm: 22.388023376464844
      vf_explained_var: -1.0
      vf_loss: 0.01250828430056572
    num_steps_sampled: 1320000
    num_steps_trained: 1320000
    wait_time_ms: 563.46
  iterations_since_restore: 33
  node_ip: 172.17.8.24
  num_metric_batches_dropped: 0
  pid: 26970
  policy_reward_mean: {}
  time_since_restore: 1867.3609631061554
  time_this_iter_s: 55.79593801498413
  time_total_s: 1867.3609631061554
  timestamp: 1594186853
  timesteps_since_restore: 1320000
  timesteps_this_iter: 40000
  timesteps_total: 1320000
  training_iteration: 33
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.3/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26970], 1867 s, 33 iter, 1320000 ts, -1.53e+03 rew

agent-1: 17.0
agent-2: 16.0
agent-3: 13.0
agent-4: 19.0
agent-5: 11.0
agent-6: 4.0
agent-7: 21.0
agent-8: 27.0
agent-9: 16.0
agent-10: 31.0
agent-11: 15.0
agent-12: 24.0
agent-13: 24.0
agent-14: 12.0
agent-15: 6.0
agent-16: 15.0
agent-17: 9.0
agent-18: 12.0
agent-19: 10.0
agent-20: 12.0
agent-21: 18.0
agent-22: 13.0
agent-23: 8.0
agent-24: 8.0
agent-25: 19.0
agent-26: 6.0
agent-27: 15.0
agent-28: 8.0
agent-29: 12.0
agent-30: 16.0
agent-31: 11.0
agent-32: 10.0
agent-33: 16.0
agent-34: 3.0
agent-35: 11.0
agent-36: 17.0
agent-37: 15.0
agent-38: 6.0
agent-39: 21.0
agent-40: 7.0
Sum Reward: 554.0
Avg Reward: 13.85
Min Reward: 3.0
Max Reward: 31.0
Gini Coefficient: 0.2486462093862816
20:20 Ratio: 3.875
Max-min Ratio: 10.333333333333334
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-08_01-41-49
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1283.0
  episode_reward_mean: -1464.939393939394
  episode_reward_min: -29997.0
  episodes_this_iter: 1
  episodes_total: 33
  experiment_id: 4e724eb5b3a34f42879644e84578eec0
  hostname: gpu024
  info:
    apply_time_ms: 2.734
    dispatch_time_ms: 8.219
    learner:
      cur_lr: 0.0012720880331471562
      grad_gnorm: 39.99999237060547
      policy_entropy: 341.209228515625
      policy_loss: 220.88925170898438
      var_gnorm: 22.39238929748535
      vf_explained_var: 0.4898861050605774
      vf_loss: 461.2791442871094
    num_steps_sampled: 1360000
    num_steps_trained: 1360000
    wait_time_ms: 528.95
  iterations_since_restore: 34
  node_ip: 172.17.8.24
  num_metric_batches_dropped: 0
  pid: 26970
  policy_reward_mean: {}
  time_since_restore: 1923.7695257663727
  time_this_iter_s: 56.408562660217285
  time_total_s: 1923.7695257663727
  timestamp: 1594186909
  timesteps_since_restore: 1360000
  timesteps_this_iter: 40000
  timesteps_total: 1360000
  training_iteration: 34
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.3/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26970], 1923 s, 34 iter, 1360000 ts, -1.46e+03 rew

agent-1: 15.0
agent-2: 12.0
agent-3: 27.0
agent-4: 8.0
agent-5: 12.0
agent-6: 13.0
agent-7: 9.0
agent-8: 12.0
agent-9: 22.0
agent-10: 12.0
agent-11: 14.0
agent-12: 14.0
agent-13: 5.0
agent-14: 18.0
agent-15: 18.0
agent-16: 20.0
agent-17: 29.0
agent-18: 22.0
agent-19: 4.0
agent-20: 5.0
agent-21: 24.0
agent-22: 20.0
agent-23: 20.0
agent-24: 10.0
agent-25: 37.0
agent-26: 6.0
agent-27: 17.0
agent-28: 10.0
agent-29: 6.0
agent-30: 7.0
agent-31: 14.0
agent-32: 14.0
agent-33: 25.0
agent-34: 20.0
agent-35: 4.0
agent-36: 22.0
agent-37: 14.0
agent-38: 16.0
agent-39: 5.0
agent-40: 17.0
Sum Reward: 599.0
Avg Reward: 14.975
Min Reward: 4.0
Max Reward: 37.0
Gini Coefficient: 0.2780884808013356
20:20 Ratio: 4.9523809523809526
Max-min Ratio: 9.25
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-08_01-42-45
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1283.0
  episode_reward_mean: -1404.235294117647
  episode_reward_min: -29997.0
  episodes_this_iter: 1
  episodes_total: 34
  experiment_id: 4e724eb5b3a34f42879644e84578eec0
  hostname: gpu024
  info:
    apply_time_ms: 2.865
    dispatch_time_ms: 5.599
    learner:
      cur_lr: 0.0012694239849224687
      grad_gnorm: 7.581191539764404
      policy_entropy: 649.2608032226562
      policy_loss: 3.5271706581115723
      var_gnorm: 22.56423568725586
      vf_explained_var: 0.363053560256958
      vf_loss: 0.00967899989336729
    num_steps_sampled: 1400000
    num_steps_trained: 1400000
    wait_time_ms: 555.718
  iterations_since_restore: 35
  node_ip: 172.17.8.24
  num_metric_batches_dropped: 0
  pid: 26970
  policy_reward_mean: {}
  time_since_restore: 1979.530752658844
  time_this_iter_s: 55.76122689247131
  time_total_s: 1979.530752658844
  timestamp: 1594186965
  timesteps_since_restore: 1400000
  timesteps_this_iter: 40000
  timesteps_total: 1400000
  training_iteration: 35
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.3/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26970], 1979 s, 35 iter, 1400000 ts, -1.4e+03 rew

agent-1: 13.0
agent-2: 16.0
agent-3: 12.0
agent-4: 15.0
agent-5: 13.0
agent-6: 20.0
agent-7: 24.0
agent-8: 20.0
agent-9: 24.0
agent-10: 11.0
agent-11: 10.0
agent-12: 16.0
agent-13: 23.0
agent-14: 16.0
agent-15: 18.0
agent-16: 3.0
agent-17: 11.0
agent-18: 10.0
agent-19: 3.0
agent-20: 8.0
agent-21: 12.0
agent-22: 12.0
agent-23: 14.0
agent-24: 11.0
agent-25: 16.0
agent-26: 8.0
agent-27: 9.0
agent-28: 19.0
agent-29: 11.0
agent-30: 22.0
agent-31: 6.0
agent-32: 24.0
agent-33: 12.0
agent-34: 14.0
agent-35: 10.0
agent-36: 17.0
agent-37: 22.0
agent-38: 16.0
agent-39: 8.0
agent-40: 7.0
Sum Reward: 556.0
Avg Reward: 13.9
Min Reward: 3.0
Max Reward: 24.0
Gini Coefficient: 0.2272482014388489
20:20 Ratio: 3.4423076923076925
Max-min Ratio: 8.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-08_01-43-41
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1283.0
  episode_reward_mean: -1348.2285714285715
  episode_reward_min: -29997.0
  episodes_this_iter: 1
  episodes_total: 35
  experiment_id: 4e724eb5b3a34f42879644e84578eec0
  hostname: gpu024
  info:
    apply_time_ms: 3.874
    dispatch_time_ms: 6.784
    learner:
      cur_lr: 0.001266760053113103
      grad_gnorm: 40.000003814697266
      policy_entropy: 353.10858154296875
      policy_loss: 242.61721801757812
      var_gnorm: 22.563190460205078
      vf_explained_var: 0.41691720485687256
      vf_loss: 506.3191223144531
    num_steps_sampled: 1440000
    num_steps_trained: 1440000
    wait_time_ms: 530.768
  iterations_since_restore: 36
  node_ip: 172.17.8.24
  num_metric_batches_dropped: 0
  pid: 26970
  policy_reward_mean: {}
  time_since_restore: 2035.9349131584167
  time_this_iter_s: 56.404160499572754
  time_total_s: 2035.9349131584167
  timestamp: 1594187021
  timesteps_since_restore: 1440000
  timesteps_this_iter: 40000
  timesteps_total: 1440000
  training_iteration: 36
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.3/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26970], 2035 s, 36 iter, 1440000 ts, -1.35e+03 rew

agent-1: 15.0
agent-2: 14.0
agent-3: 14.0
agent-4: 1.0
agent-5: 12.0
agent-6: 6.0
agent-7: 13.0
agent-8: 5.0
agent-9: 1.0
agent-10: 10.0
agent-11: 15.0
agent-12: 13.0
agent-13: 7.0
agent-14: 11.0
agent-15: 13.0
agent-16: 15.0
agent-17: 18.0
agent-18: 15.0
agent-19: 25.0
agent-20: 21.0
agent-21: 18.0
agent-22: 13.0
agent-23: 13.0
agent-24: 9.0
agent-25: 10.0
agent-26: 20.0
agent-27: 10.0
agent-28: 9.0
agent-29: 18.0
agent-30: 18.0
agent-31: 10.0
agent-32: 10.0
agent-33: 23.0
agent-34: 29.0
agent-35: 10.0
agent-36: 10.0
agent-37: 12.0
agent-38: 19.0
agent-39: 14.0
agent-40: 16.0
Sum Reward: 535.0
Avg Reward: 13.375
Min Reward: 1.0
Max Reward: 29.0
Gini Coefficient: 0.23425233644859814
20:20 Ratio: 3.6041666666666665
Max-min Ratio: 29.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-08_01-44-37
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1283.0
  episode_reward_mean: -1295.9166666666667
  episode_reward_min: -29997.0
  episodes_this_iter: 1
  episodes_total: 36
  experiment_id: 4e724eb5b3a34f42879644e84578eec0
  hostname: gpu024
  info:
    apply_time_ms: 2.474
    dispatch_time_ms: 6.821
    learner:
      cur_lr: 0.0012640960048884153
      grad_gnorm: 2.1656970977783203
      policy_entropy: 624.6183471679688
      policy_loss: -3.0854549407958984
      var_gnorm: 22.673538208007812
      vf_explained_var: -1.0
      vf_loss: 0.0038230139762163162
    num_steps_sampled: 1480000
    num_steps_trained: 1480000
    wait_time_ms: 571.215
  iterations_since_restore: 37
  node_ip: 172.17.8.24
  num_metric_batches_dropped: 0
  pid: 26970
  policy_reward_mean: {}
  time_since_restore: 2091.585419654846
  time_this_iter_s: 55.65050649642944
  time_total_s: 2091.585419654846
  timestamp: 1594187077
  timesteps_since_restore: 1480000
  timesteps_this_iter: 40000
  timesteps_total: 1480000
  training_iteration: 37
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.3/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26970], 2091 s, 37 iter, 1480000 ts, -1.3e+03 rew

agent-1: 9.0
agent-2: 8.0
agent-3: 1.0
agent-4: 9.0
agent-5: 11.0
agent-6: 8.0
agent-7: 7.0
agent-8: 12.0
agent-9: 23.0
agent-10: 14.0
agent-11: 11.0
agent-12: 14.0
agent-13: 22.0
agent-14: 14.0
agent-15: 17.0
agent-16: 12.0
agent-17: 13.0
agent-18: 20.0
agent-19: 13.0
agent-20: 27.0
agent-21: 14.0
agent-22: 11.0
agent-23: 9.0
agent-24: 16.0
agent-25: 14.0
agent-26: 8.0
agent-27: 24.0
agent-28: 7.0
agent-29: 18.0
agent-30: 25.0
agent-31: 15.0
agent-32: 18.0
agent-33: 17.0
agent-34: 12.0
agent-35: 30.0
agent-36: 18.0
agent-37: 28.0
agent-38: 13.0
agent-39: 17.0
agent-40: 18.0
Sum Reward: 597.0
Avg Reward: 14.925
Min Reward: 1.0
Max Reward: 30.0
Gini Coefficient: 0.2333752093802345
20:20 Ratio: 3.491228070175439
Max-min Ratio: 30.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-08_01-45-34
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1283.0
  episode_reward_mean: -1244.7567567567567
  episode_reward_min: -29997.0
  episodes_this_iter: 1
  episodes_total: 37
  experiment_id: 4e724eb5b3a34f42879644e84578eec0
  hostname: gpu024
  info:
    apply_time_ms: 3.544
    dispatch_time_ms: 5.634
    learner:
      cur_lr: 0.0012614319566637278
      grad_gnorm: 40.000003814697266
      policy_entropy: 417.681884765625
      policy_loss: 322.0576171875
      var_gnorm: 22.705608367919922
      vf_explained_var: 0.5959863662719727
      vf_loss: 503.6598205566406
    num_steps_sampled: 1520000
    num_steps_trained: 1520000
    wait_time_ms: 548.585
  iterations_since_restore: 38
  node_ip: 172.17.8.24
  num_metric_batches_dropped: 0
  pid: 26970
  policy_reward_mean: {}
  time_since_restore: 2148.5123419761658
  time_this_iter_s: 56.92692232131958
  time_total_s: 2148.5123419761658
  timestamp: 1594187134
  timesteps_since_restore: 1520000
  timesteps_this_iter: 40000
  timesteps_total: 1520000
  training_iteration: 38
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.3/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26970], 2148 s, 38 iter, 1520000 ts, -1.24e+03 rew

agent-1: 21.0
agent-2: 7.0
agent-3: 11.0
agent-4: 26.0
agent-5: 24.0
agent-6: 20.0
agent-7: 8.0
agent-8: 3.0
agent-9: 21.0
agent-10: 16.0
agent-11: 7.0
agent-12: 21.0
agent-13: 15.0
agent-14: 10.0
agent-15: 10.0
agent-16: 17.0
agent-17: 12.0
agent-18: 6.0
agent-19: 11.0
agent-20: 10.0
agent-21: 19.0
agent-22: 2.0
agent-23: 12.0
agent-24: 18.0
agent-25: 11.0
agent-26: 5.0
agent-27: 15.0
agent-28: 19.0
agent-29: 15.0
agent-30: 8.0
agent-31: 26.0
agent-32: 12.0
agent-33: 10.0
agent-34: 16.0
agent-35: 15.0
agent-36: 12.0
agent-37: 14.0
agent-38: 30.0
agent-39: 16.0
agent-40: 17.0
Sum Reward: 568.0
Avg Reward: 14.2
Min Reward: 2.0
Max Reward: 30.0
Gini Coefficient: 0.2518485915492958
20:20 Ratio: 4.108695652173913
Max-min Ratio: 15.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-08_01-46-29
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1283.0
  episode_reward_mean: -1197.0526315789473
  episode_reward_min: -29997.0
  episodes_this_iter: 1
  episodes_total: 38
  experiment_id: 4e724eb5b3a34f42879644e84578eec0
  hostname: gpu024
  info:
    apply_time_ms: 2.718
    dispatch_time_ms: 5.672
    learner:
      cur_lr: 0.001258768024854362
      grad_gnorm: 2.3308520317077637
      policy_entropy: 699.75146484375
      policy_loss: -3.0673110485076904
      var_gnorm: 22.94561195373535
      vf_explained_var: -1.0
      vf_loss: 0.0060301246121525764
    num_steps_sampled: 1560000
    num_steps_trained: 1560000
    wait_time_ms: 553.783
  iterations_since_restore: 39
  node_ip: 172.17.8.24
  num_metric_batches_dropped: 0
  pid: 26970
  policy_reward_mean: {}
  time_since_restore: 2204.026892185211
  time_this_iter_s: 55.51455020904541
  time_total_s: 2204.026892185211
  timestamp: 1594187189
  timesteps_since_restore: 1560000
  timesteps_this_iter: 40000
  timesteps_total: 1560000
  training_iteration: 39
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.3/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26970], 2204 s, 39 iter, 1560000 ts, -1.2e+03 rew

agent-1: 1.0
agent-2: 11.0
agent-3: 22.0
agent-4: 16.0
agent-5: 20.0
agent-6: 8.0
agent-7: 14.0
agent-8: 5.0
agent-9: 13.0
agent-10: 23.0
agent-11: 3.0
agent-12: 20.0
agent-13: 8.0
agent-14: 21.0
agent-15: 16.0
agent-16: 12.0
agent-17: 9.0
agent-18: 5.0
agent-19: 15.0
agent-20: 25.0
agent-21: 13.0
agent-22: 22.0
agent-23: 12.0
agent-24: 17.0
agent-25: 19.0
agent-26: 12.0
agent-27: 12.0
agent-28: 25.0
agent-29: 11.0
agent-30: 7.0
agent-31: 16.0
agent-32: 16.0
agent-33: 8.0
agent-34: 14.0
agent-35: 7.0
agent-36: 11.0
agent-37: 16.0
agent-38: 7.0
agent-39: 7.0
agent-40: 14.0
Sum Reward: 533.0
Avg Reward: 13.325
Min Reward: 1.0
Max Reward: 25.0
Gini Coefficient: 0.25576923076923075
20:20 Ratio: 4.238095238095238
Max-min Ratio: 25.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-08_01-47-26
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1283.0
  episode_reward_mean: -1152.6923076923076
  episode_reward_min: -29997.0
  episodes_this_iter: 1
  episodes_total: 39
  experiment_id: 4e724eb5b3a34f42879644e84578eec0
  hostname: gpu024
  info:
    apply_time_ms: 3.198
    dispatch_time_ms: 6.096
    learner:
      cur_lr: 0.0012561039766296744
      grad_gnorm: 0.9912552237510681
      policy_entropy: 728.586181640625
      policy_loss: 0.4354727566242218
      var_gnorm: 22.94538688659668
      vf_explained_var: 0.8789561986923218
      vf_loss: 0.00013116086483933032
    num_steps_sampled: 1600000
    num_steps_trained: 1600000
    wait_time_ms: 561.546
  iterations_since_restore: 40
  node_ip: 172.17.8.24
  num_metric_batches_dropped: 0
  pid: 26970
  policy_reward_mean: {}
  time_since_restore: 2260.792263031006
  time_this_iter_s: 56.76537084579468
  time_total_s: 2260.792263031006
  timestamp: 1594187246
  timesteps_since_restore: 1600000
  timesteps_this_iter: 40000
  timesteps_total: 1600000
  training_iteration: 40
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.3/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26970], 2260 s, 40 iter, 1600000 ts, -1.15e+03 rew

agent-1: 8.0
agent-2: 16.0
agent-3: 16.0
agent-4: 5.0
agent-5: 12.0
agent-6: 20.0
agent-7: 14.0
agent-8: 16.0
agent-9: 4.0
agent-10: 15.0
agent-11: 24.0
agent-12: 23.0
agent-13: 0.0
agent-14: 14.0
agent-15: 11.0
agent-16: 15.0
agent-17: 19.0
agent-18: 19.0
agent-19: 19.0
agent-20: 19.0
agent-21: 14.0
agent-22: 6.0
agent-23: 12.0
agent-24: 5.0
agent-25: 5.0
agent-26: 16.0
agent-27: 25.0
agent-28: 12.0
agent-29: 13.0
agent-30: 24.0
agent-31: 3.0
agent-32: 10.0
agent-33: 21.0
agent-34: 11.0
agent-35: 19.0
agent-36: 18.0
agent-37: 17.0
agent-38: 17.0
agent-39: 18.0
agent-40: 8.0
Sum Reward: 563.0
Avg Reward: 14.075
Min Reward: 0.0
Max Reward: 25.0
Gini Coefficient: 0.24791296625222026
20:20 Ratio: 4.861111111111111
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-08_01-48-22
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1283.0
  episode_reward_mean: -1109.8
  episode_reward_min: -29997.0
  episodes_this_iter: 1
  episodes_total: 40
  experiment_id: 4e724eb5b3a34f42879644e84578eec0
  hostname: gpu024
  info:
    apply_time_ms: 2.696
    dispatch_time_ms: 6.37
    learner:
      cur_lr: 0.0012534400448203087
      grad_gnorm: 5.859245777130127
      policy_entropy: 555.9327392578125
      policy_loss: -1.311819076538086
      var_gnorm: 23.28215217590332
      vf_explained_var: 0.37156927585601807
      vf_loss: 0.005648476537317038
    num_steps_sampled: 1640000
    num_steps_trained: 1640000
    wait_time_ms: 566.411
  iterations_since_restore: 41
  node_ip: 172.17.8.24
  num_metric_batches_dropped: 0
  pid: 26970
  policy_reward_mean: {}
  time_since_restore: 2316.7985191345215
  time_this_iter_s: 56.006256103515625
  time_total_s: 2316.7985191345215
  timestamp: 1594187302
  timesteps_since_restore: 1640000
  timesteps_this_iter: 40000
  timesteps_total: 1640000
  training_iteration: 41
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.3/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26970], 2316 s, 41 iter, 1640000 ts, -1.11e+03 rew

agent-1: 7.0
agent-2: 11.0
agent-3: 14.0
agent-4: 6.0
agent-5: 10.0
agent-6: 19.0
agent-7: 17.0
agent-8: 25.0
agent-9: 11.0
agent-10: 33.0
agent-11: 18.0
agent-12: 1.0
agent-13: 24.0
agent-14: 11.0
agent-15: 7.0
agent-16: 13.0
agent-17: 18.0
agent-18: 15.0
agent-19: 9.0
agent-20: 13.0
agent-21: 17.0
agent-22: 10.0
agent-23: 26.0
agent-24: 22.0
agent-25: 7.0
agent-26: 14.0
agent-27: 11.0
agent-28: 22.0
agent-29: 23.0
agent-30: 6.0
agent-31: 15.0
agent-32: 26.0
agent-33: 21.0
agent-34: 26.0
agent-35: 11.0
agent-36: 17.0
agent-37: -42.0
agent-38: 19.0
agent-39: 11.0
agent-40: 19.0
Sum Reward: 563.0
Avg Reward: 14.075
Min Reward: -42.0
Max Reward: 33.0
Gini Coefficient: 0.3644316163410302
20:20 Ratio: 205.0
Max-min Ratio: -0.7857142857142857
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-08_01-49-19
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1283.0
  episode_reward_mean: -1069.0
  episode_reward_min: -29997.0
  episodes_this_iter: 1
  episodes_total: 41
  experiment_id: 4e724eb5b3a34f42879644e84578eec0
  hostname: gpu024
  info:
    apply_time_ms: 2.562
    dispatch_time_ms: 7.538
    learner:
      cur_lr: 0.0012507759965956211
      grad_gnorm: 40.0
      policy_entropy: 237.75604248046875
      policy_loss: 226.93731689453125
      var_gnorm: 23.291109085083008
      vf_explained_var: 0.350972056388855
      vf_loss: 510.78179931640625
    num_steps_sampled: 1680000
    num_steps_trained: 1680000
    wait_time_ms: 521.044
  iterations_since_restore: 42
  node_ip: 172.17.8.24
  num_metric_batches_dropped: 0
  pid: 26970
  policy_reward_mean: {}
  time_since_restore: 2373.015275001526
  time_this_iter_s: 56.216755867004395
  time_total_s: 2373.015275001526
  timestamp: 1594187359
  timesteps_since_restore: 1680000
  timesteps_this_iter: 40000
  timesteps_total: 1680000
  training_iteration: 42
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.3/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26970], 2373 s, 42 iter, 1680000 ts, -1.07e+03 rew

agent-1: 7.0
agent-2: 14.0
agent-3: 13.0
agent-4: 13.0
agent-5: 13.0
agent-6: 16.0
agent-7: 10.0
agent-8: 16.0
agent-9: 16.0
agent-10: 10.0
agent-11: 7.0
agent-12: 5.0
agent-13: 34.0
agent-14: 12.0
agent-15: 29.0
agent-16: 16.0
agent-17: 9.0
agent-18: 17.0
agent-19: 19.0
agent-20: 18.0
agent-21: 15.0
agent-22: 8.0
agent-23: 11.0
agent-24: 11.0
agent-25: 16.0
agent-26: 8.0
agent-27: 19.0
agent-28: 7.0
agent-29: 25.0
agent-30: 13.0
agent-31: 11.0
agent-32: 3.0
agent-33: 9.0
agent-34: 18.0
agent-35: 25.0
agent-36: 22.0
agent-37: 14.0
agent-38: 16.0
agent-39: 9.0
agent-40: 16.0
Sum Reward: 570.0
Avg Reward: 14.25
Min Reward: 3.0
Max Reward: 34.0
Gini Coefficient: 0.24052631578947367
20:20 Ratio: 3.537037037037037
Max-min Ratio: 11.333333333333334
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-08_01-50-14
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1283.0
  episode_reward_mean: -1029.9761904761904
  episode_reward_min: -29997.0
  episodes_this_iter: 1
  episodes_total: 42
  experiment_id: 4e724eb5b3a34f42879644e84578eec0
  hostname: gpu024
  info:
    apply_time_ms: 2.902
    dispatch_time_ms: 6.484
    learner:
      cur_lr: 0.0012481119483709335
      grad_gnorm: 40.0
      policy_entropy: 694.9362182617188
      policy_loss: 18.727859497070312
      var_gnorm: 23.610315322875977
      vf_explained_var: 0.32658499479293823
      vf_loss: 33.292518615722656
    num_steps_sampled: 1720000
    num_steps_trained: 1720000
    wait_time_ms: 543.771
  iterations_since_restore: 43
  node_ip: 172.17.8.24
  num_metric_batches_dropped: 0
  pid: 26970
  policy_reward_mean: {}
  time_since_restore: 2428.830752134323
  time_this_iter_s: 55.81547713279724
  time_total_s: 2428.830752134323
  timestamp: 1594187414
  timesteps_since_restore: 1720000
  timesteps_this_iter: 40000
  timesteps_total: 1720000
  training_iteration: 43
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.3/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26970], 2428 s, 43 iter, 1720000 ts, -1.03e+03 rew

agent-1: 4.0
agent-2: 23.0
agent-3: 16.0
agent-4: 24.0
agent-5: 12.0
agent-6: 15.0
agent-7: 16.0
agent-8: 20.0
agent-9: 13.0
agent-10: 19.0
agent-11: 12.0
agent-12: 8.0
agent-13: 13.0
agent-14: 7.0
agent-15: 10.0
agent-16: 28.0
agent-17: 15.0
agent-18: 13.0
agent-19: 11.0
agent-20: 29.0
agent-21: 8.0
agent-22: 21.0
agent-23: 19.0
agent-24: 9.0
agent-25: 15.0
agent-26: 19.0
agent-27: 14.0
agent-28: 14.0
agent-29: 8.0
agent-30: 20.0
agent-31: 7.0
agent-32: 8.0
agent-33: 20.0
agent-34: 20.0
agent-35: 15.0
agent-36: 22.0
agent-37: 25.0
agent-38: 16.0
agent-39: 20.0
agent-40: 10.0
Sum Reward: 618.0
Avg Reward: 15.45
Min Reward: 4.0
Max Reward: 29.0
Gini Coefficient: 0.22063106796116505
20:20 Ratio: 3.2542372881355934
Max-min Ratio: 7.25
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-08_01-51-11
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1283.0
  episode_reward_mean: -991.6511627906976
  episode_reward_min: -29997.0
  episodes_this_iter: 1
  episodes_total: 43
  experiment_id: 4e724eb5b3a34f42879644e84578eec0
  hostname: gpu024
  info:
    apply_time_ms: 4.385
    dispatch_time_ms: 7.122
    learner:
      cur_lr: 0.0012454480165615678
      grad_gnorm: 39.99999237060547
      policy_entropy: 394.12066650390625
      policy_loss: 185.3339385986328
      var_gnorm: 23.636016845703125
      vf_explained_var: 0.4338063597679138
      vf_loss: 412.8428039550781
    num_steps_sampled: 1760000
    num_steps_trained: 1760000
    wait_time_ms: 523.552
  iterations_since_restore: 44
  node_ip: 172.17.8.24
  num_metric_batches_dropped: 0
  pid: 26970
  policy_reward_mean: {}
  time_since_restore: 2485.121992111206
  time_this_iter_s: 56.291239976882935
  time_total_s: 2485.121992111206
  timestamp: 1594187471
  timesteps_since_restore: 1760000
  timesteps_this_iter: 40000
  timesteps_total: 1760000
  training_iteration: 44
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.3/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26970], 2485 s, 44 iter, 1760000 ts, -992 rew

agent-1: 20.0
agent-2: 19.0
agent-3: 21.0
agent-4: 13.0
agent-5: 11.0
agent-6: 22.0
agent-7: 23.0
agent-8: 15.0
agent-9: 13.0
agent-10: 35.0
agent-11: 13.0
agent-12: 8.0
agent-13: 27.0
agent-14: 11.0
agent-15: 7.0
agent-16: 8.0
agent-17: 18.0
agent-18: 11.0
agent-19: 10.0
agent-20: 0.0
agent-21: 31.0
agent-22: 22.0
agent-23: 18.0
agent-24: 10.0
agent-25: 14.0
agent-26: 13.0
agent-27: 11.0
agent-28: 5.0
agent-29: 8.0
agent-30: 3.0
agent-31: 15.0
agent-32: 17.0
agent-33: 15.0
agent-34: 11.0
agent-35: 12.0
agent-36: 22.0
agent-37: 18.0
agent-38: 22.0
agent-39: 11.0
agent-40: 5.0
Sum Reward: 588.0
Avg Reward: 14.7
Min Reward: 0.0
Max Reward: 35.0
Gini Coefficient: 0.2733843537414966
20:20 Ratio: 4.636363636363637
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-08_01-52-07
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1283.0
  episode_reward_mean: -955.75
  episode_reward_min: -29997.0
  episodes_this_iter: 1
  episodes_total: 44
  experiment_id: 4e724eb5b3a34f42879644e84578eec0
  hostname: gpu024
  info:
    apply_time_ms: 2.632
    dispatch_time_ms: 6.611
    learner:
      cur_lr: 0.0012427839683368802
      grad_gnorm: 4.612599849700928
      policy_entropy: 664.485107421875
      policy_loss: 2.806906223297119
      var_gnorm: 23.90210723876953
      vf_explained_var: 0.9952285885810852
      vf_loss: 0.007552311755716801
    num_steps_sampled: 1800000
    num_steps_trained: 1800000
    wait_time_ms: 569.916
  iterations_since_restore: 45
  node_ip: 172.17.8.24
  num_metric_batches_dropped: 0
  pid: 26970
  policy_reward_mean: {}
  time_since_restore: 2541.61501121521
  time_this_iter_s: 56.493019104003906
  time_total_s: 2541.61501121521
  timestamp: 1594187527
  timesteps_since_restore: 1800000
  timesteps_this_iter: 40000
  timesteps_total: 1800000
  training_iteration: 45
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.3/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26970], 2541 s, 45 iter, 1800000 ts, -956 rew

agent-1: 1.0
agent-2: 10.0
agent-3: 12.0
agent-4: 18.0
agent-5: 13.0
agent-6: 18.0
agent-7: 11.0
agent-8: 13.0
agent-9: 8.0
agent-10: 19.0
agent-11: 23.0
agent-12: 3.0
agent-13: 7.0
agent-14: 7.0
agent-15: 20.0
agent-16: 12.0
agent-17: 9.0
agent-18: 19.0
agent-19: 17.0
agent-20: 12.0
agent-21: 14.0
agent-22: 5.0
agent-23: 17.0
agent-24: 1.0
agent-25: 14.0
agent-26: 20.0
agent-27: 2.0
agent-28: 25.0
agent-29: 18.0
agent-30: 11.0
agent-31: 19.0
agent-32: 14.0
agent-33: 14.0
agent-34: 16.0
agent-35: 7.0
agent-36: 19.0
agent-37: 10.0
agent-38: 17.0
agent-39: 12.0
agent-40: 10.0
Sum Reward: 517.0
Avg Reward: 12.925
Min Reward: 1.0
Max Reward: 25.0
Gini Coefficient: 0.2573984526112186
20:20 Ratio: 4.96969696969697
Max-min Ratio: 25.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-08_01-53-04
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1283.0
  episode_reward_mean: -923.0222222222222
  episode_reward_min: -29997.0
  episodes_this_iter: 1
  episodes_total: 45
  experiment_id: 4e724eb5b3a34f42879644e84578eec0
  hostname: gpu024
  info:
    apply_time_ms: 3.018
    dispatch_time_ms: 6.124
    learner:
      cur_lr: 0.0012401200365275145
      grad_gnorm: 40.0
      policy_entropy: 431.232177734375
      policy_loss: 257.7080993652344
      var_gnorm: 23.90882682800293
      vf_explained_var: 0.5643972754478455
      vf_loss: 315.5701904296875
    num_steps_sampled: 1840000
    num_steps_trained: 1840000
    wait_time_ms: 539.976
  iterations_since_restore: 46
  node_ip: 172.17.8.24
  num_metric_batches_dropped: 0
  pid: 26970
  policy_reward_mean: {}
  time_since_restore: 2598.107941865921
  time_this_iter_s: 56.49293065071106
  time_total_s: 2598.107941865921
  timestamp: 1594187584
  timesteps_since_restore: 1840000
  timesteps_this_iter: 40000
  timesteps_total: 1840000
  training_iteration: 46
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.3/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26970], 2598 s, 46 iter, 1840000 ts, -923 rew

agent-1: 11.0
agent-2: 10.0
agent-3: 1.0
agent-4: 13.0
agent-5: 30.0
agent-6: 7.0
agent-7: 7.0
agent-8: 8.0
agent-9: 9.0
agent-10: 14.0
agent-11: 14.0
agent-12: 20.0
agent-13: 13.0
agent-14: 14.0
agent-15: 22.0
agent-16: 20.0
agent-17: 14.0
agent-18: 6.0
agent-19: 14.0
agent-20: 15.0
agent-21: 9.0
agent-22: 17.0
agent-23: 13.0
agent-24: 21.0
agent-25: 5.0
agent-26: 5.0
agent-27: 19.0
agent-28: 10.0
agent-29: 16.0
agent-30: 17.0
agent-31: 31.0
agent-32: 19.0
agent-33: 14.0
agent-34: 21.0
agent-35: 12.0
agent-36: 12.0
agent-37: 5.0
agent-38: 14.0
agent-39: 3.0
agent-40: 18.0
Sum Reward: 543.0
Avg Reward: 13.575
Min Reward: 1.0
Max Reward: 31.0
Gini Coefficient: 0.26496316758747696
20:20 Ratio: 4.717948717948718
Max-min Ratio: 31.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-08_01-54-00
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1283.0
  episode_reward_mean: -891.1521739130435
  episode_reward_min: -29997.0
  episodes_this_iter: 1
  episodes_total: 46
  experiment_id: 4e724eb5b3a34f42879644e84578eec0
  hostname: gpu024
  info:
    apply_time_ms: 2.58
    dispatch_time_ms: 6.664
    learner:
      cur_lr: 0.0012374559883028269
      grad_gnorm: 0.6953811645507812
      policy_entropy: 672.4013671875
      policy_loss: 0.13284505903720856
      var_gnorm: 24.185346603393555
      vf_explained_var: 0.2526863217353821
      vf_loss: 0.001430662116035819
    num_steps_sampled: 1880000
    num_steps_trained: 1880000
    wait_time_ms: 551.73
  iterations_since_restore: 47
  node_ip: 172.17.8.24
  num_metric_batches_dropped: 0
  pid: 26970
  policy_reward_mean: {}
  time_since_restore: 2654.2548694610596
  time_this_iter_s: 56.14692759513855
  time_total_s: 2654.2548694610596
  timestamp: 1594187640
  timesteps_since_restore: 1880000
  timesteps_this_iter: 40000
  timesteps_total: 1880000
  training_iteration: 47
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.3/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26970], 2654 s, 47 iter, 1880000 ts, -891 rew

agent-1: 18.0
agent-2: 5.0
agent-3: 18.0
agent-4: 16.0
agent-5: 21.0
agent-6: 16.0
agent-7: 6.0
agent-8: 8.0
agent-9: 8.0
agent-10: 22.0
agent-11: 9.0
agent-12: 10.0
agent-13: 20.0
agent-14: 15.0
agent-15: 19.0
agent-16: 7.0
agent-17: 8.0
agent-18: 15.0
agent-19: 10.0
agent-20: 21.0
agent-21: 11.0
agent-22: 11.0
agent-23: 14.0
agent-24: 21.0
agent-25: 9.0
agent-26: 17.0
agent-27: 13.0
agent-28: 17.0
agent-29: 13.0
agent-30: 7.0
agent-31: 12.0
agent-32: 13.0
agent-33: 15.0
agent-34: 18.0
agent-35: 7.0
agent-36: 13.0
agent-37: 7.0
agent-38: 11.0
agent-39: 14.0
agent-40: 9.0
Sum Reward: 524.0
Avg Reward: 13.1
Min Reward: 5.0
Max Reward: 22.0
Gini Coefficient: 0.20877862595419847
20:20 Ratio: 2.909090909090909
Max-min Ratio: 4.4
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-08_01-54-56
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1283.0
  episode_reward_mean: -861.0425531914893
  episode_reward_min: -29997.0
  episodes_this_iter: 1
  episodes_total: 47
  experiment_id: 4e724eb5b3a34f42879644e84578eec0
  hostname: gpu024
  info:
    apply_time_ms: 2.788
    dispatch_time_ms: 8.004
    learner:
      cur_lr: 0.0012347920564934611
      grad_gnorm: 40.0000114440918
      policy_entropy: 404.5848693847656
      policy_loss: 220.214599609375
      var_gnorm: 24.1827335357666
      vf_explained_var: 0.5767653584480286
      vf_loss: 433.9718017578125
    num_steps_sampled: 1920000
    num_steps_trained: 1920000
    wait_time_ms: 506.207
  iterations_since_restore: 48
  node_ip: 172.17.8.24
  num_metric_batches_dropped: 0
  pid: 26970
  policy_reward_mean: {}
  time_since_restore: 2710.600212097168
  time_this_iter_s: 56.3453426361084
  time_total_s: 2710.600212097168
  timestamp: 1594187696
  timesteps_since_restore: 1920000
  timesteps_this_iter: 40000
  timesteps_total: 1920000
  training_iteration: 48
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.3/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26970], 2710 s, 48 iter, 1920000 ts, -861 rew

agent-1: 15.0
agent-2: 7.0
agent-3: 14.0
agent-4: 21.0
agent-5: 12.0
agent-6: 0.0
agent-7: 18.0
agent-8: 16.0
agent-9: 10.0
agent-10: 20.0
agent-11: 1.0
agent-12: 16.0
agent-13: 2.0
agent-14: 7.0
agent-15: 16.0
agent-16: 10.0
agent-17: 19.0
agent-18: 19.0
agent-19: 15.0
agent-20: 21.0
agent-21: 6.0
agent-22: 13.0
agent-23: 18.0
agent-24: 4.0
agent-25: 8.0
agent-26: 14.0
agent-27: 22.0
agent-28: 22.0
agent-29: 17.0
agent-30: 10.0
agent-31: 9.0
agent-32: 9.0
agent-33: 23.0
agent-34: 13.0
agent-35: 20.0
agent-36: 27.0
agent-37: 5.0
agent-38: 23.0
agent-39: 8.0
agent-40: 10.0
Sum Reward: 540.0
Avg Reward: 13.5
Min Reward: 0.0
Max Reward: 27.0
Gini Coefficient: 0.28175925925925926
20:20 Ratio: 5.59375
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-08_01-55-53
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1283.0
  episode_reward_mean: -831.8541666666666
  episode_reward_min: -29997.0
  episodes_this_iter: 1
  episodes_total: 48
  experiment_id: 4e724eb5b3a34f42879644e84578eec0
  hostname: gpu024
  info:
    apply_time_ms: 2.905
    dispatch_time_ms: 6.623
    learner:
      cur_lr: 0.0012321280082687736
      grad_gnorm: 2.6103262901306152
      policy_entropy: 647.5132446289062
      policy_loss: -1.6500244140625
      var_gnorm: 24.30525016784668
      vf_explained_var: -1.0
      vf_loss: 0.0034047183580696583
    num_steps_sampled: 1960000
    num_steps_trained: 1960000
    wait_time_ms: 559.475
  iterations_since_restore: 49
  node_ip: 172.17.8.24
  num_metric_batches_dropped: 0
  pid: 26970
  policy_reward_mean: {}
  time_since_restore: 2766.7526500225067
  time_this_iter_s: 56.152437925338745
  time_total_s: 2766.7526500225067
  timestamp: 1594187753
  timesteps_since_restore: 1960000
  timesteps_this_iter: 40000
  timesteps_total: 1960000
  training_iteration: 49
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.3/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26970], 2766 s, 49 iter, 1960000 ts, -832 rew

agent-1: 9.0
agent-2: 17.0
agent-3: 9.0
agent-4: 16.0
agent-5: 7.0
agent-6: 7.0
agent-7: 13.0
agent-8: 9.0
agent-9: 7.0
agent-10: 23.0
agent-11: 19.0
agent-12: 11.0
agent-13: 22.0
agent-14: 3.0
agent-15: 14.0
agent-16: 14.0
agent-17: 13.0
agent-18: 21.0
agent-19: 25.0
agent-20: 16.0
agent-21: 13.0
agent-22: 10.0
agent-23: 16.0
agent-24: 2.0
agent-25: 7.0
agent-26: 22.0
agent-27: 14.0
agent-28: 1.0
agent-29: 9.0
agent-30: 0.0
agent-31: 13.0
agent-32: 15.0
agent-33: 17.0
agent-34: 17.0
agent-35: 12.0
agent-36: 12.0
agent-37: 12.0
agent-38: 12.0
agent-39: 12.0
agent-40: 11.0
Sum Reward: 502.0
Avg Reward: 12.55
Min Reward: 0.0
Max Reward: 25.0
Gini Coefficient: 0.2580677290836653
20:20 Ratio: 4.882352941176471
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-08_01-56-49
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1283.0
  episode_reward_mean: -804.6326530612245
  episode_reward_min: -29997.0
  episodes_this_iter: 1
  episodes_total: 49
  experiment_id: 4e724eb5b3a34f42879644e84578eec0
  hostname: gpu024
  info:
    apply_time_ms: 2.439
    dispatch_time_ms: 5.384
    learner:
      cur_lr: 0.001229463960044086
      grad_gnorm: 1.9811094999313354
      policy_entropy: 713.9949951171875
      policy_loss: 2.3903093338012695
      var_gnorm: 24.311399459838867
      vf_explained_var: 0.952937662601471
      vf_loss: 0.0022506057284772396
    num_steps_sampled: 2000000
    num_steps_trained: 2000000
    wait_time_ms: 554.978
  iterations_since_restore: 50
  node_ip: 172.17.8.24
  num_metric_batches_dropped: 0
  pid: 26970
  policy_reward_mean: {}
  time_since_restore: 2823.582733631134
  time_this_iter_s: 56.83008360862732
  time_total_s: 2823.582733631134
  timestamp: 1594187809
  timesteps_since_restore: 2000000
  timesteps_this_iter: 40000
  timesteps_total: 2000000
  training_iteration: 50
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.3/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26970], 2823 s, 50 iter, 2000000 ts, -805 rew

agent-1: 7.0
agent-2: 3.0
agent-3: 17.0
agent-4: 8.0
agent-5: 7.0
agent-6: 20.0
agent-7: 7.0
agent-8: 11.0
agent-9: 13.0
agent-10: 12.0
agent-11: 10.0
agent-12: 4.0
agent-13: 14.0
agent-14: 8.0
agent-15: 7.0
agent-16: 20.0
agent-17: 17.0
agent-18: 12.0
agent-19: 11.0
agent-20: 13.0
agent-21: 23.0
agent-22: 12.0
agent-23: 8.0
agent-24: 18.0
agent-25: 9.0
agent-26: 18.0
agent-27: 22.0
agent-28: 20.0
agent-29: 10.0
agent-30: 10.0
agent-31: 18.0
agent-32: 7.0
agent-33: 29.0
agent-34: 12.0
agent-35: 20.0
agent-36: 9.0
agent-37: 13.0
agent-38: 12.0
agent-39: 10.0
agent-40: 6.0
Sum Reward: 507.0
Avg Reward: 12.675
Min Reward: 3.0
Max Reward: 29.0
Gini Coefficient: 0.2492603550295858
20:20 Ratio: 3.5833333333333335
Max-min Ratio: 9.666666666666666
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-08_01-57-46
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1283.0
  episode_reward_mean: -778.4
  episode_reward_min: -29997.0
  episodes_this_iter: 1
  episodes_total: 50
  experiment_id: 4e724eb5b3a34f42879644e84578eec0
  hostname: gpu024
  info:
    apply_time_ms: 2.564
    dispatch_time_ms: 7.26
    learner:
      cur_lr: 0.0012268000282347202
      grad_gnorm: 3.111353635787964
      policy_entropy: 707.9953002929688
      policy_loss: -1.8398727178573608
      var_gnorm: 24.59539031982422
      vf_explained_var: -1.0
      vf_loss: 0.025953415781259537
    num_steps_sampled: 2040000
    num_steps_trained: 2040000
    wait_time_ms: 557.882
  iterations_since_restore: 51
  node_ip: 172.17.8.24
  num_metric_batches_dropped: 0
  pid: 26970
  policy_reward_mean: {}
  time_since_restore: 2879.6304688453674
  time_this_iter_s: 56.0477352142334
  time_total_s: 2879.6304688453674
  timestamp: 1594187866
  timesteps_since_restore: 2040000
  timesteps_this_iter: 40000
  timesteps_total: 2040000
  training_iteration: 51
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.3/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26970], 2879 s, 51 iter, 2040000 ts, -778 rew

agent-1: 9.0
agent-2: 14.0
agent-3: 11.0
agent-4: 13.0
agent-5: 19.0
agent-6: 4.0
agent-7: 23.0
agent-8: 11.0
agent-9: 21.0
agent-10: 14.0
agent-11: 14.0
agent-12: 16.0
agent-13: 9.0
agent-14: 4.0
agent-15: 11.0
agent-16: 17.0
agent-17: 23.0
agent-18: 22.0
agent-19: 7.0
agent-20: 13.0
agent-21: 13.0
agent-22: 16.0
agent-23: 10.0
agent-24: 20.0
agent-25: 16.0
agent-26: 2.0
agent-27: 13.0
agent-28: 14.0
agent-29: 8.0
agent-30: 10.0
agent-31: 26.0
agent-32: 7.0
agent-33: 5.0
agent-34: 15.0
agent-35: 9.0
agent-36: 3.0
agent-37: 8.0
agent-38: 17.0
agent-39: 5.0
agent-40: 17.0
Sum Reward: 509.0
Avg Reward: 12.725
Min Reward: 2.0
Max Reward: 26.0
Gini Coefficient: 0.2635068762278978
20:20 Ratio: 4.621621621621622
Max-min Ratio: 13.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-08_01-58-42
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1283.0
  episode_reward_mean: -753.156862745098
  episode_reward_min: -29997.0
  episodes_this_iter: 1
  episodes_total: 51
  experiment_id: 4e724eb5b3a34f42879644e84578eec0
  hostname: gpu024
  info:
    apply_time_ms: 3.477
    dispatch_time_ms: 5.943
    learner:
      cur_lr: 0.0012241359800100327
      grad_gnorm: 7.600056171417236
      policy_entropy: 746.181884765625
      policy_loss: 2.6523869037628174
      var_gnorm: 24.603933334350586
      vf_explained_var: 0.1088862419128418
      vf_loss: 0.009176107123494148
    num_steps_sampled: 2080000
    num_steps_trained: 2080000
    wait_time_ms: 528.551
  iterations_since_restore: 52
  node_ip: 172.17.8.24
  num_metric_batches_dropped: 0
  pid: 26970
  policy_reward_mean: {}
  time_since_restore: 2936.27472114563
  time_this_iter_s: 56.64425230026245
  time_total_s: 2936.27472114563
  timestamp: 1594187922
  timesteps_since_restore: 2080000
  timesteps_this_iter: 40000
  timesteps_total: 2080000
  training_iteration: 52
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.3/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26970], 2936 s, 52 iter, 2080000 ts, -753 rew

agent-1: 10.0
agent-2: 6.0
agent-3: 18.0
agent-4: 13.0
agent-5: 16.0
agent-6: 15.0
agent-7: 9.0
agent-8: 14.0
agent-9: 21.0
agent-10: 14.0
agent-11: 12.0
agent-12: 14.0
agent-13: 17.0
agent-14: 7.0
agent-15: 9.0
agent-16: 2.0
agent-17: 13.0
agent-18: 11.0
agent-19: 8.0
agent-20: 2.0
agent-21: 12.0
agent-22: 9.0
agent-23: 16.0
agent-24: 8.0
agent-25: 16.0
agent-26: 13.0
agent-27: 15.0
agent-28: 10.0
agent-29: 23.0
agent-30: 2.0
agent-31: 12.0
agent-32: -38.0
agent-33: 17.0
agent-34: 5.0
agent-35: 19.0
agent-36: 11.0
agent-37: 11.0
agent-38: 14.0
agent-39: 21.0
agent-40: 2.0
Sum Reward: 429.0
Avg Reward: 10.725
Min Reward: -38.0
Max Reward: 23.0
Gini Coefficient: 0.37686480186480187
20:20 Ratio: -12.666666666666666
Max-min Ratio: -0.6052631578947368
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-08_01-59-38
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1283.0
  episode_reward_mean: -730.4230769230769
  episode_reward_min: -29997.0
  episodes_this_iter: 1
  episodes_total: 52
  experiment_id: 4e724eb5b3a34f42879644e84578eec0
  hostname: gpu024
  info:
    apply_time_ms: 2.577
    dispatch_time_ms: 6.216
    learner:
      cur_lr: 0.001221472048200667
      grad_gnorm: 2.3955366611480713
      policy_entropy: 702.166015625
      policy_loss: 2.247657537460327
      var_gnorm: 25.154333114624023
      vf_explained_var: -1.0
      vf_loss: 0.0036545293405652046
    num_steps_sampled: 2120000
    num_steps_trained: 2120000
    wait_time_ms: 554.189
  iterations_since_restore: 53
  node_ip: 172.17.8.24
  num_metric_batches_dropped: 0
  pid: 26970
  policy_reward_mean: {}
  time_since_restore: 2992.373190879822
  time_this_iter_s: 56.098469734191895
  time_total_s: 2992.373190879822
  timestamp: 1594187978
  timesteps_since_restore: 2120000
  timesteps_this_iter: 40000
  timesteps_total: 2120000
  training_iteration: 53
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.3/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26970], 2992 s, 53 iter, 2120000 ts, -730 rew

agent-1: 7.0
agent-2: 16.0
agent-3: 12.0
agent-4: 9.0
agent-5: 11.0
agent-6: 5.0
agent-7: 15.0
agent-8: 27.0
agent-9: 14.0
agent-10: 10.0
agent-11: 14.0
agent-12: 5.0
agent-13: 7.0
agent-14: 16.0
agent-15: 12.0
agent-16: 7.0
agent-17: 10.0
agent-18: 15.0
agent-19: 16.0
agent-20: 21.0
agent-21: 11.0
agent-22: 8.0
agent-23: 8.0
agent-24: 17.0
agent-25: 13.0
agent-26: 11.0
agent-27: 18.0
agent-28: 17.0
agent-29: 18.0
agent-30: 9.0
agent-31: 10.0
agent-32: 12.0
agent-33: 11.0
agent-34: 17.0
agent-35: 13.0
agent-36: 16.0
agent-37: 13.0
agent-38: 13.0
agent-39: 15.0
agent-40: 19.0
Sum Reward: 518.0
Avg Reward: 12.95
Min Reward: 5.0
Max Reward: 27.0
Gini Coefficient: 0.19237451737451738
20:20 Ratio: 2.75
Max-min Ratio: 5.4
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-08_02-00-35
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1283.0
  episode_reward_mean: -706.8679245283018
  episode_reward_min: -29997.0
  episodes_this_iter: 1
  episodes_total: 53
  experiment_id: 4e724eb5b3a34f42879644e84578eec0
  hostname: gpu024
  info:
    apply_time_ms: 2.79
    dispatch_time_ms: 6.483
    learner:
      cur_lr: 0.0012188079999759793
      grad_gnorm: 39.99999237060547
      policy_entropy: 266.6826477050781
      policy_loss: 122.13243103027344
      var_gnorm: 25.185161590576172
      vf_explained_var: 0.21701645851135254
      vf_loss: 380.1573791503906
    num_steps_sampled: 2160000
    num_steps_trained: 2160000
    wait_time_ms: 533.53
  iterations_since_restore: 54
  node_ip: 172.17.8.24
  num_metric_batches_dropped: 0
  pid: 26970
  policy_reward_mean: {}
  time_since_restore: 3049.4151515960693
  time_this_iter_s: 57.04196071624756
  time_total_s: 3049.4151515960693
  timestamp: 1594188035
  timesteps_since_restore: 2160000
  timesteps_this_iter: 40000
  timesteps_total: 2160000
  training_iteration: 54
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.3/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26970], 3049 s, 54 iter, 2160000 ts, -707 rew

agent-1: 4.0
agent-2: 11.0
agent-3: 6.0
agent-4: 8.0
agent-5: 19.0
agent-6: 9.0
agent-7: 21.0
agent-8: 12.0
agent-9: 11.0
agent-10: 17.0
agent-11: 10.0
agent-12: 10.0
agent-13: 8.0
agent-14: 23.0
agent-15: 11.0
agent-16: 16.0
agent-17: 5.0
agent-18: 3.0
agent-19: 13.0
agent-20: 18.0
agent-21: 27.0
agent-22: 5.0
agent-23: 8.0
agent-24: 16.0
agent-25: 14.0
agent-26: 13.0
agent-27: 10.0
agent-28: 17.0
agent-29: 10.0
agent-30: 15.0
agent-31: 10.0
agent-32: 17.0
agent-33: 12.0
agent-34: 15.0
agent-35: 17.0
agent-36: 21.0
agent-37: 12.0
agent-38: 6.0
agent-39: 12.0
agent-40: 13.0
Sum Reward: 505.0
Avg Reward: 12.625
Min Reward: 3.0
Max Reward: 27.0
Gini Coefficient: 0.23579207920792078
20:20 Ratio: 3.6222222222222222
Max-min Ratio: 9.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-08_02-01-31
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1283.0
  episode_reward_mean: -684.425925925926
  episode_reward_min: -29997.0
  episodes_this_iter: 1
  episodes_total: 54
  experiment_id: 4e724eb5b3a34f42879644e84578eec0
  hostname: gpu024
  info:
    apply_time_ms: 2.603
    dispatch_time_ms: 5.702
    learner:
      cur_lr: 0.0012161439517512918
      grad_gnorm: 1.4731059074401855
      policy_entropy: 702.537109375
      policy_loss: -1.1193621158599854
      var_gnorm: 25.459535598754883
      vf_explained_var: -0.1671379804611206
      vf_loss: 0.00031090452102944255
    num_steps_sampled: 2200000
    num_steps_trained: 2200000
    wait_time_ms: 557.907
  iterations_since_restore: 55
  node_ip: 172.17.8.24
  num_metric_batches_dropped: 0
  pid: 26970
  policy_reward_mean: {}
  time_since_restore: 3105.4538934230804
  time_this_iter_s: 56.03874182701111
  time_total_s: 3105.4538934230804
  timestamp: 1594188091
  timesteps_since_restore: 2200000
  timesteps_this_iter: 40000
  timesteps_total: 2200000
  training_iteration: 55
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.3/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26970], 3105 s, 55 iter, 2200000 ts, -684 rew

agent-1: 14.0
agent-2: 13.0
agent-3: 12.0
agent-4: 20.0
agent-5: 16.0
agent-6: 15.0
agent-7: 11.0
agent-8: 13.0
agent-9: 14.0
agent-10: 7.0
agent-11: 11.0
agent-12: 2.0
agent-13: 18.0
agent-14: 11.0
agent-15: 12.0
agent-16: 4.0
agent-17: 12.0
agent-18: 10.0
agent-19: 17.0
agent-20: 7.0
agent-21: 11.0
agent-22: 6.0
agent-23: 15.0
agent-24: 10.0
agent-25: 3.0
agent-26: 9.0
agent-27: 14.0
agent-28: 13.0
agent-29: 15.0
agent-30: 4.0
agent-31: 19.0
agent-32: 17.0
agent-33: 5.0
agent-34: 18.0
agent-35: 9.0
agent-36: 13.0
agent-37: 11.0
agent-38: 21.0
agent-39: 8.0
agent-40: 19.0
Sum Reward: 479.0
Avg Reward: 11.975
Min Reward: 2.0
Max Reward: 21.0
Gini Coefficient: 0.22687891440501043
20:20 Ratio: 3.9210526315789473
Max-min Ratio: 10.5
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-08_02-02-28
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1283.0
  episode_reward_mean: -663.2727272727273
  episode_reward_min: -29997.0
  episodes_this_iter: 1
  episodes_total: 55
  experiment_id: 4e724eb5b3a34f42879644e84578eec0
  hostname: gpu024
  info:
    apply_time_ms: 2.522
    dispatch_time_ms: 7.838
    learner:
      cur_lr: 0.001213480019941926
      grad_gnorm: 3.7221038341522217
      policy_entropy: 758.0807495117188
      policy_loss: -0.2933683395385742
      var_gnorm: 25.45516586303711
      vf_explained_var: 0.00038814544677734375
      vf_loss: 0.0023339916951954365
    num_steps_sampled: 2240000
    num_steps_trained: 2240000
    wait_time_ms: 571.518
  iterations_since_restore: 56
  node_ip: 172.17.8.24
  num_metric_batches_dropped: 0
  pid: 26970
  policy_reward_mean: {}
  time_since_restore: 3161.9365713596344
  time_this_iter_s: 56.482677936553955
  time_total_s: 3161.9365713596344
  timestamp: 1594188148
  timesteps_since_restore: 2240000
  timesteps_this_iter: 40000
  timesteps_total: 2240000
  training_iteration: 56
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.3/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26970], 3161 s, 56 iter, 2240000 ts, -663 rew

agent-1: 8.0
agent-2: 12.0
agent-3: 11.0
agent-4: 13.0
agent-5: 16.0
agent-6: 18.0
agent-7: 7.0
agent-8: 8.0
agent-9: 14.0
agent-10: 14.0
agent-11: 16.0
agent-12: 8.0
agent-13: 19.0
agent-14: 2.0
agent-15: 16.0
agent-16: 18.0
agent-17: 1.0
agent-18: 11.0
agent-19: 1.0
agent-20: 5.0
agent-21: 15.0
agent-22: 14.0
agent-23: 17.0
agent-24: 14.0
agent-25: 7.0
agent-26: 16.0
agent-27: 20.0
agent-28: 3.0
agent-29: 18.0
agent-30: 18.0
agent-31: 23.0
agent-32: 8.0
agent-33: 3.0
agent-34: 3.0
agent-35: 14.0
agent-36: 14.0
agent-37: 13.0
agent-38: 19.0
agent-39: 5.0
agent-40: 11.0
Sum Reward: 473.0
Avg Reward: 11.825
Min Reward: 1.0
Max Reward: 23.0
Gini Coefficient: 0.2786997885835095
20:20 Ratio: 6.6521739130434785
Max-min Ratio: 23.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-08_02-03-24
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1283.0
  episode_reward_mean: -642.9821428571429
  episode_reward_min: -29997.0
  episodes_this_iter: 1
  episodes_total: 56
  experiment_id: 4e724eb5b3a34f42879644e84578eec0
  hostname: gpu024
  info:
    apply_time_ms: 2.507
    dispatch_time_ms: 6.513
    learner:
      cur_lr: 0.0012108159717172384
      grad_gnorm: 0.9532543420791626
      policy_entropy: 770.2628173828125
      policy_loss: 0.11534157395362854
      var_gnorm: 25.63807487487793
      vf_explained_var: 0.08902347087860107
      vf_loss: 0.00014793479931540787
    num_steps_sampled: 2280000
    num_steps_trained: 2280000
    wait_time_ms: 555.761
  iterations_since_restore: 57
  node_ip: 172.17.8.24
  num_metric_batches_dropped: 0
  pid: 26970
  policy_reward_mean: {}
  time_since_restore: 3218.350294828415
  time_this_iter_s: 56.41372346878052
  time_total_s: 3218.350294828415
  timestamp: 1594188204
  timesteps_since_restore: 2280000
  timesteps_this_iter: 40000
  timesteps_total: 2280000
  training_iteration: 57
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.3/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26970], 3218 s, 57 iter, 2280000 ts, -643 rew

agent-1: 6.0
agent-2: 18.0
agent-3: 20.0
agent-4: 11.0
agent-5: 15.0
agent-6: 11.0
agent-7: 16.0
agent-8: 7.0
agent-9: 6.0
agent-10: 5.0
agent-11: 14.0
agent-12: 21.0
agent-13: 13.0
agent-14: 8.0
agent-15: 15.0
agent-16: 14.0
agent-17: 23.0
agent-18: 4.0
agent-19: 14.0
agent-20: 23.0
agent-21: 13.0
agent-22: 9.0
agent-23: 8.0
agent-24: 13.0
agent-25: 3.0
agent-26: 18.0
agent-27: 17.0
agent-28: 18.0
agent-29: 15.0
agent-30: 7.0
agent-31: 12.0
agent-32: 5.0
agent-33: 14.0
agent-34: 11.0
agent-35: 1.0
agent-36: 12.0
agent-37: 16.0
agent-38: 11.0
agent-39: 17.0
agent-40: 11.0
Sum Reward: 495.0
Avg Reward: 12.375
Min Reward: 1.0
Max Reward: 23.0
Gini Coefficient: 0.246010101010101
20:20 Ratio: 4.27027027027027
Max-min Ratio: 23.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-08_02-04-21
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1283.0
  episode_reward_mean: -623.0175438596491
  episode_reward_min: -29997.0
  episodes_this_iter: 1
  episodes_total: 57
  experiment_id: 4e724eb5b3a34f42879644e84578eec0
  hostname: gpu024
  info:
    apply_time_ms: 2.729
    dispatch_time_ms: 7.318
    learner:
      cur_lr: 0.0012081520399078727
      grad_gnorm: 39.999996185302734
      policy_entropy: 275.548828125
      policy_loss: 73.3184814453125
      var_gnorm: 25.639345169067383
      vf_explained_var: 0.3509678244590759
      vf_loss: 213.5989990234375
    num_steps_sampled: 2320000
    num_steps_trained: 2320000
    wait_time_ms: 495.956
  iterations_since_restore: 58
  node_ip: 172.17.8.24
  num_metric_batches_dropped: 0
  pid: 26970
  policy_reward_mean: {}
  time_since_restore: 3274.633152961731
  time_this_iter_s: 56.28285813331604
  time_total_s: 3274.633152961731
  timestamp: 1594188261
  timesteps_since_restore: 2320000
  timesteps_this_iter: 40000
  timesteps_total: 2320000
  training_iteration: 58
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.3/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26970], 3274 s, 58 iter, 2320000 ts, -623 rew

agent-1: 17.0
agent-2: 6.0
agent-3: 19.0
agent-4: 13.0
agent-5: 7.0
agent-6: 7.0
agent-7: 20.0
agent-8: 2.0
agent-9: 6.0
agent-10: 12.0
agent-11: 18.0
agent-12: 8.0
agent-13: 12.0
agent-14: 13.0
agent-15: 12.0
agent-16: 16.0
agent-17: 9.0
agent-18: 21.0
agent-19: 20.0
agent-20: 6.0
agent-21: 15.0
agent-22: 10.0
agent-23: 14.0
agent-24: 12.0
agent-25: 4.0
agent-26: 7.0
agent-27: 6.0
agent-28: 14.0
agent-29: 13.0
agent-30: 16.0
agent-31: 5.0
agent-32: 8.0
agent-33: 3.0
agent-34: 16.0
agent-35: 18.0
agent-36: 19.0
agent-37: 12.0
agent-38: 18.0
agent-39: 17.0
agent-40: 9.0
Sum Reward: 480.0
Avg Reward: 12.0
Min Reward: 2.0
Max Reward: 21.0
Gini Coefficient: 0.2509375
20:20 Ratio: 4.026315789473684
Max-min Ratio: 10.5
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-08_02-05-17
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1283.0
  episode_reward_mean: -604.0
  episode_reward_min: -29997.0
  episodes_this_iter: 1
  episodes_total: 58
  experiment_id: 4e724eb5b3a34f42879644e84578eec0
  hostname: gpu024
  info:
    apply_time_ms: 3.122
    dispatch_time_ms: 6.278
    learner:
      cur_lr: 0.001205487991683185
      grad_gnorm: 0.48849010467529297
      policy_entropy: 766.7630615234375
      policy_loss: -0.9333971738815308
      var_gnorm: 25.818513870239258
      vf_explained_var: 0.20267385244369507
      vf_loss: 1.949920624610968e-05
    num_steps_sampled: 2360000
    num_steps_trained: 2360000
    wait_time_ms: 560.398
  iterations_since_restore: 59
  node_ip: 172.17.8.24
  num_metric_batches_dropped: 0
  pid: 26970
  policy_reward_mean: {}
  time_since_restore: 3331.076740503311
  time_this_iter_s: 56.4435875415802
  time_total_s: 3331.076740503311
  timestamp: 1594188317
  timesteps_since_restore: 2360000
  timesteps_this_iter: 40000
  timesteps_total: 2360000
  training_iteration: 59
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.3/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26970], 3331 s, 59 iter, 2360000 ts, -604 rew

agent-1: 9.0
agent-2: 13.0
agent-3: 17.0
agent-4: 8.0
agent-5: 4.0
agent-6: 5.0
agent-7: 18.0
agent-8: 13.0
agent-9: 14.0
agent-10: 14.0
agent-11: 11.0
agent-12: 13.0
agent-13: 19.0
agent-14: 4.0
agent-15: 20.0
agent-16: 24.0
agent-17: 19.0
agent-18: 13.0
agent-19: 14.0
agent-20: 8.0
agent-21: 7.0
agent-22: 7.0
agent-23: 24.0
agent-24: 15.0
agent-25: 14.0
agent-26: 13.0
agent-27: 12.0
agent-28: 25.0
agent-29: 6.0
agent-30: 11.0
agent-31: 11.0
agent-32: 15.0
agent-33: 5.0
agent-34: 11.0
agent-35: 2.0
agent-36: 11.0
agent-37: 14.0
agent-38: 8.0
agent-39: 15.0
agent-40: 10.0
Sum Reward: 496.0
Avg Reward: 12.4
Min Reward: 2.0
Max Reward: 25.0
Gini Coefficient: 0.2470766129032258
20:20 Ratio: 4.15
Max-min Ratio: 12.5
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-08_02-06-14
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1283.0
  episode_reward_mean: -585.3559322033898
  episode_reward_min: -29997.0
  episodes_this_iter: 1
  episodes_total: 59
  experiment_id: 4e724eb5b3a34f42879644e84578eec0
  hostname: gpu024
  info:
    apply_time_ms: 2.492
    dispatch_time_ms: 10.034
    learner:
      cur_lr: 0.0012028239434584975
      grad_gnorm: 7.030483245849609
      policy_entropy: 775.705322265625
      policy_loss: -2.1042115688323975
      var_gnorm: 25.81441307067871
      vf_explained_var: 0.0040732622146606445
      vf_loss: 0.00814699474722147
    num_steps_sampled: 2400000
    num_steps_trained: 2400000
    wait_time_ms: 539.577
  iterations_since_restore: 60
  node_ip: 172.17.8.24
  num_metric_batches_dropped: 0
  pid: 26970
  policy_reward_mean: {}
  time_since_restore: 3387.5709998607635
  time_this_iter_s: 56.49425935745239
  time_total_s: 3387.5709998607635
  timestamp: 1594188374
  timesteps_since_restore: 2400000
  timesteps_this_iter: 40000
  timesteps_total: 2400000
  training_iteration: 60
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.3/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26970], 3387 s, 60 iter, 2400000 ts, -585 rew

agent-1: 14.0
agent-2: 9.0
agent-3: 9.0
agent-4: 10.0
agent-5: 10.0
agent-6: 7.0
agent-7: 16.0
agent-8: 21.0
agent-9: 12.0
agent-10: 6.0
agent-11: 12.0
agent-12: 21.0
agent-13: 8.0
agent-14: 8.0
agent-15: 22.0
agent-16: 6.0
agent-17: 12.0
agent-18: 5.0
agent-19: 16.0
agent-20: 8.0
agent-21: 10.0
agent-22: 20.0
agent-23: 12.0
agent-24: 10.0
agent-25: 12.0
agent-26: 11.0
agent-27: 3.0
agent-28: 14.0
agent-29: 11.0
agent-30: 10.0
agent-31: 19.0
agent-32: 15.0
agent-33: 10.0
agent-34: 14.0
agent-35: 11.0
agent-36: 12.0
agent-37: 13.0
agent-38: 21.0
agent-39: 16.0
agent-40: 7.0
Sum Reward: 483.0
Avg Reward: 12.075
Min Reward: 3.0
Max Reward: 22.0
Gini Coefficient: 0.21506211180124224
20:20 Ratio: 3.12
Max-min Ratio: 7.333333333333333
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-08_02-07-10
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1283.0
  episode_reward_mean: -567.55
  episode_reward_min: -29997.0
  episodes_this_iter: 1
  episodes_total: 60
  experiment_id: 4e724eb5b3a34f42879644e84578eec0
  hostname: gpu024
  info:
    apply_time_ms: 3.314
    dispatch_time_ms: 6.264
    learner:
      cur_lr: 0.0012001600116491318
      grad_gnorm: 40.0
      policy_entropy: 557.506591796875
      policy_loss: 23.278545379638672
      var_gnorm: 26.04470443725586
      vf_explained_var: 0.6255743503570557
      vf_loss: 3.2909460067749023
    num_steps_sampled: 2440000
    num_steps_trained: 2440000
    wait_time_ms: 562.001
  iterations_since_restore: 61
  node_ip: 172.17.8.24
  num_metric_batches_dropped: 0
  pid: 26970
  policy_reward_mean: {}
  time_since_restore: 3444.0246710777283
  time_this_iter_s: 56.45367121696472
  time_total_s: 3444.0246710777283
  timestamp: 1594188430
  timesteps_since_restore: 2440000
  timesteps_this_iter: 40000
  timesteps_total: 2440000
  training_iteration: 61
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.3/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26970], 3444 s, 61 iter, 2440000 ts, -568 rew

agent-1: 11.0
agent-2: 23.0
agent-3: 7.0
agent-4: 9.0
agent-5: 11.0
agent-6: 10.0
agent-7: 15.0
agent-8: 6.0
agent-9: 8.0
agent-10: 16.0
agent-11: 12.0
agent-12: 22.0
agent-13: 4.0
agent-14: 3.0
agent-15: 17.0
agent-16: 22.0
agent-17: 22.0
agent-18: 9.0
agent-19: 18.0
agent-20: 8.0
agent-21: 15.0
agent-22: 9.0
agent-23: 18.0
agent-24: 20.0
agent-25: 13.0
agent-26: 16.0
agent-27: 12.0
agent-28: 10.0
agent-29: 20.0
agent-30: 6.0
agent-31: 15.0
agent-32: 10.0
agent-33: 15.0
agent-34: 21.0
agent-35: 10.0
agent-36: 10.0
agent-37: 19.0
agent-38: 26.0
agent-39: 11.0
agent-40: 10.0
Sum Reward: 539.0
Avg Reward: 13.475
Min Reward: 3.0
Max Reward: 26.0
Gini Coefficient: 0.2384508348794063
20:20 Ratio: 3.450980392156863
Max-min Ratio: 8.666666666666666
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-08_02-08-07
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1283.0
  episode_reward_mean: -549.4098360655738
  episode_reward_min: -29997.0
  episodes_this_iter: 1
  episodes_total: 61
  experiment_id: 4e724eb5b3a34f42879644e84578eec0
  hostname: gpu024
  info:
    apply_time_ms: 2.736
    dispatch_time_ms: 7.367
    learner:
      cur_lr: 0.0011974959634244442
      grad_gnorm: 3.071662664413452
      policy_entropy: 669.96337890625
      policy_loss: -0.9813820719718933
      var_gnorm: 26.066375732421875
      vf_explained_var: -0.06463789939880371
      vf_loss: 0.0016127016860991716
    num_steps_sampled: 2480000
    num_steps_trained: 2480000
    wait_time_ms: 563.14
  iterations_since_restore: 62
  node_ip: 172.17.8.24
  num_metric_batches_dropped: 0
  pid: 26970
  policy_reward_mean: {}
  time_since_restore: 3500.633884191513
  time_this_iter_s: 56.60921311378479
  time_total_s: 3500.633884191513
  timestamp: 1594188487
  timesteps_since_restore: 2480000
  timesteps_this_iter: 40000
  timesteps_total: 2480000
  training_iteration: 62
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.3/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26970], 3500 s, 62 iter, 2480000 ts, -549 rew

agent-1: 10.0
agent-2: 8.0
agent-3: 8.0
agent-4: 19.0
agent-5: 9.0
agent-6: 12.0
agent-7: 20.0
agent-8: 8.0
agent-9: 2.0
agent-10: 15.0
agent-11: 17.0
agent-12: 10.0
agent-13: 9.0
agent-14: 13.0
agent-15: 12.0
agent-16: 23.0
agent-17: 3.0
agent-18: 11.0
agent-19: 14.0
agent-20: 13.0
agent-21: 2.0
agent-22: 16.0
agent-23: 10.0
agent-24: 15.0
agent-25: 24.0
agent-26: 13.0
agent-27: 25.0
agent-28: 32.0
agent-29: 14.0
agent-30: 15.0
agent-31: 13.0
agent-32: 6.0
agent-33: 15.0
agent-34: 12.0
agent-35: 4.0
agent-36: 13.0
agent-37: 11.0
agent-38: 15.0
agent-39: 6.0
agent-40: 14.0
Sum Reward: 511.0
Avg Reward: 12.775
Min Reward: 2.0
Max Reward: 32.0
Gini Coefficient: 0.26051859099804303
20:20 Ratio: 4.512820512820513
Max-min Ratio: 16.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-08_02-09-03
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1283.0
  episode_reward_mean: -532.3064516129032
  episode_reward_min: -29997.0
  episodes_this_iter: 1
  episodes_total: 62
  experiment_id: 4e724eb5b3a34f42879644e84578eec0
  hostname: gpu024
  info:
    apply_time_ms: 2.533
    dispatch_time_ms: 5.741
    learner:
      cur_lr: 0.0011948320316150784
      grad_gnorm: 3.3679070472717285
      policy_entropy: 702.8338623046875
      policy_loss: -1.141749620437622
      var_gnorm: 26.334144592285156
      vf_explained_var: 0.99156254529953
      vf_loss: 0.002209678292274475
    num_steps_sampled: 2520000
    num_steps_trained: 2520000
    wait_time_ms: 562.198
  iterations_since_restore: 63
  node_ip: 172.17.8.24
  num_metric_batches_dropped: 0
  pid: 26970
  policy_reward_mean: {}
  time_since_restore: 3556.9291803836823
  time_this_iter_s: 56.29529619216919
  time_total_s: 3556.9291803836823
  timestamp: 1594188543
  timesteps_since_restore: 2520000
  timesteps_this_iter: 40000
  timesteps_total: 2520000
  training_iteration: 63
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.3/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26970], 3556 s, 63 iter, 2520000 ts, -532 rew

agent-1: 15.0
agent-2: 16.0
agent-3: 17.0
agent-4: 14.0
agent-5: 1.0
agent-6: 13.0
agent-7: 13.0
agent-8: 7.0
agent-9: 14.0
agent-10: 15.0
agent-11: 16.0
agent-12: 26.0
agent-13: 5.0
agent-14: 8.0
agent-15: 5.0
agent-16: 13.0
agent-17: 16.0
agent-18: 15.0
agent-19: 13.0
agent-20: 12.0
agent-21: 7.0
agent-22: 11.0
agent-23: 18.0
agent-24: 12.0
agent-25: 11.0
agent-26: 11.0
agent-27: 14.0
agent-28: 16.0
agent-29: 9.0
agent-30: 18.0
agent-31: 14.0
agent-32: 15.0
agent-33: 10.0
agent-34: 7.0
agent-35: 5.0
agent-36: 4.0
agent-37: 17.0
agent-38: 14.0
agent-39: 7.0
agent-40: 11.0
Sum Reward: 485.0
Avg Reward: 12.125
Min Reward: 1.0
Max Reward: 26.0
Gini Coefficient: 0.21551546391752577
20:20 Ratio: 3.5121951219512195
Max-min Ratio: 26.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-08_02-10-00
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1283.0
  episode_reward_mean: -516.1587301587301
  episode_reward_min: -29997.0
  episodes_this_iter: 1
  episodes_total: 63
  experiment_id: 4e724eb5b3a34f42879644e84578eec0
  hostname: gpu024
  info:
    apply_time_ms: 2.634
    dispatch_time_ms: 5.943
    learner:
      cur_lr: 0.0011921679833903909
      grad_gnorm: 40.000003814697266
      policy_entropy: 298.8866271972656
      policy_loss: 15.255840301513672
      var_gnorm: 26.331634521484375
      vf_explained_var: 0.39064836502075195
      vf_loss: 227.677001953125
    num_steps_sampled: 2560000
    num_steps_trained: 2560000
    wait_time_ms: 515.53
  iterations_since_restore: 64
  node_ip: 172.17.8.24
  num_metric_batches_dropped: 0
  pid: 26970
  policy_reward_mean: {}
  time_since_restore: 3613.2350523471832
  time_this_iter_s: 56.30587196350098
  time_total_s: 3613.2350523471832
  timestamp: 1594188600
  timesteps_since_restore: 2560000
  timesteps_this_iter: 40000
  timesteps_total: 2560000
  training_iteration: 64
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.3/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26970], 3613 s, 64 iter, 2560000 ts, -516 rew

agent-1: 17.0
agent-2: 27.0
agent-3: 13.0
agent-4: 13.0
agent-5: 9.0
agent-6: 7.0
agent-7: 15.0
agent-8: 10.0
agent-9: 22.0
agent-10: 9.0
agent-11: 16.0
agent-12: 11.0
agent-13: 14.0
agent-14: 13.0
agent-15: 14.0
agent-16: 10.0
agent-17: 17.0
agent-18: 16.0
agent-19: 12.0
agent-20: 11.0
agent-21: 3.0
agent-22: 9.0
agent-23: 16.0
agent-24: 16.0
agent-25: 7.0
agent-26: 7.0
agent-27: 19.0
agent-28: 6.0
agent-29: 13.0
agent-30: 14.0
agent-31: 12.0
agent-32: 20.0
agent-33: 5.0
agent-34: 6.0
agent-35: 6.0
agent-36: 6.0
agent-37: 10.0
agent-38: 16.0
agent-39: 9.0
agent-40: 4.0
Sum Reward: 480.0
Avg Reward: 12.0
Min Reward: 3.0
Max Reward: 27.0
Gini Coefficient: 0.2390625
20:20 Ratio: 3.5813953488372094
Max-min Ratio: 9.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-08_02-10-56
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1283.0
  episode_reward_mean: -500.59375
  episode_reward_min: -29997.0
  episodes_this_iter: 1
  episodes_total: 64
  experiment_id: 4e724eb5b3a34f42879644e84578eec0
  hostname: gpu024
  info:
    apply_time_ms: 2.542
    dispatch_time_ms: 5.253
    learner:
      cur_lr: 0.0011895040515810251
      grad_gnorm: 7.966667175292969
      policy_entropy: 694.949462890625
      policy_loss: -4.267434120178223
      var_gnorm: 26.566234588623047
      vf_explained_var: -0.01579868793487549
      vf_loss: 0.06267356872558594
    num_steps_sampled: 2600000
    num_steps_trained: 2600000
    wait_time_ms: 552.615
  iterations_since_restore: 65
  node_ip: 172.17.8.24
  num_metric_batches_dropped: 0
  pid: 26970
  policy_reward_mean: {}
  time_since_restore: 3669.9242691993713
  time_this_iter_s: 56.68921685218811
  time_total_s: 3669.9242691993713
  timestamp: 1594188656
  timesteps_since_restore: 2600000
  timesteps_this_iter: 40000
  timesteps_total: 2600000
  training_iteration: 65
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.3/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26970], 3669 s, 65 iter, 2600000 ts, -501 rew

agent-1: 12.0
agent-2: 13.0
agent-3: 25.0
agent-4: 4.0
agent-5: 9.0
agent-6: 14.0
agent-7: 13.0
agent-8: 10.0
agent-9: 13.0
agent-10: 19.0
agent-11: 7.0
agent-12: 15.0
agent-13: 11.0
agent-14: 13.0
agent-15: 12.0
agent-16: 19.0
agent-17: -37.0
agent-18: 11.0
agent-19: 7.0
agent-20: 26.0
agent-21: 5.0
agent-22: 11.0
agent-23: 15.0
agent-24: 13.0
agent-25: 17.0
agent-26: 9.0
agent-27: 7.0
agent-28: 9.0
agent-29: 12.0
agent-30: 24.0
agent-31: 13.0
agent-32: 13.0
agent-33: 9.0
agent-34: 11.0
agent-35: 15.0
agent-36: 5.0
agent-37: 8.0
agent-38: 21.0
agent-39: 8.0
agent-40: 7.0
Sum Reward: 448.0
Avg Reward: 11.2
Min Reward: -37.0
Max Reward: 26.0
Gini Coefficient: 0.3503348214285714
20:20 Ratio: 33.2
Max-min Ratio: -0.7027027027027027
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-08_02-11-53
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1283.0
  episode_reward_mean: -486.0
  episode_reward_min: -29997.0
  episodes_this_iter: 1
  episodes_total: 65
  experiment_id: 4e724eb5b3a34f42879644e84578eec0
  hostname: gpu024
  info:
    apply_time_ms: 2.635
    dispatch_time_ms: 6.909
    learner:
      cur_lr: 0.0011868400033563375
      grad_gnorm: 11.26294231414795
      policy_entropy: 738.6739501953125
      policy_loss: -3.8030431270599365
      var_gnorm: 26.585739135742188
      vf_explained_var: 0.034888505935668945
      vf_loss: 0.020982373505830765
    num_steps_sampled: 2640000
    num_steps_trained: 2640000
    wait_time_ms: 529.405
  iterations_since_restore: 66
  node_ip: 172.17.8.24
  num_metric_batches_dropped: 0
  pid: 26970
  policy_reward_mean: {}
  time_since_restore: 3726.1600143909454
  time_this_iter_s: 56.2357451915741
  time_total_s: 3726.1600143909454
  timestamp: 1594188713
  timesteps_since_restore: 2640000
  timesteps_this_iter: 40000
  timesteps_total: 2640000
  training_iteration: 66
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.3/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26970], 3726 s, 66 iter, 2640000 ts, -486 rew

agent-1: 17.0
agent-2: 7.0
agent-3: 17.0
agent-4: 19.0
agent-5: 28.0
agent-6: 9.0
agent-7: 5.0
agent-8: 21.0
agent-9: 7.0
agent-10: 11.0
agent-11: 9.0
agent-12: 15.0
agent-13: 12.0
agent-14: 13.0
agent-15: 1.0
agent-16: 10.0
agent-17: 6.0
agent-18: 10.0
agent-19: 8.0
agent-20: 13.0
agent-21: 23.0
agent-22: 11.0
agent-23: 10.0
agent-24: 6.0
agent-25: 15.0
agent-26: 15.0
agent-27: 12.0
agent-28: 14.0
agent-29: 12.0
agent-30: 12.0
agent-31: 6.0
agent-32: 13.0
agent-33: 7.0
agent-34: 18.0
agent-35: 19.0
agent-36: 12.0
agent-37: 10.0
agent-38: 10.0
agent-39: 8.0
agent-40: 3.0
Sum Reward: 474.0
Avg Reward: 11.85
Min Reward: 1.0
Max Reward: 28.0
Gini Coefficient: 0.2521097046413502
20:20 Ratio: 3.951219512195122
Max-min Ratio: 28.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-08_02-12-49
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1283.0
  episode_reward_mean: -471.45454545454544
  episode_reward_min: -29997.0
  episodes_this_iter: 1
  episodes_total: 66
  experiment_id: 4e724eb5b3a34f42879644e84578eec0
  hostname: gpu024
  info:
    apply_time_ms: 3.6
    dispatch_time_ms: 6.04
    learner:
      cur_lr: 0.00118417595513165
      grad_gnorm: 1.2952313423156738
      policy_entropy: 718.6417236328125
      policy_loss: -0.6830605268478394
      var_gnorm: 26.76882553100586
      vf_explained_var: -0.12183129787445068
      vf_loss: 0.0003593872534111142
    num_steps_sampled: 2680000
    num_steps_trained: 2680000
    wait_time_ms: 547.21
  iterations_since_restore: 67
  node_ip: 172.17.8.24
  num_metric_batches_dropped: 0
  pid: 26970
  policy_reward_mean: {}
  time_since_restore: 3782.6552200317383
  time_this_iter_s: 56.49520564079285
  time_total_s: 3782.6552200317383
  timestamp: 1594188769
  timesteps_since_restore: 2680000
  timesteps_this_iter: 40000
  timesteps_total: 2680000
  training_iteration: 67
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.3/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26970], 3782 s, 67 iter, 2680000 ts, -471 rew

agent-1: 10.0
agent-2: 26.0
agent-3: 5.0
agent-4: 6.0
agent-5: 8.0
agent-6: 22.0
agent-7: 6.0
agent-8: 17.0
agent-9: 13.0
agent-10: 12.0
agent-11: 18.0
agent-12: 10.0
agent-13: 11.0
agent-14: 1.0
agent-15: 26.0
agent-16: 19.0
agent-17: 7.0
agent-18: 9.0
agent-19: 10.0
agent-20: 14.0
agent-21: 21.0
agent-22: 4.0
agent-23: 19.0
agent-24: 17.0
agent-25: 11.0
agent-26: 14.0
agent-27: 14.0
agent-28: 18.0
agent-29: 7.0
agent-30: 16.0
agent-31: 13.0
agent-32: 12.0
agent-33: 14.0
agent-34: 3.0
agent-35: 5.0
agent-36: 9.0
agent-37: 13.0
agent-38: 0.0
agent-39: 25.0
agent-40: 20.0
Sum Reward: 505.0
Avg Reward: 12.625
Min Reward: 0.0
Max Reward: 26.0
Gini Coefficient: 0.2956930693069307
20:20 Ratio: 5.933333333333334
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-08_02-13-46
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1283.0
  episode_reward_mean: -456.8805970149254
  episode_reward_min: -29997.0
  episodes_this_iter: 1
  episodes_total: 67
  experiment_id: 4e724eb5b3a34f42879644e84578eec0
  hostname: gpu024
  info:
    apply_time_ms: 2.723
    dispatch_time_ms: 6.717
    learner:
      cur_lr: 0.0011815120233222842
      grad_gnorm: 39.999996185302734
      policy_entropy: 459.21356201171875
      policy_loss: -10.393681526184082
      var_gnorm: 26.749967575073242
      vf_explained_var: 0.6429797410964966
      vf_loss: 83.4788818359375
    num_steps_sampled: 2720000
    num_steps_trained: 2720000
    wait_time_ms: 538.025
  iterations_since_restore: 68
  node_ip: 172.17.8.24
  num_metric_batches_dropped: 0
  pid: 26970
  policy_reward_mean: {}
  time_since_restore: 3839.4329886436462
  time_this_iter_s: 56.77776861190796
  time_total_s: 3839.4329886436462
  timestamp: 1594188826
  timesteps_since_restore: 2720000
  timesteps_this_iter: 40000
  timesteps_total: 2720000
  training_iteration: 68
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.3/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26970], 3839 s, 68 iter, 2720000 ts, -457 rew

agent-1: 15.0
agent-2: 13.0
agent-3: 5.0
agent-4: 19.0
agent-5: 9.0
agent-6: 13.0
agent-7: 6.0
agent-8: 7.0
agent-9: 8.0
agent-10: 17.0
agent-11: 19.0
agent-12: 6.0
agent-13: 11.0
agent-14: 10.0
agent-15: 9.0
agent-16: 16.0
agent-17: 16.0
agent-18: 17.0
agent-19: 14.0
agent-20: 17.0
agent-21: 26.0
agent-22: 13.0
agent-23: 16.0
agent-24: 6.0
agent-25: 13.0
agent-26: 17.0
agent-27: 5.0
agent-28: 6.0
agent-29: 15.0
agent-30: 13.0
agent-31: 10.0
agent-32: 18.0
agent-33: 19.0
agent-34: 13.0
agent-35: 2.0
agent-36: 18.0
agent-37: 8.0
agent-38: 7.0
agent-39: 14.0
agent-40: 8.0
Sum Reward: 494.0
Avg Reward: 12.35
Min Reward: 2.0
Max Reward: 26.0
Gini Coefficient: 0.23491902834008097
20:20 Ratio: 3.558139534883721
Max-min Ratio: 13.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-08_02-14-42
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1283.0
  episode_reward_mean: -442.8970588235294
  episode_reward_min: -29997.0
  episodes_this_iter: 1
  episodes_total: 68
  experiment_id: 4e724eb5b3a34f42879644e84578eec0
  hostname: gpu024
  info:
    apply_time_ms: 2.465
    dispatch_time_ms: 7.142
    learner:
      cur_lr: 0.0011788479750975966
      grad_gnorm: 1.951994776725769
      policy_entropy: 688.806640625
      policy_loss: 0.019309937953948975
      var_gnorm: 26.967464447021484
      vf_explained_var: -1.0
      vf_loss: 0.0067146578803658485
    num_steps_sampled: 2760000
    num_steps_trained: 2760000
    wait_time_ms: 557.874
  iterations_since_restore: 69
  node_ip: 172.17.8.24
  num_metric_batches_dropped: 0
  pid: 26970
  policy_reward_mean: {}
  time_since_restore: 3895.815479040146
  time_this_iter_s: 56.382490396499634
  time_total_s: 3895.815479040146
  timestamp: 1594188882
  timesteps_since_restore: 2760000
  timesteps_this_iter: 40000
  timesteps_total: 2760000
  training_iteration: 69
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.3/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26970], 3895 s, 69 iter, 2760000 ts, -443 rew

agent-1: 14.0
agent-2: 6.0
agent-3: 15.0
agent-4: 16.0
agent-5: 16.0
agent-6: 8.0
agent-7: 13.0
agent-8: 17.0
agent-9: 8.0
agent-10: 18.0
agent-11: 6.0
agent-12: 4.0
agent-13: 11.0
agent-14: 21.0
agent-15: 6.0
agent-16: 20.0
agent-17: 8.0
agent-18: 16.0
agent-19: 8.0
agent-20: 15.0
agent-21: 8.0
agent-22: 20.0
agent-23: 10.0
agent-24: 12.0
agent-25: 17.0
agent-26: 8.0
agent-27: 7.0
agent-28: 18.0
agent-29: 10.0
agent-30: 9.0
agent-31: 14.0
agent-32: 4.0
agent-33: 10.0
agent-34: 9.0
agent-35: 21.0
agent-36: 6.0
agent-37: 17.0
agent-38: 13.0
agent-39: 4.0
agent-40: 10.0
Sum Reward: 473.0
Avg Reward: 11.825
Min Reward: 4.0
Max Reward: 21.0
Gini Coefficient: 0.24223044397463003
20:20 Ratio: 3.5348837209302326
Max-min Ratio: 5.25
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-08_02-15-39
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1283.0
  episode_reward_mean: -429.6231884057971
  episode_reward_min: -29997.0
  episodes_this_iter: 1
  episodes_total: 69
  experiment_id: 4e724eb5b3a34f42879644e84578eec0
  hostname: gpu024
  info:
    apply_time_ms: 2.845
    dispatch_time_ms: 5.987
    learner:
      cur_lr: 0.001176184043288231
      grad_gnorm: 39.9999885559082
      policy_entropy: 393.5940856933594
      policy_loss: 30.223302841186523
      var_gnorm: 26.9600887298584
      vf_explained_var: 0.6042068004608154
      vf_loss: 96.60021209716797
    num_steps_sampled: 2800000
    num_steps_trained: 2800000
    wait_time_ms: 525.82
  iterations_since_restore: 70
  node_ip: 172.17.8.24
  num_metric_batches_dropped: 0
  pid: 26970
  policy_reward_mean: {}
  time_since_restore: 3952.0132644176483
  time_this_iter_s: 56.19778537750244
  time_total_s: 3952.0132644176483
  timestamp: 1594188939
  timesteps_since_restore: 2800000
  timesteps_this_iter: 40000
  timesteps_total: 2800000
  training_iteration: 70
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.3/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26970], 3952 s, 70 iter, 2800000 ts, -430 rew

agent-1: 26.0
agent-2: 15.0
agent-3: 11.0
agent-4: 12.0
agent-5: 9.0
agent-6: 6.0
agent-7: 6.0
agent-8: 11.0
agent-9: 8.0
agent-10: 10.0
agent-11: 1.0
agent-12: 14.0
agent-13: 6.0
agent-14: 16.0
agent-15: 6.0
agent-16: 9.0
agent-17: 8.0
agent-18: 16.0
agent-19: 11.0
agent-20: 18.0
agent-21: 9.0
agent-22: 14.0
agent-23: 6.0
agent-24: 10.0
agent-25: 9.0
agent-26: 14.0
agent-27: 15.0
agent-28: 20.0
agent-29: 20.0
agent-30: 13.0
agent-31: 18.0
agent-32: 16.0
agent-33: 9.0
agent-34: 23.0
agent-35: 13.0
agent-36: 24.0
agent-37: 11.0
agent-38: 9.0
agent-39: 8.0
agent-40: 13.0
Sum Reward: 493.0
Avg Reward: 12.325
Min Reward: 1.0
Max Reward: 26.0
Gini Coefficient: 0.24102434077079107
20:20 Ratio: 3.5106382978723403
Max-min Ratio: 26.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-08_02-16-35
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1283.0
  episode_reward_mean: -416.4428571428571
  episode_reward_min: -29997.0
  episodes_this_iter: 1
  episodes_total: 70
  experiment_id: 4e724eb5b3a34f42879644e84578eec0
  hostname: gpu024
  info:
    apply_time_ms: 3.518
    dispatch_time_ms: 6.508
    learner:
      cur_lr: 0.0011735199950635433
      grad_gnorm: 0.7990094423294067
      policy_entropy: 756.5796508789062
      policy_loss: -0.1528117060661316
      var_gnorm: 27.132558822631836
      vf_explained_var: -0.2034372091293335
      vf_loss: 0.00011244337656535208
    num_steps_sampled: 2840000
    num_steps_trained: 2840000
    wait_time_ms: 560.972
  iterations_since_restore: 71
  node_ip: 172.17.8.24
  num_metric_batches_dropped: 0
  pid: 26970
  policy_reward_mean: {}
  time_since_restore: 4008.8117463588715
  time_this_iter_s: 56.798481941223145
  time_total_s: 4008.8117463588715
  timestamp: 1594188995
  timesteps_since_restore: 2840000
  timesteps_this_iter: 40000
  timesteps_total: 2840000
  training_iteration: 71
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.3/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26970], 4008 s, 71 iter, 2840000 ts, -416 rew

agent-1: 16.0
agent-2: 16.0
agent-3: 5.0
agent-4: 11.0
agent-5: 5.0
agent-6: 12.0
agent-7: 11.0
agent-8: 18.0
agent-9: 12.0
agent-10: 21.0
agent-11: 12.0
agent-12: 22.0
agent-13: 8.0
agent-14: 18.0
agent-15: 12.0
agent-16: 13.0
agent-17: 9.0
agent-18: 9.0
agent-19: 13.0
agent-20: 9.0
agent-21: 6.0
agent-22: 11.0
agent-23: 12.0
agent-24: 9.0
agent-25: 5.0
agent-26: 13.0
agent-27: 14.0
agent-28: 12.0
agent-29: 8.0
agent-30: 14.0
agent-31: 14.0
agent-32: 13.0
agent-33: 9.0
agent-34: 9.0
agent-35: 16.0
agent-36: 19.0
agent-37: 15.0
agent-38: 10.0
agent-39: 14.0
agent-40: 16.0
Sum Reward: 491.0
Avg Reward: 12.275
Min Reward: 5.0
Max Reward: 22.0
Gini Coefficient: 0.18660896130346233
20:20 Ratio: 2.6545454545454548
Max-min Ratio: 4.4
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-08_02-17-32
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1283.0
  episode_reward_mean: -403.6619718309859
  episode_reward_min: -29997.0
  episodes_this_iter: 1
  episodes_total: 71
  experiment_id: 4e724eb5b3a34f42879644e84578eec0
  hostname: gpu024
  info:
    apply_time_ms: 2.364
    dispatch_time_ms: 6.497
    learner:
      cur_lr: 0.0011708559468388557
      grad_gnorm: 39.999996185302734
      policy_entropy: 571.3448486328125
      policy_loss: -27.837881088256836
      var_gnorm: 27.123645782470703
      vf_explained_var: 0.15507280826568604
      vf_loss: 60.25464630126953
    num_steps_sampled: 2880000
    num_steps_trained: 2880000
    wait_time_ms: 539.729
  iterations_since_restore: 72
  node_ip: 172.17.8.24
  num_metric_batches_dropped: 0
  pid: 26970
  policy_reward_mean: {}
  time_since_restore: 4065.2633018493652
  time_this_iter_s: 56.451555490493774
  time_total_s: 4065.2633018493652
  timestamp: 1594189052
  timesteps_since_restore: 2880000
  timesteps_this_iter: 40000
  timesteps_total: 2880000
  training_iteration: 72
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.3/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26970], 4065 s, 72 iter, 2880000 ts, -404 rew

agent-1: 16.0
agent-2: 18.0
agent-3: 11.0
agent-4: 14.0
agent-5: 18.0
agent-6: 9.0
agent-7: 12.0
agent-8: 20.0
agent-9: 7.0
agent-10: 11.0
agent-11: 13.0
agent-12: 12.0
agent-13: 8.0
agent-14: 14.0
agent-15: 18.0
agent-16: 8.0
agent-17: 2.0
agent-18: 10.0
agent-19: 10.0
agent-20: 16.0
agent-21: 16.0
agent-22: 7.0
agent-23: 14.0
agent-24: 12.0
agent-25: 12.0
agent-26: 8.0
agent-27: 12.0
agent-28: 19.0
agent-29: 11.0
agent-30: 18.0
agent-31: 10.0
agent-32: 14.0
agent-33: 18.0
agent-34: 17.0
agent-35: 10.0
agent-36: 4.0
agent-37: 7.0
agent-38: 9.0
agent-39: 27.0
agent-40: 10.0
Sum Reward: 502.0
Avg Reward: 12.55
Min Reward: 2.0
Max Reward: 27.0
Gini Coefficient: 0.21165338645418327
20:20 Ratio: 3.0588235294117645
Max-min Ratio: 13.5
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-08_02-18-28
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1283.0
  episode_reward_mean: -391.0833333333333
  episode_reward_min: -29997.0
  episodes_this_iter: 1
  episodes_total: 72
  experiment_id: 4e724eb5b3a34f42879644e84578eec0
  hostname: gpu024
  info:
    apply_time_ms: 2.717
    dispatch_time_ms: 5.95
    learner:
      cur_lr: 0.00116819201502949
      grad_gnorm: 2.6543853282928467
      policy_entropy: 741.5648193359375
      policy_loss: 1.1960519552230835
      var_gnorm: 27.316299438476562
      vf_explained_var: 0.970945417881012
      vf_loss: 0.0013518186751753092
    num_steps_sampled: 2920000
    num_steps_trained: 2920000
    wait_time_ms: 559.289
  iterations_since_restore: 73
  node_ip: 172.17.8.24
  num_metric_batches_dropped: 0
  pid: 26970
  policy_reward_mean: {}
  time_since_restore: 4121.732721328735
  time_this_iter_s: 56.46941947937012
  time_total_s: 4121.732721328735
  timestamp: 1594189108
  timesteps_since_restore: 2920000
  timesteps_this_iter: 40000
  timesteps_total: 2920000
  training_iteration: 73
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.3/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26970], 4121 s, 73 iter, 2920000 ts, -391 rew

agent-1: 15.0
agent-2: 8.0
agent-3: 9.0
agent-4: 13.0
agent-5: 14.0
agent-6: 12.0
agent-7: 15.0
agent-8: 10.0
agent-9: 8.0
agent-10: 13.0
agent-11: 14.0
agent-12: 17.0
agent-13: 8.0
agent-14: 8.0
agent-15: 4.0
agent-16: 16.0
agent-17: 12.0
agent-18: 17.0
agent-19: 9.0
agent-20: 11.0
agent-21: 13.0
agent-22: 14.0
agent-23: 8.0
agent-24: 13.0
agent-25: 6.0
agent-26: 14.0
agent-27: 13.0
agent-28: 8.0
agent-29: 17.0
agent-30: 11.0
agent-31: 13.0
agent-32: 10.0
agent-33: 8.0
agent-34: 14.0
agent-35: 8.0
agent-36: 14.0
agent-37: 13.0
agent-38: 16.0
agent-39: 3.0
agent-40: 15.0
Sum Reward: 464.0
Avg Reward: 11.6
Min Reward: 3.0
Max Reward: 17.0
Gini Coefficient: 0.1699353448275862
20:20 Ratio: 2.4150943396226414
Max-min Ratio: 5.666666666666667
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-08_02-19-25
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1283.0
  episode_reward_mean: -379.36986301369865
  episode_reward_min: -29997.0
  episodes_this_iter: 1
  episodes_total: 73
  experiment_id: 4e724eb5b3a34f42879644e84578eec0
  hostname: gpu024
  info:
    apply_time_ms: 2.579
    dispatch_time_ms: 5.244
    learner:
      cur_lr: 0.0011655279668048024
      grad_gnorm: 40.000003814697266
      policy_entropy: 459.17071533203125
      policy_loss: -78.09418487548828
      var_gnorm: 27.30987548828125
      vf_explained_var: 0.04867815971374512
      vf_loss: 202.70932006835938
    num_steps_sampled: 2960000
    num_steps_trained: 2960000
    wait_time_ms: 529.986
  iterations_since_restore: 74
  node_ip: 172.17.8.24
  num_metric_batches_dropped: 0
  pid: 26970
  policy_reward_mean: {}
  time_since_restore: 4178.17379617691
  time_this_iter_s: 56.44107484817505
  time_total_s: 4178.17379617691
  timestamp: 1594189165
  timesteps_since_restore: 2960000
  timesteps_this_iter: 40000
  timesteps_total: 2960000
  training_iteration: 74
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.3/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26970], 4178 s, 74 iter, 2960000 ts, -379 rew

agent-1: 21.0
agent-2: 5.0
agent-3: 9.0
agent-4: 15.0
agent-5: 13.0
agent-6: 9.0
agent-7: 22.0
agent-8: 15.0
agent-9: 9.0
agent-10: 13.0
agent-11: 8.0
agent-12: 6.0
agent-13: 8.0
agent-14: 13.0
agent-15: 9.0
agent-16: 10.0
agent-17: 4.0
agent-18: 22.0
agent-19: 13.0
agent-20: 7.0
agent-21: 12.0
agent-22: 17.0
agent-23: 20.0
agent-24: 16.0
agent-25: 9.0
agent-26: 4.0
agent-27: 7.0
agent-28: 18.0
agent-29: 24.0
agent-30: 17.0
agent-31: 20.0
agent-32: 7.0
agent-33: 11.0
agent-34: 6.0
agent-35: 8.0
agent-36: 25.0
agent-37: 10.0
agent-38: 16.0
agent-39: 18.0
agent-40: 18.0
Sum Reward: 514.0
Avg Reward: 12.85
Min Reward: 4.0
Max Reward: 25.0
Gini Coefficient: 0.2556420233463035
20:20 Ratio: 3.739130434782609
Max-min Ratio: 6.25
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-08_02-20-22
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1283.0
  episode_reward_mean: -367.2972972972973
  episode_reward_min: -29997.0
  episodes_this_iter: 1
  episodes_total: 74
  experiment_id: 4e724eb5b3a34f42879644e84578eec0
  hostname: gpu024
  info:
    apply_time_ms: 3.397
    dispatch_time_ms: 7.448
    learner:
      cur_lr: 0.0011628640349954367
      grad_gnorm: 5.3348236083984375
      policy_entropy: 736.12841796875
      policy_loss: -3.3230690956115723
      var_gnorm: 27.56330680847168
      vf_explained_var: -0.03935551643371582
      vf_loss: 0.0022366985213011503
    num_steps_sampled: 3000000
    num_steps_trained: 3000000
    wait_time_ms: 563.581
  iterations_since_restore: 75
  node_ip: 172.17.8.24
  num_metric_batches_dropped: 0
  pid: 26970
  policy_reward_mean: {}
  time_since_restore: 4235.007534503937
  time_this_iter_s: 56.83373832702637
  time_total_s: 4235.007534503937
  timestamp: 1594189222
  timesteps_since_restore: 3000000
  timesteps_this_iter: 40000
  timesteps_total: 3000000
  training_iteration: 75
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.3/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26970], 4235 s, 75 iter, 3000000 ts, -367 rew

agent-1: 14.0
agent-2: 16.0
agent-3: 8.0
agent-4: 16.0
agent-5: 7.0
agent-6: 12.0
agent-7: 10.0
agent-8: 16.0
agent-9: 9.0
agent-10: 8.0
agent-11: 14.0
agent-12: 23.0
agent-13: 12.0
agent-14: 7.0
agent-15: 12.0
agent-16: 11.0
agent-17: 12.0
agent-18: 16.0
agent-19: 12.0
agent-20: 9.0
agent-21: 6.0
agent-22: 2.0
agent-23: 8.0
agent-24: 21.0
agent-25: 12.0
agent-26: 5.0
agent-27: 8.0
agent-28: 22.0
agent-29: 15.0
agent-30: 7.0
agent-31: 15.0
agent-32: 15.0
agent-33: 22.0
agent-34: 18.0
agent-35: 15.0
agent-36: 8.0
agent-37: 5.0
agent-38: 8.0
agent-39: 11.0
agent-40: 17.0
Sum Reward: 484.0
Avg Reward: 12.1
Min Reward: 2.0
Max Reward: 23.0
Gini Coefficient: 0.2325413223140496
20:20 Ratio: 3.297872340425532
Max-min Ratio: 11.5
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-08_02-21-18
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1283.0
  episode_reward_mean: -355.94666666666666
  episode_reward_min: -29997.0
  episodes_this_iter: 1
  episodes_total: 75
  experiment_id: 4e724eb5b3a34f42879644e84578eec0
  hostname: gpu024
  info:
    apply_time_ms: 2.622
    dispatch_time_ms: 6.024
    learner:
      cur_lr: 0.001160199986770749
      grad_gnorm: 8.381974220275879
      policy_entropy: 757.88427734375
      policy_loss: -5.249466896057129
      var_gnorm: 27.563879013061523
      vf_explained_var: -1.0
      vf_loss: 0.018613019958138466
    num_steps_sampled: 3040000
    num_steps_trained: 3040000
    wait_time_ms: 557.289
  iterations_since_restore: 76
  node_ip: 172.17.8.24
  num_metric_batches_dropped: 0
  pid: 26970
  policy_reward_mean: {}
  time_since_restore: 4291.468306541443
  time_this_iter_s: 56.4607720375061
  time_total_s: 4291.468306541443
  timestamp: 1594189278
  timesteps_since_restore: 3040000
  timesteps_this_iter: 40000
  timesteps_total: 3040000
  training_iteration: 76
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.3/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26970], 4291 s, 76 iter, 3040000 ts, -356 rew

agent-1: 14.0
agent-2: 8.0
agent-3: 14.0
agent-4: 13.0
agent-5: 11.0
agent-6: 6.0
agent-7: 11.0
agent-8: 13.0
agent-9: 18.0
agent-10: 20.0
agent-11: 9.0
agent-12: 8.0
agent-13: 11.0
agent-14: 13.0
agent-15: 7.0
agent-16: 14.0
agent-17: 15.0
agent-18: 12.0
agent-19: 11.0
agent-20: 9.0
agent-21: 15.0
agent-22: 15.0
agent-23: 13.0
agent-24: 7.0
agent-25: 16.0
agent-26: 9.0
agent-27: 8.0
agent-28: 14.0
agent-29: 14.0
agent-30: 17.0
agent-31: 12.0
agent-32: 13.0
agent-33: 13.0
agent-34: 8.0
agent-35: 19.0
agent-36: 10.0
agent-37: 11.0
agent-38: 17.0
agent-39: 16.0
agent-40: 10.0
Sum Reward: 494.0
Avg Reward: 12.35
Min Reward: 6.0
Max Reward: 20.0
Gini Coefficient: 0.1575910931174089
20:20 Ratio: 2.262295081967213
Max-min Ratio: 3.3333333333333335
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-08_02-22-14
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1283.0
  episode_reward_mean: -344.7631578947368
  episode_reward_min: -29997.0
  episodes_this_iter: 1
  episodes_total: 76
  experiment_id: 4e724eb5b3a34f42879644e84578eec0
  hostname: gpu024
  info:
    apply_time_ms: 2.528
    dispatch_time_ms: 5.354
    learner:
      cur_lr: 0.0011575360549613833
      grad_gnorm: 2.1552927494049072
      policy_entropy: 641.967041015625
      policy_loss: 0.25931209325790405
      var_gnorm: 27.773069381713867
      vf_explained_var: -0.3941551446914673
      vf_loss: 0.0009353193454444408
    num_steps_sampled: 3080000
    num_steps_trained: 3080000
    wait_time_ms: 563.944
  iterations_since_restore: 77
  node_ip: 172.17.8.24
  num_metric_batches_dropped: 0
  pid: 26970
  policy_reward_mean: {}
  time_since_restore: 4347.624560832977
  time_this_iter_s: 56.156254291534424
  time_total_s: 4347.624560832977
  timestamp: 1594189334
  timesteps_since_restore: 3080000
  timesteps_this_iter: 40000
  timesteps_total: 3080000
  training_iteration: 77
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.3/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26970], 4347 s, 77 iter, 3080000 ts, -345 rew

agent-1: 9.0
agent-2: 7.0
agent-3: 4.0
agent-4: 14.0
agent-5: 11.0
agent-6: 20.0
agent-7: 7.0
agent-8: 16.0
agent-9: 15.0
agent-10: 8.0
agent-11: 10.0
agent-12: 9.0
agent-13: 19.0
agent-14: 17.0
agent-15: 20.0
agent-16: 9.0
agent-17: 12.0
agent-18: 15.0
agent-19: 12.0
agent-20: 11.0
agent-21: 15.0
agent-22: 17.0
agent-23: 11.0
agent-24: 11.0
agent-25: 6.0
agent-26: 20.0
agent-27: 18.0
agent-28: 14.0
agent-29: 19.0
agent-30: 14.0
agent-31: 13.0
agent-32: 14.0
agent-33: 6.0
agent-34: 11.0
agent-35: 8.0
agent-36: 11.0
agent-37: 13.0
agent-38: 17.0
agent-39: 10.0
agent-40: 16.0
Sum Reward: 509.0
Avg Reward: 12.725
Min Reward: 4.0
Max Reward: 20.0
Gini Coefficient: 0.19032416502946956
20:20 Ratio: 2.727272727272727
Max-min Ratio: 5.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-08_02-23-11
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1283.0
  episode_reward_mean: -333.6753246753247
  episode_reward_min: -29997.0
  episodes_this_iter: 1
  episodes_total: 77
  experiment_id: 4e724eb5b3a34f42879644e84578eec0
  hostname: gpu024
  info:
    apply_time_ms: 2.432
    dispatch_time_ms: 5.9
    learner:
      cur_lr: 0.0011548720067366958
      grad_gnorm: 35.42238235473633
      policy_entropy: 724.9721069335938
      policy_loss: -1.7404897212982178
      var_gnorm: 27.80619239807129
      vf_explained_var: -1.0
      vf_loss: 0.014602907933294773
    num_steps_sampled: 3120000
    num_steps_trained: 3120000
    wait_time_ms: 557.302
  iterations_since_restore: 78
  node_ip: 172.17.8.24
  num_metric_batches_dropped: 0
  pid: 26970
  policy_reward_mean: {}
  time_since_restore: 4404.427721261978
  time_this_iter_s: 56.803160429000854
  time_total_s: 4404.427721261978
  timestamp: 1594189391
  timesteps_since_restore: 3120000
  timesteps_this_iter: 40000
  timesteps_total: 3120000
  training_iteration: 78
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.3/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26970], 4404 s, 78 iter, 3120000 ts, -334 rew

agent-1: 5.0
agent-2: 18.0
agent-3: 15.0
agent-4: 14.0
agent-5: 8.0
agent-6: 2.0
agent-7: 10.0
agent-8: 8.0
agent-9: 7.0
agent-10: 10.0
agent-11: 7.0
agent-12: 9.0
agent-13: 14.0
agent-14: 25.0
agent-15: 23.0
agent-16: 23.0
agent-17: 24.0
agent-18: 11.0
agent-19: 15.0
agent-20: 9.0
agent-21: 19.0
agent-22: 14.0
agent-23: 4.0
agent-24: 11.0
agent-25: 6.0
agent-26: 17.0
agent-27: 17.0
agent-28: 21.0
agent-29: 10.0
agent-30: 24.0
agent-31: 8.0
agent-32: 7.0
agent-33: 6.0
agent-34: 13.0
agent-35: 14.0
agent-36: 19.0
agent-37: 13.0
agent-38: 9.0
agent-39: 14.0
agent-40: 10.0
Sum Reward: 513.0
Avg Reward: 12.825
Min Reward: 2.0
Max Reward: 25.0
Gini Coefficient: 0.2633040935672515
20:20 Ratio: 4.045454545454546
Max-min Ratio: 12.5
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-08_02-24-08
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1283.0
  episode_reward_mean: -322.8205128205128
  episode_reward_min: -29997.0
  episodes_this_iter: 1
  episodes_total: 78
  experiment_id: 4e724eb5b3a34f42879644e84578eec0
  hostname: gpu024
  info:
    apply_time_ms: 2.481
    dispatch_time_ms: 5.74
    learner:
      cur_lr: 0.0011522079585120082
      grad_gnorm: 0.41822901368141174
      policy_entropy: 723.6115112304688
      policy_loss: -0.37785324454307556
      var_gnorm: 27.921001434326172
      vf_explained_var: -5.2809715270996094e-05
      vf_loss: 2.003343524847878e-06
    num_steps_sampled: 3160000
    num_steps_trained: 3160000
    wait_time_ms: 558.075
  iterations_since_restore: 79
  node_ip: 172.17.8.24
  num_metric_batches_dropped: 0
  pid: 26970
  policy_reward_mean: {}
  time_since_restore: 4460.569032669067
  time_this_iter_s: 56.14131140708923
  time_total_s: 4460.569032669067
  timestamp: 1594189448
  timesteps_since_restore: 3160000
  timesteps_this_iter: 40000
  timesteps_total: 3160000
  training_iteration: 79
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26970], 4460 s, 79 iter, 3160000 ts, -323 rew

agent-1: 13.0
agent-2: 11.0
agent-3: 10.0
agent-4: 6.0
agent-5: 6.0
agent-6: 17.0
agent-7: 15.0
agent-8: 11.0
agent-9: 13.0
agent-10: 8.0
agent-11: 17.0
agent-12: 14.0
agent-13: 20.0
agent-14: 15.0
agent-15: 13.0
agent-16: 18.0
agent-17: 15.0
agent-18: 8.0
agent-19: 11.0
agent-20: 14.0
agent-21: 7.0
agent-22: 9.0
agent-23: 6.0
agent-24: 12.0
agent-25: 17.0
agent-26: 18.0
agent-27: 9.0
agent-28: 13.0
agent-29: 20.0
agent-30: 17.0
agent-31: 7.0
agent-32: 5.0
agent-33: 13.0
agent-34: 7.0
agent-35: 15.0
agent-36: 16.0
agent-37: 19.0
agent-38: 13.0
agent-39: 13.0
agent-40: 15.0
Sum Reward: 506.0
Avg Reward: 12.65
Min Reward: 5.0
Max Reward: 20.0
Gini Coefficient: 0.1884387351778656
20:20 Ratio: 2.8076923076923075
Max-min Ratio: 4.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-08_02-25-05
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1283.0
  episode_reward_mean: -312.32911392405066
  episode_reward_min: -29997.0
  episodes_this_iter: 1
  episodes_total: 79
  experiment_id: 4e724eb5b3a34f42879644e84578eec0
  hostname: gpu024
  info:
    apply_time_ms: 2.513
    dispatch_time_ms: 5.772
    learner:
      cur_lr: 0.0011495440267026424
      grad_gnorm: 11.126091003417969
      policy_entropy: 751.9779052734375
      policy_loss: -3.437598466873169
      var_gnorm: 27.912887573242188
      vf_explained_var: 2.086162567138672e-06
      vf_loss: 0.019933225587010384
    num_steps_sampled: 3200000
    num_steps_trained: 3200000
    wait_time_ms: 558.64
  iterations_since_restore: 80
  node_ip: 172.17.8.24
  num_metric_batches_dropped: 0
  pid: 26970
  policy_reward_mean: {}
  time_since_restore: 4517.5556054115295
  time_this_iter_s: 56.98657274246216
  time_total_s: 4517.5556054115295
  timestamp: 1594189505
  timesteps_since_restore: 3200000
  timesteps_this_iter: 40000
  timesteps_total: 3200000
  training_iteration: 80
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26970], 4517 s, 80 iter, 3200000 ts, -312 rew

agent-1: 13.0
agent-2: 5.0
agent-3: 9.0
agent-4: 6.0
agent-5: 14.0
agent-6: 7.0
agent-7: 14.0
agent-8: 15.0
agent-9: 6.0
agent-10: 19.0
agent-11: 11.0
agent-12: 14.0
agent-13: 13.0
agent-14: 20.0
agent-15: 18.0
agent-16: 12.0
agent-17: 8.0
agent-18: 18.0
agent-19: 12.0
agent-20: 9.0
agent-21: 21.0
agent-22: 3.0
agent-23: 12.0
agent-24: 14.0
agent-25: 13.0
agent-26: 20.0
agent-27: 13.0
agent-28: 13.0
agent-29: 11.0
agent-30: 8.0
agent-31: 14.0
agent-32: 9.0
agent-33: 11.0
agent-34: 8.0
agent-35: 10.0
agent-36: 11.0
agent-37: 19.0
agent-38: 18.0
agent-39: 13.0
agent-40: 14.0
Sum Reward: 498.0
Avg Reward: 12.45
Min Reward: 3.0
Max Reward: 21.0
Gini Coefficient: 0.1964859437751004
20:20 Ratio: 3.0
Max-min Ratio: 7.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-08_02-26-01
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1283.0
  episode_reward_mean: -302.2
  episode_reward_min: -29997.0
  episodes_this_iter: 1
  episodes_total: 80
  experiment_id: 4e724eb5b3a34f42879644e84578eec0
  hostname: gpu024
  info:
    apply_time_ms: 3.45
    dispatch_time_ms: 6.558
    learner:
      cur_lr: 0.0011468799784779549
      grad_gnorm: 0.686620831489563
      policy_entropy: 671.9241333007812
      policy_loss: 0.18441316485404968
      var_gnorm: 28.000293731689453
      vf_explained_var: -0.28082847595214844
      vf_loss: 0.0028001628816127777
    num_steps_sampled: 3240000
    num_steps_trained: 3240000
    wait_time_ms: 559.325
  iterations_since_restore: 81
  node_ip: 172.17.8.24
  num_metric_batches_dropped: 0
  pid: 26970
  policy_reward_mean: {}
  time_since_restore: 4574.1504764556885
  time_this_iter_s: 56.594871044158936
  time_total_s: 4574.1504764556885
  timestamp: 1594189561
  timesteps_since_restore: 3240000
  timesteps_this_iter: 40000
  timesteps_total: 3240000
  training_iteration: 81
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26970], 4574 s, 81 iter, 3240000 ts, -302 rew

agent-1: 11.0
agent-2: 9.0
agent-3: 18.0
agent-4: 7.0
agent-5: 2.0
agent-6: 10.0
agent-7: 15.0
agent-8: 14.0
agent-9: 16.0
agent-10: 7.0
agent-11: 10.0
agent-12: 14.0
agent-13: 10.0
agent-14: 18.0
agent-15: 12.0
agent-16: 14.0
agent-17: 10.0
agent-18: 18.0
agent-19: 6.0
agent-20: 10.0
agent-21: 12.0
agent-22: 16.0
agent-23: 12.0
agent-24: 8.0
agent-25: 9.0
agent-26: 7.0
agent-27: 20.0
agent-28: 18.0
agent-29: 6.0
agent-30: 17.0
agent-31: 15.0
agent-32: 15.0
agent-33: 22.0
agent-34: 16.0
agent-35: 21.0
agent-36: 13.0
agent-37: 10.0
agent-38: 7.0
agent-39: 11.0
agent-40: 14.0
Sum Reward: 500.0
Avg Reward: 12.5
Min Reward: 2.0
Max Reward: 22.0
Gini Coefficient: 0.2068
20:20 Ratio: 3.04
Max-min Ratio: 11.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-08_02-26-58
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1283.0
  episode_reward_mean: -292.2962962962963
  episode_reward_min: -29997.0
  episodes_this_iter: 1
  episodes_total: 81
  experiment_id: 4e724eb5b3a34f42879644e84578eec0
  hostname: gpu024
  info:
    apply_time_ms: 3.186
    dispatch_time_ms: 5.938
    learner:
      cur_lr: 0.0011442160466685891
      grad_gnorm: 4.268985271453857
      policy_entropy: 760.7587280273438
      policy_loss: -4.055039405822754
      var_gnorm: 28.014677047729492
      vf_explained_var: -0.015419602394104004
      vf_loss: 0.0028036742005497217
    num_steps_sampled: 3280000
    num_steps_trained: 3280000
    wait_time_ms: 552.011
  iterations_since_restore: 82
  node_ip: 172.17.8.24
  num_metric_batches_dropped: 0
  pid: 26970
  policy_reward_mean: {}
  time_since_restore: 4630.594942569733
  time_this_iter_s: 56.44446611404419
  time_total_s: 4630.594942569733
  timestamp: 1594189618
  timesteps_since_restore: 3280000
  timesteps_this_iter: 40000
  timesteps_total: 3280000
  training_iteration: 82
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26970], 4630 s, 82 iter, 3280000 ts, -292 rew

agent-1: 8.0
agent-2: 13.0
agent-3: 10.0
agent-4: 26.0
agent-5: 11.0
agent-6: 8.0
agent-7: 16.0
agent-8: 12.0
agent-9: 13.0
agent-10: 9.0
agent-11: 17.0
agent-12: 24.0
agent-13: 10.0
agent-14: 7.0
agent-15: 6.0
agent-16: 22.0
agent-17: 13.0
agent-18: 15.0
agent-19: 13.0
agent-20: 14.0
agent-21: 5.0
agent-22: 16.0
agent-23: 11.0
agent-24: 17.0
agent-25: 17.0
agent-26: 16.0
agent-27: 6.0
agent-28: 20.0
agent-29: 8.0
agent-30: 7.0
agent-31: 10.0
agent-32: 3.0
agent-33: 10.0
agent-34: 13.0
agent-35: 9.0
agent-36: 12.0
agent-37: 14.0
agent-38: 11.0
agent-39: 15.0
agent-40: 16.0
Sum Reward: 503.0
Avg Reward: 12.575
Min Reward: 3.0
Max Reward: 26.0
Gini Coefficient: 0.2202286282306163
20:20 Ratio: 3.18
Max-min Ratio: 8.666666666666666
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-08_02-27-54
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1283.0
  episode_reward_mean: -282.5975609756098
  episode_reward_min: -29997.0
  episodes_this_iter: 1
  episodes_total: 82
  experiment_id: 4e724eb5b3a34f42879644e84578eec0
  hostname: gpu024
  info:
    apply_time_ms: 3.004
    dispatch_time_ms: 5.712
    learner:
      cur_lr: 0.0011415519984439015
      grad_gnorm: 1.1299625635147095
      policy_entropy: 742.56396484375
      policy_loss: 2.8293604850769043
      var_gnorm: 28.215953826904297
      vf_explained_var: 0.9685749411582947
      vf_loss: 0.00019567795970942825
    num_steps_sampled: 3320000
    num_steps_trained: 3320000
    wait_time_ms: 561.594
  iterations_since_restore: 83
  node_ip: 172.17.8.24
  num_metric_batches_dropped: 0
  pid: 26970
  policy_reward_mean: {}
  time_since_restore: 4686.708209037781
  time_this_iter_s: 56.113266468048096
  time_total_s: 4686.708209037781
  timestamp: 1594189674
  timesteps_since_restore: 3320000
  timesteps_this_iter: 40000
  timesteps_total: 3320000
  training_iteration: 83
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26970], 4686 s, 83 iter, 3320000 ts, -283 rew

agent-1: 11.0
agent-2: 7.0
agent-3: 4.0
agent-4: 11.0
agent-5: 14.0
agent-6: 9.0
agent-7: 10.0
agent-8: 12.0
agent-9: 4.0
agent-10: 17.0
agent-11: 14.0
agent-12: 14.0
agent-13: 2.0
agent-14: 12.0
agent-15: 20.0
agent-16: 9.0
agent-17: 20.0
agent-18: 12.0
agent-19: 10.0
agent-20: 19.0
agent-21: 11.0
agent-22: 11.0
agent-23: 16.0
agent-24: 12.0
agent-25: 6.0
agent-26: 9.0
agent-27: 8.0
agent-28: 11.0
agent-29: 17.0
agent-30: 7.0
agent-31: 11.0
agent-32: 15.0
agent-33: 13.0
agent-34: 21.0
agent-35: 5.0
agent-36: 17.0
agent-37: 15.0
agent-38: 9.0
agent-39: 7.0
agent-40: 10.0
Sum Reward: 462.0
Avg Reward: 11.55
Min Reward: 2.0
Max Reward: 21.0
Gini Coefficient: 0.2226190476190476
20:20 Ratio: 3.5
Max-min Ratio: 10.5
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-08_02-28-51
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1283.0
  episode_reward_mean: -273.6265060240964
  episode_reward_min: -29997.0
  episodes_this_iter: 1
  episodes_total: 83
  experiment_id: 4e724eb5b3a34f42879644e84578eec0
  hostname: gpu024
  info:
    apply_time_ms: 2.894
    dispatch_time_ms: 5.848
    learner:
      cur_lr: 0.001138887950219214
      grad_gnorm: 6.847087383270264
      policy_entropy: 751.1202392578125
      policy_loss: 8.858316421508789
      var_gnorm: 28.228349685668945
      vf_explained_var: -0.14248502254486084
      vf_loss: 0.4763856828212738
    num_steps_sampled: 3360000
    num_steps_trained: 3360000
    wait_time_ms: 552.079
  iterations_since_restore: 84
  node_ip: 172.17.8.24
  num_metric_batches_dropped: 0
  pid: 26970
  policy_reward_mean: {}
  time_since_restore: 4743.517918348312
  time_this_iter_s: 56.809709310531616
  time_total_s: 4743.517918348312
  timestamp: 1594189731
  timesteps_since_restore: 3360000
  timesteps_this_iter: 40000
  timesteps_total: 3360000
  training_iteration: 84
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26970], 4743 s, 84 iter, 3360000 ts, -274 rew

agent-1: 18.0
agent-2: 15.0
agent-3: 10.0
agent-4: 6.0
agent-5: 18.0
agent-6: 11.0
agent-7: 23.0
agent-8: 14.0
agent-9: 8.0
agent-10: 11.0
agent-11: 8.0
agent-12: 11.0
agent-13: 14.0
agent-14: 16.0
agent-15: 14.0
agent-16: 11.0
agent-17: 8.0
agent-18: 11.0
agent-19: 11.0
agent-20: 12.0
agent-21: 16.0
agent-22: 8.0
agent-23: 18.0
agent-24: 10.0
agent-25: 12.0
agent-26: 9.0
agent-27: 5.0
agent-28: 11.0
agent-29: 16.0
agent-30: 7.0
agent-31: 11.0
agent-32: 7.0
agent-33: 17.0
agent-34: 21.0
agent-35: 15.0
agent-36: 16.0
agent-37: 7.0
agent-38: 9.0
agent-39: 6.0
agent-40: 13.0
Sum Reward: 484.0
Avg Reward: 12.1
Min Reward: 5.0
Max Reward: 23.0
Gini Coefficient: 0.1978305785123967
20:20 Ratio: 2.7222222222222223
Max-min Ratio: 4.6
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-08_02-29-47
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1283.0
  episode_reward_mean: -264.60714285714283
  episode_reward_min: -29997.0
  episodes_this_iter: 1
  episodes_total: 84
  experiment_id: 4e724eb5b3a34f42879644e84578eec0
  hostname: gpu024
  info:
    apply_time_ms: 2.516
    dispatch_time_ms: 6.342
    learner:
      cur_lr: 0.0011362240184098482
      grad_gnorm: 1.635596752166748
      policy_entropy: 710.5567626953125
      policy_loss: -0.27338743209838867
      var_gnorm: 28.364946365356445
      vf_explained_var: -0.8063540458679199
      vf_loss: 0.00039668084355071187
    num_steps_sampled: 3400000
    num_steps_trained: 3400000
    wait_time_ms: 546.798
  iterations_since_restore: 85
  node_ip: 172.17.8.24
  num_metric_batches_dropped: 0
  pid: 26970
  policy_reward_mean: {}
  time_since_restore: 4799.959155082703
  time_this_iter_s: 56.44123673439026
  time_total_s: 4799.959155082703
  timestamp: 1594189787
  timesteps_since_restore: 3400000
  timesteps_this_iter: 40000
  timesteps_total: 3400000
  training_iteration: 85
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26970], 4799 s, 85 iter, 3400000 ts, -265 rew

agent-1: 9.0
agent-2: 14.0
agent-3: 15.0
agent-4: 15.0
agent-5: 19.0
agent-6: 11.0
agent-7: 12.0
agent-8: 12.0
agent-9: 13.0
agent-10: 12.0
agent-11: 13.0
agent-12: 15.0
agent-13: 14.0
agent-14: 14.0
agent-15: 8.0
agent-16: -39.0
agent-17: 10.0
agent-18: 16.0
agent-19: 5.0
agent-20: 12.0
agent-21: 11.0
agent-22: 15.0
agent-23: 13.0
agent-24: 20.0
agent-25: 13.0
agent-26: 8.0
agent-27: 12.0
agent-28: 17.0
agent-29: 3.0
agent-30: 12.0
agent-31: 10.0
agent-32: 8.0
agent-33: 11.0
agent-34: 12.0
agent-35: 15.0
agent-36: 5.0
agent-37: 16.0
agent-38: 13.0
agent-39: 11.0
agent-40: 8.0
Sum Reward: 433.0
Avg Reward: 10.825
Min Reward: -39.0
Max Reward: 20.0
Gini Coefficient: 0.2872401847575058
20:20 Ratio: 22.166666666666668
Max-min Ratio: -0.5128205128205128
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-08_02-30-44
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1283.0
  episode_reward_mean: -256.4
  episode_reward_min: -29997.0
  episodes_this_iter: 1
  episodes_total: 85
  experiment_id: 4e724eb5b3a34f42879644e84578eec0
  hostname: gpu024
  info:
    apply_time_ms: 2.865
    dispatch_time_ms: 5.874
    learner:
      cur_lr: 0.0011335599701851606
      grad_gnorm: 40.0
      policy_entropy: 705.261962890625
      policy_loss: -43.24394989013672
      var_gnorm: 28.371919631958008
      vf_explained_var: 0.5384023785591125
      vf_loss: 10.449555397033691
    num_steps_sampled: 3440000
    num_steps_trained: 3440000
    wait_time_ms: 555.124
  iterations_since_restore: 86
  node_ip: 172.17.8.24
  num_metric_batches_dropped: 0
  pid: 26970
  policy_reward_mean: {}
  time_since_restore: 4856.866760253906
  time_this_iter_s: 56.90760517120361
  time_total_s: 4856.866760253906
  timestamp: 1594189844
  timesteps_since_restore: 3440000
  timesteps_this_iter: 40000
  timesteps_total: 3440000
  training_iteration: 86
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26970], 4856 s, 86 iter, 3440000 ts, -256 rew

agent-1: 11.0
agent-2: 13.0
agent-3: 8.0
agent-4: 13.0
agent-5: 12.0
agent-6: 7.0
agent-7: 16.0
agent-8: 32.0
agent-9: 9.0
agent-10: 15.0
agent-11: 10.0
agent-12: 14.0
agent-13: 12.0
agent-14: 10.0
agent-15: 13.0
agent-16: 9.0
agent-17: 13.0
agent-18: 11.0
agent-19: 12.0
agent-20: 11.0
agent-21: 7.0
agent-22: 18.0
agent-23: 16.0
agent-24: 8.0
agent-25: 2.0
agent-26: 21.0
agent-27: 12.0
agent-28: 10.0
agent-29: 14.0
agent-30: 20.0
agent-31: 13.0
agent-32: 15.0
agent-33: 13.0
agent-34: 9.0
agent-35: 7.0
agent-36: 9.0
agent-37: 11.0
agent-38: 16.0
agent-39: 12.0
agent-40: 7.0
Sum Reward: 491.0
Avg Reward: 12.275
Min Reward: 2.0
Max Reward: 32.0
Gini Coefficient: 0.19933808553971485
20:20 Ratio: 2.8
Max-min Ratio: 16.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-08_02-31-40
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1283.0
  episode_reward_mean: -247.7093023255814
  episode_reward_min: -29997.0
  episodes_this_iter: 1
  episodes_total: 86
  experiment_id: 4e724eb5b3a34f42879644e84578eec0
  hostname: gpu024
  info:
    apply_time_ms: 2.943
    dispatch_time_ms: 6.758
    learner:
      cur_lr: 0.0011308960383757949
      grad_gnorm: 1.0874656438827515
      policy_entropy: 712.974609375
      policy_loss: 2.1064651012420654
      var_gnorm: 28.53993034362793
      vf_explained_var: 0.907697319984436
      vf_loss: 0.0013180106179788709
    num_steps_sampled: 3480000
    num_steps_trained: 3480000
    wait_time_ms: 547.311
  iterations_since_restore: 87
  node_ip: 172.17.8.24
  num_metric_batches_dropped: 0
  pid: 26970
  policy_reward_mean: {}
  time_since_restore: 4913.0073211193085
  time_this_iter_s: 56.14056086540222
  time_total_s: 4913.0073211193085
  timestamp: 1594189900
  timesteps_since_restore: 3480000
  timesteps_this_iter: 40000
  timesteps_total: 3480000
  training_iteration: 87
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26970], 4913 s, 87 iter, 3480000 ts, -248 rew

agent-1: 11.0
agent-2: 15.0
agent-3: 13.0
agent-4: 18.0
agent-5: 9.0
agent-6: 10.0
agent-7: 14.0
agent-8: 6.0
agent-9: 12.0
agent-10: 11.0
agent-11: 12.0
agent-12: 13.0
agent-13: 9.0
agent-14: 11.0
agent-15: 7.0
agent-16: 10.0
agent-17: 14.0
agent-18: 14.0
agent-19: 8.0
agent-20: 6.0
agent-21: 15.0
agent-22: 18.0
agent-23: 18.0
agent-24: 8.0
agent-25: 9.0
agent-26: 13.0
agent-27: 11.0
agent-28: 11.0
agent-29: 8.0
agent-30: 9.0
agent-31: 5.0
agent-32: 10.0
agent-33: 16.0
agent-34: 7.0
agent-35: 14.0
agent-36: 10.0
agent-37: 13.0
agent-38: 11.0
agent-39: 11.0
agent-40: 11.0
Sum Reward: 451.0
Avg Reward: 11.275
Min Reward: 5.0
Max Reward: 18.0
Gini Coefficient: 0.1618070953436807
20:20 Ratio: 2.327272727272727
Max-min Ratio: 3.6
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-08_02-32-37
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1283.0
  episode_reward_mean: -239.67816091954023
  episode_reward_min: -29997.0
  episodes_this_iter: 1
  episodes_total: 87
  experiment_id: 4e724eb5b3a34f42879644e84578eec0
  hostname: gpu024
  info:
    apply_time_ms: 2.658
    dispatch_time_ms: 8.631
    learner:
      cur_lr: 0.0011282319901511073
      grad_gnorm: 2.119450092315674
      policy_entropy: 733.0197143554688
      policy_loss: -3.3993403911590576
      var_gnorm: 28.572010040283203
      vf_explained_var: -1.0
      vf_loss: 0.0006406223401427269
    num_steps_sampled: 3520000
    num_steps_trained: 3520000
    wait_time_ms: 550.869
  iterations_since_restore: 88
  node_ip: 172.17.8.24
  num_metric_batches_dropped: 0
  pid: 26970
  policy_reward_mean: {}
  time_since_restore: 4969.345349788666
  time_this_iter_s: 56.3380286693573
  time_total_s: 4969.345349788666
  timestamp: 1594189957
  timesteps_since_restore: 3520000
  timesteps_this_iter: 40000
  timesteps_total: 3520000
  training_iteration: 88
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26970], 4969 s, 88 iter, 3520000 ts, -240 rew

agent-1: 15.0
agent-2: 3.0
agent-3: 7.0
agent-4: 3.0
agent-5: 18.0
agent-6: 8.0
agent-7: 8.0
agent-8: 18.0
agent-9: 16.0
agent-10: 17.0
agent-11: 13.0
agent-12: 14.0
agent-13: 16.0
agent-14: 13.0
agent-15: 10.0
agent-16: 7.0
agent-17: 10.0
agent-18: 18.0
agent-19: 17.0
agent-20: 10.0
agent-21: 17.0
agent-22: 5.0
agent-23: 20.0
agent-24: 22.0
agent-25: 9.0
agent-26: 14.0
agent-27: 9.0
agent-28: 6.0
agent-29: 20.0
agent-30: 12.0
agent-31: 12.0
agent-32: 9.0
agent-33: 10.0
agent-34: 21.0
agent-35: 13.0
agent-36: 4.0
agent-37: 8.0
agent-38: 17.0
agent-39: 13.0
agent-40: 23.0
Sum Reward: 505.0
Avg Reward: 12.625
Min Reward: 3.0
Max Reward: 23.0
Gini Coefficient: 0.24094059405940593
20:20 Ratio: 3.7209302325581395
Max-min Ratio: 7.666666666666667
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-08_02-33-33
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1283.0
  episode_reward_mean: -231.2159090909091
  episode_reward_min: -29997.0
  episodes_this_iter: 1
  episodes_total: 88
  experiment_id: 4e724eb5b3a34f42879644e84578eec0
  hostname: gpu024
  info:
    apply_time_ms: 2.678
    dispatch_time_ms: 6.347
    learner:
      cur_lr: 0.0011255679419264197
      grad_gnorm: 4.661861419677734
      policy_entropy: 680.37060546875
      policy_loss: 4.192362308502197
      var_gnorm: 28.68670082092285
      vf_explained_var: -0.8204281330108643
      vf_loss: 0.003210019087418914
    num_steps_sampled: 3560000
    num_steps_trained: 3560000
    wait_time_ms: 561.96
  iterations_since_restore: 89
  node_ip: 172.17.8.24
  num_metric_batches_dropped: 0
  pid: 26970
  policy_reward_mean: {}
  time_since_restore: 5025.908751010895
  time_this_iter_s: 56.563401222229004
  time_total_s: 5025.908751010895
  timestamp: 1594190013
  timesteps_since_restore: 3560000
  timesteps_this_iter: 40000
  timesteps_total: 3560000
  training_iteration: 89
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26970], 5025 s, 89 iter, 3560000 ts, -231 rew

agent-1: 9.0
agent-2: 19.0
agent-3: 15.0
agent-4: 10.0
agent-5: 15.0
agent-6: 16.0
agent-7: 13.0
agent-8: 12.0
agent-9: 17.0
agent-10: 9.0
agent-11: 16.0
agent-12: 9.0
agent-13: 15.0
agent-14: 9.0
agent-15: 8.0
agent-16: 8.0
agent-17: 13.0
agent-18: 14.0
agent-19: 9.0
agent-20: 8.0
agent-21: 13.0
agent-22: 9.0
agent-23: 13.0
agent-24: 16.0
agent-25: 6.0
agent-26: 7.0
agent-27: 15.0
agent-28: 10.0
agent-29: 14.0
agent-30: 9.0
agent-31: 12.0
agent-32: 10.0
agent-33: 13.0
agent-34: 8.0
agent-35: 9.0
agent-36: 14.0
agent-37: 14.0
agent-38: 9.0
agent-39: 10.0
agent-40: 9.0
Sum Reward: 464.0
Avg Reward: 11.6
Min Reward: 6.0
Max Reward: 19.0
Gini Coefficient: 0.15398706896551725
20:20 Ratio: 2.0476190476190474
Max-min Ratio: 3.1666666666666665
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-08_02-34-30
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1283.0
  episode_reward_mean: -223.40449438202248
  episode_reward_min: -29997.0
  episodes_this_iter: 1
  episodes_total: 89
  experiment_id: 4e724eb5b3a34f42879644e84578eec0
  hostname: gpu024
  info:
    apply_time_ms: 2.677
    dispatch_time_ms: 6.938
    learner:
      cur_lr: 0.001122904010117054
      grad_gnorm: 40.000003814697266
      policy_entropy: 632.2813720703125
      policy_loss: -37.63450622558594
      var_gnorm: 28.71990394592285
      vf_explained_var: 0.618351399898529
      vf_loss: 14.221182823181152
    num_steps_sampled: 3600000
    num_steps_trained: 3600000
    wait_time_ms: 553.95
  iterations_since_restore: 90
  node_ip: 172.17.8.24
  num_metric_batches_dropped: 0
  pid: 26970
  policy_reward_mean: {}
  time_since_restore: 5082.680051088333
  time_this_iter_s: 56.771300077438354
  time_total_s: 5082.680051088333
  timestamp: 1594190070
  timesteps_since_restore: 3600000
  timesteps_this_iter: 40000
  timesteps_total: 3600000
  training_iteration: 90
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26970], 5082 s, 90 iter, 3600000 ts, -223 rew

agent-1: 19.0
agent-2: 13.0
agent-3: 12.0
agent-4: 4.0
agent-5: 14.0
agent-6: 15.0
agent-7: 14.0
agent-8: 9.0
agent-9: 14.0
agent-10: 11.0
agent-11: 8.0
agent-12: 12.0
agent-13: 15.0
agent-14: 13.0
agent-15: 9.0
agent-16: 10.0
agent-17: 10.0
agent-18: 6.0
agent-19: 5.0
agent-20: 8.0
agent-21: 22.0
agent-22: 8.0
agent-23: 6.0
agent-24: 10.0
agent-25: 11.0
agent-26: 12.0
agent-27: 15.0
agent-28: 11.0
agent-29: 17.0
agent-30: 16.0
agent-31: 15.0
agent-32: 10.0
agent-33: 14.0
agent-34: 9.0
agent-35: 15.0
agent-36: 9.0
agent-37: 4.0
agent-38: 18.0
agent-39: 2.0
agent-40: 15.0
Sum Reward: 460.0
Avg Reward: 11.5
Min Reward: 2.0
Max Reward: 22.0
Gini Coefficient: 0.21032608695652175
20:20 Ratio: 3.186046511627907
Max-min Ratio: 11.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-08_02-35-26
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1283.0
  episode_reward_mean: -215.8111111111111
  episode_reward_min: -29997.0
  episodes_this_iter: 1
  episodes_total: 90
  experiment_id: 4e724eb5b3a34f42879644e84578eec0
  hostname: gpu024
  info:
    apply_time_ms: 2.66
    dispatch_time_ms: 5.134
    learner:
      cur_lr: 0.0011202399618923664
      grad_gnorm: 7.006338596343994
      policy_entropy: 720.820068359375
      policy_loss: 4.428045272827148
      var_gnorm: 28.800457000732422
      vf_explained_var: -0.21861779689788818
      vf_loss: 0.00843834225088358
    num_steps_sampled: 3640000
    num_steps_trained: 3640000
    wait_time_ms: 551.787
  iterations_since_restore: 91
  node_ip: 172.17.8.24
  num_metric_batches_dropped: 0
  pid: 26970
  policy_reward_mean: {}
  time_since_restore: 5138.923303842545
  time_this_iter_s: 56.243252754211426
  time_total_s: 5138.923303842545
  timestamp: 1594190126
  timesteps_since_restore: 3640000
  timesteps_this_iter: 40000
  timesteps_total: 3640000
  training_iteration: 91
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26970], 5138 s, 91 iter, 3640000 ts, -216 rew

agent-1: 6.0
agent-2: 17.0
agent-3: 15.0
agent-4: 5.0
agent-5: 8.0
agent-6: 11.0
agent-7: 12.0
agent-8: 11.0
agent-9: 13.0
agent-10: 10.0
agent-11: 5.0
agent-12: 16.0
agent-13: 10.0
agent-14: 14.0
agent-15: 9.0
agent-16: 2.0
agent-17: 10.0
agent-18: 10.0
agent-19: 12.0
agent-20: 14.0
agent-21: 14.0
agent-22: 18.0
agent-23: 15.0
agent-24: 16.0
agent-25: 9.0
agent-26: 9.0
agent-27: 15.0
agent-28: 10.0
agent-29: 8.0
agent-30: 18.0
agent-31: 13.0
agent-32: 11.0
agent-33: 13.0
agent-34: 18.0
agent-35: 16.0
agent-36: 10.0
agent-37: 15.0
agent-38: 18.0
agent-39: 13.0
agent-40: 12.0
Sum Reward: 481.0
Avg Reward: 12.025
Min Reward: 2.0
Max Reward: 18.0
Gini Coefficient: 0.17957380457380456
20:20 Ratio: 2.6346153846153846
Max-min Ratio: 9.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-08_02-36-23
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1283.0
  episode_reward_mean: -208.15384615384616
  episode_reward_min: -29997.0
  episodes_this_iter: 1
  episodes_total: 91
  experiment_id: 4e724eb5b3a34f42879644e84578eec0
  hostname: gpu024
  info:
    apply_time_ms: 2.926
    dispatch_time_ms: 6.351
    learner:
      cur_lr: 0.0011175760300830007
      grad_gnorm: 39.99999237060547
      policy_entropy: 708.4022216796875
      policy_loss: -2.4207186698913574
      var_gnorm: 28.859163284301758
      vf_explained_var: 0.17532920837402344
      vf_loss: 16.609983444213867
    num_steps_sampled: 3680000
    num_steps_trained: 3680000
    wait_time_ms: 547.345
  iterations_since_restore: 92
  node_ip: 172.17.8.24
  num_metric_batches_dropped: 0
  pid: 26970
  policy_reward_mean: {}
  time_since_restore: 5195.51736664772
  time_this_iter_s: 56.59406280517578
  time_total_s: 5195.51736664772
  timestamp: 1594190183
  timesteps_since_restore: 3680000
  timesteps_this_iter: 40000
  timesteps_total: 3680000
  training_iteration: 92
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26970], 5195 s, 92 iter, 3680000 ts, -208 rew

agent-1: 9.0
agent-2: 12.0
agent-3: 11.0
agent-4: 17.0
agent-5: 12.0
agent-6: 17.0
agent-7: 15.0
agent-8: 14.0
agent-9: 14.0
agent-10: 8.0
agent-11: 10.0
agent-12: 11.0
agent-13: 9.0
agent-14: 15.0
agent-15: 19.0
agent-16: 10.0
agent-17: 10.0
agent-18: 16.0
agent-19: 15.0
agent-20: 12.0
agent-21: 18.0
agent-22: 13.0
agent-23: 21.0
agent-24: 18.0
agent-25: 8.0
agent-26: 13.0
agent-27: 8.0
agent-28: 14.0
agent-29: 8.0
agent-30: 15.0
agent-31: 7.0
agent-32: 8.0
agent-33: 11.0
agent-34: 11.0
agent-35: 15.0
agent-36: 15.0
agent-37: 12.0
agent-38: 6.0
agent-39: 10.0
agent-40: 10.0
Sum Reward: 497.0
Avg Reward: 12.425
Min Reward: 6.0
Max Reward: 21.0
Gini Coefficient: 0.16343058350100603
20:20 Ratio: 2.274193548387097
Max-min Ratio: 3.5
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-08_02-37-20
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1283.0
  episode_reward_mean: -200.4891304347826
  episode_reward_min: -29997.0
  episodes_this_iter: 1
  episodes_total: 92
  experiment_id: 4e724eb5b3a34f42879644e84578eec0
  hostname: gpu024
  info:
    apply_time_ms: 2.923
    dispatch_time_ms: 6.558
    learner:
      cur_lr: 0.001114911981858313
      grad_gnorm: 4.247262001037598
      policy_entropy: 638.7057495117188
      policy_loss: 0.9924702644348145
      var_gnorm: 29.023366928100586
      vf_explained_var: -8.344650268554688e-07
      vf_loss: 0.0028755422681570053
    num_steps_sampled: 3720000
    num_steps_trained: 3720000
    wait_time_ms: 567.892
  iterations_since_restore: 93
  node_ip: 172.17.8.24
  num_metric_batches_dropped: 0
  pid: 26970
  policy_reward_mean: {}
  time_since_restore: 5252.227654933929
  time_this_iter_s: 56.710288286209106
  time_total_s: 5252.227654933929
  timestamp: 1594190240
  timesteps_since_restore: 3720000
  timesteps_this_iter: 40000
  timesteps_total: 3720000
  training_iteration: 93
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26970], 5252 s, 93 iter, 3720000 ts, -200 rew

agent-1: 7.0
agent-2: 17.0
agent-3: 20.0
agent-4: 11.0
agent-5: 11.0
agent-6: 15.0
agent-7: 13.0
agent-8: 11.0
agent-9: 12.0
agent-10: 12.0
agent-11: 11.0
agent-12: 13.0
agent-13: 5.0
agent-14: 10.0
agent-15: 11.0
agent-16: 12.0
agent-17: 18.0
agent-18: 16.0
agent-19: 8.0
agent-20: 16.0
agent-21: 16.0
agent-22: 15.0
agent-23: 11.0
agent-24: 13.0
agent-25: 7.0
agent-26: 12.0
agent-27: 13.0
agent-28: 9.0
agent-29: 9.0
agent-30: 13.0
agent-31: 10.0
agent-32: 13.0
agent-33: 4.0
agent-34: 11.0
agent-35: 14.0
agent-36: 12.0
agent-37: 8.0
agent-38: 13.0
agent-39: 14.0
agent-40: 7.0
Sum Reward: 473.0
Avg Reward: 11.825
Min Reward: 4.0
Max Reward: 20.0
Gini Coefficient: 0.1589323467230444
20:20 Ratio: 2.418181818181818
Max-min Ratio: 5.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-08_02-38-16
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1283.0
  episode_reward_mean: -193.247311827957
  episode_reward_min: -29997.0
  episodes_this_iter: 1
  episodes_total: 93
  experiment_id: 4e724eb5b3a34f42879644e84578eec0
  hostname: gpu024
  info:
    apply_time_ms: 2.551
    dispatch_time_ms: 5.511
    learner:
      cur_lr: 0.0011122480500489473
      grad_gnorm: 40.0
      policy_entropy: 670.59619140625
      policy_loss: -31.43622589111328
      var_gnorm: 29.017942428588867
      vf_explained_var: 0.5904593467712402
      vf_loss: 1.2742953300476074
    num_steps_sampled: 3760000
    num_steps_trained: 3760000
    wait_time_ms: 551.86
  iterations_since_restore: 94
  node_ip: 172.17.8.24
  num_metric_batches_dropped: 0
  pid: 26970
  policy_reward_mean: {}
  time_since_restore: 5308.339744567871
  time_this_iter_s: 56.11208963394165
  time_total_s: 5308.339744567871
  timestamp: 1594190296
  timesteps_since_restore: 3760000
  timesteps_this_iter: 40000
  timesteps_total: 3760000
  training_iteration: 94
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26970], 5308 s, 94 iter, 3760000 ts, -193 rew

agent-1: 12.0
agent-2: 6.0
agent-3: 10.0
agent-4: 17.0
agent-5: 7.0
agent-6: 12.0
agent-7: 16.0
agent-8: 3.0
agent-9: 5.0
agent-10: 10.0
agent-11: 20.0
agent-12: 10.0
agent-13: 10.0
agent-14: 10.0
agent-15: 19.0
agent-16: 15.0
agent-17: 11.0
agent-18: 15.0
agent-19: 19.0
agent-20: 17.0
agent-21: 8.0
agent-22: 21.0
agent-23: 17.0
agent-24: 18.0
agent-25: 18.0
agent-26: 11.0
agent-27: 18.0
agent-28: 7.0
agent-29: 14.0
agent-30: 11.0
agent-31: 12.0
agent-32: 10.0
agent-33: 9.0
agent-34: 12.0
agent-35: 14.0
agent-36: 14.0
agent-37: 23.0
agent-38: 12.0
agent-39: 12.0
agent-40: 11.0
Sum Reward: 516.0
Avg Reward: 12.9
Min Reward: 3.0
Max Reward: 23.0
Gini Coefficient: 0.19932170542635658
20:20 Ratio: 2.8363636363636364
Max-min Ratio: 7.666666666666667
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-08_02-39-12
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1283.0
  episode_reward_mean: -185.70212765957447
  episode_reward_min: -29997.0
  episodes_this_iter: 1
  episodes_total: 94
  experiment_id: 4e724eb5b3a34f42879644e84578eec0
  hostname: gpu024
  info:
    apply_time_ms: 3.751
    dispatch_time_ms: 6.768
    learner:
      cur_lr: 0.0011095840018242598
      grad_gnorm: 10.1663179397583
      policy_entropy: 725.0048828125
      policy_loss: 2.2038347721099854
      var_gnorm: 29.214290618896484
      vf_explained_var: -1.0
      vf_loss: 0.01325181219726801
    num_steps_sampled: 3800000
    num_steps_trained: 3800000
    wait_time_ms: 546.719
  iterations_since_restore: 95
  node_ip: 172.17.8.24
  num_metric_batches_dropped: 0
  pid: 26970
  policy_reward_mean: {}
  time_since_restore: 5364.489790201187
  time_this_iter_s: 56.15004563331604
  time_total_s: 5364.489790201187
  timestamp: 1594190352
  timesteps_since_restore: 3800000
  timesteps_this_iter: 40000
  timesteps_total: 3800000
  training_iteration: 95
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26970], 5364 s, 95 iter, 3800000 ts, -186 rew

agent-1: 12.0
agent-2: 16.0
agent-3: 15.0
agent-4: 12.0
agent-5: 10.0
agent-6: 15.0
agent-7: 18.0
agent-8: 10.0
agent-9: 14.0
agent-10: 13.0
agent-11: 12.0
agent-12: 10.0
agent-13: 13.0
agent-14: 19.0
agent-15: 9.0
agent-16: 11.0
agent-17: 7.0
agent-18: 13.0
agent-19: 10.0
agent-20: 6.0
agent-21: 7.0
agent-22: 8.0
agent-23: 15.0
agent-24: 10.0
agent-25: 13.0
agent-26: 16.0
agent-27: 6.0
agent-28: 4.0
agent-29: 10.0
agent-30: 9.0
agent-31: 17.0
agent-32: 10.0
agent-33: 15.0
agent-34: 10.0
agent-35: 15.0
agent-36: 10.0
agent-37: 12.0
agent-38: 8.0
agent-39: 10.0
agent-40: 9.0
Sum Reward: 459.0
Avg Reward: 11.475
Min Reward: 4.0
Max Reward: 19.0
Gini Coefficient: 0.16824618736383443
20:20 Ratio: 2.381818181818182
Max-min Ratio: 4.75
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-08_02-40-09
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1283.0
  episode_reward_mean: -178.9157894736842
  episode_reward_min: -29997.0
  episodes_this_iter: 1
  episodes_total: 95
  experiment_id: 4e724eb5b3a34f42879644e84578eec0
  hostname: gpu024
  info:
    apply_time_ms: 2.891
    dispatch_time_ms: 5.549
    learner:
      cur_lr: 0.0011069199535995722
      grad_gnorm: 12.233051300048828
      policy_entropy: 761.34765625
      policy_loss: -6.716525554656982
      var_gnorm: 29.196237564086914
      vf_explained_var: -0.07238078117370605
      vf_loss: 0.024453917518258095
    num_steps_sampled: 3840000
    num_steps_trained: 3840000
    wait_time_ms: 547.843
  iterations_since_restore: 96
  node_ip: 172.17.8.24
  num_metric_batches_dropped: 0
  pid: 26970
  policy_reward_mean: {}
  time_since_restore: 5420.924151659012
  time_this_iter_s: 56.43436145782471
  time_total_s: 5420.924151659012
  timestamp: 1594190409
  timesteps_since_restore: 3840000
  timesteps_this_iter: 40000
  timesteps_total: 3840000
  training_iteration: 96
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26970], 5420 s, 96 iter, 3840000 ts, -179 rew

agent-1: 10.0
agent-2: 10.0
agent-3: 13.0
agent-4: 11.0
agent-5: 5.0
agent-6: 12.0
agent-7: 12.0
agent-8: 7.0
agent-9: 10.0
agent-10: 11.0
agent-11: 15.0
agent-12: 15.0
agent-13: 6.0
agent-14: 3.0
agent-15: 20.0
agent-16: 15.0
agent-17: 12.0
agent-18: 11.0
agent-19: 12.0
agent-20: 5.0
agent-21: 8.0
agent-22: 13.0
agent-23: 14.0
agent-24: 14.0
agent-25: 7.0
agent-26: 13.0
agent-27: 9.0
agent-28: 13.0
agent-29: 12.0
agent-30: 19.0
agent-31: 13.0
agent-32: 6.0
agent-33: 8.0
agent-34: 10.0
agent-35: 14.0
agent-36: 12.0
agent-37: 17.0
agent-38: 9.0
agent-39: 17.0
agent-40: 12.0
Sum Reward: 455.0
Avg Reward: 11.375
Min Reward: 3.0
Max Reward: 20.0
Gini Coefficient: 0.184010989010989
20:20 Ratio: 2.8085106382978724
Max-min Ratio: 6.666666666666667
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-08_02-41-05
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1283.0
  episode_reward_mean: -172.3125
  episode_reward_min: -29997.0
  episodes_this_iter: 1
  episodes_total: 96
  experiment_id: 4e724eb5b3a34f42879644e84578eec0
  hostname: gpu024
  info:
    apply_time_ms: 3.124
    dispatch_time_ms: 5.021
    learner:
      cur_lr: 0.0011042560217902064
      grad_gnorm: 1.6626105308532715
      policy_entropy: 715.8218383789062
      policy_loss: 0.1924232691526413
      var_gnorm: 29.290191650390625
      vf_explained_var: -0.998969316482544
      vf_loss: 0.004449297674000263
    num_steps_sampled: 3880000
    num_steps_trained: 3880000
    wait_time_ms: 561.61
  iterations_since_restore: 97
  node_ip: 172.17.8.24
  num_metric_batches_dropped: 0
  pid: 26970
  policy_reward_mean: {}
  time_since_restore: 5477.750834465027
  time_this_iter_s: 56.826682806015015
  time_total_s: 5477.750834465027
  timestamp: 1594190465
  timesteps_since_restore: 3880000
  timesteps_this_iter: 40000
  timesteps_total: 3880000
  training_iteration: 97
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26970], 5477 s, 97 iter, 3880000 ts, -172 rew

agent-1: 18.0
agent-2: 11.0
agent-3: 11.0
agent-4: 10.0
agent-5: 12.0
agent-6: 5.0
agent-7: 17.0
agent-8: 17.0
agent-9: 8.0
agent-10: 20.0
agent-11: 18.0
agent-12: 13.0
agent-13: 15.0
agent-14: 5.0
agent-15: 22.0
agent-16: 10.0
agent-17: 8.0
agent-18: 8.0
agent-19: 13.0
agent-20: 5.0
agent-21: 6.0
agent-22: 12.0
agent-23: 19.0
agent-24: 19.0
agent-25: 13.0
agent-26: 10.0
agent-27: 9.0
agent-28: 13.0
agent-29: 13.0
agent-30: 9.0
agent-31: 11.0
agent-32: 6.0
agent-33: 17.0
agent-34: 10.0
agent-35: 5.0
agent-36: 18.0
agent-37: 6.0
agent-38: 19.0
agent-39: 10.0
agent-40: 2.0
Sum Reward: 473.0
Avg Reward: 11.825
Min Reward: 2.0
Max Reward: 22.0
Gini Coefficient: 0.24075052854122622
20:20 Ratio: 3.825
Max-min Ratio: 11.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-08_02-42-02
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1283.0
  episode_reward_mean: -165.659793814433
  episode_reward_min: -29997.0
  episodes_this_iter: 1
  episodes_total: 97
  experiment_id: 4e724eb5b3a34f42879644e84578eec0
  hostname: gpu024
  info:
    apply_time_ms: 4.384
    dispatch_time_ms: 6.318
    learner:
      cur_lr: 0.0011015919735655189
      grad_gnorm: 40.00000762939453
      policy_entropy: 683.89501953125
      policy_loss: 0.38510704040527344
      var_gnorm: 29.30439567565918
      vf_explained_var: 0.7074731588363647
      vf_loss: 27.998409271240234
    num_steps_sampled: 3920000
    num_steps_trained: 3920000
    wait_time_ms: 550.868
  iterations_since_restore: 98
  node_ip: 172.17.8.24
  num_metric_batches_dropped: 0
  pid: 26970
  policy_reward_mean: {}
  time_since_restore: 5534.51215171814
  time_this_iter_s: 56.76131725311279
  time_total_s: 5534.51215171814
  timestamp: 1594190522
  timesteps_since_restore: 3920000
  timesteps_this_iter: 40000
  timesteps_total: 3920000
  training_iteration: 98
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26970], 5534 s, 98 iter, 3920000 ts, -166 rew

agent-1: 14.0
agent-2: 22.0
agent-3: 15.0
agent-4: 15.0
agent-5: 6.0
agent-6: 18.0
agent-7: 14.0
agent-8: 19.0
agent-9: 1.0
agent-10: 14.0
agent-11: 13.0
agent-12: 12.0
agent-13: 5.0
agent-14: 15.0
agent-15: 10.0
agent-16: 11.0
agent-17: 16.0
agent-18: 10.0
agent-19: 9.0
agent-20: 8.0
agent-21: 11.0
agent-22: 11.0
agent-23: 10.0
agent-24: 12.0
agent-25: 12.0
agent-26: 21.0
agent-27: 12.0
agent-28: 13.0
agent-29: 13.0
agent-30: 11.0
agent-31: 9.0
agent-32: 16.0
agent-33: 6.0
agent-34: 4.0
agent-35: 12.0
agent-36: 7.0
agent-37: 15.0
agent-38: 17.0
agent-39: 4.0
agent-40: 29.0
Sum Reward: 492.0
Avg Reward: 12.3
Min Reward: 1.0
Max Reward: 29.0
Gini Coefficient: 0.2318089430894309
20:20 Ratio: 3.8536585365853657
Max-min Ratio: 29.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-08_02-42-59
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1283.0
  episode_reward_mean: -158.94897959183675
  episode_reward_min: -29997.0
  episodes_this_iter: 1
  episodes_total: 98
  experiment_id: 4e724eb5b3a34f42879644e84578eec0
  hostname: gpu024
  info:
    apply_time_ms: 2.523
    dispatch_time_ms: 5.412
    learner:
      cur_lr: 0.001098928041756153
      grad_gnorm: 0.8300755620002747
      policy_entropy: 755.7105712890625
      policy_loss: 1.980116844177246
      var_gnorm: 29.457420349121094
      vf_explained_var: -1.0
      vf_loss: 0.0017389499116688967
    num_steps_sampled: 3960000
    num_steps_trained: 3960000
    wait_time_ms: 555.644
  iterations_since_restore: 99
  node_ip: 172.17.8.24
  num_metric_batches_dropped: 0
  pid: 26970
  policy_reward_mean: {}
  time_since_restore: 5591.110570192337
  time_this_iter_s: 56.59841847419739
  time_total_s: 5591.110570192337
  timestamp: 1594190579
  timesteps_since_restore: 3960000
  timesteps_this_iter: 40000
  timesteps_total: 3960000
  training_iteration: 99
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26970], 5591 s, 99 iter, 3960000 ts, -159 rew

agent-1: 11.0
agent-2: 15.0
agent-3: 18.0
agent-4: 21.0
agent-5: 15.0
agent-6: 7.0
agent-7: 7.0
agent-8: 14.0
agent-9: 1.0
agent-10: 8.0
agent-11: 12.0
agent-12: 15.0
agent-13: 30.0
agent-14: 13.0
agent-15: 11.0
agent-16: 14.0
agent-17: 15.0
agent-18: 13.0
agent-19: 2.0
agent-20: 9.0
agent-21: 14.0
agent-22: 7.0
agent-23: 14.0
agent-24: 10.0
agent-25: 18.0
agent-26: 8.0
agent-27: 8.0
agent-28: 10.0
agent-29: 10.0
agent-30: 14.0
agent-31: 14.0
agent-32: 5.0
agent-33: 17.0
agent-34: 6.0
agent-35: 11.0
agent-36: 16.0
agent-37: 13.0
agent-38: 13.0
agent-39: 6.0
agent-40: 11.0
Sum Reward: 476.0
Avg Reward: 11.9
Min Reward: 1.0
Max Reward: 30.0
Gini Coefficient: 0.2323529411764706
20:20 Ratio: 3.658536585365854
Max-min Ratio: 30.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-08_02-43-55
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1283.0
  episode_reward_mean: -152.53535353535352
  episode_reward_min: -29997.0
  episodes_this_iter: 1
  episodes_total: 99
  experiment_id: 4e724eb5b3a34f42879644e84578eec0
  hostname: gpu024
  info:
    apply_time_ms: 2.894
    dispatch_time_ms: 6.57
    learner:
      cur_lr: 0.0010962639935314655
      grad_gnorm: 0.8606065511703491
      policy_entropy: 771.0089111328125
      policy_loss: -1.5353460311889648
      var_gnorm: 29.46979522705078
      vf_explained_var: -0.6265376806259155
      vf_loss: 0.002472651656717062
    num_steps_sampled: 4000000
    num_steps_trained: 4000000
    wait_time_ms: 553.824
  iterations_since_restore: 100
  node_ip: 172.17.8.24
  num_metric_batches_dropped: 0
  pid: 26970
  policy_reward_mean: {}
  time_since_restore: 5647.309655427933
  time_this_iter_s: 56.1990852355957
  time_total_s: 5647.309655427933
  timestamp: 1594190635
  timesteps_since_restore: 4000000
  timesteps_this_iter: 40000
  timesteps_total: 4000000
  training_iteration: 100
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26970], 5647 s, 100 iter, 4000000 ts, -153 rew

agent-1: 12.0
agent-2: 7.0
agent-3: 16.0
agent-4: 9.0
agent-5: 19.0
agent-6: 9.0
agent-7: 14.0
agent-8: 12.0
agent-9: 13.0
agent-10: 12.0
agent-11: 15.0
agent-12: 11.0
agent-13: 11.0
agent-14: 15.0
agent-15: 17.0
agent-16: 9.0
agent-17: 16.0
agent-18: 9.0
agent-19: 11.0
agent-20: 10.0
agent-21: 11.0
agent-22: 6.0
agent-23: 12.0
agent-24: 11.0
agent-25: 12.0
agent-26: 12.0
agent-27: 8.0
agent-28: 7.0
agent-29: 11.0
agent-30: 11.0
agent-31: 16.0
agent-32: 7.0
agent-33: 7.0
agent-34: 9.0
agent-35: 8.0
agent-36: 17.0
agent-37: 16.0
agent-38: 3.0
agent-39: 17.0
agent-40: 18.0
Sum Reward: 466.0
Avg Reward: 11.65
Min Reward: 3.0
Max Reward: 19.0
Gini Coefficient: 0.17929184549356222
20:20 Ratio: 2.5660377358490565
Max-min Ratio: 6.333333333333333
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-08_02-44-52
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1283.0
  episode_reward_mean: -146.35
  episode_reward_min: -29997.0
  episodes_this_iter: 1
  episodes_total: 100
  experiment_id: 4e724eb5b3a34f42879644e84578eec0
  hostname: gpu024
  info:
    apply_time_ms: 3.152
    dispatch_time_ms: 5.86
    learner:
      cur_lr: 0.001093599945306778
      grad_gnorm: 3.1990578174591064
      policy_entropy: 749.2328491210938
      policy_loss: -1.0319736003875732
      var_gnorm: 29.57942771911621
      vf_explained_var: -1.0
      vf_loss: 0.08806668967008591
    num_steps_sampled: 4040000
    num_steps_trained: 4040000
    wait_time_ms: 562.995
  iterations_since_restore: 101
  node_ip: 172.17.8.24
  num_metric_batches_dropped: 0
  pid: 26970
  policy_reward_mean: {}
  time_since_restore: 5704.092530012131
  time_this_iter_s: 56.782874584198
  time_total_s: 5704.092530012131
  timestamp: 1594190692
  timesteps_since_restore: 4040000
  timesteps_this_iter: 40000
  timesteps_total: 4040000
  training_iteration: 101
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26970], 5704 s, 101 iter, 4040000 ts, -146 rew

agent-1: 12.0
agent-2: 11.0
agent-3: 13.0
agent-4: 1.0
agent-5: 17.0
agent-6: 7.0
agent-7: 13.0
agent-8: 13.0
agent-9: 9.0
agent-10: 16.0
agent-11: 11.0
agent-12: 13.0
agent-13: 18.0
agent-14: 15.0
agent-15: 15.0
agent-16: 11.0
agent-17: 11.0
agent-18: 13.0
agent-19: 11.0
agent-20: 6.0
agent-21: 12.0
agent-22: 11.0
agent-23: 16.0
agent-24: 7.0
agent-25: 19.0
agent-26: 15.0
agent-27: 10.0
agent-28: 10.0
agent-29: 12.0
agent-30: 16.0
agent-31: 14.0
agent-32: 17.0
agent-33: 13.0
agent-34: 8.0
agent-35: 12.0
agent-36: 8.0
agent-37: 8.0
agent-38: 8.0
agent-39: 17.0
agent-40: 11.0
Sum Reward: 480.0
Avg Reward: 12.0
Min Reward: 1.0
Max Reward: 19.0
Gini Coefficient: 0.16989583333333333
20:20 Ratio: 2.5660377358490565
Max-min Ratio: 19.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-08_02-45-48
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1283.0
  episode_reward_mean: 158.42
  episode_reward_min: -28796.0
  episodes_this_iter: 1
  episodes_total: 101
  experiment_id: 4e724eb5b3a34f42879644e84578eec0
  hostname: gpu024
  info:
    apply_time_ms: 2.536
    dispatch_time_ms: 6.013
    learner:
      cur_lr: 0.0010909360134974122
      grad_gnorm: 2.5206122398376465
      policy_entropy: 768.0153198242188
      policy_loss: -2.374859571456909
      var_gnorm: 29.647602081298828
      vf_explained_var: 6.9141387939453125e-06
      vf_loss: 0.0007213947828859091
    num_steps_sampled: 4080000
    num_steps_trained: 4080000
    wait_time_ms: 569.287
  iterations_since_restore: 102
  node_ip: 172.17.8.24
  num_metric_batches_dropped: 0
  pid: 26970
  policy_reward_mean: {}
  time_since_restore: 5760.187163352966
  time_this_iter_s: 56.09463334083557
  time_total_s: 5760.187163352966
  timestamp: 1594190748
  timesteps_since_restore: 4080000
  timesteps_this_iter: 40000
  timesteps_total: 4080000
  training_iteration: 102
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26970], 5760 s, 102 iter, 4080000 ts, 158 rew

agent-1: 10.0
agent-2: 12.0
agent-3: 12.0
agent-4: 19.0
agent-5: 7.0
agent-6: 27.0
agent-7: 13.0
agent-8: 7.0
agent-9: 13.0
agent-10: 12.0
agent-11: 16.0
agent-12: 13.0
agent-13: 8.0
agent-14: 10.0
agent-15: 11.0
agent-16: 9.0
agent-17: 9.0
agent-18: 7.0
agent-19: 10.0
agent-20: 11.0
agent-21: 15.0
agent-22: 13.0
agent-23: 12.0
agent-24: 15.0
agent-25: 12.0
agent-26: 9.0
agent-27: 16.0
agent-28: 9.0
agent-29: 11.0
agent-30: 10.0
agent-31: 6.0
agent-32: 11.0
agent-33: 9.0
agent-34: 12.0
agent-35: 15.0
agent-36: 6.0
agent-37: 14.0
agent-38: 8.0
agent-39: 18.0
agent-40: 10.0
Sum Reward: 467.0
Avg Reward: 11.675
Min Reward: 6.0
Max Reward: 27.0
Gini Coefficient: 0.17553533190578158
20:20 Ratio: 2.4310344827586206
Max-min Ratio: 4.5
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-08_02-46-44
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1283.0
  episode_reward_mean: 451.05
  episode_reward_min: -4381.0
  episodes_this_iter: 1
  episodes_total: 102
  experiment_id: 4e724eb5b3a34f42879644e84578eec0
  hostname: gpu024
  info:
    apply_time_ms: 4.217
    dispatch_time_ms: 7.526
    learner:
      cur_lr: 0.0010882719652727246
      grad_gnorm: 1.263710618019104
      policy_entropy: 744.2392578125
      policy_loss: 1.5138459205627441
      var_gnorm: 29.799171447753906
      vf_explained_var: -1.0
      vf_loss: 0.0003347097081132233
    num_steps_sampled: 4120000
    num_steps_trained: 4120000
    wait_time_ms: 554.432
  iterations_since_restore: 103
  node_ip: 172.17.8.24
  num_metric_batches_dropped: 0
  pid: 26970
  policy_reward_mean: {}
  time_since_restore: 5816.358569860458
  time_this_iter_s: 56.171406507492065
  time_total_s: 5816.358569860458
  timestamp: 1594190804
  timesteps_since_restore: 4120000
  timesteps_this_iter: 40000
  timesteps_total: 4120000
  training_iteration: 103
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26970], 5816 s, 103 iter, 4120000 ts, 451 rew

agent-1: 11.0
agent-2: 12.0
agent-3: 6.0
agent-4: 6.0
agent-5: 17.0
agent-6: 17.0
agent-7: 13.0
agent-8: 16.0
agent-9: 12.0
agent-10: 15.0
agent-11: 14.0
agent-12: 11.0
agent-13: 8.0
agent-14: 8.0
agent-15: 10.0
agent-16: 7.0
agent-17: 11.0
agent-18: 11.0
agent-19: 17.0
agent-20: 11.0
agent-21: 9.0
agent-22: 16.0
agent-23: 11.0
agent-24: 14.0
agent-25: 13.0
agent-26: 17.0
agent-27: 8.0
agent-28: 9.0
agent-29: 11.0
agent-30: 10.0
agent-31: 11.0
agent-32: 10.0
agent-33: 9.0
agent-34: 5.0
agent-35: 16.0
agent-36: 10.0
agent-37: 11.0
agent-38: 18.0
agent-39: 11.0
agent-40: 10.0
Sum Reward: 462.0
Avg Reward: 11.55
Min Reward: 5.0
Max Reward: 18.0
Gini Coefficient: 0.16201298701298703
20:20 Ratio: 2.3508771929824563
Max-min Ratio: 3.6
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-08_02-47-41
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1283.0
  episode_reward_mean: 499.48
  episode_reward_min: -3249.0
  episodes_this_iter: 1
  episodes_total: 103
  experiment_id: 4e724eb5b3a34f42879644e84578eec0
  hostname: gpu024
  info:
    apply_time_ms: 2.974
    dispatch_time_ms: 6.873
    learner:
      cur_lr: 0.0010856080334633589
      grad_gnorm: 3.0217268466949463
      policy_entropy: 769.852294921875
      policy_loss: -0.6384690999984741
      var_gnorm: 29.865055084228516
      vf_explained_var: -0.472953200340271
      vf_loss: 0.0015956726856529713
    num_steps_sampled: 4160000
    num_steps_trained: 4160000
    wait_time_ms: 541.038
  iterations_since_restore: 104
  node_ip: 172.17.8.24
  num_metric_batches_dropped: 0
  pid: 26970
  policy_reward_mean: {}
  time_since_restore: 5872.681679010391
  time_this_iter_s: 56.32310914993286
  time_total_s: 5872.681679010391
  timestamp: 1594190861
  timesteps_since_restore: 4160000
  timesteps_this_iter: 40000
  timesteps_total: 4160000
  training_iteration: 104
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26970], 5872 s, 104 iter, 4160000 ts, 499 rew

agent-1: 12.0
agent-2: 8.0
agent-3: 13.0
agent-4: 11.0
agent-5: 16.0
agent-6: 12.0
agent-7: 14.0
agent-8: 15.0
agent-9: 14.0
agent-10: 7.0
agent-11: 8.0
agent-12: 8.0
agent-13: 15.0
agent-14: 13.0
agent-15: 11.0
agent-16: 14.0
agent-17: 7.0
agent-18: 3.0
agent-19: 10.0
agent-20: 7.0
agent-21: 20.0
agent-22: 13.0
agent-23: 7.0
agent-24: 14.0
agent-25: 13.0
agent-26: 9.0
agent-27: 8.0
agent-28: 12.0
agent-29: 12.0
agent-30: 14.0
agent-31: 11.0
agent-32: 17.0
agent-33: 19.0
agent-34: 16.0
agent-35: 8.0
agent-36: 11.0
agent-37: 11.0
agent-38: 7.0
agent-39: 9.0
agent-40: 12.0
Sum Reward: 461.0
Avg Reward: 11.525
Min Reward: 3.0
Max Reward: 20.0
Gini Coefficient: 0.17467462039045553
20:20 Ratio: 2.4444444444444446
Max-min Ratio: 6.666666666666667
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-08_02-48-37
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1283.0
  episode_reward_mean: 536.58
  episode_reward_min: 429.0
  episodes_this_iter: 1
  episodes_total: 104
  experiment_id: 4e724eb5b3a34f42879644e84578eec0
  hostname: gpu024
  info:
    apply_time_ms: 2.817
    dispatch_time_ms: 7.265
    learner:
      cur_lr: 0.0010829439852386713
      grad_gnorm: 1.8426910638809204
      policy_entropy: 769.7998046875
      policy_loss: 3.4961137771606445
      var_gnorm: 30.011207580566406
      vf_explained_var: -0.2446218729019165
      vf_loss: 0.0004887030809186399
    num_steps_sampled: 4200000
    num_steps_trained: 4200000
    wait_time_ms: 565.96
  iterations_since_restore: 105
  node_ip: 172.17.8.24
  num_metric_batches_dropped: 0
  pid: 26970
  policy_reward_mean: {}
  time_since_restore: 5929.442817926407
  time_this_iter_s: 56.761138916015625
  time_total_s: 5929.442817926407
  timestamp: 1594190917
  timesteps_since_restore: 4200000
  timesteps_this_iter: 40000
  timesteps_total: 4200000
  training_iteration: 105
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26970], 5929 s, 105 iter, 4200000 ts, 537 rew

agent-1: 12.0
agent-2: 7.0
agent-3: 17.0
agent-4: 12.0
agent-5: 10.0
agent-6: 9.0
agent-7: 17.0
agent-8: 11.0
agent-9: 7.0
agent-10: 11.0
agent-11: 11.0
agent-12: 12.0
agent-13: 11.0
agent-14: 18.0
agent-15: 10.0
agent-16: 7.0
agent-17: 7.0
agent-18: 7.0
agent-19: 14.0
agent-20: 14.0
agent-21: 4.0
agent-22: 18.0
agent-23: 9.0
agent-24: 13.0
agent-25: 10.0
agent-26: 14.0
agent-27: 13.0
agent-28: 8.0
agent-29: 11.0
agent-30: 15.0
agent-31: 12.0
agent-32: 12.0
agent-33: 21.0
agent-34: 7.0
agent-35: 16.0
agent-36: 7.0
agent-37: 10.0
agent-38: 13.0
agent-39: 8.0
agent-40: 11.0
Sum Reward: 456.0
Avg Reward: 11.4
Min Reward: 4.0
Max Reward: 21.0
Gini Coefficient: 0.17971491228070174
20:20 Ratio: 2.5660377358490565
Max-min Ratio: 5.25
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-08_02-49-34
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1283.0
  episode_reward_mean: 529.86
  episode_reward_min: 429.0
  episodes_this_iter: 1
  episodes_total: 105
  experiment_id: 4e724eb5b3a34f42879644e84578eec0
  hostname: gpu024
  info:
    apply_time_ms: 2.307
    dispatch_time_ms: 6.05
    learner:
      cur_lr: 0.0010802800534293056
      grad_gnorm: 6.568847179412842
      policy_entropy: 773.9790649414062
      policy_loss: -1.0063064098358154
      var_gnorm: 30.021163940429688
      vf_explained_var: -0.5668693780899048
      vf_loss: 0.01194794662296772
    num_steps_sampled: 4240000
    num_steps_trained: 4240000
    wait_time_ms: 558.345
  iterations_since_restore: 106
  node_ip: 172.17.8.24
  num_metric_batches_dropped: 0
  pid: 26970
  policy_reward_mean: {}
  time_since_restore: 5986.229758262634
  time_this_iter_s: 56.78694033622742
  time_total_s: 5986.229758262634
  timestamp: 1594190974
  timesteps_since_restore: 4240000
  timesteps_this_iter: 40000
  timesteps_total: 4240000
  training_iteration: 106
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26970], 5986 s, 106 iter, 4240000 ts, 530 rew

agent-1: 16.0
agent-2: 18.0
agent-3: 6.0
agent-4: 10.0
agent-5: 13.0
agent-6: 17.0
agent-7: 10.0
agent-8: 9.0
agent-9: 8.0
agent-10: 9.0
agent-11: 9.0
agent-12: 14.0
agent-13: 10.0
agent-14: 14.0
agent-15: 11.0
agent-16: 13.0
agent-17: 11.0
agent-18: 11.0
agent-19: 14.0
agent-20: 9.0
agent-21: 10.0
agent-22: 15.0
agent-23: 19.0
agent-24: 13.0
agent-25: 7.0
agent-26: 14.0
agent-27: 7.0
agent-28: 9.0
agent-29: 9.0
agent-30: 13.0
agent-31: 16.0
agent-32: 15.0
agent-33: 13.0
agent-34: 7.0
agent-35: 14.0
agent-36: 10.0
agent-37: 13.0
agent-38: 8.0
agent-39: 16.0
agent-40: 10.0
Sum Reward: 470.0
Avg Reward: 11.75
Min Reward: 6.0
Max Reward: 19.0
Gini Coefficient: 0.1571276595744681
20:20 Ratio: 2.1639344262295084
Max-min Ratio: 3.1666666666666665
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-08_02-50-30
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1030.0
  episode_reward_mean: 521.73
  episode_reward_min: 429.0
  episodes_this_iter: 1
  episodes_total: 106
  experiment_id: 4e724eb5b3a34f42879644e84578eec0
  hostname: gpu024
  info:
    apply_time_ms: 2.441
    dispatch_time_ms: 5.952
    learner:
      cur_lr: 0.001077616005204618
      grad_gnorm: 10.760382652282715
      policy_entropy: 693.5931396484375
      policy_loss: -5.301312446594238
      var_gnorm: 30.113557815551758
      vf_explained_var: -0.058437466621398926
      vf_loss: 0.017879970371723175
    num_steps_sampled: 4280000
    num_steps_trained: 4280000
    wait_time_ms: 559.898
  iterations_since_restore: 107
  node_ip: 172.17.8.24
  num_metric_batches_dropped: 0
  pid: 26970
  policy_reward_mean: {}
  time_since_restore: 6042.372482538223
  time_this_iter_s: 56.14272427558899
  time_total_s: 6042.372482538223
  timestamp: 1594191030
  timesteps_since_restore: 4280000
  timesteps_this_iter: 40000
  timesteps_total: 4280000
  training_iteration: 107
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26970], 6042 s, 107 iter, 4280000 ts, 522 rew

agent-1: 7.0
agent-2: 10.0
agent-3: 16.0
agent-4: 6.0
agent-5: 16.0
agent-6: 12.0
agent-7: 9.0
agent-8: 13.0
agent-9: 11.0
agent-10: 7.0
agent-11: 9.0
agent-12: 11.0
agent-13: 5.0
agent-14: 8.0
agent-15: 10.0
agent-16: 12.0
agent-17: 12.0
agent-18: 13.0
agent-19: 8.0
agent-20: 21.0
agent-21: 18.0
agent-22: 8.0
agent-23: 14.0
agent-24: 16.0
agent-25: 14.0
agent-26: 11.0
agent-27: 13.0
agent-28: 11.0
agent-29: 13.0
agent-30: 15.0
agent-31: 15.0
agent-32: 6.0
agent-33: 12.0
agent-34: 12.0
agent-35: 7.0
agent-36: 14.0
agent-37: 3.0
agent-38: 15.0
agent-39: 12.0
agent-40: 9.0
Sum Reward: 454.0
Avg Reward: 11.35
Min Reward: 3.0
Max Reward: 21.0
Gini Coefficient: 0.18436123348017622
20:20 Ratio: 2.693877551020408
Max-min Ratio: 7.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-08_02-51-27
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 700.0
  episode_reward_mean: 515.97
  episode_reward_min: 429.0
  episodes_this_iter: 1
  episodes_total: 107
  experiment_id: 4e724eb5b3a34f42879644e84578eec0
  hostname: gpu024
  info:
    apply_time_ms: 2.388
    dispatch_time_ms: 5.785
    learner:
      cur_lr: 0.0010749519569799304
      grad_gnorm: 9.060983657836914
      policy_entropy: 766.1986083984375
      policy_loss: -5.238731384277344
      var_gnorm: 30.151519775390625
      vf_explained_var: -0.23906755447387695
      vf_loss: 0.014672519639134407
    num_steps_sampled: 4320000
    num_steps_trained: 4320000
    wait_time_ms: 561.271
  iterations_since_restore: 108
  node_ip: 172.17.8.24
  num_metric_batches_dropped: 0
  pid: 26970
  policy_reward_mean: {}
  time_since_restore: 6098.91676235199
  time_this_iter_s: 56.54427981376648
  time_total_s: 6098.91676235199
  timestamp: 1594191087
  timesteps_since_restore: 4320000
  timesteps_this_iter: 40000
  timesteps_total: 4320000
  training_iteration: 108
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26970], 6098 s, 108 iter, 4320000 ts, 516 rew

agent-1: 9.0
agent-2: 15.0
agent-3: 14.0
agent-4: 16.0
agent-5: 12.0
agent-6: 5.0
agent-7: 16.0
agent-8: 11.0
agent-9: 18.0
agent-10: 11.0
agent-11: 8.0
agent-12: 9.0
agent-13: 9.0
agent-14: 17.0
agent-15: 14.0
agent-16: 10.0
agent-17: 14.0
agent-18: 5.0
agent-19: 14.0
agent-20: 15.0
agent-21: 11.0
agent-22: 10.0
agent-23: 10.0
agent-24: 22.0
agent-25: 13.0
agent-26: 7.0
agent-27: 15.0
agent-28: 9.0
agent-29: 11.0
agent-30: 16.0
agent-31: 15.0
agent-32: 8.0
agent-33: 13.0
agent-34: 9.0
agent-35: 12.0
agent-36: 9.0
agent-37: 14.0
agent-38: 1.0
agent-39: 16.0
agent-40: 14.0
Sum Reward: 477.0
Avg Reward: 11.925
Min Reward: 1.0
Max Reward: 22.0
Gini Coefficient: 0.18443396226415093
20:20 Ratio: 2.6153846153846154
Max-min Ratio: 22.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-08_02-52-23
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 633.0
  episode_reward_mean: 513.74
  episode_reward_min: 429.0
  episodes_this_iter: 1
  episodes_total: 108
  experiment_id: 4e724eb5b3a34f42879644e84578eec0
  hostname: gpu024
  info:
    apply_time_ms: 3.431
    dispatch_time_ms: 6.56
    learner:
      cur_lr: 0.0010722880251705647
      grad_gnorm: 2.774355888366699
      policy_entropy: 761.7789306640625
      policy_loss: 0.8566271662712097
      var_gnorm: 30.299375534057617
      vf_explained_var: -0.003818511962890625
      vf_loss: 0.0012305412674322724
    num_steps_sampled: 4360000
    num_steps_trained: 4360000
    wait_time_ms: 545.003
  iterations_since_restore: 109
  node_ip: 172.17.8.24
  num_metric_batches_dropped: 0
  pid: 26970
  policy_reward_mean: {}
  time_since_restore: 6155.232357978821
  time_this_iter_s: 56.315595626831055
  time_total_s: 6155.232357978821
  timestamp: 1594191143
  timesteps_since_restore: 4360000
  timesteps_this_iter: 40000
  timesteps_total: 4360000
  training_iteration: 109
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26970], 6155 s, 109 iter, 4360000 ts, 514 rew

agent-1: 9.0
agent-2: 13.0
agent-3: 14.0
agent-4: 16.0
agent-5: 10.0
agent-6: 7.0
agent-7: 13.0
agent-8: 16.0
agent-9: 12.0
agent-10: 9.0
agent-11: 13.0
agent-12: 10.0
agent-13: 14.0
agent-14: 10.0
agent-15: 6.0
agent-16: 9.0
agent-17: 9.0
agent-18: 9.0
agent-19: 10.0
agent-20: 15.0
agent-21: 11.0
agent-22: 11.0
agent-23: 7.0
agent-24: 13.0
agent-25: 14.0
agent-26: 7.0
agent-27: 12.0
agent-28: 12.0
agent-29: 3.0
agent-30: 9.0
agent-31: 12.0
agent-32: 15.0
agent-33: 12.0
agent-34: 9.0
agent-35: 10.0
agent-36: 20.0
agent-37: 12.0
agent-38: 17.0
agent-39: 16.0
agent-40: 5.0
Sum Reward: 451.0
Avg Reward: 11.275
Min Reward: 3.0
Max Reward: 20.0
Gini Coefficient: 0.1708980044345898
20:20 Ratio: 2.4339622641509435
Max-min Ratio: 6.666666666666667
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-08_02-53-20
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 633.0
  episode_reward_mean: 512.47
  episode_reward_min: 429.0
  episodes_this_iter: 1
  episodes_total: 109
  experiment_id: 4e724eb5b3a34f42879644e84578eec0
  hostname: gpu024
  info:
    apply_time_ms: 3.753
    dispatch_time_ms: 5.628
    learner:
      cur_lr: 0.001069623976945877
      grad_gnorm: 39.999996185302734
      policy_entropy: 669.2589111328125
      policy_loss: -23.4888916015625
      var_gnorm: 30.293445587158203
      vf_explained_var: 0.07028263807296753
      vf_loss: 1.1124658584594727
    num_steps_sampled: 4400000
    num_steps_trained: 4400000
    wait_time_ms: 546.811
  iterations_since_restore: 110
  node_ip: 172.17.8.24
  num_metric_batches_dropped: 0
  pid: 26970
  policy_reward_mean: {}
  time_since_restore: 6211.6909301280975
  time_this_iter_s: 56.45857214927673
  time_total_s: 6211.6909301280975
  timestamp: 1594191200
  timesteps_since_restore: 4400000
  timesteps_this_iter: 40000
  timesteps_total: 4400000
  training_iteration: 110
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26970], 6211 s, 110 iter, 4400000 ts, 512 rew

agent-1: 9.0
agent-2: 19.0
agent-3: 13.0
agent-4: 8.0
agent-5: 17.0
agent-6: 5.0
agent-7: 18.0
agent-8: 9.0
agent-9: 25.0
agent-10: 16.0
agent-11: 19.0
agent-12: 15.0
agent-13: 12.0
agent-14: 19.0
agent-15: 18.0
agent-16: 13.0
agent-17: 14.0
agent-18: 17.0
agent-19: 9.0
agent-20: 10.0
agent-21: 10.0
agent-22: 12.0
agent-23: 13.0
agent-24: 17.0
agent-25: 21.0
agent-26: 16.0
agent-27: 4.0
agent-28: 16.0
agent-29: 11.0
agent-30: 14.0
agent-31: 7.0
agent-32: 14.0
agent-33: 12.0
agent-34: 3.0
agent-35: 12.0
agent-36: 2.0
agent-37: 5.0
agent-38: 6.0
agent-39: 20.0
agent-40: 9.0
Sum Reward: 509.0
Avg Reward: 12.725
Min Reward: 2.0
Max Reward: 25.0
Gini Coefficient: 0.2368860510805501
20:20 Ratio: 3.975
Max-min Ratio: 12.5
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-08_02-54-16
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 633.0
  episode_reward_mean: 512.35
  episode_reward_min: 429.0
  episodes_this_iter: 1
  episodes_total: 110
  experiment_id: 4e724eb5b3a34f42879644e84578eec0
  hostname: gpu024
  info:
    apply_time_ms: 2.733
    dispatch_time_ms: 7.026
    learner:
      cur_lr: 0.0010669600451365113
      grad_gnorm: 2.2518277168273926
      policy_entropy: 693.131591796875
      policy_loss: 2.6610984802246094
      var_gnorm: 30.39654541015625
      vf_explained_var: -1.0
      vf_loss: 0.0012821333948522806
    num_steps_sampled: 4440000
    num_steps_trained: 4440000
    wait_time_ms: 553.007
  iterations_since_restore: 111
  node_ip: 172.17.8.24
  num_metric_batches_dropped: 0
  pid: 26970
  policy_reward_mean: {}
  time_since_restore: 6268.354151725769
  time_this_iter_s: 56.66322159767151
  time_total_s: 6268.354151725769
  timestamp: 1594191256
  timesteps_since_restore: 4440000
  timesteps_this_iter: 40000
  timesteps_total: 4440000
  training_iteration: 111
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26970], 6268 s, 111 iter, 4440000 ts, 512 rew

agent-1: 15.0
agent-2: 5.0
agent-3: 4.0
agent-4: 5.0
agent-5: 8.0
agent-6: 17.0
agent-7: 9.0
agent-8: 21.0
agent-9: 13.0
agent-10: 8.0
agent-11: 12.0
agent-12: 12.0
agent-13: 12.0
agent-14: 13.0
agent-15: 14.0
agent-16: 15.0
agent-17: 16.0
agent-18: 8.0
agent-19: 10.0
agent-20: 12.0
agent-21: 12.0
agent-22: 13.0
agent-23: 10.0
agent-24: 11.0
agent-25: 15.0
agent-26: 5.0
agent-27: 14.0
agent-28: 11.0
agent-29: 12.0
agent-30: 7.0
agent-31: 9.0
agent-32: 18.0
agent-33: 9.0
agent-34: 7.0
agent-35: 7.0
agent-36: 14.0
agent-37: 14.0
agent-38: 10.0
agent-39: 14.0
agent-40: 12.0
Sum Reward: 453.0
Avg Reward: 11.325
Min Reward: 4.0
Max Reward: 21.0
Gini Coefficient: 0.18647902869757174
20:20 Ratio: 2.7291666666666665
Max-min Ratio: 5.25
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-08_02-55-13
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 633.0
  episode_reward_mean: 512.0
  episode_reward_min: 429.0
  episodes_this_iter: 1
  episodes_total: 111
  experiment_id: 4e724eb5b3a34f42879644e84578eec0
  hostname: gpu024
  info:
    apply_time_ms: 2.82
    dispatch_time_ms: 5.469
    learner:
      cur_lr: 0.0010642959969118237
      grad_gnorm: 11.108492851257324
      policy_entropy: 604.9955444335938
      policy_loss: 0.7532564401626587
      var_gnorm: 30.369979858398438
      vf_explained_var: 0.45557427406311035
      vf_loss: 1.826850414276123
    num_steps_sampled: 4480000
    num_steps_trained: 4480000
    wait_time_ms: 556.353
  iterations_since_restore: 112
  node_ip: 172.17.8.24
  num_metric_batches_dropped: 0
  pid: 26970
  policy_reward_mean: {}
  time_since_restore: 6324.666015148163
  time_this_iter_s: 56.3118634223938
  time_total_s: 6324.666015148163
  timestamp: 1594191313
  timesteps_since_restore: 4480000
  timesteps_this_iter: 40000
  timesteps_total: 4480000
  training_iteration: 112
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26970], 6324 s, 112 iter, 4480000 ts, 512 rew

agent-1: 10.0
agent-2: 17.0
agent-3: 10.0
agent-4: 8.0
agent-5: 13.0
agent-6: 20.0
agent-7: 9.0
agent-8: 14.0
agent-9: 9.0
agent-10: 13.0
agent-11: 9.0
agent-12: 14.0
agent-13: 6.0
agent-14: 15.0
agent-15: 12.0
agent-16: 5.0
agent-17: 5.0
agent-18: 18.0
agent-19: 16.0
agent-20: 11.0
agent-21: 9.0
agent-22: 14.0
agent-23: 11.0
agent-24: 11.0
agent-25: 11.0
agent-26: 10.0
agent-27: 11.0
agent-28: 7.0
agent-29: 11.0
agent-30: 13.0
agent-31: 13.0
agent-32: 15.0
agent-33: 6.0
agent-34: 11.0
agent-35: 12.0
agent-36: 12.0
agent-37: 16.0
agent-38: 5.0
agent-39: 14.0
agent-40: 8.0
Sum Reward: 454.0
Avg Reward: 11.35
Min Reward: 5.0
Max Reward: 20.0
Gini Coefficient: 0.17720264317180617
20:20 Ratio: 2.62
Max-min Ratio: 4.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-08_02-56-09
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 633.0
  episode_reward_mean: 511.47
  episode_reward_min: 429.0
  episodes_this_iter: 1
  episodes_total: 112
  experiment_id: 4e724eb5b3a34f42879644e84578eec0
  hostname: gpu024
  info:
    apply_time_ms: 2.718
    dispatch_time_ms: 6.438
    learner:
      cur_lr: 0.0010616319486871362
      grad_gnorm: 0.6424810290336609
      policy_entropy: 756.7438354492188
      policy_loss: 0.8543342351913452
      var_gnorm: 30.57503890991211
      vf_explained_var: -1.0
      vf_loss: 0.0009135890286415815
    num_steps_sampled: 4520000
    num_steps_trained: 4520000
    wait_time_ms: 551.662
  iterations_since_restore: 113
  node_ip: 172.17.8.24
  num_metric_batches_dropped: 0
  pid: 26970
  policy_reward_mean: {}
  time_since_restore: 6381.2454829216
  time_this_iter_s: 56.5794677734375
  time_total_s: 6381.2454829216
  timestamp: 1594191369
  timesteps_since_restore: 4520000
  timesteps_this_iter: 40000
  timesteps_total: 4520000
  training_iteration: 113
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26970], 6381 s, 113 iter, 4520000 ts, 511 rew

agent-1: 6.0
agent-2: 11.0
agent-3: 14.0
agent-4: 10.0
agent-5: 9.0
agent-6: 16.0
agent-7: 16.0
agent-8: 12.0
agent-9: 13.0
agent-10: 7.0
agent-11: 9.0
agent-12: 8.0
agent-13: 11.0
agent-14: 11.0
agent-15: 9.0
agent-16: 12.0
agent-17: 13.0
agent-18: 20.0
agent-19: 18.0
agent-20: 16.0
agent-21: 13.0
agent-22: 7.0
agent-23: 17.0
agent-24: 17.0
agent-25: 12.0
agent-26: 20.0
agent-27: 17.0
agent-28: 15.0
agent-29: 11.0
agent-30: 8.0
agent-31: 6.0
agent-32: 12.0
agent-33: 8.0
agent-34: 11.0
agent-35: 14.0
agent-36: 11.0
agent-37: 17.0
agent-38: 10.0
agent-39: 11.0
agent-40: 8.0
Sum Reward: 486.0
Avg Reward: 12.15
Min Reward: 6.0
Max Reward: 20.0
Gini Coefficient: 0.17458847736625516
20:20 Ratio: 2.4482758620689653
Max-min Ratio: 3.3333333333333335
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-08_02-57-06
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 633.0
  episode_reward_mean: 510.37
  episode_reward_min: 429.0
  episodes_this_iter: 1
  episodes_total: 113
  experiment_id: 4e724eb5b3a34f42879644e84578eec0
  hostname: gpu024
  info:
    apply_time_ms: 2.686
    dispatch_time_ms: 7.082
    learner:
      cur_lr: 0.0010589680168777704
      grad_gnorm: 7.948670864105225
      policy_entropy: 770.7991943359375
      policy_loss: -4.527609348297119
      var_gnorm: 30.54816246032715
      vf_explained_var: -0.404125452041626
      vf_loss: 0.3235650062561035
    num_steps_sampled: 4560000
    num_steps_trained: 4560000
    wait_time_ms: 555.528
  iterations_since_restore: 114
  node_ip: 172.17.8.24
  num_metric_batches_dropped: 0
  pid: 26970
  policy_reward_mean: {}
  time_since_restore: 6437.505646467209
  time_this_iter_s: 56.26016354560852
  time_total_s: 6437.505646467209
  timestamp: 1594191426
  timesteps_since_restore: 4560000
  timesteps_this_iter: 40000
  timesteps_total: 4560000
  training_iteration: 114
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26970], 6437 s, 114 iter, 4560000 ts, 510 rew

agent-1: 11.0
agent-2: 14.0
agent-3: 16.0
agent-4: 7.0
agent-5: 15.0
agent-6: 9.0
agent-7: 7.0
agent-8: 14.0
agent-9: 7.0
agent-10: 10.0
agent-11: 7.0
agent-12: 11.0
agent-13: 10.0
agent-14: 13.0
agent-15: 13.0
agent-16: 10.0
agent-17: 13.0
agent-18: 12.0
agent-19: 14.0
agent-20: 11.0
agent-21: 14.0
agent-22: 10.0
agent-23: 16.0
agent-24: 14.0
agent-25: 11.0
agent-26: 14.0
agent-27: 12.0
agent-28: 1.0
agent-29: 12.0
agent-30: 15.0
agent-31: 12.0
agent-32: 11.0
agent-33: 7.0
agent-34: 16.0
agent-35: 13.0
agent-36: 13.0
agent-37: 12.0
agent-38: 8.0
agent-39: 11.0
agent-40: 14.0
Sum Reward: 460.0
Avg Reward: 11.5
Min Reward: 1.0
Max Reward: 16.0
Gini Coefficient: 0.1451086956521739
20:20 Ratio: 2.2641509433962264
Max-min Ratio: 16.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-08_02-58-02
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 633.0
  episode_reward_mean: 509.62
  episode_reward_min: 429.0
  episodes_this_iter: 1
  episodes_total: 114
  experiment_id: 4e724eb5b3a34f42879644e84578eec0
  hostname: gpu024
  info:
    apply_time_ms: 2.714
    dispatch_time_ms: 6.089
    learner:
      cur_lr: 0.0010563039686530828
      grad_gnorm: 8.09467601776123
      policy_entropy: 751.5684814453125
      policy_loss: 1.91856050491333
      var_gnorm: 30.730892181396484
      vf_explained_var: -0.058006882667541504
      vf_loss: 0.3235452175140381
    num_steps_sampled: 4600000
    num_steps_trained: 4600000
    wait_time_ms: 554.349
  iterations_since_restore: 115
  node_ip: 172.17.8.24
  num_metric_batches_dropped: 0
  pid: 26970
  policy_reward_mean: {}
  time_since_restore: 6494.082607507706
  time_this_iter_s: 56.576961040496826
  time_total_s: 6494.082607507706
  timestamp: 1594191482
  timesteps_since_restore: 4600000
  timesteps_this_iter: 40000
  timesteps_total: 4600000
  training_iteration: 115
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26970], 6494 s, 115 iter, 4600000 ts, 510 rew

agent-1: 13.0
agent-2: 18.0
agent-3: 12.0
agent-4: 8.0
agent-5: 9.0
agent-6: 13.0
agent-7: 14.0
agent-8: 3.0
agent-9: 9.0
agent-10: 11.0
agent-11: 9.0
agent-12: 10.0
agent-13: 15.0
agent-14: 11.0
agent-15: 4.0
agent-16: 6.0
agent-17: 15.0
agent-18: 15.0
agent-19: 11.0
agent-20: 14.0
agent-21: 14.0
agent-22: 10.0
agent-23: 17.0
agent-24: 14.0
agent-25: 6.0
agent-26: 7.0
agent-27: 10.0
agent-28: 12.0
agent-29: 12.0
agent-30: 12.0
agent-31: 18.0
agent-32: 8.0
agent-33: 15.0
agent-34: 7.0
agent-35: 15.0
agent-36: 18.0
agent-37: 19.0
agent-38: 9.0
agent-39: 12.0
agent-40: 4.0
Sum Reward: 459.0
Avg Reward: 11.475
Min Reward: 3.0
Max Reward: 19.0
Gini Coefficient: 0.19940087145969498
20:20 Ratio: 3.0
Max-min Ratio: 6.333333333333333
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-08_02-58-58
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 633.0
  episode_reward_mean: 509.14
  episode_reward_min: 429.0
  episodes_this_iter: 1
  episodes_total: 115
  experiment_id: 4e724eb5b3a34f42879644e84578eec0
  hostname: gpu024
  info:
    apply_time_ms: 2.85
    dispatch_time_ms: 8.087
    learner:
      cur_lr: 0.001053640036843717
      grad_gnorm: 5.609419345855713
      policy_entropy: 768.9954223632812
      policy_loss: -3.385861873626709
      var_gnorm: 30.755287170410156
      vf_explained_var: -0.7001185417175293
      vf_loss: 0.018377967178821564
    num_steps_sampled: 4640000
    num_steps_trained: 4640000
    wait_time_ms: 555.313
  iterations_since_restore: 116
  node_ip: 172.17.8.24
  num_metric_batches_dropped: 0
  pid: 26970
  policy_reward_mean: {}
  time_since_restore: 6550.141872882843
  time_this_iter_s: 56.05926537513733
  time_total_s: 6550.141872882843
  timestamp: 1594191538
  timesteps_since_restore: 4640000
  timesteps_this_iter: 40000
  timesteps_total: 4640000
  training_iteration: 116
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26970], 6550 s, 116 iter, 4640000 ts, 509 rew

agent-1: 18.0
agent-2: 19.0
agent-3: 13.0
agent-4: 10.0
agent-5: 20.0
agent-6: 17.0
agent-7: 3.0
agent-8: 11.0
agent-9: 6.0
agent-10: 12.0
agent-11: 14.0
agent-12: 13.0
agent-13: 15.0
agent-14: 13.0
agent-15: 0.0
agent-16: 6.0
agent-17: 14.0
agent-18: 5.0
agent-19: 12.0
agent-20: 15.0
agent-21: 13.0
agent-22: 5.0
agent-23: 15.0
agent-24: 14.0
agent-25: 24.0
agent-26: 20.0
agent-27: 18.0
agent-28: 10.0
agent-29: 2.0
agent-30: 9.0
agent-31: 11.0
agent-32: 20.0
agent-33: 11.0
agent-34: 12.0
agent-35: 9.0
agent-36: 23.0
agent-37: 1.0
agent-38: 15.0
agent-39: 12.0
agent-40: 16.0
Sum Reward: 496.0
Avg Reward: 12.4
Min Reward: 0.0
Max Reward: 24.0
Gini Coefficient: 0.2586693548387097
20:20 Ratio: 5.785714285714286
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-08_02-59-55
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 633.0
  episode_reward_mean: 508.58
  episode_reward_min: 429.0
  episodes_this_iter: 1
  episodes_total: 116
  experiment_id: 4e724eb5b3a34f42879644e84578eec0
  hostname: gpu024
  info:
    apply_time_ms: 3.02
    dispatch_time_ms: 7.493
    learner:
      cur_lr: 0.0010509759886190295
      grad_gnorm: 0.8791133165359497
      policy_entropy: 736.9044189453125
      policy_loss: 0.4710543751716614
      var_gnorm: 30.84727668762207
      vf_explained_var: -0.9188064336776733
      vf_loss: 0.0037430929951369762
    num_steps_sampled: 4680000
    num_steps_trained: 4680000
    wait_time_ms: 560.344
  iterations_since_restore: 117
  node_ip: 172.17.8.24
  num_metric_batches_dropped: 0
  pid: 26970
  policy_reward_mean: {}
  time_since_restore: 6606.638162136078
  time_this_iter_s: 56.49628925323486
  time_total_s: 6606.638162136078
  timestamp: 1594191595
  timesteps_since_restore: 4680000
  timesteps_this_iter: 40000
  timesteps_total: 4680000
  training_iteration: 117
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26970], 6606 s, 117 iter, 4680000 ts, 509 rew

agent-1: 10.0
agent-2: 9.0
agent-3: 5.0
agent-4: 13.0
agent-5: 14.0
agent-6: 16.0
agent-7: 5.0
agent-8: 15.0
agent-9: 9.0
agent-10: 14.0
agent-11: 4.0
agent-12: 6.0
agent-13: 1.0
agent-14: 13.0
agent-15: 12.0
agent-16: 9.0
agent-17: 11.0
agent-18: 17.0
agent-19: 19.0
agent-20: 11.0
agent-21: 7.0
agent-22: 6.0
agent-23: 17.0
agent-24: 16.0
agent-25: 14.0
agent-26: 17.0
agent-27: 16.0
agent-28: 5.0
agent-29: 11.0
agent-30: 14.0
agent-31: 16.0
agent-32: 8.0
agent-33: 16.0
agent-34: 9.0
agent-35: 6.0
agent-36: 10.0
agent-37: 16.0
agent-38: 7.0
agent-39: 15.0
agent-40: 18.0
Sum Reward: 457.0
Avg Reward: 11.425
Min Reward: 1.0
Max Reward: 19.0
Gini Coefficient: 0.2275164113785558
20:20 Ratio: 3.5789473684210527
Max-min Ratio: 19.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-08_03-00-52
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 633.0
  episode_reward_mean: 506.85
  episode_reward_min: 429.0
  episodes_this_iter: 1
  episodes_total: 117
  experiment_id: 4e724eb5b3a34f42879644e84578eec0
  hostname: gpu024
  info:
    apply_time_ms: 2.718
    dispatch_time_ms: 6.215
    learner:
      cur_lr: 0.0010483120568096638
      grad_gnorm: 2.4081919193267822
      policy_entropy: 746.2803344726562
      policy_loss: -4.311635494232178
      var_gnorm: 30.911685943603516
      vf_explained_var: 0.009962737560272217
      vf_loss: 0.0004327421193011105
    num_steps_sampled: 4720000
    num_steps_trained: 4720000
    wait_time_ms: 565.729
  iterations_since_restore: 118
  node_ip: 172.17.8.24
  num_metric_batches_dropped: 0
  pid: 26970
  policy_reward_mean: {}
  time_since_restore: 6663.304951429367
  time_this_iter_s: 56.666789293289185
  time_total_s: 6663.304951429367
  timestamp: 1594191652
  timesteps_since_restore: 4720000
  timesteps_this_iter: 40000
  timesteps_total: 4720000
  training_iteration: 118
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26970], 6663 s, 118 iter, 4720000 ts, 507 rew

agent-1: 10.0
agent-2: 14.0
agent-3: 8.0
agent-4: 7.0
agent-5: 14.0
agent-6: 15.0
agent-7: 9.0
agent-8: 15.0
agent-9: 12.0
agent-10: 2.0
agent-11: 10.0
agent-12: 17.0
agent-13: 7.0
agent-14: 11.0
agent-15: 6.0
agent-16: 3.0
agent-17: 17.0
agent-18: 6.0
agent-19: 7.0
agent-20: 10.0
agent-21: 15.0
agent-22: 12.0
agent-23: 13.0
agent-24: 9.0
agent-25: 14.0
agent-26: 11.0
agent-27: 18.0
agent-28: 12.0
agent-29: 9.0
agent-30: 11.0
agent-31: 13.0
agent-32: 11.0
agent-33: 12.0
agent-34: 16.0
agent-35: 15.0
agent-36: 6.0
agent-37: 13.0
agent-38: 16.0
agent-39: 10.0
agent-40: 11.0
Sum Reward: 447.0
Avg Reward: 11.175
Min Reward: 2.0
Max Reward: 18.0
Gini Coefficient: 0.19077181208053692
20:20 Ratio: 2.9318181818181817
Max-min Ratio: 9.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-08_03-01-48
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 633.0
  episode_reward_mean: 505.57
  episode_reward_min: 429.0
  episodes_this_iter: 1
  episodes_total: 118
  experiment_id: 4e724eb5b3a34f42879644e84578eec0
  hostname: gpu024
  info:
    apply_time_ms: 2.795
    dispatch_time_ms: 5.453
    learner:
      cur_lr: 0.0010456480085849762
      grad_gnorm: 3.2871663570404053
      policy_entropy: 723.2880859375
      policy_loss: 0.35181331634521484
      var_gnorm: 30.994094848632812
      vf_explained_var: -0.5148657560348511
      vf_loss: 0.01159665733575821
    num_steps_sampled: 4760000
    num_steps_trained: 4760000
    wait_time_ms: 556.461
  iterations_since_restore: 119
  node_ip: 172.17.8.24
  num_metric_batches_dropped: 0
  pid: 26970
  policy_reward_mean: {}
  time_since_restore: 6719.638722658157
  time_this_iter_s: 56.33377122879028
  time_total_s: 6719.638722658157
  timestamp: 1594191708
  timesteps_since_restore: 4760000
  timesteps_this_iter: 40000
  timesteps_total: 4760000
  training_iteration: 119
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26970], 6719 s, 119 iter, 4760000 ts, 506 rew

agent-1: 10.0
agent-2: 13.0
agent-3: 10.0
agent-4: 18.0
agent-5: 19.0
agent-6: 13.0
agent-7: 6.0
agent-8: 7.0
agent-9: 14.0
agent-10: 10.0
agent-11: 16.0
agent-12: 7.0
agent-13: 14.0
agent-14: 16.0
agent-15: 10.0
agent-16: 17.0
agent-17: 10.0
agent-18: 8.0
agent-19: 7.0
agent-20: 6.0
agent-21: 10.0
agent-22: 12.0
agent-23: 8.0
agent-24: 12.0
agent-25: 6.0
agent-26: 10.0
agent-27: 11.0
agent-28: 8.0
agent-29: 10.0
agent-30: 9.0
agent-31: 22.0
agent-32: 14.0
agent-33: 13.0
agent-34: 16.0
agent-35: 14.0
agent-36: 7.0
agent-37: 15.0
agent-38: 6.0
agent-39: 23.0
agent-40: 10.0
Sum Reward: 467.0
Avg Reward: 11.675
Min Reward: 6.0
Max Reward: 23.0
Gini Coefficient: 0.20433618843683082
20:20 Ratio: 2.826923076923077
Max-min Ratio: 3.8333333333333335
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-08_03-02-45
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 633.0
  episode_reward_mean: 504.77
  episode_reward_min: 429.0
  episodes_this_iter: 1
  episodes_total: 119
  experiment_id: 4e724eb5b3a34f42879644e84578eec0
  hostname: gpu024
  info:
    apply_time_ms: 2.67
    dispatch_time_ms: 5.181
    learner:
      cur_lr: 0.0010429839603602886
      grad_gnorm: 2.4960601329803467
      policy_entropy: 753.4483642578125
      policy_loss: 0.48500409722328186
      var_gnorm: 31.022602081298828
      vf_explained_var: -0.5303559303283691
      vf_loss: 0.005305199883878231
    num_steps_sampled: 4800000
    num_steps_trained: 4800000
    wait_time_ms: 570.518
  iterations_since_restore: 120
  node_ip: 172.17.8.24
  num_metric_batches_dropped: 0
  pid: 26970
  policy_reward_mean: {}
  time_since_restore: 6776.359987258911
  time_this_iter_s: 56.721264600753784
  time_total_s: 6776.359987258911
  timestamp: 1594191765
  timesteps_since_restore: 4800000
  timesteps_this_iter: 40000
  timesteps_total: 4800000
  training_iteration: 120
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26970], 6776 s, 120 iter, 4800000 ts, 505 rew

agent-1: 6.0
agent-2: 6.0
agent-3: 6.0
agent-4: 15.0
agent-5: 16.0
agent-6: 18.0
agent-7: 4.0
agent-8: 9.0
agent-9: 16.0
agent-10: 11.0
agent-11: 10.0
agent-12: 13.0
agent-13: 12.0
agent-14: 11.0
agent-15: 5.0
agent-16: 9.0
agent-17: 6.0
agent-18: 4.0
agent-19: 13.0
agent-20: 17.0
agent-21: 18.0
agent-22: 14.0
agent-23: 9.0
agent-24: 11.0
agent-25: 10.0
agent-26: 20.0
agent-27: 12.0
agent-28: 15.0
agent-29: 9.0
agent-30: 4.0
agent-31: 13.0
agent-32: 11.0
agent-33: 7.0
agent-34: 17.0
agent-35: 17.0
agent-36: 18.0
agent-37: 10.0
agent-38: 12.0
agent-39: 15.0
agent-40: 7.0
Sum Reward: 456.0
Avg Reward: 11.4
Min Reward: 4.0
Max Reward: 20.0
Gini Coefficient: 0.22302631578947368
20:20 Ratio: 3.4390243902439024
Max-min Ratio: 5.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-08_03-03-42
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 633.0
  episode_reward_mean: 503.7
  episode_reward_min: 429.0
  episodes_this_iter: 1
  episodes_total: 120
  experiment_id: 4e724eb5b3a34f42879644e84578eec0
  hostname: gpu024
  info:
    apply_time_ms: 2.597
    dispatch_time_ms: 5.032
    learner:
      cur_lr: 0.0010403200285509229
      grad_gnorm: 1.5296475887298584
      policy_entropy: 763.5481567382812
      policy_loss: -0.5130394697189331
      var_gnorm: 31.13450813293457
      vf_explained_var: -1.0
      vf_loss: 0.017014415934681892
    num_steps_sampled: 4840000
    num_steps_trained: 4840000
    wait_time_ms: 571.372
  iterations_since_restore: 121
  node_ip: 172.17.8.24
  num_metric_batches_dropped: 0
  pid: 26970
  policy_reward_mean: {}
  time_since_restore: 6833.004639863968
  time_this_iter_s: 56.64465260505676
  time_total_s: 6833.004639863968
  timestamp: 1594191822
  timesteps_since_restore: 4840000
  timesteps_this_iter: 40000
  timesteps_total: 4840000
  training_iteration: 121
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26970], 6833 s, 121 iter, 4840000 ts, 504 rew

agent-1: 12.0
agent-2: 8.0
agent-3: 13.0
agent-4: 11.0
agent-5: 16.0
agent-6: 17.0
agent-7: 14.0
agent-8: 17.0
agent-9: 8.0
agent-10: 14.0
agent-11: 11.0
agent-12: 10.0
agent-13: 11.0
agent-14: 6.0
agent-15: 14.0
agent-16: 9.0
agent-17: 13.0
agent-18: 11.0
agent-19: 17.0
agent-20: 11.0
agent-21: 14.0
agent-22: 7.0
agent-23: 3.0
agent-24: 7.0
agent-25: 12.0
agent-26: 12.0
agent-27: 8.0
agent-28: 17.0
agent-29: 9.0
agent-30: 8.0
agent-31: 16.0
agent-32: 14.0
agent-33: 8.0
agent-34: 9.0
agent-35: 15.0
agent-36: 4.0
agent-37: 13.0
agent-38: 11.0
agent-39: 6.0
agent-40: 16.0
Sum Reward: 452.0
Avg Reward: 11.3
Min Reward: 3.0
Max Reward: 17.0
Gini Coefficient: 0.18595132743362833
20:20 Ratio: 2.673469387755102
Max-min Ratio: 5.666666666666667
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-08_03-04-38
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 633.0
  episode_reward_mean: 501.99
  episode_reward_min: 429.0
  episodes_this_iter: 1
  episodes_total: 121
  experiment_id: 4e724eb5b3a34f42879644e84578eec0
  hostname: gpu024
  info:
    apply_time_ms: 4.071
    dispatch_time_ms: 6.969
    learner:
      cur_lr: 0.0010376559803262353
      grad_gnorm: 9.424934387207031
      policy_entropy: 723.3324584960938
      policy_loss: -3.3910043239593506
      var_gnorm: 31.1842041015625
      vf_explained_var: 0.46927231550216675
      vf_loss: 0.5855816602706909
    num_steps_sampled: 4880000
    num_steps_trained: 4880000
    wait_time_ms: 561.287
  iterations_since_restore: 122
  node_ip: 172.17.8.24
  num_metric_batches_dropped: 0
  pid: 26970
  policy_reward_mean: {}
  time_since_restore: 6889.003162384033
  time_this_iter_s: 55.99852252006531
  time_total_s: 6889.003162384033
  timestamp: 1594191878
  timesteps_since_restore: 4880000
  timesteps_this_iter: 40000
  timesteps_total: 4880000
  training_iteration: 122
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26970], 6889 s, 122 iter, 4880000 ts, 502 rew

agent-1: 11.0
agent-2: 14.0
agent-3: 9.0
agent-4: 6.0
agent-5: 17.0
agent-6: 15.0
agent-7: 17.0
agent-8: 12.0
agent-9: 10.0
agent-10: 10.0
agent-11: 9.0
agent-12: 9.0
agent-13: 15.0
agent-14: 8.0
agent-15: 9.0
agent-16: 8.0
agent-17: 10.0
agent-18: 18.0
agent-19: 14.0
agent-20: 13.0
agent-21: 14.0
agent-22: 11.0
agent-23: 12.0
agent-24: 11.0
agent-25: 1.0
agent-26: 11.0
agent-27: 13.0
agent-28: 6.0
agent-29: 11.0
agent-30: 15.0
agent-31: 13.0
agent-32: 10.0
agent-33: 15.0
agent-34: 13.0
agent-35: 13.0
agent-36: 19.0
agent-37: 13.0
agent-38: 10.0
agent-39: 11.0
agent-40: 13.0
Sum Reward: 469.0
Avg Reward: 11.725
Min Reward: 1.0
Max Reward: 19.0
Gini Coefficient: 0.16039445628997867
20:20 Ratio: 2.3392857142857144
Max-min Ratio: 19.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-08_03-05-34
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 633.0
  episode_reward_mean: 500.38
  episode_reward_min: 429.0
  episodes_this_iter: 1
  episodes_total: 122
  experiment_id: 4e724eb5b3a34f42879644e84578eec0
  hostname: gpu024
  info:
    apply_time_ms: 2.724
    dispatch_time_ms: 6.402
    learner:
      cur_lr: 0.0010349920485168695
      grad_gnorm: 1.5569676160812378
      policy_entropy: 763.2017822265625
      policy_loss: 1.6534888744354248
      var_gnorm: 31.240615844726562
      vf_explained_var: -1.0
      vf_loss: 0.002268728567287326
    num_steps_sampled: 4920000
    num_steps_trained: 4920000
    wait_time_ms: 558.164
  iterations_since_restore: 123
  node_ip: 172.17.8.24
  num_metric_batches_dropped: 0
  pid: 26970
  policy_reward_mean: {}
  time_since_restore: 6945.416701555252
  time_this_iter_s: 56.41353917121887
  time_total_s: 6945.416701555252
  timestamp: 1594191934
  timesteps_since_restore: 4920000
  timesteps_this_iter: 40000
  timesteps_total: 4920000
  training_iteration: 123
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26970], 6945 s, 123 iter, 4920000 ts, 500 rew

agent-1: 11.0
agent-2: 11.0
agent-3: 5.0
agent-4: 9.0
agent-5: 8.0
agent-6: 16.0
agent-7: 21.0
agent-8: 12.0
agent-9: 18.0
agent-10: 11.0
agent-11: 9.0
agent-12: 6.0
agent-13: 17.0
agent-14: 6.0
agent-15: 8.0
agent-16: 9.0
agent-17: 10.0
agent-18: 1.0
agent-19: 16.0
agent-20: 13.0
agent-21: 9.0
agent-22: 12.0
agent-23: 11.0
agent-24: 20.0
agent-25: 10.0
agent-26: 21.0
agent-27: 9.0
agent-28: 5.0
agent-29: 19.0
agent-30: 15.0
agent-31: 11.0
agent-32: 16.0
agent-33: 16.0
agent-34: 17.0
agent-35: 10.0
agent-36: 15.0
agent-37: 6.0
agent-38: 11.0
agent-39: 12.0
agent-40: 8.0
Sum Reward: 470.0
Avg Reward: 11.75
Min Reward: 1.0
Max Reward: 21.0
Gini Coefficient: 0.2245744680851064
20:20 Ratio: 3.311111111111111
Max-min Ratio: 21.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-08_03-06-31
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 633.0
  episode_reward_mean: 499.25
  episode_reward_min: 429.0
  episodes_this_iter: 1
  episodes_total: 123
  experiment_id: 4e724eb5b3a34f42879644e84578eec0
  hostname: gpu024
  info:
    apply_time_ms: 3.187
    dispatch_time_ms: 7.579
    learner:
      cur_lr: 0.001032328000292182
      grad_gnorm: 4.907952308654785
      policy_entropy: 752.6885986328125
      policy_loss: -3.692744493484497
      var_gnorm: 31.26803207397461
      vf_explained_var: 0.5885536074638367
      vf_loss: 0.030549306422472
    num_steps_sampled: 4960000
    num_steps_trained: 4960000
    wait_time_ms: 551.071
  iterations_since_restore: 124
  node_ip: 172.17.8.24
  num_metric_batches_dropped: 0
  pid: 26970
  policy_reward_mean: {}
  time_since_restore: 7002.344163417816
  time_this_iter_s: 56.92746186256409
  time_total_s: 7002.344163417816
  timestamp: 1594191991
  timesteps_since_restore: 4960000
  timesteps_this_iter: 40000
  timesteps_total: 4960000
  training_iteration: 124
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26970], 7002 s, 124 iter, 4960000 ts, 499 rew

agent-1: 20.0
agent-2: 2.0
agent-3: 3.0
agent-4: 15.0
agent-5: 12.0
agent-6: 10.0
agent-7: 18.0
agent-8: 6.0
agent-9: 7.0
agent-10: 15.0
agent-11: 21.0
agent-12: 14.0
agent-13: 5.0
agent-14: 11.0
agent-15: 4.0
agent-16: 23.0
agent-17: 23.0
agent-18: 19.0
agent-19: 15.0
agent-20: 19.0
agent-21: 10.0
agent-22: 15.0
agent-23: 3.0
agent-24: 17.0
agent-25: 2.0
agent-26: 4.0
agent-27: 14.0
agent-28: 14.0
agent-29: 7.0
agent-30: 10.0
agent-31: 8.0
agent-32: 19.0
agent-33: 10.0
agent-34: 16.0
agent-35: 19.0
agent-36: 12.0
agent-37: 11.0
agent-38: 14.0
agent-39: 28.0
agent-40: 2.0
Sum Reward: 497.0
Avg Reward: 12.425
Min Reward: 2.0
Max Reward: 28.0
Gini Coefficient: 0.3006539235412475
20:20 Ratio: 6.88
Max-min Ratio: 14.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-08_03-07-27
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 633.0
  episode_reward_mean: 498.41
  episode_reward_min: 429.0
  episodes_this_iter: 1
  episodes_total: 124
  experiment_id: 4e724eb5b3a34f42879644e84578eec0
  hostname: gpu024
  info:
    apply_time_ms: 2.527
    dispatch_time_ms: 6.211
    learner:
      cur_lr: 0.0010296639520674944
      grad_gnorm: 0.9614330530166626
      policy_entropy: 751.6162109375
      policy_loss: 0.9330269694328308
      var_gnorm: 31.319782257080078
      vf_explained_var: -1.0
      vf_loss: 0.0004407220403663814
    num_steps_sampled: 5000000
    num_steps_trained: 5000000
    wait_time_ms: 554.078
  iterations_since_restore: 125
  node_ip: 172.17.8.24
  num_metric_batches_dropped: 0
  pid: 26970
  policy_reward_mean: {}
  time_since_restore: 7058.257620334625
  time_this_iter_s: 55.91345691680908
  time_total_s: 7058.257620334625
  timestamp: 1594192047
  timesteps_since_restore: 5000000
  timesteps_this_iter: 40000
  timesteps_total: 5000000
  training_iteration: 125
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26970], 7058 s, 125 iter, 5000000 ts, 498 rew

agent-1: 9.0
agent-2: 9.0
agent-3: 10.0
agent-4: 5.0
agent-5: 10.0
agent-6: 6.0
agent-7: 5.0
agent-8: 13.0
agent-9: 14.0
agent-10: 12.0
agent-11: 10.0
agent-12: 26.0
agent-13: 12.0
agent-14: 15.0
agent-15: 4.0
agent-16: 7.0
agent-17: 6.0
agent-18: 11.0
agent-19: 12.0
agent-20: 13.0
agent-21: 8.0
agent-22: 8.0
agent-23: 16.0
agent-24: 9.0
agent-25: 16.0
agent-26: 17.0
agent-27: 17.0
agent-28: 13.0
agent-29: 13.0
agent-30: 11.0
agent-31: 8.0
agent-32: 10.0
agent-33: 2.0
agent-34: 17.0
agent-35: 13.0
agent-36: 13.0
agent-37: 13.0
agent-38: 21.0
agent-39: 17.0
agent-40: 15.0
Sum Reward: 466.0
Avg Reward: 11.65
Min Reward: 2.0
Max Reward: 26.0
Gini Coefficient: 0.2225321888412017
20:20 Ratio: 3.4186046511627906
Max-min Ratio: 13.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-08_03-08-24
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 633.0
  episode_reward_mean: 497.62
  episode_reward_min: 429.0
  episodes_this_iter: 1
  episodes_total: 125
  experiment_id: 4e724eb5b3a34f42879644e84578eec0
  hostname: gpu024
  info:
    apply_time_ms: 2.872
    dispatch_time_ms: 6.114
    learner:
      cur_lr: 0.0010270000202581286
      grad_gnorm: 5.266079425811768
      policy_entropy: 759.850341796875
      policy_loss: -6.286931037902832
      var_gnorm: 31.380104064941406
      vf_explained_var: 0.5789747834205627
      vf_loss: 0.038578636944293976
    num_steps_sampled: 5040000
    num_steps_trained: 5040000
    wait_time_ms: 568.133
  iterations_since_restore: 126
  node_ip: 172.17.8.24
  num_metric_batches_dropped: 0
  pid: 26970
  policy_reward_mean: {}
  time_since_restore: 7115.339892625809
  time_this_iter_s: 57.08227229118347
  time_total_s: 7115.339892625809
  timestamp: 1594192104
  timesteps_since_restore: 5040000
  timesteps_this_iter: 40000
  timesteps_total: 5040000
  training_iteration: 126
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26970], 7115 s, 126 iter, 5040000 ts, 498 rew

agent-1: 15.0
agent-2: 12.0
agent-3: 22.0
agent-4: 16.0
agent-5: 12.0
agent-6: 20.0
agent-7: 13.0
agent-8: 5.0
agent-9: 11.0
agent-10: 15.0
agent-11: 14.0
agent-12: 13.0
agent-13: 10.0
agent-14: 14.0
agent-15: 22.0
agent-16: 13.0
agent-17: 7.0
agent-18: 10.0
agent-19: 9.0
agent-20: 3.0
agent-21: 16.0
agent-22: 16.0
agent-23: 9.0
agent-24: 6.0
agent-25: 10.0
agent-26: 13.0
agent-27: 16.0
agent-28: 4.0
agent-29: 14.0
agent-30: 15.0
agent-31: 18.0
agent-32: 5.0
agent-33: 10.0
agent-34: 12.0
agent-35: 10.0
agent-36: 4.0
agent-37: 19.0
agent-38: 8.0
agent-39: 15.0
agent-40: 15.0
Sum Reward: 491.0
Avg Reward: 12.275
Min Reward: 3.0
Max Reward: 22.0
Gini Coefficient: 0.21715885947046842
20:20 Ratio: 3.5476190476190474
Max-min Ratio: 7.333333333333333
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-08_03-09-21
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 633.0
  episode_reward_mean: 497.47
  episode_reward_min: 429.0
  episodes_this_iter: 1
  episodes_total: 126
  experiment_id: 4e724eb5b3a34f42879644e84578eec0
  hostname: gpu024
  info:
    apply_time_ms: 2.655
    dispatch_time_ms: 5.906
    learner:
      cur_lr: 0.001024335972033441
      grad_gnorm: 0.31296977400779724
      policy_entropy: 768.7794189453125
      policy_loss: -0.058587923645973206
      var_gnorm: 31.417098999023438
      vf_explained_var: -1.0
      vf_loss: 3.2703457691241056e-05
    num_steps_sampled: 5080000
    num_steps_trained: 5080000
    wait_time_ms: 583.709
  iterations_since_restore: 127
  node_ip: 172.17.8.24
  num_metric_batches_dropped: 0
  pid: 26970
  policy_reward_mean: {}
  time_since_restore: 7171.806563138962
  time_this_iter_s: 56.466670513153076
  time_total_s: 7171.806563138962
  timestamp: 1594192161
  timesteps_since_restore: 5080000
  timesteps_this_iter: 40000
  timesteps_total: 5080000
  training_iteration: 127
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26970], 7171 s, 127 iter, 5080000 ts, 497 rew

agent-1: 8.0
agent-2: 7.0
agent-3: 22.0
agent-4: 14.0
agent-5: 11.0
agent-6: 10.0
agent-7: 9.0
agent-8: 15.0
agent-9: 16.0
agent-10: 10.0
agent-11: 6.0
agent-12: 9.0
agent-13: 18.0
agent-14: 10.0
agent-15: 20.0
agent-16: 12.0
agent-17: 13.0
agent-18: 7.0
agent-19: 10.0
agent-20: 11.0
agent-21: 14.0
agent-22: 3.0
agent-23: 11.0
agent-24: 17.0
agent-25: 9.0
agent-26: 17.0
agent-27: 10.0
agent-28: 6.0
agent-29: 12.0
agent-30: 7.0
agent-31: 8.0
agent-32: 16.0
agent-33: 13.0
agent-34: 16.0
agent-35: 17.0
agent-36: 12.0
agent-37: 19.0
agent-38: 11.0
agent-39: 14.0
agent-40: 9.0
Sum Reward: 479.0
Avg Reward: 11.975
Min Reward: 3.0
Max Reward: 22.0
Gini Coefficient: 0.1994258872651357
20:20 Ratio: 2.8076923076923075
Max-min Ratio: 7.333333333333333
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-08_03-10-17
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 633.0
  episode_reward_mean: 497.26
  episode_reward_min: 429.0
  episodes_this_iter: 1
  episodes_total: 127
  experiment_id: 4e724eb5b3a34f42879644e84578eec0
  hostname: gpu024
  info:
    apply_time_ms: 3.564
    dispatch_time_ms: 5.622
    learner:
      cur_lr: 0.0010216720402240753
      grad_gnorm: 7.494500160217285
      policy_entropy: 766.2349853515625
      policy_loss: -1.455269694328308
      var_gnorm: 31.45025062561035
      vf_explained_var: -1.0
      vf_loss: 0.034300416707992554
    num_steps_sampled: 5120000
    num_steps_trained: 5120000
    wait_time_ms: 560.032
  iterations_since_restore: 128
  node_ip: 172.17.8.24
  num_metric_batches_dropped: 0
  pid: 26970
  policy_reward_mean: {}
  time_since_restore: 7228.561507225037
  time_this_iter_s: 56.75494408607483
  time_total_s: 7228.561507225037
  timestamp: 1594192217
  timesteps_since_restore: 5120000
  timesteps_this_iter: 40000
  timesteps_total: 5120000
  training_iteration: 128
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26970], 7228 s, 128 iter, 5120000 ts, 497 rew

agent-1: 13.0
agent-2: 18.0
agent-3: 16.0
agent-4: 11.0
agent-5: 16.0
agent-6: 12.0
agent-7: 2.0
agent-8: 16.0
agent-9: 14.0
agent-10: 15.0
agent-11: 13.0
agent-12: 12.0
agent-13: 4.0
agent-14: 12.0
agent-15: 11.0
agent-16: 8.0
agent-17: 11.0
agent-18: 16.0
agent-19: 11.0
agent-20: 7.0
agent-21: 22.0
agent-22: 13.0
agent-23: 8.0
agent-24: 14.0
agent-25: 12.0
agent-26: 18.0
agent-27: 3.0
agent-28: 18.0
agent-29: 15.0
agent-30: 19.0
agent-31: 11.0
agent-32: 3.0
agent-33: 9.0
agent-34: 4.0
agent-35: 15.0
agent-36: 18.0
agent-37: 12.0
agent-38: 4.0
agent-39: 13.0
agent-40: 9.0
Sum Reward: 478.0
Avg Reward: 11.95
Min Reward: 2.0
Max Reward: 22.0
Gini Coefficient: 0.22594142259414227
20:20 Ratio: 4.142857142857143
Max-min Ratio: 11.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-08_03-11-13
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 633.0
  episode_reward_mean: 496.84
  episode_reward_min: 429.0
  episodes_this_iter: 1
  episodes_total: 128
  experiment_id: 4e724eb5b3a34f42879644e84578eec0
  hostname: gpu024
  info:
    apply_time_ms: 2.542
    dispatch_time_ms: 6.355
    learner:
      cur_lr: 0.0010190079919993877
      grad_gnorm: 2.6066031455993652
      policy_entropy: 750.6417236328125
      policy_loss: 1.0106637477874756
      var_gnorm: 31.557170867919922
      vf_explained_var: -0.6293452978134155
      vf_loss: 0.0026238667778670788
    num_steps_sampled: 5160000
    num_steps_trained: 5160000
    wait_time_ms: 557.393
  iterations_since_restore: 129
  node_ip: 172.17.8.24
  num_metric_batches_dropped: 0
  pid: 26970
  policy_reward_mean: {}
  time_since_restore: 7284.434879779816
  time_this_iter_s: 55.87337255477905
  time_total_s: 7284.434879779816
  timestamp: 1594192273
  timesteps_since_restore: 5160000
  timesteps_this_iter: 40000
  timesteps_total: 5160000
  training_iteration: 129
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26970], 7284 s, 129 iter, 5160000 ts, 497 rew

agent-1: 15.0
agent-2: 7.0
agent-3: 9.0
agent-4: 18.0
agent-5: 14.0
agent-6: 15.0
agent-7: 8.0
agent-8: 7.0
agent-9: 16.0
agent-10: 12.0
agent-11: 12.0
agent-12: 8.0
agent-13: 12.0
agent-14: 15.0
agent-15: 10.0
agent-16: 6.0
agent-17: 3.0
agent-18: 10.0
agent-19: 7.0
agent-20: 19.0
agent-21: 15.0
agent-22: 14.0
agent-23: 9.0
agent-24: 8.0
agent-25: 9.0
agent-26: 5.0
agent-27: 16.0
agent-28: 18.0
agent-29: 13.0
agent-30: 15.0
agent-31: 6.0
agent-32: 14.0
agent-33: 8.0
agent-34: 13.0
agent-35: 10.0
agent-36: 10.0
agent-37: 7.0
agent-38: 16.0
agent-39: 12.0
agent-40: 9.0
Sum Reward: 450.0
Avg Reward: 11.25
Min Reward: 3.0
Max Reward: 19.0
Gini Coefficient: 0.20033333333333334
20:20 Ratio: 2.7708333333333335
Max-min Ratio: 6.333333333333333
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-08_03-12-10
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 633.0
  episode_reward_mean: 495.55
  episode_reward_min: 429.0
  episodes_this_iter: 1
  episodes_total: 129
  experiment_id: 4e724eb5b3a34f42879644e84578eec0
  hostname: gpu024
  info:
    apply_time_ms: 2.952
    dispatch_time_ms: 7.823
    learner:
      cur_lr: 0.0010163439437747002
      grad_gnorm: 7.786118984222412
      policy_entropy: 749.4471435546875
      policy_loss: -1.883575201034546
      var_gnorm: 31.544185638427734
      vf_explained_var: 0.8528555631637573
      vf_loss: 0.007489930372685194
    num_steps_sampled: 5200000
    num_steps_trained: 5200000
    wait_time_ms: 560.889
  iterations_since_restore: 130
  node_ip: 172.17.8.24
  num_metric_batches_dropped: 0
  pid: 26970
  policy_reward_mean: {}
  time_since_restore: 7341.1358869075775
  time_this_iter_s: 56.70100712776184
  time_total_s: 7341.1358869075775
  timestamp: 1594192330
  timesteps_since_restore: 5200000
  timesteps_this_iter: 40000
  timesteps_total: 5200000
  training_iteration: 130
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26970], 7341 s, 130 iter, 5200000 ts, 496 rew

agent-1: 13.0
agent-2: 17.0
agent-3: 14.0
agent-4: 3.0
agent-5: 17.0
agent-6: 10.0
agent-7: 12.0
agent-8: 8.0
agent-9: 16.0
agent-10: 6.0
agent-11: 9.0
agent-12: 9.0
agent-13: 10.0
agent-14: 8.0
agent-15: 5.0
agent-16: 12.0
agent-17: 15.0
agent-18: 8.0
agent-19: 14.0
agent-20: 18.0
agent-21: 16.0
agent-22: 10.0
agent-23: 11.0
agent-24: 12.0
agent-25: 10.0
agent-26: 15.0
agent-27: 23.0
agent-28: 10.0
agent-29: 15.0
agent-30: 17.0
agent-31: 12.0
agent-32: 19.0
agent-33: 14.0
agent-34: 12.0
agent-35: 4.0
agent-36: 21.0
agent-37: 13.0
agent-38: 7.0
agent-39: 6.0
agent-40: 13.0
Sum Reward: 484.0
Avg Reward: 12.1
Min Reward: 3.0
Max Reward: 23.0
Gini Coefficient: 0.21074380165289255
20:20 Ratio: 3.148936170212766
Max-min Ratio: 7.666666666666667
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-08_03-13-07
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 633.0
  episode_reward_mean: 494.85
  episode_reward_min: 429.0
  episodes_this_iter: 1
  episodes_total: 130
  experiment_id: 4e724eb5b3a34f42879644e84578eec0
  hostname: gpu024
  info:
    apply_time_ms: 2.446
    dispatch_time_ms: 4.966
    learner:
      cur_lr: 0.0010136800119653344
      grad_gnorm: 0.37574252486228943
      policy_entropy: 756.359619140625
      policy_loss: 0.13777825236320496
      var_gnorm: 31.721738815307617
      vf_explained_var: -1.0
      vf_loss: 0.0018269888823851943
    num_steps_sampled: 5240000
    num_steps_trained: 5240000
    wait_time_ms: 544.502
  iterations_since_restore: 131
  node_ip: 172.17.8.24
  num_metric_batches_dropped: 0
  pid: 26970
  policy_reward_mean: {}
  time_since_restore: 7398.138984918594
  time_this_iter_s: 57.003098011016846
  time_total_s: 7398.138984918594
  timestamp: 1594192387
  timesteps_since_restore: 5240000
  timesteps_this_iter: 40000
  timesteps_total: 5240000
  training_iteration: 131
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26970], 7398 s, 131 iter, 5240000 ts, 495 rew

agent-1: 11.0
agent-2: 10.0
agent-3: 9.0
agent-4: 15.0
agent-5: 14.0
agent-6: 9.0
agent-7: 11.0
agent-8: 9.0
agent-9: 4.0
agent-10: 11.0
agent-11: 7.0
agent-12: 3.0
agent-13: 10.0
agent-14: 18.0
agent-15: 12.0
agent-16: 8.0
agent-17: 18.0
agent-18: 12.0
agent-19: 8.0
agent-20: 10.0
agent-21: 14.0
agent-22: 4.0
agent-23: 13.0
agent-24: 12.0
agent-25: 13.0
agent-26: 10.0
agent-27: 8.0
agent-28: 9.0
agent-29: 13.0
agent-30: 9.0
agent-31: 9.0
agent-32: 15.0
agent-33: 11.0
agent-34: 13.0
agent-35: 10.0
agent-36: 8.0
agent-37: 10.0
agent-38: 12.0
agent-39: 15.0
agent-40: 13.0
Sum Reward: 430.0
Avg Reward: 10.75
Min Reward: 3.0
Max Reward: 18.0
Gini Coefficient: 0.1680232558139535
20:20 Ratio: 2.44
Max-min Ratio: 6.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-08_03-14-03
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 618.0
  episode_reward_mean: 492.82
  episode_reward_min: 429.0
  episodes_this_iter: 1
  episodes_total: 131
  experiment_id: 4e724eb5b3a34f42879644e84578eec0
  hostname: gpu024
  info:
    apply_time_ms: 2.91
    dispatch_time_ms: 5.65
    learner:
      cur_lr: 0.0010110159637406468
      grad_gnorm: 20.34292221069336
      policy_entropy: 740.4903564453125
      policy_loss: -8.882461547851562
      var_gnorm: 31.733173370361328
      vf_explained_var: 0.7363914251327515
      vf_loss: 0.8376054763793945
    num_steps_sampled: 5280000
    num_steps_trained: 5280000
    wait_time_ms: 544.283
  iterations_since_restore: 132
  node_ip: 172.17.8.24
  num_metric_batches_dropped: 0
  pid: 26970
  policy_reward_mean: {}
  time_since_restore: 7454.20056271553
  time_this_iter_s: 56.061577796936035
  time_total_s: 7454.20056271553
  timestamp: 1594192443
  timesteps_since_restore: 5280000
  timesteps_this_iter: 40000
  timesteps_total: 5280000
  training_iteration: 132
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26970], 7454 s, 132 iter, 5280000 ts, 493 rew

agent-1: 9.0
agent-2: 7.0
agent-3: 12.0
agent-4: 4.0
agent-5: 8.0
agent-6: 14.0
agent-7: 9.0
agent-8: 12.0
agent-9: 9.0
agent-10: 2.0
agent-11: 13.0
agent-12: 13.0
agent-13: 14.0
agent-14: 14.0
agent-15: 13.0
agent-16: 6.0
agent-17: 11.0
agent-18: 5.0
agent-19: 11.0
agent-20: 17.0
agent-21: 14.0
agent-22: 14.0
agent-23: 8.0
agent-24: 15.0
agent-25: 12.0
agent-26: 11.0
agent-27: 10.0
agent-28: 20.0
agent-29: 7.0
agent-30: 10.0
agent-31: 15.0
agent-32: 16.0
agent-33: 12.0
agent-34: 14.0
agent-35: 9.0
agent-36: 11.0
agent-37: 10.0
agent-38: 11.0
agent-39: 13.0
agent-40: 9.0
Sum Reward: 444.0
Avg Reward: 11.1
Min Reward: 2.0
Max Reward: 20.0
Gini Coefficient: 0.17882882882882883
20:20 Ratio: 2.6595744680851063
Max-min Ratio: 10.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-08_03-15-00
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 618.0
  episode_reward_mean: 491.94
  episode_reward_min: 429.0
  episodes_this_iter: 1
  episodes_total: 132
  experiment_id: 4e724eb5b3a34f42879644e84578eec0
  hostname: gpu024
  info:
    apply_time_ms: 2.761
    dispatch_time_ms: 7.104
    learner:
      cur_lr: 0.001008352031931281
      grad_gnorm: 1.372565746307373
      policy_entropy: 764.9578857421875
      policy_loss: 0.40027540922164917
      var_gnorm: 31.814510345458984
      vf_explained_var: -1.0
      vf_loss: 0.0027232388965785503
    num_steps_sampled: 5320000
    num_steps_trained: 5320000
    wait_time_ms: 556.988
  iterations_since_restore: 133
  node_ip: 172.17.8.24
  num_metric_batches_dropped: 0
  pid: 26970
  policy_reward_mean: {}
  time_since_restore: 7510.639439344406
  time_this_iter_s: 56.43887662887573
  time_total_s: 7510.639439344406
  timestamp: 1594192500
  timesteps_since_restore: 5320000
  timesteps_this_iter: 40000
  timesteps_total: 5320000
  training_iteration: 133
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26970], 7510 s, 133 iter, 5320000 ts, 492 rew

agent-1: 18.0
agent-2: 15.0
agent-3: 8.0
agent-4: 13.0
agent-5: 18.0
agent-6: 13.0
agent-7: 9.0
agent-8: 11.0
agent-9: 15.0
agent-10: 16.0
agent-11: 6.0
agent-12: 11.0
agent-13: 16.0
agent-14: 13.0
agent-15: 14.0
agent-16: 9.0
agent-17: 9.0
agent-18: 7.0
agent-19: 15.0
agent-20: 14.0
agent-21: 11.0
agent-22: 10.0
agent-23: 22.0
agent-24: 15.0
agent-25: 25.0
agent-26: 11.0
agent-27: 13.0
agent-28: 8.0
agent-29: 19.0
agent-30: 7.0
agent-31: 8.0
agent-32: 16.0
agent-33: 12.0
agent-34: 13.0
agent-35: 9.0
agent-36: 9.0
agent-37: 12.0
agent-38: 2.0
agent-39: 9.0
agent-40: 8.0
Sum Reward: 489.0
Avg Reward: 12.225
Min Reward: 2.0
Max Reward: 25.0
Gini Coefficient: 0.20097137014314928
20:20 Ratio: 2.7777777777777777
Max-min Ratio: 12.5
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-08_03-15-57
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 618.0
  episode_reward_mean: 491.29
  episode_reward_min: 429.0
  episodes_this_iter: 1
  episodes_total: 133
  experiment_id: 4e724eb5b3a34f42879644e84578eec0
  hostname: gpu024
  info:
    apply_time_ms: 2.803
    dispatch_time_ms: 8.095
    learner:
      cur_lr: 0.0010056879837065935
      grad_gnorm: 8.537439346313477
      policy_entropy: 774.369384765625
      policy_loss: -0.1032564640045166
      var_gnorm: 31.850988388061523
      vf_explained_var: 0.9556484222412109
      vf_loss: 0.011623365804553032
    num_steps_sampled: 5360000
    num_steps_trained: 5360000
    wait_time_ms: 553.327
  iterations_since_restore: 134
  node_ip: 172.17.8.24
  num_metric_batches_dropped: 0
  pid: 26970
  policy_reward_mean: {}
  time_since_restore: 7567.621950149536
  time_this_iter_s: 56.982510805130005
  time_total_s: 7567.621950149536
  timestamp: 1594192557
  timesteps_since_restore: 5360000
  timesteps_this_iter: 40000
  timesteps_total: 5360000
  training_iteration: 134
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26970], 7567 s, 134 iter, 5360000 ts, 491 rew

agent-1: 9.0
agent-2: 8.0
agent-3: 12.0
agent-4: 8.0
agent-5: 13.0
agent-6: 4.0
agent-7: 2.0
agent-8: 16.0
agent-9: 10.0
agent-10: 2.0
agent-11: 14.0
agent-12: 12.0
agent-13: 8.0
agent-14: 16.0
agent-15: 10.0
agent-16: 15.0
agent-17: 14.0
agent-18: 15.0
agent-19: 14.0
agent-20: 9.0
agent-21: 17.0
agent-22: 14.0
agent-23: 14.0
agent-24: 16.0
agent-25: 13.0
agent-26: 13.0
agent-27: 18.0
agent-28: 10.0
agent-29: 6.0
agent-30: 11.0
agent-31: 11.0
agent-32: 13.0
agent-33: 15.0
agent-34: 17.0
agent-35: 11.0
agent-36: 10.0
agent-37: 13.0
agent-38: 11.0
agent-39: 12.0
agent-40: 7.0
Sum Reward: 463.0
Avg Reward: 11.575
Min Reward: 2.0
Max Reward: 18.0
Gini Coefficient: 0.18385529157667388
20:20 Ratio: 2.888888888888889
Max-min Ratio: 9.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-08_03-16-53
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 618.0
  episode_reward_mean: 489.93
  episode_reward_min: 429.0
  episodes_this_iter: 1
  episodes_total: 134
  experiment_id: 4e724eb5b3a34f42879644e84578eec0
  hostname: gpu024
  info:
    apply_time_ms: 3.448
    dispatch_time_ms: 7.304
    learner:
      cur_lr: 0.0010030240518972278
      grad_gnorm: 1.643596887588501
      policy_entropy: 762.0484619140625
      policy_loss: -0.4622701406478882
      var_gnorm: 31.9226016998291
      vf_explained_var: -0.863876223564148
      vf_loss: 0.0024496703408658504
    num_steps_sampled: 5400000
    num_steps_trained: 5400000
    wait_time_ms: 555.614
  iterations_since_restore: 135
  node_ip: 172.17.8.24
  num_metric_batches_dropped: 0
  pid: 26970
  policy_reward_mean: {}
  time_since_restore: 7624.094154834747
  time_this_iter_s: 56.47220468521118
  time_total_s: 7624.094154834747
  timestamp: 1594192613
  timesteps_since_restore: 5400000
  timesteps_this_iter: 40000
  timesteps_total: 5400000
  training_iteration: 135
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26970], 7624 s, 135 iter, 5400000 ts, 490 rew

agent-1: 11.0
agent-2: 9.0
agent-3: 19.0
agent-4: 16.0
agent-5: 12.0
agent-6: 11.0
agent-7: 9.0
agent-8: 11.0
agent-9: 13.0
agent-10: 12.0
agent-11: 13.0
agent-12: 5.0
agent-13: 12.0
agent-14: 15.0
agent-15: 14.0
agent-16: 9.0
agent-17: 6.0
agent-18: 10.0
agent-19: 18.0
agent-20: 12.0
agent-21: 18.0
agent-22: 8.0
agent-23: 7.0
agent-24: 14.0
agent-25: 12.0
agent-26: 8.0
agent-27: 9.0
agent-28: 13.0
agent-29: 12.0
agent-30: 15.0
agent-31: 8.0
agent-32: 9.0
agent-33: 12.0
agent-34: 16.0
agent-35: 13.0
agent-36: 14.0
agent-37: 9.0
agent-38: 13.0
agent-39: 14.0
agent-40: 9.0
Sum Reward: 470.0
Avg Reward: 11.75
Min Reward: 5.0
Max Reward: 19.0
Gini Coefficient: 0.1545744680851064
20:20 Ratio: 2.183333333333333
Max-min Ratio: 3.8
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-08_03-17-49
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 618.0
  episode_reward_mean: 489.07
  episode_reward_min: 429.0
  episodes_this_iter: 1
  episodes_total: 135
  experiment_id: 4e724eb5b3a34f42879644e84578eec0
  hostname: gpu024
  info:
    apply_time_ms: 2.687
    dispatch_time_ms: 6.386
    learner:
      cur_lr: 0.0010003600036725402
      grad_gnorm: 12.281115531921387
      policy_entropy: 769.0125732421875
      policy_loss: 7.2272748947143555
      var_gnorm: 31.969911575317383
      vf_explained_var: -1.0
      vf_loss: 0.06471575796604156
    num_steps_sampled: 5440000
    num_steps_trained: 5440000
    wait_time_ms: 544.918
  iterations_since_restore: 136
  node_ip: 172.17.8.24
  num_metric_batches_dropped: 0
  pid: 26970
  policy_reward_mean: {}
  time_since_restore: 7680.286246776581
  time_this_iter_s: 56.192091941833496
  time_total_s: 7680.286246776581
  timestamp: 1594192669
  timesteps_since_restore: 5440000
  timesteps_this_iter: 40000
  timesteps_total: 5440000
  training_iteration: 136
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26970], 7680 s, 136 iter, 5440000 ts, 489 rew

agent-1: 6.0
agent-2: 17.0
agent-3: 13.0
agent-4: 17.0
agent-5: 10.0
agent-6: 12.0
agent-7: 6.0
agent-8: 14.0
agent-9: 13.0
agent-10: 16.0
agent-11: 12.0
agent-12: 8.0
agent-13: 10.0
agent-14: 17.0
agent-15: 6.0
agent-16: 8.0
agent-17: 10.0
agent-18: 12.0
agent-19: 7.0
agent-20: 14.0
agent-21: 13.0
agent-22: 7.0
agent-23: 10.0
agent-24: 18.0
agent-25: 8.0
agent-26: 14.0
agent-27: 9.0
agent-28: 10.0
agent-29: 9.0
agent-30: 15.0
agent-31: 10.0
agent-32: 18.0
agent-33: 6.0
agent-34: 9.0
agent-35: 13.0
agent-36: 14.0
agent-37: 21.0
agent-38: 11.0
agent-39: 8.0
agent-40: 12.0
Sum Reward: 463.0
Avg Reward: 11.575
Min Reward: 6.0
Max Reward: 21.0
Gini Coefficient: 0.18558315334773218
20:20 Ratio: 2.574074074074074
Max-min Ratio: 3.5
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-08_03-18-46
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 618.0
  episode_reward_mean: 488.35
  episode_reward_min: 429.0
  episodes_this_iter: 1
  episodes_total: 136
  experiment_id: 4e724eb5b3a34f42879644e84578eec0
  hostname: gpu024
  info:
    apply_time_ms: 2.814
    dispatch_time_ms: 5.863
    learner:
      cur_lr: 0.0009976959554478526
      grad_gnorm: 2.6707146167755127
      policy_entropy: 764.2756958007812
      policy_loss: 0.6719212532043457
      var_gnorm: 32.039791107177734
      vf_explained_var: -1.0
      vf_loss: 0.006817384622991085
    num_steps_sampled: 5480000
    num_steps_trained: 5480000
    wait_time_ms: 551.731
  iterations_since_restore: 137
  node_ip: 172.17.8.24
  num_metric_batches_dropped: 0
  pid: 26970
  policy_reward_mean: {}
  time_since_restore: 7736.751830816269
  time_this_iter_s: 56.46558403968811
  time_total_s: 7736.751830816269
  timestamp: 1594192726
  timesteps_since_restore: 5480000
  timesteps_this_iter: 40000
  timesteps_total: 5480000
  training_iteration: 137
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26970], 7736 s, 137 iter, 5480000 ts, 488 rew

agent-1: 7.0
agent-2: 11.0
agent-3: 15.0
agent-4: 12.0
agent-5: 10.0
agent-6: 5.0
agent-7: 14.0
agent-8: 8.0
agent-9: 8.0
agent-10: 7.0
agent-11: 11.0
agent-12: 12.0
agent-13: 4.0
agent-14: 13.0
agent-15: 13.0
agent-16: 10.0
agent-17: 12.0
agent-18: 14.0
agent-19: 7.0
agent-20: 12.0
agent-21: 13.0
agent-22: 10.0
agent-23: 9.0
agent-24: 12.0
agent-25: 12.0
agent-26: 12.0
agent-27: 10.0
agent-28: 14.0
agent-29: 13.0
agent-30: 11.0
agent-31: 10.0
agent-32: 17.0
agent-33: 13.0
agent-34: 16.0
agent-35: 16.0
agent-36: 18.0
agent-37: 12.0
agent-38: 5.0
agent-39: 15.0
agent-40: 10.0
Sum Reward: 453.0
Avg Reward: 11.325
Min Reward: 4.0
Max Reward: 18.0
Gini Coefficient: 0.1587748344370861
20:20 Ratio: 2.450980392156863
Max-min Ratio: 4.5
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-08_03-19-43
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 618.0
  episode_reward_mean: 486.91
  episode_reward_min: 429.0
  episodes_this_iter: 1
  episodes_total: 137
  experiment_id: 4e724eb5b3a34f42879644e84578eec0
  hostname: gpu024
  info:
    apply_time_ms: 2.568
    dispatch_time_ms: 5.922
    learner:
      cur_lr: 0.0009950320236384869
      grad_gnorm: 3.3942716121673584
      policy_entropy: 757.291748046875
      policy_loss: -3.8925609588623047
      var_gnorm: 32.063865661621094
      vf_explained_var: -0.16687428951263428
      vf_loss: 0.0015248798299580812
    num_steps_sampled: 5520000
    num_steps_trained: 5520000
    wait_time_ms: 565.639
  iterations_since_restore: 138
  node_ip: 172.17.8.24
  num_metric_batches_dropped: 0
  pid: 26970
  policy_reward_mean: {}
  time_since_restore: 7793.583410739899
  time_this_iter_s: 56.83157992362976
  time_total_s: 7793.583410739899
  timestamp: 1594192783
  timesteps_since_restore: 5520000
  timesteps_this_iter: 40000
  timesteps_total: 5520000
  training_iteration: 138
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26970], 7793 s, 138 iter, 5520000 ts, 487 rew

agent-1: 10.0
agent-2: 13.0
agent-3: 17.0
agent-4: 9.0
agent-5: 12.0
agent-6: 10.0
agent-7: 11.0
agent-8: 15.0
agent-9: 7.0
agent-10: 13.0
agent-11: 12.0
agent-12: 10.0
agent-13: 14.0
agent-14: 6.0
agent-15: 10.0
agent-16: 9.0
agent-17: 16.0
agent-18: 3.0
agent-19: 20.0
agent-20: 17.0
agent-21: 13.0
agent-22: 10.0
agent-23: 21.0
agent-24: 11.0
agent-25: 7.0
agent-26: 10.0
agent-27: 11.0
agent-28: 5.0
agent-29: 9.0
agent-30: 8.0
agent-31: 8.0
agent-32: 14.0
agent-33: 9.0
agent-34: 13.0
agent-35: 11.0
agent-36: 7.0
agent-37: 3.0
agent-38: 14.0
agent-39: 12.0
agent-40: 15.0
Sum Reward: 445.0
Avg Reward: 11.125
Min Reward: 3.0
Max Reward: 21.0
Gini Coefficient: 0.19882022471910113
20:20 Ratio: 2.9347826086956523
Max-min Ratio: 7.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-08_03-20-39
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 618.0
  episode_reward_mean: 485.68
  episode_reward_min: 429.0
  episodes_this_iter: 1
  episodes_total: 138
  experiment_id: 4e724eb5b3a34f42879644e84578eec0
  hostname: gpu024
  info:
    apply_time_ms: 3.715
    dispatch_time_ms: 6.793
    learner:
      cur_lr: 0.0009923679754137993
      grad_gnorm: 0.8500128984451294
      policy_entropy: 766.7940063476562
      policy_loss: 1.136966586112976
      var_gnorm: 32.0648193359375
      vf_explained_var: -1.0
      vf_loss: 0.0013749406207352877
    num_steps_sampled: 5560000
    num_steps_trained: 5560000
    wait_time_ms: 547.541
  iterations_since_restore: 139
  node_ip: 172.17.8.24
  num_metric_batches_dropped: 0
  pid: 26970
  policy_reward_mean: {}
  time_since_restore: 7850.166121721268
  time_this_iter_s: 56.58271098136902
  time_total_s: 7850.166121721268
  timestamp: 1594192839
  timesteps_since_restore: 5560000
  timesteps_this_iter: 40000
  timesteps_total: 5560000
  training_iteration: 139
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26970], 7850 s, 139 iter, 5560000 ts, 486 rew

agent-1: 14.0
agent-2: 12.0
agent-3: 8.0
agent-4: 2.0
agent-5: 10.0
agent-6: 10.0
agent-7: 9.0
agent-8: 13.0
agent-9: 6.0
agent-10: 11.0
agent-11: 9.0
agent-12: 11.0
agent-13: 11.0
agent-14: 15.0
agent-15: 14.0
agent-16: 11.0
agent-17: 16.0
agent-18: 18.0
agent-19: 10.0
agent-20: 16.0
agent-21: 10.0
agent-22: 12.0
agent-23: 4.0
agent-24: 16.0
agent-25: 14.0
agent-26: 7.0
agent-27: 11.0
agent-28: 13.0
agent-29: 16.0
agent-30: 13.0
agent-31: 5.0
agent-32: 16.0
agent-33: 11.0
agent-34: 11.0
agent-35: 13.0
agent-36: 8.0
agent-37: 4.0
agent-38: 7.0
agent-39: 10.0
agent-40: 8.0
Sum Reward: 435.0
Avg Reward: 10.875
Min Reward: 2.0
Max Reward: 18.0
Gini Coefficient: 0.19120689655172413
20:20 Ratio: 2.953488372093023
Max-min Ratio: 9.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-08_03-21-36
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 618.0
  episode_reward_mean: 484.7
  episode_reward_min: 429.0
  episodes_this_iter: 1
  episodes_total: 139
  experiment_id: 4e724eb5b3a34f42879644e84578eec0
  hostname: gpu024
  info:
    apply_time_ms: 2.66
    dispatch_time_ms: 6.976
    learner:
      cur_lr: 0.0009897040436044335
      grad_gnorm: 2.3755931854248047
      policy_entropy: 765.020751953125
      policy_loss: 2.742062568664551
      var_gnorm: 32.13957595825195
      vf_explained_var: -0.7845914363861084
      vf_loss: 0.0053866347298026085
    num_steps_sampled: 5600000
    num_steps_trained: 5600000
    wait_time_ms: 542.172
  iterations_since_restore: 140
  node_ip: 172.17.8.24
  num_metric_batches_dropped: 0
  pid: 26970
  policy_reward_mean: {}
  time_since_restore: 7906.668462753296
  time_this_iter_s: 56.5023410320282
  time_total_s: 7906.668462753296
  timestamp: 1594192896
  timesteps_since_restore: 5600000
  timesteps_this_iter: 40000
  timesteps_total: 5600000
  training_iteration: 140
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26970], 7906 s, 140 iter, 5600000 ts, 485 rew

agent-1: 13.0
agent-2: 8.0
agent-3: 11.0
agent-4: 12.0
agent-5: 13.0
agent-6: 10.0
agent-7: 12.0
agent-8: 13.0
agent-9: 9.0
agent-10: 11.0
agent-11: 6.0
agent-12: 17.0
agent-13: 12.0
agent-14: 14.0
agent-15: 6.0
agent-16: 12.0
agent-17: 12.0
agent-18: 3.0
agent-19: 10.0
agent-20: 8.0
agent-21: 9.0
agent-22: 12.0
agent-23: 12.0
agent-24: 12.0
agent-25: 8.0
agent-26: 20.0
agent-27: 9.0
agent-28: 17.0
agent-29: 10.0
agent-30: 16.0
agent-31: 5.0
agent-32: 18.0
agent-33: 9.0
agent-34: 10.0
agent-35: 9.0
agent-36: 9.0
agent-37: 13.0
agent-38: 13.0
agent-39: 11.0
agent-40: 12.0
Sum Reward: 446.0
Avg Reward: 11.15
Min Reward: 3.0
Max Reward: 20.0
Gini Coefficient: 0.16737668161434976
20:20 Ratio: 2.4150943396226414
Max-min Ratio: 6.666666666666667
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-08_03-22-32
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 618.0
  episode_reward_mean: 483.53
  episode_reward_min: 429.0
  episodes_this_iter: 1
  episodes_total: 140
  experiment_id: 4e724eb5b3a34f42879644e84578eec0
  hostname: gpu024
  info:
    apply_time_ms: 3.126
    dispatch_time_ms: 6.106
    learner:
      cur_lr: 0.000987039995379746
      grad_gnorm: 1.7321990728378296
      policy_entropy: 771.0113525390625
      policy_loss: -0.6058415174484253
      var_gnorm: 32.1542854309082
      vf_explained_var: -0.9585399627685547
      vf_loss: 0.0011516236700117588
    num_steps_sampled: 5640000
    num_steps_trained: 5640000
    wait_time_ms: 558.582
  iterations_since_restore: 141
  node_ip: 172.17.8.24
  num_metric_batches_dropped: 0
  pid: 26970
  policy_reward_mean: {}
  time_since_restore: 7962.847919464111
  time_this_iter_s: 56.17945671081543
  time_total_s: 7962.847919464111
  timestamp: 1594192952
  timesteps_since_restore: 5640000
  timesteps_this_iter: 40000
  timesteps_total: 5640000
  training_iteration: 141
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26970], 7962 s, 141 iter, 5640000 ts, 484 rew

agent-1: 11.0
agent-2: 11.0
agent-3: 8.0
agent-4: 10.0
agent-5: 4.0
agent-6: 15.0
agent-7: 8.0
agent-8: 9.0
agent-9: 11.0
agent-10: 9.0
agent-11: 6.0
agent-12: 12.0
agent-13: 17.0
agent-14: 8.0
agent-15: 16.0
agent-16: 14.0
agent-17: 13.0
agent-18: 11.0
agent-19: 8.0
agent-20: 10.0
agent-21: 10.0
agent-22: 14.0
agent-23: 13.0
agent-24: 7.0
agent-25: 15.0
agent-26: 12.0
agent-27: 11.0
agent-28: 14.0
agent-29: 13.0
agent-30: 10.0
agent-31: 11.0
agent-32: 8.0
agent-33: 18.0
agent-34: 6.0
agent-35: 13.0
agent-36: 10.0
agent-37: 6.0
agent-38: 7.0
agent-39: 12.0
agent-40: 4.0
Sum Reward: 425.0
Avg Reward: 10.625
Min Reward: 4.0
Max Reward: 18.0
Gini Coefficient: 0.17794117647058824
20:20 Ratio: 2.5625
Max-min Ratio: 4.5
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-08_03-23-29
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 618.0
  episode_reward_mean: 482.15
  episode_reward_min: 425.0
  episodes_this_iter: 1
  episodes_total: 141
  experiment_id: 4e724eb5b3a34f42879644e84578eec0
  hostname: gpu024
  info:
    apply_time_ms: 2.927
    dispatch_time_ms: 5.378
    learner:
      cur_lr: 0.0009843759471550584
      grad_gnorm: 5.19881010055542
      policy_entropy: 762.878662109375
      policy_loss: 4.210676670074463
      var_gnorm: 32.220706939697266
      vf_explained_var: -0.9329659938812256
      vf_loss: 0.006124170497059822
    num_steps_sampled: 5680000
    num_steps_trained: 5680000
    wait_time_ms: 554.827
  iterations_since_restore: 142
  node_ip: 172.17.8.24
  num_metric_batches_dropped: 0
  pid: 26970
  policy_reward_mean: {}
  time_since_restore: 8019.502883434296
  time_this_iter_s: 56.654963970184326
  time_total_s: 8019.502883434296
  timestamp: 1594193009
  timesteps_since_restore: 5680000
  timesteps_this_iter: 40000
  timesteps_total: 5680000
  training_iteration: 142
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26970], 8019 s, 142 iter, 5680000 ts, 482 rew

agent-1: 12.0
agent-2: 12.0
agent-3: 16.0
agent-4: 15.0
agent-5: 18.0
agent-6: 17.0
agent-7: 7.0
agent-8: 18.0
agent-9: 5.0
agent-10: 15.0
agent-11: 4.0
agent-12: 12.0
agent-13: 10.0
agent-14: 19.0
agent-15: 8.0
agent-16: 10.0
agent-17: 13.0
agent-18: 4.0
agent-19: 12.0
agent-20: 18.0
agent-21: 8.0
agent-22: 25.0
agent-23: 11.0
agent-24: 11.0
agent-25: 12.0
agent-26: 10.0
agent-27: 7.0
agent-28: 13.0
agent-29: 14.0
agent-30: 11.0
agent-31: 9.0
agent-32: 16.0
agent-33: 8.0
agent-34: 7.0
agent-35: 13.0
agent-36: 5.0
agent-37: 13.0
agent-38: 8.0
agent-39: 8.0
agent-40: 8.0
Sum Reward: 462.0
Avg Reward: 11.55
Min Reward: 4.0
Max Reward: 25.0
Gini Coefficient: 0.21861471861471862
20:20 Ratio: 3.127659574468085
Max-min Ratio: 6.25
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-08_03-24-25
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 618.0
  episode_reward_mean: 481.07
  episode_reward_min: 425.0
  episodes_this_iter: 1
  episodes_total: 142
  experiment_id: 4e724eb5b3a34f42879644e84578eec0
  hostname: gpu024
  info:
    apply_time_ms: 3.267
    dispatch_time_ms: 6.417
    learner:
      cur_lr: 0.0009817120153456926
      grad_gnorm: 1.98557710647583
      policy_entropy: 719.78271484375
      policy_loss: -0.7367589473724365
      var_gnorm: 32.31781768798828
      vf_explained_var: -0.39607298374176025
      vf_loss: 0.0017454053740948439
    num_steps_sampled: 5720000
    num_steps_trained: 5720000
    wait_time_ms: 560.872
  iterations_since_restore: 143
  node_ip: 172.17.8.24
  num_metric_batches_dropped: 0
  pid: 26970
  policy_reward_mean: {}
  time_since_restore: 8075.949866294861
  time_this_iter_s: 56.446982860565186
  time_total_s: 8075.949866294861
  timestamp: 1594193065
  timesteps_since_restore: 5720000
  timesteps_this_iter: 40000
  timesteps_total: 5720000
  training_iteration: 143
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26970], 8075 s, 143 iter, 5720000 ts, 481 rew

agent-1: 10.0
agent-2: 12.0
agent-3: 9.0
agent-4: 11.0
agent-5: 12.0
agent-6: 23.0
agent-7: 14.0
agent-8: 12.0
agent-9: 17.0
agent-10: 13.0
agent-11: 13.0
agent-12: 12.0
agent-13: 5.0
agent-14: 11.0
agent-15: 19.0
agent-16: 13.0
agent-17: 7.0
agent-18: 1.0
agent-19: 15.0
agent-20: 14.0
agent-21: 10.0
agent-22: 8.0
agent-23: 18.0
agent-24: 8.0
agent-25: 6.0
agent-26: 10.0
agent-27: 11.0
agent-28: 12.0
agent-29: 15.0
agent-30: 13.0
agent-31: 8.0
agent-32: 9.0
agent-33: 12.0
agent-34: 9.0
agent-35: 13.0
agent-36: 7.0
agent-37: 11.0
agent-38: 16.0
agent-39: 18.0
agent-40: 7.0
Sum Reward: 464.0
Avg Reward: 11.6
Min Reward: 1.0
Max Reward: 23.0
Gini Coefficient: 0.1951508620689655
20:20 Ratio: 2.877551020408163
Max-min Ratio: 23.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-08_03-25-22
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 588.0
  episode_reward_mean: 479.53
  episode_reward_min: 425.0
  episodes_this_iter: 1
  episodes_total: 143
  experiment_id: 4e724eb5b3a34f42879644e84578eec0
  hostname: gpu024
  info:
    apply_time_ms: 2.663
    dispatch_time_ms: 6.808
    learner:
      cur_lr: 0.000979047967121005
      grad_gnorm: 1.089375376701355
      policy_entropy: 734.2777099609375
      policy_loss: 0.7730467915534973
      var_gnorm: 32.373626708984375
      vf_explained_var: -0.05564773082733154
      vf_loss: 0.007472901605069637
    num_steps_sampled: 5760000
    num_steps_trained: 5760000
    wait_time_ms: 562.922
  iterations_since_restore: 144
  node_ip: 172.17.8.24
  num_metric_batches_dropped: 0
  pid: 26970
  policy_reward_mean: {}
  time_since_restore: 8132.972671985626
  time_this_iter_s: 57.02280569076538
  time_total_s: 8132.972671985626
  timestamp: 1594193122
  timesteps_since_restore: 5760000
  timesteps_this_iter: 40000
  timesteps_total: 5760000
  training_iteration: 144
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26970], 8132 s, 144 iter, 5760000 ts, 480 rew

agent-1: 14.0
agent-2: 9.0
agent-3: 15.0
agent-4: 15.0
agent-5: 14.0
agent-6: 11.0
agent-7: 8.0
agent-8: 11.0
agent-9: 10.0
agent-10: 18.0
agent-11: 2.0
agent-12: 11.0
agent-13: 10.0
agent-14: 15.0
agent-15: 9.0
agent-16: 10.0
agent-17: 9.0
agent-18: 12.0
agent-19: 11.0
agent-20: 17.0
agent-21: 13.0
agent-22: 8.0
agent-23: 9.0
agent-24: 15.0
agent-25: 11.0
agent-26: 16.0
agent-27: 5.0
agent-28: 15.0
agent-29: 10.0
agent-30: 8.0
agent-31: 14.0
agent-32: 12.0
agent-33: 15.0
agent-34: 7.0
agent-35: 9.0
agent-36: 14.0
agent-37: 11.0
agent-38: 12.0
agent-39: 9.0
agent-40: 12.0
Sum Reward: 456.0
Avg Reward: 11.4
Min Reward: 2.0
Max Reward: 18.0
Gini Coefficient: 0.1600877192982456
20:20 Ratio: 2.25
Max-min Ratio: 9.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-08_03-26-19
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 543.0
  episode_reward_mean: 478.21
  episode_reward_min: 425.0
  episodes_this_iter: 1
  episodes_total: 144
  experiment_id: 4e724eb5b3a34f42879644e84578eec0
  hostname: gpu024
  info:
    apply_time_ms: 2.99
    dispatch_time_ms: 5.492
    learner:
      cur_lr: 0.0009763839771039784
      grad_gnorm: 3.1042590141296387
      policy_entropy: 732.32275390625
      policy_loss: 0.8492566347122192
      var_gnorm: 32.419097900390625
      vf_explained_var: -1.0
      vf_loss: 0.06254812330007553
    num_steps_sampled: 5800000
    num_steps_trained: 5800000
    wait_time_ms: 546.301
  iterations_since_restore: 145
  node_ip: 172.17.8.24
  num_metric_batches_dropped: 0
  pid: 26970
  policy_reward_mean: {}
  time_since_restore: 8189.227886915207
  time_this_iter_s: 56.25521492958069
  time_total_s: 8189.227886915207
  timestamp: 1594193179
  timesteps_since_restore: 5800000
  timesteps_this_iter: 40000
  timesteps_total: 5800000
  training_iteration: 145
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26970], 8189 s, 145 iter, 5800000 ts, 478 rew

agent-1: 10.0
agent-2: 16.0
agent-3: 13.0
agent-4: 11.0
agent-5: 13.0
agent-6: 22.0
agent-7: 11.0
agent-8: 13.0
agent-9: 9.0
agent-10: 12.0
agent-11: 12.0
agent-12: 13.0
agent-13: 7.0
agent-14: 8.0
agent-15: 11.0
agent-16: 14.0
agent-17: 7.0
agent-18: 14.0
agent-19: 12.0
agent-20: 12.0
agent-21: 4.0
agent-22: 11.0
agent-23: 14.0
agent-24: 14.0
agent-25: 13.0
agent-26: 9.0
agent-27: 11.0
agent-28: 8.0
agent-29: 7.0
agent-30: 12.0
agent-31: 12.0
agent-32: 13.0
agent-33: 13.0
agent-34: 14.0
agent-35: 14.0
agent-36: 9.0
agent-37: 12.0
agent-38: 10.0
agent-39: 12.0
agent-40: 16.0
Sum Reward: 468.0
Avg Reward: 11.7
Min Reward: 4.0
Max Reward: 22.0
Gini Coefficient: 0.13707264957264959
20:20 Ratio: 2.1016949152542375
Max-min Ratio: 5.5
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-08_03-27-15
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 543.0
  episode_reward_mean: 477.72
  episode_reward_min: 425.0
  episodes_this_iter: 1
  episodes_total: 145
  experiment_id: 4e724eb5b3a34f42879644e84578eec0
  hostname: gpu024
  info:
    apply_time_ms: 2.709
    dispatch_time_ms: 5.834
    learner:
      cur_lr: 0.0009737199870869517
      grad_gnorm: 17.297988891601562
      policy_entropy: 743.7896728515625
      policy_loss: -2.1385021209716797
      var_gnorm: 32.47888946533203
      vf_explained_var: -1.0
      vf_loss: 0.30597078800201416
    num_steps_sampled: 5840000
    num_steps_trained: 5840000
    wait_time_ms: 561.315
  iterations_since_restore: 146
  node_ip: 172.17.8.24
  num_metric_batches_dropped: 0
  pid: 26970
  policy_reward_mean: {}
  time_since_restore: 8245.420151233673
  time_this_iter_s: 56.19226431846619
  time_total_s: 8245.420151233673
  timestamp: 1594193235
  timesteps_since_restore: 5840000
  timesteps_this_iter: 40000
  timesteps_total: 5840000
  training_iteration: 146
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26970], 8245 s, 146 iter, 5840000 ts, 478 rew

agent-1: 14.0
agent-2: 15.0
agent-3: 7.0
agent-4: 12.0
agent-5: 7.0
agent-6: 14.0
agent-7: 13.0
agent-8: 12.0
agent-9: 10.0
agent-10: 12.0
agent-11: 15.0
agent-12: 13.0
agent-13: 3.0
agent-14: 8.0
agent-15: 11.0
agent-16: 9.0
agent-17: 8.0
agent-18: 16.0
agent-19: 14.0
agent-20: 11.0
agent-21: 15.0
agent-22: 7.0
agent-23: 9.0
agent-24: 14.0
agent-25: 5.0
agent-26: 11.0
agent-27: 10.0
agent-28: 15.0
agent-29: 13.0
agent-30: 12.0
agent-31: 16.0
agent-32: 10.0
agent-33: 13.0
agent-34: 14.0
agent-35: 10.0
agent-36: 5.0
agent-37: 9.0
agent-38: 10.0
agent-39: 15.0
agent-40: 15.0
Sum Reward: 452.0
Avg Reward: 11.3
Min Reward: 3.0
Max Reward: 16.0
Gini Coefficient: 0.16238938053097346
20:20 Ratio: 2.44
Max-min Ratio: 5.333333333333333
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-08_03-28-11
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 540.0
  episode_reward_mean: 476.81
  episode_reward_min: 425.0
  episodes_this_iter: 1
  episodes_total: 146
  experiment_id: 4e724eb5b3a34f42879644e84578eec0
  hostname: gpu024
  info:
    apply_time_ms: 2.5
    dispatch_time_ms: 5.798
    learner:
      cur_lr: 0.0009710559970699251
      grad_gnorm: 1.320855736732483
      policy_entropy: 726.9002685546875
      policy_loss: 0.833640456199646
      var_gnorm: 32.537471771240234
      vf_explained_var: -1.0
      vf_loss: 0.0005192451644688845
    num_steps_sampled: 5880000
    num_steps_trained: 5880000
    wait_time_ms: 558.986
  iterations_since_restore: 147
  node_ip: 172.17.8.24
  num_metric_batches_dropped: 0
  pid: 26970
  policy_reward_mean: {}
  time_since_restore: 8301.857364416122
  time_this_iter_s: 56.43721318244934
  time_total_s: 8301.857364416122
  timestamp: 1594193291
  timesteps_since_restore: 5880000
  timesteps_this_iter: 40000
  timesteps_total: 5880000
  training_iteration: 147
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26970], 8301 s, 147 iter, 5880000 ts, 477 rew

agent-1: 15.0
agent-2: 11.0
agent-3: 8.0
agent-4: 11.0
agent-5: 10.0
agent-6: 9.0
agent-7: 11.0
agent-8: 12.0
agent-9: 7.0
agent-10: 7.0
agent-11: 17.0
agent-12: 11.0
agent-13: 16.0
agent-14: 17.0
agent-15: 7.0
agent-16: 13.0
agent-17: 14.0
agent-18: 14.0
agent-19: 8.0
agent-20: 17.0
agent-21: 14.0
agent-22: 9.0
agent-23: 12.0
agent-24: 9.0
agent-25: 9.0
agent-26: 18.0
agent-27: 13.0
agent-28: 10.0
agent-29: 11.0
agent-30: 9.0
agent-31: 10.0
agent-32: 12.0
agent-33: 8.0
agent-34: 14.0
agent-35: 11.0
agent-36: 15.0
agent-37: 10.0
agent-38: 12.0
agent-39: 12.0
agent-40: 14.0
Sum Reward: 467.0
Avg Reward: 11.675
Min Reward: 7.0
Max Reward: 18.0
Gini Coefficient: 0.14437901498929337
20:20 Ratio: 2.0476190476190474
Max-min Ratio: 2.5714285714285716
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-08_03-29-08
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 540.0
  episode_reward_mean: 476.24
  episode_reward_min: 425.0
  episodes_this_iter: 1
  episodes_total: 147
  experiment_id: 4e724eb5b3a34f42879644e84578eec0
  hostname: gpu024
  info:
    apply_time_ms: 2.429
    dispatch_time_ms: 5.605
    learner:
      cur_lr: 0.0009683920070528984
      grad_gnorm: 4.373618125915527
      policy_entropy: 769.4241943359375
      policy_loss: 5.861557960510254
      var_gnorm: 32.620277404785156
      vf_explained_var: -1.0
      vf_loss: 0.018824318423867226
    num_steps_sampled: 5920000
    num_steps_trained: 5920000
    wait_time_ms: 568.913
  iterations_since_restore: 148
  node_ip: 172.17.8.24
  num_metric_batches_dropped: 0
  pid: 26970
  policy_reward_mean: {}
  time_since_restore: 8358.57064127922
  time_this_iter_s: 56.713276863098145
  time_total_s: 8358.57064127922
  timestamp: 1594193348
  timesteps_since_restore: 5920000
  timesteps_this_iter: 40000
  timesteps_total: 5920000
  training_iteration: 148
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26970], 8358 s, 148 iter, 5920000 ts, 476 rew

agent-1: 8.0
agent-2: 16.0
agent-3: 10.0
agent-4: 8.0
agent-5: 11.0
agent-6: 10.0
agent-7: 7.0
agent-8: 13.0
agent-9: 15.0
agent-10: 8.0
agent-11: 12.0
agent-12: 12.0
agent-13: 15.0
agent-14: 15.0
agent-15: 7.0
agent-16: 9.0
agent-17: 11.0
agent-18: 6.0
agent-19: 11.0
agent-20: 11.0
agent-21: 12.0
agent-22: 10.0
agent-23: 8.0
agent-24: 3.0
agent-25: 16.0
agent-26: 13.0
agent-27: 5.0
agent-28: 14.0
agent-29: 14.0
agent-30: 12.0
agent-31: 15.0
agent-32: 13.0
agent-33: 15.0
agent-34: 6.0
agent-35: 8.0
agent-36: 14.0
agent-37: 17.0
agent-38: 6.0
agent-39: 10.0
agent-40: 11.0
Sum Reward: 437.0
Avg Reward: 10.925
Min Reward: 3.0
Max Reward: 17.0
Gini Coefficient: 0.17866132723112127
20:20 Ratio: 2.5833333333333335
Max-min Ratio: 5.666666666666667
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-08_03-30-05
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 539.0
  episode_reward_mean: 475.21
  episode_reward_min: 425.0
  episodes_this_iter: 1
  episodes_total: 148
  experiment_id: 4e724eb5b3a34f42879644e84578eec0
  hostname: gpu024
  info:
    apply_time_ms: 2.891
    dispatch_time_ms: 8.585
    learner:
      cur_lr: 0.0009657280170358717
      grad_gnorm: 6.2085490226745605
      policy_entropy: 723.0570068359375
      policy_loss: 2.482884168624878
      var_gnorm: 32.704063415527344
      vf_explained_var: -0.6859267950057983
      vf_loss: 0.00022050719417165965
    num_steps_sampled: 5960000
    num_steps_trained: 5960000
    wait_time_ms: 563.595
  iterations_since_restore: 149
  node_ip: 172.17.8.24
  num_metric_batches_dropped: 0
  pid: 26970
  policy_reward_mean: {}
  time_since_restore: 8414.987766742706
  time_this_iter_s: 56.41712546348572
  time_total_s: 8414.987766742706
  timestamp: 1594193405
  timesteps_since_restore: 5960000
  timesteps_this_iter: 40000
  timesteps_total: 5960000
  training_iteration: 149
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26970], 8414 s, 149 iter, 5960000 ts, 475 rew

agent-1: 10.0
agent-2: 15.0
agent-3: 9.0
agent-4: 12.0
agent-5: 10.0
agent-6: 16.0
agent-7: 6.0
agent-8: 11.0
agent-9: 10.0
agent-10: 14.0
agent-11: 6.0
agent-12: 18.0
agent-13: 8.0
agent-14: 10.0
agent-15: 15.0
agent-16: 12.0
agent-17: 10.0
agent-18: 11.0
agent-19: 10.0
agent-20: 10.0
agent-21: 17.0
agent-22: 8.0
agent-23: 14.0
agent-24: 16.0
agent-25: 15.0
agent-26: 9.0
agent-27: 8.0
agent-28: 11.0
agent-29: 6.0
agent-30: 13.0
agent-31: 9.0
agent-32: 12.0
agent-33: 15.0
agent-34: 11.0
agent-35: 10.0
agent-36: 14.0
agent-37: 7.0
agent-38: 7.0
agent-39: 8.0
agent-40: 9.0
Sum Reward: 442.0
Avg Reward: 11.05
Min Reward: 6.0
Max Reward: 18.0
Gini Coefficient: 0.16176470588235295
20:20 Ratio: 2.267857142857143
Max-min Ratio: 3.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-08_03-31-01
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 539.0
  episode_reward_mean: 474.61
  episode_reward_min: 425.0
  episodes_this_iter: 1
  episodes_total: 149
  experiment_id: 4e724eb5b3a34f42879644e84578eec0
  hostname: gpu024
  info:
    apply_time_ms: 3.232
    dispatch_time_ms: 6.411
    learner:
      cur_lr: 0.0009630640270188451
      grad_gnorm: 11.04128360748291
      policy_entropy: 767.0418701171875
      policy_loss: -0.8684011101722717
      var_gnorm: 32.73826599121094
      vf_explained_var: -1.0
      vf_loss: 0.004852015990763903
    num_steps_sampled: 6000000
    num_steps_trained: 6000000
    wait_time_ms: 565.391
  iterations_since_restore: 150
  node_ip: 172.17.8.24
  num_metric_batches_dropped: 0
  pid: 26970
  policy_reward_mean: {}
  time_since_restore: 8471.778434753418
  time_this_iter_s: 56.79066801071167
  time_total_s: 8471.778434753418
  timestamp: 1594193461
  timesteps_since_restore: 6000000
  timesteps_this_iter: 40000
  timesteps_total: 6000000
  training_iteration: 150
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26970], 8471 s, 150 iter, 6000000 ts, 475 rew

agent-1: 10.0
agent-2: 17.0
agent-3: 3.0
agent-4: 17.0
agent-5: 12.0
agent-6: 5.0
agent-7: 8.0
agent-8: 15.0
agent-9: 11.0
agent-10: 12.0
agent-11: 13.0
agent-12: 15.0
agent-13: 13.0
agent-14: 9.0
agent-15: 12.0
agent-16: 7.0
agent-17: 8.0
agent-18: 11.0
agent-19: 9.0
agent-20: 14.0
agent-21: 11.0
agent-22: 11.0
agent-23: 14.0
agent-24: 12.0
agent-25: 11.0
agent-26: 8.0
agent-27: 15.0
agent-28: 13.0
agent-29: 11.0
agent-30: 12.0
agent-31: 17.0
agent-32: 11.0
agent-33: 16.0
agent-34: 12.0
agent-35: 4.0
agent-36: 8.0
agent-37: 11.0
agent-38: 13.0
agent-39: 12.0
agent-40: 9.0
Sum Reward: 452.0
Avg Reward: 11.3
Min Reward: 3.0
Max Reward: 17.0
Gini Coefficient: 0.16084070796460176
20:20 Ratio: 2.4705882352941178
Max-min Ratio: 5.666666666666667
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-08_03-31-58
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 539.0
  episode_reward_mean: 474.06
  episode_reward_min: 425.0
  episodes_this_iter: 1
  episodes_total: 150
  experiment_id: 4e724eb5b3a34f42879644e84578eec0
  hostname: gpu024
  info:
    apply_time_ms: 2.541
    dispatch_time_ms: 8.313
    learner:
      cur_lr: 0.0009603999787941575
      grad_gnorm: 2.0170822143554688
      policy_entropy: 768.4313354492188
      policy_loss: 0.3738069534301758
      var_gnorm: 32.84208297729492
      vf_explained_var: 0.01759129762649536
      vf_loss: 0.0064704217948019505
    num_steps_sampled: 6040000
    num_steps_trained: 6040000
    wait_time_ms: 568.917
  iterations_since_restore: 151
  node_ip: 172.17.8.24
  num_metric_batches_dropped: 0
  pid: 26970
  policy_reward_mean: {}
  time_since_restore: 8528.554692268372
  time_this_iter_s: 56.77625751495361
  time_total_s: 8528.554692268372
  timestamp: 1594193518
  timesteps_since_restore: 6040000
  timesteps_this_iter: 40000
  timesteps_total: 6040000
  training_iteration: 151
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26970], 8528 s, 151 iter, 6040000 ts, 474 rew

agent-1: 14.0
agent-2: 11.0
agent-3: 9.0
agent-4: 15.0
agent-5: 18.0
agent-6: 11.0
agent-7: 15.0
agent-8: 14.0
agent-9: 11.0
agent-10: 6.0
agent-11: 16.0
agent-12: 12.0
agent-13: 9.0
agent-14: 13.0
agent-15: 7.0
agent-16: 11.0
agent-17: 10.0
agent-18: 14.0
agent-19: 17.0
agent-20: 4.0
agent-21: 8.0
agent-22: 14.0
agent-23: 9.0
agent-24: 11.0
agent-25: 16.0
agent-26: 13.0
agent-27: 8.0
agent-28: 14.0
agent-29: 11.0
agent-30: 13.0
agent-31: 6.0
agent-32: 7.0
agent-33: 11.0
agent-34: 14.0
agent-35: 9.0
agent-36: 19.0
agent-37: 8.0
agent-38: 8.0
agent-39: 10.0
agent-40: 11.0
Sum Reward: 457.0
Avg Reward: 11.425
Min Reward: 4.0
Max Reward: 19.0
Gini Coefficient: 0.17106126914660832
20:20 Ratio: 2.4074074074074074
Max-min Ratio: 4.75
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-08_03-32-55
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 539.0
  episode_reward_mean: 473.54
  episode_reward_min: 425.0
  episodes_this_iter: 1
  episodes_total: 151
  experiment_id: 4e724eb5b3a34f42879644e84578eec0
  hostname: gpu024
  info:
    apply_time_ms: 3.119
    dispatch_time_ms: 7.284
    learner:
      cur_lr: 0.0009577359887771308
      grad_gnorm: 4.5093913078308105
      policy_entropy: 765.0687255859375
      policy_loss: -0.5406876802444458
      var_gnorm: 32.85726547241211
      vf_explained_var: -0.5447804927825928
      vf_loss: 0.04211758077144623
    num_steps_sampled: 6080000
    num_steps_trained: 6080000
    wait_time_ms: 560.954
  iterations_since_restore: 152
  node_ip: 172.17.8.24
  num_metric_batches_dropped: 0
  pid: 26970
  policy_reward_mean: {}
  time_since_restore: 8585.026324510574
  time_this_iter_s: 56.47163224220276
  time_total_s: 8585.026324510574
  timestamp: 1594193575
  timesteps_since_restore: 6080000
  timesteps_this_iter: 40000
  timesteps_total: 6080000
  training_iteration: 152
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26970], 8585 s, 152 iter, 6080000 ts, 474 rew

agent-1: 8.0
agent-2: 10.0
agent-3: 10.0
agent-4: 12.0
agent-5: 12.0
agent-6: 8.0
agent-7: 17.0
agent-8: 5.0
agent-9: 12.0
agent-10: 16.0
agent-11: 11.0
agent-12: 8.0
agent-13: 17.0
agent-14: 6.0
agent-15: 14.0
agent-16: 11.0
agent-17: 9.0
agent-18: 6.0
agent-19: 13.0
agent-20: 8.0
agent-21: 6.0
agent-22: 13.0
agent-23: 10.0
agent-24: 14.0
agent-25: 13.0
agent-26: 8.0
agent-27: 18.0
agent-28: 10.0
agent-29: 10.0
agent-30: 11.0
agent-31: 9.0
agent-32: 9.0
agent-33: 11.0
agent-34: 12.0
agent-35: 20.0
agent-36: 13.0
agent-37: 13.0
agent-38: 16.0
agent-39: 11.0
agent-40: 13.0
Sum Reward: 453.0
Avg Reward: 11.325
Min Reward: 5.0
Max Reward: 20.0
Gini Coefficient: 0.168598233995585
20:20 Ratio: 2.4
Max-min Ratio: 4.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-08_03-33-51
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 539.0
  episode_reward_mean: 473.78
  episode_reward_min: 425.0
  episodes_this_iter: 1
  episodes_total: 152
  experiment_id: 4e724eb5b3a34f42879644e84578eec0
  hostname: gpu024
  info:
    apply_time_ms: 2.629
    dispatch_time_ms: 6.626
    learner:
      cur_lr: 0.0009550719987601042
      grad_gnorm: 7.102851867675781
      policy_entropy: 737.1744995117188
      policy_loss: 5.454556941986084
      var_gnorm: 32.92386245727539
      vf_explained_var: 0.0014644861221313477
      vf_loss: 0.019169285893440247
    num_steps_sampled: 6120000
    num_steps_trained: 6120000
    wait_time_ms: 567.315
  iterations_since_restore: 153
  node_ip: 172.17.8.24
  num_metric_batches_dropped: 0
  pid: 26970
  policy_reward_mean: {}
  time_since_restore: 8641.551009178162
  time_this_iter_s: 56.52468466758728
  time_total_s: 8641.551009178162
  timestamp: 1594193631
  timesteps_since_restore: 6120000
  timesteps_this_iter: 40000
  timesteps_total: 6120000
  training_iteration: 153
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26970], 8641 s, 153 iter, 6120000 ts, 474 rew

agent-1: 8.0
agent-2: 12.0
agent-3: 16.0
agent-4: 10.0
agent-5: 12.0
agent-6: 13.0
agent-7: 9.0
agent-8: 7.0
agent-9: 11.0
agent-10: 13.0
agent-11: 12.0
agent-12: 16.0
agent-13: 13.0
agent-14: 11.0
agent-15: 9.0
agent-16: 10.0
agent-17: 16.0
agent-18: 14.0
agent-19: 14.0
agent-20: 8.0
agent-21: 9.0
agent-22: 10.0
agent-23: 8.0
agent-24: 10.0
agent-25: 9.0
agent-26: 8.0
agent-27: 11.0
agent-28: 8.0
agent-29: 13.0
agent-30: 4.0
agent-31: 13.0
agent-32: 11.0
agent-33: 11.0
agent-34: 9.0
agent-35: 10.0
agent-36: 7.0
agent-37: 9.0
agent-38: 11.0
agent-39: 14.0
agent-40: 15.0
Sum Reward: 434.0
Avg Reward: 10.85
Min Reward: 4.0
Max Reward: 16.0
Gini Coefficient: 0.14078341013824885
20:20 Ratio: 2.0344827586206895
Max-min Ratio: 4.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-08_03-34-47
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 539.0
  episode_reward_mean: 472.94
  episode_reward_min: 425.0
  episodes_this_iter: 1
  episodes_total: 153
  experiment_id: 4e724eb5b3a34f42879644e84578eec0
  hostname: gpu024
  info:
    apply_time_ms: 2.466
    dispatch_time_ms: 5.601
    learner:
      cur_lr: 0.0009524080087430775
      grad_gnorm: 5.541069984436035
      policy_entropy: 751.8009033203125
      policy_loss: 5.468763828277588
      var_gnorm: 32.92873001098633
      vf_explained_var: 0.478643000125885
      vf_loss: 1.2496228218078613
    num_steps_sampled: 6160000
    num_steps_trained: 6160000
    wait_time_ms: 553.719
  iterations_since_restore: 154
  node_ip: 172.17.8.24
  num_metric_batches_dropped: 0
  pid: 26970
  policy_reward_mean: {}
  time_since_restore: 8697.545712471008
  time_this_iter_s: 55.99470329284668
  time_total_s: 8697.545712471008
  timestamp: 1594193687
  timesteps_since_restore: 6160000
  timesteps_this_iter: 40000
  timesteps_total: 6160000
  training_iteration: 154
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26970], 8697 s, 154 iter, 6160000 ts, 473 rew

agent-1: 4.0
agent-2: 7.0
agent-3: 11.0
agent-4: 11.0
agent-5: 18.0
agent-6: 13.0
agent-7: 6.0
agent-8: 11.0
agent-9: 12.0
agent-10: 6.0
agent-11: 7.0
agent-12: 12.0
agent-13: 15.0
agent-14: 10.0
agent-15: 13.0
agent-16: 11.0
agent-17: 12.0
agent-18: 18.0
agent-19: 13.0
agent-20: 8.0
agent-21: 12.0
agent-22: 11.0
agent-23: 13.0
agent-24: 14.0
agent-25: 8.0
agent-26: 9.0
agent-27: 15.0
agent-28: 11.0
agent-29: 12.0
agent-30: 9.0
agent-31: 10.0
agent-32: 19.0
agent-33: 9.0
agent-34: 8.0
agent-35: 11.0
agent-36: 13.0
agent-37: 2.0
agent-38: 12.0
agent-39: 14.0
agent-40: 14.0
Sum Reward: 444.0
Avg Reward: 11.1
Min Reward: 2.0
Max Reward: 19.0
Gini Coefficient: 0.1751126126126126
20:20 Ratio: 2.6458333333333335
Max-min Ratio: 9.5
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-08_03-35-44
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 539.0
  episode_reward_mean: 472.33
  episode_reward_min: 425.0
  episodes_this_iter: 1
  episodes_total: 154
  experiment_id: 4e724eb5b3a34f42879644e84578eec0
  hostname: gpu024
  info:
    apply_time_ms: 3.138
    dispatch_time_ms: 6.584
    learner:
      cur_lr: 0.0009497440187260509
      grad_gnorm: 2.7310664653778076
      policy_entropy: 763.8726806640625
      policy_loss: 3.211531162261963
      var_gnorm: 33.01097869873047
      vf_explained_var: -1.0
      vf_loss: 0.0032742698676884174
    num_steps_sampled: 6200000
    num_steps_trained: 6200000
    wait_time_ms: 564.556
  iterations_since_restore: 155
  node_ip: 172.17.8.24
  num_metric_batches_dropped: 0
  pid: 26970
  policy_reward_mean: {}
  time_since_restore: 8754.040095567703
  time_this_iter_s: 56.494383096694946
  time_total_s: 8754.040095567703
  timestamp: 1594193744
  timesteps_since_restore: 6200000
  timesteps_this_iter: 40000
  timesteps_total: 6200000
  training_iteration: 155
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26970], 8754 s, 155 iter, 6200000 ts, 472 rew

agent-1: 17.0
agent-2: 10.0
agent-3: 11.0
agent-4: 14.0
agent-5: 0.0
agent-6: 8.0
agent-7: 8.0
agent-8: 14.0
agent-9: 14.0
agent-10: 9.0
agent-11: 3.0
agent-12: 9.0
agent-13: 8.0
agent-14: 13.0
agent-15: 14.0
agent-16: 13.0
agent-17: 12.0
agent-18: 14.0
agent-19: 10.0
agent-20: 14.0
agent-21: 13.0
agent-22: 17.0
agent-23: 12.0
agent-24: 16.0
agent-25: 11.0
agent-26: 12.0
agent-27: 12.0
agent-28: 11.0
agent-29: 18.0
agent-30: 8.0
agent-31: 11.0
agent-32: 12.0
agent-33: 14.0
agent-34: 10.0
agent-35: 10.0
agent-36: 10.0
agent-37: 13.0
agent-38: 8.0
agent-39: 10.0
agent-40: 11.0
Sum Reward: 454.0
Avg Reward: 11.35
Min Reward: 0.0
Max Reward: 18.0
Gini Coefficient: 0.1604625550660793
20:20 Ratio: 2.3846153846153846
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-08_03-36-41
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 539.0
  episode_reward_mean: 472.08
  episode_reward_min: 425.0
  episodes_this_iter: 1
  episodes_total: 155
  experiment_id: 4e724eb5b3a34f42879644e84578eec0
  hostname: gpu024
  info:
    apply_time_ms: 2.704
    dispatch_time_ms: 6.494
    learner:
      cur_lr: 0.0009470800287090242
      grad_gnorm: 10.458929061889648
      policy_entropy: 758.7591552734375
      policy_loss: -1.7867422103881836
      var_gnorm: 33.11725997924805
      vf_explained_var: -1.0
      vf_loss: 0.029674848541617393
    num_steps_sampled: 6240000
    num_steps_trained: 6240000
    wait_time_ms: 566.504
  iterations_since_restore: 156
  node_ip: 172.17.8.24
  num_metric_batches_dropped: 0
  pid: 26970
  policy_reward_mean: {}
  time_since_restore: 8810.897448301315
  time_this_iter_s: 56.85735273361206
  time_total_s: 8810.897448301315
  timestamp: 1594193801
  timesteps_since_restore: 6240000
  timesteps_this_iter: 40000
  timesteps_total: 6240000
  training_iteration: 156
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26970], 8810 s, 156 iter, 6240000 ts, 472 rew

agent-1: 4.0
agent-2: 11.0
agent-3: 12.0
agent-4: 7.0
agent-5: 13.0
agent-6: 11.0
agent-7: 15.0
agent-8: 11.0
agent-9: 14.0
agent-10: 16.0
agent-11: 11.0
agent-12: 11.0
agent-13: 10.0
agent-14: 12.0
agent-15: 10.0
agent-16: 7.0
agent-17: 9.0
agent-18: 11.0
agent-19: 16.0
agent-20: 13.0
agent-21: 13.0
agent-22: 11.0
agent-23: 11.0
agent-24: 14.0
agent-25: 11.0
agent-26: 9.0
agent-27: 7.0
agent-28: 7.0
agent-29: 8.0
agent-30: 16.0
agent-31: 8.0
agent-32: 9.0
agent-33: 11.0
agent-34: 10.0
agent-35: 15.0
agent-36: 7.0
agent-37: 15.0
agent-38: 11.0
agent-39: 12.0
agent-40: 13.0
Sum Reward: 442.0
Avg Reward: 11.05
Min Reward: 4.0
Max Reward: 16.0
Gini Coefficient: 0.14377828054298641
20:20 Ratio: 2.2
Max-min Ratio: 4.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-08_03-37-37
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 539.0
  episode_reward_mean: 471.77
  episode_reward_min: 425.0
  episodes_this_iter: 1
  episodes_total: 156
  experiment_id: 4e724eb5b3a34f42879644e84578eec0
  hostname: gpu024
  info:
    apply_time_ms: 2.299
    dispatch_time_ms: 7.779
    learner:
      cur_lr: 0.0009444159804843366
      grad_gnorm: 4.085320949554443
      policy_entropy: 716.841796875
      policy_loss: 1.276865839958191
      var_gnorm: 33.210205078125
      vf_explained_var: -1.0
      vf_loss: 0.010040314868092537
    num_steps_sampled: 6280000
    num_steps_trained: 6280000
    wait_time_ms: 567.415
  iterations_since_restore: 157
  node_ip: 172.17.8.24
  num_metric_batches_dropped: 0
  pid: 26970
  policy_reward_mean: {}
  time_since_restore: 8867.383492946625
  time_this_iter_s: 56.48604464530945
  time_total_s: 8867.383492946625
  timestamp: 1594193857
  timesteps_since_restore: 6280000
  timesteps_this_iter: 40000
  timesteps_total: 6280000
  training_iteration: 157
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26970], 8867 s, 157 iter, 6280000 ts, 472 rew

agent-1: 15.0
agent-2: 10.0
agent-3: 12.0
agent-4: 16.0
agent-5: 5.0
agent-6: 11.0
agent-7: 8.0
agent-8: 9.0
agent-9: 14.0
agent-10: 8.0
agent-11: 11.0
agent-12: 12.0
agent-13: 14.0
agent-14: 14.0
agent-15: 8.0
agent-16: 7.0
agent-17: 8.0
agent-18: 11.0
agent-19: 3.0
agent-20: 7.0
agent-21: 13.0
agent-22: 10.0
agent-23: 14.0
agent-24: 10.0
agent-25: 17.0
agent-26: 18.0
agent-27: 13.0
agent-28: 11.0
agent-29: 11.0
agent-30: 8.0
agent-31: 10.0
agent-32: 10.0
agent-33: 11.0
agent-34: 19.0
agent-35: 8.0
agent-36: 5.0
agent-37: 12.0
agent-38: 16.0
agent-39: 17.0
agent-40: 11.0
Sum Reward: 447.0
Avg Reward: 11.175
Min Reward: 3.0
Max Reward: 19.0
Gini Coefficient: 0.18282997762863534
20:20 Ratio: 2.588235294117647
Max-min Ratio: 6.333333333333333
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-08_03-38-34
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 539.0
  episode_reward_mean: 471.29
  episode_reward_min: 425.0
  episodes_this_iter: 1
  episodes_total: 157
  experiment_id: 4e724eb5b3a34f42879644e84578eec0
  hostname: gpu024
  info:
    apply_time_ms: 2.59
    dispatch_time_ms: 5.944
    learner:
      cur_lr: 0.00094175199046731
      grad_gnorm: 3.8331141471862793
      policy_entropy: 713.0567626953125
      policy_loss: 2.76318359375
      var_gnorm: 33.239505767822266
      vf_explained_var: -1.0
      vf_loss: 0.004762385040521622
    num_steps_sampled: 6320000
    num_steps_trained: 6320000
    wait_time_ms: 560.496
  iterations_since_restore: 158
  node_ip: 172.17.8.24
  num_metric_batches_dropped: 0
  pid: 26970
  policy_reward_mean: {}
  time_since_restore: 8923.592487573624
  time_this_iter_s: 56.2089946269989
  time_total_s: 8923.592487573624
  timestamp: 1594193914
  timesteps_since_restore: 6320000
  timesteps_this_iter: 40000
  timesteps_total: 6320000
  training_iteration: 158
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26970], 8923 s, 158 iter, 6320000 ts, 471 rew

agent-1: 5.0
agent-2: 13.0
agent-3: 5.0
agent-4: 12.0
agent-5: 10.0
agent-6: 17.0
agent-7: 19.0
agent-8: 11.0
agent-9: 14.0
agent-10: 8.0
agent-11: 12.0
agent-12: 12.0
agent-13: 14.0
agent-14: 11.0
agent-15: 9.0
agent-16: 10.0
agent-17: 9.0
agent-18: 3.0
agent-19: 14.0
agent-20: 13.0
agent-21: 10.0
agent-22: 15.0
agent-23: 11.0
agent-24: 9.0
agent-25: 8.0
agent-26: 12.0
agent-27: 13.0
agent-28: 7.0
agent-29: 14.0
agent-30: 15.0
agent-31: 4.0
agent-32: 11.0
agent-33: 11.0
agent-34: 10.0
agent-35: 9.0
agent-36: 8.0
agent-37: 14.0
agent-38: 12.0
agent-39: 10.0
agent-40: 11.0
Sum Reward: 435.0
Avg Reward: 10.875
Min Reward: 3.0
Max Reward: 19.0
Gini Coefficient: 0.16902298850574712
20:20 Ratio: 2.5416666666666665
Max-min Ratio: 6.333333333333333
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-08_03-39-30
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 539.0
  episode_reward_mean: 470.84
  episode_reward_min: 425.0
  episodes_this_iter: 1
  episodes_total: 158
  experiment_id: 4e724eb5b3a34f42879644e84578eec0
  hostname: gpu024
  info:
    apply_time_ms: 2.566
    dispatch_time_ms: 6.477
    learner:
      cur_lr: 0.0009390880004502833
      grad_gnorm: 1.6280276775360107
      policy_entropy: 756.8544921875
      policy_loss: 0.8563140034675598
      var_gnorm: 33.281494140625
      vf_explained_var: -0.48403263092041016
      vf_loss: 0.0006887613562867045
    num_steps_sampled: 6360000
    num_steps_trained: 6360000
    wait_time_ms: 556.857
  iterations_since_restore: 159
  node_ip: 172.17.8.24
  num_metric_batches_dropped: 0
  pid: 26970
  policy_reward_mean: {}
  time_since_restore: 8979.967128753662
  time_this_iter_s: 56.37464118003845
  time_total_s: 8979.967128753662
  timestamp: 1594193970
  timesteps_since_restore: 6360000
  timesteps_this_iter: 40000
  timesteps_total: 6360000
  training_iteration: 159
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26970], 8979 s, 159 iter, 6360000 ts, 471 rew

agent-1: 4.0
agent-2: 5.0
agent-3: 11.0
agent-4: 9.0
agent-5: 9.0
agent-6: 9.0
agent-7: 14.0
agent-8: 11.0
agent-9: 13.0
agent-10: 12.0
agent-11: 10.0
agent-12: 18.0
agent-13: 12.0
agent-14: 14.0
agent-15: 4.0
agent-16: 10.0
agent-17: 9.0
agent-18: 11.0
agent-19: 6.0
agent-20: 17.0
agent-21: 14.0
agent-22: 13.0
agent-23: 10.0
agent-24: 7.0
agent-25: 13.0
agent-26: 11.0
agent-27: 11.0
agent-28: 14.0
agent-29: 17.0
agent-30: 16.0
agent-31: 10.0
agent-32: 7.0
agent-33: 13.0
agent-34: 8.0
agent-35: 12.0
agent-36: 11.0
agent-37: 11.0
agent-38: 15.0
agent-39: 11.0
agent-40: 9.0
Sum Reward: 441.0
Avg Reward: 11.025
Min Reward: 4.0
Max Reward: 18.0
Gini Coefficient: 0.16831065759637187
20:20 Ratio: 2.5
Max-min Ratio: 4.5
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-08_03-40-27
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 539.0
  episode_reward_mean: 470.29
  episode_reward_min: 425.0
  episodes_this_iter: 1
  episodes_total: 159
  experiment_id: 4e724eb5b3a34f42879644e84578eec0
  hostname: gpu024
  info:
    apply_time_ms: 2.71
    dispatch_time_ms: 7.246
    learner:
      cur_lr: 0.0009364240104332566
      grad_gnorm: 3.404384136199951
      policy_entropy: 764.5496826171875
      policy_loss: 2.7397758960723877
      var_gnorm: 33.339908599853516
      vf_explained_var: -1.0
      vf_loss: 0.001462482614442706
    num_steps_sampled: 6400000
    num_steps_trained: 6400000
    wait_time_ms: 553.21
  iterations_since_restore: 160
  node_ip: 172.17.8.24
  num_metric_batches_dropped: 0
  pid: 26970
  policy_reward_mean: {}
  time_since_restore: 9036.890981197357
  time_this_iter_s: 56.92385244369507
  time_total_s: 9036.890981197357
  timestamp: 1594194027
  timesteps_since_restore: 6400000
  timesteps_this_iter: 40000
  timesteps_total: 6400000
  training_iteration: 160
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26970], 9036 s, 160 iter, 6400000 ts, 470 rew

agent-1: 8.0
agent-2: 11.0
agent-3: 12.0
agent-4: 12.0
agent-5: 13.0
agent-6: 11.0
agent-7: 10.0
agent-8: 14.0
agent-9: 10.0
agent-10: 17.0
agent-11: 13.0
agent-12: 13.0
agent-13: 5.0
agent-14: 9.0
agent-15: 10.0
agent-16: 11.0
agent-17: 9.0
agent-18: 6.0
agent-19: 11.0
agent-20: 5.0
agent-21: 13.0
agent-22: 10.0
agent-23: 13.0
agent-24: 13.0
agent-25: 14.0
agent-26: 12.0
agent-27: 16.0
agent-28: 10.0
agent-29: 9.0
agent-30: 15.0
agent-31: 16.0
agent-32: 7.0
agent-33: 14.0
agent-34: 16.0
agent-35: 12.0
agent-36: 8.0
agent-37: 14.0
agent-38: 12.0
agent-39: 11.0
agent-40: 11.0
Sum Reward: 456.0
Avg Reward: 11.4
Min Reward: 5.0
Max Reward: 17.0
Gini Coefficient: 0.14199561403508773
20:20 Ratio: 2.1403508771929824
Max-min Ratio: 3.4
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-08_03-41-23
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 539.0
  episode_reward_mean: 470.02
  episode_reward_min: 425.0
  episodes_this_iter: 1
  episodes_total: 160
  experiment_id: 4e724eb5b3a34f42879644e84578eec0
  hostname: gpu024
  info:
    apply_time_ms: 2.668
    dispatch_time_ms: 5.434
    learner:
      cur_lr: 0.00093376002041623
      grad_gnorm: 0.65860915184021
      policy_entropy: 769.2222290039062
      policy_loss: 1.0227749347686768
      var_gnorm: 33.34564208984375
      vf_explained_var: -1.0
      vf_loss: 0.00017705745995044708
    num_steps_sampled: 6440000
    num_steps_trained: 6440000
    wait_time_ms: 557.39
  iterations_since_restore: 161
  node_ip: 172.17.8.24
  num_metric_batches_dropped: 0
  pid: 26970
  policy_reward_mean: {}
  time_since_restore: 9093.225664138794
  time_this_iter_s: 56.33468294143677
  time_total_s: 9093.225664138794
  timestamp: 1594194083
  timesteps_since_restore: 6440000
  timesteps_this_iter: 40000
  timesteps_total: 6440000
  training_iteration: 161
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26970], 9093 s, 161 iter, 6440000 ts, 470 rew

agent-1: 7.0
agent-2: 10.0
agent-3: 12.0
agent-4: 13.0
agent-5: 7.0
agent-6: 8.0
agent-7: 9.0
agent-8: 18.0
agent-9: 9.0
agent-10: 13.0
agent-11: 10.0
agent-12: 13.0
agent-13: 10.0
agent-14: 15.0
agent-15: 11.0
agent-16: 10.0
agent-17: 17.0
agent-18: 11.0
agent-19: 9.0
agent-20: 11.0
agent-21: 12.0
agent-22: 14.0
agent-23: 13.0
agent-24: 13.0
agent-25: 11.0
agent-26: 11.0
agent-27: 8.0
agent-28: 9.0
agent-29: 5.0
agent-30: 9.0
agent-31: 11.0
agent-32: 8.0
agent-33: 11.0
agent-34: 18.0
agent-35: 12.0
agent-36: 16.0
agent-37: 4.0
agent-38: 14.0
agent-39: 10.0
agent-40: 7.0
Sum Reward: 439.0
Avg Reward: 10.975
Min Reward: 4.0
Max Reward: 18.0
Gini Coefficient: 0.16042141230068338
20:20 Ratio: 2.314814814814815
Max-min Ratio: 4.5
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-08_03-42-20
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 516.0
  episode_reward_mean: 469.02
  episode_reward_min: 425.0
  episodes_this_iter: 1
  episodes_total: 161
  experiment_id: 4e724eb5b3a34f42879644e84578eec0
  hostname: gpu024
  info:
    apply_time_ms: 2.719
    dispatch_time_ms: 6.672
    learner:
      cur_lr: 0.0009310959721915424
      grad_gnorm: 39.99999237060547
      policy_entropy: 774.6444702148438
      policy_loss: -2.3448233604431152
      var_gnorm: 33.38803482055664
      vf_explained_var: -1.0
      vf_loss: 0.3171864449977875
    num_steps_sampled: 6480000
    num_steps_trained: 6480000
    wait_time_ms: 540.857
  iterations_since_restore: 162
  node_ip: 172.17.8.24
  num_metric_batches_dropped: 0
  pid: 26970
  policy_reward_mean: {}
  time_since_restore: 9149.503148794174
  time_this_iter_s: 56.27748465538025
  time_total_s: 9149.503148794174
  timestamp: 1594194140
  timesteps_since_restore: 6480000
  timesteps_this_iter: 40000
  timesteps_total: 6480000
  training_iteration: 162
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26970], 9149 s, 162 iter, 6480000 ts, 469 rew

agent-1: 6.0
agent-2: 13.0
agent-3: 12.0
agent-4: 17.0
agent-5: 9.0
agent-6: 7.0
agent-7: 15.0
agent-8: 10.0
agent-9: 13.0
agent-10: 14.0
agent-11: 8.0
agent-12: 7.0
agent-13: 17.0
agent-14: 12.0
agent-15: 5.0
agent-16: 5.0
agent-17: 9.0
agent-18: 11.0
agent-19: 13.0
agent-20: 14.0
agent-21: 6.0
agent-22: 10.0
agent-23: 14.0
agent-24: 10.0
agent-25: 13.0
agent-26: 13.0
agent-27: 9.0
agent-28: 13.0
agent-29: 17.0
agent-30: 15.0
agent-31: 11.0
agent-32: 14.0
agent-33: 14.0
agent-34: 15.0
agent-35: 3.0
agent-36: 8.0
agent-37: 8.0
agent-38: 12.0
agent-39: 12.0
agent-40: 7.0
Sum Reward: 441.0
Avg Reward: 11.025
Min Reward: 3.0
Max Reward: 17.0
Gini Coefficient: 0.1830498866213152
20:20 Ratio: 2.6956521739130435
Max-min Ratio: 5.666666666666667
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-08_03-43-16
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 516.0
  episode_reward_mean: 468.32
  episode_reward_min: 425.0
  episodes_this_iter: 1
  episodes_total: 162
  experiment_id: 4e724eb5b3a34f42879644e84578eec0
  hostname: gpu024
  info:
    apply_time_ms: 2.784
    dispatch_time_ms: 7.004
    learner:
      cur_lr: 0.0009284319821745157
      grad_gnorm: 0.777799665927887
      policy_entropy: 753.1593627929688
      policy_loss: 0.37378567457199097
      var_gnorm: 33.45718002319336
      vf_explained_var: -1.0
      vf_loss: 0.0041147321462631226
    num_steps_sampled: 6520000
    num_steps_trained: 6520000
    wait_time_ms: 554.394
  iterations_since_restore: 163
  node_ip: 172.17.8.24
  num_metric_batches_dropped: 0
  pid: 26970
  policy_reward_mean: {}
  time_since_restore: 9206.272828817368
  time_this_iter_s: 56.76968002319336
  time_total_s: 9206.272828817368
  timestamp: 1594194196
  timesteps_since_restore: 6520000
  timesteps_this_iter: 40000
  timesteps_total: 6520000
  training_iteration: 163
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26970], 9206 s, 163 iter, 6520000 ts, 468 rew

agent-1: 5.0
agent-2: 6.0
agent-3: 16.0
agent-4: 13.0
agent-5: 12.0
agent-6: 10.0
agent-7: 10.0
agent-8: 10.0
agent-9: 13.0
agent-10: 13.0
agent-11: 5.0
agent-12: 14.0
agent-13: 13.0
agent-14: 7.0
agent-15: 13.0
agent-16: 12.0
agent-17: 13.0
agent-18: 14.0
agent-19: 11.0
agent-20: 10.0
agent-21: 7.0
agent-22: 13.0
agent-23: 15.0
agent-24: 11.0
agent-25: 10.0
agent-26: 8.0
agent-27: 19.0
agent-28: 11.0
agent-29: 11.0
agent-30: 15.0
agent-31: 9.0
agent-32: 6.0
agent-33: 14.0
agent-34: 10.0
agent-35: 15.0
agent-36: 6.0
agent-37: 10.0
agent-38: 10.0
agent-39: 14.0
agent-40: 12.0
Sum Reward: 446.0
Avg Reward: 11.15
Min Reward: 5.0
Max Reward: 19.0
Gini Coefficient: 0.15908071748878924
20:20 Ratio: 2.44
Max-min Ratio: 3.8
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-08_03-44-13
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 516.0
  episode_reward_mean: 467.93
  episode_reward_min: 425.0
  episodes_this_iter: 1
  episodes_total: 163
  experiment_id: 4e724eb5b3a34f42879644e84578eec0
  hostname: gpu024
  info:
    apply_time_ms: 2.612
    dispatch_time_ms: 7.048
    learner:
      cur_lr: 0.0009257679921574891
      grad_gnorm: 2.1025335788726807
      policy_entropy: 759.9069213867188
      policy_loss: 3.433894634246826
      var_gnorm: 33.5227165222168
      vf_explained_var: -1.0
      vf_loss: 0.020117254927754402
    num_steps_sampled: 6560000
    num_steps_trained: 6560000
    wait_time_ms: 550.43
  iterations_since_restore: 164
  node_ip: 172.17.8.24
  num_metric_batches_dropped: 0
  pid: 26970
  policy_reward_mean: {}
  time_since_restore: 9262.648053884506
  time_this_iter_s: 56.37522506713867
  time_total_s: 9262.648053884506
  timestamp: 1594194253
  timesteps_since_restore: 6560000
  timesteps_this_iter: 40000
  timesteps_total: 6560000
  training_iteration: 164
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26970], 9262 s, 164 iter, 6560000 ts, 468 rew

agent-1: 10.0
agent-2: 10.0
agent-3: 11.0
agent-4: 13.0
agent-5: 9.0
agent-6: 10.0
agent-7: 13.0
agent-8: 13.0
agent-9: 10.0
agent-10: 13.0
agent-11: 9.0
agent-12: 10.0
agent-13: 14.0
agent-14: 8.0
agent-15: 10.0
agent-16: 12.0
agent-17: 10.0
agent-18: 8.0
agent-19: 13.0
agent-20: 7.0
agent-21: 10.0
agent-22: 9.0
agent-23: 12.0
agent-24: 15.0
agent-25: 13.0
agent-26: 12.0
agent-27: 10.0
agent-28: 8.0
agent-29: 5.0
agent-30: 13.0
agent-31: 11.0
agent-32: 13.0
agent-33: 13.0
agent-34: 16.0
agent-35: 10.0
agent-36: 7.0
agent-37: 12.0
agent-38: 8.0
agent-39: 15.0
agent-40: 6.0
Sum Reward: 431.0
Avg Reward: 10.775
Min Reward: 5.0
Max Reward: 16.0
Gini Coefficient: 0.13161252900232018
20:20 Ratio: 1.9649122807017543
Max-min Ratio: 3.2
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-08_03-45-09
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 516.0
  episode_reward_mean: 467.44
  episode_reward_min: 425.0
  episodes_this_iter: 1
  episodes_total: 164
  experiment_id: 4e724eb5b3a34f42879644e84578eec0
  hostname: gpu024
  info:
    apply_time_ms: 2.7
    dispatch_time_ms: 5.607
    learner:
      cur_lr: 0.0009231040021404624
      grad_gnorm: 3.4616761207580566
      policy_entropy: 769.7073364257812
      policy_loss: 2.7329938411712646
      var_gnorm: 33.56187057495117
      vf_explained_var: -1.0
      vf_loss: 0.002828359603881836
    num_steps_sampled: 6600000
    num_steps_trained: 6600000
    wait_time_ms: 550.613
  iterations_since_restore: 165
  node_ip: 172.17.8.24
  num_metric_batches_dropped: 0
  pid: 26970
  policy_reward_mean: {}
  time_since_restore: 9318.940975666046
  time_this_iter_s: 56.29292178153992
  time_total_s: 9318.940975666046
  timestamp: 1594194309
  timesteps_since_restore: 6600000
  timesteps_this_iter: 40000
  timesteps_total: 6600000
  training_iteration: 165
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26970], 9318 s, 165 iter, 6600000 ts, 467 rew

agent-1: 11.0
agent-2: 12.0
agent-3: 8.0
agent-4: 10.0
agent-5: 11.0
agent-6: 6.0
agent-7: 13.0
agent-8: 9.0
agent-9: 6.0
agent-10: 3.0
agent-11: 8.0
agent-12: 14.0
agent-13: 4.0
agent-14: 11.0
agent-15: 15.0
agent-16: 13.0
agent-17: 14.0
agent-18: 11.0
agent-19: 12.0
agent-20: 14.0
agent-21: 7.0
agent-22: 17.0
agent-23: 11.0
agent-24: 17.0
agent-25: 10.0
agent-26: 10.0
agent-27: 12.0
agent-28: 16.0
agent-29: 6.0
agent-30: 14.0
agent-31: 16.0
agent-32: 5.0
agent-33: 8.0
agent-34: 12.0
agent-35: 15.0
agent-36: 8.0
agent-37: 19.0
agent-38: 14.0
agent-39: 8.0
agent-40: 8.0
Sum Reward: 438.0
Avg Reward: 10.95
Min Reward: 3.0
Max Reward: 19.0
Gini Coefficient: 0.1973744292237443
20:20 Ratio: 2.8666666666666667
Max-min Ratio: 6.333333333333333
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-08_03-46-06
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 516.0
  episode_reward_mean: 467.34
  episode_reward_min: 425.0
  episodes_this_iter: 1
  episodes_total: 165
  experiment_id: 4e724eb5b3a34f42879644e84578eec0
  hostname: gpu024
  info:
    apply_time_ms: 2.6
    dispatch_time_ms: 5.272
    learner:
      cur_lr: 0.0009204400121234357
      grad_gnorm: 3.752126455307007
      policy_entropy: 766.8475952148438
      policy_loss: -0.954056441783905
      var_gnorm: 33.568878173828125
      vf_explained_var: -1.0
      vf_loss: 0.008785342797636986
    num_steps_sampled: 6640000
    num_steps_trained: 6640000
    wait_time_ms: 575.838
  iterations_since_restore: 166
  node_ip: 172.17.8.24
  num_metric_batches_dropped: 0
  pid: 26970
  policy_reward_mean: {}
  time_since_restore: 9375.648370027542
  time_this_iter_s: 56.70739436149597
  time_total_s: 9375.648370027542
  timestamp: 1594194366
  timesteps_since_restore: 6640000
  timesteps_this_iter: 40000
  timesteps_total: 6640000
  training_iteration: 166
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26970], 9375 s, 166 iter, 6640000 ts, 467 rew

agent-1: 14.0
agent-2: 11.0
agent-3: 15.0
agent-4: 11.0
agent-5: 13.0
agent-6: 15.0
agent-7: 7.0
agent-8: 10.0
agent-9: 18.0
agent-10: 18.0
agent-11: 15.0
agent-12: 16.0
agent-13: 15.0
agent-14: 8.0
agent-15: 11.0
agent-16: 7.0
agent-17: 7.0
agent-18: 7.0
agent-19: 8.0
agent-20: 9.0
agent-21: 9.0
agent-22: 19.0
agent-23: 10.0
agent-24: 17.0
agent-25: 15.0
agent-26: 15.0
agent-27: 15.0
agent-28: 7.0
agent-29: 8.0
agent-30: 12.0
agent-31: 8.0
agent-32: 8.0
agent-33: 13.0
agent-34: 13.0
agent-35: 12.0
agent-36: 7.0
agent-37: 9.0
agent-38: 12.0
agent-39: 11.0
agent-40: 11.0
Sum Reward: 466.0
Avg Reward: 11.65
Min Reward: 7.0
Max Reward: 19.0
Gini Coefficient: 0.17221030042918456
20:20 Ratio: 2.293103448275862
Max-min Ratio: 2.7142857142857144
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-08_03-47-02
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 516.0
  episode_reward_mean: 467.26
  episode_reward_min: 425.0
  episodes_this_iter: 1
  episodes_total: 166
  experiment_id: 4e724eb5b3a34f42879644e84578eec0
  hostname: gpu024
  info:
    apply_time_ms: 2.835
    dispatch_time_ms: 6.519
    learner:
      cur_lr: 0.0009177760221064091
      grad_gnorm: 1.0651735067367554
      policy_entropy: 741.6038818359375
      policy_loss: 0.1514953374862671
      var_gnorm: 33.64114761352539
      vf_explained_var: -1.0
      vf_loss: 0.0010397086152806878
    num_steps_sampled: 6680000
    num_steps_trained: 6680000
    wait_time_ms: 537.57
  iterations_since_restore: 167
  node_ip: 172.17.8.24
  num_metric_batches_dropped: 0
  pid: 26970
  policy_reward_mean: {}
  time_since_restore: 9432.19617819786
  time_this_iter_s: 56.5478081703186
  time_total_s: 9432.19617819786
  timestamp: 1594194422
  timesteps_since_restore: 6680000
  timesteps_this_iter: 40000
  timesteps_total: 6680000
  training_iteration: 167
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26970], 9432 s, 167 iter, 6680000 ts, 467 rew

agent-1: 20.0
agent-2: 18.0
agent-3: 10.0
agent-4: 19.0
agent-5: 14.0
agent-6: 19.0
agent-7: 2.0
agent-8: 6.0
agent-9: 14.0
agent-10: 7.0
agent-11: 15.0
agent-12: 10.0
agent-13: 8.0
agent-14: 16.0
agent-15: 13.0
agent-16: 10.0
agent-17: 11.0
agent-18: 10.0
agent-19: 7.0
agent-20: 11.0
agent-21: 14.0
agent-22: 13.0
agent-23: 14.0
agent-24: 13.0
agent-25: 9.0
agent-26: 0.0
agent-27: 17.0
agent-28: 13.0
agent-29: 12.0
agent-30: 13.0
agent-31: 10.0
agent-32: 14.0
agent-33: 9.0
agent-34: 16.0
agent-35: 8.0
agent-36: 7.0
agent-37: 19.0
agent-38: 8.0
agent-39: 14.0
agent-40: 11.0
Sum Reward: 474.0
Avg Reward: 11.85
Min Reward: 0.0
Max Reward: 20.0
Gini Coefficient: 0.20833333333333334
20:20 Ratio: 3.2
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-08_03-47-59
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 516.0
  episode_reward_mean: 466.95
  episode_reward_min: 425.0
  episodes_this_iter: 1
  episodes_total: 167
  experiment_id: 4e724eb5b3a34f42879644e84578eec0
  hostname: gpu024
  info:
    apply_time_ms: 2.807
    dispatch_time_ms: 5.471
    learner:
      cur_lr: 0.0009151119738817215
      grad_gnorm: 4.011605739593506
      policy_entropy: 765.5804443359375
      policy_loss: 3.2742748260498047
      var_gnorm: 33.618438720703125
      vf_explained_var: -0.06609153747558594
      vf_loss: 0.0022747130133211613
    num_steps_sampled: 6720000
    num_steps_trained: 6720000
    wait_time_ms: 542.091
  iterations_since_restore: 168
  node_ip: 172.17.8.24
  num_metric_batches_dropped: 0
  pid: 26970
  policy_reward_mean: {}
  time_since_restore: 9488.612484455109
  time_this_iter_s: 56.416306257247925
  time_total_s: 9488.612484455109
  timestamp: 1594194479
  timesteps_since_restore: 6720000
  timesteps_this_iter: 40000
  timesteps_total: 6720000
  training_iteration: 168
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26970], 9488 s, 168 iter, 6720000 ts, 467 rew

agent-1: 13.0
agent-2: 7.0
agent-3: 12.0
agent-4: 12.0
agent-5: 13.0
agent-6: 14.0
agent-7: 5.0
agent-8: 11.0
agent-9: 8.0
agent-10: 8.0
agent-11: 13.0
agent-12: 5.0
agent-13: 8.0
agent-14: 19.0
agent-15: 9.0
agent-16: 9.0
agent-17: 11.0
agent-18: 11.0
agent-19: 13.0
agent-20: 14.0
agent-21: 6.0
agent-22: 12.0
agent-23: 8.0
agent-24: 21.0
agent-25: 12.0
agent-26: 7.0
agent-27: 9.0
agent-28: 8.0
agent-29: 14.0
agent-30: 14.0
agent-31: 12.0
agent-32: 10.0
agent-33: 13.0
agent-34: 9.0
agent-35: 15.0
agent-36: 8.0
agent-37: 12.0
agent-38: 10.0
agent-39: 15.0
agent-40: 12.0
Sum Reward: 442.0
Avg Reward: 11.05
Min Reward: 5.0
Max Reward: 21.0
Gini Coefficient: 0.16855203619909503
20:20 Ratio: 2.3333333333333335
Max-min Ratio: 4.2
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-08_03-48-55
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 516.0
  episode_reward_mean: 466.43
  episode_reward_min: 425.0
  episodes_this_iter: 1
  episodes_total: 168
  experiment_id: 4e724eb5b3a34f42879644e84578eec0
  hostname: gpu024
  info:
    apply_time_ms: 4.061
    dispatch_time_ms: 5.957
    learner:
      cur_lr: 0.0009124479838646948
      grad_gnorm: 2.0024030208587646
      policy_entropy: 768.1380615234375
      policy_loss: -0.1205863356590271
      var_gnorm: 33.71525573730469
      vf_explained_var: -0.0221635103225708
      vf_loss: 0.0005950456252321601
    num_steps_sampled: 6760000
    num_steps_trained: 6760000
    wait_time_ms: 548.505
  iterations_since_restore: 169
  node_ip: 172.17.8.24
  num_metric_batches_dropped: 0
  pid: 26970
  policy_reward_mean: {}
  time_since_restore: 9545.07146525383
  time_this_iter_s: 56.45898079872131
  time_total_s: 9545.07146525383
  timestamp: 1594194535
  timesteps_since_restore: 6760000
  timesteps_this_iter: 40000
  timesteps_total: 6760000
  training_iteration: 169
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26970], 9545 s, 169 iter, 6760000 ts, 466 rew

agent-1: 9.0
agent-2: 8.0
agent-3: 4.0
agent-4: 10.0
agent-5: 8.0
agent-6: 15.0
agent-7: 7.0
agent-8: 11.0
agent-9: 12.0
agent-10: 13.0
agent-11: 14.0
agent-12: 3.0
agent-13: 8.0
agent-14: 13.0
agent-15: 15.0
agent-16: 9.0
agent-17: 14.0
agent-18: 11.0
agent-19: 12.0
agent-20: 12.0
agent-21: 11.0
agent-22: 17.0
agent-23: 8.0
agent-24: 12.0
agent-25: 18.0
agent-26: 10.0
agent-27: 16.0
agent-28: 12.0
agent-29: 18.0
agent-30: 6.0
agent-31: 14.0
agent-32: 16.0
agent-33: 15.0
agent-34: 10.0
agent-35: 12.0
agent-36: 9.0
agent-37: 15.0
agent-38: 13.0
agent-39: 6.0
agent-40: 8.0
Sum Reward: 454.0
Avg Reward: 11.35
Min Reward: 3.0
Max Reward: 18.0
Gini Coefficient: 0.1814977973568282
20:20 Ratio: 2.6
Max-min Ratio: 6.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-08_03-49-52
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 516.0
  episode_reward_mean: 466.24
  episode_reward_min: 425.0
  episodes_this_iter: 1
  episodes_total: 169
  experiment_id: 4e724eb5b3a34f42879644e84578eec0
  hostname: gpu024
  info:
    apply_time_ms: 2.399
    dispatch_time_ms: 5.804
    learner:
      cur_lr: 0.0009097839938476682
      grad_gnorm: 5.4085774421691895
      policy_entropy: 760.2010498046875
      policy_loss: 2.332014322280884
      var_gnorm: 33.714542388916016
      vf_explained_var: -0.2144167423248291
      vf_loss: 0.00567876361310482
    num_steps_sampled: 6800000
    num_steps_trained: 6800000
    wait_time_ms: 558.593
  iterations_since_restore: 170
  node_ip: 172.17.8.24
  num_metric_batches_dropped: 0
  pid: 26970
  policy_reward_mean: {}
  time_since_restore: 9601.969508171082
  time_this_iter_s: 56.89804291725159
  time_total_s: 9601.969508171082
  timestamp: 1594194592
  timesteps_since_restore: 6800000
  timesteps_this_iter: 40000
  timesteps_total: 6800000
  training_iteration: 170
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26970], 9601 s, 170 iter, 6800000 ts, 466 rew

agent-1: 7.0
agent-2: 12.0
agent-3: 10.0
agent-4: 13.0
agent-5: 13.0
agent-6: 9.0
agent-7: 8.0
agent-8: 13.0
agent-9: 7.0
agent-10: 14.0
agent-11: 6.0
agent-12: 2.0
agent-13: 10.0
agent-14: 13.0
agent-15: 11.0
agent-16: 16.0
agent-17: 11.0
agent-18: 8.0
agent-19: 12.0
agent-20: 19.0
agent-21: 10.0
agent-22: 11.0
agent-23: 7.0
agent-24: 10.0
agent-25: 8.0
agent-26: 11.0
agent-27: 15.0
agent-28: 12.0
agent-29: 9.0
agent-30: 14.0
agent-31: 14.0
agent-32: 11.0
agent-33: 8.0
agent-34: 10.0
agent-35: 17.0
agent-36: 14.0
agent-37: 12.0
agent-38: 6.0
agent-39: 15.0
agent-40: 11.0
Sum Reward: 439.0
Avg Reward: 10.975
Min Reward: 2.0
Max Reward: 19.0
Gini Coefficient: 0.16850797266514805
20:20 Ratio: 2.4313725490196076
Max-min Ratio: 9.5
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-08_03-50-49
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 516.0
  episode_reward_mean: 465.7
  episode_reward_min: 425.0
  episodes_this_iter: 1
  episodes_total: 170
  experiment_id: 4e724eb5b3a34f42879644e84578eec0
  hostname: gpu024
  info:
    apply_time_ms: 3.012
    dispatch_time_ms: 5.698
    learner:
      cur_lr: 0.0009071200038306415
      grad_gnorm: 6.3329057693481445
      policy_entropy: 758.2330932617188
      policy_loss: 5.592473030090332
      var_gnorm: 33.83615493774414
      vf_explained_var: -0.16360533237457275
      vf_loss: 0.006269681267440319
    num_steps_sampled: 6840000
    num_steps_trained: 6840000
    wait_time_ms: 549.266
  iterations_since_restore: 171
  node_ip: 172.17.8.24
  num_metric_batches_dropped: 0
  pid: 26970
  policy_reward_mean: {}
  time_since_restore: 9658.707726240158
  time_this_iter_s: 56.73821806907654
  time_total_s: 9658.707726240158
  timestamp: 1594194649
  timesteps_since_restore: 6840000
  timesteps_this_iter: 40000
  timesteps_total: 6840000
  training_iteration: 171
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26970], 9658 s, 171 iter, 6840000 ts, 466 rew

agent-1: 16.0
agent-2: 11.0
agent-3: 15.0
agent-4: 11.0
agent-5: 11.0
agent-6: 8.0
agent-7: 6.0
agent-8: 12.0
agent-9: 12.0
agent-10: 11.0
agent-11: 11.0
agent-12: 18.0
agent-13: 13.0
agent-14: 18.0
agent-15: 10.0
agent-16: 10.0
agent-17: 9.0
agent-18: 15.0
agent-19: 12.0
agent-20: 5.0
agent-21: 12.0
agent-22: 10.0
agent-23: 10.0
agent-24: 7.0
agent-25: 9.0
agent-26: 15.0
agent-27: 10.0
agent-28: 14.0
agent-29: 12.0
agent-30: 12.0
agent-31: 14.0
agent-32: 13.0
agent-33: 17.0
agent-34: 11.0
agent-35: 9.0
agent-36: 14.0
agent-37: 14.0
agent-38: 13.0
agent-39: 5.0
agent-40: 12.0
Sum Reward: 467.0
Avg Reward: 11.675
Min Reward: 5.0
Max Reward: 18.0
Gini Coefficient: 0.14759100642398287
20:20 Ratio: 2.206896551724138
Max-min Ratio: 3.6
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-08_03-51-45
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 516.0
  episode_reward_mean: 465.46
  episode_reward_min: 425.0
  episodes_this_iter: 1
  episodes_total: 171
  experiment_id: 4e724eb5b3a34f42879644e84578eec0
  hostname: gpu024
  info:
    apply_time_ms: 4.116
    dispatch_time_ms: 6.177
    learner:
      cur_lr: 0.0009044560138136148
      grad_gnorm: 0.960723340511322
      policy_entropy: 770.51025390625
      policy_loss: -1.8411128520965576
      var_gnorm: 33.89229202270508
      vf_explained_var: -1.0
      vf_loss: 0.00019324824097566307
    num_steps_sampled: 6880000
    num_steps_trained: 6880000
    wait_time_ms: 550.101
  iterations_since_restore: 172
  node_ip: 172.17.8.24
  num_metric_batches_dropped: 0
  pid: 26970
  policy_reward_mean: {}
  time_since_restore: 9714.720388412476
  time_this_iter_s: 56.012662172317505
  time_total_s: 9714.720388412476
  timestamp: 1594194705
  timesteps_since_restore: 6880000
  timesteps_this_iter: 40000
  timesteps_total: 6880000
  training_iteration: 172
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26970], 9714 s, 172 iter, 6880000 ts, 465 rew

agent-1: 5.0
agent-2: 8.0
agent-3: 11.0
agent-4: 12.0
agent-5: 12.0
agent-6: 13.0
agent-7: 12.0
agent-8: 18.0
agent-9: 15.0
agent-10: 18.0
agent-11: 10.0
agent-12: 16.0
agent-13: 10.0
agent-14: 16.0
agent-15: 8.0
agent-16: 16.0
agent-17: 10.0
agent-18: 6.0
agent-19: 17.0
agent-20: 14.0
agent-21: 6.0
agent-22: 10.0
agent-23: 9.0
agent-24: 7.0
agent-25: 10.0
agent-26: 13.0
agent-27: 5.0
agent-28: 4.0
agent-29: 8.0
agent-30: 18.0
agent-31: 11.0
agent-32: 8.0
agent-33: 12.0
agent-34: 14.0
agent-35: 11.0
agent-36: 9.0
agent-37: 18.0
agent-38: 11.0
agent-39: 10.0
agent-40: 7.0
Sum Reward: 448.0
Avg Reward: 11.2
Min Reward: 4.0
Max Reward: 18.0
Gini Coefficient: 0.19754464285714285
20:20 Ratio: 2.8541666666666665
Max-min Ratio: 4.5
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-08_03-52-42
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 516.0
  episode_reward_mean: 464.92
  episode_reward_min: 425.0
  episodes_this_iter: 1
  episodes_total: 172
  experiment_id: 4e724eb5b3a34f42879644e84578eec0
  hostname: gpu024
  info:
    apply_time_ms: 2.515
    dispatch_time_ms: 4.954
    learner:
      cur_lr: 0.0009017920237965882
      grad_gnorm: 2.156949996948242
      policy_entropy: 772.0179443359375
      policy_loss: -1.8148655891418457
      var_gnorm: 33.9517936706543
      vf_explained_var: -0.46492135524749756
      vf_loss: 0.0007741538574919105
    num_steps_sampled: 6920000
    num_steps_trained: 6920000
    wait_time_ms: 574.405
  iterations_since_restore: 173
  node_ip: 172.17.8.24
  num_metric_batches_dropped: 0
  pid: 26970
  policy_reward_mean: {}
  time_since_restore: 9771.497890233994
  time_this_iter_s: 56.777501821517944
  time_total_s: 9771.497890233994
  timestamp: 1594194762
  timesteps_since_restore: 6920000
  timesteps_this_iter: 40000
  timesteps_total: 6920000
  training_iteration: 173
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26970], 9771 s, 173 iter, 6920000 ts, 465 rew

agent-1: 11.0
agent-2: 11.0
agent-3: 6.0
agent-4: 20.0
agent-5: 14.0
agent-6: 14.0
agent-7: 9.0
agent-8: 7.0
agent-9: 12.0
agent-10: 11.0
agent-11: 9.0
agent-12: 16.0
agent-13: 12.0
agent-14: 9.0
agent-15: 7.0
agent-16: 9.0
agent-17: 13.0
agent-18: 7.0
agent-19: 14.0
agent-20: 10.0
agent-21: 16.0
agent-22: 10.0
agent-23: 9.0
agent-24: 10.0
agent-25: 17.0
agent-26: 12.0
agent-27: 13.0
agent-28: 6.0
agent-29: 12.0
agent-30: 14.0
agent-31: 13.0
agent-32: 14.0
agent-33: 2.0
agent-34: 12.0
agent-35: 17.0
agent-36: 12.0
agent-37: 14.0
agent-38: 15.0
agent-39: 3.0
agent-40: 12.0
Sum Reward: 454.0
Avg Reward: 11.35
Min Reward: 2.0
Max Reward: 20.0
Gini Coefficient: 0.18160792951541851
20:20 Ratio: 2.74468085106383
Max-min Ratio: 10.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-08_03-53-38
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 516.0
  episode_reward_mean: 464.82
  episode_reward_min: 425.0
  episodes_this_iter: 1
  episodes_total: 173
  experiment_id: 4e724eb5b3a34f42879644e84578eec0
  hostname: gpu024
  info:
    apply_time_ms: 3.2
    dispatch_time_ms: 6.242
    learner:
      cur_lr: 0.0008991279755719006
      grad_gnorm: 1.0611951351165771
      policy_entropy: 764.73388671875
      policy_loss: 2.0114307403564453
      var_gnorm: 33.98299026489258
      vf_explained_var: -1.0
      vf_loss: 8.48349736770615e-05
    num_steps_sampled: 6960000
    num_steps_trained: 6960000
    wait_time_ms: 553.395
  iterations_since_restore: 174
  node_ip: 172.17.8.24
  num_metric_batches_dropped: 0
  pid: 26970
  policy_reward_mean: {}
  time_since_restore: 9827.882579565048
  time_this_iter_s: 56.38468933105469
  time_total_s: 9827.882579565048
  timestamp: 1594194818
  timesteps_since_restore: 6960000
  timesteps_this_iter: 40000
  timesteps_total: 6960000
  training_iteration: 174
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26970], 9827 s, 174 iter, 6960000 ts, 465 rew

agent-1: 14.0
agent-2: 11.0
agent-3: 9.0
agent-4: 8.0
agent-5: 10.0
agent-6: 15.0
agent-7: 17.0
agent-8: 14.0
agent-9: 14.0
agent-10: 8.0
agent-11: 10.0
agent-12: 8.0
agent-13: 10.0
agent-14: 10.0
agent-15: 17.0
agent-16: 9.0
agent-17: 8.0
agent-18: 7.0
agent-19: 11.0
agent-20: 13.0
agent-21: 6.0
agent-22: 14.0
agent-23: 6.0
agent-24: 8.0
agent-25: 11.0
agent-26: 11.0
agent-27: 6.0
agent-28: 9.0
agent-29: 17.0
agent-30: 11.0
agent-31: 13.0
agent-32: 12.0
agent-33: 11.0
agent-34: 14.0
agent-35: 11.0
agent-36: 21.0
agent-37: 4.0
agent-38: 17.0
agent-39: 14.0
agent-40: 14.0
Sum Reward: 453.0
Avg Reward: 11.325
Min Reward: 4.0
Max Reward: 21.0
Gini Coefficient: 0.17985651214128034
20:20 Ratio: 2.490566037735849
Max-min Ratio: 5.25
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-08_03-54-35
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 516.0
  episode_reward_mean: 464.21
  episode_reward_min: 425.0
  episodes_this_iter: 1
  episodes_total: 174
  experiment_id: 4e724eb5b3a34f42879644e84578eec0
  hostname: gpu024
  info:
    apply_time_ms: 2.754
    dispatch_time_ms: 6.001
    learner:
      cur_lr: 0.0008964639855548739
      grad_gnorm: 0.23516137897968292
      policy_entropy: 775.621337890625
      policy_loss: 0.18032726645469666
      var_gnorm: 34.04538345336914
      vf_explained_var: -1.0
      vf_loss: 0.0005512911593541503
    num_steps_sampled: 7000000
    num_steps_trained: 7000000
    wait_time_ms: 554.679
  iterations_since_restore: 175
  node_ip: 172.17.8.24
  num_metric_batches_dropped: 0
  pid: 26970
  policy_reward_mean: {}
  time_since_restore: 9884.478217363358
  time_this_iter_s: 56.595637798309326
  time_total_s: 9884.478217363358
  timestamp: 1594194875
  timesteps_since_restore: 7000000
  timesteps_this_iter: 40000
  timesteps_total: 7000000
  training_iteration: 175
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26970], 9884 s, 175 iter, 7000000 ts, 464 rew

agent-1: 15.0
agent-2: 7.0
agent-3: 12.0
agent-4: 8.0
agent-5: 7.0
agent-6: 13.0
agent-7: 10.0
agent-8: 11.0
agent-9: 16.0
agent-10: 4.0
agent-11: 8.0
agent-12: 18.0
agent-13: 17.0
agent-14: 9.0
agent-15: 13.0
agent-16: 6.0
agent-17: 12.0
agent-18: 8.0
agent-19: 14.0
agent-20: 15.0
agent-21: 6.0
agent-22: 11.0
agent-23: 14.0
agent-24: 10.0
agent-25: 12.0
agent-26: 4.0
agent-27: 16.0
agent-28: 13.0
agent-29: 9.0
agent-30: 14.0
agent-31: 12.0
agent-32: 11.0
agent-33: 17.0
agent-34: 10.0
agent-35: 20.0
agent-36: 8.0
agent-37: 7.0
agent-38: 6.0
agent-39: 17.0
agent-40: 10.0
Sum Reward: 450.0
Avg Reward: 11.25
Min Reward: 4.0
Max Reward: 20.0
Gini Coefficient: 0.20155555555555554
20:20 Ratio: 2.893617021276596
Max-min Ratio: 5.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-08_03-55-32
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 516.0
  episode_reward_mean: 463.87
  episode_reward_min: 425.0
  episodes_this_iter: 1
  episodes_total: 175
  experiment_id: 4e724eb5b3a34f42879644e84578eec0
  hostname: gpu024
  info:
    apply_time_ms: 3.076
    dispatch_time_ms: 7.288
    learner:
      cur_lr: 0.0008937999955378473
      grad_gnorm: 3.042259931564331
      policy_entropy: 774.759521484375
      policy_loss: -2.219241142272949
      var_gnorm: 34.087310791015625
      vf_explained_var: -0.19851410388946533
      vf_loss: 0.0013204581337049603
    num_steps_sampled: 7040000
    num_steps_trained: 7040000
    wait_time_ms: 551.819
  iterations_since_restore: 176
  node_ip: 172.17.8.24
  num_metric_batches_dropped: 0
  pid: 26970
  policy_reward_mean: {}
  time_since_restore: 9941.43863105774
  time_this_iter_s: 56.960413694381714
  time_total_s: 9941.43863105774
  timestamp: 1594194932
  timesteps_since_restore: 7040000
  timesteps_this_iter: 40000
  timesteps_total: 7040000
  training_iteration: 176
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26970], 9941 s, 176 iter, 7040000 ts, 464 rew

agent-1: 7.0
agent-2: 7.0
agent-3: 11.0
agent-4: 13.0
agent-5: 12.0
agent-6: 14.0
agent-7: 7.0
agent-8: 3.0
agent-9: 11.0
agent-10: 17.0
agent-11: 13.0
agent-12: 9.0
agent-13: 5.0
agent-14: 11.0
agent-15: 20.0
agent-16: 12.0
agent-17: 16.0
agent-18: 11.0
agent-19: 15.0
agent-20: 9.0
agent-21: 7.0
agent-22: 9.0
agent-23: 15.0
agent-24: 11.0
agent-25: 9.0
agent-26: 14.0
agent-27: 12.0
agent-28: 14.0
agent-29: 9.0
agent-30: 9.0
agent-31: 12.0
agent-32: 11.0
agent-33: 16.0
agent-34: 10.0
agent-35: 12.0
agent-36: 12.0
agent-37: 12.0
agent-38: 9.0
agent-39: 14.0
agent-40: 13.0
Sum Reward: 453.0
Avg Reward: 11.325
Min Reward: 3.0
Max Reward: 20.0
Gini Coefficient: 0.16252759381898454
20:20 Ratio: 2.3518518518518516
Max-min Ratio: 6.666666666666667
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-08_03-56-28
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 516.0
  episode_reward_mean: 463.46
  episode_reward_min: 425.0
  episodes_this_iter: 1
  episodes_total: 176
  experiment_id: 4e724eb5b3a34f42879644e84578eec0
  hostname: gpu024
  info:
    apply_time_ms: 2.599
    dispatch_time_ms: 5.484
    learner:
      cur_lr: 0.0008911360055208206
      grad_gnorm: 0.7624940276145935
      policy_entropy: 772.1687622070312
      policy_loss: 0.013457417488098145
      var_gnorm: 34.152854919433594
      vf_explained_var: -1.0
      vf_loss: 0.00015673112648073584
    num_steps_sampled: 7080000
    num_steps_trained: 7080000
    wait_time_ms: 566.161
  iterations_since_restore: 177
  node_ip: 172.17.8.24
  num_metric_batches_dropped: 0
  pid: 26970
  policy_reward_mean: {}
  time_since_restore: 9997.897864818573
  time_this_iter_s: 56.45923376083374
  time_total_s: 9997.897864818573
  timestamp: 1594194988
  timesteps_since_restore: 7080000
  timesteps_this_iter: 40000
  timesteps_total: 7080000
  training_iteration: 177
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26970], 9997 s, 177 iter, 7080000 ts, 463 rew

agent-1: 9.0
agent-2: 14.0
agent-3: 15.0
agent-4: 16.0
agent-5: 13.0
agent-6: 14.0
agent-7: 19.0
agent-8: 8.0
agent-9: 15.0
agent-10: 11.0
agent-11: 7.0
agent-12: 10.0
agent-13: 13.0
agent-14: 12.0
agent-15: 9.0
agent-16: 13.0
agent-17: 9.0
agent-18: 8.0
agent-19: 17.0
agent-20: 11.0
agent-21: 7.0
agent-22: 16.0
agent-23: 2.0
agent-24: 17.0
agent-25: 11.0
agent-26: 4.0
agent-27: 13.0
agent-28: 9.0
agent-29: 14.0
agent-30: 6.0
agent-31: 9.0
agent-32: 9.0
agent-33: 2.0
agent-34: 15.0
agent-35: 7.0
agent-36: 14.0
agent-37: 7.0
agent-38: 8.0
agent-39: 9.0
agent-40: 8.0
Sum Reward: 430.0
Avg Reward: 10.75
Min Reward: 2.0
Max Reward: 19.0
Gini Coefficient: 0.2116279069767442
20:20 Ratio: 3.0952380952380953
Max-min Ratio: 9.5
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-08_03-57-25
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 516.0
  episode_reward_mean: 462.67
  episode_reward_min: 425.0
  episodes_this_iter: 1
  episodes_total: 177
  experiment_id: 4e724eb5b3a34f42879644e84578eec0
  hostname: gpu024
  info:
    apply_time_ms: 3.842
    dispatch_time_ms: 5.738
    learner:
      cur_lr: 0.000888472015503794
      grad_gnorm: 5.567241668701172
      policy_entropy: 735.5889282226562
      policy_loss: 3.1195199489593506
      var_gnorm: 34.157745361328125
      vf_explained_var: -1.0
      vf_loss: 0.07282467186450958
    num_steps_sampled: 7120000
    num_steps_trained: 7120000
    wait_time_ms: 572.733
  iterations_since_restore: 178
  node_ip: 172.17.8.24
  num_metric_batches_dropped: 0
  pid: 26970
  policy_reward_mean: {}
  time_since_restore: 10054.432971954346
  time_this_iter_s: 56.535107135772705
  time_total_s: 10054.432971954346
  timestamp: 1594195045
  timesteps_since_restore: 7120000
  timesteps_this_iter: 40000
  timesteps_total: 7120000
  training_iteration: 178
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26970], 10054 s, 178 iter, 7120000 ts, 463 rew

agent-1: 12.0
agent-2: 14.0
agent-3: 15.0
agent-4: 11.0
agent-5: 4.0
agent-6: 16.0
agent-7: 14.0
agent-8: 16.0
agent-9: 3.0
agent-10: 12.0
agent-11: 10.0
agent-12: 14.0
agent-13: 13.0
agent-14: 12.0
agent-15: 11.0
agent-16: 13.0
agent-17: 6.0
agent-18: 16.0
agent-19: 14.0
agent-20: 6.0
agent-21: 13.0
agent-22: 10.0
agent-23: 10.0
agent-24: 10.0
agent-25: 8.0
agent-26: 11.0
agent-27: 12.0
agent-28: 10.0
agent-29: 9.0
agent-30: 8.0
agent-31: 8.0
agent-32: 9.0
agent-33: 12.0
agent-34: 16.0
agent-35: 15.0
agent-36: 11.0
agent-37: 10.0
agent-38: 18.0
agent-39: 2.0
agent-40: 6.0
Sum Reward: 440.0
Avg Reward: 11.0
Min Reward: 2.0
Max Reward: 18.0
Gini Coefficient: 0.1875
20:20 Ratio: 2.9302325581395348
Max-min Ratio: 9.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-08_03-58-21
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 516.0
  episode_reward_mean: 461.94
  episode_reward_min: 425.0
  episodes_this_iter: 1
  episodes_total: 178
  experiment_id: 4e724eb5b3a34f42879644e84578eec0
  hostname: gpu024
  info:
    apply_time_ms: 2.622
    dispatch_time_ms: 6.214
    learner:
      cur_lr: 0.0008858080254867673
      grad_gnorm: 7.703603267669678
      policy_entropy: 754.2110595703125
      policy_loss: -1.596700668334961
      var_gnorm: 34.204959869384766
      vf_explained_var: -0.36909759044647217
      vf_loss: 0.005038132891058922
    num_steps_sampled: 7160000
    num_steps_trained: 7160000
    wait_time_ms: 562.286
  iterations_since_restore: 179
  node_ip: 172.17.8.24
  num_metric_batches_dropped: 0
  pid: 26970
  policy_reward_mean: {}
  time_since_restore: 10110.3930914402
  time_this_iter_s: 55.9601194858551
  time_total_s: 10110.3930914402
  timestamp: 1594195101
  timesteps_since_restore: 7160000
  timesteps_this_iter: 40000
  timesteps_total: 7160000
  training_iteration: 179
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26970], 10110 s, 179 iter, 7160000 ts, 462 rew

agent-1: 7.0
agent-2: 15.0
agent-3: 5.0
agent-4: 10.0
agent-5: 2.0
agent-6: 13.0
agent-7: 10.0
agent-8: 13.0
agent-9: 14.0
agent-10: 5.0
agent-11: 11.0
agent-12: 20.0
agent-13: 10.0
agent-14: 15.0
agent-15: 15.0
agent-16: 12.0
agent-17: 15.0
agent-18: 11.0
agent-19: 8.0
agent-20: 7.0
agent-21: 12.0
agent-22: 12.0
agent-23: 18.0
agent-24: 15.0
agent-25: 7.0
agent-26: 10.0
agent-27: 14.0
agent-28: 16.0
agent-29: 9.0
agent-30: 14.0
agent-31: 8.0
agent-32: 12.0
agent-33: 18.0
agent-34: 7.0
agent-35: 10.0
agent-36: 11.0
agent-37: 9.0
agent-38: 18.0
agent-39: 10.0
agent-40: 6.0
Sum Reward: 454.0
Avg Reward: 11.35
Min Reward: 2.0
Max Reward: 20.0
Gini Coefficient: 0.19966960352422908
20:20 Ratio: 2.9347826086956523
Max-min Ratio: 10.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-08_03-59-18
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 516.0
  episode_reward_mean: 461.42
  episode_reward_min: 425.0
  episodes_this_iter: 1
  episodes_total: 179
  experiment_id: 4e724eb5b3a34f42879644e84578eec0
  hostname: gpu024
  info:
    apply_time_ms: 3.548
    dispatch_time_ms: 6.937
    learner:
      cur_lr: 0.0008831439772620797
      grad_gnorm: 6.627414703369141
      policy_entropy: 766.619873046875
      policy_loss: 1.9330822229385376
      var_gnorm: 34.274009704589844
      vf_explained_var: -0.6837719678878784
      vf_loss: 0.002288504969328642
    num_steps_sampled: 7200000
    num_steps_trained: 7200000
    wait_time_ms: 556.545
  iterations_since_restore: 180
  node_ip: 172.17.8.24
  num_metric_batches_dropped: 0
  pid: 26970
  policy_reward_mean: {}
  time_since_restore: 10167.287953853607
  time_this_iter_s: 56.89486241340637
  time_total_s: 10167.287953853607
  timestamp: 1594195158
  timesteps_since_restore: 7200000
  timesteps_this_iter: 40000
  timesteps_total: 7200000
  training_iteration: 180
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26970], 10167 s, 180 iter, 7200000 ts, 461 rew

agent-1: 8.0
agent-2: 10.0
agent-3: 14.0
agent-4: 16.0
agent-5: 14.0
agent-6: 16.0
agent-7: 14.0
agent-8: 12.0
agent-9: 9.0
agent-10: 8.0
agent-11: 15.0
agent-12: 16.0
agent-13: 11.0
agent-14: 10.0
agent-15: 21.0
agent-16: 12.0
agent-17: 9.0
agent-18: 13.0
agent-19: 11.0
agent-20: 17.0
agent-21: 7.0
agent-22: 19.0
agent-23: 4.0
agent-24: 13.0
agent-25: 16.0
agent-26: 13.0
agent-27: 13.0
agent-28: 7.0
agent-29: 8.0
agent-30: 15.0
agent-31: 5.0
agent-32: 14.0
agent-33: 12.0
agent-34: 11.0
agent-35: 6.0
agent-36: 9.0
agent-37: 7.0
agent-38: 11.0
agent-39: 16.0
agent-40: 11.0
Sum Reward: 473.0
Avg Reward: 11.825
Min Reward: 4.0
Max Reward: 21.0
Gini Coefficient: 0.18313953488372092
20:20 Ratio: 2.6346153846153846
Max-min Ratio: 5.25
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-08_04-00-14
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 516.0
  episode_reward_mean: 461.17
  episode_reward_min: 425.0
  episodes_this_iter: 1
  episodes_total: 180
  experiment_id: 4e724eb5b3a34f42879644e84578eec0
  hostname: gpu024
  info:
    apply_time_ms: 2.974
    dispatch_time_ms: 6.122
    learner:
      cur_lr: 0.000880479987245053
      grad_gnorm: 1.6223506927490234
      policy_entropy: 753.7779541015625
      policy_loss: 0.8940492868423462
      var_gnorm: 34.315399169921875
      vf_explained_var: -0.24969780445098877
      vf_loss: 0.002437352202832699
    num_steps_sampled: 7240000
    num_steps_trained: 7240000
    wait_time_ms: 564.375
  iterations_since_restore: 181
  node_ip: 172.17.8.24
  num_metric_batches_dropped: 0
  pid: 26970
  policy_reward_mean: {}
  time_since_restore: 10223.42718052864
  time_this_iter_s: 56.13922667503357
  time_total_s: 10223.42718052864
  timestamp: 1594195214
  timesteps_since_restore: 7240000
  timesteps_this_iter: 40000
  timesteps_total: 7240000
  training_iteration: 181
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26970], 10223 s, 181 iter, 7240000 ts, 461 rew

agent-1: 5.0
agent-2: 18.0
agent-3: 13.0
agent-4: 14.0
agent-5: 12.0
agent-6: 13.0
agent-7: 9.0
agent-8: 10.0
agent-9: 12.0
agent-10: 9.0
agent-11: 5.0
agent-12: 11.0
agent-13: 13.0
agent-14: 16.0
agent-15: 15.0
agent-16: 8.0
agent-17: 9.0
agent-18: 11.0
agent-19: 3.0
agent-20: 7.0
agent-21: 8.0
agent-22: 12.0
agent-23: 6.0
agent-24: 14.0
agent-25: 13.0
agent-26: 13.0
agent-27: 12.0
agent-28: 4.0
agent-29: 8.0
agent-30: 10.0
agent-31: 10.0
agent-32: 16.0
agent-33: 14.0
agent-34: 11.0
agent-35: 17.0
agent-36: 17.0
agent-37: 12.0
agent-38: 9.0
agent-39: 15.0
agent-40: 15.0
Sum Reward: 449.0
Avg Reward: 11.225
Min Reward: 3.0
Max Reward: 18.0
Gini Coefficient: 0.18569042316258352
20:20 Ratio: 2.8043478260869565
Max-min Ratio: 6.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-08_04-01-11
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 516.0
  episode_reward_mean: 460.66
  episode_reward_min: 425.0
  episodes_this_iter: 1
  episodes_total: 181
  experiment_id: 4e724eb5b3a34f42879644e84578eec0
  hostname: gpu024
  info:
    apply_time_ms: 2.659
    dispatch_time_ms: 6.541
    learner:
      cur_lr: 0.0008778159972280264
      grad_gnorm: 1.8581355810165405
      policy_entropy: 750.822021484375
      policy_loss: -1.5212899446487427
      var_gnorm: 34.28812026977539
      vf_explained_var: -0.6984699964523315
      vf_loss: 0.0008859602967277169
    num_steps_sampled: 7280000
    num_steps_trained: 7280000
    wait_time_ms: 551.793
  iterations_since_restore: 182
  node_ip: 172.17.8.24
  num_metric_batches_dropped: 0
  pid: 26970
  policy_reward_mean: {}
  time_since_restore: 10280.389063835144
  time_this_iter_s: 56.961883306503296
  time_total_s: 10280.389063835144
  timestamp: 1594195271
  timesteps_since_restore: 7280000
  timesteps_this_iter: 40000
  timesteps_total: 7280000
  training_iteration: 182
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26970], 10280 s, 182 iter, 7280000 ts, 461 rew

agent-1: 12.0
agent-2: 10.0
agent-3: 1.0
agent-4: 8.0
agent-5: 11.0
agent-6: 13.0
agent-7: 9.0
agent-8: 18.0
agent-9: 12.0
agent-10: 9.0
agent-11: 11.0
agent-12: 13.0
agent-13: 11.0
agent-14: 9.0
agent-15: 14.0
agent-16: 16.0
agent-17: 12.0
agent-18: 10.0
agent-19: 7.0
agent-20: 15.0
agent-21: 13.0
agent-22: 7.0
agent-23: 20.0
agent-24: 9.0
agent-25: 7.0
agent-26: 7.0
agent-27: 0.0
agent-28: 12.0
agent-29: 17.0
agent-30: 19.0
agent-31: 9.0
agent-32: 10.0
agent-33: 12.0
agent-34: 20.0
agent-35: 9.0
agent-36: 17.0
agent-37: 6.0
agent-38: 10.0
agent-39: 10.0
agent-40: 14.0
Sum Reward: 449.0
Avg Reward: 11.225
Min Reward: 0.0
Max Reward: 20.0
Gini Coefficient: 0.21430957683741647
20:20 Ratio: 3.302325581395349
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-08_04-02-08
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 516.0
  episode_reward_mean: 460.12
  episode_reward_min: 425.0
  episodes_this_iter: 1
  episodes_total: 182
  experiment_id: 4e724eb5b3a34f42879644e84578eec0
  hostname: gpu024
  info:
    apply_time_ms: 3.479
    dispatch_time_ms: 6.636
    learner:
      cur_lr: 0.0008751520072109997
      grad_gnorm: 2.031266450881958
      policy_entropy: 764.4096069335938
      policy_loss: 1.3808304071426392
      var_gnorm: 34.40004348754883
      vf_explained_var: -0.7433412075042725
      vf_loss: 0.0005986307514831424
    num_steps_sampled: 7320000
    num_steps_trained: 7320000
    wait_time_ms: 550.298
  iterations_since_restore: 183
  node_ip: 172.17.8.24
  num_metric_batches_dropped: 0
  pid: 26970
  policy_reward_mean: {}
  time_since_restore: 10337.11167550087
  time_this_iter_s: 56.72261166572571
  time_total_s: 10337.11167550087
  timestamp: 1594195328
  timesteps_since_restore: 7320000
  timesteps_this_iter: 40000
  timesteps_total: 7320000
  training_iteration: 183
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26970], 10337 s, 183 iter, 7320000 ts, 460 rew

agent-1: 10.0
agent-2: 13.0
agent-3: 16.0
agent-4: 14.0
agent-5: 10.0
agent-6: 10.0
agent-7: 11.0
agent-8: 4.0
agent-9: 18.0
agent-10: 9.0
agent-11: 10.0
agent-12: 12.0
agent-13: 9.0
agent-14: 8.0
agent-15: 17.0
agent-16: 2.0
agent-17: 8.0
agent-18: 10.0
agent-19: 11.0
agent-20: 16.0
agent-21: 15.0
agent-22: 9.0
agent-23: 15.0
agent-24: 13.0
agent-25: 13.0
agent-26: 17.0
agent-27: 15.0
agent-28: 14.0
agent-29: 14.0
agent-30: 11.0
agent-31: 3.0
agent-32: 16.0
agent-33: 11.0
agent-34: 15.0
agent-35: 16.0
agent-36: 4.0
agent-37: 3.0
agent-38: 19.0
agent-39: 12.0
agent-40: 12.0
Sum Reward: 465.0
Avg Reward: 11.625
Min Reward: 2.0
Max Reward: 19.0
Gini Coefficient: 0.20306451612903226
20:20 Ratio: 3.292682926829268
Max-min Ratio: 9.5
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-08_04-03-04
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 516.0
  episode_reward_mean: 460.15
  episode_reward_min: 425.0
  episodes_this_iter: 1
  episodes_total: 183
  experiment_id: 4e724eb5b3a34f42879644e84578eec0
  hostname: gpu024
  info:
    apply_time_ms: 2.577
    dispatch_time_ms: 6.287
    learner:
      cur_lr: 0.0008724880171939731
      grad_gnorm: 2.246487617492676
      policy_entropy: 765.9683837890625
      policy_loss: -2.680429458618164
      var_gnorm: 34.4572639465332
      vf_explained_var: -0.24474287033081055
      vf_loss: 0.005081024952232838
    num_steps_sampled: 7360000
    num_steps_trained: 7360000
    wait_time_ms: 563.906
  iterations_since_restore: 184
  node_ip: 172.17.8.24
  num_metric_batches_dropped: 0
  pid: 26970
  policy_reward_mean: {}
  time_since_restore: 10393.220283031464
  time_this_iter_s: 56.10860753059387
  time_total_s: 10393.220283031464
  timestamp: 1594195384
  timesteps_since_restore: 7360000
  timesteps_this_iter: 40000
  timesteps_total: 7360000
  training_iteration: 184
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26970], 10393 s, 184 iter, 7360000 ts, 460 rew

agent-1: 18.0
agent-2: 9.0
agent-3: 15.0
agent-4: 14.0
agent-5: 11.0
agent-6: 2.0
agent-7: 18.0
agent-8: 7.0
agent-9: 10.0
agent-10: 11.0
agent-11: 15.0
agent-12: 8.0
agent-13: 8.0
agent-14: 13.0
agent-15: 13.0
agent-16: 12.0
agent-17: 9.0
agent-18: 14.0
agent-19: 9.0
agent-20: 12.0
agent-21: 17.0
agent-22: 13.0
agent-23: 13.0
agent-24: 14.0
agent-25: 9.0
agent-26: 9.0
agent-27: 9.0
agent-28: 11.0
agent-29: 7.0
agent-30: 14.0
agent-31: 20.0
agent-32: 10.0
agent-33: 2.0
agent-34: 13.0
agent-35: 10.0
agent-36: 8.0
agent-37: 7.0
agent-38: 12.0
agent-39: 10.0
agent-40: 6.0
Sum Reward: 442.0
Avg Reward: 11.05
Min Reward: 2.0
Max Reward: 20.0
Gini Coefficient: 0.19366515837104073
20:20 Ratio: 2.7872340425531914
Max-min Ratio: 10.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-08_04-04-01
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 516.0
  episode_reward_mean: 459.73
  episode_reward_min: 425.0
  episodes_this_iter: 1
  episodes_total: 184
  experiment_id: 4e724eb5b3a34f42879644e84578eec0
  hostname: gpu024
  info:
    apply_time_ms: 2.708
    dispatch_time_ms: 6.382
    learner:
      cur_lr: 0.0008698240271769464
      grad_gnorm: 0.9378971457481384
      policy_entropy: 760.7764892578125
      policy_loss: -1.021246075630188
      var_gnorm: 34.48779296875
      vf_explained_var: -1.0
      vf_loss: 0.003152434481307864
    num_steps_sampled: 7400000
    num_steps_trained: 7400000
    wait_time_ms: 561.39
  iterations_since_restore: 185
  node_ip: 172.17.8.24
  num_metric_batches_dropped: 0
  pid: 26970
  policy_reward_mean: {}
  time_since_restore: 10449.898689508438
  time_this_iter_s: 56.67840647697449
  time_total_s: 10449.898689508438
  timestamp: 1594195441
  timesteps_since_restore: 7400000
  timesteps_this_iter: 40000
  timesteps_total: 7400000
  training_iteration: 185
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26970], 10449 s, 185 iter, 7400000 ts, 460 rew

agent-1: 11.0
agent-2: 10.0
agent-3: 12.0
agent-4: 9.0
agent-5: 12.0
agent-6: 4.0
agent-7: 10.0
agent-8: 15.0
agent-9: 10.0
agent-10: 9.0
agent-11: 12.0
agent-12: 11.0
agent-13: 14.0
agent-14: 13.0
agent-15: 11.0
agent-16: 9.0
agent-17: 15.0
agent-18: 10.0
agent-19: 18.0
agent-20: 12.0
agent-21: 8.0
agent-22: 6.0
agent-23: 7.0
agent-24: 8.0
agent-25: 5.0
agent-26: 14.0
agent-27: 6.0
agent-28: 13.0
agent-29: 11.0
agent-30: 14.0
agent-31: 9.0
agent-32: 11.0
agent-33: 15.0
agent-34: 13.0
agent-35: 18.0
agent-36: 12.0
agent-37: 13.0
agent-38: 11.0
agent-39: 5.0
agent-40: 4.0
Sum Reward: 430.0
Avg Reward: 10.75
Min Reward: 4.0
Max Reward: 18.0
Gini Coefficient: 0.17802325581395348
20:20 Ratio: 2.7333333333333334
Max-min Ratio: 4.5
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-08_04-04-58
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 516.0
  episode_reward_mean: 459.7
  episode_reward_min: 425.0
  episodes_this_iter: 1
  episodes_total: 185
  experiment_id: 4e724eb5b3a34f42879644e84578eec0
  hostname: gpu024
  info:
    apply_time_ms: 2.811
    dispatch_time_ms: 5.838
    learner:
      cur_lr: 0.0008671599789522588
      grad_gnorm: 0.7746174335479736
      policy_entropy: 757.2680053710938
      policy_loss: 0.017056375741958618
      var_gnorm: 34.50945281982422
      vf_explained_var: -1.0
      vf_loss: 0.0006543188355863094
    num_steps_sampled: 7440000
    num_steps_trained: 7440000
    wait_time_ms: 555.939
  iterations_since_restore: 186
  node_ip: 172.17.8.24
  num_metric_batches_dropped: 0
  pid: 26970
  policy_reward_mean: {}
  time_since_restore: 10506.67915558815
  time_this_iter_s: 56.780466079711914
  time_total_s: 10506.67915558815
  timestamp: 1594195498
  timesteps_since_restore: 7440000
  timesteps_this_iter: 40000
  timesteps_total: 7440000
  training_iteration: 186
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26970], 10506 s, 186 iter, 7440000 ts, 460 rew

agent-1: 14.0
agent-2: 12.0
agent-3: 10.0
agent-4: 11.0
agent-5: 12.0
agent-6: 15.0
agent-7: 11.0
agent-8: 6.0
agent-9: 12.0
agent-10: 13.0
agent-11: 10.0
agent-12: 10.0
agent-13: 13.0
agent-14: 15.0
agent-15: 4.0
agent-16: 10.0
agent-17: 17.0
agent-18: 16.0
agent-19: 10.0
agent-20: 7.0
agent-21: 9.0
agent-22: 17.0
agent-23: 11.0
agent-24: 15.0
agent-25: 13.0
agent-26: 18.0
agent-27: 5.0
agent-28: 11.0
agent-29: 13.0
agent-30: 17.0
agent-31: 9.0
agent-32: 9.0
agent-33: 7.0
agent-34: 8.0
agent-35: 14.0
agent-36: 11.0
agent-37: 5.0
agent-38: 12.0
agent-39: 9.0
agent-40: 17.0
Sum Reward: 458.0
Avg Reward: 11.45
Min Reward: 4.0
Max Reward: 18.0
Gini Coefficient: 0.17587336244541485
20:20 Ratio: 2.588235294117647
Max-min Ratio: 4.5
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-08_04-05-54
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 516.0
  episode_reward_mean: 459.37
  episode_reward_min: 425.0
  episodes_this_iter: 1
  episodes_total: 186
  experiment_id: 4e724eb5b3a34f42879644e84578eec0
  hostname: gpu024
  info:
    apply_time_ms: 2.894
    dispatch_time_ms: 6.128
    learner:
      cur_lr: 0.0008644959889352322
      grad_gnorm: 1.4673140048980713
      policy_entropy: 751.3072509765625
      policy_loss: -1.6603330373764038
      var_gnorm: 34.550331115722656
      vf_explained_var: -1.0
      vf_loss: 0.00025260233087465167
    num_steps_sampled: 7480000
    num_steps_trained: 7480000
    wait_time_ms: 556.633
  iterations_since_restore: 187
  node_ip: 172.17.8.24
  num_metric_batches_dropped: 0
  pid: 26970
  policy_reward_mean: {}
  time_since_restore: 10563.078214883804
  time_this_iter_s: 56.3990592956543
  time_total_s: 10563.078214883804
  timestamp: 1594195554
  timesteps_since_restore: 7480000
  timesteps_this_iter: 40000
  timesteps_total: 7480000
  training_iteration: 187
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26970], 10563 s, 187 iter, 7480000 ts, 459 rew

agent-1: 15.0
agent-2: 17.0
agent-3: 8.0
agent-4: 10.0
agent-5: 10.0
agent-6: 14.0
agent-7: 11.0
agent-8: 12.0
agent-9: 6.0
agent-10: 8.0
agent-11: 16.0
agent-12: 10.0
agent-13: 14.0
agent-14: 12.0
agent-15: 14.0
agent-16: 12.0
agent-17: 4.0
agent-18: 9.0
agent-19: 5.0
agent-20: 15.0
agent-21: 8.0
agent-22: 6.0
agent-23: 10.0
agent-24: 16.0
agent-25: 14.0
agent-26: 15.0
agent-27: 7.0
agent-28: 16.0
agent-29: 10.0
agent-30: 11.0
agent-31: 6.0
agent-32: 9.0
agent-33: 15.0
agent-34: 12.0
agent-35: 5.0
agent-36: 13.0
agent-37: 13.0
agent-38: 10.0
agent-39: 9.0
agent-40: 10.0
Sum Reward: 437.0
Avg Reward: 10.925
Min Reward: 4.0
Max Reward: 17.0
Gini Coefficient: 0.18140732265446224
20:20 Ratio: 2.6595744680851063
Max-min Ratio: 4.25
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-08_04-06-51
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 516.0
  episode_reward_mean: 459.23
  episode_reward_min: 425.0
  episodes_this_iter: 1
  episodes_total: 187
  experiment_id: 4e724eb5b3a34f42879644e84578eec0
  hostname: gpu024
  info:
    apply_time_ms: 2.41
    dispatch_time_ms: 7.521
    learner:
      cur_lr: 0.0008618319989182055
      grad_gnorm: 4.377297401428223
      policy_entropy: 747.3209228515625
      policy_loss: 4.29156494140625
      var_gnorm: 34.55817413330078
      vf_explained_var: -1.0
      vf_loss: 0.007778732571750879
    num_steps_sampled: 7520000
    num_steps_trained: 7520000
    wait_time_ms: 543.307
  iterations_since_restore: 188
  node_ip: 172.17.8.24
  num_metric_batches_dropped: 0
  pid: 26970
  policy_reward_mean: {}
  time_since_restore: 10619.858490467072
  time_this_iter_s: 56.78027558326721
  time_total_s: 10619.858490467072
  timestamp: 1594195611
  timesteps_since_restore: 7520000
  timesteps_this_iter: 40000
  timesteps_total: 7520000
  training_iteration: 188
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26970], 10619 s, 188 iter, 7520000 ts, 459 rew

agent-1: 9.0
agent-2: 9.0
agent-3: 5.0
agent-4: 14.0
agent-5: 17.0
agent-6: 10.0
agent-7: 15.0
agent-8: 7.0
agent-9: 6.0
agent-10: 10.0
agent-11: 6.0
agent-12: 10.0
agent-13: 13.0
agent-14: 16.0
agent-15: 15.0
agent-16: 14.0
agent-17: 7.0
agent-18: 12.0
agent-19: 13.0
agent-20: 12.0
agent-21: 8.0
agent-22: 12.0
agent-23: 7.0
agent-24: 12.0
agent-25: 9.0
agent-26: 7.0
agent-27: 11.0
agent-28: 15.0
agent-29: 13.0
agent-30: 19.0
agent-31: 10.0
agent-32: 7.0
agent-33: 13.0
agent-34: 7.0
agent-35: 11.0
agent-36: 11.0
agent-37: 10.0
agent-38: 14.0
agent-39: 15.0
agent-40: 8.0
Sum Reward: 439.0
Avg Reward: 10.975
Min Reward: 5.0
Max Reward: 19.0
Gini Coefficient: 0.17465831435079726
20:20 Ratio: 2.423076923076923
Max-min Ratio: 3.8
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-08_04-07-47
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 516.0
  episode_reward_mean: 458.57
  episode_reward_min: 425.0
  episodes_this_iter: 1
  episodes_total: 188
  experiment_id: 4e724eb5b3a34f42879644e84578eec0
  hostname: gpu024
  info:
    apply_time_ms: 3.611
    dispatch_time_ms: 5.693
    learner:
      cur_lr: 0.0008591680089011788
      grad_gnorm: 5.493716716766357
      policy_entropy: 774.2901611328125
      policy_loss: 3.9593327045440674
      var_gnorm: 34.6390266418457
      vf_explained_var: -0.001351475715637207
      vf_loss: 0.004732062574476004
    num_steps_sampled: 7560000
    num_steps_trained: 7560000
    wait_time_ms: 560.941
  iterations_since_restore: 189
  node_ip: 172.17.8.24
  num_metric_batches_dropped: 0
  pid: 26970
  policy_reward_mean: {}
  time_since_restore: 10676.22661447525
  time_this_iter_s: 56.36812400817871
  time_total_s: 10676.22661447525
  timestamp: 1594195667
  timesteps_since_restore: 7560000
  timesteps_this_iter: 40000
  timesteps_total: 7560000
  training_iteration: 189
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26970], 10676 s, 189 iter, 7560000 ts, 459 rew

agent-1: 13.0
agent-2: 12.0
agent-3: 11.0
agent-4: 13.0
agent-5: 7.0
agent-6: 20.0
agent-7: 3.0
agent-8: 12.0
agent-9: 14.0
agent-10: 13.0
agent-11: 16.0
agent-12: 12.0
agent-13: 16.0
agent-14: 9.0
agent-15: 11.0
agent-16: 8.0
agent-17: 12.0
agent-18: 9.0
agent-19: 11.0
agent-20: 23.0
agent-21: 9.0
agent-22: 7.0
agent-23: 5.0
agent-24: 12.0
agent-25: 12.0
agent-26: 11.0
agent-27: 8.0
agent-28: 12.0
agent-29: 2.0
agent-30: 10.0
agent-31: 11.0
agent-32: 20.0
agent-33: 17.0
agent-34: 10.0
agent-35: 5.0
agent-36: 9.0
agent-37: 11.0
agent-38: 10.0
agent-39: 15.0
agent-40: 8.0
Sum Reward: 449.0
Avg Reward: 11.225
Min Reward: 2.0
Max Reward: 23.0
Gini Coefficient: 0.20584632516703785
20:20 Ratio: 3.1333333333333333
Max-min Ratio: 11.5
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-08_04-08-44
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 516.0
  episode_reward_mean: 458.42
  episode_reward_min: 425.0
  episodes_this_iter: 1
  episodes_total: 189
  experiment_id: 4e724eb5b3a34f42879644e84578eec0
  hostname: gpu024
  info:
    apply_time_ms: 2.646
    dispatch_time_ms: 5.702
    learner:
      cur_lr: 0.0008565040188841522
      grad_gnorm: 1.357688307762146
      policy_entropy: 775.8078002929688
      policy_loss: -0.20402729511260986
      var_gnorm: 34.632328033447266
      vf_explained_var: -0.13044989109039307
      vf_loss: 0.00029435628675855696
    num_steps_sampled: 7600000
    num_steps_trained: 7600000
    wait_time_ms: 572.522
  iterations_since_restore: 190
  node_ip: 172.17.8.24
  num_metric_batches_dropped: 0
  pid: 26970
  policy_reward_mean: {}
  time_since_restore: 10732.87489938736
  time_this_iter_s: 56.648284912109375
  time_total_s: 10732.87489938736
  timestamp: 1594195724
  timesteps_since_restore: 7600000
  timesteps_this_iter: 40000
  timesteps_total: 7600000
  training_iteration: 190
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26970], 10732 s, 190 iter, 7600000 ts, 458 rew

agent-1: 3.0
agent-2: 7.0
agent-3: 8.0
agent-4: 5.0
agent-5: 13.0
agent-6: 21.0
agent-7: 17.0
agent-8: 11.0
agent-9: 11.0
agent-10: 11.0
agent-11: 2.0
agent-12: 12.0
agent-13: 13.0
agent-14: 9.0
agent-15: 3.0
agent-16: 11.0
agent-17: 12.0
agent-18: 11.0
agent-19: 7.0
agent-20: 11.0
agent-21: 10.0
agent-22: 12.0
agent-23: 15.0
agent-24: 17.0
agent-25: 5.0
agent-26: 19.0
agent-27: 12.0
agent-28: 11.0
agent-29: 11.0
agent-30: 18.0
agent-31: 12.0
agent-32: 12.0
agent-33: 10.0
agent-34: 11.0
agent-35: 17.0
agent-36: 11.0
agent-37: 9.0
agent-38: 13.0
agent-39: 13.0
agent-40: 5.0
Sum Reward: 441.0
Avg Reward: 11.025
Min Reward: 2.0
Max Reward: 21.0
Gini Coefficient: 0.21082766439909298
20:20 Ratio: 3.7027027027027026
Max-min Ratio: 10.5
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-08_04-09-41
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 516.0
  episode_reward_mean: 458.23
  episode_reward_min: 425.0
  episodes_this_iter: 1
  episodes_total: 190
  experiment_id: 4e724eb5b3a34f42879644e84578eec0
  hostname: gpu024
  info:
    apply_time_ms: 2.669
    dispatch_time_ms: 8.464
    learner:
      cur_lr: 0.0008538400288671255
      grad_gnorm: 3.3976237773895264
      policy_entropy: 773.9219360351562
      policy_loss: 2.7697830200195312
      var_gnorm: 34.731014251708984
      vf_explained_var: -0.049886465072631836
      vf_loss: 0.0018571119289845228
    num_steps_sampled: 7640000
    num_steps_trained: 7640000
    wait_time_ms: 554.197
  iterations_since_restore: 191
  node_ip: 172.17.8.24
  num_metric_batches_dropped: 0
  pid: 26970
  policy_reward_mean: {}
  time_since_restore: 10789.400695323944
  time_this_iter_s: 56.52579593658447
  time_total_s: 10789.400695323944
  timestamp: 1594195781
  timesteps_since_restore: 7640000
  timesteps_this_iter: 40000
  timesteps_total: 7640000
  training_iteration: 191
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26970], 10789 s, 191 iter, 7640000 ts, 458 rew

agent-1: 15.0
agent-2: 12.0
agent-3: 10.0
agent-4: 8.0
agent-5: 5.0
agent-6: 10.0
agent-7: 15.0
agent-8: 18.0
agent-9: 7.0
agent-10: 13.0
agent-11: 11.0
agent-12: 14.0
agent-13: 16.0
agent-14: 17.0
agent-15: 10.0
agent-16: 13.0
agent-17: 18.0
agent-18: 10.0
agent-19: 15.0
agent-20: 4.0
agent-21: 11.0
agent-22: 16.0
agent-23: 9.0
agent-24: 16.0
agent-25: 11.0
agent-26: 20.0
agent-27: 8.0
agent-28: 9.0
agent-29: 16.0
agent-30: 10.0
agent-31: 7.0
agent-32: 8.0
agent-33: 11.0
agent-34: 7.0
agent-35: 9.0
agent-36: 2.0
agent-37: 8.0
agent-38: 8.0
agent-39: 12.0
agent-40: 9.0
Sum Reward: 448.0
Avg Reward: 11.2
Min Reward: 2.0
Max Reward: 20.0
Gini Coefficient: 0.20457589285714287
20:20 Ratio: 2.8541666666666665
Max-min Ratio: 10.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-08_04-10-37
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 516.0
  episode_reward_mean: 457.9
  episode_reward_min: 425.0
  episodes_this_iter: 1
  episodes_total: 191
  experiment_id: 4e724eb5b3a34f42879644e84578eec0
  hostname: gpu024
  info:
    apply_time_ms: 3.141
    dispatch_time_ms: 5.977
    learner:
      cur_lr: 0.0008511759806424379
      grad_gnorm: 2.0293281078338623
      policy_entropy: 775.696044921875
      policy_loss: 0.36243271827697754
      var_gnorm: 34.77632522583008
      vf_explained_var: -4.303455352783203e-05
      vf_loss: 0.0017353103030472994
    num_steps_sampled: 7680000
    num_steps_trained: 7680000
    wait_time_ms: 560.4
  iterations_since_restore: 192
  node_ip: 172.17.8.24
  num_metric_batches_dropped: 0
  pid: 26970
  policy_reward_mean: {}
  time_since_restore: 10845.81268119812
  time_this_iter_s: 56.411985874176025
  time_total_s: 10845.81268119812
  timestamp: 1594195837
  timesteps_since_restore: 7680000
  timesteps_this_iter: 40000
  timesteps_total: 7680000
  training_iteration: 192
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26970], 10845 s, 192 iter, 7680000 ts, 458 rew

agent-1: 9.0
agent-2: 8.0
agent-3: 5.0
agent-4: 9.0
agent-5: 13.0
agent-6: 21.0
agent-7: 17.0
agent-8: 7.0
agent-9: 8.0
agent-10: 14.0
agent-11: 1.0
agent-12: 11.0
agent-13: 10.0
agent-14: 12.0
agent-15: 10.0
agent-16: 22.0
agent-17: 4.0
agent-18: 18.0
agent-19: 14.0
agent-20: 12.0
agent-21: 15.0
agent-22: 12.0
agent-23: 12.0
agent-24: 6.0
agent-25: 21.0
agent-26: 7.0
agent-27: 12.0
agent-28: 1.0
agent-29: 8.0
agent-30: 15.0
agent-31: 19.0
agent-32: 18.0
agent-33: 11.0
agent-34: 14.0
agent-35: 4.0
agent-36: 15.0
agent-37: 5.0
agent-38: 12.0
agent-39: 8.0
agent-40: 20.0
Sum Reward: 460.0
Avg Reward: 11.5
Min Reward: 1.0
Max Reward: 22.0
Gini Coefficient: 0.2647826086956522
20:20 Ratio: 4.7272727272727275
Max-min Ratio: 22.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-08_04-11-33
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 516.0
  episode_reward_mean: 457.53
  episode_reward_min: 425.0
  episodes_this_iter: 1
  episodes_total: 192
  experiment_id: 4e724eb5b3a34f42879644e84578eec0
  hostname: gpu024
  info:
    apply_time_ms: 2.67
    dispatch_time_ms: 6.551
    learner:
      cur_lr: 0.0008485119906254113
      grad_gnorm: 4.466246128082275
      policy_entropy: 768.4644775390625
      policy_loss: -0.9960998892784119
      var_gnorm: 34.818946838378906
      vf_explained_var: -0.8946291208267212
      vf_loss: 0.006335685960948467
    num_steps_sampled: 7720000
    num_steps_trained: 7720000
    wait_time_ms: 555.176
  iterations_since_restore: 193
  node_ip: 172.17.8.24
  num_metric_batches_dropped: 0
  pid: 26970
  policy_reward_mean: {}
  time_since_restore: 10901.836082935333
  time_this_iter_s: 56.023401737213135
  time_total_s: 10901.836082935333
  timestamp: 1594195893
  timesteps_since_restore: 7720000
  timesteps_this_iter: 40000
  timesteps_total: 7720000
  training_iteration: 193
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26970], 10901 s, 193 iter, 7720000 ts, 458 rew

agent-1: 7.0
agent-2: 11.0
agent-3: 12.0
agent-4: 4.0
agent-5: 12.0
agent-6: 4.0
agent-7: 15.0
agent-8: 9.0
agent-9: 12.0
agent-10: 12.0
agent-11: 7.0
agent-12: 10.0
agent-13: 11.0
agent-14: 12.0
agent-15: 12.0
agent-16: 6.0
agent-17: 10.0
agent-18: 8.0
agent-19: 8.0
agent-20: 12.0
agent-21: 8.0
agent-22: 17.0
agent-23: 10.0
agent-24: 15.0
agent-25: 13.0
agent-26: 6.0
agent-27: 17.0
agent-28: 10.0
agent-29: 12.0
agent-30: 13.0
agent-31: 17.0
agent-32: 17.0
agent-33: 14.0
agent-34: 15.0
agent-35: 13.0
agent-36: 10.0
agent-37: 14.0
agent-38: 11.0
agent-39: 16.0
agent-40: 8.0
Sum Reward: 450.0
Avg Reward: 11.25
Min Reward: 4.0
Max Reward: 17.0
Gini Coefficient: 0.17377777777777778
20:20 Ratio: 2.58
Max-min Ratio: 4.25
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-08_04-12-30
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 516.0
  episode_reward_mean: 457.3
  episode_reward_min: 425.0
  episodes_this_iter: 1
  episodes_total: 193
  experiment_id: 4e724eb5b3a34f42879644e84578eec0
  hostname: gpu024
  info:
    apply_time_ms: 2.717
    dispatch_time_ms: 5.977
    learner:
      cur_lr: 0.0008458480006083846
      grad_gnorm: 1.5098384618759155
      policy_entropy: 768.6920166015625
      policy_loss: 1.5578367710113525
      var_gnorm: 34.838844299316406
      vf_explained_var: -0.7116340398788452
      vf_loss: 0.00167562544811517
    num_steps_sampled: 7760000
    num_steps_trained: 7760000
    wait_time_ms: 553.845
  iterations_since_restore: 194
  node_ip: 172.17.8.24
  num_metric_batches_dropped: 0
  pid: 26970
  policy_reward_mean: {}
  time_since_restore: 10958.345981836319
  time_this_iter_s: 56.50989890098572
  time_total_s: 10958.345981836319
  timestamp: 1594195950
  timesteps_since_restore: 7760000
  timesteps_this_iter: 40000
  timesteps_total: 7760000
  training_iteration: 194
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26970], 10958 s, 194 iter, 7760000 ts, 457 rew

agent-1: 20.0
agent-2: 4.0
agent-3: 12.0
agent-4: 8.0
agent-5: 12.0
agent-6: 12.0
agent-7: 12.0
agent-8: 10.0
agent-9: 12.0
agent-10: 12.0
agent-11: 11.0
agent-12: 13.0
agent-13: 16.0
agent-14: 6.0
agent-15: 8.0
agent-16: 13.0
agent-17: 12.0
agent-18: 9.0
agent-19: 14.0
agent-20: 11.0
agent-21: 4.0
agent-22: 13.0
agent-23: 11.0
agent-24: 12.0
agent-25: 12.0
agent-26: 9.0
agent-27: 15.0
agent-28: 9.0
agent-29: 16.0
agent-30: 8.0
agent-31: 14.0
agent-32: 16.0
agent-33: 9.0
agent-34: 14.0
agent-35: 10.0
agent-36: 10.0
agent-37: 14.0
agent-38: 17.0
agent-39: 8.0
agent-40: 15.0
Sum Reward: 463.0
Avg Reward: 11.575
Min Reward: 4.0
Max Reward: 20.0
Gini Coefficient: 0.15988120950323975
20:20 Ratio: 2.3454545454545452
Max-min Ratio: 5.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-08_04-13-26
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 509.0
  episode_reward_mean: 456.77
  episode_reward_min: 425.0
  episodes_this_iter: 1
  episodes_total: 194
  experiment_id: 4e724eb5b3a34f42879644e84578eec0
  hostname: gpu024
  info:
    apply_time_ms: 2.754
    dispatch_time_ms: 5.99
    learner:
      cur_lr: 0.000843184010591358
      grad_gnorm: 1.3537929058074951
      policy_entropy: 773.5894775390625
      policy_loss: -0.9878281950950623
      var_gnorm: 34.960968017578125
      vf_explained_var: -1.0
      vf_loss: 0.00031731504714116454
    num_steps_sampled: 7800000
    num_steps_trained: 7800000
    wait_time_ms: 562.472
  iterations_since_restore: 195
  node_ip: 172.17.8.24
  num_metric_batches_dropped: 0
  pid: 26970
  policy_reward_mean: {}
  time_since_restore: 11015.116734266281
  time_this_iter_s: 56.77075242996216
  time_total_s: 11015.116734266281
  timestamp: 1594196006
  timesteps_since_restore: 7800000
  timesteps_this_iter: 40000
  timesteps_total: 7800000
  training_iteration: 195
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26970], 11015 s, 195 iter, 7800000 ts, 457 rew

agent-1: 14.0
agent-2: 9.0
agent-3: 12.0
agent-4: 16.0
agent-5: 13.0
agent-6: 6.0
agent-7: 17.0
agent-8: 9.0
agent-9: 8.0
agent-10: 9.0
agent-11: 14.0
agent-12: 6.0
agent-13: 11.0
agent-14: 7.0
agent-15: 17.0
agent-16: 6.0
agent-17: 10.0
agent-18: 13.0
agent-19: 15.0
agent-20: 18.0
agent-21: 6.0
agent-22: 9.0
agent-23: 8.0
agent-24: 14.0
agent-25: 19.0
agent-26: 8.0
agent-27: 6.0
agent-28: 15.0
agent-29: 16.0
agent-30: 14.0
agent-31: 16.0
agent-32: 9.0
agent-33: 17.0
agent-34: 13.0
agent-35: 3.0
agent-36: 13.0
agent-37: 15.0
agent-38: 14.0
agent-39: 3.0
agent-40: 13.0
Sum Reward: 461.0
Avg Reward: 11.525
Min Reward: 3.0
Max Reward: 19.0
Gini Coefficient: 0.20894793926247288
20:20 Ratio: 3.1627906976744184
Max-min Ratio: 6.333333333333333
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-08_04-14-23
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 509.0
  episode_reward_mean: 456.79
  episode_reward_min: 425.0
  episodes_this_iter: 1
  episodes_total: 195
  experiment_id: 4e724eb5b3a34f42879644e84578eec0
  hostname: gpu024
  info:
    apply_time_ms: 2.617
    dispatch_time_ms: 7.581
    learner:
      cur_lr: 0.0008405200205743313
      grad_gnorm: 8.042739868164062
      policy_entropy: 760.0562744140625
      policy_loss: -0.7503114342689514
      var_gnorm: 34.94353103637695
      vf_explained_var: -0.7301069498062134
      vf_loss: 0.016861341893672943
    num_steps_sampled: 7840000
    num_steps_trained: 7840000
    wait_time_ms: 556.661
  iterations_since_restore: 196
  node_ip: 172.17.8.24
  num_metric_batches_dropped: 0
  pid: 26970
  policy_reward_mean: {}
  time_since_restore: 11071.275214195251
  time_this_iter_s: 56.15847992897034
  time_total_s: 11071.275214195251
  timestamp: 1594196063
  timesteps_since_restore: 7840000
  timesteps_this_iter: 40000
  timesteps_total: 7840000
  training_iteration: 196
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26970], 11071 s, 196 iter, 7840000 ts, 457 rew

agent-1: 7.0
agent-2: 12.0
agent-3: 11.0
agent-4: 12.0
agent-5: 15.0
agent-6: 16.0
agent-7: 16.0
agent-8: 11.0
agent-9: 14.0
agent-10: 10.0
agent-11: 8.0
agent-12: 13.0
agent-13: 7.0
agent-14: 9.0
agent-15: 12.0
agent-16: 16.0
agent-17: 9.0
agent-18: 11.0
agent-19: 8.0
agent-20: 16.0
agent-21: 14.0
agent-22: 17.0
agent-23: 3.0
agent-24: 12.0
agent-25: 7.0
agent-26: 13.0
agent-27: 11.0
agent-28: 14.0
agent-29: 20.0
agent-30: 12.0
agent-31: 4.0
agent-32: 19.0
agent-33: 11.0
agent-34: 6.0
agent-35: 13.0
agent-36: 11.0
agent-37: 7.0
agent-38: 13.0
agent-39: 9.0
agent-40: 6.0
Sum Reward: 455.0
Avg Reward: 11.375
Min Reward: 3.0
Max Reward: 20.0
Gini Coefficient: 0.1917032967032967
20:20 Ratio: 2.872340425531915
Max-min Ratio: 6.666666666666667
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-08_04-15-19
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 509.0
  episode_reward_mean: 456.79
  episode_reward_min: 425.0
  episodes_this_iter: 1
  episodes_total: 196
  experiment_id: 4e724eb5b3a34f42879644e84578eec0
  hostname: gpu024
  info:
    apply_time_ms: 2.939
    dispatch_time_ms: 7.919
    learner:
      cur_lr: 0.0008378559723496437
      grad_gnorm: 2.9727981090545654
      policy_entropy: 751.6945190429688
      policy_loss: 1.6308269500732422
      var_gnorm: 35.01342010498047
      vf_explained_var: -1.0
      vf_loss: 0.007826728746294975
    num_steps_sampled: 7880000
    num_steps_trained: 7880000
    wait_time_ms: 555.436
  iterations_since_restore: 197
  node_ip: 172.17.8.24
  num_metric_batches_dropped: 0
  pid: 26970
  policy_reward_mean: {}
  time_since_restore: 11127.777758836746
  time_this_iter_s: 56.50254464149475
  time_total_s: 11127.777758836746
  timestamp: 1594196119
  timesteps_since_restore: 7880000
  timesteps_this_iter: 40000
  timesteps_total: 7880000
  training_iteration: 197
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26970], 11127 s, 197 iter, 7880000 ts, 457 rew

agent-1: 11.0
agent-2: 7.0
agent-3: 13.0
agent-4: 13.0
agent-5: 10.0
agent-6: 9.0
agent-7: 9.0
agent-8: 16.0
agent-9: 13.0
agent-10: 13.0
agent-11: 7.0
agent-12: 10.0
agent-13: 14.0
agent-14: 15.0
agent-15: 12.0
agent-16: 12.0
agent-17: 15.0
agent-18: 11.0
agent-19: 10.0
agent-20: 11.0
agent-21: 5.0
agent-22: 11.0
agent-23: 5.0
agent-24: 9.0
agent-25: 8.0
agent-26: 11.0
agent-27: 14.0
agent-28: 12.0
agent-29: 15.0
agent-30: 11.0
agent-31: 6.0
agent-32: 9.0
agent-33: 13.0
agent-34: 16.0
agent-35: 17.0
agent-36: 9.0
agent-37: 18.0
agent-38: 9.0
agent-39: 8.0
agent-40: 10.0
Sum Reward: 447.0
Avg Reward: 11.175
Min Reward: 5.0
Max Reward: 18.0
Gini Coefficient: 0.1598993288590604
20:20 Ratio: 2.290909090909091
Max-min Ratio: 3.6
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-08_04-16-16
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 509.0
  episode_reward_mean: 456.53
  episode_reward_min: 425.0
  episodes_this_iter: 1
  episodes_total: 197
  experiment_id: 4e724eb5b3a34f42879644e84578eec0
  hostname: gpu024
  info:
    apply_time_ms: 2.423
    dispatch_time_ms: 6.625
    learner:
      cur_lr: 0.000835191982332617
      grad_gnorm: 3.473759651184082
      policy_entropy: 765.982666015625
      policy_loss: -2.4548165798187256
      var_gnorm: 35.02003860473633
      vf_explained_var: -1.0
      vf_loss: 0.002534650731831789
    num_steps_sampled: 7920000
    num_steps_trained: 7920000
    wait_time_ms: 567.029
  iterations_since_restore: 198
  node_ip: 172.17.8.24
  num_metric_batches_dropped: 0
  pid: 26970
  policy_reward_mean: {}
  time_since_restore: 11184.38311958313
  time_this_iter_s: 56.60536074638367
  time_total_s: 11184.38311958313
  timestamp: 1594196176
  timesteps_since_restore: 7920000
  timesteps_this_iter: 40000
  timesteps_total: 7920000
  training_iteration: 198
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26970], 11184 s, 198 iter, 7920000 ts, 457 rew

agent-1: 7.0
agent-2: 10.0
agent-3: 9.0
agent-4: 14.0
agent-5: 11.0
agent-6: 12.0
agent-7: 11.0
agent-8: 13.0
agent-9: 13.0
agent-10: 10.0
agent-11: 11.0
agent-12: 21.0
agent-13: 10.0
agent-14: 10.0
agent-15: 15.0
agent-16: 11.0
agent-17: 8.0
agent-18: 16.0
agent-19: 7.0
agent-20: 10.0
agent-21: 11.0
agent-22: 8.0
agent-23: 11.0
agent-24: 9.0
agent-25: 10.0
agent-26: 14.0
agent-27: 13.0
agent-28: 10.0
agent-29: 8.0
agent-30: 8.0
agent-31: 13.0
agent-32: 15.0
agent-33: 9.0
agent-34: 5.0
agent-35: 11.0
agent-36: 4.0
agent-37: 15.0
agent-38: 11.0
agent-39: 11.0
agent-40: 8.0
Sum Reward: 433.0
Avg Reward: 10.825
Min Reward: 4.0
Max Reward: 21.0
Gini Coefficient: 0.15479214780600462
20:20 Ratio: 2.2363636363636363
Max-min Ratio: 5.25
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-08_04-17-12
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 509.0
  episode_reward_mean: 455.94
  episode_reward_min: 425.0
  episodes_this_iter: 1
  episodes_total: 198
  experiment_id: 4e724eb5b3a34f42879644e84578eec0
  hostname: gpu024
  info:
    apply_time_ms: 2.687
    dispatch_time_ms: 6.45
    learner:
      cur_lr: 0.0008325279923155904
      grad_gnorm: 2.1983108520507812
      policy_entropy: 761.3828735351562
      policy_loss: 0.9662927389144897
      var_gnorm: 35.06203842163086
      vf_explained_var: -1.0
      vf_loss: 0.0018388477619737387
    num_steps_sampled: 7960000
    num_steps_trained: 7960000
    wait_time_ms: 555.087
  iterations_since_restore: 199
  node_ip: 172.17.8.24
  num_metric_batches_dropped: 0
  pid: 26970
  policy_reward_mean: {}
  time_since_restore: 11241.05303478241
  time_this_iter_s: 56.669915199279785
  time_total_s: 11241.05303478241
  timestamp: 1594196232
  timesteps_since_restore: 7960000
  timesteps_this_iter: 40000
  timesteps_total: 7960000
  training_iteration: 199
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26970], 11241 s, 199 iter, 7960000 ts, 456 rew

agent-1: 16.0
agent-2: 3.0
agent-3: 11.0
agent-4: 16.0
agent-5: 13.0
agent-6: 13.0
agent-7: 12.0
agent-8: 11.0
agent-9: 8.0
agent-10: 14.0
agent-11: 14.0
agent-12: 4.0
agent-13: 13.0
agent-14: 10.0
agent-15: 12.0
agent-16: 12.0
agent-17: 9.0
agent-18: 11.0
agent-19: 9.0
agent-20: 14.0
agent-21: 7.0
agent-22: 9.0
agent-23: 10.0
agent-24: 6.0
agent-25: 20.0
agent-26: 8.0
agent-27: 18.0
agent-28: 9.0
agent-29: 13.0
agent-30: 14.0
agent-31: 9.0
agent-32: 8.0
agent-33: 8.0
agent-34: 12.0
agent-35: 3.0
agent-36: 14.0
agent-37: 13.0
agent-38: 15.0
agent-39: 9.0
agent-40: 16.0
Sum Reward: 446.0
Avg Reward: 11.15
Min Reward: 3.0
Max Reward: 20.0
Gini Coefficient: 0.1891255605381166
20:20 Ratio: 2.74468085106383
Max-min Ratio: 6.666666666666667
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-08_04-18-09
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 509.0
  episode_reward_mean: 455.64
  episode_reward_min: 425.0
  episodes_this_iter: 1
  episodes_total: 199
  experiment_id: 4e724eb5b3a34f42879644e84578eec0
  hostname: gpu024
  info:
    apply_time_ms: 3.035
    dispatch_time_ms: 6.599
    learner:
      cur_lr: 0.0008298640022985637
      grad_gnorm: 2.7359557151794434
      policy_entropy: 773.38525390625
      policy_loss: -1.0695934295654297
      var_gnorm: 35.08352279663086
      vf_explained_var: -0.38284504413604736
      vf_loss: 0.0033216297160834074
    num_steps_sampled: 8000000
    num_steps_trained: 8000000
    wait_time_ms: 553.136
  iterations_since_restore: 200
  node_ip: 172.17.8.24
  num_metric_batches_dropped: 0
  pid: 26970
  policy_reward_mean: {}
  time_since_restore: 11297.509669303894
  time_this_iter_s: 56.456634521484375
  time_total_s: 11297.509669303894
  timestamp: 1594196289
  timesteps_since_restore: 8000000
  timesteps_this_iter: 40000
  timesteps_total: 8000000
  training_iteration: 200
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26970], 11297 s, 200 iter, 8000000 ts, 456 rew

agent-1: 23.0
agent-2: 15.0
agent-3: 10.0
agent-4: 10.0
agent-5: 13.0
agent-6: 18.0
agent-7: 7.0
agent-8: 6.0
agent-9: 16.0
agent-10: 11.0
agent-11: 9.0
agent-12: 17.0
agent-13: 13.0
agent-14: 11.0
agent-15: 13.0
agent-16: 11.0
agent-17: 9.0
agent-18: 12.0
agent-19: 8.0
agent-20: 10.0
agent-21: 12.0
agent-22: 11.0
agent-23: 13.0
agent-24: 12.0
agent-25: 12.0
agent-26: 7.0
agent-27: 17.0
agent-28: 10.0
agent-29: 18.0
agent-30: 10.0
agent-31: 7.0
agent-32: 11.0
agent-33: 3.0
agent-34: 15.0
agent-35: 11.0
agent-36: 11.0
agent-37: 12.0
agent-38: 11.0
agent-39: 13.0
agent-40: 9.0
Sum Reward: 467.0
Avg Reward: 11.675
Min Reward: 3.0
Max Reward: 23.0
Gini Coefficient: 0.16911134903640257
20:20 Ratio: 2.482142857142857
Max-min Ratio: 7.666666666666667
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-08_04-19-05
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 509.0
  episode_reward_mean: 455.65
  episode_reward_min: 425.0
  episodes_this_iter: 1
  episodes_total: 200
  experiment_id: 4e724eb5b3a34f42879644e84578eec0
  hostname: gpu024
  info:
    apply_time_ms: 2.569
    dispatch_time_ms: 8.766
    learner:
      cur_lr: 0.0008272000122815371
      grad_gnorm: 1.1463959217071533
      policy_entropy: 765.9696044921875
      policy_loss: 1.418006420135498
      var_gnorm: 35.20286560058594
      vf_explained_var: -1.0
      vf_loss: 0.00047459639608860016
    num_steps_sampled: 8040000
    num_steps_trained: 8040000
    wait_time_ms: 558.001
  iterations_since_restore: 201
  node_ip: 172.17.8.24
  num_metric_batches_dropped: 0
  pid: 26970
  policy_reward_mean: {}
  time_since_restore: 11353.745511293411
  time_this_iter_s: 56.23584198951721
  time_total_s: 11353.745511293411
  timestamp: 1594196345
  timesteps_since_restore: 8040000
  timesteps_this_iter: 40000
  timesteps_total: 8040000
  training_iteration: 201
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26970], 11353 s, 201 iter, 8040000 ts, 456 rew

agent-1: 15.0
agent-2: 3.0
agent-3: 15.0
agent-4: 7.0
agent-5: 8.0
agent-6: 9.0
agent-7: 15.0
agent-8: 5.0
agent-9: 9.0
agent-10: 12.0
agent-11: 13.0
agent-12: 11.0
agent-13: 20.0
agent-14: 16.0
agent-15: 3.0
agent-16: 15.0
agent-17: 15.0
agent-18: 14.0
agent-19: 7.0
agent-20: 7.0
agent-21: 11.0
agent-22: 12.0
agent-23: 12.0
agent-24: 11.0
agent-25: 11.0
agent-26: 8.0
agent-27: 12.0
agent-28: 15.0
agent-29: 11.0
agent-30: 11.0
agent-31: 10.0
agent-32: 12.0
agent-33: 8.0
agent-34: 11.0
agent-35: 12.0
agent-36: 7.0
agent-37: 7.0
agent-38: 13.0
agent-39: 13.0
agent-40: 14.0
Sum Reward: 440.0
Avg Reward: 11.0
Min Reward: 3.0
Max Reward: 20.0
Gini Coefficient: 0.1819318181818182
20:20 Ratio: 2.739130434782609
Max-min Ratio: 6.666666666666667
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-08_04-20-02
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 509.0
  episode_reward_mean: 455.25
  episode_reward_min: 425.0
  episodes_this_iter: 1
  episodes_total: 201
  experiment_id: 4e724eb5b3a34f42879644e84578eec0
  hostname: gpu024
  info:
    apply_time_ms: 2.417
    dispatch_time_ms: 6.647
    learner:
      cur_lr: 0.0008245360222645104
      grad_gnorm: 1.1609879732131958
      policy_entropy: 739.445556640625
      policy_loss: 2.4354536533355713
      var_gnorm: 35.17678451538086
      vf_explained_var: -1.0
      vf_loss: 0.009409947320818901
    num_steps_sampled: 8080000
    num_steps_trained: 8080000
    wait_time_ms: 546.521
  iterations_since_restore: 202
  node_ip: 172.17.8.24
  num_metric_batches_dropped: 0
  pid: 26970
  policy_reward_mean: {}
  time_since_restore: 11410.439576625824
  time_this_iter_s: 56.69406533241272
  time_total_s: 11410.439576625824
  timestamp: 1594196402
  timesteps_since_restore: 8080000
  timesteps_this_iter: 40000
  timesteps_total: 8080000
  training_iteration: 202
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26970], 11410 s, 202 iter, 8080000 ts, 455 rew

agent-1: 14.0
agent-2: 10.0
agent-3: 14.0
agent-4: 9.0
agent-5: 13.0
agent-6: 11.0
agent-7: 12.0
agent-8: 15.0
agent-9: 7.0
agent-10: 13.0
agent-11: 11.0
agent-12: 10.0
agent-13: 18.0
agent-14: 9.0
agent-15: 10.0
agent-16: 8.0
agent-17: 11.0
agent-18: 13.0
agent-19: 11.0
agent-20: 5.0
agent-21: 17.0
agent-22: 10.0
agent-23: 7.0
agent-24: 9.0
agent-25: 9.0
agent-26: 15.0
agent-27: 10.0
agent-28: 11.0
agent-29: 7.0
agent-30: 12.0
agent-31: 12.0
agent-32: 11.0
agent-33: 6.0
agent-34: 16.0
agent-35: 12.0
agent-36: 8.0
agent-37: 9.0
agent-38: 13.0
agent-39: 11.0
agent-40: 16.0
Sum Reward: 445.0
Avg Reward: 11.125
Min Reward: 5.0
Max Reward: 18.0
Gini Coefficient: 0.15095505617977528
20:20 Ratio: 2.192982456140351
Max-min Ratio: 3.6
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-08_04-20-58
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 509.0
  episode_reward_mean: 455.03
  episode_reward_min: 425.0
  episodes_this_iter: 1
  episodes_total: 202
  experiment_id: 4e724eb5b3a34f42879644e84578eec0
  hostname: gpu024
  info:
    apply_time_ms: 2.834
    dispatch_time_ms: 6.898
    learner:
      cur_lr: 0.0008218719740398228
      grad_gnorm: 5.936995506286621
      policy_entropy: 721.7129516601562
      policy_loss: 1.586934208869934
      var_gnorm: 35.29636764526367
      vf_explained_var: -0.2118210792541504
      vf_loss: 0.006212675478309393
    num_steps_sampled: 8120000
    num_steps_trained: 8120000
    wait_time_ms: 555.2
  iterations_since_restore: 203
  node_ip: 172.17.8.24
  num_metric_batches_dropped: 0
  pid: 26970
  policy_reward_mean: {}
  time_since_restore: 11466.80559539795
  time_this_iter_s: 56.366018772125244
  time_total_s: 11466.80559539795
  timestamp: 1594196458
  timesteps_since_restore: 8120000
  timesteps_this_iter: 40000
  timesteps_total: 8120000
  training_iteration: 203
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26970], 11466 s, 203 iter, 8120000 ts, 455 rew

agent-1: 7.0
agent-2: 8.0
agent-3: 20.0
agent-4: 7.0
agent-5: 13.0
agent-6: 8.0
agent-7: 10.0
agent-8: 12.0
agent-9: 13.0
agent-10: 16.0
agent-11: 13.0
agent-12: 10.0
agent-13: 12.0
agent-14: 9.0
agent-15: 10.0
agent-16: 10.0
agent-17: 13.0
agent-18: 12.0
agent-19: 4.0
agent-20: 10.0
agent-21: 14.0
agent-22: 13.0
agent-23: 15.0
agent-24: 5.0
agent-25: 12.0
agent-26: 13.0
agent-27: 15.0
agent-28: 7.0
agent-29: 10.0
agent-30: 12.0
agent-31: 8.0
agent-32: 14.0
agent-33: 16.0
agent-34: 9.0
agent-35: 6.0
agent-36: 4.0
agent-37: 12.0
agent-38: 11.0
agent-39: 13.0
agent-40: 11.0
Sum Reward: 437.0
Avg Reward: 10.925
Min Reward: 4.0
Max Reward: 20.0
Gini Coefficient: 0.17339816933638444
20:20 Ratio: 2.5625
Max-min Ratio: 5.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-08_04-21-55
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 509.0
  episode_reward_mean: 454.78
  episode_reward_min: 425.0
  episodes_this_iter: 1
  episodes_total: 203
  experiment_id: 4e724eb5b3a34f42879644e84578eec0
  hostname: gpu024
  info:
    apply_time_ms: 2.417
    dispatch_time_ms: 5.367
    learner:
      cur_lr: 0.0008192079840227962
      grad_gnorm: 2.887916326522827
      policy_entropy: 766.0496215820312
      policy_loss: -1.2790333032608032
      var_gnorm: 35.338539123535156
      vf_explained_var: -0.6402002573013306
      vf_loss: 0.0018850970081984997
    num_steps_sampled: 8160000
    num_steps_trained: 8160000
    wait_time_ms: 551.466
  iterations_since_restore: 204
  node_ip: 172.17.8.24
  num_metric_batches_dropped: 0
  pid: 26970
  policy_reward_mean: {}
  time_since_restore: 11523.659863471985
  time_this_iter_s: 56.854268074035645
  time_total_s: 11523.659863471985
  timestamp: 1594196515
  timesteps_since_restore: 8160000
  timesteps_this_iter: 40000
  timesteps_total: 8160000
  training_iteration: 204
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26970], 11523 s, 204 iter, 8160000 ts, 455 rew

agent-1: 8.0
agent-2: 7.0
agent-3: 13.0
agent-4: 8.0
agent-5: 13.0
agent-6: 10.0
agent-7: 8.0
agent-8: 17.0
agent-9: 15.0
agent-10: 11.0
agent-11: 10.0
agent-12: 15.0
agent-13: 14.0
agent-14: 12.0
agent-15: 9.0
agent-16: 14.0
agent-17: 12.0
agent-18: 9.0
agent-19: 10.0
agent-20: 14.0
agent-21: 12.0
agent-22: 2.0
agent-23: 8.0
agent-24: 14.0
agent-25: 12.0
agent-26: 14.0
agent-27: 6.0
agent-28: 15.0
agent-29: 7.0
agent-30: 10.0
agent-31: 11.0
agent-32: 16.0
agent-33: 16.0
agent-34: 15.0
agent-35: 6.0
agent-36: 2.0
agent-37: 15.0
agent-38: 14.0
agent-39: 8.0
agent-40: 11.0
Sum Reward: 443.0
Avg Reward: 11.075
Min Reward: 2.0
Max Reward: 17.0
Gini Coefficient: 0.18436794582392776
20:20 Ratio: 2.6956521739130435
Max-min Ratio: 8.5
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-08_04-22-52
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 509.0
  episode_reward_mean: 454.6
  episode_reward_min: 425.0
  episodes_this_iter: 1
  episodes_total: 204
  experiment_id: 4e724eb5b3a34f42879644e84578eec0
  hostname: gpu024
  info:
    apply_time_ms: 3.066
    dispatch_time_ms: 6.97
    learner:
      cur_lr: 0.0008165439940057695
      grad_gnorm: 0.4905278980731964
      policy_entropy: 767.1407470703125
      policy_loss: 0.17025400698184967
      var_gnorm: 35.443389892578125
      vf_explained_var: -0.32976293563842773
      vf_loss: 0.0005983843002468348
    num_steps_sampled: 8200000
    num_steps_trained: 8200000
    wait_time_ms: 570.254
  iterations_since_restore: 205
  node_ip: 172.17.8.24
  num_metric_batches_dropped: 0
  pid: 26970
  policy_reward_mean: {}
  time_since_restore: 11580.471385240555
  time_this_iter_s: 56.811521768569946
  time_total_s: 11580.471385240555
  timestamp: 1594196572
  timesteps_since_restore: 8200000
  timesteps_this_iter: 40000
  timesteps_total: 8200000
  training_iteration: 205
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26970], 11580 s, 205 iter, 8200000 ts, 455 rew

agent-1: 14.0
agent-2: 18.0
agent-3: 5.0
agent-4: 6.0
agent-5: 13.0
agent-6: 8.0
agent-7: 14.0
agent-8: 13.0
agent-9: 13.0
agent-10: 11.0
agent-11: 12.0
agent-12: 10.0
agent-13: 11.0
agent-14: 6.0
agent-15: 12.0
agent-16: 4.0
agent-17: 16.0
agent-18: 11.0
agent-19: 11.0
agent-20: 11.0
agent-21: 14.0
agent-22: 10.0
agent-23: 12.0
agent-24: 5.0
agent-25: 13.0
agent-26: 8.0
agent-27: 7.0
agent-28: 12.0
agent-29: 6.0
agent-30: 12.0
agent-31: 7.0
agent-32: 12.0
agent-33: 21.0
agent-34: 14.0
agent-35: 12.0
agent-36: 15.0
agent-37: 12.0
agent-38: 9.0
agent-39: 10.0
agent-40: 11.0
Sum Reward: 441.0
Avg Reward: 11.025
Min Reward: 4.0
Max Reward: 21.0
Gini Coefficient: 0.1762471655328798
20:20 Ratio: 2.739130434782609
Max-min Ratio: 5.25
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-08_04-23-48
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 509.0
  episode_reward_mean: 454.45
  episode_reward_min: 425.0
  episodes_this_iter: 1
  episodes_total: 205
  experiment_id: 4e724eb5b3a34f42879644e84578eec0
  hostname: gpu024
  info:
    apply_time_ms: 3.143
    dispatch_time_ms: 5.726
    learner:
      cur_lr: 0.0008138800039887428
      grad_gnorm: 7.765757083892822
      policy_entropy: 736.24853515625
      policy_loss: -1.91634202003479
      var_gnorm: 35.49592971801758
      vf_explained_var: -0.005354762077331543
      vf_loss: 0.06284703314304352
    num_steps_sampled: 8240000
    num_steps_trained: 8240000
    wait_time_ms: 556.024
  iterations_since_restore: 206
  node_ip: 172.17.8.24
  num_metric_batches_dropped: 0
  pid: 26970
  policy_reward_mean: {}
  time_since_restore: 11636.691181659698
  time_this_iter_s: 56.21979641914368
  time_total_s: 11636.691181659698
  timestamp: 1594196628
  timesteps_since_restore: 8240000
  timesteps_this_iter: 40000
  timesteps_total: 8240000
  training_iteration: 206
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26970], 11636 s, 206 iter, 8240000 ts, 454 rew

agent-1: 8.0
agent-2: 4.0
agent-3: 12.0
agent-4: 6.0
agent-5: 14.0
agent-6: 8.0
agent-7: 7.0
agent-8: 15.0
agent-9: 12.0
agent-10: 15.0
agent-11: 10.0
agent-12: 13.0
agent-13: 9.0
agent-14: 13.0
agent-15: 14.0
agent-16: 14.0
agent-17: 9.0
agent-18: 5.0
agent-19: 13.0
agent-20: 18.0
agent-21: 9.0
agent-22: 8.0
agent-23: 13.0
agent-24: 8.0
agent-25: 12.0
agent-26: 9.0
agent-27: 9.0
agent-28: 11.0
agent-29: 17.0
agent-30: 9.0
agent-31: 12.0
agent-32: 13.0
agent-33: 18.0
agent-34: 18.0
agent-35: 5.0
agent-36: 13.0
agent-37: 14.0
agent-38: 8.0
agent-39: 12.0
agent-40: 9.0
Sum Reward: 446.0
Avg Reward: 11.15
Min Reward: 4.0
Max Reward: 18.0
Gini Coefficient: 0.18172645739910315
20:20 Ratio: 2.5294117647058822
Max-min Ratio: 4.5
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-08_04-24-45
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 509.0
  episode_reward_mean: 454.21
  episode_reward_min: 425.0
  episodes_this_iter: 1
  episodes_total: 206
  experiment_id: 4e724eb5b3a34f42879644e84578eec0
  hostname: gpu024
  info:
    apply_time_ms: 3.0
    dispatch_time_ms: 6.065
    learner:
      cur_lr: 0.0008112160139717162
      grad_gnorm: 2.2717511653900146
      policy_entropy: 756.9746704101562
      policy_loss: -4.110386848449707
      var_gnorm: 35.52182388305664
      vf_explained_var: -0.915347695350647
      vf_loss: 0.0002549175114836544
    num_steps_sampled: 8280000
    num_steps_trained: 8280000
    wait_time_ms: 541.792
  iterations_since_restore: 207
  node_ip: 172.17.8.24
  num_metric_batches_dropped: 0
  pid: 26970
  policy_reward_mean: {}
  time_since_restore: 11692.942240953445
  time_this_iter_s: 56.25105929374695
  time_total_s: 11692.942240953445
  timestamp: 1594196685
  timesteps_since_restore: 8280000
  timesteps_this_iter: 40000
  timesteps_total: 8280000
  training_iteration: 207
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26970], 11692 s, 207 iter, 8280000 ts, 454 rew

agent-1: 9.0
agent-2: 9.0
agent-3: 12.0
agent-4: 13.0
agent-5: 15.0
agent-6: 7.0
agent-7: 10.0
agent-8: 10.0
agent-9: 10.0
agent-10: 11.0
agent-11: 9.0
agent-12: 10.0
agent-13: 13.0
agent-14: 12.0
agent-15: 6.0
agent-16: 10.0
agent-17: 14.0
agent-18: 7.0
agent-19: 11.0
agent-20: 11.0
agent-21: 11.0
agent-22: 8.0
agent-23: 13.0
agent-24: 12.0
agent-25: 15.0
agent-26: 9.0
agent-27: 13.0
agent-28: 13.0
agent-29: 8.0
agent-30: 15.0
agent-31: 15.0
agent-32: 16.0
agent-33: 9.0
agent-34: 16.0
agent-35: 15.0
agent-36: 10.0
agent-37: 16.0
agent-38: 8.0
agent-39: 13.0
agent-40: 10.0
Sum Reward: 454.0
Avg Reward: 11.35
Min Reward: 6.0
Max Reward: 16.0
Gini Coefficient: 0.1368942731277533
20:20 Ratio: 1.9838709677419355
Max-min Ratio: 2.6666666666666665
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-08_04-25-42
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 509.0
  episode_reward_mean: 454.21
  episode_reward_min: 425.0
  episodes_this_iter: 1
  episodes_total: 207
  experiment_id: 4e724eb5b3a34f42879644e84578eec0
  hostname: gpu024
  info:
    apply_time_ms: 2.48
    dispatch_time_ms: 5.963
    learner:
      cur_lr: 0.0008085520239546895
      grad_gnorm: 2.083007574081421
      policy_entropy: 763.44580078125
      policy_loss: -1.3105852603912354
      var_gnorm: 35.51817321777344
      vf_explained_var: -0.34836459159851074
      vf_loss: 0.0011259084567427635
    num_steps_sampled: 8320000
    num_steps_trained: 8320000
    wait_time_ms: 540.997
  iterations_since_restore: 208
  node_ip: 172.17.8.24
  num_metric_batches_dropped: 0
  pid: 26970
  policy_reward_mean: {}
  time_since_restore: 11749.779809951782
  time_this_iter_s: 56.83756899833679
  time_total_s: 11749.779809951782
  timestamp: 1594196742
  timesteps_since_restore: 8320000
  timesteps_this_iter: 40000
  timesteps_total: 8320000
  training_iteration: 208
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26970], 11749 s, 208 iter, 8320000 ts, 454 rew

agent-1: 10.0
agent-2: 11.0
agent-3: 13.0
agent-4: 11.0
agent-5: 8.0
agent-6: 8.0
agent-7: 18.0
agent-8: 15.0
agent-9: 12.0
agent-10: 10.0
agent-11: 4.0
agent-12: 15.0
agent-13: 10.0
agent-14: 8.0
agent-15: 7.0
agent-16: 14.0
agent-17: 10.0
agent-18: 13.0
agent-19: 5.0
agent-20: 13.0
agent-21: 11.0
agent-22: 11.0
agent-23: 9.0
agent-24: 8.0
agent-25: 13.0
agent-26: 13.0
agent-27: 19.0
agent-28: 19.0
agent-29: 9.0
agent-30: 10.0
agent-31: 8.0
agent-32: 18.0
agent-33: 12.0
agent-34: 7.0
agent-35: 10.0
agent-36: 12.0
agent-37: 16.0
agent-38: 14.0
agent-39: 4.0
agent-40: 7.0
Sum Reward: 445.0
Avg Reward: 11.125
Min Reward: 4.0
Max Reward: 19.0
Gini Coefficient: 0.1896067415730337
20:20 Ratio: 2.68
Max-min Ratio: 4.75
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-08_04-26-38
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 509.0
  episode_reward_mean: 453.89
  episode_reward_min: 425.0
  episodes_this_iter: 1
  episodes_total: 208
  experiment_id: 4e724eb5b3a34f42879644e84578eec0
  hostname: gpu024
  info:
    apply_time_ms: 2.884
    dispatch_time_ms: 5.938
    learner:
      cur_lr: 0.0008058879757300019
      grad_gnorm: 2.926042318344116
      policy_entropy: 765.3770751953125
      policy_loss: -3.221580982208252
      var_gnorm: 35.650596618652344
      vf_explained_var: -0.42664599418640137
      vf_loss: 0.0015420938143506646
    num_steps_sampled: 8360000
    num_steps_trained: 8360000
    wait_time_ms: 564.592
  iterations_since_restore: 209
  node_ip: 172.17.8.24
  num_metric_batches_dropped: 0
  pid: 26970
  policy_reward_mean: {}
  time_since_restore: 11806.553166627884
  time_this_iter_s: 56.773356676101685
  time_total_s: 11806.553166627884
  timestamp: 1594196798
  timesteps_since_restore: 8360000
  timesteps_this_iter: 40000
  timesteps_total: 8360000
  training_iteration: 209
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26970], 11806 s, 209 iter, 8360000 ts, 454 rew

agent-1: 5.0
agent-2: 7.0
agent-3: 13.0
agent-4: 10.0
agent-5: 5.0
agent-6: 12.0
agent-7: 11.0
agent-8: 8.0
agent-9: 20.0
agent-10: 11.0
agent-11: 12.0
agent-12: 12.0
agent-13: 8.0
agent-14: 11.0
agent-15: 15.0
agent-16: 13.0
agent-17: 9.0
agent-18: 11.0
agent-19: 9.0
agent-20: 12.0
agent-21: 7.0
agent-22: 16.0
agent-23: 10.0
agent-24: 9.0
agent-25: 9.0
agent-26: 10.0
agent-27: 8.0
agent-28: 18.0
agent-29: 21.0
agent-30: 9.0
agent-31: 11.0
agent-32: 10.0
agent-33: 16.0
agent-34: 10.0
agent-35: 7.0
agent-36: 14.0
agent-37: 12.0
agent-38: 10.0
agent-39: 9.0
agent-40: 9.0
Sum Reward: 439.0
Avg Reward: 10.975
Min Reward: 5.0
Max Reward: 21.0
Gini Coefficient: 0.1721526195899772
20:20 Ratio: 2.418181818181818
Max-min Ratio: 4.2
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-08_04-27-35
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 509.0
  episode_reward_mean: 453.77
  episode_reward_min: 425.0
  episodes_this_iter: 1
  episodes_total: 209
  experiment_id: 4e724eb5b3a34f42879644e84578eec0
  hostname: gpu024
  info:
    apply_time_ms: 2.966
    dispatch_time_ms: 9.075
    learner:
      cur_lr: 0.0008032239857129753
      grad_gnorm: 2.322239875793457
      policy_entropy: 770.41064453125
      policy_loss: -4.453749656677246
      var_gnorm: 35.66341018676758
      vf_explained_var: -0.6636892557144165
      vf_loss: 0.0007756238337606192
    num_steps_sampled: 8400000
    num_steps_trained: 8400000
    wait_time_ms: 539.55
  iterations_since_restore: 210
  node_ip: 172.17.8.24
  num_metric_batches_dropped: 0
  pid: 26970
  policy_reward_mean: {}
  time_since_restore: 11862.79082775116
  time_this_iter_s: 56.23766112327576
  time_total_s: 11862.79082775116
  timestamp: 1594196855
  timesteps_since_restore: 8400000
  timesteps_this_iter: 40000
  timesteps_total: 8400000
  training_iteration: 210
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26970], 11862 s, 210 iter, 8400000 ts, 454 rew

agent-1: 13.0
agent-2: 10.0
agent-3: 12.0
agent-4: 7.0
agent-5: 11.0
agent-6: 13.0
agent-7: 13.0
agent-8: 10.0
agent-9: 9.0
agent-10: 8.0
agent-11: 18.0
agent-12: 16.0
agent-13: 16.0
agent-14: 18.0
agent-15: 6.0
agent-16: 20.0
agent-17: 13.0
agent-18: 12.0
agent-19: 15.0
agent-20: 6.0
agent-21: 12.0
agent-22: 10.0
agent-23: 16.0
agent-24: 13.0
agent-25: 7.0
agent-26: 8.0
agent-27: 9.0
agent-28: 13.0
agent-29: 13.0
agent-30: 11.0
agent-31: 9.0
agent-32: 6.0
agent-33: 7.0
agent-34: 13.0
agent-35: 10.0
agent-36: 1.0
agent-37: 20.0
agent-38: 15.0
agent-39: 8.0
agent-40: 12.0
Sum Reward: 459.0
Avg Reward: 11.475
Min Reward: 1.0
Max Reward: 20.0
Gini Coefficient: 0.19776688453159041
20:20 Ratio: 2.8958333333333335
Max-min Ratio: 20.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-08_04-28-31
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 497.0
  episode_reward_mean: 453.27
  episode_reward_min: 425.0
  episodes_this_iter: 1
  episodes_total: 210
  experiment_id: 4e724eb5b3a34f42879644e84578eec0
  hostname: gpu024
  info:
    apply_time_ms: 2.538
    dispatch_time_ms: 5.923
    learner:
      cur_lr: 0.0008005599956959486
      grad_gnorm: 2.0070557594299316
      policy_entropy: 771.4901123046875
      policy_loss: -1.1890321969985962
      var_gnorm: 35.71958923339844
      vf_explained_var: -0.3643876314163208
      vf_loss: 0.0013786604395136237
    num_steps_sampled: 8440000
    num_steps_trained: 8440000
    wait_time_ms: 557.016
  iterations_since_restore: 211
  node_ip: 172.17.8.24
  num_metric_batches_dropped: 0
  pid: 26970
  policy_reward_mean: {}
  time_since_restore: 11919.368183612823
  time_this_iter_s: 56.57735586166382
  time_total_s: 11919.368183612823
  timestamp: 1594196911
  timesteps_since_restore: 8440000
  timesteps_this_iter: 40000
  timesteps_total: 8440000
  training_iteration: 211
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26970], 11919 s, 211 iter, 8440000 ts, 453 rew

agent-1: 9.0
agent-2: 11.0
agent-3: 9.0
agent-4: 10.0
agent-5: 12.0
agent-6: 14.0
agent-7: 9.0
agent-8: 10.0
agent-9: 15.0
agent-10: 16.0
agent-11: 14.0
agent-12: 11.0
agent-13: 8.0
agent-14: 12.0
agent-15: 9.0
agent-16: 12.0
agent-17: 8.0
agent-18: 13.0
agent-19: 10.0
agent-20: 13.0
agent-21: 9.0
agent-22: 9.0
agent-23: 11.0
agent-24: 13.0
agent-25: 10.0
agent-26: 7.0
agent-27: 13.0
agent-28: 20.0
agent-29: 12.0
agent-30: 10.0
agent-31: 8.0
agent-32: 11.0
agent-33: 11.0
agent-34: 13.0
agent-35: 7.0
agent-36: 11.0
agent-37: 10.0
agent-38: 6.0
agent-39: 14.0
agent-40: 9.0
Sum Reward: 439.0
Avg Reward: 10.975
Min Reward: 6.0
Max Reward: 20.0
Gini Coefficient: 0.13354214123006833
20:20 Ratio: 1.9193548387096775
Max-min Ratio: 3.3333333333333335
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-08_04-29-28
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 497.0
  episode_reward_mean: 453.13
  episode_reward_min: 425.0
  episodes_this_iter: 1
  episodes_total: 211
  experiment_id: 4e724eb5b3a34f42879644e84578eec0
  hostname: gpu024
  info:
    apply_time_ms: 2.445
    dispatch_time_ms: 6.913
    learner:
      cur_lr: 0.0007978960056789219
      grad_gnorm: 1.3871097564697266
      policy_entropy: 768.9483642578125
      policy_loss: -1.1809219121932983
      var_gnorm: 35.76268005371094
      vf_explained_var: -1.0
      vf_loss: 0.007179585285484791
    num_steps_sampled: 8480000
    num_steps_trained: 8480000
    wait_time_ms: 566.107
  iterations_since_restore: 212
  node_ip: 172.17.8.24
  num_metric_batches_dropped: 0
  pid: 26970
  policy_reward_mean: {}
  time_since_restore: 11976.248488426208
  time_this_iter_s: 56.88030481338501
  time_total_s: 11976.248488426208
  timestamp: 1594196968
  timesteps_since_restore: 8480000
  timesteps_this_iter: 40000
  timesteps_total: 8480000
  training_iteration: 212
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26970], 11976 s, 212 iter, 8480000 ts, 453 rew

agent-1: 11.0
agent-2: 17.0
agent-3: 2.0
agent-4: 8.0
agent-5: 14.0
agent-6: 10.0
agent-7: 11.0
agent-8: 9.0
agent-9: 8.0
agent-10: 13.0
agent-11: 7.0
agent-12: 8.0
agent-13: 15.0
agent-14: 15.0
agent-15: 12.0
agent-16: 7.0
agent-17: 13.0
agent-18: 10.0
agent-19: 7.0
agent-20: 6.0
agent-21: 15.0
agent-22: 13.0
agent-23: 20.0
agent-24: 10.0
agent-25: 12.0
agent-26: 15.0
agent-27: 10.0
agent-28: 16.0
agent-29: 12.0
agent-30: 7.0
agent-31: 14.0
agent-32: 14.0
agent-33: 10.0
agent-34: 11.0
agent-35: 15.0
agent-36: 16.0
agent-37: 14.0
agent-38: 11.0
agent-39: 7.0
agent-40: 5.0
Sum Reward: 450.0
Avg Reward: 11.25
Min Reward: 2.0
Max Reward: 20.0
Gini Coefficient: 0.18644444444444444
20:20 Ratio: 2.6875
Max-min Ratio: 10.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-08_04-30-25
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 497.0
  episode_reward_mean: 453.09
  episode_reward_min: 425.0
  episodes_this_iter: 1
  episodes_total: 212
  experiment_id: 4e724eb5b3a34f42879644e84578eec0
  hostname: gpu024
  info:
    apply_time_ms: 2.564
    dispatch_time_ms: 6.508
    learner:
      cur_lr: 0.0007952320156618953
      grad_gnorm: 0.8424333333969116
      policy_entropy: 770.8299560546875
      policy_loss: -0.39056551456451416
      var_gnorm: 35.87444305419922
      vf_explained_var: -1.0
      vf_loss: 0.0011468390002846718
    num_steps_sampled: 8520000
    num_steps_trained: 8520000
    wait_time_ms: 547.935
  iterations_since_restore: 213
  node_ip: 172.17.8.24
  num_metric_batches_dropped: 0
  pid: 26970
  policy_reward_mean: {}
  time_since_restore: 12032.76693868637
  time_this_iter_s: 56.51845026016235
  time_total_s: 12032.76693868637
  timestamp: 1594197025
  timesteps_since_restore: 8520000
  timesteps_this_iter: 40000
  timesteps_total: 8520000
  training_iteration: 213
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26970], 12032 s, 213 iter, 8520000 ts, 453 rew

agent-1: 12.0
agent-2: 7.0
agent-3: 8.0
agent-4: 7.0
agent-5: 8.0
agent-6: 10.0
agent-7: 8.0
agent-8: 11.0
agent-9: 16.0
agent-10: 11.0
agent-11: 8.0
agent-12: 17.0
agent-13: 12.0
agent-14: 10.0
agent-15: 18.0
agent-16: 14.0
agent-17: 8.0
agent-18: 11.0
agent-19: 11.0
agent-20: 9.0
agent-21: 13.0
agent-22: 11.0
agent-23: 12.0
agent-24: 9.0
agent-25: 6.0
agent-26: 12.0
agent-27: 7.0
agent-28: 7.0
agent-29: 6.0
agent-30: 18.0
agent-31: 18.0
agent-32: 10.0
agent-33: 12.0
agent-34: 15.0
agent-35: 15.0
agent-36: 12.0
agent-37: 11.0
agent-38: 11.0
agent-39: 17.0
agent-40: 11.0
Sum Reward: 449.0
Avg Reward: 11.225
Min Reward: 6.0
Max Reward: 18.0
Gini Coefficient: 0.16943207126948776
20:20 Ratio: 2.392857142857143
Max-min Ratio: 3.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-08_04-31-21
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 497.0
  episode_reward_mean: 452.72
  episode_reward_min: 425.0
  episodes_this_iter: 1
  episodes_total: 213
  experiment_id: 4e724eb5b3a34f42879644e84578eec0
  hostname: gpu024
  info:
    apply_time_ms: 2.452
    dispatch_time_ms: 6.134
    learner:
      cur_lr: 0.0007925680256448686
      grad_gnorm: 4.10493278503418
      policy_entropy: 752.734375
      policy_loss: -2.9432036876678467
      var_gnorm: 35.88096237182617
      vf_explained_var: -0.03425753116607666
      vf_loss: 0.0025642558466643095
    num_steps_sampled: 8560000
    num_steps_trained: 8560000
    wait_time_ms: 564.998
  iterations_since_restore: 214
  node_ip: 172.17.8.24
  num_metric_batches_dropped: 0
  pid: 26970
  policy_reward_mean: {}
  time_since_restore: 12088.828624725342
  time_this_iter_s: 56.06168603897095
  time_total_s: 12088.828624725342
  timestamp: 1594197081
  timesteps_since_restore: 8560000
  timesteps_this_iter: 40000
  timesteps_total: 8560000
  training_iteration: 214
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26970], 12088 s, 214 iter, 8560000 ts, 453 rew

agent-1: 10.0
agent-2: 9.0
agent-3: 19.0
agent-4: 11.0
agent-5: 11.0
agent-6: 22.0
agent-7: 15.0
agent-8: 12.0
agent-9: 10.0
agent-10: 14.0
agent-11: 17.0
agent-12: 14.0
agent-13: 12.0
agent-14: 10.0
agent-15: 17.0
agent-16: 9.0
agent-17: 5.0
agent-18: 14.0
agent-19: 9.0
agent-20: 11.0
agent-21: 11.0
agent-22: 8.0
agent-23: 8.0
agent-24: 13.0
agent-25: 10.0
agent-26: 8.0
agent-27: 11.0
agent-28: 15.0
agent-29: 12.0
agent-30: 16.0
agent-31: 6.0
agent-32: 15.0
agent-33: 12.0
agent-34: 12.0
agent-35: 21.0
agent-36: 8.0
agent-37: 4.0
agent-38: 14.0
agent-39: 15.0
agent-40: 14.0
Sum Reward: 484.0
Avg Reward: 12.1
Min Reward: 4.0
Max Reward: 22.0
Gini Coefficient: 0.17985537190082646
20:20 Ratio: 2.5357142857142856
Max-min Ratio: 5.5
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-08_04-32-18
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 497.0
  episode_reward_mean: 452.96
  episode_reward_min: 425.0
  episodes_this_iter: 1
  episodes_total: 214
  experiment_id: 4e724eb5b3a34f42879644e84578eec0
  hostname: gpu024
  info:
    apply_time_ms: 3.434
    dispatch_time_ms: 5.534
    learner:
      cur_lr: 0.000789903977420181
      grad_gnorm: 4.957557678222656
      policy_entropy: 754.119140625
      policy_loss: -3.6188929080963135
      var_gnorm: 35.94688034057617
      vf_explained_var: -0.0316699743270874
      vf_loss: 0.003604510333389044
    num_steps_sampled: 8600000
    num_steps_trained: 8600000
    wait_time_ms: 559.397
  iterations_since_restore: 215
  node_ip: 172.17.8.24
  num_metric_batches_dropped: 0
  pid: 26970
  policy_reward_mean: {}
  time_since_restore: 12145.62939786911
  time_this_iter_s: 56.80077314376831
  time_total_s: 12145.62939786911
  timestamp: 1594197138
  timesteps_since_restore: 8600000
  timesteps_this_iter: 40000
  timesteps_total: 8600000
  training_iteration: 215
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26970], 12145 s, 215 iter, 8600000 ts, 453 rew

agent-1: 12.0
agent-2: 12.0
agent-3: 16.0
agent-4: 9.0
agent-5: 9.0
agent-6: 7.0
agent-7: 15.0
agent-8: 10.0
agent-9: 11.0
agent-10: 17.0
agent-11: 10.0
agent-12: 10.0
agent-13: 14.0
agent-14: 8.0
agent-15: 11.0
agent-16: 6.0
agent-17: 8.0
agent-18: 13.0
agent-19: 15.0
agent-20: 13.0
agent-21: 13.0
agent-22: 8.0
agent-23: 8.0
agent-24: 12.0
agent-25: 9.0
agent-26: 8.0
agent-27: 8.0
agent-28: 12.0
agent-29: 14.0
agent-30: 12.0
agent-31: 15.0
agent-32: 7.0
agent-33: 2.0
agent-34: 18.0
agent-35: 13.0
agent-36: 8.0
agent-37: 11.0
agent-38: 14.0
agent-39: 11.0
agent-40: 12.0
Sum Reward: 441.0
Avg Reward: 11.025
Min Reward: 2.0
Max Reward: 18.0
Gini Coefficient: 0.1649092970521542
20:20 Ratio: 2.2962962962962963
Max-min Ratio: 9.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-08_04-33-14
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 497.0
  episode_reward_mean: 452.78
  episode_reward_min: 425.0
  episodes_this_iter: 1
  episodes_total: 215
  experiment_id: 4e724eb5b3a34f42879644e84578eec0
  hostname: gpu024
  info:
    apply_time_ms: 3.108
    dispatch_time_ms: 5.176
    learner:
      cur_lr: 0.0007872399874031544
      grad_gnorm: 2.0889666080474854
      policy_entropy: 758.7459716796875
      policy_loss: -0.17340755462646484
      var_gnorm: 35.976890563964844
      vf_explained_var: -1.0
      vf_loss: 0.001609924016520381
    num_steps_sampled: 8640000
    num_steps_trained: 8640000
    wait_time_ms: 552.125
  iterations_since_restore: 216
  node_ip: 172.17.8.24
  num_metric_batches_dropped: 0
  pid: 26970
  policy_reward_mean: {}
  time_since_restore: 12202.348853349686
  time_this_iter_s: 56.71945548057556
  time_total_s: 12202.348853349686
  timestamp: 1594197194
  timesteps_since_restore: 8640000
  timesteps_this_iter: 40000
  timesteps_total: 8640000
  training_iteration: 216
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26970], 12202 s, 216 iter, 8640000 ts, 453 rew

agent-1: 16.0
agent-2: 14.0
agent-3: 12.0
agent-4: 7.0
agent-5: 11.0
agent-6: 15.0
agent-7: 19.0
agent-8: 15.0
agent-9: 9.0
agent-10: 10.0
agent-11: 17.0
agent-12: 12.0
agent-13: 12.0
agent-14: 12.0
agent-15: 7.0
agent-16: 6.0
agent-17: 17.0
agent-18: 9.0
agent-19: 13.0
agent-20: 11.0
agent-21: 11.0
agent-22: 11.0
agent-23: 16.0
agent-24: 12.0
agent-25: 10.0
agent-26: 11.0
agent-27: 16.0
agent-28: 7.0
agent-29: 12.0
agent-30: 9.0
agent-31: 9.0
agent-32: 1.0
agent-33: 10.0
agent-34: 16.0
agent-35: 5.0
agent-36: 4.0
agent-37: 12.0
agent-38: 11.0
agent-39: 14.0
agent-40: 10.0
Sum Reward: 451.0
Avg Reward: 11.275
Min Reward: 1.0
Max Reward: 19.0
Gini Coefficient: 0.18608647450110866
20:20 Ratio: 2.869565217391304
Max-min Ratio: 19.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-08_04-34-11
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 497.0
  episode_reward_mean: 452.33
  episode_reward_min: 425.0
  episodes_this_iter: 1
  episodes_total: 216
  experiment_id: 4e724eb5b3a34f42879644e84578eec0
  hostname: gpu024
  info:
    apply_time_ms: 2.562
    dispatch_time_ms: 6.345
    learner:
      cur_lr: 0.0007845759973861277
      grad_gnorm: 3.2480242252349854
      policy_entropy: 767.5590209960938
      policy_loss: -1.6947426795959473
      var_gnorm: 36.00335693359375
      vf_explained_var: -0.5656914710998535
      vf_loss: 0.0017807036638259888
    num_steps_sampled: 8680000
    num_steps_trained: 8680000
    wait_time_ms: 559.141
  iterations_since_restore: 217
  node_ip: 172.17.8.24
  num_metric_batches_dropped: 0
  pid: 26970
  policy_reward_mean: {}
  time_since_restore: 12258.70665192604
  time_this_iter_s: 56.35779857635498
  time_total_s: 12258.70665192604
  timestamp: 1594197251
  timesteps_since_restore: 8680000
  timesteps_this_iter: 40000
  timesteps_total: 8680000
  training_iteration: 217
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26970], 12258 s, 217 iter, 8680000 ts, 452 rew

agent-1: 13.0
agent-2: 20.0
agent-3: 15.0
agent-4: 7.0
agent-5: 9.0
agent-6: 8.0
agent-7: 9.0
agent-8: 16.0
agent-9: 12.0
agent-10: 6.0
agent-11: 16.0
agent-12: 8.0
agent-13: 7.0
agent-14: 12.0
agent-15: 11.0
agent-16: 10.0
agent-17: 11.0
agent-18: 20.0
agent-19: 10.0
agent-20: 13.0
agent-21: 11.0
agent-22: 2.0
agent-23: 12.0
agent-24: 10.0
agent-25: 9.0
agent-26: 12.0
agent-27: 9.0
agent-28: 8.0
agent-29: 7.0
agent-30: 10.0
agent-31: 8.0
agent-32: 17.0
agent-33: 12.0
agent-34: 14.0
agent-35: 14.0
agent-36: 9.0
agent-37: 11.0
agent-38: 15.0
agent-39: 9.0
agent-40: 14.0
Sum Reward: 446.0
Avg Reward: 11.15
Min Reward: 2.0
Max Reward: 20.0
Gini Coefficient: 0.18116591928251122
20:20 Ratio: 2.509433962264151
Max-min Ratio: 10.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-08_04-35-07
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 497.0
  episode_reward_mean: 452.22
  episode_reward_min: 425.0
  episodes_this_iter: 1
  episodes_total: 217
  experiment_id: 4e724eb5b3a34f42879644e84578eec0
  hostname: gpu024
  info:
    apply_time_ms: 2.831
    dispatch_time_ms: 5.418
    learner:
      cur_lr: 0.000781912007369101
      grad_gnorm: 1.245619297027588
      policy_entropy: 763.098876953125
      policy_loss: 0.06891325116157532
      var_gnorm: 36.067970275878906
      vf_explained_var: -0.22704339027404785
      vf_loss: 0.00022059553884901106
    num_steps_sampled: 8720000
    num_steps_trained: 8720000
    wait_time_ms: 554.907
  iterations_since_restore: 218
  node_ip: 172.17.8.24
  num_metric_batches_dropped: 0
  pid: 26970
  policy_reward_mean: {}
  time_since_restore: 12315.00234079361
  time_this_iter_s: 56.29568886756897
  time_total_s: 12315.00234079361
  timestamp: 1594197307
  timesteps_since_restore: 8720000
  timesteps_this_iter: 40000
  timesteps_total: 8720000
  training_iteration: 218
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26970], 12315 s, 218 iter, 8720000 ts, 452 rew

agent-1: 13.0
agent-2: 10.0
agent-3: 12.0
agent-4: 19.0
agent-5: 13.0
agent-6: 12.0
agent-7: 13.0
agent-8: 15.0
agent-9: 9.0
agent-10: 12.0
agent-11: 11.0
agent-12: 8.0
agent-13: 9.0
agent-14: 3.0
agent-15: 10.0
agent-16: 21.0
agent-17: 14.0
agent-18: 11.0
agent-19: 10.0
agent-20: 10.0
agent-21: 7.0
agent-22: 18.0
agent-23: 12.0
agent-24: 11.0
agent-25: 15.0
agent-26: 10.0
agent-27: 11.0
agent-28: 16.0
agent-29: 16.0
agent-30: 12.0
agent-31: 11.0
agent-32: 6.0
agent-33: 6.0
agent-34: 11.0
agent-35: 10.0
agent-36: 9.0
agent-37: 12.0
agent-38: 5.0
agent-39: 22.0
agent-40: 7.0
Sum Reward: 462.0
Avg Reward: 11.55
Min Reward: 3.0
Max Reward: 22.0
Gini Coefficient: 0.1882034632034632
20:20 Ratio: 2.784313725490196
Max-min Ratio: 7.333333333333333
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-08_04-36-04
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 497.0
  episode_reward_mean: 452.37
  episode_reward_min: 425.0
  episodes_this_iter: 1
  episodes_total: 218
  experiment_id: 4e724eb5b3a34f42879644e84578eec0
  hostname: gpu024
  info:
    apply_time_ms: 2.517
    dispatch_time_ms: 5.865
    learner:
      cur_lr: 0.0007792480173520744
      grad_gnorm: 1.049358606338501
      policy_entropy: 772.9368896484375
      policy_loss: 0.822471559047699
      var_gnorm: 36.12033462524414
      vf_explained_var: -0.9845243692398071
      vf_loss: 0.00016705844609532505
    num_steps_sampled: 8760000
    num_steps_trained: 8760000
    wait_time_ms: 541.869
  iterations_since_restore: 219
  node_ip: 172.17.8.24
  num_metric_batches_dropped: 0
  pid: 26970
  policy_reward_mean: {}
  time_since_restore: 12371.53509092331
  time_this_iter_s: 56.53275012969971
  time_total_s: 12371.53509092331
  timestamp: 1594197364
  timesteps_since_restore: 8760000
  timesteps_this_iter: 40000
  timesteps_total: 8760000
  training_iteration: 219
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26970], 12371 s, 219 iter, 8760000 ts, 452 rew

agent-1: 12.0
agent-2: 9.0
agent-3: 12.0
agent-4: 11.0
agent-5: 10.0
agent-6: 13.0
agent-7: 13.0
agent-8: 11.0
agent-9: 15.0
agent-10: 7.0
agent-11: 3.0
agent-12: 10.0
agent-13: 11.0
agent-14: 10.0
agent-15: 13.0
agent-16: 27.0
agent-17: 8.0
agent-18: 9.0
agent-19: 5.0
agent-20: 12.0
agent-21: 13.0
agent-22: 19.0
agent-23: 15.0
agent-24: 10.0
agent-25: 9.0
agent-26: 17.0
agent-27: 4.0
agent-28: 5.0
agent-29: 14.0
agent-30: 12.0
agent-31: 10.0
agent-32: 12.0
agent-33: 9.0
agent-34: 5.0
agent-35: 9.0
agent-36: 13.0
agent-37: 8.0
agent-38: 9.0
agent-39: 19.0
agent-40: 17.0
Sum Reward: 450.0
Avg Reward: 11.25
Min Reward: 3.0
Max Reward: 27.0
Gini Coefficient: 0.21144444444444443
20:20 Ratio: 3.1777777777777776
Max-min Ratio: 9.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-08_04-37-00
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 497.0
  episode_reward_mean: 452.2
  episode_reward_min: 425.0
  episodes_this_iter: 1
  episodes_total: 219
  experiment_id: 4e724eb5b3a34f42879644e84578eec0
  hostname: gpu024
  info:
    apply_time_ms: 3.516
    dispatch_time_ms: 6.968
    learner:
      cur_lr: 0.0007765840273350477
      grad_gnorm: 6.082189083099365
      policy_entropy: 763.7235107421875
      policy_loss: -3.621354103088379
      var_gnorm: 36.18211364746094
      vf_explained_var: -1.0
      vf_loss: 0.15598870813846588
    num_steps_sampled: 8800000
    num_steps_trained: 8800000
    wait_time_ms: 560.893
  iterations_since_restore: 220
  node_ip: 172.17.8.24
  num_metric_batches_dropped: 0
  pid: 26970
  policy_reward_mean: {}
  time_since_restore: 12428.090303182602
  time_this_iter_s: 56.5552122592926
  time_total_s: 12428.090303182602
  timestamp: 1594197420
  timesteps_since_restore: 8800000
  timesteps_this_iter: 40000
  timesteps_total: 8800000
  training_iteration: 220
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26970], 12428 s, 220 iter, 8800000 ts, 452 rew

agent-1: 12.0
agent-2: 1.0
agent-3: 14.0
agent-4: 11.0
agent-5: 15.0
agent-6: 15.0
agent-7: 7.0
agent-8: 14.0
agent-9: 16.0
agent-10: 16.0
agent-11: 16.0
agent-12: 10.0
agent-13: 16.0
agent-14: 10.0
agent-15: 10.0
agent-16: 11.0
agent-17: 9.0
agent-18: 9.0
agent-19: 12.0
agent-20: 4.0
agent-21: 6.0
agent-22: 9.0
agent-23: 8.0
agent-24: 2.0
agent-25: 7.0
agent-26: 15.0
agent-27: 18.0
agent-28: 17.0
agent-29: 8.0
agent-30: 13.0
agent-31: 11.0
agent-32: 10.0
agent-33: 17.0
agent-34: 14.0
agent-35: 10.0
agent-36: 8.0
agent-37: 14.0
agent-38: 15.0
agent-39: 13.0
agent-40: 11.0
Sum Reward: 454.0
Avg Reward: 11.35
Min Reward: 1.0
Max Reward: 18.0
Gini Coefficient: 0.2
20:20 Ratio: 3.046511627906977
Max-min Ratio: 18.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-08_04-37-57
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 497.0
  episode_reward_mean: 452.18
  episode_reward_min: 425.0
  episodes_this_iter: 1
  episodes_total: 220
  experiment_id: 4e724eb5b3a34f42879644e84578eec0
  hostname: gpu024
  info:
    apply_time_ms: 2.659
    dispatch_time_ms: 6.461
    learner:
      cur_lr: 0.0007739199791103601
      grad_gnorm: 1.478724479675293
      policy_entropy: 767.6737060546875
      policy_loss: -1.236995816230774
      var_gnorm: 36.215545654296875
      vf_explained_var: -0.5543439388275146
      vf_loss: 0.0014206224586814642
    num_steps_sampled: 8840000
    num_steps_trained: 8840000
    wait_time_ms: 560.11
  iterations_since_restore: 221
  node_ip: 172.17.8.24
  num_metric_batches_dropped: 0
  pid: 26970
  policy_reward_mean: {}
  time_since_restore: 12484.375805139542
  time_this_iter_s: 56.2855019569397
  time_total_s: 12484.375805139542
  timestamp: 1594197477
  timesteps_since_restore: 8840000
  timesteps_this_iter: 40000
  timesteps_total: 8840000
  training_iteration: 221
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26970], 12484 s, 221 iter, 8840000 ts, 452 rew

agent-1: 5.0
agent-2: 11.0
agent-3: 8.0
agent-4: 10.0
agent-5: 10.0
agent-6: 7.0
agent-7: 15.0
agent-8: 6.0
agent-9: 10.0
agent-10: 6.0
agent-11: 13.0
agent-12: 11.0
agent-13: 12.0
agent-14: 10.0
agent-15: 11.0
agent-16: 12.0
agent-17: 11.0
agent-18: 16.0
agent-19: 7.0
agent-20: 10.0
agent-21: 11.0
agent-22: 12.0
agent-23: 11.0
agent-24: 17.0
agent-25: 15.0
agent-26: 14.0
agent-27: 16.0
agent-28: 16.0
agent-29: 9.0
agent-30: 15.0
agent-31: 9.0
agent-32: 7.0
agent-33: 12.0
agent-34: 13.0
agent-35: 10.0
agent-36: 18.0
agent-37: 15.0
agent-38: 10.0
agent-39: 7.0
agent-40: 10.0
Sum Reward: 448.0
Avg Reward: 11.2
Min Reward: 5.0
Max Reward: 18.0
Gini Coefficient: 0.1630580357142857
20:20 Ratio: 2.4150943396226414
Max-min Ratio: 3.6
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-08_04-38-54
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 497.0
  episode_reward_mean: 452.14
  episode_reward_min: 425.0
  episodes_this_iter: 1
  episodes_total: 221
  experiment_id: 4e724eb5b3a34f42879644e84578eec0
  hostname: gpu024
  info:
    apply_time_ms: 2.722
    dispatch_time_ms: 5.808
    learner:
      cur_lr: 0.0007712559890933335
      grad_gnorm: 1.7925326824188232
      policy_entropy: 774.37646484375
      policy_loss: 1.279477596282959
      var_gnorm: 36.22917938232422
      vf_explained_var: -0.14426708221435547
      vf_loss: 0.0004362321924418211
    num_steps_sampled: 8880000
    num_steps_trained: 8880000
    wait_time_ms: 557.662
  iterations_since_restore: 222
  node_ip: 172.17.8.24
  num_metric_batches_dropped: 0
  pid: 26970
  policy_reward_mean: {}
  time_since_restore: 12541.445905685425
  time_this_iter_s: 57.07010054588318
  time_total_s: 12541.445905685425
  timestamp: 1594197534
  timesteps_since_restore: 8880000
  timesteps_this_iter: 40000
  timesteps_total: 8880000
  training_iteration: 222
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26970], 12541 s, 222 iter, 8880000 ts, 452 rew

agent-1: 15.0
agent-2: 7.0
agent-3: 13.0
agent-4: 7.0
agent-5: 13.0
agent-6: 7.0
agent-7: 11.0
agent-8: 11.0
agent-9: 12.0
agent-10: 10.0
agent-11: 16.0
agent-12: 10.0
agent-13: 8.0
agent-14: 14.0
agent-15: 7.0
agent-16: 15.0
agent-17: 12.0
agent-18: 9.0
agent-19: 10.0
agent-20: 10.0
agent-21: 6.0
agent-22: 15.0
agent-23: 10.0
agent-24: 4.0
agent-25: 11.0
agent-26: 15.0
agent-27: 8.0
agent-28: 10.0
agent-29: 14.0
agent-30: 14.0
agent-31: 10.0
agent-32: 12.0
agent-33: 5.0
agent-34: 11.0
agent-35: 7.0
agent-36: 12.0
agent-37: 12.0
agent-38: 16.0
agent-39: 8.0
agent-40: 10.0
Sum Reward: 427.0
Avg Reward: 10.675
Min Reward: 4.0
Max Reward: 16.0
Gini Coefficient: 0.16387587822014052
20:20 Ratio: 2.4
Max-min Ratio: 4.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-08_04-39-50
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 497.0
  episode_reward_mean: 451.72
  episode_reward_min: 425.0
  episodes_this_iter: 1
  episodes_total: 222
  experiment_id: 4e724eb5b3a34f42879644e84578eec0
  hostname: gpu024
  info:
    apply_time_ms: 2.503
    dispatch_time_ms: 5.564
    learner:
      cur_lr: 0.0007685919990763068
      grad_gnorm: 3.6347711086273193
      policy_entropy: 770.1160888671875
      policy_loss: 0.9624978303909302
      var_gnorm: 36.25701904296875
      vf_explained_var: -1.0
      vf_loss: 0.0142579460516572
    num_steps_sampled: 8920000
    num_steps_trained: 8920000
    wait_time_ms: 553.908
  iterations_since_restore: 223
  node_ip: 172.17.8.24
  num_metric_batches_dropped: 0
  pid: 26970
  policy_reward_mean: {}
  time_since_restore: 12597.735856056213
  time_this_iter_s: 56.289950370788574
  time_total_s: 12597.735856056213
  timestamp: 1594197590
  timesteps_since_restore: 8920000
  timesteps_this_iter: 40000
  timesteps_total: 8920000
  training_iteration: 223
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26970], 12597 s, 223 iter, 8920000 ts, 452 rew

agent-1: 12.0
agent-2: 11.0
agent-3: 13.0
agent-4: 16.0
agent-5: 17.0
agent-6: 5.0
agent-7: 4.0
agent-8: 6.0
agent-9: 13.0
agent-10: 6.0
agent-11: 12.0
agent-12: 12.0
agent-13: 14.0
agent-14: 6.0
agent-15: 8.0
agent-16: 11.0
agent-17: 14.0
agent-18: 12.0
agent-19: 6.0
agent-20: 15.0
agent-21: 4.0
agent-22: 14.0
agent-23: 10.0
agent-24: 7.0
agent-25: 13.0
agent-26: 8.0
agent-27: 10.0
agent-28: 8.0
agent-29: 20.0
agent-30: 13.0
agent-31: 8.0
agent-32: 10.0
agent-33: 8.0
agent-34: 19.0
agent-35: 10.0
agent-36: 11.0
agent-37: 14.0
agent-38: 11.0
agent-39: 13.0
agent-40: 10.0
Sum Reward: 434.0
Avg Reward: 10.85
Min Reward: 4.0
Max Reward: 20.0
Gini Coefficient: 0.1976958525345622
20:20 Ratio: 2.9318181818181817
Max-min Ratio: 5.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-08_04-40-46
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 497.0
  episode_reward_mean: 451.36
  episode_reward_min: 425.0
  episodes_this_iter: 1
  episodes_total: 223
  experiment_id: 4e724eb5b3a34f42879644e84578eec0
  hostname: gpu024
  info:
    apply_time_ms: 4.184
    dispatch_time_ms: 6.304
    learner:
      cur_lr: 0.0007659280090592802
      grad_gnorm: 2.470698118209839
      policy_entropy: 763.1788330078125
      policy_loss: -0.47351711988449097
      var_gnorm: 36.3288459777832
      vf_explained_var: -0.2775975465774536
      vf_loss: 0.0059127770364284515
    num_steps_sampled: 8960000
    num_steps_trained: 8960000
    wait_time_ms: 553.247
  iterations_since_restore: 224
  node_ip: 172.17.8.24
  num_metric_batches_dropped: 0
  pid: 26970
  policy_reward_mean: {}
  time_since_restore: 12654.158896684647
  time_this_iter_s: 56.42304062843323
  time_total_s: 12654.158896684647
  timestamp: 1594197646
  timesteps_since_restore: 8960000
  timesteps_this_iter: 40000
  timesteps_total: 8960000
  training_iteration: 224
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26970], 12654 s, 224 iter, 8960000 ts, 451 rew

agent-1: 18.0
agent-2: 9.0
agent-3: 16.0
agent-4: 9.0
agent-5: 6.0
agent-6: 10.0
agent-7: 9.0
agent-8: 8.0
agent-9: 7.0
agent-10: 12.0
agent-11: 10.0
agent-12: 11.0
agent-13: 13.0
agent-14: 18.0
agent-15: 14.0
agent-16: 9.0
agent-17: 9.0
agent-18: 11.0
agent-19: 12.0
agent-20: 15.0
agent-21: 13.0
agent-22: 9.0
agent-23: 14.0
agent-24: 9.0
agent-25: 20.0
agent-26: 8.0
agent-27: 10.0
agent-28: 11.0
agent-29: 8.0
agent-30: 2.0
agent-31: 12.0
agent-32: 17.0
agent-33: 12.0
agent-34: 10.0
agent-35: 14.0
agent-36: 13.0
agent-37: 15.0
agent-38: 7.0
agent-39: 14.0
agent-40: 8.0
Sum Reward: 452.0
Avg Reward: 11.3
Min Reward: 2.0
Max Reward: 20.0
Gini Coefficient: 0.17831858407079645
20:20 Ratio: 2.462962962962963
Max-min Ratio: 10.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-08_04-41-43
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 491.0
  episode_reward_mean: 450.91
  episode_reward_min: 425.0
  episodes_this_iter: 1
  episodes_total: 224
  experiment_id: 4e724eb5b3a34f42879644e84578eec0
  hostname: gpu024
  info:
    apply_time_ms: 2.421
    dispatch_time_ms: 6.018
    learner:
      cur_lr: 0.0007632640190422535
      grad_gnorm: 3.0779287815093994
      policy_entropy: 771.2825927734375
      policy_loss: -2.3769257068634033
      var_gnorm: 36.353981018066406
      vf_explained_var: -0.3910212516784668
      vf_loss: 0.001670044381171465
    num_steps_sampled: 9000000
    num_steps_trained: 9000000
    wait_time_ms: 563.137
  iterations_since_restore: 225
  node_ip: 172.17.8.24
  num_metric_batches_dropped: 0
  pid: 26970
  policy_reward_mean: {}
  time_since_restore: 12710.832866191864
  time_this_iter_s: 56.67396950721741
  time_total_s: 12710.832866191864
  timestamp: 1594197703
  timesteps_since_restore: 9000000
  timesteps_this_iter: 40000
  timesteps_total: 9000000
  training_iteration: 225
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26970], 12710 s, 225 iter, 9000000 ts, 451 rew

agent-1: 17.0
agent-2: 9.0
agent-3: 12.0
agent-4: 11.0
agent-5: 8.0
agent-6: 12.0
agent-7: 10.0
agent-8: 10.0
agent-9: 14.0
agent-10: 9.0
agent-11: 18.0
agent-12: 10.0
agent-13: 11.0
agent-14: 12.0
agent-15: 12.0
agent-16: 11.0
agent-17: 3.0
agent-18: 10.0
agent-19: 10.0
agent-20: 9.0
agent-21: 8.0
agent-22: 11.0
agent-23: 10.0
agent-24: 6.0
agent-25: 8.0
agent-26: 8.0
agent-27: 10.0
agent-28: 12.0
agent-29: 16.0
agent-30: 11.0
agent-31: 7.0
agent-32: 17.0
agent-33: 16.0
agent-34: 26.0
agent-35: 8.0
agent-36: 8.0
agent-37: 8.0
agent-38: 16.0
agent-39: 20.0
agent-40: 10.0
Sum Reward: 454.0
Avg Reward: 11.35
Min Reward: 3.0
Max Reward: 26.0
Gini Coefficient: 0.1905286343612335
20:20 Ratio: 2.607142857142857
Max-min Ratio: 8.666666666666666
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-08_04-42-40
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 491.0
  episode_reward_mean: 450.79
  episode_reward_min: 425.0
  episodes_this_iter: 1
  episodes_total: 225
  experiment_id: 4e724eb5b3a34f42879644e84578eec0
  hostname: gpu024
  info:
    apply_time_ms: 2.575
    dispatch_time_ms: 6.249
    learner:
      cur_lr: 0.0007606000290252268
      grad_gnorm: 4.045897006988525
      policy_entropy: 771.352783203125
      policy_loss: 2.8068389892578125
      var_gnorm: 36.390987396240234
      vf_explained_var: -1.0
      vf_loss: 0.003720854641869664
    num_steps_sampled: 9040000
    num_steps_trained: 9040000
    wait_time_ms: 544.204
  iterations_since_restore: 226
  node_ip: 172.17.8.24
  num_metric_batches_dropped: 0
  pid: 26970
  policy_reward_mean: {}
  time_since_restore: 12767.34412908554
  time_this_iter_s: 56.51126289367676
  time_total_s: 12767.34412908554
  timestamp: 1594197760
  timesteps_since_restore: 9040000
  timesteps_this_iter: 40000
  timesteps_total: 9040000
  training_iteration: 226
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26970], 12767 s, 226 iter, 9040000 ts, 451 rew

agent-1: 11.0
agent-2: 12.0
agent-3: 8.0
agent-4: 14.0
agent-5: 13.0
agent-6: 20.0
agent-7: 5.0
agent-8: 16.0
agent-9: 18.0
agent-10: 15.0
agent-11: 11.0
agent-12: 9.0
agent-13: 9.0
agent-14: 12.0
agent-15: 11.0
agent-16: 12.0
agent-17: 5.0
agent-18: 10.0
agent-19: 14.0
agent-20: 16.0
agent-21: 14.0
agent-22: 9.0
agent-23: 13.0
agent-24: 10.0
agent-25: 14.0
agent-26: 7.0
agent-27: 7.0
agent-28: 19.0
agent-29: 7.0
agent-30: 8.0
agent-31: 13.0
agent-32: 9.0
agent-33: 18.0
agent-34: 13.0
agent-35: 17.0
agent-36: 17.0
agent-37: 8.0
agent-38: 13.0
agent-39: 11.0
agent-40: 11.0
Sum Reward: 479.0
Avg Reward: 11.975
Min Reward: 5.0
Max Reward: 20.0
Gini Coefficient: 0.17886221294363258
20:20 Ratio: 2.5636363636363635
Max-min Ratio: 4.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-08_04-43-36
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 489.0
  episode_reward_mean: 450.67
  episode_reward_min: 425.0
  episodes_this_iter: 1
  episodes_total: 226
  experiment_id: 4e724eb5b3a34f42879644e84578eec0
  hostname: gpu024
  info:
    apply_time_ms: 2.735
    dispatch_time_ms: 5.753
    learner:
      cur_lr: 0.0007579359808005393
      grad_gnorm: 0.8242361545562744
      policy_entropy: 765.1993408203125
      policy_loss: -1.8210875988006592
      var_gnorm: 36.40797424316406
      vf_explained_var: -1.0
      vf_loss: 5.677223816746846e-05
    num_steps_sampled: 9080000
    num_steps_trained: 9080000
    wait_time_ms: 549.308
  iterations_since_restore: 227
  node_ip: 172.17.8.24
  num_metric_batches_dropped: 0
  pid: 26970
  policy_reward_mean: {}
  time_since_restore: 12823.633068799973
  time_this_iter_s: 56.28893971443176
  time_total_s: 12823.633068799973
  timestamp: 1594197816
  timesteps_since_restore: 9080000
  timesteps_this_iter: 40000
  timesteps_total: 9080000
  training_iteration: 227
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26970], 12823 s, 227 iter, 9080000 ts, 451 rew

agent-1: 5.0
agent-2: 14.0
agent-3: 7.0
agent-4: 12.0
agent-5: 12.0
agent-6: 9.0
agent-7: 9.0
agent-8: 11.0
agent-9: 14.0
agent-10: 12.0
agent-11: 11.0
agent-12: 11.0
agent-13: 3.0
agent-14: 10.0
agent-15: 18.0
agent-16: 12.0
agent-17: 13.0
agent-18: 15.0
agent-19: 6.0
agent-20: 9.0
agent-21: 7.0
agent-22: 7.0
agent-23: 13.0
agent-24: 7.0
agent-25: 12.0
agent-26: 12.0
agent-27: 12.0
agent-28: 12.0
agent-29: 9.0
agent-30: 9.0
agent-31: 9.0
agent-32: 17.0
agent-33: 11.0
agent-34: 9.0
agent-35: 12.0
agent-36: 12.0
agent-37: 16.0
agent-38: 10.0
agent-39: 12.0
agent-40: 10.0
Sum Reward: 431.0
Avg Reward: 10.775
Min Reward: 3.0
Max Reward: 18.0
Gini Coefficient: 0.15725058004640372
20:20 Ratio: 2.3529411764705883
Max-min Ratio: 6.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-08_04-44-33
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 489.0
  episode_reward_mean: 450.19
  episode_reward_min: 425.0
  episodes_this_iter: 1
  episodes_total: 227
  experiment_id: 4e724eb5b3a34f42879644e84578eec0
  hostname: gpu024
  info:
    apply_time_ms: 2.624
    dispatch_time_ms: 5.928
    learner:
      cur_lr: 0.0007552719907835126
      grad_gnorm: 0.26122936606407166
      policy_entropy: 776.3016967773438
      policy_loss: 0.22698251903057098
      var_gnorm: 36.449562072753906
      vf_explained_var: -1.0
      vf_loss: 5.917993803450372e-06
    num_steps_sampled: 9120000
    num_steps_trained: 9120000
    wait_time_ms: 556.485
  iterations_since_restore: 228
  node_ip: 172.17.8.24
  num_metric_batches_dropped: 0
  pid: 26970
  policy_reward_mean: {}
  time_since_restore: 12880.499961614609
  time_this_iter_s: 56.86689281463623
  time_total_s: 12880.499961614609
  timestamp: 1594197873
  timesteps_since_restore: 9120000
  timesteps_this_iter: 40000
  timesteps_total: 9120000
  training_iteration: 228
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26970], 12880 s, 228 iter, 9120000 ts, 450 rew

agent-1: 14.0
agent-2: 8.0
agent-3: 14.0
agent-4: 16.0
agent-5: 10.0
agent-6: 11.0
agent-7: 12.0
agent-8: 13.0
agent-9: 15.0
agent-10: 10.0
agent-11: 5.0
agent-12: 16.0
agent-13: 4.0
agent-14: 14.0
agent-15: 12.0
agent-16: 10.0
agent-17: 11.0
agent-18: 13.0
agent-19: 8.0
agent-20: 12.0
agent-21: 13.0
agent-22: 8.0
agent-23: 5.0
agent-24: 10.0
agent-25: 12.0
agent-26: 12.0
agent-27: 10.0
agent-28: 14.0
agent-29: 8.0
agent-30: 13.0
agent-31: 13.0
agent-32: 13.0
agent-33: 10.0
agent-34: 13.0
agent-35: 16.0
agent-36: 10.0
agent-37: 12.0
agent-38: 8.0
agent-39: 16.0
agent-40: 11.0
Sum Reward: 455.0
Avg Reward: 11.375
Min Reward: 4.0
Max Reward: 16.0
Gini Coefficient: 0.1448901098901099
20:20 Ratio: 2.240740740740741
Max-min Ratio: 4.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-08_04-45-30
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 489.0
  episode_reward_mean: 449.96
  episode_reward_min: 425.0
  episodes_this_iter: 1
  episodes_total: 228
  experiment_id: 4e724eb5b3a34f42879644e84578eec0
  hostname: gpu024
  info:
    apply_time_ms: 2.501
    dispatch_time_ms: 7.332
    learner:
      cur_lr: 0.0007526080007664859
      grad_gnorm: 1.4971319437026978
      policy_entropy: 774.5849609375
      policy_loss: -0.12291789054870605
      var_gnorm: 36.5039176940918
      vf_explained_var: -0.15514206886291504
      vf_loss: 0.0003242410020902753
    num_steps_sampled: 9160000
    num_steps_trained: 9160000
    wait_time_ms: 552.472
  iterations_since_restore: 229
  node_ip: 172.17.8.24
  num_metric_batches_dropped: 0
  pid: 26970
  policy_reward_mean: {}
  time_since_restore: 12937.16726231575
  time_this_iter_s: 56.66730070114136
  time_total_s: 12937.16726231575
  timestamp: 1594197930
  timesteps_since_restore: 9160000
  timesteps_this_iter: 40000
  timesteps_total: 9160000
  training_iteration: 229
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26970], 12937 s, 229 iter, 9160000 ts, 450 rew

agent-1: 6.0
agent-2: 10.0
agent-3: 16.0
agent-4: 12.0
agent-5: 11.0
agent-6: 11.0
agent-7: 8.0
agent-8: 16.0
agent-9: 14.0
agent-10: 15.0
agent-11: 14.0
agent-12: 14.0
agent-13: 11.0
agent-14: 10.0
agent-15: 13.0
agent-16: 16.0
agent-17: 9.0
agent-18: 4.0
agent-19: 6.0
agent-20: 15.0
agent-21: 13.0
agent-22: 11.0
agent-23: 10.0
agent-24: 21.0
agent-25: 14.0
agent-26: 4.0
agent-27: 10.0
agent-28: 11.0
agent-29: 7.0
agent-30: 15.0
agent-31: 11.0
agent-32: 11.0
agent-33: 11.0
agent-34: 11.0
agent-35: 11.0
agent-36: 13.0
agent-37: 8.0
agent-38: 13.0
agent-39: 9.0
agent-40: 10.0
Sum Reward: 455.0
Avg Reward: 11.375
Min Reward: 4.0
Max Reward: 21.0
Gini Coefficient: 0.16445054945054946
20:20 Ratio: 2.4615384615384617
Max-min Ratio: 5.25
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-08_04-46-26
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 489.0
  episode_reward_mean: 450.01
  episode_reward_min: 425.0
  episodes_this_iter: 1
  episodes_total: 229
  experiment_id: 4e724eb5b3a34f42879644e84578eec0
  hostname: gpu024
  info:
    apply_time_ms: 3.003
    dispatch_time_ms: 5.73
    learner:
      cur_lr: 0.0007499440107494593
      grad_gnorm: 3.490950584411621
      policy_entropy: 746.0056762695312
      policy_loss: -0.17374885082244873
      var_gnorm: 36.50102996826172
      vf_explained_var: -1.0
      vf_loss: 0.0022140848450362682
    num_steps_sampled: 9200000
    num_steps_trained: 9200000
    wait_time_ms: 560.961
  iterations_since_restore: 230
  node_ip: 172.17.8.24
  num_metric_batches_dropped: 0
  pid: 26970
  policy_reward_mean: {}
  time_since_restore: 12993.422372341156
  time_this_iter_s: 56.255110025405884
  time_total_s: 12993.422372341156
  timestamp: 1594197986
  timesteps_since_restore: 9200000
  timesteps_this_iter: 40000
  timesteps_total: 9200000
  training_iteration: 230
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26970], 12993 s, 230 iter, 9200000 ts, 450 rew

agent-1: 15.0
agent-2: 4.0
agent-3: 7.0
agent-4: 13.0
agent-5: 19.0
agent-6: 12.0
agent-7: 5.0
agent-8: 11.0
agent-9: 13.0
agent-10: 4.0
agent-11: 17.0
agent-12: 17.0
agent-13: 12.0
agent-14: 10.0
agent-15: 22.0
agent-16: 14.0
agent-17: 8.0
agent-18: 12.0
agent-19: 9.0
agent-20: 16.0
agent-21: 7.0
agent-22: 12.0
agent-23: 5.0
agent-24: 10.0
agent-25: 10.0
agent-26: 9.0
agent-27: 6.0
agent-28: 11.0
agent-29: 13.0
agent-30: 17.0
agent-31: 8.0
agent-32: 11.0
agent-33: 14.0
agent-34: 9.0
agent-35: 13.0
agent-36: 15.0
agent-37: 10.0
agent-38: 11.0
agent-39: 14.0
agent-40: 10.0
Sum Reward: 455.0
Avg Reward: 11.375
Min Reward: 4.0
Max Reward: 22.0
Gini Coefficient: 0.1993956043956044
20:20 Ratio: 3.0
Max-min Ratio: 5.5
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-08_04-47-23
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 489.0
  episode_reward_mean: 449.72
  episode_reward_min: 425.0
  episodes_this_iter: 1
  episodes_total: 230
  experiment_id: 4e724eb5b3a34f42879644e84578eec0
  hostname: gpu024
  info:
    apply_time_ms: 2.427
    dispatch_time_ms: 7.938
    learner:
      cur_lr: 0.0007472800207324326
      grad_gnorm: 5.560983657836914
      policy_entropy: 756.488037109375
      policy_loss: -1.30644953250885
      var_gnorm: 36.564598083496094
      vf_explained_var: -0.4286245107650757
      vf_loss: 0.004963995888829231
    num_steps_sampled: 9240000
    num_steps_trained: 9240000
    wait_time_ms: 557.114
  iterations_since_restore: 231
  node_ip: 172.17.8.24
  num_metric_batches_dropped: 0
  pid: 26970
  policy_reward_mean: {}
  time_since_restore: 13050.371846675873
  time_this_iter_s: 56.9494743347168
  time_total_s: 13050.371846675873
  timestamp: 1594198043
  timesteps_since_restore: 9240000
  timesteps_this_iter: 40000
  timesteps_total: 9240000
  training_iteration: 231
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26970], 13050 s, 231 iter, 9240000 ts, 450 rew

agent-1: 12.0
agent-2: 16.0
agent-3: 9.0
agent-4: 7.0
agent-5: 8.0
agent-6: 9.0
agent-7: 13.0
agent-8: 8.0
agent-9: 13.0
agent-10: 11.0
agent-11: 16.0
agent-12: 8.0
agent-13: 13.0
agent-14: 18.0
agent-15: 11.0
agent-16: 10.0
agent-17: 15.0
agent-18: 8.0
agent-19: 9.0
agent-20: 16.0
agent-21: 17.0
agent-22: 15.0
agent-23: 2.0
agent-24: 15.0
agent-25: 9.0
agent-26: 8.0
agent-27: 16.0
agent-28: 16.0
agent-29: 11.0
agent-30: 9.0
agent-31: 11.0
agent-32: 9.0
agent-33: 15.0
agent-34: 8.0
agent-35: 11.0
agent-36: 10.0
agent-37: 9.0
agent-38: 3.0
agent-39: 14.0
agent-40: 14.0
Sum Reward: 452.0
Avg Reward: 11.3
Min Reward: 2.0
Max Reward: 18.0
Gini Coefficient: 0.1827433628318584
20:20 Ratio: 2.5
Max-min Ratio: 9.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-08_04-48-19
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 489.0
  episode_reward_mean: 449.94
  episode_reward_min: 425.0
  episodes_this_iter: 1
  episodes_total: 231
  experiment_id: 4e724eb5b3a34f42879644e84578eec0
  hostname: gpu024
  info:
    apply_time_ms: 2.52
    dispatch_time_ms: 5.628
    learner:
      cur_lr: 0.000744615972507745
      grad_gnorm: 34.31608963012695
      policy_entropy: 749.281005859375
      policy_loss: -2.726597309112549
      var_gnorm: 36.54750061035156
      vf_explained_var: -1.0
      vf_loss: 0.10160282254219055
    num_steps_sampled: 9280000
    num_steps_trained: 9280000
    wait_time_ms: 560.587
  iterations_since_restore: 232
  node_ip: 172.17.8.24
  num_metric_batches_dropped: 0
  pid: 26970
  policy_reward_mean: {}
  time_since_restore: 13106.78537774086
  time_this_iter_s: 56.41353106498718
  time_total_s: 13106.78537774086
  timestamp: 1594198099
  timesteps_since_restore: 9280000
  timesteps_this_iter: 40000
  timesteps_total: 9280000
  training_iteration: 232
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26970], 13106 s, 232 iter, 9280000 ts, 450 rew

agent-1: 15.0
agent-2: 12.0
agent-3: 12.0
agent-4: 17.0
agent-5: 11.0
agent-6: 10.0
agent-7: 14.0
agent-8: 7.0
agent-9: 8.0
agent-10: 15.0
agent-11: 13.0
agent-12: 25.0
agent-13: 12.0
agent-14: 11.0
agent-15: 2.0
agent-16: 9.0
agent-17: 4.0
agent-18: 17.0
agent-19: 12.0
agent-20: 6.0
agent-21: 14.0
agent-22: 11.0
agent-23: 8.0
agent-24: 11.0
agent-25: 14.0
agent-26: 18.0
agent-27: 9.0
agent-28: 9.0
agent-29: 12.0
agent-30: 13.0
agent-31: 7.0
agent-32: 10.0
agent-33: 10.0
agent-34: 21.0
agent-35: 19.0
agent-36: 19.0
agent-37: 13.0
agent-38: 14.0
agent-39: 12.0
agent-40: 5.0
Sum Reward: 481.0
Avg Reward: 12.025
Min Reward: 2.0
Max Reward: 25.0
Gini Coefficient: 0.21055093555093554
20:20 Ratio: 3.2127659574468086
Max-min Ratio: 12.5
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-08_04-49-16
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 489.0
  episode_reward_mean: 450.31
  episode_reward_min: 425.0
  episodes_this_iter: 1
  episodes_total: 232
  experiment_id: 4e724eb5b3a34f42879644e84578eec0
  hostname: gpu024
  info:
    apply_time_ms: 2.355
    dispatch_time_ms: 5.322
    learner:
      cur_lr: 0.0007419519824907184
      grad_gnorm: 3.6961629390716553
      policy_entropy: 734.9356689453125
      policy_loss: 1.3247838020324707
      var_gnorm: 36.63551712036133
      vf_explained_var: -1.0
      vf_loss: 0.010461585596203804
    num_steps_sampled: 9320000
    num_steps_trained: 9320000
    wait_time_ms: 562.308
  iterations_since_restore: 233
  node_ip: 172.17.8.24
  num_metric_batches_dropped: 0
  pid: 26970
  policy_reward_mean: {}
  time_since_restore: 13163.33511686325
  time_this_iter_s: 56.54973912239075
  time_total_s: 13163.33511686325
  timestamp: 1594198156
  timesteps_since_restore: 9320000
  timesteps_this_iter: 40000
  timesteps_total: 9320000
  training_iteration: 233
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26970], 13163 s, 233 iter, 9320000 ts, 450 rew

agent-1: 14.0
agent-2: 15.0
agent-3: 13.0
agent-4: 18.0
agent-5: 11.0
agent-6: 7.0
agent-7: 14.0
agent-8: 11.0
agent-9: 10.0
agent-10: 3.0
agent-11: 13.0
agent-12: 13.0
agent-13: 12.0
agent-14: 12.0
agent-15: 14.0
agent-16: 20.0
agent-17: 10.0
agent-18: 8.0
agent-19: 9.0
agent-20: 17.0
agent-21: 11.0
agent-22: 6.0
agent-23: 12.0
agent-24: 14.0
agent-25: 11.0
agent-26: 7.0
agent-27: 10.0
agent-28: 13.0
agent-29: 13.0
agent-30: 10.0
agent-31: 10.0
agent-32: 11.0
agent-33: 12.0
agent-34: 7.0
agent-35: 5.0
agent-36: 18.0
agent-37: 16.0
agent-38: 5.0
agent-39: 13.0
agent-40: 10.0
Sum Reward: 458.0
Avg Reward: 11.45
Min Reward: 3.0
Max Reward: 20.0
Gini Coefficient: 0.1784934497816594
20:20 Ratio: 2.75
Max-min Ratio: 6.666666666666667
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-08_04-50-12
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 484.0
  episode_reward_mean: 450.0
  episode_reward_min: 425.0
  episodes_this_iter: 1
  episodes_total: 233
  experiment_id: 4e724eb5b3a34f42879644e84578eec0
  hostname: gpu024
  info:
    apply_time_ms: 2.453
    dispatch_time_ms: 5.254
    learner:
      cur_lr: 0.0007392879924736917
      grad_gnorm: 2.0526697635650635
      policy_entropy: 776.0126342773438
      policy_loss: 1.2629272937774658
      var_gnorm: 36.670684814453125
      vf_explained_var: -0.6740472316741943
      vf_loss: 0.0008260500617325306
    num_steps_sampled: 9360000
    num_steps_trained: 9360000
    wait_time_ms: 548.483
  iterations_since_restore: 234
  node_ip: 172.17.8.24
  num_metric_batches_dropped: 0
  pid: 26970
  policy_reward_mean: {}
  time_since_restore: 13219.652364253998
  time_this_iter_s: 56.31724739074707
  time_total_s: 13219.652364253998
  timestamp: 1594198212
  timesteps_since_restore: 9360000
  timesteps_this_iter: 40000
  timesteps_total: 9360000
  training_iteration: 234
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26970], 13219 s, 234 iter, 9360000 ts, 450 rew

agent-1: 11.0
agent-2: 10.0
agent-3: 8.0
agent-4: 15.0
agent-5: 16.0
agent-6: 9.0
agent-7: 5.0
agent-8: 11.0
agent-9: 6.0
agent-10: 16.0
agent-11: 6.0
agent-12: 21.0
agent-13: 10.0
agent-14: 6.0
agent-15: 3.0
agent-16: 17.0
agent-17: 11.0
agent-18: 11.0
agent-19: 17.0
agent-20: 12.0
agent-21: 12.0
agent-22: 8.0
agent-23: 9.0
agent-24: 14.0
agent-25: 11.0
agent-26: 16.0
agent-27: 16.0
agent-28: 6.0
agent-29: 17.0
agent-30: 16.0
agent-31: 16.0
agent-32: 18.0
agent-33: 4.0
agent-34: 11.0
agent-35: 8.0
agent-36: 5.0
agent-37: 12.0
agent-38: 7.0
agent-39: 11.0
agent-40: 7.0
Sum Reward: 445.0
Avg Reward: 11.125
Min Reward: 3.0
Max Reward: 21.0
Gini Coefficient: 0.22702247191011235
20:20 Ratio: 3.3658536585365852
Max-min Ratio: 7.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-08_04-51-09
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 484.0
  episode_reward_mean: 449.82
  episode_reward_min: 425.0
  episodes_this_iter: 1
  episodes_total: 234
  experiment_id: 4e724eb5b3a34f42879644e84578eec0
  hostname: gpu024
  info:
    apply_time_ms: 3.063
    dispatch_time_ms: 5.685
    learner:
      cur_lr: 0.000736624002456665
      grad_gnorm: 1.9361516237258911
      policy_entropy: 768.9598388671875
      policy_loss: 0.33391261100769043
      var_gnorm: 36.68083953857422
      vf_explained_var: -0.7909852266311646
      vf_loss: 0.001256565097719431
    num_steps_sampled: 9400000
    num_steps_trained: 9400000
    wait_time_ms: 546.938
  iterations_since_restore: 235
  node_ip: 172.17.8.24
  num_metric_batches_dropped: 0
  pid: 26970
  policy_reward_mean: {}
  time_since_restore: 13276.28746509552
  time_this_iter_s: 56.63510084152222
  time_total_s: 13276.28746509552
  timestamp: 1594198269
  timesteps_since_restore: 9400000
  timesteps_this_iter: 40000
  timesteps_total: 9400000
  training_iteration: 235
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26970], 13276 s, 235 iter, 9400000 ts, 450 rew

agent-1: 8.0
agent-2: 14.0
agent-3: 6.0
agent-4: 14.0
agent-5: 11.0
agent-6: 19.0
agent-7: 8.0
agent-8: 16.0
agent-9: 14.0
agent-10: 12.0
agent-11: 12.0
agent-12: 5.0
agent-13: 8.0
agent-14: 13.0
agent-15: 9.0
agent-16: 14.0
agent-17: 17.0
agent-18: 7.0
agent-19: 13.0
agent-20: 8.0
agent-21: 13.0
agent-22: 12.0
agent-23: 15.0
agent-24: 5.0
agent-25: 14.0
agent-26: 8.0
agent-27: 8.0
agent-28: 15.0
agent-29: 12.0
agent-30: 10.0
agent-31: 14.0
agent-32: 9.0
agent-33: 12.0
agent-34: 7.0
agent-35: 15.0
agent-36: 15.0
agent-37: 15.0
agent-38: 11.0
agent-39: 19.0
agent-40: 17.0
Sum Reward: 474.0
Avg Reward: 11.85
Min Reward: 5.0
Max Reward: 19.0
Gini Coefficient: 0.1758438818565401
20:20 Ratio: 2.462962962962963
Max-min Ratio: 3.8
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-08_04-52-06
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 484.0
  episode_reward_mean: 449.86
  episode_reward_min: 425.0
  episodes_this_iter: 1
  episodes_total: 235
  experiment_id: 4e724eb5b3a34f42879644e84578eec0
  hostname: gpu024
  info:
    apply_time_ms: 3.328
    dispatch_time_ms: 5.856
    learner:
      cur_lr: 0.0007339600124396384
      grad_gnorm: 2.7128639221191406
      policy_entropy: 765.6051635742188
      policy_loss: 1.6860826015472412
      var_gnorm: 36.73261260986328
      vf_explained_var: -0.25119078159332275
      vf_loss: 0.001378515618853271
    num_steps_sampled: 9440000
    num_steps_trained: 9440000
    wait_time_ms: 550.589
  iterations_since_restore: 236
  node_ip: 172.17.8.24
  num_metric_batches_dropped: 0
  pid: 26970
  policy_reward_mean: {}
  time_since_restore: 13332.756754159927
  time_this_iter_s: 56.46928906440735
  time_total_s: 13332.756754159927
  timestamp: 1594198326
  timesteps_since_restore: 9440000
  timesteps_this_iter: 40000
  timesteps_total: 9440000
  training_iteration: 236
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26970], 13332 s, 236 iter, 9440000 ts, 450 rew

agent-1: 14.0
agent-2: 13.0
agent-3: 8.0
agent-4: 9.0
agent-5: 13.0
agent-6: 13.0
agent-7: 13.0
agent-8: 8.0
agent-9: 10.0
agent-10: 10.0
agent-11: 12.0
agent-12: 11.0
agent-13: 16.0
agent-14: 3.0
agent-15: 8.0
agent-16: 12.0
agent-17: 11.0
agent-18: 10.0
agent-19: 8.0
agent-20: 6.0
agent-21: 7.0
agent-22: 11.0
agent-23: 12.0
agent-24: 7.0
agent-25: 10.0
agent-26: 17.0
agent-27: 9.0
agent-28: 7.0
agent-29: 13.0
agent-30: 14.0
agent-31: 11.0
agent-32: 11.0
agent-33: 13.0
agent-34: 8.0
agent-35: 10.0
agent-36: 13.0
agent-37: 9.0
agent-38: 11.0
agent-39: 9.0
agent-40: 14.0
Sum Reward: 424.0
Avg Reward: 10.6
Min Reward: 3.0
Max Reward: 17.0
Gini Coefficient: 0.14787735849056605
20:20 Ratio: 2.111111111111111
Max-min Ratio: 5.666666666666667
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-08_04-53-02
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 484.0
  episode_reward_mean: 449.47
  episode_reward_min: 424.0
  episodes_this_iter: 1
  episodes_total: 236
  experiment_id: 4e724eb5b3a34f42879644e84578eec0
  hostname: gpu024
  info:
    apply_time_ms: 2.44
    dispatch_time_ms: 5.372
    learner:
      cur_lr: 0.0007312960224226117
      grad_gnorm: 6.458331108093262
      policy_entropy: 766.3036499023438
      policy_loss: 2.8665571212768555
      var_gnorm: 36.743865966796875
      vf_explained_var: -1.0
      vf_loss: 0.0063257343135774136
    num_steps_sampled: 9480000
    num_steps_trained: 9480000
    wait_time_ms: 569.549
  iterations_since_restore: 237
  node_ip: 172.17.8.24
  num_metric_batches_dropped: 0
  pid: 26970
  policy_reward_mean: {}
  time_since_restore: 13389.329051971436
  time_this_iter_s: 56.57229781150818
  time_total_s: 13389.329051971436
  timestamp: 1594198382
  timesteps_since_restore: 9480000
  timesteps_this_iter: 40000
  timesteps_total: 9480000
  training_iteration: 237
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26970], 13389 s, 237 iter, 9480000 ts, 449 rew

agent-1: 8.0
agent-2: 11.0
agent-3: 10.0
agent-4: 15.0
agent-5: 11.0
agent-6: 12.0
agent-7: 12.0
agent-8: 7.0
agent-9: 12.0
agent-10: 13.0
agent-11: 6.0
agent-12: 9.0
agent-13: 10.0
agent-14: 10.0
agent-15: 9.0
agent-16: 17.0
agent-17: 10.0
agent-18: 10.0
agent-19: 19.0
agent-20: 4.0
agent-21: 17.0
agent-22: 13.0
agent-23: 13.0
agent-24: 12.0
agent-25: 8.0
agent-26: 9.0
agent-27: 10.0
agent-28: 12.0
agent-29: 13.0
agent-30: 6.0
agent-31: 18.0
agent-32: 7.0
agent-33: 10.0
agent-34: 15.0
agent-35: 16.0
agent-36: 12.0
agent-37: 16.0
agent-38: 8.0
agent-39: 16.0
agent-40: 13.0
Sum Reward: 459.0
Avg Reward: 11.475
Min Reward: 4.0
Max Reward: 19.0
Gini Coefficient: 0.17140522875816994
20:20 Ratio: 2.4814814814814814
Max-min Ratio: 4.75
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-08_04-53-59
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 484.0
  episode_reward_mean: 449.53
  episode_reward_min: 424.0
  episodes_this_iter: 1
  episodes_total: 237
  experiment_id: 4e724eb5b3a34f42879644e84578eec0
  hostname: gpu024
  info:
    apply_time_ms: 3.577
    dispatch_time_ms: 7.832
    learner:
      cur_lr: 0.0007286319741979241
      grad_gnorm: 1.5149977207183838
      policy_entropy: 770.1973266601562
      policy_loss: 0.7679320573806763
      var_gnorm: 36.75321960449219
      vf_explained_var: -0.5612590312957764
      vf_loss: 0.0006732257315889001
    num_steps_sampled: 9520000
    num_steps_trained: 9520000
    wait_time_ms: 568.783
  iterations_since_restore: 238
  node_ip: 172.17.8.24
  num_metric_batches_dropped: 0
  pid: 26970
  policy_reward_mean: {}
  time_since_restore: 13446.259024620056
  time_this_iter_s: 56.929972648620605
  time_total_s: 13446.259024620056
  timestamp: 1594198439
  timesteps_since_restore: 9520000
  timesteps_this_iter: 40000
  timesteps_total: 9520000
  training_iteration: 238
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26970], 13446 s, 238 iter, 9520000 ts, 450 rew

agent-1: 13.0
agent-2: 8.0
agent-3: 6.0
agent-4: 9.0
agent-5: 17.0
agent-6: 12.0
agent-7: 16.0
agent-8: 6.0
agent-9: 10.0
agent-10: 16.0
agent-11: 15.0
agent-12: 8.0
agent-13: 11.0
agent-14: 12.0
agent-15: 14.0
agent-16: 13.0
agent-17: 13.0
agent-18: 9.0
agent-19: 16.0
agent-20: 11.0
agent-21: 10.0
agent-22: 10.0
agent-23: 8.0
agent-24: 10.0
agent-25: 10.0
agent-26: 7.0
agent-27: 13.0
agent-28: 6.0
agent-29: 11.0
agent-30: 19.0
agent-31: 14.0
agent-32: 6.0
agent-33: 9.0
agent-34: 9.0
agent-35: 13.0
agent-36: 13.0
agent-37: 9.0
agent-38: 9.0
agent-39: 12.0
agent-40: 17.0
Sum Reward: 450.0
Avg Reward: 11.25
Min Reward: 6.0
Max Reward: 19.0
Gini Coefficient: 0.16733333333333333
20:20 Ratio: 2.3636363636363638
Max-min Ratio: 3.1666666666666665
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-08_04-54-55
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 484.0
  episode_reward_mean: 449.58
  episode_reward_min: 424.0
  episodes_this_iter: 1
  episodes_total: 238
  experiment_id: 4e724eb5b3a34f42879644e84578eec0
  hostname: gpu024
  info:
    apply_time_ms: 2.485
    dispatch_time_ms: 5.733
    learner:
      cur_lr: 0.0007259679841808975
      grad_gnorm: 2.8188490867614746
      policy_entropy: 742.5697631835938
      policy_loss: 7.373312950134277
      var_gnorm: 36.780391693115234
      vf_explained_var: -1.0
      vf_loss: 0.00034894829150289297
    num_steps_sampled: 9560000
    num_steps_trained: 9560000
    wait_time_ms: 553.645
  iterations_since_restore: 239
  node_ip: 172.17.8.24
  num_metric_batches_dropped: 0
  pid: 26970
  policy_reward_mean: {}
  time_since_restore: 13502.57354259491
  time_this_iter_s: 56.314517974853516
  time_total_s: 13502.57354259491
  timestamp: 1594198495
  timesteps_since_restore: 9560000
  timesteps_this_iter: 40000
  timesteps_total: 9560000
  training_iteration: 239
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26970], 13502 s, 239 iter, 9560000 ts, 450 rew

agent-1: 15.0
agent-2: 5.0
agent-3: 10.0
agent-4: 8.0
agent-5: 14.0
agent-6: 11.0
agent-7: 5.0
agent-8: 10.0
agent-9: 13.0
agent-10: 8.0
agent-11: 8.0
agent-12: 12.0
agent-13: 10.0
agent-14: 16.0
agent-15: 9.0
agent-16: 18.0
agent-17: 14.0
agent-18: 16.0
agent-19: 2.0
agent-20: 15.0
agent-21: 8.0
agent-22: 14.0
agent-23: 7.0
agent-24: 15.0
agent-25: 13.0
agent-26: 6.0
agent-27: 12.0
agent-28: 13.0
agent-29: 9.0
agent-30: 12.0
agent-31: 18.0
agent-32: 7.0
agent-33: 10.0
agent-34: 10.0
agent-35: 25.0
agent-36: 9.0
agent-37: 8.0
agent-38: 14.0
agent-39: 4.0
agent-40: 13.0
Sum Reward: 446.0
Avg Reward: 11.15
Min Reward: 2.0
Max Reward: 25.0
Gini Coefficient: 0.2163677130044843
20:20 Ratio: 3.1363636363636362
Max-min Ratio: 12.5
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-08_04-55-52
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 484.0
  episode_reward_mean: 449.69
  episode_reward_min: 424.0
  episodes_this_iter: 1
  episodes_total: 239
  experiment_id: 4e724eb5b3a34f42879644e84578eec0
  hostname: gpu024
  info:
    apply_time_ms: 2.672
    dispatch_time_ms: 5.467
    learner:
      cur_lr: 0.0007233039941638708
      grad_gnorm: 1.034812569618225
      policy_entropy: 744.308837890625
      policy_loss: -0.47492629289627075
      var_gnorm: 36.842750549316406
      vf_explained_var: -0.8405530452728271
      vf_loss: 0.0004540583468042314
    num_steps_sampled: 9600000
    num_steps_trained: 9600000
    wait_time_ms: 558.633
  iterations_since_restore: 240
  node_ip: 172.17.8.24
  num_metric_batches_dropped: 0
  pid: 26970
  policy_reward_mean: {}
  time_since_restore: 13558.586394071579
  time_this_iter_s: 56.01285147666931
  time_total_s: 13558.586394071579
  timestamp: 1594198552
  timesteps_since_restore: 9600000
  timesteps_this_iter: 40000
  timesteps_total: 9600000
  training_iteration: 240
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26970], 13558 s, 240 iter, 9600000 ts, 450 rew

agent-1: 13.0
agent-2: 15.0
agent-3: 19.0
agent-4: 12.0
agent-5: 15.0
agent-6: 3.0
agent-7: 12.0
agent-8: 14.0
agent-9: 6.0
agent-10: 10.0
agent-11: 9.0
agent-12: 7.0
agent-13: 13.0
agent-14: 11.0
agent-15: 10.0
agent-16: 12.0
agent-17: 8.0
agent-18: 11.0
agent-19: 11.0
agent-20: 12.0
agent-21: 14.0
agent-22: 9.0
agent-23: 13.0
agent-24: 11.0
agent-25: 16.0
agent-26: 8.0
agent-27: 7.0
agent-28: 13.0
agent-29: 13.0
agent-30: 14.0
agent-31: 9.0
agent-32: 10.0
agent-33: 15.0
agent-34: 7.0
agent-35: 11.0
agent-36: 9.0
agent-37: 15.0
agent-38: 5.0
agent-39: 17.0
agent-40: 10.0
Sum Reward: 449.0
Avg Reward: 11.225
Min Reward: 3.0
Max Reward: 19.0
Gini Coefficient: 0.1678730512249443
20:20 Ratio: 2.4705882352941178
Max-min Ratio: 6.333333333333333
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-08_04-56-48
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 484.0
  episode_reward_mean: 449.72
  episode_reward_min: 424.0
  episodes_this_iter: 1
  episodes_total: 240
  experiment_id: 4e724eb5b3a34f42879644e84578eec0
  hostname: gpu024
  info:
    apply_time_ms: 2.801
    dispatch_time_ms: 8.434
    learner:
      cur_lr: 0.0007206400041468441
      grad_gnorm: 4.354020595550537
      policy_entropy: 759.0375366210938
      policy_loss: 4.097352981567383
      var_gnorm: 36.84786605834961
      vf_explained_var: -0.37115347385406494
      vf_loss: 0.002876074519008398
    num_steps_sampled: 9640000
    num_steps_trained: 9640000
    wait_time_ms: 552.633
  iterations_since_restore: 241
  node_ip: 172.17.8.24
  num_metric_batches_dropped: 0
  pid: 26970
  policy_reward_mean: {}
  time_since_restore: 13614.969429016113
  time_this_iter_s: 56.3830349445343
  time_total_s: 13614.969429016113
  timestamp: 1594198608
  timesteps_since_restore: 9640000
  timesteps_this_iter: 40000
  timesteps_total: 9640000
  training_iteration: 241
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26970], 13614 s, 241 iter, 9640000 ts, 450 rew

agent-1: 18.0
agent-2: 14.0
agent-3: 12.0
agent-4: 13.0
agent-5: 16.0
agent-6: 6.0
agent-7: 5.0
agent-8: 6.0
agent-9: 13.0
agent-10: 16.0
agent-11: 12.0
agent-12: 9.0
agent-13: 11.0
agent-14: 11.0
agent-15: 9.0
agent-16: 7.0
agent-17: 13.0
agent-18: 6.0
agent-19: 17.0
agent-20: 12.0
agent-21: 6.0
agent-22: 9.0
agent-23: 17.0
agent-24: 10.0
agent-25: 12.0
agent-26: 6.0
agent-27: 7.0
agent-28: 18.0
agent-29: 15.0
agent-30: 11.0
agent-31: 8.0
agent-32: 13.0
agent-33: 9.0
agent-34: 1.0
agent-35: 16.0
agent-36: 13.0
agent-37: 13.0
agent-38: 9.0
agent-39: 8.0
agent-40: 12.0
Sum Reward: 439.0
Avg Reward: 10.975
Min Reward: 1.0
Max Reward: 18.0
Gini Coefficient: 0.20484054669703872
20:20 Ratio: 3.0930232558139537
Max-min Ratio: 18.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-08_04-57-45
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 484.0
  episode_reward_mean: 449.86
  episode_reward_min: 424.0
  episodes_this_iter: 1
  episodes_total: 241
  experiment_id: 4e724eb5b3a34f42879644e84578eec0
  hostname: gpu024
  info:
    apply_time_ms: 2.546
    dispatch_time_ms: 6.291
    learner:
      cur_lr: 0.0007179760141298175
      grad_gnorm: 2.942586898803711
      policy_entropy: 747.0851440429688
      policy_loss: 0.9563998579978943
      var_gnorm: 36.8421745300293
      vf_explained_var: -0.20594656467437744
      vf_loss: 0.0014557228423655033
    num_steps_sampled: 9680000
    num_steps_trained: 9680000
    wait_time_ms: 567.479
  iterations_since_restore: 242
  node_ip: 172.17.8.24
  num_metric_batches_dropped: 0
  pid: 26970
  policy_reward_mean: {}
  time_since_restore: 13671.726923942566
  time_this_iter_s: 56.75749492645264
  time_total_s: 13671.726923942566
  timestamp: 1594198665
  timesteps_since_restore: 9680000
  timesteps_this_iter: 40000
  timesteps_total: 9680000
  training_iteration: 242
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26970], 13671 s, 242 iter, 9680000 ts, 450 rew

agent-1: 14.0
agent-2: 15.0
agent-3: 10.0
agent-4: 23.0
agent-5: 11.0
agent-6: 14.0
agent-7: 7.0
agent-8: 19.0
agent-9: 17.0
agent-10: 10.0
agent-11: 16.0
agent-12: 13.0
agent-13: 14.0
agent-14: 5.0
agent-15: 13.0
agent-16: 13.0
agent-17: 17.0
agent-18: 12.0
agent-19: 10.0
agent-20: 19.0
agent-21: 13.0
agent-22: 3.0
agent-23: 6.0
agent-24: 12.0
agent-25: 6.0
agent-26: 8.0
agent-27: 9.0
agent-28: 9.0
agent-29: 10.0
agent-30: 15.0
agent-31: 15.0
agent-32: 5.0
agent-33: 12.0
agent-34: 7.0
agent-35: 10.0
agent-36: 9.0
agent-37: 9.0
agent-38: 10.0
agent-39: 6.0
agent-40: 11.0
Sum Reward: 457.0
Avg Reward: 11.425
Min Reward: 3.0
Max Reward: 23.0
Gini Coefficient: 0.2096827133479212
20:20 Ratio: 3.1333333333333333
Max-min Ratio: 7.666666666666667
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-08_04-58-41
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 484.0
  episode_reward_mean: 449.81
  episode_reward_min: 424.0
  episodes_this_iter: 1
  episodes_total: 242
  experiment_id: 4e724eb5b3a34f42879644e84578eec0
  hostname: gpu024
  info:
    apply_time_ms: 2.507
    dispatch_time_ms: 5.1
    learner:
      cur_lr: 0.0007153120241127908
      grad_gnorm: 40.000003814697266
      policy_entropy: 732.63134765625
      policy_loss: -54.63420104980469
      var_gnorm: 36.89445495605469
      vf_explained_var: 0.002271711826324463
      vf_loss: 1.5728802680969238
    num_steps_sampled: 9720000
    num_steps_trained: 9720000
    wait_time_ms: 569.916
  iterations_since_restore: 243
  node_ip: 172.17.8.24
  num_metric_batches_dropped: 0
  pid: 26970
  policy_reward_mean: {}
  time_since_restore: 13728.139207363129
  time_this_iter_s: 56.412283420562744
  time_total_s: 13728.139207363129
  timestamp: 1594198721
  timesteps_since_restore: 9720000
  timesteps_this_iter: 40000
  timesteps_total: 9720000
  training_iteration: 243
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26970], 13728 s, 243 iter, 9720000 ts, 450 rew

agent-1: 18.0
agent-2: 9.0
agent-3: 12.0
agent-4: 14.0
agent-5: 11.0
agent-6: 16.0
agent-7: 9.0
agent-8: 8.0
agent-9: 7.0
agent-10: 7.0
agent-11: 11.0
agent-12: 10.0
agent-13: 14.0
agent-14: 11.0
agent-15: 14.0
agent-16: 11.0
agent-17: 15.0
agent-18: 17.0
agent-19: 4.0
agent-20: 17.0
agent-21: 16.0
agent-22: 15.0
agent-23: 9.0
agent-24: 9.0
agent-25: 10.0
agent-26: 15.0
agent-27: 12.0
agent-28: 12.0
agent-29: 16.0
agent-30: 17.0
agent-31: 12.0
agent-32: 12.0
agent-33: 13.0
agent-34: 7.0
agent-35: 15.0
agent-36: 10.0
agent-37: 12.0
agent-38: 1.0
agent-39: 5.0
agent-40: 8.0
Sum Reward: 461.0
Avg Reward: 11.525
Min Reward: 1.0
Max Reward: 18.0
Gini Coefficient: 0.18747288503253795
20:20 Ratio: 2.8085106382978724
Max-min Ratio: 18.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-08_04-59-38
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 484.0
  episode_reward_mean: 449.78
  episode_reward_min: 424.0
  episodes_this_iter: 1
  episodes_total: 243
  experiment_id: 4e724eb5b3a34f42879644e84578eec0
  hostname: gpu024
  info:
    apply_time_ms: 2.662
    dispatch_time_ms: 6.431
    learner:
      cur_lr: 0.0007126479758881032
      grad_gnorm: 2.7965874671936035
      policy_entropy: 740.2088623046875
      policy_loss: -2.657259941101074
      var_gnorm: 36.87867736816406
      vf_explained_var: 3.5762786865234375e-07
      vf_loss: 0.00116910960059613
    num_steps_sampled: 9760000
    num_steps_trained: 9760000
    wait_time_ms: 555.756
  iterations_since_restore: 244
  node_ip: 172.17.8.24
  num_metric_batches_dropped: 0
  pid: 26970
  policy_reward_mean: {}
  time_since_restore: 13784.69985985756
  time_this_iter_s: 56.56065249443054
  time_total_s: 13784.69985985756
  timestamp: 1594198778
  timesteps_since_restore: 9760000
  timesteps_this_iter: 40000
  timesteps_total: 9760000
  training_iteration: 244
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26970], 13784 s, 244 iter, 9760000 ts, 450 rew

agent-1: 14.0
agent-2: 12.0
agent-3: 15.0
agent-4: 11.0
agent-5: 11.0
agent-6: 5.0
agent-7: 11.0
agent-8: 7.0
agent-9: 11.0
agent-10: 8.0
agent-11: 11.0
agent-12: 12.0
agent-13: 18.0
agent-14: 15.0
agent-15: 2.0
agent-16: 15.0
agent-17: 14.0
agent-18: 18.0
agent-19: 10.0
agent-20: 5.0
agent-21: 6.0
agent-22: 11.0
agent-23: 11.0
agent-24: 5.0
agent-25: 15.0
agent-26: 11.0
agent-27: 8.0
agent-28: 3.0
agent-29: 17.0
agent-30: 15.0
agent-31: 6.0
agent-32: 17.0
agent-33: 11.0
agent-34: 15.0
agent-35: 14.0
agent-36: 10.0
agent-37: 15.0
agent-38: 11.0
agent-39: 16.0
agent-40: 8.0
Sum Reward: 450.0
Avg Reward: 11.25
Min Reward: 2.0
Max Reward: 18.0
Gini Coefficient: 0.20633333333333334
20:20 Ratio: 3.358974358974359
Max-min Ratio: 9.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-08_05-00-34
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 484.0
  episode_reward_mean: 449.72
  episode_reward_min: 424.0
  episodes_this_iter: 1
  episodes_total: 244
  experiment_id: 4e724eb5b3a34f42879644e84578eec0
  hostname: gpu024
  info:
    apply_time_ms: 2.735
    dispatch_time_ms: 6.062
    learner:
      cur_lr: 0.0007099839858710766
      grad_gnorm: 5.652562618255615
      policy_entropy: 770.1996459960938
      policy_loss: 6.163565158843994
      var_gnorm: 36.92627716064453
      vf_explained_var: -2.384185791015625e-06
      vf_loss: 0.004309867043048143
    num_steps_sampled: 9800000
    num_steps_trained: 9800000
    wait_time_ms: 556.348
  iterations_since_restore: 245
  node_ip: 172.17.8.24
  num_metric_batches_dropped: 0
  pid: 26970
  policy_reward_mean: {}
  time_since_restore: 13841.049823760986
  time_this_iter_s: 56.349963903427124
  time_total_s: 13841.049823760986
  timestamp: 1594198834
  timesteps_since_restore: 9800000
  timesteps_this_iter: 40000
  timesteps_total: 9800000
  training_iteration: 245
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26970], 13841 s, 245 iter, 9800000 ts, 450 rew

agent-1: 5.0
agent-2: 14.0
agent-3: 12.0
agent-4: 11.0
agent-5: 13.0
agent-6: 14.0
agent-7: 18.0
agent-8: 6.0
agent-9: 12.0
agent-10: 12.0
agent-11: 12.0
agent-12: 9.0
agent-13: 16.0
agent-14: 8.0
agent-15: 10.0
agent-16: 11.0
agent-17: 11.0
agent-18: 13.0
agent-19: 9.0
agent-20: 10.0
agent-21: 13.0
agent-22: 8.0
agent-23: 15.0
agent-24: 15.0
agent-25: 26.0
agent-26: 8.0
agent-27: 8.0
agent-28: 12.0
agent-29: 15.0
agent-30: 6.0
agent-31: 15.0
agent-32: 7.0
agent-33: 13.0
agent-34: 10.0
agent-35: 9.0
agent-36: 6.0
agent-37: 6.0
agent-38: 3.0
agent-39: 11.0
agent-40: 7.0
Sum Reward: 439.0
Avg Reward: 10.975
Min Reward: 3.0
Max Reward: 26.0
Gini Coefficient: 0.20233485193621867
20:20 Ratio: 2.9130434782608696
Max-min Ratio: 8.666666666666666
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-08_05-01-31
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 484.0
  episode_reward_mean: 449.43
  episode_reward_min: 424.0
  episodes_this_iter: 1
  episodes_total: 245
  experiment_id: 4e724eb5b3a34f42879644e84578eec0
  hostname: gpu024
  info:
    apply_time_ms: 2.709
    dispatch_time_ms: 6.835
    learner:
      cur_lr: 0.0007073199958540499
      grad_gnorm: 1.0598983764648438
      policy_entropy: 775.4210815429688
      policy_loss: -0.942589282989502
      var_gnorm: 36.924102783203125
      vf_explained_var: -0.00027573108673095703
      vf_loss: 0.0001699291169643402
    num_steps_sampled: 9840000
    num_steps_trained: 9840000
    wait_time_ms: 566.634
  iterations_since_restore: 246
  node_ip: 172.17.8.24
  num_metric_batches_dropped: 0
  pid: 26970
  policy_reward_mean: {}
  time_since_restore: 13897.832220077515
  time_this_iter_s: 56.78239631652832
  time_total_s: 13897.832220077515
  timestamp: 1594198891
  timesteps_since_restore: 9840000
  timesteps_this_iter: 40000
  timesteps_total: 9840000
  training_iteration: 246
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26970], 13897 s, 246 iter, 9840000 ts, 449 rew

agent-1: 13.0
agent-2: 7.0
agent-3: 18.0
agent-4: 14.0
agent-5: 16.0
agent-6: 12.0
agent-7: 6.0
agent-8: 8.0
agent-9: 13.0
agent-10: 4.0
agent-11: 7.0
agent-12: 4.0
agent-13: 17.0
agent-14: 5.0
agent-15: 13.0
agent-16: 12.0
agent-17: 17.0
agent-18: 13.0
agent-19: 13.0
agent-20: 15.0
agent-21: 10.0
agent-22: 10.0
agent-23: 15.0
agent-24: 13.0
agent-25: 12.0
agent-26: 14.0
agent-27: 15.0
agent-28: 17.0
agent-29: 9.0
agent-30: 5.0
agent-31: 18.0
agent-32: 10.0
agent-33: 11.0
agent-34: 16.0
agent-35: 13.0
agent-36: 9.0
agent-37: 9.0
agent-38: 10.0
agent-39: 16.0
agent-40: 14.0
Sum Reward: 473.0
Avg Reward: 11.825
Min Reward: 4.0
Max Reward: 18.0
Gini Coefficient: 0.18757928118393236
20:20 Ratio: 2.9347826086956523
Max-min Ratio: 4.5
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-08_05-02-28
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 484.0
  episode_reward_mean: 449.64
  episode_reward_min: 424.0
  episodes_this_iter: 1
  episodes_total: 246
  experiment_id: 4e724eb5b3a34f42879644e84578eec0
  hostname: gpu024
  info:
    apply_time_ms: 2.536
    dispatch_time_ms: 7.069
    learner:
      cur_lr: 0.0007046560058370233
      grad_gnorm: 1.5248585939407349
      policy_entropy: 775.4054565429688
      policy_loss: 1.376662015914917
      var_gnorm: 36.93166732788086
      vf_explained_var: -0.02770543098449707
      vf_loss: 0.0003524125786498189
    num_steps_sampled: 9880000
    num_steps_trained: 9880000
    wait_time_ms: 561.709
  iterations_since_restore: 247
  node_ip: 172.17.8.24
  num_metric_batches_dropped: 0
  pid: 26970
  policy_reward_mean: {}
  time_since_restore: 13954.336993932724
  time_this_iter_s: 56.50477385520935
  time_total_s: 13954.336993932724
  timestamp: 1594198948
  timesteps_since_restore: 9880000
  timesteps_this_iter: 40000
  timesteps_total: 9880000
  training_iteration: 247
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26970], 13954 s, 247 iter, 9880000 ts, 450 rew

agent-1: 8.0
agent-2: 12.0
agent-3: 17.0
agent-4: 12.0
agent-5: 14.0
agent-6: 12.0
agent-7: 9.0
agent-8: 12.0
agent-9: 10.0
agent-10: 8.0
agent-11: 6.0
agent-12: 7.0
agent-13: 17.0
agent-14: 5.0
agent-15: 4.0
agent-16: 16.0
agent-17: 9.0
agent-18: 15.0
agent-19: 7.0
agent-20: 7.0
agent-21: 19.0
agent-22: 13.0
agent-23: 9.0
agent-24: 16.0
agent-25: 7.0
agent-26: 7.0
agent-27: 13.0
agent-28: 9.0
agent-29: 16.0
agent-30: 11.0
agent-31: 8.0
agent-32: 11.0
agent-33: 17.0
agent-34: 4.0
agent-35: 9.0
agent-36: 11.0
agent-37: 6.0
agent-38: 14.0
agent-39: 16.0
agent-40: 20.0
Sum Reward: 443.0
Avg Reward: 11.075
Min Reward: 4.0
Max Reward: 20.0
Gini Coefficient: 0.21721218961625283
20:20 Ratio: 3.0
Max-min Ratio: 5.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-08_05-03-24
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 484.0
  episode_reward_mean: 449.4
  episode_reward_min: 424.0
  episodes_this_iter: 1
  episodes_total: 247
  experiment_id: 4e724eb5b3a34f42879644e84578eec0
  hostname: gpu024
  info:
    apply_time_ms: 3.384
    dispatch_time_ms: 5.947
    learner:
      cur_lr: 0.0007019920158199966
      grad_gnorm: 0.22611567378044128
      policy_entropy: 774.9235229492188
      policy_loss: -0.41855740547180176
      var_gnorm: 36.9864501953125
      vf_explained_var: 0.995976984500885
      vf_loss: 2.803363349812571e-05
    num_steps_sampled: 9920000
    num_steps_trained: 9920000
    wait_time_ms: 553.127
  iterations_since_restore: 248
  node_ip: 172.17.8.24
  num_metric_batches_dropped: 0
  pid: 26970
  policy_reward_mean: {}
  time_since_restore: 14010.714747667313
  time_this_iter_s: 56.37775373458862
  time_total_s: 14010.714747667313
  timestamp: 1594199004
  timesteps_since_restore: 9920000
  timesteps_this_iter: 40000
  timesteps_total: 9920000
  training_iteration: 248
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26970], 14010 s, 248 iter, 9920000 ts, 449 rew

agent-1: 7.0
agent-2: 11.0
agent-3: 15.0
agent-4: 7.0
agent-5: 11.0
agent-6: 16.0
agent-7: 13.0
agent-8: 13.0
agent-9: 16.0
agent-10: 7.0
agent-11: 13.0
agent-12: 10.0
agent-13: 10.0
agent-14: 10.0
agent-15: 13.0
agent-16: 11.0
agent-17: 13.0
agent-18: 7.0
agent-19: 5.0
agent-20: 8.0
agent-21: 11.0
agent-22: 11.0
agent-23: 10.0
agent-24: 12.0
agent-25: 23.0
agent-26: 9.0
agent-27: 8.0
agent-28: 9.0
agent-29: 14.0
agent-30: 10.0
agent-31: 17.0
agent-32: 9.0
agent-33: 9.0
agent-34: 9.0
agent-35: 11.0
agent-36: 18.0
agent-37: 15.0
agent-38: 13.0
agent-39: 14.0
agent-40: 5.0
Sum Reward: 453.0
Avg Reward: 11.325
Min Reward: 5.0
Max Reward: 23.0
Gini Coefficient: 0.17577262693156734
20:20 Ratio: 2.4814814814814814
Max-min Ratio: 4.6
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-08_05-04-21
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 484.0
  episode_reward_mean: 449.56
  episode_reward_min: 424.0
  episodes_this_iter: 1
  episodes_total: 248
  experiment_id: 4e724eb5b3a34f42879644e84578eec0
  hostname: gpu024
  info:
    apply_time_ms: 2.539
    dispatch_time_ms: 5.086
    learner:
      cur_lr: 0.0006993280258029699
      grad_gnorm: 1.587719202041626
      policy_entropy: 765.3412475585938
      policy_loss: 2.6671268939971924
      var_gnorm: 37.006927490234375
      vf_explained_var: 5.561113357543945e-05
      vf_loss: 4.515086402534507e-06
    num_steps_sampled: 9960000
    num_steps_trained: 9960000
    wait_time_ms: 568.003
  iterations_since_restore: 249
  node_ip: 172.17.8.24
  num_metric_batches_dropped: 0
  pid: 26970
  policy_reward_mean: {}
  time_since_restore: 14067.374243021011
  time_this_iter_s: 56.65949535369873
  time_total_s: 14067.374243021011
  timestamp: 1594199061
  timesteps_since_restore: 9960000
  timesteps_this_iter: 40000
  timesteps_total: 9960000
  training_iteration: 249
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26970], 14067 s, 249 iter, 9960000 ts, 450 rew

agent-1: 16.0
agent-2: 10.0
agent-3: 15.0
agent-4: 2.0
agent-5: 9.0
agent-6: 14.0
agent-7: 15.0
agent-8: 7.0
agent-9: 9.0
agent-10: 11.0
agent-11: 14.0
agent-12: 19.0
agent-13: 14.0
agent-14: 13.0
agent-15: 14.0
agent-16: 13.0
agent-17: 16.0
agent-18: 13.0
agent-19: 13.0
agent-20: 11.0
agent-21: 7.0
agent-22: 3.0
agent-23: 7.0
agent-24: 9.0
agent-25: 15.0
agent-26: 15.0
agent-27: 13.0
agent-28: 13.0
agent-29: 15.0
agent-30: 8.0
agent-31: 14.0
agent-32: 12.0
agent-33: 12.0
agent-34: 2.0
agent-35: 3.0
agent-36: 16.0
agent-37: 17.0
agent-38: 10.0
agent-39: 14.0
agent-40: 16.0
Sum Reward: 469.0
Avg Reward: 11.725
Min Reward: 2.0
Max Reward: 19.0
Gini Coefficient: 0.19418976545842218
20:20 Ratio: 3.3333333333333335
Max-min Ratio: 9.5
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-08_05-05-17
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 484.0
  episode_reward_mean: 449.83
  episode_reward_min: 424.0
  episodes_this_iter: 1
  episodes_total: 249
  experiment_id: 4e724eb5b3a34f42879644e84578eec0
  hostname: gpu024
  info:
    apply_time_ms: 2.628
    dispatch_time_ms: 5.405
    learner:
      cur_lr: 0.0006966639775782824
      grad_gnorm: 2.013903856277466
      policy_entropy: 768.354736328125
      policy_loss: -0.44059014320373535
      var_gnorm: 37.05309295654297
      vf_explained_var: 0.9959522485733032
      vf_loss: 0.012865463271737099
    num_steps_sampled: 10000000
    num_steps_trained: 10000000
    wait_time_ms: 557.22
  iterations_since_restore: 250
  node_ip: 172.17.8.24
  num_metric_batches_dropped: 0
  pid: 26970
  policy_reward_mean: {}
  time_since_restore: 14123.418479919434
  time_this_iter_s: 56.04423689842224
  time_total_s: 14123.418479919434
  timestamp: 1594199117
  timesteps_since_restore: 10000000
  timesteps_this_iter: 40000
  timesteps_total: 10000000
  training_iteration: 250
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26970], 14123 s, 250 iter, 10000000 ts, 450 rew

agent-1: 5.0
agent-2: 10.0
agent-3: 11.0
agent-4: 16.0
agent-5: 8.0
agent-6: 9.0
agent-7: 17.0
agent-8: 8.0
agent-9: 10.0
agent-10: 10.0
agent-11: 10.0
agent-12: 14.0
agent-13: 11.0
agent-14: 18.0
agent-15: 9.0
agent-16: 9.0
agent-17: 6.0
agent-18: 14.0
agent-19: 18.0
agent-20: 12.0
agent-21: 10.0
agent-22: 6.0
agent-23: 14.0
agent-24: 13.0
agent-25: 10.0
agent-26: 10.0
agent-27: 12.0
agent-28: 17.0
agent-29: 7.0
agent-30: 18.0
agent-31: 10.0
agent-32: 11.0
agent-33: 18.0
agent-34: 15.0
agent-35: 11.0
agent-36: 8.0
agent-37: 9.0
agent-38: 14.0
agent-39: 12.0
agent-40: 3.0
Sum Reward: 453.0
Avg Reward: 11.325
Min Reward: 3.0
Max Reward: 18.0
Gini Coefficient: 0.18603752759381897
20:20 Ratio: 2.6862745098039214
Max-min Ratio: 6.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-08_05-06-14
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 484.0
  episode_reward_mean: 449.84
  episode_reward_min: 424.0
  episodes_this_iter: 1
  episodes_total: 250
  experiment_id: 4e724eb5b3a34f42879644e84578eec0
  hostname: gpu024
  info:
    apply_time_ms: 3.101
    dispatch_time_ms: 6.918
    learner:
      cur_lr: 0.0006939999875612557
      grad_gnorm: 9.887103080749512
      policy_entropy: 756.6771240234375
      policy_loss: -6.747237682342529
      var_gnorm: 37.09077835083008
      vf_explained_var: 2.1517276763916016e-05
      vf_loss: 0.015085364691913128
    num_steps_sampled: 10040000
    num_steps_trained: 10040000
    wait_time_ms: 557.403
  iterations_since_restore: 251
  node_ip: 172.17.8.24
  num_metric_batches_dropped: 0
  pid: 26970
  policy_reward_mean: {}
  time_since_restore: 14180.263429403305
  time_this_iter_s: 56.84494948387146
  time_total_s: 14180.263429403305
  timestamp: 1594199174
  timesteps_since_restore: 10040000
  timesteps_this_iter: 40000
  timesteps_total: 10040000
  training_iteration: 251
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26970], 14180 s, 251 iter, 10040000 ts, 450 rew

agent-1: 19.0
agent-2: 7.0
agent-3: 11.0
agent-4: 16.0
agent-5: 10.0
agent-6: 11.0
agent-7: 6.0
agent-8: 13.0
agent-9: 16.0
agent-10: 6.0
agent-11: 18.0
agent-12: 7.0
agent-13: 10.0
agent-14: 8.0
agent-15: 12.0
agent-16: 9.0
agent-17: 14.0
agent-18: 11.0
agent-19: 16.0
agent-20: 15.0
agent-21: 8.0
agent-22: 7.0
agent-23: 18.0
agent-24: 13.0
agent-25: 8.0
agent-26: 15.0
agent-27: 7.0
agent-28: 11.0
agent-29: 16.0
agent-30: 12.0
agent-31: 7.0
agent-32: 13.0
agent-33: 19.0
agent-34: 3.0
agent-35: 9.0
agent-36: 8.0
agent-37: 15.0
agent-38: 10.0
agent-39: 5.0
agent-40: 8.0
Sum Reward: 447.0
Avg Reward: 11.175
Min Reward: 3.0
Max Reward: 19.0
Gini Coefficient: 0.2105704697986577
20:20 Ratio: 2.875
Max-min Ratio: 6.333333333333333
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-08_05-07-10
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 484.0
  episode_reward_mean: 449.74
  episode_reward_min: 424.0
  episodes_this_iter: 1
  episodes_total: 251
  experiment_id: 4e724eb5b3a34f42879644e84578eec0
  hostname: gpu024
  info:
    apply_time_ms: 2.752
    dispatch_time_ms: 6.049
    learner:
      cur_lr: 0.000691335997544229
      grad_gnorm: 1.9300347566604614
      policy_entropy: 765.7646484375
      policy_loss: -1.1439898014068604
      var_gnorm: 37.112754821777344
      vf_explained_var: -0.31697797775268555
      vf_loss: 0.0006112289847806096
    num_steps_sampled: 10080000
    num_steps_trained: 10080000
    wait_time_ms: 548.716
  iterations_since_restore: 252
  node_ip: 172.17.8.24
  num_metric_batches_dropped: 0
  pid: 26970
  policy_reward_mean: {}
  time_since_restore: 14236.875167369843
  time_this_iter_s: 56.611737966537476
  time_total_s: 14236.875167369843
  timestamp: 1594199230
  timesteps_since_restore: 10080000
  timesteps_this_iter: 40000
  timesteps_total: 10080000
  training_iteration: 252
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26970], 14236 s, 252 iter, 10080000 ts, 450 rew

agent-1: 10.0
agent-2: 16.0
agent-3: 9.0
agent-4: 11.0
agent-5: 7.0
agent-6: 16.0
agent-7: 10.0
agent-8: 14.0
agent-9: 9.0
agent-10: 14.0
agent-11: 14.0
agent-12: 9.0
agent-13: 11.0
agent-14: 15.0
agent-15: 13.0
agent-16: 7.0
agent-17: 7.0
agent-18: 12.0
agent-19: 9.0
agent-20: 12.0
agent-21: 9.0
agent-22: 15.0
agent-23: 13.0
agent-24: 12.0
agent-25: 8.0
agent-26: 11.0
agent-27: 17.0
agent-28: 13.0
agent-29: 10.0
agent-30: 12.0
agent-31: 10.0
agent-32: 14.0
agent-33: 12.0
agent-34: 12.0
agent-35: 6.0
agent-36: 7.0
agent-37: 10.0
agent-38: 4.0
agent-39: 7.0
agent-40: 7.0
Sum Reward: 434.0
Avg Reward: 10.85
Min Reward: 4.0
Max Reward: 17.0
Gini Coefficient: 0.16059907834101383
20:20 Ratio: 2.326923076923077
Max-min Ratio: 4.25
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-08_05-08-07
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 484.0
  episode_reward_mean: 449.55
  episode_reward_min: 424.0
  episodes_this_iter: 1
  episodes_total: 252
  experiment_id: 4e724eb5b3a34f42879644e84578eec0
  hostname: gpu024
  info:
    apply_time_ms: 2.94
    dispatch_time_ms: 6.179
    learner:
      cur_lr: 0.0006886720075272024
      grad_gnorm: 1.391777753829956
      policy_entropy: 772.000244140625
      policy_loss: -0.5368514060974121
      var_gnorm: 37.0975341796875
      vf_explained_var: -1.0
      vf_loss: 0.01729537546634674
    num_steps_sampled: 10120000
    num_steps_trained: 10120000
    wait_time_ms: 556.299
  iterations_since_restore: 253
  node_ip: 172.17.8.24
  num_metric_batches_dropped: 0
  pid: 26970
  policy_reward_mean: {}
  time_since_restore: 14293.476615667343
  time_this_iter_s: 56.60144829750061
  time_total_s: 14293.476615667343
  timestamp: 1594199287
  timesteps_since_restore: 10120000
  timesteps_this_iter: 40000
  timesteps_total: 10120000
  training_iteration: 253
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26970], 14293 s, 253 iter, 10120000 ts, 450 rew

agent-1: 8.0
agent-2: 10.0
agent-3: 15.0
agent-4: 15.0
agent-5: 13.0
agent-6: 11.0
agent-7: 11.0
agent-8: 10.0
agent-9: 10.0
agent-10: 14.0
agent-11: 9.0
agent-12: 14.0
agent-13: 8.0
agent-14: 11.0
agent-15: 9.0
agent-16: 4.0
agent-17: 11.0
agent-18: 6.0
agent-19: 9.0
agent-20: 9.0
agent-21: 15.0
agent-22: 16.0
agent-23: 11.0
agent-24: 12.0
agent-25: 10.0
agent-26: 11.0
agent-27: 20.0
agent-28: 13.0
agent-29: 9.0
agent-30: 9.0
agent-31: 0.0
agent-32: 9.0
agent-33: 1.0
agent-34: 11.0
agent-35: 18.0
agent-36: 15.0
agent-37: 13.0
agent-38: 14.0
agent-39: 14.0
agent-40: 11.0
Sum Reward: 439.0
Avg Reward: 10.975
Min Reward: 0.0
Max Reward: 20.0
Gini Coefficient: 0.19094533029612756
20:20 Ratio: 2.8444444444444446
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-08_05-09-03
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 484.0
  episode_reward_mean: 449.6
  episode_reward_min: 424.0
  episodes_this_iter: 1
  episodes_total: 253
  experiment_id: 4e724eb5b3a34f42879644e84578eec0
  hostname: gpu024
  info:
    apply_time_ms: 2.686
    dispatch_time_ms: 5.162
    learner:
      cur_lr: 0.0006860080175101757
      grad_gnorm: 3.603698492050171
      policy_entropy: 775.33203125
      policy_loss: 1.5786833763122559
      var_gnorm: 37.124656677246094
      vf_explained_var: -0.8343420028686523
      vf_loss: 0.0023131645284593105
    num_steps_sampled: 10160000
    num_steps_trained: 10160000
    wait_time_ms: 559.098
  iterations_since_restore: 254
  node_ip: 172.17.8.24
  num_metric_batches_dropped: 0
  pid: 26970
  policy_reward_mean: {}
  time_since_restore: 14349.927825927734
  time_this_iter_s: 56.451210260391235
  time_total_s: 14349.927825927734
  timestamp: 1594199343
  timesteps_since_restore: 10160000
  timesteps_this_iter: 40000
  timesteps_total: 10160000
  training_iteration: 254
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26970], 14349 s, 254 iter, 10160000 ts, 450 rew

agent-1: 10.0
agent-2: 7.0
agent-3: 12.0
agent-4: 14.0
agent-5: 7.0
agent-6: 12.0
agent-7: 18.0
agent-8: 13.0
agent-9: 8.0
agent-10: 15.0
agent-11: 13.0
agent-12: 13.0
agent-13: 8.0
agent-14: 13.0
agent-15: 15.0
agent-16: 12.0
agent-17: 12.0
agent-18: 21.0
agent-19: 10.0
agent-20: 9.0
agent-21: 13.0
agent-22: 5.0
agent-23: 9.0
agent-24: 10.0
agent-25: 11.0
agent-26: 12.0
agent-27: 11.0
agent-28: 10.0
agent-29: 8.0
agent-30: 9.0
agent-31: 17.0
agent-32: 6.0
agent-33: 17.0
agent-34: 14.0
agent-35: 17.0
agent-36: 15.0
agent-37: 11.0
agent-38: 10.0
agent-39: 14.0
agent-40: 7.0
Sum Reward: 468.0
Avg Reward: 11.7
Min Reward: 5.0
Max Reward: 21.0
Gini Coefficient: 0.16826923076923078
20:20 Ratio: 2.4107142857142856
Max-min Ratio: 4.2
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-08_05-10-00
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 484.0
  episode_reward_mean: 449.84
  episode_reward_min: 424.0
  episodes_this_iter: 1
  episodes_total: 254
  experiment_id: 4e724eb5b3a34f42879644e84578eec0
  hostname: gpu024
  info:
    apply_time_ms: 2.548
    dispatch_time_ms: 7.322
    learner:
      cur_lr: 0.000683344027493149
      grad_gnorm: 10.032699584960938
      policy_entropy: 760.65087890625
      policy_loss: 0.7167031168937683
      var_gnorm: 37.209964752197266
      vf_explained_var: -1.0
      vf_loss: 0.0320998840034008
    num_steps_sampled: 10200000
    num_steps_trained: 10200000
    wait_time_ms: 566.783
  iterations_since_restore: 255
  node_ip: 172.17.8.24
  num_metric_batches_dropped: 0
  pid: 26970
  policy_reward_mean: {}
  time_since_restore: 14406.53934764862
  time_this_iter_s: 56.61152172088623
  time_total_s: 14406.53934764862
  timestamp: 1594199400
  timesteps_since_restore: 10200000
  timesteps_this_iter: 40000
  timesteps_total: 10200000
  training_iteration: 255
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26970], 14406 s, 255 iter, 10200000 ts, 450 rew

agent-1: 3.0
agent-2: 12.0
agent-3: 11.0
agent-4: 11.0
agent-5: 11.0
agent-6: 20.0
agent-7: 13.0
agent-8: 14.0
agent-9: 5.0
agent-10: 15.0
agent-11: 5.0
agent-12: 12.0
agent-13: 2.0
agent-14: 12.0
agent-15: 3.0
agent-16: 17.0
agent-17: 9.0
agent-18: 12.0
agent-19: 13.0
agent-20: 19.0
agent-21: 8.0
agent-22: 12.0
agent-23: 5.0
agent-24: 11.0
agent-25: 17.0
agent-26: 11.0
agent-27: 6.0
agent-28: 9.0
agent-29: 13.0
agent-30: 15.0
agent-31: 9.0
agent-32: 6.0
agent-33: 14.0
agent-34: 13.0
agent-35: 17.0
agent-36: 10.0
agent-37: 11.0
agent-38: 7.0
agent-39: 13.0
agent-40: 17.0
Sum Reward: 443.0
Avg Reward: 11.075
Min Reward: 2.0
Max Reward: 20.0
Gini Coefficient: 0.2226297968397291
20:20 Ratio: 3.914285714285714
Max-min Ratio: 10.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-08_05-10-57
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 484.0
  episode_reward_mean: 449.73
  episode_reward_min: 424.0
  episodes_this_iter: 1
  episodes_total: 255
  experiment_id: 4e724eb5b3a34f42879644e84578eec0
  hostname: gpu024
  info:
    apply_time_ms: 2.884
    dispatch_time_ms: 5.949
    learner:
      cur_lr: 0.0006806799792684615
      grad_gnorm: 1.094912052154541
      policy_entropy: 768.995849609375
      policy_loss: -0.09564509987831116
      var_gnorm: 37.234764099121094
      vf_explained_var: -1.0
      vf_loss: 0.00045336814946494997
    num_steps_sampled: 10240000
    num_steps_trained: 10240000
    wait_time_ms: 567.306
  iterations_since_restore: 256
  node_ip: 172.17.8.24
  num_metric_batches_dropped: 0
  pid: 26970
  policy_reward_mean: {}
  time_since_restore: 14463.270881652832
  time_this_iter_s: 56.731534004211426
  time_total_s: 14463.270881652832
  timestamp: 1594199457
  timesteps_since_restore: 10240000
  timesteps_this_iter: 40000
  timesteps_total: 10240000
  training_iteration: 256
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26970], 14463 s, 256 iter, 10240000 ts, 450 rew

agent-1: 11.0
agent-2: 6.0
agent-3: 11.0
agent-4: 4.0
agent-5: 9.0
agent-6: 16.0
agent-7: 21.0
agent-8: 13.0
agent-9: 10.0
agent-10: 7.0
agent-11: 16.0
agent-12: 11.0
agent-13: 12.0
agent-14: 16.0
agent-15: 9.0
agent-16: 15.0
agent-17: 6.0
agent-18: 15.0
agent-19: 13.0
agent-20: 20.0
agent-21: 9.0
agent-22: 18.0
agent-23: 17.0
agent-24: 8.0
agent-25: 8.0
agent-26: 13.0
agent-27: 13.0
agent-28: 18.0
agent-29: 14.0
agent-30: 8.0
agent-31: 15.0
agent-32: 6.0
agent-33: 16.0
agent-34: 6.0
agent-35: 11.0
agent-36: 10.0
agent-37: 7.0
agent-38: 5.0
agent-39: 13.0
agent-40: 10.0
Sum Reward: 466.0
Avg Reward: 11.65
Min Reward: 4.0
Max Reward: 21.0
Gini Coefficient: 0.21030042918454936
20:20 Ratio: 3.021276595744681
Max-min Ratio: 5.25
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-08_05-11-53
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 484.0
  episode_reward_mean: 449.97
  episode_reward_min: 424.0
  episodes_this_iter: 1
  episodes_total: 256
  experiment_id: 4e724eb5b3a34f42879644e84578eec0
  hostname: gpu024
  info:
    apply_time_ms: 3.299
    dispatch_time_ms: 7.42
    learner:
      cur_lr: 0.0006780159892514348
      grad_gnorm: 0.9214054942131042
      policy_entropy: 775.980224609375
      policy_loss: 0.4386172592639923
      var_gnorm: 37.22657012939453
      vf_explained_var: -1.0
      vf_loss: 0.0006200532079674304
    num_steps_sampled: 10280000
    num_steps_trained: 10280000
    wait_time_ms: 555.904
  iterations_since_restore: 257
  node_ip: 172.17.8.24
  num_metric_batches_dropped: 0
  pid: 26970
  policy_reward_mean: {}
  time_since_restore: 14519.437330961227
  time_this_iter_s: 56.166449308395386
  time_total_s: 14519.437330961227
  timestamp: 1594199513
  timesteps_since_restore: 10280000
  timesteps_this_iter: 40000
  timesteps_total: 10280000
  training_iteration: 257
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26970], 14519 s, 257 iter, 10280000 ts, 450 rew

agent-1: 13.0
agent-2: 7.0
agent-3: 13.0
agent-4: 14.0
agent-5: 14.0
agent-6: 19.0
agent-7: 7.0
agent-8: 14.0
agent-9: 8.0
agent-10: 12.0
agent-11: 10.0
agent-12: 15.0
agent-13: 10.0
agent-14: 13.0
agent-15: 14.0
agent-16: 17.0
agent-17: 12.0
agent-18: 12.0
agent-19: 11.0
agent-20: 18.0
agent-21: 9.0
agent-22: 7.0
agent-23: 7.0
agent-24: 13.0
agent-25: 17.0
agent-26: 14.0
agent-27: 3.0
agent-28: 9.0
agent-29: 11.0
agent-30: 1.0
agent-31: 13.0
agent-32: 10.0
agent-33: 8.0
agent-34: 8.0
agent-35: 14.0
agent-36: 9.0
agent-37: 8.0
agent-38: 9.0
agent-39: 7.0
agent-40: 9.0
Sum Reward: 439.0
Avg Reward: 10.975
Min Reward: 1.0
Max Reward: 19.0
Gini Coefficient: 0.19333712984054668
20:20 Ratio: 2.723404255319149
Max-min Ratio: 19.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-08_05-12-50
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 484.0
  episode_reward_mean: 449.89
  episode_reward_min: 424.0
  episodes_this_iter: 1
  episodes_total: 257
  experiment_id: 4e724eb5b3a34f42879644e84578eec0
  hostname: gpu024
  info:
    apply_time_ms: 2.545
    dispatch_time_ms: 7.946
    learner:
      cur_lr: 0.0006753519992344081
      grad_gnorm: 1.3193614482879639
      policy_entropy: 777.8380126953125
      policy_loss: 1.2630778551101685
      var_gnorm: 37.253543853759766
      vf_explained_var: -1.0
      vf_loss: 0.0004467663529794663
    num_steps_sampled: 10320000
    num_steps_trained: 10320000
    wait_time_ms: 552.9
  iterations_since_restore: 258
  node_ip: 172.17.8.24
  num_metric_batches_dropped: 0
  pid: 26970
  policy_reward_mean: {}
  time_since_restore: 14575.985423088074
  time_this_iter_s: 56.54809212684631
  time_total_s: 14575.985423088074
  timestamp: 1594199570
  timesteps_since_restore: 10320000
  timesteps_this_iter: 40000
  timesteps_total: 10320000
  training_iteration: 258
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26970], 14575 s, 258 iter, 10320000 ts, 450 rew

agent-1: 15.0
agent-2: 8.0
agent-3: 9.0
agent-4: 7.0
agent-5: 15.0
agent-6: 4.0
agent-7: 7.0
agent-8: 9.0
agent-9: 12.0
agent-10: 18.0
agent-11: 14.0
agent-12: 18.0
agent-13: 11.0
agent-14: 10.0
agent-15: 10.0
agent-16: 7.0
agent-17: 10.0
agent-18: 14.0
agent-19: 13.0
agent-20: 16.0
agent-21: 14.0
agent-22: 8.0
agent-23: 10.0
agent-24: 10.0
agent-25: 9.0
agent-26: 9.0
agent-27: 12.0
agent-28: 11.0
agent-29: 7.0
agent-30: 8.0
agent-31: 6.0
agent-32: 11.0
agent-33: 12.0
agent-34: 5.0
agent-35: 10.0
agent-36: 13.0
agent-37: 9.0
agent-38: 13.0
agent-39: 11.0
agent-40: 8.0
Sum Reward: 423.0
Avg Reward: 10.575
Min Reward: 4.0
Max Reward: 18.0
Gini Coefficient: 0.1733451536643026
20:20 Ratio: 2.4313725490196076
Max-min Ratio: 4.5
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-08_05-13-47
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 484.0
  episode_reward_mean: 449.77
  episode_reward_min: 423.0
  episodes_this_iter: 1
  episodes_total: 258
  experiment_id: 4e724eb5b3a34f42879644e84578eec0
  hostname: gpu024
  info:
    apply_time_ms: 2.929
    dispatch_time_ms: 6.987
    learner:
      cur_lr: 0.0006726880092173815
      grad_gnorm: 1.1731526851654053
      policy_entropy: 777.0363159179688
      policy_loss: -1.1053184270858765
      var_gnorm: 37.27498245239258
      vf_explained_var: -1.0
      vf_loss: 0.012541884556412697
    num_steps_sampled: 10360000
    num_steps_trained: 10360000
    wait_time_ms: 572.391
  iterations_since_restore: 259
  node_ip: 172.17.8.24
  num_metric_batches_dropped: 0
  pid: 26970
  policy_reward_mean: {}
  time_since_restore: 14632.887268543243
  time_this_iter_s: 56.90184545516968
  time_total_s: 14632.887268543243
  timestamp: 1594199627
  timesteps_since_restore: 10360000
  timesteps_this_iter: 40000
  timesteps_total: 10360000
  training_iteration: 259
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26970], 14632 s, 259 iter, 10360000 ts, 450 rew

agent-1: 6.0
agent-2: 10.0
agent-3: 12.0
agent-4: 11.0
agent-5: 13.0
agent-6: 10.0
agent-7: 8.0
agent-8: 14.0
agent-9: 15.0
agent-10: 14.0
agent-11: 15.0
agent-12: 11.0
agent-13: 14.0
agent-14: 19.0
agent-15: 16.0
agent-16: 8.0
agent-17: 5.0
agent-18: 5.0
agent-19: 13.0
agent-20: 14.0
agent-21: 11.0
agent-22: 10.0
agent-23: 7.0
agent-24: 11.0
agent-25: 9.0
agent-26: 14.0
agent-27: 6.0
agent-28: 8.0
agent-29: 7.0
agent-30: 10.0
agent-31: 13.0
agent-32: 12.0
agent-33: 9.0
agent-34: 16.0
agent-35: 7.0
agent-36: 12.0
agent-37: 16.0
agent-38: 6.0
agent-39: 8.0
agent-40: 16.0
Sum Reward: 441.0
Avg Reward: 11.025
Min Reward: 5.0
Max Reward: 19.0
Gini Coefficient: 0.18327664399092972
20:20 Ratio: 2.5918367346938775
Max-min Ratio: 3.8
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-08_05-14-43
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 484.0
  episode_reward_mean: 449.77
  episode_reward_min: 423.0
  episodes_this_iter: 1
  episodes_total: 259
  experiment_id: 4e724eb5b3a34f42879644e84578eec0
  hostname: gpu024
  info:
    apply_time_ms: 2.774
    dispatch_time_ms: 7.286
    learner:
      cur_lr: 0.0006700240192003548
      grad_gnorm: 5.9302568435668945
      policy_entropy: 762.0506591796875
      policy_loss: 0.7047439813613892
      var_gnorm: 37.271419525146484
      vf_explained_var: -0.9013911485671997
      vf_loss: 0.12950417399406433
    num_steps_sampled: 10400000
    num_steps_trained: 10400000
    wait_time_ms: 532.529
  iterations_since_restore: 260
  node_ip: 172.17.8.24
  num_metric_batches_dropped: 0
  pid: 26970
  policy_reward_mean: {}
  time_since_restore: 14689.003702402115
  time_this_iter_s: 56.11643385887146
  time_total_s: 14689.003702402115
  timestamp: 1594199683
  timesteps_since_restore: 10400000
  timesteps_this_iter: 40000
  timesteps_total: 10400000
  training_iteration: 260
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26970], 14689 s, 260 iter, 10400000 ts, 450 rew

agent-1: 6.0
agent-2: 11.0
agent-3: 21.0
agent-4: 14.0
agent-5: 13.0
agent-6: 15.0
agent-7: 18.0
agent-8: 16.0
agent-9: 11.0
agent-10: 12.0
agent-11: 13.0
agent-12: 11.0
agent-13: 12.0
agent-14: 8.0
agent-15: 10.0
agent-16: 7.0
agent-17: 9.0
agent-18: 9.0
agent-19: 9.0
agent-20: 13.0
agent-21: 5.0
agent-22: 5.0
agent-23: 18.0
agent-24: 13.0
agent-25: 13.0
agent-26: 13.0
agent-27: 13.0
agent-28: 10.0
agent-29: 10.0
agent-30: 9.0
agent-31: 9.0
agent-32: 7.0
agent-33: 10.0
agent-34: 12.0
agent-35: 18.0
agent-36: 12.0
agent-37: 8.0
agent-38: 10.0
agent-39: 8.0
agent-40: 13.0
Sum Reward: 454.0
Avg Reward: 11.35
Min Reward: 5.0
Max Reward: 21.0
Gini Coefficient: 0.1736784140969163
20:20 Ratio: 2.462962962962963
Max-min Ratio: 4.2
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-08_05-15-40
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 484.0
  episode_reward_mean: 449.75
  episode_reward_min: 423.0
  episodes_this_iter: 1
  episodes_total: 260
  experiment_id: 4e724eb5b3a34f42879644e84578eec0
  hostname: gpu024
  info:
    apply_time_ms: 3.233
    dispatch_time_ms: 5.535
    learner:
      cur_lr: 0.0006673599709756672
      grad_gnorm: 32.87602233886719
      policy_entropy: 752.0457763671875
      policy_loss: 11.489116668701172
      var_gnorm: 37.366790771484375
      vf_explained_var: 0.7668694853782654
      vf_loss: 7.005998611450195
    num_steps_sampled: 10440000
    num_steps_trained: 10440000
    wait_time_ms: 560.089
  iterations_since_restore: 261
  node_ip: 172.17.8.24
  num_metric_batches_dropped: 0
  pid: 26970
  policy_reward_mean: {}
  time_since_restore: 14745.833004951477
  time_this_iter_s: 56.82930254936218
  time_total_s: 14745.833004951477
  timestamp: 1594199740
  timesteps_since_restore: 10440000
  timesteps_this_iter: 40000
  timesteps_total: 10440000
  training_iteration: 261
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26970], 14745 s, 261 iter, 10440000 ts, 450 rew

agent-1: 12.0
agent-2: 13.0
agent-3: 21.0
agent-4: 15.0
agent-5: 10.0
agent-6: 12.0
agent-7: 6.0
agent-8: 8.0
agent-9: 8.0
agent-10: 7.0
agent-11: 12.0
agent-12: 13.0
agent-13: 6.0
agent-14: 6.0
agent-15: 13.0
agent-16: 9.0
agent-17: 10.0
agent-18: 20.0
agent-19: 17.0
agent-20: 8.0
agent-21: 17.0
agent-22: 8.0
agent-23: 6.0
agent-24: 11.0
agent-25: 16.0
agent-26: 11.0
agent-27: 5.0
agent-28: 11.0
agent-29: 8.0
agent-30: 12.0
agent-31: 12.0
agent-32: 13.0
agent-33: 10.0
agent-34: 17.0
agent-35: 11.0
agent-36: 13.0
agent-37: 11.0
agent-38: 9.0
agent-39: 14.0
agent-40: 9.0
Sum Reward: 450.0
Avg Reward: 11.25
Min Reward: 5.0
Max Reward: 21.0
Gini Coefficient: 0.18733333333333332
20:20 Ratio: 2.6346153846153846
Max-min Ratio: 4.2
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-08_05-16-36
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 484.0
  episode_reward_mean: 449.86
  episode_reward_min: 423.0
  episodes_this_iter: 1
  episodes_total: 261
  experiment_id: 4e724eb5b3a34f42879644e84578eec0
  hostname: gpu024
  info:
    apply_time_ms: 2.498
    dispatch_time_ms: 6.263
    learner:
      cur_lr: 0.0006646959809586406
      grad_gnorm: 1.1696642637252808
      policy_entropy: 762.2584228515625
      policy_loss: 0.36410242319107056
      var_gnorm: 37.37152099609375
      vf_explained_var: -1.0
      vf_loss: 0.00030569342197850347
    num_steps_sampled: 10480000
    num_steps_trained: 10480000
    wait_time_ms: 566.728
  iterations_since_restore: 262
  node_ip: 172.17.8.24
  num_metric_batches_dropped: 0
  pid: 26970
  policy_reward_mean: {}
  time_since_restore: 14802.031836986542
  time_this_iter_s: 56.1988320350647
  time_total_s: 14802.031836986542
  timestamp: 1594199796
  timesteps_since_restore: 10480000
  timesteps_this_iter: 40000
  timesteps_total: 10480000
  training_iteration: 262
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26970], 14802 s, 262 iter, 10480000 ts, 450 rew

agent-1: 12.0
agent-2: 17.0
agent-3: 13.0
agent-4: 9.0
agent-5: 11.0
agent-6: 11.0
agent-7: 6.0
agent-8: 8.0
agent-9: 9.0
agent-10: 10.0
agent-11: 10.0
agent-12: 12.0
agent-13: 8.0
agent-14: 9.0
agent-15: 11.0
agent-16: 8.0
agent-17: 8.0
agent-18: 6.0
agent-19: 15.0
agent-20: 10.0
agent-21: 10.0
agent-22: 6.0
agent-23: 12.0
agent-24: 15.0
agent-25: 17.0
agent-26: 13.0
agent-27: 9.0
agent-28: 13.0
agent-29: 10.0
agent-30: 7.0
agent-31: 11.0
agent-32: 9.0
agent-33: 11.0
agent-34: 13.0
agent-35: 12.0
agent-36: 12.0
agent-37: 12.0
agent-38: 16.0
agent-39: 7.0
agent-40: 17.0
Sum Reward: 435.0
Avg Reward: 10.875
Min Reward: 6.0
Max Reward: 17.0
Gini Coefficient: 0.15373563218390804
20:20 Ratio: 2.1964285714285716
Max-min Ratio: 2.8333333333333335
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-08_05-17-33
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 484.0
  episode_reward_mean: 449.8
  episode_reward_min: 423.0
  episodes_this_iter: 1
  episodes_total: 262
  experiment_id: 4e724eb5b3a34f42879644e84578eec0
  hostname: gpu024
  info:
    apply_time_ms: 2.497
    dispatch_time_ms: 6.283
    learner:
      cur_lr: 0.0006620319909416139
      grad_gnorm: 1.0440441370010376
      policy_entropy: 767.4654541015625
      policy_loss: 0.3196265995502472
      var_gnorm: 37.40190124511719
      vf_explained_var: -1.0
      vf_loss: 0.00018446266767568886
    num_steps_sampled: 10520000
    num_steps_trained: 10520000
    wait_time_ms: 577.178
  iterations_since_restore: 263
  node_ip: 172.17.8.24
  num_metric_batches_dropped: 0
  pid: 26970
  policy_reward_mean: {}
  time_since_restore: 14858.701253175735
  time_this_iter_s: 56.669416189193726
  time_total_s: 14858.701253175735
  timestamp: 1594199853
  timesteps_since_restore: 10520000
  timesteps_this_iter: 40000
  timesteps_total: 10520000
  training_iteration: 263
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26970], 14858 s, 263 iter, 10520000 ts, 450 rew

agent-1: 11.0
agent-2: 12.0
agent-3: 13.0
agent-4: 8.0
agent-5: 12.0
agent-6: 11.0
agent-7: 8.0
agent-8: 4.0
agent-9: 9.0
agent-10: 6.0
agent-11: 8.0
agent-12: 9.0
agent-13: 11.0
agent-14: 13.0
agent-15: 17.0
agent-16: 18.0
agent-17: 11.0
agent-18: 14.0
agent-19: 12.0
agent-20: 11.0
agent-21: 10.0
agent-22: 9.0
agent-23: 11.0
agent-24: 13.0
agent-25: 9.0
agent-26: 11.0
agent-27: 14.0
agent-28: 7.0
agent-29: 12.0
agent-30: 16.0
agent-31: 8.0
agent-32: 11.0
agent-33: 14.0
agent-34: 10.0
agent-35: 10.0
agent-36: 12.0
agent-37: 13.0
agent-38: 7.0
agent-39: 9.0
agent-40: 16.0
Sum Reward: 440.0
Avg Reward: 11.0
Min Reward: 4.0
Max Reward: 18.0
Gini Coefficient: 0.14920454545454545
20:20 Ratio: 2.1785714285714284
Max-min Ratio: 4.5
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-08_05-18-29
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 484.0
  episode_reward_mean: 449.74
  episode_reward_min: 423.0
  episodes_this_iter: 1
  episodes_total: 263
  experiment_id: 4e724eb5b3a34f42879644e84578eec0
  hostname: gpu024
  info:
    apply_time_ms: 2.713
    dispatch_time_ms: 6.502
    learner:
      cur_lr: 0.0006593680009245872
      grad_gnorm: 0.8918811082839966
      policy_entropy: 765.9603881835938
      policy_loss: 0.31734222173690796
      var_gnorm: 37.426658630371094
      vf_explained_var: -0.5773154497146606
      vf_loss: 0.00013698455586563796
    num_steps_sampled: 10560000
    num_steps_trained: 10560000
    wait_time_ms: 548.189
  iterations_since_restore: 264
  node_ip: 172.17.8.24
  num_metric_batches_dropped: 0
  pid: 26970
  policy_reward_mean: {}
  time_since_restore: 14914.853136777878
  time_this_iter_s: 56.151883602142334
  time_total_s: 14914.853136777878
  timestamp: 1594199909
  timesteps_since_restore: 10560000
  timesteps_this_iter: 40000
  timesteps_total: 10560000
  training_iteration: 264
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26970], 14914 s, 264 iter, 10560000 ts, 450 rew

agent-1: 10.0
agent-2: 6.0
agent-3: 10.0
agent-4: 12.0
agent-5: 6.0
agent-6: 14.0
agent-7: 10.0
agent-8: 9.0
agent-9: 10.0
agent-10: 9.0
agent-11: 12.0
agent-12: 12.0
agent-13: 7.0
agent-14: 12.0
agent-15: 13.0
agent-16: 8.0
agent-17: 13.0
agent-18: 9.0
agent-19: 9.0
agent-20: 12.0
agent-21: 11.0
agent-22: 14.0
agent-23: 10.0
agent-24: 7.0
agent-25: 13.0
agent-26: 10.0
agent-27: 13.0
agent-28: 14.0
agent-29: 15.0
agent-30: 9.0
agent-31: 14.0
agent-32: 14.0
agent-33: 7.0
agent-34: 12.0
agent-35: 16.0
agent-36: 4.0
agent-37: 14.0
agent-38: 18.0
agent-39: 8.0
agent-40: 11.0
Sum Reward: 437.0
Avg Reward: 10.925
Min Reward: 4.0
Max Reward: 18.0
Gini Coefficient: 0.15406178489702518
20:20 Ratio: 2.2452830188679247
Max-min Ratio: 4.5
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-08_05-19-26
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 484.0
  episode_reward_mean: 449.8
  episode_reward_min: 423.0
  episodes_this_iter: 1
  episodes_total: 264
  experiment_id: 4e724eb5b3a34f42879644e84578eec0
  hostname: gpu024
  info:
    apply_time_ms: 3.059
    dispatch_time_ms: 6.153
    learner:
      cur_lr: 0.0006567040109075606
      grad_gnorm: 3.1247873306274414
      policy_entropy: 769.1417846679688
      policy_loss: 1.8435096740722656
      var_gnorm: 37.443870544433594
      vf_explained_var: 0.6932728290557861
      vf_loss: 0.0015051951631903648
    num_steps_sampled: 10600000
    num_steps_trained: 10600000
    wait_time_ms: 557.472
  iterations_since_restore: 265
  node_ip: 172.17.8.24
  num_metric_batches_dropped: 0
  pid: 26970
  policy_reward_mean: {}
  time_since_restore: 14971.655304670334
  time_this_iter_s: 56.802167892456055
  time_total_s: 14971.655304670334
  timestamp: 1594199966
  timesteps_since_restore: 10600000
  timesteps_this_iter: 40000
  timesteps_total: 10600000
  training_iteration: 265
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26970], 14971 s, 265 iter, 10600000 ts, 450 rew

agent-1: 12.0
agent-2: 13.0
agent-3: 5.0
agent-4: 5.0
agent-5: 8.0
agent-6: 12.0
agent-7: 14.0
agent-8: 7.0
agent-9: 12.0
agent-10: 15.0
agent-11: 16.0
agent-12: 18.0
agent-13: 14.0
agent-14: 7.0
agent-15: 11.0
agent-16: 9.0
agent-17: 11.0
agent-18: 14.0
agent-19: 7.0
agent-20: 11.0
agent-21: 7.0
agent-22: 12.0
agent-23: 8.0
agent-24: 15.0
agent-25: 14.0
agent-26: 10.0
agent-27: 10.0
agent-28: 12.0
agent-29: 14.0
agent-30: 10.0
agent-31: 14.0
agent-32: 13.0
agent-33: 10.0
agent-34: 5.0
agent-35: 13.0
agent-36: 12.0
agent-37: 6.0
agent-38: 12.0
agent-39: 12.0
agent-40: 10.0
Sum Reward: 440.0
Avg Reward: 11.0
Min Reward: 5.0
Max Reward: 18.0
Gini Coefficient: 0.16261363636363638
20:20 Ratio: 2.4489795918367347
Max-min Ratio: 3.6
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-08_05-20-22
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 484.0
  episode_reward_mean: 449.82
  episode_reward_min: 423.0
  episodes_this_iter: 1
  episodes_total: 265
  experiment_id: 4e724eb5b3a34f42879644e84578eec0
  hostname: gpu024
  info:
    apply_time_ms: 2.548
    dispatch_time_ms: 7.004
    learner:
      cur_lr: 0.0006540400208905339
      grad_gnorm: 1.6857304573059082
      policy_entropy: 766.889892578125
      policy_loss: 1.6241950988769531
      var_gnorm: 37.42637634277344
      vf_explained_var: 0.8956180810928345
      vf_loss: 0.0004138426738791168
    num_steps_sampled: 10640000
    num_steps_trained: 10640000
    wait_time_ms: 548.475
  iterations_since_restore: 266
  node_ip: 172.17.8.24
  num_metric_batches_dropped: 0
  pid: 26970
  policy_reward_mean: {}
  time_since_restore: 15027.791959047318
  time_this_iter_s: 56.13665437698364
  time_total_s: 15027.791959047318
  timestamp: 1594200022
  timesteps_since_restore: 10640000
  timesteps_this_iter: 40000
  timesteps_total: 10640000
  training_iteration: 266
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26970], 15027 s, 266 iter, 10640000 ts, 450 rew

agent-1: 16.0
agent-2: 13.0
agent-3: 12.0
agent-4: 15.0
agent-5: 11.0
agent-6: 12.0
agent-7: 11.0
agent-8: 9.0
agent-9: 8.0
agent-10: 12.0
agent-11: 8.0
agent-12: 15.0
agent-13: 12.0
agent-14: 14.0
agent-15: 13.0
agent-16: 9.0
agent-17: 6.0
agent-18: 10.0
agent-19: 14.0
agent-20: 16.0
agent-21: 13.0
agent-22: 8.0
agent-23: 0.0
agent-24: 15.0
agent-25: 14.0
agent-26: 7.0
agent-27: 6.0
agent-28: 14.0
agent-29: 13.0
agent-30: 12.0
agent-31: 8.0
agent-32: 11.0
agent-33: 12.0
agent-34: 11.0
agent-35: 7.0
agent-36: 17.0
agent-37: 17.0
agent-38: 4.0
agent-39: 10.0
agent-40: 12.0
Sum Reward: 447.0
Avg Reward: 11.175
Min Reward: 0.0
Max Reward: 17.0
Gini Coefficient: 0.17880313199105147
20:20 Ratio: 2.717391304347826
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-08_05-21-18
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 484.0
  episode_reward_mean: 449.63
  episode_reward_min: 423.0
  episodes_this_iter: 1
  episodes_total: 266
  experiment_id: 4e724eb5b3a34f42879644e84578eec0
  hostname: gpu024
  info:
    apply_time_ms: 3.009
    dispatch_time_ms: 6.967
    learner:
      cur_lr: 0.0006513759726658463
      grad_gnorm: 3.1507601737976074
      policy_entropy: 768.10791015625
      policy_loss: 1.4738538265228271
      var_gnorm: 37.45949935913086
      vf_explained_var: 0.9893455505371094
      vf_loss: 0.01852935552597046
    num_steps_sampled: 10680000
    num_steps_trained: 10680000
    wait_time_ms: 559.293
  iterations_since_restore: 267
  node_ip: 172.17.8.24
  num_metric_batches_dropped: 0
  pid: 26970
  policy_reward_mean: {}
  time_since_restore: 15084.476679801941
  time_this_iter_s: 56.68472075462341
  time_total_s: 15084.476679801941
  timestamp: 1594200078
  timesteps_since_restore: 10680000
  timesteps_this_iter: 40000
  timesteps_total: 10680000
  training_iteration: 267
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26970], 15084 s, 267 iter, 10680000 ts, 450 rew

agent-1: 8.0
agent-2: 12.0
agent-3: 9.0
agent-4: 15.0
agent-5: 17.0
agent-6: 10.0
agent-7: 5.0
agent-8: 11.0
agent-9: 12.0
agent-10: 12.0
agent-11: 14.0
agent-12: 7.0
agent-13: 6.0
agent-14: 11.0
agent-15: 12.0
agent-16: 9.0
agent-17: 13.0
agent-18: 13.0
agent-19: 12.0
agent-20: 12.0
agent-21: 13.0
agent-22: 15.0
agent-23: 15.0
agent-24: 8.0
agent-25: 15.0
agent-26: 13.0
agent-27: 13.0
agent-28: 7.0
agent-29: 6.0
agent-30: 10.0
agent-31: 14.0
agent-32: 6.0
agent-33: 11.0
agent-34: 10.0
agent-35: 17.0
agent-36: 11.0
agent-37: 13.0
agent-38: 15.0
agent-39: 12.0
agent-40: 6.0
Sum Reward: 450.0
Avg Reward: 11.25
Min Reward: 5.0
Max Reward: 17.0
Gini Coefficient: 0.15777777777777777
20:20 Ratio: 2.411764705882353
Max-min Ratio: 3.4
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-08_05-22-15
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 484.0
  episode_reward_mean: 449.39
  episode_reward_min: 423.0
  episodes_this_iter: 1
  episodes_total: 267
  experiment_id: 4e724eb5b3a34f42879644e84578eec0
  hostname: gpu024
  info:
    apply_time_ms: 3.08
    dispatch_time_ms: 6.915
    learner:
      cur_lr: 0.0006487119826488197
      grad_gnorm: 2.180248975753784
      policy_entropy: 765.4659423828125
      policy_loss: -1.0387470722198486
      var_gnorm: 37.5186882019043
      vf_explained_var: 0.995963990688324
      vf_loss: 0.020978299900889397
    num_steps_sampled: 10720000
    num_steps_trained: 10720000
    wait_time_ms: 561.531
  iterations_since_restore: 268
  node_ip: 172.17.8.24
  num_metric_batches_dropped: 0
  pid: 26970
  policy_reward_mean: {}
  time_since_restore: 15141.406439304352
  time_this_iter_s: 56.92975950241089
  time_total_s: 15141.406439304352
  timestamp: 1594200135
  timesteps_since_restore: 10720000
  timesteps_this_iter: 40000
  timesteps_total: 10720000
  training_iteration: 268
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26970], 15141 s, 268 iter, 10720000 ts, 449 rew

agent-1: 14.0
agent-2: 6.0
agent-3: 6.0
agent-4: 13.0
agent-5: 15.0
agent-6: 4.0
agent-7: 12.0
agent-8: 0.0
agent-9: 19.0
agent-10: 6.0
agent-11: 3.0
agent-12: 16.0
agent-13: 16.0
agent-14: 6.0
agent-15: 9.0
agent-16: 10.0
agent-17: 13.0
agent-18: 14.0
agent-19: 11.0
agent-20: 11.0
agent-21: 9.0
agent-22: 6.0
agent-23: 17.0
agent-24: 15.0
agent-25: 12.0
agent-26: 14.0
agent-27: 9.0
agent-28: 14.0
agent-29: 12.0
agent-30: 15.0
agent-31: 8.0
agent-32: 10.0
agent-33: 20.0
agent-34: 14.0
agent-35: 13.0
agent-36: 13.0
agent-37: 9.0
agent-38: 12.0
agent-39: 9.0
agent-40: 9.0
Sum Reward: 444.0
Avg Reward: 11.1
Min Reward: 0.0
Max Reward: 20.0
Gini Coefficient: 0.21655405405405406
20:20 Ratio: 3.5945945945945947
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-08_05-23-12
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 484.0
  episode_reward_mean: 449.41
  episode_reward_min: 423.0
  episodes_this_iter: 1
  episodes_total: 268
  experiment_id: 4e724eb5b3a34f42879644e84578eec0
  hostname: gpu024
  info:
    apply_time_ms: 2.589
    dispatch_time_ms: 5.828
    learner:
      cur_lr: 0.000646047992631793
      grad_gnorm: 0.4312562346458435
      policy_entropy: 774.6226806640625
      policy_loss: -0.49143266677856445
      var_gnorm: 37.5455322265625
      vf_explained_var: -0.5864061117172241
      vf_loss: 7.82064234954305e-05
    num_steps_sampled: 10760000
    num_steps_trained: 10760000
    wait_time_ms: 570.376
  iterations_since_restore: 269
  node_ip: 172.17.8.24
  num_metric_batches_dropped: 0
  pid: 26970
  policy_reward_mean: {}
  time_since_restore: 15197.730001211166
  time_this_iter_s: 56.323561906814575
  time_total_s: 15197.730001211166
  timestamp: 1594200192
  timesteps_since_restore: 10760000
  timesteps_this_iter: 40000
  timesteps_total: 10760000
  training_iteration: 269
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26970], 15197 s, 269 iter, 10760000 ts, 449 rew

agent-1: 10.0
agent-2: 14.0
agent-3: 17.0
agent-4: 10.0
agent-5: 12.0
agent-6: 14.0
agent-7: 18.0
agent-8: 11.0
agent-9: 8.0
agent-10: 7.0
agent-11: 11.0
agent-12: 10.0
agent-13: 11.0
agent-14: 14.0
agent-15: 9.0
agent-16: 8.0
agent-17: 11.0
agent-18: 11.0
agent-19: 5.0
agent-20: 11.0
agent-21: 9.0
agent-22: 6.0
agent-23: 14.0
agent-24: 13.0
agent-25: 15.0
agent-26: 17.0
agent-27: 8.0
agent-28: 8.0
agent-29: 17.0
agent-30: 5.0
agent-31: 13.0
agent-32: 11.0
agent-33: 12.0
agent-34: 14.0
agent-35: 11.0
agent-36: 10.0
agent-37: 12.0
agent-38: 14.0
agent-39: 8.0
agent-40: 8.0
Sum Reward: 447.0
Avg Reward: 11.175
Min Reward: 5.0
Max Reward: 18.0
Gini Coefficient: 0.16258389261744965
20:20 Ratio: 2.290909090909091
Max-min Ratio: 3.6
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-08_05-24-08
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 484.0
  episode_reward_mean: 449.34
  episode_reward_min: 423.0
  episodes_this_iter: 1
  episodes_total: 269
  experiment_id: 4e724eb5b3a34f42879644e84578eec0
  hostname: gpu024
  info:
    apply_time_ms: 2.603
    dispatch_time_ms: 5.731
    learner:
      cur_lr: 0.0006433840026147664
      grad_gnorm: 1.1598231792449951
      policy_entropy: 770.34326171875
      policy_loss: -1.6755160093307495
      var_gnorm: 37.59235382080078
      vf_explained_var: -1.0
      vf_loss: 0.0005555597599595785
    num_steps_sampled: 10800000
    num_steps_trained: 10800000
    wait_time_ms: 553.09
  iterations_since_restore: 270
  node_ip: 172.17.8.24
  num_metric_batches_dropped: 0
  pid: 26970
  policy_reward_mean: {}
  time_since_restore: 15253.998660087585
  time_this_iter_s: 56.26865887641907
  time_total_s: 15253.998660087585
  timestamp: 1594200248
  timesteps_since_restore: 10800000
  timesteps_this_iter: 40000
  timesteps_total: 10800000
  training_iteration: 270
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26970], 15253 s, 270 iter, 10800000 ts, 449 rew

agent-1: 10.0
agent-2: 8.0
agent-3: 9.0
agent-4: 7.0
agent-5: 17.0
agent-6: 14.0
agent-7: 9.0
agent-8: 12.0
agent-9: 12.0
agent-10: 12.0
agent-11: 9.0
agent-12: 9.0
agent-13: 17.0
agent-14: 8.0
agent-15: 7.0
agent-16: 9.0
agent-17: 15.0
agent-18: 7.0
agent-19: 11.0
agent-20: 10.0
agent-21: 12.0
agent-22: 10.0
agent-23: 11.0
agent-24: 7.0
agent-25: 5.0
agent-26: 14.0
agent-27: 11.0
agent-28: 18.0
agent-29: 7.0
agent-30: 13.0
agent-31: 24.0
agent-32: 14.0
agent-33: 15.0
agent-34: 8.0
agent-35: 18.0
agent-36: 14.0
agent-37: 14.0
agent-38: 11.0
agent-39: 12.0
agent-40: 13.0
Sum Reward: 463.0
Avg Reward: 11.575
Min Reward: 5.0
Max Reward: 24.0
Gini Coefficient: 0.18039956803455723
20:20 Ratio: 2.4642857142857144
Max-min Ratio: 4.8
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-08_05-25-05
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 484.0
  episode_reward_mean: 449.58
  episode_reward_min: 423.0
  episodes_this_iter: 1
  episodes_total: 270
  experiment_id: 4e724eb5b3a34f42879644e84578eec0
  hostname: gpu024
  info:
    apply_time_ms: 3.764
    dispatch_time_ms: 6.267
    learner:
      cur_lr: 0.0006407200125977397
      grad_gnorm: 2.8396964073181152
      policy_entropy: 771.7760620117188
      policy_loss: 0.3549509644508362
      var_gnorm: 37.62732696533203
      vf_explained_var: -1.0
      vf_loss: 0.007018037140369415
    num_steps_sampled: 10840000
    num_steps_trained: 10840000
    wait_time_ms: 575.069
  iterations_since_restore: 271
  node_ip: 172.17.8.24
  num_metric_batches_dropped: 0
  pid: 26970
  policy_reward_mean: {}
  time_since_restore: 15310.6004114151
  time_this_iter_s: 56.60175132751465
  time_total_s: 15310.6004114151
  timestamp: 1594200305
  timesteps_since_restore: 10840000
  timesteps_this_iter: 40000
  timesteps_total: 10840000
  training_iteration: 271
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26970], 15310 s, 271 iter, 10840000 ts, 450 rew

agent-1: 8.0
agent-2: 18.0
agent-3: 21.0
agent-4: 16.0
agent-5: 1.0
agent-6: 15.0
agent-7: 6.0
agent-8: 7.0
agent-9: 13.0
agent-10: 14.0
agent-11: 10.0
agent-12: 21.0
agent-13: 10.0
agent-14: 17.0
agent-15: 15.0
agent-16: 14.0
agent-17: 12.0
agent-18: 7.0
agent-19: 7.0
agent-20: 8.0
agent-21: 11.0
agent-22: 12.0
agent-23: 15.0
agent-24: 10.0
agent-25: 20.0
agent-26: 9.0
agent-27: 10.0
agent-28: 7.0
agent-29: 12.0
agent-30: 14.0
agent-31: 11.0
agent-32: 14.0
agent-33: 10.0
agent-34: 8.0
agent-35: 14.0
agent-36: 10.0
agent-37: 9.0
agent-38: 8.0
agent-39: 9.0
agent-40: 6.0
Sum Reward: 459.0
Avg Reward: 11.475
Min Reward: 1.0
Max Reward: 21.0
Gini Coefficient: 0.2099673202614379
20:20 Ratio: 2.9183673469387754
Max-min Ratio: 21.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-08_05-26-01
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 484.0
  episode_reward_mean: 449.5
  episode_reward_min: 423.0
  episodes_this_iter: 1
  episodes_total: 271
  experiment_id: 4e724eb5b3a34f42879644e84578eec0
  hostname: gpu024
  info:
    apply_time_ms: 2.914
    dispatch_time_ms: 5.948
    learner:
      cur_lr: 0.000638056022580713
      grad_gnorm: 1.2438781261444092
      policy_entropy: 774.1505126953125
      policy_loss: 1.8079404830932617
      var_gnorm: 37.61207962036133
      vf_explained_var: -0.604386568069458
      vf_loss: 0.0001150316238636151
    num_steps_sampled: 10880000
    num_steps_trained: 10880000
    wait_time_ms: 557.093
  iterations_since_restore: 272
  node_ip: 172.17.8.24
  num_metric_batches_dropped: 0
  pid: 26970
  policy_reward_mean: {}
  time_since_restore: 15367.010231733322
  time_this_iter_s: 56.409820318222046
  time_total_s: 15367.010231733322
  timestamp: 1594200361
  timesteps_since_restore: 10880000
  timesteps_this_iter: 40000
  timesteps_total: 10880000
  training_iteration: 272
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26970], 15367 s, 272 iter, 10880000 ts, 450 rew

agent-1: 16.0
agent-2: 12.0
agent-3: 9.0
agent-4: 7.0
agent-5: 8.0
agent-6: 8.0
agent-7: 13.0
agent-8: 16.0
agent-9: 10.0
agent-10: 1.0
agent-11: 16.0
agent-12: 1.0
agent-13: 12.0
agent-14: 18.0
agent-15: 10.0
agent-16: 5.0
agent-17: 13.0
agent-18: 13.0
agent-19: 15.0
agent-20: 9.0
agent-21: 17.0
agent-22: 15.0
agent-23: 6.0
agent-24: 13.0
agent-25: 14.0
agent-26: 4.0
agent-27: 8.0
agent-28: 15.0
agent-29: 12.0
agent-30: 18.0
agent-31: 15.0
agent-32: 14.0
agent-33: 13.0
agent-34: 14.0
agent-35: 10.0
agent-36: 6.0
agent-37: 13.0
agent-38: 9.0
agent-39: 14.0
agent-40: 11.0
Sum Reward: 453.0
Avg Reward: 11.325
Min Reward: 1.0
Max Reward: 18.0
Gini Coefficient: 0.20965783664459162
20:20 Ratio: 3.4473684210526314
Max-min Ratio: 18.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-08_05-26-58
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 484.0
  episode_reward_mean: 449.55
  episode_reward_min: 423.0
  episodes_this_iter: 1
  episodes_total: 272
  experiment_id: 4e724eb5b3a34f42879644e84578eec0
  hostname: gpu024
  info:
    apply_time_ms: 3.12
    dispatch_time_ms: 6.341
    learner:
      cur_lr: 0.0006353919743560255
      grad_gnorm: 4.965541839599609
      policy_entropy: 772.97021484375
      policy_loss: 4.5193939208984375
      var_gnorm: 37.64760971069336
      vf_explained_var: -0.4546360969543457
      vf_loss: 0.0038813361898064613
    num_steps_sampled: 10920000
    num_steps_trained: 10920000
    wait_time_ms: 552.13
  iterations_since_restore: 273
  node_ip: 172.17.8.24
  num_metric_batches_dropped: 0
  pid: 26970
  policy_reward_mean: {}
  time_since_restore: 15423.842762231827
  time_this_iter_s: 56.83253049850464
  time_total_s: 15423.842762231827
  timestamp: 1594200418
  timesteps_since_restore: 10920000
  timesteps_this_iter: 40000
  timesteps_total: 10920000
  training_iteration: 273
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26970], 15423 s, 273 iter, 10920000 ts, 450 rew

agent-1: 6.0
agent-2: 18.0
agent-3: 7.0
agent-4: 9.0
agent-5: 4.0
agent-6: 9.0
agent-7: 22.0
agent-8: 13.0
agent-9: 12.0
agent-10: 12.0
agent-11: 15.0
agent-12: 9.0
agent-13: 5.0
agent-14: 8.0
agent-15: 15.0
agent-16: 11.0
agent-17: 12.0
agent-18: 16.0
agent-19: 20.0
agent-20: 7.0
agent-21: 10.0
agent-22: 4.0
agent-23: 7.0
agent-24: 13.0
agent-25: 11.0
agent-26: 11.0
agent-27: 10.0
agent-28: 11.0
agent-29: 14.0
agent-30: 13.0
agent-31: 9.0
agent-32: 3.0
agent-33: 9.0
agent-34: 5.0
agent-35: 15.0
agent-36: 15.0
agent-37: 16.0
agent-38: 8.0
agent-39: 13.0
agent-40: 12.0
Sum Reward: 439.0
Avg Reward: 10.975
Min Reward: 3.0
Max Reward: 22.0
Gini Coefficient: 0.22055808656036446
20:20 Ratio: 3.341463414634146
Max-min Ratio: 7.333333333333333
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-08_05-27-54
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 484.0
  episode_reward_mean: 449.4
  episode_reward_min: 423.0
  episodes_this_iter: 1
  episodes_total: 273
  experiment_id: 4e724eb5b3a34f42879644e84578eec0
  hostname: gpu024
  info:
    apply_time_ms: 3.9
    dispatch_time_ms: 5.864
    learner:
      cur_lr: 0.0006327279843389988
      grad_gnorm: 2.1489923000335693
      policy_entropy: 770.8952026367188
      policy_loss: 0.36370307207107544
      var_gnorm: 37.68974304199219
      vf_explained_var: -0.455338716506958
      vf_loss: 0.00017802495858632028
    num_steps_sampled: 10960000
    num_steps_trained: 10960000
    wait_time_ms: 552.681
  iterations_since_restore: 274
  node_ip: 172.17.8.24
  num_metric_batches_dropped: 0
  pid: 26970
  policy_reward_mean: {}
  time_since_restore: 15480.145093202591
  time_this_iter_s: 56.30233097076416
  time_total_s: 15480.145093202591
  timestamp: 1594200474
  timesteps_since_restore: 10960000
  timesteps_this_iter: 40000
  timesteps_total: 10960000
  training_iteration: 274
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26970], 15480 s, 274 iter, 10960000 ts, 449 rew

agent-1: 16.0
agent-2: 12.0
agent-3: 14.0
agent-4: 16.0
agent-5: 9.0
agent-6: 12.0
agent-7: 15.0
agent-8: 21.0
agent-9: 12.0
agent-10: 15.0
agent-11: 2.0
agent-12: 10.0
agent-13: 15.0
agent-14: 15.0
agent-15: 5.0
agent-16: 9.0
agent-17: 1.0
agent-18: 11.0
agent-19: 5.0
agent-20: 11.0
agent-21: 22.0
agent-22: 7.0
agent-23: 7.0
agent-24: 4.0
agent-25: 8.0
agent-26: 14.0
agent-27: 13.0
agent-28: 9.0
agent-29: 14.0
agent-30: 8.0
agent-31: 16.0
agent-32: 12.0
agent-33: 14.0
agent-34: 13.0
agent-35: 10.0
agent-36: 11.0
agent-37: 15.0
agent-38: 8.0
agent-39: 5.0
agent-40: 10.0
Sum Reward: 446.0
Avg Reward: 11.15
Min Reward: 1.0
Max Reward: 22.0
Gini Coefficient: 0.22881165919282512
20:20 Ratio: 3.7777777777777777
Max-min Ratio: 22.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-08_05-28-51
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 484.0
  episode_reward_mean: 449.33
  episode_reward_min: 423.0
  episodes_this_iter: 1
  episodes_total: 274
  experiment_id: 4e724eb5b3a34f42879644e84578eec0
  hostname: gpu024
  info:
    apply_time_ms: 2.801
    dispatch_time_ms: 7.089
    learner:
      cur_lr: 0.0006300639943219721
      grad_gnorm: 0.712039053440094
      policy_entropy: 776.2650146484375
      policy_loss: 0.598740816116333
      var_gnorm: 37.70079040527344
      vf_explained_var: -0.24802911281585693
      vf_loss: 8.934456127462909e-05
    num_steps_sampled: 11000000
    num_steps_trained: 11000000
    wait_time_ms: 558.613
  iterations_since_restore: 275
  node_ip: 172.17.8.24
  num_metric_batches_dropped: 0
  pid: 26970
  policy_reward_mean: {}
  time_since_restore: 15537.062715530396
  time_this_iter_s: 56.917622327804565
  time_total_s: 15537.062715530396
  timestamp: 1594200531
  timesteps_since_restore: 11000000
  timesteps_this_iter: 40000
  timesteps_total: 11000000
  training_iteration: 275
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26970], 15537 s, 275 iter, 11000000 ts, 449 rew

agent-1: 12.0
agent-2: 8.0
agent-3: 15.0
agent-4: 9.0
agent-5: 13.0
agent-6: 9.0
agent-7: 11.0
agent-8: 11.0
agent-9: 12.0
agent-10: 17.0
agent-11: 11.0
agent-12: 19.0
agent-13: 9.0
agent-14: 5.0
agent-15: 13.0
agent-16: 16.0
agent-17: 7.0
agent-18: 19.0
agent-19: 9.0
agent-20: 15.0
agent-21: 11.0
agent-22: 10.0
agent-23: 4.0
agent-24: 19.0
agent-25: 6.0
agent-26: 6.0
agent-27: 17.0
agent-28: 13.0
agent-29: 11.0
agent-30: 13.0
agent-31: 15.0
agent-32: 11.0
agent-33: 7.0
agent-34: 9.0
agent-35: 9.0
agent-36: 6.0
agent-37: 10.0
agent-38: 9.0
agent-39: 3.0
agent-40: 10.0
Sum Reward: 439.0
Avg Reward: 10.975
Min Reward: 3.0
Max Reward: 19.0
Gini Coefficient: 0.20689066059225514
20:20 Ratio: 3.1136363636363638
Max-min Ratio: 6.333333333333333
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-08_05-29-48
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 484.0
  episode_reward_mean: 449.22
  episode_reward_min: 423.0
  episodes_this_iter: 1
  episodes_total: 275
  experiment_id: 4e724eb5b3a34f42879644e84578eec0
  hostname: gpu024
  info:
    apply_time_ms: 2.632
    dispatch_time_ms: 5.401
    learner:
      cur_lr: 0.0006274000043049455
      grad_gnorm: 0.7469198107719421
      policy_entropy: 773.2840576171875
      policy_loss: -0.6418849229812622
      var_gnorm: 37.6684455871582
      vf_explained_var: -0.1665722131729126
      vf_loss: 8.892298501450568e-05
    num_steps_sampled: 11040000
    num_steps_trained: 11040000
    wait_time_ms: 561.695
  iterations_since_restore: 276
  node_ip: 172.17.8.24
  num_metric_batches_dropped: 0
  pid: 26970
  policy_reward_mean: {}
  time_since_restore: 15593.212882518768
  time_this_iter_s: 56.1501669883728
  time_total_s: 15593.212882518768
  timestamp: 1594200588
  timesteps_since_restore: 11040000
  timesteps_this_iter: 40000
  timesteps_total: 11040000
  training_iteration: 276
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26970], 15593 s, 276 iter, 11040000 ts, 449 rew

agent-1: 15.0
agent-2: 10.0
agent-3: 12.0
agent-4: 9.0
agent-5: 15.0
agent-6: 10.0
agent-7: 15.0
agent-8: 15.0
agent-9: 9.0
agent-10: 12.0
agent-11: 13.0
agent-12: 3.0
agent-13: 11.0
agent-14: 8.0
agent-15: 15.0
agent-16: 8.0
agent-17: 10.0
agent-18: 13.0
agent-19: 3.0
agent-20: 5.0
agent-21: 11.0
agent-22: 4.0
agent-23: 6.0
agent-24: 11.0
agent-25: 15.0
agent-26: 15.0
agent-27: 15.0
agent-28: 17.0
agent-29: 10.0
agent-30: 13.0
agent-31: 13.0
agent-32: 6.0
agent-33: 10.0
agent-34: 17.0
agent-35: 7.0
agent-36: 7.0
agent-37: 12.0
agent-38: 6.0
agent-39: 12.0
agent-40: 16.0
Sum Reward: 434.0
Avg Reward: 10.85
Min Reward: 3.0
Max Reward: 17.0
Gini Coefficient: 0.20195852534562211
20:20 Ratio: 3.125
Max-min Ratio: 5.666666666666667
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-08_05-30-44
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 484.0
  episode_reward_mean: 449.03
  episode_reward_min: 423.0
  episodes_this_iter: 1
  episodes_total: 276
  experiment_id: 4e724eb5b3a34f42879644e84578eec0
  hostname: gpu024
  info:
    apply_time_ms: 2.77
    dispatch_time_ms: 6.229
    learner:
      cur_lr: 0.0006247360142879188
      grad_gnorm: 1.2759513854980469
      policy_entropy: 776.8894653320312
      policy_loss: 1.478508710861206
      var_gnorm: 37.683807373046875
      vf_explained_var: -1.0
      vf_loss: 0.00037620298098772764
    num_steps_sampled: 11080000
    num_steps_trained: 11080000
    wait_time_ms: 558.415
  iterations_since_restore: 277
  node_ip: 172.17.8.24
  num_metric_batches_dropped: 0
  pid: 26970
  policy_reward_mean: {}
  time_since_restore: 15649.574348688126
  time_this_iter_s: 56.3614661693573
  time_total_s: 15649.574348688126
  timestamp: 1594200644
  timesteps_since_restore: 11080000
  timesteps_this_iter: 40000
  timesteps_total: 11080000
  training_iteration: 277
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26970], 15649 s, 277 iter, 11080000 ts, 449 rew

agent-1: 9.0
agent-2: 13.0
agent-3: 7.0
agent-4: 10.0
agent-5: 13.0
agent-6: 12.0
agent-7: 11.0
agent-8: 15.0
agent-9: 13.0
agent-10: 5.0
agent-11: 8.0
agent-12: 13.0
agent-13: 14.0
agent-14: 11.0
agent-15: 5.0
agent-16: 10.0
agent-17: 6.0
agent-18: 10.0
agent-19: 15.0
agent-20: 13.0
agent-21: 11.0
agent-22: 18.0
agent-23: 5.0
agent-24: 6.0
agent-25: 15.0
agent-26: 11.0
agent-27: 14.0
agent-28: 13.0
agent-29: 8.0
agent-30: 11.0
agent-31: 9.0
agent-32: 19.0
agent-33: 6.0
agent-34: 6.0
agent-35: 6.0
agent-36: 15.0
agent-37: 15.0
agent-38: 12.0
agent-39: 8.0
agent-40: 11.0
Sum Reward: 432.0
Avg Reward: 10.8
Min Reward: 5.0
Max Reward: 19.0
Gini Coefficient: 0.18981481481481483
20:20 Ratio: 2.8
Max-min Ratio: 3.8
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-08_05-31-41
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 484.0
  episode_reward_mean: 449.05
  episode_reward_min: 423.0
  episodes_this_iter: 1
  episodes_total: 277
  experiment_id: 4e724eb5b3a34f42879644e84578eec0
  hostname: gpu024
  info:
    apply_time_ms: 3.863
    dispatch_time_ms: 6.095
    learner:
      cur_lr: 0.0006220720242708921
      grad_gnorm: 1.3511483669281006
      policy_entropy: 777.769775390625
      policy_loss: 0.6153348684310913
      var_gnorm: 37.6904411315918
      vf_explained_var: -0.44303619861602783
      vf_loss: 0.00029169381014071405
    num_steps_sampled: 11120000
    num_steps_trained: 11120000
    wait_time_ms: 561.525
  iterations_since_restore: 278
  node_ip: 172.17.8.24
  num_metric_batches_dropped: 0
  pid: 26970
  policy_reward_mean: {}
  time_since_restore: 15706.31874012947
  time_this_iter_s: 56.744391441345215
  time_total_s: 15706.31874012947
  timestamp: 1594200701
  timesteps_since_restore: 11120000
  timesteps_this_iter: 40000
  timesteps_total: 11120000
  training_iteration: 278
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26970], 15706 s, 278 iter, 11120000 ts, 449 rew

agent-1: 12.0
agent-2: 15.0
agent-3: 13.0
agent-4: 12.0
agent-5: 8.0
agent-6: 13.0
agent-7: 17.0
agent-8: 16.0
agent-9: 18.0
agent-10: 4.0
agent-11: 5.0
agent-12: 7.0
agent-13: 8.0
agent-14: 11.0
agent-15: 2.0
agent-16: 12.0
agent-17: 11.0
agent-18: 11.0
agent-19: 7.0
agent-20: 12.0
agent-21: 13.0
agent-22: 10.0
agent-23: 11.0
agent-24: 4.0
agent-25: 7.0
agent-26: 11.0
agent-27: 12.0
agent-28: 14.0
agent-29: 17.0
agent-30: 17.0
agent-31: 8.0
agent-32: 13.0
agent-33: 9.0
agent-34: 3.0
agent-35: 8.0
agent-36: 16.0
agent-37: 16.0
agent-38: 19.0
agent-39: 16.0
agent-40: 5.0
Sum Reward: 443.0
Avg Reward: 11.075
Min Reward: 2.0
Max Reward: 19.0
Gini Coefficient: 0.22567720090293453
20:20 Ratio: 3.675675675675676
Max-min Ratio: 9.5
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-08_05-32-37
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 484.0
  episode_reward_mean: 449.08
  episode_reward_min: 423.0
  episodes_this_iter: 1
  episodes_total: 278
  experiment_id: 4e724eb5b3a34f42879644e84578eec0
  hostname: gpu024
  info:
    apply_time_ms: 3.053
    dispatch_time_ms: 8.171
    learner:
      cur_lr: 0.0006194079760462046
      grad_gnorm: 2.308013677597046
      policy_entropy: 771.6578369140625
      policy_loss: 1.3130563497543335
      var_gnorm: 37.730594635009766
      vf_explained_var: -0.13672339916229248
      vf_loss: 0.0015493577811866999
    num_steps_sampled: 11160000
    num_steps_trained: 11160000
    wait_time_ms: 562.174
  iterations_since_restore: 279
  node_ip: 172.17.8.24
  num_metric_batches_dropped: 0
  pid: 26970
  policy_reward_mean: {}
  time_since_restore: 15762.534390687943
  time_this_iter_s: 56.21565055847168
  time_total_s: 15762.534390687943
  timestamp: 1594200757
  timesteps_since_restore: 11160000
  timesteps_this_iter: 40000
  timesteps_total: 11160000
  training_iteration: 279
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26970], 15762 s, 279 iter, 11160000 ts, 449 rew

agent-1: 10.0
agent-2: 11.0
agent-3: 7.0
agent-4: 11.0
agent-5: 13.0
agent-6: 15.0
agent-7: 16.0
agent-8: 11.0
agent-9: 9.0
agent-10: 10.0
agent-11: 9.0
agent-12: 2.0
agent-13: 12.0
agent-14: 5.0
agent-15: 13.0
agent-16: 16.0
agent-17: 1.0
agent-18: 9.0
agent-19: 12.0
agent-20: 10.0
agent-21: 9.0
agent-22: 12.0
agent-23: 12.0
agent-24: 10.0
agent-25: 14.0
agent-26: 7.0
agent-27: 13.0
agent-28: 13.0
agent-29: 11.0
agent-30: 11.0
agent-31: 13.0
agent-32: 7.0
agent-33: 14.0
agent-34: 11.0
agent-35: 16.0
agent-36: 15.0
agent-37: 18.0
agent-38: 17.0
agent-39: 17.0
agent-40: 12.0
Sum Reward: 454.0
Avg Reward: 11.35
Min Reward: 1.0
Max Reward: 18.0
Gini Coefficient: 0.1787444933920705
20:20 Ratio: 2.765957446808511
Max-min Ratio: 18.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-08_05-33-34
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 484.0
  episode_reward_mean: 449.08
  episode_reward_min: 423.0
  episodes_this_iter: 1
  episodes_total: 279
  experiment_id: 4e724eb5b3a34f42879644e84578eec0
  hostname: gpu024
  info:
    apply_time_ms: 2.925
    dispatch_time_ms: 6.936
    learner:
      cur_lr: 0.0006167439860291779
      grad_gnorm: 1.0984423160552979
      policy_entropy: 776.616455078125
      policy_loss: 0.7130845785140991
      var_gnorm: 37.73973846435547
      vf_explained_var: -1.0
      vf_loss: 0.0006365145090967417
    num_steps_sampled: 11200000
    num_steps_trained: 11200000
    wait_time_ms: 556.142
  iterations_since_restore: 280
  node_ip: 172.17.8.24
  num_metric_batches_dropped: 0
  pid: 26970
  policy_reward_mean: {}
  time_since_restore: 15819.585847616196
  time_this_iter_s: 57.051456928253174
  time_total_s: 15819.585847616196
  timestamp: 1594200814
  timesteps_since_restore: 11200000
  timesteps_this_iter: 40000
  timesteps_total: 11200000
  training_iteration: 280
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26970], 15819 s, 280 iter, 11200000 ts, 449 rew

agent-1: 16.0
agent-2: 3.0
agent-3: 13.0
agent-4: 6.0
agent-5: 8.0
agent-6: 12.0
agent-7: 14.0
agent-8: 10.0
agent-9: 12.0
agent-10: 19.0
agent-11: 6.0
agent-12: 12.0
agent-13: 10.0
agent-14: 9.0
agent-15: 10.0
agent-16: 4.0
agent-17: 14.0
agent-18: 15.0
agent-19: 15.0
agent-20: 19.0
agent-21: 14.0
agent-22: 17.0
agent-23: 11.0
agent-24: 5.0
agent-25: 5.0
agent-26: 12.0
agent-27: 10.0
agent-28: 9.0
agent-29: 14.0
agent-30: 15.0
agent-31: 13.0
agent-32: 11.0
agent-33: 16.0
agent-34: 15.0
agent-35: 8.0
agent-36: 4.0
agent-37: 5.0
agent-38: 13.0
agent-39: 8.0
agent-40: 17.0
Sum Reward: 449.0
Avg Reward: 11.225
Min Reward: 3.0
Max Reward: 19.0
Gini Coefficient: 0.2160913140311804
20:20 Ratio: 3.526315789473684
Max-min Ratio: 6.333333333333333
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-08_05-34-31
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 484.0
  episode_reward_mean: 448.84
  episode_reward_min: 423.0
  episodes_this_iter: 1
  episodes_total: 280
  experiment_id: 4e724eb5b3a34f42879644e84578eec0
  hostname: gpu024
  info:
    apply_time_ms: 2.632
    dispatch_time_ms: 6.004
    learner:
      cur_lr: 0.0006140799960121512
      grad_gnorm: 3.881617546081543
      policy_entropy: 774.8434448242188
      policy_loss: 2.23319935798645
      var_gnorm: 37.77164840698242
      vf_explained_var: -0.3926682472229004
      vf_loss: 0.0038539685774594545
    num_steps_sampled: 11240000
    num_steps_trained: 11240000
    wait_time_ms: 556.179
  iterations_since_restore: 281
  node_ip: 172.17.8.24
  num_metric_batches_dropped: 0
  pid: 26970
  policy_reward_mean: {}
  time_since_restore: 15876.133823871613
  time_this_iter_s: 56.54797625541687
  time_total_s: 15876.133823871613
  timestamp: 1594200871
  timesteps_since_restore: 11240000
  timesteps_this_iter: 40000
  timesteps_total: 11240000
  training_iteration: 281
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26970], 15876 s, 281 iter, 11240000 ts, 449 rew

agent-1: 5.0
agent-2: 9.0
agent-3: 10.0
agent-4: 9.0
agent-5: 14.0
agent-6: 13.0
agent-7: 8.0
agent-8: 11.0
agent-9: 11.0
agent-10: 7.0
agent-11: 8.0
agent-12: 5.0
agent-13: 14.0
agent-14: 12.0
agent-15: 1.0
agent-16: 10.0
agent-17: 16.0
agent-18: 14.0
agent-19: 15.0
agent-20: 17.0
agent-21: 15.0
agent-22: 7.0
agent-23: 7.0
agent-24: 15.0
agent-25: 6.0
agent-26: 17.0
agent-27: 12.0
agent-28: 10.0
agent-29: 8.0
agent-30: 10.0
agent-31: 10.0
agent-32: 14.0
agent-33: 11.0
agent-34: 10.0
agent-35: 10.0
agent-36: 11.0
agent-37: 10.0
agent-38: 12.0
agent-39: 18.0
agent-40: 11.0
Sum Reward: 433.0
Avg Reward: 10.825
Min Reward: 1.0
Max Reward: 18.0
Gini Coefficient: 0.18666281755196304
20:20 Ratio: 2.760869565217391
Max-min Ratio: 18.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-08_05-35-27
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 484.0
  episode_reward_mean: 448.68
  episode_reward_min: 423.0
  episodes_this_iter: 1
  episodes_total: 281
  experiment_id: 4e724eb5b3a34f42879644e84578eec0
  hostname: gpu024
  info:
    apply_time_ms: 2.521
    dispatch_time_ms: 7.6
    learner:
      cur_lr: 0.0006114160059951246
      grad_gnorm: 1.2496588230133057
      policy_entropy: 774.6847534179688
      policy_loss: -0.7534732818603516
      var_gnorm: 37.817386627197266
      vf_explained_var: -1.0
      vf_loss: 0.000779904774390161
    num_steps_sampled: 11280000
    num_steps_trained: 11280000
    wait_time_ms: 557.921
  iterations_since_restore: 282
  node_ip: 172.17.8.24
  num_metric_batches_dropped: 0
  pid: 26970
  policy_reward_mean: {}
  time_since_restore: 15932.030766010284
  time_this_iter_s: 55.896942138671875
  time_total_s: 15932.030766010284
  timestamp: 1594200927
  timesteps_since_restore: 11280000
  timesteps_this_iter: 40000
  timesteps_total: 11280000
  training_iteration: 282
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26970], 15932 s, 282 iter, 11280000 ts, 449 rew

agent-1: 14.0
agent-2: 8.0
agent-3: 12.0
agent-4: 14.0
agent-5: 8.0
agent-6: 9.0
agent-7: 12.0
agent-8: 7.0
agent-9: 7.0
agent-10: 15.0
agent-11: 13.0
agent-12: 15.0
agent-13: 13.0
agent-14: 16.0
agent-15: 12.0
agent-16: 13.0
agent-17: 8.0
agent-18: 9.0
agent-19: 7.0
agent-20: 9.0
agent-21: 11.0
agent-22: 5.0
agent-23: 9.0
agent-24: 8.0
agent-25: 9.0
agent-26: 10.0
agent-27: 13.0
agent-28: 14.0
agent-29: 10.0
agent-30: 14.0
agent-31: 10.0
agent-32: 4.0
agent-33: 7.0
agent-34: 17.0
agent-35: 11.0
agent-36: 12.0
agent-37: 10.0
agent-38: 5.0
agent-39: 12.0
agent-40: 12.0
Sum Reward: 424.0
Avg Reward: 10.6
Min Reward: 4.0
Max Reward: 17.0
Gini Coefficient: 0.16757075471698113
20:20 Ratio: 2.38
Max-min Ratio: 4.25
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-08_05-36-23
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 484.0
  episode_reward_mean: 448.43
  episode_reward_min: 423.0
  episodes_this_iter: 1
  episodes_total: 282
  experiment_id: 4e724eb5b3a34f42879644e84578eec0
  hostname: gpu024
  info:
    apply_time_ms: 3.379
    dispatch_time_ms: 8.592
    learner:
      cur_lr: 0.0006087520159780979
      grad_gnorm: 4.138972759246826
      policy_entropy: 777.222900390625
      policy_loss: 2.4922618865966797
      var_gnorm: 37.83091735839844
      vf_explained_var: -0.4499324560165405
      vf_loss: 0.00243638944812119
    num_steps_sampled: 11320000
    num_steps_trained: 11320000
    wait_time_ms: 557.215
  iterations_since_restore: 283
  node_ip: 172.17.8.24
  num_metric_batches_dropped: 0
  pid: 26970
  policy_reward_mean: {}
  time_since_restore: 15988.500925779343
  time_this_iter_s: 56.47015976905823
  time_total_s: 15988.500925779343
  timestamp: 1594200983
  timesteps_since_restore: 11320000
  timesteps_this_iter: 40000
  timesteps_total: 11320000
  training_iteration: 283
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26970], 15988 s, 283 iter, 11320000 ts, 448 rew

agent-1: 8.0
agent-2: 14.0
agent-3: 13.0
agent-4: 11.0
agent-5: 11.0
agent-6: 16.0
agent-7: 6.0
agent-8: 4.0
agent-9: 13.0
agent-10: 8.0
agent-11: 10.0
agent-12: 11.0
agent-13: 8.0
agent-14: 10.0
agent-15: 11.0
agent-16: 12.0
agent-17: 17.0
agent-18: 13.0
agent-19: 12.0
agent-20: 7.0
agent-21: 10.0
agent-22: 15.0
agent-23: 7.0
agent-24: 7.0
agent-25: 12.0
agent-26: 12.0
agent-27: 9.0
agent-28: 16.0
agent-29: 7.0
agent-30: 8.0
agent-31: 8.0
agent-32: 7.0
agent-33: 10.0
agent-34: 11.0
agent-35: 13.0
agent-36: 12.0
agent-37: 14.0
agent-38: 9.0
agent-39: 12.0
agent-40: 13.0
Sum Reward: 427.0
Avg Reward: 10.675
Min Reward: 4.0
Max Reward: 17.0
Gini Coefficient: 0.15743559718969555
20:20 Ratio: 2.2264150943396226
Max-min Ratio: 4.25
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-08_05-37-20
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 484.0
  episode_reward_mean: 448.05
  episode_reward_min: 423.0
  episodes_this_iter: 1
  episodes_total: 283
  experiment_id: 4e724eb5b3a34f42879644e84578eec0
  hostname: gpu024
  info:
    apply_time_ms: 2.668
    dispatch_time_ms: 7.296
    learner:
      cur_lr: 0.0006060880259610713
      grad_gnorm: 1.3669440746307373
      policy_entropy: 774.7953491210938
      policy_loss: 0.48291245102882385
      var_gnorm: 37.856929779052734
      vf_explained_var: -1.0
      vf_loss: 0.0020023940596729517
    num_steps_sampled: 11360000
    num_steps_trained: 11360000
    wait_time_ms: 548.457
  iterations_since_restore: 284
  node_ip: 172.17.8.24
  num_metric_batches_dropped: 0
  pid: 26970
  policy_reward_mean: {}
  time_since_restore: 16045.444111585617
  time_this_iter_s: 56.943185806274414
  time_total_s: 16045.444111585617
  timestamp: 1594201040
  timesteps_since_restore: 11360000
  timesteps_this_iter: 40000
  timesteps_total: 11360000
  training_iteration: 284
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26970], 16045 s, 284 iter, 11360000 ts, 448 rew

agent-1: 8.0
agent-2: 14.0
agent-3: 9.0
agent-4: 16.0
agent-5: 6.0
agent-6: 12.0
agent-7: 11.0
agent-8: 14.0
agent-9: 14.0
agent-10: 10.0
agent-11: 11.0
agent-12: 5.0
agent-13: 11.0
agent-14: 12.0
agent-15: 11.0
agent-16: 21.0
agent-17: 13.0
agent-18: 14.0
agent-19: 12.0
agent-20: 12.0
agent-21: 7.0
agent-22: 16.0
agent-23: 7.0
agent-24: 14.0
agent-25: 11.0
agent-26: 6.0
agent-27: 8.0
agent-28: 10.0
agent-29: 14.0
agent-30: 7.0
agent-31: 11.0
agent-32: 13.0
agent-33: 18.0
agent-34: 10.0
agent-35: 14.0
agent-36: 16.0
agent-37: 7.0
agent-38: 14.0
agent-39: 12.0
agent-40: 2.0
Sum Reward: 453.0
Avg Reward: 11.325
Min Reward: 2.0
Max Reward: 21.0
Gini Coefficient: 0.18327814569536424
20:20 Ratio: 2.74468085106383
Max-min Ratio: 10.5
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-08_05-38-16
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 484.0
  episode_reward_mean: 448.16
  episode_reward_min: 423.0
  episodes_this_iter: 1
  episodes_total: 284
  experiment_id: 4e724eb5b3a34f42879644e84578eec0
  hostname: gpu024
  info:
    apply_time_ms: 2.639
    dispatch_time_ms: 7.224
    learner:
      cur_lr: 0.0006034239777363837
      grad_gnorm: 3.05425763130188
      policy_entropy: 772.5989990234375
      policy_loss: -2.140123128890991
      var_gnorm: 37.856529235839844
      vf_explained_var: -1.0
      vf_loss: 0.004905669949948788
    num_steps_sampled: 11400000
    num_steps_trained: 11400000
    wait_time_ms: 558.716
  iterations_since_restore: 285
  node_ip: 172.17.8.24
  num_metric_batches_dropped: 0
  pid: 26970
  policy_reward_mean: {}
  time_since_restore: 16101.538747549057
  time_this_iter_s: 56.09463596343994
  time_total_s: 16101.538747549057
  timestamp: 1594201096
  timesteps_since_restore: 11400000
  timesteps_this_iter: 40000
  timesteps_total: 11400000
  training_iteration: 285
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26970], 16101 s, 285 iter, 11400000 ts, 448 rew

agent-1: 7.0
agent-2: 6.0
agent-3: 16.0
agent-4: 9.0
agent-5: 14.0
agent-6: 18.0
agent-7: 9.0
agent-8: 12.0
agent-9: 11.0
agent-10: 12.0
agent-11: 12.0
agent-12: 17.0
agent-13: 12.0
agent-14: 8.0
agent-15: 6.0
agent-16: 11.0
agent-17: 6.0
agent-18: 10.0
agent-19: 14.0
agent-20: 8.0
agent-21: 17.0
agent-22: 11.0
agent-23: 15.0
agent-24: 16.0
agent-25: 12.0
agent-26: 9.0
agent-27: 8.0
agent-28: 15.0
agent-29: 13.0
agent-30: 12.0
agent-31: 9.0
agent-32: 8.0
agent-33: 12.0
agent-34: 10.0
agent-35: 10.0
agent-36: 10.0
agent-37: 15.0
agent-38: 13.0
agent-39: 24.0
agent-40: 15.0
Sum Reward: 472.0
Avg Reward: 11.8
Min Reward: 6.0
Max Reward: 24.0
Gini Coefficient: 0.17415254237288136
20:20 Ratio: 2.4210526315789473
Max-min Ratio: 4.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-08_05-39-13
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 484.0
  episode_reward_mean: 448.58
  episode_reward_min: 423.0
  episodes_this_iter: 1
  episodes_total: 285
  experiment_id: 4e724eb5b3a34f42879644e84578eec0
  hostname: gpu024
  info:
    apply_time_ms: 3.044
    dispatch_time_ms: 6.884
    learner:
      cur_lr: 0.000600759987719357
      grad_gnorm: 0.5570249557495117
      policy_entropy: 770.123779296875
      policy_loss: -0.3226585388183594
      var_gnorm: 37.958377838134766
      vf_explained_var: -0.18744111061096191
      vf_loss: 0.0007940296200104058
    num_steps_sampled: 11440000
    num_steps_trained: 11440000
    wait_time_ms: 553.648
  iterations_since_restore: 286
  node_ip: 172.17.8.24
  num_metric_batches_dropped: 0
  pid: 26970
  policy_reward_mean: {}
  time_since_restore: 16158.121831655502
  time_this_iter_s: 56.58308410644531
  time_total_s: 16158.121831655502
  timestamp: 1594201153
  timesteps_since_restore: 11440000
  timesteps_this_iter: 40000
  timesteps_total: 11440000
  training_iteration: 286
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26970], 16158 s, 286 iter, 11440000 ts, 449 rew

agent-1: 14.0
agent-2: 15.0
agent-3: 18.0
agent-4: 5.0
agent-5: 13.0
agent-6: 12.0
agent-7: 12.0
agent-8: 14.0
agent-9: 9.0
agent-10: 17.0
agent-11: 11.0
agent-12: 9.0
agent-13: 7.0
agent-14: 9.0
agent-15: 9.0
agent-16: 5.0
agent-17: 8.0
agent-18: 11.0
agent-19: 11.0
agent-20: 10.0
agent-21: 10.0
agent-22: 9.0
agent-23: 12.0
agent-24: 16.0
agent-25: 16.0
agent-26: 13.0
agent-27: 14.0
agent-28: 16.0
agent-29: 11.0
agent-30: 14.0
agent-31: 6.0
agent-32: 12.0
agent-33: 12.0
agent-34: 12.0
agent-35: 10.0
agent-36: 9.0
agent-37: 8.0
agent-38: 9.0
agent-39: 13.0
agent-40: 15.0
Sum Reward: 456.0
Avg Reward: 11.4
Min Reward: 5.0
Max Reward: 18.0
Gini Coefficient: 0.15756578947368421
20:20 Ratio: 2.2280701754385963
Max-min Ratio: 3.6
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-08_05-40-10
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 484.0
  episode_reward_mean: 448.56
  episode_reward_min: 423.0
  episodes_this_iter: 1
  episodes_total: 286
  experiment_id: 4e724eb5b3a34f42879644e84578eec0
  hostname: gpu024
  info:
    apply_time_ms: 3.357
    dispatch_time_ms: 5.961
    learner:
      cur_lr: 0.0005980959977023304
      grad_gnorm: 1.4450160264968872
      policy_entropy: 774.0443115234375
      policy_loss: -1.9188555479049683
      var_gnorm: 37.94742202758789
      vf_explained_var: -0.9032238721847534
      vf_loss: 4.430055560078472e-05
    num_steps_sampled: 11480000
    num_steps_trained: 11480000
    wait_time_ms: 541.716
  iterations_since_restore: 287
  node_ip: 172.17.8.24
  num_metric_batches_dropped: 0
  pid: 26970
  policy_reward_mean: {}
  time_since_restore: 16214.87164902687
  time_this_iter_s: 56.74981737136841
  time_total_s: 16214.87164902687
  timestamp: 1594201210
  timesteps_since_restore: 11480000
  timesteps_this_iter: 40000
  timesteps_total: 11480000
  training_iteration: 287
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26970], 16214 s, 287 iter, 11480000 ts, 449 rew

agent-1: 10.0
agent-2: 9.0
agent-3: 11.0
agent-4: 10.0
agent-5: 12.0
agent-6: 10.0
agent-7: 7.0
agent-8: 7.0
agent-9: 14.0
agent-10: 12.0
agent-11: 16.0
agent-12: 6.0
agent-13: 6.0
agent-14: 10.0
agent-15: 8.0
agent-16: 8.0
agent-17: 7.0
agent-18: 20.0
agent-19: 10.0
agent-20: 12.0
agent-21: 10.0
agent-22: 13.0
agent-23: 14.0
agent-24: 11.0
agent-25: 14.0
agent-26: 7.0
agent-27: 18.0
agent-28: 10.0
agent-29: 20.0
agent-30: 6.0
agent-31: 12.0
agent-32: 10.0
agent-33: 9.0
agent-34: 16.0
agent-35: 13.0
agent-36: 9.0
agent-37: 12.0
agent-38: 9.0
agent-39: 10.0
agent-40: 12.0
Sum Reward: 440.0
Avg Reward: 11.0
Min Reward: 6.0
Max Reward: 20.0
Gini Coefficient: 0.17227272727272727
20:20 Ratio: 2.4444444444444446
Max-min Ratio: 3.3333333333333335
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-08_05-41-06
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 484.0
  episode_reward_mean: 448.59
  episode_reward_min: 423.0
  episodes_this_iter: 1
  episodes_total: 287
  experiment_id: 4e724eb5b3a34f42879644e84578eec0
  hostname: gpu024
  info:
    apply_time_ms: 2.51
    dispatch_time_ms: 6.002
    learner:
      cur_lr: 0.0005954320076853037
      grad_gnorm: 0.3650650084018707
      policy_entropy: 772.9340209960938
      policy_loss: 0.11460274457931519
      var_gnorm: 37.932743072509766
      vf_explained_var: -1.0
      vf_loss: 0.00016966680414043367
    num_steps_sampled: 11520000
    num_steps_trained: 11520000
    wait_time_ms: 563.431
  iterations_since_restore: 288
  node_ip: 172.17.8.24
  num_metric_batches_dropped: 0
  pid: 26970
  policy_reward_mean: {}
  time_since_restore: 16271.508249759674
  time_this_iter_s: 56.636600732803345
  time_total_s: 16271.508249759674
  timestamp: 1594201266
  timesteps_since_restore: 11520000
  timesteps_this_iter: 40000
  timesteps_total: 11520000
  training_iteration: 288
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26970], 16271 s, 288 iter, 11520000 ts, 449 rew

agent-1: 10.0
agent-2: 13.0
agent-3: 11.0
agent-4: 14.0
agent-5: 10.0
agent-6: 9.0
agent-7: 9.0
agent-8: 11.0
agent-9: 13.0
agent-10: 14.0
agent-11: 14.0
agent-12: 12.0
agent-13: 13.0
agent-14: 10.0
agent-15: 19.0
agent-16: 16.0
agent-17: 11.0
agent-18: 6.0
agent-19: 10.0
agent-20: 16.0
agent-21: 16.0
agent-22: 7.0
agent-23: 13.0
agent-24: 4.0
agent-25: 10.0
agent-26: 12.0
agent-27: 15.0
agent-28: 5.0
agent-29: 5.0
agent-30: 14.0
agent-31: 8.0
agent-32: 9.0
agent-33: 21.0
agent-34: 12.0
agent-35: 9.0
agent-36: 10.0
agent-37: 15.0
agent-38: 14.0
agent-39: 5.0
agent-40: 12.0
Sum Reward: 457.0
Avg Reward: 11.425
Min Reward: 4.0
Max Reward: 21.0
Gini Coefficient: 0.1824398249452954
20:20 Ratio: 2.693877551020408
Max-min Ratio: 5.25
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-08_05-42-03
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 484.0
  episode_reward_mean: 448.77
  episode_reward_min: 423.0
  episodes_this_iter: 1
  episodes_total: 288
  experiment_id: 4e724eb5b3a34f42879644e84578eec0
  hostname: gpu024
  info:
    apply_time_ms: 2.649
    dispatch_time_ms: 7.013
    learner:
      cur_lr: 0.000592768017668277
      grad_gnorm: 4.557960033416748
      policy_entropy: 772.0093994140625
      policy_loss: 3.8050689697265625
      var_gnorm: 37.983253479003906
      vf_explained_var: 0.1297091245651245
      vf_loss: 0.003019397845491767
    num_steps_sampled: 11560000
    num_steps_trained: 11560000
    wait_time_ms: 562.921
  iterations_since_restore: 289
  node_ip: 172.17.8.24
  num_metric_batches_dropped: 0
  pid: 26970
  policy_reward_mean: {}
  time_since_restore: 16327.839769363403
  time_this_iter_s: 56.33151960372925
  time_total_s: 16327.839769363403
  timestamp: 1594201323
  timesteps_since_restore: 11560000
  timesteps_this_iter: 40000
  timesteps_total: 11560000
  training_iteration: 289
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26970], 16327 s, 289 iter, 11560000 ts, 449 rew

agent-1: 13.0
agent-2: 8.0
agent-3: 9.0
agent-4: 14.0
agent-5: 11.0
agent-6: 10.0
agent-7: 5.0
agent-8: 13.0
agent-9: 13.0
agent-10: 10.0
agent-11: 19.0
agent-12: 9.0
agent-13: 11.0
agent-14: 12.0
agent-15: 15.0
agent-16: 13.0
agent-17: 9.0
agent-18: 9.0
agent-19: 5.0
agent-20: 6.0
agent-21: 4.0
agent-22: 7.0
agent-23: 13.0
agent-24: 7.0
agent-25: 14.0
agent-26: 10.0
agent-27: 20.0
agent-28: 10.0
agent-29: 8.0
agent-30: 14.0
agent-31: 12.0
agent-32: 10.0
agent-33: 11.0
agent-34: 16.0
agent-35: 13.0
agent-36: 18.0
agent-37: 13.0
agent-38: 20.0
agent-39: 4.0
agent-40: 16.0
Sum Reward: 454.0
Avg Reward: 11.35
Min Reward: 4.0
Max Reward: 20.0
Gini Coefficient: 0.20110132158590308
20:20 Ratio: 3.0
Max-min Ratio: 5.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-08_05-42-59
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 484.0
  episode_reward_mean: 448.82
  episode_reward_min: 423.0
  episodes_this_iter: 1
  episodes_total: 289
  experiment_id: 4e724eb5b3a34f42879644e84578eec0
  hostname: gpu024
  info:
    apply_time_ms: 3.796
    dispatch_time_ms: 7.502
    learner:
      cur_lr: 0.0005901040276512504
      grad_gnorm: 0.4434795379638672
      policy_entropy: 767.7132568359375
      policy_loss: 0.9997203946113586
      var_gnorm: 38.00728225708008
      vf_explained_var: -1.0
      vf_loss: 6.846943870186806e-05
    num_steps_sampled: 11600000
    num_steps_trained: 11600000
    wait_time_ms: 557.74
  iterations_since_restore: 290
  node_ip: 172.17.8.24
  num_metric_batches_dropped: 0
  pid: 26970
  policy_reward_mean: {}
  time_since_restore: 16384.506122112274
  time_this_iter_s: 56.66635274887085
  time_total_s: 16384.506122112274
  timestamp: 1594201379
  timesteps_since_restore: 11600000
  timesteps_this_iter: 40000
  timesteps_total: 11600000
  training_iteration: 290
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26970], 16384 s, 290 iter, 11600000 ts, 449 rew

agent-1: 10.0
agent-2: 19.0
agent-3: 15.0
agent-4: 11.0
agent-5: 15.0
agent-6: 15.0
agent-7: 17.0
agent-8: 4.0
agent-9: 13.0
agent-10: 17.0
agent-11: 7.0
agent-12: 10.0
agent-13: 8.0
agent-14: 16.0
agent-15: 15.0
agent-16: 9.0
agent-17: 12.0
agent-18: 6.0
agent-19: 16.0
agent-20: 9.0
agent-21: 10.0
agent-22: 15.0
agent-23: 11.0
agent-24: 13.0
agent-25: 14.0
agent-26: 11.0
agent-27: 12.0
agent-28: 10.0
agent-29: 10.0
agent-30: 7.0
agent-31: 7.0
agent-32: 14.0
agent-33: 4.0
agent-34: 10.0
agent-35: 10.0
agent-36: 7.0
agent-37: 14.0
agent-38: 12.0
agent-39: 9.0
agent-40: 7.0
Sum Reward: 451.0
Avg Reward: 11.275
Min Reward: 4.0
Max Reward: 19.0
Gini Coefficient: 0.18398004434589801
20:20 Ratio: 2.6530612244897958
Max-min Ratio: 4.75
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-08_05-43-56
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 484.0
  episode_reward_mean: 448.92
  episode_reward_min: 423.0
  episodes_this_iter: 1
  episodes_total: 290
  experiment_id: 4e724eb5b3a34f42879644e84578eec0
  hostname: gpu024
  info:
    apply_time_ms: 2.987
    dispatch_time_ms: 5.299
    learner:
      cur_lr: 0.0005874399794265628
      grad_gnorm: 2.887752056121826
      policy_entropy: 777.4147338867188
      policy_loss: 1.386044979095459
      var_gnorm: 38.03633499145508
      vf_explained_var: -0.07412958145141602
      vf_loss: 0.001294043380767107
    num_steps_sampled: 11640000
    num_steps_trained: 11640000
    wait_time_ms: 559.739
  iterations_since_restore: 291
  node_ip: 172.17.8.24
  num_metric_batches_dropped: 0
  pid: 26970
  policy_reward_mean: {}
  time_since_restore: 16441.007577896118
  time_this_iter_s: 56.501455783843994
  time_total_s: 16441.007577896118
  timestamp: 1594201436
  timesteps_since_restore: 11640000
  timesteps_this_iter: 40000
  timesteps_total: 11640000
  training_iteration: 291
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26970], 16441 s, 291 iter, 11640000 ts, 449 rew

agent-1: 12.0
agent-2: 11.0
agent-3: 15.0
agent-4: 6.0
agent-5: 2.0
agent-6: 14.0
agent-7: 12.0
agent-8: 19.0
agent-9: 10.0
agent-10: 4.0
agent-11: 12.0
agent-12: 4.0
agent-13: 11.0
agent-14: 10.0
agent-15: 18.0
agent-16: 8.0
agent-17: 14.0
agent-18: 15.0
agent-19: 13.0
agent-20: 10.0
agent-21: 14.0
agent-22: 11.0
agent-23: 11.0
agent-24: 11.0
agent-25: 9.0
agent-26: 16.0
agent-27: 8.0
agent-28: 6.0
agent-29: 7.0
agent-30: 11.0
agent-31: 15.0
agent-32: 6.0
agent-33: 11.0
agent-34: 8.0
agent-35: 10.0
agent-36: 8.0
agent-37: 23.0
agent-38: 11.0
agent-39: 15.0
agent-40: 14.0
Sum Reward: 445.0
Avg Reward: 11.125
Min Reward: 2.0
Max Reward: 23.0
Gini Coefficient: 0.20780898876404494
20:20 Ratio: 3.1627906976744184
Max-min Ratio: 11.5
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-08_05-44-52
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 484.0
  episode_reward_mean: 448.89
  episode_reward_min: 423.0
  episodes_this_iter: 1
  episodes_total: 291
  experiment_id: 4e724eb5b3a34f42879644e84578eec0
  hostname: gpu024
  info:
    apply_time_ms: 2.442
    dispatch_time_ms: 7.369
    learner:
      cur_lr: 0.0005847759894095361
      grad_gnorm: 1.0615299940109253
      policy_entropy: 777.0598754882812
      policy_loss: -0.5846381187438965
      var_gnorm: 38.03590393066406
      vf_explained_var: -1.0
      vf_loss: 0.001528944936580956
    num_steps_sampled: 11680000
    num_steps_trained: 11680000
    wait_time_ms: 554.626
  iterations_since_restore: 292
  node_ip: 172.17.8.24
  num_metric_batches_dropped: 0
  pid: 26970
  policy_reward_mean: {}
  time_since_restore: 16497.11401629448
  time_this_iter_s: 56.106438398361206
  time_total_s: 16497.11401629448
  timestamp: 1594201492
  timesteps_since_restore: 11680000
  timesteps_this_iter: 40000
  timesteps_total: 11680000
  training_iteration: 292
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26970], 16497 s, 292 iter, 11680000 ts, 449 rew

agent-1: 19.0
agent-2: 17.0
agent-3: 15.0
agent-4: 14.0
agent-5: 9.0
agent-6: 9.0
agent-7: 13.0
agent-8: 10.0
agent-9: 13.0
agent-10: 13.0
agent-11: 9.0
agent-12: 15.0
agent-13: 14.0
agent-14: 13.0
agent-15: 4.0
agent-16: 13.0
agent-17: 10.0
agent-18: 10.0
agent-19: 8.0
agent-20: 12.0
agent-21: 12.0
agent-22: 9.0
agent-23: 11.0
agent-24: 12.0
agent-25: 8.0
agent-26: 12.0
agent-27: 17.0
agent-28: 10.0
agent-29: 14.0
agent-30: 8.0
agent-31: 13.0
agent-32: 5.0
agent-33: 8.0
agent-34: 14.0
agent-35: 6.0
agent-36: 4.0
agent-37: 14.0
agent-38: 9.0
agent-39: 13.0
agent-40: 13.0
Sum Reward: 452.0
Avg Reward: 11.3
Min Reward: 4.0
Max Reward: 19.0
Gini Coefficient: 0.168141592920354
20:20 Ratio: 2.450980392156863
Max-min Ratio: 4.75
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-08_05-45-49
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 484.0
  episode_reward_mean: 448.81
  episode_reward_min: 423.0
  episodes_this_iter: 1
  episodes_total: 292
  experiment_id: 4e724eb5b3a34f42879644e84578eec0
  hostname: gpu024
  info:
    apply_time_ms: 3.163
    dispatch_time_ms: 6.345
    learner:
      cur_lr: 0.0005821119993925095
      grad_gnorm: 7.638021469116211
      policy_entropy: 768.4700927734375
      policy_loss: -6.416910171508789
      var_gnorm: 38.018707275390625
      vf_explained_var: -1.0
      vf_loss: 0.01580604538321495
    num_steps_sampled: 11720000
    num_steps_trained: 11720000
    wait_time_ms: 553.482
  iterations_since_restore: 293
  node_ip: 172.17.8.24
  num_metric_batches_dropped: 0
  pid: 26970
  policy_reward_mean: {}
  time_since_restore: 16553.92675471306
  time_this_iter_s: 56.8127384185791
  time_total_s: 16553.92675471306
  timestamp: 1594201549
  timesteps_since_restore: 11720000
  timesteps_this_iter: 40000
  timesteps_total: 11720000
  training_iteration: 293
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26970], 16553 s, 293 iter, 11720000 ts, 449 rew

agent-1: 14.0
agent-2: 16.0
agent-3: 14.0
agent-4: 7.0
agent-5: -39.0
agent-6: 10.0
agent-7: 11.0
agent-8: 17.0
agent-9: 10.0
agent-10: 7.0
agent-11: 13.0
agent-12: 14.0
agent-13: 9.0
agent-14: 11.0
agent-15: 12.0
agent-16: 9.0
agent-17: 12.0
agent-18: 11.0
agent-19: 12.0
agent-20: 16.0
agent-21: 9.0
agent-22: 8.0
agent-23: 5.0
agent-24: 15.0
agent-25: 13.0
agent-26: 10.0
agent-27: 15.0
agent-28: 10.0
agent-29: 19.0
agent-30: 14.0
agent-31: 6.0
agent-32: 9.0
agent-33: 7.0
agent-34: 11.0
agent-35: 13.0
agent-36: 7.0
agent-37: 9.0
agent-38: 7.0
agent-39: 9.0
agent-40: 10.0
Sum Reward: 392.0
Avg Reward: 9.8
Min Reward: -39.0
Max Reward: 19.0
Gini Coefficient: 0.30293367346938777
20:20 Ratio: 18.0
Max-min Ratio: -0.48717948717948717
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-08_05-46-45
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 484.0
  episode_reward_mean: 448.23
  episode_reward_min: 392.0
  episodes_this_iter: 1
  episodes_total: 293
  experiment_id: 4e724eb5b3a34f42879644e84578eec0
  hostname: gpu024
  info:
    apply_time_ms: 2.532
    dispatch_time_ms: 5.132
    learner:
      cur_lr: 0.0005794480093754828
      grad_gnorm: 1.729651689529419
      policy_entropy: 765.992431640625
      policy_loss: -0.8706409931182861
      var_gnorm: 38.04947280883789
      vf_explained_var: -0.4338686466217041
      vf_loss: 0.0006712981266900897
    num_steps_sampled: 11760000
    num_steps_trained: 11760000
    wait_time_ms: 549.415
  iterations_since_restore: 294
  node_ip: 172.17.8.24
  num_metric_batches_dropped: 0
  pid: 26970
  policy_reward_mean: {}
  time_since_restore: 16610.499571800232
  time_this_iter_s: 56.57281708717346
  time_total_s: 16610.499571800232
  timestamp: 1594201605
  timesteps_since_restore: 11760000
  timesteps_this_iter: 40000
  timesteps_total: 11760000
  training_iteration: 294
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26970], 16610 s, 294 iter, 11760000 ts, 448 rew

agent-1: 21.0
agent-2: 5.0
agent-3: 8.0
agent-4: 21.0
agent-5: 0.0
agent-6: 18.0
agent-7: 18.0
agent-8: 18.0
agent-9: 11.0
agent-10: 15.0
agent-11: 11.0
agent-12: 12.0
agent-13: 8.0
agent-14: 10.0
agent-15: 12.0
agent-16: 15.0
agent-17: 10.0
agent-18: 19.0
agent-19: 12.0
agent-20: 2.0
agent-21: 9.0
agent-22: 19.0
agent-23: 6.0
agent-24: 8.0
agent-25: 4.0
agent-26: 18.0
agent-27: 2.0
agent-28: 4.0
agent-29: 17.0
agent-30: 10.0
agent-31: 13.0
agent-32: 2.0
agent-33: 8.0
agent-34: 15.0
agent-35: 7.0
agent-36: 11.0
agent-37: 11.0
agent-38: 12.0
agent-39: 12.0
agent-40: 11.0
Sum Reward: 445.0
Avg Reward: 11.125
Min Reward: 0.0
Max Reward: 21.0
Gini Coefficient: 0.2792696629213483
20:20 Ratio: 6.08
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-08_05-47-42
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 484.0
  episode_reward_mean: 448.05
  episode_reward_min: 392.0
  episodes_this_iter: 1
  episodes_total: 294
  experiment_id: 4e724eb5b3a34f42879644e84578eec0
  hostname: gpu024
  info:
    apply_time_ms: 2.5
    dispatch_time_ms: 6.814
    learner:
      cur_lr: 0.0005767840193584561
      grad_gnorm: 4.078890800476074
      policy_entropy: 773.0589599609375
      policy_loss: 1.7058266401290894
      var_gnorm: 38.02513885498047
      vf_explained_var: -0.415918231010437
      vf_loss: 0.0028376090340316296
    num_steps_sampled: 11800000
    num_steps_trained: 11800000
    wait_time_ms: 559.923
  iterations_since_restore: 295
  node_ip: 172.17.8.24
  num_metric_batches_dropped: 0
  pid: 26970
  policy_reward_mean: {}
  time_since_restore: 16666.998963832855
  time_this_iter_s: 56.49939203262329
  time_total_s: 16666.998963832855
  timestamp: 1594201662
  timesteps_since_restore: 11800000
  timesteps_this_iter: 40000
  timesteps_total: 11800000
  training_iteration: 295
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26970], 16666 s, 295 iter, 11800000 ts, 448 rew

agent-1: 12.0
agent-2: 18.0
agent-3: 16.0
agent-4: 15.0
agent-5: 8.0
agent-6: 10.0
agent-7: 7.0
agent-8: 5.0
agent-9: 22.0
agent-10: 11.0
agent-11: 15.0
agent-12: 10.0
agent-13: 14.0
agent-14: 6.0
agent-15: 14.0
agent-16: 15.0
agent-17: 19.0
agent-18: 18.0
agent-19: 11.0
agent-20: 19.0
agent-21: 13.0
agent-22: 12.0
agent-23: 14.0
agent-24: 13.0
agent-25: 11.0
agent-26: 10.0
agent-27: 6.0
agent-28: 9.0
agent-29: 12.0
agent-30: 5.0
agent-31: 14.0
agent-32: 4.0
agent-33: 8.0
agent-34: 8.0
agent-35: 12.0
agent-36: 16.0
agent-37: 4.0
agent-38: 10.0
agent-39: 3.0
agent-40: 14.0
Sum Reward: 463.0
Avg Reward: 11.575
Min Reward: 3.0
Max Reward: 22.0
Gini Coefficient: 0.22273218142548595
20:20 Ratio: 3.575
Max-min Ratio: 7.333333333333333
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-08_05-48-38
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 484.0
  episode_reward_mean: 448.07
  episode_reward_min: 392.0
  episodes_this_iter: 1
  episodes_total: 295
  experiment_id: 4e724eb5b3a34f42879644e84578eec0
  hostname: gpu024
  info:
    apply_time_ms: 2.696
    dispatch_time_ms: 6.113
    learner:
      cur_lr: 0.0005741199711337686
      grad_gnorm: 0.7916550040245056
      policy_entropy: 771.209716796875
      policy_loss: -0.010667849332094193
      var_gnorm: 38.08955001831055
      vf_explained_var: -0.5222303867340088
      vf_loss: 0.00044282377348281443
    num_steps_sampled: 11840000
    num_steps_trained: 11840000
    wait_time_ms: 548.235
  iterations_since_restore: 296
  node_ip: 172.17.8.24
  num_metric_batches_dropped: 0
  pid: 26970
  policy_reward_mean: {}
  time_since_restore: 16722.88167476654
  time_this_iter_s: 55.8827109336853
  time_total_s: 16722.88167476654
  timestamp: 1594201718
  timesteps_since_restore: 11840000
  timesteps_this_iter: 40000
  timesteps_total: 11840000
  training_iteration: 296
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26970], 16722 s, 296 iter, 11840000 ts, 448 rew

agent-1: 5.0
agent-2: 12.0
agent-3: 9.0
agent-4: 3.0
agent-5: 4.0
agent-6: 9.0
agent-7: 16.0
agent-8: 8.0
agent-9: 12.0
agent-10: 6.0
agent-11: 23.0
agent-12: 19.0
agent-13: 12.0
agent-14: 9.0
agent-15: 10.0
agent-16: 14.0
agent-17: 8.0
agent-18: 5.0
agent-19: 16.0
agent-20: 13.0
agent-21: 4.0
agent-22: 20.0
agent-23: 13.0
agent-24: 15.0
agent-25: 17.0
agent-26: 19.0
agent-27: 5.0
agent-28: 13.0
agent-29: 8.0
agent-30: 11.0
agent-31: 22.0
agent-32: 15.0
agent-33: 14.0
agent-34: 8.0
agent-35: 7.0
agent-36: 10.0
agent-37: 14.0
agent-38: 20.0
agent-39: 12.0
agent-40: 19.0
Sum Reward: 479.0
Avg Reward: 11.975
Min Reward: 3.0
Max Reward: 23.0
Gini Coefficient: 0.2504697286012526
20:20 Ratio: 4.076923076923077
Max-min Ratio: 7.666666666666667
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-08_05-49-34
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 484.0
  episode_reward_mean: 448.31
  episode_reward_min: 392.0
  episodes_this_iter: 1
  episodes_total: 296
  experiment_id: 4e724eb5b3a34f42879644e84578eec0
  hostname: gpu024
  info:
    apply_time_ms: 2.602
    dispatch_time_ms: 6.957
    learner:
      cur_lr: 0.0005714559811167419
      grad_gnorm: 3.829282760620117
      policy_entropy: 753.986083984375
      policy_loss: 1.515113353729248
      var_gnorm: 38.10280227661133
      vf_explained_var: -1.0
      vf_loss: 0.0063310228288173676
    num_steps_sampled: 11880000
    num_steps_trained: 11880000
    wait_time_ms: 547.408
  iterations_since_restore: 297
  node_ip: 172.17.8.24
  num_metric_batches_dropped: 0
  pid: 26970
  policy_reward_mean: {}
  time_since_restore: 16779.281918287277
  time_this_iter_s: 56.400243520736694
  time_total_s: 16779.281918287277
  timestamp: 1594201774
  timesteps_since_restore: 11880000
  timesteps_this_iter: 40000
  timesteps_total: 11880000
  training_iteration: 297
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26970], 16779 s, 297 iter, 11880000 ts, 448 rew

agent-1: 4.0
agent-2: 19.0
agent-3: 2.0
agent-4: 11.0
agent-5: 7.0
agent-6: 12.0
agent-7: 16.0
agent-8: 9.0
agent-9: 17.0
agent-10: 10.0
agent-11: 14.0
agent-12: 20.0
agent-13: 15.0
agent-14: 16.0
agent-15: 16.0
agent-16: 1.0
agent-17: 12.0
agent-18: 17.0
agent-19: 4.0
agent-20: 2.0
agent-21: 16.0
agent-22: 10.0
agent-23: 17.0
agent-24: 14.0
agent-25: 11.0
agent-26: 9.0
agent-27: 15.0
agent-28: 3.0
agent-29: 22.0
agent-30: 15.0
agent-31: 0.0
agent-32: 17.0
agent-33: 5.0
agent-34: 12.0
agent-35: 20.0
agent-36: 10.0
agent-37: 11.0
agent-38: 14.0
agent-39: 13.0
agent-40: 6.0
Sum Reward: 464.0
Avg Reward: 11.6
Min Reward: 0.0
Max Reward: 22.0
Gini Coefficient: 0.27726293103448274
20:20 Ratio: 7.095238095238095
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-08_05-50-31
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 484.0
  episode_reward_mean: 448.48
  episode_reward_min: 392.0
  episodes_this_iter: 1
  episodes_total: 297
  experiment_id: 4e724eb5b3a34f42879644e84578eec0
  hostname: gpu024
  info:
    apply_time_ms: 2.492
    dispatch_time_ms: 5.652
    learner:
      cur_lr: 0.0005687919910997152
      grad_gnorm: 0.5269613862037659
      policy_entropy: 770.46044921875
      policy_loss: -0.2587786316871643
      var_gnorm: 38.12898254394531
      vf_explained_var: -0.7568390369415283
      vf_loss: 0.00010982243838952854
    num_steps_sampled: 11920000
    num_steps_trained: 11920000
    wait_time_ms: 555.474
  iterations_since_restore: 298
  node_ip: 172.17.8.24
  num_metric_batches_dropped: 0
  pid: 26970
  policy_reward_mean: {}
  time_since_restore: 16836.030335903168
  time_this_iter_s: 56.7484176158905
  time_total_s: 16836.030335903168
  timestamp: 1594201831
  timesteps_since_restore: 11920000
  timesteps_this_iter: 40000
  timesteps_total: 11920000
  training_iteration: 298
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26970], 16836 s, 298 iter, 11920000 ts, 448 rew

agent-1: 9.0
agent-2: 8.0
agent-3: 17.0
agent-4: 21.0
agent-5: 13.0
agent-6: 16.0
agent-7: 15.0
agent-8: 5.0
agent-9: 14.0
agent-10: 3.0
agent-11: 16.0
agent-12: 14.0
agent-13: 11.0
agent-14: 13.0
agent-15: 15.0
agent-16: 9.0
agent-17: 7.0
agent-18: 22.0
agent-19: 0.0
agent-20: 13.0
agent-21: 9.0
agent-22: 11.0
agent-23: 1.0
agent-24: 15.0
agent-25: 11.0
agent-26: 9.0
agent-27: 20.0
agent-28: 13.0
agent-29: 0.0
agent-30: 17.0
agent-31: 13.0
agent-32: 5.0
agent-33: 13.0
agent-34: 5.0
agent-35: 19.0
agent-36: 14.0
agent-37: 12.0
agent-38: 8.0
agent-39: 14.0
agent-40: 5.0
Sum Reward: 455.0
Avg Reward: 11.375
Min Reward: 0.0
Max Reward: 22.0
Gini Coefficient: 0.26972527472527474
20:20 Ratio: 6.166666666666667
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-08_05-51-28
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 484.0
  episode_reward_mean: 448.7
  episode_reward_min: 392.0
  episodes_this_iter: 1
  episodes_total: 298
  experiment_id: 4e724eb5b3a34f42879644e84578eec0
  hostname: gpu024
  info:
    apply_time_ms: 2.803
    dispatch_time_ms: 6.647
    learner:
      cur_lr: 0.0005661280010826886
      grad_gnorm: 7.855673313140869
      policy_entropy: 629.499267578125
      policy_loss: -3.501495122909546
      var_gnorm: 38.14888000488281
      vf_explained_var: 0.4025269150733948
      vf_loss: 0.024051956832408905
    num_steps_sampled: 11960000
    num_steps_trained: 11960000
    wait_time_ms: 555.776
  iterations_since_restore: 299
  node_ip: 172.17.8.24
  num_metric_batches_dropped: 0
  pid: 26970
  policy_reward_mean: {}
  time_since_restore: 16892.537818431854
  time_this_iter_s: 56.50748252868652
  time_total_s: 16892.537818431854
  timestamp: 1594201888
  timesteps_since_restore: 11960000
  timesteps_this_iter: 40000
  timesteps_total: 11960000
  training_iteration: 299
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26970], 16892 s, 299 iter, 11960000 ts, 449 rew

agent-1: 9.0
agent-2: 10.0
agent-3: 11.0
agent-4: 12.0
agent-5: 1.0
agent-6: 20.0
agent-7: 14.0
agent-8: 14.0
agent-9: 16.0
agent-10: 10.0
agent-11: 12.0
agent-12: 10.0
agent-13: 10.0
agent-14: 14.0
agent-15: 20.0
agent-16: 6.0
agent-17: 16.0
agent-18: 11.0
agent-19: 6.0
agent-20: 11.0
agent-21: 9.0
agent-22: 15.0
agent-23: 7.0
agent-24: 18.0
agent-25: 4.0
agent-26: 12.0
agent-27: 12.0
agent-28: 15.0
agent-29: 7.0
agent-30: 6.0
agent-31: 10.0
agent-32: 8.0
agent-33: 15.0
agent-34: 10.0
agent-35: 12.0
agent-36: 12.0
agent-37: 3.0
agent-38: 17.0
agent-39: 17.0
agent-40: 13.0
Sum Reward: 455.0
Avg Reward: 11.375
Min Reward: 1.0
Max Reward: 20.0
Gini Coefficient: 0.21478021978021977
20:20 Ratio: 3.475
Max-min Ratio: 20.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-08_05-52-24
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 484.0
  episode_reward_mean: 448.79
  episode_reward_min: 392.0
  episodes_this_iter: 1
  episodes_total: 299
  experiment_id: 4e724eb5b3a34f42879644e84578eec0
  hostname: gpu024
  info:
    apply_time_ms: 2.849
    dispatch_time_ms: 6.956
    learner:
      cur_lr: 0.0005634640110656619
      grad_gnorm: 1.1039332151412964
      policy_entropy: 774.5023803710938
      policy_loss: -0.6087217330932617
      var_gnorm: 38.145423889160156
      vf_explained_var: -0.36999285221099854
      vf_loss: 0.00023603843874298036
    num_steps_sampled: 12000000
    num_steps_trained: 12000000
    wait_time_ms: 549.863
  iterations_since_restore: 300
  node_ip: 172.17.8.24
  num_metric_batches_dropped: 0
  pid: 26970
  policy_reward_mean: {}
  time_since_restore: 16948.66431570053
  time_this_iter_s: 56.12649726867676
  time_total_s: 16948.66431570053
  timestamp: 1594201944
  timesteps_since_restore: 12000000
  timesteps_this_iter: 40000
  timesteps_total: 12000000
  training_iteration: 300
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26970], 16948 s, 300 iter, 12000000 ts, 449 rew

agent-1: 15.0
agent-2: 22.0
agent-3: 15.0
agent-4: 8.0
agent-5: 6.0
agent-6: 4.0
agent-7: 19.0
agent-8: 6.0
agent-9: 0.0
agent-10: 6.0
agent-11: 20.0
agent-12: 0.0
agent-13: 2.0
agent-14: 16.0
agent-15: 12.0
agent-16: 1.0
agent-17: 14.0
agent-18: 16.0
agent-19: 14.0
agent-20: 15.0
agent-21: 13.0
agent-22: 6.0
agent-23: 5.0
agent-24: 16.0
agent-25: 23.0
agent-26: 20.0
agent-27: 14.0
agent-28: 7.0
agent-29: 9.0
agent-30: 24.0
agent-31: 16.0
agent-32: 12.0
agent-33: 8.0
agent-34: 10.0
agent-35: 6.0
agent-36: 26.0
agent-37: 16.0
agent-38: 19.0
agent-39: 13.0
agent-40: 13.0
Sum Reward: 487.0
Avg Reward: 12.175
Min Reward: 0.0
Max Reward: 26.0
Gini Coefficient: 0.311652977412731
20:20 Ratio: 7.208333333333333
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-08_05-53-20
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 487.0
  episode_reward_mean: 448.99
  episode_reward_min: 392.0
  episodes_this_iter: 1
  episodes_total: 300
  experiment_id: 4e724eb5b3a34f42879644e84578eec0
  hostname: gpu024
  info:
    apply_time_ms: 2.506
    dispatch_time_ms: 5.819
    learner:
      cur_lr: 0.0005608000210486352
      grad_gnorm: 1.2174897193908691
      policy_entropy: 698.7432250976562
      policy_loss: 0.6267942190170288
      var_gnorm: 38.150489807128906
      vf_explained_var: -0.3845479488372803
      vf_loss: 0.007868649438023567
    num_steps_sampled: 12040000
    num_steps_trained: 12040000
    wait_time_ms: 559.475
  iterations_since_restore: 301
  node_ip: 172.17.8.24
  num_metric_batches_dropped: 0
  pid: 26970
  policy_reward_mean: {}
  time_since_restore: 17005.250002622604
  time_this_iter_s: 56.585686922073364
  time_total_s: 17005.250002622604
  timestamp: 1594202000
  timesteps_since_restore: 12040000
  timesteps_this_iter: 40000
  timesteps_total: 12040000
  training_iteration: 301
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26970], 17005 s, 301 iter, 12040000 ts, 449 rew

agent-1: 16.0
agent-2: 14.0
agent-3: 12.0
agent-4: 10.0
agent-5: 10.0
agent-6: 15.0
agent-7: 4.0
agent-8: 14.0
agent-9: 8.0
agent-10: 16.0
agent-11: 16.0
agent-12: 9.0
agent-13: 12.0
agent-14: 12.0
agent-15: 16.0
agent-16: 5.0
agent-17: 16.0
agent-18: 13.0
agent-19: 8.0
agent-20: 16.0
agent-21: 9.0
agent-22: 13.0
agent-23: 2.0
agent-24: 14.0
agent-25: 6.0
agent-26: 13.0
agent-27: 9.0
agent-28: 12.0
agent-29: 8.0
agent-30: 8.0
agent-31: 10.0
agent-32: 8.0
agent-33: 27.0
agent-34: 17.0
agent-35: 11.0
agent-36: 4.0
agent-37: 6.0
agent-38: 0.0
agent-39: 14.0
agent-40: 21.0
Sum Reward: 454.0
Avg Reward: 11.35
Min Reward: 0.0
Max Reward: 27.0
Gini Coefficient: 0.24779735682819384
20:20 Ratio: 4.142857142857143
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-08_05-54-17
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 487.0
  episode_reward_mean: 449.13
  episode_reward_min: 392.0
  episodes_this_iter: 1
  episodes_total: 301
  experiment_id: 4e724eb5b3a34f42879644e84578eec0
  hostname: gpu024
  info:
    apply_time_ms: 2.614
    dispatch_time_ms: 5.217
    learner:
      cur_lr: 0.0005581359728239477
      grad_gnorm: 0.5589139461517334
      policy_entropy: 776.9658203125
      policy_loss: -0.04209935665130615
      var_gnorm: 38.177303314208984
      vf_explained_var: -1.0
      vf_loss: 0.0001129930024035275
    num_steps_sampled: 12080000
    num_steps_trained: 12080000
    wait_time_ms: 548.291
  iterations_since_restore: 302
  node_ip: 172.17.8.24
  num_metric_batches_dropped: 0
  pid: 26970
  policy_reward_mean: {}
  time_since_restore: 17061.840196847916
  time_this_iter_s: 56.59019422531128
  time_total_s: 17061.840196847916
  timestamp: 1594202057
  timesteps_since_restore: 12080000
  timesteps_this_iter: 40000
  timesteps_total: 12080000
  training_iteration: 302
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26970], 17061 s, 302 iter, 12080000 ts, 449 rew

agent-1: 16.0
agent-2: 12.0
agent-3: 7.0
agent-4: 19.0
agent-5: 18.0
agent-6: 17.0
agent-7: 13.0
agent-8: 10.0
agent-9: 17.0
agent-10: 14.0
agent-11: 5.0
agent-12: 11.0
agent-13: 3.0
agent-14: 13.0
agent-15: 4.0
agent-16: 7.0
agent-17: 13.0
agent-18: 11.0
agent-19: 15.0
agent-20: 1.0
agent-21: 11.0
agent-22: 10.0
agent-23: 11.0
agent-24: 9.0
agent-25: 10.0
agent-26: 13.0
agent-27: 13.0
agent-28: 13.0
agent-29: 12.0
agent-30: 8.0
agent-31: 18.0
agent-32: 3.0
agent-33: 10.0
agent-34: 20.0
agent-35: 20.0
agent-36: 12.0
agent-37: 13.0
agent-38: 15.0
agent-39: 7.0
agent-40: 12.0
Sum Reward: 466.0
Avg Reward: 11.65
Min Reward: 1.0
Max Reward: 20.0
Gini Coefficient: 0.22221030042918455
20:20 Ratio: 3.918918918918919
Max-min Ratio: 20.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-08_05-55-14
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 487.0
  episode_reward_mean: 449.34
  episode_reward_min: 392.0
  episodes_this_iter: 1
  episodes_total: 302
  experiment_id: 4e724eb5b3a34f42879644e84578eec0
  hostname: gpu024
  info:
    apply_time_ms: 3.278
    dispatch_time_ms: 7.299
    learner:
      cur_lr: 0.000555471982806921
      grad_gnorm: 5.182084083557129
      policy_entropy: 742.1776123046875
      policy_loss: 2.280289649963379
      var_gnorm: 38.17326736450195
      vf_explained_var: 0.3337399363517761
      vf_loss: 0.00863086711615324
    num_steps_sampled: 12120000
    num_steps_trained: 12120000
    wait_time_ms: 552.794
  iterations_since_restore: 303
  node_ip: 172.17.8.24
  num_metric_batches_dropped: 0
  pid: 26970
  policy_reward_mean: {}
  time_since_restore: 17118.665249824524
  time_this_iter_s: 56.825052976608276
  time_total_s: 17118.665249824524
  timestamp: 1594202114
  timesteps_since_restore: 12120000
  timesteps_this_iter: 40000
  timesteps_total: 12120000
  training_iteration: 303
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26970], 17118 s, 303 iter, 12120000 ts, 449 rew

agent-1: 16.0
agent-2: 8.0
agent-3: 17.0
agent-4: 15.0
agent-5: 10.0
agent-6: 12.0
agent-7: 11.0
agent-8: 13.0
agent-9: 15.0
agent-10: 15.0
agent-11: 10.0
agent-12: 11.0
agent-13: 9.0
agent-14: 17.0
agent-15: 11.0
agent-16: 5.0
agent-17: 3.0
agent-18: 2.0
agent-19: 8.0
agent-20: 13.0
agent-21: 11.0
agent-22: 14.0
agent-23: 16.0
agent-24: 13.0
agent-25: 15.0
agent-26: 9.0
agent-27: 13.0
agent-28: 12.0
agent-29: 17.0
agent-30: 5.0
agent-31: 18.0
agent-32: 18.0
agent-33: 17.0
agent-34: 9.0
agent-35: 6.0
agent-36: 6.0
agent-37: 12.0
agent-38: 13.0
agent-39: 7.0
agent-40: 8.0
Sum Reward: 460.0
Avg Reward: 11.5
Min Reward: 2.0
Max Reward: 18.0
Gini Coefficient: 0.20728260869565218
20:20 Ratio: 3.238095238095238
Max-min Ratio: 9.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-08_05-56-10
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 487.0
  episode_reward_mean: 449.57
  episode_reward_min: 392.0
  episodes_this_iter: 1
  episodes_total: 303
  experiment_id: 4e724eb5b3a34f42879644e84578eec0
  hostname: gpu024
  info:
    apply_time_ms: 2.655
    dispatch_time_ms: 5.769
    learner:
      cur_lr: 0.0005528079927898943
      grad_gnorm: 0.513676106929779
      policy_entropy: 775.39208984375
      policy_loss: 0.4624986946582794
      var_gnorm: 38.22435760498047
      vf_explained_var: -0.7794177532196045
      vf_loss: 5.6868444517022e-05
    num_steps_sampled: 12160000
    num_steps_trained: 12160000
    wait_time_ms: 566.943
  iterations_since_restore: 304
  node_ip: 172.17.8.24
  num_metric_batches_dropped: 0
  pid: 26970
  policy_reward_mean: {}
  time_since_restore: 17174.928754091263
  time_this_iter_s: 56.26350426673889
  time_total_s: 17174.928754091263
  timestamp: 1594202170
  timesteps_since_restore: 12160000
  timesteps_this_iter: 40000
  timesteps_total: 12160000
  training_iteration: 304
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26970], 17174 s, 304 iter, 12160000 ts, 450 rew

agent-1: 1.0
agent-2: 3.0
agent-3: 12.0
agent-4: 12.0
agent-5: 18.0
agent-6: 2.0
agent-7: 7.0
agent-8: 11.0
agent-9: 11.0
agent-10: 8.0
agent-11: 8.0
agent-12: 8.0
agent-13: 12.0
agent-14: 17.0
agent-15: 17.0
agent-16: 2.0
agent-17: 8.0
agent-18: 6.0
agent-19: 13.0
agent-20: 11.0
agent-21: 11.0
agent-22: 8.0
agent-23: 11.0
agent-24: 9.0
agent-25: 10.0
agent-26: 15.0
agent-27: 21.0
agent-28: 10.0
agent-29: 21.0
agent-30: 16.0
agent-31: 11.0
agent-32: 16.0
agent-33: 5.0
agent-34: 15.0
agent-35: 9.0
agent-36: 13.0
agent-37: 14.0
agent-38: 14.0
agent-39: 13.0
agent-40: 15.0
Sum Reward: 444.0
Avg Reward: 11.1
Min Reward: 1.0
Max Reward: 21.0
Gini Coefficient: 0.24121621621621622
20:20 Ratio: 4.147058823529412
Max-min Ratio: 21.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-08_05-57-07
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 487.0
  episode_reward_mean: 449.58
  episode_reward_min: 392.0
  episodes_this_iter: 1
  episodes_total: 304
  experiment_id: 4e724eb5b3a34f42879644e84578eec0
  hostname: gpu024
  info:
    apply_time_ms: 3.629
    dispatch_time_ms: 5.932
    learner:
      cur_lr: 0.0005501440027728677
      grad_gnorm: 6.644115924835205
      policy_entropy: 774.1962890625
      policy_loss: -2.1750848293304443
      var_gnorm: 38.20705032348633
      vf_explained_var: -0.014701247215270996
      vf_loss: 0.006734367925673723
    num_steps_sampled: 12200000
    num_steps_trained: 12200000
    wait_time_ms: 554.66
  iterations_since_restore: 305
  node_ip: 172.17.8.24
  num_metric_batches_dropped: 0
  pid: 26970
  policy_reward_mean: {}
  time_since_restore: 17231.241312742233
  time_this_iter_s: 56.31255865097046
  time_total_s: 17231.241312742233
  timestamp: 1594202227
  timesteps_since_restore: 12200000
  timesteps_this_iter: 40000
  timesteps_total: 12200000
  training_iteration: 305
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26970], 17231 s, 305 iter, 12200000 ts, 450 rew

agent-1: 9.0
agent-2: 12.0
agent-3: 16.0
agent-4: 10.0
agent-5: 16.0
agent-6: 7.0
agent-7: 15.0
agent-8: 18.0
agent-9: 12.0
agent-10: 11.0
agent-11: 19.0
agent-12: 13.0
agent-13: 12.0
agent-14: 12.0
agent-15: 1.0
agent-16: 6.0
agent-17: 11.0
agent-18: 15.0
agent-19: 8.0
agent-20: 16.0
agent-21: 10.0
agent-22: 11.0
agent-23: 10.0
agent-24: 5.0
agent-25: 16.0
agent-26: 15.0
agent-27: 6.0
agent-28: 19.0
agent-29: 11.0
agent-30: 11.0
agent-31: 12.0
agent-32: 8.0
agent-33: 16.0
agent-34: 21.0
agent-35: 13.0
agent-36: 14.0
agent-37: 7.0
agent-38: 5.0
agent-39: 7.0
agent-40: 8.0
Sum Reward: 464.0
Avg Reward: 11.6
Min Reward: 1.0
Max Reward: 21.0
Gini Coefficient: 0.21260775862068965
20:20 Ratio: 3.2045454545454546
Max-min Ratio: 21.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-08_05-58-03
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 487.0
  episode_reward_mean: 449.81
  episode_reward_min: 392.0
  episodes_this_iter: 1
  episodes_total: 305
  experiment_id: 4e724eb5b3a34f42879644e84578eec0
  hostname: gpu024
  info:
    apply_time_ms: 2.785
    dispatch_time_ms: 6.694
    learner:
      cur_lr: 0.000547480012755841
      grad_gnorm: 1.0896399021148682
      policy_entropy: 769.6392822265625
      policy_loss: -0.4658364951610565
      var_gnorm: 38.180416107177734
      vf_explained_var: -1.0
      vf_loss: 0.0002685205836314708
    num_steps_sampled: 12240000
    num_steps_trained: 12240000
    wait_time_ms: 567.602
  iterations_since_restore: 306
  node_ip: 172.17.8.24
  num_metric_batches_dropped: 0
  pid: 26970
  policy_reward_mean: {}
  time_since_restore: 17287.924536705017
  time_this_iter_s: 56.68322396278381
  time_total_s: 17287.924536705017
  timestamp: 1594202283
  timesteps_since_restore: 12240000
  timesteps_this_iter: 40000
  timesteps_total: 12240000
  training_iteration: 306
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26970], 17287 s, 306 iter, 12240000 ts, 450 rew

agent-1: 14.0
agent-2: 0.0
agent-3: 9.0
agent-4: 14.0
agent-5: 13.0
agent-6: 5.0
agent-7: 7.0
agent-8: 15.0
agent-9: 13.0
agent-10: 9.0
agent-11: 9.0
agent-12: 9.0
agent-13: 12.0
agent-14: 15.0
agent-15: 2.0
agent-16: 19.0
agent-17: 13.0
agent-18: 9.0
agent-19: 15.0
agent-20: 16.0
agent-21: 17.0
agent-22: 7.0
agent-23: 13.0
agent-24: 13.0
agent-25: 17.0
agent-26: 12.0
agent-27: 10.0
agent-28: 10.0
agent-29: 14.0
agent-30: 14.0
agent-31: 13.0
agent-32: 6.0
agent-33: 11.0
agent-34: 17.0
agent-35: 13.0
agent-36: 10.0
agent-37: 7.0
agent-38: 14.0
agent-39: 12.0
agent-40: 12.0
Sum Reward: 460.0
Avg Reward: 11.5
Min Reward: 0.0
Max Reward: 19.0
Gini Coefficient: 0.19141304347826088
20:20 Ratio: 3.046511627906977
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-08_05-59-00
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 487.0
  episode_reward_mean: 449.95
  episode_reward_min: 392.0
  episodes_this_iter: 1
  episodes_total: 306
  experiment_id: 4e724eb5b3a34f42879644e84578eec0
  hostname: gpu024
  info:
    apply_time_ms: 2.577
    dispatch_time_ms: 7.073
    learner:
      cur_lr: 0.0005448160227388144
      grad_gnorm: 3.7095305919647217
      policy_entropy: 715.519287109375
      policy_loss: -2.4049367904663086
      var_gnorm: 38.19247817993164
      vf_explained_var: 0.4212414622306824
      vf_loss: 0.008286272175610065
    num_steps_sampled: 12280000
    num_steps_trained: 12280000
    wait_time_ms: 549.438
  iterations_since_restore: 307
  node_ip: 172.17.8.24
  num_metric_batches_dropped: 0
  pid: 26970
  policy_reward_mean: {}
  time_since_restore: 17344.283266544342
  time_this_iter_s: 56.35872983932495
  time_total_s: 17344.283266544342
  timestamp: 1594202340
  timesteps_since_restore: 12280000
  timesteps_this_iter: 40000
  timesteps_total: 12280000
  training_iteration: 307
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26970], 17344 s, 307 iter, 12280000 ts, 450 rew

agent-1: 11.0
agent-2: 8.0
agent-3: 14.0
agent-4: 8.0
agent-5: 6.0
agent-6: 12.0
agent-7: 5.0
agent-8: 13.0
agent-9: 13.0
agent-10: 18.0
agent-11: 15.0
agent-12: 15.0
agent-13: 16.0
agent-14: 6.0
agent-15: 12.0
agent-16: 11.0
agent-17: 9.0
agent-18: 14.0
agent-19: 13.0
agent-20: 9.0
agent-21: 11.0
agent-22: 8.0
agent-23: 13.0
agent-24: 14.0
agent-25: 12.0
agent-26: 12.0
agent-27: 0.0
agent-28: 5.0
agent-29: 11.0
agent-30: 14.0
agent-31: 17.0
agent-32: 8.0
agent-33: 9.0
agent-34: 11.0
agent-35: 14.0
agent-36: 14.0
agent-37: 17.0
agent-38: 11.0
agent-39: 9.0
agent-40: 16.0
Sum Reward: 454.0
Avg Reward: 11.35
Min Reward: 0.0
Max Reward: 18.0
Gini Coefficient: 0.18359030837004406
20:20 Ratio: 2.782608695652174
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-08_05-59-57
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 487.0
  episode_reward_mean: 449.95
  episode_reward_min: 392.0
  episodes_this_iter: 1
  episodes_total: 307
  experiment_id: 4e724eb5b3a34f42879644e84578eec0
  hostname: gpu024
  info:
    apply_time_ms: 2.764
    dispatch_time_ms: 6.629
    learner:
      cur_lr: 0.0005421519745141268
      grad_gnorm: 0.51381915807724
      policy_entropy: 776.0302734375
      policy_loss: -0.05362690985202789
      var_gnorm: 38.27300262451172
      vf_explained_var: -0.7149919271469116
      vf_loss: 0.00010571048915153369
    num_steps_sampled: 12320000
    num_steps_trained: 12320000
    wait_time_ms: 561.551
  iterations_since_restore: 308
  node_ip: 172.17.8.24
  num_metric_batches_dropped: 0
  pid: 26970
  policy_reward_mean: {}
  time_since_restore: 17401.083713293076
  time_this_iter_s: 56.80044674873352
  time_total_s: 17401.083713293076
  timestamp: 1594202397
  timesteps_since_restore: 12320000
  timesteps_this_iter: 40000
  timesteps_total: 12320000
  training_iteration: 308
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26970], 17401 s, 308 iter, 12320000 ts, 450 rew

agent-1: 2.0
agent-2: 12.0
agent-3: 14.0
agent-4: 14.0
agent-5: 7.0
agent-6: 14.0
agent-7: 10.0
agent-8: 12.0
agent-9: 8.0
agent-10: 8.0
agent-11: 10.0
agent-12: 2.0
agent-13: 10.0
agent-14: 16.0
agent-15: 15.0
agent-16: 16.0
agent-17: 12.0
agent-18: 11.0
agent-19: 15.0
agent-20: 12.0
agent-21: 5.0
agent-22: 15.0
agent-23: 8.0
agent-24: 9.0
agent-25: 12.0
agent-26: 11.0
agent-27: 10.0
agent-28: 13.0
agent-29: 10.0
agent-30: 11.0
agent-31: 10.0
agent-32: 12.0
agent-33: 20.0
agent-34: 10.0
agent-35: 13.0
agent-36: 18.0
agent-37: 6.0
agent-38: 10.0
agent-39: 12.0
agent-40: 20.0
Sum Reward: 455.0
Avg Reward: 11.375
Min Reward: 2.0
Max Reward: 20.0
Gini Coefficient: 0.19005494505494505
20:20 Ratio: 2.9347826086956523
Max-min Ratio: 10.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-08_06-00-53
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 487.0
  episode_reward_mean: 450.05
  episode_reward_min: 392.0
  episodes_this_iter: 1
  episodes_total: 308
  experiment_id: 4e724eb5b3a34f42879644e84578eec0
  hostname: gpu024
  info:
    apply_time_ms: 3.349
    dispatch_time_ms: 6.974
    learner:
      cur_lr: 0.0005394879844971001
      grad_gnorm: 13.955432891845703
      policy_entropy: 723.7774658203125
      policy_loss: -6.829395771026611
      var_gnorm: 38.263675689697266
      vf_explained_var: 0.7905250787734985
      vf_loss: 0.1445164978504181
    num_steps_sampled: 12360000
    num_steps_trained: 12360000
    wait_time_ms: 557.85
  iterations_since_restore: 309
  node_ip: 172.17.8.24
  num_metric_batches_dropped: 0
  pid: 26970
  policy_reward_mean: {}
  time_since_restore: 17457.496008634567
  time_this_iter_s: 56.4122953414917
  time_total_s: 17457.496008634567
  timestamp: 1594202453
  timesteps_since_restore: 12360000
  timesteps_this_iter: 40000
  timesteps_total: 12360000
  training_iteration: 309
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26970], 17457 s, 309 iter, 12360000 ts, 450 rew

agent-1: 11.0
agent-2: 12.0
agent-3: 13.0
agent-4: 12.0
agent-5: 7.0
agent-6: 15.0
agent-7: 11.0
agent-8: 17.0
agent-9: 2.0
agent-10: 21.0
agent-11: 8.0
agent-12: 9.0
agent-13: 10.0
agent-14: 8.0
agent-15: 12.0
agent-16: 11.0
agent-17: 8.0
agent-18: 11.0
agent-19: 14.0
agent-20: 15.0
agent-21: 15.0
agent-22: 14.0
agent-23: 14.0
agent-24: 5.0
agent-25: 22.0
agent-26: 14.0
agent-27: 7.0
agent-28: 14.0
agent-29: 12.0
agent-30: 24.0
agent-31: 4.0
agent-32: 9.0
agent-33: 10.0
agent-34: 6.0
agent-35: 13.0
agent-36: 10.0
agent-37: 15.0
agent-38: 16.0
agent-39: 5.0
agent-40: 9.0
Sum Reward: 465.0
Avg Reward: 11.625
Min Reward: 2.0
Max Reward: 24.0
Gini Coefficient: 0.21951612903225806
20:20 Ratio: 3.2954545454545454
Max-min Ratio: 12.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-08_06-01-50
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 487.0
  episode_reward_mean: 450.31
  episode_reward_min: 392.0
  episodes_this_iter: 1
  episodes_total: 309
  experiment_id: 4e724eb5b3a34f42879644e84578eec0
  hostname: gpu024
  info:
    apply_time_ms: 2.819
    dispatch_time_ms: 5.282
    learner:
      cur_lr: 0.0005368239944800735
      grad_gnorm: 2.139225959777832
      policy_entropy: 770.8893432617188
      policy_loss: -1.45263671875
      var_gnorm: 38.28466033935547
      vf_explained_var: -0.335408091545105
      vf_loss: 0.0007604858838021755
    num_steps_sampled: 12400000
    num_steps_trained: 12400000
    wait_time_ms: 564.951
  iterations_since_restore: 310
  node_ip: 172.17.8.24
  num_metric_batches_dropped: 0
  pid: 26970
  policy_reward_mean: {}
  time_since_restore: 17514.188358545303
  time_this_iter_s: 56.692349910736084
  time_total_s: 17514.188358545303
  timestamp: 1594202510
  timesteps_since_restore: 12400000
  timesteps_this_iter: 40000
  timesteps_total: 12400000
  training_iteration: 310
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26970], 17514 s, 310 iter, 12400000 ts, 450 rew

agent-1: 8.0
agent-2: 10.0
agent-3: 14.0
agent-4: 9.0
agent-5: 12.0
agent-6: 10.0
agent-7: 11.0
agent-8: 16.0
agent-9: 11.0
agent-10: 12.0
agent-11: 3.0
agent-12: 12.0
agent-13: 8.0
agent-14: 8.0
agent-15: 19.0
agent-16: 15.0
agent-17: 16.0
agent-18: 16.0
agent-19: 10.0
agent-20: 8.0
agent-21: 13.0
agent-22: 8.0
agent-23: 12.0
agent-24: 9.0
agent-25: 16.0
agent-26: 12.0
agent-27: 13.0
agent-28: 7.0
agent-29: 14.0
agent-30: 14.0
agent-31: 14.0
agent-32: 12.0
agent-33: 13.0
agent-34: 10.0
agent-35: 14.0
agent-36: 11.0
agent-37: 14.0
agent-38: 14.0
agent-39: 11.0
agent-40: 13.0
Sum Reward: 472.0
Avg Reward: 11.8
Min Reward: 3.0
Max Reward: 19.0
Gini Coefficient: 0.14417372881355933
20:20 Ratio: 2.135593220338983
Max-min Ratio: 6.333333333333333
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-08_06-02-46
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 487.0
  episode_reward_mean: 450.44
  episode_reward_min: 392.0
  episodes_this_iter: 1
  episodes_total: 310
  experiment_id: 4e724eb5b3a34f42879644e84578eec0
  hostname: gpu024
  info:
    apply_time_ms: 2.349
    dispatch_time_ms: 5.247
    learner:
      cur_lr: 0.0005341600044630468
      grad_gnorm: 1.8674455881118774
      policy_entropy: 774.337158203125
      policy_loss: -2.0223515033721924
      var_gnorm: 38.28812789916992
      vf_explained_var: -1.0
      vf_loss: 0.001513914903625846
    num_steps_sampled: 12440000
    num_steps_trained: 12440000
    wait_time_ms: 556.447
  iterations_since_restore: 311
  node_ip: 172.17.8.24
  num_metric_batches_dropped: 0
  pid: 26970
  policy_reward_mean: {}
  time_since_restore: 17570.478616952896
  time_this_iter_s: 56.29025840759277
  time_total_s: 17570.478616952896
  timestamp: 1594202566
  timesteps_since_restore: 12440000
  timesteps_this_iter: 40000
  timesteps_total: 12440000
  training_iteration: 311
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26970], 17570 s, 311 iter, 12440000 ts, 450 rew

agent-1: 12.0
agent-2: 14.0
agent-3: 13.0
agent-4: 11.0
agent-5: 8.0
agent-6: 13.0
agent-7: 14.0
agent-8: 7.0
agent-9: 3.0
agent-10: 9.0
agent-11: 17.0
agent-12: 7.0
agent-13: 17.0
agent-14: 9.0
agent-15: 16.0
agent-16: 14.0
agent-17: 10.0
agent-18: 13.0
agent-19: 16.0
agent-20: 12.0
agent-21: 13.0
agent-22: 13.0
agent-23: 4.0
agent-24: 13.0
agent-25: 12.0
agent-26: 13.0
agent-27: 8.0
agent-28: 12.0
agent-29: 11.0
agent-30: 9.0
agent-31: 13.0
agent-32: 5.0
agent-33: 14.0
agent-34: 9.0
agent-35: 3.0
agent-36: 16.0
agent-37: 16.0
agent-38: 9.0
agent-39: 9.0
agent-40: 7.0
Sum Reward: 444.0
Avg Reward: 11.1
Min Reward: 3.0
Max Reward: 17.0
Gini Coefficient: 0.18693693693693694
20:20 Ratio: 2.8636363636363638
Max-min Ratio: 5.666666666666667
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-08_06-03-43
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 487.0
  episode_reward_mean: 450.49
  episode_reward_min: 392.0
  episodes_this_iter: 1
  episodes_total: 311
  experiment_id: 4e724eb5b3a34f42879644e84578eec0
  hostname: gpu024
  info:
    apply_time_ms: 3.113
    dispatch_time_ms: 6.947
    learner:
      cur_lr: 0.0005314960144460201
      grad_gnorm: 0.5592585206031799
      policy_entropy: 767.1837158203125
      policy_loss: -0.3729603886604309
      var_gnorm: 38.30481719970703
      vf_explained_var: -1.0
      vf_loss: 0.00035395630402490497
    num_steps_sampled: 12480000
    num_steps_trained: 12480000
    wait_time_ms: 561.679
  iterations_since_restore: 312
  node_ip: 172.17.8.24
  num_metric_batches_dropped: 0
  pid: 26970
  policy_reward_mean: {}
  time_since_restore: 17626.89753985405
  time_this_iter_s: 56.418922901153564
  time_total_s: 17626.89753985405
  timestamp: 1594202623
  timesteps_since_restore: 12480000
  timesteps_this_iter: 40000
  timesteps_total: 12480000
  training_iteration: 312
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26970], 17626 s, 312 iter, 12480000 ts, 450 rew

agent-1: 7.0
agent-2: 12.0
agent-3: 15.0
agent-4: 7.0
agent-5: 7.0
agent-6: 2.0
agent-7: 5.0
agent-8: 17.0
agent-9: 13.0
agent-10: 15.0
agent-11: 15.0
agent-12: 12.0
agent-13: 11.0
agent-14: 13.0
agent-15: 11.0
agent-16: 19.0
agent-17: 7.0
agent-18: 8.0
agent-19: 11.0
agent-20: 14.0
agent-21: 13.0
agent-22: 7.0
agent-23: 14.0
agent-24: 11.0
agent-25: 11.0
agent-26: 13.0
agent-27: 14.0
agent-28: 10.0
agent-29: 15.0
agent-30: 13.0
agent-31: 11.0
agent-32: 12.0
agent-33: 12.0
agent-34: 11.0
agent-35: 11.0
agent-36: 15.0
agent-37: 11.0
agent-38: 4.0
agent-39: 7.0
agent-40: 5.0
Sum Reward: 441.0
Avg Reward: 11.025
Min Reward: 2.0
Max Reward: 19.0
Gini Coefficient: 0.184297052154195
20:20 Ratio: 2.840909090909091
Max-min Ratio: 9.5
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-08_06-04-39
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 487.0
  episode_reward_mean: 450.4
  episode_reward_min: 392.0
  episodes_this_iter: 1
  episodes_total: 312
  experiment_id: 4e724eb5b3a34f42879644e84578eec0
  hostname: gpu024
  info:
    apply_time_ms: 2.568
    dispatch_time_ms: 5.437
    learner:
      cur_lr: 0.0005288320244289935
      grad_gnorm: 2.2292044162750244
      policy_entropy: 739.057373046875
      policy_loss: -0.19437074661254883
      var_gnorm: 38.31608581542969
      vf_explained_var: 0.6196709871292114
      vf_loss: 0.0020860512740910053
    num_steps_sampled: 12520000
    num_steps_trained: 12520000
    wait_time_ms: 553.549
  iterations_since_restore: 313
  node_ip: 172.17.8.24
  num_metric_batches_dropped: 0
  pid: 26970
  policy_reward_mean: {}
  time_since_restore: 17683.47838139534
  time_this_iter_s: 56.58084154129028
  time_total_s: 17683.47838139534
  timestamp: 1594202679
  timesteps_since_restore: 12520000
  timesteps_this_iter: 40000
  timesteps_total: 12520000
  training_iteration: 313
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26970], 17683 s, 313 iter, 12520000 ts, 450 rew

agent-1: 13.0
agent-2: 12.0
agent-3: 13.0
agent-4: 10.0
agent-5: 12.0
agent-6: 11.0
agent-7: 9.0
agent-8: 6.0
agent-9: 13.0
agent-10: 14.0
agent-11: 7.0
agent-12: 12.0
agent-13: 9.0
agent-14: 12.0
agent-15: 16.0
agent-16: 6.0
agent-17: 11.0
agent-18: 11.0
agent-19: 9.0
agent-20: 10.0
agent-21: 11.0
agent-22: 9.0
agent-23: 13.0
agent-24: 14.0
agent-25: 17.0
agent-26: 4.0
agent-27: 11.0
agent-28: 10.0
agent-29: 12.0
agent-30: 9.0
agent-31: 11.0
agent-32: 10.0
agent-33: 7.0
agent-34: 14.0
agent-35: 7.0
agent-36: 10.0
agent-37: 7.0
agent-38: 14.0
agent-39: 9.0
agent-40: 16.0
Sum Reward: 431.0
Avg Reward: 10.775
Min Reward: 4.0
Max Reward: 17.0
Gini Coefficient: 0.1504060324825986
20:20 Ratio: 2.2264150943396226
Max-min Ratio: 4.25
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-08_06-05-36
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 487.0
  episode_reward_mean: 450.22
  episode_reward_min: 392.0
  episodes_this_iter: 1
  episodes_total: 313
  experiment_id: 4e724eb5b3a34f42879644e84578eec0
  hostname: gpu024
  info:
    apply_time_ms: 4.121
    dispatch_time_ms: 6.084
    learner:
      cur_lr: 0.0005261679762043059
      grad_gnorm: 1.2189382314682007
      policy_entropy: 769.6781616210938
      policy_loss: 1.1422185897827148
      var_gnorm: 38.333744049072266
      vf_explained_var: -0.2553892135620117
      vf_loss: 0.0002603050088509917
    num_steps_sampled: 12560000
    num_steps_trained: 12560000
    wait_time_ms: 552.167
  iterations_since_restore: 314
  node_ip: 172.17.8.24
  num_metric_batches_dropped: 0
  pid: 26970
  policy_reward_mean: {}
  time_since_restore: 17740.062024116516
  time_this_iter_s: 56.58364272117615
  time_total_s: 17740.062024116516
  timestamp: 1594202736
  timesteps_since_restore: 12560000
  timesteps_this_iter: 40000
  timesteps_total: 12560000
  training_iteration: 314
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26970], 17740 s, 314 iter, 12560000 ts, 450 rew

agent-1: 11.0
agent-2: 10.0
agent-3: 15.0
agent-4: 12.0
agent-5: 9.0
agent-6: 11.0
agent-7: 11.0
agent-8: 21.0
agent-9: 10.0
agent-10: 12.0
agent-11: 12.0
agent-12: 11.0
agent-13: 9.0
agent-14: 12.0
agent-15: 15.0
agent-16: 8.0
agent-17: 7.0
agent-18: 13.0
agent-19: 13.0
agent-20: 8.0
agent-21: 6.0
agent-22: 15.0
agent-23: 8.0
agent-24: 12.0
agent-25: 10.0
agent-26: 12.0
agent-27: 12.0
agent-28: 14.0
agent-29: 5.0
agent-30: 7.0
agent-31: 13.0
agent-32: 12.0
agent-33: 16.0
agent-34: 10.0
agent-35: 7.0
agent-36: 9.0
agent-37: 10.0
agent-38: 12.0
agent-39: 14.0
agent-40: 13.0
Sum Reward: 447.0
Avg Reward: 11.175
Min Reward: 5.0
Max Reward: 21.0
Gini Coefficient: 0.14793064876957496
20:20 Ratio: 2.1964285714285716
Max-min Ratio: 4.2
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-08_06-06-32
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 487.0
  episode_reward_mean: 449.85
  episode_reward_min: 392.0
  episodes_this_iter: 1
  episodes_total: 314
  experiment_id: 4e724eb5b3a34f42879644e84578eec0
  hostname: gpu024
  info:
    apply_time_ms: 2.62
    dispatch_time_ms: 6.07
    learner:
      cur_lr: 0.0005235039861872792
      grad_gnorm: 6.035961627960205
      policy_entropy: 737.0919189453125
      policy_loss: -2.349529266357422
      var_gnorm: 38.33711624145508
      vf_explained_var: -1.0
      vf_loss: 0.33357006311416626
    num_steps_sampled: 12600000
    num_steps_trained: 12600000
    wait_time_ms: 553.479
  iterations_since_restore: 315
  node_ip: 172.17.8.24
  num_metric_batches_dropped: 0
  pid: 26970
  policy_reward_mean: {}
  time_since_restore: 17796.632780313492
  time_this_iter_s: 56.57075619697571
  time_total_s: 17796.632780313492
  timestamp: 1594202792
  timesteps_since_restore: 12600000
  timesteps_this_iter: 40000
  timesteps_total: 12600000
  training_iteration: 315
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26970], 17796 s, 315 iter, 12600000 ts, 450 rew

agent-1: 12.0
agent-2: 11.0
agent-3: 14.0
agent-4: 11.0
agent-5: 8.0
agent-6: 13.0
agent-7: 12.0
agent-8: 5.0
agent-9: 14.0
agent-10: 9.0
agent-11: 19.0
agent-12: 8.0
agent-13: 10.0
agent-14: 8.0
agent-15: 7.0
agent-16: 8.0
agent-17: 12.0
agent-18: 9.0
agent-19: 13.0
agent-20: 6.0
agent-21: 9.0
agent-22: 15.0
agent-23: 12.0
agent-24: 9.0
agent-25: 11.0
agent-26: 10.0
agent-27: 11.0
agent-28: 10.0
agent-29: 12.0
agent-30: 10.0
agent-31: 16.0
agent-32: 11.0
agent-33: 6.0
agent-34: 16.0
agent-35: 14.0
agent-36: 6.0
agent-37: 13.0
agent-38: 12.0
agent-39: 10.0
agent-40: 17.0
Sum Reward: 439.0
Avg Reward: 10.975
Min Reward: 5.0
Max Reward: 19.0
Gini Coefficient: 0.1607630979498861
20:20 Ratio: 2.314814814814815
Max-min Ratio: 3.8
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-08_06-07-29
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 487.0
  episode_reward_mean: 449.83
  episode_reward_min: 392.0
  episodes_this_iter: 1
  episodes_total: 315
  experiment_id: 4e724eb5b3a34f42879644e84578eec0
  hostname: gpu024
  info:
    apply_time_ms: 2.596
    dispatch_time_ms: 5.689
    learner:
      cur_lr: 0.0005208399961702526
      grad_gnorm: 7.040884494781494
      policy_entropy: 728.7064819335938
      policy_loss: -3.0061144828796387
      var_gnorm: 38.40625
      vf_explained_var: -1.0
      vf_loss: 0.03719688951969147
    num_steps_sampled: 12640000
    num_steps_trained: 12640000
    wait_time_ms: 563.729
  iterations_since_restore: 316
  node_ip: 172.17.8.24
  num_metric_batches_dropped: 0
  pid: 26970
  policy_reward_mean: {}
  time_since_restore: 17853.49223470688
  time_this_iter_s: 56.85945439338684
  time_total_s: 17853.49223470688
  timestamp: 1594202849
  timesteps_since_restore: 12640000
  timesteps_this_iter: 40000
  timesteps_total: 12640000
  training_iteration: 316
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26970], 17853 s, 316 iter, 12640000 ts, 450 rew

agent-1: 14.0
agent-2: 7.0
agent-3: 10.0
agent-4: 9.0
agent-5: 3.0
agent-6: 14.0
agent-7: 7.0
agent-8: 7.0
agent-9: 2.0
agent-10: 11.0
agent-11: 12.0
agent-12: 5.0
agent-13: 10.0
agent-14: 14.0
agent-15: 9.0
agent-16: 10.0
agent-17: 10.0
agent-18: 13.0
agent-19: 13.0
agent-20: 11.0
agent-21: 13.0
agent-22: 9.0
agent-23: 9.0
agent-24: 15.0
agent-25: 11.0
agent-26: 11.0
agent-27: 7.0
agent-28: 11.0
agent-29: 10.0
agent-30: 23.0
agent-31: 10.0
agent-32: 14.0
agent-33: 10.0
agent-34: 12.0
agent-35: 15.0
agent-36: 15.0
agent-37: 10.0
agent-38: 12.0
agent-39: 10.0
agent-40: 7.0
Sum Reward: 425.0
Avg Reward: 10.625
Min Reward: 2.0
Max Reward: 23.0
Gini Coefficient: 0.1797058823529412
20:20 Ratio: 2.7555555555555555
Max-min Ratio: 11.5
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-08_06-08-26
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 487.0
  episode_reward_mean: 449.57
  episode_reward_min: 392.0
  episodes_this_iter: 1
  episodes_total: 316
  experiment_id: 4e724eb5b3a34f42879644e84578eec0
  hostname: gpu024
  info:
    apply_time_ms: 2.807
    dispatch_time_ms: 6.569
    learner:
      cur_lr: 0.0005181760061532259
      grad_gnorm: 10.777097702026367
      policy_entropy: 681.6012573242188
      policy_loss: -1.3652927875518799
      var_gnorm: 38.452606201171875
      vf_explained_var: -0.42644190788269043
      vf_loss: 0.023756854236125946
    num_steps_sampled: 12680000
    num_steps_trained: 12680000
    wait_time_ms: 561.091
  iterations_since_restore: 317
  node_ip: 172.17.8.24
  num_metric_batches_dropped: 0
  pid: 26970
  policy_reward_mean: {}
  time_since_restore: 17910.314728736877
  time_this_iter_s: 56.82249402999878
  time_total_s: 17910.314728736877
  timestamp: 1594202906
  timesteps_since_restore: 12680000
  timesteps_this_iter: 40000
  timesteps_total: 12680000
  training_iteration: 317
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26970], 17910 s, 317 iter, 12680000 ts, 450 rew

agent-1: 8.0
agent-2: 13.0
agent-3: 18.0
agent-4: 10.0
agent-5: 12.0
agent-6: 8.0
agent-7: 9.0
agent-8: 12.0
agent-9: 8.0
agent-10: 15.0
agent-11: 16.0
agent-12: 14.0
agent-13: 13.0
agent-14: 14.0
agent-15: 6.0
agent-16: 9.0
agent-17: 13.0
agent-18: 8.0
agent-19: 9.0
agent-20: 6.0
agent-21: 8.0
agent-22: 12.0
agent-23: 8.0
agent-24: 14.0
agent-25: 12.0
agent-26: 10.0
agent-27: 9.0
agent-28: 11.0
agent-29: 11.0
agent-30: 12.0
agent-31: 9.0
agent-32: 12.0
agent-33: 8.0
agent-34: 6.0
agent-35: 13.0
agent-36: 9.0
agent-37: 8.0
agent-38: 9.0
agent-39: 8.0
agent-40: 15.0
Sum Reward: 425.0
Avg Reward: 10.625
Min Reward: 6.0
Max Reward: 18.0
Gini Coefficient: 0.1526470588235294
20:20 Ratio: 2.0517241379310347
Max-min Ratio: 3.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-08_06-09-23
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 487.0
  episode_reward_mean: 449.36
  episode_reward_min: 392.0
  episodes_this_iter: 1
  episodes_total: 317
  experiment_id: 4e724eb5b3a34f42879644e84578eec0
  hostname: gpu024
  info:
    apply_time_ms: 2.469
    dispatch_time_ms: 5.779
    learner:
      cur_lr: 0.0005155120161361992
      grad_gnorm: 3.969888687133789
      policy_entropy: 757.3106689453125
      policy_loss: -1.2458763122558594
      var_gnorm: 38.48786163330078
      vf_explained_var: -1.0
      vf_loss: 0.005791506730020046
    num_steps_sampled: 12720000
    num_steps_trained: 12720000
    wait_time_ms: 573.83
  iterations_since_restore: 318
  node_ip: 172.17.8.24
  num_metric_batches_dropped: 0
  pid: 26970
  policy_reward_mean: {}
  time_since_restore: 17966.870500326157
  time_this_iter_s: 56.555771589279175
  time_total_s: 17966.870500326157
  timestamp: 1594202963
  timesteps_since_restore: 12720000
  timesteps_this_iter: 40000
  timesteps_total: 12720000
  training_iteration: 318
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26970], 17966 s, 318 iter, 12720000 ts, 449 rew

agent-1: 15.0
agent-2: 14.0
agent-3: 3.0
agent-4: 10.0
agent-5: 11.0
agent-6: 9.0
agent-7: 7.0
agent-8: 11.0
agent-9: 16.0
agent-10: 13.0
agent-11: 13.0
agent-12: 6.0
agent-13: 6.0
agent-14: 16.0
agent-15: 14.0
agent-16: 16.0
agent-17: 17.0
agent-18: 8.0
agent-19: 9.0
agent-20: 15.0
agent-21: 10.0
agent-22: 14.0
agent-23: 13.0
agent-24: 15.0
agent-25: 14.0
agent-26: 17.0
agent-27: 8.0
agent-28: 6.0
agent-29: 9.0
agent-30: 12.0
agent-31: 14.0
agent-32: 9.0
agent-33: 11.0
agent-34: 9.0
agent-35: 12.0
agent-36: 12.0
agent-37: 9.0
agent-38: 10.0
agent-39: 13.0
agent-40: 8.0
Sum Reward: 454.0
Avg Reward: 11.35
Min Reward: 3.0
Max Reward: 17.0
Gini Coefficient: 0.17048458149779736
20:20 Ratio: 2.4423076923076925
Max-min Ratio: 5.666666666666667
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-08_06-10-20
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 487.0
  episode_reward_mean: 449.28
  episode_reward_min: 392.0
  episodes_this_iter: 1
  episodes_total: 318
  experiment_id: 4e724eb5b3a34f42879644e84578eec0
  hostname: gpu024
  info:
    apply_time_ms: 2.966
    dispatch_time_ms: 6.291
    learner:
      cur_lr: 0.0005128480261191726
      grad_gnorm: 8.659180641174316
      policy_entropy: 737.0948486328125
      policy_loss: 1.244901180267334
      var_gnorm: 38.491573333740234
      vf_explained_var: -0.1589881181716919
      vf_loss: 0.0317414291203022
    num_steps_sampled: 12760000
    num_steps_trained: 12760000
    wait_time_ms: 577.453
  iterations_since_restore: 319
  node_ip: 172.17.8.24
  num_metric_batches_dropped: 0
  pid: 26970
  policy_reward_mean: {}
  time_since_restore: 18023.913696289062
  time_this_iter_s: 57.043195962905884
  time_total_s: 18023.913696289062
  timestamp: 1594203020
  timesteps_since_restore: 12760000
  timesteps_this_iter: 40000
  timesteps_total: 12760000
  training_iteration: 319
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26970], 18023 s, 319 iter, 12760000 ts, 449 rew

agent-1: 10.0
agent-2: 8.0
agent-3: 14.0
agent-4: 7.0
agent-5: 9.0
agent-6: 14.0
agent-7: 6.0
agent-8: 9.0
agent-9: 8.0
agent-10: 10.0
agent-11: 10.0
agent-12: 16.0
agent-13: 12.0
agent-14: 11.0
agent-15: 7.0
agent-16: 16.0
agent-17: 15.0
agent-18: 11.0
agent-19: 11.0
agent-20: 13.0
agent-21: 15.0
agent-22: 13.0
agent-23: 10.0
agent-24: 5.0
agent-25: 11.0
agent-26: 17.0
agent-27: 15.0
agent-28: 10.0
agent-29: 7.0
agent-30: 17.0
agent-31: 17.0
agent-32: 7.0
agent-33: 11.0
agent-34: 10.0
agent-35: 10.0
agent-36: 8.0
agent-37: 7.0
agent-38: 18.0
agent-39: 9.0
agent-40: 3.0
Sum Reward: 437.0
Avg Reward: 10.925
Min Reward: 3.0
Max Reward: 18.0
Gini Coefficient: 0.1889588100686499
20:20 Ratio: 2.673469387755102
Max-min Ratio: 6.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-08_06-11-16
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 487.0
  episode_reward_mean: 449.15
  episode_reward_min: 392.0
  episodes_this_iter: 1
  episodes_total: 319
  experiment_id: 4e724eb5b3a34f42879644e84578eec0
  hostname: gpu024
  info:
    apply_time_ms: 2.547
    dispatch_time_ms: 5.878
    learner:
      cur_lr: 0.000510183977894485
      grad_gnorm: 1.1041535139083862
      policy_entropy: 763.3638916015625
      policy_loss: 0.32408836483955383
      var_gnorm: 38.51627731323242
      vf_explained_var: -1.0
      vf_loss: 0.001414661412127316
    num_steps_sampled: 12800000
    num_steps_trained: 12800000
    wait_time_ms: 562.611
  iterations_since_restore: 320
  node_ip: 172.17.8.24
  num_metric_batches_dropped: 0
  pid: 26970
  policy_reward_mean: {}
  time_since_restore: 18080.349773168564
  time_this_iter_s: 56.43607687950134
  time_total_s: 18080.349773168564
  timestamp: 1594203076
  timesteps_since_restore: 12800000
  timesteps_this_iter: 40000
  timesteps_total: 12800000
  training_iteration: 320
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26970], 18080 s, 320 iter, 12800000 ts, 449 rew

agent-1: 9.0
agent-2: 10.0
agent-3: 9.0
agent-4: 10.0
agent-5: 10.0
agent-6: 14.0
agent-7: 21.0
agent-8: 10.0
agent-9: 5.0
agent-10: 13.0
agent-11: 17.0
agent-12: 13.0
agent-13: 8.0
agent-14: 9.0
agent-15: 12.0
agent-16: 4.0
agent-17: 6.0
agent-18: 8.0
agent-19: 20.0
agent-20: 14.0
agent-21: 17.0
agent-22: 8.0
agent-23: 14.0
agent-24: 15.0
agent-25: 16.0
agent-26: 9.0
agent-27: 10.0
agent-28: 6.0
agent-29: 10.0
agent-30: 11.0
agent-31: 9.0
agent-32: 10.0
agent-33: 4.0
agent-34: 11.0
agent-35: 15.0
agent-36: 17.0
agent-37: 11.0
agent-38: 13.0
agent-39: 10.0
agent-40: 8.0
Sum Reward: 446.0
Avg Reward: 11.15
Min Reward: 4.0
Max Reward: 21.0
Gini Coefficient: 0.19820627802690582
20:20 Ratio: 2.816326530612245
Max-min Ratio: 5.25
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-08_06-12-13
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 487.0
  episode_reward_mean: 449.07
  episode_reward_min: 392.0
  episodes_this_iter: 1
  episodes_total: 320
  experiment_id: 4e724eb5b3a34f42879644e84578eec0
  hostname: gpu024
  info:
    apply_time_ms: 3.589
    dispatch_time_ms: 6.782
    learner:
      cur_lr: 0.0005075199878774583
      grad_gnorm: 2.172673225402832
      policy_entropy: 768.4462890625
      policy_loss: -0.889628529548645
      var_gnorm: 38.52980422973633
      vf_explained_var: -1.0
      vf_loss: 0.0016071328427642584
    num_steps_sampled: 12840000
    num_steps_trained: 12840000
    wait_time_ms: 574.63
  iterations_since_restore: 321
  node_ip: 172.17.8.24
  num_metric_batches_dropped: 0
  pid: 26970
  policy_reward_mean: {}
  time_since_restore: 18136.855754375458
  time_this_iter_s: 56.50598120689392
  time_total_s: 18136.855754375458
  timestamp: 1594203133
  timesteps_since_restore: 12840000
  timesteps_this_iter: 40000
  timesteps_total: 12840000
  training_iteration: 321
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26970], 18136 s, 321 iter, 12840000 ts, 449 rew

agent-1: 15.0
agent-2: 9.0
agent-3: 10.0
agent-4: 13.0
agent-5: 9.0
agent-6: 17.0
agent-7: 12.0
agent-8: 14.0
agent-9: 15.0
agent-10: 10.0
agent-11: 5.0
agent-12: 8.0
agent-13: 5.0
agent-14: 4.0
agent-15: 14.0
agent-16: 14.0
agent-17: 19.0
agent-18: 10.0
agent-19: 10.0
agent-20: 8.0
agent-21: 14.0
agent-22: 16.0
agent-23: 12.0
agent-24: 9.0
agent-25: 7.0
agent-26: 12.0
agent-27: 11.0
agent-28: 10.0
agent-29: 10.0
agent-30: 12.0
agent-31: 11.0
agent-32: 11.0
agent-33: 9.0
agent-34: 18.0
agent-35: 10.0
agent-36: 11.0
agent-37: 10.0
agent-38: 11.0
agent-39: 11.0
agent-40: 13.0
Sum Reward: 449.0
Avg Reward: 11.225
Min Reward: 4.0
Max Reward: 19.0
Gini Coefficient: 0.16141425389755013
20:20 Ratio: 2.327272727272727
Max-min Ratio: 4.75
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-08_06-13-10
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 487.0
  episode_reward_mean: 449.08
  episode_reward_min: 392.0
  episodes_this_iter: 1
  episodes_total: 321
  experiment_id: 4e724eb5b3a34f42879644e84578eec0
  hostname: gpu024
  info:
    apply_time_ms: 2.647
    dispatch_time_ms: 7.431
    learner:
      cur_lr: 0.0005048559978604317
      grad_gnorm: 0.7826520800590515
      policy_entropy: 770.5263671875
      policy_loss: -0.005265101790428162
      var_gnorm: 38.55040740966797
      vf_explained_var: -1.0
      vf_loss: 0.00038540398236364126
    num_steps_sampled: 12880000
    num_steps_trained: 12880000
    wait_time_ms: 567.948
  iterations_since_restore: 322
  node_ip: 172.17.8.24
  num_metric_batches_dropped: 0
  pid: 26970
  policy_reward_mean: {}
  time_since_restore: 18193.49807548523
  time_this_iter_s: 56.64232110977173
  time_total_s: 18193.49807548523
  timestamp: 1594203190
  timesteps_since_restore: 12880000
  timesteps_this_iter: 40000
  timesteps_total: 12880000
  training_iteration: 322
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26970], 18193 s, 322 iter, 12880000 ts, 449 rew

agent-1: 15.0
agent-2: 9.0
agent-3: 13.0
agent-4: 14.0
agent-5: 13.0
agent-6: 5.0
agent-7: 18.0
agent-8: 14.0
agent-9: 14.0
agent-10: 14.0
agent-11: 10.0
agent-12: 7.0
agent-13: 13.0
agent-14: 13.0
agent-15: 17.0
agent-16: 12.0
agent-17: 9.0
agent-18: 14.0
agent-19: 13.0
agent-20: 9.0
agent-21: 9.0
agent-22: 12.0
agent-23: 8.0
agent-24: 9.0
agent-25: 15.0
agent-26: 7.0
agent-27: 8.0
agent-28: 10.0
agent-29: 11.0
agent-30: 8.0
agent-31: 9.0
agent-32: 11.0
agent-33: 8.0
agent-34: 6.0
agent-35: 12.0
agent-36: 6.0
agent-37: 10.0
agent-38: 15.0
agent-39: 10.0
agent-40: 3.0
Sum Reward: 433.0
Avg Reward: 10.825
Min Reward: 3.0
Max Reward: 18.0
Gini Coefficient: 0.17453810623556582
20:20 Ratio: 2.44
Max-min Ratio: 6.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-08_06-14-06
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 487.0
  episode_reward_mean: 449.14
  episode_reward_min: 392.0
  episodes_this_iter: 1
  episodes_total: 322
  experiment_id: 4e724eb5b3a34f42879644e84578eec0
  hostname: gpu024
  info:
    apply_time_ms: 2.838
    dispatch_time_ms: 7.034
    learner:
      cur_lr: 0.000502192007843405
      grad_gnorm: 22.310638427734375
      policy_entropy: 660.37109375
      policy_loss: -5.003267765045166
      var_gnorm: 38.57284164428711
      vf_explained_var: 0.4454556107521057
      vf_loss: 7.571393013000488
    num_steps_sampled: 12920000
    num_steps_trained: 12920000
    wait_time_ms: 556.779
  iterations_since_restore: 323
  node_ip: 172.17.8.24
  num_metric_batches_dropped: 0
  pid: 26970
  policy_reward_mean: {}
  time_since_restore: 18250.222551822662
  time_this_iter_s: 56.72447633743286
  time_total_s: 18250.222551822662
  timestamp: 1594203246
  timesteps_since_restore: 12920000
  timesteps_this_iter: 40000
  timesteps_total: 12920000
  training_iteration: 323
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26970], 18250 s, 323 iter, 12920000 ts, 449 rew

agent-1: 9.0
agent-2: 12.0
agent-3: 13.0
agent-4: 13.0
agent-5: 11.0
agent-6: 10.0
agent-7: 6.0
agent-8: 12.0
agent-9: 7.0
agent-10: 12.0
agent-11: 15.0
agent-12: 17.0
agent-13: 6.0
agent-14: 8.0
agent-15: 14.0
agent-16: 6.0
agent-17: 11.0
agent-18: 14.0
agent-19: 18.0
agent-20: 13.0
agent-21: 14.0
agent-22: 16.0
agent-23: 8.0
agent-24: 9.0
agent-25: 12.0
agent-26: 9.0
agent-27: 3.0
agent-28: 14.0
agent-29: 11.0
agent-30: 17.0
agent-31: 13.0
agent-32: 5.0
agent-33: 13.0
agent-34: 10.0
agent-35: 13.0
agent-36: 8.0
agent-37: 17.0
agent-38: 13.0
agent-39: 9.0
agent-40: 10.0
Sum Reward: 451.0
Avg Reward: 11.275
Min Reward: 3.0
Max Reward: 18.0
Gini Coefficient: 0.17732815964523282
20:20 Ratio: 2.6122448979591835
Max-min Ratio: 6.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-08_06-15-03
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 487.0
  episode_reward_mean: 449.31
  episode_reward_min: 392.0
  episodes_this_iter: 1
  episodes_total: 323
  experiment_id: 4e724eb5b3a34f42879644e84578eec0
  hostname: gpu024
  info:
    apply_time_ms: 3.286
    dispatch_time_ms: 6.229
    learner:
      cur_lr: 0.0004995280178263783
      grad_gnorm: 6.939272880554199
      policy_entropy: 761.6637573242188
      policy_loss: 0.2174375057220459
      var_gnorm: 38.58793258666992
      vf_explained_var: -1.0
      vf_loss: 0.0036642258055508137
    num_steps_sampled: 12960000
    num_steps_trained: 12960000
    wait_time_ms: 551.44
  iterations_since_restore: 324
  node_ip: 172.17.8.24
  num_metric_batches_dropped: 0
  pid: 26970
  policy_reward_mean: {}
  time_since_restore: 18306.40558075905
  time_this_iter_s: 56.18302893638611
  time_total_s: 18306.40558075905
  timestamp: 1594203303
  timesteps_since_restore: 12960000
  timesteps_this_iter: 40000
  timesteps_total: 12960000
  training_iteration: 324
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26970], 18306 s, 324 iter, 12960000 ts, 449 rew

agent-1: 13.0
agent-2: 7.0
agent-3: 9.0
agent-4: 11.0
agent-5: 11.0
agent-6: 16.0
agent-7: 11.0
agent-8: 9.0
agent-9: 12.0
agent-10: 16.0
agent-11: 5.0
agent-12: 11.0
agent-13: 19.0
agent-14: 14.0
agent-15: 15.0
agent-16: 13.0
agent-17: 9.0
agent-18: 11.0
agent-19: 8.0
agent-20: 10.0
agent-21: 8.0
agent-22: 18.0
agent-23: 9.0
agent-24: 15.0
agent-25: 11.0
agent-26: 7.0
agent-27: 14.0
agent-28: 12.0
agent-29: 9.0
agent-30: 9.0
agent-31: 14.0
agent-32: 10.0
agent-33: 16.0
agent-34: 9.0
agent-35: 9.0
agent-36: 16.0
agent-37: 15.0
agent-38: 12.0
agent-39: 5.0
agent-40: 11.0
Sum Reward: 459.0
Avg Reward: 11.475
Min Reward: 5.0
Max Reward: 19.0
Gini Coefficient: 0.16410675381263617
20:20 Ratio: 2.2586206896551726
Max-min Ratio: 3.8
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-08_06-15-59
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 487.0
  episode_reward_mean: 449.38
  episode_reward_min: 392.0
  episodes_this_iter: 1
  episodes_total: 324
  experiment_id: 4e724eb5b3a34f42879644e84578eec0
  hostname: gpu024
  info:
    apply_time_ms: 2.548
    dispatch_time_ms: 7.907
    learner:
      cur_lr: 0.0004968640278093517
      grad_gnorm: 25.380367279052734
      policy_entropy: 629.1029052734375
      policy_loss: -12.157215118408203
      var_gnorm: 38.58445739746094
      vf_explained_var: 0.5766677260398865
      vf_loss: 0.19067487120628357
    num_steps_sampled: 13000000
    num_steps_trained: 13000000
    wait_time_ms: 559.212
  iterations_since_restore: 325
  node_ip: 172.17.8.24
  num_metric_batches_dropped: 0
  pid: 26970
  policy_reward_mean: {}
  time_since_restore: 18363.070524930954
  time_this_iter_s: 56.66494417190552
  time_total_s: 18363.070524930954
  timestamp: 1594203359
  timesteps_since_restore: 13000000
  timesteps_this_iter: 40000
  timesteps_total: 13000000
  training_iteration: 325
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26970], 18363 s, 325 iter, 13000000 ts, 449 rew

agent-1: 13.0
agent-2: 7.0
agent-3: 8.0
agent-4: 10.0
agent-5: 14.0
agent-6: 12.0
agent-7: 14.0
agent-8: 9.0
agent-9: 11.0
agent-10: 9.0
agent-11: 11.0
agent-12: 12.0
agent-13: 12.0
agent-14: 14.0
agent-15: 11.0
agent-16: 8.0
agent-17: 11.0
agent-18: 15.0
agent-19: 13.0
agent-20: 25.0
agent-21: 8.0
agent-22: 16.0
agent-23: 12.0
agent-24: 19.0
agent-25: 19.0
agent-26: 14.0
agent-27: 6.0
agent-28: 8.0
agent-29: 9.0
agent-30: 9.0
agent-31: 18.0
agent-32: 13.0
agent-33: 4.0
agent-34: 9.0
agent-35: 8.0
agent-36: 10.0
agent-37: 4.0
agent-38: 6.0
agent-39: 4.0
agent-40: 16.0
Sum Reward: 451.0
Avg Reward: 11.275
Min Reward: 4.0
Max Reward: 25.0
Gini Coefficient: 0.21324833702882484
20:20 Ratio: 3.021276595744681
Max-min Ratio: 6.25
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-08_06-16-56
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 487.0
  episode_reward_mean: 449.35
  episode_reward_min: 392.0
  episodes_this_iter: 1
  episodes_total: 325
  experiment_id: 4e724eb5b3a34f42879644e84578eec0
  hostname: gpu024
  info:
    apply_time_ms: 2.614
    dispatch_time_ms: 6.425
    learner:
      cur_lr: 0.0004941999795846641
      grad_gnorm: 0.7351463437080383
      policy_entropy: 767.3992919921875
      policy_loss: 0.057455629110336304
      var_gnorm: 38.57749938964844
      vf_explained_var: -0.17666828632354736
      vf_loss: 0.0003923752228729427
    num_steps_sampled: 13040000
    num_steps_trained: 13040000
    wait_time_ms: 564.655
  iterations_since_restore: 326
  node_ip: 172.17.8.24
  num_metric_batches_dropped: 0
  pid: 26970
  policy_reward_mean: {}
  time_since_restore: 18419.634615659714
  time_this_iter_s: 56.564090728759766
  time_total_s: 18419.634615659714
  timestamp: 1594203416
  timesteps_since_restore: 13040000
  timesteps_this_iter: 40000
  timesteps_total: 13040000
  training_iteration: 326
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26970], 18419 s, 326 iter, 13040000 ts, 449 rew

agent-1: 8.0
agent-2: 6.0
agent-3: 8.0
agent-4: 15.0
agent-5: 9.0
agent-6: 11.0
agent-7: 9.0
agent-8: 12.0
agent-9: 13.0
agent-10: 14.0
agent-11: 14.0
agent-12: 8.0
agent-13: 9.0
agent-14: 5.0
agent-15: 15.0
agent-16: 11.0
agent-17: 12.0
agent-18: 7.0
agent-19: 11.0
agent-20: 13.0
agent-21: 9.0
agent-22: 9.0
agent-23: 10.0
agent-24: 15.0
agent-25: 21.0
agent-26: 10.0
agent-27: 4.0
agent-28: 12.0
agent-29: 10.0
agent-30: 11.0
agent-31: 13.0
agent-32: 12.0
agent-33: 11.0
agent-34: 14.0
agent-35: 12.0
agent-36: 16.0
agent-37: 10.0
agent-38: 13.0
agent-39: 6.0
agent-40: 8.0
Sum Reward: 436.0
Avg Reward: 10.9
Min Reward: 4.0
Max Reward: 21.0
Gini Coefficient: 0.16639908256880734
20:20 Ratio: 2.3846153846153846
Max-min Ratio: 5.25
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-08_06-17-52
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 487.0
  episode_reward_mean: 448.92
  episode_reward_min: 392.0
  episodes_this_iter: 1
  episodes_total: 326
  experiment_id: 4e724eb5b3a34f42879644e84578eec0
  hostname: gpu024
  info:
    apply_time_ms: 2.612
    dispatch_time_ms: 5.665
    learner:
      cur_lr: 0.0004915359895676374
      grad_gnorm: 1.021867036819458
      policy_entropy: 776.070068359375
      policy_loss: 0.49688830971717834
      var_gnorm: 38.60310363769531
      vf_explained_var: -0.2656984329223633
      vf_loss: 0.0003801415441557765
    num_steps_sampled: 13080000
    num_steps_trained: 13080000
    wait_time_ms: 550.974
  iterations_since_restore: 327
  node_ip: 172.17.8.24
  num_metric_batches_dropped: 0
  pid: 26970
  policy_reward_mean: {}
  time_since_restore: 18476.10130929947
  time_this_iter_s: 56.46669363975525
  time_total_s: 18476.10130929947
  timestamp: 1594203472
  timesteps_since_restore: 13080000
  timesteps_this_iter: 40000
  timesteps_total: 13080000
  training_iteration: 327
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26970], 18476 s, 327 iter, 13080000 ts, 449 rew

agent-1: 10.0
agent-2: 16.0
agent-3: 12.0
agent-4: 15.0
agent-5: 11.0
agent-6: 14.0
agent-7: 11.0
agent-8: 0.0
agent-9: 9.0
agent-10: 5.0
agent-11: 11.0
agent-12: 15.0
agent-13: 8.0
agent-14: 6.0
agent-15: 15.0
agent-16: 6.0
agent-17: 11.0
agent-18: 7.0
agent-19: 12.0
agent-20: 10.0
agent-21: 8.0
agent-22: 16.0
agent-23: 22.0
agent-24: 9.0
agent-25: 8.0
agent-26: 4.0
agent-27: 15.0
agent-28: 11.0
agent-29: 19.0
agent-30: 10.0
agent-31: 9.0
agent-32: 11.0
agent-33: 10.0
agent-34: 16.0
agent-35: 14.0
agent-36: 15.0
agent-37: 8.0
agent-38: 13.0
agent-39: 8.0
agent-40: 8.0
Sum Reward: 438.0
Avg Reward: 10.95
Min Reward: 0.0
Max Reward: 22.0
Gini Coefficient: 0.21198630136986302
20:20 Ratio: 3.0454545454545454
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-08_06-18-49
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 487.0
  episode_reward_mean: 448.99
  episode_reward_min: 392.0
  episodes_this_iter: 1
  episodes_total: 327
  experiment_id: 4e724eb5b3a34f42879644e84578eec0
  hostname: gpu024
  info:
    apply_time_ms: 2.846
    dispatch_time_ms: 6.679
    learner:
      cur_lr: 0.0004888719995506108
      grad_gnorm: 1.2098456621170044
      policy_entropy: 774.0919189453125
      policy_loss: -0.5593562126159668
      var_gnorm: 38.63538360595703
      vf_explained_var: -1.0
      vf_loss: 0.0011421778472140431
    num_steps_sampled: 13120000
    num_steps_trained: 13120000
    wait_time_ms: 554.806
  iterations_since_restore: 328
  node_ip: 172.17.8.24
  num_metric_batches_dropped: 0
  pid: 26970
  policy_reward_mean: {}
  time_since_restore: 18532.509225845337
  time_this_iter_s: 56.40791654586792
  time_total_s: 18532.509225845337
  timestamp: 1594203529
  timesteps_since_restore: 13120000
  timesteps_this_iter: 40000
  timesteps_total: 13120000
  training_iteration: 328
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26970], 18532 s, 328 iter, 13120000 ts, 449 rew

agent-1: 19.0
agent-2: 10.0
agent-3: 7.0
agent-4: 11.0
agent-5: 5.0
agent-6: 8.0
agent-7: 9.0
agent-8: 11.0
agent-9: 12.0
agent-10: 11.0
agent-11: 16.0
agent-12: 12.0
agent-13: 14.0
agent-14: 13.0
agent-15: 14.0
agent-16: 15.0
agent-17: 11.0
agent-18: 8.0
agent-19: 12.0
agent-20: 10.0
agent-21: 10.0
agent-22: 12.0
agent-23: 7.0
agent-24: 11.0
agent-25: 10.0
agent-26: 11.0
agent-27: 7.0
agent-28: 17.0
agent-29: 13.0
agent-30: 9.0
agent-31: 1.0
agent-32: 14.0
agent-33: 7.0
agent-34: 10.0
agent-35: 6.0
agent-36: 18.0
agent-37: 17.0
agent-38: 12.0
agent-39: 12.0
agent-40: 13.0
Sum Reward: 445.0
Avg Reward: 11.125
Min Reward: 1.0
Max Reward: 19.0
Gini Coefficient: 0.1800561797752809
20:20 Ratio: 2.7083333333333335
Max-min Ratio: 19.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-08_06-19-45
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 487.0
  episode_reward_mean: 448.89
  episode_reward_min: 392.0
  episodes_this_iter: 1
  episodes_total: 328
  experiment_id: 4e724eb5b3a34f42879644e84578eec0
  hostname: gpu024
  info:
    apply_time_ms: 2.731
    dispatch_time_ms: 6.469
    learner:
      cur_lr: 0.0004862080095335841
      grad_gnorm: 1.6899287700653076
      policy_entropy: 775.3797607421875
      policy_loss: -1.6142888069152832
      var_gnorm: 38.63319778442383
      vf_explained_var: -1.0
      vf_loss: 0.0008096208912320435
    num_steps_sampled: 13160000
    num_steps_trained: 13160000
    wait_time_ms: 546.632
  iterations_since_restore: 329
  node_ip: 172.17.8.24
  num_metric_batches_dropped: 0
  pid: 26970
  policy_reward_mean: {}
  time_since_restore: 18589.006842136383
  time_this_iter_s: 56.49761629104614
  time_total_s: 18589.006842136383
  timestamp: 1594203585
  timesteps_since_restore: 13160000
  timesteps_this_iter: 40000
  timesteps_total: 13160000
  training_iteration: 329
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26970], 18589 s, 329 iter, 13160000 ts, 449 rew

agent-1: 10.0
agent-2: 11.0
agent-3: 19.0
agent-4: 12.0
agent-5: 12.0
agent-6: 13.0
agent-7: 14.0
agent-8: 6.0
agent-9: 6.0
agent-10: 10.0
agent-11: 12.0
agent-12: 9.0
agent-13: 11.0
agent-14: 14.0
agent-15: 15.0
agent-16: 11.0
agent-17: 18.0
agent-18: 8.0
agent-19: 9.0
agent-20: 15.0
agent-21: 8.0
agent-22: 17.0
agent-23: 4.0
agent-24: 4.0
agent-25: 9.0
agent-26: 16.0
agent-27: 5.0
agent-28: 10.0
agent-29: 8.0
agent-30: 14.0
agent-31: 16.0
agent-32: 13.0
agent-33: 8.0
agent-34: 6.0
agent-35: 12.0
agent-36: 11.0
agent-37: 13.0
agent-38: 10.0
agent-39: 7.0
agent-40: 8.0
Sum Reward: 434.0
Avg Reward: 10.85
Min Reward: 4.0
Max Reward: 19.0
Gini Coefficient: 0.19619815668202764
20:20 Ratio: 2.8260869565217392
Max-min Ratio: 4.75
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-08_06-20-42
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 487.0
  episode_reward_mean: 448.68
  episode_reward_min: 392.0
  episodes_this_iter: 1
  episodes_total: 329
  experiment_id: 4e724eb5b3a34f42879644e84578eec0
  hostname: gpu024
  info:
    apply_time_ms: 2.543
    dispatch_time_ms: 5.796
    learner:
      cur_lr: 0.000483543990412727
      grad_gnorm: 0.49125048518180847
      policy_entropy: 773.3599853515625
      policy_loss: -0.13242945075035095
      var_gnorm: 38.64862060546875
      vf_explained_var: -0.15337681770324707
      vf_loss: 3.249841392971575e-05
    num_steps_sampled: 13200000
    num_steps_trained: 13200000
    wait_time_ms: 578.579
  iterations_since_restore: 330
  node_ip: 172.17.8.24
  num_metric_batches_dropped: 0
  pid: 26970
  policy_reward_mean: {}
  time_since_restore: 18645.886539697647
  time_this_iter_s: 56.87969756126404
  time_total_s: 18645.886539697647
  timestamp: 1594203642
  timesteps_since_restore: 13200000
  timesteps_this_iter: 40000
  timesteps_total: 13200000
  training_iteration: 330
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26970], 18645 s, 330 iter, 13200000 ts, 449 rew

agent-1: 16.0
agent-2: 7.0
agent-3: 4.0
agent-4: 15.0
agent-5: 13.0
agent-6: 15.0
agent-7: 12.0
agent-8: 12.0
agent-9: 11.0
agent-10: 10.0
agent-11: 8.0
agent-12: 9.0
agent-13: 10.0
agent-14: 8.0
agent-15: 10.0
agent-16: 13.0
agent-17: 13.0
agent-18: 13.0
agent-19: 5.0
agent-20: 11.0
agent-21: 14.0
agent-22: 12.0
agent-23: 6.0
agent-24: 16.0
agent-25: 11.0
agent-26: 7.0
agent-27: 14.0
agent-28: 11.0
agent-29: 16.0
agent-30: 12.0
agent-31: 13.0
agent-32: 11.0
agent-33: 7.0
agent-34: 9.0
agent-35: 10.0
agent-36: 9.0
agent-37: 14.0
agent-38: 12.0
agent-39: 6.0
agent-40: 16.0
Sum Reward: 441.0
Avg Reward: 11.025
Min Reward: 4.0
Max Reward: 16.0
Gini Coefficient: 0.16320861678004536
20:20 Ratio: 2.44
Max-min Ratio: 4.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-08_06-21-39
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 487.0
  episode_reward_mean: 448.54
  episode_reward_min: 392.0
  episodes_this_iter: 1
  episodes_total: 330
  experiment_id: 4e724eb5b3a34f42879644e84578eec0
  hostname: gpu024
  info:
    apply_time_ms: 2.591
    dispatch_time_ms: 6.224
    learner:
      cur_lr: 0.00048088000039570034
      grad_gnorm: 40.00001525878906
      policy_entropy: 617.419677734375
      policy_loss: 8.41775894165039
      var_gnorm: 38.65632247924805
      vf_explained_var: 0.6181899905204773
      vf_loss: 7.498774528503418
    num_steps_sampled: 13240000
    num_steps_trained: 13240000
    wait_time_ms: 543.912
  iterations_since_restore: 331
  node_ip: 172.17.8.24
  num_metric_batches_dropped: 0
  pid: 26970
  policy_reward_mean: {}
  time_since_restore: 18702.270106315613
  time_this_iter_s: 56.3835666179657
  time_total_s: 18702.270106315613
  timestamp: 1594203699
  timesteps_since_restore: 13240000
  timesteps_this_iter: 40000
  timesteps_total: 13240000
  training_iteration: 331
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26970], 18702 s, 331 iter, 13240000 ts, 449 rew

agent-1: 13.0
agent-2: 13.0
agent-3: 19.0
agent-4: 12.0
agent-5: 10.0
agent-6: 0.0
agent-7: 12.0
agent-8: 12.0
agent-9: 16.0
agent-10: 11.0
agent-11: 9.0
agent-12: 7.0
agent-13: 8.0
agent-14: 8.0
agent-15: 14.0
agent-16: 16.0
agent-17: 13.0
agent-18: 16.0
agent-19: 7.0
agent-20: 14.0
agent-21: 10.0
agent-22: 12.0
agent-23: 12.0
agent-24: 14.0
agent-25: 15.0
agent-26: 8.0
agent-27: 5.0
agent-28: 19.0
agent-29: 13.0
agent-30: 13.0
agent-31: 12.0
agent-32: 10.0
agent-33: 10.0
agent-34: 15.0
agent-35: 11.0
agent-36: 16.0
agent-37: 10.0
agent-38: 13.0
agent-39: 15.0
agent-40: 9.0
Sum Reward: 472.0
Avg Reward: 11.8
Min Reward: 0.0
Max Reward: 19.0
Gini Coefficient: 0.1690677966101695
20:20 Ratio: 2.5384615384615383
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-08_06-22-35
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 487.0
  episode_reward_mean: 448.74
  episode_reward_min: 392.0
  episodes_this_iter: 1
  episodes_total: 331
  experiment_id: 4e724eb5b3a34f42879644e84578eec0
  hostname: gpu024
  info:
    apply_time_ms: 2.494
    dispatch_time_ms: 5.447
    learner:
      cur_lr: 0.00047821601037867367
      grad_gnorm: 23.511533737182617
      policy_entropy: 773.0973510742188
      policy_loss: -0.5099412798881531
      var_gnorm: 38.66284942626953
      vf_explained_var: -1.0
      vf_loss: 0.002769879763945937
    num_steps_sampled: 13280000
    num_steps_trained: 13280000
    wait_time_ms: 539.783
  iterations_since_restore: 332
  node_ip: 172.17.8.24
  num_metric_batches_dropped: 0
  pid: 26970
  policy_reward_mean: {}
  time_since_restore: 18758.631781816483
  time_this_iter_s: 56.36167550086975
  time_total_s: 18758.631781816483
  timestamp: 1594203755
  timesteps_since_restore: 13280000
  timesteps_this_iter: 40000
  timesteps_total: 13280000
  training_iteration: 332
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26970], 18758 s, 332 iter, 13280000 ts, 449 rew

agent-1: 9.0
agent-2: 4.0
agent-3: 6.0
agent-4: 6.0
agent-5: 11.0
agent-6: 12.0
agent-7: 13.0
agent-8: 15.0
agent-9: 18.0
agent-10: 18.0
agent-11: 11.0
agent-12: 4.0
agent-13: 14.0
agent-14: 13.0
agent-15: 15.0
agent-16: 6.0
agent-17: 12.0
agent-18: 13.0
agent-19: 9.0
agent-20: 15.0
agent-21: 5.0
agent-22: 9.0
agent-23: 8.0
agent-24: 7.0
agent-25: 10.0
agent-26: 8.0
agent-27: 7.0
agent-28: 10.0
agent-29: 6.0
agent-30: 12.0
agent-31: 13.0
agent-32: 15.0
agent-33: 12.0
agent-34: 16.0
agent-35: 15.0
agent-36: 12.0
agent-37: 11.0
agent-38: 11.0
agent-39: 7.0
agent-40: 13.0
Sum Reward: 431.0
Avg Reward: 10.775
Min Reward: 4.0
Max Reward: 18.0
Gini Coefficient: 0.1961136890951276
20:20 Ratio: 2.8863636363636362
Max-min Ratio: 4.5
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-08_06-23-32
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 487.0
  episode_reward_mean: 448.24
  episode_reward_min: 392.0
  episodes_this_iter: 1
  episodes_total: 332
  experiment_id: 4e724eb5b3a34f42879644e84578eec0
  hostname: gpu024
  info:
    apply_time_ms: 3.031
    dispatch_time_ms: 6.68
    learner:
      cur_lr: 0.00047555199125781655
      grad_gnorm: 1.2930853366851807
      policy_entropy: 776.006103515625
      policy_loss: 0.022851288318634033
      var_gnorm: 38.66872024536133
      vf_explained_var: -0.13582062721252441
      vf_loss: 0.009222215041518211
    num_steps_sampled: 13320000
    num_steps_trained: 13320000
    wait_time_ms: 551.927
  iterations_since_restore: 333
  node_ip: 172.17.8.24
  num_metric_batches_dropped: 0
  pid: 26970
  policy_reward_mean: {}
  time_since_restore: 18815.263196468353
  time_this_iter_s: 56.63141465187073
  time_total_s: 18815.263196468353
  timestamp: 1594203812
  timesteps_since_restore: 13320000
  timesteps_this_iter: 40000
  timesteps_total: 13320000
  training_iteration: 333
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26970], 18815 s, 333 iter, 13320000 ts, 448 rew

agent-1: 13.0
agent-2: 4.0
agent-3: 11.0
agent-4: 10.0
agent-5: 10.0
agent-6: 13.0
agent-7: 12.0
agent-8: 17.0
agent-9: 7.0
agent-10: 15.0
agent-11: 9.0
agent-12: 10.0
agent-13: 8.0
agent-14: 17.0
agent-15: 22.0
agent-16: 15.0
agent-17: 11.0
agent-18: 7.0
agent-19: 10.0
agent-20: 9.0
agent-21: 12.0
agent-22: 7.0
agent-23: 8.0
agent-24: 18.0
agent-25: 7.0
agent-26: 10.0
agent-27: 7.0
agent-28: 13.0
agent-29: 8.0
agent-30: 18.0
agent-31: 11.0
agent-32: 8.0
agent-33: 6.0
agent-34: 12.0
agent-35: 11.0
agent-36: 12.0
agent-37: 5.0
agent-38: 6.0
agent-39: 9.0
agent-40: 16.0
Sum Reward: 434.0
Avg Reward: 10.85
Min Reward: 4.0
Max Reward: 22.0
Gini Coefficient: 0.2029953917050691
20:20 Ratio: 2.816326530612245
Max-min Ratio: 5.5
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-08_06-24-28
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 487.0
  episode_reward_mean: 448.0
  episode_reward_min: 392.0
  episodes_this_iter: 1
  episodes_total: 333
  experiment_id: 4e724eb5b3a34f42879644e84578eec0
  hostname: gpu024
  info:
    apply_time_ms: 2.561
    dispatch_time_ms: 5.694
    learner:
      cur_lr: 0.0004728880012407899
      grad_gnorm: 0.12045544385910034
      policy_entropy: 774.8588256835938
      policy_loss: 0.03859776258468628
      var_gnorm: 38.682247161865234
      vf_explained_var: -0.24529671669006348
      vf_loss: 0.00011591886868700385
    num_steps_sampled: 13360000
    num_steps_trained: 13360000
    wait_time_ms: 556.872
  iterations_since_restore: 334
  node_ip: 172.17.8.24
  num_metric_batches_dropped: 0
  pid: 26970
  policy_reward_mean: {}
  time_since_restore: 18871.487649440765
  time_this_iter_s: 56.22445297241211
  time_total_s: 18871.487649440765
  timestamp: 1594203868
  timesteps_since_restore: 13360000
  timesteps_this_iter: 40000
  timesteps_total: 13360000
  training_iteration: 334
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26970], 18871 s, 334 iter, 13360000 ts, 448 rew

agent-1: 13.0
agent-2: 3.0
agent-3: 8.0
agent-4: 13.0
agent-5: 11.0
agent-6: 17.0
agent-7: 16.0
agent-8: 11.0
agent-9: 10.0
agent-10: 10.0
agent-11: 9.0
agent-12: 17.0
agent-13: 10.0
agent-14: 13.0
agent-15: 12.0
agent-16: 4.0
agent-17: 14.0
agent-18: 14.0
agent-19: 13.0
agent-20: 20.0
agent-21: 8.0
agent-22: 12.0
agent-23: 14.0
agent-24: 11.0
agent-25: 16.0
agent-26: 9.0
agent-27: 14.0
agent-28: 9.0
agent-29: 10.0
agent-30: 5.0
agent-31: 7.0
agent-32: 10.0
agent-33: 16.0
agent-34: 14.0
agent-35: 6.0
agent-36: 1.0
agent-37: 13.0
agent-38: 9.0
agent-39: 16.0
agent-40: 12.0
Sum Reward: 450.0
Avg Reward: 11.25
Min Reward: 1.0
Max Reward: 20.0
Gini Coefficient: 0.19933333333333333
20:20 Ratio: 3.142857142857143
Max-min Ratio: 20.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-08_06-25-25
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 487.0
  episode_reward_mean: 448.05
  episode_reward_min: 392.0
  episodes_this_iter: 1
  episodes_total: 334
  experiment_id: 4e724eb5b3a34f42879644e84578eec0
  hostname: gpu024
  info:
    apply_time_ms: 3.144
    dispatch_time_ms: 7.002
    learner:
      cur_lr: 0.00047022401122376323
      grad_gnorm: 21.18975257873535
      policy_entropy: 623.66162109375
      policy_loss: -0.7601259350776672
      var_gnorm: 38.68990707397461
      vf_explained_var: 0.5560736656188965
      vf_loss: 1.055161952972412
    num_steps_sampled: 13400000
    num_steps_trained: 13400000
    wait_time_ms: 550.362
  iterations_since_restore: 335
  node_ip: 172.17.8.24
  num_metric_batches_dropped: 0
  pid: 26970
  policy_reward_mean: {}
  time_since_restore: 18928.54535126686
  time_this_iter_s: 57.05770182609558
  time_total_s: 18928.54535126686
  timestamp: 1594203925
  timesteps_since_restore: 13400000
  timesteps_this_iter: 40000
  timesteps_total: 13400000
  training_iteration: 335
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26970], 18928 s, 335 iter, 13400000 ts, 448 rew

agent-1: 10.0
agent-2: 11.0
agent-3: 13.0
agent-4: 4.0
agent-5: 5.0
agent-6: 14.0
agent-7: 7.0
agent-8: 15.0
agent-9: 12.0
agent-10: 7.0
agent-11: 5.0
agent-12: 17.0
agent-13: 13.0
agent-14: 15.0
agent-15: 8.0
agent-16: 10.0
agent-17: 15.0
agent-18: 12.0
agent-19: 14.0
agent-20: 6.0
agent-21: 11.0
agent-22: 11.0
agent-23: 6.0
agent-24: 10.0
agent-25: 14.0
agent-26: 14.0
agent-27: 9.0
agent-28: 11.0
agent-29: 11.0
agent-30: 8.0
agent-31: 11.0
agent-32: 15.0
agent-33: 12.0
agent-34: 14.0
agent-35: 14.0
agent-36: 19.0
agent-37: 11.0
agent-38: 13.0
agent-39: 7.0
agent-40: 12.0
Sum Reward: 446.0
Avg Reward: 11.15
Min Reward: 4.0
Max Reward: 19.0
Gini Coefficient: 0.1742152466367713
20:20 Ratio: 2.6382978723404253
Max-min Ratio: 4.75
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-08_06-26-21
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 487.0
  episode_reward_mean: 447.77
  episode_reward_min: 392.0
  episodes_this_iter: 1
  episodes_total: 335
  experiment_id: 4e724eb5b3a34f42879644e84578eec0
  hostname: gpu024
  info:
    apply_time_ms: 3.514
    dispatch_time_ms: 6.679
    learner:
      cur_lr: 0.0004675599921029061
      grad_gnorm: 0.18249283730983734
      policy_entropy: 775.22265625
      policy_loss: 0.40052834153175354
      var_gnorm: 38.6748161315918
      vf_explained_var: -0.3949493169784546
      vf_loss: 4.386061482364312e-05
    num_steps_sampled: 13440000
    num_steps_trained: 13440000
    wait_time_ms: 556.44
  iterations_since_restore: 336
  node_ip: 172.17.8.24
  num_metric_batches_dropped: 0
  pid: 26970
  policy_reward_mean: {}
  time_since_restore: 18984.86137366295
  time_this_iter_s: 56.31602239608765
  time_total_s: 18984.86137366295
  timestamp: 1594203981
  timesteps_since_restore: 13440000
  timesteps_this_iter: 40000
  timesteps_total: 13440000
  training_iteration: 336
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26970], 18984 s, 336 iter, 13440000 ts, 448 rew

agent-1: 3.0
agent-2: 11.0
agent-3: 12.0
agent-4: 20.0
agent-5: 11.0
agent-6: 12.0
agent-7: 11.0
agent-8: 9.0
agent-9: 8.0
agent-10: 15.0
agent-11: 13.0
agent-12: 13.0
agent-13: 8.0
agent-14: 6.0
agent-15: 12.0
agent-16: 13.0
agent-17: 9.0
agent-18: 16.0
agent-19: 11.0
agent-20: 10.0
agent-21: 4.0
agent-22: 15.0
agent-23: 8.0
agent-24: 7.0
agent-25: 13.0
agent-26: 14.0
agent-27: 9.0
agent-28: 11.0
agent-29: 13.0
agent-30: 16.0
agent-31: 12.0
agent-32: 12.0
agent-33: 16.0
agent-34: 8.0
agent-35: 16.0
agent-36: 5.0
agent-37: 11.0
agent-38: 12.0
agent-39: 13.0
agent-40: 13.0
Sum Reward: 451.0
Avg Reward: 11.275
Min Reward: 3.0
Max Reward: 20.0
Gini Coefficient: 0.17200665188470066
20:20 Ratio: 2.6122448979591835
Max-min Ratio: 6.666666666666667
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-08_06-27-18
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 487.0
  episode_reward_mean: 448.04
  episode_reward_min: 392.0
  episodes_this_iter: 1
  episodes_total: 336
  experiment_id: 4e724eb5b3a34f42879644e84578eec0
  hostname: gpu024
  info:
    apply_time_ms: 3.179
    dispatch_time_ms: 6.079
    learner:
      cur_lr: 0.00046489600208587945
      grad_gnorm: 2.7053046226501465
      policy_entropy: 776.4832153320312
      policy_loss: 0.29293954372406006
      var_gnorm: 38.674400329589844
      vf_explained_var: -1.0
      vf_loss: 0.0008294148137792945
    num_steps_sampled: 13480000
    num_steps_trained: 13480000
    wait_time_ms: 570.591
  iterations_since_restore: 337
  node_ip: 172.17.8.24
  num_metric_batches_dropped: 0
  pid: 26970
  policy_reward_mean: {}
  time_since_restore: 19041.73201107979
  time_this_iter_s: 56.8706374168396
  time_total_s: 19041.73201107979
  timestamp: 1594204038
  timesteps_since_restore: 13480000
  timesteps_this_iter: 40000
  timesteps_total: 13480000
  training_iteration: 337
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26970], 19041 s, 337 iter, 13480000 ts, 448 rew

agent-1: 18.0
agent-2: 15.0
agent-3: 14.0
agent-4: 15.0
agent-5: 10.0
agent-6: 23.0
agent-7: 12.0
agent-8: 14.0
agent-9: 4.0
agent-10: 17.0
agent-11: 13.0
agent-12: 12.0
agent-13: 17.0
agent-14: 3.0
agent-15: 18.0
agent-16: 15.0
agent-17: 11.0
agent-18: 10.0
agent-19: 9.0
agent-20: 9.0
agent-21: 10.0
agent-22: 17.0
agent-23: 14.0
agent-24: 9.0
agent-25: 14.0
agent-26: 10.0
agent-27: 5.0
agent-28: 12.0
agent-29: 5.0
agent-30: 7.0
agent-31: 8.0
agent-32: 15.0
agent-33: 16.0
agent-34: 11.0
agent-35: 8.0
agent-36: 8.0
agent-37: 11.0
agent-38: 16.0
agent-39: 8.0
agent-40: 8.0
Sum Reward: 471.0
Avg Reward: 11.775
Min Reward: 3.0
Max Reward: 23.0
Gini Coefficient: 0.2068471337579618
20:20 Ratio: 2.9583333333333335
Max-min Ratio: 7.666666666666667
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-08_06-28-15
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 487.0
  episode_reward_mean: 448.16
  episode_reward_min: 392.0
  episodes_this_iter: 1
  episodes_total: 337
  experiment_id: 4e724eb5b3a34f42879644e84578eec0
  hostname: gpu024
  info:
    apply_time_ms: 2.976
    dispatch_time_ms: 5.98
    learner:
      cur_lr: 0.0004622320120688528
      grad_gnorm: 3.6283817291259766
      policy_entropy: 775.7745361328125
      policy_loss: -0.02129928022623062
      var_gnorm: 38.71427917480469
      vf_explained_var: -1.0
      vf_loss: 0.0017378099728375673
    num_steps_sampled: 13520000
    num_steps_trained: 13520000
    wait_time_ms: 558.972
  iterations_since_restore: 338
  node_ip: 172.17.8.24
  num_metric_batches_dropped: 0
  pid: 26970
  policy_reward_mean: {}
  time_since_restore: 19097.9656355381
  time_this_iter_s: 56.23362445831299
  time_total_s: 19097.9656355381
  timestamp: 1594204095
  timesteps_since_restore: 13520000
  timesteps_this_iter: 40000
  timesteps_total: 13520000
  training_iteration: 338
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26970], 19097 s, 338 iter, 13520000 ts, 448 rew

agent-1: 18.0
agent-2: 8.0
agent-3: 9.0
agent-4: 12.0
agent-5: 9.0
agent-6: 10.0
agent-7: 14.0
agent-8: 11.0
agent-9: 8.0
agent-10: 13.0
agent-11: 7.0
agent-12: 7.0
agent-13: 8.0
agent-14: 14.0
agent-15: 16.0
agent-16: 16.0
agent-17: 12.0
agent-18: 0.0
agent-19: 8.0
agent-20: 10.0
agent-21: 7.0
agent-22: 17.0
agent-23: 17.0
agent-24: 10.0
agent-25: 11.0
agent-26: 9.0
agent-27: 11.0
agent-28: 8.0
agent-29: 12.0
agent-30: 10.0
agent-31: 12.0
agent-32: 11.0
agent-33: 13.0
agent-34: 12.0
agent-35: 13.0
agent-36: 14.0
agent-37: 4.0
agent-38: 14.0
agent-39: 14.0
agent-40: 17.0
Sum Reward: 446.0
Avg Reward: 11.15
Min Reward: 0.0
Max Reward: 18.0
Gini Coefficient: 0.1835201793721973
20:20 Ratio: 2.63265306122449
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-08_06-29-11
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 487.0
  episode_reward_mean: 448.12
  episode_reward_min: 392.0
  episodes_this_iter: 1
  episodes_total: 338
  experiment_id: 4e724eb5b3a34f42879644e84578eec0
  hostname: gpu024
  info:
    apply_time_ms: 4.161
    dispatch_time_ms: 6.586
    learner:
      cur_lr: 0.00045956799294799566
      grad_gnorm: 40.0
      policy_entropy: 351.7325439453125
      policy_loss: -19.113279342651367
      var_gnorm: 38.73596954345703
      vf_explained_var: 0.267825722694397
      vf_loss: 104.4450454711914
    num_steps_sampled: 13560000
    num_steps_trained: 13560000
    wait_time_ms: 527.473
  iterations_since_restore: 339
  node_ip: 172.17.8.24
  num_metric_batches_dropped: 0
  pid: 26970
  policy_reward_mean: {}
  time_since_restore: 19154.488511562347
  time_this_iter_s: 56.522876024246216
  time_total_s: 19154.488511562347
  timestamp: 1594204151
  timesteps_since_restore: 13560000
  timesteps_this_iter: 40000
  timesteps_total: 13560000
  training_iteration: 339
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26970], 19154 s, 339 iter, 13560000 ts, 448 rew

agent-1: 5.0
agent-2: 7.0
agent-3: 12.0
agent-4: 10.0
agent-5: 9.0
agent-6: 5.0
agent-7: 18.0
agent-8: 9.0
agent-9: 15.0
agent-10: 11.0
agent-11: 15.0
agent-12: 14.0
agent-13: 15.0
agent-14: 15.0
agent-15: 11.0
agent-16: 16.0
agent-17: 9.0
agent-18: 9.0
agent-19: 16.0
agent-20: 23.0
agent-21: 11.0
agent-22: 16.0
agent-23: 13.0
agent-24: 14.0
agent-25: 9.0
agent-26: 12.0
agent-27: 11.0
agent-28: 5.0
agent-29: 18.0
agent-30: 12.0
agent-31: 14.0
agent-32: 15.0
agent-33: 15.0
agent-34: 11.0
agent-35: 14.0
agent-36: 10.0
agent-37: 5.0
agent-38: 6.0
agent-39: 8.0
agent-40: 8.0
Sum Reward: 471.0
Avg Reward: 11.775
Min Reward: 5.0
Max Reward: 23.0
Gini Coefficient: 0.1930467091295117
20:20 Ratio: 2.795918367346939
Max-min Ratio: 4.6
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-08_06-30-08
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 487.0
  episode_reward_mean: 448.37
  episode_reward_min: 392.0
  episodes_this_iter: 1
  episodes_total: 339
  experiment_id: 4e724eb5b3a34f42879644e84578eec0
  hostname: gpu024
  info:
    apply_time_ms: 3.646
    dispatch_time_ms: 5.205
    learner:
      cur_lr: 0.000456904002930969
      grad_gnorm: 0.2342403531074524
      policy_entropy: 777.334228515625
      policy_loss: -0.12566722929477692
      var_gnorm: 38.764442443847656
      vf_explained_var: -1.0
      vf_loss: 4.683849329012446e-05
    num_steps_sampled: 13600000
    num_steps_trained: 13600000
    wait_time_ms: 549.306
  iterations_since_restore: 340
  node_ip: 172.17.8.24
  num_metric_batches_dropped: 0
  pid: 26970
  policy_reward_mean: {}
  time_since_restore: 19210.974783420563
  time_this_iter_s: 56.48627185821533
  time_total_s: 19210.974783420563
  timestamp: 1594204208
  timesteps_since_restore: 13600000
  timesteps_this_iter: 40000
  timesteps_total: 13600000
  training_iteration: 340
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26970], 19210 s, 340 iter, 13600000 ts, 448 rew

agent-1: 12.0
agent-2: 13.0
agent-3: 12.0
agent-4: 4.0
agent-5: 18.0
agent-6: 21.0
agent-7: 12.0
agent-8: 12.0
agent-9: 9.0
agent-10: 18.0
agent-11: 8.0
agent-12: 7.0
agent-13: 15.0
agent-14: 4.0
agent-15: 15.0
agent-16: 4.0
agent-17: 14.0
agent-18: 17.0
agent-19: 18.0
agent-20: 11.0
agent-21: 13.0
agent-22: 12.0
agent-23: 14.0
agent-24: 14.0
agent-25: 11.0
agent-26: 15.0
agent-27: 7.0
agent-28: 13.0
agent-29: 6.0
agent-30: 10.0
agent-31: 13.0
agent-32: 14.0
agent-33: 12.0
agent-34: 6.0
agent-35: 5.0
agent-36: 12.0
agent-37: 14.0
agent-38: 8.0
agent-39: 9.0
agent-40: 10.0
Sum Reward: 462.0
Avg Reward: 11.55
Min Reward: 4.0
Max Reward: 21.0
Gini Coefficient: 0.20064935064935066
20:20 Ratio: 3.186046511627907
Max-min Ratio: 5.25
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-08_06-31-04
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 487.0
  episode_reward_mean: 448.5
  episode_reward_min: 392.0
  episodes_this_iter: 1
  episodes_total: 340
  experiment_id: 4e724eb5b3a34f42879644e84578eec0
  hostname: gpu024
  info:
    apply_time_ms: 2.485
    dispatch_time_ms: 7.093
    learner:
      cur_lr: 0.00045424001291394234
      grad_gnorm: 2.4382612705230713
      policy_entropy: 778.13427734375
      policy_loss: -1.3480069637298584
      var_gnorm: 38.77960205078125
      vf_explained_var: -0.5522429943084717
      vf_loss: 0.0009509290102869272
    num_steps_sampled: 13640000
    num_steps_trained: 13640000
    wait_time_ms: 564.503
  iterations_since_restore: 341
  node_ip: 172.17.8.24
  num_metric_batches_dropped: 0
  pid: 26970
  policy_reward_mean: {}
  time_since_restore: 19267.568437099457
  time_this_iter_s: 56.59365367889404
  time_total_s: 19267.568437099457
  timestamp: 1594204264
  timesteps_since_restore: 13640000
  timesteps_this_iter: 40000
  timesteps_total: 13640000
  training_iteration: 341
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26970], 19267 s, 341 iter, 13640000 ts, 448 rew

agent-1: 8.0
agent-2: 13.0
agent-3: 8.0
agent-4: 11.0
agent-5: 3.0
agent-6: 14.0
agent-7: 13.0
agent-8: 5.0
agent-9: 9.0
agent-10: 13.0
agent-11: 14.0
agent-12: 20.0
agent-13: 13.0
agent-14: 9.0
agent-15: 13.0
agent-16: 6.0
agent-17: 6.0
agent-18: 9.0
agent-19: 8.0
agent-20: 19.0
agent-21: 18.0
agent-22: 10.0
agent-23: 11.0
agent-24: 13.0
agent-25: 13.0
agent-26: 12.0
agent-27: 10.0
agent-28: 11.0
agent-29: 9.0
agent-30: 14.0
agent-31: 12.0
agent-32: 14.0
agent-33: 17.0
agent-34: 15.0
agent-35: 7.0
agent-36: 10.0
agent-37: 10.0
agent-38: 10.0
agent-39: 8.0
agent-40: 10.0
Sum Reward: 448.0
Avg Reward: 11.2
Min Reward: 3.0
Max Reward: 20.0
Gini Coefficient: 0.18136160714285715
20:20 Ratio: 2.5686274509803924
Max-min Ratio: 6.666666666666667
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-08_06-32-01
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 487.0
  episode_reward_mean: 448.59
  episode_reward_min: 392.0
  episodes_this_iter: 1
  episodes_total: 341
  experiment_id: 4e724eb5b3a34f42879644e84578eec0
  hostname: gpu024
  info:
    apply_time_ms: 2.433
    dispatch_time_ms: 7.489
    learner:
      cur_lr: 0.0004515759937930852
      grad_gnorm: 0.3353840708732605
      policy_entropy: 776.1005859375
      policy_loss: -0.09397262334823608
      var_gnorm: 38.823551177978516
      vf_explained_var: 0.00729745626449585
      vf_loss: 9.951789979822934e-05
    num_steps_sampled: 13680000
    num_steps_trained: 13680000
    wait_time_ms: 555.691
  iterations_since_restore: 342
  node_ip: 172.17.8.24
  num_metric_batches_dropped: 0
  pid: 26970
  policy_reward_mean: {}
  time_since_restore: 19323.952877759933
  time_this_iter_s: 56.384440660476685
  time_total_s: 19323.952877759933
  timestamp: 1594204321
  timesteps_since_restore: 13680000
  timesteps_this_iter: 40000
  timesteps_total: 13680000
  training_iteration: 342
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26970], 19323 s, 342 iter, 13680000 ts, 449 rew

agent-1: 21.0
agent-2: 8.0
agent-3: 9.0
agent-4: 17.0
agent-5: 17.0
agent-6: 15.0
agent-7: 10.0
agent-8: 3.0
agent-9: 17.0
agent-10: 12.0
agent-11: 8.0
agent-12: 13.0
agent-13: 19.0
agent-14: 16.0
agent-15: 6.0
agent-16: 10.0
agent-17: 14.0
agent-18: 15.0
agent-19: 12.0
agent-20: 13.0
agent-21: 8.0
agent-22: 13.0
agent-23: 6.0
agent-24: 9.0
agent-25: 9.0
agent-26: 14.0
agent-27: 18.0
agent-28: 1.0
agent-29: 18.0
agent-30: 5.0
agent-31: 18.0
agent-32: 11.0
agent-33: 19.0
agent-34: 0.0
agent-35: 10.0
agent-36: 13.0
agent-37: 21.0
agent-38: 12.0
agent-39: 7.0
agent-40: 15.0
Sum Reward: 482.0
Avg Reward: 12.05
Min Reward: 0.0
Max Reward: 21.0
Gini Coefficient: 0.24439834024896265
20:20 Ratio: 4.194444444444445
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-08_06-32-58
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 487.0
  episode_reward_mean: 448.84
  episode_reward_min: 392.0
  episodes_this_iter: 1
  episodes_total: 342
  experiment_id: 4e724eb5b3a34f42879644e84578eec0
  hostname: gpu024
  info:
    apply_time_ms: 3.696
    dispatch_time_ms: 5.341
    learner:
      cur_lr: 0.00044891200377605855
      grad_gnorm: 40.0
      policy_entropy: 444.4631652832031
      policy_loss: 28.84613800048828
      var_gnorm: 38.821109771728516
      vf_explained_var: 0.5324344635009766
      vf_loss: 78.75563049316406
    num_steps_sampled: 13720000
    num_steps_trained: 13720000
    wait_time_ms: 558.757
  iterations_since_restore: 343
  node_ip: 172.17.8.24
  num_metric_batches_dropped: 0
  pid: 26970
  policy_reward_mean: {}
  time_since_restore: 19380.83067703247
  time_this_iter_s: 56.87779927253723
  time_total_s: 19380.83067703247
  timestamp: 1594204378
  timesteps_since_restore: 13720000
  timesteps_this_iter: 40000
  timesteps_total: 13720000
  training_iteration: 343
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26970], 19380 s, 343 iter, 13720000 ts, 449 rew

agent-1: 5.0
agent-2: 6.0
agent-3: 20.0
agent-4: 12.0
agent-5: 12.0
agent-6: 7.0
agent-7: 3.0
agent-8: 13.0
agent-9: 14.0
agent-10: 11.0
agent-11: 19.0
agent-12: 11.0
agent-13: 15.0
agent-14: 13.0
agent-15: 10.0
agent-16: 15.0
agent-17: 9.0
agent-18: 22.0
agent-19: 8.0
agent-20: 10.0
agent-21: 17.0
agent-22: 9.0
agent-23: 13.0
agent-24: 13.0
agent-25: 11.0
agent-26: 8.0
agent-27: 8.0
agent-28: 9.0
agent-29: 6.0
agent-30: 7.0
agent-31: 15.0
agent-32: 14.0
agent-33: 9.0
agent-34: 8.0
agent-35: 13.0
agent-36: 15.0
agent-37: 7.0
agent-38: 15.0
agent-39: 16.0
agent-40: 7.0
Sum Reward: 455.0
Avg Reward: 11.375
Min Reward: 3.0
Max Reward: 22.0
Gini Coefficient: 0.2082967032967033
20:20 Ratio: 2.8958333333333335
Max-min Ratio: 7.333333333333333
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-08_06-33-54
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 487.0
  episode_reward_mean: 448.78
  episode_reward_min: 392.0
  episodes_this_iter: 1
  episodes_total: 343
  experiment_id: 4e724eb5b3a34f42879644e84578eec0
  hostname: gpu024
  info:
    apply_time_ms: 3.97
    dispatch_time_ms: 9.802
    learner:
      cur_lr: 0.0004462480137590319
      grad_gnorm: 0.42015382647514343
      policy_entropy: 775.46435546875
      policy_loss: 0.10326532274484634
      var_gnorm: 38.82486343383789
      vf_explained_var: -0.13065552711486816
      vf_loss: 0.0006022906163707376
    num_steps_sampled: 13760000
    num_steps_trained: 13760000
    wait_time_ms: 540.706
  iterations_since_restore: 344
  node_ip: 172.17.8.24
  num_metric_batches_dropped: 0
  pid: 26970
  policy_reward_mean: {}
  time_since_restore: 19437.266986131668
  time_this_iter_s: 56.43630909919739
  time_total_s: 19437.266986131668
  timestamp: 1594204434
  timesteps_since_restore: 13760000
  timesteps_this_iter: 40000
  timesteps_total: 13760000
  training_iteration: 344
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26970], 19437 s, 344 iter, 13760000 ts, 449 rew

agent-1: 16.0
agent-2: 14.0
agent-3: 11.0
agent-4: 14.0
agent-5: 1.0
agent-6: 13.0
agent-7: 12.0
agent-8: 9.0
agent-9: 15.0
agent-10: 13.0
agent-11: 13.0
agent-12: 16.0
agent-13: 10.0
agent-14: 14.0
agent-15: 4.0
agent-16: 14.0
agent-17: 11.0
agent-18: 9.0
agent-19: 16.0
agent-20: 3.0
agent-21: 9.0
agent-22: 9.0
agent-23: 11.0
agent-24: 16.0
agent-25: 12.0
agent-26: 10.0
agent-27: 15.0
agent-28: 1.0
agent-29: 14.0
agent-30: 14.0
agent-31: 14.0
agent-32: 15.0
agent-33: 11.0
agent-34: 8.0
agent-35: 12.0
agent-36: 9.0
agent-37: 7.0
agent-38: 7.0
agent-39: 8.0
agent-40: 19.0
Sum Reward: 449.0
Avg Reward: 11.225
Min Reward: 1.0
Max Reward: 19.0
Gini Coefficient: 0.20038975501113584
20:20 Ratio: 3.282051282051282
Max-min Ratio: 19.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-08_06-34-51
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 487.0
  episode_reward_mean: 448.77
  episode_reward_min: 392.0
  episodes_this_iter: 1
  episodes_total: 344
  experiment_id: 4e724eb5b3a34f42879644e84578eec0
  hostname: gpu024
  info:
    apply_time_ms: 3.877
    dispatch_time_ms: 6.51
    learner:
      cur_lr: 0.00044358399463817477
      grad_gnorm: 1.2637276649475098
      policy_entropy: 777.5379638671875
      policy_loss: 0.2856368124485016
      var_gnorm: 38.8206787109375
      vf_explained_var: -1.0
      vf_loss: 0.0006018559215590358
    num_steps_sampled: 13800000
    num_steps_trained: 13800000
    wait_time_ms: 555.81
  iterations_since_restore: 345
  node_ip: 172.17.8.24
  num_metric_batches_dropped: 0
  pid: 26970
  policy_reward_mean: {}
  time_since_restore: 19493.930879831314
  time_this_iter_s: 56.663893699645996
  time_total_s: 19493.930879831314
  timestamp: 1594204491
  timesteps_since_restore: 13800000
  timesteps_this_iter: 40000
  timesteps_total: 13800000
  training_iteration: 345
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26970], 19493 s, 345 iter, 13800000 ts, 449 rew

agent-1: 10.0
agent-2: 10.0
agent-3: 16.0
agent-4: 17.0
agent-5: 11.0
agent-6: 12.0
agent-7: 11.0
agent-8: 7.0
agent-9: 8.0
agent-10: 10.0
agent-11: 0.0
agent-12: 9.0
agent-13: 10.0
agent-14: 11.0
agent-15: 13.0
agent-16: 14.0
agent-17: 15.0
agent-18: 8.0
agent-19: 19.0
agent-20: 14.0
agent-21: 13.0
agent-22: 5.0
agent-23: 9.0
agent-24: 12.0
agent-25: 8.0
agent-26: 9.0
agent-27: 12.0
agent-28: 13.0
agent-29: 15.0
agent-30: 11.0
agent-31: 13.0
agent-32: 13.0
agent-33: 10.0
agent-34: 9.0
agent-35: 12.0
agent-36: 11.0
agent-37: 8.0
agent-38: 18.0
agent-39: 12.0
agent-40: 4.0
Sum Reward: 442.0
Avg Reward: 11.05
Min Reward: 0.0
Max Reward: 19.0
Gini Coefficient: 0.17861990950226245
20:20 Ratio: 2.6666666666666665
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-08_06-35-47
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 487.0
  episode_reward_mean: 448.8
  episode_reward_min: 392.0
  episodes_this_iter: 1
  episodes_total: 345
  experiment_id: 4e724eb5b3a34f42879644e84578eec0
  hostname: gpu024
  info:
    apply_time_ms: 2.491
    dispatch_time_ms: 6.517
    learner:
      cur_lr: 0.0004409200046211481
      grad_gnorm: 4.091256141662598
      policy_entropy: 769.97998046875
      policy_loss: -0.011504027992486954
      var_gnorm: 38.84782409667969
      vf_explained_var: -1.0
      vf_loss: 0.0012395621743053198
    num_steps_sampled: 13840000
    num_steps_trained: 13840000
    wait_time_ms: 560.77
  iterations_since_restore: 346
  node_ip: 172.17.8.24
  num_metric_batches_dropped: 0
  pid: 26970
  policy_reward_mean: {}
  time_since_restore: 19550.178349733353
  time_this_iter_s: 56.247469902038574
  time_total_s: 19550.178349733353
  timestamp: 1594204547
  timesteps_since_restore: 13840000
  timesteps_this_iter: 40000
  timesteps_total: 13840000
  training_iteration: 346
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26970], 19550 s, 346 iter, 13840000 ts, 449 rew

agent-1: 18.0
agent-2: 5.0
agent-3: 13.0
agent-4: 11.0
agent-5: 28.0
agent-6: 5.0
agent-7: 14.0
agent-8: 11.0
agent-9: 11.0
agent-10: 15.0
agent-11: 6.0
agent-12: 7.0
agent-13: 6.0
agent-14: 7.0
agent-15: 15.0
agent-16: 12.0
agent-17: 13.0
agent-18: 19.0
agent-19: 18.0
agent-20: 11.0
agent-21: 12.0
agent-22: 16.0
agent-23: 12.0
agent-24: 12.0
agent-25: 13.0
agent-26: 6.0
agent-27: 13.0
agent-28: 5.0
agent-29: 7.0
agent-30: 12.0
agent-31: 13.0
agent-32: 11.0
agent-33: 13.0
agent-34: 13.0
agent-35: 11.0
agent-36: 15.0
agent-37: 9.0
agent-38: 12.0
agent-39: 13.0
agent-40: 19.0
Sum Reward: 482.0
Avg Reward: 12.05
Min Reward: 5.0
Max Reward: 28.0
Gini Coefficient: 0.1995850622406639
20:20 Ratio: 3.148936170212766
Max-min Ratio: 5.6
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-08_06-36-44
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 487.0
  episode_reward_mean: 448.89
  episode_reward_min: 392.0
  episodes_this_iter: 1
  episodes_total: 346
  experiment_id: 4e724eb5b3a34f42879644e84578eec0
  hostname: gpu024
  info:
    apply_time_ms: 2.624
    dispatch_time_ms: 7.124
    learner:
      cur_lr: 0.000438255985500291
      grad_gnorm: 0.10046467930078506
      policy_entropy: 777.4603271484375
      policy_loss: -0.22660893201828003
      var_gnorm: 38.861473083496094
      vf_explained_var: -1.0
      vf_loss: 0.0002301826752955094
    num_steps_sampled: 13880000
    num_steps_trained: 13880000
    wait_time_ms: 552.695
  iterations_since_restore: 347
  node_ip: 172.17.8.24
  num_metric_batches_dropped: 0
  pid: 26970
  policy_reward_mean: {}
  time_since_restore: 19606.661390066147
  time_this_iter_s: 56.48304033279419
  time_total_s: 19606.661390066147
  timestamp: 1594204604
  timesteps_since_restore: 13880000
  timesteps_this_iter: 40000
  timesteps_total: 13880000
  training_iteration: 347
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26970], 19606 s, 347 iter, 13880000 ts, 449 rew

agent-1: 15.0
agent-2: 10.0
agent-3: 8.0
agent-4: 18.0
agent-5: 8.0
agent-6: 6.0
agent-7: 4.0
agent-8: 8.0
agent-9: 11.0
agent-10: 6.0
agent-11: 8.0
agent-12: 8.0
agent-13: 5.0
agent-14: 15.0
agent-15: 11.0
agent-16: 15.0
agent-17: 17.0
agent-18: 10.0
agent-19: 14.0
agent-20: 12.0
agent-21: 2.0
agent-22: 9.0
agent-23: 16.0
agent-24: 12.0
agent-25: 15.0
agent-26: 14.0
agent-27: 11.0
agent-28: 10.0
agent-29: 16.0
agent-30: 6.0
agent-31: 11.0
agent-32: 14.0
agent-33: 18.0
agent-34: 13.0
agent-35: 13.0
agent-36: 13.0
agent-37: 16.0
agent-38: 4.0
agent-39: 13.0
agent-40: 7.0
Sum Reward: 442.0
Avg Reward: 11.05
Min Reward: 2.0
Max Reward: 18.0
Gini Coefficient: 0.21255656108597284
20:20 Ratio: 3.275
Max-min Ratio: 9.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-08_06-37-40
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 487.0
  episode_reward_mean: 448.88
  episode_reward_min: 392.0
  episodes_this_iter: 1
  episodes_total: 347
  experiment_id: 4e724eb5b3a34f42879644e84578eec0
  hostname: gpu024
  info:
    apply_time_ms: 3.175
    dispatch_time_ms: 6.738
    learner:
      cur_lr: 0.0004355919954832643
      grad_gnorm: 0.2860880196094513
      policy_entropy: 775.098876953125
      policy_loss: -0.1445656716823578
      var_gnorm: 38.883907318115234
      vf_explained_var: -1.0
      vf_loss: 0.0002589214127510786
    num_steps_sampled: 13920000
    num_steps_trained: 13920000
    wait_time_ms: 558.436
  iterations_since_restore: 348
  node_ip: 172.17.8.24
  num_metric_batches_dropped: 0
  pid: 26970
  policy_reward_mean: {}
  time_since_restore: 19663.0623755455
  time_this_iter_s: 56.40098547935486
  time_total_s: 19663.0623755455
  timestamp: 1594204660
  timesteps_since_restore: 13920000
  timesteps_this_iter: 40000
  timesteps_total: 13920000
  training_iteration: 348
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26970], 19663 s, 348 iter, 13920000 ts, 449 rew

agent-1: 14.0
agent-2: 9.0
agent-3: 3.0
agent-4: 9.0
agent-5: 13.0
agent-6: 11.0
agent-7: 19.0
agent-8: 15.0
agent-9: 13.0
agent-10: 6.0
agent-11: 19.0
agent-12: 16.0
agent-13: 14.0
agent-14: 12.0
agent-15: 11.0
agent-16: 9.0
agent-17: 6.0
agent-18: 9.0
agent-19: 18.0
agent-20: 5.0
agent-21: 12.0
agent-22: 12.0
agent-23: 10.0
agent-24: 15.0
agent-25: 12.0
agent-26: 8.0
agent-27: 11.0
agent-28: 12.0
agent-29: 11.0
agent-30: 12.0
agent-31: 11.0
agent-32: 4.0
agent-33: 11.0
agent-34: 8.0
agent-35: 8.0
agent-36: 6.0
agent-37: 10.0
agent-38: 3.0
agent-39: 11.0
agent-40: 16.0
Sum Reward: 434.0
Avg Reward: 10.85
Min Reward: 3.0
Max Reward: 19.0
Gini Coefficient: 0.20357142857142857
20:20 Ratio: 3.2195121951219514
Max-min Ratio: 6.333333333333333
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-08_06-38-37
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 487.0
  episode_reward_mean: 448.69
  episode_reward_min: 392.0
  episodes_this_iter: 1
  episodes_total: 348
  experiment_id: 4e724eb5b3a34f42879644e84578eec0
  hostname: gpu024
  info:
    apply_time_ms: 3.371
    dispatch_time_ms: 7.363
    learner:
      cur_lr: 0.00043292800546623766
      grad_gnorm: 0.6476857662200928
      policy_entropy: 777.8016967773438
      policy_loss: -0.603890597820282
      var_gnorm: 38.89888000488281
      vf_explained_var: -0.16831791400909424
      vf_loss: 7.319503492908552e-05
    num_steps_sampled: 13960000
    num_steps_trained: 13960000
    wait_time_ms: 541.278
  iterations_since_restore: 349
  node_ip: 172.17.8.24
  num_metric_batches_dropped: 0
  pid: 26970
  policy_reward_mean: {}
  time_since_restore: 19719.53698372841
  time_this_iter_s: 56.474608182907104
  time_total_s: 19719.53698372841
  timestamp: 1594204717
  timesteps_since_restore: 13960000
  timesteps_this_iter: 40000
  timesteps_total: 13960000
  training_iteration: 349
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26970], 19719 s, 349 iter, 13960000 ts, 449 rew

agent-1: 16.0
agent-2: 8.0
agent-3: 5.0
agent-4: 11.0
agent-5: 16.0
agent-6: 16.0
agent-7: 11.0
agent-8: 7.0
agent-9: 8.0
agent-10: 7.0
agent-11: 19.0
agent-12: 11.0
agent-13: 14.0
agent-14: 17.0
agent-15: 11.0
agent-16: 6.0
agent-17: 7.0
agent-18: 12.0
agent-19: 12.0
agent-20: 10.0
agent-21: 13.0
agent-22: 20.0
agent-23: 5.0
agent-24: 10.0
agent-25: 12.0
agent-26: 12.0
agent-27: 15.0
agent-28: 15.0
agent-29: 11.0
agent-30: 16.0
agent-31: 10.0
agent-32: 15.0
agent-33: 0.0
agent-34: 9.0
agent-35: 10.0
agent-36: 9.0
agent-37: 16.0
agent-38: 10.0
agent-39: 12.0
agent-40: 6.0
Sum Reward: 450.0
Avg Reward: 11.25
Min Reward: 0.0
Max Reward: 20.0
Gini Coefficient: 0.2068888888888889
20:20 Ratio: 3.1627906976744184
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-08_06-39-33
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 487.0
  episode_reward_mean: 448.5
  episode_reward_min: 392.0
  episodes_this_iter: 1
  episodes_total: 349
  experiment_id: 4e724eb5b3a34f42879644e84578eec0
  hostname: gpu024
  info:
    apply_time_ms: 2.438
    dispatch_time_ms: 5.867
    learner:
      cur_lr: 0.00043026398634538054
      grad_gnorm: 1.6475679874420166
      policy_entropy: 773.8676147460938
      policy_loss: 0.14090166985988617
      var_gnorm: 38.90100860595703
      vf_explained_var: -0.677556037902832
      vf_loss: 0.0028000259771943092
    num_steps_sampled: 14000000
    num_steps_trained: 14000000
    wait_time_ms: 547.427
  iterations_since_restore: 350
  node_ip: 172.17.8.24
  num_metric_batches_dropped: 0
  pid: 26970
  policy_reward_mean: {}
  time_since_restore: 19776.22102546692
  time_this_iter_s: 56.68404173851013
  time_total_s: 19776.22102546692
  timestamp: 1594204773
  timesteps_since_restore: 14000000
  timesteps_this_iter: 40000
  timesteps_total: 14000000
  training_iteration: 350
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26970], 19776 s, 350 iter, 14000000 ts, 448 rew

agent-1: 5.0
agent-2: 12.0
agent-3: 6.0
agent-4: 7.0
agent-5: 6.0
agent-6: 13.0
agent-7: 11.0
agent-8: 19.0
agent-9: 15.0
agent-10: 14.0
agent-11: 11.0
agent-12: 10.0
agent-13: 14.0
agent-14: 13.0
agent-15: 12.0
agent-16: 19.0
agent-17: 16.0
agent-18: 14.0
agent-19: 15.0
agent-20: 16.0
agent-21: 10.0
agent-22: 9.0
agent-23: 6.0
agent-24: 5.0
agent-25: 0.0
agent-26: 9.0
agent-27: 10.0
agent-28: 6.0
agent-29: 17.0
agent-30: 8.0
agent-31: 11.0
agent-32: 14.0
agent-33: 11.0
agent-34: 12.0
agent-35: 10.0
agent-36: 20.0
agent-37: 7.0
agent-38: 9.0
agent-39: 15.0
agent-40: 15.0
Sum Reward: 452.0
Avg Reward: 11.3
Min Reward: 0.0
Max Reward: 20.0
Gini Coefficient: 0.21648230088495576
20:20 Ratio: 3.341463414634146
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-08_06-40-30
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 487.0
  episode_reward_mean: 448.49
  episode_reward_min: 392.0
  episodes_this_iter: 1
  episodes_total: 350
  experiment_id: 4e724eb5b3a34f42879644e84578eec0
  hostname: gpu024
  info:
    apply_time_ms: 2.566
    dispatch_time_ms: 6.064
    learner:
      cur_lr: 0.0004275999963283539
      grad_gnorm: 40.0
      policy_entropy: 152.3533477783203
      policy_loss: 35.38536071777344
      var_gnorm: 38.89963912963867
      vf_explained_var: 0.3382960557937622
      vf_loss: 209.6722412109375
    num_steps_sampled: 14040000
    num_steps_trained: 14040000
    wait_time_ms: 512.724
  iterations_since_restore: 351
  node_ip: 172.17.8.24
  num_metric_batches_dropped: 0
  pid: 26970
  policy_reward_mean: {}
  time_since_restore: 19832.74801683426
  time_this_iter_s: 56.52699136734009
  time_total_s: 19832.74801683426
  timestamp: 1594204830
  timesteps_since_restore: 14040000
  timesteps_this_iter: 40000
  timesteps_total: 14040000
  training_iteration: 351
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26970], 19832 s, 351 iter, 14040000 ts, 448 rew

agent-1: 9.0
agent-2: 15.0
agent-3: 9.0
agent-4: 10.0
agent-5: 7.0
agent-6: 7.0
agent-7: 13.0
agent-8: 21.0
agent-9: 11.0
agent-10: 7.0
agent-11: 11.0
agent-12: 7.0
agent-13: 10.0
agent-14: 6.0
agent-15: 10.0
agent-16: 12.0
agent-17: 10.0
agent-18: 11.0
agent-19: 17.0
agent-20: 14.0
agent-21: 7.0
agent-22: 9.0
agent-23: 6.0
agent-24: 22.0
agent-25: 7.0
agent-26: 13.0
agent-27: 11.0
agent-28: 9.0
agent-29: 10.0
agent-30: 18.0
agent-31: 14.0
agent-32: 7.0
agent-33: 5.0
agent-34: 9.0
agent-35: 14.0
agent-36: 14.0
agent-37: 8.0
agent-38: 12.0
agent-39: 14.0
agent-40: 10.0
Sum Reward: 436.0
Avg Reward: 10.9
Min Reward: 5.0
Max Reward: 22.0
Gini Coefficient: 0.19438073394495411
20:20 Ratio: 2.5961538461538463
Max-min Ratio: 4.4
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-08_06-41-27
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 487.0
  episode_reward_mean: 448.38
  episode_reward_min: 392.0
  episodes_this_iter: 1
  episodes_total: 351
  experiment_id: 4e724eb5b3a34f42879644e84578eec0
  hostname: gpu024
  info:
    apply_time_ms: 2.526
    dispatch_time_ms: 5.966
    learner:
      cur_lr: 0.0004249360063113272
      grad_gnorm: 1.4280273914337158
      policy_entropy: 766.7838134765625
      policy_loss: 0.09263753145933151
      var_gnorm: 38.92946243286133
      vf_explained_var: -0.700160026550293
      vf_loss: 0.0008860973175615072
    num_steps_sampled: 14080000
    num_steps_trained: 14080000
    wait_time_ms: 554.804
  iterations_since_restore: 352
  node_ip: 172.17.8.24
  num_metric_batches_dropped: 0
  pid: 26970
  policy_reward_mean: {}
  time_since_restore: 19889.362647771835
  time_this_iter_s: 56.614630937576294
  time_total_s: 19889.362647771835
  timestamp: 1594204887
  timesteps_since_restore: 14080000
  timesteps_this_iter: 40000
  timesteps_total: 14080000
  training_iteration: 352
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26970], 19889 s, 352 iter, 14080000 ts, 448 rew

agent-1: 12.0
agent-2: 18.0
agent-3: 21.0
agent-4: 5.0
agent-5: 13.0
agent-6: 12.0
agent-7: 15.0
agent-8: 9.0
agent-9: 14.0
agent-10: 19.0
agent-11: 9.0
agent-12: 9.0
agent-13: 14.0
agent-14: 20.0
agent-15: 10.0
agent-16: 13.0
agent-17: 9.0
agent-18: 13.0
agent-19: 11.0
agent-20: 0.0
agent-21: 13.0
agent-22: 18.0
agent-23: 1.0
agent-24: 7.0
agent-25: 10.0
agent-26: 12.0
agent-27: 2.0
agent-28: 14.0
agent-29: 16.0
agent-30: 12.0
agent-31: 9.0
agent-32: 10.0
agent-33: 13.0
agent-34: 12.0
agent-35: 5.0
agent-36: 13.0
agent-37: 15.0
agent-38: 10.0
agent-39: 17.0
agent-40: 11.0
Sum Reward: 466.0
Avg Reward: 11.65
Min Reward: 0.0
Max Reward: 21.0
Gini Coefficient: 0.22199570815450645
20:20 Ratio: 3.789473684210526
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-08_06-42-23
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 487.0
  episode_reward_mean: 448.7
  episode_reward_min: 392.0
  episodes_this_iter: 1
  episodes_total: 352
  experiment_id: 4e724eb5b3a34f42879644e84578eec0
  hostname: gpu024
  info:
    apply_time_ms: 2.405
    dispatch_time_ms: 6.084
    learner:
      cur_lr: 0.0004222719871904701
      grad_gnorm: 1.333073616027832
      policy_entropy: 776.51416015625
      policy_loss: -0.09471747279167175
      var_gnorm: 38.92197036743164
      vf_explained_var: -1.0
      vf_loss: 0.00029554252978414297
    num_steps_sampled: 14120000
    num_steps_trained: 14120000
    wait_time_ms: 556.689
  iterations_since_restore: 353
  node_ip: 172.17.8.24
  num_metric_batches_dropped: 0
  pid: 26970
  policy_reward_mean: {}
  time_since_restore: 19945.70656991005
  time_this_iter_s: 56.34392213821411
  time_total_s: 19945.70656991005
  timestamp: 1594204943
  timesteps_since_restore: 14120000
  timesteps_this_iter: 40000
  timesteps_total: 14120000
  training_iteration: 353
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26970], 19945 s, 353 iter, 14120000 ts, 449 rew

agent-1: 11.0
agent-2: 13.0
agent-3: 8.0
agent-4: 19.0
agent-5: 17.0
agent-6: 11.0
agent-7: 12.0
agent-8: 16.0
agent-9: 14.0
agent-10: 10.0
agent-11: 12.0
agent-12: 10.0
agent-13: 8.0
agent-14: 17.0
agent-15: 10.0
agent-16: 15.0
agent-17: 4.0
agent-18: 14.0
agent-19: 12.0
agent-20: 8.0
agent-21: 19.0
agent-22: 16.0
agent-23: 10.0
agent-24: 8.0
agent-25: 0.0
agent-26: 13.0
agent-27: 11.0
agent-28: 16.0
agent-29: 3.0
agent-30: 12.0
agent-31: 7.0
agent-32: 11.0
agent-33: 8.0
agent-34: 14.0
agent-35: 12.0
agent-36: 18.0
agent-37: 2.0
agent-38: 7.0
agent-39: 17.0
agent-40: 15.0
Sum Reward: 460.0
Avg Reward: 11.5
Min Reward: 0.0
Max Reward: 19.0
Gini Coefficient: 0.22010869565217392
20:20 Ratio: 3.5641025641025643
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-08_06-43-19
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 487.0
  episode_reward_mean: 448.91
  episode_reward_min: 392.0
  episodes_this_iter: 1
  episodes_total: 353
  experiment_id: 4e724eb5b3a34f42879644e84578eec0
  hostname: gpu024
  info:
    apply_time_ms: 2.79
    dispatch_time_ms: 6.615
    learner:
      cur_lr: 0.00041960799717344344
      grad_gnorm: 0.5154659748077393
      policy_entropy: 777.1424560546875
      policy_loss: 0.2383449375629425
      var_gnorm: 38.95336151123047
      vf_explained_var: -1.0
      vf_loss: 0.00010567651770543307
    num_steps_sampled: 14160000
    num_steps_trained: 14160000
    wait_time_ms: 550.688
  iterations_since_restore: 354
  node_ip: 172.17.8.24
  num_metric_batches_dropped: 0
  pid: 26970
  policy_reward_mean: {}
  time_since_restore: 20001.942267656326
  time_this_iter_s: 56.235697746276855
  time_total_s: 20001.942267656326
  timestamp: 1594204999
  timesteps_since_restore: 14160000
  timesteps_this_iter: 40000
  timesteps_total: 14160000
  training_iteration: 354
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26970], 20001 s, 354 iter, 14160000 ts, 449 rew

agent-1: 9.0
agent-2: 14.0
agent-3: 12.0
agent-4: 12.0
agent-5: 11.0
agent-6: 4.0
agent-7: 10.0
agent-8: 15.0
agent-9: 13.0
agent-10: 15.0
agent-11: 12.0
agent-12: 17.0
agent-13: 11.0
agent-14: 15.0
agent-15: 17.0
agent-16: 15.0
agent-17: 16.0
agent-18: 20.0
agent-19: 3.0
agent-20: 4.0
agent-21: 12.0
agent-22: 22.0
agent-23: 13.0
agent-24: 2.0
agent-25: 16.0
agent-26: 12.0
agent-27: 4.0
agent-28: 14.0
agent-29: 16.0
agent-30: 12.0
agent-31: 16.0
agent-32: 7.0
agent-33: 13.0
agent-34: 14.0
agent-35: 13.0
agent-36: 8.0
agent-37: 7.0
agent-38: 10.0
agent-39: 6.0
agent-40: 6.0
Sum Reward: 468.0
Avg Reward: 11.7
Min Reward: 2.0
Max Reward: 22.0
Gini Coefficient: 0.22094017094017093
20:20 Ratio: 3.888888888888889
Max-min Ratio: 11.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-08_06-44-16
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 487.0
  episode_reward_mean: 448.91
  episode_reward_min: 392.0
  episodes_this_iter: 1
  episodes_total: 354
  experiment_id: 4e724eb5b3a34f42879644e84578eec0
  hostname: gpu024
  info:
    apply_time_ms: 3.485
    dispatch_time_ms: 7.832
    learner:
      cur_lr: 0.0004169440071564168
      grad_gnorm: 39.99999237060547
      policy_entropy: 31.324710845947266
      policy_loss: -6.885692119598389
      var_gnorm: 38.9528694152832
      vf_explained_var: -0.28607845306396484
      vf_loss: 704.9248046875
    num_steps_sampled: 14200000
    num_steps_trained: 14200000
    wait_time_ms: 520.84
  iterations_since_restore: 355
  node_ip: 172.17.8.24
  num_metric_batches_dropped: 0
  pid: 26970
  policy_reward_mean: {}
  time_since_restore: 20058.404888629913
  time_this_iter_s: 56.462620973587036
  time_total_s: 20058.404888629913
  timestamp: 1594205056
  timesteps_since_restore: 14200000
  timesteps_this_iter: 40000
  timesteps_total: 14200000
  training_iteration: 355
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26970], 20058 s, 355 iter, 14200000 ts, 449 rew

agent-1: 8.0
agent-2: 9.0
agent-3: 5.0
agent-4: 14.0
agent-5: 8.0
agent-6: 3.0
agent-7: 18.0
agent-8: 9.0
agent-9: 13.0
agent-10: 12.0
agent-11: 9.0
agent-12: 20.0
agent-13: 6.0
agent-14: 11.0
agent-15: 6.0
agent-16: 13.0
agent-17: 2.0
agent-18: 13.0
agent-19: 16.0
agent-20: 12.0
agent-21: 11.0
agent-22: 20.0
agent-23: 11.0
agent-24: 16.0
agent-25: 11.0
agent-26: 3.0
agent-27: 15.0
agent-28: 15.0
agent-29: 11.0
agent-30: 2.0
agent-31: 12.0
agent-32: 9.0
agent-33: 12.0
agent-34: 15.0
agent-35: 16.0
agent-36: 10.0
agent-37: 17.0
agent-38: 10.0
agent-39: 16.0
agent-40: 11.0
Sum Reward: 450.0
Avg Reward: 11.25
Min Reward: 2.0
Max Reward: 20.0
Gini Coefficient: 0.22766666666666666
20:20 Ratio: 3.9714285714285715
Max-min Ratio: 10.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-08_06-45-12
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 487.0
  episode_reward_mean: 448.98
  episode_reward_min: 392.0
  episodes_this_iter: 1
  episodes_total: 355
  experiment_id: 4e724eb5b3a34f42879644e84578eec0
  hostname: gpu024
  info:
    apply_time_ms: 2.812
    dispatch_time_ms: 6.962
    learner:
      cur_lr: 0.00041427998803555965
      grad_gnorm: 0.4185120463371277
      policy_entropy: 776.83447265625
      policy_loss: -0.2872457206249237
      var_gnorm: 38.972023010253906
      vf_explained_var: -1.0
      vf_loss: 0.0005840722587890923
    num_steps_sampled: 14240000
    num_steps_trained: 14240000
    wait_time_ms: 563.465
  iterations_since_restore: 356
  node_ip: 172.17.8.24
  num_metric_batches_dropped: 0
  pid: 26970
  policy_reward_mean: {}
  time_since_restore: 20114.82743358612
  time_this_iter_s: 56.422544956207275
  time_total_s: 20114.82743358612
  timestamp: 1594205112
  timesteps_since_restore: 14240000
  timesteps_this_iter: 40000
  timesteps_total: 14240000
  training_iteration: 356
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26970], 20114 s, 356 iter, 14240000 ts, 449 rew

agent-1: 5.0
agent-2: 15.0
agent-3: 6.0
agent-4: 12.0
agent-5: 14.0
agent-6: 6.0
agent-7: 11.0
agent-8: 7.0
agent-9: 13.0
agent-10: 16.0
agent-11: 13.0
agent-12: 15.0
agent-13: 12.0
agent-14: 9.0
agent-15: 14.0
agent-16: 13.0
agent-17: 12.0
agent-18: 15.0
agent-19: 10.0
agent-20: 17.0
agent-21: 5.0
agent-22: 6.0
agent-23: 13.0
agent-24: 7.0
agent-25: 10.0
agent-26: 10.0
agent-27: 11.0
agent-28: 16.0
agent-29: 9.0
agent-30: 15.0
agent-31: 15.0
agent-32: 15.0
agent-33: 7.0
agent-34: 5.0
agent-35: 13.0
agent-36: 14.0
agent-37: 14.0
agent-38: 0.0
agent-39: 9.0
agent-40: 10.0
Sum Reward: 439.0
Avg Reward: 10.975
Min Reward: 0.0
Max Reward: 17.0
Gini Coefficient: 0.1985763097949886
20:20 Ratio: 3.1
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-08_06-46-09
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 487.0
  episode_reward_mean: 448.71
  episode_reward_min: 392.0
  episodes_this_iter: 1
  episodes_total: 356
  experiment_id: 4e724eb5b3a34f42879644e84578eec0
  hostname: gpu024
  info:
    apply_time_ms: 2.909
    dispatch_time_ms: 6.507
    learner:
      cur_lr: 0.000411615998018533
      grad_gnorm: 39.999996185302734
      policy_entropy: 34.727577209472656
      policy_loss: 7.383319854736328
      var_gnorm: 38.974937438964844
      vf_explained_var: 0.3727591633796692
      vf_loss: 342.5162353515625
    num_steps_sampled: 14280000
    num_steps_trained: 14280000
    wait_time_ms: 519.631
  iterations_since_restore: 357
  node_ip: 172.17.8.24
  num_metric_batches_dropped: 0
  pid: 26970
  policy_reward_mean: {}
  time_since_restore: 20171.724722862244
  time_this_iter_s: 56.89728927612305
  time_total_s: 20171.724722862244
  timestamp: 1594205169
  timesteps_since_restore: 14280000
  timesteps_this_iter: 40000
  timesteps_total: 14280000
  training_iteration: 357
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26970], 20171 s, 357 iter, 14280000 ts, 449 rew

agent-1: 15.0
agent-2: 0.0
agent-3: 14.0
agent-4: 14.0
agent-5: 11.0
agent-6: 4.0
agent-7: 12.0
agent-8: 6.0
agent-9: 18.0
agent-10: 7.0
agent-11: 12.0
agent-12: 24.0
agent-13: 11.0
agent-14: 5.0
agent-15: 5.0
agent-16: 7.0
agent-17: 7.0
agent-18: 14.0
agent-19: 13.0
agent-20: 12.0
agent-21: 8.0
agent-22: 8.0
agent-23: 13.0
agent-24: 12.0
agent-25: 9.0
agent-26: 14.0
agent-27: 14.0
agent-28: 10.0
agent-29: 14.0
agent-30: 10.0
agent-31: 15.0
agent-32: 13.0
agent-33: 7.0
agent-34: 14.0
agent-35: 14.0
agent-36: 10.0
agent-37: 4.0
agent-38: 10.0
agent-39: 6.0
agent-40: 12.0
Sum Reward: 428.0
Avg Reward: 10.7
Min Reward: 0.0
Max Reward: 24.0
Gini Coefficient: 0.22313084112149534
20:20 Ratio: 3.4594594594594597
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-08_06-47-06
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 487.0
  episode_reward_mean: 448.6
  episode_reward_min: 392.0
  episodes_this_iter: 1
  episodes_total: 357
  experiment_id: 4e724eb5b3a34f42879644e84578eec0
  hostname: gpu024
  info:
    apply_time_ms: 2.853
    dispatch_time_ms: 6.248
    learner:
      cur_lr: 0.00040895200800150633
      grad_gnorm: 0.9067869186401367
      policy_entropy: 774.252685546875
      policy_loss: -0.5202479362487793
      var_gnorm: 39.00025177001953
      vf_explained_var: -1.0
      vf_loss: 0.00021098929573781788
    num_steps_sampled: 14320000
    num_steps_trained: 14320000
    wait_time_ms: 540.347
  iterations_since_restore: 358
  node_ip: 172.17.8.24
  num_metric_batches_dropped: 0
  pid: 26970
  policy_reward_mean: {}
  time_since_restore: 20228.097653865814
  time_this_iter_s: 56.37293100357056
  time_total_s: 20228.097653865814
  timestamp: 1594205226
  timesteps_since_restore: 14320000
  timesteps_this_iter: 40000
  timesteps_total: 14320000
  training_iteration: 358
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26970], 20228 s, 358 iter, 14320000 ts, 449 rew

agent-1: 11.0
agent-2: 11.0
agent-3: 10.0
agent-4: 9.0
agent-5: 17.0
agent-6: 13.0
agent-7: 21.0
agent-8: 12.0
agent-9: 8.0
agent-10: 15.0
agent-11: 17.0
agent-12: 16.0
agent-13: 12.0
agent-14: 13.0
agent-15: 18.0
agent-16: 9.0
agent-17: 8.0
agent-18: 12.0
agent-19: 9.0
agent-20: 16.0
agent-21: 14.0
agent-22: 4.0
agent-23: 12.0
agent-24: 1.0
agent-25: 11.0
agent-26: 9.0
agent-27: 15.0
agent-28: 10.0
agent-29: 10.0
agent-30: 14.0
agent-31: 8.0
agent-32: 17.0
agent-33: 8.0
agent-34: 0.0
agent-35: 1.0
agent-36: 11.0
agent-37: 8.0
agent-38: 14.0
agent-39: 10.0
agent-40: 12.0
Sum Reward: 446.0
Avg Reward: 11.15
Min Reward: 0.0
Max Reward: 21.0
Gini Coefficient: 0.2211883408071749
20:20 Ratio: 3.6052631578947367
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-08_06-48-02
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 487.0
  episode_reward_mean: 448.83
  episode_reward_min: 392.0
  episodes_this_iter: 1
  episodes_total: 358
  experiment_id: 4e724eb5b3a34f42879644e84578eec0
  hostname: gpu024
  info:
    apply_time_ms: 2.523
    dispatch_time_ms: 5.609
    learner:
      cur_lr: 0.0004062879888806492
      grad_gnorm: 40.0
      policy_entropy: 41.512840270996094
      policy_loss: -10.991025924682617
      var_gnorm: 38.99899673461914
      vf_explained_var: 0.29776430130004883
      vf_loss: 454.17962646484375
    num_steps_sampled: 14360000
    num_steps_trained: 14360000
    wait_time_ms: 539.839
  iterations_since_restore: 359
  node_ip: 172.17.8.24
  num_metric_batches_dropped: 0
  pid: 26970
  policy_reward_mean: {}
  time_since_restore: 20284.82185602188
  time_this_iter_s: 56.724202156066895
  time_total_s: 20284.82185602188
  timestamp: 1594205282
  timesteps_since_restore: 14360000
  timesteps_this_iter: 40000
  timesteps_total: 14360000
  training_iteration: 359
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26970], 20284 s, 359 iter, 14360000 ts, 449 rew

agent-1: 13.0
agent-2: 5.0
agent-3: 8.0
agent-4: 6.0
agent-5: 5.0
agent-6: 13.0
agent-7: 18.0
agent-8: 13.0
agent-9: 4.0
agent-10: 2.0
agent-11: 13.0
agent-12: 15.0
agent-13: 14.0
agent-14: 11.0
agent-15: 17.0
agent-16: 14.0
agent-17: 11.0
agent-18: 9.0
agent-19: 11.0
agent-20: 10.0
agent-21: 13.0
agent-22: 9.0
agent-23: 15.0
agent-24: 10.0
agent-25: 9.0
agent-26: 5.0
agent-27: 14.0
agent-28: 9.0
agent-29: 14.0
agent-30: 8.0
agent-31: 16.0
agent-32: 16.0
agent-33: 13.0
agent-34: 10.0
agent-35: 17.0
agent-36: 16.0
agent-37: 7.0
agent-38: 13.0
agent-39: 9.0
agent-40: 1.0
Sum Reward: 436.0
Avg Reward: 10.9
Min Reward: 1.0
Max Reward: 18.0
Gini Coefficient: 0.21834862385321102
20:20 Ratio: 3.7142857142857144
Max-min Ratio: 18.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-08_06-48-59
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 487.0
  episode_reward_mean: 448.78
  episode_reward_min: 392.0
  episodes_this_iter: 1
  episodes_total: 359
  experiment_id: 4e724eb5b3a34f42879644e84578eec0
  hostname: gpu024
  info:
    apply_time_ms: 2.54
    dispatch_time_ms: 6.023
    learner:
      cur_lr: 0.00040362399886362255
      grad_gnorm: 0.7038870453834534
      policy_entropy: 775.427978515625
      policy_loss: 0.6477245092391968
      var_gnorm: 39.027626037597656
      vf_explained_var: -0.012709379196166992
      vf_loss: 7.249144255183637e-05
    num_steps_sampled: 14400000
    num_steps_trained: 14400000
    wait_time_ms: 557.21
  iterations_since_restore: 360
  node_ip: 172.17.8.24
  num_metric_batches_dropped: 0
  pid: 26970
  policy_reward_mean: {}
  time_since_restore: 20340.945093154907
  time_this_iter_s: 56.12323713302612
  time_total_s: 20340.945093154907
  timestamp: 1594205339
  timesteps_since_restore: 14400000
  timesteps_this_iter: 40000
  timesteps_total: 14400000
  training_iteration: 360
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26970], 20340 s, 360 iter, 14400000 ts, 449 rew

agent-1: 15.0
agent-2: 11.0
agent-3: 8.0
agent-4: 6.0
agent-5: 0.0
agent-6: 14.0
agent-7: 18.0
agent-8: 9.0
agent-9: 12.0
agent-10: 12.0
agent-11: 8.0
agent-12: 8.0
agent-13: 13.0
agent-14: 1.0
agent-15: 12.0
agent-16: 12.0
agent-17: 11.0
agent-18: 16.0
agent-19: 18.0
agent-20: 18.0
agent-21: 9.0
agent-22: 13.0
agent-23: 10.0
agent-24: 9.0
agent-25: 11.0
agent-26: 6.0
agent-27: 11.0
agent-28: 9.0
agent-29: 19.0
agent-30: 9.0
agent-31: 11.0
agent-32: 8.0
agent-33: 9.0
agent-34: 6.0
agent-35: 12.0
agent-36: 8.0
agent-37: 12.0
agent-38: 8.0
agent-39: 5.0
agent-40: 14.0
Sum Reward: 421.0
Avg Reward: 10.525
Min Reward: 0.0
Max Reward: 19.0
Gini Coefficient: 0.21609263657957245
20:20 Ratio: 3.3
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-08_06-49-55
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 487.0
  episode_reward_mean: 448.45
  episode_reward_min: 392.0
  episodes_this_iter: 1
  episodes_total: 360
  experiment_id: 4e724eb5b3a34f42879644e84578eec0
  hostname: gpu024
  info:
    apply_time_ms: 2.718
    dispatch_time_ms: 5.218
    learner:
      cur_lr: 0.0004009600088465959
      grad_gnorm: 0.2796785533428192
      policy_entropy: 777.8811645507812
      policy_loss: 0.12442497909069061
      var_gnorm: 39.02588653564453
      vf_explained_var: -0.04857611656188965
      vf_loss: 9.023358870763332e-06
    num_steps_sampled: 14440000
    num_steps_trained: 14440000
    wait_time_ms: 558.546
  iterations_since_restore: 361
  node_ip: 172.17.8.24
  num_metric_batches_dropped: 0
  pid: 26970
  policy_reward_mean: {}
  time_since_restore: 20397.5898706913
  time_this_iter_s: 56.64477753639221
  time_total_s: 20397.5898706913
  timestamp: 1594205395
  timesteps_since_restore: 14440000
  timesteps_this_iter: 40000
  timesteps_total: 14440000
  training_iteration: 361
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26970], 20397 s, 361 iter, 14440000 ts, 448 rew

agent-1: 7.0
agent-2: 13.0
agent-3: 10.0
agent-4: 15.0
agent-5: 11.0
agent-6: 9.0
agent-7: 10.0
agent-8: 15.0
agent-9: 9.0
agent-10: 6.0
agent-11: 15.0
agent-12: 10.0
agent-13: 6.0
agent-14: 13.0
agent-15: 18.0
agent-16: 4.0
agent-17: 16.0
agent-18: 16.0
agent-19: 19.0
agent-20: 16.0
agent-21: 14.0
agent-22: 13.0
agent-23: 10.0
agent-24: 10.0
agent-25: 9.0
agent-26: 11.0
agent-27: 4.0
agent-28: 5.0
agent-29: 11.0
agent-30: 9.0
agent-31: 17.0
agent-32: 11.0
agent-33: 15.0
agent-34: 4.0
agent-35: 16.0
agent-36: 10.0
agent-37: 8.0
agent-38: 10.0
agent-39: 15.0
agent-40: 11.0
Sum Reward: 451.0
Avg Reward: 11.275
Min Reward: 4.0
Max Reward: 19.0
Gini Coefficient: 0.19916851441241684
20:20 Ratio: 3.022727272727273
Max-min Ratio: 4.75
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-08_06-50-52
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 487.0
  episode_reward_mean: 448.46
  episode_reward_min: 392.0
  episodes_this_iter: 1
  episodes_total: 361
  experiment_id: 4e724eb5b3a34f42879644e84578eec0
  hostname: gpu024
  info:
    apply_time_ms: 2.969
    dispatch_time_ms: 5.725
    learner:
      cur_lr: 0.00039829598972573876
      grad_gnorm: 0.4947335422039032
      policy_entropy: 772.2744750976562
      policy_loss: -0.27413439750671387
      var_gnorm: 39.05144119262695
      vf_explained_var: -0.5104920864105225
      vf_loss: 6.290891906246543e-05
    num_steps_sampled: 14480000
    num_steps_trained: 14480000
    wait_time_ms: 558.375
  iterations_since_restore: 362
  node_ip: 172.17.8.24
  num_metric_batches_dropped: 0
  pid: 26970
  policy_reward_mean: {}
  time_since_restore: 20454.298080682755
  time_this_iter_s: 56.70820999145508
  time_total_s: 20454.298080682755
  timestamp: 1594205452
  timesteps_since_restore: 14480000
  timesteps_this_iter: 40000
  timesteps_total: 14480000
  training_iteration: 362
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26970], 20454 s, 362 iter, 14480000 ts, 448 rew

agent-1: 14.0
agent-2: 5.0
agent-3: 12.0
agent-4: 7.0
agent-5: 19.0
agent-6: 16.0
agent-7: 13.0
agent-8: 14.0
agent-9: 13.0
agent-10: 13.0
agent-11: 11.0
agent-12: 14.0
agent-13: 11.0
agent-14: 6.0
agent-15: 18.0
agent-16: 11.0
agent-17: 3.0
agent-18: 12.0
agent-19: 12.0
agent-20: 8.0
agent-21: 10.0
agent-22: 16.0
agent-23: 3.0
agent-24: 11.0
agent-25: 12.0
agent-26: 9.0
agent-27: 12.0
agent-28: 13.0
agent-29: 13.0
agent-30: 9.0
agent-31: 8.0
agent-32: 8.0
agent-33: 14.0
agent-34: 12.0
agent-35: 11.0
agent-36: 11.0
agent-37: 14.0
agent-38: 4.0
agent-39: 13.0
agent-40: 18.0
Sum Reward: 453.0
Avg Reward: 11.325
Min Reward: 3.0
Max Reward: 19.0
Gini Coefficient: 0.18405077262693156
20:20 Ratio: 2.9318181818181817
Max-min Ratio: 6.333333333333333
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-08_06-51-48
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 487.0
  episode_reward_mean: 448.64
  episode_reward_min: 392.0
  episodes_this_iter: 1
  episodes_total: 362
  experiment_id: 4e724eb5b3a34f42879644e84578eec0
  hostname: gpu024
  info:
    apply_time_ms: 2.796
    dispatch_time_ms: 6.002
    learner:
      cur_lr: 0.0003956319997087121
      grad_gnorm: 0.050412967801094055
      policy_entropy: 776.9403076171875
      policy_loss: 0.015149913728237152
      var_gnorm: 39.05169677734375
      vf_explained_var: -1.0
      vf_loss: 1.643754785618512e-07
    num_steps_sampled: 14520000
    num_steps_trained: 14520000
    wait_time_ms: 562.324
  iterations_since_restore: 363
  node_ip: 172.17.8.24
  num_metric_batches_dropped: 0
  pid: 26970
  policy_reward_mean: {}
  time_since_restore: 20510.80359506607
  time_this_iter_s: 56.50551438331604
  time_total_s: 20510.80359506607
  timestamp: 1594205508
  timesteps_since_restore: 14520000
  timesteps_this_iter: 40000
  timesteps_total: 14520000
  training_iteration: 363
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26970], 20510 s, 363 iter, 14520000 ts, 449 rew

agent-1: 10.0
agent-2: 12.0
agent-3: 7.0
agent-4: 7.0
agent-5: 11.0
agent-6: 12.0
agent-7: 14.0
agent-8: 17.0
agent-9: 16.0
agent-10: 9.0
agent-11: 10.0
agent-12: 7.0
agent-13: 11.0
agent-14: 8.0
agent-15: 14.0
agent-16: 13.0
agent-17: 6.0
agent-18: 10.0
agent-19: 8.0
agent-20: 5.0
agent-21: 12.0
agent-22: 15.0
agent-23: 9.0
agent-24: 13.0
agent-25: 11.0
agent-26: 11.0
agent-27: 12.0
agent-28: 12.0
agent-29: 13.0
agent-30: 14.0
agent-31: 9.0
agent-32: 14.0
agent-33: 14.0
agent-34: 10.0
agent-35: 9.0
agent-36: 12.0
agent-37: 12.0
agent-38: 16.0
agent-39: 14.0
agent-40: 14.0
Sum Reward: 453.0
Avg Reward: 11.325
Min Reward: 5.0
Max Reward: 17.0
Gini Coefficient: 0.14299116997792494
20:20 Ratio: 2.1052631578947367
Max-min Ratio: 3.4
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-08_06-52-45
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 487.0
  episode_reward_mean: 448.77
  episode_reward_min: 392.0
  episodes_this_iter: 1
  episodes_total: 363
  experiment_id: 4e724eb5b3a34f42879644e84578eec0
  hostname: gpu024
  info:
    apply_time_ms: 4.064
    dispatch_time_ms: 7.391
    learner:
      cur_lr: 0.00039296800969168544
      grad_gnorm: 0.3169769048690796
      policy_entropy: 771.4766845703125
      policy_loss: -0.2926860451698303
      var_gnorm: 39.02900695800781
      vf_explained_var: -0.5574082136154175
      vf_loss: 2.4856406525941566e-05
    num_steps_sampled: 14560000
    num_steps_trained: 14560000
    wait_time_ms: 555.669
  iterations_since_restore: 364
  node_ip: 172.17.8.24
  num_metric_batches_dropped: 0
  pid: 26970
  policy_reward_mean: {}
  time_since_restore: 20566.90351676941
  time_this_iter_s: 56.09992170333862
  time_total_s: 20566.90351676941
  timestamp: 1594205565
  timesteps_since_restore: 14560000
  timesteps_this_iter: 40000
  timesteps_total: 14560000
  training_iteration: 364
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26970], 20566 s, 364 iter, 14560000 ts, 449 rew

agent-1: 5.0
agent-2: 17.0
agent-3: 12.0
agent-4: 7.0
agent-5: 13.0
agent-6: 9.0
agent-7: 11.0
agent-8: 18.0
agent-9: 16.0
agent-10: 12.0
agent-11: 4.0
agent-12: 9.0
agent-13: 13.0
agent-14: 11.0
agent-15: 11.0
agent-16: 15.0
agent-17: 16.0
agent-18: 11.0
agent-19: 12.0
agent-20: 10.0
agent-21: 4.0
agent-22: 16.0
agent-23: 8.0
agent-24: 10.0
agent-25: 10.0
agent-26: 9.0
agent-27: 6.0
agent-28: 5.0
agent-29: 9.0
agent-30: 18.0
agent-31: 12.0
agent-32: 11.0
agent-33: 13.0
agent-34: 20.0
agent-35: 6.0
agent-36: 6.0
agent-37: 13.0
agent-38: 10.0
agent-39: 13.0
agent-40: 13.0
Sum Reward: 444.0
Avg Reward: 11.1
Min Reward: 4.0
Max Reward: 20.0
Gini Coefficient: 0.20067567567567568
20:20 Ratio: 3.1627906976744184
Max-min Ratio: 5.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-08_06-53-42
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 487.0
  episode_reward_mean: 448.84
  episode_reward_min: 392.0
  episodes_this_iter: 1
  episodes_total: 364
  experiment_id: 4e724eb5b3a34f42879644e84578eec0
  hostname: gpu024
  info:
    apply_time_ms: 2.89
    dispatch_time_ms: 5.492
    learner:
      cur_lr: 0.0003903039905708283
      grad_gnorm: 0.14836779236793518
      policy_entropy: 776.372802734375
      policy_loss: 0.007925668731331825
      var_gnorm: 39.02947998046875
      vf_explained_var: -1.0
      vf_loss: 0.000231374564464204
    num_steps_sampled: 14600000
    num_steps_trained: 14600000
    wait_time_ms: 546.728
  iterations_since_restore: 365
  node_ip: 172.17.8.24
  num_metric_batches_dropped: 0
  pid: 26970
  policy_reward_mean: {}
  time_since_restore: 20623.723017454147
  time_this_iter_s: 56.81950068473816
  time_total_s: 20623.723017454147
  timestamp: 1594205622
  timesteps_since_restore: 14600000
  timesteps_this_iter: 40000
  timesteps_total: 14600000
  training_iteration: 365
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26970], 20623 s, 365 iter, 14600000 ts, 449 rew

agent-1: 9.0
agent-2: 17.0
agent-3: 9.0
agent-4: 10.0
agent-5: 13.0
agent-6: 14.0
agent-7: 7.0
agent-8: 13.0
agent-9: 12.0
agent-10: 8.0
agent-11: 8.0
agent-12: 8.0
agent-13: 11.0
agent-14: 10.0
agent-15: 13.0
agent-16: 14.0
agent-17: 13.0
agent-18: 8.0
agent-19: 10.0
agent-20: 9.0
agent-21: 10.0
agent-22: 9.0
agent-23: 13.0
agent-24: 12.0
agent-25: 9.0
agent-26: 11.0
agent-27: 6.0
agent-28: 12.0
agent-29: 16.0
agent-30: 12.0
agent-31: 18.0
agent-32: 16.0
agent-33: 13.0
agent-34: 13.0
agent-35: 2.0
agent-36: 10.0
agent-37: 10.0
agent-38: 14.0
agent-39: 6.0
agent-40: 9.0
Sum Reward: 437.0
Avg Reward: 10.925
Min Reward: 2.0
Max Reward: 18.0
Gini Coefficient: 0.1616132723112128
20:20 Ratio: 2.30188679245283
Max-min Ratio: 9.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-08_06-54-38
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 487.0
  episode_reward_mean: 448.81
  episode_reward_min: 392.0
  episodes_this_iter: 1
  episodes_total: 365
  experiment_id: 4e724eb5b3a34f42879644e84578eec0
  hostname: gpu024
  info:
    apply_time_ms: 2.735
    dispatch_time_ms: 5.825
    learner:
      cur_lr: 0.00038764000055380166
      grad_gnorm: 0.6800575852394104
      policy_entropy: 774.8558959960938
      policy_loss: -0.753631591796875
      var_gnorm: 39.03957748413086
      vf_explained_var: -1.0
      vf_loss: 0.0010383430635556579
    num_steps_sampled: 14640000
    num_steps_trained: 14640000
    wait_time_ms: 555.684
  iterations_since_restore: 366
  node_ip: 172.17.8.24
  num_metric_batches_dropped: 0
  pid: 26970
  policy_reward_mean: {}
  time_since_restore: 20680.23100376129
  time_this_iter_s: 56.507986307144165
  time_total_s: 20680.23100376129
  timestamp: 1594205678
  timesteps_since_restore: 14640000
  timesteps_this_iter: 40000
  timesteps_total: 14640000
  training_iteration: 366
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26970], 20680 s, 366 iter, 14640000 ts, 449 rew

agent-1: 9.0
agent-2: 14.0
agent-3: 18.0
agent-4: 11.0
agent-5: 16.0
agent-6: 10.0
agent-7: 8.0
agent-8: 7.0
agent-9: 9.0
agent-10: 6.0
agent-11: 13.0
agent-12: 10.0
agent-13: 13.0
agent-14: 12.0
agent-15: 11.0
agent-16: 10.0
agent-17: 17.0
agent-18: 6.0
agent-19: 13.0
agent-20: 10.0
agent-21: 14.0
agent-22: 12.0
agent-23: 12.0
agent-24: 8.0
agent-25: 10.0
agent-26: 15.0
agent-27: 12.0
agent-28: 13.0
agent-29: 10.0
agent-30: 12.0
agent-31: 11.0
agent-32: 9.0
agent-33: 13.0
agent-34: 12.0
agent-35: 9.0
agent-36: 13.0
agent-37: 12.0
agent-38: 13.0
agent-39: 16.0
agent-40: 16.0
Sum Reward: 465.0
Avg Reward: 11.625
Min Reward: 6.0
Max Reward: 18.0
Gini Coefficient: 0.13639784946236558
20:20 Ratio: 2.032258064516129
Max-min Ratio: 3.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-08_06-55-35
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 487.0
  episode_reward_mean: 448.99
  episode_reward_min: 392.0
  episodes_this_iter: 1
  episodes_total: 366
  experiment_id: 4e724eb5b3a34f42879644e84578eec0
  hostname: gpu024
  info:
    apply_time_ms: 3.909
    dispatch_time_ms: 5.916
    learner:
      cur_lr: 0.000384976010536775
      grad_gnorm: 40.000003814697266
      policy_entropy: 40.00164031982422
      policy_loss: 11.359909057617188
      var_gnorm: 39.03916931152344
      vf_explained_var: 0.5309922695159912
      vf_loss: 584.7083740234375
    num_steps_sampled: 14680000
    num_steps_trained: 14680000
    wait_time_ms: 541.769
  iterations_since_restore: 367
  node_ip: 172.17.8.24
  num_metric_batches_dropped: 0
  pid: 26970
  policy_reward_mean: {}
  time_since_restore: 20736.892775535583
  time_this_iter_s: 56.66177177429199
  time_total_s: 20736.892775535583
  timestamp: 1594205735
  timesteps_since_restore: 14680000
  timesteps_this_iter: 40000
  timesteps_total: 14680000
  training_iteration: 367
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26970], 20736 s, 367 iter, 14680000 ts, 449 rew

agent-1: 12.0
agent-2: 13.0
agent-3: 10.0
agent-4: 9.0
agent-5: 17.0
agent-6: 10.0
agent-7: 2.0
agent-8: 10.0
agent-9: 13.0
agent-10: 12.0
agent-11: 8.0
agent-12: 3.0
agent-13: 6.0
agent-14: 12.0
agent-15: 9.0
agent-16: 9.0
agent-17: 12.0
agent-18: 12.0
agent-19: 5.0
agent-20: 7.0
agent-21: 14.0
agent-22: 12.0
agent-23: 12.0
agent-24: 16.0
agent-25: 7.0
agent-26: 12.0
agent-27: 11.0
agent-28: 12.0
agent-29: 12.0
agent-30: 6.0
agent-31: 6.0
agent-32: 14.0
agent-33: 8.0
agent-34: 8.0
agent-35: 12.0
agent-36: 11.0
agent-37: 13.0
agent-38: 21.0
agent-39: 13.0
agent-40: 14.0
Sum Reward: 425.0
Avg Reward: 10.625
Min Reward: 2.0
Max Reward: 21.0
Gini Coefficient: 0.1878235294117647
20:20 Ratio: 2.9047619047619047
Max-min Ratio: 10.5
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-08_06-56-32
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 487.0
  episode_reward_mean: 448.74
  episode_reward_min: 392.0
  episodes_this_iter: 1
  episodes_total: 367
  experiment_id: 4e724eb5b3a34f42879644e84578eec0
  hostname: gpu024
  info:
    apply_time_ms: 2.585
    dispatch_time_ms: 6.129
    learner:
      cur_lr: 0.0003823119914159179
      grad_gnorm: 0.3085917830467224
      policy_entropy: 775.930419921875
      policy_loss: 0.19693268835544586
      var_gnorm: 39.08784484863281
      vf_explained_var: -1.0
      vf_loss: 1.69262639246881e-05
    num_steps_sampled: 14720000
    num_steps_trained: 14720000
    wait_time_ms: 555.886
  iterations_since_restore: 368
  node_ip: 172.17.8.24
  num_metric_batches_dropped: 0
  pid: 26970
  policy_reward_mean: {}
  time_since_restore: 20793.617235660553
  time_this_iter_s: 56.72446012496948
  time_total_s: 20793.617235660553
  timestamp: 1594205792
  timesteps_since_restore: 14720000
  timesteps_this_iter: 40000
  timesteps_total: 14720000
  training_iteration: 368
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26970], 20793 s, 368 iter, 14720000 ts, 449 rew

agent-1: 15.0
agent-2: 4.0
agent-3: 12.0
agent-4: 12.0
agent-5: 10.0
agent-6: 16.0
agent-7: 14.0
agent-8: 13.0
agent-9: 20.0
agent-10: 8.0
agent-11: 1.0
agent-12: 16.0
agent-13: 9.0
agent-14: 9.0
agent-15: 15.0
agent-16: 13.0
agent-17: 9.0
agent-18: 7.0
agent-19: 10.0
agent-20: 11.0
agent-21: 7.0
agent-22: 8.0
agent-23: 12.0
agent-24: 13.0
agent-25: 10.0
agent-26: 6.0
agent-27: 9.0
agent-28: 14.0
agent-29: 13.0
agent-30: 10.0
agent-31: 6.0
agent-32: 13.0
agent-33: 11.0
agent-34: 13.0
agent-35: 7.0
agent-36: 16.0
agent-37: 13.0
agent-38: 11.0
agent-39: 9.0
agent-40: 17.0
Sum Reward: 442.0
Avg Reward: 11.05
Min Reward: 1.0
Max Reward: 20.0
Gini Coefficient: 0.18914027149321266
20:20 Ratio: 2.8043478260869565
Max-min Ratio: 20.0
agent-1: 7.0
agent-2: 9.0
agent-3: 8.0
agent-4: 15.0
agent-5: 9.0
agent-6: 13.0
agent-7: 9.0
agent-8: 12.0
agent-9: 8.0
agent-10: 12.0
agent-11: 5.0
agent-12: 15.0
agent-13: 4.0
agent-14: 11.0
agent-15: 11.0
agent-16: 17.0
agent-17: 9.0
agent-18: 12.0
agent-19: 10.0
agent-20: 11.0
agent-21: 8.0
agent-22: 16.0
agent-23: 6.0
agent-24: 8.0
agent-25: 14.0
agent-26: 13.0
agent-27: 10.0
agent-28: 10.0
agent-29: 14.0
agent-30: 9.0
agent-31: 13.0
agent-32: 18.0
agent-33: 6.0
agent-34: 12.0
agent-35: 13.0
agent-36: 13.0
agent-37: 12.0
agent-38: 2.0
agent-39: 18.0
agent-40: 9.0
Sum Reward: 431.0
Avg Reward: 10.775
Min Reward: 2.0
Max Reward: 18.0
Gini Coefficient: 0.18938515081206497
20:20 Ratio: 2.760869565217391
Max-min Ratio: 9.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-08_06-57-28
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 487.0
  episode_reward_mean: 448.56
  episode_reward_min: 392.0
  episodes_this_iter: 2
  episodes_total: 369
  experiment_id: 4e724eb5b3a34f42879644e84578eec0
  hostname: gpu024
  info:
    apply_time_ms: 4.176
    dispatch_time_ms: 5.824
    learner:
      cur_lr: 0.0003796480013988912
      grad_gnorm: 0.6427894830703735
      policy_entropy: 777.3585205078125
      policy_loss: -0.32859206199645996
      var_gnorm: 39.08787536621094
      vf_explained_var: -1.0
      vf_loss: 7.818992889951915e-05
    num_steps_sampled: 14760000
    num_steps_trained: 14760000
    wait_time_ms: 537.516
  iterations_since_restore: 369
  node_ip: 172.17.8.24
  num_metric_batches_dropped: 0
  pid: 26970
  policy_reward_mean: {}
  time_since_restore: 20849.982250213623
  time_this_iter_s: 56.36501455307007
  time_total_s: 20849.982250213623
  timestamp: 1594205848
  timesteps_since_restore: 14760000
  timesteps_this_iter: 40000
  timesteps_total: 14760000
  training_iteration: 369
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26970], 20849 s, 369 iter, 14760000 ts, 449 rew

Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-08_06-58-24
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 487.0
  episode_reward_mean: 448.56
  episode_reward_min: 392.0
  episodes_this_iter: 0
  episodes_total: 369
  experiment_id: 4e724eb5b3a34f42879644e84578eec0
  hostname: gpu024
  info:
    apply_time_ms: 2.47
    dispatch_time_ms: 5.938
    learner:
      cur_lr: 0.00037698401138186455
      grad_gnorm: 0.17514753341674805
      policy_entropy: 775.374267578125
      policy_loss: -0.11048614233732224
      var_gnorm: 39.0925178527832
      vf_explained_var: -1.0
      vf_loss: 0.00025366857880726457
    num_steps_sampled: 14800000
    num_steps_trained: 14800000
    wait_time_ms: 570.392
  iterations_since_restore: 370
  node_ip: 172.17.8.24
  num_metric_batches_dropped: 0
  pid: 26970
  policy_reward_mean: {}
  time_since_restore: 20906.475528478622
  time_this_iter_s: 56.49327826499939
  time_total_s: 20906.475528478622
  timestamp: 1594205904
  timesteps_since_restore: 14800000
  timesteps_this_iter: 40000
  timesteps_total: 14800000
  training_iteration: 370
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26970], 20906 s, 370 iter, 14800000 ts, 449 rew

agent-1: 17.0
agent-2: 17.0
agent-3: 11.0
agent-4: 18.0
agent-5: 2.0
agent-6: 3.0
agent-7: 6.0
agent-8: 10.0
agent-9: 8.0
agent-10: 11.0
agent-11: 10.0
agent-12: 9.0
agent-13: 8.0
agent-14: 11.0
agent-15: 11.0
agent-16: 14.0
agent-17: 4.0
agent-18: 13.0
agent-19: 11.0
agent-20: 11.0
agent-21: 12.0
agent-22: 20.0
agent-23: 13.0
agent-24: 13.0
agent-25: 11.0
agent-26: 15.0
agent-27: 4.0
agent-28: 11.0
agent-29: 12.0
agent-30: 8.0
agent-31: 12.0
agent-32: 9.0
agent-33: 10.0
agent-34: 13.0
agent-35: 15.0
agent-36: 12.0
agent-37: 7.0
agent-38: 14.0
agent-39: 8.0
agent-40: 9.0
Sum Reward: 433.0
Avg Reward: 10.825
Min Reward: 2.0
Max Reward: 20.0
Gini Coefficient: 0.19855658198614318
20:20 Ratio: 3.0952380952380953
Max-min Ratio: 10.0
agent-1: 18.0
agent-2: 14.0
agent-3: 4.0
agent-4: 7.0
agent-5: 6.0
agent-6: 8.0
agent-7: 8.0
agent-8: 12.0
agent-9: 13.0
agent-10: 9.0
agent-11: 14.0
agent-12: 11.0
agent-13: 16.0
agent-14: 16.0
agent-15: 9.0
agent-16: 11.0
agent-17: 16.0
agent-18: 19.0
agent-19: 12.0
agent-20: 15.0
agent-21: 7.0
agent-22: 9.0
agent-23: 4.0
agent-24: 9.0
agent-25: 5.0
agent-26: 12.0
agent-27: 10.0
agent-28: 12.0
agent-29: 8.0
agent-30: 14.0
agent-31: 13.0
agent-32: 4.0
agent-33: 11.0
agent-34: 13.0
agent-35: 13.0
agent-36: 12.0
agent-37: 10.0
agent-38: 18.0
agent-39: 8.0
agent-40: 9.0
Sum Reward: 439.0
Avg Reward: 10.975
Min Reward: 4.0
Max Reward: 19.0
Gini Coefficient: 0.2003986332574032
20:20 Ratio: 2.933333333333333
Max-min Ratio: 4.75
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-08_06-59-21
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 487.0
  episode_reward_mean: 448.06
  episode_reward_min: 392.0
  episodes_this_iter: 2
  episodes_total: 371
  experiment_id: 4e724eb5b3a34f42879644e84578eec0
  hostname: gpu024
  info:
    apply_time_ms: 2.527
    dispatch_time_ms: 5.996
    learner:
      cur_lr: 0.00037431999226100743
      grad_gnorm: 0.19293828308582306
      policy_entropy: 777.3342895507812
      policy_loss: 0.11802805215120316
      var_gnorm: 39.09257125854492
      vf_explained_var: -1.0
      vf_loss: 9.533605407341383e-06
    num_steps_sampled: 14840000
    num_steps_trained: 14840000
    wait_time_ms: 561.964
  iterations_since_restore: 371
  node_ip: 172.17.8.24
  num_metric_batches_dropped: 0
  pid: 26970
  policy_reward_mean: {}
  time_since_restore: 20963.077898025513
  time_this_iter_s: 56.60236954689026
  time_total_s: 20963.077898025513
  timestamp: 1594205961
  timesteps_since_restore: 14840000
  timesteps_this_iter: 40000
  timesteps_total: 14840000
  training_iteration: 371
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26970], 20963 s, 371 iter, 14840000 ts, 448 rew

Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-08_07-00-17
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 487.0
  episode_reward_mean: 448.06
  episode_reward_min: 392.0
  episodes_this_iter: 0
  episodes_total: 371
  experiment_id: 4e724eb5b3a34f42879644e84578eec0
  hostname: gpu024
  info:
    apply_time_ms: 3.055
    dispatch_time_ms: 6.523
    learner:
      cur_lr: 0.00037165600224398077
      grad_gnorm: 0.9192540645599365
      policy_entropy: 762.8626708984375
      policy_loss: 0.06721541285514832
      var_gnorm: 39.09678268432617
      vf_explained_var: -1.0
      vf_loss: 0.0008917190134525299
    num_steps_sampled: 14880000
    num_steps_trained: 14880000
    wait_time_ms: 572.643
  iterations_since_restore: 372
  node_ip: 172.17.8.24
  num_metric_batches_dropped: 0
  pid: 26970
  policy_reward_mean: {}
  time_since_restore: 21019.417459964752
  time_this_iter_s: 56.3395619392395
  time_total_s: 21019.417459964752
  timestamp: 1594206017
  timesteps_since_restore: 14880000
  timesteps_this_iter: 40000
  timesteps_total: 14880000
  training_iteration: 372
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26970], 21019 s, 372 iter, 14880000 ts, 448 rew

agent-1: 16.0
agent-2: 5.0
agent-3: 9.0
agent-4: 14.0
agent-5: 12.0
agent-6: 12.0
agent-7: 7.0
agent-8: 12.0
agent-9: 14.0
agent-10: 10.0
agent-11: 12.0
agent-12: 11.0
agent-13: 16.0
agent-14: 12.0
agent-15: 18.0
agent-16: 11.0
agent-17: 7.0
agent-18: 8.0
agent-19: 8.0
agent-20: 7.0
agent-21: 10.0
agent-22: 7.0
agent-23: 17.0
agent-24: 12.0
agent-25: 16.0
agent-26: 9.0
agent-27: 11.0
agent-28: 15.0
agent-29: 15.0
agent-30: 6.0
agent-31: 11.0
agent-32: 16.0
agent-33: 12.0
agent-34: 15.0
agent-35: 7.0
agent-36: 10.0
agent-37: 11.0
agent-38: 2.0
agent-39: 7.0
agent-40: 8.0
Sum Reward: 438.0
Avg Reward: 10.95
Min Reward: 2.0
Max Reward: 18.0
Gini Coefficient: 0.1886986301369863
20:20 Ratio: 2.6875
Max-min Ratio: 9.0
agent-1: 6.0
agent-2: 12.0
agent-3: 10.0
agent-4: 9.0
agent-5: 12.0
agent-6: 17.0
agent-7: 12.0
agent-8: 11.0
agent-9: 6.0
agent-10: 8.0
agent-11: 14.0
agent-12: 7.0
agent-13: 7.0
agent-14: 11.0
agent-15: 15.0
agent-16: 6.0
agent-17: 17.0
agent-18: 12.0
agent-19: 14.0
agent-20: 12.0
agent-21: 12.0
agent-22: 8.0
agent-23: 14.0
agent-24: 11.0
agent-25: 10.0
agent-26: 10.0
agent-27: 11.0
agent-28: 11.0
agent-29: 12.0
agent-30: 12.0
agent-31: 8.0
agent-32: 10.0
agent-33: 18.0
agent-34: 11.0
agent-35: 11.0
agent-36: 13.0
agent-37: 16.0
agent-38: 13.0
agent-39: 8.0
agent-40: 12.0
Sum Reward: 449.0
Avg Reward: 11.225
Min Reward: 6.0
Max Reward: 18.0
Gini Coefficient: 0.14771714922048998
20:20 Ratio: 2.232142857142857
Max-min Ratio: 3.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-08_07-01-15
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 487.0
  episode_reward_mean: 448.01
  episode_reward_min: 392.0
  episodes_this_iter: 2
  episodes_total: 373
  experiment_id: 4e724eb5b3a34f42879644e84578eec0
  hostname: gpu024
  info:
    apply_time_ms: 2.534
    dispatch_time_ms: 6.762
    learner:
      cur_lr: 0.0003689920122269541
      grad_gnorm: 1.0572795867919922
      policy_entropy: 774.08544921875
      policy_loss: 0.6530404090881348
      var_gnorm: 39.097225189208984
      vf_explained_var: -1.0
      vf_loss: 0.00037645691190846264
    num_steps_sampled: 14920000
    num_steps_trained: 14920000
    wait_time_ms: 585.384
  iterations_since_restore: 373
  node_ip: 172.17.8.24
  num_metric_batches_dropped: 0
  pid: 26970
  policy_reward_mean: {}
  time_since_restore: 21076.427293539047
  time_this_iter_s: 57.009833574295044
  time_total_s: 21076.427293539047
  timestamp: 1594206075
  timesteps_since_restore: 14920000
  timesteps_this_iter: 40000
  timesteps_total: 14920000
  training_iteration: 373
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26970], 21076 s, 373 iter, 14920000 ts, 448 rew

Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-08_07-02-11
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 487.0
  episode_reward_mean: 448.01
  episode_reward_min: 392.0
  episodes_this_iter: 0
  episodes_total: 373
  experiment_id: 4e724eb5b3a34f42879644e84578eec0
  hostname: gpu024
  info:
    apply_time_ms: 2.755
    dispatch_time_ms: 7.391
    learner:
      cur_lr: 0.000366327993106097
      grad_gnorm: 0.25750410556793213
      policy_entropy: 773.2772216796875
      policy_loss: -0.20814581215381622
      var_gnorm: 39.1005859375
      vf_explained_var: -1.0
      vf_loss: 0.00022283068392425776
    num_steps_sampled: 14960000
    num_steps_trained: 14960000
    wait_time_ms: 552.175
  iterations_since_restore: 374
  node_ip: 172.17.8.24
  num_metric_batches_dropped: 0
  pid: 26970
  policy_reward_mean: {}
  time_since_restore: 21132.622667074203
  time_this_iter_s: 56.19537353515625
  time_total_s: 21132.622667074203
  timestamp: 1594206131
  timesteps_since_restore: 14960000
  timesteps_this_iter: 40000
  timesteps_total: 14960000
  training_iteration: 374
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26970], 21132 s, 374 iter, 14960000 ts, 448 rew

agent-1: 12.0
agent-2: 14.0
agent-3: 14.0
agent-4: 10.0
agent-5: 10.0
agent-6: 10.0
agent-7: 12.0
agent-8: 14.0
agent-9: 9.0
agent-10: 16.0
agent-11: 9.0
agent-12: 15.0
agent-13: 7.0
agent-14: 13.0
agent-15: 8.0
agent-16: 12.0
agent-17: 11.0
agent-18: 14.0
agent-19: 14.0
agent-20: 12.0
agent-21: 13.0
agent-22: 8.0
agent-23: 11.0
agent-24: 7.0
agent-25: 14.0
agent-26: 17.0
agent-27: 9.0
agent-28: 9.0
agent-29: 12.0
agent-30: 8.0
agent-31: 8.0
agent-32: 2.0
agent-33: 16.0
agent-34: 9.0
agent-35: 12.0
agent-36: 10.0
agent-37: 10.0
agent-38: 17.0
agent-39: 12.0
agent-40: 11.0
Sum Reward: 451.0
Avg Reward: 11.275
Min Reward: 2.0
Max Reward: 17.0
Gini Coefficient: 0.1512749445676275
20:20 Ratio: 2.1578947368421053
Max-min Ratio: 8.5
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-08_07-03-07
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 487.0
  episode_reward_mean: 448.06
  episode_reward_min: 392.0
  episodes_this_iter: 1
  episodes_total: 374
  experiment_id: 4e724eb5b3a34f42879644e84578eec0
  hostname: gpu024
  info:
    apply_time_ms: 2.756
    dispatch_time_ms: 5.602
    learner:
      cur_lr: 0.0003636640030890703
      grad_gnorm: 40.0
      policy_entropy: 36.39171600341797
      policy_loss: 21.70480728149414
      var_gnorm: 39.104766845703125
      vf_explained_var: 0.5246992111206055
      vf_loss: 469.98236083984375
    num_steps_sampled: 15000000
    num_steps_trained: 15000000
    wait_time_ms: 544.145
  iterations_since_restore: 375
  node_ip: 172.17.8.24
  num_metric_batches_dropped: 0
  pid: 26970
  policy_reward_mean: {}
  time_since_restore: 21189.06180548668
  time_this_iter_s: 56.439138412475586
  time_total_s: 21189.06180548668
  timestamp: 1594206187
  timesteps_since_restore: 15000000
  timesteps_this_iter: 40000
  timesteps_total: 15000000
  training_iteration: 375
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26970], 21189 s, 375 iter, 15000000 ts, 448 rew

agent-1: 8.0
agent-2: 9.0
agent-3: 12.0
agent-4: 11.0
agent-5: 9.0
agent-6: 12.0
agent-7: 11.0
agent-8: 9.0
agent-9: 16.0
agent-10: 13.0
agent-11: 10.0
agent-12: 11.0
agent-13: 12.0
agent-14: 10.0
agent-15: 14.0
agent-16: 11.0
agent-17: 13.0
agent-18: 6.0
agent-19: 11.0
agent-20: 7.0
agent-21: 10.0
agent-22: 18.0
agent-23: 3.0
agent-24: 13.0
agent-25: 13.0
agent-26: 8.0
agent-27: 15.0
agent-28: 7.0
agent-29: 8.0
agent-30: 15.0
agent-31: 13.0
agent-32: 17.0
agent-33: 11.0
agent-34: 7.0
agent-35: 8.0
agent-36: 11.0
agent-37: 7.0
agent-38: 15.0
agent-39: 10.0
agent-40: 13.0
Sum Reward: 437.0
Avg Reward: 10.925
Min Reward: 3.0
Max Reward: 18.0
Gini Coefficient: 0.1621853546910755
20:20 Ratio: 2.3207547169811322
Max-min Ratio: 6.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-08_07-04-04
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 487.0
  episode_reward_mean: 448.04
  episode_reward_min: 392.0
  episodes_this_iter: 1
  episodes_total: 375
  experiment_id: 4e724eb5b3a34f42879644e84578eec0
  hostname: gpu024
  info:
    apply_time_ms: 2.936
    dispatch_time_ms: 7.584
    learner:
      cur_lr: 0.00036100001307204366
      grad_gnorm: 2.4768149852752686
      policy_entropy: 772.6982421875
      policy_loss: 1.6483790874481201
      var_gnorm: 39.13479232788086
      vf_explained_var: -0.024260997772216797
      vf_loss: 0.0008981251739896834
    num_steps_sampled: 15040000
    num_steps_trained: 15040000
    wait_time_ms: 570.848
  iterations_since_restore: 376
  node_ip: 172.17.8.24
  num_metric_batches_dropped: 0
  pid: 26970
  policy_reward_mean: {}
  time_since_restore: 21245.45361351967
  time_this_iter_s: 56.3918080329895
  time_total_s: 21245.45361351967
  timestamp: 1594206244
  timesteps_since_restore: 15040000
  timesteps_this_iter: 40000
  timesteps_total: 15040000
  training_iteration: 376
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26970], 21245 s, 376 iter, 15040000 ts, 448 rew

agent-1: 19.0
agent-2: 10.0
agent-3: 9.0
agent-4: 15.0
agent-5: 4.0
agent-6: 12.0
agent-7: 10.0
agent-8: 14.0
agent-9: 17.0
agent-10: 13.0
agent-11: 9.0
agent-12: 15.0
agent-13: 9.0
agent-14: 3.0
agent-15: 9.0
agent-16: 15.0
agent-17: 13.0
agent-18: 14.0
agent-19: 6.0
agent-20: 9.0
agent-21: 10.0
agent-22: 13.0
agent-23: 7.0
agent-24: 15.0
agent-25: 10.0
agent-26: 8.0
agent-27: 9.0
agent-28: 14.0
agent-29: 13.0
agent-30: 12.0
agent-31: 14.0
agent-32: 12.0
agent-33: 13.0
agent-34: 8.0
agent-35: 6.0
agent-36: 8.0
agent-37: 10.0
agent-38: 15.0
agent-39: 11.0
agent-40: 15.0
Sum Reward: 448.0
Avg Reward: 11.2
Min Reward: 3.0
Max Reward: 19.0
Gini Coefficient: 0.17533482142857143
20:20 Ratio: 2.52
Max-min Ratio: 6.333333333333333
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-08_07-05-00
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 487.0
  episode_reward_mean: 448.18
  episode_reward_min: 392.0
  episodes_this_iter: 1
  episodes_total: 376
  experiment_id: 4e724eb5b3a34f42879644e84578eec0
  hostname: gpu024
  info:
    apply_time_ms: 2.685
    dispatch_time_ms: 7.574
    learner:
      cur_lr: 0.00035833599395118654
      grad_gnorm: 0.07038207352161407
      policy_entropy: 774.84619140625
      policy_loss: -0.0696198120713234
      var_gnorm: 39.13591384887695
      vf_explained_var: -0.535211443901062
      vf_loss: 4.209154802481407e-09
    num_steps_sampled: 15080000
    num_steps_trained: 15080000
    wait_time_ms: 550.056
  iterations_since_restore: 377
  node_ip: 172.17.8.24
  num_metric_batches_dropped: 0
  pid: 26970
  policy_reward_mean: {}
  time_since_restore: 21302.041704416275
  time_this_iter_s: 56.588090896606445
  time_total_s: 21302.041704416275
  timestamp: 1594206300
  timesteps_since_restore: 15080000
  timesteps_this_iter: 40000
  timesteps_total: 15080000
  training_iteration: 377
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26970], 21302 s, 377 iter, 15080000 ts, 448 rew

agent-1: 11.0
agent-2: 7.0
agent-3: 12.0
agent-4: 15.0
agent-5: 14.0
agent-6: 6.0
agent-7: 10.0
agent-8: 13.0
agent-9: 15.0
agent-10: 13.0
agent-11: 17.0
agent-12: 9.0
agent-13: 8.0
agent-14: 15.0
agent-15: 8.0
agent-16: 12.0
agent-17: 11.0
agent-18: 13.0
agent-19: 11.0
agent-20: 8.0
agent-21: 10.0
agent-22: 15.0
agent-23: 12.0
agent-24: 8.0
agent-25: 11.0
agent-26: 15.0
agent-27: 6.0
agent-28: 17.0
agent-29: 11.0
agent-30: 7.0
agent-31: 12.0
agent-32: 16.0
agent-33: 13.0
agent-34: 2.0
agent-35: 13.0
agent-36: 9.0
agent-37: 2.0
agent-38: 10.0
agent-39: 13.0
agent-40: 12.0
Sum Reward: 442.0
Avg Reward: 11.05
Min Reward: 2.0
Max Reward: 17.0
Gini Coefficient: 0.17873303167420815
20:20 Ratio: 2.717391304347826
Max-min Ratio: 8.5
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-08_07-05-57
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 487.0
  episode_reward_mean: 448.28
  episode_reward_min: 392.0
  episodes_this_iter: 1
  episodes_total: 377
  experiment_id: 4e724eb5b3a34f42879644e84578eec0
  hostname: gpu024
  info:
    apply_time_ms: 3.081
    dispatch_time_ms: 7.852
    learner:
      cur_lr: 0.0003556720039341599
      grad_gnorm: 0.586081326007843
      policy_entropy: 767.1478271484375
      policy_loss: -0.7769235372543335
      var_gnorm: 39.170806884765625
      vf_explained_var: -0.03203690052032471
      vf_loss: 5.10620629938785e-05
    num_steps_sampled: 15120000
    num_steps_trained: 15120000
    wait_time_ms: 550.114
  iterations_since_restore: 378
  node_ip: 172.17.8.24
  num_metric_batches_dropped: 0
  pid: 26970
  policy_reward_mean: {}
  time_since_restore: 21358.331001758575
  time_this_iter_s: 56.289297342300415
  time_total_s: 21358.331001758575
  timestamp: 1594206357
  timesteps_since_restore: 15120000
  timesteps_this_iter: 40000
  timesteps_total: 15120000
  training_iteration: 378
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26970], 21358 s, 378 iter, 15120000 ts, 448 rew

agent-1: 16.0
agent-2: 11.0
agent-3: 14.0
agent-4: 9.0
agent-5: 14.0
agent-6: 7.0
agent-7: 8.0
agent-8: 12.0
agent-9: 10.0
agent-10: 10.0
agent-11: 14.0
agent-12: 14.0
agent-13: 17.0
agent-14: 11.0
agent-15: 12.0
agent-16: 14.0
agent-17: 9.0
agent-18: 8.0
agent-19: 9.0
agent-20: 12.0
agent-21: 11.0
agent-22: 13.0
agent-23: 10.0
agent-24: 9.0
agent-25: 12.0
agent-26: 9.0
agent-27: 12.0
agent-28: 14.0
agent-29: 14.0
agent-30: 9.0
agent-31: 15.0
agent-32: 11.0
agent-33: 8.0
agent-34: 7.0
agent-35: 12.0
agent-36: 13.0
agent-37: 12.0
agent-38: 7.0
agent-39: 8.0
agent-40: 7.0
Sum Reward: 444.0
Avg Reward: 11.1
Min Reward: 7.0
Max Reward: 17.0
Gini Coefficient: 0.13603603603603603
20:20 Ratio: 1.9666666666666666
Max-min Ratio: 2.4285714285714284
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-08_07-06-53
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 487.0
  episode_reward_mean: 448.29
  episode_reward_min: 392.0
  episodes_this_iter: 1
  episodes_total: 378
  experiment_id: 4e724eb5b3a34f42879644e84578eec0
  hostname: gpu024
  info:
    apply_time_ms: 3.665
    dispatch_time_ms: 8.568
    learner:
      cur_lr: 0.0003530080139171332
      grad_gnorm: 0.25050416588783264
      policy_entropy: 773.6607666015625
      policy_loss: 0.061264246702194214
      var_gnorm: 39.17405700683594
      vf_explained_var: -1.0
      vf_loss: 2.8914671929669566e-05
    num_steps_sampled: 15160000
    num_steps_trained: 15160000
    wait_time_ms: 558.566
  iterations_since_restore: 379
  node_ip: 172.17.8.24
  num_metric_batches_dropped: 0
  pid: 26970
  policy_reward_mean: {}
  time_since_restore: 21414.941712141037
  time_this_iter_s: 56.61071038246155
  time_total_s: 21414.941712141037
  timestamp: 1594206413
  timesteps_since_restore: 15160000
  timesteps_this_iter: 40000
  timesteps_total: 15160000
  training_iteration: 379
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26970], 21414 s, 379 iter, 15160000 ts, 448 rew

agent-1: 9.0
agent-2: 10.0
agent-3: 15.0
agent-4: 7.0
agent-5: 13.0
agent-6: 9.0
agent-7: 9.0
agent-8: 10.0
agent-9: 10.0
agent-10: 13.0
agent-11: 13.0
agent-12: 11.0
agent-13: 12.0
agent-14: 9.0
agent-15: 14.0
agent-16: 10.0
agent-17: 7.0
agent-18: 6.0
agent-19: 10.0
agent-20: 10.0
agent-21: 10.0
agent-22: 11.0
agent-23: 8.0
agent-24: 9.0
agent-25: 9.0
agent-26: 15.0
agent-27: 15.0
agent-28: 10.0
agent-29: 13.0
agent-30: 13.0
agent-31: 11.0
agent-32: 10.0
agent-33: 10.0
agent-34: 12.0
agent-35: 11.0
agent-36: 12.0
agent-37: 15.0
agent-38: 11.0
agent-39: 13.0
agent-40: 9.0
Sum Reward: 434.0
Avg Reward: 10.85
Min Reward: 6.0
Max Reward: 15.0
Gini Coefficient: 0.11601382488479263
20:20 Ratio: 1.765625
Max-min Ratio: 2.5
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-08_07-07-50
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 487.0
  episode_reward_mean: 448.09
  episode_reward_min: 392.0
  episodes_this_iter: 1
  episodes_total: 379
  experiment_id: 4e724eb5b3a34f42879644e84578eec0
  hostname: gpu024
  info:
    apply_time_ms: 2.515
    dispatch_time_ms: 5.846
    learner:
      cur_lr: 0.0003503439947962761
      grad_gnorm: 2.1268224716186523
      policy_entropy: 771.0617065429688
      policy_loss: -0.7664426565170288
      var_gnorm: 39.199066162109375
      vf_explained_var: -1.0
      vf_loss: 0.02935749664902687
    num_steps_sampled: 15200000
    num_steps_trained: 15200000
    wait_time_ms: 572.767
  iterations_since_restore: 380
  node_ip: 172.17.8.24
  num_metric_batches_dropped: 0
  pid: 26970
  policy_reward_mean: {}
  time_since_restore: 21471.331782102585
  time_this_iter_s: 56.39006996154785
  time_total_s: 21471.331782102585
  timestamp: 1594206470
  timesteps_since_restore: 15200000
  timesteps_this_iter: 40000
  timesteps_total: 15200000
  training_iteration: 380
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26970], 21471 s, 380 iter, 15200000 ts, 448 rew

agent-1: 10.0
agent-2: 7.0
agent-3: 12.0
agent-4: 17.0
agent-5: 9.0
agent-6: 4.0
agent-7: 15.0
agent-8: 12.0
agent-9: 9.0
agent-10: 6.0
agent-11: 14.0
agent-12: 13.0
agent-13: 10.0
agent-14: 9.0
agent-15: 8.0
agent-16: 8.0
agent-17: 12.0
agent-18: 12.0
agent-19: 9.0
agent-20: 11.0
agent-21: 6.0
agent-22: 9.0
agent-23: 15.0
agent-24: 13.0
agent-25: 12.0
agent-26: 11.0
agent-27: 9.0
agent-28: 9.0
agent-29: 10.0
agent-30: 15.0
agent-31: 14.0
agent-32: 11.0
agent-33: 16.0
agent-34: 6.0
agent-35: 10.0
agent-36: 11.0
agent-37: 9.0
agent-38: 12.0
agent-39: 10.0
agent-40: 9.0
Sum Reward: 424.0
Avg Reward: 10.6
Min Reward: 4.0
Max Reward: 17.0
Gini Coefficient: 0.15247641509433962
20:20 Ratio: 2.2037037037037037
Max-min Ratio: 4.25
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-08_07-08-47
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 487.0
  episode_reward_mean: 447.84
  episode_reward_min: 392.0
  episodes_this_iter: 1
  episodes_total: 380
  experiment_id: 4e724eb5b3a34f42879644e84578eec0
  hostname: gpu024
  info:
    apply_time_ms: 2.477
    dispatch_time_ms: 5.766
    learner:
      cur_lr: 0.00034768000477924943
      grad_gnorm: 40.000003814697266
      policy_entropy: 78.7122573852539
      policy_loss: 15.584362983703613
      var_gnorm: 39.20220947265625
      vf_explained_var: 0.45597201585769653
      vf_loss: 461.4597473144531
    num_steps_sampled: 15240000
    num_steps_trained: 15240000
    wait_time_ms: 548.178
  iterations_since_restore: 381
  node_ip: 172.17.8.24
  num_metric_batches_dropped: 0
  pid: 26970
  policy_reward_mean: {}
  time_since_restore: 21528.106657505035
  time_this_iter_s: 56.77487540245056
  time_total_s: 21528.106657505035
  timestamp: 1594206527
  timesteps_since_restore: 15240000
  timesteps_this_iter: 40000
  timesteps_total: 15240000
  training_iteration: 381
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26970], 21528 s, 381 iter, 15240000 ts, 448 rew

agent-1: 8.0
agent-2: 12.0
agent-3: 19.0
agent-4: 6.0
agent-5: 18.0
agent-6: 9.0
agent-7: 10.0
agent-8: 11.0
agent-9: 15.0
agent-10: 8.0
agent-11: 8.0
agent-12: 10.0
agent-13: 14.0
agent-14: 9.0
agent-15: 13.0
agent-16: 12.0
agent-17: 14.0
agent-18: 7.0
agent-19: 13.0
agent-20: 10.0
agent-21: 8.0
agent-22: 10.0
agent-23: 18.0
agent-24: 14.0
agent-25: 11.0
agent-26: 9.0
agent-27: 17.0
agent-28: 10.0
agent-29: 11.0
agent-30: 16.0
agent-31: 10.0
agent-32: 11.0
agent-33: 5.0
agent-34: 12.0
agent-35: 16.0
agent-36: 13.0
agent-37: 11.0
agent-38: 10.0
agent-39: 11.0
agent-40: 12.0
Sum Reward: 461.0
Avg Reward: 11.525
Min Reward: 5.0
Max Reward: 19.0
Gini Coefficient: 0.15829718004338394
20:20 Ratio: 2.2542372881355934
Max-min Ratio: 3.8
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-08_07-09-43
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 487.0
  episode_reward_mean: 448.12
  episode_reward_min: 392.0
  episodes_this_iter: 1
  episodes_total: 381
  experiment_id: 4e724eb5b3a34f42879644e84578eec0
  hostname: gpu024
  info:
    apply_time_ms: 2.592
    dispatch_time_ms: 7.139
    learner:
      cur_lr: 0.0003450159856583923
      grad_gnorm: 0.13846372067928314
      policy_entropy: 770.8994140625
      policy_loss: -0.07255461812019348
      var_gnorm: 39.1942024230957
      vf_explained_var: -1.0
      vf_loss: 1.3816586942994036e-05
    num_steps_sampled: 15280000
    num_steps_trained: 15280000
    wait_time_ms: 558.286
  iterations_since_restore: 382
  node_ip: 172.17.8.24
  num_metric_batches_dropped: 0
  pid: 26970
  policy_reward_mean: {}
  time_since_restore: 21584.54883813858
  time_this_iter_s: 56.44218063354492
  time_total_s: 21584.54883813858
  timestamp: 1594206583
  timesteps_since_restore: 15280000
  timesteps_this_iter: 40000
  timesteps_total: 15280000
  training_iteration: 382
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26970], 21584 s, 382 iter, 15280000 ts, 448 rew

agent-1: 15.0
agent-2: 12.0
agent-3: 21.0
agent-4: 9.0
agent-5: 7.0
agent-6: 10.0
agent-7: 10.0
agent-8: 8.0
agent-9: 10.0
agent-10: 9.0
agent-11: 15.0
agent-12: 5.0
agent-13: 17.0
agent-14: 5.0
agent-15: 7.0
agent-16: 8.0
agent-17: 9.0
agent-18: 13.0
agent-19: 11.0
agent-20: 12.0
agent-21: 13.0
agent-22: 11.0
agent-23: 10.0
agent-24: 14.0
agent-25: 15.0
agent-26: 13.0
agent-27: 12.0
agent-28: 7.0
agent-29: 7.0
agent-30: 13.0
agent-31: 13.0
agent-32: 10.0
agent-33: 12.0
agent-34: 19.0
agent-35: 15.0
agent-36: 13.0
agent-37: 15.0
agent-38: 11.0
agent-39: 6.0
agent-40: 13.0
Sum Reward: 455.0
Avg Reward: 11.375
Min Reward: 5.0
Max Reward: 21.0
Gini Coefficient: 0.17554945054945054
20:20 Ratio: 2.5384615384615383
Max-min Ratio: 4.2
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-08_07-10-39
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 487.0
  episode_reward_mean: 448.43
  episode_reward_min: 392.0
  episodes_this_iter: 1
  episodes_total: 382
  experiment_id: 4e724eb5b3a34f42879644e84578eec0
  hostname: gpu024
  info:
    apply_time_ms: 3.179
    dispatch_time_ms: 5.915
    learner:
      cur_lr: 0.00034235199564136565
      grad_gnorm: 0.10044313967227936
      policy_entropy: 774.3888549804688
      policy_loss: 0.04305935278534889
      var_gnorm: 39.192413330078125
      vf_explained_var: -1.0
      vf_loss: 2.289105623276555e-06
    num_steps_sampled: 15320000
    num_steps_trained: 15320000
    wait_time_ms: 553.29
  iterations_since_restore: 383
  node_ip: 172.17.8.24
  num_metric_batches_dropped: 0
  pid: 26970
  policy_reward_mean: {}
  time_since_restore: 21640.8400888443
  time_this_iter_s: 56.291250705718994
  time_total_s: 21640.8400888443
  timestamp: 1594206639
  timesteps_since_restore: 15320000
  timesteps_this_iter: 40000
  timesteps_total: 15320000
  training_iteration: 383
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26970], 21640 s, 383 iter, 15320000 ts, 448 rew

agent-1: 19.0
agent-2: 12.0
agent-3: 14.0
agent-4: 13.0
agent-5: 12.0
agent-6: 9.0
agent-7: 10.0
agent-8: 12.0
agent-9: 10.0
agent-10: 14.0
agent-11: 12.0
agent-12: 11.0
agent-13: 13.0
agent-14: 6.0
agent-15: 8.0
agent-16: 8.0
agent-17: 8.0
agent-18: 17.0
agent-19: 13.0
agent-20: 15.0
agent-21: 9.0
agent-22: 8.0
agent-23: 12.0
agent-24: 8.0
agent-25: 20.0
agent-26: 14.0
agent-27: 16.0
agent-28: 18.0
agent-29: 6.0
agent-30: 17.0
agent-31: 7.0
agent-32: 13.0
agent-33: 14.0
agent-34: 8.0
agent-35: 5.0
agent-36: 11.0
agent-37: 11.0
agent-38: 9.0
agent-39: 12.0
agent-40: 10.0
Sum Reward: 464.0
Avg Reward: 11.6
Min Reward: 5.0
Max Reward: 20.0
Gini Coefficient: 0.17553879310344828
20:20 Ratio: 2.4285714285714284
Max-min Ratio: 4.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-08_07-11-36
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 487.0
  episode_reward_mean: 448.8
  episode_reward_min: 392.0
  episodes_this_iter: 1
  episodes_total: 383
  experiment_id: 4e724eb5b3a34f42879644e84578eec0
  hostname: gpu024
  info:
    apply_time_ms: 2.363
    dispatch_time_ms: 5.349
    learner:
      cur_lr: 0.000339688005624339
      grad_gnorm: 0.49990829825401306
      policy_entropy: 775.5247802734375
      policy_loss: -0.2495407611131668
      var_gnorm: 39.21131134033203
      vf_explained_var: -1.0
      vf_loss: 5.587158375419676e-05
    num_steps_sampled: 15360000
    num_steps_trained: 15360000
    wait_time_ms: 555.164
  iterations_since_restore: 384
  node_ip: 172.17.8.24
  num_metric_batches_dropped: 0
  pid: 26970
  policy_reward_mean: {}
  time_since_restore: 21697.101699352264
  time_this_iter_s: 56.26161050796509
  time_total_s: 21697.101699352264
  timestamp: 1594206696
  timesteps_since_restore: 15360000
  timesteps_this_iter: 40000
  timesteps_total: 15360000
  training_iteration: 384
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26970], 21697 s, 384 iter, 15360000 ts, 449 rew

agent-1: 13.0
agent-2: 14.0
agent-3: 13.0
agent-4: 10.0
agent-5: 14.0
agent-6: 8.0
agent-7: 7.0
agent-8: 8.0
agent-9: 10.0
agent-10: 9.0
agent-11: 11.0
agent-12: 15.0
agent-13: 5.0
agent-14: 15.0
agent-15: 11.0
agent-16: 9.0
agent-17: 11.0
agent-18: 11.0
agent-19: 9.0
agent-20: 10.0
agent-21: 11.0
agent-22: 7.0
agent-23: 13.0
agent-24: 12.0
agent-25: 11.0
agent-26: 13.0
agent-27: 11.0
agent-28: 13.0
agent-29: 7.0
agent-30: 13.0
agent-31: 13.0
agent-32: 13.0
agent-33: 13.0
agent-34: 12.0
agent-35: 15.0
agent-36: 19.0
agent-37: 11.0
agent-38: 11.0
agent-39: 12.0
agent-40: 6.0
Sum Reward: 449.0
Avg Reward: 11.225
Min Reward: 5.0
Max Reward: 19.0
Gini Coefficient: 0.13624721603563475
20:20 Ratio: 2.0701754385964914
Max-min Ratio: 3.8
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-08_07-12-33
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 487.0
  episode_reward_mean: 448.76
  episode_reward_min: 392.0
  episodes_this_iter: 1
  episodes_total: 384
  experiment_id: 4e724eb5b3a34f42879644e84578eec0
  hostname: gpu024
  info:
    apply_time_ms: 3.187
    dispatch_time_ms: 7.283
    learner:
      cur_lr: 0.00033702398650348186
      grad_gnorm: 0.24791808426380157
      policy_entropy: 776.92431640625
      policy_loss: -0.00656219944357872
      var_gnorm: 39.21229553222656
      vf_explained_var: -1.0
      vf_loss: 0.0001787115033948794
    num_steps_sampled: 15400000
    num_steps_trained: 15400000
    wait_time_ms: 565.209
  iterations_since_restore: 385
  node_ip: 172.17.8.24
  num_metric_batches_dropped: 0
  pid: 26970
  policy_reward_mean: {}
  time_since_restore: 21754.18626689911
  time_this_iter_s: 57.08456754684448
  time_total_s: 21754.18626689911
  timestamp: 1594206753
  timesteps_since_restore: 15400000
  timesteps_this_iter: 40000
  timesteps_total: 15400000
  training_iteration: 385
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26970], 21754 s, 385 iter, 15400000 ts, 449 rew

agent-1: 12.0
agent-2: 15.0
agent-3: 10.0
agent-4: 14.0
agent-5: 14.0
agent-6: 14.0
agent-7: 7.0
agent-8: 11.0
agent-9: 7.0
agent-10: 11.0
agent-11: 11.0
agent-12: 12.0
agent-13: 4.0
agent-14: 15.0
agent-15: 9.0
agent-16: 5.0
agent-17: 11.0
agent-18: 15.0
agent-19: 11.0
agent-20: 19.0
agent-21: 11.0
agent-22: 13.0
agent-23: 12.0
agent-24: 6.0
agent-25: 9.0
agent-26: 10.0
agent-27: 7.0
agent-28: 13.0
agent-29: 16.0
agent-30: 10.0
agent-31: 8.0
agent-32: 10.0
agent-33: 12.0
agent-34: 7.0
agent-35: 12.0
agent-36: 11.0
agent-37: 15.0
agent-38: 13.0
agent-39: 10.0
agent-40: 11.0
Sum Reward: 443.0
Avg Reward: 11.075
Min Reward: 4.0
Max Reward: 19.0
Gini Coefficient: 0.1575056433408578
20:20 Ratio: 2.411764705882353
Max-min Ratio: 4.75
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-08_07-13-29
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 487.0
  episode_reward_mean: 448.47
  episode_reward_min: 392.0
  episodes_this_iter: 1
  episodes_total: 385
  experiment_id: 4e724eb5b3a34f42879644e84578eec0
  hostname: gpu024
  info:
    apply_time_ms: 2.713
    dispatch_time_ms: 6.735
    learner:
      cur_lr: 0.0003343599964864552
      grad_gnorm: 0.15220089256763458
      policy_entropy: 777.1932373046875
      policy_loss: -0.17540699243545532
      var_gnorm: 39.239566802978516
      vf_explained_var: -1.0
      vf_loss: 5.411359779827762e-06
    num_steps_sampled: 15440000
    num_steps_trained: 15440000
    wait_time_ms: 558.81
  iterations_since_restore: 386
  node_ip: 172.17.8.24
  num_metric_batches_dropped: 0
  pid: 26970
  policy_reward_mean: {}
  time_since_restore: 21810.222920656204
  time_this_iter_s: 56.03665375709534
  time_total_s: 21810.222920656204
  timestamp: 1594206809
  timesteps_since_restore: 15440000
  timesteps_this_iter: 40000
  timesteps_total: 15440000
  training_iteration: 386
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26970], 21810 s, 386 iter, 15440000 ts, 448 rew

agent-1: 14.0
agent-2: 6.0
agent-3: 10.0
agent-4: 13.0
agent-5: 14.0
agent-6: 13.0
agent-7: 16.0
agent-8: 15.0
agent-9: 7.0
agent-10: 5.0
agent-11: 11.0
agent-12: 3.0
agent-13: 6.0
agent-14: 6.0
agent-15: 11.0
agent-16: 13.0
agent-17: 10.0
agent-18: 13.0
agent-19: 11.0
agent-20: 12.0
agent-21: 8.0
agent-22: 12.0
agent-23: 13.0
agent-24: 10.0
agent-25: 13.0
agent-26: 20.0
agent-27: 16.0
agent-28: 13.0
agent-29: 6.0
agent-30: 11.0
agent-31: 13.0
agent-32: 11.0
agent-33: 19.0
agent-34: 9.0
agent-35: 7.0
agent-36: 15.0
agent-37: 11.0
agent-38: 12.0
agent-39: 6.0
agent-40: 8.0
Sum Reward: 442.0
Avg Reward: 11.05
Min Reward: 3.0
Max Reward: 20.0
Gini Coefficient: 0.18936651583710407
20:20 Ratio: 2.8666666666666667
Max-min Ratio: 6.666666666666667
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-08_07-14-26
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 487.0
  episode_reward_mean: 448.33
  episode_reward_min: 392.0
  episodes_this_iter: 1
  episodes_total: 386
  experiment_id: 4e724eb5b3a34f42879644e84578eec0
  hostname: gpu024
  info:
    apply_time_ms: 2.316
    dispatch_time_ms: 5.728
    learner:
      cur_lr: 0.00033169600646942854
      grad_gnorm: 0.5717691779136658
      policy_entropy: 778.046630859375
      policy_loss: 0.1122557520866394
      var_gnorm: 39.238590240478516
      vf_explained_var: -1.0
      vf_loss: 4.8777746997075155e-05
    num_steps_sampled: 15480000
    num_steps_trained: 15480000
    wait_time_ms: 572.327
  iterations_since_restore: 387
  node_ip: 172.17.8.24
  num_metric_batches_dropped: 0
  pid: 26970
  policy_reward_mean: {}
  time_since_restore: 21867.161504983902
  time_this_iter_s: 56.938584327697754
  time_total_s: 21867.161504983902
  timestamp: 1594206866
  timesteps_since_restore: 15480000
  timesteps_this_iter: 40000
  timesteps_total: 15480000
  training_iteration: 387
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26970], 21867 s, 387 iter, 15480000 ts, 448 rew

agent-1: 20.0
agent-2: 5.0
agent-3: 10.0
agent-4: 9.0
agent-5: 9.0
agent-6: 11.0
agent-7: 14.0
agent-8: 7.0
agent-9: 7.0
agent-10: 9.0
agent-11: 14.0
agent-12: 5.0
agent-13: 13.0
agent-14: 12.0
agent-15: 10.0
agent-16: 11.0
agent-17: 6.0
agent-18: 12.0
agent-19: 7.0
agent-20: 9.0
agent-21: 5.0
agent-22: 13.0
agent-23: 11.0
agent-24: 5.0
agent-25: 12.0
agent-26: 9.0
agent-27: 13.0
agent-28: 10.0
agent-29: 9.0
agent-30: 9.0
agent-31: 12.0
agent-32: 15.0
agent-33: 9.0
agent-34: 18.0
agent-35: 11.0
agent-36: 14.0
agent-37: 11.0
agent-38: 15.0
agent-39: 16.0
agent-40: 10.0
Sum Reward: 427.0
Avg Reward: 10.675
Min Reward: 5.0
Max Reward: 20.0
Gini Coefficient: 0.1803864168618267
20:20 Ratio: 2.6808510638297873
Max-min Ratio: 4.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-08_07-15-22
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 487.0
  episode_reward_mean: 448.2
  episode_reward_min: 392.0
  episodes_this_iter: 1
  episodes_total: 387
  experiment_id: 4e724eb5b3a34f42879644e84578eec0
  hostname: gpu024
  info:
    apply_time_ms: 2.734
    dispatch_time_ms: 7.143
    learner:
      cur_lr: 0.0003290319873485714
      grad_gnorm: 1.3120801448822021
      policy_entropy: 774.1447143554688
      policy_loss: -0.3053145408630371
      var_gnorm: 39.234336853027344
      vf_explained_var: -1.0
      vf_loss: 0.0007169703603722155
    num_steps_sampled: 15520000
    num_steps_trained: 15520000
    wait_time_ms: 549.043
  iterations_since_restore: 388
  node_ip: 172.17.8.24
  num_metric_batches_dropped: 0
  pid: 26970
  policy_reward_mean: {}
  time_since_restore: 21923.606466770172
  time_this_iter_s: 56.44496178627014
  time_total_s: 21923.606466770172
  timestamp: 1594206922
  timesteps_since_restore: 15520000
  timesteps_this_iter: 40000
  timesteps_total: 15520000
  training_iteration: 388
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26970], 21923 s, 388 iter, 15520000 ts, 448 rew

agent-1: 20.0
agent-2: 12.0
agent-3: 14.0
agent-4: 10.0
agent-5: 13.0
agent-6: 11.0
agent-7: 7.0
agent-8: 15.0
agent-9: 15.0
agent-10: 10.0
agent-11: 7.0
agent-12: 5.0
agent-13: 5.0
agent-14: 11.0
agent-15: 18.0
agent-16: 11.0
agent-17: 8.0
agent-18: 13.0
agent-19: 15.0
agent-20: 11.0
agent-21: 15.0
agent-22: 8.0
agent-23: 10.0
agent-24: 8.0
agent-25: 17.0
agent-26: 14.0
agent-27: 16.0
agent-28: 2.0
agent-29: 8.0
agent-30: 8.0
agent-31: 9.0
agent-32: 6.0
agent-33: 8.0
agent-34: 10.0
agent-35: 20.0
agent-36: 5.0
agent-37: 15.0
agent-38: 11.0
agent-39: 11.0
agent-40: 14.0
Sum Reward: 446.0
Avg Reward: 11.15
Min Reward: 2.0
Max Reward: 20.0
Gini Coefficient: 0.21132286995515695
20:20 Ratio: 3.022222222222222
Max-min Ratio: 10.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-08_07-16-19
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 487.0
  episode_reward_mean: 448.09
  episode_reward_min: 392.0
  episodes_this_iter: 1
  episodes_total: 388
  experiment_id: 4e724eb5b3a34f42879644e84578eec0
  hostname: gpu024
  info:
    apply_time_ms: 3.257
    dispatch_time_ms: 5.743
    learner:
      cur_lr: 0.00032636799733154476
      grad_gnorm: 1.3455418348312378
      policy_entropy: 777.315185546875
      policy_loss: -0.25569388270378113
      var_gnorm: 39.24032211303711
      vf_explained_var: -1.0
      vf_loss: 0.00219421717338264
    num_steps_sampled: 15560000
    num_steps_trained: 15560000
    wait_time_ms: 522.219
  iterations_since_restore: 389
  node_ip: 172.17.8.24
  num_metric_batches_dropped: 0
  pid: 26970
  policy_reward_mean: {}
  time_since_restore: 21979.84029698372
  time_this_iter_s: 56.23383021354675
  time_total_s: 21979.84029698372
  timestamp: 1594206979
  timesteps_since_restore: 15560000
  timesteps_this_iter: 40000
  timesteps_total: 15560000
  training_iteration: 389
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26970], 21979 s, 389 iter, 15560000 ts, 448 rew

agent-1: 9.0
agent-2: 10.0
agent-3: 11.0
agent-4: 11.0
agent-5: 11.0
agent-6: 13.0
agent-7: 16.0
agent-8: 12.0
agent-9: 16.0
agent-10: 9.0
agent-11: 11.0
agent-12: 7.0
agent-13: 14.0
agent-14: 16.0
agent-15: 13.0
agent-16: 17.0
agent-17: 10.0
agent-18: 10.0
agent-19: 8.0
agent-20: 11.0
agent-21: 12.0
agent-22: 6.0
agent-23: 9.0
agent-24: 15.0
agent-25: 11.0
agent-26: 7.0
agent-27: 10.0
agent-28: 11.0
agent-29: 13.0
agent-30: 6.0
agent-31: 12.0
agent-32: 12.0
agent-33: 12.0
agent-34: 11.0
agent-35: 10.0
agent-36: 9.0
agent-37: 13.0
agent-38: 10.0
agent-39: 5.0
agent-40: 13.0
Sum Reward: 442.0
Avg Reward: 11.05
Min Reward: 5.0
Max Reward: 17.0
Gini Coefficient: 0.14015837104072398
20:20 Ratio: 2.1052631578947367
Max-min Ratio: 3.4
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-08_07-17-15
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 487.0
  episode_reward_mean: 447.97
  episode_reward_min: 392.0
  episodes_this_iter: 1
  episodes_total: 389
  experiment_id: 4e724eb5b3a34f42879644e84578eec0
  hostname: gpu024
  info:
    apply_time_ms: 2.896
    dispatch_time_ms: 7.042
    learner:
      cur_lr: 0.0003237040073145181
      grad_gnorm: 0.5240123271942139
      policy_entropy: 774.6041259765625
      policy_loss: 0.05226336419582367
      var_gnorm: 39.25080871582031
      vf_explained_var: -0.19100451469421387
      vf_loss: 0.0010488538537174463
    num_steps_sampled: 15600000
    num_steps_trained: 15600000
    wait_time_ms: 557.365
  iterations_since_restore: 390
  node_ip: 172.17.8.24
  num_metric_batches_dropped: 0
  pid: 26970
  policy_reward_mean: {}
  time_since_restore: 22036.330233097076
  time_this_iter_s: 56.489936113357544
  time_total_s: 22036.330233097076
  timestamp: 1594207035
  timesteps_since_restore: 15600000
  timesteps_this_iter: 40000
  timesteps_total: 15600000
  training_iteration: 390
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26970], 22036 s, 390 iter, 15600000 ts, 448 rew

agent-1: 12.0
agent-2: 18.0
agent-3: 12.0
agent-4: 9.0
agent-5: 7.0
agent-6: 9.0
agent-7: 9.0
agent-8: 12.0
agent-9: 10.0
agent-10: 8.0
agent-11: 10.0
agent-12: 14.0
agent-13: 11.0
agent-14: 11.0
agent-15: 3.0
agent-16: 6.0
agent-17: 15.0
agent-18: 13.0
agent-19: 7.0
agent-20: 15.0
agent-21: 13.0
agent-22: 8.0
agent-23: 6.0
agent-24: 16.0
agent-25: 14.0
agent-26: 6.0
agent-27: 13.0
agent-28: 11.0
agent-29: 12.0
agent-30: 14.0
agent-31: 17.0
agent-32: 11.0
agent-33: 18.0
agent-34: 17.0
agent-35: 8.0
agent-36: 11.0
agent-37: 16.0
agent-38: 11.0
agent-39: 6.0
agent-40: 12.0
Sum Reward: 451.0
Avg Reward: 11.275
Min Reward: 3.0
Max Reward: 18.0
Gini Coefficient: 0.18353658536585366
20:20 Ratio: 2.693877551020408
Max-min Ratio: 6.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-08_07-18-12
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 487.0
  episode_reward_mean: 447.97
  episode_reward_min: 392.0
  episodes_this_iter: 1
  episodes_total: 390
  experiment_id: 4e724eb5b3a34f42879644e84578eec0
  hostname: gpu024
  info:
    apply_time_ms: 3.264
    dispatch_time_ms: 6.651
    learner:
      cur_lr: 0.000321039988193661
      grad_gnorm: 0.5447406768798828
      policy_entropy: 776.31787109375
      policy_loss: -0.34161585569381714
      var_gnorm: 39.24807357788086
      vf_explained_var: -1.0
      vf_loss: 0.00016459538892377168
    num_steps_sampled: 15640000
    num_steps_trained: 15640000
    wait_time_ms: 569.028
  iterations_since_restore: 391
  node_ip: 172.17.8.24
  num_metric_batches_dropped: 0
  pid: 26970
  policy_reward_mean: {}
  time_since_restore: 22093.147610664368
  time_this_iter_s: 56.81737756729126
  time_total_s: 22093.147610664368
  timestamp: 1594207092
  timesteps_since_restore: 15640000
  timesteps_this_iter: 40000
  timesteps_total: 15640000
  training_iteration: 391
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26970], 22093 s, 391 iter, 15640000 ts, 448 rew

agent-1: 16.0
agent-2: 6.0
agent-3: 10.0
agent-4: 14.0
agent-5: 14.0
agent-6: 7.0
agent-7: 14.0
agent-8: 12.0
agent-9: 6.0
agent-10: 9.0
agent-11: 12.0
agent-12: 9.0
agent-13: 10.0
agent-14: 9.0
agent-15: 16.0
agent-16: 4.0
agent-17: 7.0
agent-18: 14.0
agent-19: 14.0
agent-20: 14.0
agent-21: 9.0
agent-22: 2.0
agent-23: 6.0
agent-24: 10.0
agent-25: 10.0
agent-26: 14.0
agent-27: 12.0
agent-28: 10.0
agent-29: 15.0
agent-30: 13.0
agent-31: 7.0
agent-32: 8.0
agent-33: 9.0
agent-34: 16.0
agent-35: 12.0
agent-36: 13.0
agent-37: 13.0
agent-38: 11.0
agent-39: 9.0
agent-40: 19.0
Sum Reward: 435.0
Avg Reward: 10.875
Min Reward: 2.0
Max Reward: 19.0
Gini Coefficient: 0.18741379310344827
20:20 Ratio: 2.7555555555555555
Max-min Ratio: 9.5
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-08_07-19-09
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 487.0
  episode_reward_mean: 447.87
  episode_reward_min: 392.0
  episodes_this_iter: 1
  episodes_total: 391
  experiment_id: 4e724eb5b3a34f42879644e84578eec0
  hostname: gpu024
  info:
    apply_time_ms: 2.475
    dispatch_time_ms: 5.279
    learner:
      cur_lr: 0.0003183759981766343
      grad_gnorm: 0.3724841773509979
      policy_entropy: 773.7482299804688
      policy_loss: -0.3101438581943512
      var_gnorm: 39.28045654296875
      vf_explained_var: -0.6804569959640503
      vf_loss: 0.00011195346451131627
    num_steps_sampled: 15680000
    num_steps_trained: 15680000
    wait_time_ms: 564.061
  iterations_since_restore: 392
  node_ip: 172.17.8.24
  num_metric_batches_dropped: 0
  pid: 26970
  policy_reward_mean: {}
  time_since_restore: 22149.798969745636
  time_this_iter_s: 56.65135908126831
  time_total_s: 22149.798969745636
  timestamp: 1594207149
  timesteps_since_restore: 15680000
  timesteps_this_iter: 40000
  timesteps_total: 15680000
  training_iteration: 392
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26970], 22149 s, 392 iter, 15680000 ts, 448 rew

agent-1: 15.0
agent-2: 18.0
agent-3: 8.0
agent-4: 5.0
agent-5: 12.0
agent-6: 11.0
agent-7: 6.0
agent-8: 12.0
agent-9: 12.0
agent-10: 13.0
agent-11: 13.0
agent-12: 10.0
agent-13: 11.0
agent-14: 3.0
agent-15: 9.0
agent-16: 9.0
agent-17: 6.0
agent-18: 7.0
agent-19: 5.0
agent-20: 12.0
agent-21: 8.0
agent-22: 9.0
agent-23: 14.0
agent-24: 11.0
agent-25: 8.0
agent-26: 10.0
agent-27: 11.0
agent-28: 11.0
agent-29: 11.0
agent-30: 11.0
agent-31: 15.0
agent-32: 14.0
agent-33: 13.0
agent-34: 12.0
agent-35: 14.0
agent-36: 14.0
agent-37: 13.0
agent-38: 16.0
agent-39: 14.0
agent-40: 14.0
Sum Reward: 440.0
Avg Reward: 11.0
Min Reward: 3.0
Max Reward: 18.0
Gini Coefficient: 0.16522727272727272
20:20 Ratio: 2.5
Max-min Ratio: 6.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-08_07-20-05
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 487.0
  episode_reward_mean: 447.75
  episode_reward_min: 392.0
  episodes_this_iter: 1
  episodes_total: 392
  experiment_id: 4e724eb5b3a34f42879644e84578eec0
  hostname: gpu024
  info:
    apply_time_ms: 2.635
    dispatch_time_ms: 5.916
    learner:
      cur_lr: 0.00031571200815960765
      grad_gnorm: 40.0
      policy_entropy: 325.18597412109375
      policy_loss: -0.5211243629455566
      var_gnorm: 39.28980255126953
      vf_explained_var: 0.4021676182746887
      vf_loss: 45.898048400878906
    num_steps_sampled: 15720000
    num_steps_trained: 15720000
    wait_time_ms: 520.012
  iterations_since_restore: 393
  node_ip: 172.17.8.24
  num_metric_batches_dropped: 0
  pid: 26970
  policy_reward_mean: {}
  time_since_restore: 22206.27591943741
  time_this_iter_s: 56.47694969177246
  time_total_s: 22206.27591943741
  timestamp: 1594207205
  timesteps_since_restore: 15720000
  timesteps_this_iter: 40000
  timesteps_total: 15720000
  training_iteration: 393
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26970], 22206 s, 393 iter, 15720000 ts, 448 rew

agent-1: 11.0
agent-2: 8.0
agent-3: 16.0
agent-4: 10.0
agent-5: 6.0
agent-6: 4.0
agent-7: 14.0
agent-8: 15.0
agent-9: 13.0
agent-10: 12.0
agent-11: 19.0
agent-12: 13.0
agent-13: 13.0
agent-14: 14.0
agent-15: 14.0
agent-16: 15.0
agent-17: 15.0
agent-18: 13.0
agent-19: 8.0
agent-20: 4.0
agent-21: 10.0
agent-22: 10.0
agent-23: 11.0
agent-24: 10.0
agent-25: 14.0
agent-26: 4.0
agent-27: 9.0
agent-28: 12.0
agent-29: 19.0
agent-30: 11.0
agent-31: 10.0
agent-32: 16.0
agent-33: 9.0
agent-34: 14.0
agent-35: 10.0
agent-36: 7.0
agent-37: 8.0
agent-38: 6.0
agent-39: 13.0
agent-40: 8.0
Sum Reward: 448.0
Avg Reward: 11.2
Min Reward: 4.0
Max Reward: 19.0
Gini Coefficient: 0.18761160714285716
20:20 Ratio: 2.74468085106383
Max-min Ratio: 4.75
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-08_07-21-02
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 487.0
  episode_reward_mean: 448.31
  episode_reward_min: 421.0
  episodes_this_iter: 1
  episodes_total: 393
  experiment_id: 4e724eb5b3a34f42879644e84578eec0
  hostname: gpu024
  info:
    apply_time_ms: 3.003
    dispatch_time_ms: 7.009
    learner:
      cur_lr: 0.00031304798903875053
      grad_gnorm: 0.6836814880371094
      policy_entropy: 775.18017578125
      policy_loss: -0.02379819005727768
      var_gnorm: 39.293941497802734
      vf_explained_var: -1.0
      vf_loss: 0.0001410205732099712
    num_steps_sampled: 15760000
    num_steps_trained: 15760000
    wait_time_ms: 553.983
  iterations_since_restore: 394
  node_ip: 172.17.8.24
  num_metric_batches_dropped: 0
  pid: 26970
  policy_reward_mean: {}
  time_since_restore: 22262.897013902664
  time_this_iter_s: 56.62109446525574
  time_total_s: 22262.897013902664
  timestamp: 1594207262
  timesteps_since_restore: 15760000
  timesteps_this_iter: 40000
  timesteps_total: 15760000
  training_iteration: 394
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26970], 22262 s, 394 iter, 15760000 ts, 448 rew

agent-1: 12.0
agent-2: 12.0
agent-3: 6.0
agent-4: 13.0
agent-5: 5.0
agent-6: 11.0
agent-7: 15.0
agent-8: 8.0
agent-9: 8.0
agent-10: 13.0
agent-11: 12.0
agent-12: 9.0
agent-13: 13.0
agent-14: 11.0
agent-15: 13.0
agent-16: 10.0
agent-17: 8.0
agent-18: 12.0
agent-19: 5.0
agent-20: 9.0
agent-21: 13.0
agent-22: 14.0
agent-23: 5.0
agent-24: 16.0
agent-25: 11.0
agent-26: 10.0
agent-27: 12.0
agent-28: 12.0
agent-29: 8.0
agent-30: 15.0
agent-31: 15.0
agent-32: 10.0
agent-33: 10.0
agent-34: 7.0
agent-35: 15.0
agent-36: 12.0
agent-37: 11.0
agent-38: 14.0
agent-39: 8.0
agent-40: 13.0
Sum Reward: 436.0
Avg Reward: 10.9
Min Reward: 5.0
Max Reward: 16.0
Gini Coefficient: 0.15172018348623853
20:20 Ratio: 2.25
Max-min Ratio: 3.2
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-08_07-21-58
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 487.0
  episode_reward_mean: 448.22
  episode_reward_min: 421.0
  episodes_this_iter: 1
  episodes_total: 394
  experiment_id: 4e724eb5b3a34f42879644e84578eec0
  hostname: gpu024
  info:
    apply_time_ms: 2.453
    dispatch_time_ms: 5.757
    learner:
      cur_lr: 0.00031038399902172387
      grad_gnorm: 39.999996185302734
      policy_entropy: 259.2768249511719
      policy_loss: -5.445298194885254
      var_gnorm: 39.29205322265625
      vf_explained_var: 0.5910772085189819
      vf_loss: 52.5713996887207
    num_steps_sampled: 15800000
    num_steps_trained: 15800000
    wait_time_ms: 502.024
  iterations_since_restore: 395
  node_ip: 172.17.8.24
  num_metric_batches_dropped: 0
  pid: 26970
  policy_reward_mean: {}
  time_since_restore: 22319.12667775154
  time_this_iter_s: 56.22966384887695
  time_total_s: 22319.12667775154
  timestamp: 1594207318
  timesteps_since_restore: 15800000
  timesteps_this_iter: 40000
  timesteps_total: 15800000
  training_iteration: 395
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26970], 22319 s, 395 iter, 15800000 ts, 448 rew

agent-1: 14.0
agent-2: 10.0
agent-3: 12.0
agent-4: 15.0
agent-5: 17.0
agent-6: 13.0
agent-7: 13.0
agent-8: 9.0
agent-9: 9.0
agent-10: 11.0
agent-11: 9.0
agent-12: 9.0
agent-13: 10.0
agent-14: 13.0
agent-15: 12.0
agent-16: 3.0
agent-17: 16.0
agent-18: 11.0
agent-19: 15.0
agent-20: 12.0
agent-21: 15.0
agent-22: 13.0
agent-23: 7.0
agent-24: 6.0
agent-25: 10.0
agent-26: 14.0
agent-27: 6.0
agent-28: 15.0
agent-29: 10.0
agent-30: 12.0
agent-31: 14.0
agent-32: 6.0
agent-33: 12.0
agent-34: 11.0
agent-35: 9.0
agent-36: 12.0
agent-37: 8.0
agent-38: 9.0
agent-39: 9.0
agent-40: 8.0
Sum Reward: 439.0
Avg Reward: 10.975
Min Reward: 3.0
Max Reward: 17.0
Gini Coefficient: 0.15802961275626423
20:20 Ratio: 2.2830188679245285
Max-min Ratio: 5.666666666666667
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-08_07-22-55
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 487.0
  episode_reward_mean: 447.98
  episode_reward_min: 421.0
  episodes_this_iter: 1
  episodes_total: 395
  experiment_id: 4e724eb5b3a34f42879644e84578eec0
  hostname: gpu024
  info:
    apply_time_ms: 2.504
    dispatch_time_ms: 6.518
    learner:
      cur_lr: 0.0003077200090046972
      grad_gnorm: 0.40357154607772827
      policy_entropy: 771.6836547851562
      policy_loss: -0.3051997423171997
      var_gnorm: 39.29936981201172
      vf_explained_var: -0.261438250541687
      vf_loss: 8.277977758552879e-05
    num_steps_sampled: 15840000
    num_steps_trained: 15840000
    wait_time_ms: 570.073
  iterations_since_restore: 396
  node_ip: 172.17.8.24
  num_metric_batches_dropped: 0
  pid: 26970
  policy_reward_mean: {}
  time_since_restore: 22376.017632722855
  time_this_iter_s: 56.89095497131348
  time_total_s: 22376.017632722855
  timestamp: 1594207375
  timesteps_since_restore: 15840000
  timesteps_this_iter: 40000
  timesteps_total: 15840000
  training_iteration: 396
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26970], 22376 s, 396 iter, 15840000 ts, 448 rew

agent-1: 10.0
agent-2: 17.0
agent-3: 11.0
agent-4: 8.0
agent-5: 10.0
agent-6: 9.0
agent-7: 12.0
agent-8: 14.0
agent-9: 17.0
agent-10: 4.0
agent-11: 11.0
agent-12: 15.0
agent-13: 10.0
agent-14: 11.0
agent-15: 10.0
agent-16: 10.0
agent-17: 16.0
agent-18: 9.0
agent-19: 8.0
agent-20: 13.0
agent-21: 7.0
agent-22: 5.0
agent-23: 11.0
agent-24: 10.0
agent-25: 13.0
agent-26: 3.0
agent-27: 8.0
agent-28: 15.0
agent-29: 12.0
agent-30: 8.0
agent-31: 8.0
agent-32: 15.0
agent-33: 8.0
agent-34: 12.0
agent-35: 11.0
agent-36: 14.0
agent-37: 14.0
agent-38: 10.0
agent-39: 11.0
agent-40: 11.0
Sum Reward: 431.0
Avg Reward: 10.775
Min Reward: 3.0
Max Reward: 17.0
Gini Coefficient: 0.166415313225058
20:20 Ratio: 2.411764705882353
Max-min Ratio: 5.666666666666667
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-08_07-23-51
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 487.0
  episode_reward_mean: 447.5
  episode_reward_min: 421.0
  episodes_this_iter: 1
  episodes_total: 396
  experiment_id: 4e724eb5b3a34f42879644e84578eec0
  hostname: gpu024
  info:
    apply_time_ms: 2.997
    dispatch_time_ms: 6.649
    learner:
      cur_lr: 0.0003050559898838401
      grad_gnorm: 39.9999885559082
      policy_entropy: 557.31005859375
      policy_loss: 6.744458198547363
      var_gnorm: 39.309146881103516
      vf_explained_var: 0.6461021304130554
      vf_loss: 28.121103286743164
    num_steps_sampled: 15880000
    num_steps_trained: 15880000
    wait_time_ms: 549.928
  iterations_since_restore: 397
  node_ip: 172.17.8.24
  num_metric_batches_dropped: 0
  pid: 26970
  policy_reward_mean: {}
  time_since_restore: 22432.331142425537
  time_this_iter_s: 56.313509702682495
  time_total_s: 22432.331142425537
  timestamp: 1594207431
  timesteps_since_restore: 15880000
  timesteps_this_iter: 40000
  timesteps_total: 15880000
  training_iteration: 397
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26970], 22432 s, 397 iter, 15880000 ts, 448 rew

agent-1: 10.0
agent-2: 10.0
agent-3: 9.0
agent-4: 13.0
agent-5: 11.0
agent-6: 13.0
agent-7: 5.0
agent-8: 9.0
agent-9: 8.0
agent-10: 12.0
agent-11: 10.0
agent-12: 13.0
agent-13: 16.0
agent-14: 10.0
agent-15: 14.0
agent-16: 12.0
agent-17: 11.0
agent-18: 7.0
agent-19: 12.0
agent-20: 5.0
agent-21: 12.0
agent-22: 11.0
agent-23: 19.0
agent-24: 11.0
agent-25: 13.0
agent-26: 13.0
agent-27: 8.0
agent-28: 17.0
agent-29: 9.0
agent-30: 19.0
agent-31: 8.0
agent-32: 4.0
agent-33: 11.0
agent-34: 10.0
agent-35: 15.0
agent-36: 7.0
agent-37: 8.0
agent-38: 11.0
agent-39: 6.0
agent-40: 10.0
Sum Reward: 432.0
Avg Reward: 10.8
Min Reward: 4.0
Max Reward: 19.0
Gini Coefficient: 0.1752314814814815
20:20 Ratio: 2.52
Max-min Ratio: 4.75
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-08_07-24-48
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 487.0
  episode_reward_mean: 447.18
  episode_reward_min: 421.0
  episodes_this_iter: 1
  episodes_total: 397
  experiment_id: 4e724eb5b3a34f42879644e84578eec0
  hostname: gpu024
  info:
    apply_time_ms: 2.438
    dispatch_time_ms: 6.801
    learner:
      cur_lr: 0.0003023919998668134
      grad_gnorm: 0.1852976679801941
      policy_entropy: 774.6134033203125
      policy_loss: 0.08000101149082184
      var_gnorm: 39.32908248901367
      vf_explained_var: -1.0
      vf_loss: 2.2929867554921657e-05
    num_steps_sampled: 15920000
    num_steps_trained: 15920000
    wait_time_ms: 564.296
  iterations_since_restore: 398
  node_ip: 172.17.8.24
  num_metric_batches_dropped: 0
  pid: 26970
  policy_reward_mean: {}
  time_since_restore: 22488.97110581398
  time_this_iter_s: 56.63996338844299
  time_total_s: 22488.97110581398
  timestamp: 1594207488
  timesteps_since_restore: 15920000
  timesteps_this_iter: 40000
  timesteps_total: 15920000
  training_iteration: 398
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26970], 22488 s, 398 iter, 15920000 ts, 447 rew

agent-1: 12.0
agent-2: 12.0
agent-3: 7.0
agent-4: 24.0
agent-5: 9.0
agent-6: 7.0
agent-7: 4.0
agent-8: 15.0
agent-9: 12.0
agent-10: 13.0
agent-11: 6.0
agent-12: 10.0
agent-13: 11.0
agent-14: 13.0
agent-15: 6.0
agent-16: 11.0
agent-17: 12.0
agent-18: 15.0
agent-19: 9.0
agent-20: 4.0
agent-21: 9.0
agent-22: 11.0
agent-23: 11.0
agent-24: 7.0
agent-25: 12.0
agent-26: 9.0
agent-27: 11.0
agent-28: 6.0
agent-29: 11.0
agent-30: 15.0
agent-31: 15.0
agent-32: 17.0
agent-33: 11.0
agent-34: 12.0
agent-35: 9.0
agent-36: 9.0
agent-37: 14.0
agent-38: 10.0
agent-39: 16.0
agent-40: 5.0
Sum Reward: 432.0
Avg Reward: 10.8
Min Reward: 4.0
Max Reward: 24.0
Gini Coefficient: 0.19363425925925926
20:20 Ratio: 2.911111111111111
Max-min Ratio: 6.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-08_07-25-44
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 487.0
  episode_reward_mean: 446.95
  episode_reward_min: 421.0
  episodes_this_iter: 1
  episodes_total: 398
  experiment_id: 4e724eb5b3a34f42879644e84578eec0
  hostname: gpu024
  info:
    apply_time_ms: 2.712
    dispatch_time_ms: 6.179
    learner:
      cur_lr: 0.00029972800984978676
      grad_gnorm: 39.99999237060547
      policy_entropy: 562.383544921875
      policy_loss: 9.790251731872559
      var_gnorm: 39.32848358154297
      vf_explained_var: 0.4896177649497986
      vf_loss: 14.696002006530762
    num_steps_sampled: 15960000
    num_steps_trained: 15960000
    wait_time_ms: 531.556
  iterations_since_restore: 399
  node_ip: 172.17.8.24
  num_metric_batches_dropped: 0
  pid: 26970
  policy_reward_mean: {}
  time_since_restore: 22545.032433986664
  time_this_iter_s: 56.061328172683716
  time_total_s: 22545.032433986664
  timestamp: 1594207544
  timesteps_since_restore: 15960000
  timesteps_this_iter: 40000
  timesteps_total: 15960000
  training_iteration: 399
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26970], 22545 s, 399 iter, 15960000 ts, 447 rew

agent-1: 15.0
agent-2: 9.0
agent-3: 12.0
agent-4: 12.0
agent-5: 12.0
agent-6: 7.0
agent-7: 7.0
agent-8: 14.0
agent-9: 12.0
agent-10: 14.0
agent-11: 9.0
agent-12: 12.0
agent-13: 14.0
agent-14: 13.0
agent-15: 11.0
agent-16: 8.0
agent-17: 13.0
agent-18: 11.0
agent-19: 15.0
agent-20: 5.0
agent-21: 14.0
agent-22: 6.0
agent-23: 9.0
agent-24: 10.0
agent-25: 9.0
agent-26: 15.0
agent-27: 14.0
agent-28: 9.0
agent-29: 8.0
agent-30: 8.0
agent-31: 11.0
agent-32: 7.0
agent-33: 15.0
agent-34: 16.0
agent-35: 9.0
agent-36: 11.0
agent-37: 13.0
agent-38: 10.0
agent-39: 6.0
agent-40: 6.0
Sum Reward: 431.0
Avg Reward: 10.775
Min Reward: 5.0
Max Reward: 16.0
Gini Coefficient: 0.15980278422273783
20:20 Ratio: 2.269230769230769
Max-min Ratio: 3.2
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-08_07-26-41
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 487.0
  episode_reward_mean: 446.71
  episode_reward_min: 421.0
  episodes_this_iter: 1
  episodes_total: 399
  experiment_id: 4e724eb5b3a34f42879644e84578eec0
  hostname: gpu024
  info:
    apply_time_ms: 2.725
    dispatch_time_ms: 5.835
    learner:
      cur_lr: 0.00029706399072892964
      grad_gnorm: 0.2856592535972595
      policy_entropy: 777.19384765625
      policy_loss: 0.10355103760957718
      var_gnorm: 39.33726119995117
      vf_explained_var: -1.0
      vf_loss: 0.0008826425182633102
    num_steps_sampled: 16000000
    num_steps_trained: 16000000
    wait_time_ms: 560.225
  iterations_since_restore: 400
  node_ip: 172.17.8.24
  num_metric_batches_dropped: 0
  pid: 26970
  policy_reward_mean: {}
  time_since_restore: 22601.490563631058
  time_this_iter_s: 56.45812964439392
  time_total_s: 22601.490563631058
  timestamp: 1594207601
  timesteps_since_restore: 16000000
  timesteps_this_iter: 40000
  timesteps_total: 16000000
  training_iteration: 400
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26970], 22601 s, 400 iter, 16000000 ts, 447 rew

agent-1: 10.0
agent-2: 9.0
agent-3: 11.0
agent-4: 13.0
agent-5: 5.0
agent-6: 17.0
agent-7: 14.0
agent-8: 11.0
agent-9: 6.0
agent-10: 15.0
agent-11: 6.0
agent-12: 7.0
agent-13: 9.0
agent-14: 13.0
agent-15: 11.0
agent-16: 7.0
agent-17: 8.0
agent-18: 13.0
agent-19: 13.0
agent-20: 12.0
agent-21: 13.0
agent-22: 5.0
agent-23: 10.0
agent-24: 10.0
agent-25: 13.0
agent-26: 13.0
agent-27: 11.0
agent-28: 12.0
agent-29: 10.0
agent-30: 14.0
agent-31: 11.0
agent-32: 19.0
agent-33: 18.0
agent-34: 10.0
agent-35: 14.0
agent-36: 12.0
agent-37: 13.0
agent-38: 9.0
agent-39: 14.0
agent-40: 12.0
Sum Reward: 453.0
Avg Reward: 11.325
Min Reward: 5.0
Max Reward: 19.0
Gini Coefficient: 0.15733995584988963
20:20 Ratio: 2.358490566037736
Max-min Ratio: 3.8
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-08_07-27-37
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 482.0
  episode_reward_mean: 446.37
  episode_reward_min: 421.0
  episodes_this_iter: 1
  episodes_total: 400
  experiment_id: 4e724eb5b3a34f42879644e84578eec0
  hostname: gpu024
  info:
    apply_time_ms: 2.589
    dispatch_time_ms: 5.986
    learner:
      cur_lr: 0.000294400000711903
      grad_gnorm: 0.5956249237060547
      policy_entropy: 777.4720458984375
      policy_loss: -0.8518582582473755
      var_gnorm: 39.333919525146484
      vf_explained_var: -0.973310112953186
      vf_loss: 0.00019391649402678013
    num_steps_sampled: 16040000
    num_steps_trained: 16040000
    wait_time_ms: 552.174
  iterations_since_restore: 401
  node_ip: 172.17.8.24
  num_metric_batches_dropped: 0
  pid: 26970
  policy_reward_mean: {}
  time_since_restore: 22658.28827404976
  time_this_iter_s: 56.79771041870117
  time_total_s: 22658.28827404976
  timestamp: 1594207657
  timesteps_since_restore: 16040000
  timesteps_this_iter: 40000
  timesteps_total: 16040000
  training_iteration: 401
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26970], 22658 s, 401 iter, 16040000 ts, 446 rew

agent-1: 11.0
agent-2: 7.0
agent-3: 14.0
agent-4: 7.0
agent-5: 13.0
agent-6: 14.0
agent-7: 9.0
agent-8: 11.0
agent-9: 6.0
agent-10: 9.0
agent-11: 13.0
agent-12: 10.0
agent-13: 13.0
agent-14: 7.0
agent-15: 5.0
agent-16: 10.0
agent-17: 13.0
agent-18: 13.0
agent-19: 7.0
agent-20: 13.0
agent-21: 18.0
agent-22: 16.0
agent-23: 14.0
agent-24: 8.0
agent-25: 15.0
agent-26: 17.0
agent-27: 13.0
agent-28: 12.0
agent-29: 9.0
agent-30: 11.0
agent-31: 7.0
agent-32: 9.0
agent-33: 10.0
agent-34: 8.0
agent-35: 9.0
agent-36: 12.0
agent-37: 18.0
agent-38: 7.0
agent-39: 7.0
agent-40: 11.0
Sum Reward: 436.0
Avg Reward: 10.9
Min Reward: 5.0
Max Reward: 18.0
Gini Coefficient: 0.17339449541284405
20:20 Ratio: 2.3773584905660377
Max-min Ratio: 3.6
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-08_07-28-34
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 482.0
  episode_reward_mean: 446.19
  episode_reward_min: 421.0
  episodes_this_iter: 1
  episodes_total: 401
  experiment_id: 4e724eb5b3a34f42879644e84578eec0
  hostname: gpu024
  info:
    apply_time_ms: 2.589
    dispatch_time_ms: 5.654
    learner:
      cur_lr: 0.0002917360106948763
      grad_gnorm: 0.18189777433872223
      policy_entropy: 774.5416870117188
      policy_loss: 0.2823998034000397
      var_gnorm: 39.3372802734375
      vf_explained_var: -0.508953332901001
      vf_loss: 0.0001867510873125866
    num_steps_sampled: 16080000
    num_steps_trained: 16080000
    wait_time_ms: 569.132
  iterations_since_restore: 402
  node_ip: 172.17.8.24
  num_metric_batches_dropped: 0
  pid: 26970
  policy_reward_mean: {}
  time_since_restore: 22714.71158671379
  time_this_iter_s: 56.42331266403198
  time_total_s: 22714.71158671379
  timestamp: 1594207714
  timesteps_since_restore: 16080000
  timesteps_this_iter: 40000
  timesteps_total: 16080000
  training_iteration: 402
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26970], 22714 s, 402 iter, 16080000 ts, 446 rew

agent-1: 14.0
agent-2: 14.0
agent-3: 15.0
agent-4: 11.0
agent-5: 11.0
agent-6: 9.0
agent-7: 18.0
agent-8: 13.0
agent-9: 10.0
agent-10: 8.0
agent-11: 13.0
agent-12: 8.0
agent-13: 16.0
agent-14: 15.0
agent-15: 5.0
agent-16: 18.0
agent-17: 9.0
agent-18: 10.0
agent-19: 9.0
agent-20: 11.0
agent-21: 11.0
agent-22: 10.0
agent-23: 7.0
agent-24: 13.0
agent-25: 11.0
agent-26: 13.0
agent-27: 9.0
agent-28: 5.0
agent-29: 7.0
agent-30: 5.0
agent-31: 8.0
agent-32: 8.0
agent-33: 15.0
agent-34: 7.0
agent-35: 9.0
agent-36: 13.0
agent-37: 9.0
agent-38: 12.0
agent-39: 6.0
agent-40: 17.0
Sum Reward: 432.0
Avg Reward: 10.8
Min Reward: 5.0
Max Reward: 18.0
Gini Coefficient: 0.1837962962962963
20:20 Ratio: 2.56
Max-min Ratio: 3.6
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-08_07-29-31
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 482.0
  episode_reward_mean: 445.85
  episode_reward_min: 421.0
  episodes_this_iter: 1
  episodes_total: 402
  experiment_id: 4e724eb5b3a34f42879644e84578eec0
  hostname: gpu024
  info:
    apply_time_ms: 2.803
    dispatch_time_ms: 6.175
    learner:
      cur_lr: 0.0002890719915740192
      grad_gnorm: 0.9435340166091919
      policy_entropy: 776.9909057617188
      policy_loss: 0.1775675117969513
      var_gnorm: 39.34410858154297
      vf_explained_var: -0.26239824295043945
      vf_loss: 0.0001393181155435741
    num_steps_sampled: 16120000
    num_steps_trained: 16120000
    wait_time_ms: 548.921
  iterations_since_restore: 403
  node_ip: 172.17.8.24
  num_metric_batches_dropped: 0
  pid: 26970
  policy_reward_mean: {}
  time_since_restore: 22771.254653930664
  time_this_iter_s: 56.54306721687317
  time_total_s: 22771.254653930664
  timestamp: 1594207771
  timesteps_since_restore: 16120000
  timesteps_this_iter: 40000
  timesteps_total: 16120000
  training_iteration: 403
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26970], 22771 s, 403 iter, 16120000 ts, 446 rew

agent-1: 15.0
agent-2: 4.0
agent-3: 14.0
agent-4: 10.0
agent-5: 8.0
agent-6: 12.0
agent-7: 13.0
agent-8: 11.0
agent-9: 13.0
agent-10: 12.0
agent-11: 8.0
agent-12: 10.0
agent-13: 7.0
agent-14: 5.0
agent-15: 12.0
agent-16: 12.0
agent-17: 11.0
agent-18: 16.0
agent-19: 6.0
agent-20: 12.0
agent-21: 7.0
agent-22: 10.0
agent-23: 13.0
agent-24: 6.0
agent-25: 11.0
agent-26: 17.0
agent-27: 15.0
agent-28: 12.0
agent-29: 11.0
agent-30: 11.0
agent-31: 11.0
agent-32: 13.0
agent-33: 10.0
agent-34: 14.0
agent-35: 14.0
agent-36: 8.0
agent-37: 14.0
agent-38: 9.0
agent-39: 9.0
agent-40: 17.0
Sum Reward: 443.0
Avg Reward: 11.075
Min Reward: 4.0
Max Reward: 17.0
Gini Coefficient: 0.1595372460496614
20:20 Ratio: 2.392156862745098
Max-min Ratio: 4.25
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-08_07-30-27
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 482.0
  episode_reward_mean: 445.68
  episode_reward_min: 421.0
  episodes_this_iter: 1
  episodes_total: 403
  experiment_id: 4e724eb5b3a34f42879644e84578eec0
  hostname: gpu024
  info:
    apply_time_ms: 3.268
    dispatch_time_ms: 7.269
    learner:
      cur_lr: 0.00028640800155699253
      grad_gnorm: 0.23684462904930115
      policy_entropy: 774.0885009765625
      policy_loss: 0.2915384769439697
      var_gnorm: 39.33796310424805
      vf_explained_var: -0.7730860710144043
      vf_loss: 0.00011398112110327929
    num_steps_sampled: 16160000
    num_steps_trained: 16160000
    wait_time_ms: 564.652
  iterations_since_restore: 404
  node_ip: 172.17.8.24
  num_metric_batches_dropped: 0
  pid: 26970
  policy_reward_mean: {}
  time_since_restore: 22827.674869775772
  time_this_iter_s: 56.42021584510803
  time_total_s: 22827.674869775772
  timestamp: 1594207827
  timesteps_since_restore: 16160000
  timesteps_this_iter: 40000
  timesteps_total: 16160000
  training_iteration: 404
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26970], 22827 s, 404 iter, 16160000 ts, 446 rew

agent-1: 6.0
agent-2: 13.0
agent-3: 14.0
agent-4: 13.0
agent-5: 13.0
agent-6: 8.0
agent-7: 7.0
agent-8: 8.0
agent-9: 10.0
agent-10: 7.0
agent-11: 14.0
agent-12: 7.0
agent-13: 12.0
agent-14: 14.0
agent-15: 13.0
agent-16: 8.0
agent-17: 10.0
agent-18: 8.0
agent-19: 5.0
agent-20: 8.0
agent-21: 18.0
agent-22: 6.0
agent-23: 9.0
agent-24: 9.0
agent-25: 16.0
agent-26: 6.0
agent-27: 16.0
agent-28: 17.0
agent-29: 10.0
agent-30: 15.0
agent-31: 14.0
agent-32: 5.0
agent-33: 13.0
agent-34: 14.0
agent-35: 11.0
agent-36: 11.0
agent-37: 15.0
agent-38: 17.0
agent-39: 12.0
agent-40: 13.0
Sum Reward: 445.0
Avg Reward: 11.125
Min Reward: 5.0
Max Reward: 18.0
Gini Coefficient: 0.18634831460674156
20:20 Ratio: 2.6122448979591835
Max-min Ratio: 3.6
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-08_07-31-24
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 482.0
  episode_reward_mean: 445.69
  episode_reward_min: 421.0
  episodes_this_iter: 1
  episodes_total: 404
  experiment_id: 4e724eb5b3a34f42879644e84578eec0
  hostname: gpu024
  info:
    apply_time_ms: 2.487
    dispatch_time_ms: 7.6
    learner:
      cur_lr: 0.00028374401153996587
      grad_gnorm: 39.999996185302734
      policy_entropy: 510.63299560546875
      policy_loss: 45.24839782714844
      var_gnorm: 39.33158874511719
      vf_explained_var: 0.7793311476707458
      vf_loss: 22.597793579101562
    num_steps_sampled: 16200000
    num_steps_trained: 16200000
    wait_time_ms: 527.106
  iterations_since_restore: 405
  node_ip: 172.17.8.24
  num_metric_batches_dropped: 0
  pid: 26970
  policy_reward_mean: {}
  time_since_restore: 22884.267147779465
  time_this_iter_s: 56.59227800369263
  time_total_s: 22884.267147779465
  timestamp: 1594207884
  timesteps_since_restore: 16200000
  timesteps_this_iter: 40000
  timesteps_total: 16200000
  training_iteration: 405
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26970], 22884 s, 405 iter, 16200000 ts, 446 rew

agent-1: 13.0
agent-2: 11.0
agent-3: 10.0
agent-4: 9.0
agent-5: 10.0
agent-6: 12.0
agent-7: 7.0
agent-8: 8.0
agent-9: 14.0
agent-10: 12.0
agent-11: 14.0
agent-12: 8.0
agent-13: 14.0
agent-14: 5.0
agent-15: 11.0
agent-16: 8.0
agent-17: 5.0
agent-18: 10.0
agent-19: 12.0
agent-20: 16.0
agent-21: 5.0
agent-22: 11.0
agent-23: 17.0
agent-24: 14.0
agent-25: 13.0
agent-26: 16.0
agent-27: 12.0
agent-28: 10.0
agent-29: 12.0
agent-30: 11.0
agent-31: 12.0
agent-32: 8.0
agent-33: 11.0
agent-34: 14.0
agent-35: 18.0
agent-36: 7.0
agent-37: 13.0
agent-38: 14.0
agent-39: 5.0
agent-40: 12.0
Sum Reward: 444.0
Avg Reward: 11.1
Min Reward: 5.0
Max Reward: 18.0
Gini Coefficient: 0.16554054054054054
20:20 Ratio: 2.46
Max-min Ratio: 3.6
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-08_07-32-20
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 482.0
  episode_reward_mean: 445.49
  episode_reward_min: 421.0
  episodes_this_iter: 1
  episodes_total: 405
  experiment_id: 4e724eb5b3a34f42879644e84578eec0
  hostname: gpu024
  info:
    apply_time_ms: 2.68
    dispatch_time_ms: 5.711
    learner:
      cur_lr: 0.00028107999241910875
      grad_gnorm: 0.4350005090236664
      policy_entropy: 771.9385375976562
      policy_loss: 0.1423063725233078
      var_gnorm: 39.35044479370117
      vf_explained_var: -0.7718491554260254
      vf_loss: 6.558710447279736e-05
    num_steps_sampled: 16240000
    num_steps_trained: 16240000
    wait_time_ms: 560.131
  iterations_since_restore: 406
  node_ip: 172.17.8.24
  num_metric_batches_dropped: 0
  pid: 26970
  policy_reward_mean: {}
  time_since_restore: 22940.841854572296
  time_this_iter_s: 56.57470679283142
  time_total_s: 22940.841854572296
  timestamp: 1594207940
  timesteps_since_restore: 16240000
  timesteps_this_iter: 40000
  timesteps_total: 16240000
  training_iteration: 406
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26970], 22940 s, 406 iter, 16240000 ts, 445 rew

agent-1: 14.0
agent-2: 11.0
agent-3: 7.0
agent-4: 15.0
agent-5: 11.0
agent-6: 10.0
agent-7: 12.0
agent-8: 12.0
agent-9: 14.0
agent-10: 11.0
agent-11: 13.0
agent-12: 11.0
agent-13: 10.0
agent-14: 10.0
agent-15: 20.0
agent-16: 9.0
agent-17: 14.0
agent-18: 10.0
agent-19: 10.0
agent-20: 14.0
agent-21: 18.0
agent-22: 8.0
agent-23: 15.0
agent-24: 9.0
agent-25: 6.0
agent-26: 12.0
agent-27: 13.0
agent-28: 11.0
agent-29: 11.0
agent-30: 16.0
agent-31: 10.0
agent-32: 11.0
agent-33: 8.0
agent-34: 11.0
agent-35: 3.0
agent-36: 13.0
agent-37: 12.0
agent-38: 12.0
agent-39: 17.0
agent-40: 10.0
Sum Reward: 464.0
Avg Reward: 11.6
Min Reward: 3.0
Max Reward: 20.0
Gini Coefficient: 0.1473060344827586
20:20 Ratio: 2.15
Max-min Ratio: 6.666666666666667
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-08_07-33-17
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 482.0
  episode_reward_mean: 445.53
  episode_reward_min: 421.0
  episodes_this_iter: 1
  episodes_total: 406
  experiment_id: 4e724eb5b3a34f42879644e84578eec0
  hostname: gpu024
  info:
    apply_time_ms: 2.799
    dispatch_time_ms: 6.54
    learner:
      cur_lr: 0.0002784160024020821
      grad_gnorm: 0.7314578890800476
      policy_entropy: 773.4385375976562
      policy_loss: -0.2866065204143524
      var_gnorm: 39.36561965942383
      vf_explained_var: -0.09803736209869385
      vf_loss: 8.680877363076434e-05
    num_steps_sampled: 16280000
    num_steps_trained: 16280000
    wait_time_ms: 562.128
  iterations_since_restore: 407
  node_ip: 172.17.8.24
  num_metric_batches_dropped: 0
  pid: 26970
  policy_reward_mean: {}
  time_since_restore: 22997.421661376953
  time_this_iter_s: 56.57980680465698
  time_total_s: 22997.421661376953
  timestamp: 1594207997
  timesteps_since_restore: 16280000
  timesteps_this_iter: 40000
  timesteps_total: 16280000
  training_iteration: 407
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26970], 22997 s, 407 iter, 16280000 ts, 446 rew

agent-1: 12.0
agent-2: 6.0
agent-3: 18.0
agent-4: 6.0
agent-5: 9.0
agent-6: 15.0
agent-7: 13.0
agent-8: 12.0
agent-9: 13.0
agent-10: 12.0
agent-11: 15.0
agent-12: 14.0
agent-13: 11.0
agent-14: 10.0
agent-15: 7.0
agent-16: 14.0
agent-17: 16.0
agent-18: 13.0
agent-19: 8.0
agent-20: 6.0
agent-21: 12.0
agent-22: 11.0
agent-23: 13.0
agent-24: 7.0
agent-25: 9.0
agent-26: 13.0
agent-27: 13.0
agent-28: 8.0
agent-29: 6.0
agent-30: 15.0
agent-31: 10.0
agent-32: 16.0
agent-33: 17.0
agent-34: 9.0
agent-35: 12.0
agent-36: 14.0
agent-37: 10.0
agent-38: 7.0
agent-39: 4.0
agent-40: 9.0
Sum Reward: 445.0
Avg Reward: 11.125
Min Reward: 4.0
Max Reward: 18.0
Gini Coefficient: 0.17623595505617978
20:20 Ratio: 2.5714285714285716
Max-min Ratio: 4.5
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-08_07-34-13
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 482.0
  episode_reward_mean: 445.44
  episode_reward_min: 421.0
  episodes_this_iter: 1
  episodes_total: 407
  experiment_id: 4e724eb5b3a34f42879644e84578eec0
  hostname: gpu024
  info:
    apply_time_ms: 2.901
    dispatch_time_ms: 5.8
    learner:
      cur_lr: 0.0002757520123850554
      grad_gnorm: 2.2447316646575928
      policy_entropy: 768.0267333984375
      policy_loss: -0.17018648982048035
      var_gnorm: 39.383567810058594
      vf_explained_var: -1.0
      vf_loss: 0.0674176886677742
    num_steps_sampled: 16320000
    num_steps_trained: 16320000
    wait_time_ms: 569.768
  iterations_since_restore: 408
  node_ip: 172.17.8.24
  num_metric_batches_dropped: 0
  pid: 26970
  policy_reward_mean: {}
  time_since_restore: 23053.859619617462
  time_this_iter_s: 56.43795824050903
  time_total_s: 23053.859619617462
  timestamp: 1594208053
  timesteps_since_restore: 16320000
  timesteps_this_iter: 40000
  timesteps_total: 16320000
  training_iteration: 408
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26970], 23053 s, 408 iter, 16320000 ts, 445 rew

agent-1: 15.0
agent-2: 12.0
agent-3: 7.0
agent-4: 13.0
agent-5: 12.0
agent-6: 8.0
agent-7: 13.0
agent-8: 18.0
agent-9: 7.0
agent-10: 13.0
agent-11: 11.0
agent-12: 18.0
agent-13: 10.0
agent-14: 9.0
agent-15: 16.0
agent-16: 11.0
agent-17: 16.0
agent-18: 10.0
agent-19: 10.0
agent-20: 12.0
agent-21: 9.0
agent-22: 11.0
agent-23: 7.0
agent-24: 9.0
agent-25: 9.0
agent-26: 13.0
agent-27: 9.0
agent-28: 11.0
agent-29: 7.0
agent-30: 13.0
agent-31: 12.0
agent-32: 16.0
agent-33: 15.0
agent-34: 16.0
agent-35: 6.0
agent-36: 18.0
agent-37: 9.0
agent-38: 16.0
agent-39: 10.0
agent-40: 8.0
Sum Reward: 465.0
Avg Reward: 11.625
Min Reward: 6.0
Max Reward: 18.0
Gini Coefficient: 0.16338709677419355
20:20 Ratio: 2.2711864406779663
Max-min Ratio: 3.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-08_07-35-10
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 482.0
  episode_reward_mean: 445.54
  episode_reward_min: 421.0
  episodes_this_iter: 1
  episodes_total: 408
  experiment_id: 4e724eb5b3a34f42879644e84578eec0
  hostname: gpu024
  info:
    apply_time_ms: 2.47
    dispatch_time_ms: 6.31
    learner:
      cur_lr: 0.0002730879932641983
      grad_gnorm: 20.81963539123535
      policy_entropy: 597.7938232421875
      policy_loss: -1.9617393016815186
      var_gnorm: 39.37031555175781
      vf_explained_var: 0.7916635274887085
      vf_loss: 2.7391955852508545
    num_steps_sampled: 16360000
    num_steps_trained: 16360000
    wait_time_ms: 521.279
  iterations_since_restore: 409
  node_ip: 172.17.8.24
  num_metric_batches_dropped: 0
  pid: 26970
  policy_reward_mean: {}
  time_since_restore: 23110.364357471466
  time_this_iter_s: 56.504737854003906
  time_total_s: 23110.364357471466
  timestamp: 1594208110
  timesteps_since_restore: 16360000
  timesteps_this_iter: 40000
  timesteps_total: 16360000
  training_iteration: 409
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26970], 23110 s, 409 iter, 16360000 ts, 446 rew

agent-1: 9.0
agent-2: 14.0
agent-3: 11.0
agent-4: 5.0
agent-5: 11.0
agent-6: 7.0
agent-7: 10.0
agent-8: 13.0
agent-9: 7.0
agent-10: 14.0
agent-11: 5.0
agent-12: 13.0
agent-13: 12.0
agent-14: 11.0
agent-15: 18.0
agent-16: 14.0
agent-17: 8.0
agent-18: 11.0
agent-19: 16.0
agent-20: 7.0
agent-21: 8.0
agent-22: 9.0
agent-23: 17.0
agent-24: 12.0
agent-25: 10.0
agent-26: 10.0
agent-27: 11.0
agent-28: 6.0
agent-29: 9.0
agent-30: 10.0
agent-31: 11.0
agent-32: 9.0
agent-33: 11.0
agent-34: 13.0
agent-35: 7.0
agent-36: 12.0
agent-37: 14.0
agent-38: 10.0
agent-39: 17.0
agent-40: 11.0
Sum Reward: 433.0
Avg Reward: 10.825
Min Reward: 5.0
Max Reward: 18.0
Gini Coefficient: 0.16287528868360276
20:20 Ratio: 2.3846153846153846
Max-min Ratio: 3.6
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-08_07-36-07
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 482.0
  episode_reward_mean: 445.22
  episode_reward_min: 421.0
  episodes_this_iter: 1
  episodes_total: 409
  experiment_id: 4e724eb5b3a34f42879644e84578eec0
  hostname: gpu024
  info:
    apply_time_ms: 2.958
    dispatch_time_ms: 6.795
    learner:
      cur_lr: 0.00027042400324717164
      grad_gnorm: 0.906387448310852
      policy_entropy: 762.5969848632812
      policy_loss: 0.03513003885746002
      var_gnorm: 39.36424255371094
      vf_explained_var: -0.834949254989624
      vf_loss: 0.0002182390890084207
    num_steps_sampled: 16400000
    num_steps_trained: 16400000
    wait_time_ms: 547.203
  iterations_since_restore: 410
  node_ip: 172.17.8.24
  num_metric_batches_dropped: 0
  pid: 26970
  policy_reward_mean: {}
  time_since_restore: 23167.159518003464
  time_this_iter_s: 56.79516053199768
  time_total_s: 23167.159518003464
  timestamp: 1594208167
  timesteps_since_restore: 16400000
  timesteps_this_iter: 40000
  timesteps_total: 16400000
  training_iteration: 410
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26970], 23167 s, 410 iter, 16400000 ts, 445 rew

agent-1: 9.0
agent-2: 16.0
agent-3: 13.0
agent-4: 13.0
agent-5: 7.0
agent-6: 10.0
agent-7: 9.0
agent-8: 16.0
agent-9: 6.0
agent-10: 7.0
agent-11: 10.0
agent-12: 8.0
agent-13: 17.0
agent-14: 13.0
agent-15: 14.0
agent-16: 10.0
agent-17: 11.0
agent-18: 7.0
agent-19: 5.0
agent-20: 9.0
agent-21: 15.0
agent-22: 7.0
agent-23: 11.0
agent-24: 11.0
agent-25: 11.0
agent-26: 12.0
agent-27: 14.0
agent-28: 10.0
agent-29: 12.0
agent-30: 16.0
agent-31: 8.0
agent-32: 10.0
agent-33: 14.0
agent-34: 12.0
agent-35: 15.0
agent-36: 9.0
agent-37: 9.0
agent-38: 19.0
agent-39: 8.0
agent-40: 15.0
Sum Reward: 448.0
Avg Reward: 11.2
Min Reward: 5.0
Max Reward: 19.0
Gini Coefficient: 0.16852678571428573
20:20 Ratio: 2.3454545454545452
Max-min Ratio: 3.8
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-08_07-37-03
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 482.0
  episode_reward_mean: 444.98
  episode_reward_min: 421.0
  episodes_this_iter: 1
  episodes_total: 410
  experiment_id: 4e724eb5b3a34f42879644e84578eec0
  hostname: gpu024
  info:
    apply_time_ms: 3.089
    dispatch_time_ms: 7.18
    learner:
      cur_lr: 0.000267760013230145
      grad_gnorm: 0.3786975145339966
      policy_entropy: 767.814208984375
      policy_loss: 0.039196498692035675
      var_gnorm: 39.372562408447266
      vf_explained_var: -0.5546426773071289
      vf_loss: 2.6802679713000543e-05
    num_steps_sampled: 16440000
    num_steps_trained: 16440000
    wait_time_ms: 560.64
  iterations_since_restore: 411
  node_ip: 172.17.8.24
  num_metric_batches_dropped: 0
  pid: 26970
  policy_reward_mean: {}
  time_since_restore: 23223.32804083824
  time_this_iter_s: 56.16852283477783
  time_total_s: 23223.32804083824
  timestamp: 1594208223
  timesteps_since_restore: 16440000
  timesteps_this_iter: 40000
  timesteps_total: 16440000
  training_iteration: 411
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26970], 23223 s, 411 iter, 16440000 ts, 445 rew

agent-1: 13.0
agent-2: 11.0
agent-3: 5.0
agent-4: 17.0
agent-5: 12.0
agent-6: 12.0
agent-7: 12.0
agent-8: 8.0
agent-9: 12.0
agent-10: 7.0
agent-11: 9.0
agent-12: 14.0
agent-13: 10.0
agent-14: 9.0
agent-15: 10.0
agent-16: 5.0
agent-17: 9.0
agent-18: 11.0
agent-19: 12.0
agent-20: 9.0
agent-21: 9.0
agent-22: 13.0
agent-23: 14.0
agent-24: 8.0
agent-25: 8.0
agent-26: 14.0
agent-27: 12.0
agent-28: 18.0
agent-29: 18.0
agent-30: 10.0
agent-31: 14.0
agent-32: 7.0
agent-33: 16.0
agent-34: 16.0
agent-35: 7.0
agent-36: 9.0
agent-37: 14.0
agent-38: 10.0
agent-39: 11.0
agent-40: 13.0
Sum Reward: 448.0
Avg Reward: 11.2
Min Reward: 5.0
Max Reward: 18.0
Gini Coefficient: 0.16350446428571427
20:20 Ratio: 2.309090909090909
Max-min Ratio: 3.6
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-08_07-37-59
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 482.0
  episode_reward_mean: 445.02
  episode_reward_min: 421.0
  episodes_this_iter: 1
  episodes_total: 411
  experiment_id: 4e724eb5b3a34f42879644e84578eec0
  hostname: gpu024
  info:
    apply_time_ms: 2.74
    dispatch_time_ms: 7.349
    learner:
      cur_lr: 0.00026509599410928786
      grad_gnorm: 2.5574240684509277
      policy_entropy: 769.9207153320312
      policy_loss: -0.6243262887001038
      var_gnorm: 39.37229919433594
      vf_explained_var: -1.0
      vf_loss: 0.07573781907558441
    num_steps_sampled: 16480000
    num_steps_trained: 16480000
    wait_time_ms: 560.84
  iterations_since_restore: 412
  node_ip: 172.17.8.24
  num_metric_batches_dropped: 0
  pid: 26970
  policy_reward_mean: {}
  time_since_restore: 23279.695509433746
  time_this_iter_s: 56.36746859550476
  time_total_s: 23279.695509433746
  timestamp: 1594208279
  timesteps_since_restore: 16480000
  timesteps_this_iter: 40000
  timesteps_total: 16480000
  training_iteration: 412
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26970], 23279 s, 412 iter, 16480000 ts, 445 rew

agent-1: 8.0
agent-2: 6.0
agent-3: 8.0
agent-4: 16.0
agent-5: 7.0
agent-6: 9.0
agent-7: 16.0
agent-8: 9.0
agent-9: 7.0
agent-10: 17.0
agent-11: 7.0
agent-12: 12.0
agent-13: 11.0
agent-14: 12.0
agent-15: 6.0
agent-16: 15.0
agent-17: 10.0
agent-18: 9.0
agent-19: 17.0
agent-20: 6.0
agent-21: 15.0
agent-22: 12.0
agent-23: 15.0
agent-24: 11.0
agent-25: 15.0
agent-26: 11.0
agent-27: 15.0
agent-28: 10.0
agent-29: 14.0
agent-30: 15.0
agent-31: 12.0
agent-32: 12.0
agent-33: 18.0
agent-34: 11.0
agent-35: 10.0
agent-36: 17.0
agent-37: 3.0
agent-38: 9.0
agent-39: 10.0
agent-40: 5.0
Sum Reward: 448.0
Avg Reward: 11.2
Min Reward: 3.0
Max Reward: 18.0
Gini Coefficient: 0.19341517857142856
20:20 Ratio: 2.7872340425531914
Max-min Ratio: 6.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-08_07-38-56
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 482.0
  episode_reward_mean: 445.09
  episode_reward_min: 421.0
  episodes_this_iter: 1
  episodes_total: 412
  experiment_id: 4e724eb5b3a34f42879644e84578eec0
  hostname: gpu024
  info:
    apply_time_ms: 2.481
    dispatch_time_ms: 5.829
    learner:
      cur_lr: 0.0002624320040922612
      grad_gnorm: 40.00001525878906
      policy_entropy: 617.4559326171875
      policy_loss: 4.420804023742676
      var_gnorm: 39.38003921508789
      vf_explained_var: 0.3866993188858032
      vf_loss: 3.860698699951172
    num_steps_sampled: 16520000
    num_steps_trained: 16520000
    wait_time_ms: 536.994
  iterations_since_restore: 413
  node_ip: 172.17.8.24
  num_metric_batches_dropped: 0
  pid: 26970
  policy_reward_mean: {}
  time_since_restore: 23336.360310554504
  time_this_iter_s: 56.66480112075806
  time_total_s: 23336.360310554504
  timestamp: 1594208336
  timesteps_since_restore: 16520000
  timesteps_this_iter: 40000
  timesteps_total: 16520000
  training_iteration: 413
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26970], 23336 s, 413 iter, 16520000 ts, 445 rew

agent-1: 8.0
agent-2: 11.0
agent-3: 15.0
agent-4: 8.0
agent-5: 14.0
agent-6: 6.0
agent-7: 13.0
agent-8: 5.0
agent-9: 12.0
agent-10: 11.0
agent-11: 12.0
agent-12: 14.0
agent-13: 7.0
agent-14: 6.0
agent-15: 11.0
agent-16: 12.0
agent-17: 8.0
agent-18: 10.0
agent-19: 11.0
agent-20: 17.0
agent-21: 12.0
agent-22: 18.0
agent-23: 13.0
agent-24: 12.0
agent-25: 10.0
agent-26: 5.0
agent-27: 8.0
agent-28: 9.0
agent-29: 15.0
agent-30: 10.0
agent-31: 7.0
agent-32: 13.0
agent-33: 13.0
agent-34: 11.0
agent-35: 12.0
agent-36: 16.0
agent-37: 10.0
agent-38: 9.0
agent-39: 15.0
agent-40: 11.0
Sum Reward: 440.0
Avg Reward: 11.0
Min Reward: 5.0
Max Reward: 18.0
Gini Coefficient: 0.16261363636363638
20:20 Ratio: 2.3846153846153846
Max-min Ratio: 3.6
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-08_07-39-52
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 482.0
  episode_reward_mean: 445.18
  episode_reward_min: 421.0
  episodes_this_iter: 1
  episodes_total: 413
  experiment_id: 4e724eb5b3a34f42879644e84578eec0
  hostname: gpu024
  info:
    apply_time_ms: 3.03
    dispatch_time_ms: 7.406
    learner:
      cur_lr: 0.00025976801407523453
      grad_gnorm: 0.3115457594394684
      policy_entropy: 769.8756103515625
      policy_loss: 0.052314385771751404
      var_gnorm: 39.39871597290039
      vf_explained_var: -1.0
      vf_loss: 0.0008210352971218526
    num_steps_sampled: 16560000
    num_steps_trained: 16560000
    wait_time_ms: 563.049
  iterations_since_restore: 414
  node_ip: 172.17.8.24
  num_metric_batches_dropped: 0
  pid: 26970
  policy_reward_mean: {}
  time_since_restore: 23392.74140882492
  time_this_iter_s: 56.38109827041626
  time_total_s: 23392.74140882492
  timestamp: 1594208392
  timesteps_since_restore: 16560000
  timesteps_this_iter: 40000
  timesteps_total: 16560000
  training_iteration: 414
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26970], 23392 s, 414 iter, 16560000 ts, 445 rew

agent-1: 7.0
agent-2: 15.0
agent-3: 14.0
agent-4: 13.0
agent-5: 12.0
agent-6: 14.0
agent-7: 9.0
agent-8: 11.0
agent-9: 11.0
agent-10: 8.0
agent-11: 10.0
agent-12: 12.0
agent-13: 13.0
agent-14: 17.0
agent-15: 10.0
agent-16: 14.0
agent-17: 12.0
agent-18: 8.0
agent-19: 15.0
agent-20: 9.0
agent-21: 12.0
agent-22: 11.0
agent-23: 10.0
agent-24: 11.0
agent-25: 7.0
agent-26: 5.0
agent-27: 6.0
agent-28: 13.0
agent-29: 16.0
agent-30: 15.0
agent-31: 12.0
agent-32: 11.0
agent-33: 16.0
agent-34: 6.0
agent-35: 8.0
agent-36: 8.0
agent-37: 20.0
agent-38: 11.0
agent-39: 12.0
agent-40: 8.0
Sum Reward: 452.0
Avg Reward: 11.3
Min Reward: 5.0
Max Reward: 20.0
Gini Coefficient: 0.1633849557522124
20:20 Ratio: 2.327272727272727
Max-min Ratio: 4.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-08_07-40-49
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 482.0
  episode_reward_mean: 445.23
  episode_reward_min: 421.0
  episodes_this_iter: 1
  episodes_total: 414
  experiment_id: 4e724eb5b3a34f42879644e84578eec0
  hostname: gpu024
  info:
    apply_time_ms: 2.483
    dispatch_time_ms: 5.22
    learner:
      cur_lr: 0.0002571039949543774
      grad_gnorm: 2.771174907684326
      policy_entropy: 771.94140625
      policy_loss: -0.7403110861778259
      var_gnorm: 39.40159225463867
      vf_explained_var: -0.045812129974365234
      vf_loss: 0.0009407573379576206
    num_steps_sampled: 16600000
    num_steps_trained: 16600000
    wait_time_ms: 553.688
  iterations_since_restore: 415
  node_ip: 172.17.8.24
  num_metric_batches_dropped: 0
  pid: 26970
  policy_reward_mean: {}
  time_since_restore: 23449.573170661926
  time_this_iter_s: 56.831761837005615
  time_total_s: 23449.573170661926
  timestamp: 1594208449
  timesteps_since_restore: 16600000
  timesteps_this_iter: 40000
  timesteps_total: 16600000
  training_iteration: 415
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26970], 23449 s, 415 iter, 16600000 ts, 445 rew

agent-1: 10.0
agent-2: 12.0
agent-3: 11.0
agent-4: 11.0
agent-5: 9.0
agent-6: 8.0
agent-7: 8.0
agent-8: 9.0
agent-9: 12.0
agent-10: 16.0
agent-11: 14.0
agent-12: 12.0
agent-13: 12.0
agent-14: 13.0
agent-15: 7.0
agent-16: 6.0
agent-17: 11.0
agent-18: 11.0
agent-19: 8.0
agent-20: 7.0
agent-21: 14.0
agent-22: 10.0
agent-23: 10.0
agent-24: 12.0
agent-25: 11.0
agent-26: 10.0
agent-27: 9.0
agent-28: 9.0
agent-29: 16.0
agent-30: 10.0
agent-31: 13.0
agent-32: 12.0
agent-33: 7.0
agent-34: 14.0
agent-35: 7.0
agent-36: 13.0
agent-37: 11.0
agent-38: 10.0
agent-39: 11.0
agent-40: 10.0
Sum Reward: 426.0
Avg Reward: 10.65
Min Reward: 6.0
Max Reward: 16.0
Gini Coefficient: 0.12629107981220658
20:20 Ratio: 1.9482758620689655
Max-min Ratio: 2.6666666666666665
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-08_07-41-46
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 482.0
  episode_reward_mean: 445.1
  episode_reward_min: 421.0
  episodes_this_iter: 1
  episodes_total: 415
  experiment_id: 4e724eb5b3a34f42879644e84578eec0
  hostname: gpu024
  info:
    apply_time_ms: 2.462
    dispatch_time_ms: 6.347
    learner:
      cur_lr: 0.00025444000493735075
      grad_gnorm: 2.9368796348571777
      policy_entropy: 771.9456787109375
      policy_loss: -0.3685222566127777
      var_gnorm: 39.411617279052734
      vf_explained_var: -1.0
      vf_loss: 0.0006425221799872816
    num_steps_sampled: 16640000
    num_steps_trained: 16640000
    wait_time_ms: 554.421
  iterations_since_restore: 416
  node_ip: 172.17.8.24
  num_metric_batches_dropped: 0
  pid: 26970
  policy_reward_mean: {}
  time_since_restore: 23506.20792078972
  time_this_iter_s: 56.63475012779236
  time_total_s: 23506.20792078972
  timestamp: 1594208506
  timesteps_since_restore: 16640000
  timesteps_this_iter: 40000
  timesteps_total: 16640000
  training_iteration: 416
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26970], 23506 s, 416 iter, 16640000 ts, 445 rew

agent-1: 16.0
agent-2: 14.0
agent-3: 8.0
agent-4: 10.0
agent-5: 11.0
agent-6: 17.0
agent-7: 10.0
agent-8: 7.0
agent-9: 10.0
agent-10: 10.0
agent-11: 16.0
agent-12: 7.0
agent-13: 10.0
agent-14: 12.0
agent-15: 13.0
agent-16: 11.0
agent-17: 14.0
agent-18: 9.0
agent-19: 5.0
agent-20: 5.0
agent-21: 11.0
agent-22: 15.0
agent-23: 19.0
agent-24: 16.0
agent-25: 12.0
agent-26: 12.0
agent-27: 11.0
agent-28: 15.0
agent-29: 8.0
agent-30: 12.0
agent-31: 16.0
agent-32: 11.0
agent-33: 6.0
agent-34: 6.0
agent-35: 14.0
agent-36: 15.0
agent-37: 12.0
agent-38: 12.0
agent-39: 7.0
agent-40: 8.0
Sum Reward: 453.0
Avg Reward: 11.325
Min Reward: 5.0
Max Reward: 19.0
Gini Coefficient: 0.17533112582781457
20:20 Ratio: 2.549019607843137
Max-min Ratio: 3.8
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-08_07-42-42
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 482.0
  episode_reward_mean: 445.38
  episode_reward_min: 421.0
  episodes_this_iter: 1
  episodes_total: 416
  experiment_id: 4e724eb5b3a34f42879644e84578eec0
  hostname: gpu024
  info:
    apply_time_ms: 2.825
    dispatch_time_ms: 5.438
    learner:
      cur_lr: 0.00025177598581649363
      grad_gnorm: 13.635754585266113
      policy_entropy: 649.8529052734375
      policy_loss: -5.4956159591674805
      var_gnorm: 39.41510009765625
      vf_explained_var: 0.2967657446861267
      vf_loss: 0.04810602217912674
    num_steps_sampled: 16680000
    num_steps_trained: 16680000
    wait_time_ms: 551.326
  iterations_since_restore: 417
  node_ip: 172.17.8.24
  num_metric_batches_dropped: 0
  pid: 26970
  policy_reward_mean: {}
  time_since_restore: 23562.386875629425
  time_this_iter_s: 56.17895483970642
  time_total_s: 23562.386875629425
  timestamp: 1594208562
  timesteps_since_restore: 16680000
  timesteps_this_iter: 40000
  timesteps_total: 16680000
  training_iteration: 417
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26970], 23562 s, 417 iter, 16680000 ts, 445 rew

agent-1: 15.0
agent-2: 7.0
agent-3: 6.0
agent-4: 12.0
agent-5: 13.0
agent-6: 15.0
agent-7: 13.0
agent-8: 7.0
agent-9: 15.0
agent-10: 12.0
agent-11: 12.0
agent-12: 10.0
agent-13: 9.0
agent-14: 14.0
agent-15: 16.0
agent-16: 11.0
agent-17: 15.0
agent-18: 10.0
agent-19: 15.0
agent-20: 9.0
agent-21: 15.0
agent-22: 10.0
agent-23: 18.0
agent-24: 5.0
agent-25: 10.0
agent-26: 9.0
agent-27: 10.0
agent-28: 8.0
agent-29: 11.0
agent-30: 16.0
agent-31: 14.0
agent-32: 14.0
agent-33: 13.0
agent-34: 11.0
agent-35: 12.0
agent-36: 7.0
agent-37: 8.0
agent-38: 8.0
agent-39: 7.0
agent-40: 9.0
Sum Reward: 451.0
Avg Reward: 11.275
Min Reward: 5.0
Max Reward: 18.0
Gini Coefficient: 0.16202882483370287
20:20 Ratio: 2.272727272727273
Max-min Ratio: 3.6
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-08_07-43-38
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 482.0
  episode_reward_mean: 445.64
  episode_reward_min: 421.0
  episodes_this_iter: 1
  episodes_total: 417
  experiment_id: 4e724eb5b3a34f42879644e84578eec0
  hostname: gpu024
  info:
    apply_time_ms: 2.561
    dispatch_time_ms: 6.893
    learner:
      cur_lr: 0.00024911199579946697
      grad_gnorm: 2.1986446380615234
      policy_entropy: 771.9619140625
      policy_loss: 0.4298485517501831
      var_gnorm: 39.413394927978516
      vf_explained_var: -0.2028108835220337
      vf_loss: 0.0009496350539848208
    num_steps_sampled: 16720000
    num_steps_trained: 16720000
    wait_time_ms: 555.678
  iterations_since_restore: 418
  node_ip: 172.17.8.24
  num_metric_batches_dropped: 0
  pid: 26970
  policy_reward_mean: {}
  time_since_restore: 23618.645526885986
  time_this_iter_s: 56.25865125656128
  time_total_s: 23618.645526885986
  timestamp: 1594208618
  timesteps_since_restore: 16720000
  timesteps_this_iter: 40000
  timesteps_total: 16720000
  training_iteration: 418
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26970], 23618 s, 418 iter, 16720000 ts, 446 rew

agent-1: 8.0
agent-2: 9.0
agent-3: 13.0
agent-4: 10.0
agent-5: 13.0
agent-6: 4.0
agent-7: 9.0
agent-8: 15.0
agent-9: 6.0
agent-10: 14.0
agent-11: 11.0
agent-12: 11.0
agent-13: 6.0
agent-14: 6.0
agent-15: 11.0
agent-16: 16.0
agent-17: 17.0
agent-18: 11.0
agent-19: 9.0
agent-20: 18.0
agent-21: 12.0
agent-22: 8.0
agent-23: 13.0
agent-24: 15.0
agent-25: 12.0
agent-26: 6.0
agent-27: 11.0
agent-28: 11.0
agent-29: 9.0
agent-30: 13.0
agent-31: 13.0
agent-32: 10.0
agent-33: 13.0
agent-34: 15.0
agent-35: 14.0
agent-36: 11.0
agent-37: 16.0
agent-38: 12.0
agent-39: 10.0
agent-40: 8.0
Sum Reward: 449.0
Avg Reward: 11.225
Min Reward: 4.0
Max Reward: 18.0
Gini Coefficient: 0.16341870824053453
20:20 Ratio: 2.423076923076923
Max-min Ratio: 4.5
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-08_07-44-35
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 482.0
  episode_reward_mean: 445.59
  episode_reward_min: 421.0
  episodes_this_iter: 1
  episodes_total: 418
  experiment_id: 4e724eb5b3a34f42879644e84578eec0
  hostname: gpu024
  info:
    apply_time_ms: 2.633
    dispatch_time_ms: 6.239
    learner:
      cur_lr: 0.0002464480057824403
      grad_gnorm: 0.952038049697876
      policy_entropy: 772.8157348632812
      policy_loss: -0.3418737053871155
      var_gnorm: 39.414100646972656
      vf_explained_var: -0.09598863124847412
      vf_loss: 0.0010442195925861597
    num_steps_sampled: 16760000
    num_steps_trained: 16760000
    wait_time_ms: 563.85
  iterations_since_restore: 419
  node_ip: 172.17.8.24
  num_metric_batches_dropped: 0
  pid: 26970
  policy_reward_mean: {}
  time_since_restore: 23675.29734969139
  time_this_iter_s: 56.65182280540466
  time_total_s: 23675.29734969139
  timestamp: 1594208675
  timesteps_since_restore: 16760000
  timesteps_this_iter: 40000
  timesteps_total: 16760000
  training_iteration: 419
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26970], 23675 s, 419 iter, 16760000 ts, 446 rew

agent-1: 10.0
agent-2: 9.0
agent-3: 9.0
agent-4: 13.0
agent-5: 18.0
agent-6: 8.0
agent-7: 9.0
agent-8: 14.0
agent-9: 11.0
agent-10: 13.0
agent-11: 11.0
agent-12: 8.0
agent-13: 11.0
agent-14: 11.0
agent-15: 12.0
agent-16: 14.0
agent-17: 14.0
agent-18: 11.0
agent-19: 12.0
agent-20: 11.0
agent-21: 10.0
agent-22: 9.0
agent-23: 13.0
agent-24: 11.0
agent-25: 9.0
agent-26: 7.0
agent-27: 6.0
agent-28: 16.0
agent-29: 9.0
agent-30: 11.0
agent-31: 11.0
agent-32: 15.0
agent-33: 12.0
agent-34: 5.0
agent-35: 14.0
agent-36: 14.0
agent-37: 11.0
agent-38: 13.0
agent-39: 16.0
agent-40: 6.0
Sum Reward: 447.0
Avg Reward: 11.175
Min Reward: 5.0
Max Reward: 18.0
Gini Coefficient: 0.142337807606264
20:20 Ratio: 2.086206896551724
Max-min Ratio: 3.6
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-08_07-45-32
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 482.0
  episode_reward_mean: 445.69
  episode_reward_min: 421.0
  episodes_this_iter: 1
  episodes_total: 419
  experiment_id: 4e724eb5b3a34f42879644e84578eec0
  hostname: gpu024
  info:
    apply_time_ms: 2.783
    dispatch_time_ms: 5.622
    learner:
      cur_lr: 0.00024378400121349841
      grad_gnorm: 0.7254458069801331
      policy_entropy: 771.4693603515625
      policy_loss: 0.27438780665397644
      var_gnorm: 39.421207427978516
      vf_explained_var: -1.0
      vf_loss: 0.000865263631567359
    num_steps_sampled: 16800000
    num_steps_trained: 16800000
    wait_time_ms: 561.907
  iterations_since_restore: 420
  node_ip: 172.17.8.24
  num_metric_batches_dropped: 0
  pid: 26970
  policy_reward_mean: {}
  time_since_restore: 23731.81772184372
  time_this_iter_s: 56.52037215232849
  time_total_s: 23731.81772184372
  timestamp: 1594208732
  timesteps_since_restore: 16800000
  timesteps_this_iter: 40000
  timesteps_total: 16800000
  training_iteration: 420
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26970], 23731 s, 420 iter, 16800000 ts, 446 rew

agent-1: 15.0
agent-2: 19.0
agent-3: 17.0
agent-4: 16.0
agent-5: 9.0
agent-6: 12.0
agent-7: 10.0
agent-8: 10.0
agent-9: 9.0
agent-10: 11.0
agent-11: 11.0
agent-12: 14.0
agent-13: 11.0
agent-14: 9.0
agent-15: 11.0
agent-16: 9.0
agent-17: 12.0
agent-18: 8.0
agent-19: 7.0
agent-20: 11.0
agent-21: 14.0
agent-22: 11.0
agent-23: 9.0
agent-24: 10.0
agent-25: 15.0
agent-26: 4.0
agent-27: 10.0
agent-28: 12.0
agent-29: 8.0
agent-30: 12.0
agent-31: 10.0
agent-32: 9.0
agent-33: 12.0
agent-34: 12.0
agent-35: 10.0
agent-36: 14.0
agent-37: 9.0
agent-38: 8.0
agent-39: 8.0
agent-40: 6.0
Sum Reward: 434.0
Avg Reward: 10.85
Min Reward: 4.0
Max Reward: 19.0
Gini Coefficient: 0.14838709677419354
20:20 Ratio: 2.1379310344827585
Max-min Ratio: 4.75
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-08_07-46-28
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 482.0
  episode_reward_mean: 445.57
  episode_reward_min: 421.0
  episodes_this_iter: 1
  episodes_total: 420
  experiment_id: 4e724eb5b3a34f42879644e84578eec0
  hostname: gpu024
  info:
    apply_time_ms: 2.514
    dispatch_time_ms: 5.487
    learner:
      cur_lr: 0.00024111999664455652
      grad_gnorm: 1.6792449951171875
      policy_entropy: 772.2501220703125
      policy_loss: -0.9866327047348022
      var_gnorm: 39.418212890625
      vf_explained_var: -1.0
      vf_loss: 0.0006323317065834999
    num_steps_sampled: 16840000
    num_steps_trained: 16840000
    wait_time_ms: 564.025
  iterations_since_restore: 421
  node_ip: 172.17.8.24
  num_metric_batches_dropped: 0
  pid: 26970
  policy_reward_mean: {}
  time_since_restore: 23788.49765253067
  time_this_iter_s: 56.679930686950684
  time_total_s: 23788.49765253067
  timestamp: 1594208788
  timesteps_since_restore: 16840000
  timesteps_this_iter: 40000
  timesteps_total: 16840000
  training_iteration: 421
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26970], 23788 s, 421 iter, 16840000 ts, 446 rew

agent-1: 11.0
agent-2: 12.0
agent-3: 15.0
agent-4: 12.0
agent-5: 16.0
agent-6: 9.0
agent-7: 10.0
agent-8: 16.0
agent-9: 12.0
agent-10: 11.0
agent-11: 11.0
agent-12: 10.0
agent-13: 13.0
agent-14: 8.0
agent-15: 16.0
agent-16: 10.0
agent-17: 8.0
agent-18: 7.0
agent-19: 17.0
agent-20: 11.0
agent-21: 9.0
agent-22: 8.0
agent-23: 9.0
agent-24: 10.0
agent-25: 7.0
agent-26: 12.0
agent-27: 9.0
agent-28: 14.0
agent-29: 16.0
agent-30: 13.0
agent-31: 11.0
agent-32: 9.0
agent-33: 11.0
agent-34: 11.0
agent-35: 7.0
agent-36: 8.0
agent-37: 9.0
agent-38: 13.0
agent-39: 13.0
agent-40: 9.0
Sum Reward: 443.0
Avg Reward: 11.075
Min Reward: 7.0
Max Reward: 17.0
Gini Coefficient: 0.13797968397291197
20:20 Ratio: 1.9838709677419355
Max-min Ratio: 2.4285714285714284
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-08_07-47-25
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 482.0
  episode_reward_mean: 445.51
  episode_reward_min: 421.0
  episodes_this_iter: 1
  episodes_total: 421
  experiment_id: 4e724eb5b3a34f42879644e84578eec0
  hostname: gpu024
  info:
    apply_time_ms: 2.556
    dispatch_time_ms: 5.951
    learner:
      cur_lr: 0.00023845600662752986
      grad_gnorm: 1.378351092338562
      policy_entropy: 770.2752685546875
      policy_loss: -0.38219988346099854
      var_gnorm: 39.42660140991211
      vf_explained_var: -0.2048734426498413
      vf_loss: 0.0044480860233306885
    num_steps_sampled: 16880000
    num_steps_trained: 16880000
    wait_time_ms: 553.13
  iterations_since_restore: 422
  node_ip: 172.17.8.24
  num_metric_batches_dropped: 0
  pid: 26970
  policy_reward_mean: {}
  time_since_restore: 23844.99925470352
  time_this_iter_s: 56.50160217285156
  time_total_s: 23844.99925470352
  timestamp: 1594208845
  timesteps_since_restore: 16880000
  timesteps_this_iter: 40000
  timesteps_total: 16880000
  training_iteration: 422
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26970], 23844 s, 422 iter, 16880000 ts, 446 rew

agent-1: 15.0
agent-2: 8.0
agent-3: 16.0
agent-4: 8.0
agent-5: 9.0
agent-6: 11.0
agent-7: 18.0
agent-8: 13.0
agent-9: 14.0
agent-10: 14.0
agent-11: 12.0
agent-12: 10.0
agent-13: 8.0
agent-14: 10.0
agent-15: 10.0
agent-16: 6.0
agent-17: 13.0
agent-18: 7.0
agent-19: 8.0
agent-20: 12.0
agent-21: 12.0
agent-22: 7.0
agent-23: 10.0
agent-24: 13.0
agent-25: 13.0
agent-26: 18.0
agent-27: 9.0
agent-28: 11.0
agent-29: 8.0
agent-30: 10.0
agent-31: 5.0
agent-32: 11.0
agent-33: 12.0
agent-34: 9.0
agent-35: 11.0
agent-36: 12.0
agent-37: 17.0
agent-38: 10.0
agent-39: 13.0
agent-40: 7.0
Sum Reward: 440.0
Avg Reward: 11.0
Min Reward: 5.0
Max Reward: 18.0
Gini Coefficient: 0.15931818181818183
20:20 Ratio: 2.232142857142857
Max-min Ratio: 3.6
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-08_07-48-22
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 482.0
  episode_reward_mean: 445.58
  episode_reward_min: 421.0
  episodes_this_iter: 1
  episodes_total: 422
  experiment_id: 4e724eb5b3a34f42879644e84578eec0
  hostname: gpu024
  info:
    apply_time_ms: 2.593
    dispatch_time_ms: 5.57
    learner:
      cur_lr: 0.00023579200205858797
      grad_gnorm: 1.5420722961425781
      policy_entropy: 774.201904296875
      policy_loss: -0.9815047383308411
      var_gnorm: 39.42106246948242
      vf_explained_var: -0.8405627012252808
      vf_loss: 0.00046805155579932034
    num_steps_sampled: 16920000
    num_steps_trained: 16920000
    wait_time_ms: 567.551
  iterations_since_restore: 423
  node_ip: 172.17.8.24
  num_metric_batches_dropped: 0
  pid: 26970
  policy_reward_mean: {}
  time_since_restore: 23901.5994617939
  time_this_iter_s: 56.60020709037781
  time_total_s: 23901.5994617939
  timestamp: 1594208902
  timesteps_since_restore: 16920000
  timesteps_this_iter: 40000
  timesteps_total: 16920000
  training_iteration: 423
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26970], 23901 s, 423 iter, 16920000 ts, 446 rew

agent-1: 10.0
agent-2: 12.0
agent-3: 10.0
agent-4: 14.0
agent-5: 11.0
agent-6: 11.0
agent-7: 5.0
agent-8: 4.0
agent-9: 9.0
agent-10: 13.0
agent-11: 9.0
agent-12: 15.0
agent-13: 13.0
agent-14: 13.0
agent-15: 17.0
agent-16: 14.0
agent-17: 9.0
agent-18: 8.0
agent-19: 5.0
agent-20: 9.0
agent-21: 11.0
agent-22: 15.0
agent-23: 5.0
agent-24: 10.0
agent-25: 11.0
agent-26: 14.0
agent-27: 8.0
agent-28: 13.0
agent-29: 10.0
agent-30: 7.0
agent-31: 9.0
agent-32: 11.0
agent-33: 14.0
agent-34: 5.0
agent-35: 6.0
agent-36: 16.0
agent-37: 14.0
agent-38: 9.0
agent-39: 12.0
agent-40: 12.0
Sum Reward: 423.0
Avg Reward: 10.575
Min Reward: 4.0
Max Reward: 17.0
Gini Coefficient: 0.1758274231678487
20:20 Ratio: 2.6444444444444444
Max-min Ratio: 4.25
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-08_07-49-18
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 482.0
  episode_reward_mean: 445.3
  episode_reward_min: 421.0
  episodes_this_iter: 1
  episodes_total: 423
  experiment_id: 4e724eb5b3a34f42879644e84578eec0
  hostname: gpu024
  info:
    apply_time_ms: 2.991
    dispatch_time_ms: 5.286
    learner:
      cur_lr: 0.00023312799748964608
      grad_gnorm: 0.43264177441596985
      policy_entropy: 772.8270263671875
      policy_loss: 0.12608511745929718
      var_gnorm: 39.43103790283203
      vf_explained_var: -0.8226591348648071
      vf_loss: 0.00020402803784236312
    num_steps_sampled: 16960000
    num_steps_trained: 16960000
    wait_time_ms: 557.876
  iterations_since_restore: 424
  node_ip: 172.17.8.24
  num_metric_batches_dropped: 0
  pid: 26970
  policy_reward_mean: {}
  time_since_restore: 23958.14799427986
  time_this_iter_s: 56.548532485961914
  time_total_s: 23958.14799427986
  timestamp: 1594208958
  timesteps_since_restore: 16960000
  timesteps_this_iter: 40000
  timesteps_total: 16960000
  training_iteration: 424
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26970], 23958 s, 424 iter, 16960000 ts, 445 rew

agent-1: 11.0
agent-2: 4.0
agent-3: 8.0
agent-4: 11.0
agent-5: 10.0
agent-6: 13.0
agent-7: 15.0
agent-8: 9.0
agent-9: 13.0
agent-10: 19.0
agent-11: 13.0
agent-12: 9.0
agent-13: 14.0
agent-14: 8.0
agent-15: 6.0
agent-16: 12.0
agent-17: 10.0
agent-18: 17.0
agent-19: 2.0
agent-20: 10.0
agent-21: 10.0
agent-22: 11.0
agent-23: 17.0
agent-24: 17.0
agent-25: 13.0
agent-26: 14.0
agent-27: 10.0
agent-28: 11.0
agent-29: 12.0
agent-30: 11.0
agent-31: 11.0
agent-32: 10.0
agent-33: 15.0
agent-34: 7.0
agent-35: 11.0
agent-36: 9.0
agent-37: 11.0
agent-38: 11.0
agent-39: 8.0
agent-40: 9.0
Sum Reward: 442.0
Avg Reward: 11.05
Min Reward: 2.0
Max Reward: 19.0
Gini Coefficient: 0.1669683257918552
20:20 Ratio: 2.4615384615384617
Max-min Ratio: 9.5
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-08_07-50-15
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 482.0
  episode_reward_mean: 445.13
  episode_reward_min: 421.0
  episodes_this_iter: 1
  episodes_total: 424
  experiment_id: 4e724eb5b3a34f42879644e84578eec0
  hostname: gpu024
  info:
    apply_time_ms: 2.955
    dispatch_time_ms: 6.66
    learner:
      cur_lr: 0.00023046399292070419
      grad_gnorm: 1.1800477504730225
      policy_entropy: 755.435546875
      policy_loss: -1.1773595809936523
      var_gnorm: 39.41566848754883
      vf_explained_var: 0.03236877918243408
      vf_loss: 0.0007401226321235299
    num_steps_sampled: 17000000
    num_steps_trained: 17000000
    wait_time_ms: 569.413
  iterations_since_restore: 425
  node_ip: 172.17.8.24
  num_metric_batches_dropped: 0
  pid: 26970
  policy_reward_mean: {}
  time_since_restore: 24014.605050563812
  time_this_iter_s: 56.457056283950806
  time_total_s: 24014.605050563812
  timestamp: 1594209015
  timesteps_since_restore: 17000000
  timesteps_this_iter: 40000
  timesteps_total: 17000000
  training_iteration: 425
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26970], 24014 s, 425 iter, 17000000 ts, 445 rew

agent-1: 12.0
agent-2: 11.0
agent-3: 10.0
agent-4: 11.0
agent-5: 14.0
agent-6: 9.0
agent-7: 14.0
agent-8: 14.0
agent-9: 11.0
agent-10: 11.0
agent-11: 16.0
agent-12: 7.0
agent-13: 9.0
agent-14: 9.0
agent-15: 13.0
agent-16: 13.0
agent-17: 13.0
agent-18: 8.0
agent-19: 9.0
agent-20: 14.0
agent-21: 11.0
agent-22: 7.0
agent-23: 13.0
agent-24: 17.0
agent-25: 11.0
agent-26: 12.0
agent-27: 9.0
agent-28: 14.0
agent-29: 11.0
agent-30: 7.0
agent-31: 7.0
agent-32: 5.0
agent-33: 11.0
agent-34: 9.0
agent-35: 13.0
agent-36: 9.0
agent-37: 11.0
agent-38: 5.0
agent-39: 11.0
agent-40: 15.0
Sum Reward: 436.0
Avg Reward: 10.9
Min Reward: 5.0
Max Reward: 17.0
Gini Coefficient: 0.14529816513761468
20:20 Ratio: 2.1454545454545455
Max-min Ratio: 3.4
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-08_07-51-11
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 482.0
  episode_reward_mean: 444.98
  episode_reward_min: 421.0
  episodes_this_iter: 1
  episodes_total: 425
  experiment_id: 4e724eb5b3a34f42879644e84578eec0
  hostname: gpu024
  info:
    apply_time_ms: 2.696
    dispatch_time_ms: 6.211
    learner:
      cur_lr: 0.00022780000290367752
      grad_gnorm: 0.41330793499946594
      policy_entropy: 771.4275512695312
      policy_loss: -0.3307766914367676
      var_gnorm: 39.42244338989258
      vf_explained_var: -1.0
      vf_loss: 0.0007987443241290748
    num_steps_sampled: 17040000
    num_steps_trained: 17040000
    wait_time_ms: 562.962
  iterations_since_restore: 426
  node_ip: 172.17.8.24
  num_metric_batches_dropped: 0
  pid: 26970
  policy_reward_mean: {}
  time_since_restore: 24071.22951221466
  time_this_iter_s: 56.62446165084839
  time_total_s: 24071.22951221466
  timestamp: 1594209071
  timesteps_since_restore: 17040000
  timesteps_this_iter: 40000
  timesteps_total: 17040000
  training_iteration: 426
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26970], 24071 s, 426 iter, 17040000 ts, 445 rew

agent-1: 11.0
agent-2: 8.0
agent-3: 6.0
agent-4: 14.0
agent-5: 10.0
agent-6: 12.0
agent-7: 7.0
agent-8: 13.0
agent-9: 11.0
agent-10: 10.0
agent-11: 11.0
agent-12: 11.0
agent-13: 16.0
agent-14: 14.0
agent-15: 7.0
agent-16: 15.0
agent-17: 12.0
agent-18: 13.0
agent-19: 9.0
agent-20: 11.0
agent-21: 7.0
agent-22: 7.0
agent-23: 11.0
agent-24: 18.0
agent-25: 13.0
agent-26: 13.0
agent-27: 15.0
agent-28: 11.0
agent-29: 15.0
agent-30: 10.0
agent-31: 10.0
agent-32: 12.0
agent-33: 12.0
agent-34: 9.0
agent-35: 11.0
agent-36: 4.0
agent-37: 5.0
agent-38: 8.0
agent-39: 12.0
agent-40: 13.0
Sum Reward: 437.0
Avg Reward: 10.925
Min Reward: 4.0
Max Reward: 18.0
Gini Coefficient: 0.15543478260869564
20:20 Ratio: 2.3529411764705883
Max-min Ratio: 4.5
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-08_07-52-08
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 482.0
  episode_reward_mean: 444.99
  episode_reward_min: 421.0
  episodes_this_iter: 1
  episodes_total: 426
  experiment_id: 4e724eb5b3a34f42879644e84578eec0
  hostname: gpu024
  info:
    apply_time_ms: 2.992
    dispatch_time_ms: 6.73
    learner:
      cur_lr: 0.00022513599833473563
      grad_gnorm: 0.9587587118148804
      policy_entropy: 774.9154052734375
      policy_loss: -0.5524348020553589
      var_gnorm: 39.438655853271484
      vf_explained_var: -1.0
      vf_loss: 0.0007744599715806544
    num_steps_sampled: 17080000
    num_steps_trained: 17080000
    wait_time_ms: 546.559
  iterations_since_restore: 427
  node_ip: 172.17.8.24
  num_metric_batches_dropped: 0
  pid: 26970
  policy_reward_mean: {}
  time_since_restore: 24127.367208719254
  time_this_iter_s: 56.137696504592896
  time_total_s: 24127.367208719254
  timestamp: 1594209128
  timesteps_since_restore: 17080000
  timesteps_this_iter: 40000
  timesteps_total: 17080000
  training_iteration: 427
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26970], 24127 s, 427 iter, 17080000 ts, 445 rew

agent-1: 12.0
agent-2: 13.0
agent-3: 2.0
agent-4: 15.0
agent-5: 6.0
agent-6: 8.0
agent-7: 19.0
agent-8: 7.0
agent-9: 15.0
agent-10: 10.0
agent-11: 13.0
agent-12: 12.0
agent-13: 5.0
agent-14: 3.0
agent-15: 14.0
agent-16: 10.0
agent-17: 8.0
agent-18: 8.0
agent-19: 9.0
agent-20: 10.0
agent-21: 13.0
agent-22: 13.0
agent-23: 9.0
agent-24: 12.0
agent-25: 17.0
agent-26: 14.0
agent-27: 6.0
agent-28: 12.0
agent-29: 10.0
agent-30: 13.0
agent-31: 15.0
agent-32: 11.0
agent-33: 12.0
agent-34: 15.0
agent-35: 14.0
agent-36: 9.0
agent-37: 13.0
agent-38: 11.0
agent-39: 11.0
agent-40: 7.0
Sum Reward: 436.0
Avg Reward: 10.9
Min Reward: 2.0
Max Reward: 19.0
Gini Coefficient: 0.1856651376146789
20:20 Ratio: 2.8181818181818183
Max-min Ratio: 9.5
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-08_07-53-04
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 482.0
  episode_reward_mean: 444.97
  episode_reward_min: 421.0
  episodes_this_iter: 1
  episodes_total: 427
  experiment_id: 4e724eb5b3a34f42879644e84578eec0
  hostname: gpu024
  info:
    apply_time_ms: 2.761
    dispatch_time_ms: 5.853
    learner:
      cur_lr: 0.00022247199376579374
      grad_gnorm: 0.6287596821784973
      policy_entropy: 775.6692504882812
      policy_loss: 0.17060771584510803
      var_gnorm: 39.464515686035156
      vf_explained_var: -0.09120535850524902
      vf_loss: 0.0005894082714803517
    num_steps_sampled: 17120000
    num_steps_trained: 17120000
    wait_time_ms: 561.963
  iterations_since_restore: 428
  node_ip: 172.17.8.24
  num_metric_batches_dropped: 0
  pid: 26970
  policy_reward_mean: {}
  time_since_restore: 24184.015350818634
  time_this_iter_s: 56.64814209938049
  time_total_s: 24184.015350818634
  timestamp: 1594209184
  timesteps_since_restore: 17120000
  timesteps_this_iter: 40000
  timesteps_total: 17120000
  training_iteration: 428
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26970], 24184 s, 428 iter, 17120000 ts, 445 rew

agent-1: 13.0
agent-2: 14.0
agent-3: 16.0
agent-4: 13.0
agent-5: 6.0
agent-6: 13.0
agent-7: 11.0
agent-8: 15.0
agent-9: 12.0
agent-10: 5.0
agent-11: 5.0
agent-12: 10.0
agent-13: 13.0
agent-14: 7.0
agent-15: 14.0
agent-16: 12.0
agent-17: 10.0
agent-18: 14.0
agent-19: 12.0
agent-20: 7.0
agent-21: 10.0
agent-22: 10.0
agent-23: 10.0
agent-24: 12.0
agent-25: 14.0
agent-26: 15.0
agent-27: 11.0
agent-28: 14.0
agent-29: 11.0
agent-30: 7.0
agent-31: 7.0
agent-32: 15.0
agent-33: 14.0
agent-34: 14.0
agent-35: 13.0
agent-36: 8.0
agent-37: 11.0
agent-38: 8.0
agent-39: 8.0
agent-40: 11.0
Sum Reward: 445.0
Avg Reward: 11.125
Min Reward: 5.0
Max Reward: 16.0
Gini Coefficient: 0.1505056179775281
20:20 Ratio: 2.25
Max-min Ratio: 3.2
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-08_07-54-01
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 482.0
  episode_reward_mean: 444.97
  episode_reward_min: 421.0
  episodes_this_iter: 1
  episodes_total: 428
  experiment_id: 4e724eb5b3a34f42879644e84578eec0
  hostname: gpu024
  info:
    apply_time_ms: 2.838
    dispatch_time_ms: 5.66
    learner:
      cur_lr: 0.00021980800374876708
      grad_gnorm: 3.8514552116394043
      policy_entropy: 766.92724609375
      policy_loss: -2.485018014907837
      var_gnorm: 39.4664306640625
      vf_explained_var: -1.0
      vf_loss: 0.005115200765430927
    num_steps_sampled: 17160000
    num_steps_trained: 17160000
    wait_time_ms: 553.506
  iterations_since_restore: 429
  node_ip: 172.17.8.24
  num_metric_batches_dropped: 0
  pid: 26970
  policy_reward_mean: {}
  time_since_restore: 24240.491955041885
  time_this_iter_s: 56.47660422325134
  time_total_s: 24240.491955041885
  timestamp: 1594209241
  timesteps_since_restore: 17160000
  timesteps_this_iter: 40000
  timesteps_total: 17160000
  training_iteration: 429
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26970], 24240 s, 429 iter, 17160000 ts, 445 rew

agent-1: 7.0
agent-2: 14.0
agent-3: 14.0
agent-4: 7.0
agent-5: 7.0
agent-6: 14.0
agent-7: 11.0
agent-8: 14.0
agent-9: 9.0
agent-10: 13.0
agent-11: 16.0
agent-12: 9.0
agent-13: 14.0
agent-14: 11.0
agent-15: 19.0
agent-16: 10.0
agent-17: 12.0
agent-18: 3.0
agent-19: 6.0
agent-20: 9.0
agent-21: 9.0
agent-22: 11.0
agent-23: 10.0
agent-24: 13.0
agent-25: 10.0
agent-26: 14.0
agent-27: 14.0
agent-28: 9.0
agent-29: 10.0
agent-30: 10.0
agent-31: 14.0
agent-32: 9.0
agent-33: 11.0
agent-34: 9.0
agent-35: 13.0
agent-36: 9.0
agent-37: 11.0
agent-38: 15.0
agent-39: 9.0
agent-40: 8.0
Sum Reward: 437.0
Avg Reward: 10.925
Min Reward: 3.0
Max Reward: 19.0
Gini Coefficient: 0.1549771167048055
20:20 Ratio: 2.142857142857143
Max-min Ratio: 6.333333333333333
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-08_07-54-57
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 482.0
  episode_reward_mean: 445.0
  episode_reward_min: 421.0
  episodes_this_iter: 1
  episodes_total: 429
  experiment_id: 4e724eb5b3a34f42879644e84578eec0
  hostname: gpu024
  info:
    apply_time_ms: 3.316
    dispatch_time_ms: 6.695
    learner:
      cur_lr: 0.0002171439991798252
      grad_gnorm: 0.3995242416858673
      policy_entropy: 775.5763549804688
      policy_loss: -0.09634701907634735
      var_gnorm: 39.446651458740234
      vf_explained_var: -0.2387697696685791
      vf_loss: 0.0001941792288562283
    num_steps_sampled: 17200000
    num_steps_trained: 17200000
    wait_time_ms: 554.632
  iterations_since_restore: 430
  node_ip: 172.17.8.24
  num_metric_batches_dropped: 0
  pid: 26970
  policy_reward_mean: {}
  time_since_restore: 24297.127698898315
  time_this_iter_s: 56.635743856430054
  time_total_s: 24297.127698898315
  timestamp: 1594209297
  timesteps_since_restore: 17200000
  timesteps_this_iter: 40000
  timesteps_total: 17200000
  training_iteration: 430
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26970], 24297 s, 430 iter, 17200000 ts, 445 rew

agent-1: 10.0
agent-2: 6.0
agent-3: 10.0
agent-4: 14.0
agent-5: 16.0
agent-6: 7.0
agent-7: 15.0
agent-8: 7.0
agent-9: 10.0
agent-10: 11.0
agent-11: 11.0
agent-12: 10.0
agent-13: 8.0
agent-14: 8.0
agent-15: 9.0
agent-16: 8.0
agent-17: 10.0
agent-18: 8.0
agent-19: 11.0
agent-20: 12.0
agent-21: 9.0
agent-22: 8.0
agent-23: 13.0
agent-24: 4.0
agent-25: 15.0
agent-26: 15.0
agent-27: 14.0
agent-28: 7.0
agent-29: 13.0
agent-30: 8.0
agent-31: 10.0
agent-32: 10.0
agent-33: 16.0
agent-34: 13.0
agent-35: 9.0
agent-36: 12.0
agent-37: 8.0
agent-38: 21.0
agent-39: 11.0
agent-40: 12.0
Sum Reward: 429.0
Avg Reward: 10.725
Min Reward: 4.0
Max Reward: 21.0
Gini Coefficient: 0.16812354312354313
20:20 Ratio: 2.290909090909091
Max-min Ratio: 5.25
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-08_07-55-54
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 482.0
  episode_reward_mean: 444.88
  episode_reward_min: 421.0
  episodes_this_iter: 1
  episodes_total: 430
  experiment_id: 4e724eb5b3a34f42879644e84578eec0
  hostname: gpu024
  info:
    apply_time_ms: 2.653
    dispatch_time_ms: 6.21
    learner:
      cur_lr: 0.0002144799946108833
      grad_gnorm: 1.8875048160552979
      policy_entropy: 774.4572143554688
      policy_loss: -1.3192131519317627
      var_gnorm: 39.45008087158203
      vf_explained_var: -1.0
      vf_loss: 0.0015397584065794945
    num_steps_sampled: 17240000
    num_steps_trained: 17240000
    wait_time_ms: 557.329
  iterations_since_restore: 431
  node_ip: 172.17.8.24
  num_metric_batches_dropped: 0
  pid: 26970
  policy_reward_mean: {}
  time_since_restore: 24353.406757354736
  time_this_iter_s: 56.2790584564209
  time_total_s: 24353.406757354736
  timestamp: 1594209354
  timesteps_since_restore: 17240000
  timesteps_this_iter: 40000
  timesteps_total: 17240000
  training_iteration: 431
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26970], 24353 s, 431 iter, 17240000 ts, 445 rew

agent-1: 11.0
agent-2: 9.0
agent-3: 12.0
agent-4: 15.0
agent-5: 11.0
agent-6: 18.0
agent-7: 13.0
agent-8: 9.0
agent-9: 8.0
agent-10: 17.0
agent-11: 14.0
agent-12: 13.0
agent-13: 3.0
agent-14: 4.0
agent-15: 9.0
agent-16: 10.0
agent-17: 8.0
agent-18: 9.0
agent-19: 14.0
agent-20: 12.0
agent-21: 12.0
agent-22: 8.0
agent-23: 10.0
agent-24: 9.0
agent-25: 9.0
agent-26: 8.0
agent-27: 12.0
agent-28: 13.0
agent-29: 15.0
agent-30: 8.0
agent-31: 10.0
agent-32: 17.0
agent-33: 9.0
agent-34: 10.0
agent-35: 11.0
agent-36: 11.0
agent-37: 11.0
agent-38: 9.0
agent-39: 16.0
agent-40: 13.0
Sum Reward: 440.0
Avg Reward: 11.0
Min Reward: 3.0
Max Reward: 18.0
Gini Coefficient: 0.1603409090909091
20:20 Ratio: 2.25
Max-min Ratio: 6.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-08_07-56-50
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 482.0
  episode_reward_mean: 444.56
  episode_reward_min: 421.0
  episodes_this_iter: 1
  episodes_total: 431
  experiment_id: 4e724eb5b3a34f42879644e84578eec0
  hostname: gpu024
  info:
    apply_time_ms: 2.604
    dispatch_time_ms: 5.679
    learner:
      cur_lr: 0.00021181600459385663
      grad_gnorm: 0.5672864317893982
      policy_entropy: 775.92041015625
      policy_loss: 0.10740318894386292
      var_gnorm: 39.46388626098633
      vf_explained_var: -0.3878244161605835
      vf_loss: 0.00019900008919648826
    num_steps_sampled: 17280000
    num_steps_trained: 17280000
    wait_time_ms: 547.784
  iterations_since_restore: 432
  node_ip: 172.17.8.24
  num_metric_batches_dropped: 0
  pid: 26970
  policy_reward_mean: {}
  time_since_restore: 24409.83769774437
  time_this_iter_s: 56.43094038963318
  time_total_s: 24409.83769774437
  timestamp: 1594209410
  timesteps_since_restore: 17280000
  timesteps_this_iter: 40000
  timesteps_total: 17280000
  training_iteration: 432
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26970], 24409 s, 432 iter, 17280000 ts, 445 rew

agent-1: 14.0
agent-2: 6.0
agent-3: 12.0
agent-4: 16.0
agent-5: 12.0
agent-6: 8.0
agent-7: 6.0
agent-8: 6.0
agent-9: 10.0
agent-10: 6.0
agent-11: 15.0
agent-12: 15.0
agent-13: 11.0
agent-14: 11.0
agent-15: 12.0
agent-16: 16.0
agent-17: 7.0
agent-18: 5.0
agent-19: 12.0
agent-20: 16.0
agent-21: 15.0
agent-22: 2.0
agent-23: 16.0
agent-24: 17.0
agent-25: 15.0
agent-26: 10.0
agent-27: 12.0
agent-28: 15.0
agent-29: 10.0
agent-30: 14.0
agent-31: 15.0
agent-32: 11.0
agent-33: 10.0
agent-34: 7.0
agent-35: 13.0
agent-36: 11.0
agent-37: 11.0
agent-38: 9.0
agent-39: 8.0
agent-40: 12.0
Sum Reward: 449.0
Avg Reward: 11.225
Min Reward: 2.0
Max Reward: 17.0
Gini Coefficient: 0.1834632516703786
20:20 Ratio: 2.8
Max-min Ratio: 8.5
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-08_07-57-47
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 482.0
  episode_reward_mean: 444.74
  episode_reward_min: 421.0
  episodes_this_iter: 1
  episodes_total: 432
  experiment_id: 4e724eb5b3a34f42879644e84578eec0
  hostname: gpu024
  info:
    apply_time_ms: 2.812
    dispatch_time_ms: 6.222
    learner:
      cur_lr: 0.00020915200002491474
      grad_gnorm: 4.164065361022949
      policy_entropy: 770.5767822265625
      policy_loss: -2.1949245929718018
      var_gnorm: 39.45255661010742
      vf_explained_var: -1.0
      vf_loss: 0.0063552772626280785
    num_steps_sampled: 17320000
    num_steps_trained: 17320000
    wait_time_ms: 547.154
  iterations_since_restore: 433
  node_ip: 172.17.8.24
  num_metric_batches_dropped: 0
  pid: 26970
  policy_reward_mean: {}
  time_since_restore: 24466.689663648605
  time_this_iter_s: 56.85196590423584
  time_total_s: 24466.689663648605
  timestamp: 1594209467
  timesteps_since_restore: 17320000
  timesteps_this_iter: 40000
  timesteps_total: 17320000
  training_iteration: 433
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26970], 24466 s, 433 iter, 17320000 ts, 445 rew

agent-1: 12.0
agent-2: 7.0
agent-3: 10.0
agent-4: 11.0
agent-5: 10.0
agent-6: 13.0
agent-7: 12.0
agent-8: 8.0
agent-9: 10.0
agent-10: 12.0
agent-11: 11.0
agent-12: 18.0
agent-13: 7.0
agent-14: 16.0
agent-15: 8.0
agent-16: 9.0
agent-17: 10.0
agent-18: 13.0
agent-19: 8.0
agent-20: 17.0
agent-21: 13.0
agent-22: 7.0
agent-23: 11.0
agent-24: 11.0
agent-25: 11.0
agent-26: 10.0
agent-27: 10.0
agent-28: 11.0
agent-29: 11.0
agent-30: 13.0
agent-31: 13.0
agent-32: 7.0
agent-33: 10.0
agent-34: 13.0
agent-35: 5.0
agent-36: 14.0
agent-37: 7.0
agent-38: 9.0
agent-39: 10.0
agent-40: 13.0
Sum Reward: 431.0
Avg Reward: 10.775
Min Reward: 5.0
Max Reward: 18.0
Gini Coefficient: 0.14170533642691416
20:20 Ratio: 2.0892857142857144
Max-min Ratio: 3.6
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-08_07-58-44
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 482.0
  episode_reward_mean: 444.71
  episode_reward_min: 421.0
  episodes_this_iter: 1
  episodes_total: 433
  experiment_id: 4e724eb5b3a34f42879644e84578eec0
  hostname: gpu024
  info:
    apply_time_ms: 2.522
    dispatch_time_ms: 5.744
    learner:
      cur_lr: 0.00020648799545597285
      grad_gnorm: 0.34685736894607544
      policy_entropy: 776.7590942382812
      policy_loss: -0.055258095264434814
      var_gnorm: 39.456756591796875
      vf_explained_var: -1.0
      vf_loss: 0.0007319637225009501
    num_steps_sampled: 17360000
    num_steps_trained: 17360000
    wait_time_ms: 564.693
  iterations_since_restore: 434
  node_ip: 172.17.8.24
  num_metric_batches_dropped: 0
  pid: 26970
  policy_reward_mean: {}
  time_since_restore: 24523.26117682457
  time_this_iter_s: 56.571513175964355
  time_total_s: 24523.26117682457
  timestamp: 1594209524
  timesteps_since_restore: 17360000
  timesteps_this_iter: 40000
  timesteps_total: 17360000
  training_iteration: 434
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26970], 24523 s, 434 iter, 17360000 ts, 445 rew

agent-1: 10.0
agent-2: 15.0
agent-3: 16.0
agent-4: 13.0
agent-5: 12.0
agent-6: 9.0
agent-7: 4.0
agent-8: 10.0
agent-9: 8.0
agent-10: 14.0
agent-11: 9.0
agent-12: 14.0
agent-13: 10.0
agent-14: 16.0
agent-15: 14.0
agent-16: 8.0
agent-17: 11.0
agent-18: 14.0
agent-19: 13.0
agent-20: 13.0
agent-21: 5.0
agent-22: 13.0
agent-23: 10.0
agent-24: 14.0
agent-25: 10.0
agent-26: 10.0
agent-27: 6.0
agent-28: 10.0
agent-29: 13.0
agent-30: 13.0
agent-31: 14.0
agent-32: 8.0
agent-33: 10.0
agent-34: 8.0
agent-35: 4.0
agent-36: 7.0
agent-37: 9.0
agent-38: 14.0
agent-39: 13.0
agent-40: 7.0
Sum Reward: 431.0
Avg Reward: 10.775
Min Reward: 4.0
Max Reward: 16.0
Gini Coefficient: 0.1658352668213457
20:20 Ratio: 2.3877551020408165
Max-min Ratio: 4.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-08_07-59-40
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 482.0
  episode_reward_mean: 444.52
  episode_reward_min: 421.0
  episodes_this_iter: 1
  episodes_total: 434
  experiment_id: 4e724eb5b3a34f42879644e84578eec0
  hostname: gpu024
  info:
    apply_time_ms: 3.153
    dispatch_time_ms: 6.146
    learner:
      cur_lr: 0.0002038240054389462
      grad_gnorm: 0.3998049795627594
      policy_entropy: 777.259521484375
      policy_loss: -0.7111161947250366
      var_gnorm: 39.44932174682617
      vf_explained_var: -1.0
      vf_loss: 4.044049637741409e-05
    num_steps_sampled: 17400000
    num_steps_trained: 17400000
    wait_time_ms: 570.139
  iterations_since_restore: 435
  node_ip: 172.17.8.24
  num_metric_batches_dropped: 0
  pid: 26970
  policy_reward_mean: {}
  time_since_restore: 24579.402626514435
  time_this_iter_s: 56.14144968986511
  time_total_s: 24579.402626514435
  timestamp: 1594209580
  timesteps_since_restore: 17400000
  timesteps_this_iter: 40000
  timesteps_total: 17400000
  training_iteration: 435
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26970], 24579 s, 435 iter, 17400000 ts, 445 rew

agent-1: 5.0
agent-2: 12.0
agent-3: 8.0
agent-4: 11.0
agent-5: 13.0
agent-6: 14.0
agent-7: 16.0
agent-8: 13.0
agent-9: 8.0
agent-10: 9.0
agent-11: 12.0
agent-12: 12.0
agent-13: 11.0
agent-14: 14.0
agent-15: 10.0
agent-16: 14.0
agent-17: 11.0
agent-18: 18.0
agent-19: 9.0
agent-20: 9.0
agent-21: 13.0
agent-22: 10.0
agent-23: 8.0
agent-24: 10.0
agent-25: 11.0
agent-26: 14.0
agent-27: 6.0
agent-28: 12.0
agent-29: 11.0
agent-30: 14.0
agent-31: 13.0
agent-32: 9.0
agent-33: 8.0
agent-34: 12.0
agent-35: 9.0
agent-36: 17.0
agent-37: 9.0
agent-38: 10.0
agent-39: 16.0
agent-40: 10.0
Sum Reward: 451.0
Avg Reward: 11.275
Min Reward: 5.0
Max Reward: 18.0
Gini Coefficient: 0.1414079822616408
20:20 Ratio: 2.0163934426229506
Max-min Ratio: 3.6
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-08_08-00-37
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 482.0
  episode_reward_mean: 444.57
  episode_reward_min: 421.0
  episodes_this_iter: 1
  episodes_total: 435
  experiment_id: 4e724eb5b3a34f42879644e84578eec0
  hostname: gpu024
  info:
    apply_time_ms: 2.761
    dispatch_time_ms: 7.578
    learner:
      cur_lr: 0.0002011600008700043
      grad_gnorm: 0.37447890639305115
      policy_entropy: 775.5057983398438
      policy_loss: -0.29160934686660767
      var_gnorm: 39.459388732910156
      vf_explained_var: -1.0
      vf_loss: 7.836773875169456e-05
    num_steps_sampled: 17440000
    num_steps_trained: 17440000
    wait_time_ms: 559.645
  iterations_since_restore: 436
  node_ip: 172.17.8.24
  num_metric_batches_dropped: 0
  pid: 26970
  policy_reward_mean: {}
  time_since_restore: 24636.158231019974
  time_this_iter_s: 56.75560450553894
  time_total_s: 24636.158231019974
  timestamp: 1594209637
  timesteps_since_restore: 17440000
  timesteps_this_iter: 40000
  timesteps_total: 17440000
  training_iteration: 436
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26970], 24636 s, 436 iter, 17440000 ts, 445 rew

agent-1: 13.0
agent-2: 9.0
agent-3: 7.0
agent-4: 9.0
agent-5: 9.0
agent-6: 12.0
agent-7: 9.0
agent-8: 9.0
agent-9: 14.0
agent-10: 10.0
agent-11: 8.0
agent-12: 21.0
agent-13: 10.0
agent-14: 10.0
agent-15: 13.0
agent-16: 9.0
agent-17: 11.0
agent-18: 12.0
agent-19: 9.0
agent-20: 11.0
agent-21: 9.0
agent-22: 9.0
agent-23: 15.0
agent-24: 11.0
agent-25: 13.0
agent-26: 13.0
agent-27: 10.0
agent-28: 10.0
agent-29: 19.0
agent-30: 13.0
agent-31: 15.0
agent-32: 6.0
agent-33: 8.0
agent-34: 8.0
agent-35: 13.0
agent-36: 18.0
agent-37: 13.0
agent-38: 11.0
agent-39: 9.0
agent-40: 12.0
Sum Reward: 450.0
Avg Reward: 11.25
Min Reward: 6.0
Max Reward: 21.0
Gini Coefficient: 0.1481111111111111
20:20 Ratio: 2.0
Max-min Ratio: 3.5
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-08_08-01-33
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 482.0
  episode_reward_mean: 444.56
  episode_reward_min: 421.0
  episodes_this_iter: 1
  episodes_total: 436
  experiment_id: 4e724eb5b3a34f42879644e84578eec0
  hostname: gpu024
  info:
    apply_time_ms: 2.358
    dispatch_time_ms: 6.996
    learner:
      cur_lr: 0.0001984959963010624
      grad_gnorm: 1.957877278327942
      policy_entropy: 754.1029052734375
      policy_loss: 0.2234068214893341
      var_gnorm: 39.459590911865234
      vf_explained_var: 0.031834304332733154
      vf_loss: 0.012183258309960365
    num_steps_sampled: 17480000
    num_steps_trained: 17480000
    wait_time_ms: 554.81
  iterations_since_restore: 437
  node_ip: 172.17.8.24
  num_metric_batches_dropped: 0
  pid: 26970
  policy_reward_mean: {}
  time_since_restore: 24692.203658103943
  time_this_iter_s: 56.045427083969116
  time_total_s: 24692.203658103943
  timestamp: 1594209693
  timesteps_since_restore: 17480000
  timesteps_this_iter: 40000
  timesteps_total: 17480000
  training_iteration: 437
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26970], 24692 s, 437 iter, 17480000 ts, 445 rew

agent-1: 15.0
agent-2: 14.0
agent-3: 9.0
agent-4: 16.0
agent-5: 16.0
agent-6: 10.0
agent-7: 14.0
agent-8: 9.0
agent-9: 12.0
agent-10: 8.0
agent-11: 9.0
agent-12: 4.0
agent-13: 18.0
agent-14: 8.0
agent-15: 10.0
agent-16: 5.0
agent-17: 10.0
agent-18: 9.0
agent-19: 10.0
agent-20: 12.0
agent-21: 8.0
agent-22: 5.0
agent-23: 13.0
agent-24: 10.0
agent-25: 13.0
agent-26: 14.0
agent-27: 12.0
agent-28: 13.0
agent-29: 8.0
agent-30: 8.0
agent-31: 16.0
agent-32: 9.0
agent-33: 15.0
agent-34: 8.0
agent-35: 11.0
agent-36: 12.0
agent-37: 14.0
agent-38: 15.0
agent-39: 10.0
agent-40: 9.0
Sum Reward: 441.0
Avg Reward: 11.025
Min Reward: 4.0
Max Reward: 18.0
Gini Coefficient: 0.16763038548752834
20:20 Ratio: 2.314814814814815
Max-min Ratio: 4.5
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-08_08-02-29
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 482.0
  episode_reward_mean: 444.26
  episode_reward_min: 421.0
  episodes_this_iter: 1
  episodes_total: 437
  experiment_id: 4e724eb5b3a34f42879644e84578eec0
  hostname: gpu024
  info:
    apply_time_ms: 2.851
    dispatch_time_ms: 6.397
    learner:
      cur_lr: 0.00019583200628403574
      grad_gnorm: 2.5938291549682617
      policy_entropy: 775.510986328125
      policy_loss: 0.05211030691862106
      var_gnorm: 39.45867156982422
      vf_explained_var: -1.0
      vf_loss: 0.0008886923897080123
    num_steps_sampled: 17520000
    num_steps_trained: 17520000
    wait_time_ms: 561.402
  iterations_since_restore: 438
  node_ip: 172.17.8.24
  num_metric_batches_dropped: 0
  pid: 26970
  policy_reward_mean: {}
  time_since_restore: 24748.83876132965
  time_this_iter_s: 56.63510322570801
  time_total_s: 24748.83876132965
  timestamp: 1594209749
  timesteps_since_restore: 17520000
  timesteps_this_iter: 40000
  timesteps_total: 17520000
  training_iteration: 438
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26970], 24748 s, 438 iter, 17520000 ts, 444 rew

agent-1: 12.0
agent-2: 16.0
agent-3: 11.0
agent-4: 13.0
agent-5: 9.0
agent-6: 9.0
agent-7: 13.0
agent-8: 7.0
agent-9: 6.0
agent-10: 10.0
agent-11: 11.0
agent-12: 7.0
agent-13: 13.0
agent-14: 11.0
agent-15: 16.0
agent-16: 13.0
agent-17: 16.0
agent-18: 8.0
agent-19: 9.0
agent-20: 11.0
agent-21: 10.0
agent-22: 6.0
agent-23: 13.0
agent-24: 12.0
agent-25: 8.0
agent-26: 12.0
agent-27: 11.0
agent-28: 15.0
agent-29: 13.0
agent-30: 15.0
agent-31: 14.0
agent-32: 10.0
agent-33: 12.0
agent-34: 15.0
agent-35: 14.0
agent-36: 14.0
agent-37: 11.0
agent-38: 9.0
agent-39: 11.0
agent-40: 13.0
Sum Reward: 459.0
Avg Reward: 11.475
Min Reward: 6.0
Max Reward: 16.0
Gini Coefficient: 0.13360566448801742
20:20 Ratio: 2.0166666666666666
Max-min Ratio: 2.6666666666666665
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-08_08-03-26
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 482.0
  episode_reward_mean: 444.39
  episode_reward_min: 421.0
  episodes_this_iter: 1
  episodes_total: 438
  experiment_id: 4e724eb5b3a34f42879644e84578eec0
  hostname: gpu024
  info:
    apply_time_ms: 2.882
    dispatch_time_ms: 8.215
    learner:
      cur_lr: 0.00019316800171509385
      grad_gnorm: 1.4743467569351196
      policy_entropy: 772.5669555664062
      policy_loss: -0.7576724886894226
      var_gnorm: 39.47075653076172
      vf_explained_var: -1.0
      vf_loss: 0.001255248673260212
    num_steps_sampled: 17560000
    num_steps_trained: 17560000
    wait_time_ms: 556.417
  iterations_since_restore: 439
  node_ip: 172.17.8.24
  num_metric_batches_dropped: 0
  pid: 26970
  policy_reward_mean: {}
  time_since_restore: 24805.706054210663
  time_this_iter_s: 56.86729288101196
  time_total_s: 24805.706054210663
  timestamp: 1594209806
  timesteps_since_restore: 17560000
  timesteps_this_iter: 40000
  timesteps_total: 17560000
  training_iteration: 439
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26970], 24805 s, 439 iter, 17560000 ts, 444 rew

agent-1: 9.0
agent-2: 12.0
agent-3: 13.0
agent-4: 15.0
agent-5: 17.0
agent-6: 11.0
agent-7: 13.0
agent-8: 8.0
agent-9: 18.0
agent-10: 16.0
agent-11: 5.0
agent-12: 10.0
agent-13: 11.0
agent-14: 14.0
agent-15: 12.0
agent-16: 10.0
agent-17: 11.0
agent-18: 8.0
agent-19: 13.0
agent-20: 14.0
agent-21: 9.0
agent-22: 10.0
agent-23: 14.0
agent-24: 7.0
agent-25: 11.0
agent-26: 12.0
agent-27: 9.0
agent-28: 10.0
agent-29: 12.0
agent-30: 4.0
agent-31: 10.0
agent-32: 15.0
agent-33: 15.0
agent-34: 8.0
agent-35: 8.0
agent-36: 13.0
agent-37: 11.0
agent-38: 9.0
agent-39: 16.0
agent-40: 10.0
Sum Reward: 453.0
Avg Reward: 11.325
Min Reward: 4.0
Max Reward: 18.0
Gini Coefficient: 0.1541390728476821
20:20 Ratio: 2.210526315789474
Max-min Ratio: 4.5
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-08_08-04-23
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 482.0
  episode_reward_mean: 444.21
  episode_reward_min: 421.0
  episodes_this_iter: 1
  episodes_total: 439
  experiment_id: 4e724eb5b3a34f42879644e84578eec0
  hostname: gpu024
  info:
    apply_time_ms: 3.748
    dispatch_time_ms: 5.726
    learner:
      cur_lr: 0.00019050399714615196
      grad_gnorm: 0.893698513507843
      policy_entropy: 776.8929443359375
      policy_loss: -0.5174278616905212
      var_gnorm: 39.469234466552734
      vf_explained_var: -1.0
      vf_loss: 0.001265564700588584
    num_steps_sampled: 17600000
    num_steps_trained: 17600000
    wait_time_ms: 548.586
  iterations_since_restore: 440
  node_ip: 172.17.8.24
  num_metric_batches_dropped: 0
  pid: 26970
  policy_reward_mean: {}
  time_since_restore: 24862.058194875717
  time_this_iter_s: 56.35214066505432
  time_total_s: 24862.058194875717
  timestamp: 1594209863
  timesteps_since_restore: 17600000
  timesteps_this_iter: 40000
  timesteps_total: 17600000
  training_iteration: 440
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26970], 24862 s, 440 iter, 17600000 ts, 444 rew

agent-1: 11.0
agent-2: 8.0
agent-3: 13.0
agent-4: 13.0
agent-5: 11.0
agent-6: 16.0
agent-7: 9.0
agent-8: 8.0
agent-9: 8.0
agent-10: 15.0
agent-11: 11.0
agent-12: 11.0
agent-13: 9.0
agent-14: 8.0
agent-15: 12.0
agent-16: 11.0
agent-17: 14.0
agent-18: 10.0
agent-19: 16.0
agent-20: 13.0
agent-21: 12.0
agent-22: 14.0
agent-23: 14.0
agent-24: 14.0
agent-25: 13.0
agent-26: 9.0
agent-27: 14.0
agent-28: 15.0
agent-29: 10.0
agent-30: 11.0
agent-31: 8.0
agent-32: 8.0
agent-33: 10.0
agent-34: 8.0
agent-35: 6.0
agent-36: 8.0
agent-37: 10.0
agent-38: 7.0
agent-39: 11.0
agent-40: 12.0
Sum Reward: 441.0
Avg Reward: 11.025
Min Reward: 6.0
Max Reward: 16.0
Gini Coefficient: 0.13554421768707484
20:20 Ratio: 1.9344262295081966
Max-min Ratio: 2.6666666666666665
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-08_08-05-19
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 482.0
  episode_reward_mean: 444.0
  episode_reward_min: 421.0
  episodes_this_iter: 1
  episodes_total: 440
  experiment_id: 4e724eb5b3a34f42879644e84578eec0
  hostname: gpu024
  info:
    apply_time_ms: 2.439
    dispatch_time_ms: 6.27
    learner:
      cur_lr: 0.0001878400071291253
      grad_gnorm: 2.5910286903381348
      policy_entropy: 773.7442626953125
      policy_loss: 0.253043532371521
      var_gnorm: 39.475772857666016
      vf_explained_var: -0.7524306774139404
      vf_loss: 0.007240724749863148
    num_steps_sampled: 17640000
    num_steps_trained: 17640000
    wait_time_ms: 568.466
  iterations_since_restore: 441
  node_ip: 172.17.8.24
  num_metric_batches_dropped: 0
  pid: 26970
  policy_reward_mean: {}
  time_since_restore: 24918.657759666443
  time_this_iter_s: 56.59956479072571
  time_total_s: 24918.657759666443
  timestamp: 1594209919
  timesteps_since_restore: 17640000
  timesteps_this_iter: 40000
  timesteps_total: 17640000
  training_iteration: 441
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26970], 24918 s, 441 iter, 17640000 ts, 444 rew

agent-1: 13.0
agent-2: 8.0
agent-3: 12.0
agent-4: 12.0
agent-5: 10.0
agent-6: 8.0
agent-7: 17.0
agent-8: 15.0
agent-9: 13.0
agent-10: 14.0
agent-11: 8.0
agent-12: 4.0
agent-13: 12.0
agent-14: 11.0
agent-15: 12.0
agent-16: 10.0
agent-17: 12.0
agent-18: 13.0
agent-19: 8.0
agent-20: 15.0
agent-21: 6.0
agent-22: 18.0
agent-23: 8.0
agent-24: 15.0
agent-25: 6.0
agent-26: 9.0
agent-27: 9.0
agent-28: 8.0
agent-29: 14.0
agent-30: 17.0
agent-31: 10.0
agent-32: 13.0
agent-33: 13.0
agent-34: 12.0
agent-35: 14.0
agent-36: 12.0
agent-37: 12.0
agent-38: 10.0
agent-39: 16.0
agent-40: 5.0
Sum Reward: 454.0
Avg Reward: 11.35
Min Reward: 4.0
Max Reward: 18.0
Gini Coefficient: 0.16596916299559472
20:20 Ratio: 2.3962264150943398
Max-min Ratio: 4.5
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-08_08-06-16
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 482.0
  episode_reward_mean: 444.06
  episode_reward_min: 421.0
  episodes_this_iter: 1
  episodes_total: 441
  experiment_id: 4e724eb5b3a34f42879644e84578eec0
  hostname: gpu024
  info:
    apply_time_ms: 3.478
    dispatch_time_ms: 5.487
    learner:
      cur_lr: 0.0001851760025601834
      grad_gnorm: 0.7151268124580383
      policy_entropy: 772.14013671875
      policy_loss: 0.32847481966018677
      var_gnorm: 39.48813247680664
      vf_explained_var: -0.9406445026397705
      vf_loss: 0.005229996517300606
    num_steps_sampled: 17680000
    num_steps_trained: 17680000
    wait_time_ms: 563.739
  iterations_since_restore: 442
  node_ip: 172.17.8.24
  num_metric_batches_dropped: 0
  pid: 26970
  policy_reward_mean: {}
  time_since_restore: 24975.226848840714
  time_this_iter_s: 56.56908917427063
  time_total_s: 24975.226848840714
  timestamp: 1594209976
  timesteps_since_restore: 17680000
  timesteps_this_iter: 40000
  timesteps_total: 17680000
  training_iteration: 442
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26970], 24975 s, 442 iter, 17680000 ts, 444 rew

agent-1: 6.0
agent-2: 15.0
agent-3: 14.0
agent-4: 12.0
agent-5: 9.0
agent-6: 11.0
agent-7: 12.0
agent-8: 11.0
agent-9: 13.0
agent-10: 13.0
agent-11: 7.0
agent-12: 10.0
agent-13: 14.0
agent-14: 5.0
agent-15: 2.0
agent-16: 9.0
agent-17: 9.0
agent-18: 13.0
agent-19: 13.0
agent-20: 15.0
agent-21: 11.0
agent-22: 7.0
agent-23: 8.0
agent-24: 10.0
agent-25: 16.0
agent-26: 16.0
agent-27: 15.0
agent-28: 14.0
agent-29: 10.0
agent-30: 15.0
agent-31: 11.0
agent-32: 8.0
agent-33: 8.0
agent-34: 13.0
agent-35: 8.0
agent-36: 11.0
agent-37: 10.0
agent-38: 7.0
agent-39: 13.0
agent-40: 15.0
Sum Reward: 439.0
Avg Reward: 10.975
Min Reward: 2.0
Max Reward: 16.0
Gini Coefficient: 0.16725512528473804
20:20 Ratio: 2.42
Max-min Ratio: 8.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-08_08-07-12
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 482.0
  episode_reward_mean: 443.63
  episode_reward_min: 421.0
  episodes_this_iter: 1
  episodes_total: 442
  experiment_id: 4e724eb5b3a34f42879644e84578eec0
  hostname: gpu024
  info:
    apply_time_ms: 2.754
    dispatch_time_ms: 6.131
    learner:
      cur_lr: 0.00018251199799124151
      grad_gnorm: 3.1679015159606934
      policy_entropy: 775.1356811523438
      policy_loss: -0.08602263033390045
      var_gnorm: 39.48611068725586
      vf_explained_var: -1.0
      vf_loss: 0.0008394084288738668
    num_steps_sampled: 17720000
    num_steps_trained: 17720000
    wait_time_ms: 567.481
  iterations_since_restore: 443
  node_ip: 172.17.8.24
  num_metric_batches_dropped: 0
  pid: 26970
  policy_reward_mean: {}
  time_since_restore: 25031.66803908348
  time_this_iter_s: 56.441190242767334
  time_total_s: 25031.66803908348
  timestamp: 1594210032
  timesteps_since_restore: 17720000
  timesteps_this_iter: 40000
  timesteps_total: 17720000
  training_iteration: 443
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26970], 25031 s, 443 iter, 17720000 ts, 444 rew

agent-1: 10.0
agent-2: 13.0
agent-3: 4.0
agent-4: 17.0
agent-5: 11.0
agent-6: 9.0
agent-7: 7.0
agent-8: 10.0
agent-9: 11.0
agent-10: 10.0
agent-11: 8.0
agent-12: 15.0
agent-13: 10.0
agent-14: 6.0
agent-15: 12.0
agent-16: 12.0
agent-17: 9.0
agent-18: 11.0
agent-19: 13.0
agent-20: 14.0
agent-21: 14.0
agent-22: 15.0
agent-23: 12.0
agent-24: 12.0
agent-25: 11.0
agent-26: 10.0
agent-27: 15.0
agent-28: 7.0
agent-29: 14.0
agent-30: 11.0
agent-31: 13.0
agent-32: 10.0
agent-33: 8.0
agent-34: 18.0
agent-35: 8.0
agent-36: 14.0
agent-37: 6.0
agent-38: 13.0
agent-39: 12.0
agent-40: 13.0
Sum Reward: 448.0
Avg Reward: 11.2
Min Reward: 4.0
Max Reward: 18.0
Gini Coefficient: 0.1513392857142857
20:20 Ratio: 2.259259259259259
Max-min Ratio: 4.5
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-08_08-08-09
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 482.0
  episode_reward_mean: 443.56
  episode_reward_min: 421.0
  episodes_this_iter: 1
  episodes_total: 443
  experiment_id: 4e724eb5b3a34f42879644e84578eec0
  hostname: gpu024
  info:
    apply_time_ms: 2.999
    dispatch_time_ms: 6.614
    learner:
      cur_lr: 0.00017984799342229962
      grad_gnorm: 0.25913169980049133
      policy_entropy: 775.840576171875
      policy_loss: -0.06914140284061432
      var_gnorm: 39.47630310058594
      vf_explained_var: -1.0
      vf_loss: 0.00036678483593277633
    num_steps_sampled: 17760000
    num_steps_trained: 17760000
    wait_time_ms: 555.384
  iterations_since_restore: 444
  node_ip: 172.17.8.24
  num_metric_batches_dropped: 0
  pid: 26970
  policy_reward_mean: {}
  time_since_restore: 25088.193114042282
  time_this_iter_s: 56.52507495880127
  time_total_s: 25088.193114042282
  timestamp: 1594210089
  timesteps_since_restore: 17760000
  timesteps_this_iter: 40000
  timesteps_total: 17760000
  training_iteration: 444
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26970], 25088 s, 444 iter, 17760000 ts, 444 rew

agent-1: 5.0
agent-2: 11.0
agent-3: 12.0
agent-4: 17.0
agent-5: 16.0
agent-6: 8.0
agent-7: 6.0
agent-8: 11.0
agent-9: 10.0
agent-10: 10.0
agent-11: 10.0
agent-12: 11.0
agent-13: 13.0
agent-14: 9.0
agent-15: 15.0
agent-16: 7.0
agent-17: 13.0
agent-18: 9.0
agent-19: 15.0
agent-20: 11.0
agent-21: 11.0
agent-22: 10.0
agent-23: 10.0
agent-24: 9.0
agent-25: 11.0
agent-26: 14.0
agent-27: 13.0
agent-28: 13.0
agent-29: 9.0
agent-30: 9.0
agent-31: 16.0
agent-32: 11.0
agent-33: 18.0
agent-34: 11.0
agent-35: 5.0
agent-36: 14.0
agent-37: 12.0
agent-38: 15.0
agent-39: 10.0
agent-40: 9.0
Sum Reward: 449.0
Avg Reward: 11.225
Min Reward: 5.0
Max Reward: 18.0
Gini Coefficient: 0.15094654788418707
20:20 Ratio: 2.1724137931034484
Max-min Ratio: 3.6
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-08_08-09-06
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 482.0
  episode_reward_mean: 443.56
  episode_reward_min: 421.0
  episodes_this_iter: 1
  episodes_total: 444
  experiment_id: 4e724eb5b3a34f42879644e84578eec0
  hostname: gpu024
  info:
    apply_time_ms: 3.838
    dispatch_time_ms: 5.794
    learner:
      cur_lr: 0.00017718400340527296
      grad_gnorm: 0.6308422088623047
      policy_entropy: 773.5115356445312
      policy_loss: 0.06514528393745422
      var_gnorm: 39.463111877441406
      vf_explained_var: -1.0
      vf_loss: 0.000860871747136116
    num_steps_sampled: 17800000
    num_steps_trained: 17800000
    wait_time_ms: 559.814
  iterations_since_restore: 445
  node_ip: 172.17.8.24
  num_metric_batches_dropped: 0
  pid: 26970
  policy_reward_mean: {}
  time_since_restore: 25144.788684368134
  time_this_iter_s: 56.59557032585144
  time_total_s: 25144.788684368134
  timestamp: 1594210146
  timesteps_since_restore: 17800000
  timesteps_this_iter: 40000
  timesteps_total: 17800000
  training_iteration: 445
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26970], 25144 s, 445 iter, 17800000 ts, 444 rew

agent-1: 14.0
agent-2: 10.0
agent-3: 10.0
agent-4: 11.0
agent-5: 11.0
agent-6: 12.0
agent-7: 13.0
agent-8: 8.0
agent-9: 6.0
agent-10: 15.0
agent-11: 9.0
agent-12: 7.0
agent-13: 18.0
agent-14: 13.0
agent-15: 10.0
agent-16: 11.0
agent-17: 8.0
agent-18: 17.0
agent-19: 10.0
agent-20: 13.0
agent-21: 15.0
agent-22: 10.0
agent-23: 19.0
agent-24: 9.0
agent-25: 10.0
agent-26: 11.0
agent-27: 14.0
agent-28: 9.0
agent-29: 13.0
agent-30: 13.0
agent-31: 13.0
agent-32: 9.0
agent-33: 10.0
agent-34: 13.0
agent-35: 10.0
agent-36: 8.0
agent-37: 12.0
agent-38: 12.0
agent-39: 9.0
agent-40: 9.0
Sum Reward: 454.0
Avg Reward: 11.35
Min Reward: 6.0
Max Reward: 19.0
Gini Coefficient: 0.13799559471365638
20:20 Ratio: 1.953125
Max-min Ratio: 3.1666666666666665
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-08_08-10-02
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 482.0
  episode_reward_mean: 443.68
  episode_reward_min: 421.0
  episodes_this_iter: 1
  episodes_total: 445
  experiment_id: 4e724eb5b3a34f42879644e84578eec0
  hostname: gpu024
  info:
    apply_time_ms: 2.364
    dispatch_time_ms: 6.159
    learner:
      cur_lr: 0.00017451999883633107
      grad_gnorm: 0.348911315202713
      policy_entropy: 776.0196533203125
      policy_loss: 0.05994702875614166
      var_gnorm: 39.46437072753906
      vf_explained_var: -1.0
      vf_loss: 0.00010932733857771382
    num_steps_sampled: 17840000
    num_steps_trained: 17840000
    wait_time_ms: 566.334
  iterations_since_restore: 446
  node_ip: 172.17.8.24
  num_metric_batches_dropped: 0
  pid: 26970
  policy_reward_mean: {}
  time_since_restore: 25201.293026685715
  time_this_iter_s: 56.50434231758118
  time_total_s: 25201.293026685715
  timestamp: 1594210202
  timesteps_since_restore: 17840000
  timesteps_this_iter: 40000
  timesteps_total: 17840000
  training_iteration: 446
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26970], 25201 s, 446 iter, 17840000 ts, 444 rew

agent-1: 17.0
agent-2: 13.0
agent-3: 13.0
agent-4: 7.0
agent-5: 17.0
agent-6: 7.0
agent-7: 13.0
agent-8: 18.0
agent-9: 9.0
agent-10: 13.0
agent-11: 16.0
agent-12: 9.0
agent-13: 10.0
agent-14: 11.0
agent-15: 17.0
agent-16: 15.0
agent-17: 9.0
agent-18: 10.0
agent-19: 6.0
agent-20: 7.0
agent-21: 14.0
agent-22: 16.0
agent-23: 11.0
agent-24: 7.0
agent-25: 12.0
agent-26: 11.0
agent-27: 11.0
agent-28: 6.0
agent-29: 13.0
agent-30: 13.0
agent-31: 9.0
agent-32: 7.0
agent-33: 7.0
agent-34: 9.0
agent-35: 10.0
agent-36: 10.0
agent-37: 11.0
agent-38: 10.0
agent-39: 12.0
agent-40: 6.0
Sum Reward: 442.0
Avg Reward: 11.05
Min Reward: 6.0
Max Reward: 18.0
Gini Coefficient: 0.17273755656108597
20:20 Ratio: 2.452830188679245
Max-min Ratio: 3.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-08_08-10-59
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 468.0
  episode_reward_mean: 443.28
  episode_reward_min: 421.0
  episodes_this_iter: 1
  episodes_total: 446
  experiment_id: 4e724eb5b3a34f42879644e84578eec0
  hostname: gpu024
  info:
    apply_time_ms: 2.533
    dispatch_time_ms: 5.286
    learner:
      cur_lr: 0.00017185599426738918
      grad_gnorm: 1.7319649457931519
      policy_entropy: 766.987548828125
      policy_loss: -1.1226890087127686
      var_gnorm: 39.46479797363281
      vf_explained_var: -1.0
      vf_loss: 0.0007801303872838616
    num_steps_sampled: 17880000
    num_steps_trained: 17880000
    wait_time_ms: 566.07
  iterations_since_restore: 447
  node_ip: 172.17.8.24
  num_metric_batches_dropped: 0
  pid: 26970
  policy_reward_mean: {}
  time_since_restore: 25257.636671066284
  time_this_iter_s: 56.34364438056946
  time_total_s: 25257.636671066284
  timestamp: 1594210259
  timesteps_since_restore: 17880000
  timesteps_this_iter: 40000
  timesteps_total: 17880000
  training_iteration: 447
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26970], 25257 s, 447 iter, 17880000 ts, 443 rew

agent-1: 12.0
agent-2: 16.0
agent-3: 4.0
agent-4: 11.0
agent-5: 12.0
agent-6: 10.0
agent-7: 15.0
agent-8: 9.0
agent-9: 10.0
agent-10: 8.0
agent-11: 10.0
agent-12: 13.0
agent-13: 9.0
agent-14: 12.0
agent-15: 7.0
agent-16: 3.0
agent-17: 14.0
agent-18: 15.0
agent-19: 21.0
agent-20: 10.0
agent-21: 7.0
agent-22: 7.0
agent-23: 15.0
agent-24: 11.0
agent-25: 9.0
agent-26: 5.0
agent-27: 16.0
agent-28: 19.0
agent-29: 8.0
agent-30: 12.0
agent-31: 12.0
agent-32: 8.0
agent-33: 12.0
agent-34: 11.0
agent-35: 10.0
agent-36: 9.0
agent-37: 17.0
agent-38: 13.0
agent-39: 6.0
agent-40: 9.0
Sum Reward: 437.0
Avg Reward: 10.925
Min Reward: 3.0
Max Reward: 21.0
Gini Coefficient: 0.19662471395881007
20:20 Ratio: 2.851063829787234
Max-min Ratio: 7.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-08_08-11-55
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 468.0
  episode_reward_mean: 443.23
  episode_reward_min: 421.0
  episodes_this_iter: 1
  episodes_total: 447
  experiment_id: 4e724eb5b3a34f42879644e84578eec0
  hostname: gpu024
  info:
    apply_time_ms: 2.521
    dispatch_time_ms: 5.718
    learner:
      cur_lr: 0.00016919200425036252
      grad_gnorm: 0.37427636981010437
      policy_entropy: 776.5653076171875
      policy_loss: -0.14429262280464172
      var_gnorm: 39.47486877441406
      vf_explained_var: -1.0
      vf_loss: 0.00011393360910005867
    num_steps_sampled: 17920000
    num_steps_trained: 17920000
    wait_time_ms: 561.611
  iterations_since_restore: 448
  node_ip: 172.17.8.24
  num_metric_batches_dropped: 0
  pid: 26970
  policy_reward_mean: {}
  time_since_restore: 25313.905615091324
  time_this_iter_s: 56.26894402503967
  time_total_s: 25313.905615091324
  timestamp: 1594210315
  timesteps_since_restore: 17920000
  timesteps_this_iter: 40000
  timesteps_total: 17920000
  training_iteration: 448
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26970], 25313 s, 448 iter, 17920000 ts, 443 rew

agent-1: 9.0
agent-2: 7.0
agent-3: 10.0
agent-4: 19.0
agent-5: 11.0
agent-6: 10.0
agent-7: 6.0
agent-8: 10.0
agent-9: 10.0
agent-10: 12.0
agent-11: 12.0
agent-12: 12.0
agent-13: 12.0
agent-14: 10.0
agent-15: 14.0
agent-16: 9.0
agent-17: 6.0
agent-18: 13.0
agent-19: 11.0
agent-20: 12.0
agent-21: 12.0
agent-22: 7.0
agent-23: 6.0
agent-24: 7.0
agent-25: 16.0
agent-26: 11.0
agent-27: 12.0
agent-28: 13.0
agent-29: 17.0
agent-30: 14.0
agent-31: 19.0
agent-32: 13.0
agent-33: 11.0
agent-34: 9.0
agent-35: 16.0
agent-36: 13.0
agent-37: 15.0
agent-38: 6.0
agent-39: 12.0
agent-40: 12.0
Sum Reward: 456.0
Avg Reward: 11.4
Min Reward: 6.0
Max Reward: 19.0
Gini Coefficient: 0.15975877192982457
20:20 Ratio: 2.4074074074074074
Max-min Ratio: 3.1666666666666665
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-08_08-12-51
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 468.0
  episode_reward_mean: 443.45
  episode_reward_min: 421.0
  episodes_this_iter: 1
  episodes_total: 448
  experiment_id: 4e724eb5b3a34f42879644e84578eec0
  hostname: gpu024
  info:
    apply_time_ms: 3.117
    dispatch_time_ms: 7.072
    learner:
      cur_lr: 0.00016652799968142062
      grad_gnorm: 2.21077299118042
      policy_entropy: 777.0942993164062
      policy_loss: 1.4518377780914307
      var_gnorm: 39.47954559326172
      vf_explained_var: -0.8182696104049683
      vf_loss: 0.0008410901064053178
    num_steps_sampled: 17960000
    num_steps_trained: 17960000
    wait_time_ms: 555.983
  iterations_since_restore: 449
  node_ip: 172.17.8.24
  num_metric_batches_dropped: 0
  pid: 26970
  policy_reward_mean: {}
  time_since_restore: 25370.439079284668
  time_this_iter_s: 56.533464193344116
  time_total_s: 25370.439079284668
  timestamp: 1594210371
  timesteps_since_restore: 17960000
  timesteps_this_iter: 40000
  timesteps_total: 17960000
  training_iteration: 449
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26970], 25370 s, 449 iter, 17960000 ts, 443 rew

agent-1: 12.0
agent-2: 5.0
agent-3: 15.0
agent-4: 9.0
agent-5: 9.0
agent-6: 9.0
agent-7: 14.0
agent-8: 10.0
agent-9: 12.0
agent-10: 14.0
agent-11: 12.0
agent-12: 7.0
agent-13: 12.0
agent-14: 8.0
agent-15: 18.0
agent-16: 15.0
agent-17: 6.0
agent-18: 12.0
agent-19: 9.0
agent-20: 15.0
agent-21: 17.0
agent-22: 18.0
agent-23: 10.0
agent-24: 19.0
agent-25: 10.0
agent-26: 6.0
agent-27: 12.0
agent-28: 7.0
agent-29: 10.0
agent-30: 11.0
agent-31: 7.0
agent-32: 12.0
agent-33: 15.0
agent-34: 12.0
agent-35: 11.0
agent-36: 15.0
agent-37: 10.0
agent-38: 10.0
agent-39: 12.0
agent-40: 13.0
Sum Reward: 460.0
Avg Reward: 11.5
Min Reward: 5.0
Max Reward: 19.0
Gini Coefficient: 0.1666304347826087
20:20 Ratio: 2.4
Max-min Ratio: 3.8
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-08_08-13-48
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 468.0
  episode_reward_mean: 443.55
  episode_reward_min: 421.0
  episodes_this_iter: 1
  episodes_total: 449
  experiment_id: 4e724eb5b3a34f42879644e84578eec0
  hostname: gpu024
  info:
    apply_time_ms: 2.764
    dispatch_time_ms: 5.735
    learner:
      cur_lr: 0.00016386399511247873
      grad_gnorm: 2.8198230266571045
      policy_entropy: 776.5362548828125
      policy_loss: 0.023778704926371574
      var_gnorm: 39.47596740722656
      vf_explained_var: -0.451326847076416
      vf_loss: 0.0004501554067246616
    num_steps_sampled: 18000000
    num_steps_trained: 18000000
    wait_time_ms: 557.013
  iterations_since_restore: 450
  node_ip: 172.17.8.24
  num_metric_batches_dropped: 0
  pid: 26970
  policy_reward_mean: {}
  time_since_restore: 25426.840395212173
  time_this_iter_s: 56.40131592750549
  time_total_s: 25426.840395212173
  timestamp: 1594210428
  timesteps_since_restore: 18000000
  timesteps_this_iter: 40000
  timesteps_total: 18000000
  training_iteration: 450
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26970], 25426 s, 450 iter, 18000000 ts, 444 rew

agent-1: 13.0
agent-2: 10.0
agent-3: 7.0
agent-4: 8.0
agent-5: 8.0
agent-6: 13.0
agent-7: 14.0
agent-8: 15.0
agent-9: 7.0
agent-10: 13.0
agent-11: 9.0
agent-12: 11.0
agent-13: 15.0
agent-14: 6.0
agent-15: 6.0
agent-16: 13.0
agent-17: 13.0
agent-18: 9.0
agent-19: 12.0
agent-20: 13.0
agent-21: 8.0
agent-22: 12.0
agent-23: 9.0
agent-24: 11.0
agent-25: 11.0
agent-26: 7.0
agent-27: 9.0
agent-28: 10.0
agent-29: 16.0
agent-30: 20.0
agent-31: 9.0
agent-32: 4.0
agent-33: 14.0
agent-34: 15.0
agent-35: 10.0
agent-36: 12.0
agent-37: 13.0
agent-38: 10.0
agent-39: 10.0
agent-40: 10.0
Sum Reward: 435.0
Avg Reward: 10.875
Min Reward: 4.0
Max Reward: 20.0
Gini Coefficient: 0.16258620689655173
20:20 Ratio: 2.30188679245283
Max-min Ratio: 5.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-08_08-14-45
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 468.0
  episode_reward_mean: 443.38
  episode_reward_min: 421.0
  episodes_this_iter: 1
  episodes_total: 450
  experiment_id: 4e724eb5b3a34f42879644e84578eec0
  hostname: gpu024
  info:
    apply_time_ms: 2.573
    dispatch_time_ms: 5.705
    learner:
      cur_lr: 0.00016120000509545207
      grad_gnorm: 1.6660454273223877
      policy_entropy: 776.361083984375
      policy_loss: -1.0151960849761963
      var_gnorm: 39.47550582885742
      vf_explained_var: -0.4017319679260254
      vf_loss: 0.001202598912641406
    num_steps_sampled: 18040000
    num_steps_trained: 18040000
    wait_time_ms: 557.893
  iterations_since_restore: 451
  node_ip: 172.17.8.24
  num_metric_batches_dropped: 0
  pid: 26970
  policy_reward_mean: {}
  time_since_restore: 25483.678832769394
  time_this_iter_s: 56.83843755722046
  time_total_s: 25483.678832769394
  timestamp: 1594210485
  timesteps_since_restore: 18040000
  timesteps_this_iter: 40000
  timesteps_total: 18040000
  training_iteration: 451
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26970], 25483 s, 451 iter, 18040000 ts, 443 rew

agent-1: 9.0
agent-2: 19.0
agent-3: 6.0
agent-4: 16.0
agent-5: 8.0
agent-6: 9.0
agent-7: 14.0
agent-8: 12.0
agent-9: 17.0
agent-10: 12.0
agent-11: 10.0
agent-12: 16.0
agent-13: 16.0
agent-14: 16.0
agent-15: 12.0
agent-16: 12.0
agent-17: 13.0
agent-18: 3.0
agent-19: 12.0
agent-20: 12.0
agent-21: 12.0
agent-22: 14.0
agent-23: 11.0
agent-24: 11.0
agent-25: 9.0
agent-26: 13.0
agent-27: 5.0
agent-28: 8.0
agent-29: 7.0
agent-30: 11.0
agent-31: 3.0
agent-32: 9.0
agent-33: 6.0
agent-34: 17.0
agent-35: 13.0
agent-36: 14.0
agent-37: 8.0
agent-38: 6.0
agent-39: 7.0
agent-40: 8.0
Sum Reward: 436.0
Avg Reward: 10.9
Min Reward: 3.0
Max Reward: 19.0
Gini Coefficient: 0.20275229357798166
20:20 Ratio: 3.046511627906977
Max-min Ratio: 6.333333333333333
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-08_08-15-41
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 468.0
  episode_reward_mean: 443.38
  episode_reward_min: 421.0
  episodes_this_iter: 1
  episodes_total: 451
  experiment_id: 4e724eb5b3a34f42879644e84578eec0
  hostname: gpu024
  info:
    apply_time_ms: 2.503
    dispatch_time_ms: 6.656
    learner:
      cur_lr: 0.00015853600052651018
      grad_gnorm: 1.0916976928710938
      policy_entropy: 776.4059448242188
      policy_loss: -0.02104470133781433
      var_gnorm: 39.475955963134766
      vf_explained_var: -1.0
      vf_loss: 0.00035690917866304517
    num_steps_sampled: 18080000
    num_steps_trained: 18080000
    wait_time_ms: 551.938
  iterations_since_restore: 452
  node_ip: 172.17.8.24
  num_metric_batches_dropped: 0
  pid: 26970
  policy_reward_mean: {}
  time_since_restore: 25540.276262521744
  time_this_iter_s: 56.59742975234985
  time_total_s: 25540.276262521744
  timestamp: 1594210541
  timesteps_since_restore: 18080000
  timesteps_this_iter: 40000
  timesteps_total: 18080000
  training_iteration: 452
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26970], 25540 s, 452 iter, 18080000 ts, 443 rew

agent-1: 9.0
agent-2: 12.0
agent-3: 5.0
agent-4: 10.0
agent-5: 17.0
agent-6: 12.0
agent-7: 13.0
agent-8: 9.0
agent-9: 11.0
agent-10: 16.0
agent-11: 11.0
agent-12: 13.0
agent-13: 19.0
agent-14: 7.0
agent-15: 5.0
agent-16: 10.0
agent-17: 16.0
agent-18: 14.0
agent-19: 11.0
agent-20: 14.0
agent-21: 5.0
agent-22: 8.0
agent-23: 9.0
agent-24: 11.0
agent-25: 10.0
agent-26: 10.0
agent-27: 8.0
agent-28: 16.0
agent-29: 12.0
agent-30: 9.0
agent-31: 11.0
agent-32: 10.0
agent-33: 14.0
agent-34: 6.0
agent-35: 15.0
agent-36: 9.0
agent-37: 4.0
agent-38: 15.0
agent-39: 14.0
agent-40: 14.0
Sum Reward: 444.0
Avg Reward: 11.1
Min Reward: 4.0
Max Reward: 19.0
Gini Coefficient: 0.1810810810810811
20:20 Ratio: 2.6666666666666665
Max-min Ratio: 4.75
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-08_08-16-38
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 468.0
  episode_reward_mean: 443.16
  episode_reward_min: 421.0
  episodes_this_iter: 1
  episodes_total: 452
  experiment_id: 4e724eb5b3a34f42879644e84578eec0
  hostname: gpu024
  info:
    apply_time_ms: 2.977
    dispatch_time_ms: 5.36
    learner:
      cur_lr: 0.0001558719959575683
      grad_gnorm: 2.0287137031555176
      policy_entropy: 776.44189453125
      policy_loss: 0.42432400584220886
      var_gnorm: 39.4830207824707
      vf_explained_var: -1.0
      vf_loss: 0.0009146079537458718
    num_steps_sampled: 18120000
    num_steps_trained: 18120000
    wait_time_ms: 574.843
  iterations_since_restore: 453
  node_ip: 172.17.8.24
  num_metric_batches_dropped: 0
  pid: 26970
  policy_reward_mean: {}
  time_since_restore: 25596.903736114502
  time_this_iter_s: 56.62747359275818
  time_total_s: 25596.903736114502
  timestamp: 1594210598
  timesteps_since_restore: 18120000
  timesteps_this_iter: 40000
  timesteps_total: 18120000
  training_iteration: 453
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26970], 25596 s, 453 iter, 18120000 ts, 443 rew

agent-1: 15.0
agent-2: 11.0
agent-3: 9.0
agent-4: 17.0
agent-5: 18.0
agent-6: 10.0
agent-7: 13.0
agent-8: 12.0
agent-9: 14.0
agent-10: 9.0
agent-11: 15.0
agent-12: 10.0
agent-13: 9.0
agent-14: 9.0
agent-15: 11.0
agent-16: 8.0
agent-17: 14.0
agent-18: 9.0
agent-19: 12.0
agent-20: 13.0
agent-21: 12.0
agent-22: 13.0
agent-23: 7.0
agent-24: 11.0
agent-25: 14.0
agent-26: 10.0
agent-27: 13.0
agent-28: 8.0
agent-29: 11.0
agent-30: 10.0
agent-31: 13.0
agent-32: 3.0
agent-33: 15.0
agent-34: 13.0
agent-35: 14.0
agent-36: 9.0
agent-37: 12.0
agent-38: 7.0
agent-39: 7.0
agent-40: 14.0
Sum Reward: 454.0
Avg Reward: 11.35
Min Reward: 3.0
Max Reward: 18.0
Gini Coefficient: 0.1472466960352423
20:20 Ratio: 2.103448275862069
Max-min Ratio: 6.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-08_08-17-35
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 468.0
  episode_reward_mean: 443.1
  episode_reward_min: 421.0
  episodes_this_iter: 1
  episodes_total: 453
  experiment_id: 4e724eb5b3a34f42879644e84578eec0
  hostname: gpu024
  info:
    apply_time_ms: 3.214
    dispatch_time_ms: 5.941
    learner:
      cur_lr: 0.00015320800594054163
      grad_gnorm: 1.0893062353134155
      policy_entropy: 775.8795166015625
      policy_loss: 0.13337530195713043
      var_gnorm: 39.4912109375
      vf_explained_var: -1.0
      vf_loss: 0.00023103650892153382
    num_steps_sampled: 18160000
    num_steps_trained: 18160000
    wait_time_ms: 567.145
  iterations_since_restore: 454
  node_ip: 172.17.8.24
  num_metric_batches_dropped: 0
  pid: 26970
  policy_reward_mean: {}
  time_since_restore: 25653.370988607407
  time_this_iter_s: 56.46725249290466
  time_total_s: 25653.370988607407
  timestamp: 1594210655
  timesteps_since_restore: 18160000
  timesteps_this_iter: 40000
  timesteps_total: 18160000
  training_iteration: 454
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26970], 25653 s, 454 iter, 18160000 ts, 443 rew

agent-1: 9.0
agent-2: 11.0
agent-3: 15.0
agent-4: 6.0
agent-5: 6.0
agent-6: 12.0
agent-7: 14.0
agent-8: 6.0
agent-9: 8.0
agent-10: 9.0
agent-11: 9.0
agent-12: 15.0
agent-13: 12.0
agent-14: 6.0
agent-15: 10.0
agent-16: 15.0
agent-17: 10.0
agent-18: 13.0
agent-19: 7.0
agent-20: 11.0
agent-21: 3.0
agent-22: 10.0
agent-23: 10.0
agent-24: 15.0
agent-25: 12.0
agent-26: 7.0
agent-27: 11.0
agent-28: 15.0
agent-29: 12.0
agent-30: 13.0
agent-31: 15.0
agent-32: 9.0
agent-33: 13.0
agent-34: 12.0
agent-35: 11.0
agent-36: 13.0
agent-37: 7.0
agent-38: 11.0
agent-39: 12.0
agent-40: 12.0
Sum Reward: 427.0
Avg Reward: 10.675
Min Reward: 3.0
Max Reward: 15.0
Gini Coefficient: 0.159192037470726
20:20 Ratio: 2.4375
Max-min Ratio: 5.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-08_08-18-31
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 465.0
  episode_reward_mean: 442.69
  episode_reward_min: 421.0
  episodes_this_iter: 1
  episodes_total: 454
  experiment_id: 4e724eb5b3a34f42879644e84578eec0
  hostname: gpu024
  info:
    apply_time_ms: 3.655
    dispatch_time_ms: 5.226
    learner:
      cur_lr: 0.00015054400137159973
      grad_gnorm: 1.015048861503601
      policy_entropy: 776.6458740234375
      policy_loss: 0.8558944463729858
      var_gnorm: 39.49961853027344
      vf_explained_var: -1.0
      vf_loss: 0.0002564239548519254
    num_steps_sampled: 18200000
    num_steps_trained: 18200000
    wait_time_ms: 557.669
  iterations_since_restore: 455
  node_ip: 172.17.8.24
  num_metric_batches_dropped: 0
  pid: 26970
  policy_reward_mean: {}
  time_since_restore: 25709.978848457336
  time_this_iter_s: 56.60785984992981
  time_total_s: 25709.978848457336
  timestamp: 1594210711
  timesteps_since_restore: 18200000
  timesteps_this_iter: 40000
  timesteps_total: 18200000
  training_iteration: 455
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26970], 25709 s, 455 iter, 18200000 ts, 443 rew

agent-1: 8.0
agent-2: 15.0
agent-3: 14.0
agent-4: 7.0
agent-5: 10.0
agent-6: 9.0
agent-7: 10.0
agent-8: 17.0
agent-9: 12.0
agent-10: 9.0
agent-11: 6.0
agent-12: 6.0
agent-13: 11.0
agent-14: 10.0
agent-15: 11.0
agent-16: 19.0
agent-17: 14.0
agent-18: 13.0
agent-19: 12.0
agent-20: 13.0
agent-21: 9.0
agent-22: 12.0
agent-23: 11.0
agent-24: 13.0
agent-25: 10.0
agent-26: 9.0
agent-27: 14.0
agent-28: 7.0
agent-29: 9.0
agent-30: 10.0
agent-31: 10.0
agent-32: 13.0
agent-33: 12.0
agent-34: 8.0
agent-35: 5.0
agent-36: 14.0
agent-37: 8.0
agent-38: 11.0
agent-39: 11.0
agent-40: 11.0
Sum Reward: 433.0
Avg Reward: 10.825
Min Reward: 5.0
Max Reward: 19.0
Gini Coefficient: 0.14994226327944574
20:20 Ratio: 2.1818181818181817
Max-min Ratio: 3.8
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-08_08-19-28
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 465.0
  episode_reward_mean: 442.52
  episode_reward_min: 421.0
  episodes_this_iter: 1
  episodes_total: 455
  experiment_id: 4e724eb5b3a34f42879644e84578eec0
  hostname: gpu024
  info:
    apply_time_ms: 2.417
    dispatch_time_ms: 5.546
    learner:
      cur_lr: 0.00014787999680265784
      grad_gnorm: 0.32776036858558655
      policy_entropy: 777.0106201171875
      policy_loss: 0.220086932182312
      var_gnorm: 39.498226165771484
      vf_explained_var: -0.20442485809326172
      vf_loss: 0.00010184603161178529
    num_steps_sampled: 18240000
    num_steps_trained: 18240000
    wait_time_ms: 562.535
  iterations_since_restore: 456
  node_ip: 172.17.8.24
  num_metric_batches_dropped: 0
  pid: 26970
  policy_reward_mean: {}
  time_since_restore: 25766.536462783813
  time_this_iter_s: 56.55761432647705
  time_total_s: 25766.536462783813
  timestamp: 1594210768
  timesteps_since_restore: 18240000
  timesteps_this_iter: 40000
  timesteps_total: 18240000
  training_iteration: 456
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26970], 25766 s, 456 iter, 18240000 ts, 443 rew

agent-1: 3.0
agent-2: 5.0
agent-3: 11.0
agent-4: 11.0
agent-5: 11.0
agent-6: 13.0
agent-7: 12.0
agent-8: 11.0
agent-9: 18.0
agent-10: 12.0
agent-11: 13.0
agent-12: 16.0
agent-13: 14.0
agent-14: 10.0
agent-15: 6.0
agent-16: 9.0
agent-17: 7.0
agent-18: 13.0
agent-19: 9.0
agent-20: 7.0
agent-21: 17.0
agent-22: 8.0
agent-23: 11.0
agent-24: 12.0
agent-25: 11.0
agent-26: 12.0
agent-27: 14.0
agent-28: 18.0
agent-29: 14.0
agent-30: 9.0
agent-31: 18.0
agent-32: 8.0
agent-33: 11.0
agent-34: 14.0
agent-35: 4.0
agent-36: 10.0
agent-37: 10.0
agent-38: 10.0
agent-39: 11.0
agent-40: 5.0
Sum Reward: 438.0
Avg Reward: 10.95
Min Reward: 3.0
Max Reward: 18.0
Gini Coefficient: 0.1865296803652968
20:20 Ratio: 2.8666666666666667
Max-min Ratio: 6.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-08_08-20-24
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 465.0
  episode_reward_mean: 442.51
  episode_reward_min: 421.0
  episodes_this_iter: 1
  episodes_total: 456
  experiment_id: 4e724eb5b3a34f42879644e84578eec0
  hostname: gpu024
  info:
    apply_time_ms: 3.134
    dispatch_time_ms: 6.859
    learner:
      cur_lr: 0.00014521600678563118
      grad_gnorm: 2.0346107482910156
      policy_entropy: 775.9041748046875
      policy_loss: -1.5564541816711426
      var_gnorm: 39.51194381713867
      vf_explained_var: -1.0
      vf_loss: 0.0008843024261295795
    num_steps_sampled: 18280000
    num_steps_trained: 18280000
    wait_time_ms: 553.692
  iterations_since_restore: 457
  node_ip: 172.17.8.24
  num_metric_batches_dropped: 0
  pid: 26970
  policy_reward_mean: {}
  time_since_restore: 25822.759859085083
  time_this_iter_s: 56.22339630126953
  time_total_s: 25822.759859085083
  timestamp: 1594210824
  timesteps_since_restore: 18280000
  timesteps_this_iter: 40000
  timesteps_total: 18280000
  training_iteration: 457
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26970], 25822 s, 457 iter, 18280000 ts, 443 rew

agent-1: 6.0
agent-2: 7.0
agent-3: 12.0
agent-4: 10.0
agent-5: 8.0
agent-6: 10.0
agent-7: 9.0
agent-8: 10.0
agent-9: 9.0
agent-10: 15.0
agent-11: 11.0
agent-12: 10.0
agent-13: 14.0
agent-14: 14.0
agent-15: 12.0
agent-16: 12.0
agent-17: 10.0
agent-18: 12.0
agent-19: 14.0
agent-20: 12.0
agent-21: 11.0
agent-22: 12.0
agent-23: 11.0
agent-24: 13.0
agent-25: 9.0
agent-26: 16.0
agent-27: 13.0
agent-28: 11.0
agent-29: 6.0
agent-30: 18.0
agent-31: 9.0
agent-32: 14.0
agent-33: 12.0
agent-34: 7.0
agent-35: 3.0
agent-36: 13.0
agent-37: 9.0
agent-38: 10.0
agent-39: 11.0
agent-40: 10.0
Sum Reward: 435.0
Avg Reward: 10.875
Min Reward: 3.0
Max Reward: 18.0
Gini Coefficient: 0.14419540229885058
20:20 Ratio: 2.1454545454545455
Max-min Ratio: 6.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-08_08-21-21
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 465.0
  episode_reward_mean: 442.58
  episode_reward_min: 421.0
  episodes_this_iter: 1
  episodes_total: 457
  experiment_id: 4e724eb5b3a34f42879644e84578eec0
  hostname: gpu024
  info:
    apply_time_ms: 2.794
    dispatch_time_ms: 7.977
    learner:
      cur_lr: 0.0001425520022166893
      grad_gnorm: 0.29191282391548157
      policy_entropy: 776.255615234375
      policy_loss: -0.028075890615582466
      var_gnorm: 39.520469665527344
      vf_explained_var: -1.0
      vf_loss: 5.346635589376092e-05
    num_steps_sampled: 18320000
    num_steps_trained: 18320000
    wait_time_ms: 553.568
  iterations_since_restore: 458
  node_ip: 172.17.8.24
  num_metric_batches_dropped: 0
  pid: 26970
  policy_reward_mean: {}
  time_since_restore: 25879.698350429535
  time_this_iter_s: 56.938491344451904
  time_total_s: 25879.698350429535
  timestamp: 1594210881
  timesteps_since_restore: 18320000
  timesteps_this_iter: 40000
  timesteps_total: 18320000
  training_iteration: 458
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26970], 25879 s, 458 iter, 18320000 ts, 443 rew

agent-1: 14.0
agent-2: 8.0
agent-3: 10.0
agent-4: 9.0
agent-5: 8.0
agent-6: 12.0
agent-7: 12.0
agent-8: 6.0
agent-9: 10.0
agent-10: 14.0
agent-11: 8.0
agent-12: 7.0
agent-13: 7.0
agent-14: 13.0
agent-15: 11.0
agent-16: 13.0
agent-17: 18.0
agent-18: 15.0
agent-19: 11.0
agent-20: 16.0
agent-21: 13.0
agent-22: 10.0
agent-23: 9.0
agent-24: 7.0
agent-25: 12.0
agent-26: 10.0
agent-27: 13.0
agent-28: 10.0
agent-29: 12.0
agent-30: 16.0
agent-31: 12.0
agent-32: 15.0
agent-33: 10.0
agent-34: 7.0
agent-35: 9.0
agent-36: 12.0
agent-37: 10.0
agent-38: 5.0
agent-39: 7.0
agent-40: 11.0
Sum Reward: 432.0
Avg Reward: 10.8
Min Reward: 5.0
Max Reward: 18.0
Gini Coefficient: 0.15636574074074075
20:20 Ratio: 2.240740740740741
Max-min Ratio: 3.6
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-08_08-22-17
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 465.0
  episode_reward_mean: 442.44
  episode_reward_min: 421.0
  episodes_this_iter: 1
  episodes_total: 458
  experiment_id: 4e724eb5b3a34f42879644e84578eec0
  hostname: gpu024
  info:
    apply_time_ms: 3.097
    dispatch_time_ms: 6.859
    learner:
      cur_lr: 0.0001398879976477474
      grad_gnorm: 0.9655625224113464
      policy_entropy: 775.9227294921875
      policy_loss: -0.958419919013977
      var_gnorm: 39.517330169677734
      vf_explained_var: -1.0
      vf_loss: 0.00018842403369490057
    num_steps_sampled: 18360000
    num_steps_trained: 18360000
    wait_time_ms: 550.628
  iterations_since_restore: 459
  node_ip: 172.17.8.24
  num_metric_batches_dropped: 0
  pid: 26970
  policy_reward_mean: {}
  time_since_restore: 25935.838721752167
  time_this_iter_s: 56.140371322631836
  time_total_s: 25935.838721752167
  timestamp: 1594210937
  timesteps_since_restore: 18360000
  timesteps_this_iter: 40000
  timesteps_total: 18360000
  training_iteration: 459
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26970], 25935 s, 459 iter, 18360000 ts, 442 rew

agent-1: 10.0
agent-2: 13.0
agent-3: 15.0
agent-4: 10.0
agent-5: 14.0
agent-6: 13.0
agent-7: 11.0
agent-8: 6.0
agent-9: 9.0
agent-10: 15.0
agent-11: 9.0
agent-12: 9.0
agent-13: 16.0
agent-14: 15.0
agent-15: 10.0
agent-16: 9.0
agent-17: 9.0
agent-18: 14.0
agent-19: 15.0
agent-20: 10.0
agent-21: 6.0
agent-22: 4.0
agent-23: 5.0
agent-24: 13.0
agent-25: 13.0
agent-26: 14.0
agent-27: 9.0
agent-28: 12.0
agent-29: 14.0
agent-30: 12.0
agent-31: 10.0
agent-32: 15.0
agent-33: 13.0
agent-34: 15.0
agent-35: 16.0
agent-36: 9.0
agent-37: 6.0
agent-38: 16.0
agent-39: 14.0
agent-40: 12.0
Sum Reward: 460.0
Avg Reward: 11.5
Min Reward: 4.0
Max Reward: 16.0
Gini Coefficient: 0.1584782608695652
20:20 Ratio: 2.2777777777777777
Max-min Ratio: 4.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-08_08-23-14
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 465.0
  episode_reward_mean: 442.68
  episode_reward_min: 421.0
  episodes_this_iter: 1
  episodes_total: 459
  experiment_id: 4e724eb5b3a34f42879644e84578eec0
  hostname: gpu024
  info:
    apply_time_ms: 2.785
    dispatch_time_ms: 8.059
    learner:
      cur_lr: 0.0001372239930788055
      grad_gnorm: 0.20973791182041168
      policy_entropy: 777.0107421875
      policy_loss: -0.07514990866184235
      var_gnorm: 39.51383972167969
      vf_explained_var: -0.8556778430938721
      vf_loss: 9.75732400547713e-05
    num_steps_sampled: 18400000
    num_steps_trained: 18400000
    wait_time_ms: 565.795
  iterations_since_restore: 460
  node_ip: 172.17.8.24
  num_metric_batches_dropped: 0
  pid: 26970
  policy_reward_mean: {}
  time_since_restore: 25992.3961687088
  time_this_iter_s: 56.55744695663452
  time_total_s: 25992.3961687088
  timestamp: 1594210994
  timesteps_since_restore: 18400000
  timesteps_this_iter: 40000
  timesteps_total: 18400000
  training_iteration: 460
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26970], 25992 s, 460 iter, 18400000 ts, 443 rew

agent-1: 10.0
agent-2: 9.0
agent-3: 15.0
agent-4: 9.0
agent-5: 13.0
agent-6: 14.0
agent-7: 10.0
agent-8: 14.0
agent-9: 12.0
agent-10: 12.0
agent-11: 9.0
agent-12: 9.0
agent-13: 9.0
agent-14: 12.0
agent-15: 11.0
agent-16: 16.0
agent-17: 15.0
agent-18: 14.0
agent-19: 7.0
agent-20: 12.0
agent-21: 9.0
agent-22: 8.0
agent-23: 10.0
agent-24: 17.0
agent-25: 9.0
agent-26: 9.0
agent-27: 10.0
agent-28: 10.0
agent-29: 19.0
agent-30: 8.0
agent-31: 12.0
agent-32: 10.0
agent-33: 9.0
agent-34: 9.0
agent-35: 8.0
agent-36: 9.0
agent-37: 6.0
agent-38: 16.0
agent-39: 8.0
agent-40: 16.0
Sum Reward: 444.0
Avg Reward: 11.1
Min Reward: 6.0
Max Reward: 19.0
Gini Coefficient: 0.15
20:20 Ratio: 2.0317460317460316
Max-min Ratio: 3.1666666666666665
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-08_08-24-11
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 465.0
  episode_reward_mean: 442.91
  episode_reward_min: 423.0
  episodes_this_iter: 1
  episodes_total: 460
  experiment_id: 4e724eb5b3a34f42879644e84578eec0
  hostname: gpu024
  info:
    apply_time_ms: 2.851
    dispatch_time_ms: 5.721
    learner:
      cur_lr: 0.00013456000306177884
      grad_gnorm: 1.3730735778808594
      policy_entropy: 776.1362915039062
      policy_loss: 0.8061104416847229
      var_gnorm: 39.50633239746094
      vf_explained_var: -1.0
      vf_loss: 0.0002879235544241965
    num_steps_sampled: 18440000
    num_steps_trained: 18440000
    wait_time_ms: 563.262
  iterations_since_restore: 461
  node_ip: 172.17.8.24
  num_metric_batches_dropped: 0
  pid: 26970
  policy_reward_mean: {}
  time_since_restore: 26049.038457632065
  time_this_iter_s: 56.64228892326355
  time_total_s: 26049.038457632065
  timestamp: 1594211051
  timesteps_since_restore: 18440000
  timesteps_this_iter: 40000
  timesteps_total: 18440000
  training_iteration: 461
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26970], 26049 s, 461 iter, 18440000 ts, 443 rew

agent-1: 8.0
agent-2: 9.0
agent-3: 10.0
agent-4: 18.0
agent-5: 11.0
agent-6: 9.0
agent-7: 12.0
agent-8: 11.0
agent-9: 11.0
agent-10: 17.0
agent-11: 7.0
agent-12: 10.0
agent-13: 13.0
agent-14: 9.0
agent-15: 16.0
agent-16: 15.0
agent-17: 8.0
agent-18: 10.0
agent-19: 12.0
agent-20: 12.0
agent-21: 14.0
agent-22: 5.0
agent-23: 8.0
agent-24: 19.0
agent-25: 14.0
agent-26: 12.0
agent-27: 15.0
agent-28: 13.0
agent-29: 6.0
agent-30: 19.0
agent-31: 9.0
agent-32: 7.0
agent-33: 14.0
agent-34: 12.0
agent-35: 3.0
agent-36: 8.0
agent-37: 15.0
agent-38: 10.0
agent-39: 11.0
agent-40: 11.0
Sum Reward: 453.0
Avg Reward: 11.325
Min Reward: 3.0
Max Reward: 19.0
Gini Coefficient: 0.1815121412803532
20:20 Ratio: 2.576923076923077
Max-min Ratio: 6.333333333333333
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-08_08-25-07
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 465.0
  episode_reward_mean: 442.93
  episode_reward_min: 423.0
  episodes_this_iter: 1
  episodes_total: 461
  experiment_id: 4e724eb5b3a34f42879644e84578eec0
  hostname: gpu024
  info:
    apply_time_ms: 2.855
    dispatch_time_ms: 6.752
    learner:
      cur_lr: 0.00013189599849283695
      grad_gnorm: 0.4389590322971344
      policy_entropy: 773.2474365234375
      policy_loss: 0.2564733326435089
      var_gnorm: 39.4990234375
      vf_explained_var: -1.0
      vf_loss: 0.00011259593884460628
    num_steps_sampled: 18480000
    num_steps_trained: 18480000
    wait_time_ms: 557.761
  iterations_since_restore: 462
  node_ip: 172.17.8.24
  num_metric_batches_dropped: 0
  pid: 26970
  policy_reward_mean: {}
  time_since_restore: 26105.81022787094
  time_this_iter_s: 56.77177023887634
  time_total_s: 26105.81022787094
  timestamp: 1594211107
  timesteps_since_restore: 18480000
  timesteps_this_iter: 40000
  timesteps_total: 18480000
  training_iteration: 462
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26970], 26105 s, 462 iter, 18480000 ts, 443 rew

agent-1: 9.0
agent-2: 8.0
agent-3: 9.0
agent-4: 15.0
agent-5: 10.0
agent-6: 10.0
agent-7: 13.0
agent-8: 18.0
agent-9: 13.0
agent-10: 16.0
agent-11: 11.0
agent-12: 18.0
agent-13: 13.0
agent-14: 7.0
agent-15: 6.0
agent-16: 7.0
agent-17: 10.0
agent-18: 14.0
agent-19: 10.0
agent-20: 11.0
agent-21: 13.0
agent-22: 9.0
agent-23: 10.0
agent-24: 8.0
agent-25: 11.0
agent-26: 8.0
agent-27: 8.0
agent-28: 13.0
agent-29: 12.0
agent-30: 11.0
agent-31: 14.0
agent-32: 13.0
agent-33: 13.0
agent-34: 13.0
agent-35: 9.0
agent-36: 11.0
agent-37: 5.0
agent-38: 17.0
agent-39: 10.0
agent-40: 14.0
Sum Reward: 450.0
Avg Reward: 11.25
Min Reward: 5.0
Max Reward: 18.0
Gini Coefficient: 0.15466666666666667
20:20 Ratio: 2.210526315789474
Max-min Ratio: 3.6
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-08_08-26-04
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 465.0
  episode_reward_mean: 442.9
  episode_reward_min: 423.0
  episodes_this_iter: 1
  episodes_total: 462
  experiment_id: 4e724eb5b3a34f42879644e84578eec0
  hostname: gpu024
  info:
    apply_time_ms: 2.905
    dispatch_time_ms: 6.697
    learner:
      cur_lr: 0.00012923199392389506
      grad_gnorm: 0.7777758836746216
      policy_entropy: 774.3602294921875
      policy_loss: 0.17581212520599365
      var_gnorm: 39.501251220703125
      vf_explained_var: -1.0
      vf_loss: 6.241828668862581e-05
    num_steps_sampled: 18520000
    num_steps_trained: 18520000
    wait_time_ms: 567.207
  iterations_since_restore: 463
  node_ip: 172.17.8.24
  num_metric_batches_dropped: 0
  pid: 26970
  policy_reward_mean: {}
  time_since_restore: 26162.07887506485
  time_this_iter_s: 56.26864719390869
  time_total_s: 26162.07887506485
  timestamp: 1594211164
  timesteps_since_restore: 18520000
  timesteps_this_iter: 40000
  timesteps_total: 18520000
  training_iteration: 463
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26970], 26162 s, 463 iter, 18520000 ts, 443 rew

agent-1: 16.0
agent-2: 10.0
agent-3: 15.0
agent-4: 12.0
agent-5: 8.0
agent-6: 14.0
agent-7: 12.0
agent-8: 13.0
agent-9: 13.0
agent-10: 12.0
agent-11: 11.0
agent-12: 10.0
agent-13: 9.0
agent-14: 7.0
agent-15: 17.0
agent-16: 9.0
agent-17: 11.0
agent-18: 12.0
agent-19: 6.0
agent-20: 10.0
agent-21: 13.0
agent-22: 11.0
agent-23: 9.0
agent-24: 4.0
agent-25: 18.0
agent-26: 12.0
agent-27: 9.0
agent-28: 9.0
agent-29: 12.0
agent-30: 9.0
agent-31: 10.0
agent-32: 16.0
agent-33: 14.0
agent-34: 13.0
agent-35: 7.0
agent-36: 9.0
agent-37: 13.0
agent-38: 14.0
agent-39: 7.0
agent-40: 8.0
Sum Reward: 444.0
Avg Reward: 11.1
Min Reward: 4.0
Max Reward: 18.0
Gini Coefficient: 0.1554054054054054
20:20 Ratio: 2.2142857142857144
Max-min Ratio: 4.5
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-08_08-27-00
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 465.0
  episode_reward_mean: 442.81
  episode_reward_min: 423.0
  episodes_this_iter: 1
  episodes_total: 463
  experiment_id: 4e724eb5b3a34f42879644e84578eec0
  hostname: gpu024
  info:
    apply_time_ms: 3.287
    dispatch_time_ms: 8.127
    learner:
      cur_lr: 0.0001265680039068684
      grad_gnorm: 0.13645295798778534
      policy_entropy: 776.3743896484375
      policy_loss: -0.0025205635465681553
      var_gnorm: 39.49803161621094
      vf_explained_var: -1.0
      vf_loss: 0.00011839520448120311
    num_steps_sampled: 18560000
    num_steps_trained: 18560000
    wait_time_ms: 557.879
  iterations_since_restore: 464
  node_ip: 172.17.8.24
  num_metric_batches_dropped: 0
  pid: 26970
  policy_reward_mean: {}
  time_since_restore: 26218.615963935852
  time_this_iter_s: 56.5370888710022
  time_total_s: 26218.615963935852
  timestamp: 1594211220
  timesteps_since_restore: 18560000
  timesteps_this_iter: 40000
  timesteps_total: 18560000
  training_iteration: 464
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26970], 26218 s, 464 iter, 18560000 ts, 443 rew

agent-1: 12.0
agent-2: 11.0
agent-3: 9.0
agent-4: 7.0
agent-5: 6.0
agent-6: 10.0
agent-7: 11.0
agent-8: 10.0
agent-9: 13.0
agent-10: 11.0
agent-11: 2.0
agent-12: 15.0
agent-13: 12.0
agent-14: 13.0
agent-15: 15.0
agent-16: 12.0
agent-17: 12.0
agent-18: 13.0
agent-19: 8.0
agent-20: 14.0
agent-21: 12.0
agent-22: 12.0
agent-23: 13.0
agent-24: 15.0
agent-25: 10.0
agent-26: 8.0
agent-27: 6.0
agent-28: 12.0
agent-29: 9.0
agent-30: 12.0
agent-31: 10.0
agent-32: 8.0
agent-33: 10.0
agent-34: 8.0
agent-35: 19.0
agent-36: 16.0
agent-37: 12.0
agent-38: 8.0
agent-39: 10.0
agent-40: 19.0
Sum Reward: 445.0
Avg Reward: 11.125
Min Reward: 2.0
Max Reward: 19.0
Gini Coefficient: 0.16252808988764045
20:20 Ratio: 2.3773584905660377
Max-min Ratio: 9.5
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-08_08-27-57
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 465.0
  episode_reward_mean: 442.82
  episode_reward_min: 423.0
  episodes_this_iter: 1
  episodes_total: 464
  experiment_id: 4e724eb5b3a34f42879644e84578eec0
  hostname: gpu024
  info:
    apply_time_ms: 2.81
    dispatch_time_ms: 7.316
    learner:
      cur_lr: 0.0001239039993379265
      grad_gnorm: 0.893936812877655
      policy_entropy: 777.4757080078125
      policy_loss: 0.7601556181907654
      var_gnorm: 39.5043830871582
      vf_explained_var: -0.1629927158355713
      vf_loss: 0.00015482475282624364
    num_steps_sampled: 18600000
    num_steps_trained: 18600000
    wait_time_ms: 555.562
  iterations_since_restore: 465
  node_ip: 172.17.8.24
  num_metric_batches_dropped: 0
  pid: 26970
  policy_reward_mean: {}
  time_since_restore: 26275.025433778763
  time_this_iter_s: 56.40946984291077
  time_total_s: 26275.025433778763
  timestamp: 1594211277
  timesteps_since_restore: 18600000
  timesteps_this_iter: 40000
  timesteps_total: 18600000
  training_iteration: 465
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26970], 26275 s, 465 iter, 18600000 ts, 443 rew

agent-1: 13.0
agent-2: 16.0
agent-3: 13.0
agent-4: 13.0
agent-5: 12.0
agent-6: 10.0
agent-7: 12.0
agent-8: 4.0
agent-9: 10.0
agent-10: 17.0
agent-11: 9.0
agent-12: 9.0
agent-13: 9.0
agent-14: 8.0
agent-15: 15.0
agent-16: 14.0
agent-17: 16.0
agent-18: 14.0
agent-19: 9.0
agent-20: 14.0
agent-21: 7.0
agent-22: 15.0
agent-23: 13.0
agent-24: 7.0
agent-25: 8.0
agent-26: 10.0
agent-27: 13.0
agent-28: 17.0
agent-29: 6.0
agent-30: 9.0
agent-31: 13.0
agent-32: 12.0
agent-33: 8.0
agent-34: 14.0
agent-35: 17.0
agent-36: 11.0
agent-37: 8.0
agent-38: 12.0
agent-39: 7.0
agent-40: 11.0
Sum Reward: 455.0
Avg Reward: 11.375
Min Reward: 4.0
Max Reward: 17.0
Gini Coefficient: 0.16423076923076924
20:20 Ratio: 2.309090909090909
Max-min Ratio: 4.25
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-08_08-28-53
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 465.0
  episode_reward_mean: 443.0
  episode_reward_min: 423.0
  episodes_this_iter: 1
  episodes_total: 465
  experiment_id: 4e724eb5b3a34f42879644e84578eec0
  hostname: gpu024
  info:
    apply_time_ms: 2.739
    dispatch_time_ms: 6.039
    learner:
      cur_lr: 0.00012124000204494223
      grad_gnorm: 0.09113849699497223
      policy_entropy: 777.6534423828125
      policy_loss: 0.01332462951540947
      var_gnorm: 39.502384185791016
      vf_explained_var: -1.0
      vf_loss: 9.84060752671212e-05
    num_steps_sampled: 18640000
    num_steps_trained: 18640000
    wait_time_ms: 560.004
  iterations_since_restore: 466
  node_ip: 172.17.8.24
  num_metric_batches_dropped: 0
  pid: 26970
  policy_reward_mean: {}
  time_since_restore: 26331.480089902878
  time_this_iter_s: 56.45465612411499
  time_total_s: 26331.480089902878
  timestamp: 1594211333
  timesteps_since_restore: 18640000
  timesteps_this_iter: 40000
  timesteps_total: 18640000
  training_iteration: 466
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26970], 26331 s, 466 iter, 18640000 ts, 443 rew

agent-1: 6.0
agent-2: 9.0
agent-3: 14.0
agent-4: 9.0
agent-5: 12.0
agent-6: 12.0
agent-7: 15.0
agent-8: 11.0
agent-9: 1.0
agent-10: 12.0
agent-11: 12.0
agent-12: 8.0
agent-13: 10.0
agent-14: 11.0
agent-15: 11.0
agent-16: 16.0
agent-17: 9.0
agent-18: 12.0
agent-19: 10.0
agent-20: 13.0
agent-21: 13.0
agent-22: 13.0
agent-23: 8.0
agent-24: 9.0
agent-25: 16.0
agent-26: 4.0
agent-27: 10.0
agent-28: 13.0
agent-29: 10.0
agent-30: 7.0
agent-31: 7.0
agent-32: 11.0
agent-33: 12.0
agent-34: 13.0
agent-35: 20.0
agent-36: 13.0
agent-37: 9.0
agent-38: 13.0
agent-39: 9.0
agent-40: 9.0
Sum Reward: 432.0
Avg Reward: 10.8
Min Reward: 1.0
Max Reward: 20.0
Gini Coefficient: 0.16574074074074074
20:20 Ratio: 2.4
Max-min Ratio: 20.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-08_08-29-50
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 465.0
  episode_reward_mean: 442.67
  episode_reward_min: 423.0
  episodes_this_iter: 1
  episodes_total: 466
  experiment_id: 4e724eb5b3a34f42879644e84578eec0
  hostname: gpu024
  info:
    apply_time_ms: 2.696
    dispatch_time_ms: 6.589
    learner:
      cur_lr: 0.00011857599747600034
      grad_gnorm: 0.20651087164878845
      policy_entropy: 777.5947265625
      policy_loss: -0.14018142223358154
      var_gnorm: 39.5108757019043
      vf_explained_var: -1.0
      vf_loss: 7.534339965786785e-05
    num_steps_sampled: 18680000
    num_steps_trained: 18680000
    wait_time_ms: 546.442
  iterations_since_restore: 467
  node_ip: 172.17.8.24
  num_metric_batches_dropped: 0
  pid: 26970
  policy_reward_mean: {}
  time_since_restore: 26388.050597429276
  time_this_iter_s: 56.570507526397705
  time_total_s: 26388.050597429276
  timestamp: 1594211390
  timesteps_since_restore: 18680000
  timesteps_this_iter: 40000
  timesteps_total: 18680000
  training_iteration: 467
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26970], 26388 s, 467 iter, 18680000 ts, 443 rew

agent-1: 14.0
agent-2: 9.0
agent-3: 4.0
agent-4: 13.0
agent-5: 11.0
agent-6: 13.0
agent-7: 14.0
agent-8: 12.0
agent-9: 12.0
agent-10: 10.0
agent-11: 9.0
agent-12: 8.0
agent-13: 6.0
agent-14: 15.0
agent-15: 11.0
agent-16: 12.0
agent-17: 16.0
agent-18: 9.0
agent-19: 12.0
agent-20: 10.0
agent-21: 5.0
agent-22: 7.0
agent-23: 15.0
agent-24: 18.0
agent-25: 13.0
agent-26: 15.0
agent-27: 10.0
agent-28: 8.0
agent-29: 10.0
agent-30: 11.0
agent-31: 9.0
agent-32: 5.0
agent-33: 13.0
agent-34: 4.0
agent-35: 13.0
agent-36: 9.0
agent-37: 9.0
agent-38: 14.0
agent-39: 9.0
agent-40: 12.0
Sum Reward: 429.0
Avg Reward: 10.725
Min Reward: 4.0
Max Reward: 18.0
Gini Coefficient: 0.17255244755244756
20:20 Ratio: 2.574468085106383
Max-min Ratio: 4.5
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-08_08-30-46
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 465.0
  episode_reward_mean: 442.71
  episode_reward_min: 423.0
  episodes_this_iter: 1
  episodes_total: 467
  experiment_id: 4e724eb5b3a34f42879644e84578eec0
  hostname: gpu024
  info:
    apply_time_ms: 3.865
    dispatch_time_ms: 6.36
    learner:
      cur_lr: 0.00011591200018301606
      grad_gnorm: 0.12049269676208496
      policy_entropy: 777.4896850585938
      policy_loss: 0.1024884283542633
      var_gnorm: 39.51286697387695
      vf_explained_var: -1.0
      vf_loss: 3.2192051548918243e-06
    num_steps_sampled: 18720000
    num_steps_trained: 18720000
    wait_time_ms: 555.179
  iterations_since_restore: 468
  node_ip: 172.17.8.24
  num_metric_batches_dropped: 0
  pid: 26970
  policy_reward_mean: {}
  time_since_restore: 26444.50246334076
  time_this_iter_s: 56.451865911483765
  time_total_s: 26444.50246334076
  timestamp: 1594211446
  timesteps_since_restore: 18720000
  timesteps_this_iter: 40000
  timesteps_total: 18720000
  training_iteration: 468
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26970], 26444 s, 468 iter, 18720000 ts, 443 rew

agent-1: 13.0
agent-2: 7.0
agent-3: 9.0
agent-4: 11.0
agent-5: 15.0
agent-6: 14.0
agent-7: 14.0
agent-8: 13.0
agent-9: 13.0
agent-10: 15.0
agent-11: 12.0
agent-12: 4.0
agent-13: 8.0
agent-14: 10.0
agent-15: 12.0
agent-16: 11.0
agent-17: 5.0
agent-18: 13.0
agent-19: 9.0
agent-20: 14.0
agent-21: 13.0
agent-22: 10.0
agent-23: 10.0
agent-24: 11.0
agent-25: 11.0
agent-26: 10.0
agent-27: 12.0
agent-28: 9.0
agent-29: 8.0
agent-30: 9.0
agent-31: 4.0
agent-32: 12.0
agent-33: 11.0
agent-34: 8.0
agent-35: 8.0
agent-36: 11.0
agent-37: 12.0
agent-38: 6.0
agent-39: 8.0
agent-40: 9.0
Sum Reward: 414.0
Avg Reward: 10.35
Min Reward: 4.0
Max Reward: 15.0
Gini Coefficient: 0.15132850241545895
20:20 Ratio: 2.22
Max-min Ratio: 3.75
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-08_08-31-43
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 465.0
  episode_reward_mean: 442.43
  episode_reward_min: 414.0
  episodes_this_iter: 1
  episodes_total: 468
  experiment_id: 4e724eb5b3a34f42879644e84578eec0
  hostname: gpu024
  info:
    apply_time_ms: 2.881
    dispatch_time_ms: 6.13
    learner:
      cur_lr: 0.00011324800289003178
      grad_gnorm: 1.1193102598190308
      policy_entropy: 777.50244140625
      policy_loss: -0.959114670753479
      var_gnorm: 39.52089309692383
      vf_explained_var: -0.711124062538147
      vf_loss: 0.00024921473232097924
    num_steps_sampled: 18760000
    num_steps_trained: 18760000
    wait_time_ms: 555.98
  iterations_since_restore: 469
  node_ip: 172.17.8.24
  num_metric_batches_dropped: 0
  pid: 26970
  policy_reward_mean: {}
  time_since_restore: 26501.20346236229
  time_this_iter_s: 56.70099902153015
  time_total_s: 26501.20346236229
  timestamp: 1594211503
  timesteps_since_restore: 18760000
  timesteps_this_iter: 40000
  timesteps_total: 18760000
  training_iteration: 469
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26970], 26501 s, 469 iter, 18760000 ts, 442 rew

agent-1: 15.0
agent-2: 12.0
agent-3: 17.0
agent-4: 6.0
agent-5: 13.0
agent-6: 4.0
agent-7: 8.0
agent-8: 15.0
agent-9: 9.0
agent-10: 8.0
agent-11: 15.0
agent-12: 10.0
agent-13: 10.0
agent-14: 8.0
agent-15: 6.0
agent-16: 13.0
agent-17: 6.0
agent-18: 17.0
agent-19: 9.0
agent-20: 13.0
agent-21: 14.0
agent-22: 10.0
agent-23: 9.0
agent-24: 15.0
agent-25: 17.0
agent-26: 10.0
agent-27: 10.0
agent-28: 7.0
agent-29: 8.0
agent-30: 9.0
agent-31: 16.0
agent-32: 18.0
agent-33: 7.0
agent-34: 12.0
agent-35: 7.0
agent-36: 6.0
agent-37: 14.0
agent-38: 12.0
agent-39: 15.0
agent-40: 12.0
Sum Reward: 442.0
Avg Reward: 11.05
Min Reward: 4.0
Max Reward: 18.0
Gini Coefficient: 0.19208144796380092
20:20 Ratio: 2.6530612244897958
Max-min Ratio: 4.5
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-08_08-32-40
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 465.0
  episode_reward_mean: 442.54
  episode_reward_min: 414.0
  episodes_this_iter: 1
  episodes_total: 469
  experiment_id: 4e724eb5b3a34f42879644e84578eec0
  hostname: gpu024
  info:
    apply_time_ms: 2.408
    dispatch_time_ms: 6.989
    learner:
      cur_lr: 0.0001105839983210899
      grad_gnorm: 0.23960065841674805
      policy_entropy: 777.625244140625
      policy_loss: 0.18861699104309082
      var_gnorm: 39.52047348022461
      vf_explained_var: -0.27355945110321045
      vf_loss: 8.339274063473567e-05
    num_steps_sampled: 18800000
    num_steps_trained: 18800000
    wait_time_ms: 569.306
  iterations_since_restore: 470
  node_ip: 172.17.8.24
  num_metric_batches_dropped: 0
  pid: 26970
  policy_reward_mean: {}
  time_since_restore: 26557.800621032715
  time_this_iter_s: 56.597158670425415
  time_total_s: 26557.800621032715
  timestamp: 1594211560
  timesteps_since_restore: 18800000
  timesteps_this_iter: 40000
  timesteps_total: 18800000
  training_iteration: 470
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26970], 26557 s, 470 iter, 18800000 ts, 443 rew

agent-1: 15.0
agent-2: 9.0
agent-3: 12.0
agent-4: 10.0
agent-5: 10.0
agent-6: 10.0
agent-7: 7.0
agent-8: 4.0
agent-9: 9.0
agent-10: 12.0
agent-11: 13.0
agent-12: 9.0
agent-13: 10.0
agent-14: 11.0
agent-15: 12.0
agent-16: 12.0
agent-17: 13.0
agent-18: 13.0
agent-19: 10.0
agent-20: 13.0
agent-21: 11.0
agent-22: 9.0
agent-23: 10.0
agent-24: 15.0
agent-25: 9.0
agent-26: 12.0
agent-27: 9.0
agent-28: 16.0
agent-29: 8.0
agent-30: 11.0
agent-31: 12.0
agent-32: 10.0
agent-33: 12.0
agent-34: 13.0
agent-35: 11.0
agent-36: 9.0
agent-37: 14.0
agent-38: 11.0
agent-39: 9.0
agent-40: 13.0
Sum Reward: 438.0
Avg Reward: 10.95
Min Reward: 4.0
Max Reward: 16.0
Gini Coefficient: 0.11438356164383562
20:20 Ratio: 1.75
Max-min Ratio: 4.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-08_08-33-36
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 465.0
  episode_reward_mean: 442.53
  episode_reward_min: 414.0
  episodes_this_iter: 1
  episodes_total: 470
  experiment_id: 4e724eb5b3a34f42879644e84578eec0
  hostname: gpu024
  info:
    apply_time_ms: 2.493
    dispatch_time_ms: 8.216
    learner:
      cur_lr: 0.00010792000102810562
      grad_gnorm: 0.3961837887763977
      policy_entropy: 777.6473388671875
      policy_loss: 0.2179231345653534
      var_gnorm: 39.51872253417969
      vf_explained_var: -1.0
      vf_loss: 5.19005989190191e-05
    num_steps_sampled: 18840000
    num_steps_trained: 18840000
    wait_time_ms: 556.729
  iterations_since_restore: 471
  node_ip: 172.17.8.24
  num_metric_batches_dropped: 0
  pid: 26970
  policy_reward_mean: {}
  time_since_restore: 26613.805669546127
  time_this_iter_s: 56.005048513412476
  time_total_s: 26613.805669546127
  timestamp: 1594211616
  timesteps_since_restore: 18840000
  timesteps_this_iter: 40000
  timesteps_total: 18840000
  training_iteration: 471
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26970], 26613 s, 471 iter, 18840000 ts, 443 rew

agent-1: 12.0
agent-2: 8.0
agent-3: 9.0
agent-4: 13.0
agent-5: 10.0
agent-6: 11.0
agent-7: 13.0
agent-8: 12.0
agent-9: 14.0
agent-10: 16.0
agent-11: 8.0
agent-12: 13.0
agent-13: 13.0
agent-14: 11.0
agent-15: 10.0
agent-16: 14.0
agent-17: 10.0
agent-18: 12.0
agent-19: 9.0
agent-20: 8.0
agent-21: 10.0
agent-22: 9.0
agent-23: 12.0
agent-24: 9.0
agent-25: 16.0
agent-26: 11.0
agent-27: 11.0
agent-28: 7.0
agent-29: 13.0
agent-30: 10.0
agent-31: 13.0
agent-32: 8.0
agent-33: 13.0
agent-34: 12.0
agent-35: 14.0
agent-36: 9.0
agent-37: 12.0
agent-38: 10.0
agent-39: 11.0
agent-40: 8.0
Sum Reward: 444.0
Avg Reward: 11.1
Min Reward: 7.0
Max Reward: 16.0
Gini Coefficient: 0.11328828828828828
20:20 Ratio: 1.7384615384615385
Max-min Ratio: 2.2857142857142856
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-08_08-34-32
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 465.0
  episode_reward_mean: 442.64
  episode_reward_min: 414.0
  episodes_this_iter: 1
  episodes_total: 471
  experiment_id: 4e724eb5b3a34f42879644e84578eec0
  hostname: gpu024
  info:
    apply_time_ms: 2.581
    dispatch_time_ms: 6.541
    learner:
      cur_lr: 0.00010525599645916373
      grad_gnorm: 1.1234917640686035
      policy_entropy: 777.2227172851562
      policy_loss: -0.05099773779511452
      var_gnorm: 39.511512756347656
      vf_explained_var: -1.0
      vf_loss: 0.00012769061140716076
    num_steps_sampled: 18880000
    num_steps_trained: 18880000
    wait_time_ms: 550.188
  iterations_since_restore: 472
  node_ip: 172.17.8.24
  num_metric_batches_dropped: 0
  pid: 26970
  policy_reward_mean: {}
  time_since_restore: 26670.1534883976
  time_this_iter_s: 56.34781885147095
  time_total_s: 26670.1534883976
  timestamp: 1594211672
  timesteps_since_restore: 18880000
  timesteps_this_iter: 40000
  timesteps_total: 18880000
  training_iteration: 472
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26970], 26670 s, 472 iter, 18880000 ts, 443 rew

agent-1: 16.0
agent-2: 6.0
agent-3: 13.0
agent-4: 11.0
agent-5: 12.0
agent-6: 15.0
agent-7: 12.0
agent-8: 8.0
agent-9: 13.0
agent-10: 10.0
agent-11: 13.0
agent-12: 10.0
agent-13: 10.0
agent-14: 10.0
agent-15: 16.0
agent-16: 9.0
agent-17: 12.0
agent-18: 12.0
agent-19: 7.0
agent-20: 9.0
agent-21: 11.0
agent-22: 14.0
agent-23: 13.0
agent-24: 15.0
agent-25: 10.0
agent-26: 13.0
agent-27: 7.0
agent-28: 13.0
agent-29: 16.0
agent-30: 9.0
agent-31: 9.0
agent-32: 6.0
agent-33: 19.0
agent-34: 8.0
agent-35: 13.0
agent-36: 6.0
agent-37: 6.0
agent-38: 8.0
agent-39: 6.0
agent-40: 12.0
Sum Reward: 438.0
Avg Reward: 10.95
Min Reward: 6.0
Max Reward: 19.0
Gini Coefficient: 0.16712328767123288
20:20 Ratio: 2.3846153846153846
Max-min Ratio: 3.1666666666666665
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-08_08-35-29
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 465.0
  episode_reward_mean: 442.53
  episode_reward_min: 414.0
  episodes_this_iter: 1
  episodes_total: 472
  experiment_id: 4e724eb5b3a34f42879644e84578eec0
  hostname: gpu024
  info:
    apply_time_ms: 3.023
    dispatch_time_ms: 9.251
    learner:
      cur_lr: 0.00010259199916617945
      grad_gnorm: 0.17398282885551453
      policy_entropy: 777.7069091796875
      policy_loss: 0.025414517149329185
      var_gnorm: 39.51034164428711
      vf_explained_var: -1.0
      vf_loss: 7.995702617336065e-05
    num_steps_sampled: 18920000
    num_steps_trained: 18920000
    wait_time_ms: 563.762
  iterations_since_restore: 473
  node_ip: 172.17.8.24
  num_metric_batches_dropped: 0
  pid: 26970
  policy_reward_mean: {}
  time_since_restore: 26726.913863897324
  time_this_iter_s: 56.76037549972534
  time_total_s: 26726.913863897324
  timestamp: 1594211729
  timesteps_since_restore: 18920000
  timesteps_this_iter: 40000
  timesteps_total: 18920000
  training_iteration: 473
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26970], 26726 s, 473 iter, 18920000 ts, 443 rew

agent-1: 9.0
agent-2: 6.0
agent-3: 11.0
agent-4: 1.0
agent-5: 11.0
agent-6: 11.0
agent-7: 13.0
agent-8: 13.0
agent-9: 10.0
agent-10: 10.0
agent-11: 12.0
agent-12: 11.0
agent-13: 11.0
agent-14: 6.0
agent-15: 8.0
agent-16: 15.0
agent-17: 12.0
agent-18: 13.0
agent-19: 15.0
agent-20: 6.0
agent-21: 14.0
agent-22: 11.0
agent-23: 12.0
agent-24: 8.0
agent-25: 14.0
agent-26: 9.0
agent-27: 14.0
agent-28: 11.0
agent-29: 17.0
agent-30: 12.0
agent-31: 7.0
agent-32: 17.0
agent-33: 13.0
agent-34: 11.0
agent-35: 11.0
agent-36: 13.0
agent-37: 5.0
agent-38: 9.0
agent-39: 12.0
agent-40: 12.0
Sum Reward: 436.0
Avg Reward: 10.9
Min Reward: 1.0
Max Reward: 17.0
Gini Coefficient: 0.16032110091743118
20:20 Ratio: 2.5319148936170213
Max-min Ratio: 17.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-08_08-36-25
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 465.0
  episode_reward_mean: 442.51
  episode_reward_min: 414.0
  episodes_this_iter: 1
  episodes_total: 473
  experiment_id: 4e724eb5b3a34f42879644e84578eec0
  hostname: gpu024
  info:
    apply_time_ms: 2.409
    dispatch_time_ms: 7.251
    learner:
      cur_lr: 9.992800187319517e-05
      grad_gnorm: 0.734458327293396
      policy_entropy: 777.32666015625
      policy_loss: -0.43832188844680786
      var_gnorm: 39.51618576049805
      vf_explained_var: -1.0
      vf_loss: 5.395662083174102e-05
    num_steps_sampled: 18960000
    num_steps_trained: 18960000
    wait_time_ms: 561.995
  iterations_since_restore: 474
  node_ip: 172.17.8.24
  num_metric_batches_dropped: 0
  pid: 26970
  policy_reward_mean: {}
  time_since_restore: 26783.364929676056
  time_this_iter_s: 56.4510657787323
  time_total_s: 26783.364929676056
  timestamp: 1594211785
  timesteps_since_restore: 18960000
  timesteps_this_iter: 40000
  timesteps_total: 18960000
  training_iteration: 474
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26970], 26783 s, 474 iter, 18960000 ts, 443 rew

agent-1: 7.0
agent-2: 7.0
agent-3: 13.0
agent-4: 15.0
agent-5: 14.0
agent-6: 10.0
agent-7: 9.0
agent-8: 13.0
agent-9: 15.0
agent-10: 13.0
agent-11: 14.0
agent-12: 10.0
agent-13: 11.0
agent-14: 16.0
agent-15: 13.0
agent-16: 10.0
agent-17: 19.0
agent-18: 7.0
agent-19: 13.0
agent-20: 12.0
agent-21: 9.0
agent-22: 11.0
agent-23: 13.0
agent-24: 15.0
agent-25: 9.0
agent-26: 13.0
agent-27: 6.0
agent-28: 15.0
agent-29: 15.0
agent-30: 10.0
agent-31: 17.0
agent-32: 5.0
agent-33: 11.0
agent-34: 13.0
agent-35: 7.0
agent-36: 6.0
agent-37: 12.0
agent-38: 8.0
agent-39: 9.0
agent-40: 7.0
Sum Reward: 452.0
Avg Reward: 11.3
Min Reward: 5.0
Max Reward: 19.0
Gini Coefficient: 0.16836283185840709
20:20 Ratio: 2.4423076923076925
Max-min Ratio: 3.8
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-08_08-37-22
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 465.0
  episode_reward_mean: 442.52
  episode_reward_min: 414.0
  episodes_this_iter: 1
  episodes_total: 474
  experiment_id: 4e724eb5b3a34f42879644e84578eec0
  hostname: gpu024
  info:
    apply_time_ms: 3.11
    dispatch_time_ms: 5.368
    learner:
      cur_lr: 9.726399730425328e-05
      grad_gnorm: 0.38984444737434387
      policy_entropy: 776.2626342773438
      policy_loss: -0.3163808584213257
      var_gnorm: 39.5170783996582
      vf_explained_var: -0.6285046339035034
      vf_loss: 5.709744800697081e-05
    num_steps_sampled: 19000000
    num_steps_trained: 19000000
    wait_time_ms: 567.613
  iterations_since_restore: 475
  node_ip: 172.17.8.24
  num_metric_batches_dropped: 0
  pid: 26970
  policy_reward_mean: {}
  time_since_restore: 26840.26399564743
  time_this_iter_s: 56.89906597137451
  time_total_s: 26840.26399564743
  timestamp: 1594211842
  timesteps_since_restore: 19000000
  timesteps_this_iter: 40000
  timesteps_total: 19000000
  training_iteration: 475
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26970], 26840 s, 475 iter, 19000000 ts, 443 rew

agent-1: 8.0
agent-2: 12.0
agent-3: 12.0
agent-4: 11.0
agent-5: 8.0
agent-6: 2.0
agent-7: 13.0
agent-8: 12.0
agent-9: 14.0
agent-10: 9.0
agent-11: 16.0
agent-12: 14.0
agent-13: 10.0
agent-14: 5.0
agent-15: 9.0
agent-16: 10.0
agent-17: 9.0
agent-18: 13.0
agent-19: 13.0
agent-20: 9.0
agent-21: 8.0
agent-22: 9.0
agent-23: 14.0
agent-24: 11.0
agent-25: 12.0
agent-26: 4.0
agent-27: 8.0
agent-28: 17.0
agent-29: 12.0
agent-30: 19.0
agent-31: 11.0
agent-32: 14.0
agent-33: 10.0
agent-34: 20.0
agent-35: 14.0
agent-36: 8.0
agent-37: 14.0
agent-38: 10.0
agent-39: 6.0
agent-40: 10.0
Sum Reward: 440.0
Avg Reward: 11.0
Min Reward: 2.0
Max Reward: 20.0
Gini Coefficient: 0.18363636363636363
20:20 Ratio: 2.6122448979591835
Max-min Ratio: 10.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-08_08-38-19
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 465.0
  episode_reward_mean: 442.55
  episode_reward_min: 414.0
  episodes_this_iter: 1
  episodes_total: 475
  experiment_id: 4e724eb5b3a34f42879644e84578eec0
  hostname: gpu024
  info:
    apply_time_ms: 2.631
    dispatch_time_ms: 7.686
    learner:
      cur_lr: 9.4600000011269e-05
      grad_gnorm: 0.15629294514656067
      policy_entropy: 776.0584716796875
      policy_loss: -0.038141973316669464
      var_gnorm: 39.51509094238281
      vf_explained_var: -1.0
      vf_loss: 4.781785901286639e-05
    num_steps_sampled: 19040000
    num_steps_trained: 19040000
    wait_time_ms: 557.374
  iterations_since_restore: 476
  node_ip: 172.17.8.24
  num_metric_batches_dropped: 0
  pid: 26970
  policy_reward_mean: {}
  time_since_restore: 26896.51350569725
  time_this_iter_s: 56.249510049819946
  time_total_s: 26896.51350569725
  timestamp: 1594211899
  timesteps_since_restore: 19040000
  timesteps_this_iter: 40000
  timesteps_total: 19040000
  training_iteration: 476
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26970], 26896 s, 476 iter, 19040000 ts, 443 rew

agent-1: 15.0
agent-2: 13.0
agent-3: 12.0
agent-4: 14.0
agent-5: 8.0
agent-6: 11.0
agent-7: 10.0
agent-8: 14.0
agent-9: 14.0
agent-10: 13.0
agent-11: 11.0
agent-12: 14.0
agent-13: 11.0
agent-14: 15.0
agent-15: 9.0
agent-16: 7.0
agent-17: 12.0
agent-18: 9.0
agent-19: 4.0
agent-20: 5.0
agent-21: 6.0
agent-22: 13.0
agent-23: 11.0
agent-24: 12.0
agent-25: 10.0
agent-26: 7.0
agent-27: 7.0
agent-28: 5.0
agent-29: 12.0
agent-30: 10.0
agent-31: 9.0
agent-32: 18.0
agent-33: 9.0
agent-34: 20.0
agent-35: 10.0
agent-36: 9.0
agent-37: 13.0
agent-38: 11.0
agent-39: 12.0
agent-40: 8.0
Sum Reward: 433.0
Avg Reward: 10.825
Min Reward: 4.0
Max Reward: 20.0
Gini Coefficient: 0.17303695150115472
20:20 Ratio: 2.5306122448979593
Max-min Ratio: 5.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-08_08-39-15
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 465.0
  episode_reward_mean: 442.4
  episode_reward_min: 414.0
  episodes_this_iter: 1
  episodes_total: 476
  experiment_id: 4e724eb5b3a34f42879644e84578eec0
  hostname: gpu024
  info:
    apply_time_ms: 2.537
    dispatch_time_ms: 5.435
    learner:
      cur_lr: 9.193600271828473e-05
      grad_gnorm: 0.15945641696453094
      policy_entropy: 776.555419921875
      policy_loss: -0.019584812223911285
      var_gnorm: 39.51612091064453
      vf_explained_var: -1.0
      vf_loss: 5.1974588131997734e-05
    num_steps_sampled: 19080000
    num_steps_trained: 19080000
    wait_time_ms: 559.782
  iterations_since_restore: 477
  node_ip: 172.17.8.24
  num_metric_batches_dropped: 0
  pid: 26970
  policy_reward_mean: {}
  time_since_restore: 26953.064379930496
  time_this_iter_s: 56.55087423324585
  time_total_s: 26953.064379930496
  timestamp: 1594211955
  timesteps_since_restore: 19080000
  timesteps_this_iter: 40000
  timesteps_total: 19080000
  training_iteration: 477
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26970], 26953 s, 477 iter, 19080000 ts, 442 rew

agent-1: 13.0
agent-2: 11.0
agent-3: 15.0
agent-4: 10.0
agent-5: 8.0
agent-6: 15.0
agent-7: 11.0
agent-8: 11.0
agent-9: 13.0
agent-10: 14.0
agent-11: 9.0
agent-12: 6.0
agent-13: 11.0
agent-14: 15.0
agent-15: 11.0
agent-16: 6.0
agent-17: 12.0
agent-18: 15.0
agent-19: 12.0
agent-20: 10.0
agent-21: 12.0
agent-22: 8.0
agent-23: 10.0
agent-24: 11.0
agent-25: 5.0
agent-26: 6.0
agent-27: 6.0
agent-28: 7.0
agent-29: 11.0
agent-30: 11.0
agent-31: 8.0
agent-32: 15.0
agent-33: 15.0
agent-34: 14.0
agent-35: 9.0
agent-36: 17.0
agent-37: 12.0
agent-38: 12.0
agent-39: 13.0
agent-40: 12.0
Sum Reward: 442.0
Avg Reward: 11.05
Min Reward: 5.0
Max Reward: 17.0
Gini Coefficient: 0.15271493212669685
20:20 Ratio: 2.326923076923077
Max-min Ratio: 3.4
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-08_08-40-12
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 465.0
  episode_reward_mean: 442.4
  episode_reward_min: 414.0
  episodes_this_iter: 1
  episodes_total: 477
  experiment_id: 4e724eb5b3a34f42879644e84578eec0
  hostname: gpu024
  info:
    apply_time_ms: 4.24
    dispatch_time_ms: 7.145
    learner:
      cur_lr: 8.927199814934283e-05
      grad_gnorm: 0.3291913866996765
      policy_entropy: 776.9073486328125
      policy_loss: -0.10028158128261566
      var_gnorm: 39.51961135864258
      vf_explained_var: -1.0
      vf_loss: 3.777466918108985e-05
    num_steps_sampled: 19120000
    num_steps_trained: 19120000
    wait_time_ms: 562.747
  iterations_since_restore: 478
  node_ip: 172.17.8.24
  num_metric_batches_dropped: 0
  pid: 26970
  policy_reward_mean: {}
  time_since_restore: 27009.547127962112
  time_this_iter_s: 56.48274803161621
  time_total_s: 27009.547127962112
  timestamp: 1594212012
  timesteps_since_restore: 19120000
  timesteps_this_iter: 40000
  timesteps_total: 19120000
  training_iteration: 478
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26970], 27009 s, 478 iter, 19120000 ts, 442 rew

agent-1: 8.0
agent-2: 12.0
agent-3: 14.0
agent-4: 7.0
agent-5: 11.0
agent-6: 7.0
agent-7: 14.0
agent-8: 14.0
agent-9: 9.0
agent-10: 11.0
agent-11: 16.0
agent-12: 9.0
agent-13: 7.0
agent-14: 10.0
agent-15: 8.0
agent-16: 14.0
agent-17: 14.0
agent-18: 10.0
agent-19: 7.0
agent-20: 8.0
agent-21: 9.0
agent-22: 10.0
agent-23: 10.0
agent-24: 13.0
agent-25: 7.0
agent-26: 9.0
agent-27: 13.0
agent-28: 12.0
agent-29: 9.0
agent-30: 14.0
agent-31: 12.0
agent-32: 10.0
agent-33: 10.0
agent-34: 15.0
agent-35: 11.0
agent-36: 8.0
agent-37: 7.0
agent-38: 16.0
agent-39: 12.0
agent-40: 8.0
Sum Reward: 425.0
Avg Reward: 10.625
Min Reward: 7.0
Max Reward: 16.0
Gini Coefficient: 0.14488235294117646
20:20 Ratio: 2.0172413793103448
Max-min Ratio: 2.2857142857142856
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-08_08-41-08
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 465.0
  episode_reward_mean: 442.21
  episode_reward_min: 414.0
  episodes_this_iter: 1
  episodes_total: 478
  experiment_id: 4e724eb5b3a34f42879644e84578eec0
  hostname: gpu024
  info:
    apply_time_ms: 2.457
    dispatch_time_ms: 5.611
    learner:
      cur_lr: 8.660800085635856e-05
      grad_gnorm: 0.11726971715688705
      policy_entropy: 776.9288330078125
      policy_loss: 0.06368465721607208
      var_gnorm: 39.5177116394043
      vf_explained_var: -1.0
      vf_loss: 3.354279760969803e-05
    num_steps_sampled: 19160000
    num_steps_trained: 19160000
    wait_time_ms: 556.13
  iterations_since_restore: 479
  node_ip: 172.17.8.24
  num_metric_batches_dropped: 0
  pid: 26970
  policy_reward_mean: {}
  time_since_restore: 27065.98740339279
  time_this_iter_s: 56.44027543067932
  time_total_s: 27065.98740339279
  timestamp: 1594212068
  timesteps_since_restore: 19160000
  timesteps_this_iter: 40000
  timesteps_total: 19160000
  training_iteration: 479
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26970], 27065 s, 479 iter, 19160000 ts, 442 rew

agent-1: 15.0
agent-2: 11.0
agent-3: 13.0
agent-4: 8.0
agent-5: 15.0
agent-6: 11.0
agent-7: 7.0
agent-8: 11.0
agent-9: 15.0
agent-10: 11.0
agent-11: 11.0
agent-12: 6.0
agent-13: 16.0
agent-14: 12.0
agent-15: 9.0
agent-16: 9.0
agent-17: 2.0
agent-18: 10.0
agent-19: 9.0
agent-20: 8.0
agent-21: 9.0
agent-22: 10.0
agent-23: 10.0
agent-24: 14.0
agent-25: 12.0
agent-26: 10.0
agent-27: 14.0
agent-28: 11.0
agent-29: 10.0
agent-30: 12.0
agent-31: 11.0
agent-32: 7.0
agent-33: 14.0
agent-34: 9.0
agent-35: 10.0
agent-36: 9.0
agent-37: 16.0
agent-38: 8.0
agent-39: 7.0
agent-40: 7.0
Sum Reward: 419.0
Avg Reward: 10.475
Min Reward: 2.0
Max Reward: 16.0
Gini Coefficient: 0.1557875894988067
20:20 Ratio: 2.2884615384615383
Max-min Ratio: 8.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-08_08-42-05
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 465.0
  episode_reward_mean: 442.06
  episode_reward_min: 414.0
  episodes_this_iter: 1
  episodes_total: 479
  experiment_id: 4e724eb5b3a34f42879644e84578eec0
  hostname: gpu024
  info:
    apply_time_ms: 2.622
    dispatch_time_ms: 8.588
    learner:
      cur_lr: 8.394400356337428e-05
      grad_gnorm: 0.3662198781967163
      policy_entropy: 777.027099609375
      policy_loss: -0.04139753058552742
      var_gnorm: 39.52009963989258
      vf_explained_var: -1.0
      vf_loss: 0.0007350146188400686
    num_steps_sampled: 19200000
    num_steps_trained: 19200000
    wait_time_ms: 548.997
  iterations_since_restore: 480
  node_ip: 172.17.8.24
  num_metric_batches_dropped: 0
  pid: 26970
  policy_reward_mean: {}
  time_since_restore: 27122.55437850952
  time_this_iter_s: 56.566975116729736
  time_total_s: 27122.55437850952
  timestamp: 1594212125
  timesteps_since_restore: 19200000
  timesteps_this_iter: 40000
  timesteps_total: 19200000
  training_iteration: 480
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26970], 27122 s, 480 iter, 19200000 ts, 442 rew

agent-1: 13.0
agent-2: 12.0
agent-3: 13.0
agent-4: 10.0
agent-5: 18.0
agent-6: 6.0
agent-7: 5.0
agent-8: 10.0
agent-9: 13.0
agent-10: 12.0
agent-11: 7.0
agent-12: 13.0
agent-13: 14.0
agent-14: 5.0
agent-15: 10.0
agent-16: 6.0
agent-17: 8.0
agent-18: 8.0
agent-19: 11.0
agent-20: 17.0
agent-21: 11.0
agent-22: 9.0
agent-23: 13.0
agent-24: 11.0
agent-25: 10.0
agent-26: 11.0
agent-27: 7.0
agent-28: 17.0
agent-29: 10.0
agent-30: 6.0
agent-31: 14.0
agent-32: 20.0
agent-33: 14.0
agent-34: 11.0
agent-35: 6.0
agent-36: 12.0
agent-37: 17.0
agent-38: 5.0
agent-39: 8.0
agent-40: 15.0
Sum Reward: 438.0
Avg Reward: 10.95
Min Reward: 5.0
Max Reward: 20.0
Gini Coefficient: 0.19668949771689498
20:20 Ratio: 2.869565217391304
Max-min Ratio: 4.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-08_08-43-02
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 465.0
  episode_reward_mean: 442.2
  episode_reward_min: 414.0
  episodes_this_iter: 1
  episodes_total: 480
  experiment_id: 4e724eb5b3a34f42879644e84578eec0
  hostname: gpu024
  info:
    apply_time_ms: 2.535
    dispatch_time_ms: 5.799
    learner:
      cur_lr: 8.127999899443239e-05
      grad_gnorm: 0.8517984747886658
      policy_entropy: 777.1331787109375
      policy_loss: 0.43431830406188965
      var_gnorm: 39.51792907714844
      vf_explained_var: -0.4575585126876831
      vf_loss: 0.00015946044004522264
    num_steps_sampled: 19240000
    num_steps_trained: 19240000
    wait_time_ms: 555.345
  iterations_since_restore: 481
  node_ip: 172.17.8.24
  num_metric_batches_dropped: 0
  pid: 26970
  policy_reward_mean: {}
  time_since_restore: 27179.284735679626
  time_this_iter_s: 56.73035717010498
  time_total_s: 27179.284735679626
  timestamp: 1594212182
  timesteps_since_restore: 19240000
  timesteps_this_iter: 40000
  timesteps_total: 19240000
  training_iteration: 481
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26970], 27179 s, 481 iter, 19240000 ts, 442 rew

agent-1: 12.0
agent-2: 9.0
agent-3: 13.0
agent-4: 5.0
agent-5: 13.0
agent-6: 9.0
agent-7: 9.0
agent-8: 10.0
agent-9: 13.0
agent-10: 19.0
agent-11: 16.0
agent-12: 15.0
agent-13: 9.0
agent-14: 12.0
agent-15: 16.0
agent-16: 7.0
agent-17: 15.0
agent-18: 15.0
agent-19: 17.0
agent-20: 17.0
agent-21: 9.0
agent-22: 12.0
agent-23: 7.0
agent-24: 8.0
agent-25: 12.0
agent-26: 7.0
agent-27: 18.0
agent-28: 11.0
agent-29: 8.0
agent-30: 6.0
agent-31: 18.0
agent-32: 4.0
agent-33: 10.0
agent-34: 8.0
agent-35: 10.0
agent-36: 10.0
agent-37: 8.0
agent-38: 7.0
agent-39: 16.0
agent-40: 11.0
Sum Reward: 451.0
Avg Reward: 11.275
Min Reward: 4.0
Max Reward: 19.0
Gini Coefficient: 0.1961751662971175
20:20 Ratio: 2.6862745098039214
Max-min Ratio: 4.75
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-08_08-43-58
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 465.0
  episode_reward_mean: 442.1
  episode_reward_min: 414.0
  episodes_this_iter: 1
  episodes_total: 481
  experiment_id: 4e724eb5b3a34f42879644e84578eec0
  hostname: gpu024
  info:
    apply_time_ms: 3.086
    dispatch_time_ms: 5.921
    learner:
      cur_lr: 7.861600170144811e-05
      grad_gnorm: 0.13579951226711273
      policy_entropy: 777.39990234375
      policy_loss: 0.0015218730550259352
      var_gnorm: 39.521522521972656
      vf_explained_var: -1.0
      vf_loss: 5.1076964155072346e-05
    num_steps_sampled: 19280000
    num_steps_trained: 19280000
    wait_time_ms: 572.29
  iterations_since_restore: 482
  node_ip: 172.17.8.24
  num_metric_batches_dropped: 0
  pid: 26970
  policy_reward_mean: {}
  time_since_restore: 27235.9473028183
  time_this_iter_s: 56.662567138671875
  time_total_s: 27235.9473028183
  timestamp: 1594212238
  timesteps_since_restore: 19280000
  timesteps_this_iter: 40000
  timesteps_total: 19280000
  training_iteration: 482
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26970], 27235 s, 482 iter, 19280000 ts, 442 rew

agent-1: 9.0
agent-2: 14.0
agent-3: 16.0
agent-4: 12.0
agent-5: 12.0
agent-6: 16.0
agent-7: 7.0
agent-8: 13.0
agent-9: 4.0
agent-10: 16.0
agent-11: 5.0
agent-12: 7.0
agent-13: 9.0
agent-14: 8.0
agent-15: 12.0
agent-16: 7.0
agent-17: 7.0
agent-18: 8.0
agent-19: 12.0
agent-20: 3.0
agent-21: 7.0
agent-22: 10.0
agent-23: 7.0
agent-24: 9.0
agent-25: 14.0
agent-26: 13.0
agent-27: 17.0
agent-28: 12.0
agent-29: 12.0
agent-30: 13.0
agent-31: 15.0
agent-32: 18.0
agent-33: 11.0
agent-34: 7.0
agent-35: 9.0
agent-36: 11.0
agent-37: 11.0
agent-38: 16.0
agent-39: 11.0
agent-40: 17.0
Sum Reward: 437.0
Avg Reward: 10.925
Min Reward: 3.0
Max Reward: 18.0
Gini Coefficient: 0.19651029748283752
20:20 Ratio: 2.7872340425531914
Max-min Ratio: 6.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-08_08-44-54
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 465.0
  episode_reward_mean: 441.92
  episode_reward_min: 414.0
  episodes_this_iter: 1
  episodes_total: 482
  experiment_id: 4e724eb5b3a34f42879644e84578eec0
  hostname: gpu024
  info:
    apply_time_ms: 2.517
    dispatch_time_ms: 6.039
    learner:
      cur_lr: 7.595199713250622e-05
      grad_gnorm: 0.16174064576625824
      policy_entropy: 777.1195068359375
      policy_loss: 0.04022516310214996
      var_gnorm: 39.52589416503906
      vf_explained_var: -1.0
      vf_loss: 5.721607885789126e-05
    num_steps_sampled: 19320000
    num_steps_trained: 19320000
    wait_time_ms: 555.026
  iterations_since_restore: 483
  node_ip: 172.17.8.24
  num_metric_batches_dropped: 0
  pid: 26970
  policy_reward_mean: {}
  time_since_restore: 27291.996963262558
  time_this_iter_s: 56.049660444259644
  time_total_s: 27291.996963262558
  timestamp: 1594212294
  timesteps_since_restore: 19320000
  timesteps_this_iter: 40000
  timesteps_total: 19320000
  training_iteration: 483
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26970], 27291 s, 483 iter, 19320000 ts, 442 rew

agent-1: 9.0
agent-2: 8.0
agent-3: 13.0
agent-4: 8.0
agent-5: 12.0
agent-6: 14.0
agent-7: 11.0
agent-8: 16.0
agent-9: 16.0
agent-10: 12.0
agent-11: 11.0
agent-12: 21.0
agent-13: 12.0
agent-14: 12.0
agent-15: 4.0
agent-16: 16.0
agent-17: 16.0
agent-18: 7.0
agent-19: 3.0
agent-20: 10.0
agent-21: 8.0
agent-22: 6.0
agent-23: 12.0
agent-24: 18.0
agent-25: 14.0
agent-26: 11.0
agent-27: 8.0
agent-28: 13.0
agent-29: 5.0
agent-30: 13.0
agent-31: 8.0
agent-32: 8.0
agent-33: 10.0
agent-34: 12.0
agent-35: 17.0
agent-36: 7.0
agent-37: 8.0
agent-38: 6.0
agent-39: 11.0
agent-40: 8.0
Sum Reward: 434.0
Avg Reward: 10.85
Min Reward: 3.0
Max Reward: 21.0
Gini Coefficient: 0.20529953917050692
20:20 Ratio: 2.9130434782608696
Max-min Ratio: 7.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-08_08-45-51
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 465.0
  episode_reward_mean: 441.62
  episode_reward_min: 414.0
  episodes_this_iter: 1
  episodes_total: 483
  experiment_id: 4e724eb5b3a34f42879644e84578eec0
  hostname: gpu024
  info:
    apply_time_ms: 3.09
    dispatch_time_ms: 7.389
    learner:
      cur_lr: 7.328799983952194e-05
      grad_gnorm: 0.1899285912513733
      policy_entropy: 777.4530029296875
      policy_loss: 0.11691192537546158
      var_gnorm: 39.52275848388672
      vf_explained_var: -0.8129063844680786
      vf_loss: 0.00016152637545019388
    num_steps_sampled: 19360000
    num_steps_trained: 19360000
    wait_time_ms: 554.41
  iterations_since_restore: 484
  node_ip: 172.17.8.24
  num_metric_batches_dropped: 0
  pid: 26970
  policy_reward_mean: {}
  time_since_restore: 27348.395534992218
  time_this_iter_s: 56.398571729660034
  time_total_s: 27348.395534992218
  timestamp: 1594212351
  timesteps_since_restore: 19360000
  timesteps_this_iter: 40000
  timesteps_total: 19360000
  training_iteration: 484
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26970], 27348 s, 484 iter, 19360000 ts, 442 rew

agent-1: 9.0
agent-2: 14.0
agent-3: 14.0
agent-4: 9.0
agent-5: 13.0
agent-6: 11.0
agent-7: 9.0
agent-8: 4.0
agent-9: 13.0
agent-10: 14.0
agent-11: 14.0
agent-12: 9.0
agent-13: 4.0
agent-14: 17.0
agent-15: 9.0
agent-16: 22.0
agent-17: 9.0
agent-18: 11.0
agent-19: 13.0
agent-20: 7.0
agent-21: 5.0
agent-22: 5.0
agent-23: 11.0
agent-24: 15.0
agent-25: 9.0
agent-26: 12.0
agent-27: 8.0
agent-28: 13.0
agent-29: 14.0
agent-30: 8.0
agent-31: 12.0
agent-32: 6.0
agent-33: 9.0
agent-34: 12.0
agent-35: 4.0
agent-36: 6.0
agent-37: 16.0
agent-38: 15.0
agent-39: 7.0
agent-40: 10.0
Sum Reward: 422.0
Avg Reward: 10.55
Min Reward: 4.0
Max Reward: 22.0
Gini Coefficient: 0.20888625592417062
20:20 Ratio: 3.097560975609756
Max-min Ratio: 5.5
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-08_08-46-48
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 465.0
  episode_reward_mean: 441.35
  episode_reward_min: 414.0
  episodes_this_iter: 1
  episodes_total: 484
  experiment_id: 4e724eb5b3a34f42879644e84578eec0
  hostname: gpu024
  info:
    apply_time_ms: 2.851
    dispatch_time_ms: 5.729
    learner:
      cur_lr: 7.062400254653767e-05
      grad_gnorm: 0.5282149314880371
      policy_entropy: 777.8360595703125
      policy_loss: 0.31940385699272156
      var_gnorm: 39.5239143371582
      vf_explained_var: -0.5897468328475952
      vf_loss: 0.0003037269925698638
    num_steps_sampled: 19400000
    num_steps_trained: 19400000
    wait_time_ms: 561.502
  iterations_since_restore: 485
  node_ip: 172.17.8.24
  num_metric_batches_dropped: 0
  pid: 26970
  policy_reward_mean: {}
  time_since_restore: 27405.38068842888
  time_this_iter_s: 56.98515343666077
  time_total_s: 27405.38068842888
  timestamp: 1594212408
  timesteps_since_restore: 19400000
  timesteps_this_iter: 40000
  timesteps_total: 19400000
  training_iteration: 485
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26970], 27405 s, 485 iter, 19400000 ts, 441 rew

agent-1: 15.0
agent-2: 14.0
agent-3: 11.0
agent-4: 7.0
agent-5: 6.0
agent-6: 7.0
agent-7: 15.0
agent-8: 12.0
agent-9: 12.0
agent-10: 9.0
agent-11: 11.0
agent-12: 11.0
agent-13: 12.0
agent-14: 9.0
agent-15: 7.0
agent-16: 3.0
agent-17: 16.0
agent-18: 14.0
agent-19: 15.0
agent-20: 10.0
agent-21: 11.0
agent-22: 12.0
agent-23: 8.0
agent-24: 10.0
agent-25: 11.0
agent-26: 9.0
agent-27: 11.0
agent-28: 6.0
agent-29: 10.0
agent-30: 14.0
agent-31: 14.0
agent-32: 12.0
agent-33: 13.0
agent-34: 9.0
agent-35: 14.0
agent-36: 10.0
agent-37: 15.0
agent-38: 15.0
agent-39: 9.0
agent-40: 14.0
Sum Reward: 443.0
Avg Reward: 11.075
Min Reward: 3.0
Max Reward: 16.0
Gini Coefficient: 0.15287810383747177
20:20 Ratio: 2.2452830188679247
Max-min Ratio: 5.333333333333333
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-08_08-47-45
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 465.0
  episode_reward_mean: 441.35
  episode_reward_min: 414.0
  episodes_this_iter: 1
  episodes_total: 485
  experiment_id: 4e724eb5b3a34f42879644e84578eec0
  hostname: gpu024
  info:
    apply_time_ms: 3.429
    dispatch_time_ms: 5.904
    learner:
      cur_lr: 6.795999797759578e-05
      grad_gnorm: 0.16700631380081177
      policy_entropy: 776.5400390625
      policy_loss: -0.03213490918278694
      var_gnorm: 39.526123046875
      vf_explained_var: -1.0
      vf_loss: 9.60961333476007e-05
    num_steps_sampled: 19440000
    num_steps_trained: 19440000
    wait_time_ms: 565.214
  iterations_since_restore: 486
  node_ip: 172.17.8.24
  num_metric_batches_dropped: 0
  pid: 26970
  policy_reward_mean: {}
  time_since_restore: 27462.063071012497
  time_this_iter_s: 56.682382583618164
  time_total_s: 27462.063071012497
  timestamp: 1594212465
  timesteps_since_restore: 19440000
  timesteps_this_iter: 40000
  timesteps_total: 19440000
  training_iteration: 486
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26970], 27462 s, 486 iter, 19440000 ts, 441 rew

agent-1: 14.0
agent-2: 12.0
agent-3: 14.0
agent-4: 11.0
agent-5: 7.0
agent-6: 10.0
agent-7: 13.0
agent-8: 5.0
agent-9: 15.0
agent-10: 9.0
agent-11: 6.0
agent-12: 14.0
agent-13: 18.0
agent-14: 12.0
agent-15: 8.0
agent-16: 11.0
agent-17: 18.0
agent-18: 14.0
agent-19: 7.0
agent-20: 11.0
agent-21: 11.0
agent-22: 9.0
agent-23: 9.0
agent-24: 8.0
agent-25: 10.0
agent-26: 8.0
agent-27: 10.0
agent-28: 7.0
agent-29: 14.0
agent-30: 11.0
agent-31: 12.0
agent-32: 9.0
agent-33: 13.0
agent-34: 3.0
agent-35: 9.0
agent-36: 10.0
agent-37: 13.0
agent-38: 15.0
agent-39: 15.0
agent-40: 18.0
Sum Reward: 443.0
Avg Reward: 11.075
Min Reward: 3.0
Max Reward: 18.0
Gini Coefficient: 0.1760158013544018
20:20 Ratio: 2.4901960784313726
Max-min Ratio: 6.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-08_08-48-41
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 465.0
  episode_reward_mean: 441.36
  episode_reward_min: 414.0
  episodes_this_iter: 1
  episodes_total: 486
  experiment_id: 4e724eb5b3a34f42879644e84578eec0
  hostname: gpu024
  info:
    apply_time_ms: 3.083
    dispatch_time_ms: 6.341
    learner:
      cur_lr: 6.52960006846115e-05
      grad_gnorm: 0.8722385168075562
      policy_entropy: 777.2922973632812
      policy_loss: -0.23032981157302856
      var_gnorm: 39.525062561035156
      vf_explained_var: -1.0
      vf_loss: 0.00015789773897267878
    num_steps_sampled: 19480000
    num_steps_trained: 19480000
    wait_time_ms: 556.603
  iterations_since_restore: 487
  node_ip: 172.17.8.24
  num_metric_batches_dropped: 0
  pid: 26970
  policy_reward_mean: {}
  time_since_restore: 27518.52638411522
  time_this_iter_s: 56.46331310272217
  time_total_s: 27518.52638411522
  timestamp: 1594212521
  timesteps_since_restore: 19480000
  timesteps_this_iter: 40000
  timesteps_total: 19480000
  training_iteration: 487
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26970], 27518 s, 487 iter, 19480000 ts, 441 rew

agent-1: 17.0
agent-2: 9.0
agent-3: 9.0
agent-4: 13.0
agent-5: 11.0
agent-6: 11.0
agent-7: 13.0
agent-8: 9.0
agent-9: 11.0
agent-10: 11.0
agent-11: 13.0
agent-12: 14.0
agent-13: 10.0
agent-14: 13.0
agent-15: 16.0
agent-16: 2.0
agent-17: 10.0
agent-18: 13.0
agent-19: 8.0
agent-20: 9.0
agent-21: 11.0
agent-22: 15.0
agent-23: 11.0
agent-24: 14.0
agent-25: 10.0
agent-26: 10.0
agent-27: 12.0
agent-28: 7.0
agent-29: 14.0
agent-30: 7.0
agent-31: 5.0
agent-32: 15.0
agent-33: 9.0
agent-34: 10.0
agent-35: 13.0
agent-36: 8.0
agent-37: 10.0
agent-38: 5.0
agent-39: 9.0
agent-40: 10.0
Sum Reward: 427.0
Avg Reward: 10.675
Min Reward: 2.0
Max Reward: 17.0
Gini Coefficient: 0.15813817330210772
20:20 Ratio: 2.3137254901960786
Max-min Ratio: 8.5
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-08_08-49-37
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 465.0
  episode_reward_mean: 441.36
  episode_reward_min: 414.0
  episodes_this_iter: 1
  episodes_total: 487
  experiment_id: 4e724eb5b3a34f42879644e84578eec0
  hostname: gpu024
  info:
    apply_time_ms: 2.957
    dispatch_time_ms: 5.519
    learner:
      cur_lr: 6.263200339162722e-05
      grad_gnorm: 0.6697943806648254
      policy_entropy: 777.3287353515625
      policy_loss: -0.08602305501699448
      var_gnorm: 39.52791976928711
      vf_explained_var: -0.2260349988937378
      vf_loss: 0.00027564464835450053
    num_steps_sampled: 19520000
    num_steps_trained: 19520000
    wait_time_ms: 555.502
  iterations_since_restore: 488
  node_ip: 172.17.8.24
  num_metric_batches_dropped: 0
  pid: 26970
  policy_reward_mean: {}
  time_since_restore: 27574.890718460083
  time_this_iter_s: 56.36433434486389
  time_total_s: 27574.890718460083
  timestamp: 1594212577
  timesteps_since_restore: 19520000
  timesteps_this_iter: 40000
  timesteps_total: 19520000
  training_iteration: 488
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26970], 27574 s, 488 iter, 19520000 ts, 441 rew

agent-1: 3.0
agent-2: 6.0
agent-3: 16.0
agent-4: 14.0
agent-5: 4.0
agent-6: 10.0
agent-7: 11.0
agent-8: 7.0
agent-9: 12.0
agent-10: 12.0
agent-11: 6.0
agent-12: 12.0
agent-13: 16.0
agent-14: 10.0
agent-15: 14.0
agent-16: 7.0
agent-17: 11.0
agent-18: 10.0
agent-19: 6.0
agent-20: 15.0
agent-21: 10.0
agent-22: 7.0
agent-23: 16.0
agent-24: 11.0
agent-25: 9.0
agent-26: 10.0
agent-27: 11.0
agent-28: 14.0
agent-29: 15.0
agent-30: 9.0
agent-31: 13.0
agent-32: 12.0
agent-33: 11.0
agent-34: 15.0
agent-35: 7.0
agent-36: 13.0
agent-37: 12.0
agent-38: 15.0
agent-39: 14.0
agent-40: 8.0
Sum Reward: 434.0
Avg Reward: 10.85
Min Reward: 3.0
Max Reward: 16.0
Gini Coefficient: 0.1774193548387097
20:20 Ratio: 2.652173913043478
Max-min Ratio: 5.333333333333333
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-08_08-50-34
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 465.0
  episode_reward_mean: 441.24
  episode_reward_min: 414.0
  episodes_this_iter: 1
  episodes_total: 488
  experiment_id: 4e724eb5b3a34f42879644e84578eec0
  hostname: gpu024
  info:
    apply_time_ms: 2.889
    dispatch_time_ms: 6.0
    learner:
      cur_lr: 5.996799882268533e-05
      grad_gnorm: 0.34779298305511475
      policy_entropy: 776.481689453125
      policy_loss: 0.004778839647769928
      var_gnorm: 39.53093338012695
      vf_explained_var: -1.0
      vf_loss: 0.00017011801537591964
    num_steps_sampled: 19560000
    num_steps_trained: 19560000
    wait_time_ms: 552.018
  iterations_since_restore: 489
  node_ip: 172.17.8.24
  num_metric_batches_dropped: 0
  pid: 26970
  policy_reward_mean: {}
  time_since_restore: 27631.296562194824
  time_this_iter_s: 56.40584373474121
  time_total_s: 27631.296562194824
  timestamp: 1594212634
  timesteps_since_restore: 19560000
  timesteps_this_iter: 40000
  timesteps_total: 19560000
  training_iteration: 489
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26970], 27631 s, 489 iter, 19560000 ts, 441 rew

agent-1: 9.0
agent-2: 17.0
agent-3: 8.0
agent-4: 11.0
agent-5: 12.0
agent-6: 6.0
agent-7: 6.0
agent-8: 7.0
agent-9: 17.0
agent-10: 7.0
agent-11: 16.0
agent-12: 9.0
agent-13: 16.0
agent-14: 20.0
agent-15: 9.0
agent-16: 9.0
agent-17: 13.0
agent-18: 15.0
agent-19: 14.0
agent-20: 14.0
agent-21: 9.0
agent-22: 3.0
agent-23: 2.0
agent-24: 14.0
agent-25: 15.0
agent-26: 12.0
agent-27: 12.0
agent-28: 12.0
agent-29: 7.0
agent-30: 13.0
agent-31: 9.0
agent-32: 11.0
agent-33: 11.0
agent-34: 12.0
agent-35: 11.0
agent-36: 7.0
agent-37: 16.0
agent-38: 11.0
agent-39: 14.0
agent-40: 12.0
Sum Reward: 448.0
Avg Reward: 11.2
Min Reward: 2.0
Max Reward: 20.0
Gini Coefficient: 0.19441964285714286
20:20 Ratio: 2.933333333333333
Max-min Ratio: 10.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-08_08-51-30
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 465.0
  episode_reward_mean: 441.3
  episode_reward_min: 414.0
  episodes_this_iter: 1
  episodes_total: 489
  experiment_id: 4e724eb5b3a34f42879644e84578eec0
  hostname: gpu024
  info:
    apply_time_ms: 2.666
    dispatch_time_ms: 6.502
    learner:
      cur_lr: 5.7304001529701054e-05
      grad_gnorm: 0.428204208612442
      policy_entropy: 777.1356201171875
      policy_loss: 0.18997640907764435
      var_gnorm: 39.52696228027344
      vf_explained_var: -0.6860220432281494
      vf_loss: 0.00015180544869508594
    num_steps_sampled: 19600000
    num_steps_trained: 19600000
    wait_time_ms: 548.895
  iterations_since_restore: 490
  node_ip: 172.17.8.24
  num_metric_batches_dropped: 0
  pid: 26970
  policy_reward_mean: {}
  time_since_restore: 27687.791439294815
  time_this_iter_s: 56.494877099990845
  time_total_s: 27687.791439294815
  timestamp: 1594212690
  timesteps_since_restore: 19600000
  timesteps_this_iter: 40000
  timesteps_total: 19600000
  training_iteration: 490
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26970], 27687 s, 490 iter, 19600000 ts, 441 rew

agent-1: 9.0
agent-2: 8.0
agent-3: 10.0
agent-4: 13.0
agent-5: 6.0
agent-6: 7.0
agent-7: 15.0
agent-8: 14.0
agent-9: 9.0
agent-10: 9.0
agent-11: 15.0
agent-12: 12.0
agent-13: 8.0
agent-14: 12.0
agent-15: 8.0
agent-16: 8.0
agent-17: 19.0
agent-18: 11.0
agent-19: 12.0
agent-20: 16.0
agent-21: 13.0
agent-22: 8.0
agent-23: 15.0
agent-24: -39.0
agent-25: 17.0
agent-26: 14.0
agent-27: 12.0
agent-28: -40.0
agent-29: 8.0
agent-30: 4.0
agent-31: 9.0
agent-32: 8.0
agent-33: 9.0
agent-34: 11.0
agent-35: 9.0
agent-36: 10.0
agent-37: 4.0
agent-38: 9.0
agent-39: 10.0
agent-40: 13.0
Sum Reward: 325.0
Avg Reward: 8.125
Min Reward: -40.0
Max Reward: 19.0
Gini Coefficient: 0.5026923076923077
20:20 Ratio: -2.9761904761904763
Max-min Ratio: -0.475
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-08_08-52-27
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 465.0
  episode_reward_mean: 440.04
  episode_reward_min: 325.0
  episodes_this_iter: 1
  episodes_total: 490
  experiment_id: 4e724eb5b3a34f42879644e84578eec0
  hostname: gpu024
  info:
    apply_time_ms: 3.235
    dispatch_time_ms: 5.171
    learner:
      cur_lr: 5.464000059873797e-05
      grad_gnorm: 0.19981448352336884
      policy_entropy: 776.8654174804688
      policy_loss: 0.02720816247165203
      var_gnorm: 39.52926254272461
      vf_explained_var: -1.0
      vf_loss: 8.485576108796522e-05
    num_steps_sampled: 19640000
    num_steps_trained: 19640000
    wait_time_ms: 572.106
  iterations_since_restore: 491
  node_ip: 172.17.8.24
  num_metric_batches_dropped: 0
  pid: 26970
  policy_reward_mean: {}
  time_since_restore: 27744.621881723404
  time_this_iter_s: 56.83044242858887
  time_total_s: 27744.621881723404
  timestamp: 1594212747
  timesteps_since_restore: 19640000
  timesteps_this_iter: 40000
  timesteps_total: 19640000
  training_iteration: 491
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26970], 27744 s, 491 iter, 19640000 ts, 440 rew

agent-1: 15.0
agent-2: 10.0
agent-3: 9.0
agent-4: 8.0
agent-5: 12.0
agent-6: 7.0
agent-7: 14.0
agent-8: 8.0
agent-9: 4.0
agent-10: 8.0
agent-11: 8.0
agent-12: 9.0
agent-13: 9.0
agent-14: 19.0
agent-15: 15.0
agent-16: 6.0
agent-17: 15.0
agent-18: 9.0
agent-19: 10.0
agent-20: 7.0
agent-21: 19.0
agent-22: 4.0
agent-23: 19.0
agent-24: 12.0
agent-25: 17.0
agent-26: 15.0
agent-27: 8.0
agent-28: 11.0
agent-29: 11.0
agent-30: 16.0
agent-31: 15.0
agent-32: 12.0
agent-33: 9.0
agent-34: 12.0
agent-35: 11.0
agent-36: 18.0
agent-37: 14.0
agent-38: 12.0
agent-39: 9.0
agent-40: 5.0
Sum Reward: 451.0
Avg Reward: 11.275
Min Reward: 4.0
Max Reward: 19.0
Gini Coefficient: 0.20482261640798227
20:20 Ratio: 2.816326530612245
Max-min Ratio: 4.75
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-08_08-53-24
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 465.0
  episode_reward_mean: 440.2
  episode_reward_min: 325.0
  episodes_this_iter: 1
  episodes_total: 491
  experiment_id: 4e724eb5b3a34f42879644e84578eec0
  hostname: gpu024
  info:
    apply_time_ms: 2.843
    dispatch_time_ms: 5.984
    learner:
      cur_lr: 5.1975999667774886e-05
      grad_gnorm: 0.9997455477714539
      policy_entropy: 777.09033203125
      policy_loss: -0.1188376396894455
      var_gnorm: 39.527915954589844
      vf_explained_var: -1.0
      vf_loss: 0.0007933269953355193
    num_steps_sampled: 19680000
    num_steps_trained: 19680000
    wait_time_ms: 562.406
  iterations_since_restore: 492
  node_ip: 172.17.8.24
  num_metric_batches_dropped: 0
  pid: 26970
  policy_reward_mean: {}
  time_since_restore: 27801.138931035995
  time_this_iter_s: 56.51704931259155
  time_total_s: 27801.138931035995
  timestamp: 1594212804
  timesteps_since_restore: 19680000
  timesteps_this_iter: 40000
  timesteps_total: 19680000
  training_iteration: 492
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26970], 27801 s, 492 iter, 19680000 ts, 440 rew

agent-1: 15.0
agent-2: 10.0
agent-3: 3.0
agent-4: 15.0
agent-5: 9.0
agent-6: 6.0
agent-7: 15.0
agent-8: 7.0
agent-9: 7.0
agent-10: 11.0
agent-11: 9.0
agent-12: 7.0
agent-13: 7.0
agent-14: 10.0
agent-15: 11.0
agent-16: 13.0
agent-17: 15.0
agent-18: 6.0
agent-19: 12.0
agent-20: 9.0
agent-21: 11.0
agent-22: 14.0
agent-23: 12.0
agent-24: 9.0
agent-25: 17.0
agent-26: 8.0
agent-27: 14.0
agent-28: 8.0
agent-29: 13.0
agent-30: 14.0
agent-31: 13.0
agent-32: 9.0
agent-33: 8.0
agent-34: 8.0
agent-35: 12.0
agent-36: 12.0
agent-37: 11.0
agent-38: 13.0
agent-39: 9.0
agent-40: 11.0
Sum Reward: 423.0
Avg Reward: 10.575
Min Reward: 3.0
Max Reward: 17.0
Gini Coefficient: 0.16530732860520095
20:20 Ratio: 2.3333333333333335
Max-min Ratio: 5.666666666666667
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-08_08-54-20
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 465.0
  episode_reward_mean: 440.03
  episode_reward_min: 325.0
  episodes_this_iter: 1
  episodes_total: 492
  experiment_id: 4e724eb5b3a34f42879644e84578eec0
  hostname: gpu024
  info:
    apply_time_ms: 4.112
    dispatch_time_ms: 7.165
    learner:
      cur_lr: 4.93119987368118e-05
      grad_gnorm: 0.3698485791683197
      policy_entropy: 777.4791259765625
      policy_loss: -0.07034794986248016
      var_gnorm: 39.528316497802734
      vf_explained_var: -0.7439758777618408
      vf_loss: 0.00012073439575033262
    num_steps_sampled: 19720000
    num_steps_trained: 19720000
    wait_time_ms: 566.934
  iterations_since_restore: 493
  node_ip: 172.17.8.24
  num_metric_batches_dropped: 0
  pid: 26970
  policy_reward_mean: {}
  time_since_restore: 27857.712696313858
  time_this_iter_s: 56.57376527786255
  time_total_s: 27857.712696313858
  timestamp: 1594212860
  timesteps_since_restore: 19720000
  timesteps_this_iter: 40000
  timesteps_total: 19720000
  training_iteration: 493
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26970], 27857 s, 493 iter, 19720000 ts, 440 rew

agent-1: 6.0
agent-2: 14.0
agent-3: 10.0
agent-4: 7.0
agent-5: 14.0
agent-6: 8.0
agent-7: 9.0
agent-8: 12.0
agent-9: 10.0
agent-10: 18.0
agent-11: 12.0
agent-12: 16.0
agent-13: 14.0
agent-14: 15.0
agent-15: 12.0
agent-16: 9.0
agent-17: 16.0
agent-18: 12.0
agent-19: 10.0
agent-20: 14.0
agent-21: 11.0
agent-22: 10.0
agent-23: 11.0
agent-24: 9.0
agent-25: 6.0
agent-26: 7.0
agent-27: 6.0
agent-28: 13.0
agent-29: 13.0
agent-30: 11.0
agent-31: 16.0
agent-32: 7.0
agent-33: 13.0
agent-34: 8.0
agent-35: 7.0
agent-36: 8.0
agent-37: 12.0
agent-38: 6.0
agent-39: 10.0
agent-40: 10.0
Sum Reward: 432.0
Avg Reward: 10.8
Min Reward: 6.0
Max Reward: 18.0
Gini Coefficient: 0.16701388888888888
20:20 Ratio: 2.3653846153846154
Max-min Ratio: 3.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-08_08-55-17
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 465.0
  episode_reward_mean: 439.87
  episode_reward_min: 325.0
  episodes_this_iter: 1
  episodes_total: 493
  experiment_id: 4e724eb5b3a34f42879644e84578eec0
  hostname: gpu024
  info:
    apply_time_ms: 3.337
    dispatch_time_ms: 6.486
    learner:
      cur_lr: 4.6648001443827525e-05
      grad_gnorm: 0.11547376960515976
      policy_entropy: 777.7784423828125
      policy_loss: 0.06614476442337036
      var_gnorm: 39.5275993347168
      vf_explained_var: -1.0
      vf_loss: 4.200545299681835e-05
    num_steps_sampled: 19760000
    num_steps_trained: 19760000
    wait_time_ms: 554.869
  iterations_since_restore: 494
  node_ip: 172.17.8.24
  num_metric_batches_dropped: 0
  pid: 26970
  policy_reward_mean: {}
  time_since_restore: 27914.15861415863
  time_this_iter_s: 56.44591784477234
  time_total_s: 27914.15861415863
  timestamp: 1594212917
  timesteps_since_restore: 19760000
  timesteps_this_iter: 40000
  timesteps_total: 19760000
  training_iteration: 494
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26970], 27914 s, 494 iter, 19760000 ts, 440 rew

agent-1: 10.0
agent-2: 7.0
agent-3: 10.0
agent-4: 12.0
agent-5: 9.0
agent-6: 13.0
agent-7: 7.0
agent-8: 7.0
agent-9: 15.0
agent-10: 15.0
agent-11: 9.0
agent-12: 10.0
agent-13: 15.0
agent-14: 13.0
agent-15: 7.0
agent-16: 14.0
agent-17: 9.0
agent-18: 10.0
agent-19: 7.0
agent-20: 12.0
agent-21: 15.0
agent-22: 10.0
agent-23: 16.0
agent-24: 12.0
agent-25: 7.0
agent-26: 15.0
agent-27: 9.0
agent-28: 6.0
agent-29: 12.0
agent-30: 10.0
agent-31: 14.0
agent-32: 7.0
agent-33: 11.0
agent-34: 12.0
agent-35: 4.0
agent-36: 9.0
agent-37: 15.0
agent-38: 11.0
agent-39: 11.0
agent-40: 7.0
Sum Reward: 424.0
Avg Reward: 10.6
Min Reward: 4.0
Max Reward: 16.0
Gini Coefficient: 0.16391509433962265
20:20 Ratio: 2.3076923076923075
Max-min Ratio: 4.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-08_08-56-14
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 465.0
  episode_reward_mean: 439.75
  episode_reward_min: 325.0
  episodes_this_iter: 1
  episodes_total: 494
  experiment_id: 4e724eb5b3a34f42879644e84578eec0
  hostname: gpu024
  info:
    apply_time_ms: 2.51
    dispatch_time_ms: 5.375
    learner:
      cur_lr: 4.398400051286444e-05
      grad_gnorm: 0.5651036500930786
      policy_entropy: 777.0726318359375
      policy_loss: 0.0034366766922175884
      var_gnorm: 39.530033111572266
      vf_explained_var: -1.0
      vf_loss: 8.85170156834647e-05
    num_steps_sampled: 19800000
    num_steps_trained: 19800000
    wait_time_ms: 564.649
  iterations_since_restore: 495
  node_ip: 172.17.8.24
  num_metric_batches_dropped: 0
  pid: 26970
  policy_reward_mean: {}
  time_since_restore: 27970.744394302368
  time_this_iter_s: 56.58578014373779
  time_total_s: 27970.744394302368
  timestamp: 1594212974
  timesteps_since_restore: 19800000
  timesteps_this_iter: 40000
  timesteps_total: 19800000
  training_iteration: 495
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26970], 27970 s, 495 iter, 19800000 ts, 440 rew

agent-1: 2.0
agent-2: 7.0
agent-3: 13.0
agent-4: 12.0
agent-5: 6.0
agent-6: 13.0
agent-7: 13.0
agent-8: 8.0
agent-9: 9.0
agent-10: 13.0
agent-11: 10.0
agent-12: 12.0
agent-13: 16.0
agent-14: 9.0
agent-15: 12.0
agent-16: 11.0
agent-17: 10.0
agent-18: 10.0
agent-19: 6.0
agent-20: 19.0
agent-21: 11.0
agent-22: 14.0
agent-23: 15.0
agent-24: 13.0
agent-25: 11.0
agent-26: 13.0
agent-27: 12.0
agent-28: 9.0
agent-29: 21.0
agent-30: 10.0
agent-31: 16.0
agent-32: 13.0
agent-33: 6.0
agent-34: 12.0
agent-35: 8.0
agent-36: 9.0
agent-37: 11.0
agent-38: 5.0
agent-39: 10.0
agent-40: 12.0
Sum Reward: 442.0
Avg Reward: 11.05
Min Reward: 2.0
Max Reward: 21.0
Gini Coefficient: 0.17726244343891404
20:20 Ratio: 2.6458333333333335
Max-min Ratio: 10.5
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-08_08-57-10
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 465.0
  episode_reward_mean: 439.78
  episode_reward_min: 325.0
  episodes_this_iter: 1
  episodes_total: 495
  experiment_id: 4e724eb5b3a34f42879644e84578eec0
  hostname: gpu024
  info:
    apply_time_ms: 2.913
    dispatch_time_ms: 5.391
    learner:
      cur_lr: 4.1319999581901357e-05
      grad_gnorm: 0.6776686906814575
      policy_entropy: 776.4395751953125
      policy_loss: -0.41974109411239624
      var_gnorm: 39.52873992919922
      vf_explained_var: -1.0
      vf_loss: 0.0012107546208426356
    num_steps_sampled: 19840000
    num_steps_trained: 19840000
    wait_time_ms: 556.565
  iterations_since_restore: 496
  node_ip: 172.17.8.24
  num_metric_batches_dropped: 0
  pid: 26970
  policy_reward_mean: {}
  time_since_restore: 28027.319550275803
  time_this_iter_s: 56.57515597343445
  time_total_s: 28027.319550275803
  timestamp: 1594213030
  timesteps_since_restore: 19840000
  timesteps_this_iter: 40000
  timesteps_total: 19840000
  training_iteration: 496
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26970], 28027 s, 496 iter, 19840000 ts, 440 rew

agent-1: 4.0
agent-2: 10.0
agent-3: 14.0
agent-4: 13.0
agent-5: 15.0
agent-6: 19.0
agent-7: 13.0
agent-8: 10.0
agent-9: 8.0
agent-10: 11.0
agent-11: 8.0
agent-12: 18.0
agent-13: 11.0
agent-14: 10.0
agent-15: 12.0
agent-16: 13.0
agent-17: 7.0
agent-18: 11.0
agent-19: 14.0
agent-20: 11.0
agent-21: 16.0
agent-22: 1.0
agent-23: 10.0
agent-24: 13.0
agent-25: 9.0
agent-26: 5.0
agent-27: 13.0
agent-28: 10.0
agent-29: 14.0
agent-30: 12.0
agent-31: 11.0
agent-32: 10.0
agent-33: 16.0
agent-34: 16.0
agent-35: 12.0
agent-36: 8.0
agent-37: 15.0
agent-38: 13.0
agent-39: 13.0
agent-40: 9.0
Sum Reward: 458.0
Avg Reward: 11.45
Min Reward: 1.0
Max Reward: 19.0
Gini Coefficient: 0.17096069868995634
20:20 Ratio: 2.58
Max-min Ratio: 19.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-08_08-58-07
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 465.0
  episode_reward_mean: 440.05
  episode_reward_min: 325.0
  episodes_this_iter: 1
  episodes_total: 496
  experiment_id: 4e724eb5b3a34f42879644e84578eec0
  hostname: gpu024
  info:
    apply_time_ms: 2.514
    dispatch_time_ms: 6.077
    learner:
      cur_lr: 3.865599865093827e-05
      grad_gnorm: 1.126786470413208
      policy_entropy: 777.8787841796875
      policy_loss: -0.7665371894836426
      var_gnorm: 39.52725601196289
      vf_explained_var: -1.0
      vf_loss: 0.0002648612135089934
    num_steps_sampled: 19880000
    num_steps_trained: 19880000
    wait_time_ms: 570.836
  iterations_since_restore: 497
  node_ip: 172.17.8.24
  num_metric_batches_dropped: 0
  pid: 26970
  policy_reward_mean: {}
  time_since_restore: 28083.86282658577
  time_this_iter_s: 56.54327630996704
  time_total_s: 28083.86282658577
  timestamp: 1594213087
  timesteps_since_restore: 19880000
  timesteps_this_iter: 40000
  timesteps_total: 19880000
  training_iteration: 497
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26970], 28083 s, 497 iter, 19880000 ts, 440 rew

agent-1: 15.0
agent-2: 6.0
agent-3: 13.0
agent-4: 14.0
agent-5: 11.0
agent-6: 10.0
agent-7: 16.0
agent-8: 15.0
agent-9: 6.0
agent-10: 10.0
agent-11: 5.0
agent-12: 14.0
agent-13: 11.0
agent-14: 16.0
agent-15: 14.0
agent-16: 12.0
agent-17: 11.0
agent-18: 10.0
agent-19: 8.0
agent-20: 7.0
agent-21: 10.0
agent-22: 6.0
agent-23: 10.0
agent-24: 10.0
agent-25: 9.0
agent-26: 13.0
agent-27: 5.0
agent-28: 12.0
agent-29: 7.0
agent-30: 11.0
agent-31: 18.0
agent-32: 12.0
agent-33: 13.0
agent-34: 15.0
agent-35: 15.0
agent-36: 6.0
agent-37: 9.0
agent-38: 11.0
agent-39: 12.0
agent-40: 11.0
Sum Reward: 439.0
Avg Reward: 10.975
Min Reward: 5.0
Max Reward: 18.0
Gini Coefficient: 0.17010250569476082
20:20 Ratio: 2.5833333333333335
Max-min Ratio: 3.6
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-08_08-59-03
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 465.0
  episode_reward_mean: 440.12
  episode_reward_min: 325.0
  episodes_this_iter: 1
  episodes_total: 497
  experiment_id: 4e724eb5b3a34f42879644e84578eec0
  hostname: gpu024
  info:
    apply_time_ms: 3.429
    dispatch_time_ms: 5.662
    learner:
      cur_lr: 3.5992001357953995e-05
      grad_gnorm: 0.36580562591552734
      policy_entropy: 776.9423217773438
      policy_loss: -0.2127029448747635
      var_gnorm: 39.5279541015625
      vf_explained_var: -0.8340191841125488
      vf_loss: 0.0002735554298851639
    num_steps_sampled: 19920000
    num_steps_trained: 19920000
    wait_time_ms: 556.865
  iterations_since_restore: 498
  node_ip: 172.17.8.24
  num_metric_batches_dropped: 0
  pid: 26970
  policy_reward_mean: {}
  time_since_restore: 28140.29251742363
  time_this_iter_s: 56.42969083786011
  time_total_s: 28140.29251742363
  timestamp: 1594213143
  timesteps_since_restore: 19920000
  timesteps_this_iter: 40000
  timesteps_total: 19920000
  training_iteration: 498
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26970], 28140 s, 498 iter, 19920000 ts, 440 rew

agent-1: 12.0
agent-2: 14.0
agent-3: 14.0
agent-4: 12.0
agent-5: 11.0
agent-6: 14.0
agent-7: 8.0
agent-8: 15.0
agent-9: 7.0
agent-10: 11.0
agent-11: 10.0
agent-12: 14.0
agent-13: 13.0
agent-14: 12.0
agent-15: 9.0
agent-16: 16.0
agent-17: 10.0
agent-18: 10.0
agent-19: 8.0
agent-20: 8.0
agent-21: 9.0
agent-22: 11.0
agent-23: 11.0
agent-24: 11.0
agent-25: 12.0
agent-26: 20.0
agent-27: 15.0
agent-28: 4.0
agent-29: 5.0
agent-30: 12.0
agent-31: 9.0
agent-32: 15.0
agent-33: 4.0
agent-34: 9.0
agent-35: 16.0
agent-36: 12.0
agent-37: 13.0
agent-38: 10.0
agent-39: 12.0
agent-40: 14.0
Sum Reward: 452.0
Avg Reward: 11.3
Min Reward: 4.0
Max Reward: 20.0
Gini Coefficient: 0.16084070796460176
20:20 Ratio: 2.358490566037736
Max-min Ratio: 5.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-08_08-59-59
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 465.0
  episode_reward_mean: 440.32
  episode_reward_min: 325.0
  episodes_this_iter: 1
  episodes_total: 498
  experiment_id: 4e724eb5b3a34f42879644e84578eec0
  hostname: gpu024
  info:
    apply_time_ms: 2.532
    dispatch_time_ms: 5.588
    learner:
      cur_lr: 3.332800042699091e-05
      grad_gnorm: 0.13593196868896484
      policy_entropy: 777.559326171875
      policy_loss: -0.004032609984278679
      var_gnorm: 39.5310173034668
      vf_explained_var: -1.0
      vf_loss: 9.064180630957708e-05
    num_steps_sampled: 19960000
    num_steps_trained: 19960000
    wait_time_ms: 559.16
  iterations_since_restore: 499
  node_ip: 172.17.8.24
  num_metric_batches_dropped: 0
  pid: 26970
  policy_reward_mean: {}
  time_since_restore: 28196.528450012207
  time_this_iter_s: 56.23593258857727
  time_total_s: 28196.528450012207
  timestamp: 1594213199
  timesteps_since_restore: 19960000
  timesteps_this_iter: 40000
  timesteps_total: 19960000
  training_iteration: 499
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26970], 28196 s, 499 iter, 19960000 ts, 440 rew

agent-1: 13.0
agent-2: 10.0
agent-3: 11.0
agent-4: 8.0
agent-5: 14.0
agent-6: 18.0
agent-7: 7.0
agent-8: 10.0
agent-9: 7.0
agent-10: 15.0
agent-11: 11.0
agent-12: 12.0
agent-13: 12.0
agent-14: 8.0
agent-15: 9.0
agent-16: 12.0
agent-17: 17.0
agent-18: 10.0
agent-19: 4.0
agent-20: 10.0
agent-21: 10.0
agent-22: 11.0
agent-23: 13.0
agent-24: 11.0
agent-25: 12.0
agent-26: 12.0
agent-27: 10.0
agent-28: 12.0
agent-29: 13.0
agent-30: 11.0
agent-31: 11.0
agent-32: 15.0
agent-33: 14.0
agent-34: 16.0
agent-35: 12.0
agent-36: 13.0
agent-37: 9.0
agent-38: 11.0
agent-39: 11.0
agent-40: 12.0
Sum Reward: 457.0
Avg Reward: 11.425
Min Reward: 4.0
Max Reward: 18.0
Gini Coefficient: 0.12773522975929977
20:20 Ratio: 1.967741935483871
Max-min Ratio: 4.5
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-08_09-00-56
  done: true
  episode_len_mean: 1000.0
  episode_reward_max: 465.0
  episode_reward_mean: 440.58
  episode_reward_min: 325.0
  episodes_this_iter: 1
  episodes_total: 499
  experiment_id: 4e724eb5b3a34f42879644e84578eec0
  hostname: gpu024
  info:
    apply_time_ms: 2.867
    dispatch_time_ms: 6.512
    learner:
      cur_lr: 3.066399949602783e-05
      grad_gnorm: 0.18176838755607605
      policy_entropy: 778.04345703125
      policy_loss: 0.11513610184192657
      var_gnorm: 39.530799865722656
      vf_explained_var: -1.0
      vf_loss: 6.140591722214594e-05
    num_steps_sampled: 20000000
    num_steps_trained: 20000000
    wait_time_ms: 548.092
  iterations_since_restore: 500
  node_ip: 172.17.8.24
  num_metric_batches_dropped: 0
  pid: 26970
  policy_reward_mean: {}
  time_since_restore: 28253.01611804962
  time_this_iter_s: 56.48766803741455
  time_total_s: 28253.01611804962
  timestamp: 1594213256
  timesteps_since_restore: 20000000
  timesteps_this_iter: 40000
  timesteps_total: 20000000
  training_iteration: 500
  
[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.[0m
/h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/numpy/core/fromnumeric.py:3335: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/numpy/core/_methods.py:161: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)
W0708 09:00:56.691339 26965 client_connection.cc:255] [worker]ProcessMessage with type 7 took 118 ms.
Commencing experiment harvest_A3C
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 0.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
TERMINATED trials:
 - A3C_harvest_env_0:	TERMINATED [pid=26970], 28253 s, 500 iter, 20000000 ts, 441 rew

== Status ==
Using FIFO scheduling algorithm.
Resources requested: 0.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
TERMINATED trials:
 - A3C_harvest_env_0:	TERMINATED [pid=26970], 28253 s, 500 iter, 20000000 ts, 441 rew

