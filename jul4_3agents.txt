/h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:523: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint8 = np.dtype([("qint8", np.int8, 1)])
/h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:524: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint8 = np.dtype([("quint8", np.uint8, 1)])
/h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint16 = np.dtype([("qint16", np.int16, 1)])
/h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint16 = np.dtype([("quint16", np.uint16, 1)])
/h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint32 = np.dtype([("qint32", np.int32, 1)])
/h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:532: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  np_resource = np.dtype([("resource", np.ubyte, 1)])
Process STDOUT and STDERR is being redirected to /tmp/ray/session_2020-07-04_13-17-43_16663/logs.
Waiting for redis server at 127.0.0.1:32584 to respond...
Waiting for redis server at 127.0.0.1:55781 to respond...
Warning: Capping object memory store to 20.0GB. To increase this further, specify `object_store_memory` when calling ray.init() or ray start.
Starting the Plasma object store with 20.0 GB memory using /dev/shm.

======================================================================
View the web UI at http://localhost:8888/notebooks/ray_ui.ipynb?token=cf7640e51ccca10c370388e9fbd33c73d6de7da7ee42939e
======================================================================

== Status ==
Using FIFO scheduling algorithm.
Resources requested: 0/2 CPUs, 0/1 GPUs
Memory usage on this node: 16.9/202.5 GB

Created LogSyncer for /h/zhaostep/ray_results/harvest_A3C/A3C_harvest_env_0_2020-07-04_13-17-43marl5cuv -> 
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 16.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING

/h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:523: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint8 = np.dtype([("qint8", np.int8, 1)])
/h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:524: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint8 = np.dtype([("quint8", np.uint8, 1)])
/h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint16 = np.dtype([("qint16", np.int16, 1)])
/h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint16 = np.dtype([("quint16", np.uint16, 1)])
/h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint32 = np.dtype([("qint32", np.int32, 1)])
/h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:532: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  np_resource = np.dtype([("resource", np.ubyte, 1)])
2020-07-04 13:17:56,582	INFO policy_evaluator.py:262 -- Creating policy evaluation worker 0 on CPU (please ignore any CUDA init errors)
2020-07-04 13:17:56.582692: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
From /h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/ray/rllib/models/lstm.py:59: BasicLSTMCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.
Instructions for updating:
This class is deprecated, please use tf.nn.rnn_cell.LSTMCell, which supports all the feature this cell currently has. Please replace the existing code with tf.nn.rnn_cell.LSTMCell(name='basic_lstm_cell').
/h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:523: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint8 = np.dtype([("qint8", np.int8, 1)])
/h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:524: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint8 = np.dtype([("quint8", np.uint8, 1)])
/h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint16 = np.dtype([("qint16", np.int16, 1)])
/h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint16 = np.dtype([("quint16", np.uint16, 1)])
/h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint32 = np.dtype([("qint32", np.int32, 1)])
/h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:532: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  np_resource = np.dtype([("resource", np.ubyte, 1)])
2020-07-04 13:18:09,796	INFO policy_evaluator.py:262 -- Creating policy evaluation worker 1 on CPU (please ignore any CUDA init errors)
2020-07-04 13:18:09.798271: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
/h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:523: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint8 = np.dtype([("qint8", np.int8, 1)])
/h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:524: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint8 = np.dtype([("quint8", np.uint8, 1)])
/h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint16 = np.dtype([("qint16", np.int16, 1)])
/h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint16 = np.dtype([("quint16", np.uint16, 1)])
/h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint32 = np.dtype([("qint32", np.int32, 1)])
/h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:532: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  np_resource = np.dtype([("resource", np.ubyte, 1)])
2020-07-04 13:18:10,002	INFO policy_evaluator.py:262 -- Creating policy evaluation worker 2 on CPU (please ignore any CUDA init errors)
2020-07-04 13:18:10.004420: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
From /h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/ray/rllib/models/lstm.py:59: BasicLSTMCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.
Instructions for updating:
This class is deprecated, please use tf.nn.rnn_cell.LSTMCell, which supports all the feature this cell currently has. Please replace the existing code with tf.nn.rnn_cell.LSTMCell(name='basic_lstm_cell').
From /h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/ray/rllib/models/lstm.py:59: BasicLSTMCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.
Instructions for updating:
This class is deprecated, please use tf.nn.rnn_cell.LSTMCell, which supports all the feature this cell currently has. Please replace the existing code with tf.nn.rnn_cell.LSTMCell(name='basic_lstm_cell').
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_13-18-20
  done: false
  episode_len_mean: .nan
  episode_reward_max: .nan
  episode_reward_mean: .nan
  episode_reward_min: .nan
  episodes_this_iter: 0
  episodes_total: 0
  experiment_id: 86e053a9c80f439496ed6b19bfe1ab59
  hostname: gpu003
  info:
    apply_time_ms: 3.547
    dispatch_time_ms: 10.058
    learner:
      cur_lr: 0.0013599999947473407
      grad_gnorm: 40.0
      policy_entropy: 51.6883544921875
      policy_loss: 32.159488677978516
      var_gnorm: 17.946334838867188
      vf_explained_var: 0.04524463415145874
      vf_loss: 34.745784759521484
    num_steps_sampled: 3000
    num_steps_trained: 3000
    wait_time_ms: 62.619
  iterations_since_restore: 1
  node_ip: 172.17.8.3
  num_metric_batches_dropped: 0
  pid: 16746
  policy_reward_mean: {}
  time_since_restore: 22.251687049865723
  time_this_iter_s: 22.251687049865723
  time_total_s: 22.251687049865723
  timestamp: 1593883100
  timesteps_since_restore: 3000
  timesteps_this_iter: 3000
  timesteps_total: 3000
  training_iteration: 1
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 17.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=16746], 22 s, 1 iter, 3000 ts, nan rew

[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.[0m
agent-1: 45.0
agent-2: -24.0
agent-3: 98.0
Sum Reward: 119.0
Avg Reward: 39.666666666666664
Min Reward: -24.0
Gini Coefficient: 0.6834733893557423
20:20 Ratio: -4.083333333333333
Max-min Ratio: -4.083333333333333
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_13-18-27
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 119.0
  episode_reward_mean: 119.0
  episode_reward_min: 119.0
  episodes_this_iter: 1
  episodes_total: 1
  experiment_id: 86e053a9c80f439496ed6b19bfe1ab59
  hostname: gpu003
  info:
    apply_time_ms: 4.118
    dispatch_time_ms: 11.068
    learner:
      cur_lr: 0.0013598002260550857
      grad_gnorm: 39.99999237060547
      policy_entropy: 43.38994216918945
      policy_loss: 29.50673484802246
      var_gnorm: 17.987638473510742
      vf_explained_var: 0.055917441844940186
      vf_loss: 30.54500389099121
    num_steps_sampled: 6000
    num_steps_trained: 6000
    wait_time_ms: 61.565
  iterations_since_restore: 2
  node_ip: 172.17.8.3
  num_metric_batches_dropped: 0
  pid: 16746
  policy_reward_mean: {}
  time_since_restore: 29.789101362228394
  time_this_iter_s: 7.537414312362671
  time_total_s: 29.789101362228394
  timestamp: 1593883107
  timesteps_since_restore: 6000
  timesteps_this_iter: 3000
  timesteps_total: 6000
  training_iteration: 2
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 18.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=16746], 29 s, 2 iter, 6000 ts, 119 rew

[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.[0m
agent-1: 96.0
agent-2: -205.0
agent-3: 93.0
Sum Reward: -16.0
Avg Reward: -5.333333333333333
Min Reward: -205.0
Gini Coefficient: -12.541666666666666
20:20 Ratio: -0.4682926829268293
Max-min Ratio: -0.4682926829268293
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_13-18-35
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 119.0
  episode_reward_mean: 51.5
  episode_reward_min: -16.0
  episodes_this_iter: 1
  episodes_total: 2
  experiment_id: 86e053a9c80f439496ed6b19bfe1ab59
  hostname: gpu003
  info:
    apply_time_ms: 2.812
    dispatch_time_ms: 5.919
    learner:
      cur_lr: 0.0013596004573628306
      grad_gnorm: 40.000003814697266
      policy_entropy: 45.70642852783203
      policy_loss: 28.81706428527832
      var_gnorm: 18.190746307373047
      vf_explained_var: 0.008521795272827148
      vf_loss: 21.576799392700195
    num_steps_sampled: 9000
    num_steps_trained: 9000
    wait_time_ms: 67.434
  iterations_since_restore: 3
  node_ip: 172.17.8.3
  num_metric_batches_dropped: 0
  pid: 16746
  policy_reward_mean: {}
  time_since_restore: 37.077070474624634
  time_this_iter_s: 7.28796911239624
  time_total_s: 37.077070474624634
  timestamp: 1593883115
  timesteps_since_restore: 9000
  timesteps_this_iter: 3000
  timesteps_total: 9000
  training_iteration: 3
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 18.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=16746], 37 s, 3 iter, 9000 ts, 51.5 rew

agent-1: 151.0
agent-2: 128.0
agent-3: 133.0
Sum Reward: 412.0
Avg Reward: 137.33333333333334
Min Reward: 128.0
Gini Coefficient: 0.0372168284789644
20:20 Ratio: 1.1796875
Max-min Ratio: 1.1796875
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_13-18-42
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 412.0
  episode_reward_mean: 171.66666666666666
  episode_reward_min: -16.0
  episodes_this_iter: 1
  episodes_total: 3
  experiment_id: 86e053a9c80f439496ed6b19bfe1ab59
  hostname: gpu003
  info:
    apply_time_ms: 4.18
    dispatch_time_ms: 11.708
    learner:
      cur_lr: 0.0013594005722552538
      grad_gnorm: 40.00001525878906
      policy_entropy: 36.108577728271484
      policy_loss: 26.218852996826172
      var_gnorm: 18.362524032592773
      vf_explained_var: 0.2474600076675415
      vf_loss: 15.660091400146484
    num_steps_sampled: 12000
    num_steps_trained: 12000
    wait_time_ms: 61.27
  iterations_since_restore: 4
  node_ip: 172.17.8.3
  num_metric_batches_dropped: 0
  pid: 16746
  policy_reward_mean: {}
  time_since_restore: 44.5143506526947
  time_this_iter_s: 7.437280178070068
  time_total_s: 44.5143506526947
  timestamp: 1593883122
  timesteps_since_restore: 12000
  timesteps_this_iter: 3000
  timesteps_total: 12000
  training_iteration: 4
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 18.3/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=16746], 44 s, 4 iter, 12000 ts, 172 rew

agent-1: 115.0
agent-2: 46.0
agent-3: 101.0
Sum Reward: 262.0
Avg Reward: 87.33333333333333
Min Reward: 46.0
Gini Coefficient: 0.17557251908396945
20:20 Ratio: 2.5
Max-min Ratio: 2.5
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_13-18-50
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 412.0
  episode_reward_mean: 194.25
  episode_reward_min: -16.0
  episodes_this_iter: 1
  episodes_total: 4
  experiment_id: 86e053a9c80f439496ed6b19bfe1ab59
  hostname: gpu003
  info:
    apply_time_ms: 2.745
    dispatch_time_ms: 6.613
    learner:
      cur_lr: 0.0013592008035629988
      grad_gnorm: 40.0000114440918
      policy_entropy: 35.78632736206055
      policy_loss: -0.5417132377624512
      var_gnorm: 18.545406341552734
      vf_explained_var: 0.41812795400619507
      vf_loss: 12.870522499084473
    num_steps_sampled: 15000
    num_steps_trained: 15000
    wait_time_ms: 72.396
  iterations_since_restore: 5
  node_ip: 172.17.8.3
  num_metric_batches_dropped: 0
  pid: 16746
  policy_reward_mean: {}
  time_since_restore: 52.05783820152283
  time_this_iter_s: 7.543487548828125
  time_total_s: 52.05783820152283
  timestamp: 1593883130
  timesteps_since_restore: 15000
  timesteps_this_iter: 3000
  timesteps_total: 15000
  training_iteration: 5
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 18.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=16746], 52 s, 5 iter, 15000 ts, 194 rew

agent-1: 160.0
agent-2: 190.0
agent-3: 95.0
Sum Reward: 445.0
Avg Reward: 148.33333333333334
Min Reward: 95.0
Gini Coefficient: 0.14232209737827714
20:20 Ratio: 2.0
Max-min Ratio: 2.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_13-18-57
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 445.0
  episode_reward_mean: 244.4
  episode_reward_min: -16.0
  episodes_this_iter: 1
  episodes_total: 5
  experiment_id: 86e053a9c80f439496ed6b19bfe1ab59
  hostname: gpu003
  info:
    apply_time_ms: 3.302
    dispatch_time_ms: 8.454
    learner:
      cur_lr: 0.0013590010348707438
      grad_gnorm: 39.999996185302734
      policy_entropy: 37.168365478515625
      policy_loss: -11.451152801513672
      var_gnorm: 18.7283878326416
      vf_explained_var: 0.15405166149139404
      vf_loss: 20.38497543334961
    num_steps_sampled: 18000
    num_steps_trained: 18000
    wait_time_ms: 67.465
  iterations_since_restore: 6
  node_ip: 172.17.8.3
  num_metric_batches_dropped: 0
  pid: 16746
  policy_reward_mean: {}
  time_since_restore: 59.84097361564636
  time_this_iter_s: 7.783135414123535
  time_total_s: 59.84097361564636
  timestamp: 1593883137
  timesteps_since_restore: 18000
  timesteps_this_iter: 3000
  timesteps_total: 18000
  training_iteration: 6
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 18.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=16746], 59 s, 6 iter, 18000 ts, 244 rew

agent-1: 142.0
agent-2: 119.0
agent-3: 156.0
Sum Reward: 417.0
Avg Reward: 139.0
Min Reward: 119.0
Gini Coefficient: 0.05915267785771383
20:20 Ratio: 1.3109243697478992
Max-min Ratio: 1.3109243697478992
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_13-19-05
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 445.0
  episode_reward_mean: 273.1666666666667
  episode_reward_min: -16.0
  episodes_this_iter: 1
  episodes_total: 6
  experiment_id: 86e053a9c80f439496ed6b19bfe1ab59
  hostname: gpu003
  info:
    apply_time_ms: 2.883
    dispatch_time_ms: 11.472
    learner:
      cur_lr: 0.001358801149763167
      grad_gnorm: 39.999996185302734
      policy_entropy: 31.877216339111328
      policy_loss: 51.895469665527344
      var_gnorm: 18.88784408569336
      vf_explained_var: 0.010464191436767578
      vf_loss: 60.65224075317383
    num_steps_sampled: 21000
    num_steps_trained: 21000
    wait_time_ms: 65.303
  iterations_since_restore: 7
  node_ip: 172.17.8.3
  num_metric_batches_dropped: 0
  pid: 16746
  policy_reward_mean: {}
  time_since_restore: 67.52626419067383
  time_this_iter_s: 7.685290575027466
  time_total_s: 67.52626419067383
  timestamp: 1593883145
  timesteps_since_restore: 21000
  timesteps_this_iter: 3000
  timesteps_total: 21000
  training_iteration: 7
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 18.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=16746], 67 s, 7 iter, 21000 ts, 273 rew

agent-1: 197.0
agent-2: 162.0
agent-3: 192.0
Sum Reward: 551.0
Avg Reward: 183.66666666666666
Min Reward: 162.0
Gini Coefficient: 0.04234724742891712
20:20 Ratio: 1.2160493827160495
Max-min Ratio: 1.2160493827160495
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_13-19-13
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 551.0
  episode_reward_mean: 312.85714285714283
  episode_reward_min: -16.0
  episodes_this_iter: 1
  episodes_total: 7
  experiment_id: 86e053a9c80f439496ed6b19bfe1ab59
  hostname: gpu003
  info:
    apply_time_ms: 2.99
    dispatch_time_ms: 11.362
    learner:
      cur_lr: 0.0013586013810709119
      grad_gnorm: 40.0
      policy_entropy: 35.298492431640625
      policy_loss: 31.485668182373047
      var_gnorm: 19.079010009765625
      vf_explained_var: -1.0
      vf_loss: 14.881546020507812
    num_steps_sampled: 24000
    num_steps_trained: 24000
    wait_time_ms: 67.686
  iterations_since_restore: 8
  node_ip: 172.17.8.3
  num_metric_batches_dropped: 0
  pid: 16746
  policy_reward_mean: {}
  time_since_restore: 75.54458236694336
  time_this_iter_s: 8.018318176269531
  time_total_s: 75.54458236694336
  timestamp: 1593883153
  timesteps_since_restore: 24000
  timesteps_this_iter: 3000
  timesteps_total: 24000
  training_iteration: 8
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 18.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=16746], 75 s, 8 iter, 24000 ts, 313 rew

agent-1: 113.0
agent-2: 161.0
agent-3: 214.0
Sum Reward: 488.0
Avg Reward: 162.66666666666666
Min Reward: 113.0
Gini Coefficient: 0.13797814207650272
20:20 Ratio: 1.8938053097345133
Max-min Ratio: 1.8938053097345133
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_13-19-21
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 551.0
  episode_reward_mean: 334.75
  episode_reward_min: -16.0
  episodes_this_iter: 1
  episodes_total: 8
  experiment_id: 86e053a9c80f439496ed6b19bfe1ab59
  hostname: gpu003
  info:
    apply_time_ms: 2.806
    dispatch_time_ms: 12.563
    learner:
      cur_lr: 0.0013584016123786569
      grad_gnorm: 40.0
      policy_entropy: 36.30648422241211
      policy_loss: -17.881195068359375
      var_gnorm: 19.281251907348633
      vf_explained_var: -0.5638830661773682
      vf_loss: 14.26974868774414
    num_steps_sampled: 27000
    num_steps_trained: 27000
    wait_time_ms: 64.003
  iterations_since_restore: 9
  node_ip: 172.17.8.3
  num_metric_batches_dropped: 0
  pid: 16746
  policy_reward_mean: {}
  time_since_restore: 83.35190010070801
  time_this_iter_s: 7.807317733764648
  time_total_s: 83.35190010070801
  timestamp: 1593883161
  timesteps_since_restore: 27000
  timesteps_this_iter: 3000
  timesteps_total: 27000
  training_iteration: 9
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 19.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=16746], 83 s, 9 iter, 27000 ts, 335 rew

agent-1: 158.0
agent-2: 173.0
agent-3: 189.0
Sum Reward: 520.0
Avg Reward: 173.33333333333334
Min Reward: 158.0
Gini Coefficient: 0.03974358974358974
20:20 Ratio: 1.1962025316455696
Max-min Ratio: 1.1962025316455696
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_13-19-29
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 551.0
  episode_reward_mean: 355.3333333333333
  episode_reward_min: -16.0
  episodes_this_iter: 1
  episodes_total: 9
  experiment_id: 86e053a9c80f439496ed6b19bfe1ab59
  hostname: gpu003
  info:
    apply_time_ms: 2.961
    dispatch_time_ms: 10.127
    learner:
      cur_lr: 0.0013582018436864018
      grad_gnorm: 39.999996185302734
      policy_entropy: 35.348751068115234
      policy_loss: 33.397483825683594
      var_gnorm: 19.31670379638672
      vf_explained_var: 0.10067635774612427
      vf_loss: 50.58900833129883
    num_steps_sampled: 30000
    num_steps_trained: 30000
    wait_time_ms: 57.897
  iterations_since_restore: 10
  node_ip: 172.17.8.3
  num_metric_batches_dropped: 0
  pid: 16746
  policy_reward_mean: {}
  time_since_restore: 90.79939699172974
  time_this_iter_s: 7.4474968910217285
  time_total_s: 90.79939699172974
  timestamp: 1593883169
  timesteps_since_restore: 30000
  timesteps_this_iter: 3000
  timesteps_total: 30000
  training_iteration: 10
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 19.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=16746], 90 s, 10 iter, 30000 ts, 355 rew

agent-1: 159.0
agent-2: 147.0
agent-3: 180.0
Sum Reward: 486.0
Avg Reward: 162.0
Min Reward: 147.0
Gini Coefficient: 0.04526748971193416
20:20 Ratio: 1.2244897959183674
Max-min Ratio: 1.2244897959183674
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_13-19-36
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 551.0
  episode_reward_mean: 368.4
  episode_reward_min: -16.0
  episodes_this_iter: 1
  episodes_total: 10
  experiment_id: 86e053a9c80f439496ed6b19bfe1ab59
  hostname: gpu003
  info:
    apply_time_ms: 2.793
    dispatch_time_ms: 11.014
    learner:
      cur_lr: 0.001358001958578825
      grad_gnorm: 40.00001525878906
      policy_entropy: 31.465065002441406
      policy_loss: -24.857011795043945
      var_gnorm: 19.428632736206055
      vf_explained_var: -0.03670024871826172
      vf_loss: 14.934218406677246
    num_steps_sampled: 33000
    num_steps_trained: 33000
    wait_time_ms: 65.893
  iterations_since_restore: 11
  node_ip: 172.17.8.3
  num_metric_batches_dropped: 0
  pid: 16746
  policy_reward_mean: {}
  time_since_restore: 98.13970828056335
  time_this_iter_s: 7.340311288833618
  time_total_s: 98.13970828056335
  timestamp: 1593883176
  timesteps_since_restore: 33000
  timesteps_this_iter: 3000
  timesteps_total: 33000
  training_iteration: 11
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 19.3/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=16746], 98 s, 11 iter, 33000 ts, 368 rew

agent-1: 239.0
agent-2: 227.0
agent-3: 166.0
Sum Reward: 632.0
Avg Reward: 210.66666666666666
Min Reward: 166.0
Gini Coefficient: 0.0770042194092827
20:20 Ratio: 1.4397590361445782
Max-min Ratio: 1.4397590361445782
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_13-19-44
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 632.0
  episode_reward_mean: 392.3636363636364
  episode_reward_min: -16.0
  episodes_this_iter: 1
  episodes_total: 11
  experiment_id: 86e053a9c80f439496ed6b19bfe1ab59
  hostname: gpu003
  info:
    apply_time_ms: 4.129
    dispatch_time_ms: 8.976
    learner:
      cur_lr: 0.00135780218988657
      grad_gnorm: 40.000003814697266
      policy_entropy: 20.967294692993164
      policy_loss: 28.712289810180664
      var_gnorm: 19.590412139892578
      vf_explained_var: -0.11876058578491211
      vf_loss: 49.61637496948242
    num_steps_sampled: 36000
    num_steps_trained: 36000
    wait_time_ms: 67.905
  iterations_since_restore: 12
  node_ip: 172.17.8.3
  num_metric_batches_dropped: 0
  pid: 16746
  policy_reward_mean: {}
  time_since_restore: 106.09253740310669
  time_this_iter_s: 7.952829122543335
  time_total_s: 106.09253740310669
  timestamp: 1593883184
  timesteps_since_restore: 36000
  timesteps_this_iter: 3000
  timesteps_total: 36000
  training_iteration: 12
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 19.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=16746], 106 s, 12 iter, 36000 ts, 392 rew

agent-1: 202.0
agent-2: 200.0
agent-3: 234.0
Sum Reward: 636.0
Avg Reward: 212.0
Min Reward: 200.0
Gini Coefficient: 0.03563941299790356
20:20 Ratio: 1.17
Max-min Ratio: 1.17
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_13-19-51
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 636.0
  episode_reward_mean: 412.6666666666667
  episode_reward_min: -16.0
  episodes_this_iter: 1
  episodes_total: 12
  experiment_id: 86e053a9c80f439496ed6b19bfe1ab59
  hostname: gpu003
  info:
    apply_time_ms: 3.701
    dispatch_time_ms: 8.732
    learner:
      cur_lr: 0.001357602421194315
      grad_gnorm: 12.29622745513916
      policy_entropy: 23.39647102355957
      policy_loss: -2.122220993041992
      var_gnorm: 19.72100067138672
      vf_explained_var: -0.0017703771591186523
      vf_loss: 20.72831153869629
    num_steps_sampled: 39000
    num_steps_trained: 39000
    wait_time_ms: 62.701
  iterations_since_restore: 13
  node_ip: 172.17.8.3
  num_metric_batches_dropped: 0
  pid: 16746
  policy_reward_mean: {}
  time_since_restore: 113.60327649116516
  time_this_iter_s: 7.510739088058472
  time_total_s: 113.60327649116516
  timestamp: 1593883191
  timesteps_since_restore: 39000
  timesteps_this_iter: 3000
  timesteps_total: 39000
  training_iteration: 13
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 19.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=16746], 113 s, 13 iter, 39000 ts, 413 rew

agent-1: 177.0
agent-2: 206.0
agent-3: 167.0
Sum Reward: 550.0
Avg Reward: 183.33333333333334
Min Reward: 167.0
Gini Coefficient: 0.04727272727272727
20:20 Ratio: 1.2335329341317365
Max-min Ratio: 1.2335329341317365
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_13-19-59
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 636.0
  episode_reward_mean: 423.2307692307692
  episode_reward_min: -16.0
  episodes_this_iter: 1
  episodes_total: 13
  experiment_id: 86e053a9c80f439496ed6b19bfe1ab59
  hostname: gpu003
  info:
    apply_time_ms: 2.809
    dispatch_time_ms: 6.35
    learner:
      cur_lr: 0.00135740265250206
      grad_gnorm: 39.9999885559082
      policy_entropy: 24.423002243041992
      policy_loss: -1.8433291912078857
      var_gnorm: 19.691856384277344
      vf_explained_var: -0.039809346199035645
      vf_loss: 8.964109420776367
    num_steps_sampled: 42000
    num_steps_trained: 42000
    wait_time_ms: 66.934
  iterations_since_restore: 14
  node_ip: 172.17.8.3
  num_metric_batches_dropped: 0
  pid: 16746
  policy_reward_mean: {}
  time_since_restore: 121.21619629859924
  time_this_iter_s: 7.612919807434082
  time_total_s: 121.21619629859924
  timestamp: 1593883199
  timesteps_since_restore: 42000
  timesteps_this_iter: 3000
  timesteps_total: 42000
  training_iteration: 14
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 19.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=16746], 121 s, 14 iter, 42000 ts, 423 rew

agent-1: 201.0
agent-2: 212.0
agent-3: 158.0
Sum Reward: 571.0
Avg Reward: 190.33333333333334
Min Reward: 158.0
Gini Coefficient: 0.06304728546409807
20:20 Ratio: 1.3417721518987342
Max-min Ratio: 1.3417721518987342
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_13-20-07
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 636.0
  episode_reward_mean: 433.7857142857143
  episode_reward_min: -16.0
  episodes_this_iter: 1
  episodes_total: 14
  experiment_id: 86e053a9c80f439496ed6b19bfe1ab59
  hostname: gpu003
  info:
    apply_time_ms: 3.802
    dispatch_time_ms: 10.737
    learner:
      cur_lr: 0.001357202767394483
      grad_gnorm: 40.0
      policy_entropy: 18.347393035888672
      policy_loss: -13.279020309448242
      var_gnorm: 19.84888458251953
      vf_explained_var: 0.2578887343406677
      vf_loss: 11.37721061706543
    num_steps_sampled: 45000
    num_steps_trained: 45000
    wait_time_ms: 65.151
  iterations_since_restore: 15
  node_ip: 172.17.8.3
  num_metric_batches_dropped: 0
  pid: 16746
  policy_reward_mean: {}
  time_since_restore: 128.95191955566406
  time_this_iter_s: 7.735723257064819
  time_total_s: 128.95191955566406
  timestamp: 1593883207
  timesteps_since_restore: 45000
  timesteps_this_iter: 3000
  timesteps_total: 45000
  training_iteration: 15
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 19.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=16746], 128 s, 15 iter, 45000 ts, 434 rew

agent-1: 239.0
agent-2: 288.0
agent-3: 224.0
Sum Reward: 751.0
Avg Reward: 250.33333333333334
Min Reward: 224.0
Gini Coefficient: 0.056813138038171326
20:20 Ratio: 1.2857142857142858
Max-min Ratio: 1.2857142857142858
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_13-20-15
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 751.0
  episode_reward_mean: 454.93333333333334
  episode_reward_min: -16.0
  episodes_this_iter: 1
  episodes_total: 15
  experiment_id: 86e053a9c80f439496ed6b19bfe1ab59
  hostname: gpu003
  info:
    apply_time_ms: 2.941
    dispatch_time_ms: 8.508
    learner:
      cur_lr: 0.001357002998702228
      grad_gnorm: 40.000022888183594
      policy_entropy: 29.232757568359375
      policy_loss: 3.795886516571045
      var_gnorm: 19.95713996887207
      vf_explained_var: 0.4322202205657959
      vf_loss: 11.97719955444336
    num_steps_sampled: 48000
    num_steps_trained: 48000
    wait_time_ms: 60.915
  iterations_since_restore: 16
  node_ip: 172.17.8.3
  num_metric_batches_dropped: 0
  pid: 16746
  policy_reward_mean: {}
  time_since_restore: 136.93834900856018
  time_this_iter_s: 7.986429452896118
  time_total_s: 136.93834900856018
  timestamp: 1593883215
  timesteps_since_restore: 48000
  timesteps_this_iter: 3000
  timesteps_total: 48000
  training_iteration: 16
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 20.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=16746], 136 s, 16 iter, 48000 ts, 455 rew

agent-1: 230.0
agent-2: 245.0
agent-3: 244.0
Sum Reward: 719.0
Avg Reward: 239.66666666666666
Min Reward: 230.0
Gini Coefficient: 0.013908205841446454
20:20 Ratio: 1.065217391304348
Max-min Ratio: 1.065217391304348
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_13-20-23
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 751.0
  episode_reward_mean: 471.4375
  episode_reward_min: -16.0
  episodes_this_iter: 1
  episodes_total: 16
  experiment_id: 86e053a9c80f439496ed6b19bfe1ab59
  hostname: gpu003
  info:
    apply_time_ms: 4.314
    dispatch_time_ms: 10.093
    learner:
      cur_lr: 0.001356803230009973
      grad_gnorm: 39.99999237060547
      policy_entropy: 24.045272827148438
      policy_loss: -4.292811393737793
      var_gnorm: 20.07709312438965
      vf_explained_var: 0.2507922053337097
      vf_loss: 20.174543380737305
    num_steps_sampled: 51000
    num_steps_trained: 51000
    wait_time_ms: 73.114
  iterations_since_restore: 17
  node_ip: 172.17.8.3
  num_metric_batches_dropped: 0
  pid: 16746
  policy_reward_mean: {}
  time_since_restore: 144.8789258003235
  time_this_iter_s: 7.940576791763306
  time_total_s: 144.8789258003235
  timestamp: 1593883223
  timesteps_since_restore: 51000
  timesteps_this_iter: 3000
  timesteps_total: 51000
  training_iteration: 17
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 20.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=16746], 144 s, 17 iter, 51000 ts, 471 rew

agent-1: 225.0
agent-2: 157.0
agent-3: 252.0
Sum Reward: 634.0
Avg Reward: 211.33333333333334
Min Reward: 157.0
Gini Coefficient: 0.09989484752891693
20:20 Ratio: 1.605095541401274
Max-min Ratio: 1.605095541401274
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_13-20-31
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 751.0
  episode_reward_mean: 481.0
  episode_reward_min: -16.0
  episodes_this_iter: 1
  episodes_total: 17
  experiment_id: 86e053a9c80f439496ed6b19bfe1ab59
  hostname: gpu003
  info:
    apply_time_ms: 3.538
    dispatch_time_ms: 12.761
    learner:
      cur_lr: 0.0013566033449023962
      grad_gnorm: 40.00000762939453
      policy_entropy: 16.701051712036133
      policy_loss: 20.010639190673828
      var_gnorm: 20.169269561767578
      vf_explained_var: 0.2154405117034912
      vf_loss: 20.99874496459961
    num_steps_sampled: 54000
    num_steps_trained: 54000
    wait_time_ms: 64.876
  iterations_since_restore: 18
  node_ip: 172.17.8.3
  num_metric_batches_dropped: 0
  pid: 16746
  policy_reward_mean: {}
  time_since_restore: 153.3294734954834
  time_this_iter_s: 8.450547695159912
  time_total_s: 153.3294734954834
  timestamp: 1593883231
  timesteps_since_restore: 54000
  timesteps_this_iter: 3000
  timesteps_total: 54000
  training_iteration: 18
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 20.3/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=16746], 153 s, 18 iter, 54000 ts, 481 rew

agent-1: 222.0
agent-2: 245.0
agent-3: 209.0
Sum Reward: 676.0
Avg Reward: 225.33333333333334
Min Reward: 209.0
Gini Coefficient: 0.03550295857988166
20:20 Ratio: 1.1722488038277512
Max-min Ratio: 1.1722488038277512
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_13-20-39
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 751.0
  episode_reward_mean: 491.8333333333333
  episode_reward_min: -16.0
  episodes_this_iter: 1
  episodes_total: 18
  experiment_id: 86e053a9c80f439496ed6b19bfe1ab59
  hostname: gpu003
  info:
    apply_time_ms: 3.156
    dispatch_time_ms: 12.16
    learner:
      cur_lr: 0.0013564035762101412
      grad_gnorm: 39.316463470458984
      policy_entropy: 7.587151527404785
      policy_loss: 5.445418834686279
      var_gnorm: 20.29111099243164
      vf_explained_var: 0.11238223314285278
      vf_loss: 21.70212745666504
    num_steps_sampled: 57000
    num_steps_trained: 57000
    wait_time_ms: 66.455
  iterations_since_restore: 19
  node_ip: 172.17.8.3
  num_metric_batches_dropped: 0
  pid: 16746
  policy_reward_mean: {}
  time_since_restore: 161.13232564926147
  time_this_iter_s: 7.802852153778076
  time_total_s: 161.13232564926147
  timestamp: 1593883239
  timesteps_since_restore: 57000
  timesteps_this_iter: 3000
  timesteps_total: 57000
  training_iteration: 19
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 20.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=16746], 161 s, 19 iter, 57000 ts, 492 rew

agent-1: 246.0
agent-2: 260.0
agent-3: 266.0
Sum Reward: 772.0
Avg Reward: 257.3333333333333
Min Reward: 246.0
Gini Coefficient: 0.017271157167530225
20:20 Ratio: 1.08130081300813
Max-min Ratio: 1.08130081300813
agent-1: 264.0
agent-2: 253.0
agent-3: 222.0
Sum Reward: 739.0
Avg Reward: 246.33333333333334
Min Reward: 222.0
Gini Coefficient: 0.037889039242219216
20:20 Ratio: 1.1891891891891893
Max-min Ratio: 1.1891891891891893
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_13-20-47
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 772.0
  episode_reward_mean: 518.2
  episode_reward_min: -16.0
  episodes_this_iter: 2
  episodes_total: 20
  experiment_id: 86e053a9c80f439496ed6b19bfe1ab59
  hostname: gpu003
  info:
    apply_time_ms: 2.878
    dispatch_time_ms: 9.12
    learner:
      cur_lr: 0.0013562038075178862
      grad_gnorm: 40.0
      policy_entropy: 17.07085418701172
      policy_loss: -391.6136779785156
      var_gnorm: 20.475927352905273
      vf_explained_var: -1.0
      vf_loss: 7143.92431640625
    num_steps_sampled: 60000
    num_steps_trained: 60000
    wait_time_ms: 66.245
  iterations_since_restore: 20
  node_ip: 172.17.8.3
  num_metric_batches_dropped: 0
  pid: 16746
  policy_reward_mean: {}
  time_since_restore: 169.46426653862
  time_this_iter_s: 8.33194088935852
  time_total_s: 169.46426653862
  timestamp: 1593883247
  timesteps_since_restore: 60000
  timesteps_this_iter: 3000
  timesteps_total: 60000
  training_iteration: 20
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 20.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=16746], 169 s, 20 iter, 60000 ts, 518 rew

Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_13-20-55
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 772.0
  episode_reward_mean: 518.2
  episode_reward_min: -16.0
  episodes_this_iter: 0
  episodes_total: 20
  experiment_id: 86e053a9c80f439496ed6b19bfe1ab59
  hostname: gpu003
  info:
    apply_time_ms: 3.86
    dispatch_time_ms: 6.429
    learner:
      cur_lr: 0.0013560040388256311
      grad_gnorm: 40.00000762939453
      policy_entropy: 20.537269592285156
      policy_loss: 15.280363082885742
      var_gnorm: 20.661237716674805
      vf_explained_var: 0.03806149959564209
      vf_loss: 31.572355270385742
    num_steps_sampled: 63000
    num_steps_trained: 63000
    wait_time_ms: 65.732
  iterations_since_restore: 21
  node_ip: 172.17.8.3
  num_metric_batches_dropped: 0
  pid: 16746
  policy_reward_mean: {}
  time_since_restore: 176.66078662872314
  time_this_iter_s: 7.196520090103149
  time_total_s: 176.66078662872314
  timestamp: 1593883255
  timesteps_since_restore: 63000
  timesteps_this_iter: 3000
  timesteps_total: 63000
  training_iteration: 21
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 20.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=16746], 176 s, 21 iter, 63000 ts, 518 rew

agent-1: 216.0
agent-2: 225.0
agent-3: 202.0
Sum Reward: 643.0
Avg Reward: 214.33333333333334
Min Reward: 202.0
Gini Coefficient: 0.023846552617936754
20:20 Ratio: 1.113861386138614
Max-min Ratio: 1.113861386138614
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_13-21-03
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 772.0
  episode_reward_mean: 524.1428571428571
  episode_reward_min: -16.0
  episodes_this_iter: 1
  episodes_total: 21
  experiment_id: 86e053a9c80f439496ed6b19bfe1ab59
  hostname: gpu003
  info:
    apply_time_ms: 2.777
    dispatch_time_ms: 6.657
    learner:
      cur_lr: 0.0013558041537180543
      grad_gnorm: 40.000030517578125
      policy_entropy: 20.321491241455078
      policy_loss: 13.678686141967773
      var_gnorm: 20.80830192565918
      vf_explained_var: 0.43257880210876465
      vf_loss: 80.1789779663086
    num_steps_sampled: 66000
    num_steps_trained: 66000
    wait_time_ms: 70.537
  iterations_since_restore: 22
  node_ip: 172.17.8.3
  num_metric_batches_dropped: 0
  pid: 16746
  policy_reward_mean: {}
  time_since_restore: 184.6513102054596
  time_this_iter_s: 7.99052357673645
  time_total_s: 184.6513102054596
  timestamp: 1593883263
  timesteps_since_restore: 66000
  timesteps_this_iter: 3000
  timesteps_total: 66000
  training_iteration: 22
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 20.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=16746], 184 s, 22 iter, 66000 ts, 524 rew

agent-1: 222.0
agent-2: 192.0
agent-3: 234.0
Sum Reward: 648.0
Avg Reward: 216.0
Min Reward: 192.0
Gini Coefficient: 0.043209876543209874
20:20 Ratio: 1.21875
Max-min Ratio: 1.21875
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_13-21-11
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 772.0
  episode_reward_mean: 529.7727272727273
  episode_reward_min: -16.0
  episodes_this_iter: 1
  episodes_total: 22
  experiment_id: 86e053a9c80f439496ed6b19bfe1ab59
  hostname: gpu003
  info:
    apply_time_ms: 2.672
    dispatch_time_ms: 6.1
    learner:
      cur_lr: 0.0013556043850257993
      grad_gnorm: 37.07542037963867
      policy_entropy: 16.018558502197266
      policy_loss: -4.587921619415283
      var_gnorm: 20.940441131591797
      vf_explained_var: 0.0027686357498168945
      vf_loss: 8.156168937683105
    num_steps_sampled: 69000
    num_steps_trained: 69000
    wait_time_ms: 73.204
  iterations_since_restore: 23
  node_ip: 172.17.8.3
  num_metric_batches_dropped: 0
  pid: 16746
  policy_reward_mean: {}
  time_since_restore: 192.4025113582611
  time_this_iter_s: 7.751201152801514
  time_total_s: 192.4025113582611
  timestamp: 1593883271
  timesteps_since_restore: 69000
  timesteps_this_iter: 3000
  timesteps_total: 69000
  training_iteration: 23
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 21.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=16746], 192 s, 23 iter, 69000 ts, 530 rew

agent-1: 220.0
agent-2: 251.0
agent-3: 244.0
Sum Reward: 715.0
Avg Reward: 238.33333333333334
Min Reward: 220.0
Gini Coefficient: 0.028904428904428906
20:20 Ratio: 1.1409090909090909
Max-min Ratio: 1.1409090909090909
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_13-21-19
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 772.0
  episode_reward_mean: 537.8260869565217
  episode_reward_min: -16.0
  episodes_this_iter: 1
  episodes_total: 23
  experiment_id: 86e053a9c80f439496ed6b19bfe1ab59
  hostname: gpu003
  info:
    apply_time_ms: 2.806
    dispatch_time_ms: 11.552
    learner:
      cur_lr: 0.0013554046163335443
      grad_gnorm: 34.382225036621094
      policy_entropy: 25.0793514251709
      policy_loss: 6.653573989868164
      var_gnorm: 21.057693481445312
      vf_explained_var: 0.19674807786941528
      vf_loss: 9.082032203674316
    num_steps_sampled: 72000
    num_steps_trained: 72000
    wait_time_ms: 62.086
  iterations_since_restore: 24
  node_ip: 172.17.8.3
  num_metric_batches_dropped: 0
  pid: 16746
  policy_reward_mean: {}
  time_since_restore: 200.5620985031128
  time_this_iter_s: 8.159587144851685
  time_total_s: 200.5620985031128
  timestamp: 1593883279
  timesteps_since_restore: 72000
  timesteps_this_iter: 3000
  timesteps_total: 72000
  training_iteration: 24
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 21.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=16746], 200 s, 24 iter, 72000 ts, 538 rew

agent-1: 192.0
agent-2: 244.0
agent-3: 219.0
Sum Reward: 655.0
Avg Reward: 218.33333333333334
Min Reward: 192.0
Gini Coefficient: 0.05292620865139949
20:20 Ratio: 1.2708333333333333
Max-min Ratio: 1.2708333333333333
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_13-21-26
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 772.0
  episode_reward_mean: 542.7083333333334
  episode_reward_min: -16.0
  episodes_this_iter: 1
  episodes_total: 24
  experiment_id: 86e053a9c80f439496ed6b19bfe1ab59
  hostname: gpu003
  info:
    apply_time_ms: 2.972
    dispatch_time_ms: 9.519
    learner:
      cur_lr: 0.0013552048476412892
      grad_gnorm: 40.00001525878906
      policy_entropy: 19.375211715698242
      policy_loss: -9.966385841369629
      var_gnorm: 21.20530128479004
      vf_explained_var: 0.33466559648513794
      vf_loss: 6.883751392364502
    num_steps_sampled: 75000
    num_steps_trained: 75000
    wait_time_ms: 69.114
  iterations_since_restore: 25
  node_ip: 172.17.8.3
  num_metric_batches_dropped: 0
  pid: 16746
  policy_reward_mean: {}
  time_since_restore: 208.25144219398499
  time_this_iter_s: 7.689343690872192
  time_total_s: 208.25144219398499
  timestamp: 1593883286
  timesteps_since_restore: 75000
  timesteps_this_iter: 3000
  timesteps_total: 75000
  training_iteration: 25
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 21.3/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=16746], 208 s, 25 iter, 75000 ts, 543 rew

agent-1: 257.0
agent-2: 230.0
agent-3: 240.0
Sum Reward: 727.0
Avg Reward: 242.33333333333334
Min Reward: 230.0
Gini Coefficient: 0.024759284731774415
20:20 Ratio: 1.117391304347826
Max-min Ratio: 1.117391304347826
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_13-21-35
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 772.0
  episode_reward_mean: 550.08
  episode_reward_min: -16.0
  episodes_this_iter: 1
  episodes_total: 25
  experiment_id: 86e053a9c80f439496ed6b19bfe1ab59
  hostname: gpu003
  info:
    apply_time_ms: 4.233
    dispatch_time_ms: 9.95
    learner:
      cur_lr: 0.0013550049625337124
      grad_gnorm: 40.0000114440918
      policy_entropy: 28.298904418945312
      policy_loss: -0.47283852100372314
      var_gnorm: 21.291000366210938
      vf_explained_var: 0.12127864360809326
      vf_loss: 16.086824417114258
    num_steps_sampled: 78000
    num_steps_trained: 78000
    wait_time_ms: 71.057
  iterations_since_restore: 26
  node_ip: 172.17.8.3
  num_metric_batches_dropped: 0
  pid: 16746
  policy_reward_mean: {}
  time_since_restore: 216.51414585113525
  time_this_iter_s: 8.262703657150269
  time_total_s: 216.51414585113525
  timestamp: 1593883295
  timesteps_since_restore: 78000
  timesteps_this_iter: 3000
  timesteps_total: 78000
  training_iteration: 26
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 21.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=16746], 216 s, 26 iter, 78000 ts, 550 rew

agent-1: 260.0
agent-2: 223.0
agent-3: 265.0
Sum Reward: 748.0
Avg Reward: 249.33333333333334
Min Reward: 223.0
Gini Coefficient: 0.0374331550802139
20:20 Ratio: 1.188340807174888
Max-min Ratio: 1.188340807174888
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_13-21-43
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 772.0
  episode_reward_mean: 557.6923076923077
  episode_reward_min: -16.0
  episodes_this_iter: 1
  episodes_total: 26
  experiment_id: 86e053a9c80f439496ed6b19bfe1ab59
  hostname: gpu003
  info:
    apply_time_ms: 2.633
    dispatch_time_ms: 7.058
    learner:
      cur_lr: 0.0013548051938414574
      grad_gnorm: 40.00000762939453
      policy_entropy: 27.951725006103516
      policy_loss: -4.695292949676514
      var_gnorm: 21.468935012817383
      vf_explained_var: -0.06278586387634277
      vf_loss: 5.7209882736206055
    num_steps_sampled: 81000
    num_steps_trained: 81000
    wait_time_ms: 78.853
  iterations_since_restore: 27
  node_ip: 172.17.8.3
  num_metric_batches_dropped: 0
  pid: 16746
  policy_reward_mean: {}
  time_since_restore: 224.48647832870483
  time_this_iter_s: 7.97233247756958
  time_total_s: 224.48647832870483
  timestamp: 1593883303
  timesteps_since_restore: 81000
  timesteps_this_iter: 3000
  timesteps_total: 81000
  training_iteration: 27
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 21.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=16746], 224 s, 27 iter, 81000 ts, 558 rew

agent-1: 241.0
agent-2: 182.0
agent-3: 189.0
Sum Reward: 612.0
Avg Reward: 204.0
Min Reward: 182.0
Gini Coefficient: 0.06427015250544663
20:20 Ratio: 1.3241758241758241
Max-min Ratio: 1.3241758241758241
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_13-21-52
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 772.0
  episode_reward_mean: 559.7037037037037
  episode_reward_min: -16.0
  episodes_this_iter: 1
  episodes_total: 27
  experiment_id: 86e053a9c80f439496ed6b19bfe1ab59
  hostname: gpu003
  info:
    apply_time_ms: 3.268
    dispatch_time_ms: 12.296
    learner:
      cur_lr: 0.0013546054251492023
      grad_gnorm: 39.999996185302734
      policy_entropy: 30.034860610961914
      policy_loss: -12.602783203125
      var_gnorm: 21.53010368347168
      vf_explained_var: 0.3015868067741394
      vf_loss: 7.7773118019104
    num_steps_sampled: 84000
    num_steps_trained: 84000
    wait_time_ms: 80.694
  iterations_since_restore: 28
  node_ip: 172.17.8.3
  num_metric_batches_dropped: 0
  pid: 16746
  policy_reward_mean: {}
  time_since_restore: 233.6499729156494
  time_this_iter_s: 9.16349458694458
  time_total_s: 233.6499729156494
  timestamp: 1593883312
  timesteps_since_restore: 84000
  timesteps_this_iter: 3000
  timesteps_total: 84000
  training_iteration: 28
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 21.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=16746], 233 s, 28 iter, 84000 ts, 560 rew

agent-1: 240.0
agent-2: 209.0
agent-3: 191.0
Sum Reward: 640.0
Avg Reward: 213.33333333333334
Min Reward: 191.0
Gini Coefficient: 0.051041666666666666
20:20 Ratio: 1.256544502617801
Max-min Ratio: 1.256544502617801
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_13-22-00
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 772.0
  episode_reward_mean: 562.5714285714286
  episode_reward_min: -16.0
  episodes_this_iter: 1
  episodes_total: 28
  experiment_id: 86e053a9c80f439496ed6b19bfe1ab59
  hostname: gpu003
  info:
    apply_time_ms: 3.119
    dispatch_time_ms: 10.396
    learner:
      cur_lr: 0.0013544056564569473
      grad_gnorm: 40.0
      policy_entropy: 27.168716430664062
      policy_loss: 16.744964599609375
      var_gnorm: 21.661510467529297
      vf_explained_var: 0.3031388521194458
      vf_loss: 29.61886978149414
    num_steps_sampled: 87000
    num_steps_trained: 87000
    wait_time_ms: 66.6
  iterations_since_restore: 29
  node_ip: 172.17.8.3
  num_metric_batches_dropped: 0
  pid: 16746
  policy_reward_mean: {}
  time_since_restore: 241.39561867713928
  time_this_iter_s: 7.745645761489868
  time_total_s: 241.39561867713928
  timestamp: 1593883320
  timesteps_since_restore: 87000
  timesteps_this_iter: 3000
  timesteps_total: 87000
  training_iteration: 29
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 21.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=16746], 241 s, 29 iter, 87000 ts, 563 rew

agent-1: 252.0
agent-2: 238.0
agent-3: 222.0
Sum Reward: 712.0
Avg Reward: 237.33333333333334
Min Reward: 222.0
Gini Coefficient: 0.028089887640449437
20:20 Ratio: 1.135135135135135
Max-min Ratio: 1.135135135135135
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_13-22-08
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 772.0
  episode_reward_mean: 567.7241379310345
  episode_reward_min: -16.0
  episodes_this_iter: 1
  episodes_total: 29
  experiment_id: 86e053a9c80f439496ed6b19bfe1ab59
  hostname: gpu003
  info:
    apply_time_ms: 2.925
    dispatch_time_ms: 9.428
    learner:
      cur_lr: 0.0013542057713493705
      grad_gnorm: 40.0
      policy_entropy: 13.931816101074219
      policy_loss: 7.7454633712768555
      var_gnorm: 21.77640151977539
      vf_explained_var: 0.03500109910964966
      vf_loss: 42.652915954589844
    num_steps_sampled: 90000
    num_steps_trained: 90000
    wait_time_ms: 73.225
  iterations_since_restore: 30
  node_ip: 172.17.8.3
  num_metric_batches_dropped: 0
  pid: 16746
  policy_reward_mean: {}
  time_since_restore: 249.4616916179657
  time_this_iter_s: 8.066072940826416
  time_total_s: 249.4616916179657
  timestamp: 1593883328
  timesteps_since_restore: 90000
  timesteps_this_iter: 3000
  timesteps_total: 90000
  training_iteration: 30
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 22.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=16746], 249 s, 30 iter, 90000 ts, 568 rew

agent-1: 237.0
agent-2: 263.0
agent-3: 268.0
Sum Reward: 768.0
Avg Reward: 256.0
Min Reward: 237.0
Gini Coefficient: 0.026909722222222224
20:20 Ratio: 1.130801687763713
Max-min Ratio: 1.130801687763713
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_13-22-16
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 772.0
  episode_reward_mean: 574.4
  episode_reward_min: -16.0
  episodes_this_iter: 1
  episodes_total: 30
  experiment_id: 86e053a9c80f439496ed6b19bfe1ab59
  hostname: gpu003
  info:
    apply_time_ms: 3.177
    dispatch_time_ms: 7.881
    learner:
      cur_lr: 0.0013540060026571155
      grad_gnorm: 39.999996185302734
      policy_entropy: 10.400806427001953
      policy_loss: 17.731407165527344
      var_gnorm: 21.882062911987305
      vf_explained_var: 0.45750558376312256
      vf_loss: 28.372453689575195
    num_steps_sampled: 93000
    num_steps_trained: 93000
    wait_time_ms: 72.697
  iterations_since_restore: 31
  node_ip: 172.17.8.3
  num_metric_batches_dropped: 0
  pid: 16746
  policy_reward_mean: {}
  time_since_restore: 257.3477523326874
  time_this_iter_s: 7.88606071472168
  time_total_s: 257.3477523326874
  timestamp: 1593883336
  timesteps_since_restore: 93000
  timesteps_this_iter: 3000
  timesteps_total: 93000
  training_iteration: 31
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 22.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=16746], 257 s, 31 iter, 93000 ts, 574 rew

agent-1: 171.0
agent-2: 245.0
agent-3: 181.0
Sum Reward: 597.0
Avg Reward: 199.0
Min Reward: 171.0
Gini Coefficient: 0.0826353992183138
20:20 Ratio: 1.432748538011696
Max-min Ratio: 1.432748538011696
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_13-22-24
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 772.0
  episode_reward_mean: 575.1290322580645
  episode_reward_min: -16.0
  episodes_this_iter: 1
  episodes_total: 31
  experiment_id: 86e053a9c80f439496ed6b19bfe1ab59
  hostname: gpu003
  info:
    apply_time_ms: 3.326
    dispatch_time_ms: 7.03
    learner:
      cur_lr: 0.0013538062339648604
      grad_gnorm: 40.000003814697266
      policy_entropy: 30.11008071899414
      policy_loss: -25.39137077331543
      var_gnorm: 21.924596786499023
      vf_explained_var: 0.3526592254638672
      vf_loss: 23.134998321533203
    num_steps_sampled: 96000
    num_steps_trained: 96000
    wait_time_ms: 66.703
  iterations_since_restore: 32
  node_ip: 172.17.8.3
  num_metric_batches_dropped: 0
  pid: 16746
  policy_reward_mean: {}
  time_since_restore: 265.6023828983307
  time_this_iter_s: 8.25463056564331
  time_total_s: 265.6023828983307
  timestamp: 1593883344
  timesteps_since_restore: 96000
  timesteps_this_iter: 3000
  timesteps_total: 96000
  training_iteration: 32
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 22.3/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=16746], 265 s, 32 iter, 96000 ts, 575 rew

agent-1: 274.0
agent-2: 261.0
agent-3: 243.0
Sum Reward: 778.0
Avg Reward: 259.3333333333333
Min Reward: 243.0
Gini Coefficient: 0.026563838903170524
20:20 Ratio: 1.1275720164609053
Max-min Ratio: 1.1275720164609053
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_13-22-32
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 778.0
  episode_reward_mean: 581.46875
  episode_reward_min: -16.0
  episodes_this_iter: 1
  episodes_total: 32
  experiment_id: 86e053a9c80f439496ed6b19bfe1ab59
  hostname: gpu003
  info:
    apply_time_ms: 2.848
    dispatch_time_ms: 7.747
    learner:
      cur_lr: 0.0013536063488572836
      grad_gnorm: 19.250808715820312
      policy_entropy: 27.93023681640625
      policy_loss: -1.2723782062530518
      var_gnorm: 21.964458465576172
      vf_explained_var: 0.15121746063232422
      vf_loss: 12.964710235595703
    num_steps_sampled: 99000
    num_steps_trained: 99000
    wait_time_ms: 70.996
  iterations_since_restore: 33
  node_ip: 172.17.8.3
  num_metric_batches_dropped: 0
  pid: 16746
  policy_reward_mean: {}
  time_since_restore: 273.26574301719666
  time_this_iter_s: 7.663360118865967
  time_total_s: 273.26574301719666
  timestamp: 1593883352
  timesteps_since_restore: 99000
  timesteps_this_iter: 3000
  timesteps_total: 99000
  training_iteration: 33
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 22.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=16746], 273 s, 33 iter, 99000 ts, 581 rew

agent-1: 241.0
agent-2: 170.0
agent-3: 224.0
Sum Reward: 635.0
Avg Reward: 211.66666666666666
Min Reward: 170.0
Gini Coefficient: 0.07454068241469816
20:20 Ratio: 1.4176470588235295
Max-min Ratio: 1.4176470588235295
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_13-22-40
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 778.0
  episode_reward_mean: 583.0909090909091
  episode_reward_min: -16.0
  episodes_this_iter: 1
  episodes_total: 33
  experiment_id: 86e053a9c80f439496ed6b19bfe1ab59
  hostname: gpu003
  info:
    apply_time_ms: 2.727
    dispatch_time_ms: 9.689
    learner:
      cur_lr: 0.0013534065801650286
      grad_gnorm: 40.0
      policy_entropy: 23.911067962646484
      policy_loss: -13.902438163757324
      var_gnorm: 22.04587745666504
      vf_explained_var: 0.6018624901771545
      vf_loss: 10.937488555908203
    num_steps_sampled: 102000
    num_steps_trained: 102000
    wait_time_ms: 66.522
  iterations_since_restore: 34
  node_ip: 172.17.8.3
  num_metric_batches_dropped: 0
  pid: 16746
  policy_reward_mean: {}
  time_since_restore: 281.7020878791809
  time_this_iter_s: 8.436344861984253
  time_total_s: 281.7020878791809
  timestamp: 1593883360
  timesteps_since_restore: 102000
  timesteps_this_iter: 3000
  timesteps_total: 102000
  training_iteration: 34
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 22.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=16746], 281 s, 34 iter, 102000 ts, 583 rew

agent-1: 241.0
agent-2: 285.0
agent-3: 184.0
Sum Reward: 710.0
Avg Reward: 236.66666666666666
Min Reward: 184.0
Gini Coefficient: 0.09483568075117371
20:20 Ratio: 1.548913043478261
Max-min Ratio: 1.548913043478261
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_13-22-48
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 778.0
  episode_reward_mean: 586.8235294117648
  episode_reward_min: -16.0
  episodes_this_iter: 1
  episodes_total: 34
  experiment_id: 86e053a9c80f439496ed6b19bfe1ab59
  hostname: gpu003
  info:
    apply_time_ms: 4.114
    dispatch_time_ms: 10.358
    learner:
      cur_lr: 0.0013532068114727736
      grad_gnorm: 40.00000762939453
      policy_entropy: 15.697653770446777
      policy_loss: -12.324607849121094
      var_gnorm: 22.14325714111328
      vf_explained_var: 0.45587456226348877
      vf_loss: 35.4324951171875
    num_steps_sampled: 105000
    num_steps_trained: 105000
    wait_time_ms: 69.509
  iterations_since_restore: 35
  node_ip: 172.17.8.3
  num_metric_batches_dropped: 0
  pid: 16746
  policy_reward_mean: {}
  time_since_restore: 289.6686460971832
  time_this_iter_s: 7.966558218002319
  time_total_s: 289.6686460971832
  timestamp: 1593883368
  timesteps_since_restore: 105000
  timesteps_this_iter: 3000
  timesteps_total: 105000
  training_iteration: 35
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 22.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=16746], 289 s, 35 iter, 105000 ts, 587 rew

agent-1: 295.0
agent-2: 297.0
agent-3: 257.0
Sum Reward: 849.0
Avg Reward: 283.0
Min Reward: 257.0
Gini Coefficient: 0.031409501374165684
20:20 Ratio: 1.1556420233463034
Max-min Ratio: 1.1556420233463034
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_13-22-56
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 849.0
  episode_reward_mean: 594.3142857142857
  episode_reward_min: -16.0
  episodes_this_iter: 1
  episodes_total: 35
  experiment_id: 86e053a9c80f439496ed6b19bfe1ab59
  hostname: gpu003
  info:
    apply_time_ms: 3.278
    dispatch_time_ms: 10.058
    learner:
      cur_lr: 0.0013530070427805185
      grad_gnorm: 40.000003814697266
      policy_entropy: 10.73178482055664
      policy_loss: 6.047317981719971
      var_gnorm: 22.240385055541992
      vf_explained_var: 0.06281554698944092
      vf_loss: 47.28596878051758
    num_steps_sampled: 108000
    num_steps_trained: 108000
    wait_time_ms: 62.96
  iterations_since_restore: 36
  node_ip: 172.17.8.3
  num_metric_batches_dropped: 0
  pid: 16746
  policy_reward_mean: {}
  time_since_restore: 297.6062819957733
  time_this_iter_s: 7.937635898590088
  time_total_s: 297.6062819957733
  timestamp: 1593883376
  timesteps_since_restore: 108000
  timesteps_this_iter: 3000
  timesteps_total: 108000
  training_iteration: 36
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 22.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=16746], 297 s, 36 iter, 108000 ts, 594 rew

agent-1: 259.0
agent-2: 260.0
agent-3: 284.0
Sum Reward: 803.0
Avg Reward: 267.6666666666667
Min Reward: 259.0
Gini Coefficient: 0.020755500207555
20:20 Ratio: 1.0965250965250966
Max-min Ratio: 1.0965250965250966
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_13-23-04
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 849.0
  episode_reward_mean: 600.1111111111111
  episode_reward_min: -16.0
  episodes_this_iter: 1
  episodes_total: 36
  experiment_id: 86e053a9c80f439496ed6b19bfe1ab59
  hostname: gpu003
  info:
    apply_time_ms: 3.16
    dispatch_time_ms: 13.002
    learner:
      cur_lr: 0.0013528071576729417
      grad_gnorm: 39.999996185302734
      policy_entropy: 17.781784057617188
      policy_loss: 21.095748901367188
      var_gnorm: 22.29888916015625
      vf_explained_var: -0.01984691619873047
      vf_loss: 35.42832946777344
    num_steps_sampled: 111000
    num_steps_trained: 111000
    wait_time_ms: 62.518
  iterations_since_restore: 37
  node_ip: 172.17.8.3
  num_metric_batches_dropped: 0
  pid: 16746
  policy_reward_mean: {}
  time_since_restore: 305.31675720214844
  time_this_iter_s: 7.710475206375122
  time_total_s: 305.31675720214844
  timestamp: 1593883384
  timesteps_since_restore: 111000
  timesteps_this_iter: 3000
  timesteps_total: 111000
  training_iteration: 37
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 23.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=16746], 305 s, 37 iter, 111000 ts, 600 rew

agent-1: 288.0
agent-2: 302.0
agent-3: 271.0
Sum Reward: 861.0
Avg Reward: 287.0
Min Reward: 271.0
Gini Coefficient: 0.024003097173828883
20:20 Ratio: 1.1143911439114391
Max-min Ratio: 1.1143911439114391
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_13-23-12
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 861.0
  episode_reward_mean: 607.1621621621622
  episode_reward_min: -16.0
  episodes_this_iter: 1
  episodes_total: 37
  experiment_id: 86e053a9c80f439496ed6b19bfe1ab59
  hostname: gpu003
  info:
    apply_time_ms: 2.904
    dispatch_time_ms: 9.295
    learner:
      cur_lr: 0.0013526073889806867
      grad_gnorm: 37.214111328125
      policy_entropy: 14.488471984863281
      policy_loss: 4.1062188148498535
      var_gnorm: 22.34137535095215
      vf_explained_var: 0.009965896606445312
      vf_loss: 10.58741283416748
    num_steps_sampled: 114000
    num_steps_trained: 114000
    wait_time_ms: 70.999
  iterations_since_restore: 38
  node_ip: 172.17.8.3
  num_metric_batches_dropped: 0
  pid: 16746
  policy_reward_mean: {}
  time_since_restore: 313.68711948394775
  time_this_iter_s: 8.370362281799316
  time_total_s: 313.68711948394775
  timestamp: 1593883392
  timesteps_since_restore: 114000
  timesteps_this_iter: 3000
  timesteps_total: 114000
  training_iteration: 38
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 23.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=16746], 313 s, 38 iter, 114000 ts, 607 rew

agent-1: 291.0
agent-2: 311.0
agent-3: 275.0
Sum Reward: 877.0
Avg Reward: 292.3333333333333
Min Reward: 275.0
Gini Coefficient: 0.027366020524515394
20:20 Ratio: 1.1309090909090909
Max-min Ratio: 1.1309090909090909
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_13-23-21
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 877.0
  episode_reward_mean: 614.2631578947369
  episode_reward_min: -16.0
  episodes_this_iter: 1
  episodes_total: 38
  experiment_id: 86e053a9c80f439496ed6b19bfe1ab59
  hostname: gpu003
  info:
    apply_time_ms: 2.871
    dispatch_time_ms: 11.593
    learner:
      cur_lr: 0.0013524076202884316
      grad_gnorm: 40.00001907348633
      policy_entropy: 21.131704330444336
      policy_loss: -0.8477449417114258
      var_gnorm: 22.420879364013672
      vf_explained_var: 0.3376479148864746
      vf_loss: 6.021522045135498
    num_steps_sampled: 117000
    num_steps_trained: 117000
    wait_time_ms: 69.711
  iterations_since_restore: 39
  node_ip: 172.17.8.3
  num_metric_batches_dropped: 0
  pid: 16746
  policy_reward_mean: {}
  time_since_restore: 321.905503988266
  time_this_iter_s: 8.218384504318237
  time_total_s: 321.905503988266
  timestamp: 1593883401
  timesteps_since_restore: 117000
  timesteps_this_iter: 3000
  timesteps_total: 117000
  training_iteration: 39
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 23.3/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=16746], 321 s, 39 iter, 117000 ts, 614 rew

agent-1: 249.0
agent-2: 309.0
agent-3: 324.0
Sum Reward: 882.0
Avg Reward: 294.0
Min Reward: 249.0
Gini Coefficient: 0.05668934240362812
20:20 Ratio: 1.3012048192771084
Max-min Ratio: 1.3012048192771084
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_13-23-29
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 882.0
  episode_reward_mean: 621.1282051282051
  episode_reward_min: -16.0
  episodes_this_iter: 1
  episodes_total: 39
  experiment_id: 86e053a9c80f439496ed6b19bfe1ab59
  hostname: gpu003
  info:
    apply_time_ms: 3.038
    dispatch_time_ms: 7.805
    learner:
      cur_lr: 0.0013522078515961766
      grad_gnorm: 40.0
      policy_entropy: 9.54556941986084
      policy_loss: 2.362734317779541
      var_gnorm: 22.39759635925293
      vf_explained_var: -0.017328381538391113
      vf_loss: 21.954025268554688
    num_steps_sampled: 120000
    num_steps_trained: 120000
    wait_time_ms: 74.07
  iterations_since_restore: 40
  node_ip: 172.17.8.3
  num_metric_batches_dropped: 0
  pid: 16746
  policy_reward_mean: {}
  time_since_restore: 330.6668634414673
  time_this_iter_s: 8.761359453201294
  time_total_s: 330.6668634414673
  timestamp: 1593883409
  timesteps_since_restore: 120000
  timesteps_this_iter: 3000
  timesteps_total: 120000
  training_iteration: 40
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 23.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=16746], 330 s, 40 iter, 120000 ts, 621 rew

agent-1: 241.0
agent-2: 216.0
agent-3: 218.0
Sum Reward: 675.0
Avg Reward: 225.0
Min Reward: 216.0
Gini Coefficient: 0.024691358024691357
20:20 Ratio: 1.1157407407407407
Max-min Ratio: 1.1157407407407407
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_13-23-38
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 882.0
  episode_reward_mean: 622.475
  episode_reward_min: -16.0
  episodes_this_iter: 1
  episodes_total: 40
  experiment_id: 86e053a9c80f439496ed6b19bfe1ab59
  hostname: gpu003
  info:
    apply_time_ms: 3.291
    dispatch_time_ms: 6.735
    learner:
      cur_lr: 0.0013520079664885998
      grad_gnorm: 40.00001525878906
      policy_entropy: 11.07944107055664
      policy_loss: 1.3914741277694702
      var_gnorm: 22.50495147705078
      vf_explained_var: 0.18566381931304932
      vf_loss: 11.022604942321777
    num_steps_sampled: 123000
    num_steps_trained: 123000
    wait_time_ms: 71.95
  iterations_since_restore: 41
  node_ip: 172.17.8.3
  num_metric_batches_dropped: 0
  pid: 16746
  policy_reward_mean: {}
  time_since_restore: 338.76589941978455
  time_this_iter_s: 8.09903597831726
  time_total_s: 338.76589941978455
  timestamp: 1593883418
  timesteps_since_restore: 123000
  timesteps_this_iter: 3000
  timesteps_total: 123000
  training_iteration: 41
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 23.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=16746], 338 s, 41 iter, 123000 ts, 622 rew

agent-1: 260.0
agent-2: 289.0
agent-3: 303.0
Sum Reward: 852.0
Avg Reward: 284.0
Min Reward: 260.0
Gini Coefficient: 0.033646322378716745
20:20 Ratio: 1.1653846153846155
Max-min Ratio: 1.1653846153846155
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_13-23-46
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 882.0
  episode_reward_mean: 628.0731707317074
  episode_reward_min: -16.0
  episodes_this_iter: 1
  episodes_total: 41
  experiment_id: 86e053a9c80f439496ed6b19bfe1ab59
  hostname: gpu003
  info:
    apply_time_ms: 3.359
    dispatch_time_ms: 10.259
    learner:
      cur_lr: 0.0013518081977963448
      grad_gnorm: 40.00000762939453
      policy_entropy: 6.863333225250244
      policy_loss: 3.2904765605926514
      var_gnorm: 22.591257095336914
      vf_explained_var: -0.15162229537963867
      vf_loss: 16.524763107299805
    num_steps_sampled: 126000
    num_steps_trained: 126000
    wait_time_ms: 65.708
  iterations_since_restore: 42
  node_ip: 172.17.8.3
  num_metric_batches_dropped: 0
  pid: 16746
  policy_reward_mean: {}
  time_since_restore: 346.94427585601807
  time_this_iter_s: 8.17837643623352
  time_total_s: 346.94427585601807
  timestamp: 1593883426
  timesteps_since_restore: 126000
  timesteps_this_iter: 3000
  timesteps_total: 126000
  training_iteration: 42
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 23.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=16746], 346 s, 42 iter, 126000 ts, 628 rew

agent-1: 304.0
agent-2: 276.0
agent-3: 272.0
Sum Reward: 852.0
Avg Reward: 284.0
Min Reward: 272.0
Gini Coefficient: 0.025039123630672927
20:20 Ratio: 1.1176470588235294
Max-min Ratio: 1.1176470588235294
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_13-23-54
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 882.0
  episode_reward_mean: 633.4047619047619
  episode_reward_min: -16.0
  episodes_this_iter: 1
  episodes_total: 42
  experiment_id: 86e053a9c80f439496ed6b19bfe1ab59
  hostname: gpu003
  info:
    apply_time_ms: 3.252
    dispatch_time_ms: 10.534
    learner:
      cur_lr: 0.0013516084291040897
      grad_gnorm: 40.000003814697266
      policy_entropy: 20.32122802734375
      policy_loss: -19.876239776611328
      var_gnorm: 22.71070671081543
      vf_explained_var: 0.3910183310508728
      vf_loss: 28.90939712524414
    num_steps_sampled: 129000
    num_steps_trained: 129000
    wait_time_ms: 78.771
  iterations_since_restore: 43
  node_ip: 172.17.8.3
  num_metric_batches_dropped: 0
  pid: 16746
  policy_reward_mean: {}
  time_since_restore: 355.1768844127655
  time_this_iter_s: 8.232608556747437
  time_total_s: 355.1768844127655
  timestamp: 1593883434
  timesteps_since_restore: 129000
  timesteps_this_iter: 3000
  timesteps_total: 129000
  training_iteration: 43
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 23.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=16746], 355 s, 43 iter, 129000 ts, 633 rew

agent-1: 237.0
agent-2: 225.0
agent-3: 227.0
Sum Reward: 689.0
Avg Reward: 229.66666666666666
Min Reward: 225.0
Gini Coefficient: 0.011611030478955007
20:20 Ratio: 1.0533333333333332
Max-min Ratio: 1.0533333333333332
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_13-24-03
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 882.0
  episode_reward_mean: 634.6976744186046
  episode_reward_min: -16.0
  episodes_this_iter: 1
  episodes_total: 43
  experiment_id: 86e053a9c80f439496ed6b19bfe1ab59
  hostname: gpu003
  info:
    apply_time_ms: 3.751
    dispatch_time_ms: 8.714
    learner:
      cur_lr: 0.0013514085439965129
      grad_gnorm: 28.888004302978516
      policy_entropy: 29.97158432006836
      policy_loss: -9.026880264282227
      var_gnorm: 22.78750228881836
      vf_explained_var: 0.07198494672775269
      vf_loss: 15.298425674438477
    num_steps_sampled: 132000
    num_steps_trained: 132000
    wait_time_ms: 74.952
  iterations_since_restore: 44
  node_ip: 172.17.8.3
  num_metric_batches_dropped: 0
  pid: 16746
  policy_reward_mean: {}
  time_since_restore: 364.1102397441864
  time_this_iter_s: 8.933355331420898
  time_total_s: 364.1102397441864
  timestamp: 1593883443
  timesteps_since_restore: 132000
  timesteps_this_iter: 3000
  timesteps_total: 132000
  training_iteration: 44
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 24.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=16746], 364 s, 44 iter, 132000 ts, 635 rew

agent-1: 203.0
agent-2: 238.0
agent-3: 191.0
Sum Reward: 632.0
Avg Reward: 210.66666666666666
Min Reward: 191.0
Gini Coefficient: 0.049578059071729956
20:20 Ratio: 1.2460732984293195
Max-min Ratio: 1.2460732984293195
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_13-24-11
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 882.0
  episode_reward_mean: 634.6363636363636
  episode_reward_min: -16.0
  episodes_this_iter: 1
  episodes_total: 44
  experiment_id: 86e053a9c80f439496ed6b19bfe1ab59
  hostname: gpu003
  info:
    apply_time_ms: 3.553
    dispatch_time_ms: 11.677
    learner:
      cur_lr: 0.0013512087753042579
      grad_gnorm: 35.237430572509766
      policy_entropy: 14.797990798950195
      policy_loss: -0.22133421897888184
      var_gnorm: 22.89124870300293
      vf_explained_var: 0.11040681600570679
      vf_loss: 11.655237197875977
    num_steps_sampled: 135000
    num_steps_trained: 135000
    wait_time_ms: 69.002
  iterations_since_restore: 45
  node_ip: 172.17.8.3
  num_metric_batches_dropped: 0
  pid: 16746
  policy_reward_mean: {}
  time_since_restore: 372.0722961425781
  time_this_iter_s: 7.962056398391724
  time_total_s: 372.0722961425781
  timestamp: 1593883451
  timesteps_since_restore: 135000
  timesteps_this_iter: 3000
  timesteps_total: 135000
  training_iteration: 45
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 24.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=16746], 372 s, 45 iter, 135000 ts, 635 rew

agent-1: 248.0
agent-2: 191.0
agent-3: 200.0
Sum Reward: 639.0
Avg Reward: 213.0
Min Reward: 191.0
Gini Coefficient: 0.0594679186228482
20:20 Ratio: 1.2984293193717278
Max-min Ratio: 1.2984293193717278
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_13-24-19
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 882.0
  episode_reward_mean: 634.7333333333333
  episode_reward_min: -16.0
  episodes_this_iter: 1
  episodes_total: 45
  experiment_id: 86e053a9c80f439496ed6b19bfe1ab59
  hostname: gpu003
  info:
    apply_time_ms: 3.844
    dispatch_time_ms: 10.617
    learner:
      cur_lr: 0.0013510090066120028
      grad_gnorm: 40.0
      policy_entropy: 16.841205596923828
      policy_loss: 8.83762264251709
      var_gnorm: 22.97064781188965
      vf_explained_var: 0.46299779415130615
      vf_loss: 25.403175354003906
    num_steps_sampled: 138000
    num_steps_trained: 138000
    wait_time_ms: 65.577
  iterations_since_restore: 46
  node_ip: 172.17.8.3
  num_metric_batches_dropped: 0
  pid: 16746
  policy_reward_mean: {}
  time_since_restore: 380.3930661678314
  time_this_iter_s: 8.320770025253296
  time_total_s: 380.3930661678314
  timestamp: 1593883459
  timesteps_since_restore: 138000
  timesteps_this_iter: 3000
  timesteps_total: 138000
  training_iteration: 46
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 24.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=16746], 380 s, 46 iter, 138000 ts, 635 rew

agent-1: 268.0
agent-2: 296.0
agent-3: 274.0
Sum Reward: 838.0
Avg Reward: 279.3333333333333
Min Reward: 268.0
Gini Coefficient: 0.022275258552108195
20:20 Ratio: 1.1044776119402986
Max-min Ratio: 1.1044776119402986
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_13-24-27
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 882.0
  episode_reward_mean: 639.1521739130435
  episode_reward_min: -16.0
  episodes_this_iter: 1
  episodes_total: 46
  experiment_id: 86e053a9c80f439496ed6b19bfe1ab59
  hostname: gpu003
  info:
    apply_time_ms: 2.91
    dispatch_time_ms: 8.679
    learner:
      cur_lr: 0.0013508092379197478
      grad_gnorm: 40.0
      policy_entropy: 12.312745094299316
      policy_loss: -7.6262102127075195
      var_gnorm: 23.094066619873047
      vf_explained_var: 0.364091694355011
      vf_loss: 63.59025573730469
    num_steps_sampled: 141000
    num_steps_trained: 141000
    wait_time_ms: 67.669
  iterations_since_restore: 47
  node_ip: 172.17.8.3
  num_metric_batches_dropped: 0
  pid: 16746
  policy_reward_mean: {}
  time_since_restore: 388.35050535202026
  time_this_iter_s: 7.957439184188843
  time_total_s: 388.35050535202026
  timestamp: 1593883467
  timesteps_since_restore: 141000
  timesteps_this_iter: 3000
  timesteps_total: 141000
  training_iteration: 47
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 24.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=16746], 388 s, 47 iter, 141000 ts, 639 rew

agent-1: 270.0
agent-2: 315.0
agent-3: 315.0
Sum Reward: 900.0
Avg Reward: 300.0
Min Reward: 270.0
Gini Coefficient: 0.03333333333333333
20:20 Ratio: 1.1666666666666667
Max-min Ratio: 1.1666666666666667
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_13-24-36
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 900.0
  episode_reward_mean: 644.7021276595744
  episode_reward_min: -16.0
  episodes_this_iter: 1
  episodes_total: 47
  experiment_id: 86e053a9c80f439496ed6b19bfe1ab59
  hostname: gpu003
  info:
    apply_time_ms: 3.507
    dispatch_time_ms: 10.495
    learner:
      cur_lr: 0.001350609352812171
      grad_gnorm: 40.0
      policy_entropy: 8.680155754089355
      policy_loss: 3.4582221508026123
      var_gnorm: 23.162410736083984
      vf_explained_var: -0.10593521595001221
      vf_loss: 31.763126373291016
    num_steps_sampled: 144000
    num_steps_trained: 144000
    wait_time_ms: 62.965
  iterations_since_restore: 48
  node_ip: 172.17.8.3
  num_metric_batches_dropped: 0
  pid: 16746
  policy_reward_mean: {}
  time_since_restore: 396.5909240245819
  time_this_iter_s: 8.240418672561646
  time_total_s: 396.5909240245819
  timestamp: 1593883476
  timesteps_since_restore: 144000
  timesteps_this_iter: 3000
  timesteps_total: 144000
  training_iteration: 48
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 24.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=16746], 396 s, 48 iter, 144000 ts, 645 rew

agent-1: 321.0
agent-2: 312.0
agent-3: 253.0
Sum Reward: 886.0
Avg Reward: 295.3333333333333
Min Reward: 253.0
Gini Coefficient: 0.051166290443942816
20:20 Ratio: 1.2687747035573123
Max-min Ratio: 1.2687747035573123
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_13-24-43
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 900.0
  episode_reward_mean: 649.7291666666666
  episode_reward_min: -16.0
  episodes_this_iter: 1
  episodes_total: 48
  experiment_id: 86e053a9c80f439496ed6b19bfe1ab59
  hostname: gpu003
  info:
    apply_time_ms: 2.884
    dispatch_time_ms: 10.837
    learner:
      cur_lr: 0.001350409584119916
      grad_gnorm: 40.0
      policy_entropy: 18.068815231323242
      policy_loss: 3.2207112312316895
      var_gnorm: 23.219072341918945
      vf_explained_var: 0.5614504814147949
      vf_loss: 58.5487060546875
    num_steps_sampled: 147000
    num_steps_trained: 147000
    wait_time_ms: 64.413
  iterations_since_restore: 49
  node_ip: 172.17.8.3
  num_metric_batches_dropped: 0
  pid: 16746
  policy_reward_mean: {}
  time_since_restore: 404.4509754180908
  time_this_iter_s: 7.860051393508911
  time_total_s: 404.4509754180908
  timestamp: 1593883483
  timesteps_since_restore: 147000
  timesteps_this_iter: 3000
  timesteps_total: 147000
  training_iteration: 49
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 24.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=16746], 404 s, 49 iter, 147000 ts, 650 rew

agent-1: 223.0
agent-2: 244.0
agent-3: 214.0
Sum Reward: 681.0
Avg Reward: 227.0
Min Reward: 214.0
Gini Coefficient: 0.02936857562408223
20:20 Ratio: 1.1401869158878504
Max-min Ratio: 1.1401869158878504
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_13-24-52
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 900.0
  episode_reward_mean: 650.3673469387755
  episode_reward_min: -16.0
  episodes_this_iter: 1
  episodes_total: 49
  experiment_id: 86e053a9c80f439496ed6b19bfe1ab59
  hostname: gpu003
  info:
    apply_time_ms: 2.932
    dispatch_time_ms: 6.888
    learner:
      cur_lr: 0.001350209815427661
      grad_gnorm: 40.0
      policy_entropy: 20.31578826904297
      policy_loss: 7.830302715301514
      var_gnorm: 23.24583625793457
      vf_explained_var: 0.26011282205581665
      vf_loss: 47.24671173095703
    num_steps_sampled: 150000
    num_steps_trained: 150000
    wait_time_ms: 69.867
  iterations_since_restore: 50
  node_ip: 172.17.8.3
  num_metric_batches_dropped: 0
  pid: 16746
  policy_reward_mean: {}
  time_since_restore: 412.59428572654724
  time_this_iter_s: 8.143310308456421
  time_total_s: 412.59428572654724
  timestamp: 1593883492
  timesteps_since_restore: 150000
  timesteps_this_iter: 3000
  timesteps_total: 150000
  training_iteration: 50
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 24.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=16746], 412 s, 50 iter, 150000 ts, 650 rew

agent-1: 190.0
agent-2: 199.0
agent-3: 214.0
Sum Reward: 603.0
Avg Reward: 201.0
Min Reward: 190.0
Gini Coefficient: 0.026533996683250415
20:20 Ratio: 1.1263157894736842
Max-min Ratio: 1.1263157894736842
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_13-24-59
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 900.0
  episode_reward_mean: 649.42
  episode_reward_min: -16.0
  episodes_this_iter: 1
  episodes_total: 50
  experiment_id: 86e053a9c80f439496ed6b19bfe1ab59
  hostname: gpu003
  info:
    apply_time_ms: 3.135
    dispatch_time_ms: 9.699
    learner:
      cur_lr: 0.001350010046735406
      grad_gnorm: 38.04413986206055
      policy_entropy: 25.440563201904297
      policy_loss: 1.3228178024291992
      var_gnorm: 23.296844482421875
      vf_explained_var: 0.667474627494812
      vf_loss: 24.62594985961914
    num_steps_sampled: 153000
    num_steps_trained: 153000
    wait_time_ms: 66.517
  iterations_since_restore: 51
  node_ip: 172.17.8.3
  num_metric_batches_dropped: 0
  pid: 16746
  policy_reward_mean: {}
  time_since_restore: 420.17013239860535
  time_this_iter_s: 7.5758466720581055
  time_total_s: 420.17013239860535
  timestamp: 1593883499
  timesteps_since_restore: 153000
  timesteps_this_iter: 3000
  timesteps_total: 153000
  training_iteration: 51
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=16746], 420 s, 51 iter, 153000 ts, 649 rew

agent-1: 194.0
agent-2: 292.0
agent-3: 212.0
Sum Reward: 698.0
Avg Reward: 232.66666666666666
Min Reward: 194.0
Gini Coefficient: 0.0936007640878701
20:20 Ratio: 1.5051546391752577
Max-min Ratio: 1.5051546391752577
agent-1: 225.0
agent-2: 266.0
agent-3: 224.0
Sum Reward: 715.0
Avg Reward: 238.33333333333334
Min Reward: 224.0
Gini Coefficient: 0.039160839160839164
20:20 Ratio: 1.1875
Max-min Ratio: 1.1875
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_13-25-08
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 900.0
  episode_reward_mean: 650.3725490196078
  episode_reward_min: -16.0
  episodes_this_iter: 1
  episodes_total: 51
  experiment_id: 86e053a9c80f439496ed6b19bfe1ab59
  hostname: gpu003
  info:
    apply_time_ms: 3.256
    dispatch_time_ms: 11.912
    learner:
      cur_lr: 0.001349810161627829
      grad_gnorm: 39.999996185302734
      policy_entropy: 17.297100067138672
      policy_loss: 27.910715103149414
      var_gnorm: 23.36779022216797
      vf_explained_var: 0.14730298519134521
      vf_loss: 82.83509063720703
    num_steps_sampled: 156000
    num_steps_trained: 156000
    wait_time_ms: 67.697
  iterations_since_restore: 52
  node_ip: 172.17.8.3
  num_metric_batches_dropped: 0
  pid: 16746
  policy_reward_mean: {}
  time_since_restore: 428.4334924221039
  time_this_iter_s: 8.263360023498535
  time_total_s: 428.4334924221039
  timestamp: 1593883508
  timesteps_since_restore: 156000
  timesteps_this_iter: 3000
  timesteps_total: 156000
  training_iteration: 52
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=16746], 428 s, 52 iter, 156000 ts, 650 rew

Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_13-25-16
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 900.0
  episode_reward_mean: 651.6153846153846
  episode_reward_min: -16.0
  episodes_this_iter: 1
  episodes_total: 52
  experiment_id: 86e053a9c80f439496ed6b19bfe1ab59
  hostname: gpu003
  info:
    apply_time_ms: 2.714
    dispatch_time_ms: 5.49
    learner:
      cur_lr: 0.001349610392935574
      grad_gnorm: 40.0
      policy_entropy: 21.27104377746582
      policy_loss: -11.493943214416504
      var_gnorm: 23.5095157623291
      vf_explained_var: 0.6615865230560303
      vf_loss: 12.585260391235352
    num_steps_sampled: 159000
    num_steps_trained: 159000
    wait_time_ms: 75.922
  iterations_since_restore: 53
  node_ip: 172.17.8.3
  num_metric_batches_dropped: 0
  pid: 16746
  policy_reward_mean: {}
  time_since_restore: 436.4051752090454
  time_this_iter_s: 7.971682786941528
  time_total_s: 436.4051752090454
  timestamp: 1593883516
  timesteps_since_restore: 159000
  timesteps_this_iter: 3000
  timesteps_total: 159000
  training_iteration: 53
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=16746], 436 s, 53 iter, 159000 ts, 652 rew

agent-1: 236.0
agent-2: 305.0
agent-3: 275.0
Sum Reward: 816.0
Avg Reward: 272.0
Min Reward: 236.0
Gini Coefficient: 0.056372549019607844
20:20 Ratio: 1.2923728813559323
Max-min Ratio: 1.2923728813559323
agent-1: 256.0
agent-2: 268.0
agent-3: 212.0
Sum Reward: 736.0
Avg Reward: 245.33333333333334
Min Reward: 212.0
Gini Coefficient: 0.050724637681159424
20:20 Ratio: 1.2641509433962264
Max-min Ratio: 1.2641509433962264
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_13-25-24
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 900.0
  episode_reward_mean: 656.2222222222222
  episode_reward_min: -16.0
  episodes_this_iter: 2
  episodes_total: 54
  experiment_id: 86e053a9c80f439496ed6b19bfe1ab59
  hostname: gpu003
  info:
    apply_time_ms: 3.9
    dispatch_time_ms: 9.548
    learner:
      cur_lr: 0.001349410624243319
      grad_gnorm: 40.0
      policy_entropy: 23.94729995727539
      policy_loss: -586.6348266601562
      var_gnorm: 23.571292877197266
      vf_explained_var: 0.09267622232437134
      vf_loss: 7565.73291015625
    num_steps_sampled: 162000
    num_steps_trained: 162000
    wait_time_ms: 72.81
  iterations_since_restore: 54
  node_ip: 172.17.8.3
  num_metric_batches_dropped: 0
  pid: 16746
  policy_reward_mean: {}
  time_since_restore: 444.7292625904083
  time_this_iter_s: 8.324087381362915
  time_total_s: 444.7292625904083
  timestamp: 1593883524
  timesteps_since_restore: 162000
  timesteps_this_iter: 3000
  timesteps_total: 162000
  training_iteration: 54
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=16746], 444 s, 54 iter, 162000 ts, 656 rew

Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_13-25-32
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 900.0
  episode_reward_mean: 656.2222222222222
  episode_reward_min: -16.0
  episodes_this_iter: 0
  episodes_total: 54
  experiment_id: 86e053a9c80f439496ed6b19bfe1ab59
  hostname: gpu003
  info:
    apply_time_ms: 3.906
    dispatch_time_ms: 12.331
    learner:
      cur_lr: 0.001349210855551064
      grad_gnorm: 40.0
      policy_entropy: 24.90764045715332
      policy_loss: 9.371590614318848
      var_gnorm: 23.63065528869629
      vf_explained_var: 0.1445820927619934
      vf_loss: 12.657268524169922
    num_steps_sampled: 165000
    num_steps_trained: 165000
    wait_time_ms: 65.976
  iterations_since_restore: 55
  node_ip: 172.17.8.3
  num_metric_batches_dropped: 0
  pid: 16746
  policy_reward_mean: {}
  time_since_restore: 452.56389260292053
  time_this_iter_s: 7.834630012512207
  time_total_s: 452.56389260292053
  timestamp: 1593883532
  timesteps_since_restore: 165000
  timesteps_this_iter: 3000
  timesteps_total: 165000
  training_iteration: 55
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=16746], 452 s, 55 iter, 165000 ts, 656 rew

agent-1: 278.0
agent-2: 324.0
agent-3: 274.0
Sum Reward: 876.0
Avg Reward: 292.0
Min Reward: 274.0
Gini Coefficient: 0.0380517503805175
20:20 Ratio: 1.1824817518248176
Max-min Ratio: 1.1824817518248176
agent-1: 275.0
agent-2: 272.0
agent-3: 247.0
Sum Reward: 794.0
Avg Reward: 264.6666666666667
Min Reward: 247.0
Gini Coefficient: 0.023509655751469353
20:20 Ratio: 1.1133603238866396
Max-min Ratio: 1.1133603238866396
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_13-25-40
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 900.0
  episode_reward_mean: 662.6071428571429
  episode_reward_min: -16.0
  episodes_this_iter: 2
  episodes_total: 56
  experiment_id: 86e053a9c80f439496ed6b19bfe1ab59
  hostname: gpu003
  info:
    apply_time_ms: 2.973
    dispatch_time_ms: 10.466
    learner:
      cur_lr: 0.0013490109704434872
      grad_gnorm: 40.0
      policy_entropy: 14.200539588928223
      policy_loss: -379.7135314941406
      var_gnorm: 23.71299934387207
      vf_explained_var: 0.5381312370300293
      vf_loss: 9479.9208984375
    num_steps_sampled: 168000
    num_steps_trained: 168000
    wait_time_ms: 74.72
  iterations_since_restore: 56
  node_ip: 172.17.8.3
  num_metric_batches_dropped: 0
  pid: 16746
  policy_reward_mean: {}
  time_since_restore: 460.7759757041931
  time_this_iter_s: 8.212083101272583
  time_total_s: 460.7759757041931
  timestamp: 1593883540
  timesteps_since_restore: 168000
  timesteps_this_iter: 3000
  timesteps_total: 168000
  training_iteration: 56
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=16746], 460 s, 56 iter, 168000 ts, 663 rew

Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_13-25-48
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 900.0
  episode_reward_mean: 662.6071428571429
  episode_reward_min: -16.0
  episodes_this_iter: 0
  episodes_total: 56
  experiment_id: 86e053a9c80f439496ed6b19bfe1ab59
  hostname: gpu003
  info:
    apply_time_ms: 3.782
    dispatch_time_ms: 6.861
    learner:
      cur_lr: 0.0013488112017512321
      grad_gnorm: 16.79184341430664
      policy_entropy: 14.286050796508789
      policy_loss: 7.086923122406006
      var_gnorm: 23.795135498046875
      vf_explained_var: -0.22989559173583984
      vf_loss: 14.732475280761719
    num_steps_sampled: 171000
    num_steps_trained: 171000
    wait_time_ms: 70.781
  iterations_since_restore: 57
  node_ip: 172.17.8.3
  num_metric_batches_dropped: 0
  pid: 16746
  policy_reward_mean: {}
  time_since_restore: 468.66754508018494
  time_this_iter_s: 7.891569375991821
  time_total_s: 468.66754508018494
  timestamp: 1593883548
  timesteps_since_restore: 171000
  timesteps_this_iter: 3000
  timesteps_total: 171000
  training_iteration: 57
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=16746], 468 s, 57 iter, 171000 ts, 663 rew

agent-1: 269.0
agent-2: 226.0
agent-3: 204.0
Sum Reward: 699.0
Avg Reward: 233.0
Min Reward: 204.0
Gini Coefficient: 0.061993323795898905
20:20 Ratio: 1.3186274509803921
Max-min Ratio: 1.3186274509803921
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_13-25-57
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 900.0
  episode_reward_mean: 663.2456140350877
  episode_reward_min: -16.0
  episodes_this_iter: 1
  episodes_total: 57
  experiment_id: 86e053a9c80f439496ed6b19bfe1ab59
  hostname: gpu003
  info:
    apply_time_ms: 3.141
    dispatch_time_ms: 6.627
    learner:
      cur_lr: 0.0013486114330589771
      grad_gnorm: 40.0
      policy_entropy: 20.711814880371094
      policy_loss: -11.494791030883789
      var_gnorm: 23.83461570739746
      vf_explained_var: 0.7380691766738892
      vf_loss: 18.584667205810547
    num_steps_sampled: 174000
    num_steps_trained: 174000
    wait_time_ms: 77.186
  iterations_since_restore: 58
  node_ip: 172.17.8.3
  num_metric_batches_dropped: 0
  pid: 16746
  policy_reward_mean: {}
  time_since_restore: 477.607839345932
  time_this_iter_s: 8.94029426574707
  time_total_s: 477.607839345932
  timestamp: 1593883557
  timesteps_since_restore: 174000
  timesteps_this_iter: 3000
  timesteps_total: 174000
  training_iteration: 58
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=16746], 477 s, 58 iter, 174000 ts, 663 rew

agent-1: 267.0
agent-2: 217.0
agent-3: 265.0
Sum Reward: 749.0
Avg Reward: 249.66666666666666
Min Reward: 217.0
Gini Coefficient: 0.04450378282153983
20:20 Ratio: 1.2304147465437787
Max-min Ratio: 1.2304147465437787
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_13-26-05
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 900.0
  episode_reward_mean: 664.7241379310345
  episode_reward_min: -16.0
  episodes_this_iter: 1
  episodes_total: 58
  experiment_id: 86e053a9c80f439496ed6b19bfe1ab59
  hostname: gpu003
  info:
    apply_time_ms: 2.682
    dispatch_time_ms: 10.537
    learner:
      cur_lr: 0.0013484115479514003
      grad_gnorm: 39.99999237060547
      policy_entropy: 11.38524055480957
      policy_loss: 2.1527509689331055
      var_gnorm: 23.930339813232422
      vf_explained_var: -0.6387945413589478
      vf_loss: 20.385936737060547
    num_steps_sampled: 177000
    num_steps_trained: 177000
    wait_time_ms: 69.861
  iterations_since_restore: 59
  node_ip: 172.17.8.3
  num_metric_batches_dropped: 0
  pid: 16746
  policy_reward_mean: {}
  time_since_restore: 485.546156167984
  time_this_iter_s: 7.938316822052002
  time_total_s: 485.546156167984
  timestamp: 1593883565
  timesteps_since_restore: 177000
  timesteps_this_iter: 3000
  timesteps_total: 177000
  training_iteration: 59
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.3/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=16746], 485 s, 59 iter, 177000 ts, 665 rew

agent-1: 243.0
agent-2: 241.0
agent-3: 265.0
Sum Reward: 749.0
Avg Reward: 249.66666666666666
Min Reward: 241.0
Gini Coefficient: 0.021361815754339118
20:20 Ratio: 1.099585062240664
Max-min Ratio: 1.099585062240664
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_13-26-14
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 900.0
  episode_reward_mean: 666.1525423728814
  episode_reward_min: -16.0
  episodes_this_iter: 1
  episodes_total: 59
  experiment_id: 86e053a9c80f439496ed6b19bfe1ab59
  hostname: gpu003
  info:
    apply_time_ms: 3.596
    dispatch_time_ms: 8.41
    learner:
      cur_lr: 0.0013482117792591453
      grad_gnorm: 31.702972412109375
      policy_entropy: 16.791973114013672
      policy_loss: -0.8977776765823364
      var_gnorm: 24.030221939086914
      vf_explained_var: 0.612299919128418
      vf_loss: 10.856407165527344
    num_steps_sampled: 180000
    num_steps_trained: 180000
    wait_time_ms: 87.054
  iterations_since_restore: 60
  node_ip: 172.17.8.3
  num_metric_batches_dropped: 0
  pid: 16746
  policy_reward_mean: {}
  time_since_restore: 494.5484755039215
  time_this_iter_s: 9.0023193359375
  time_total_s: 494.5484755039215
  timestamp: 1593883574
  timesteps_since_restore: 180000
  timesteps_this_iter: 3000
  timesteps_total: 180000
  training_iteration: 60
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=16746], 494 s, 60 iter, 180000 ts, 666 rew

agent-1: 214.0
agent-2: 248.0
agent-3: 256.0
Sum Reward: 718.0
Avg Reward: 239.33333333333334
Min Reward: 214.0
Gini Coefficient: 0.03899721448467967
20:20 Ratio: 1.1962616822429906
Max-min Ratio: 1.1962616822429906
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_13-26-22
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 900.0
  episode_reward_mean: 667.0166666666667
  episode_reward_min: -16.0
  episodes_this_iter: 1
  episodes_total: 60
  experiment_id: 86e053a9c80f439496ed6b19bfe1ab59
  hostname: gpu003
  info:
    apply_time_ms: 2.742
    dispatch_time_ms: 10.123
    learner:
      cur_lr: 0.0013480120105668902
      grad_gnorm: 31.664220809936523
      policy_entropy: 16.38199234008789
      policy_loss: -8.04769229888916
      var_gnorm: 24.129793167114258
      vf_explained_var: 0.24164974689483643
      vf_loss: 6.36268424987793
    num_steps_sampled: 183000
    num_steps_trained: 183000
    wait_time_ms: 67.71
  iterations_since_restore: 61
  node_ip: 172.17.8.3
  num_metric_batches_dropped: 0
  pid: 16746
  policy_reward_mean: {}
  time_since_restore: 502.4511065483093
  time_this_iter_s: 7.902631044387817
  time_total_s: 502.4511065483093
  timestamp: 1593883582
  timesteps_since_restore: 183000
  timesteps_this_iter: 3000
  timesteps_total: 183000
  training_iteration: 61
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=16746], 502 s, 61 iter, 183000 ts, 667 rew

agent-1: 287.0
agent-2: 279.0
agent-3: 251.0
Sum Reward: 817.0
Avg Reward: 272.3333333333333
Min Reward: 251.0
Gini Coefficient: 0.02937576499388005
20:20 Ratio: 1.1434262948207172
Max-min Ratio: 1.1434262948207172
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_13-26-31
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 900.0
  episode_reward_mean: 669.4754098360655
  episode_reward_min: -16.0
  episodes_this_iter: 1
  episodes_total: 61
  experiment_id: 86e053a9c80f439496ed6b19bfe1ab59
  hostname: gpu003
  info:
    apply_time_ms: 3.011
    dispatch_time_ms: 8.817
    learner:
      cur_lr: 0.0013478122418746352
      grad_gnorm: 40.00000762939453
      policy_entropy: 19.293622970581055
      policy_loss: -4.565509796142578
      var_gnorm: 24.237150192260742
      vf_explained_var: 0.8547055721282959
      vf_loss: 15.228153228759766
    num_steps_sampled: 186000
    num_steps_trained: 186000
    wait_time_ms: 64.053
  iterations_since_restore: 62
  node_ip: 172.17.8.3
  num_metric_batches_dropped: 0
  pid: 16746
  policy_reward_mean: {}
  time_since_restore: 511.1592171192169
  time_this_iter_s: 8.708110570907593
  time_total_s: 511.1592171192169
  timestamp: 1593883591
  timesteps_since_restore: 186000
  timesteps_this_iter: 3000
  timesteps_total: 186000
  training_iteration: 62
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=16746], 511 s, 62 iter, 186000 ts, 669 rew

agent-1: 241.0
agent-2: 262.0
agent-3: 241.0
Sum Reward: 744.0
Avg Reward: 248.0
Min Reward: 241.0
Gini Coefficient: 0.01881720430107527
20:20 Ratio: 1.0871369294605808
Max-min Ratio: 1.0871369294605808
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_13-26-39
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 900.0
  episode_reward_mean: 670.6774193548387
  episode_reward_min: -16.0
  episodes_this_iter: 1
  episodes_total: 62
  experiment_id: 86e053a9c80f439496ed6b19bfe1ab59
  hostname: gpu003
  info:
    apply_time_ms: 3.476
    dispatch_time_ms: 9.847
    learner:
      cur_lr: 0.0013476123567670584
      grad_gnorm: 40.0
      policy_entropy: 13.555632591247559
      policy_loss: 16.36404800415039
      var_gnorm: 24.394222259521484
      vf_explained_var: 0.6130518317222595
      vf_loss: 25.512310028076172
    num_steps_sampled: 189000
    num_steps_trained: 189000
    wait_time_ms: 70.344
  iterations_since_restore: 63
  node_ip: 172.17.8.3
  num_metric_batches_dropped: 0
  pid: 16746
  policy_reward_mean: {}
  time_since_restore: 519.2740337848663
  time_this_iter_s: 8.114816665649414
  time_total_s: 519.2740337848663
  timestamp: 1593883599
  timesteps_since_restore: 189000
  timesteps_this_iter: 3000
  timesteps_total: 189000
  training_iteration: 63
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=16746], 519 s, 63 iter, 189000 ts, 671 rew

agent-1: 256.0
agent-2: 289.0
agent-3: 253.0
Sum Reward: 798.0
Avg Reward: 266.0
Min Reward: 253.0
Gini Coefficient: 0.03007518796992481
20:20 Ratio: 1.1422924901185771
Max-min Ratio: 1.1422924901185771
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_13-26-47
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 900.0
  episode_reward_mean: 672.6984126984127
  episode_reward_min: -16.0
  episodes_this_iter: 1
  episodes_total: 63
  experiment_id: 86e053a9c80f439496ed6b19bfe1ab59
  hostname: gpu003
  info:
    apply_time_ms: 2.73
    dispatch_time_ms: 8.836
    learner:
      cur_lr: 0.0013474125880748034
      grad_gnorm: 39.99999237060547
      policy_entropy: 10.97240924835205
      policy_loss: 32.47880935668945
      var_gnorm: 24.505048751831055
      vf_explained_var: -1.0
      vf_loss: 81.69181060791016
    num_steps_sampled: 192000
    num_steps_trained: 192000
    wait_time_ms: 60.762
  iterations_since_restore: 64
  node_ip: 172.17.8.3
  num_metric_batches_dropped: 0
  pid: 16746
  policy_reward_mean: {}
  time_since_restore: 527.523134469986
  time_this_iter_s: 8.249100685119629
  time_total_s: 527.523134469986
  timestamp: 1593883607
  timesteps_since_restore: 192000
  timesteps_this_iter: 3000
  timesteps_total: 192000
  training_iteration: 64
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 27.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=16746], 527 s, 64 iter, 192000 ts, 673 rew

agent-1: 254.0
agent-2: 235.0
agent-3: 248.0
Sum Reward: 737.0
Avg Reward: 245.66666666666666
Min Reward: 235.0
Gini Coefficient: 0.017186793306196293
20:20 Ratio: 1.0808510638297872
Max-min Ratio: 1.0808510638297872
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_13-26-55
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 900.0
  episode_reward_mean: 673.703125
  episode_reward_min: -16.0
  episodes_this_iter: 1
  episodes_total: 64
  experiment_id: 86e053a9c80f439496ed6b19bfe1ab59
  hostname: gpu003
  info:
    apply_time_ms: 2.665
    dispatch_time_ms: 8.597
    learner:
      cur_lr: 0.0013472128193825483
      grad_gnorm: 39.999996185302734
      policy_entropy: 10.025666236877441
      policy_loss: 16.82143211364746
      var_gnorm: 24.687501907348633
      vf_explained_var: -0.9517121315002441
      vf_loss: 27.70685386657715
    num_steps_sampled: 195000
    num_steps_trained: 195000
    wait_time_ms: 66.525
  iterations_since_restore: 65
  node_ip: 172.17.8.3
  num_metric_batches_dropped: 0
  pid: 16746
  policy_reward_mean: {}
  time_since_restore: 535.5560457706451
  time_this_iter_s: 8.03291130065918
  time_total_s: 535.5560457706451
  timestamp: 1593883615
  timesteps_since_restore: 195000
  timesteps_this_iter: 3000
  timesteps_total: 195000
  training_iteration: 65
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 27.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=16746], 535 s, 65 iter, 195000 ts, 674 rew

agent-1: 233.0
agent-2: 282.0
agent-3: 253.0
Sum Reward: 768.0
Avg Reward: 256.0
Min Reward: 233.0
Gini Coefficient: 0.042534722222222224
20:20 Ratio: 1.2103004291845494
Max-min Ratio: 1.2103004291845494
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_13-27-04
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 900.0
  episode_reward_mean: 675.1538461538462
  episode_reward_min: -16.0
  episodes_this_iter: 1
  episodes_total: 65
  experiment_id: 86e053a9c80f439496ed6b19bfe1ab59
  hostname: gpu003
  info:
    apply_time_ms: 2.948
    dispatch_time_ms: 7.768
    learner:
      cur_lr: 0.0013470130506902933
      grad_gnorm: 39.999996185302734
      policy_entropy: 11.04940414428711
      policy_loss: 3.092668056488037
      var_gnorm: 24.761919021606445
      vf_explained_var: 0.02038252353668213
      vf_loss: 14.289182662963867
    num_steps_sampled: 198000
    num_steps_trained: 198000
    wait_time_ms: 72.894
  iterations_since_restore: 66
  node_ip: 172.17.8.3
  num_metric_batches_dropped: 0
  pid: 16746
  policy_reward_mean: {}
  time_since_restore: 543.9577429294586
  time_this_iter_s: 8.401697158813477
  time_total_s: 543.9577429294586
  timestamp: 1593883624
  timesteps_since_restore: 198000
  timesteps_this_iter: 3000
  timesteps_total: 198000
  training_iteration: 66
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 27.3/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=16746], 543 s, 66 iter, 198000 ts, 675 rew

agent-1: 296.0
agent-2: 248.0
agent-3: 247.0
Sum Reward: 791.0
Avg Reward: 263.6666666666667
Min Reward: 247.0
Gini Coefficient: 0.04129793510324484
20:20 Ratio: 1.1983805668016194
Max-min Ratio: 1.1983805668016194
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_13-27-12
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 900.0
  episode_reward_mean: 676.9090909090909
  episode_reward_min: -16.0
  episodes_this_iter: 1
  episodes_total: 66
  experiment_id: 86e053a9c80f439496ed6b19bfe1ab59
  hostname: gpu003
  info:
    apply_time_ms: 2.744
    dispatch_time_ms: 6.356
    learner:
      cur_lr: 0.0013468131655827165
      grad_gnorm: 39.999996185302734
      policy_entropy: 13.776101112365723
      policy_loss: 10.269732475280762
      var_gnorm: 24.849184036254883
      vf_explained_var: 0.4073992967605591
      vf_loss: 32.19833755493164
    num_steps_sampled: 201000
    num_steps_trained: 201000
    wait_time_ms: 70.04
  iterations_since_restore: 67
  node_ip: 172.17.8.3
  num_metric_batches_dropped: 0
  pid: 16746
  policy_reward_mean: {}
  time_since_restore: 551.955913066864
  time_this_iter_s: 7.9981701374053955
  time_total_s: 551.955913066864
  timestamp: 1593883632
  timesteps_since_restore: 201000
  timesteps_this_iter: 3000
  timesteps_total: 201000
  training_iteration: 67
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 27.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=16746], 551 s, 67 iter, 201000 ts, 677 rew

agent-1: 257.0
agent-2: 331.0
agent-3: 315.0
Sum Reward: 903.0
Avg Reward: 301.0
Min Reward: 257.0
Gini Coefficient: 0.05463270579549649
20:20 Ratio: 1.2879377431906616
Max-min Ratio: 1.2879377431906616
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_13-27-20
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 903.0
  episode_reward_mean: 680.2835820895523
  episode_reward_min: -16.0
  episodes_this_iter: 1
  episodes_total: 67
  experiment_id: 86e053a9c80f439496ed6b19bfe1ab59
  hostname: gpu003
  info:
    apply_time_ms: 2.851
    dispatch_time_ms: 7.736
    learner:
      cur_lr: 0.0013466133968904614
      grad_gnorm: 40.0
      policy_entropy: 16.7510986328125
      policy_loss: 15.368066787719727
      var_gnorm: 24.87738037109375
      vf_explained_var: 0.2153947353363037
      vf_loss: 24.875591278076172
    num_steps_sampled: 204000
    num_steps_trained: 204000
    wait_time_ms: 66.806
  iterations_since_restore: 68
  node_ip: 172.17.8.3
  num_metric_batches_dropped: 0
  pid: 16746
  policy_reward_mean: {}
  time_since_restore: 560.099059343338
  time_this_iter_s: 8.143146276473999
  time_total_s: 560.099059343338
  timestamp: 1593883640
  timesteps_since_restore: 204000
  timesteps_this_iter: 3000
  timesteps_total: 204000
  training_iteration: 68
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 27.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=16746], 560 s, 68 iter, 204000 ts, 680 rew

agent-1: 307.0
agent-2: 284.0
agent-3: 262.0
Sum Reward: 853.0
Avg Reward: 284.3333333333333
Min Reward: 262.0
Gini Coefficient: 0.035169988276670575
20:20 Ratio: 1.1717557251908397
Max-min Ratio: 1.1717557251908397
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_13-27-28
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 903.0
  episode_reward_mean: 682.8235294117648
  episode_reward_min: -16.0
  episodes_this_iter: 1
  episodes_total: 68
  experiment_id: 86e053a9c80f439496ed6b19bfe1ab59
  hostname: gpu003
  info:
    apply_time_ms: 2.959
    dispatch_time_ms: 7.421
    learner:
      cur_lr: 0.0013464136281982064
      grad_gnorm: 40.0
      policy_entropy: 14.992833137512207
      policy_loss: -7.935602188110352
      var_gnorm: 24.94096565246582
      vf_explained_var: 0.8446094989776611
      vf_loss: 16.075027465820312
    num_steps_sampled: 207000
    num_steps_trained: 207000
    wait_time_ms: 79.146
  iterations_since_restore: 69
  node_ip: 172.17.8.3
  num_metric_batches_dropped: 0
  pid: 16746
  policy_reward_mean: {}
  time_since_restore: 568.5430593490601
  time_this_iter_s: 8.444000005722046
  time_total_s: 568.5430593490601
  timestamp: 1593883648
  timesteps_since_restore: 207000
  timesteps_this_iter: 3000
  timesteps_total: 207000
  training_iteration: 69
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 27.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=16746], 568 s, 69 iter, 207000 ts, 683 rew

agent-1: 203.0
agent-2: 207.0
agent-3: 193.0
Sum Reward: 603.0
Avg Reward: 201.0
Min Reward: 193.0
Gini Coefficient: 0.015478164731896076
20:20 Ratio: 1.072538860103627
Max-min Ratio: 1.072538860103627
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_13-27-37
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 903.0
  episode_reward_mean: 681.6666666666666
  episode_reward_min: -16.0
  episodes_this_iter: 1
  episodes_total: 69
  experiment_id: 86e053a9c80f439496ed6b19bfe1ab59
  hostname: gpu003
  info:
    apply_time_ms: 2.551
    dispatch_time_ms: 9.738
    learner:
      cur_lr: 0.0013462137430906296
      grad_gnorm: 39.99999237060547
      policy_entropy: 9.566661834716797
      policy_loss: 9.464448928833008
      var_gnorm: 24.953367233276367
      vf_explained_var: 0.2973150610923767
      vf_loss: 23.852113723754883
    num_steps_sampled: 210000
    num_steps_trained: 210000
    wait_time_ms: 66.807
  iterations_since_restore: 70
  node_ip: 172.17.8.3
  num_metric_batches_dropped: 0
  pid: 16746
  policy_reward_mean: {}
  time_since_restore: 577.6269414424896
  time_this_iter_s: 9.083882093429565
  time_total_s: 577.6269414424896
  timestamp: 1593883657
  timesteps_since_restore: 210000
  timesteps_this_iter: 3000
  timesteps_total: 210000
  training_iteration: 70
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 27.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=16746], 577 s, 70 iter, 210000 ts, 682 rew

agent-1: 220.0
agent-2: 253.0
agent-3: 254.0
Sum Reward: 727.0
Avg Reward: 242.33333333333334
Min Reward: 220.0
Gini Coefficient: 0.031178358551123338
20:20 Ratio: 1.1545454545454545
Max-min Ratio: 1.1545454545454545
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_13-27-46
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 903.0
  episode_reward_mean: 682.3142857142857
  episode_reward_min: -16.0
  episodes_this_iter: 1
  episodes_total: 70
  experiment_id: 86e053a9c80f439496ed6b19bfe1ab59
  hostname: gpu003
  info:
    apply_time_ms: 2.687
    dispatch_time_ms: 5.495
    learner:
      cur_lr: 0.0013460139743983746
      grad_gnorm: 20.05840301513672
      policy_entropy: 11.355121612548828
      policy_loss: -1.4194928407669067
      var_gnorm: 25.013648986816406
      vf_explained_var: 0.4982905983924866
      vf_loss: 14.443169593811035
    num_steps_sampled: 213000
    num_steps_trained: 213000
    wait_time_ms: 77.58
  iterations_since_restore: 71
  node_ip: 172.17.8.3
  num_metric_batches_dropped: 0
  pid: 16746
  policy_reward_mean: {}
  time_since_restore: 585.9787168502808
  time_this_iter_s: 8.351775407791138
  time_total_s: 585.9787168502808
  timestamp: 1593883666
  timesteps_since_restore: 213000
  timesteps_this_iter: 3000
  timesteps_total: 213000
  training_iteration: 71
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=16746], 585 s, 71 iter, 213000 ts, 682 rew

agent-1: 254.0
agent-2: 199.0
agent-3: 282.0
Sum Reward: 735.0
Avg Reward: 245.0
Min Reward: 199.0
Gini Coefficient: 0.07528344671201814
20:20 Ratio: 1.4170854271356783
Max-min Ratio: 1.4170854271356783
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_13-27-55
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 903.0
  episode_reward_mean: 683.056338028169
  episode_reward_min: -16.0
  episodes_this_iter: 1
  episodes_total: 71
  experiment_id: 86e053a9c80f439496ed6b19bfe1ab59
  hostname: gpu003
  info:
    apply_time_ms: 2.793
    dispatch_time_ms: 8.571
    learner:
      cur_lr: 0.0013458142057061195
      grad_gnorm: 40.0
      policy_entropy: 15.988146781921387
      policy_loss: 14.275802612304688
      var_gnorm: 25.10201644897461
      vf_explained_var: 0.2775135636329651
      vf_loss: 25.010986328125
    num_steps_sampled: 216000
    num_steps_trained: 216000
    wait_time_ms: 79.322
  iterations_since_restore: 72
  node_ip: 172.17.8.3
  num_metric_batches_dropped: 0
  pid: 16746
  policy_reward_mean: {}
  time_since_restore: 595.0649185180664
  time_this_iter_s: 9.086201667785645
  time_total_s: 595.0649185180664
  timestamp: 1593883675
  timesteps_since_restore: 216000
  timesteps_this_iter: 3000
  timesteps_total: 216000
  training_iteration: 72
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=16746], 595 s, 72 iter, 216000 ts, 683 rew

agent-1: 242.0
agent-2: 228.0
agent-3: 244.0
Sum Reward: 714.0
Avg Reward: 238.0
Min Reward: 228.0
Gini Coefficient: 0.014939309056956116
20:20 Ratio: 1.0701754385964912
Max-min Ratio: 1.0701754385964912
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_13-28-03
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 903.0
  episode_reward_mean: 683.4861111111111
  episode_reward_min: -16.0
  episodes_this_iter: 1
  episodes_total: 72
  experiment_id: 86e053a9c80f439496ed6b19bfe1ab59
  hostname: gpu003
  info:
    apply_time_ms: 3.286
    dispatch_time_ms: 11.964
    learner:
      cur_lr: 0.0013456144370138645
      grad_gnorm: 39.99998474121094
      policy_entropy: 15.868782043457031
      policy_loss: -16.865291595458984
      var_gnorm: 25.28577423095703
      vf_explained_var: 0.35990989208221436
      vf_loss: 79.0358657836914
    num_steps_sampled: 219000
    num_steps_trained: 219000
    wait_time_ms: 70.864
  iterations_since_restore: 73
  node_ip: 172.17.8.3
  num_metric_batches_dropped: 0
  pid: 16746
  policy_reward_mean: {}
  time_since_restore: 603.5268428325653
  time_this_iter_s: 8.461924314498901
  time_total_s: 603.5268428325653
  timestamp: 1593883683
  timesteps_since_restore: 219000
  timesteps_this_iter: 3000
  timesteps_total: 219000
  training_iteration: 73
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.3/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=16746], 603 s, 73 iter, 219000 ts, 683 rew

agent-1: 237.0
agent-2: 270.0
agent-3: 239.0
Sum Reward: 746.0
Avg Reward: 248.66666666666666
Min Reward: 237.0
Gini Coefficient: 0.029490616621983913
20:20 Ratio: 1.139240506329114
Max-min Ratio: 1.139240506329114
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_13-28-12
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 903.0
  episode_reward_mean: 684.3424657534247
  episode_reward_min: -16.0
  episodes_this_iter: 1
  episodes_total: 73
  experiment_id: 86e053a9c80f439496ed6b19bfe1ab59
  hostname: gpu003
  info:
    apply_time_ms: 3.317
    dispatch_time_ms: 8.183
    learner:
      cur_lr: 0.0013454145519062877
      grad_gnorm: 40.0
      policy_entropy: 9.328300476074219
      policy_loss: 8.24226188659668
      var_gnorm: 25.396942138671875
      vf_explained_var: 0.37000972032546997
      vf_loss: 50.27622604370117
    num_steps_sampled: 222000
    num_steps_trained: 222000
    wait_time_ms: 65.316
  iterations_since_restore: 74
  node_ip: 172.17.8.3
  num_metric_batches_dropped: 0
  pid: 16746
  policy_reward_mean: {}
  time_since_restore: 611.9810571670532
  time_this_iter_s: 8.454214334487915
  time_total_s: 611.9810571670532
  timestamp: 1593883692
  timesteps_since_restore: 222000
  timesteps_this_iter: 3000
  timesteps_total: 222000
  training_iteration: 74
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=16746], 611 s, 74 iter, 222000 ts, 684 rew

agent-1: 273.0
agent-2: 253.0
agent-3: 220.0
Sum Reward: 746.0
Avg Reward: 248.66666666666666
Min Reward: 220.0
Gini Coefficient: 0.04736371760500447
20:20 Ratio: 1.240909090909091
Max-min Ratio: 1.240909090909091
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_13-28-20
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 903.0
  episode_reward_mean: 685.1756756756756
  episode_reward_min: -16.0
  episodes_this_iter: 1
  episodes_total: 74
  experiment_id: 86e053a9c80f439496ed6b19bfe1ab59
  hostname: gpu003
  info:
    apply_time_ms: 2.896
    dispatch_time_ms: 10.883
    learner:
      cur_lr: 0.0013452147832140326
      grad_gnorm: 16.948122024536133
      policy_entropy: 6.21104621887207
      policy_loss: -2.0621678829193115
      var_gnorm: 25.461362838745117
      vf_explained_var: 0.901767909526825
      vf_loss: 15.710481643676758
    num_steps_sampled: 225000
    num_steps_trained: 225000
    wait_time_ms: 68.79
  iterations_since_restore: 75
  node_ip: 172.17.8.3
  num_metric_batches_dropped: 0
  pid: 16746
  policy_reward_mean: {}
  time_since_restore: 620.317622423172
  time_this_iter_s: 8.336565256118774
  time_total_s: 620.317622423172
  timestamp: 1593883700
  timesteps_since_restore: 225000
  timesteps_this_iter: 3000
  timesteps_total: 225000
  training_iteration: 75
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=16746], 620 s, 75 iter, 225000 ts, 685 rew

agent-1: 253.0
agent-2: 232.0
agent-3: 254.0
Sum Reward: 739.0
Avg Reward: 246.33333333333334
Min Reward: 232.0
Gini Coefficient: 0.019846639603067207
20:20 Ratio: 1.0948275862068966
Max-min Ratio: 1.0948275862068966
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_13-28-29
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 903.0
  episode_reward_mean: 685.8933333333333
  episode_reward_min: -16.0
  episodes_this_iter: 1
  episodes_total: 75
  experiment_id: 86e053a9c80f439496ed6b19bfe1ab59
  hostname: gpu003
  info:
    apply_time_ms: 2.816
    dispatch_time_ms: 7.794
    learner:
      cur_lr: 0.0013450150145217776
      grad_gnorm: 25.6602840423584
      policy_entropy: 22.928770065307617
      policy_loss: -5.229196071624756
      var_gnorm: 25.47332763671875
      vf_explained_var: 0.7002164721488953
      vf_loss: 22.408037185668945
    num_steps_sampled: 228000
    num_steps_trained: 228000
    wait_time_ms: 69.794
  iterations_since_restore: 76
  node_ip: 172.17.8.3
  num_metric_batches_dropped: 0
  pid: 16746
  policy_reward_mean: {}
  time_since_restore: 628.8727531433105
  time_this_iter_s: 8.55513072013855
  time_total_s: 628.8727531433105
  timestamp: 1593883709
  timesteps_since_restore: 228000
  timesteps_this_iter: 3000
  timesteps_total: 228000
  training_iteration: 76
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=16746], 628 s, 76 iter, 228000 ts, 686 rew

agent-1: 218.0
agent-2: 219.0
agent-3: 226.0
Sum Reward: 663.0
Avg Reward: 221.0
Min Reward: 218.0
Gini Coefficient: 0.008044243338360985
20:20 Ratio: 1.036697247706422
Max-min Ratio: 1.036697247706422
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_13-28-37
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 903.0
  episode_reward_mean: 685.5921052631579
  episode_reward_min: -16.0
  episodes_this_iter: 1
  episodes_total: 76
  experiment_id: 86e053a9c80f439496ed6b19bfe1ab59
  hostname: gpu003
  info:
    apply_time_ms: 2.494
    dispatch_time_ms: 9.287
    learner:
      cur_lr: 0.0013448152458295226
      grad_gnorm: 40.0
      policy_entropy: 16.491680145263672
      policy_loss: 10.1583251953125
      var_gnorm: 25.564348220825195
      vf_explained_var: 0.5673292875289917
      vf_loss: 14.890295028686523
    num_steps_sampled: 231000
    num_steps_trained: 231000
    wait_time_ms: 72.746
  iterations_since_restore: 77
  node_ip: 172.17.8.3
  num_metric_batches_dropped: 0
  pid: 16746
  policy_reward_mean: {}
  time_since_restore: 637.1388301849365
  time_this_iter_s: 8.266077041625977
  time_total_s: 637.1388301849365
  timestamp: 1593883717
  timesteps_since_restore: 231000
  timesteps_this_iter: 3000
  timesteps_total: 231000
  training_iteration: 77
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=16746], 637 s, 77 iter, 231000 ts, 686 rew

agent-1: 247.0
agent-2: 244.0
agent-3: 254.0
Sum Reward: 745.0
Avg Reward: 248.33333333333334
Min Reward: 244.0
Gini Coefficient: 0.008948545861297539
20:20 Ratio: 1.040983606557377
Max-min Ratio: 1.040983606557377
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_13-28-46
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 903.0
  episode_reward_mean: 686.3636363636364
  episode_reward_min: -16.0
  episodes_this_iter: 1
  episodes_total: 77
  experiment_id: 86e053a9c80f439496ed6b19bfe1ab59
  hostname: gpu003
  info:
    apply_time_ms: 2.656
    dispatch_time_ms: 7.54
    learner:
      cur_lr: 0.0013446153607219458
      grad_gnorm: 21.724273681640625
      policy_entropy: 10.52031135559082
      policy_loss: -7.606691837310791
      var_gnorm: 25.60698699951172
      vf_explained_var: -0.1814591884613037
      vf_loss: 14.870267868041992
    num_steps_sampled: 234000
    num_steps_trained: 234000
    wait_time_ms: 76.327
  iterations_since_restore: 78
  node_ip: 172.17.8.3
  num_metric_batches_dropped: 0
  pid: 16746
  policy_reward_mean: {}
  time_since_restore: 645.8600511550903
  time_this_iter_s: 8.721220970153809
  time_total_s: 645.8600511550903
  timestamp: 1593883726
  timesteps_since_restore: 234000
  timesteps_this_iter: 3000
  timesteps_total: 234000
  training_iteration: 78
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 29.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=16746], 645 s, 78 iter, 234000 ts, 686 rew

agent-1: 205.0
agent-2: 300.0
agent-3: 265.0
Sum Reward: 770.0
Avg Reward: 256.6666666666667
Min Reward: 205.0
Gini Coefficient: 0.08225108225108226
20:20 Ratio: 1.4634146341463414
Max-min Ratio: 1.4634146341463414
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_13-28-54
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 903.0
  episode_reward_mean: 687.4358974358975
  episode_reward_min: -16.0
  episodes_this_iter: 1
  episodes_total: 78
  experiment_id: 86e053a9c80f439496ed6b19bfe1ab59
  hostname: gpu003
  info:
    apply_time_ms: 3.068
    dispatch_time_ms: 6.685
    learner:
      cur_lr: 0.0013444155920296907
      grad_gnorm: 40.0
      policy_entropy: 12.213089942932129
      policy_loss: -7.683142185211182
      var_gnorm: 25.665990829467773
      vf_explained_var: 0.5367562770843506
      vf_loss: 40.447044372558594
    num_steps_sampled: 237000
    num_steps_trained: 237000
    wait_time_ms: 73.519
  iterations_since_restore: 79
  node_ip: 172.17.8.3
  num_metric_batches_dropped: 0
  pid: 16746
  policy_reward_mean: {}
  time_since_restore: 654.3365263938904
  time_this_iter_s: 8.476475238800049
  time_total_s: 654.3365263938904
  timestamp: 1593883734
  timesteps_since_restore: 237000
  timesteps_this_iter: 3000
  timesteps_total: 237000
  training_iteration: 79
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 29.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=16746], 654 s, 79 iter, 237000 ts, 687 rew

agent-1: 233.0
agent-2: 294.0
agent-3: 205.0
Sum Reward: 732.0
Avg Reward: 244.0
Min Reward: 205.0
Gini Coefficient: 0.08105646630236794
20:20 Ratio: 1.4341463414634146
Max-min Ratio: 1.4341463414634146
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_13-29-03
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 903.0
  episode_reward_mean: 688.0
  episode_reward_min: -16.0
  episodes_this_iter: 1
  episodes_total: 79
  experiment_id: 86e053a9c80f439496ed6b19bfe1ab59
  hostname: gpu003
  info:
    apply_time_ms: 3.119
    dispatch_time_ms: 7.383
    learner:
      cur_lr: 0.0013442158233374357
      grad_gnorm: 40.0
      policy_entropy: 9.70473861694336
      policy_loss: 3.858865737915039
      var_gnorm: 25.738048553466797
      vf_explained_var: -0.17142832279205322
      vf_loss: 15.130889892578125
    num_steps_sampled: 240000
    num_steps_trained: 240000
    wait_time_ms: 76.004
  iterations_since_restore: 80
  node_ip: 172.17.8.3
  num_metric_batches_dropped: 0
  pid: 16746
  policy_reward_mean: {}
  time_since_restore: 662.5501346588135
  time_this_iter_s: 8.213608264923096
  time_total_s: 662.5501346588135
  timestamp: 1593883743
  timesteps_since_restore: 240000
  timesteps_this_iter: 3000
  timesteps_total: 240000
  training_iteration: 80
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 29.3/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=16746], 662 s, 80 iter, 240000 ts, 688 rew

agent-1: 199.0
agent-2: 241.0
agent-3: 249.0
Sum Reward: 689.0
Avg Reward: 229.66666666666666
Min Reward: 199.0
Gini Coefficient: 0.04837929366231253
20:20 Ratio: 1.2512562814070352
Max-min Ratio: 1.2512562814070352
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_13-29-10
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 903.0
  episode_reward_mean: 688.0125
  episode_reward_min: -16.0
  episodes_this_iter: 1
  episodes_total: 80
  experiment_id: 86e053a9c80f439496ed6b19bfe1ab59
  hostname: gpu003
  info:
    apply_time_ms: 2.638
    dispatch_time_ms: 9.663
    learner:
      cur_lr: 0.0013440160546451807
      grad_gnorm: 40.00001525878906
      policy_entropy: 26.81412124633789
      policy_loss: -6.650415897369385
      var_gnorm: 25.791810989379883
      vf_explained_var: 0.5548086166381836
      vf_loss: 14.63431167602539
    num_steps_sampled: 243000
    num_steps_trained: 243000
    wait_time_ms: 66.118
  iterations_since_restore: 81
  node_ip: 172.17.8.3
  num_metric_batches_dropped: 0
  pid: 16746
  policy_reward_mean: {}
  time_since_restore: 670.2600111961365
  time_this_iter_s: 7.709876537322998
  time_total_s: 670.2600111961365
  timestamp: 1593883750
  timesteps_since_restore: 243000
  timesteps_this_iter: 3000
  timesteps_total: 243000
  training_iteration: 81
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 29.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=16746], 670 s, 81 iter, 243000 ts, 688 rew

agent-1: 261.0
agent-2: 308.0
agent-3: 220.0
Sum Reward: 789.0
Avg Reward: 263.0
Min Reward: 220.0
Gini Coefficient: 0.07435572454583861
20:20 Ratio: 1.4
Max-min Ratio: 1.4
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_13-29-18
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 903.0
  episode_reward_mean: 689.2592592592592
  episode_reward_min: -16.0
  episodes_this_iter: 1
  episodes_total: 81
  experiment_id: 86e053a9c80f439496ed6b19bfe1ab59
  hostname: gpu003
  info:
    apply_time_ms: 2.449
    dispatch_time_ms: 7.119
    learner:
      cur_lr: 0.0013438161695376039
      grad_gnorm: 40.000003814697266
      policy_entropy: 19.546724319458008
      policy_loss: 40.0244255065918
      var_gnorm: 25.85580062866211
      vf_explained_var: -0.7937535047531128
      vf_loss: 66.06613159179688
    num_steps_sampled: 246000
    num_steps_trained: 246000
    wait_time_ms: 69.708
  iterations_since_restore: 82
  node_ip: 172.17.8.3
  num_metric_batches_dropped: 0
  pid: 16746
  policy_reward_mean: {}
  time_since_restore: 678.2633428573608
  time_this_iter_s: 8.003331661224365
  time_total_s: 678.2633428573608
  timestamp: 1593883758
  timesteps_since_restore: 246000
  timesteps_this_iter: 3000
  timesteps_total: 246000
  training_iteration: 82
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 29.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=16746], 678 s, 82 iter, 246000 ts, 689 rew

agent-1: 163.0
agent-2: 255.0
agent-3: 240.0
Sum Reward: 658.0
Avg Reward: 219.33333333333334
Min Reward: 163.0
Gini Coefficient: 0.09321175278622088
20:20 Ratio: 1.5644171779141105
Max-min Ratio: 1.5644171779141105
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_13-29-27
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 903.0
  episode_reward_mean: 688.8780487804878
  episode_reward_min: -16.0
  episodes_this_iter: 1
  episodes_total: 82
  experiment_id: 86e053a9c80f439496ed6b19bfe1ab59
  hostname: gpu003
  info:
    apply_time_ms: 2.932
    dispatch_time_ms: 9.516
    learner:
      cur_lr: 0.0013436164008453488
      grad_gnorm: 39.999996185302734
      policy_entropy: 30.10063934326172
      policy_loss: -52.10401153564453
      var_gnorm: 25.8853759765625
      vf_explained_var: -0.3241318464279175
      vf_loss: 63.54931640625
    num_steps_sampled: 249000
    num_steps_trained: 249000
    wait_time_ms: 67.156
  iterations_since_restore: 83
  node_ip: 172.17.8.3
  num_metric_batches_dropped: 0
  pid: 16746
  policy_reward_mean: {}
  time_since_restore: 686.3622300624847
  time_this_iter_s: 8.098887205123901
  time_total_s: 686.3622300624847
  timestamp: 1593883767
  timesteps_since_restore: 249000
  timesteps_this_iter: 3000
  timesteps_total: 249000
  training_iteration: 83
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 29.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=16746], 686 s, 83 iter, 249000 ts, 689 rew

agent-1: 251.0
agent-2: 269.0
agent-3: 216.0
Sum Reward: 736.0
Avg Reward: 245.33333333333334
Min Reward: 216.0
Gini Coefficient: 0.04800724637681159
20:20 Ratio: 1.2453703703703705
Max-min Ratio: 1.2453703703703705
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_13-29-35
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 903.0
  episode_reward_mean: 689.4457831325301
  episode_reward_min: -16.0
  episodes_this_iter: 1
  episodes_total: 83
  experiment_id: 86e053a9c80f439496ed6b19bfe1ab59
  hostname: gpu003
  info:
    apply_time_ms: 4.172
    dispatch_time_ms: 7.283
    learner:
      cur_lr: 0.0013434166321530938
      grad_gnorm: 40.0
      policy_entropy: 31.788753509521484
      policy_loss: -37.424888610839844
      var_gnorm: 25.882091522216797
      vf_explained_var: 0.4780341386795044
      vf_loss: 26.75336265563965
    num_steps_sampled: 252000
    num_steps_trained: 252000
    wait_time_ms: 66.516
  iterations_since_restore: 84
  node_ip: 172.17.8.3
  num_metric_batches_dropped: 0
  pid: 16746
  policy_reward_mean: {}
  time_since_restore: 694.3403940200806
  time_this_iter_s: 7.978163957595825
  time_total_s: 694.3403940200806
  timestamp: 1593883775
  timesteps_since_restore: 252000
  timesteps_this_iter: 3000
  timesteps_total: 252000
  training_iteration: 84
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 29.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=16746], 694 s, 84 iter, 252000 ts, 689 rew

agent-1: 219.0
agent-2: 237.0
agent-3: 230.0
Sum Reward: 686.0
Avg Reward: 228.66666666666666
Min Reward: 219.0
Gini Coefficient: 0.01749271137026239
20:20 Ratio: 1.082191780821918
Max-min Ratio: 1.082191780821918
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_13-29-43
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 903.0
  episode_reward_mean: 689.4047619047619
  episode_reward_min: -16.0
  episodes_this_iter: 1
  episodes_total: 84
  experiment_id: 86e053a9c80f439496ed6b19bfe1ab59
  hostname: gpu003
  info:
    apply_time_ms: 3.01
    dispatch_time_ms: 6.972
    learner:
      cur_lr: 0.001343216747045517
      grad_gnorm: 39.999996185302734
      policy_entropy: 26.038211822509766
      policy_loss: 13.373434066772461
      var_gnorm: 25.95694351196289
      vf_explained_var: 0.38523614406585693
      vf_loss: 8.318260192871094
    num_steps_sampled: 255000
    num_steps_trained: 255000
    wait_time_ms: 71.237
  iterations_since_restore: 85
  node_ip: 172.17.8.3
  num_metric_batches_dropped: 0
  pid: 16746
  policy_reward_mean: {}
  time_since_restore: 702.2074711322784
  time_this_iter_s: 7.867077112197876
  time_total_s: 702.2074711322784
  timestamp: 1593883783
  timesteps_since_restore: 255000
  timesteps_this_iter: 3000
  timesteps_total: 255000
  training_iteration: 85
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=16746], 702 s, 85 iter, 255000 ts, 689 rew

agent-1: 238.0
agent-2: 262.0
agent-3: 215.0
Sum Reward: 715.0
Avg Reward: 238.33333333333334
Min Reward: 215.0
Gini Coefficient: 0.04382284382284382
20:20 Ratio: 1.2186046511627906
Max-min Ratio: 1.2186046511627906
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_13-29-50
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 903.0
  episode_reward_mean: 689.7058823529412
  episode_reward_min: -16.0
  episodes_this_iter: 1
  episodes_total: 85
  experiment_id: 86e053a9c80f439496ed6b19bfe1ab59
  hostname: gpu003
  info:
    apply_time_ms: 3.662
    dispatch_time_ms: 11.055
    learner:
      cur_lr: 0.001343016978353262
      grad_gnorm: 40.0
      policy_entropy: 17.996295928955078
      policy_loss: 17.110727310180664
      var_gnorm: 26.052570343017578
      vf_explained_var: 0.48205453157424927
      vf_loss: 36.8140983581543
    num_steps_sampled: 258000
    num_steps_trained: 258000
    wait_time_ms: 62.735
  iterations_since_restore: 86
  node_ip: 172.17.8.3
  num_metric_batches_dropped: 0
  pid: 16746
  policy_reward_mean: {}
  time_since_restore: 709.8225049972534
  time_this_iter_s: 7.615033864974976
  time_total_s: 709.8225049972534
  timestamp: 1593883790
  timesteps_since_restore: 258000
  timesteps_this_iter: 3000
  timesteps_total: 258000
  training_iteration: 86
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=16746], 709 s, 86 iter, 258000 ts, 690 rew

agent-1: 257.0
agent-2: 280.0
agent-3: 288.0
Sum Reward: 825.0
Avg Reward: 275.0
Min Reward: 257.0
Gini Coefficient: 0.025050505050505052
20:20 Ratio: 1.1206225680933852
Max-min Ratio: 1.1206225680933852
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_13-29-58
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 903.0
  episode_reward_mean: 691.2790697674419
  episode_reward_min: -16.0
  episodes_this_iter: 1
  episodes_total: 86
  experiment_id: 86e053a9c80f439496ed6b19bfe1ab59
  hostname: gpu003
  info:
    apply_time_ms: 3.411
    dispatch_time_ms: 11.127
    learner:
      cur_lr: 0.001342817209661007
      grad_gnorm: 39.999996185302734
      policy_entropy: 7.855477333068848
      policy_loss: -2.9758477210998535
      var_gnorm: 26.10787010192871
      vf_explained_var: 0.12305903434753418
      vf_loss: 29.729007720947266
    num_steps_sampled: 261000
    num_steps_trained: 261000
    wait_time_ms: 65.668
  iterations_since_restore: 87
  node_ip: 172.17.8.3
  num_metric_batches_dropped: 0
  pid: 16746
  policy_reward_mean: {}
  time_since_restore: 717.6435687541962
  time_this_iter_s: 7.821063756942749
  time_total_s: 717.6435687541962
  timestamp: 1593883798
  timesteps_since_restore: 261000
  timesteps_this_iter: 3000
  timesteps_total: 261000
  training_iteration: 87
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.3/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=16746], 717 s, 87 iter, 261000 ts, 691 rew

agent-1: 266.0
agent-2: 253.0
agent-3: 260.0
Sum Reward: 779.0
Avg Reward: 259.6666666666667
Min Reward: 253.0
Gini Coefficient: 0.011125374411638854
20:20 Ratio: 1.051383399209486
Max-min Ratio: 1.051383399209486
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_13-30-06
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 903.0
  episode_reward_mean: 692.2873563218391
  episode_reward_min: -16.0
  episodes_this_iter: 1
  episodes_total: 87
  experiment_id: 86e053a9c80f439496ed6b19bfe1ab59
  hostname: gpu003
  info:
    apply_time_ms: 2.896
    dispatch_time_ms: 8.812
    learner:
      cur_lr: 0.001342617440968752
      grad_gnorm: 40.000003814697266
      policy_entropy: 9.602558135986328
      policy_loss: 0.235536128282547
      var_gnorm: 26.19049644470215
      vf_explained_var: 0.5985387563705444
      vf_loss: 3.416862964630127
    num_steps_sampled: 264000
    num_steps_trained: 264000
    wait_time_ms: 64.884
  iterations_since_restore: 88
  node_ip: 172.17.8.3
  num_metric_batches_dropped: 0
  pid: 16746
  policy_reward_mean: {}
  time_since_restore: 725.6015439033508
  time_this_iter_s: 7.957975149154663
  time_total_s: 725.6015439033508
  timestamp: 1593883806
  timesteps_since_restore: 264000
  timesteps_this_iter: 3000
  timesteps_total: 264000
  training_iteration: 88
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=16746], 725 s, 88 iter, 264000 ts, 692 rew

agent-1: 274.0
agent-2: 300.0
agent-3: 246.0
Sum Reward: 820.0
Avg Reward: 273.3333333333333
Min Reward: 246.0
Gini Coefficient: 0.04390243902439024
20:20 Ratio: 1.2195121951219512
Max-min Ratio: 1.2195121951219512
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_13-30-14
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 903.0
  episode_reward_mean: 693.7386363636364
  episode_reward_min: -16.0
  episodes_this_iter: 1
  episodes_total: 88
  experiment_id: 86e053a9c80f439496ed6b19bfe1ab59
  hostname: gpu003
  info:
    apply_time_ms: 2.934
    dispatch_time_ms: 6.4
    learner:
      cur_lr: 0.001342417555861175
      grad_gnorm: 40.000003814697266
      policy_entropy: 8.507973670959473
      policy_loss: 3.8458595275878906
      var_gnorm: 26.230770111083984
      vf_explained_var: -0.10947954654693604
      vf_loss: 14.462124824523926
    num_steps_sampled: 267000
    num_steps_trained: 267000
    wait_time_ms: 66.919
  iterations_since_restore: 89
  node_ip: 172.17.8.3
  num_metric_batches_dropped: 0
  pid: 16746
  policy_reward_mean: {}
  time_since_restore: 733.3707156181335
  time_this_iter_s: 7.769171714782715
  time_total_s: 733.3707156181335
  timestamp: 1593883814
  timesteps_since_restore: 267000
  timesteps_this_iter: 3000
  timesteps_total: 267000
  training_iteration: 89
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=16746], 733 s, 89 iter, 267000 ts, 694 rew

agent-1: 269.0
agent-2: 318.0
agent-3: 266.0
Sum Reward: 853.0
Avg Reward: 284.3333333333333
Min Reward: 266.0
Gini Coefficient: 0.04064087534193044
20:20 Ratio: 1.1954887218045114
Max-min Ratio: 1.1954887218045114
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_13-30-22
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 903.0
  episode_reward_mean: 695.5280898876405
  episode_reward_min: -16.0
  episodes_this_iter: 1
  episodes_total: 89
  experiment_id: 86e053a9c80f439496ed6b19bfe1ab59
  hostname: gpu003
  info:
    apply_time_ms: 2.855
    dispatch_time_ms: 7.372
    learner:
      cur_lr: 0.00134221778716892
      grad_gnorm: 38.701904296875
      policy_entropy: 9.676037788391113
      policy_loss: -5.922446250915527
      var_gnorm: 26.321788787841797
      vf_explained_var: 0.23696523904800415
      vf_loss: 24.728914260864258
    num_steps_sampled: 270000
    num_steps_trained: 270000
    wait_time_ms: 66.702
  iterations_since_restore: 90
  node_ip: 172.17.8.3
  num_metric_batches_dropped: 0
  pid: 16746
  policy_reward_mean: {}
  time_since_restore: 741.3678333759308
  time_this_iter_s: 7.997117757797241
  time_total_s: 741.3678333759308
  timestamp: 1593883822
  timesteps_since_restore: 270000
  timesteps_this_iter: 3000
  timesteps_total: 270000
  training_iteration: 90
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=16746], 741 s, 90 iter, 270000 ts, 696 rew

agent-1: 286.0
agent-2: 288.0
agent-3: 284.0
Sum Reward: 858.0
Avg Reward: 286.0
Min Reward: 284.0
Gini Coefficient: 0.003108003108003108
20:20 Ratio: 1.0140845070422535
Max-min Ratio: 1.0140845070422535
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_13-30-30
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 903.0
  episode_reward_mean: 697.3333333333334
  episode_reward_min: -16.0
  episodes_this_iter: 1
  episodes_total: 90
  experiment_id: 86e053a9c80f439496ed6b19bfe1ab59
  hostname: gpu003
  info:
    apply_time_ms: 3.163
    dispatch_time_ms: 10.494
    learner:
      cur_lr: 0.001342018018476665
      grad_gnorm: 40.000003814697266
      policy_entropy: 10.315566062927246
      policy_loss: 15.378432273864746
      var_gnorm: 26.35140609741211
      vf_explained_var: -0.1130295991897583
      vf_loss: 26.2544002532959
    num_steps_sampled: 273000
    num_steps_trained: 273000
    wait_time_ms: 68.341
  iterations_since_restore: 91
  node_ip: 172.17.8.3
  num_metric_batches_dropped: 0
  pid: 16746
  policy_reward_mean: {}
  time_since_restore: 749.4428038597107
  time_this_iter_s: 8.074970483779907
  time_total_s: 749.4428038597107
  timestamp: 1593883830
  timesteps_since_restore: 273000
  timesteps_this_iter: 3000
  timesteps_total: 273000
  training_iteration: 91
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=16746], 749 s, 91 iter, 273000 ts, 697 rew

agent-1: 301.0
agent-2: 298.0
agent-3: 288.0
Sum Reward: 887.0
Avg Reward: 295.6666666666667
Min Reward: 288.0
Gini Coefficient: 0.00977076287110109
20:20 Ratio: 1.0451388888888888
Max-min Ratio: 1.0451388888888888
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_13-30-38
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 903.0
  episode_reward_mean: 699.4175824175824
  episode_reward_min: -16.0
  episodes_this_iter: 1
  episodes_total: 91
  experiment_id: 86e053a9c80f439496ed6b19bfe1ab59
  hostname: gpu003
  info:
    apply_time_ms: 3.099
    dispatch_time_ms: 8.328
    learner:
      cur_lr: 0.00134181824978441
      grad_gnorm: 29.547143936157227
      policy_entropy: 16.383256912231445
      policy_loss: 2.315680980682373
      var_gnorm: 26.396425247192383
      vf_explained_var: 0.6255965828895569
      vf_loss: 14.644668579101562
    num_steps_sampled: 276000
    num_steps_trained: 276000
    wait_time_ms: 69.764
  iterations_since_restore: 92
  node_ip: 172.17.8.3
  num_metric_batches_dropped: 0
  pid: 16746
  policy_reward_mean: {}
  time_since_restore: 757.6756670475006
  time_this_iter_s: 8.232863187789917
  time_total_s: 757.6756670475006
  timestamp: 1593883838
  timesteps_since_restore: 276000
  timesteps_this_iter: 3000
  timesteps_total: 276000
  training_iteration: 92
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=16746], 757 s, 92 iter, 276000 ts, 699 rew

agent-1: 227.0
agent-2: 246.0
agent-3: 263.0
Sum Reward: 736.0
Avg Reward: 245.33333333333334
Min Reward: 227.0
Gini Coefficient: 0.03260869565217391
20:20 Ratio: 1.158590308370044
Max-min Ratio: 1.158590308370044
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_13-30-47
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 903.0
  episode_reward_mean: 699.8152173913044
  episode_reward_min: -16.0
  episodes_this_iter: 1
  episodes_total: 92
  experiment_id: 86e053a9c80f439496ed6b19bfe1ab59
  hostname: gpu003
  info:
    apply_time_ms: 2.886
    dispatch_time_ms: 11.549
    learner:
      cur_lr: 0.0013416183646768332
      grad_gnorm: 19.84220314025879
      policy_entropy: 12.065712928771973
      policy_loss: -2.4678266048431396
      var_gnorm: 26.451351165771484
      vf_explained_var: 0.6780108213424683
      vf_loss: 7.275924205780029
    num_steps_sampled: 279000
    num_steps_trained: 279000
    wait_time_ms: 65.425
  iterations_since_restore: 93
  node_ip: 172.17.8.3
  num_metric_batches_dropped: 0
  pid: 16746
  policy_reward_mean: {}
  time_since_restore: 765.8976011276245
  time_this_iter_s: 8.221934080123901
  time_total_s: 765.8976011276245
  timestamp: 1593883847
  timesteps_since_restore: 279000
  timesteps_this_iter: 3000
  timesteps_total: 279000
  training_iteration: 93
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=16746], 765 s, 93 iter, 279000 ts, 700 rew

agent-1: 257.0
agent-2: 246.0
agent-3: 231.0
Sum Reward: 734.0
Avg Reward: 244.66666666666666
Min Reward: 231.0
Gini Coefficient: 0.023614895549500452
20:20 Ratio: 1.1125541125541125
Max-min Ratio: 1.1125541125541125
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_13-30-55
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 903.0
  episode_reward_mean: 700.1827956989247
  episode_reward_min: -16.0
  episodes_this_iter: 1
  episodes_total: 93
  experiment_id: 86e053a9c80f439496ed6b19bfe1ab59
  hostname: gpu003
  info:
    apply_time_ms: 2.78
    dispatch_time_ms: 8.646
    learner:
      cur_lr: 0.0013414185959845781
      grad_gnorm: 40.00001907348633
      policy_entropy: 8.199172019958496
      policy_loss: 1.4348628520965576
      var_gnorm: 26.493995666503906
      vf_explained_var: 0.2817363739013672
      vf_loss: 4.058067321777344
    num_steps_sampled: 282000
    num_steps_trained: 282000
    wait_time_ms: 70.504
  iterations_since_restore: 94
  node_ip: 172.17.8.3
  num_metric_batches_dropped: 0
  pid: 16746
  policy_reward_mean: {}
  time_since_restore: 773.9928636550903
  time_this_iter_s: 8.09526252746582
  time_total_s: 773.9928636550903
  timestamp: 1593883855
  timesteps_since_restore: 282000
  timesteps_this_iter: 3000
  timesteps_total: 282000
  training_iteration: 94
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.3/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=16746], 773 s, 94 iter, 282000 ts, 700 rew

agent-1: 292.0
agent-2: 257.0
agent-3: 280.0
Sum Reward: 829.0
Avg Reward: 276.3333333333333
Min Reward: 257.0
Gini Coefficient: 0.02814636107760354
20:20 Ratio: 1.1361867704280155
Max-min Ratio: 1.1361867704280155
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_13-31-03
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 903.0
  episode_reward_mean: 701.5531914893617
  episode_reward_min: -16.0
  episodes_this_iter: 1
  episodes_total: 94
  experiment_id: 86e053a9c80f439496ed6b19bfe1ab59
  hostname: gpu003
  info:
    apply_time_ms: 2.822
    dispatch_time_ms: 10.745
    learner:
      cur_lr: 0.0013412188272923231
      grad_gnorm: 39.99999237060547
      policy_entropy: 16.895530700683594
      policy_loss: -4.999971389770508
      var_gnorm: 26.631040573120117
      vf_explained_var: 0.5133389234542847
      vf_loss: 14.002567291259766
    num_steps_sampled: 285000
    num_steps_trained: 285000
    wait_time_ms: 68.671
  iterations_since_restore: 95
  node_ip: 172.17.8.3
  num_metric_batches_dropped: 0
  pid: 16746
  policy_reward_mean: {}
  time_since_restore: 782.2185609340668
  time_this_iter_s: 8.22569727897644
  time_total_s: 782.2185609340668
  timestamp: 1593883863
  timesteps_since_restore: 285000
  timesteps_this_iter: 3000
  timesteps_total: 285000
  training_iteration: 95
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=16746], 782 s, 95 iter, 285000 ts, 702 rew

agent-1: 318.0
agent-2: 265.0
agent-3: 316.0
Sum Reward: 899.0
Avg Reward: 299.6666666666667
Min Reward: 265.0
Gini Coefficient: 0.039302929180571
20:20 Ratio: 1.2
Max-min Ratio: 1.2
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_13-31-11
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 903.0
  episode_reward_mean: 703.6315789473684
  episode_reward_min: -16.0
  episodes_this_iter: 1
  episodes_total: 95
  experiment_id: 86e053a9c80f439496ed6b19bfe1ab59
  hostname: gpu003
  info:
    apply_time_ms: 4.013
    dispatch_time_ms: 9.719
    learner:
      cur_lr: 0.0013410189421847463
      grad_gnorm: 37.51815414428711
      policy_entropy: 13.949249267578125
      policy_loss: -11.357904434204102
      var_gnorm: 26.71384048461914
      vf_explained_var: 0.09496104717254639
      vf_loss: 11.859460830688477
    num_steps_sampled: 288000
    num_steps_trained: 288000
    wait_time_ms: 70.558
  iterations_since_restore: 96
  node_ip: 172.17.8.3
  num_metric_batches_dropped: 0
  pid: 16746
  policy_reward_mean: {}
  time_since_restore: 790.4357554912567
  time_this_iter_s: 8.217194557189941
  time_total_s: 790.4357554912567
  timestamp: 1593883871
  timesteps_since_restore: 288000
  timesteps_this_iter: 3000
  timesteps_total: 288000
  training_iteration: 96
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=16746], 790 s, 96 iter, 288000 ts, 704 rew

agent-1: 254.0
agent-2: 257.0
agent-3: 248.0
Sum Reward: 759.0
Avg Reward: 253.0
Min Reward: 248.0
Gini Coefficient: 0.007905138339920948
20:20 Ratio: 1.0362903225806452
Max-min Ratio: 1.0362903225806452
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_13-31-20
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 903.0
  episode_reward_mean: 704.2083333333334
  episode_reward_min: -16.0
  episodes_this_iter: 1
  episodes_total: 96
  experiment_id: 86e053a9c80f439496ed6b19bfe1ab59
  hostname: gpu003
  info:
    apply_time_ms: 3.967
    dispatch_time_ms: 6.533
    learner:
      cur_lr: 0.0013408191734924912
      grad_gnorm: 39.999996185302734
      policy_entropy: 16.737899780273438
      policy_loss: 13.877225875854492
      var_gnorm: 26.77947425842285
      vf_explained_var: -0.1078791618347168
      vf_loss: 25.019315719604492
    num_steps_sampled: 291000
    num_steps_trained: 291000
    wait_time_ms: 75.417
  iterations_since_restore: 97
  node_ip: 172.17.8.3
  num_metric_batches_dropped: 0
  pid: 16746
  policy_reward_mean: {}
  time_since_restore: 798.7863094806671
  time_this_iter_s: 8.3505539894104
  time_total_s: 798.7863094806671
  timestamp: 1593883880
  timesteps_since_restore: 291000
  timesteps_this_iter: 3000
  timesteps_total: 291000
  training_iteration: 97
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=16746], 798 s, 97 iter, 291000 ts, 704 rew

agent-1: 258.0
agent-2: 221.0
agent-3: 260.0
Sum Reward: 739.0
Avg Reward: 246.33333333333334
Min Reward: 221.0
Gini Coefficient: 0.035182679296346414
20:20 Ratio: 1.1764705882352942
Max-min Ratio: 1.1764705882352942
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_13-31-28
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 903.0
  episode_reward_mean: 704.5670103092783
  episode_reward_min: -16.0
  episodes_this_iter: 1
  episodes_total: 97
  experiment_id: 86e053a9c80f439496ed6b19bfe1ab59
  hostname: gpu003
  info:
    apply_time_ms: 2.767
    dispatch_time_ms: 6.749
    learner:
      cur_lr: 0.0013406194048002362
      grad_gnorm: 35.57467269897461
      policy_entropy: 7.900203227996826
      policy_loss: 8.10439395904541
      var_gnorm: 26.90614128112793
      vf_explained_var: 0.5365577936172485
      vf_loss: 14.973797798156738
    num_steps_sampled: 294000
    num_steps_trained: 294000
    wait_time_ms: 73.215
  iterations_since_restore: 98
  node_ip: 172.17.8.3
  num_metric_batches_dropped: 0
  pid: 16746
  policy_reward_mean: {}
  time_since_restore: 807.1646778583527
  time_this_iter_s: 8.378368377685547
  time_total_s: 807.1646778583527
  timestamp: 1593883888
  timesteps_since_restore: 294000
  timesteps_this_iter: 3000
  timesteps_total: 294000
  training_iteration: 98
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=16746], 807 s, 98 iter, 294000 ts, 705 rew

agent-1: 321.0
agent-2: 250.0
agent-3: 273.0
Sum Reward: 844.0
Avg Reward: 281.3333333333333
Min Reward: 250.0
Gini Coefficient: 0.05608214849921011
20:20 Ratio: 1.284
Max-min Ratio: 1.284
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_13-31-36
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 903.0
  episode_reward_mean: 705.9897959183673
  episode_reward_min: -16.0
  episodes_this_iter: 1
  episodes_total: 98
  experiment_id: 86e053a9c80f439496ed6b19bfe1ab59
  hostname: gpu003
  info:
    apply_time_ms: 3.135
    dispatch_time_ms: 7.133
    learner:
      cur_lr: 0.0013404196361079812
      grad_gnorm: 40.000003814697266
      policy_entropy: 14.995987892150879
      policy_loss: -4.753866195678711
      var_gnorm: 27.010009765625
      vf_explained_var: 0.4277225732803345
      vf_loss: 22.505748748779297
    num_steps_sampled: 297000
    num_steps_trained: 297000
    wait_time_ms: 80.334
  iterations_since_restore: 99
  node_ip: 172.17.8.3
  num_metric_batches_dropped: 0
  pid: 16746
  policy_reward_mean: {}
  time_since_restore: 815.4031100273132
  time_this_iter_s: 8.238432168960571
  time_total_s: 815.4031100273132
  timestamp: 1593883896
  timesteps_since_restore: 297000
  timesteps_this_iter: 3000
  timesteps_total: 297000
  training_iteration: 99
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=16746], 815 s, 99 iter, 297000 ts, 706 rew

agent-1: 260.0
agent-2: 260.0
agent-3: 276.0
Sum Reward: 796.0
Avg Reward: 265.3333333333333
Min Reward: 260.0
Gini Coefficient: 0.01340033500837521
20:20 Ratio: 1.0615384615384615
Max-min Ratio: 1.0615384615384615
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_13-31-44
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 903.0
  episode_reward_mean: 706.89898989899
  episode_reward_min: -16.0
  episodes_this_iter: 1
  episodes_total: 99
  experiment_id: 86e053a9c80f439496ed6b19bfe1ab59
  hostname: gpu003
  info:
    apply_time_ms: 4.836
    dispatch_time_ms: 8.514
    learner:
      cur_lr: 0.0013402197510004044
      grad_gnorm: 40.0
      policy_entropy: 10.17802619934082
      policy_loss: -14.013148307800293
      var_gnorm: 27.109663009643555
      vf_explained_var: 0.8016549348831177
      vf_loss: 21.288999557495117
    num_steps_sampled: 300000
    num_steps_trained: 300000
    wait_time_ms: 72.185
  iterations_since_restore: 100
  node_ip: 172.17.8.3
  num_metric_batches_dropped: 0
  pid: 16746
  policy_reward_mean: {}
  time_since_restore: 823.5084600448608
  time_this_iter_s: 8.105350017547607
  time_total_s: 823.5084600448608
  timestamp: 1593883904
  timesteps_since_restore: 300000
  timesteps_this_iter: 3000
  timesteps_total: 300000
  training_iteration: 100
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=16746], 823 s, 100 iter, 300000 ts, 707 rew

agent-1: 281.0
agent-2: 254.0
agent-3: 269.0
Sum Reward: 804.0
Avg Reward: 268.0
Min Reward: 254.0
Gini Coefficient: 0.022388059701492536
20:20 Ratio: 1.1062992125984252
Max-min Ratio: 1.1062992125984252
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_13-31-52
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 903.0
  episode_reward_mean: 707.87
  episode_reward_min: -16.0
  episodes_this_iter: 1
  episodes_total: 100
  experiment_id: 86e053a9c80f439496ed6b19bfe1ab59
  hostname: gpu003
  info:
    apply_time_ms: 2.929
    dispatch_time_ms: 6.723
    learner:
      cur_lr: 0.0013400199823081493
      grad_gnorm: 40.0
      policy_entropy: 16.314443588256836
      policy_loss: 5.496583938598633
      var_gnorm: 27.171560287475586
      vf_explained_var: 0.5412899255752563
      vf_loss: 32.27435302734375
    num_steps_sampled: 303000
    num_steps_trained: 303000
    wait_time_ms: 73.696
  iterations_since_restore: 101
  node_ip: 172.17.8.3
  num_metric_batches_dropped: 0
  pid: 16746
  policy_reward_mean: {}
  time_since_restore: 831.4775896072388
  time_this_iter_s: 7.96912956237793
  time_total_s: 831.4775896072388
  timestamp: 1593883912
  timesteps_since_restore: 303000
  timesteps_this_iter: 3000
  timesteps_total: 303000
  training_iteration: 101
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.3/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=16746], 831 s, 101 iter, 303000 ts, 708 rew

agent-1: 281.0
agent-2: 282.0
agent-3: 319.0
Sum Reward: 882.0
Avg Reward: 294.0
Min Reward: 281.0
Gini Coefficient: 0.02872260015117158
20:20 Ratio: 1.1352313167259787
Max-min Ratio: 1.1352313167259787
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_13-32-00
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 903.0
  episode_reward_mean: 715.5
  episode_reward_min: -16.0
  episodes_this_iter: 1
  episodes_total: 101
  experiment_id: 86e053a9c80f439496ed6b19bfe1ab59
  hostname: gpu003
  info:
    apply_time_ms: 2.916
    dispatch_time_ms: 10.464
    learner:
      cur_lr: 0.0013398202136158943
      grad_gnorm: 40.0
      policy_entropy: 12.884319305419922
      policy_loss: 9.401315689086914
      var_gnorm: 27.191200256347656
      vf_explained_var: -0.09802985191345215
      vf_loss: 37.3512077331543
    num_steps_sampled: 306000
    num_steps_trained: 306000
    wait_time_ms: 69.619
  iterations_since_restore: 102
  node_ip: 172.17.8.3
  num_metric_batches_dropped: 0
  pid: 16746
  policy_reward_mean: {}
  time_since_restore: 839.5080027580261
  time_this_iter_s: 8.030413150787354
  time_total_s: 839.5080027580261
  timestamp: 1593883920
  timesteps_since_restore: 306000
  timesteps_this_iter: 3000
  timesteps_total: 306000
  training_iteration: 102
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=16746], 839 s, 102 iter, 306000 ts, 716 rew

agent-1: 291.0
agent-2: 316.0
agent-3: 274.0
Sum Reward: 881.0
Avg Reward: 293.6666666666667
Min Reward: 274.0
Gini Coefficient: 0.03178206583427923
20:20 Ratio: 1.1532846715328466
Max-min Ratio: 1.1532846715328466
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_13-32-09
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 903.0
  episode_reward_mean: 724.47
  episode_reward_min: 262.0
  episodes_this_iter: 1
  episodes_total: 102
  experiment_id: 86e053a9c80f439496ed6b19bfe1ab59
  hostname: gpu003
  info:
    apply_time_ms: 3.017
    dispatch_time_ms: 11.944
    learner:
      cur_lr: 0.0013396204449236393
      grad_gnorm: 40.0
      policy_entropy: 16.56410026550293
      policy_loss: 18.68229103088379
      var_gnorm: 27.322114944458008
      vf_explained_var: 0.3008774518966675
      vf_loss: 67.74826049804688
    num_steps_sampled: 309000
    num_steps_trained: 309000
    wait_time_ms: 64.64
  iterations_since_restore: 103
  node_ip: 172.17.8.3
  num_metric_batches_dropped: 0
  pid: 16746
  policy_reward_mean: {}
  time_since_restore: 847.6058592796326
  time_this_iter_s: 8.097856521606445
  time_total_s: 847.6058592796326
  timestamp: 1593883929
  timesteps_since_restore: 309000
  timesteps_this_iter: 3000
  timesteps_total: 309000
  training_iteration: 103
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=16746], 847 s, 103 iter, 309000 ts, 724 rew

agent-1: 266.0
agent-2: 177.0
agent-3: 301.0
Sum Reward: 744.0
Avg Reward: 248.0
Min Reward: 177.0
Gini Coefficient: 0.1111111111111111
20:20 Ratio: 1.7005649717514124
Max-min Ratio: 1.7005649717514124
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_13-32-17
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 903.0
  episode_reward_mean: 727.79
  episode_reward_min: 262.0
  episodes_this_iter: 1
  episodes_total: 103
  experiment_id: 86e053a9c80f439496ed6b19bfe1ab59
  hostname: gpu003
  info:
    apply_time_ms: 3.576
    dispatch_time_ms: 8.726
    learner:
      cur_lr: 0.0013394205598160625
      grad_gnorm: 39.9999885559082
      policy_entropy: 8.275453567504883
      policy_loss: 2.480240821838379
      var_gnorm: 27.345489501953125
      vf_explained_var: 0.2098185420036316
      vf_loss: 20.100505828857422
    num_steps_sampled: 312000
    num_steps_trained: 312000
    wait_time_ms: 68.223
  iterations_since_restore: 104
  node_ip: 172.17.8.3
  num_metric_batches_dropped: 0
  pid: 16746
  policy_reward_mean: {}
  time_since_restore: 855.4993371963501
  time_this_iter_s: 7.893477916717529
  time_total_s: 855.4993371963501
  timestamp: 1593883937
  timesteps_since_restore: 312000
  timesteps_this_iter: 3000
  timesteps_total: 312000
  training_iteration: 104
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=16746], 855 s, 104 iter, 312000 ts, 728 rew

agent-1: 283.0
agent-2: 300.0
agent-3: 297.0
Sum Reward: 880.0
Avg Reward: 293.3333333333333
Min Reward: 283.0
Gini Coefficient: 0.012878787878787878
20:20 Ratio: 1.0600706713780919
Max-min Ratio: 1.0600706713780919
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_13-32-25
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 903.0
  episode_reward_mean: 733.97
  episode_reward_min: 417.0
  episodes_this_iter: 1
  episodes_total: 104
  experiment_id: 86e053a9c80f439496ed6b19bfe1ab59
  hostname: gpu003
  info:
    apply_time_ms: 2.706
    dispatch_time_ms: 6.917
    learner:
      cur_lr: 0.0013392207911238074
      grad_gnorm: 35.5479850769043
      policy_entropy: 18.477205276489258
      policy_loss: 8.504465103149414
      var_gnorm: 27.428070068359375
      vf_explained_var: -0.15798485279083252
      vf_loss: 21.672969818115234
    num_steps_sampled: 315000
    num_steps_trained: 315000
    wait_time_ms: 76.197
  iterations_since_restore: 105
  node_ip: 172.17.8.3
  num_metric_batches_dropped: 0
  pid: 16746
  policy_reward_mean: {}
  time_since_restore: 863.6357626914978
  time_this_iter_s: 8.136425495147705
  time_total_s: 863.6357626914978
  timestamp: 1593883945
  timesteps_since_restore: 315000
  timesteps_this_iter: 3000
  timesteps_total: 315000
  training_iteration: 105
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=16746], 863 s, 105 iter, 315000 ts, 734 rew

agent-1: 251.0
agent-2: 220.0
agent-3: 237.0
Sum Reward: 708.0
Avg Reward: 236.0
Min Reward: 220.0
Gini Coefficient: 0.02919020715630885
20:20 Ratio: 1.1409090909090909
Max-min Ratio: 1.1409090909090909
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_13-32-33
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 903.0
  episode_reward_mean: 736.6
  episode_reward_min: 417.0
  episodes_this_iter: 1
  episodes_total: 105
  experiment_id: 86e053a9c80f439496ed6b19bfe1ab59
  hostname: gpu003
  info:
    apply_time_ms: 3.729
    dispatch_time_ms: 8.995
    learner:
      cur_lr: 0.0013390210224315524
      grad_gnorm: 39.99998474121094
      policy_entropy: 15.171313285827637
      policy_loss: -5.335063934326172
      var_gnorm: 27.492341995239258
      vf_explained_var: -0.21900534629821777
      vf_loss: 9.434600830078125
    num_steps_sampled: 318000
    num_steps_trained: 318000
    wait_time_ms: 68.34
  iterations_since_restore: 106
  node_ip: 172.17.8.3
  num_metric_batches_dropped: 0
  pid: 16746
  policy_reward_mean: {}
  time_since_restore: 871.7458782196045
  time_this_iter_s: 8.11011552810669
  time_total_s: 871.7458782196045
  timestamp: 1593883953
  timesteps_since_restore: 318000
  timesteps_this_iter: 3000
  timesteps_total: 318000
  training_iteration: 106
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 33.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=16746], 871 s, 106 iter, 318000 ts, 737 rew

agent-1: 232.0
agent-2: 280.0
agent-3: 263.0
Sum Reward: 775.0
Avg Reward: 258.3333333333333
Min Reward: 232.0
Gini Coefficient: 0.04129032258064516
20:20 Ratio: 1.206896551724138
Max-min Ratio: 1.206896551724138
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_13-32-41
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 903.0
  episode_reward_mean: 740.18
  episode_reward_min: 486.0
  episodes_this_iter: 1
  episodes_total: 106
  experiment_id: 86e053a9c80f439496ed6b19bfe1ab59
  hostname: gpu003
  info:
    apply_time_ms: 2.984
    dispatch_time_ms: 8.53
    learner:
      cur_lr: 0.0013388212537392974
      grad_gnorm: 27.36016082763672
      policy_entropy: 6.196568965911865
      policy_loss: 0.580978512763977
      var_gnorm: 27.525779724121094
      vf_explained_var: -0.2913026809692383
      vf_loss: 8.297457695007324
    num_steps_sampled: 321000
    num_steps_trained: 321000
    wait_time_ms: 72.467
  iterations_since_restore: 107
  node_ip: 172.17.8.3
  num_metric_batches_dropped: 0
  pid: 16746
  policy_reward_mean: {}
  time_since_restore: 879.876446723938
  time_this_iter_s: 8.130568504333496
  time_total_s: 879.876446723938
  timestamp: 1593883961
  timesteps_since_restore: 321000
  timesteps_this_iter: 3000
  timesteps_total: 321000
  training_iteration: 107
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 33.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=16746], 879 s, 107 iter, 321000 ts, 740 rew

agent-1: 250.0
agent-2: 269.0
agent-3: 278.0
Sum Reward: 797.0
Avg Reward: 265.6666666666667
Min Reward: 250.0
Gini Coefficient: 0.02342116269343371
20:20 Ratio: 1.112
Max-min Ratio: 1.112
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_13-32-49
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 903.0
  episode_reward_mean: 742.64
  episode_reward_min: 486.0
  episodes_this_iter: 1
  episodes_total: 107
  experiment_id: 86e053a9c80f439496ed6b19bfe1ab59
  hostname: gpu003
  info:
    apply_time_ms: 3.45
    dispatch_time_ms: 9.256
    learner:
      cur_lr: 0.0013386213686317205
      grad_gnorm: 25.772125244140625
      policy_entropy: 6.244375228881836
      policy_loss: 3.3563647270202637
      var_gnorm: 27.56793212890625
      vf_explained_var: 0.4601680040359497
      vf_loss: 21.168493270874023
    num_steps_sampled: 324000
    num_steps_trained: 324000
    wait_time_ms: 71.689
  iterations_since_restore: 108
  node_ip: 172.17.8.3
  num_metric_batches_dropped: 0
  pid: 16746
  policy_reward_mean: {}
  time_since_restore: 888.3095932006836
  time_this_iter_s: 8.433146476745605
  time_total_s: 888.3095932006836
  timestamp: 1593883969
  timesteps_since_restore: 324000
  timesteps_this_iter: 3000
  timesteps_total: 324000
  training_iteration: 108
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 33.3/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=16746], 888 s, 108 iter, 324000 ts, 743 rew

agent-1: 212.0
agent-2: 255.0
agent-3: 238.0
Sum Reward: 705.0
Avg Reward: 235.0
Min Reward: 212.0
Gini Coefficient: 0.04066193853427896
20:20 Ratio: 1.2028301886792452
Max-min Ratio: 1.2028301886792452
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_13-32-58
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 903.0
  episode_reward_mean: 744.81
  episode_reward_min: 486.0
  episodes_this_iter: 1
  episodes_total: 108
  experiment_id: 86e053a9c80f439496ed6b19bfe1ab59
  hostname: gpu003
  info:
    apply_time_ms: 2.827
    dispatch_time_ms: 11.988
    learner:
      cur_lr: 0.0013384215999394655
      grad_gnorm: 40.0
      policy_entropy: 16.189598083496094
      policy_loss: -18.890670776367188
      var_gnorm: 27.695194244384766
      vf_explained_var: -0.23889172077178955
      vf_loss: 18.12179183959961
    num_steps_sampled: 327000
    num_steps_trained: 327000
    wait_time_ms: 55.806
  iterations_since_restore: 109
  node_ip: 172.17.8.3
  num_metric_batches_dropped: 0
  pid: 16746
  policy_reward_mean: {}
  time_since_restore: 896.388486623764
  time_this_iter_s: 8.078893423080444
  time_total_s: 896.388486623764
  timestamp: 1593883978
  timesteps_since_restore: 327000
  timesteps_this_iter: 3000
  timesteps_total: 327000
  training_iteration: 109
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 33.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=16746], 896 s, 109 iter, 327000 ts, 745 rew

agent-1: 242.0
agent-2: 246.0
agent-3: 230.0
Sum Reward: 718.0
Avg Reward: 239.33333333333334
Min Reward: 230.0
Gini Coefficient: 0.014856081708449397
20:20 Ratio: 1.0695652173913044
Max-min Ratio: 1.0695652173913044
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_13-33-05
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 903.0
  episode_reward_mean: 746.79
  episode_reward_min: 486.0
  episodes_this_iter: 1
  episodes_total: 109
  experiment_id: 86e053a9c80f439496ed6b19bfe1ab59
  hostname: gpu003
  info:
    apply_time_ms: 3.524
    dispatch_time_ms: 8.412
    learner:
      cur_lr: 0.0013382218312472105
      grad_gnorm: 40.0
      policy_entropy: 10.485258102416992
      policy_loss: 17.10042953491211
      var_gnorm: 27.71368408203125
      vf_explained_var: -0.6821941137313843
      vf_loss: 115.11685180664062
    num_steps_sampled: 330000
    num_steps_trained: 330000
    wait_time_ms: 60.132
  iterations_since_restore: 110
  node_ip: 172.17.8.3
  num_metric_batches_dropped: 0
  pid: 16746
  policy_reward_mean: {}
  time_since_restore: 903.6864049434662
  time_this_iter_s: 7.297918319702148
  time_total_s: 903.6864049434662
  timestamp: 1593883985
  timesteps_since_restore: 330000
  timesteps_this_iter: 3000
  timesteps_total: 330000
  training_iteration: 110
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 33.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=16746], 903 s, 110 iter, 330000 ts, 747 rew

agent-1: 169.0
agent-2: 230.0
agent-3: 162.0
Sum Reward: 561.0
Avg Reward: 187.0
Min Reward: 162.0
Gini Coefficient: 0.08080808080808081
20:20 Ratio: 1.4197530864197532
Max-min Ratio: 1.4197530864197532
W0704 13:33:22.179785 16738 node_manager.cc:250] Last heartbeat was sent 7577 ms ago 
W0704 13:33:47.517356 16738 node_manager.cc:250] Last heartbeat was sent 15270 ms ago 
W0704 13:33:49.114341 16738 node_manager.cc:250] Last heartbeat was sent 1392 ms ago 
W0704 13:33:52.604866 16738 node_manager.cc:250] Last heartbeat was sent 1830 ms ago 
W0704 13:33:57.065562 16738 node_manager.cc:250] Last heartbeat was sent 784 ms ago 
W0704 13:33:58.241605 16738 node_manager.cc:250] Last heartbeat was sent 532 ms ago 
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_13-34-04
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 903.0
  episode_reward_mean: 747.54
  episode_reward_min: 550.0
  episodes_this_iter: 1
  episodes_total: 110
  experiment_id: 86e053a9c80f439496ed6b19bfe1ab59
  hostname: gpu003
  info:
    apply_time_ms: 36.984
    dispatch_time_ms: 85.07
    learner:
      cur_lr: 0.0013380219461396337
      grad_gnorm: 28.493484497070312
      policy_entropy: 14.826977729797363
      policy_loss: -8.609755516052246
      var_gnorm: 27.69599151611328
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 7.668297290802002
    num_steps_sampled: 333000
    num_steps_trained: 333000
    wait_time_ms: 939.475
  iterations_since_restore: 111
  node_ip: 172.17.8.3
  num_metric_batches_dropped: 0
  pid: 16746
  policy_reward_mean: {}
  time_since_restore: 962.9440460205078
  time_this_iter_s: 59.257641077041626
  time_total_s: 962.9440460205078
  timestamp: 1593884044
  timesteps_since_restore: 333000
  timesteps_this_iter: 3000
  timesteps_total: 333000
  training_iteration: 111
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=16746], 962 s, 111 iter, 333000 ts, 748 rew

agent-1: 169.0
agent-2: 153.0
agent-3: 127.0
Sum Reward: 449.0
Avg Reward: 149.66666666666666
Min Reward: 127.0
Gini Coefficient: 0.062360801781737196
20:20 Ratio: 1.330708661417323
Max-min Ratio: 1.330708661417323
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_13-34-29
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 903.0
  episode_reward_mean: 745.71
  episode_reward_min: 449.0
  episodes_this_iter: 1
  episodes_total: 111
  experiment_id: 86e053a9c80f439496ed6b19bfe1ab59
  hostname: gpu003
  info:
    apply_time_ms: 5.012
    dispatch_time_ms: 14.148
    learner:
      cur_lr: 0.0013378221774473786
      grad_gnorm: 20.09491729736328
      policy_entropy: 8.732826232910156
      policy_loss: 0.6154951453208923
      var_gnorm: 27.71965980529785
      vf_explained_var: 0.3587249517440796
      vf_loss: 18.039226531982422
    num_steps_sampled: 336000
    num_steps_trained: 336000
    wait_time_ms: 57.805
  iterations_since_restore: 112
  node_ip: 172.17.8.3
  num_metric_batches_dropped: 0
  pid: 16746
  policy_reward_mean: {}
  time_since_restore: 980.6594824790955
  time_this_iter_s: 17.715436458587646
  time_total_s: 980.6594824790955
  timestamp: 1593884069
  timesteps_since_restore: 336000
  timesteps_this_iter: 3000
  timesteps_total: 336000
  training_iteration: 112
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=16746], 980 s, 112 iter, 336000 ts, 746 rew

agent-1: 169.0
agent-2: 216.0
agent-3: 209.0
Sum Reward: 594.0
Avg Reward: 198.0
Min Reward: 169.0
Gini Coefficient: 0.052749719416386086
20:20 Ratio: 1.2781065088757397
Max-min Ratio: 1.2781065088757397
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_13-34-37
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 903.0
  episode_reward_mean: 745.29
  episode_reward_min: 449.0
  episodes_this_iter: 1
  episodes_total: 112
  experiment_id: 86e053a9c80f439496ed6b19bfe1ab59
  hostname: gpu003
  info:
    apply_time_ms: 2.875
    dispatch_time_ms: 7.532
    learner:
      cur_lr: 0.0013376224087551236
      grad_gnorm: 13.319647789001465
      policy_entropy: 3.9685428142547607
      policy_loss: 1.407555341720581
      var_gnorm: 27.730817794799805
      vf_explained_var: -0.09867489337921143
      vf_loss: 23.91414451599121
    num_steps_sampled: 339000
    num_steps_trained: 339000
    wait_time_ms: 71.007
  iterations_since_restore: 113
  node_ip: 172.17.8.3
  num_metric_batches_dropped: 0
  pid: 16746
  policy_reward_mean: {}
  time_since_restore: 988.0306165218353
  time_this_iter_s: 7.371134042739868
  time_total_s: 988.0306165218353
  timestamp: 1593884077
  timesteps_since_restore: 339000
  timesteps_this_iter: 3000
  timesteps_total: 339000
  training_iteration: 113
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=16746], 988 s, 113 iter, 339000 ts, 745 rew

agent-1: 215.0
agent-2: 239.0
agent-3: 269.0
Sum Reward: 723.0
Avg Reward: 241.0
Min Reward: 215.0
Gini Coefficient: 0.04979253112033195
20:20 Ratio: 1.2511627906976743
Max-min Ratio: 1.2511627906976743
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_13-34-45
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 903.0
  episode_reward_mean: 747.02
  episode_reward_min: 449.0
  episodes_this_iter: 1
  episodes_total: 113
  experiment_id: 86e053a9c80f439496ed6b19bfe1ab59
  hostname: gpu003
  info:
    apply_time_ms: 2.779
    dispatch_time_ms: 6.478
    learner:
      cur_lr: 0.0013374226400628686
      grad_gnorm: 40.000003814697266
      policy_entropy: 3.58097767829895
      policy_loss: -0.5864795446395874
      var_gnorm: 27.794193267822266
      vf_explained_var: -0.27251553535461426
      vf_loss: 22.646745681762695
    num_steps_sampled: 342000
    num_steps_trained: 342000
    wait_time_ms: 69.113
  iterations_since_restore: 114
  node_ip: 172.17.8.3
  num_metric_batches_dropped: 0
  pid: 16746
  policy_reward_mean: {}
  time_since_restore: 995.8753349781036
  time_this_iter_s: 7.8447184562683105
  time_total_s: 995.8753349781036
  timestamp: 1593884085
  timesteps_since_restore: 342000
  timesteps_this_iter: 3000
  timesteps_total: 342000
  training_iteration: 114
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 33.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=16746], 995 s, 114 iter, 342000 ts, 747 rew

agent-1: 292.0
agent-2: 306.0
agent-3: 287.0
Sum Reward: 885.0
Avg Reward: 295.0
Min Reward: 287.0
Gini Coefficient: 0.01431261770244821
20:20 Ratio: 1.0662020905923344
Max-min Ratio: 1.0662020905923344
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_13-34-53
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 903.0
  episode_reward_mean: 750.16
  episode_reward_min: 449.0
  episodes_this_iter: 1
  episodes_total: 114
  experiment_id: 86e053a9c80f439496ed6b19bfe1ab59
  hostname: gpu003
  info:
    apply_time_ms: 4.061
    dispatch_time_ms: 8.977
    learner:
      cur_lr: 0.0013372227549552917
      grad_gnorm: 40.000003814697266
      policy_entropy: 6.840198516845703
      policy_loss: 0.8709936738014221
      var_gnorm: 27.88336944580078
      vf_explained_var: 0.44881337881088257
      vf_loss: 64.09690856933594
    num_steps_sampled: 345000
    num_steps_trained: 345000
    wait_time_ms: 61.889
  iterations_since_restore: 115
  node_ip: 172.17.8.3
  num_metric_batches_dropped: 0
  pid: 16746
  policy_reward_mean: {}
  time_since_restore: 1003.8605060577393
  time_this_iter_s: 7.98517107963562
  time_total_s: 1003.8605060577393
  timestamp: 1593884093
  timesteps_since_restore: 345000
  timesteps_this_iter: 3000
  timesteps_total: 345000
  training_iteration: 115
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 33.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=16746], 1003 s, 115 iter, 345000 ts, 750 rew

agent-1: 276.0
agent-2: 293.0
agent-3: 296.0
Sum Reward: 865.0
Avg Reward: 288.3333333333333
Min Reward: 276.0
Gini Coefficient: 0.015414258188824663
20:20 Ratio: 1.0724637681159421
Max-min Ratio: 1.0724637681159421
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_13-35-01
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 903.0
  episode_reward_mean: 751.3
  episode_reward_min: 449.0
  episodes_this_iter: 1
  episodes_total: 115
  experiment_id: 86e053a9c80f439496ed6b19bfe1ab59
  hostname: gpu003
  info:
    apply_time_ms: 3.334
    dispatch_time_ms: 9.682
    learner:
      cur_lr: 0.0013370229862630367
      grad_gnorm: 40.0
      policy_entropy: 7.79835844039917
      policy_loss: 12.906292915344238
      var_gnorm: 27.959684371948242
      vf_explained_var: -1.0
      vf_loss: 32.05672073364258
    num_steps_sampled: 348000
    num_steps_trained: 348000
    wait_time_ms: 64.644
  iterations_since_restore: 116
  node_ip: 172.17.8.3
  num_metric_batches_dropped: 0
  pid: 16746
  policy_reward_mean: {}
  time_since_restore: 1011.9623446464539
  time_this_iter_s: 8.1018385887146
  time_total_s: 1011.9623446464539
  timestamp: 1593884101
  timesteps_since_restore: 348000
  timesteps_this_iter: 3000
  timesteps_total: 348000
  training_iteration: 116
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 33.3/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=16746], 1011 s, 116 iter, 348000 ts, 751 rew

agent-1: 312.0
agent-2: 245.0
agent-3: 277.0
Sum Reward: 834.0
Avg Reward: 278.0
Min Reward: 245.0
Gini Coefficient: 0.053557154276578735
20:20 Ratio: 1.273469387755102
Max-min Ratio: 1.273469387755102
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_13-35-09
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 903.0
  episode_reward_mean: 752.45
  episode_reward_min: 449.0
  episodes_this_iter: 1
  episodes_total: 116
  experiment_id: 86e053a9c80f439496ed6b19bfe1ab59
  hostname: gpu003
  info:
    apply_time_ms: 2.634
    dispatch_time_ms: 9.769
    learner:
      cur_lr: 0.0013368232175707817
      grad_gnorm: 40.0
      policy_entropy: 14.403316497802734
      policy_loss: -5.162015438079834
      var_gnorm: 28.00114631652832
      vf_explained_var: 0.647010326385498
      vf_loss: 30.57671356201172
    num_steps_sampled: 351000
    num_steps_trained: 351000
    wait_time_ms: 73.243
  iterations_since_restore: 117
  node_ip: 172.17.8.3
  num_metric_batches_dropped: 0
  pid: 16746
  policy_reward_mean: {}
  time_since_restore: 1020.0724022388458
  time_this_iter_s: 8.110057592391968
  time_total_s: 1020.0724022388458
  timestamp: 1593884109
  timesteps_since_restore: 351000
  timesteps_this_iter: 3000
  timesteps_total: 351000
  training_iteration: 117
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 33.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=16746], 1020 s, 117 iter, 351000 ts, 752 rew

agent-1: 254.0
agent-2: 239.0
agent-3: 250.0
Sum Reward: 743.0
Avg Reward: 247.66666666666666
Min Reward: 239.0
Gini Coefficient: 0.013458950201884253
20:20 Ratio: 1.0627615062761506
Max-min Ratio: 1.0627615062761506
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_13-35-17
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 903.0
  episode_reward_mean: 753.54
  episode_reward_min: 449.0
  episodes_this_iter: 1
  episodes_total: 117
  experiment_id: 86e053a9c80f439496ed6b19bfe1ab59
  hostname: gpu003
  info:
    apply_time_ms: 3.143
    dispatch_time_ms: 8.559
    learner:
      cur_lr: 0.0013366234488785267
      grad_gnorm: 40.0
      policy_entropy: 9.529684066772461
      policy_loss: -4.085848808288574
      var_gnorm: 28.105981826782227
      vf_explained_var: -0.029573678970336914
      vf_loss: 78.82659149169922
    num_steps_sampled: 354000
    num_steps_trained: 354000
    wait_time_ms: 66.914
  iterations_since_restore: 118
  node_ip: 172.17.8.3
  num_metric_batches_dropped: 0
  pid: 16746
  policy_reward_mean: {}
  time_since_restore: 1028.2230122089386
  time_this_iter_s: 8.150609970092773
  time_total_s: 1028.2230122089386
  timestamp: 1593884117
  timesteps_since_restore: 354000
  timesteps_this_iter: 3000
  timesteps_total: 354000
  training_iteration: 118
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 33.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=16746], 1028 s, 118 iter, 354000 ts, 754 rew

agent-1: 293.0
agent-2: 242.0
agent-3: 261.0
Sum Reward: 796.0
Avg Reward: 265.3333333333333
Min Reward: 242.0
Gini Coefficient: 0.04271356783919598
20:20 Ratio: 1.2107438016528926
Max-min Ratio: 1.2107438016528926
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_13-35-25
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 903.0
  episode_reward_mean: 754.74
  episode_reward_min: 449.0
  episodes_this_iter: 1
  episodes_total: 118
  experiment_id: 86e053a9c80f439496ed6b19bfe1ab59
  hostname: gpu003
  info:
    apply_time_ms: 2.777
    dispatch_time_ms: 9.06
    learner:
      cur_lr: 0.0013364235637709498
      grad_gnorm: 31.822134017944336
      policy_entropy: 8.142824172973633
      policy_loss: 0.8928581476211548
      var_gnorm: 28.141109466552734
      vf_explained_var: 0.29451656341552734
      vf_loss: 17.24667739868164
    num_steps_sampled: 357000
    num_steps_trained: 357000
    wait_time_ms: 67.612
  iterations_since_restore: 119
  node_ip: 172.17.8.3
  num_metric_batches_dropped: 0
  pid: 16746
  policy_reward_mean: {}
  time_since_restore: 1036.3933563232422
  time_this_iter_s: 8.170344114303589
  time_total_s: 1036.3933563232422
  timestamp: 1593884125
  timesteps_since_restore: 357000
  timesteps_this_iter: 3000
  timesteps_total: 357000
  training_iteration: 119
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 33.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=16746], 1036 s, 119 iter, 357000 ts, 755 rew

agent-1: 244.0
agent-2: 271.0
agent-3: 300.0
Sum Reward: 815.0
Avg Reward: 271.6666666666667
Min Reward: 244.0
Gini Coefficient: 0.045807770961145196
20:20 Ratio: 1.2295081967213115
Max-min Ratio: 1.2295081967213115
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_13-35-34
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 903.0
  episode_reward_mean: 755.5
  episode_reward_min: 449.0
  episodes_this_iter: 1
  episodes_total: 119
  experiment_id: 86e053a9c80f439496ed6b19bfe1ab59
  hostname: gpu003
  info:
    apply_time_ms: 4.016
    dispatch_time_ms: 12.214
    learner:
      cur_lr: 0.0013362237950786948
      grad_gnorm: 39.999996185302734
      policy_entropy: 15.551070213317871
      policy_loss: -21.625690460205078
      var_gnorm: 28.241426467895508
      vf_explained_var: 0.8034101724624634
      vf_loss: 24.38762855529785
    num_steps_sampled: 360000
    num_steps_trained: 360000
    wait_time_ms: 66.472
  iterations_since_restore: 120
  node_ip: 172.17.8.3
  num_metric_batches_dropped: 0
  pid: 16746
  policy_reward_mean: {}
  time_since_restore: 1044.6438355445862
  time_this_iter_s: 8.250479221343994
  time_total_s: 1044.6438355445862
  timestamp: 1593884134
  timesteps_since_restore: 360000
  timesteps_this_iter: 3000
  timesteps_total: 360000
  training_iteration: 120
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 33.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=16746], 1044 s, 120 iter, 360000 ts, 756 rew

agent-1: 261.0
agent-2: 244.0
agent-3: 311.0
Sum Reward: 816.0
Avg Reward: 272.0
Min Reward: 244.0
Gini Coefficient: 0.05473856209150327
20:20 Ratio: 1.2745901639344261
Max-min Ratio: 1.2745901639344261
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_13-35-47
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 903.0
  episode_reward_mean: 755.94
  episode_reward_min: 449.0
  episodes_this_iter: 1
  episodes_total: 120
  experiment_id: 86e053a9c80f439496ed6b19bfe1ab59
  hostname: gpu003
  info:
    apply_time_ms: 2.974
    dispatch_time_ms: 16.002
    learner:
      cur_lr: 0.0013360240263864398
      grad_gnorm: 40.000003814697266
      policy_entropy: 13.148431777954102
      policy_loss: -3.4968953132629395
      var_gnorm: 28.28260040283203
      vf_explained_var: 0.8690090775489807
      vf_loss: 22.602581024169922
    num_steps_sampled: 363000
    num_steps_trained: 363000
    wait_time_ms: 65.192
  iterations_since_restore: 121
  node_ip: 172.17.8.3
  num_metric_batches_dropped: 0
  pid: 16746
  policy_reward_mean: {}
  time_since_restore: 1057.5704493522644
  time_this_iter_s: 12.926613807678223
  time_total_s: 1057.5704493522644
  timestamp: 1593884147
  timesteps_since_restore: 363000
  timesteps_this_iter: 3000
  timesteps_total: 363000
  training_iteration: 121
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 33.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=16746], 1057 s, 121 iter, 363000 ts, 756 rew

agent-1: 290.0
agent-2: 266.0
agent-3: 218.0
Sum Reward: 774.0
Avg Reward: 258.0
Min Reward: 218.0
Gini Coefficient: 0.06201550387596899
20:20 Ratio: 1.3302752293577982
Max-min Ratio: 1.3302752293577982
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_13-35-56
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 903.0
  episode_reward_mean: 757.25
  episode_reward_min: 449.0
  episodes_this_iter: 1
  episodes_total: 121
  experiment_id: 86e053a9c80f439496ed6b19bfe1ab59
  hostname: gpu003
  info:
    apply_time_ms: 3.421
    dispatch_time_ms: 13.538
    learner:
      cur_lr: 0.0013358242576941848
      grad_gnorm: 18.56503677368164
      policy_entropy: 12.07742977142334
      policy_loss: 0.957321286201477
      var_gnorm: 28.35000991821289
      vf_explained_var: 0.5661648511886597
      vf_loss: 9.740314483642578
    num_steps_sampled: 366000
    num_steps_trained: 366000
    wait_time_ms: 66.019
  iterations_since_restore: 122
  node_ip: 172.17.8.3
  num_metric_batches_dropped: 0
  pid: 16746
  policy_reward_mean: {}
  time_since_restore: 1065.9128575325012
  time_this_iter_s: 8.342408180236816
  time_total_s: 1065.9128575325012
  timestamp: 1593884156
  timesteps_since_restore: 366000
  timesteps_this_iter: 3000
  timesteps_total: 366000
  training_iteration: 122
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 33.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=16746], 1065 s, 122 iter, 366000 ts, 757 rew

agent-1: 320.0
agent-2: 326.0
agent-3: 228.0
Sum Reward: 874.0
Avg Reward: 291.3333333333333
Min Reward: 228.0
Gini Coefficient: 0.07475209763539283
20:20 Ratio: 1.4298245614035088
Max-min Ratio: 1.4298245614035088
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_13-36-04
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 903.0
  episode_reward_mean: 759.51
  episode_reward_min: 449.0
  episodes_this_iter: 1
  episodes_total: 122
  experiment_id: 86e053a9c80f439496ed6b19bfe1ab59
  hostname: gpu003
  info:
    apply_time_ms: 3.517
    dispatch_time_ms: 8.188
    learner:
      cur_lr: 0.001335624372586608
      grad_gnorm: 39.999996185302734
      policy_entropy: 16.594499588012695
      policy_loss: -19.345611572265625
      var_gnorm: 28.494081497192383
      vf_explained_var: 0.17885571718215942
      vf_loss: 30.443029403686523
    num_steps_sampled: 369000
    num_steps_trained: 369000
    wait_time_ms: 70.56
  iterations_since_restore: 123
  node_ip: 172.17.8.3
  num_metric_batches_dropped: 0
  pid: 16746
  policy_reward_mean: {}
  time_since_restore: 1074.116013765335
  time_this_iter_s: 8.203156232833862
  time_total_s: 1074.116013765335
  timestamp: 1593884164
  timesteps_since_restore: 369000
  timesteps_this_iter: 3000
  timesteps_total: 369000
  training_iteration: 123
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 33.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=16746], 1074 s, 123 iter, 369000 ts, 760 rew

agent-1: 166.0
agent-2: 213.0
agent-3: 227.0
Sum Reward: 606.0
Avg Reward: 202.0
Min Reward: 166.0
Gini Coefficient: 0.0671067106710671
20:20 Ratio: 1.3674698795180722
Max-min Ratio: 1.3674698795180722
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_13-36-12
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 903.0
  episode_reward_mean: 758.42
  episode_reward_min: 449.0
  episodes_this_iter: 1
  episodes_total: 123
  experiment_id: 86e053a9c80f439496ed6b19bfe1ab59
  hostname: gpu003
  info:
    apply_time_ms: 3.112
    dispatch_time_ms: 14.286
    learner:
      cur_lr: 0.001335424603894353
      grad_gnorm: 40.0
      policy_entropy: 9.338493347167969
      policy_loss: -7.367280960083008
      var_gnorm: 28.545673370361328
      vf_explained_var: 0.07264828681945801
      vf_loss: 25.946876525878906
    num_steps_sampled: 372000
    num_steps_trained: 372000
    wait_time_ms: 65.607
  iterations_since_restore: 124
  node_ip: 172.17.8.3
  num_metric_batches_dropped: 0
  pid: 16746
  policy_reward_mean: {}
  time_since_restore: 1082.0799441337585
  time_this_iter_s: 7.963930368423462
  time_total_s: 1082.0799441337585
  timestamp: 1593884172
  timesteps_since_restore: 372000
  timesteps_this_iter: 3000
  timesteps_total: 372000
  training_iteration: 124
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 33.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=16746], 1082 s, 124 iter, 372000 ts, 758 rew

agent-1: 191.0
agent-2: 224.0
agent-3: 184.0
Sum Reward: 599.0
Avg Reward: 199.66666666666666
Min Reward: 184.0
Gini Coefficient: 0.044518642181413465
20:20 Ratio: 1.2173913043478262
Max-min Ratio: 1.2173913043478262
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_13-36-20
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 903.0
  episode_reward_mean: 757.86
  episode_reward_min: 449.0
  episodes_this_iter: 1
  episodes_total: 124
  experiment_id: 86e053a9c80f439496ed6b19bfe1ab59
  hostname: gpu003
  info:
    apply_time_ms: 3.145
    dispatch_time_ms: 31.063
    learner:
      cur_lr: 0.001335224835202098
      grad_gnorm: 40.000003814697266
      policy_entropy: 21.655601501464844
      policy_loss: -16.23861312866211
      var_gnorm: 28.50699234008789
      vf_explained_var: 0.3890249729156494
      vf_loss: 11.185078620910645
    num_steps_sampled: 375000
    num_steps_trained: 375000
    wait_time_ms: 34.562
  iterations_since_restore: 125
  node_ip: 172.17.8.3
  num_metric_batches_dropped: 0
  pid: 16746
  policy_reward_mean: {}
  time_since_restore: 1089.7275383472443
  time_this_iter_s: 7.647594213485718
  time_total_s: 1089.7275383472443
  timestamp: 1593884180
  timesteps_since_restore: 375000
  timesteps_this_iter: 3000
  timesteps_total: 375000
  training_iteration: 125
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 33.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=16746], 1089 s, 125 iter, 375000 ts, 758 rew

agent-1: 185.0
agent-2: 233.0
agent-3: 125.0
Sum Reward: 543.0
Avg Reward: 181.0
Min Reward: 125.0
Gini Coefficient: 0.13259668508287292
20:20 Ratio: 1.864
Max-min Ratio: 1.864
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_13-36-28
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 903.0
  episode_reward_mean: 756.02
  episode_reward_min: 449.0
  episodes_this_iter: 1
  episodes_total: 125
  experiment_id: 86e053a9c80f439496ed6b19bfe1ab59
  hostname: gpu003
  info:
    apply_time_ms: 3.543
    dispatch_time_ms: 29.689
    learner:
      cur_lr: 0.001335024950094521
      grad_gnorm: 39.999996185302734
      policy_entropy: 19.26788902282715
      policy_loss: 13.743656158447266
      var_gnorm: 28.50597381591797
      vf_explained_var: 0.3639533519744873
      vf_loss: 29.85797119140625
    num_steps_sampled: 378000
    num_steps_trained: 378000
    wait_time_ms: 51.553
  iterations_since_restore: 126
  node_ip: 172.17.8.3
  num_metric_batches_dropped: 0
  pid: 16746
  policy_reward_mean: {}
  time_since_restore: 1097.6301426887512
  time_this_iter_s: 7.902604341506958
  time_total_s: 1097.6301426887512
  timestamp: 1593884188
  timesteps_since_restore: 378000
  timesteps_this_iter: 3000
  timesteps_total: 378000
  training_iteration: 126
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 33.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=16746], 1097 s, 126 iter, 378000 ts, 756 rew

agent-1: 175.0
agent-2: 193.0
agent-3: 197.0
Sum Reward: 565.0
Avg Reward: 188.33333333333334
Min Reward: 175.0
Gini Coefficient: 0.025958702064896755
20:20 Ratio: 1.1257142857142857
Max-min Ratio: 1.1257142857142857
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_13-36-36
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 903.0
  episode_reward_mean: 754.19
  episode_reward_min: 449.0
  episodes_this_iter: 1
  episodes_total: 126
  experiment_id: 86e053a9c80f439496ed6b19bfe1ab59
  hostname: gpu003
  info:
    apply_time_ms: 3.158
    dispatch_time_ms: 36.355
    learner:
      cur_lr: 0.001334825181402266
      grad_gnorm: 40.0
      policy_entropy: 15.470706939697266
      policy_loss: -0.5207309722900391
      var_gnorm: 28.586984634399414
      vf_explained_var: 0.10926681756973267
      vf_loss: 36.80320739746094
    num_steps_sampled: 381000
    num_steps_trained: 381000
    wait_time_ms: 44.623
  iterations_since_restore: 127
  node_ip: 172.17.8.3
  num_metric_batches_dropped: 0
  pid: 16746
  policy_reward_mean: {}
  time_since_restore: 1105.3278059959412
  time_this_iter_s: 7.697663307189941
  time_total_s: 1105.3278059959412
  timestamp: 1593884196
  timesteps_since_restore: 381000
  timesteps_this_iter: 3000
  timesteps_total: 381000
  training_iteration: 127
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 33.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=16746], 1105 s, 127 iter, 381000 ts, 754 rew

agent-1: 286.0
agent-2: 301.0
agent-3: 255.0
Sum Reward: 842.0
Avg Reward: 280.6666666666667
Min Reward: 255.0
Gini Coefficient: 0.03642121931908155
20:20 Ratio: 1.1803921568627451
Max-min Ratio: 1.1803921568627451
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_13-36-45
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 903.0
  episode_reward_mean: 756.49
  episode_reward_min: 449.0
  episodes_this_iter: 1
  episodes_total: 127
  experiment_id: 86e053a9c80f439496ed6b19bfe1ab59
  hostname: gpu003
  info:
    apply_time_ms: 2.941
    dispatch_time_ms: 24.279
    learner:
      cur_lr: 0.001334625412710011
      grad_gnorm: 38.96411895751953
      policy_entropy: 21.682004928588867
      policy_loss: -11.67491626739502
      var_gnorm: 28.75240135192871
      vf_explained_var: -0.18592584133148193
      vf_loss: 13.921964645385742
    num_steps_sampled: 384000
    num_steps_trained: 384000
    wait_time_ms: 60.072
  iterations_since_restore: 128
  node_ip: 172.17.8.3
  num_metric_batches_dropped: 0
  pid: 16746
  policy_reward_mean: {}
  time_since_restore: 1113.7875027656555
  time_this_iter_s: 8.459696769714355
  time_total_s: 1113.7875027656555
  timestamp: 1593884205
  timesteps_since_restore: 384000
  timesteps_this_iter: 3000
  timesteps_total: 384000
  training_iteration: 128
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 33.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=16746], 1113 s, 128 iter, 384000 ts, 756 rew

agent-1: 274.0
agent-2: 230.0
agent-3: 279.0
Sum Reward: 783.0
Avg Reward: 261.0
Min Reward: 230.0
Gini Coefficient: 0.04171988080034057
20:20 Ratio: 1.2130434782608697
Max-min Ratio: 1.2130434782608697
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_13-36-54
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 903.0
  episode_reward_mean: 757.92
  episode_reward_min: 449.0
  episodes_this_iter: 1
  episodes_total: 128
  experiment_id: 86e053a9c80f439496ed6b19bfe1ab59
  hostname: gpu003
  info:
    apply_time_ms: 5.231
    dispatch_time_ms: 27.628
    learner:
      cur_lr: 0.001334425644017756
      grad_gnorm: 40.000003814697266
      policy_entropy: 26.801864624023438
      policy_loss: -24.08136749267578
      var_gnorm: 28.855337142944336
      vf_explained_var: 0.0667424201965332
      vf_loss: 25.508588790893555
    num_steps_sampled: 387000
    num_steps_trained: 387000
    wait_time_ms: 49.508
  iterations_since_restore: 129
  node_ip: 172.17.8.3
  num_metric_batches_dropped: 0
  pid: 16746
  policy_reward_mean: {}
  time_since_restore: 1122.5726737976074
  time_this_iter_s: 8.785171031951904
  time_total_s: 1122.5726737976074
  timestamp: 1593884214
  timesteps_since_restore: 387000
  timesteps_this_iter: 3000
  timesteps_total: 387000
  training_iteration: 129
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 33.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=16746], 1122 s, 129 iter, 387000 ts, 758 rew

agent-1: 269.0
agent-2: 258.0
agent-3: 205.0
Sum Reward: 732.0
Avg Reward: 244.0
Min Reward: 205.0
Gini Coefficient: 0.058287795992714025
20:20 Ratio: 1.3121951219512196
Max-min Ratio: 1.3121951219512196
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_13-37-02
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 903.0
  episode_reward_mean: 758.12
  episode_reward_min: 449.0
  episodes_this_iter: 1
  episodes_total: 129
  experiment_id: 86e053a9c80f439496ed6b19bfe1ab59
  hostname: gpu003
  info:
    apply_time_ms: 3.286
    dispatch_time_ms: 35.344
    learner:
      cur_lr: 0.0013342257589101791
      grad_gnorm: 38.58707809448242
      policy_entropy: 15.748220443725586
      policy_loss: 6.92824125289917
      var_gnorm: 28.876407623291016
      vf_explained_var: -0.43579554557800293
      vf_loss: 24.159069061279297
    num_steps_sampled: 390000
    num_steps_trained: 390000
    wait_time_ms: 55.695
  iterations_since_restore: 130
  node_ip: 172.17.8.3
  num_metric_batches_dropped: 0
  pid: 16746
  policy_reward_mean: {}
  time_since_restore: 1130.7600450515747
  time_this_iter_s: 8.187371253967285
  time_total_s: 1130.7600450515747
  timestamp: 1593884222
  timesteps_since_restore: 390000
  timesteps_this_iter: 3000
  timesteps_total: 390000
  training_iteration: 130
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 33.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=16746], 1130 s, 130 iter, 390000 ts, 758 rew

agent-1: 258.0
agent-2: 242.0
agent-3: 185.0
Sum Reward: 685.0
Avg Reward: 228.33333333333334
Min Reward: 185.0
Gini Coefficient: 0.07104622871046229
20:20 Ratio: 1.3945945945945946
Max-min Ratio: 1.3945945945945946
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_13-37-11
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 903.0
  episode_reward_mean: 757.29
  episode_reward_min: 449.0
  episodes_this_iter: 1
  episodes_total: 130
  experiment_id: 86e053a9c80f439496ed6b19bfe1ab59
  hostname: gpu003
  info:
    apply_time_ms: 2.824
    dispatch_time_ms: 40.418
    learner:
      cur_lr: 0.0013340259902179241
      grad_gnorm: 39.99999237060547
      policy_entropy: 17.891019821166992
      policy_loss: -17.872846603393555
      var_gnorm: 28.941865921020508
      vf_explained_var: -1.0
      vf_loss: 46.138885498046875
    num_steps_sampled: 393000
    num_steps_trained: 393000
    wait_time_ms: 49.369
  iterations_since_restore: 131
  node_ip: 172.17.8.3
  num_metric_batches_dropped: 0
  pid: 16746
  policy_reward_mean: {}
  time_since_restore: 1139.6626410484314
  time_this_iter_s: 8.90259599685669
  time_total_s: 1139.6626410484314
  timestamp: 1593884231
  timesteps_since_restore: 393000
  timesteps_this_iter: 3000
  timesteps_total: 393000
  training_iteration: 131
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 33.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=16746], 1139 s, 131 iter, 393000 ts, 757 rew

agent-1: 223.0
agent-2: 209.0
agent-3: 246.0
Sum Reward: 678.0
Avg Reward: 226.0
Min Reward: 209.0
Gini Coefficient: 0.03638151425762045
20:20 Ratio: 1.1770334928229664
Max-min Ratio: 1.1770334928229664
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_13-37-20
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 903.0
  episode_reward_mean: 758.1
  episode_reward_min: 449.0
  episodes_this_iter: 1
  episodes_total: 131
  experiment_id: 86e053a9c80f439496ed6b19bfe1ab59
  hostname: gpu003
  info:
    apply_time_ms: 2.71
    dispatch_time_ms: 41.57
    learner:
      cur_lr: 0.001333826221525669
      grad_gnorm: 40.0
      policy_entropy: 12.079456329345703
      policy_loss: -6.938325881958008
      var_gnorm: 29.026737213134766
      vf_explained_var: -1.0
      vf_loss: 19.36894416809082
    num_steps_sampled: 396000
    num_steps_trained: 396000
    wait_time_ms: 46.407
  iterations_since_restore: 132
  node_ip: 172.17.8.3
  num_metric_batches_dropped: 0
  pid: 16746
  policy_reward_mean: {}
  time_since_restore: 1148.368507862091
  time_this_iter_s: 8.705866813659668
  time_total_s: 1148.368507862091
  timestamp: 1593884240
  timesteps_since_restore: 396000
  timesteps_this_iter: 3000
  timesteps_total: 396000
  training_iteration: 132
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 33.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=16746], 1148 s, 132 iter, 396000 ts, 758 rew

agent-1: 238.0
agent-2: 258.0
agent-3: 200.0
Sum Reward: 696.0
Avg Reward: 232.0
Min Reward: 200.0
Gini Coefficient: 0.05555555555555555
20:20 Ratio: 1.29
Max-min Ratio: 1.29
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_13-37-28
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 903.0
  episode_reward_mean: 757.28
  episode_reward_min: 449.0
  episodes_this_iter: 1
  episodes_total: 132
  experiment_id: 86e053a9c80f439496ed6b19bfe1ab59
  hostname: gpu003
  info:
    apply_time_ms: 3.795
    dispatch_time_ms: 36.856
    learner:
      cur_lr: 0.001333626452833414
      grad_gnorm: 12.390135765075684
      policy_entropy: 9.99350643157959
      policy_loss: 1.9338151216506958
      var_gnorm: 29.139297485351562
      vf_explained_var: -0.26154637336730957
      vf_loss: 8.033456802368164
    num_steps_sampled: 399000
    num_steps_trained: 399000
    wait_time_ms: 41.547
  iterations_since_restore: 133
  node_ip: 172.17.8.3
  num_metric_batches_dropped: 0
  pid: 16746
  policy_reward_mean: {}
  time_since_restore: 1156.8269438743591
  time_this_iter_s: 8.458436012268066
  time_total_s: 1156.8269438743591
  timestamp: 1593884248
  timesteps_since_restore: 399000
  timesteps_this_iter: 3000
  timesteps_total: 399000
  training_iteration: 133
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 33.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=16746], 1156 s, 133 iter, 399000 ts, 757 rew

agent-1: 279.0
agent-2: 226.0
agent-3: 244.0
Sum Reward: 749.0
Avg Reward: 249.66666666666666
Min Reward: 226.0
Gini Coefficient: 0.04717400979083222
20:20 Ratio: 1.2345132743362832
Max-min Ratio: 1.2345132743362832
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_13-37-37
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 903.0
  episode_reward_mean: 758.42
  episode_reward_min: 449.0
  episodes_this_iter: 1
  episodes_total: 133
  experiment_id: 86e053a9c80f439496ed6b19bfe1ab59
  hostname: gpu003
  info:
    apply_time_ms: 2.74
    dispatch_time_ms: 46.261
    learner:
      cur_lr: 0.0013334265677258372
      grad_gnorm: 40.0
      policy_entropy: 20.964580535888672
      policy_loss: 6.586374282836914
      var_gnorm: 29.181482315063477
      vf_explained_var: 0.6515751481056213
      vf_loss: 28.533733367919922
    num_steps_sampled: 402000
    num_steps_trained: 402000
    wait_time_ms: 34.795
  iterations_since_restore: 134
  node_ip: 172.17.8.3
  num_metric_batches_dropped: 0
  pid: 16746
  policy_reward_mean: {}
  time_since_restore: 1165.2367379665375
  time_this_iter_s: 8.409794092178345
  time_total_s: 1165.2367379665375
  timestamp: 1593884257
  timesteps_since_restore: 402000
  timesteps_this_iter: 3000
  timesteps_total: 402000
  training_iteration: 134
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 33.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=16746], 1165 s, 134 iter, 402000 ts, 758 rew

agent-1: 270.0
agent-2: 216.0
agent-3: 210.0
Sum Reward: 696.0
Avg Reward: 232.0
Min Reward: 210.0
Gini Coefficient: 0.05747126436781609
20:20 Ratio: 1.2857142857142858
Max-min Ratio: 1.2857142857142858
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_13-37-45
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 903.0
  episode_reward_mean: 758.28
  episode_reward_min: 449.0
  episodes_this_iter: 1
  episodes_total: 134
  experiment_id: 86e053a9c80f439496ed6b19bfe1ab59
  hostname: gpu003
  info:
    apply_time_ms: 3.059
    dispatch_time_ms: 20.138
    learner:
      cur_lr: 0.0013332267990335822
      grad_gnorm: 39.99999237060547
      policy_entropy: 16.198156356811523
      policy_loss: 22.995792388916016
      var_gnorm: 29.23967170715332
      vf_explained_var: -0.4325704574584961
      vf_loss: 32.40750503540039
    num_steps_sampled: 405000
    num_steps_trained: 405000
    wait_time_ms: 55.193
  iterations_since_restore: 135
  node_ip: 172.17.8.3
  num_metric_batches_dropped: 0
  pid: 16746
  policy_reward_mean: {}
  time_since_restore: 1173.5347056388855
  time_this_iter_s: 8.297967672348022
  time_total_s: 1173.5347056388855
  timestamp: 1593884265
  timesteps_since_restore: 405000
  timesteps_this_iter: 3000
  timesteps_total: 405000
  training_iteration: 135
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 33.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=16746], 1173 s, 135 iter, 405000 ts, 758 rew

agent-1: 197.0
agent-2: 230.0
agent-3: 265.0
Sum Reward: 692.0
Avg Reward: 230.66666666666666
Min Reward: 197.0
Gini Coefficient: 0.06551059730250482
20:20 Ratio: 1.3451776649746192
Max-min Ratio: 1.3451776649746192
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_13-37-54
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 903.0
  episode_reward_mean: 756.71
  episode_reward_min: 449.0
  episodes_this_iter: 1
  episodes_total: 135
  experiment_id: 86e053a9c80f439496ed6b19bfe1ab59
  hostname: gpu003
  info:
    apply_time_ms: 3.185
    dispatch_time_ms: 28.438
    learner:
      cur_lr: 0.0013330270303413272
      grad_gnorm: 40.0
      policy_entropy: 26.416763305664062
      policy_loss: -29.270252227783203
      var_gnorm: 29.278242111206055
      vf_explained_var: 0.4498460292816162
      vf_loss: 19.641674041748047
    num_steps_sampled: 408000
    num_steps_trained: 408000
    wait_time_ms: 46.493
  iterations_since_restore: 136
  node_ip: 172.17.8.3
  num_metric_batches_dropped: 0
  pid: 16746
  policy_reward_mean: {}
  time_since_restore: 1182.0372602939606
  time_this_iter_s: 8.502554655075073
  time_total_s: 1182.0372602939606
  timestamp: 1593884274
  timesteps_since_restore: 408000
  timesteps_this_iter: 3000
  timesteps_total: 408000
  training_iteration: 136
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 33.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=16746], 1182 s, 136 iter, 408000 ts, 757 rew

agent-1: 250.0
agent-2: 266.0
agent-3: 261.0
Sum Reward: 777.0
Avg Reward: 259.0
Min Reward: 250.0
Gini Coefficient: 0.013728013728013728
20:20 Ratio: 1.064
Max-min Ratio: 1.064
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_13-38-02
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 903.0
  episode_reward_mean: 756.45
  episode_reward_min: 449.0
  episodes_this_iter: 1
  episodes_total: 136
  experiment_id: 86e053a9c80f439496ed6b19bfe1ab59
  hostname: gpu003
  info:
    apply_time_ms: 3.719
    dispatch_time_ms: 31.59
    learner:
      cur_lr: 0.0013328271452337503
      grad_gnorm: 39.999996185302734
      policy_entropy: 19.238285064697266
      policy_loss: 12.196027755737305
      var_gnorm: 29.31036949157715
      vf_explained_var: -0.15787136554718018
      vf_loss: 24.81458282470703
    num_steps_sampled: 411000
    num_steps_trained: 411000
    wait_time_ms: 58.501
  iterations_since_restore: 137
  node_ip: 172.17.8.3
  num_metric_batches_dropped: 0
  pid: 16746
  policy_reward_mean: {}
  time_since_restore: 1190.263365983963
  time_this_iter_s: 8.226105690002441
  time_total_s: 1190.263365983963
  timestamp: 1593884282
  timesteps_since_restore: 411000
  timesteps_this_iter: 3000
  timesteps_total: 411000
  training_iteration: 137
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 33.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=16746], 1190 s, 137 iter, 411000 ts, 756 rew

agent-1: 206.0
agent-2: 273.0
agent-3: 253.0
Sum Reward: 732.0
Avg Reward: 244.0
Min Reward: 206.0
Gini Coefficient: 0.0610200364298725
20:20 Ratio: 1.325242718446602
Max-min Ratio: 1.325242718446602
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_13-38-11
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 903.0
  episode_reward_mean: 755.16
  episode_reward_min: 449.0
  episodes_this_iter: 1
  episodes_total: 137
  experiment_id: 86e053a9c80f439496ed6b19bfe1ab59
  hostname: gpu003
  info:
    apply_time_ms: 2.92
    dispatch_time_ms: 39.378
    learner:
      cur_lr: 0.0013326273765414953
      grad_gnorm: 40.0
      policy_entropy: 17.277414321899414
      policy_loss: 4.090423107147217
      var_gnorm: 29.346229553222656
      vf_explained_var: 0.38832390308380127
      vf_loss: 38.278419494628906
    num_steps_sampled: 414000
    num_steps_trained: 414000
    wait_time_ms: 38.525
  iterations_since_restore: 138
  node_ip: 172.17.8.3
  num_metric_batches_dropped: 0
  pid: 16746
  policy_reward_mean: {}
  time_since_restore: 1199.3655738830566
  time_this_iter_s: 9.102207899093628
  time_total_s: 1199.3655738830566
  timestamp: 1593884291
  timesteps_since_restore: 414000
  timesteps_this_iter: 3000
  timesteps_total: 414000
  training_iteration: 138
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 33.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=16746], 1199 s, 138 iter, 414000 ts, 755 rew

agent-1: 227.0
agent-2: 195.0
agent-3: 154.0
Sum Reward: 576.0
Avg Reward: 192.0
Min Reward: 154.0
Gini Coefficient: 0.08449074074074074
20:20 Ratio: 1.474025974025974
Max-min Ratio: 1.474025974025974
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_13-38-20
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 903.0
  episode_reward_mean: 752.15
  episode_reward_min: 449.0
  episodes_this_iter: 1
  episodes_total: 138
  experiment_id: 86e053a9c80f439496ed6b19bfe1ab59
  hostname: gpu003
  info:
    apply_time_ms: 3.404
    dispatch_time_ms: 31.141
    learner:
      cur_lr: 0.0013324276078492403
      grad_gnorm: 40.0
      policy_entropy: 16.24419403076172
      policy_loss: -11.53702163696289
      var_gnorm: 29.34564971923828
      vf_explained_var: -0.9846960306167603
      vf_loss: 35.52529525756836
    num_steps_sampled: 417000
    num_steps_trained: 417000
    wait_time_ms: 59.582
  iterations_since_restore: 139
  node_ip: 172.17.8.3
  num_metric_batches_dropped: 0
  pid: 16746
  policy_reward_mean: {}
  time_since_restore: 1208.356435060501
  time_this_iter_s: 8.990861177444458
  time_total_s: 1208.356435060501
  timestamp: 1593884300
  timesteps_since_restore: 417000
  timesteps_this_iter: 3000
  timesteps_total: 417000
  training_iteration: 139
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 33.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=16746], 1208 s, 139 iter, 417000 ts, 752 rew

agent-1: 176.0
agent-2: 219.0
agent-3: 202.0
Sum Reward: 597.0
Avg Reward: 199.0
Min Reward: 176.0
Gini Coefficient: 0.0480178671133445
20:20 Ratio: 1.2443181818181819
Max-min Ratio: 1.2443181818181819
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_13-38-29
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 903.0
  episode_reward_mean: 749.3
  episode_reward_min: 449.0
  episodes_this_iter: 1
  episodes_total: 139
  experiment_id: 86e053a9c80f439496ed6b19bfe1ab59
  hostname: gpu003
  info:
    apply_time_ms: 2.617
    dispatch_time_ms: 37.289
    learner:
      cur_lr: 0.0013322278391569853
      grad_gnorm: 40.0
      policy_entropy: 14.28072738647461
      policy_loss: -15.263031959533691
      var_gnorm: 29.400978088378906
      vf_explained_var: -0.1281125545501709
      vf_loss: 31.167760848999023
    num_steps_sampled: 420000
    num_steps_trained: 420000
    wait_time_ms: 49.374
  iterations_since_restore: 140
  node_ip: 172.17.8.3
  num_metric_batches_dropped: 0
  pid: 16746
  policy_reward_mean: {}
  time_since_restore: 1217.2957091331482
  time_this_iter_s: 8.939274072647095
  time_total_s: 1217.2957091331482
  timestamp: 1593884309
  timesteps_since_restore: 420000
  timesteps_this_iter: 3000
  timesteps_total: 420000
  training_iteration: 140
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 33.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=16746], 1217 s, 140 iter, 420000 ts, 749 rew

agent-1: 215.0
agent-2: 238.0
agent-3: 183.0
Sum Reward: 636.0
Avg Reward: 212.0
Min Reward: 183.0
Gini Coefficient: 0.057651991614255764
20:20 Ratio: 1.3005464480874316
Max-min Ratio: 1.3005464480874316
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_13-38-40
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 903.0
  episode_reward_mean: 748.91
  episode_reward_min: 449.0
  episodes_this_iter: 1
  episodes_total: 140
  experiment_id: 86e053a9c80f439496ed6b19bfe1ab59
  hostname: gpu003
  info:
    apply_time_ms: 2.72
    dispatch_time_ms: 17.074
    learner:
      cur_lr: 0.0013320279540494084
      grad_gnorm: 39.999996185302734
      policy_entropy: 14.422473907470703
      policy_loss: 8.09408950805664
      var_gnorm: 29.464496612548828
      vf_explained_var: -0.0002313852310180664
      vf_loss: 11.395779609680176
    num_steps_sampled: 423000
    num_steps_trained: 423000
    wait_time_ms: 57.037
  iterations_since_restore: 141
  node_ip: 172.17.8.3
  num_metric_batches_dropped: 0
  pid: 16746
  policy_reward_mean: {}
  time_since_restore: 1225.4710628986359
  time_this_iter_s: 8.175353765487671
  time_total_s: 1225.4710628986359
  timestamp: 1593884320
  timesteps_since_restore: 423000
  timesteps_this_iter: 3000
  timesteps_total: 423000
  training_iteration: 141
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 33.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=16746], 1225 s, 141 iter, 423000 ts, 749 rew

agent-1: 218.0
agent-2: 243.0
agent-3: 252.0
Sum Reward: 713.0
Avg Reward: 237.66666666666666
Min Reward: 218.0
Gini Coefficient: 0.031790556334735855
20:20 Ratio: 1.1559633027522935
Max-min Ratio: 1.1559633027522935
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_13-38-48
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 903.0
  episode_reward_mean: 747.52
  episode_reward_min: 449.0
  episodes_this_iter: 1
  episodes_total: 141
  experiment_id: 86e053a9c80f439496ed6b19bfe1ab59
  hostname: gpu003
  info:
    apply_time_ms: 3.119
    dispatch_time_ms: 35.293
    learner:
      cur_lr: 0.0013318281853571534
      grad_gnorm: 40.00001907348633
      policy_entropy: 11.293827056884766
      policy_loss: 13.296257019042969
      var_gnorm: 29.501564025878906
      vf_explained_var: -1.0
      vf_loss: 15.286032676696777
    num_steps_sampled: 426000
    num_steps_trained: 426000
    wait_time_ms: 46.726
  iterations_since_restore: 142
  node_ip: 172.17.8.3
  num_metric_batches_dropped: 0
  pid: 16746
  policy_reward_mean: {}
  time_since_restore: 1233.6934113502502
  time_this_iter_s: 8.22234845161438
  time_total_s: 1233.6934113502502
  timestamp: 1593884328
  timesteps_since_restore: 426000
  timesteps_this_iter: 3000
  timesteps_total: 426000
  training_iteration: 142
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 33.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=16746], 1233 s, 142 iter, 426000 ts, 748 rew

agent-1: 255.0
agent-2: 221.0
agent-3: 231.0
Sum Reward: 707.0
Avg Reward: 235.66666666666666
Min Reward: 221.0
Gini Coefficient: 0.03206034889203206
20:20 Ratio: 1.1538461538461537
Max-min Ratio: 1.1538461538461537
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_13-38-57
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 903.0
  episode_reward_mean: 746.07
  episode_reward_min: 449.0
  episodes_this_iter: 1
  episodes_total: 142
  experiment_id: 86e053a9c80f439496ed6b19bfe1ab59
  hostname: gpu003
  info:
    apply_time_ms: 3.425
    dispatch_time_ms: 30.682
    learner:
      cur_lr: 0.0013316284166648984
      grad_gnorm: 40.0
      policy_entropy: 23.324913024902344
      policy_loss: -10.691941261291504
      var_gnorm: 29.554182052612305
      vf_explained_var: 0.24278849363327026
      vf_loss: 16.45280647277832
    num_steps_sampled: 429000
    num_steps_trained: 429000
    wait_time_ms: 62.399
  iterations_since_restore: 143
  node_ip: 172.17.8.3
  num_metric_batches_dropped: 0
  pid: 16746
  policy_reward_mean: {}
  time_since_restore: 1242.4278943538666
  time_this_iter_s: 8.734483003616333
  time_total_s: 1242.4278943538666
  timestamp: 1593884337
  timesteps_since_restore: 429000
  timesteps_this_iter: 3000
  timesteps_total: 429000
  training_iteration: 143
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 33.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=16746], 1242 s, 143 iter, 429000 ts, 746 rew

agent-1: 269.0
agent-2: 232.0
agent-3: 219.0
Sum Reward: 720.0
Avg Reward: 240.0
Min Reward: 219.0
Gini Coefficient: 0.046296296296296294
20:20 Ratio: 1.2283105022831051
Max-min Ratio: 1.2283105022831051
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_13-39-06
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 903.0
  episode_reward_mean: 746.38
  episode_reward_min: 449.0
  episodes_this_iter: 1
  episodes_total: 143
  experiment_id: 86e053a9c80f439496ed6b19bfe1ab59
  hostname: gpu003
  info:
    apply_time_ms: 3.442
    dispatch_time_ms: 32.141
    learner:
      cur_lr: 0.0013314286479726434
      grad_gnorm: 40.000003814697266
      policy_entropy: 26.023204803466797
      policy_loss: -21.6734561920166
      var_gnorm: 29.614360809326172
      vf_explained_var: -0.32616710662841797
      vf_loss: 17.780824661254883
    num_steps_sampled: 432000
    num_steps_trained: 432000
    wait_time_ms: 60.279
  iterations_since_restore: 144
  node_ip: 172.17.8.3
  num_metric_batches_dropped: 0
  pid: 16746
  policy_reward_mean: {}
  time_since_restore: 1251.2953836917877
  time_this_iter_s: 8.867489337921143
  time_total_s: 1251.2953836917877
  timestamp: 1593884346
  timesteps_since_restore: 432000
  timesteps_this_iter: 3000
  timesteps_total: 432000
  training_iteration: 144
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 33.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=16746], 1251 s, 144 iter, 432000 ts, 746 rew

agent-1: 196.0
agent-2: 200.0
agent-3: 191.0
Sum Reward: 587.0
Avg Reward: 195.66666666666666
Min Reward: 191.0
Gini Coefficient: 0.010221465076660987
20:20 Ratio: 1.0471204188481675
Max-min Ratio: 1.0471204188481675
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_13-39-15
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 903.0
  episode_reward_mean: 745.93
  episode_reward_min: 449.0
  episodes_this_iter: 1
  episodes_total: 144
  experiment_id: 86e053a9c80f439496ed6b19bfe1ab59
  hostname: gpu003
  info:
    apply_time_ms: 2.712
    dispatch_time_ms: 42.779
    learner:
      cur_lr: 0.0013312287628650665
      grad_gnorm: 39.999977111816406
      policy_entropy: 20.92763900756836
      policy_loss: -12.820610046386719
      var_gnorm: 29.697372436523438
      vf_explained_var: -1.0
      vf_loss: 43.04853439331055
    num_steps_sampled: 435000
    num_steps_trained: 435000
    wait_time_ms: 43.381
  iterations_since_restore: 145
  node_ip: 172.17.8.3
  num_metric_batches_dropped: 0
  pid: 16746
  policy_reward_mean: {}
  time_since_restore: 1260.2774739265442
  time_this_iter_s: 8.98209023475647
  time_total_s: 1260.2774739265442
  timestamp: 1593884355
  timesteps_since_restore: 435000
  timesteps_this_iter: 3000
  timesteps_total: 435000
  training_iteration: 145
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 33.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=16746], 1260 s, 145 iter, 435000 ts, 746 rew

agent-1: 232.0
agent-2: 252.0
agent-3: 241.0
Sum Reward: 725.0
Avg Reward: 241.66666666666666
Min Reward: 232.0
Gini Coefficient: 0.01839080459770115
20:20 Ratio: 1.0862068965517242
Max-min Ratio: 1.0862068965517242
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_13-39-23
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 903.0
  episode_reward_mean: 746.79
  episode_reward_min: 449.0
  episodes_this_iter: 1
  episodes_total: 145
  experiment_id: 86e053a9c80f439496ed6b19bfe1ab59
  hostname: gpu003
  info:
    apply_time_ms: 3.257
    dispatch_time_ms: 44.688
    learner:
      cur_lr: 0.0013310289941728115
      grad_gnorm: 40.000003814697266
      policy_entropy: 14.12492561340332
      policy_loss: 5.298874855041504
      var_gnorm: 29.773887634277344
      vf_explained_var: -0.038103580474853516
      vf_loss: 61.892303466796875
    num_steps_sampled: 438000
    num_steps_trained: 438000
    wait_time_ms: 38.068
  iterations_since_restore: 146
  node_ip: 172.17.8.3
  num_metric_batches_dropped: 0
  pid: 16746
  policy_reward_mean: {}
  time_since_restore: 1268.8219830989838
  time_this_iter_s: 8.544509172439575
  time_total_s: 1268.8219830989838
  timestamp: 1593884363
  timesteps_since_restore: 438000
  timesteps_this_iter: 3000
  timesteps_total: 438000
  training_iteration: 146
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 33.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=16746], 1268 s, 146 iter, 438000 ts, 747 rew

agent-1: 278.0
agent-2: 290.0
agent-3: 259.0
Sum Reward: 827.0
Avg Reward: 275.6666666666667
Min Reward: 259.0
Gini Coefficient: 0.024989923417976623
20:20 Ratio: 1.1196911196911197
Max-min Ratio: 1.1196911196911197
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_13-39-32
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 903.0
  episode_reward_mean: 746.68
  episode_reward_min: 449.0
  episodes_this_iter: 1
  episodes_total: 146
  experiment_id: 86e053a9c80f439496ed6b19bfe1ab59
  hostname: gpu003
  info:
    apply_time_ms: 2.799
    dispatch_time_ms: 30.944
    learner:
      cur_lr: 0.0013308292254805565
      grad_gnorm: 35.41754150390625
      policy_entropy: 4.693767547607422
      policy_loss: 4.236860275268555
      var_gnorm: 29.82459259033203
      vf_explained_var: 0.5619338750839233
      vf_loss: 8.59860897064209
    num_steps_sampled: 441000
    num_steps_trained: 441000
    wait_time_ms: 49.249
  iterations_since_restore: 147
  node_ip: 172.17.8.3
  num_metric_batches_dropped: 0
  pid: 16746
  policy_reward_mean: {}
  time_since_restore: 1277.6329727172852
  time_this_iter_s: 8.810989618301392
  time_total_s: 1277.6329727172852
  timestamp: 1593884372
  timesteps_since_restore: 441000
  timesteps_this_iter: 3000
  timesteps_total: 441000
  training_iteration: 147
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 33.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=16746], 1277 s, 147 iter, 441000 ts, 747 rew

agent-1: 308.0
agent-2: 246.0
agent-3: 287.0
Sum Reward: 841.0
Avg Reward: 280.3333333333333
Min Reward: 246.0
Gini Coefficient: 0.049147839873166864
20:20 Ratio: 1.2520325203252032
Max-min Ratio: 1.2520325203252032
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_13-39-41
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 903.0
  episode_reward_mean: 746.09
  episode_reward_min: 449.0
  episodes_this_iter: 1
  episodes_total: 147
  experiment_id: 86e053a9c80f439496ed6b19bfe1ab59
  hostname: gpu003
  info:
    apply_time_ms: 2.738
    dispatch_time_ms: 32.356
    learner:
      cur_lr: 0.0013306294567883015
      grad_gnorm: 40.000003814697266
      policy_entropy: 2.838679790496826
      policy_loss: 0.6553683280944824
      var_gnorm: 29.86638832092285
      vf_explained_var: 0.03554147481918335
      vf_loss: 21.21016502380371
    num_steps_sampled: 444000
    num_steps_trained: 444000
    wait_time_ms: 51.836
  iterations_since_restore: 148
  node_ip: 172.17.8.3
  num_metric_batches_dropped: 0
  pid: 16746
  policy_reward_mean: {}
  time_since_restore: 1286.0749707221985
  time_this_iter_s: 8.44199800491333
  time_total_s: 1286.0749707221985
  timestamp: 1593884381
  timesteps_since_restore: 444000
  timesteps_this_iter: 3000
  timesteps_total: 444000
  training_iteration: 148
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 33.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=16746], 1286 s, 148 iter, 444000 ts, 746 rew

agent-1: 268.0
agent-2: 244.0
agent-3: 246.0
Sum Reward: 758.0
Avg Reward: 252.66666666666666
Min Reward: 244.0
Gini Coefficient: 0.021108179419525065
20:20 Ratio: 1.098360655737705
Max-min Ratio: 1.098360655737705
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_13-39-54
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 903.0
  episode_reward_mean: 744.81
  episode_reward_min: 449.0
  episodes_this_iter: 1
  episodes_total: 148
  experiment_id: 86e053a9c80f439496ed6b19bfe1ab59
  hostname: gpu003
  info:
    apply_time_ms: 3.609
    dispatch_time_ms: 25.953
    learner:
      cur_lr: 0.0013304295716807246
      grad_gnorm: 35.76417541503906
      policy_entropy: 7.637709140777588
      policy_loss: 1.8217875957489014
      var_gnorm: 29.933029174804688
      vf_explained_var: 0.6894950866699219
      vf_loss: 17.742040634155273
    num_steps_sampled: 447000
    num_steps_trained: 447000
    wait_time_ms: 29.03
  iterations_since_restore: 149
  node_ip: 172.17.8.3
  num_metric_batches_dropped: 0
  pid: 16746
  policy_reward_mean: {}
  time_since_restore: 1299.675861120224
  time_this_iter_s: 13.600890398025513
  time_total_s: 1299.675861120224
  timestamp: 1593884394
  timesteps_since_restore: 447000
  timesteps_this_iter: 3000
  timesteps_total: 447000
  training_iteration: 149
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 33.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=16746], 1299 s, 149 iter, 447000 ts, 745 rew

agent-1: 274.0
agent-2: 231.0
agent-3: 280.0
Sum Reward: 785.0
Avg Reward: 261.6666666666667
Min Reward: 231.0
Gini Coefficient: 0.041613588110403395
20:20 Ratio: 1.2121212121212122
Max-min Ratio: 1.2121212121212122
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_13-40-03
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 903.0
  episode_reward_mean: 745.85
  episode_reward_min: 449.0
  episodes_this_iter: 1
  episodes_total: 149
  experiment_id: 86e053a9c80f439496ed6b19bfe1ab59
  hostname: gpu003
  info:
    apply_time_ms: 2.887
    dispatch_time_ms: 34.146
    learner:
      cur_lr: 0.0013302298029884696
      grad_gnorm: 30.297744750976562
      policy_entropy: 5.5904083251953125
      policy_loss: 9.324460983276367
      var_gnorm: 29.953325271606445
      vf_explained_var: -0.5199806690216064
      vf_loss: 12.762410163879395
    num_steps_sampled: 450000
    num_steps_trained: 450000
    wait_time_ms: 45.667
  iterations_since_restore: 150
  node_ip: 172.17.8.3
  num_metric_batches_dropped: 0
  pid: 16746
  policy_reward_mean: {}
  time_since_restore: 1307.953626871109
  time_this_iter_s: 8.27776575088501
  time_total_s: 1307.953626871109
  timestamp: 1593884403
  timesteps_since_restore: 450000
  timesteps_this_iter: 3000
  timesteps_total: 450000
  training_iteration: 150
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 33.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=16746], 1307 s, 150 iter, 450000 ts, 746 rew

agent-1: 271.0
agent-2: 253.0
agent-3: 299.0
Sum Reward: 823.0
Avg Reward: 274.3333333333333
Min Reward: 253.0
Gini Coefficient: 0.0372620494127177
20:20 Ratio: 1.1818181818181819
Max-min Ratio: 1.1818181818181819
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_13-40-12
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 903.0
  episode_reward_mean: 748.05
  episode_reward_min: 449.0
  episodes_this_iter: 1
  episodes_total: 150
  experiment_id: 86e053a9c80f439496ed6b19bfe1ab59
  hostname: gpu003
  info:
    apply_time_ms: 3.602
    dispatch_time_ms: 35.64
    learner:
      cur_lr: 0.0013300300342962146
      grad_gnorm: 27.082500457763672
      policy_entropy: 3.501394271850586
      policy_loss: -2.2074596881866455
      var_gnorm: 29.97332763671875
      vf_explained_var: 0.1260673999786377
      vf_loss: 5.62441349029541
    num_steps_sampled: 453000
    num_steps_trained: 453000
    wait_time_ms: 48.825
  iterations_since_restore: 151
  node_ip: 172.17.8.3
  num_metric_batches_dropped: 0
  pid: 16746
  policy_reward_mean: {}
  time_since_restore: 1316.1200544834137
  time_this_iter_s: 8.166427612304688
  time_total_s: 1316.1200544834137
  timestamp: 1593884412
  timesteps_since_restore: 453000
  timesteps_this_iter: 3000
  timesteps_total: 453000
  training_iteration: 151
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 33.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=16746], 1316 s, 151 iter, 453000 ts, 748 rew

agent-1: 288.0
agent-2: 269.0
agent-3: 269.0
Sum Reward: 826.0
Avg Reward: 275.3333333333333
Min Reward: 269.0
Gini Coefficient: 0.01533494753833737
20:20 Ratio: 1.070631970260223
Max-min Ratio: 1.070631970260223
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_13-40-20
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 903.0
  episode_reward_mean: 749.33
  episode_reward_min: 449.0
  episodes_this_iter: 1
  episodes_total: 151
  experiment_id: 86e053a9c80f439496ed6b19bfe1ab59
  hostname: gpu003
  info:
    apply_time_ms: 2.941
    dispatch_time_ms: 32.318
    learner:
      cur_lr: 0.0013298301491886377
      grad_gnorm: 38.014915466308594
      policy_entropy: 9.958090782165527
      policy_loss: 2.688279867172241
      var_gnorm: 30.019775390625
      vf_explained_var: -0.35485970973968506
      vf_loss: 10.607586860656738
    num_steps_sampled: 456000
    num_steps_trained: 456000
    wait_time_ms: 50.915
  iterations_since_restore: 152
  node_ip: 172.17.8.3
  num_metric_batches_dropped: 0
  pid: 16746
  policy_reward_mean: {}
  time_since_restore: 1324.2207489013672
  time_this_iter_s: 8.100694417953491
  time_total_s: 1324.2207489013672
  timestamp: 1593884420
  timesteps_since_restore: 456000
  timesteps_this_iter: 3000
  timesteps_total: 456000
  training_iteration: 152
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 33.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=16746], 1324 s, 152 iter, 456000 ts, 749 rew

agent-1: 292.0
agent-2: 316.0
agent-3: 277.0
Sum Reward: 885.0
Avg Reward: 295.0
Min Reward: 277.0
Gini Coefficient: 0.02937853107344633
20:20 Ratio: 1.1407942238267148
Max-min Ratio: 1.1407942238267148
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_13-40-28
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 903.0
  episode_reward_mean: 751.03
  episode_reward_min: 449.0
  episodes_this_iter: 1
  episodes_total: 152
  experiment_id: 86e053a9c80f439496ed6b19bfe1ab59
  hostname: gpu003
  info:
    apply_time_ms: 2.781
    dispatch_time_ms: 23.907
    learner:
      cur_lr: 0.0013296303804963827
      grad_gnorm: 40.000003814697266
      policy_entropy: 2.8850655555725098
      policy_loss: 4.127684593200684
      var_gnorm: 30.06706428527832
      vf_explained_var: -0.5196090936660767
      vf_loss: 20.820777893066406
    num_steps_sampled: 459000
    num_steps_trained: 459000
    wait_time_ms: 64.972
  iterations_since_restore: 153
  node_ip: 172.17.8.3
  num_metric_batches_dropped: 0
  pid: 16746
  policy_reward_mean: {}
  time_since_restore: 1332.5982995033264
  time_this_iter_s: 8.377550601959229
  time_total_s: 1332.5982995033264
  timestamp: 1593884428
  timesteps_since_restore: 459000
  timesteps_this_iter: 3000
  timesteps_total: 459000
  training_iteration: 153
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 33.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=16746], 1332 s, 153 iter, 459000 ts, 751 rew

agent-1: 268.0
agent-2: 251.0
agent-3: 231.0
Sum Reward: 750.0
Avg Reward: 250.0
Min Reward: 231.0
Gini Coefficient: 0.03288888888888889
20:20 Ratio: 1.1601731601731602
Max-min Ratio: 1.1601731601731602
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_13-40-37
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 903.0
  episode_reward_mean: 750.37
  episode_reward_min: 449.0
  episodes_this_iter: 1
  episodes_total: 153
  experiment_id: 86e053a9c80f439496ed6b19bfe1ab59
  hostname: gpu003
  info:
    apply_time_ms: 3.312
    dispatch_time_ms: 39.194
    learner:
      cur_lr: 0.0013294306118041277
      grad_gnorm: 40.00000762939453
      policy_entropy: 16.61671257019043
      policy_loss: 7.629351615905762
      var_gnorm: 30.08346176147461
      vf_explained_var: 0.25570839643478394
      vf_loss: 30.215072631835938
    num_steps_sampled: 462000
    num_steps_trained: 462000
    wait_time_ms: 42.02
  iterations_since_restore: 154
  node_ip: 172.17.8.3
  num_metric_batches_dropped: 0
  pid: 16746
  policy_reward_mean: {}
  time_since_restore: 1340.990395307541
  time_this_iter_s: 8.392095804214478
  time_total_s: 1340.990395307541
  timestamp: 1593884437
  timesteps_since_restore: 462000
  timesteps_this_iter: 3000
  timesteps_total: 462000
  training_iteration: 154
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 33.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=16746], 1340 s, 154 iter, 462000 ts, 750 rew

agent-1: 286.0
agent-2: 245.0
agent-3: 267.0
Sum Reward: 798.0
Avg Reward: 266.0
Min Reward: 245.0
Gini Coefficient: 0.034252297410192145
20:20 Ratio: 1.1673469387755102
Max-min Ratio: 1.1673469387755102
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_13-40-45
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 903.0
  episode_reward_mean: 750.99
  episode_reward_min: 449.0
  episodes_this_iter: 1
  episodes_total: 154
  experiment_id: 86e053a9c80f439496ed6b19bfe1ab59
  hostname: gpu003
  info:
    apply_time_ms: 3.68
    dispatch_time_ms: 31.237
    learner:
      cur_lr: 0.0013292308431118727
      grad_gnorm: 37.30659866333008
      policy_entropy: 16.459117889404297
      policy_loss: -1.107533574104309
      var_gnorm: 30.11739730834961
      vf_explained_var: 0.662333607673645
      vf_loss: 16.53661346435547
    num_steps_sampled: 465000
    num_steps_trained: 465000
    wait_time_ms: 50.966
  iterations_since_restore: 155
  node_ip: 172.17.8.3
  num_metric_batches_dropped: 0
  pid: 16746
  policy_reward_mean: {}
  time_since_restore: 1349.1227564811707
  time_this_iter_s: 8.13236117362976
  time_total_s: 1349.1227564811707
  timestamp: 1593884445
  timesteps_since_restore: 465000
  timesteps_this_iter: 3000
  timesteps_total: 465000
  training_iteration: 155
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 33.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=16746], 1349 s, 155 iter, 465000 ts, 751 rew

agent-1: 236.0
agent-2: 277.0
agent-3: 234.0
Sum Reward: 747.0
Avg Reward: 249.0
Min Reward: 234.0
Gini Coefficient: 0.038375725122713075
20:20 Ratio: 1.1837606837606838
Max-min Ratio: 1.1837606837606838
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_13-40-53
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 903.0
  episode_reward_mean: 750.52
  episode_reward_min: 449.0
  episodes_this_iter: 1
  episodes_total: 155
  experiment_id: 86e053a9c80f439496ed6b19bfe1ab59
  hostname: gpu003
  info:
    apply_time_ms: 2.873
    dispatch_time_ms: 36.762
    learner:
      cur_lr: 0.0013290309580042958
      grad_gnorm: 40.0
      policy_entropy: 8.836787223815918
      policy_loss: 6.100391387939453
      var_gnorm: 30.14027214050293
      vf_explained_var: -0.8190133571624756
      vf_loss: 21.790176391601562
    num_steps_sampled: 468000
    num_steps_trained: 468000
    wait_time_ms: 35.77
  iterations_since_restore: 156
  node_ip: 172.17.8.3
  num_metric_batches_dropped: 0
  pid: 16746
  policy_reward_mean: {}
  time_since_restore: 1357.5808970928192
  time_this_iter_s: 8.45814061164856
  time_total_s: 1357.5808970928192
  timestamp: 1593884453
  timesteps_since_restore: 468000
  timesteps_this_iter: 3000
  timesteps_total: 468000
  training_iteration: 156
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 33.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=16746], 1357 s, 156 iter, 468000 ts, 751 rew

agent-1: 253.0
agent-2: 273.0
agent-3: 230.0
Sum Reward: 756.0
Avg Reward: 252.0
Min Reward: 230.0
Gini Coefficient: 0.03791887125220458
20:20 Ratio: 1.1869565217391305
Max-min Ratio: 1.1869565217391305
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_13-41-02
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 903.0
  episode_reward_mean: 749.32
  episode_reward_min: 449.0
  episodes_this_iter: 1
  episodes_total: 156
  experiment_id: 86e053a9c80f439496ed6b19bfe1ab59
  hostname: gpu003
  info:
    apply_time_ms: 3.039
    dispatch_time_ms: 37.73
    learner:
      cur_lr: 0.0013288311893120408
      grad_gnorm: 33.2452278137207
      policy_entropy: 18.2517032623291
      policy_loss: 3.395404100418091
      var_gnorm: 30.1534423828125
      vf_explained_var: 0.34906309843063354
      vf_loss: 12.715571403503418
    num_steps_sampled: 471000
    num_steps_trained: 471000
    wait_time_ms: 43.088
  iterations_since_restore: 157
  node_ip: 172.17.8.3
  num_metric_batches_dropped: 0
  pid: 16746
  policy_reward_mean: {}
  time_since_restore: 1365.7915077209473
  time_this_iter_s: 8.210610628128052
  time_total_s: 1365.7915077209473
  timestamp: 1593884462
  timesteps_since_restore: 471000
  timesteps_this_iter: 3000
  timesteps_total: 471000
  training_iteration: 157
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 33.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=16746], 1365 s, 157 iter, 471000 ts, 749 rew

agent-1: 229.0
agent-2: 250.0
agent-3: 244.0
Sum Reward: 723.0
Avg Reward: 241.0
Min Reward: 229.0
Gini Coefficient: 0.019363762102351315
20:20 Ratio: 1.091703056768559
Max-min Ratio: 1.091703056768559
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_13-41-10
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 903.0
  episode_reward_mean: 749.56
  episode_reward_min: 449.0
  episodes_this_iter: 1
  episodes_total: 157
  experiment_id: 86e053a9c80f439496ed6b19bfe1ab59
  hostname: gpu003
  info:
    apply_time_ms: 3.231
    dispatch_time_ms: 44.841
    learner:
      cur_lr: 0.0013286314206197858
      grad_gnorm: 40.0
      policy_entropy: 20.38612174987793
      policy_loss: 9.301519393920898
      var_gnorm: 30.245018005371094
      vf_explained_var: 0.6116688251495361
      vf_loss: 7.076531410217285
    num_steps_sampled: 474000
    num_steps_trained: 474000
    wait_time_ms: 38.172
  iterations_since_restore: 158
  node_ip: 172.17.8.3
  num_metric_batches_dropped: 0
  pid: 16746
  policy_reward_mean: {}
  time_since_restore: 1374.5053868293762
  time_this_iter_s: 8.713879108428955
  time_total_s: 1374.5053868293762
  timestamp: 1593884470
  timesteps_since_restore: 474000
  timesteps_this_iter: 3000
  timesteps_total: 474000
  training_iteration: 158
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 33.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=16746], 1374 s, 158 iter, 474000 ts, 750 rew

agent-1: 323.0
agent-2: 272.0
agent-3: 301.0
Sum Reward: 896.0
Avg Reward: 298.6666666666667
Min Reward: 272.0
Gini Coefficient: 0.03794642857142857
20:20 Ratio: 1.1875
Max-min Ratio: 1.1875
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_13-41-19
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 903.0
  episode_reward_mean: 751.03
  episode_reward_min: 449.0
  episodes_this_iter: 1
  episodes_total: 158
  experiment_id: 86e053a9c80f439496ed6b19bfe1ab59
  hostname: gpu003
  info:
    apply_time_ms: 2.846
    dispatch_time_ms: 27.998
    learner:
      cur_lr: 0.0013284316519275308
      grad_gnorm: 40.0
      policy_entropy: 26.855236053466797
      policy_loss: -16.875019073486328
      var_gnorm: 30.28335189819336
      vf_explained_var: 0.6053155660629272
      vf_loss: 32.029396057128906
    num_steps_sampled: 477000
    num_steps_trained: 477000
    wait_time_ms: 54.762
  iterations_since_restore: 159
  node_ip: 172.17.8.3
  num_metric_batches_dropped: 0
  pid: 16746
  policy_reward_mean: {}
  time_since_restore: 1382.847484111786
  time_this_iter_s: 8.342097282409668
  time_total_s: 1382.847484111786
  timestamp: 1593884479
  timesteps_since_restore: 477000
  timesteps_this_iter: 3000
  timesteps_total: 477000
  training_iteration: 159
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 33.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=16746], 1382 s, 159 iter, 477000 ts, 751 rew

agent-1: 233.0
agent-2: 255.0
agent-3: 285.0
Sum Reward: 773.0
Avg Reward: 257.6666666666667
Min Reward: 233.0
Gini Coefficient: 0.04484691677447176
20:20 Ratio: 1.2231759656652361
Max-min Ratio: 1.2231759656652361
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_13-41-27
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 903.0
  episode_reward_mean: 751.27
  episode_reward_min: 449.0
  episodes_this_iter: 1
  episodes_total: 159
  experiment_id: 86e053a9c80f439496ed6b19bfe1ab59
  hostname: gpu003
  info:
    apply_time_ms: 3.502
    dispatch_time_ms: 33.25
    learner:
      cur_lr: 0.001328231766819954
      grad_gnorm: 40.0
      policy_entropy: 21.896854400634766
      policy_loss: -11.923606872558594
      var_gnorm: 30.313692092895508
      vf_explained_var: 0.7682048082351685
      vf_loss: 24.976604461669922
    num_steps_sampled: 480000
    num_steps_trained: 480000
    wait_time_ms: 47.105
  iterations_since_restore: 160
  node_ip: 172.17.8.3
  num_metric_batches_dropped: 0
  pid: 16746
  policy_reward_mean: {}
  time_since_restore: 1390.9568634033203
  time_this_iter_s: 8.109379291534424
  time_total_s: 1390.9568634033203
  timestamp: 1593884487
  timesteps_since_restore: 480000
  timesteps_this_iter: 3000
  timesteps_total: 480000
  training_iteration: 160
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 33.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=16746], 1390 s, 160 iter, 480000 ts, 751 rew

agent-1: 239.0
agent-2: 277.0
agent-3: 242.0
Sum Reward: 758.0
Avg Reward: 252.66666666666666
Min Reward: 239.0
Gini Coefficient: 0.03342128408091469
20:20 Ratio: 1.1589958158995817
Max-min Ratio: 1.1589958158995817
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_13-41-36
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 903.0
  episode_reward_mean: 751.67
  episode_reward_min: 449.0
  episodes_this_iter: 1
  episodes_total: 160
  experiment_id: 86e053a9c80f439496ed6b19bfe1ab59
  hostname: gpu003
  info:
    apply_time_ms: 4.671
    dispatch_time_ms: 40.243
    learner:
      cur_lr: 0.001328031998127699
      grad_gnorm: 40.000003814697266
      policy_entropy: 15.642295837402344
      policy_loss: -35.1589241027832
      var_gnorm: 30.341089248657227
      vf_explained_var: 0.3462352156639099
      vf_loss: 95.57505798339844
    num_steps_sampled: 483000
    num_steps_trained: 483000
    wait_time_ms: 44.742
  iterations_since_restore: 161
  node_ip: 172.17.8.3
  num_metric_batches_dropped: 0
  pid: 16746
  policy_reward_mean: {}
  time_since_restore: 1398.8006949424744
  time_this_iter_s: 7.843831539154053
  time_total_s: 1398.8006949424744
  timestamp: 1593884496
  timesteps_since_restore: 483000
  timesteps_this_iter: 3000
  timesteps_total: 483000
  training_iteration: 161
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 33.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=16746], 1398 s, 161 iter, 483000 ts, 752 rew

agent-1: 301.0
agent-2: 218.0
agent-3: 274.0
Sum Reward: 793.0
Avg Reward: 264.3333333333333
Min Reward: 218.0
Gini Coefficient: 0.06977721731820093
20:20 Ratio: 1.3807339449541285
Max-min Ratio: 1.3807339449541285
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_13-41-45
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 903.0
  episode_reward_mean: 751.43
  episode_reward_min: 449.0
  episodes_this_iter: 1
  episodes_total: 161
  experiment_id: 86e053a9c80f439496ed6b19bfe1ab59
  hostname: gpu003
  info:
    apply_time_ms: 2.916
    dispatch_time_ms: 40.199
    learner:
      cur_lr: 0.0013278322294354439
      grad_gnorm: 39.999996185302734
      policy_entropy: 15.621166229248047
      policy_loss: -11.064142227172852
      var_gnorm: 30.41299819946289
      vf_explained_var: 0.20022505521774292
      vf_loss: 50.65088653564453
    num_steps_sampled: 486000
    num_steps_trained: 486000
    wait_time_ms: 43.725
  iterations_since_restore: 162
  node_ip: 172.17.8.3
  num_metric_batches_dropped: 0
  pid: 16746
  policy_reward_mean: {}
  time_since_restore: 1407.5038440227509
  time_this_iter_s: 8.70314908027649
  time_total_s: 1407.5038440227509
  timestamp: 1593884505
  timesteps_since_restore: 486000
  timesteps_this_iter: 3000
  timesteps_total: 486000
  training_iteration: 162
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 33.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=16746], 1407 s, 162 iter, 486000 ts, 751 rew

agent-1: 213.0
agent-2: 258.0
agent-3: 206.0
Sum Reward: 677.0
Avg Reward: 225.66666666666666
Min Reward: 206.0
Gini Coefficient: 0.05120630231413097
20:20 Ratio: 1.2524271844660195
Max-min Ratio: 1.2524271844660195
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_13-41-54
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 903.0
  episode_reward_mean: 750.76
  episode_reward_min: 449.0
  episodes_this_iter: 1
  episodes_total: 162
  experiment_id: 86e053a9c80f439496ed6b19bfe1ab59
  hostname: gpu003
  info:
    apply_time_ms: 4.132
    dispatch_time_ms: 36.381
    learner:
      cur_lr: 0.001327632344327867
      grad_gnorm: 15.680577278137207
      policy_entropy: 11.333806037902832
      policy_loss: -4.033486366271973
      var_gnorm: 30.47714614868164
      vf_explained_var: 0.623445987701416
      vf_loss: 23.14492416381836
    num_steps_sampled: 489000
    num_steps_trained: 489000
    wait_time_ms: 44.148
  iterations_since_restore: 163
  node_ip: 172.17.8.3
  num_metric_batches_dropped: 0
  pid: 16746
  policy_reward_mean: {}
  time_since_restore: 1416.4481377601624
  time_this_iter_s: 8.944293737411499
  time_total_s: 1416.4481377601624
  timestamp: 1593884514
  timesteps_since_restore: 489000
  timesteps_this_iter: 3000
  timesteps_total: 489000
  training_iteration: 163
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 33.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=16746], 1416 s, 163 iter, 489000 ts, 751 rew

agent-1: 283.0
agent-2: 243.0
agent-3: 251.0
Sum Reward: 777.0
Avg Reward: 259.0
Min Reward: 243.0
Gini Coefficient: 0.03432003432003432
20:20 Ratio: 1.1646090534979423
Max-min Ratio: 1.1646090534979423
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_13-42-03
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 903.0
  episode_reward_mean: 750.55
  episode_reward_min: 449.0
  episodes_this_iter: 1
  episodes_total: 163
  experiment_id: 86e053a9c80f439496ed6b19bfe1ab59
  hostname: gpu003
  info:
    apply_time_ms: 3.224
    dispatch_time_ms: 34.676
    learner:
      cur_lr: 0.001327432575635612
      grad_gnorm: 9.550060272216797
      policy_entropy: 16.452041625976562
      policy_loss: -3.7146449089050293
      var_gnorm: 30.582653045654297
      vf_explained_var: 0.11559730768203735
      vf_loss: 8.763998031616211
    num_steps_sampled: 492000
    num_steps_trained: 492000
    wait_time_ms: 52.989
  iterations_since_restore: 164
  node_ip: 172.17.8.3
  num_metric_batches_dropped: 0
  pid: 16746
  policy_reward_mean: {}
  time_since_restore: 1425.028358221054
  time_this_iter_s: 8.580220460891724
  time_total_s: 1425.028358221054
  timestamp: 1593884523
  timesteps_since_restore: 492000
  timesteps_this_iter: 3000
  timesteps_total: 492000
  training_iteration: 164
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 33.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=16746], 1425 s, 164 iter, 492000 ts, 751 rew

agent-1: 205.0
agent-2: 184.0
agent-3: 233.0
Sum Reward: 622.0
Avg Reward: 207.33333333333334
Min Reward: 184.0
Gini Coefficient: 0.05251875669882101
20:20 Ratio: 1.266304347826087
Max-min Ratio: 1.266304347826087
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_13-42-11
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 903.0
  episode_reward_mean: 749.4
  episode_reward_min: 449.0
  episodes_this_iter: 1
  episodes_total: 164
  experiment_id: 86e053a9c80f439496ed6b19bfe1ab59
  hostname: gpu003
  info:
    apply_time_ms: 4.047
    dispatch_time_ms: 32.446
    learner:
      cur_lr: 0.001327232806943357
      grad_gnorm: 40.0
      policy_entropy: 25.97974395751953
      policy_loss: 9.604455947875977
      var_gnorm: 30.585519790649414
      vf_explained_var: 0.2760363817214966
      vf_loss: 16.62065887451172
    num_steps_sampled: 495000
    num_steps_trained: 495000
    wait_time_ms: 50.76
  iterations_since_restore: 165
  node_ip: 172.17.8.3
  num_metric_batches_dropped: 0
  pid: 16746
  policy_reward_mean: {}
  time_since_restore: 1433.7389159202576
  time_this_iter_s: 8.710557699203491
  time_total_s: 1433.7389159202576
  timestamp: 1593884531
  timesteps_since_restore: 495000
  timesteps_this_iter: 3000
  timesteps_total: 495000
  training_iteration: 165
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 33.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=16746], 1433 s, 165 iter, 495000 ts, 749 rew

agent-1: 289.0
agent-2: 264.0
agent-3: 228.0
Sum Reward: 781.0
Avg Reward: 260.3333333333333
Min Reward: 228.0
Gini Coefficient: 0.052069995731967564
20:20 Ratio: 1.2675438596491229
Max-min Ratio: 1.2675438596491229
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_13-42-20
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 903.0
  episode_reward_mean: 749.53
  episode_reward_min: 449.0
  episodes_this_iter: 1
  episodes_total: 165
  experiment_id: 86e053a9c80f439496ed6b19bfe1ab59
  hostname: gpu003
  info:
    apply_time_ms: 3.507
    dispatch_time_ms: 28.939
    learner:
      cur_lr: 0.001327033038251102
      grad_gnorm: 39.999996185302734
      policy_entropy: 15.340587615966797
      policy_loss: -3.9298362731933594
      var_gnorm: 30.616579055786133
      vf_explained_var: 0.4474046230316162
      vf_loss: 21.98080062866211
    num_steps_sampled: 498000
    num_steps_trained: 498000
    wait_time_ms: 60.801
  iterations_since_restore: 166
  node_ip: 172.17.8.3
  num_metric_batches_dropped: 0
  pid: 16746
  policy_reward_mean: {}
  time_since_restore: 1442.5236554145813
  time_this_iter_s: 8.78473949432373
  time_total_s: 1442.5236554145813
  timestamp: 1593884540
  timesteps_since_restore: 498000
  timesteps_this_iter: 3000
  timesteps_total: 498000
  training_iteration: 166
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 33.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=16746], 1442 s, 166 iter, 498000 ts, 750 rew

agent-1: 222.0
agent-2: 250.0
agent-3: 284.0
Sum Reward: 756.0
Avg Reward: 252.0
Min Reward: 222.0
Gini Coefficient: 0.054673721340388004
20:20 Ratio: 1.2792792792792793
Max-min Ratio: 1.2792792792792793
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_13-42-29
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 903.0
  episode_reward_mean: 749.18
  episode_reward_min: 449.0
  episodes_this_iter: 1
  episodes_total: 166
  experiment_id: 86e053a9c80f439496ed6b19bfe1ab59
  hostname: gpu003
  info:
    apply_time_ms: 3.162
    dispatch_time_ms: 41.945
    learner:
      cur_lr: 0.0013268331531435251
      grad_gnorm: 40.0
      policy_entropy: 8.550350189208984
      policy_loss: 10.94063949584961
      var_gnorm: 30.634246826171875
      vf_explained_var: -0.06255757808685303
      vf_loss: 27.61895179748535
    num_steps_sampled: 501000
    num_steps_trained: 501000
    wait_time_ms: 43.584
  iterations_since_restore: 167
  node_ip: 172.17.8.3
  num_metric_batches_dropped: 0
  pid: 16746
  policy_reward_mean: {}
  time_since_restore: 1451.4482753276825
  time_this_iter_s: 8.924619913101196
  time_total_s: 1451.4482753276825
  timestamp: 1593884549
  timesteps_since_restore: 501000
  timesteps_this_iter: 3000
  timesteps_total: 501000
  training_iteration: 167
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 33.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=16746], 1451 s, 167 iter, 501000 ts, 749 rew

agent-1: 212.0
agent-2: 222.0
agent-3: 197.0
Sum Reward: 631.0
Avg Reward: 210.33333333333334
Min Reward: 197.0
Gini Coefficient: 0.02641310089804543
20:20 Ratio: 1.1269035532994924
Max-min Ratio: 1.1269035532994924
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_13-42-38
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 899.0
  episode_reward_mean: 746.46
  episode_reward_min: 449.0
  episodes_this_iter: 1
  episodes_total: 167
  experiment_id: 86e053a9c80f439496ed6b19bfe1ab59
  hostname: gpu003
  info:
    apply_time_ms: 2.826
    dispatch_time_ms: 39.349
    learner:
      cur_lr: 0.00132663338445127
      grad_gnorm: 40.0
      policy_entropy: 9.424867630004883
      policy_loss: 2.728010416030884
      var_gnorm: 30.660442352294922
      vf_explained_var: 0.4706442952156067
      vf_loss: 44.304542541503906
    num_steps_sampled: 504000
    num_steps_trained: 504000
    wait_time_ms: 41.884
  iterations_since_restore: 168
  node_ip: 172.17.8.3
  num_metric_batches_dropped: 0
  pid: 16746
  policy_reward_mean: {}
  time_since_restore: 1460.0327122211456
  time_this_iter_s: 8.584436893463135
  time_total_s: 1460.0327122211456
  timestamp: 1593884558
  timesteps_since_restore: 504000
  timesteps_this_iter: 3000
  timesteps_total: 504000
  training_iteration: 168
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 33.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=16746], 1460 s, 168 iter, 504000 ts, 746 rew

agent-1: 246.0
agent-2: 249.0
agent-3: 243.0
Sum Reward: 738.0
Avg Reward: 246.0
Min Reward: 243.0
Gini Coefficient: 0.005420054200542005
20:20 Ratio: 1.0246913580246915
Max-min Ratio: 1.0246913580246915
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_13-42-46
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 899.0
  episode_reward_mean: 745.31
  episode_reward_min: 449.0
  episodes_this_iter: 1
  episodes_total: 168
  experiment_id: 86e053a9c80f439496ed6b19bfe1ab59
  hostname: gpu003
  info:
    apply_time_ms: 3.552
    dispatch_time_ms: 32.356
    learner:
      cur_lr: 0.001326433615759015
      grad_gnorm: 26.072641372680664
      policy_entropy: 5.016057968139648
      policy_loss: 1.2946650981903076
      var_gnorm: 30.696308135986328
      vf_explained_var: 0.5743023753166199
      vf_loss: 5.283938407897949
    num_steps_sampled: 507000
    num_steps_trained: 507000
    wait_time_ms: 45.8
  iterations_since_restore: 169
  node_ip: 172.17.8.3
  num_metric_batches_dropped: 0
  pid: 16746
  policy_reward_mean: {}
  time_since_restore: 1468.6003682613373
  time_this_iter_s: 8.56765604019165
  time_total_s: 1468.6003682613373
  timestamp: 1593884566
  timesteps_since_restore: 507000
  timesteps_this_iter: 3000
  timesteps_total: 507000
  training_iteration: 169
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 33.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=16746], 1468 s, 169 iter, 507000 ts, 745 rew

agent-1: 324.0
agent-2: 304.0
agent-3: 300.0
Sum Reward: 928.0
Avg Reward: 309.3333333333333
Min Reward: 300.0
Gini Coefficient: 0.017241379310344827
20:20 Ratio: 1.08
Max-min Ratio: 1.08
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_13-42-55
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 928.0
  episode_reward_mean: 748.56
  episode_reward_min: 449.0
  episodes_this_iter: 1
  episodes_total: 169
  experiment_id: 86e053a9c80f439496ed6b19bfe1ab59
  hostname: gpu003
  info:
    apply_time_ms: 2.72
    dispatch_time_ms: 28.937
    learner:
      cur_lr: 0.00132623384706676
      grad_gnorm: 28.633617401123047
      policy_entropy: 19.7271671295166
      policy_loss: -8.86767864227295
      var_gnorm: 30.76110076904297
      vf_explained_var: 0.6789332628250122
      vf_loss: 28.710838317871094
    num_steps_sampled: 510000
    num_steps_trained: 510000
    wait_time_ms: 59.443
  iterations_since_restore: 170
  node_ip: 172.17.8.3
  num_metric_batches_dropped: 0
  pid: 16746
  policy_reward_mean: {}
  time_since_restore: 1477.412160396576
  time_this_iter_s: 8.811792135238647
  time_total_s: 1477.412160396576
  timestamp: 1593884575
  timesteps_since_restore: 510000
  timesteps_this_iter: 3000
  timesteps_total: 510000
  training_iteration: 170
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 33.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=16746], 1477 s, 170 iter, 510000 ts, 749 rew

agent-1: 235.0
agent-2: 173.0
agent-3: 233.0
Sum Reward: 641.0
Avg Reward: 213.66666666666666
Min Reward: 173.0
Gini Coefficient: 0.06448257930317212
20:20 Ratio: 1.3583815028901733
Max-min Ratio: 1.3583815028901733
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_13-43-05
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 928.0
  episode_reward_mean: 747.7
  episode_reward_min: 449.0
  episodes_this_iter: 1
  episodes_total: 170
  experiment_id: 86e053a9c80f439496ed6b19bfe1ab59
  hostname: gpu003
  info:
    apply_time_ms: 3.353
    dispatch_time_ms: 38.592
    learner:
      cur_lr: 0.0013260339619591832
      grad_gnorm: 39.99999237060547
      policy_entropy: 15.970319747924805
      policy_loss: 9.680275917053223
      var_gnorm: 30.780719757080078
      vf_explained_var: 0.06998103857040405
      vf_loss: 9.677159309387207
    num_steps_sampled: 513000
    num_steps_trained: 513000
    wait_time_ms: 43.614
  iterations_since_restore: 171
  node_ip: 172.17.8.3
  num_metric_batches_dropped: 0
  pid: 16746
  policy_reward_mean: {}
  time_since_restore: 1486.8722729682922
  time_this_iter_s: 9.460112571716309
  time_total_s: 1486.8722729682922
  timestamp: 1593884585
  timesteps_since_restore: 513000
  timesteps_this_iter: 3000
  timesteps_total: 513000
  training_iteration: 171
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 33.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=16746], 1486 s, 171 iter, 513000 ts, 748 rew

agent-1: 264.0
agent-2: 275.0
agent-3: 228.0
Sum Reward: 767.0
Avg Reward: 255.66666666666666
Min Reward: 228.0
Gini Coefficient: 0.04085180356366797
20:20 Ratio: 1.206140350877193
Max-min Ratio: 1.206140350877193
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_13-43-13
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 928.0
  episode_reward_mean: 748.02
  episode_reward_min: 449.0
  episodes_this_iter: 1
  episodes_total: 171
  experiment_id: 86e053a9c80f439496ed6b19bfe1ab59
  hostname: gpu003
  info:
    apply_time_ms: 2.814
    dispatch_time_ms: 30.306
    learner:
      cur_lr: 0.0013258341932669282
      grad_gnorm: 38.641380310058594
      policy_entropy: 17.976621627807617
      policy_loss: 3.5290515422821045
      var_gnorm: 30.84429168701172
      vf_explained_var: 0.006367623805999756
      vf_loss: 32.64597702026367
    num_steps_sampled: 516000
    num_steps_trained: 516000
    wait_time_ms: 58.483
  iterations_since_restore: 172
  node_ip: 172.17.8.3
  num_metric_batches_dropped: 0
  pid: 16746
  policy_reward_mean: {}
  time_since_restore: 1495.1992650032043
  time_this_iter_s: 8.32699203491211
  time_total_s: 1495.1992650032043
  timestamp: 1593884593
  timesteps_since_restore: 516000
  timesteps_this_iter: 3000
  timesteps_total: 516000
  training_iteration: 172
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 33.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=16746], 1495 s, 172 iter, 516000 ts, 748 rew

agent-1: 253.0
agent-2: 306.0
agent-3: 250.0
Sum Reward: 809.0
Avg Reward: 269.6666666666667
Min Reward: 250.0
Gini Coefficient: 0.046147507210548
20:20 Ratio: 1.224
Max-min Ratio: 1.224
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_13-43-22
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 928.0
  episode_reward_mean: 748.97
  episode_reward_min: 449.0
  episodes_this_iter: 1
  episodes_total: 172
  experiment_id: 86e053a9c80f439496ed6b19bfe1ab59
  hostname: gpu003
  info:
    apply_time_ms: 3.509
    dispatch_time_ms: 42.958
    learner:
      cur_lr: 0.0013256344245746732
      grad_gnorm: 8.498064041137695
      policy_entropy: 11.006145477294922
      policy_loss: -0.12778908014297485
      var_gnorm: 30.870973587036133
      vf_explained_var: 0.11409938335418701
      vf_loss: 7.306857585906982
    num_steps_sampled: 519000
    num_steps_trained: 519000
    wait_time_ms: 42.019
  iterations_since_restore: 173
  node_ip: 172.17.8.3
  num_metric_batches_dropped: 0
  pid: 16746
  policy_reward_mean: {}
  time_since_restore: 1504.0896451473236
  time_this_iter_s: 8.890380144119263
  time_total_s: 1504.0896451473236
  timestamp: 1593884602
  timesteps_since_restore: 519000
  timesteps_this_iter: 3000
  timesteps_total: 519000
  training_iteration: 173
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 33.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=16746], 1504 s, 173 iter, 519000 ts, 749 rew

agent-1: 215.0
agent-2: 268.0
agent-3: 231.0
Sum Reward: 714.0
Avg Reward: 238.0
Min Reward: 215.0
Gini Coefficient: 0.04948646125116713
20:20 Ratio: 1.2465116279069768
Max-min Ratio: 1.2465116279069768
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_13-43-30
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 928.0
  episode_reward_mean: 748.65
  episode_reward_min: 449.0
  episodes_this_iter: 1
  episodes_total: 173
  experiment_id: 86e053a9c80f439496ed6b19bfe1ab59
  hostname: gpu003
  info:
    apply_time_ms: 2.917
    dispatch_time_ms: 23.479
    learner:
      cur_lr: 0.0013254346558824182
      grad_gnorm: 39.999996185302734
      policy_entropy: 15.485225677490234
      policy_loss: 19.149614334106445
      var_gnorm: 30.96263885498047
      vf_explained_var: 0.18460261821746826
      vf_loss: 28.144866943359375
    num_steps_sampled: 522000
    num_steps_trained: 522000
    wait_time_ms: 61.718
  iterations_since_restore: 174
  node_ip: 172.17.8.3
  num_metric_batches_dropped: 0
  pid: 16746
  policy_reward_mean: {}
  time_since_restore: 1512.212720155716
  time_this_iter_s: 8.123075008392334
  time_total_s: 1512.212720155716
  timestamp: 1593884610
  timesteps_since_restore: 522000
  timesteps_this_iter: 3000
  timesteps_total: 522000
  training_iteration: 174
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 33.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=16746], 1512 s, 174 iter, 522000 ts, 749 rew

agent-1: 281.0
agent-2: 304.0
agent-3: 292.0
Sum Reward: 877.0
Avg Reward: 292.3333333333333
Min Reward: 281.0
Gini Coefficient: 0.017483846446218167
20:20 Ratio: 1.0818505338078293
Max-min Ratio: 1.0818505338078293
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_13-43-39
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 928.0
  episode_reward_mean: 749.96
  episode_reward_min: 449.0
  episodes_this_iter: 1
  episodes_total: 174
  experiment_id: 86e053a9c80f439496ed6b19bfe1ab59
  hostname: gpu003
  info:
    apply_time_ms: 3.006
    dispatch_time_ms: 45.987
    learner:
      cur_lr: 0.0013252347707748413
      grad_gnorm: 40.00000762939453
      policy_entropy: 21.423757553100586
      policy_loss: -13.548662185668945
      var_gnorm: 31.02313804626465
      vf_explained_var: 0.34086400270462036
      vf_loss: 41.019351959228516
    num_steps_sampled: 525000
    num_steps_trained: 525000
    wait_time_ms: 42.638
  iterations_since_restore: 175
  node_ip: 172.17.8.3
  num_metric_batches_dropped: 0
  pid: 16746
  policy_reward_mean: {}
  time_since_restore: 1521.20791721344
  time_this_iter_s: 8.995197057723999
  time_total_s: 1521.20791721344
  timestamp: 1593884619
  timesteps_since_restore: 525000
  timesteps_this_iter: 3000
  timesteps_total: 525000
  training_iteration: 175
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 33.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=16746], 1521 s, 175 iter, 525000 ts, 750 rew

agent-1: 286.0
agent-2: 199.0
agent-3: 242.0
Sum Reward: 727.0
Avg Reward: 242.33333333333334
Min Reward: 199.0
Gini Coefficient: 0.07977991746905089
20:20 Ratio: 1.4371859296482412
Max-min Ratio: 1.4371859296482412
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_13-43-48
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 928.0
  episode_reward_mean: 749.84
  episode_reward_min: 449.0
  episodes_this_iter: 1
  episodes_total: 175
  experiment_id: 86e053a9c80f439496ed6b19bfe1ab59
  hostname: gpu003
  info:
    apply_time_ms: 3.693
    dispatch_time_ms: 26.694
    learner:
      cur_lr: 0.0013250350020825863
      grad_gnorm: 40.0
      policy_entropy: 32.16197204589844
      policy_loss: -19.500537872314453
      var_gnorm: 31.121227264404297
      vf_explained_var: 0.15022069215774536
      vf_loss: 50.00448226928711
    num_steps_sampled: 528000
    num_steps_trained: 528000
    wait_time_ms: 57.387
  iterations_since_restore: 176
  node_ip: 172.17.8.3
  num_metric_batches_dropped: 0
  pid: 16746
  policy_reward_mean: {}
  time_since_restore: 1529.6826350688934
  time_this_iter_s: 8.474717855453491
  time_total_s: 1529.6826350688934
  timestamp: 1593884628
  timesteps_since_restore: 528000
  timesteps_this_iter: 3000
  timesteps_total: 528000
  training_iteration: 176
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 33.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=16746], 1529 s, 176 iter, 528000 ts, 750 rew

agent-1: 197.0
agent-2: 224.0
agent-3: 243.0
Sum Reward: 664.0
Avg Reward: 221.33333333333334
Min Reward: 197.0
Gini Coefficient: 0.04618473895582329
20:20 Ratio: 1.233502538071066
Max-min Ratio: 1.233502538071066
I0704 13:44:05.466135 16738 node_manager.cc:1721] Resubmitting task 00000000acffbf6fbedb75e74edd8b56fbc70ea8 on client cf48fbd876c7f5bb44a12cae381f09bae92eefc7
W0704 13:44:05.524541 16738 node_manager.cc:31] A task was resubmitted, so we are ignoring it. This should only happen during reconstruction.
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_13-44-35
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 928.0
  episode_reward_mean: 749.85
  episode_reward_min: 449.0
  episodes_this_iter: 1
  episodes_total: 176
  experiment_id: 86e053a9c80f439496ed6b19bfe1ab59
  hostname: gpu003
  info:
    apply_time_ms: 1941.332
    dispatch_time_ms: 21.504
    learner:
      cur_lr: 0.0013248352333903313
      grad_gnorm: 40.0
      policy_entropy: 30.57675552368164
      policy_loss: -1.3812718391418457
      var_gnorm: 31.134071350097656
      vf_explained_var: -0.09225165843963623
      vf_loss: 12.187932014465332
    num_steps_sampled: 531000
    num_steps_trained: 531000
    wait_time_ms: 30.203
  iterations_since_restore: 177
  node_ip: 172.17.8.3
  num_metric_batches_dropped: 0
  pid: 16746
  policy_reward_mean: {}
  time_since_restore: 1576.5666062831879
  time_this_iter_s: 46.883971214294434
  time_total_s: 1576.5666062831879
  timestamp: 1593884675
  timesteps_since_restore: 531000
  timesteps_this_iter: 3000
  timesteps_total: 531000
  training_iteration: 177
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 33.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=16746], 1576 s, 177 iter, 531000 ts, 750 rew

agent-1: 233.0
agent-2: 182.0
agent-3: 181.0
Sum Reward: 596.0
Avg Reward: 198.66666666666666
Min Reward: 181.0
Gini Coefficient: 0.058165548098434
20:20 Ratio: 1.287292817679558
Max-min Ratio: 1.287292817679558
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_13-44-42
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 928.0
  episode_reward_mean: 748.36
  episode_reward_min: 449.0
  episodes_this_iter: 1
  episodes_total: 177
  experiment_id: 86e053a9c80f439496ed6b19bfe1ab59
  hostname: gpu003
  info:
    apply_time_ms: 2.765
    dispatch_time_ms: 20.825
    learner:
      cur_lr: 0.0013246353482827544
      grad_gnorm: 40.0
      policy_entropy: 20.093568801879883
      policy_loss: 14.610869407653809
      var_gnorm: 31.106618881225586
      vf_explained_var: 0.14635485410690308
      vf_loss: 24.49740982055664
    num_steps_sampled: 534000
    num_steps_trained: 534000
    wait_time_ms: 58.622
  iterations_since_restore: 178
  node_ip: 172.17.8.3
  num_metric_batches_dropped: 0
  pid: 16746
  policy_reward_mean: {}
  time_since_restore: 1583.8007752895355
  time_this_iter_s: 7.234169006347656
  time_total_s: 1583.8007752895355
  timestamp: 1593884682
  timesteps_since_restore: 534000
  timesteps_this_iter: 3000
  timesteps_total: 534000
  training_iteration: 178
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 33.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=16746], 1583 s, 178 iter, 534000 ts, 748 rew

agent-1: 130.0
agent-2: 255.0
agent-3: 236.0
Sum Reward: 621.0
Avg Reward: 207.0
Min Reward: 130.0
Gini Coefficient: 0.13419216317767044
20:20 Ratio: 1.9615384615384615
Max-min Ratio: 1.9615384615384615
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_13-44-50
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 928.0
  episode_reward_mean: 746.87
  episode_reward_min: 449.0
  episodes_this_iter: 1
  episodes_total: 178
  experiment_id: 86e053a9c80f439496ed6b19bfe1ab59
  hostname: gpu003
  info:
    apply_time_ms: 2.792
    dispatch_time_ms: 14.954
    learner:
      cur_lr: 0.0013244355795904994
      grad_gnorm: 40.000003814697266
      policy_entropy: 25.934043884277344
      policy_loss: 14.660262107849121
      var_gnorm: 31.20965003967285
      vf_explained_var: -0.5985375642776489
      vf_loss: 25.434682846069336
    num_steps_sampled: 537000
    num_steps_trained: 537000
    wait_time_ms: 64.485
  iterations_since_restore: 179
  node_ip: 172.17.8.3
  num_metric_batches_dropped: 0
  pid: 16746
  policy_reward_mean: {}
  time_since_restore: 1591.8974723815918
  time_this_iter_s: 8.096697092056274
  time_total_s: 1591.8974723815918
  timestamp: 1593884690
  timesteps_since_restore: 537000
  timesteps_this_iter: 3000
  timesteps_total: 537000
  training_iteration: 179
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 33.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=16746], 1591 s, 179 iter, 537000 ts, 747 rew

agent-1: 264.0
agent-2: 250.0
agent-3: 251.0
Sum Reward: 765.0
Avg Reward: 255.0
Min Reward: 250.0
Gini Coefficient: 0.012200435729847494
20:20 Ratio: 1.056
Max-min Ratio: 1.056
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_13-44-58
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 928.0
  episode_reward_mean: 747.2
  episode_reward_min: 449.0
  episodes_this_iter: 1
  episodes_total: 179
  experiment_id: 86e053a9c80f439496ed6b19bfe1ab59
  hostname: gpu003
  info:
    apply_time_ms: 3.802
    dispatch_time_ms: 13.748
    learner:
      cur_lr: 0.0013242358108982444
      grad_gnorm: 33.01542282104492
      policy_entropy: 22.81496810913086
      policy_loss: -14.572754859924316
      var_gnorm: 31.21671485900879
      vf_explained_var: 0.35255706310272217
      vf_loss: 25.8955078125
    num_steps_sampled: 540000
    num_steps_trained: 540000
    wait_time_ms: 67.951
  iterations_since_restore: 180
  node_ip: 172.17.8.3
  num_metric_batches_dropped: 0
  pid: 16746
  policy_reward_mean: {}
  time_since_restore: 1599.8696579933167
  time_this_iter_s: 7.9721856117248535
  time_total_s: 1599.8696579933167
  timestamp: 1593884698
  timesteps_since_restore: 540000
  timesteps_this_iter: 3000
  timesteps_total: 540000
  training_iteration: 180
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 33.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=16746], 1599 s, 180 iter, 540000 ts, 747 rew

agent-1: 226.0
agent-2: 243.0
agent-3: 228.0
Sum Reward: 697.0
Avg Reward: 232.33333333333334
Min Reward: 226.0
Gini Coefficient: 0.016260162601626018
20:20 Ratio: 1.075221238938053
Max-min Ratio: 1.075221238938053
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_13-45-06
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 928.0
  episode_reward_mean: 747.28
  episode_reward_min: 449.0
  episodes_this_iter: 1
  episodes_total: 180
  experiment_id: 86e053a9c80f439496ed6b19bfe1ab59
  hostname: gpu003
  info:
    apply_time_ms: 2.868
    dispatch_time_ms: 6.762
    learner:
      cur_lr: 0.0013240360422059894
      grad_gnorm: 40.0
      policy_entropy: 17.82040023803711
      policy_loss: -14.34681510925293
      var_gnorm: 31.255523681640625
      vf_explained_var: 0.31194716691970825
      vf_loss: 11.773834228515625
    num_steps_sampled: 543000
    num_steps_trained: 543000
    wait_time_ms: 69.686
  iterations_since_restore: 181
  node_ip: 172.17.8.3
  num_metric_batches_dropped: 0
  pid: 16746
  policy_reward_mean: {}
  time_since_restore: 1607.9827268123627
  time_this_iter_s: 8.11306881904602
  time_total_s: 1607.9827268123627
  timestamp: 1593884706
  timesteps_since_restore: 543000
  timesteps_this_iter: 3000
  timesteps_total: 543000
  training_iteration: 181
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 33.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=16746], 1607 s, 181 iter, 543000 ts, 747 rew

agent-1: 238.0
agent-2: 222.0
agent-3: 274.0
Sum Reward: 734.0
Avg Reward: 244.66666666666666
Min Reward: 222.0
Gini Coefficient: 0.047229791099000905
20:20 Ratio: 1.2342342342342343
Max-min Ratio: 1.2342342342342343
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_13-45-15
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 928.0
  episode_reward_mean: 746.73
  episode_reward_min: 449.0
  episodes_this_iter: 1
  episodes_total: 181
  experiment_id: 86e053a9c80f439496ed6b19bfe1ab59
  hostname: gpu003
  info:
    apply_time_ms: 2.942
    dispatch_time_ms: 23.658
    learner:
      cur_lr: 0.0013238361570984125
      grad_gnorm: 27.33889389038086
      policy_entropy: 22.70323371887207
      policy_loss: 0.39995574951171875
      var_gnorm: 31.339113235473633
      vf_explained_var: 0.1904175877571106
      vf_loss: 21.21516990661621
    num_steps_sampled: 546000
    num_steps_trained: 546000
    wait_time_ms: 64.54
  iterations_since_restore: 182
  node_ip: 172.17.8.3
  num_metric_batches_dropped: 0
  pid: 16746
  policy_reward_mean: {}
  time_since_restore: 1616.2169225215912
  time_this_iter_s: 8.234195709228516
  time_total_s: 1616.2169225215912
  timestamp: 1593884715
  timesteps_since_restore: 546000
  timesteps_this_iter: 3000
  timesteps_total: 546000
  training_iteration: 182
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 33.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=16746], 1616 s, 182 iter, 546000 ts, 747 rew

agent-1: 220.0
agent-2: 229.0
agent-3: 223.0
Sum Reward: 672.0
Avg Reward: 224.0
Min Reward: 220.0
Gini Coefficient: 0.008928571428571428
20:20 Ratio: 1.040909090909091
Max-min Ratio: 1.040909090909091
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_13-45-24
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 928.0
  episode_reward_mean: 746.87
  episode_reward_min: 449.0
  episodes_this_iter: 1
  episodes_total: 182
  experiment_id: 86e053a9c80f439496ed6b19bfe1ab59
  hostname: gpu003
  info:
    apply_time_ms: 2.967
    dispatch_time_ms: 28.76
    learner:
      cur_lr: 0.0013236363884061575
      grad_gnorm: 40.000003814697266
      policy_entropy: 18.039199829101562
      policy_loss: 15.77890682220459
      var_gnorm: 31.308691024780273
      vf_explained_var: 0.5901306867599487
      vf_loss: 13.909156799316406
    num_steps_sampled: 549000
    num_steps_trained: 549000
    wait_time_ms: 64.312
  iterations_since_restore: 183
  node_ip: 172.17.8.3
  num_metric_batches_dropped: 0
  pid: 16746
  policy_reward_mean: {}
  time_since_restore: 1625.4287481307983
  time_this_iter_s: 9.211825609207153
  time_total_s: 1625.4287481307983
  timestamp: 1593884724
  timesteps_since_restore: 549000
  timesteps_this_iter: 3000
  timesteps_total: 549000
  training_iteration: 183
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 33.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=16746], 1625 s, 183 iter, 549000 ts, 747 rew

agent-1: 236.0
agent-2: 315.0
agent-3: 224.0
Sum Reward: 775.0
Avg Reward: 258.3333333333333
Min Reward: 224.0
Gini Coefficient: 0.07827956989247312
20:20 Ratio: 1.40625
Max-min Ratio: 1.40625
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_13-45-33
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 928.0
  episode_reward_mean: 747.26
  episode_reward_min: 449.0
  episodes_this_iter: 1
  episodes_total: 183
  experiment_id: 86e053a9c80f439496ed6b19bfe1ab59
  hostname: gpu003
  info:
    apply_time_ms: 3.408
    dispatch_time_ms: 23.711
    learner:
      cur_lr: 0.0013234366197139025
      grad_gnorm: 40.00000762939453
      policy_entropy: 19.88775634765625
      policy_loss: -13.788607597351074
      var_gnorm: 31.376310348510742
      vf_explained_var: 0.5420080423355103
      vf_loss: 51.76144790649414
    num_steps_sampled: 552000
    num_steps_trained: 552000
    wait_time_ms: 62.169
  iterations_since_restore: 184
  node_ip: 172.17.8.3
  num_metric_batches_dropped: 0
  pid: 16746
  policy_reward_mean: {}
  time_since_restore: 1634.1699485778809
  time_this_iter_s: 8.74120044708252
  time_total_s: 1634.1699485778809
  timestamp: 1593884733
  timesteps_since_restore: 552000
  timesteps_this_iter: 3000
  timesteps_total: 552000
  training_iteration: 184
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 33.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=16746], 1634 s, 184 iter, 552000 ts, 747 rew

agent-1: 339.0
agent-2: 288.0
agent-3: 301.0
Sum Reward: 928.0
Avg Reward: 309.3333333333333
Min Reward: 288.0
Gini Coefficient: 0.036637931034482756
20:20 Ratio: 1.1770833333333333
Max-min Ratio: 1.1770833333333333
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_13-45-42
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 928.0
  episode_reward_mean: 749.68
  episode_reward_min: 449.0
  episodes_this_iter: 1
  episodes_total: 184
  experiment_id: 86e053a9c80f439496ed6b19bfe1ab59
  hostname: gpu003
  info:
    apply_time_ms: 2.813
    dispatch_time_ms: 28.814
    learner:
      cur_lr: 0.0013232368510216475
      grad_gnorm: 40.0
      policy_entropy: 18.55495834350586
      policy_loss: 3.6509318351745605
      var_gnorm: 31.44364356994629
      vf_explained_var: -0.19661033153533936
      vf_loss: 25.446210861206055
    num_steps_sampled: 555000
    num_steps_trained: 555000
    wait_time_ms: 49.452
  iterations_since_restore: 185
  node_ip: 172.17.8.3
  num_metric_batches_dropped: 0
  pid: 16746
  policy_reward_mean: {}
  time_since_restore: 1643.2588465213776
  time_this_iter_s: 9.088897943496704
  time_total_s: 1643.2588465213776
  timestamp: 1593884742
  timesteps_since_restore: 555000
  timesteps_this_iter: 3000
  timesteps_total: 555000
  training_iteration: 185
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 33.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=16746], 1643 s, 185 iter, 555000 ts, 750 rew

agent-1: 228.0
agent-2: 202.0
agent-3: 201.0
Sum Reward: 631.0
Avg Reward: 210.33333333333334
Min Reward: 201.0
Gini Coefficient: 0.028526148969889066
20:20 Ratio: 1.1343283582089552
Max-min Ratio: 1.1343283582089552
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_13-45-50
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 928.0
  episode_reward_mean: 748.84
  episode_reward_min: 449.0
  episodes_this_iter: 1
  episodes_total: 185
  experiment_id: 86e053a9c80f439496ed6b19bfe1ab59
  hostname: gpu003
  info:
    apply_time_ms: 2.869
    dispatch_time_ms: 28.192
    learner:
      cur_lr: 0.0013230369659140706
      grad_gnorm: 40.000003814697266
      policy_entropy: 18.119733810424805
      policy_loss: -4.528372764587402
      var_gnorm: 31.48473358154297
      vf_explained_var: 0.7352311611175537
      vf_loss: 35.0490837097168
    num_steps_sampled: 558000
    num_steps_trained: 558000
    wait_time_ms: 64.434
  iterations_since_restore: 186
  node_ip: 172.17.8.3
  num_metric_batches_dropped: 0
  pid: 16746
  policy_reward_mean: {}
  time_since_restore: 1651.8007955551147
  time_this_iter_s: 8.541949033737183
  time_total_s: 1651.8007955551147
  timestamp: 1593884750
  timesteps_since_restore: 558000
  timesteps_this_iter: 3000
  timesteps_total: 558000
  training_iteration: 186
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 33.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=16746], 1651 s, 186 iter, 558000 ts, 749 rew

agent-1: 220.0
agent-2: 265.0
agent-3: 274.0
Sum Reward: 759.0
Avg Reward: 253.0
Min Reward: 220.0
Gini Coefficient: 0.04743083003952569
20:20 Ratio: 1.2454545454545454
Max-min Ratio: 1.2454545454545454
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_13-46-00
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 928.0
  episode_reward_mean: 748.18
  episode_reward_min: 449.0
  episodes_this_iter: 1
  episodes_total: 186
  experiment_id: 86e053a9c80f439496ed6b19bfe1ab59
  hostname: gpu003
  info:
    apply_time_ms: 2.683
    dispatch_time_ms: 27.583
    learner:
      cur_lr: 0.0013228371972218156
      grad_gnorm: 26.817487716674805
      policy_entropy: 13.55374813079834
      policy_loss: 0.578150749206543
      var_gnorm: 31.49224281311035
      vf_explained_var: 0.1595640778541565
      vf_loss: 23.453638076782227
    num_steps_sampled: 561000
    num_steps_trained: 561000
    wait_time_ms: 69.538
  iterations_since_restore: 187
  node_ip: 172.17.8.3
  num_metric_batches_dropped: 0
  pid: 16746
  policy_reward_mean: {}
  time_since_restore: 1661.1599152088165
  time_this_iter_s: 9.359119653701782
  time_total_s: 1661.1599152088165
  timestamp: 1593884760
  timesteps_since_restore: 561000
  timesteps_this_iter: 3000
  timesteps_total: 561000
  training_iteration: 187
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 33.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=16746], 1661 s, 187 iter, 561000 ts, 748 rew

agent-1: 187.0
agent-2: 183.0
agent-3: 168.0
Sum Reward: 538.0
Avg Reward: 179.33333333333334
Min Reward: 168.0
Gini Coefficient: 0.023543990086741014
20:20 Ratio: 1.1130952380952381
Max-min Ratio: 1.1130952380952381
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_13-46-08
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 928.0
  episode_reward_mean: 745.77
  episode_reward_min: 449.0
  episodes_this_iter: 1
  episodes_total: 187
  experiment_id: 86e053a9c80f439496ed6b19bfe1ab59
  hostname: gpu003
  info:
    apply_time_ms: 3.798
    dispatch_time_ms: 26.959
    learner:
      cur_lr: 0.0013226374285295606
      grad_gnorm: 18.57897186279297
      policy_entropy: 11.089712142944336
      policy_loss: 7.194366455078125
      var_gnorm: 31.57823944091797
      vf_explained_var: 0.7192246317863464
      vf_loss: 18.165822982788086
    num_steps_sampled: 564000
    num_steps_trained: 564000
    wait_time_ms: 66.97
  iterations_since_restore: 188
  node_ip: 172.17.8.3
  num_metric_batches_dropped: 0
  pid: 16746
  policy_reward_mean: {}
  time_since_restore: 1669.8497574329376
  time_this_iter_s: 8.689842224121094
  time_total_s: 1669.8497574329376
  timestamp: 1593884768
  timesteps_since_restore: 564000
  timesteps_this_iter: 3000
  timesteps_total: 564000
  training_iteration: 188
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 33.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=16746], 1669 s, 188 iter, 564000 ts, 746 rew

agent-1: 240.0
agent-2: 229.0
agent-3: 259.0
Sum Reward: 728.0
Avg Reward: 242.66666666666666
Min Reward: 229.0
Gini Coefficient: 0.027472527472527472
20:20 Ratio: 1.1310043668122272
Max-min Ratio: 1.1310043668122272
agent-1: 222.0
agent-2: 224.0
agent-3: 214.0
Sum Reward: 660.0
Avg Reward: 220.0
Min Reward: 214.0
Gini Coefficient: 0.010101010101010102
20:20 Ratio: 1.0467289719626167
Max-min Ratio: 1.0467289719626167
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_13-46-18
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 928.0
  episode_reward_mean: 742.92
  episode_reward_min: 449.0
  episodes_this_iter: 2
  episodes_total: 189
  experiment_id: 86e053a9c80f439496ed6b19bfe1ab59
  hostname: gpu003
  info:
    apply_time_ms: 3.612
    dispatch_time_ms: 29.593
    learner:
      cur_lr: 0.0013224375434219837
      grad_gnorm: 40.0
      policy_entropy: 14.678009986877441
      policy_loss: 41.86000442504883
      var_gnorm: 31.638538360595703
      vf_explained_var: 0.3470120429992676
      vf_loss: 132.0684814453125
    num_steps_sampled: 567000
    num_steps_trained: 567000
    wait_time_ms: 56.672
  iterations_since_restore: 189
  node_ip: 172.17.8.3
  num_metric_batches_dropped: 0
  pid: 16746
  policy_reward_mean: {}
  time_since_restore: 1679.0914714336395
  time_this_iter_s: 9.241714000701904
  time_total_s: 1679.0914714336395
  timestamp: 1593884778
  timesteps_since_restore: 567000
  timesteps_this_iter: 3000
  timesteps_total: 567000
  training_iteration: 189
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 33.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=16746], 1679 s, 189 iter, 567000 ts, 743 rew

Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_13-46-26
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 928.0
  episode_reward_mean: 742.92
  episode_reward_min: 449.0
  episodes_this_iter: 0
  episodes_total: 189
  experiment_id: 86e053a9c80f439496ed6b19bfe1ab59
  hostname: gpu003
  info:
    apply_time_ms: 3.463
    dispatch_time_ms: 29.009
    learner:
      cur_lr: 0.0013222377747297287
      grad_gnorm: 29.13678550720215
      policy_entropy: 26.1646728515625
      policy_loss: -7.190684795379639
      var_gnorm: 31.723400115966797
      vf_explained_var: 0.5872734785079956
      vf_loss: 9.64450740814209
    num_steps_sampled: 570000
    num_steps_trained: 570000
    wait_time_ms: 56.535
  iterations_since_restore: 190
  node_ip: 172.17.8.3
  num_metric_batches_dropped: 0
  pid: 16746
  policy_reward_mean: {}
  time_since_restore: 1687.1215291023254
  time_this_iter_s: 8.030057668685913
  time_total_s: 1687.1215291023254
  timestamp: 1593884786
  timesteps_since_restore: 570000
  timesteps_this_iter: 3000
  timesteps_total: 570000
  training_iteration: 190
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 33.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=16746], 1687 s, 190 iter, 570000 ts, 743 rew

agent-1: 220.0
agent-2: 255.0
agent-3: 266.0
Sum Reward: 741.0
Avg Reward: 247.0
Min Reward: 220.0
Gini Coefficient: 0.0413855150697256
20:20 Ratio: 1.209090909090909
Max-min Ratio: 1.209090909090909
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_13-46-34
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 928.0
  episode_reward_mean: 741.75
  episode_reward_min: 449.0
  episodes_this_iter: 1
  episodes_total: 190
  experiment_id: 86e053a9c80f439496ed6b19bfe1ab59
  hostname: gpu003
  info:
    apply_time_ms: 2.498
    dispatch_time_ms: 30.417
    learner:
      cur_lr: 0.0013220380060374737
      grad_gnorm: 40.0
      policy_entropy: 15.729175567626953
      policy_loss: -7.561493873596191
      var_gnorm: 31.80070686340332
      vf_explained_var: 0.42206090688705444
      vf_loss: 17.724681854248047
    num_steps_sampled: 573000
    num_steps_trained: 573000
    wait_time_ms: 55.479
  iterations_since_restore: 191
  node_ip: 172.17.8.3
  num_metric_batches_dropped: 0
  pid: 16746
  policy_reward_mean: {}
  time_since_restore: 1695.7171063423157
  time_this_iter_s: 8.595577239990234
  time_total_s: 1695.7171063423157
  timestamp: 1593884794
  timesteps_since_restore: 573000
  timesteps_this_iter: 3000
  timesteps_total: 573000
  training_iteration: 191
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 33.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=16746], 1695 s, 191 iter, 573000 ts, 742 rew

agent-1: 247.0
agent-2: 235.0
agent-3: 205.0
Sum Reward: 687.0
Avg Reward: 229.0
Min Reward: 205.0
Gini Coefficient: 0.040756914119359534
20:20 Ratio: 1.2048780487804878
Max-min Ratio: 1.2048780487804878
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_13-46-42
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 928.0
  episode_reward_mean: 739.75
  episode_reward_min: 449.0
  episodes_this_iter: 1
  episodes_total: 191
  experiment_id: 86e053a9c80f439496ed6b19bfe1ab59
  hostname: gpu003
  info:
    apply_time_ms: 2.582
    dispatch_time_ms: 29.702
    learner:
      cur_lr: 0.0013218382373452187
      grad_gnorm: 40.0
      policy_entropy: 12.423829078674316
      policy_loss: 7.1056060791015625
      var_gnorm: 31.85552978515625
      vf_explained_var: -1.0
      vf_loss: 63.1639518737793
    num_steps_sampled: 576000
    num_steps_trained: 576000
    wait_time_ms: 51.368
  iterations_since_restore: 192
  node_ip: 172.17.8.3
  num_metric_batches_dropped: 0
  pid: 16746
  policy_reward_mean: {}
  time_since_restore: 1703.6631317138672
  time_this_iter_s: 7.946025371551514
  time_total_s: 1703.6631317138672
  timestamp: 1593884802
  timesteps_since_restore: 576000
  timesteps_this_iter: 3000
  timesteps_total: 576000
  training_iteration: 192
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 33.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=16746], 1703 s, 192 iter, 576000 ts, 740 rew

agent-1: 203.0
agent-2: 210.0
agent-3: 214.0
Sum Reward: 627.0
Avg Reward: 209.0
Min Reward: 203.0
Gini Coefficient: 0.011695906432748537
20:20 Ratio: 1.0541871921182266
Max-min Ratio: 1.0541871921182266
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_13-46-51
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 928.0
  episode_reward_mean: 738.66
  episode_reward_min: 449.0
  episodes_this_iter: 1
  episodes_total: 192
  experiment_id: 86e053a9c80f439496ed6b19bfe1ab59
  hostname: gpu003
  info:
    apply_time_ms: 3.163
    dispatch_time_ms: 54.955
    learner:
      cur_lr: 0.0013216383522376418
      grad_gnorm: 39.999996185302734
      policy_entropy: 27.506898880004883
      policy_loss: 23.842060089111328
      var_gnorm: 31.89656639099121
      vf_explained_var: -0.012267589569091797
      vf_loss: 68.72714233398438
    num_steps_sampled: 579000
    num_steps_trained: 579000
    wait_time_ms: 31.714
  iterations_since_restore: 193
  node_ip: 172.17.8.3
  num_metric_batches_dropped: 0
  pid: 16746
  policy_reward_mean: {}
  time_since_restore: 1712.070574760437
  time_this_iter_s: 8.407443046569824
  time_total_s: 1712.070574760437
  timestamp: 1593884811
  timesteps_since_restore: 579000
  timesteps_this_iter: 3000
  timesteps_total: 579000
  training_iteration: 193
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 33.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=16746], 1712 s, 193 iter, 579000 ts, 739 rew

agent-1: 201.0
agent-2: 254.0
agent-3: 219.0
Sum Reward: 674.0
Avg Reward: 224.66666666666666
Min Reward: 201.0
Gini Coefficient: 0.05242334322453017
20:20 Ratio: 1.263681592039801
Max-min Ratio: 1.263681592039801
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_13-46-59
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 928.0
  episode_reward_mean: 738.06
  episode_reward_min: 449.0
  episodes_this_iter: 1
  episodes_total: 193
  experiment_id: 86e053a9c80f439496ed6b19bfe1ab59
  hostname: gpu003
  info:
    apply_time_ms: 2.646
    dispatch_time_ms: 34.657
    learner:
      cur_lr: 0.0013214385835453868
      grad_gnorm: 22.516618728637695
      policy_entropy: 19.591144561767578
      policy_loss: 10.313758850097656
      var_gnorm: 31.90945816040039
      vf_explained_var: 0.44969242811203003
      vf_loss: 60.546356201171875
    num_steps_sampled: 582000
    num_steps_trained: 582000
    wait_time_ms: 46.887
  iterations_since_restore: 194
  node_ip: 172.17.8.3
  num_metric_batches_dropped: 0
  pid: 16746
  policy_reward_mean: {}
  time_since_restore: 1720.1199486255646
  time_this_iter_s: 8.049373865127563
  time_total_s: 1720.1199486255646
  timestamp: 1593884819
  timesteps_since_restore: 582000
  timesteps_this_iter: 3000
  timesteps_total: 582000
  training_iteration: 194
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 33.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=16746], 1720 s, 194 iter, 582000 ts, 738 rew

agent-1: 192.0
agent-2: 229.0
agent-3: 228.0
Sum Reward: 649.0
Avg Reward: 216.33333333333334
Min Reward: 192.0
Gini Coefficient: 0.03800719054956343
20:20 Ratio: 1.1927083333333333
Max-min Ratio: 1.1927083333333333
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_13-47-08
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 928.0
  episode_reward_mean: 736.26
  episode_reward_min: 449.0
  episodes_this_iter: 1
  episodes_total: 194
  experiment_id: 86e053a9c80f439496ed6b19bfe1ab59
  hostname: gpu003
  info:
    apply_time_ms: 2.991
    dispatch_time_ms: 29.305
    learner:
      cur_lr: 0.0013212388148531318
      grad_gnorm: 40.0
      policy_entropy: 24.699649810791016
      policy_loss: 33.95676040649414
      var_gnorm: 31.90126609802246
      vf_explained_var: 0.1414172649383545
      vf_loss: 62.70431137084961
    num_steps_sampled: 585000
    num_steps_trained: 585000
    wait_time_ms: 61.298
  iterations_since_restore: 195
  node_ip: 172.17.8.3
  num_metric_batches_dropped: 0
  pid: 16746
  policy_reward_mean: {}
  time_since_restore: 1729.335495710373
  time_this_iter_s: 9.21554708480835
  time_total_s: 1729.335495710373
  timestamp: 1593884828
  timesteps_since_restore: 585000
  timesteps_this_iter: 3000
  timesteps_total: 585000
  training_iteration: 195
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 33.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=16746], 1729 s, 195 iter, 585000 ts, 736 rew

agent-1: 253.0
agent-2: 272.0
agent-3: 263.0
Sum Reward: 788.0
Avg Reward: 262.6666666666667
Min Reward: 253.0
Gini Coefficient: 0.016074450084602367
20:20 Ratio: 1.075098814229249
Max-min Ratio: 1.075098814229249
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_13-47-16
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 928.0
  episode_reward_mean: 735.15
  episode_reward_min: 449.0
  episodes_this_iter: 1
  episodes_total: 195
  experiment_id: 86e053a9c80f439496ed6b19bfe1ab59
  hostname: gpu003
  info:
    apply_time_ms: 3.747
    dispatch_time_ms: 26.997
    learner:
      cur_lr: 0.0013210390461608768
      grad_gnorm: 40.000003814697266
      policy_entropy: 15.333291053771973
      policy_loss: -8.432908058166504
      var_gnorm: 31.932994842529297
      vf_explained_var: 0.6908230781555176
      vf_loss: 28.042776107788086
    num_steps_sampled: 588000
    num_steps_trained: 588000
    wait_time_ms: 53.967
  iterations_since_restore: 196
  node_ip: 172.17.8.3
  num_metric_batches_dropped: 0
  pid: 16746
  policy_reward_mean: {}
  time_since_restore: 1737.5768752098083
  time_this_iter_s: 8.241379499435425
  time_total_s: 1737.5768752098083
  timestamp: 1593884836
  timesteps_since_restore: 588000
  timesteps_this_iter: 3000
  timesteps_total: 588000
  training_iteration: 196
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 33.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=16746], 1737 s, 196 iter, 588000 ts, 735 rew

agent-1: 310.0
agent-2: 249.0
agent-3: 317.0
Sum Reward: 876.0
Avg Reward: 292.0
Min Reward: 249.0
Gini Coefficient: 0.0517503805175038
20:20 Ratio: 1.2730923694779117
Max-min Ratio: 1.2730923694779117
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_13-47-26
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 928.0
  episode_reward_mean: 736.32
  episode_reward_min: 449.0
  episodes_this_iter: 1
  episodes_total: 196
  experiment_id: 86e053a9c80f439496ed6b19bfe1ab59
  hostname: gpu003
  info:
    apply_time_ms: 3.04
    dispatch_time_ms: 25.775
    learner:
      cur_lr: 0.0013208391610533
      grad_gnorm: 40.0
      policy_entropy: 22.161827087402344
      policy_loss: -4.578413963317871
      var_gnorm: 31.969738006591797
      vf_explained_var: -0.19716966152191162
      vf_loss: 24.12795639038086
    num_steps_sampled: 591000
    num_steps_trained: 591000
    wait_time_ms: 60.137
  iterations_since_restore: 197
  node_ip: 172.17.8.3
  num_metric_batches_dropped: 0
  pid: 16746
  policy_reward_mean: {}
  time_since_restore: 1746.902509212494
  time_this_iter_s: 9.325634002685547
  time_total_s: 1746.902509212494
  timestamp: 1593884846
  timesteps_since_restore: 591000
  timesteps_this_iter: 3000
  timesteps_total: 591000
  training_iteration: 197
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 33.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=16746], 1746 s, 197 iter, 591000 ts, 736 rew

agent-1: 198.0
agent-2: 217.0
agent-3: 212.0
Sum Reward: 627.0
Avg Reward: 209.0
Min Reward: 198.0
Gini Coefficient: 0.020202020202020204
20:20 Ratio: 1.095959595959596
Max-min Ratio: 1.095959595959596
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_13-47-35
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 928.0
  episode_reward_mean: 735.2
  episode_reward_min: 449.0
  episodes_this_iter: 1
  episodes_total: 197
  experiment_id: 86e053a9c80f439496ed6b19bfe1ab59
  hostname: gpu003
  info:
    apply_time_ms: 2.956
    dispatch_time_ms: 45.472
    learner:
      cur_lr: 0.0013206393923610449
      grad_gnorm: 40.000003814697266
      policy_entropy: 18.998767852783203
      policy_loss: -16.88924789428711
      var_gnorm: 32.05953598022461
      vf_explained_var: -1.0
      vf_loss: 96.68746948242188
    num_steps_sampled: 594000
    num_steps_trained: 594000
    wait_time_ms: 47.429
  iterations_since_restore: 198
  node_ip: 172.17.8.3
  num_metric_batches_dropped: 0
  pid: 16746
  policy_reward_mean: {}
  time_since_restore: 1755.7130527496338
  time_this_iter_s: 8.810543537139893
  time_total_s: 1755.7130527496338
  timestamp: 1593884855
  timesteps_since_restore: 594000
  timesteps_this_iter: 3000
  timesteps_total: 594000
  training_iteration: 198
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 33.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=16746], 1755 s, 198 iter, 594000 ts, 735 rew

agent-1: 266.0
agent-2: 235.0
agent-3: 254.0
Sum Reward: 755.0
Avg Reward: 251.66666666666666
Min Reward: 235.0
Gini Coefficient: 0.027373068432671083
20:20 Ratio: 1.1319148936170214
Max-min Ratio: 1.1319148936170214
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_13-47-43
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 928.0
  episode_reward_mean: 734.31
  episode_reward_min: 449.0
  episodes_this_iter: 1
  episodes_total: 198
  experiment_id: 86e053a9c80f439496ed6b19bfe1ab59
  hostname: gpu003
  info:
    apply_time_ms: 2.78
    dispatch_time_ms: 39.372
    learner:
      cur_lr: 0.0013204396236687899
      grad_gnorm: 18.07308578491211
      policy_entropy: 15.824387550354004
      policy_loss: 3.9075047969818115
      var_gnorm: 32.12482833862305
      vf_explained_var: -0.7657983303070068
      vf_loss: 11.962879180908203
    num_steps_sampled: 597000
    num_steps_trained: 597000
    wait_time_ms: 36.159
  iterations_since_restore: 199
  node_ip: 172.17.8.3
  num_metric_batches_dropped: 0
  pid: 16746
  policy_reward_mean: {}
  time_since_restore: 1764.4109790325165
  time_this_iter_s: 8.69792628288269
  time_total_s: 1764.4109790325165
  timestamp: 1593884863
  timesteps_since_restore: 597000
  timesteps_this_iter: 3000
  timesteps_total: 597000
  training_iteration: 199
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 33.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=16746], 1764 s, 199 iter, 597000 ts, 734 rew

agent-1: 223.0
agent-2: 301.0
agent-3: 232.0
Sum Reward: 756.0
Avg Reward: 252.0
Min Reward: 223.0
Gini Coefficient: 0.06878306878306878
20:20 Ratio: 1.3497757847533631
Max-min Ratio: 1.3497757847533631
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_13-47-52
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 928.0
  episode_reward_mean: 733.91
  episode_reward_min: 449.0
  episodes_this_iter: 1
  episodes_total: 199
  experiment_id: 86e053a9c80f439496ed6b19bfe1ab59
  hostname: gpu003
  info:
    apply_time_ms: 3.419
    dispatch_time_ms: 33.817
    learner:
      cur_lr: 0.0013202398549765348
      grad_gnorm: 40.0
      policy_entropy: 15.930761337280273
      policy_loss: 6.39449405670166
      var_gnorm: 32.20770263671875
      vf_explained_var: -1.0
      vf_loss: 47.271240234375
    num_steps_sampled: 600000
    num_steps_trained: 600000
    wait_time_ms: 51.737
  iterations_since_restore: 200
  node_ip: 172.17.8.3
  num_metric_batches_dropped: 0
  pid: 16746
  policy_reward_mean: {}
  time_since_restore: 1773.056348323822
  time_this_iter_s: 8.645369291305542
  time_total_s: 1773.056348323822
  timestamp: 1593884872
  timesteps_since_restore: 600000
  timesteps_this_iter: 3000
  timesteps_total: 600000
  training_iteration: 200
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 33.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=16746], 1773 s, 200 iter, 600000 ts, 734 rew

agent-1: 240.0
agent-2: 270.0
agent-3: 244.0
Sum Reward: 754.0
Avg Reward: 251.33333333333334
Min Reward: 240.0
Gini Coefficient: 0.026525198938992044
20:20 Ratio: 1.125
Max-min Ratio: 1.125
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_13-48-02
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 928.0
  episode_reward_mean: 733.41
  episode_reward_min: 449.0
  episodes_this_iter: 1
  episodes_total: 200
  experiment_id: 86e053a9c80f439496ed6b19bfe1ab59
  hostname: gpu003
  info:
    apply_time_ms: 4.007
    dispatch_time_ms: 29.149
    learner:
      cur_lr: 0.001320039969868958
      grad_gnorm: 40.0
      policy_entropy: 14.491154670715332
      policy_loss: 12.479031562805176
      var_gnorm: 32.2408332824707
      vf_explained_var: 0.5761185884475708
      vf_loss: 31.05504608154297
    num_steps_sampled: 603000
    num_steps_trained: 603000
    wait_time_ms: 48.807
  iterations_since_restore: 201
  node_ip: 172.17.8.3
  num_metric_batches_dropped: 0
  pid: 16746
  policy_reward_mean: {}
  time_since_restore: 1781.2625131607056
  time_this_iter_s: 8.206164836883545
  time_total_s: 1781.2625131607056
  timestamp: 1593884882
  timesteps_since_restore: 603000
  timesteps_this_iter: 3000
  timesteps_total: 603000
  training_iteration: 201
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 33.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=16746], 1781 s, 201 iter, 603000 ts, 733 rew

agent-1: 305.0
agent-2: 294.0
agent-3: 243.0
Sum Reward: 842.0
Avg Reward: 280.6666666666667
Min Reward: 243.0
Gini Coefficient: 0.04908946951702296
20:20 Ratio: 1.2551440329218106
Max-min Ratio: 1.2551440329218106
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_13-48-11
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 928.0
  episode_reward_mean: 733.01
  episode_reward_min: 449.0
  episodes_this_iter: 1
  episodes_total: 201
  experiment_id: 86e053a9c80f439496ed6b19bfe1ab59
  hostname: gpu003
  info:
    apply_time_ms: 3.07
    dispatch_time_ms: 39.392
    learner:
      cur_lr: 0.001319840201176703
      grad_gnorm: 40.000003814697266
      policy_entropy: 12.13835334777832
      policy_loss: -9.23975944519043
      var_gnorm: 32.3394775390625
      vf_explained_var: -0.29068100452423096
      vf_loss: 55.957942962646484
    num_steps_sampled: 606000
    num_steps_trained: 606000
    wait_time_ms: 41.329
  iterations_since_restore: 202
  node_ip: 172.17.8.3
  num_metric_batches_dropped: 0
  pid: 16746
  policy_reward_mean: {}
  time_since_restore: 1789.9578840732574
  time_this_iter_s: 8.69537091255188
  time_total_s: 1789.9578840732574
  timestamp: 1593884891
  timesteps_since_restore: 606000
  timesteps_this_iter: 3000
  timesteps_total: 606000
  training_iteration: 202
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 33.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=16746], 1789 s, 202 iter, 606000 ts, 733 rew

agent-1: 200.0
agent-2: 272.0
agent-3: 224.0
Sum Reward: 696.0
Avg Reward: 232.0
Min Reward: 200.0
Gini Coefficient: 0.06896551724137931
20:20 Ratio: 1.36
Max-min Ratio: 1.36
agent-1: 255.0
agent-2: 235.0
agent-3: 292.0
Sum Reward: 782.0
Avg Reward: 260.6666666666667
Min Reward: 235.0
Gini Coefficient: 0.04859335038363171
20:20 Ratio: 1.2425531914893617
Max-min Ratio: 1.2425531914893617
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_13-48-23
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 928.0
  episode_reward_mean: 731.54
  episode_reward_min: 449.0
  episodes_this_iter: 2
  episodes_total: 203
  experiment_id: 86e053a9c80f439496ed6b19bfe1ab59
  hostname: gpu003
  info:
    apply_time_ms: 274.188
    dispatch_time_ms: 95.972
    learner:
      cur_lr: 0.001319640432484448
      grad_gnorm: 39.999996185302734
      policy_entropy: 9.2979097366333
      policy_loss: -2.7762136459350586
      var_gnorm: 32.36708068847656
      vf_explained_var: 0.4628329873085022
      vf_loss: 34.751373291015625
    num_steps_sampled: 609000
    num_steps_trained: 609000
    wait_time_ms: 46.815
  iterations_since_restore: 203
  node_ip: 172.17.8.3
  num_metric_batches_dropped: 0
  pid: 16746
  policy_reward_mean: {}
  time_since_restore: 1802.3768219947815
  time_this_iter_s: 12.418937921524048
  time_total_s: 1802.3768219947815
  timestamp: 1593884903
  timesteps_since_restore: 609000
  timesteps_this_iter: 3000
  timesteps_total: 609000
  training_iteration: 203
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 33.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=16746], 1802 s, 203 iter, 609000 ts, 732 rew

Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_13-48-31
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 928.0
  episode_reward_mean: 731.54
  episode_reward_min: 449.0
  episodes_this_iter: 0
  episodes_total: 203
  experiment_id: 86e053a9c80f439496ed6b19bfe1ab59
  hostname: gpu003
  info:
    apply_time_ms: 2.923
    dispatch_time_ms: 20.115
    learner:
      cur_lr: 0.0013194405473768711
      grad_gnorm: 23.145767211914062
      policy_entropy: 8.997567176818848
      policy_loss: -1.209465742111206
      var_gnorm: 32.45929718017578
      vf_explained_var: -0.21006011962890625
      vf_loss: 28.852603912353516
    num_steps_sampled: 612000
    num_steps_trained: 612000
    wait_time_ms: 62.413
  iterations_since_restore: 204
  node_ip: 172.17.8.3
  num_metric_batches_dropped: 0
  pid: 16746
  policy_reward_mean: {}
  time_since_restore: 1809.8893039226532
  time_this_iter_s: 7.512481927871704
  time_total_s: 1809.8893039226532
  timestamp: 1593884911
  timesteps_since_restore: 612000
  timesteps_this_iter: 3000
  timesteps_total: 612000
  training_iteration: 204
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 33.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=16746], 1809 s, 204 iter, 612000 ts, 732 rew

agent-1: 262.0
agent-2: 257.0
agent-3: 224.0
Sum Reward: 743.0
Avg Reward: 247.66666666666666
Min Reward: 224.0
Gini Coefficient: 0.03409600717810678
20:20 Ratio: 1.1696428571428572
Max-min Ratio: 1.1696428571428572
agent-1: 300.0
agent-2: 280.0
agent-3: 280.0
Sum Reward: 860.0
Avg Reward: 286.6666666666667
Min Reward: 280.0
Gini Coefficient: 0.015503875968992248
20:20 Ratio: 1.0714285714285714
Max-min Ratio: 1.0714285714285714
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_13-48-53
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 928.0
  episode_reward_mean: 731.69
  episode_reward_min: 449.0
  episodes_this_iter: 2
  episodes_total: 205
  experiment_id: 86e053a9c80f439496ed6b19bfe1ab59
  hostname: gpu003
  info:
    apply_time_ms: 4.105
    dispatch_time_ms: 1283.712
    learner:
      cur_lr: 0.001319240778684616
      grad_gnorm: 40.000003814697266
      policy_entropy: 19.45586585998535
      policy_loss: -4.062980651855469
      var_gnorm: 32.5140266418457
      vf_explained_var: 0.8529690504074097
      vf_loss: 16.534528732299805
    num_steps_sampled: 615000
    num_steps_trained: 615000
    wait_time_ms: 79.671
  iterations_since_restore: 205
  node_ip: 172.17.8.3
  num_metric_batches_dropped: 0
  pid: 16746
  policy_reward_mean: {}
  time_since_restore: 1831.7288188934326
  time_this_iter_s: 21.83951497077942
  time_total_s: 1831.7288188934326
  timestamp: 1593884933
  timesteps_since_restore: 615000
  timesteps_this_iter: 3000
  timesteps_total: 615000
  training_iteration: 205
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 33.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=16746], 1831 s, 205 iter, 615000 ts, 732 rew

Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_13-49-01
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 928.0
  episode_reward_mean: 731.69
  episode_reward_min: 449.0
  episodes_this_iter: 0
  episodes_total: 205
  experiment_id: 86e053a9c80f439496ed6b19bfe1ab59
  hostname: gpu003
  info:
    apply_time_ms: 2.821
    dispatch_time_ms: 16.598
    learner:
      cur_lr: 0.001319041009992361
      grad_gnorm: 37.08916473388672
      policy_entropy: 18.22307777404785
      policy_loss: -6.686341285705566
      var_gnorm: 32.544673919677734
      vf_explained_var: 0.908423900604248
      vf_loss: 11.896728515625
    num_steps_sampled: 618000
    num_steps_trained: 618000
    wait_time_ms: 72.489
  iterations_since_restore: 206
  node_ip: 172.17.8.3
  num_metric_batches_dropped: 0
  pid: 16746
  policy_reward_mean: {}
  time_since_restore: 1839.7116162776947
  time_this_iter_s: 7.982797384262085
  time_total_s: 1839.7116162776947
  timestamp: 1593884941
  timesteps_since_restore: 618000
  timesteps_this_iter: 3000
  timesteps_total: 618000
  training_iteration: 206
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 33.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=16746], 1839 s, 206 iter, 618000 ts, 732 rew

agent-1: 218.0
agent-2: 261.0
agent-3: 221.0
Sum Reward: 700.0
Avg Reward: 233.33333333333334
Min Reward: 218.0
Gini Coefficient: 0.040952380952380955
20:20 Ratio: 1.1972477064220184
Max-min Ratio: 1.1972477064220184
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_13-49-10
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 928.0
  episode_reward_mean: 730.94
  episode_reward_min: 449.0
  episodes_this_iter: 1
  episodes_total: 206
  experiment_id: 86e053a9c80f439496ed6b19bfe1ab59
  hostname: gpu003
  info:
    apply_time_ms: 4.035
    dispatch_time_ms: 17.416
    learner:
      cur_lr: 0.001318841241300106
      grad_gnorm: 39.999996185302734
      policy_entropy: 17.036701202392578
      policy_loss: -24.628047943115234
      var_gnorm: 32.54556655883789
      vf_explained_var: -0.6275161504745483
      vf_loss: 67.18449401855469
    num_steps_sampled: 621000
    num_steps_trained: 621000
    wait_time_ms: 72.311
  iterations_since_restore: 207
  node_ip: 172.17.8.3
  num_metric_batches_dropped: 0
  pid: 16746
  policy_reward_mean: {}
  time_since_restore: 1848.9366517066956
  time_this_iter_s: 9.225035429000854
  time_total_s: 1848.9366517066956
  timestamp: 1593884950
  timesteps_since_restore: 621000
  timesteps_this_iter: 3000
  timesteps_total: 621000
  training_iteration: 207
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 33.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=16746], 1848 s, 207 iter, 621000 ts, 731 rew

agent-1: 231.0
agent-2: 192.0
agent-3: 224.0
Sum Reward: 647.0
Avg Reward: 215.66666666666666
Min Reward: 192.0
Gini Coefficient: 0.0401854714064915
20:20 Ratio: 1.203125
Max-min Ratio: 1.203125
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_13-49-18
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 928.0
  episode_reward_mean: 729.44
  episode_reward_min: 449.0
  episodes_this_iter: 1
  episodes_total: 207
  experiment_id: 86e053a9c80f439496ed6b19bfe1ab59
  hostname: gpu003
  info:
    apply_time_ms: 3.985
    dispatch_time_ms: 35.231
    learner:
      cur_lr: 0.0013186413561925292
      grad_gnorm: 36.06006622314453
      policy_entropy: 24.57512092590332
      policy_loss: -15.123390197753906
      var_gnorm: 32.64418411254883
      vf_explained_var: 0.8102164268493652
      vf_loss: 36.366397857666016
    num_steps_sampled: 624000
    num_steps_trained: 624000
    wait_time_ms: 46.594
  iterations_since_restore: 208
  node_ip: 172.17.8.3
  num_metric_batches_dropped: 0
  pid: 16746
  policy_reward_mean: {}
  time_since_restore: 1857.4831359386444
  time_this_iter_s: 8.546484231948853
  time_total_s: 1857.4831359386444
  timestamp: 1593884958
  timesteps_since_restore: 624000
  timesteps_this_iter: 3000
  timesteps_total: 624000
  training_iteration: 208
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 33.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=16746], 1857 s, 208 iter, 624000 ts, 729 rew

agent-1: 277.0
agent-2: 264.0
agent-3: 264.0
Sum Reward: 805.0
Avg Reward: 268.3333333333333
Min Reward: 264.0
Gini Coefficient: 0.010766045548654244
20:20 Ratio: 1.0492424242424243
Max-min Ratio: 1.0492424242424243
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_13-49-28
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 928.0
  episode_reward_mean: 730.44
  episode_reward_min: 449.0
  episodes_this_iter: 1
  episodes_total: 208
  experiment_id: 86e053a9c80f439496ed6b19bfe1ab59
  hostname: gpu003
  info:
    apply_time_ms: 3.274
    dispatch_time_ms: 27.853
    learner:
      cur_lr: 0.0013184415875002742
      grad_gnorm: 24.54355812072754
      policy_entropy: 15.299673080444336
      policy_loss: 6.05617094039917
      var_gnorm: 32.642303466796875
      vf_explained_var: -1.0
      vf_loss: 16.57545280456543
    num_steps_sampled: 627000
    num_steps_trained: 627000
    wait_time_ms: 66.757
  iterations_since_restore: 209
  node_ip: 172.17.8.3
  num_metric_batches_dropped: 0
  pid: 16746
  policy_reward_mean: {}
  time_since_restore: 1866.6383950710297
  time_this_iter_s: 9.155259132385254
  time_total_s: 1866.6383950710297
  timestamp: 1593884968
  timesteps_since_restore: 627000
  timesteps_this_iter: 3000
  timesteps_total: 627000
  training_iteration: 209
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 33.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=16746], 1866 s, 209 iter, 627000 ts, 730 rew

agent-1: 270.0
agent-2: 249.0
agent-3: 276.0
Sum Reward: 795.0
Avg Reward: 265.0
Min Reward: 249.0
Gini Coefficient: 0.022641509433962263
20:20 Ratio: 1.108433734939759
Max-min Ratio: 1.108433734939759
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_13-49-36
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 928.0
  episode_reward_mean: 731.21
  episode_reward_min: 449.0
  episodes_this_iter: 1
  episodes_total: 209
  experiment_id: 86e053a9c80f439496ed6b19bfe1ab59
  hostname: gpu003
  info:
    apply_time_ms: 3.02
    dispatch_time_ms: 31.692
    learner:
      cur_lr: 0.0013182418188080192
      grad_gnorm: 39.999996185302734
      policy_entropy: 14.241388320922852
      policy_loss: 6.775137424468994
      var_gnorm: 32.6540641784668
      vf_explained_var: 0.6537125110626221
      vf_loss: 28.860443115234375
    num_steps_sampled: 630000
    num_steps_trained: 630000
    wait_time_ms: 55.306
  iterations_since_restore: 210
  node_ip: 172.17.8.3
  num_metric_batches_dropped: 0
  pid: 16746
  policy_reward_mean: {}
  time_since_restore: 1875.1467688083649
  time_this_iter_s: 8.508373737335205
  time_total_s: 1875.1467688083649
  timestamp: 1593884976
  timesteps_since_restore: 630000
  timesteps_this_iter: 3000
  timesteps_total: 630000
  training_iteration: 210
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 33.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=16746], 1875 s, 210 iter, 630000 ts, 731 rew

agent-1: 242.0
agent-2: 264.0
agent-3: 281.0
Sum Reward: 787.0
Avg Reward: 262.3333333333333
Min Reward: 242.0
Gini Coefficient: 0.03303684879288437
20:20 Ratio: 1.1611570247933884
Max-min Ratio: 1.1611570247933884
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_13-49-45
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 928.0
  episode_reward_mean: 733.47
  episode_reward_min: 449.0
  episodes_this_iter: 1
  episodes_total: 210
  experiment_id: 86e053a9c80f439496ed6b19bfe1ab59
  hostname: gpu003
  info:
    apply_time_ms: 2.635
    dispatch_time_ms: 30.236
    learner:
      cur_lr: 0.0013180420501157641
      grad_gnorm: 34.42496109008789
      policy_entropy: 25.426916122436523
      policy_loss: -0.7730774879455566
      var_gnorm: 32.69266128540039
      vf_explained_var: -0.6787476539611816
      vf_loss: 41.949615478515625
    num_steps_sampled: 633000
    num_steps_trained: 633000
    wait_time_ms: 46.83
  iterations_since_restore: 211
  node_ip: 172.17.8.3
  num_metric_batches_dropped: 0
  pid: 16746
  policy_reward_mean: {}
  time_since_restore: 1883.460461616516
  time_this_iter_s: 8.313692808151245
  time_total_s: 1883.460461616516
  timestamp: 1593884985
  timesteps_since_restore: 633000
  timesteps_this_iter: 3000
  timesteps_total: 633000
  training_iteration: 211
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 33.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=16746], 1883 s, 211 iter, 633000 ts, 733 rew

agent-1: 238.0
agent-2: 245.0
agent-3: 210.0
Sum Reward: 693.0
Avg Reward: 231.0
Min Reward: 210.0
Gini Coefficient: 0.03367003367003367
20:20 Ratio: 1.1666666666666667
Max-min Ratio: 1.1666666666666667
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_13-49-53
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 928.0
  episode_reward_mean: 735.91
  episode_reward_min: 538.0
  episodes_this_iter: 1
  episodes_total: 211
  experiment_id: 86e053a9c80f439496ed6b19bfe1ab59
  hostname: gpu003
  info:
    apply_time_ms: 3.727
    dispatch_time_ms: 42.018
    learner:
      cur_lr: 0.0013178421650081873
      grad_gnorm: 30.634918212890625
      policy_entropy: 19.092086791992188
      policy_loss: 2.113860607147217
      var_gnorm: 32.72461700439453
      vf_explained_var: 0.5587165355682373
      vf_loss: 49.58209228515625
    num_steps_sampled: 636000
    num_steps_trained: 636000
    wait_time_ms: 43.229
  iterations_since_restore: 212
  node_ip: 172.17.8.3
  num_metric_batches_dropped: 0
  pid: 16746
  policy_reward_mean: {}
  time_since_restore: 1891.6617465019226
  time_this_iter_s: 8.201284885406494
  time_total_s: 1891.6617465019226
  timestamp: 1593884993
  timesteps_since_restore: 636000
  timesteps_this_iter: 3000
  timesteps_total: 636000
  training_iteration: 212
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 33.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=16746], 1891 s, 212 iter, 636000 ts, 736 rew

agent-1: 217.0
agent-2: 225.0
agent-3: 151.0
Sum Reward: 593.0
Avg Reward: 197.66666666666666
Min Reward: 151.0
Gini Coefficient: 0.08319280494659921
20:20 Ratio: 1.490066225165563
Max-min Ratio: 1.490066225165563
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_13-50-01
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 928.0
  episode_reward_mean: 735.9
  episode_reward_min: 538.0
  episodes_this_iter: 1
  episodes_total: 212
  experiment_id: 86e053a9c80f439496ed6b19bfe1ab59
  hostname: gpu003
  info:
    apply_time_ms: 3.172
    dispatch_time_ms: 32.053
    learner:
      cur_lr: 0.0013176423963159323
      grad_gnorm: 39.999996185302734
      policy_entropy: 23.939599990844727
      policy_loss: -22.17873764038086
      var_gnorm: 32.739646911621094
      vf_explained_var: -0.123421311378479
      vf_loss: 27.66309928894043
    num_steps_sampled: 639000
    num_steps_trained: 639000
    wait_time_ms: 42.015
  iterations_since_restore: 213
  node_ip: 172.17.8.3
  num_metric_batches_dropped: 0
  pid: 16746
  policy_reward_mean: {}
  time_since_restore: 1899.4862442016602
  time_this_iter_s: 7.824497699737549
  time_total_s: 1899.4862442016602
  timestamp: 1593885001
  timesteps_since_restore: 639000
  timesteps_this_iter: 3000
  timesteps_total: 639000
  training_iteration: 213
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 33.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=16746], 1899 s, 213 iter, 639000 ts, 736 rew

agent-1: 189.0
agent-2: 211.0
agent-3: 207.0
Sum Reward: 607.0
Avg Reward: 202.33333333333334
Min Reward: 189.0
Gini Coefficient: 0.02416254805052169
20:20 Ratio: 1.1164021164021165
Max-min Ratio: 1.1164021164021165
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_13-50-08
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 928.0
  episode_reward_mean: 734.74
  episode_reward_min: 538.0
  episodes_this_iter: 1
  episodes_total: 213
  experiment_id: 86e053a9c80f439496ed6b19bfe1ab59
  hostname: gpu003
  info:
    apply_time_ms: 2.852
    dispatch_time_ms: 38.994
    learner:
      cur_lr: 0.0013174426276236773
      grad_gnorm: 40.00000762939453
      policy_entropy: 19.009462356567383
      policy_loss: 3.505373477935791
      var_gnorm: 32.742733001708984
      vf_explained_var: 0.6728781461715698
      vf_loss: 23.797500610351562
    num_steps_sampled: 642000
    num_steps_trained: 642000
    wait_time_ms: 41.067
  iterations_since_restore: 214
  node_ip: 172.17.8.3
  num_metric_batches_dropped: 0
  pid: 16746
  policy_reward_mean: {}
  time_since_restore: 1907.2702028751373
  time_this_iter_s: 7.783958673477173
  time_total_s: 1907.2702028751373
  timestamp: 1593885008
  timesteps_since_restore: 642000
  timesteps_this_iter: 3000
  timesteps_total: 642000
  training_iteration: 214
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 33.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=16746], 1907 s, 214 iter, 642000 ts, 735 rew

agent-1: 187.0
agent-2: 210.0
agent-3: 207.0
Sum Reward: 604.0
Avg Reward: 201.33333333333334
Min Reward: 187.0
Gini Coefficient: 0.025386313465783666
20:20 Ratio: 1.1229946524064172
Max-min Ratio: 1.1229946524064172
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_13-50-17
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 928.0
  episode_reward_mean: 731.93
  episode_reward_min: 538.0
  episodes_this_iter: 1
  episodes_total: 214
  experiment_id: 86e053a9c80f439496ed6b19bfe1ab59
  hostname: gpu003
  info:
    apply_time_ms: 3.055
    dispatch_time_ms: 37.069
    learner:
      cur_lr: 0.0013172427425161004
      grad_gnorm: 39.999996185302734
      policy_entropy: 22.430580139160156
      policy_loss: -14.859065055847168
      var_gnorm: 32.80833435058594
      vf_explained_var: 0.5762841701507568
      vf_loss: 15.413461685180664
    num_steps_sampled: 645000
    num_steps_trained: 645000
    wait_time_ms: 35.946
  iterations_since_restore: 215
  node_ip: 172.17.8.3
  num_metric_batches_dropped: 0
  pid: 16746
  policy_reward_mean: {}
  time_since_restore: 1915.3842585086823
  time_this_iter_s: 8.114055633544922
  time_total_s: 1915.3842585086823
  timestamp: 1593885017
  timesteps_since_restore: 645000
  timesteps_this_iter: 3000
  timesteps_total: 645000
  training_iteration: 215
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 33.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=16746], 1915 s, 215 iter, 645000 ts, 732 rew

agent-1: 170.0
agent-2: 222.0
agent-3: 201.0
Sum Reward: 593.0
Avg Reward: 197.66666666666666
Min Reward: 170.0
Gini Coefficient: 0.05845980888139404
20:20 Ratio: 1.3058823529411765
Max-min Ratio: 1.3058823529411765
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_13-50-24
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 928.0
  episode_reward_mean: 729.21
  episode_reward_min: 538.0
  episodes_this_iter: 1
  episodes_total: 215
  experiment_id: 86e053a9c80f439496ed6b19bfe1ab59
  hostname: gpu003
  info:
    apply_time_ms: 2.844
    dispatch_time_ms: 28.544
    learner:
      cur_lr: 0.0013170429738238454
      grad_gnorm: 39.999996185302734
      policy_entropy: 16.967985153198242
      policy_loss: 9.116230010986328
      var_gnorm: 32.8282585144043
      vf_explained_var: 0.5381698608398438
      vf_loss: 44.31050491333008
    num_steps_sampled: 648000
    num_steps_trained: 648000
    wait_time_ms: 49.636
  iterations_since_restore: 216
  node_ip: 172.17.8.3
  num_metric_batches_dropped: 0
  pid: 16746
  policy_reward_mean: {}
  time_since_restore: 1922.8816237449646
  time_this_iter_s: 7.497365236282349
  time_total_s: 1922.8816237449646
  timestamp: 1593885024
  timesteps_since_restore: 648000
  timesteps_this_iter: 3000
  timesteps_total: 648000
  training_iteration: 216
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 33.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=16746], 1922 s, 216 iter, 648000 ts, 729 rew

agent-1: 160.0
agent-2: 225.0
agent-3: 169.0
Sum Reward: 554.0
Avg Reward: 184.66666666666666
Min Reward: 160.0
Gini Coefficient: 0.07821901323706378
20:20 Ratio: 1.40625
Max-min Ratio: 1.40625
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_13-50-32
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 928.0
  episode_reward_mean: 726.41
  episode_reward_min: 538.0
  episodes_this_iter: 1
  episodes_total: 216
  experiment_id: 86e053a9c80f439496ed6b19bfe1ab59
  hostname: gpu003
  info:
    apply_time_ms: 3.669
    dispatch_time_ms: 35.352
    learner:
      cur_lr: 0.0013168432051315904
      grad_gnorm: 40.0
      policy_entropy: 16.119335174560547
      policy_loss: 6.088801860809326
      var_gnorm: 32.863155364990234
      vf_explained_var: -1.0
      vf_loss: 31.018598556518555
    num_steps_sampled: 651000
    num_steps_trained: 651000
    wait_time_ms: 43.602
  iterations_since_restore: 217
  node_ip: 172.17.8.3
  num_metric_batches_dropped: 0
  pid: 16746
  policy_reward_mean: {}
  time_since_restore: 1930.779783964157
  time_this_iter_s: 7.898160219192505
  time_total_s: 1930.779783964157
  timestamp: 1593885032
  timesteps_since_restore: 651000
  timesteps_this_iter: 3000
  timesteps_total: 651000
  training_iteration: 217
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 33.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=16746], 1930 s, 217 iter, 651000 ts, 726 rew

agent-1: 170.0
agent-2: 207.0
agent-3: 195.0
Sum Reward: 572.0
Avg Reward: 190.66666666666666
Min Reward: 170.0
Gini Coefficient: 0.04312354312354312
20:20 Ratio: 1.2176470588235293
Max-min Ratio: 1.2176470588235293
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_13-50-40
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 928.0
  episode_reward_mean: 724.7
  episode_reward_min: 538.0
  episodes_this_iter: 1
  episodes_total: 217
  experiment_id: 86e053a9c80f439496ed6b19bfe1ab59
  hostname: gpu003
  info:
    apply_time_ms: 2.43
    dispatch_time_ms: 45.464
    learner:
      cur_lr: 0.0013166434364393353
      grad_gnorm: 40.0
      policy_entropy: 11.104569435119629
      policy_loss: 1.9750962257385254
      var_gnorm: 32.885650634765625
      vf_explained_var: -0.21251606941223145
      vf_loss: 32.34719467163086
    num_steps_sampled: 654000
    num_steps_trained: 654000
    wait_time_ms: 30.278
  iterations_since_restore: 218
  node_ip: 172.17.8.3
  num_metric_batches_dropped: 0
  pid: 16746
  policy_reward_mean: {}
  time_since_restore: 1938.7465274333954
  time_this_iter_s: 7.966743469238281
  time_total_s: 1938.7465274333954
  timestamp: 1593885040
  timesteps_since_restore: 654000
  timesteps_this_iter: 3000
  timesteps_total: 654000
  training_iteration: 218
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 33.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=16746], 1938 s, 218 iter, 654000 ts, 725 rew

agent-1: 204.0
agent-2: 168.0
agent-3: 198.0
Sum Reward: 570.0
Avg Reward: 190.0
Min Reward: 168.0
Gini Coefficient: 0.042105263157894736
20:20 Ratio: 1.2142857142857142
Max-min Ratio: 1.2142857142857142
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_13-50-48
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 928.0
  episode_reward_mean: 722.44
  episode_reward_min: 538.0
  episodes_this_iter: 1
  episodes_total: 218
  experiment_id: 86e053a9c80f439496ed6b19bfe1ab59
  hostname: gpu003
  info:
    apply_time_ms: 3.167
    dispatch_time_ms: 29.182
    learner:
      cur_lr: 0.0013164435513317585
      grad_gnorm: 36.09758758544922
      policy_entropy: 10.608052253723145
      policy_loss: -0.7578017115592957
      var_gnorm: 32.90880584716797
      vf_explained_var: 0.7201092839241028
      vf_loss: 10.058353424072266
    num_steps_sampled: 657000
    num_steps_trained: 657000
    wait_time_ms: 44.178
  iterations_since_restore: 219
  node_ip: 172.17.8.3
  num_metric_batches_dropped: 0
  pid: 16746
  policy_reward_mean: {}
  time_since_restore: 1946.3233006000519
  time_this_iter_s: 7.576773166656494
  time_total_s: 1946.3233006000519
  timestamp: 1593885048
  timesteps_since_restore: 657000
  timesteps_this_iter: 3000
  timesteps_total: 657000
  training_iteration: 219
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 33.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=16746], 1946 s, 219 iter, 657000 ts, 722 rew

agent-1: 135.0
agent-2: 194.0
agent-3: 224.0
Sum Reward: 553.0
Avg Reward: 184.33333333333334
Min Reward: 135.0
Gini Coefficient: 0.10729355033152502
20:20 Ratio: 1.6592592592592592
Max-min Ratio: 1.6592592592592592
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_13-50-56
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 928.0
  episode_reward_mean: 719.82
  episode_reward_min: 538.0
  episodes_this_iter: 1
  episodes_total: 219
  experiment_id: 86e053a9c80f439496ed6b19bfe1ab59
  hostname: gpu003
  info:
    apply_time_ms: 2.602
    dispatch_time_ms: 26.375
    learner:
      cur_lr: 0.0013162437826395035
      grad_gnorm: 40.0
      policy_entropy: 16.727500915527344
      policy_loss: 16.938758850097656
      var_gnorm: 32.919883728027344
      vf_explained_var: -0.5951972007751465
      vf_loss: 50.28594970703125
    num_steps_sampled: 660000
    num_steps_trained: 660000
    wait_time_ms: 52.612
  iterations_since_restore: 220
  node_ip: 172.17.8.3
  num_metric_batches_dropped: 0
  pid: 16746
  policy_reward_mean: {}
  time_since_restore: 1954.1635994911194
  time_this_iter_s: 7.840298891067505
  time_total_s: 1954.1635994911194
  timestamp: 1593885056
  timesteps_since_restore: 660000
  timesteps_this_iter: 3000
  timesteps_total: 660000
  training_iteration: 220
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 33.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=16746], 1954 s, 220 iter, 660000 ts, 720 rew

agent-1: 189.0
agent-2: 265.0
agent-3: 204.0
Sum Reward: 658.0
Avg Reward: 219.33333333333334
Min Reward: 189.0
Gini Coefficient: 0.07700101317122594
20:20 Ratio: 1.402116402116402
Max-min Ratio: 1.402116402116402
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_13-51-04
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 928.0
  episode_reward_mean: 718.24
  episode_reward_min: 538.0
  episodes_this_iter: 1
  episodes_total: 220
  experiment_id: 86e053a9c80f439496ed6b19bfe1ab59
  hostname: gpu003
  info:
    apply_time_ms: 3.351
    dispatch_time_ms: 31.066
    learner:
      cur_lr: 0.0013160440139472485
      grad_gnorm: 40.0
      policy_entropy: 19.631078720092773
      policy_loss: -13.66828727722168
      var_gnorm: 32.946624755859375
      vf_explained_var: -1.0
      vf_loss: 52.95587921142578
    num_steps_sampled: 663000
    num_steps_trained: 663000
    wait_time_ms: 45.264
  iterations_since_restore: 221
  node_ip: 172.17.8.3
  num_metric_batches_dropped: 0
  pid: 16746
  policy_reward_mean: {}
  time_since_restore: 1962.2336947917938
  time_this_iter_s: 8.070095300674438
  time_total_s: 1962.2336947917938
  timestamp: 1593885064
  timesteps_since_restore: 663000
  timesteps_this_iter: 3000
  timesteps_total: 663000
  training_iteration: 221
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 33.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=16746], 1962 s, 221 iter, 663000 ts, 718 rew

agent-1: 233.0
agent-2: 202.0
agent-3: 216.0
Sum Reward: 651.0
Avg Reward: 217.0
Min Reward: 202.0
Gini Coefficient: 0.031746031746031744
20:20 Ratio: 1.1534653465346534
Max-min Ratio: 1.1534653465346534
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_13-51-12
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 928.0
  episode_reward_mean: 717.01
  episode_reward_min: 538.0
  episodes_this_iter: 1
  episodes_total: 221
  experiment_id: 86e053a9c80f439496ed6b19bfe1ab59
  hostname: gpu003
  info:
    apply_time_ms: 4.032
    dispatch_time_ms: 31.473
    learner:
      cur_lr: 0.0013158442452549934
      grad_gnorm: 40.0
      policy_entropy: 9.28831672668457
      policy_loss: 13.390373229980469
      var_gnorm: 32.969974517822266
      vf_explained_var: -0.21601128578186035
      vf_loss: 29.660781860351562
    num_steps_sampled: 666000
    num_steps_trained: 666000
    wait_time_ms: 49.445
  iterations_since_restore: 222
  node_ip: 172.17.8.3
  num_metric_batches_dropped: 0
  pid: 16746
  policy_reward_mean: {}
  time_since_restore: 1970.3009765148163
  time_this_iter_s: 8.067281723022461
  time_total_s: 1970.3009765148163
  timestamp: 1593885072
  timesteps_since_restore: 666000
  timesteps_this_iter: 3000
  timesteps_total: 666000
  training_iteration: 222
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 33.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=16746], 1970 s, 222 iter, 666000 ts, 717 rew

agent-1: 293.0
agent-2: 155.0
agent-3: 245.0
Sum Reward: 693.0
Avg Reward: 231.0
Min Reward: 155.0
Gini Coefficient: 0.13275613275613277
20:20 Ratio: 1.8903225806451613
Max-min Ratio: 1.8903225806451613
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_13-51-21
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 928.0
  episode_reward_mean: 715.2
  episode_reward_min: 538.0
  episodes_this_iter: 1
  episodes_total: 222
  experiment_id: 86e053a9c80f439496ed6b19bfe1ab59
  hostname: gpu003
  info:
    apply_time_ms: 3.139
    dispatch_time_ms: 24.058
    learner:
      cur_lr: 0.0013156443601474166
      grad_gnorm: 20.308229446411133
      policy_entropy: 23.644351959228516
      policy_loss: 4.043672561645508
      var_gnorm: 33.078651428222656
      vf_explained_var: 0.25780463218688965
      vf_loss: 44.08626174926758
    num_steps_sampled: 669000
    num_steps_trained: 669000
    wait_time_ms: 57.183
  iterations_since_restore: 223
  node_ip: 172.17.8.3
  num_metric_batches_dropped: 0
  pid: 16746
  policy_reward_mean: {}
  time_since_restore: 1978.2947397232056
  time_this_iter_s: 7.993763208389282
  time_total_s: 1978.2947397232056
  timestamp: 1593885081
  timesteps_since_restore: 669000
  timesteps_this_iter: 3000
  timesteps_total: 669000
  training_iteration: 223
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 33.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=16746], 1978 s, 223 iter, 669000 ts, 715 rew

agent-1: 206.0
agent-2: 228.0
agent-3: 233.0
Sum Reward: 667.0
Avg Reward: 222.33333333333334
Min Reward: 206.0
Gini Coefficient: 0.026986506746626688
20:20 Ratio: 1.1310679611650485
Max-min Ratio: 1.1310679611650485
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_13-51-29
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 928.0
  episode_reward_mean: 715.81
  episode_reward_min: 538.0
  episodes_this_iter: 1
  episodes_total: 223
  experiment_id: 86e053a9c80f439496ed6b19bfe1ab59
  hostname: gpu003
  info:
    apply_time_ms: 2.986
    dispatch_time_ms: 36.289
    learner:
      cur_lr: 0.0013154445914551616
      grad_gnorm: 40.0
      policy_entropy: 27.508777618408203
      policy_loss: -17.247901916503906
      var_gnorm: 33.09868621826172
      vf_explained_var: 0.4350297451019287
      vf_loss: 15.279455184936523
    num_steps_sampled: 672000
    num_steps_trained: 672000
    wait_time_ms: 42.51
  iterations_since_restore: 224
  node_ip: 172.17.8.3
  num_metric_batches_dropped: 0
  pid: 16746
  policy_reward_mean: {}
  time_since_restore: 1986.2786917686462
  time_this_iter_s: 7.983952045440674
  time_total_s: 1986.2786917686462
  timestamp: 1593885089
  timesteps_since_restore: 672000
  timesteps_this_iter: 3000
  timesteps_total: 672000
  training_iteration: 224
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 33.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=16746], 1986 s, 224 iter, 672000 ts, 716 rew

agent-1: 211.0
agent-2: 188.0
agent-3: 237.0
Sum Reward: 636.0
Avg Reward: 212.0
Min Reward: 188.0
Gini Coefficient: 0.051362683438155136
20:20 Ratio: 1.2606382978723405
Max-min Ratio: 1.2606382978723405
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_13-51-37
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 928.0
  episode_reward_mean: 716.18
  episode_reward_min: 538.0
  episodes_this_iter: 1
  episodes_total: 224
  experiment_id: 86e053a9c80f439496ed6b19bfe1ab59
  hostname: gpu003
  info:
    apply_time_ms: 2.749
    dispatch_time_ms: 30.905
    learner:
      cur_lr: 0.0013152448227629066
      grad_gnorm: 18.711557388305664
      policy_entropy: 26.65578842163086
      policy_loss: -3.727323532104492
      var_gnorm: 33.14424514770508
      vf_explained_var: 0.02926015853881836
      vf_loss: 43.90928268432617
    num_steps_sampled: 675000
    num_steps_trained: 675000
    wait_time_ms: 44.047
  iterations_since_restore: 225
  node_ip: 172.17.8.3
  num_metric_batches_dropped: 0
  pid: 16746
  policy_reward_mean: {}
  time_since_restore: 1994.2391030788422
  time_this_iter_s: 7.960411310195923
  time_total_s: 1994.2391030788422
  timestamp: 1593885097
  timesteps_since_restore: 675000
  timesteps_this_iter: 3000
  timesteps_total: 675000
  training_iteration: 225
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 33.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=16746], 1994 s, 225 iter, 675000 ts, 716 rew

agent-1: 210.0
agent-2: 233.0
agent-3: 223.0
Sum Reward: 666.0
Avg Reward: 222.0
Min Reward: 210.0
Gini Coefficient: 0.023023023023023025
20:20 Ratio: 1.1095238095238096
Max-min Ratio: 1.1095238095238096
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_13-51-45
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 928.0
  episode_reward_mean: 717.41
  episode_reward_min: 538.0
  episodes_this_iter: 1
  episodes_total: 225
  experiment_id: 86e053a9c80f439496ed6b19bfe1ab59
  hostname: gpu003
  info:
    apply_time_ms: 3.96
    dispatch_time_ms: 28.526
    learner:
      cur_lr: 0.0013150450540706515
      grad_gnorm: 40.0
      policy_entropy: 22.032194137573242
      policy_loss: -3.470022201538086
      var_gnorm: 33.160213470458984
      vf_explained_var: 0.441736102104187
      vf_loss: 30.659788131713867
    num_steps_sampled: 678000
    num_steps_trained: 678000
    wait_time_ms: 47.463
  iterations_since_restore: 226
  node_ip: 172.17.8.3
  num_metric_batches_dropped: 0
  pid: 16746
  policy_reward_mean: {}
  time_since_restore: 2002.0923249721527
  time_this_iter_s: 7.853221893310547
  time_total_s: 2002.0923249721527
  timestamp: 1593885105
  timesteps_since_restore: 678000
  timesteps_this_iter: 3000
  timesteps_total: 678000
  training_iteration: 226
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 33.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=16746], 2002 s, 226 iter, 678000 ts, 717 rew

agent-1: 213.0
agent-2: 189.0
agent-3: 224.0
Sum Reward: 626.0
Avg Reward: 208.66666666666666
Min Reward: 189.0
Gini Coefficient: 0.03727369542066028
20:20 Ratio: 1.1851851851851851
Max-min Ratio: 1.1851851851851851
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_13-51-53
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 928.0
  episode_reward_mean: 718.02
  episode_reward_min: 538.0
  episodes_this_iter: 1
  episodes_total: 226
  experiment_id: 86e053a9c80f439496ed6b19bfe1ab59
  hostname: gpu003
  info:
    apply_time_ms: 3.04
    dispatch_time_ms: 41.116
    learner:
      cur_lr: 0.0013148451689630747
      grad_gnorm: 40.0
      policy_entropy: 23.208354949951172
      policy_loss: 4.260496139526367
      var_gnorm: 33.161170959472656
      vf_explained_var: 0.22097253799438477
      vf_loss: 78.21421813964844
    num_steps_sampled: 681000
    num_steps_trained: 681000
    wait_time_ms: 35.181
  iterations_since_restore: 227
  node_ip: 172.17.8.3
  num_metric_batches_dropped: 0
  pid: 16746
  policy_reward_mean: {}
  time_since_restore: 2010.3872454166412
  time_this_iter_s: 8.294920444488525
  time_total_s: 2010.3872454166412
  timestamp: 1593885113
  timesteps_since_restore: 681000
  timesteps_this_iter: 3000
  timesteps_total: 681000
  training_iteration: 227
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 33.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=16746], 2010 s, 227 iter, 681000 ts, 718 rew

agent-1: 181.0
agent-2: 236.0
agent-3: 277.0
Sum Reward: 694.0
Avg Reward: 231.33333333333334
Min Reward: 181.0
Gini Coefficient: 0.09221902017291066
20:20 Ratio: 1.5303867403314917
Max-min Ratio: 1.5303867403314917
W0704 13:51:57.493547 16738 client_connection.cc:255] [worker]ProcessMessage with type 16 took 253 ms.
W0704 13:51:57.734596 16738 node_manager.cc:250] Last heartbeat was sent 619 ms ago 
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_13-52-02
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 928.0
  episode_reward_mean: 716.54
  episode_reward_min: 538.0
  episodes_this_iter: 1
  episodes_total: 227
  experiment_id: 86e053a9c80f439496ed6b19bfe1ab59
  hostname: gpu003
  info:
    apply_time_ms: 2.841
    dispatch_time_ms: 26.207
    learner:
      cur_lr: 0.0013146454002708197
      grad_gnorm: 10.76688003540039
      policy_entropy: 24.371971130371094
      policy_loss: -1.2256755828857422
      var_gnorm: 33.21929168701172
      vf_explained_var: 0.05499523878097534
      vf_loss: 9.015308380126953
    num_steps_sampled: 684000
    num_steps_trained: 684000
    wait_time_ms: 52.158
  iterations_since_restore: 228
  node_ip: 172.17.8.3
  num_metric_batches_dropped: 0
  pid: 16746
  policy_reward_mean: {}
  time_since_restore: 2019.6038875579834
  time_this_iter_s: 9.216642141342163
  time_total_s: 2019.6038875579834
  timestamp: 1593885122
  timesteps_since_restore: 684000
  timesteps_this_iter: 3000
  timesteps_total: 684000
  training_iteration: 228
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 33.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=16746], 2019 s, 228 iter, 684000 ts, 717 rew

agent-1: 269.0
agent-2: 282.0
agent-3: 176.0
Sum Reward: 727.0
Avg Reward: 242.33333333333334
Min Reward: 176.0
Gini Coefficient: 0.09720311783585511
20:20 Ratio: 1.6022727272727273
Max-min Ratio: 1.6022727272727273
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_13-52-11
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 928.0
  episode_reward_mean: 715.98
  episode_reward_min: 538.0
  episodes_this_iter: 1
  episodes_total: 228
  experiment_id: 86e053a9c80f439496ed6b19bfe1ab59
  hostname: gpu003
  info:
    apply_time_ms: 2.944
    dispatch_time_ms: 32.102
    learner:
      cur_lr: 0.0013144456315785646
      grad_gnorm: 39.999996185302734
      policy_entropy: 22.394058227539062
      policy_loss: 34.999874114990234
      var_gnorm: 33.24523162841797
      vf_explained_var: -1.0
      vf_loss: 41.12339782714844
    num_steps_sampled: 687000
    num_steps_trained: 687000
    wait_time_ms: 45.559
  iterations_since_restore: 229
  node_ip: 172.17.8.3
  num_metric_batches_dropped: 0
  pid: 16746
  policy_reward_mean: {}
  time_since_restore: 2028.0072922706604
  time_this_iter_s: 8.403404712677002
  time_total_s: 2028.0072922706604
  timestamp: 1593885131
  timesteps_since_restore: 687000
  timesteps_this_iter: 3000
  timesteps_total: 687000
  training_iteration: 229
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 33.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=16746], 2028 s, 229 iter, 687000 ts, 716 rew

agent-1: 289.0
agent-2: 267.0
agent-3: 252.0
Sum Reward: 808.0
Avg Reward: 269.3333333333333
Min Reward: 252.0
Gini Coefficient: 0.03052805280528053
20:20 Ratio: 1.1468253968253967
Max-min Ratio: 1.1468253968253967
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_13-52-19
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 928.0
  episode_reward_mean: 716.74
  episode_reward_min: 538.0
  episodes_this_iter: 1
  episodes_total: 229
  experiment_id: 86e053a9c80f439496ed6b19bfe1ab59
  hostname: gpu003
  info:
    apply_time_ms: 2.797
    dispatch_time_ms: 38.746
    learner:
      cur_lr: 0.0013142457464709878
      grad_gnorm: 27.690370559692383
      policy_entropy: 21.08722686767578
      policy_loss: -12.640905380249023
      var_gnorm: 33.324119567871094
      vf_explained_var: 0.6408178806304932
      vf_loss: 22.75057029724121
    num_steps_sampled: 690000
    num_steps_trained: 690000
    wait_time_ms: 38.16
  iterations_since_restore: 230
  node_ip: 172.17.8.3
  num_metric_batches_dropped: 0
  pid: 16746
  policy_reward_mean: {}
  time_since_restore: 2036.4386563301086
  time_this_iter_s: 8.431364059448242
  time_total_s: 2036.4386563301086
  timestamp: 1593885139
  timesteps_since_restore: 690000
  timesteps_this_iter: 3000
  timesteps_total: 690000
  training_iteration: 230
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 33.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=16746], 2036 s, 230 iter, 690000 ts, 717 rew

agent-1: 259.0
agent-2: 277.0
agent-3: 277.0
Sum Reward: 813.0
Avg Reward: 271.0
Min Reward: 259.0
Gini Coefficient: 0.014760147601476014
20:20 Ratio: 1.0694980694980696
Max-min Ratio: 1.0694980694980696
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_13-52-28
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 928.0
  episode_reward_mean: 718.02
  episode_reward_min: 538.0
  episodes_this_iter: 1
  episodes_total: 230
  experiment_id: 86e053a9c80f439496ed6b19bfe1ab59
  hostname: gpu003
  info:
    apply_time_ms: 2.811
    dispatch_time_ms: 45.234
    learner:
      cur_lr: 0.0013140459777787328
      grad_gnorm: 40.0
      policy_entropy: 25.754974365234375
      policy_loss: -13.926949501037598
      var_gnorm: 33.42155456542969
      vf_explained_var: 0.6209605932235718
      vf_loss: 28.274141311645508
    num_steps_sampled: 693000
    num_steps_trained: 693000
    wait_time_ms: 45.185
  iterations_since_restore: 231
  node_ip: 172.17.8.3
  num_metric_batches_dropped: 0
  pid: 16746
  policy_reward_mean: {}
  time_since_restore: 2045.232988357544
  time_this_iter_s: 8.794332027435303
  time_total_s: 2045.232988357544
  timestamp: 1593885148
  timesteps_since_restore: 693000
  timesteps_this_iter: 3000
  timesteps_total: 693000
  training_iteration: 231
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 33.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=16746], 2045 s, 231 iter, 693000 ts, 718 rew

agent-1: 264.0
agent-2: 262.0
agent-3: 233.0
Sum Reward: 759.0
Avg Reward: 253.0
Min Reward: 233.0
Gini Coefficient: 0.027228809837505488
20:20 Ratio: 1.1330472103004292
Max-min Ratio: 1.1330472103004292
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_13-52-37
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 928.0
  episode_reward_mean: 718.83
  episode_reward_min: 538.0
  episodes_this_iter: 1
  episodes_total: 231
  experiment_id: 86e053a9c80f439496ed6b19bfe1ab59
  hostname: gpu003
  info:
    apply_time_ms: 3.288
    dispatch_time_ms: 44.622
    learner:
      cur_lr: 0.0013138462090864778
      grad_gnorm: 40.000003814697266
      policy_entropy: 19.2183837890625
      policy_loss: 8.727350234985352
      var_gnorm: 33.51874923706055
      vf_explained_var: 0.09120035171508789
      vf_loss: 45.288658142089844
    num_steps_sampled: 696000
    num_steps_trained: 696000
    wait_time_ms: 60.376
  iterations_since_restore: 232
  node_ip: 172.17.8.3
  num_metric_batches_dropped: 0
  pid: 16746
  policy_reward_mean: {}
  time_since_restore: 2053.9509522914886
  time_this_iter_s: 8.717963933944702
  time_total_s: 2053.9509522914886
  timestamp: 1593885157
  timesteps_since_restore: 696000
  timesteps_this_iter: 3000
  timesteps_total: 696000
  training_iteration: 232
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 33.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=16746], 2053 s, 232 iter, 696000 ts, 719 rew

agent-1: 216.0
agent-2: 303.0
agent-3: 292.0
Sum Reward: 811.0
Avg Reward: 270.3333333333333
Min Reward: 216.0
Gini Coefficient: 0.07151664611590629
20:20 Ratio: 1.4027777777777777
Max-min Ratio: 1.4027777777777777
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_13-52-45
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 928.0
  episode_reward_mean: 719.98
  episode_reward_min: 538.0
  episodes_this_iter: 1
  episodes_total: 232
  experiment_id: 86e053a9c80f439496ed6b19bfe1ab59
  hostname: gpu003
  info:
    apply_time_ms: 2.538
    dispatch_time_ms: 35.347
    learner:
      cur_lr: 0.0013136464403942227
      grad_gnorm: 40.0
      policy_entropy: 20.8549861907959
      policy_loss: -19.173601150512695
      var_gnorm: 33.54106903076172
      vf_explained_var: 0.8198753595352173
      vf_loss: 14.217679023742676
    num_steps_sampled: 699000
    num_steps_trained: 699000
    wait_time_ms: 50.328
  iterations_since_restore: 233
  node_ip: 172.17.8.3
  num_metric_batches_dropped: 0
  pid: 16746
  policy_reward_mean: {}
  time_since_restore: 2062.152101993561
  time_this_iter_s: 8.201149702072144
  time_total_s: 2062.152101993561
  timestamp: 1593885165
  timesteps_since_restore: 699000
  timesteps_this_iter: 3000
  timesteps_total: 699000
  training_iteration: 233
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 33.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=16746], 2062 s, 233 iter, 699000 ts, 720 rew

agent-1: 233.0
agent-2: 317.0
agent-3: 295.0
Sum Reward: 845.0
Avg Reward: 281.6666666666667
Min Reward: 233.0
Gini Coefficient: 0.06627218934911243
20:20 Ratio: 1.3605150214592274
Max-min Ratio: 1.3605150214592274
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_13-53-06
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 928.0
  episode_reward_mean: 720.94
  episode_reward_min: 538.0
  episodes_this_iter: 1
  episodes_total: 233
  experiment_id: 86e053a9c80f439496ed6b19bfe1ab59
  hostname: gpu003
  info:
    apply_time_ms: 3.588
    dispatch_time_ms: 6.313
    learner:
      cur_lr: 0.0013134465552866459
      grad_gnorm: 33.71995544433594
      policy_entropy: 11.276126861572266
      policy_loss: 1.9157688617706299
      var_gnorm: 33.56397247314453
      vf_explained_var: 0.4261799454689026
      vf_loss: 14.541370391845703
    num_steps_sampled: 702000
    num_steps_trained: 702000
    wait_time_ms: 71.336
  iterations_since_restore: 234
  node_ip: 172.17.8.3
  num_metric_batches_dropped: 0
  pid: 16746
  policy_reward_mean: {}
  time_since_restore: 2082.581010580063
  time_this_iter_s: 20.428908586502075
  time_total_s: 2082.581010580063
  timestamp: 1593885186
  timesteps_since_restore: 702000
  timesteps_this_iter: 3000
  timesteps_total: 702000
  training_iteration: 234
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 33.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=16746], 2082 s, 234 iter, 702000 ts, 721 rew

agent-1: 315.0
agent-2: 232.0
agent-3: 226.0
Sum Reward: 773.0
Avg Reward: 257.6666666666667
Min Reward: 226.0
Gini Coefficient: 0.07675722294092281
20:20 Ratio: 1.3938053097345133
Max-min Ratio: 1.3938053097345133
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_13-53-14
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 928.0
  episode_reward_mean: 721.71
  episode_reward_min: 538.0
  episodes_this_iter: 1
  episodes_total: 234
  experiment_id: 86e053a9c80f439496ed6b19bfe1ab59
  hostname: gpu003
  info:
    apply_time_ms: 3.289
    dispatch_time_ms: 28.021
    learner:
      cur_lr: 0.0013132467865943909
      grad_gnorm: 40.000003814697266
      policy_entropy: 24.611446380615234
      policy_loss: -15.52469539642334
      var_gnorm: 33.618038177490234
      vf_explained_var: 0.4266895651817322
      vf_loss: 9.523490905761719
    num_steps_sampled: 705000
    num_steps_trained: 705000
    wait_time_ms: 52.883
  iterations_since_restore: 235
  node_ip: 172.17.8.3
  num_metric_batches_dropped: 0
  pid: 16746
  policy_reward_mean: {}
  time_since_restore: 2091.083943605423
  time_this_iter_s: 8.502933025360107
  time_total_s: 2091.083943605423
  timestamp: 1593885194
  timesteps_since_restore: 705000
  timesteps_this_iter: 3000
  timesteps_total: 705000
  training_iteration: 235
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 33.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=16746], 2091 s, 235 iter, 705000 ts, 722 rew

agent-1: 263.0
agent-2: 254.0
agent-3: 280.0
Sum Reward: 797.0
Avg Reward: 265.6666666666667
Min Reward: 254.0
Gini Coefficient: 0.021748222501045588
20:20 Ratio: 1.1023622047244095
Max-min Ratio: 1.1023622047244095
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_13-53-23
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 928.0
  episode_reward_mean: 722.76
  episode_reward_min: 538.0
  episodes_this_iter: 1
  episodes_total: 235
  experiment_id: 86e053a9c80f439496ed6b19bfe1ab59
  hostname: gpu003
  info:
    apply_time_ms: 3.384
    dispatch_time_ms: 20.756
    learner:
      cur_lr: 0.0013130470179021358
      grad_gnorm: 40.0
      policy_entropy: 21.160717010498047
      policy_loss: 7.574337005615234
      var_gnorm: 33.62024688720703
      vf_explained_var: 0.7144365310668945
      vf_loss: 45.48927307128906
    num_steps_sampled: 708000
    num_steps_trained: 708000
    wait_time_ms: 61.456
  iterations_since_restore: 236
  node_ip: 172.17.8.3
  num_metric_batches_dropped: 0
  pid: 16746
  policy_reward_mean: {}
  time_since_restore: 2099.393277168274
  time_this_iter_s: 8.309333562850952
  time_total_s: 2099.393277168274
  timestamp: 1593885203
  timesteps_since_restore: 708000
  timesteps_this_iter: 3000
  timesteps_total: 708000
  training_iteration: 236
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 33.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=16746], 2099 s, 236 iter, 708000 ts, 723 rew

agent-1: 246.0
agent-2: 263.0
agent-3: 271.0
Sum Reward: 780.0
Avg Reward: 260.0
Min Reward: 246.0
Gini Coefficient: 0.021367521367521368
20:20 Ratio: 1.1016260162601625
Max-min Ratio: 1.1016260162601625
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_13-53-31
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 928.0
  episode_reward_mean: 722.79
  episode_reward_min: 538.0
  episodes_this_iter: 1
  episodes_total: 236
  experiment_id: 86e053a9c80f439496ed6b19bfe1ab59
  hostname: gpu003
  info:
    apply_time_ms: 2.785
    dispatch_time_ms: 7.075
    learner:
      cur_lr: 0.0013128472492098808
      grad_gnorm: 40.0
      policy_entropy: 21.3591365814209
      policy_loss: 27.199039459228516
      var_gnorm: 33.63568115234375
      vf_explained_var: 0.6028234958648682
      vf_loss: 40.19533157348633
    num_steps_sampled: 711000
    num_steps_trained: 711000
    wait_time_ms: 69.955
  iterations_since_restore: 237
  node_ip: 172.17.8.3
  num_metric_batches_dropped: 0
  pid: 16746
  policy_reward_mean: {}
  time_since_restore: 2107.2974770069122
  time_this_iter_s: 7.904199838638306
  time_total_s: 2107.2974770069122
  timestamp: 1593885211
  timesteps_since_restore: 711000
  timesteps_this_iter: 3000
  timesteps_total: 711000
  training_iteration: 237
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 33.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=16746], 2107 s, 237 iter, 711000 ts, 723 rew

agent-1: 289.0
agent-2: 204.0
agent-3: 226.0
Sum Reward: 719.0
Avg Reward: 239.66666666666666
Min Reward: 204.0
Gini Coefficient: 0.07881316643486323
20:20 Ratio: 1.4166666666666667
Max-min Ratio: 1.4166666666666667
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_13-53-39
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 928.0
  episode_reward_mean: 722.66
  episode_reward_min: 538.0
  episodes_this_iter: 1
  episodes_total: 237
  experiment_id: 86e053a9c80f439496ed6b19bfe1ab59
  hostname: gpu003
  info:
    apply_time_ms: 2.814
    dispatch_time_ms: 5.128
    learner:
      cur_lr: 0.001312647364102304
      grad_gnorm: 40.0
      policy_entropy: 23.572998046875
      policy_loss: -36.22914123535156
      var_gnorm: 33.676570892333984
      vf_explained_var: 0.07605350017547607
      vf_loss: 34.794395446777344
    num_steps_sampled: 714000
    num_steps_trained: 714000
    wait_time_ms: 69.769
  iterations_since_restore: 238
  node_ip: 172.17.8.3
  num_metric_batches_dropped: 0
  pid: 16746
  policy_reward_mean: {}
  time_since_restore: 2115.2390241622925
  time_this_iter_s: 7.941547155380249
  time_total_s: 2115.2390241622925
  timestamp: 1593885219
  timesteps_since_restore: 714000
  timesteps_this_iter: 3000
  timesteps_total: 714000
  training_iteration: 238
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 33.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=16746], 2115 s, 238 iter, 714000 ts, 723 rew

agent-1: 265.0
agent-2: 248.0
agent-3: 237.0
Sum Reward: 750.0
Avg Reward: 250.0
Min Reward: 237.0
Gini Coefficient: 0.024888888888888887
20:20 Ratio: 1.1181434599156117
Max-min Ratio: 1.1181434599156117
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_13-53-47
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 928.0
  episode_reward_mean: 724.4
  episode_reward_min: 538.0
  episodes_this_iter: 1
  episodes_total: 238
  experiment_id: 86e053a9c80f439496ed6b19bfe1ab59
  hostname: gpu003
  info:
    apply_time_ms: 3.218
    dispatch_time_ms: 9.623
    learner:
      cur_lr: 0.001312447595410049
      grad_gnorm: 40.0
      policy_entropy: 21.994949340820312
      policy_loss: -5.7519378662109375
      var_gnorm: 33.74419403076172
      vf_explained_var: 0.7292220592498779
      vf_loss: 20.676860809326172
    num_steps_sampled: 717000
    num_steps_trained: 717000
    wait_time_ms: 66.314
  iterations_since_restore: 239
  node_ip: 172.17.8.3
  num_metric_batches_dropped: 0
  pid: 16746
  policy_reward_mean: {}
  time_since_restore: 2123.1974477767944
  time_this_iter_s: 7.958423614501953
  time_total_s: 2123.1974477767944
  timestamp: 1593885227
  timesteps_since_restore: 717000
  timesteps_this_iter: 3000
  timesteps_total: 717000
  training_iteration: 239
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 33.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=16746], 2123 s, 239 iter, 717000 ts, 724 rew

agent-1: 268.0
agent-2: 299.0
agent-3: 242.0
Sum Reward: 809.0
Avg Reward: 269.6666666666667
Min Reward: 242.0
Gini Coefficient: 0.04697156983930779
20:20 Ratio: 1.2355371900826446
Max-min Ratio: 1.2355371900826446
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_13-53-54
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 928.0
  episode_reward_mean: 726.52
  episode_reward_min: 538.0
  episodes_this_iter: 1
  episodes_total: 239
  experiment_id: 86e053a9c80f439496ed6b19bfe1ab59
  hostname: gpu003
  info:
    apply_time_ms: 2.761
    dispatch_time_ms: 8.823
    learner:
      cur_lr: 0.001312247826717794
      grad_gnorm: 40.0
      policy_entropy: 24.09980010986328
      policy_loss: 13.668143272399902
      var_gnorm: 33.82152557373047
      vf_explained_var: 0.49238526821136475
      vf_loss: 31.629087448120117
    num_steps_sampled: 720000
    num_steps_trained: 720000
    wait_time_ms: 67.704
  iterations_since_restore: 240
  node_ip: 172.17.8.3
  num_metric_batches_dropped: 0
  pid: 16746
  policy_reward_mean: {}
  time_since_restore: 2131.0141835212708
  time_this_iter_s: 7.816735744476318
  time_total_s: 2131.0141835212708
  timestamp: 1593885234
  timesteps_since_restore: 720000
  timesteps_this_iter: 3000
  timesteps_total: 720000
  training_iteration: 240
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 33.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=16746], 2131 s, 240 iter, 720000 ts, 727 rew

agent-1: 318.0
agent-2: 315.0
agent-3: 266.0
Sum Reward: 899.0
Avg Reward: 299.6666666666667
Min Reward: 266.0
Gini Coefficient: 0.0385613644790508
20:20 Ratio: 1.1954887218045114
Max-min Ratio: 1.1954887218045114
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_13-54-03
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 928.0
  episode_reward_mean: 729.15
  episode_reward_min: 538.0
  episodes_this_iter: 1
  episodes_total: 240
  experiment_id: 86e053a9c80f439496ed6b19bfe1ab59
  hostname: gpu003
  info:
    apply_time_ms: 3.694
    dispatch_time_ms: 9.262
    learner:
      cur_lr: 0.001312048058025539
      grad_gnorm: 33.91380310058594
      policy_entropy: 14.853448867797852
      policy_loss: -5.170635223388672
      var_gnorm: 33.870262145996094
      vf_explained_var: -0.130997896194458
      vf_loss: 14.159610748291016
    num_steps_sampled: 723000
    num_steps_trained: 723000
    wait_time_ms: 70.413
  iterations_since_restore: 241
  node_ip: 172.17.8.3
  num_metric_batches_dropped: 0
  pid: 16746
  policy_reward_mean: {}
  time_since_restore: 2139.106477499008
  time_this_iter_s: 8.092293977737427
  time_total_s: 2139.106477499008
  timestamp: 1593885243
  timesteps_since_restore: 723000
  timesteps_this_iter: 3000
  timesteps_total: 723000
  training_iteration: 241
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 33.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=16746], 2139 s, 241 iter, 723000 ts, 729 rew

agent-1: 270.0
agent-2: 256.0
agent-3: 252.0
Sum Reward: 778.0
Avg Reward: 259.3333333333333
Min Reward: 252.0
Gini Coefficient: 0.015424164524421594
20:20 Ratio: 1.0714285714285714
Max-min Ratio: 1.0714285714285714
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_13-54-11
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 928.0
  episode_reward_mean: 729.8
  episode_reward_min: 538.0
  episodes_this_iter: 1
  episodes_total: 241
  experiment_id: 86e053a9c80f439496ed6b19bfe1ab59
  hostname: gpu003
  info:
    apply_time_ms: 3.601
    dispatch_time_ms: 7.684
    learner:
      cur_lr: 0.001311848172917962
      grad_gnorm: 31.47349739074707
      policy_entropy: 19.996788024902344
      policy_loss: -3.3708419799804688
      var_gnorm: 33.90587615966797
      vf_explained_var: 0.6348940134048462
      vf_loss: 28.202054977416992
    num_steps_sampled: 726000
    num_steps_trained: 726000
    wait_time_ms: 73.019
  iterations_since_restore: 242
  node_ip: 172.17.8.3
  num_metric_batches_dropped: 0
  pid: 16746
  policy_reward_mean: {}
  time_since_restore: 2147.1589517593384
  time_this_iter_s: 8.0524742603302
  time_total_s: 2147.1589517593384
  timestamp: 1593885251
  timesteps_since_restore: 726000
  timesteps_this_iter: 3000
  timesteps_total: 726000
  training_iteration: 242
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 33.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=16746], 2147 s, 242 iter, 726000 ts, 730 rew

agent-1: 242.0
agent-2: 282.0
agent-3: 209.0
Sum Reward: 733.0
Avg Reward: 244.33333333333334
Min Reward: 209.0
Gini Coefficient: 0.06639381537062301
20:20 Ratio: 1.3492822966507176
Max-min Ratio: 1.3492822966507176
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_13-54-19
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 928.0
  episode_reward_mean: 730.06
  episode_reward_min: 538.0
  episodes_this_iter: 1
  episodes_total: 242
  experiment_id: 86e053a9c80f439496ed6b19bfe1ab59
  hostname: gpu003
  info:
    apply_time_ms: 3.285
    dispatch_time_ms: 6.368
    learner:
      cur_lr: 0.001311648404225707
      grad_gnorm: 40.0
      policy_entropy: 19.91118812561035
      policy_loss: 9.500995635986328
      var_gnorm: 33.90851593017578
      vf_explained_var: 0.7791405916213989
      vf_loss: 18.409610748291016
    num_steps_sampled: 729000
    num_steps_trained: 729000
    wait_time_ms: 73.097
  iterations_since_restore: 243
  node_ip: 172.17.8.3
  num_metric_batches_dropped: 0
  pid: 16746
  policy_reward_mean: {}
  time_since_restore: 2155.237044811249
  time_this_iter_s: 8.0780930519104
  time_total_s: 2155.237044811249
  timestamp: 1593885259
  timesteps_since_restore: 729000
  timesteps_this_iter: 3000
  timesteps_total: 729000
  training_iteration: 243
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 33.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=16746], 2155 s, 243 iter, 729000 ts, 730 rew

agent-1: 252.0
agent-2: 271.0
agent-3: 252.0
Sum Reward: 775.0
Avg Reward: 258.3333333333333
Min Reward: 252.0
Gini Coefficient: 0.016344086021505378
20:20 Ratio: 1.0753968253968254
Max-min Ratio: 1.0753968253968254
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_13-54-27
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 928.0
  episode_reward_mean: 730.61
  episode_reward_min: 538.0
  episodes_this_iter: 1
  episodes_total: 243
  experiment_id: 86e053a9c80f439496ed6b19bfe1ab59
  hostname: gpu003
  info:
    apply_time_ms: 3.468
    dispatch_time_ms: 9.399
    learner:
      cur_lr: 0.001311448635533452
      grad_gnorm: 40.0
      policy_entropy: 19.6180419921875
      policy_loss: -11.457242012023926
      var_gnorm: 33.972145080566406
      vf_explained_var: 0.7392842769622803
      vf_loss: 12.157665252685547
    num_steps_sampled: 732000
    num_steps_trained: 732000
    wait_time_ms: 66.869
  iterations_since_restore: 244
  node_ip: 172.17.8.3
  num_metric_batches_dropped: 0
  pid: 16746
  policy_reward_mean: {}
  time_since_restore: 2163.1936423778534
  time_this_iter_s: 7.956597566604614
  time_total_s: 2163.1936423778534
  timestamp: 1593885267
  timesteps_since_restore: 732000
  timesteps_this_iter: 3000
  timesteps_total: 732000
  training_iteration: 244
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 33.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=16746], 2163 s, 244 iter, 732000 ts, 731 rew

agent-1: 306.0
agent-2: 319.0
agent-3: 301.0
Sum Reward: 926.0
Avg Reward: 308.6666666666667
Min Reward: 301.0
Gini Coefficient: 0.012958963282937365
20:20 Ratio: 1.0598006644518272
Max-min Ratio: 1.0598006644518272
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_13-54-35
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 928.0
  episode_reward_mean: 734.0
  episode_reward_min: 538.0
  episodes_this_iter: 1
  episodes_total: 244
  experiment_id: 86e053a9c80f439496ed6b19bfe1ab59
  hostname: gpu003
  info:
    apply_time_ms: 2.996
    dispatch_time_ms: 7.782
    learner:
      cur_lr: 0.0013112487504258752
      grad_gnorm: 23.529024124145508
      policy_entropy: 10.531200408935547
      policy_loss: -6.458258628845215
      var_gnorm: 33.99306106567383
      vf_explained_var: 0.4942862391471863
      vf_loss: 30.85584831237793
    num_steps_sampled: 735000
    num_steps_trained: 735000
    wait_time_ms: 69.932
  iterations_since_restore: 245
  node_ip: 172.17.8.3
  num_metric_batches_dropped: 0
  pid: 16746
  policy_reward_mean: {}
  time_since_restore: 2171.326949596405
  time_this_iter_s: 8.133307218551636
  time_total_s: 2171.326949596405
  timestamp: 1593885275
  timesteps_since_restore: 735000
  timesteps_this_iter: 3000
  timesteps_total: 735000
  training_iteration: 245
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 33.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=16746], 2171 s, 245 iter, 735000 ts, 734 rew

agent-1: 249.0
agent-2: 258.0
agent-3: 218.0
Sum Reward: 725.0
Avg Reward: 241.66666666666666
Min Reward: 218.0
Gini Coefficient: 0.0367816091954023
20:20 Ratio: 1.18348623853211
Max-min Ratio: 1.18348623853211
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_13-54-43
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 928.0
  episode_reward_mean: 734.0
  episode_reward_min: 538.0
  episodes_this_iter: 1
  episodes_total: 245
  experiment_id: 86e053a9c80f439496ed6b19bfe1ab59
  hostname: gpu003
  info:
    apply_time_ms: 2.884
    dispatch_time_ms: 6.751
    learner:
      cur_lr: 0.0013110489817336202
      grad_gnorm: 40.000003814697266
      policy_entropy: 9.645752906799316
      policy_loss: 1.1016535758972168
      var_gnorm: 34.034400939941406
      vf_explained_var: 0.7322481870651245
      vf_loss: 17.828319549560547
    num_steps_sampled: 738000
    num_steps_trained: 738000
    wait_time_ms: 64.506
  iterations_since_restore: 246
  node_ip: 172.17.8.3
  num_metric_batches_dropped: 0
  pid: 16746
  policy_reward_mean: {}
  time_since_restore: 2179.2220599651337
  time_this_iter_s: 7.895110368728638
  time_total_s: 2179.2220599651337
  timestamp: 1593885283
  timesteps_since_restore: 738000
  timesteps_this_iter: 3000
  timesteps_total: 738000
  training_iteration: 246
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 33.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=16746], 2179 s, 246 iter, 738000 ts, 734 rew

agent-1: 254.0
agent-2: 313.0
agent-3: 284.0
Sum Reward: 851.0
Avg Reward: 283.6666666666667
Min Reward: 254.0
Gini Coefficient: 0.046220133176654916
20:20 Ratio: 1.2322834645669292
Max-min Ratio: 1.2322834645669292
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_13-54-51
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 928.0
  episode_reward_mean: 734.24
  episode_reward_min: 538.0
  episodes_this_iter: 1
  episodes_total: 246
  experiment_id: 86e053a9c80f439496ed6b19bfe1ab59
  hostname: gpu003
  info:
    apply_time_ms: 2.873
    dispatch_time_ms: 8.426
    learner:
      cur_lr: 0.0013108492130413651
      grad_gnorm: 3.351428747177124
      policy_entropy: 15.26539421081543
      policy_loss: -1.1038861274719238
      var_gnorm: 34.09077835083008
      vf_explained_var: 0.08681201934814453
      vf_loss: 14.417439460754395
    num_steps_sampled: 741000
    num_steps_trained: 741000
    wait_time_ms: 69.653
  iterations_since_restore: 247
  node_ip: 172.17.8.3
  num_metric_batches_dropped: 0
  pid: 16746
  policy_reward_mean: {}
  time_since_restore: 2187.347503185272
  time_this_iter_s: 8.12544322013855
  time_total_s: 2187.347503185272
  timestamp: 1593885291
  timesteps_since_restore: 741000
  timesteps_this_iter: 3000
  timesteps_total: 741000
  training_iteration: 247
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 33.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=16746], 2187 s, 247 iter, 741000 ts, 734 rew

agent-1: 274.0
agent-2: 308.0
agent-3: 286.0
Sum Reward: 868.0
Avg Reward: 289.3333333333333
Min Reward: 274.0
Gini Coefficient: 0.026113671274961597
20:20 Ratio: 1.1240875912408759
Max-min Ratio: 1.1240875912408759
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_13-54-59
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 928.0
  episode_reward_mean: 734.51
  episode_reward_min: 538.0
  episodes_this_iter: 1
  episodes_total: 247
  experiment_id: 86e053a9c80f439496ed6b19bfe1ab59
  hostname: gpu003
  info:
    apply_time_ms: 3.633
    dispatch_time_ms: 9.254
    learner:
      cur_lr: 0.0013106494443491101
      grad_gnorm: 40.000003814697266
      policy_entropy: 13.284808158874512
      policy_loss: -11.719684600830078
      var_gnorm: 34.125919342041016
      vf_explained_var: 0.8807328343391418
      vf_loss: 17.41185188293457
    num_steps_sampled: 744000
    num_steps_trained: 744000
    wait_time_ms: 66.017
  iterations_since_restore: 248
  node_ip: 172.17.8.3
  num_metric_batches_dropped: 0
  pid: 16746
  policy_reward_mean: {}
  time_since_restore: 2195.2987632751465
  time_this_iter_s: 7.951260089874268
  time_total_s: 2195.2987632751465
  timestamp: 1593885299
  timesteps_since_restore: 744000
  timesteps_this_iter: 3000
  timesteps_total: 744000
  training_iteration: 248
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 33.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=16746], 2195 s, 248 iter, 744000 ts, 735 rew

agent-1: 285.0
agent-2: 256.0
agent-3: 290.0
Sum Reward: 831.0
Avg Reward: 277.0
Min Reward: 256.0
Gini Coefficient: 0.02727637384677096
20:20 Ratio: 1.1328125
Max-min Ratio: 1.1328125
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_13-55-07
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 928.0
  episode_reward_mean: 735.24
  episode_reward_min: 538.0
  episodes_this_iter: 1
  episodes_total: 248
  experiment_id: 86e053a9c80f439496ed6b19bfe1ab59
  hostname: gpu003
  info:
    apply_time_ms: 3.057
    dispatch_time_ms: 7.448
    learner:
      cur_lr: 0.0013104495592415333
      grad_gnorm: 40.0
      policy_entropy: 7.503917694091797
      policy_loss: -5.254714488983154
      var_gnorm: 34.14447021484375
      vf_explained_var: 0.3115522265434265
      vf_loss: 42.34369659423828
    num_steps_sampled: 747000
    num_steps_trained: 747000
    wait_time_ms: 68.769
  iterations_since_restore: 249
  node_ip: 172.17.8.3
  num_metric_batches_dropped: 0
  pid: 16746
  policy_reward_mean: {}
  time_since_restore: 2203.0984930992126
  time_this_iter_s: 7.799729824066162
  time_total_s: 2203.0984930992126
  timestamp: 1593885307
  timesteps_since_restore: 747000
  timesteps_this_iter: 3000
  timesteps_total: 747000
  training_iteration: 249
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 33.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=16746], 2203 s, 249 iter, 747000 ts, 735 rew

agent-1: 309.0
agent-2: 324.0
agent-3: 208.0
Sum Reward: 841.0
Avg Reward: 280.3333333333333
Min Reward: 208.0
Gini Coefficient: 0.09195402298850575
20:20 Ratio: 1.5576923076923077
Max-min Ratio: 1.5576923076923077
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_13-55-15
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 928.0
  episode_reward_mean: 735.8
  episode_reward_min: 538.0
  episodes_this_iter: 1
  episodes_total: 249
  experiment_id: 86e053a9c80f439496ed6b19bfe1ab59
  hostname: gpu003
  info:
    apply_time_ms: 3.235
    dispatch_time_ms: 8.394
    learner:
      cur_lr: 0.0013102497905492783
      grad_gnorm: 40.0
      policy_entropy: 23.161264419555664
      policy_loss: -11.759111404418945
      var_gnorm: 34.15877151489258
      vf_explained_var: 0.8736357092857361
      vf_loss: 21.398883819580078
    num_steps_sampled: 750000
    num_steps_trained: 750000
    wait_time_ms: 73.455
  iterations_since_restore: 250
  node_ip: 172.17.8.3
  num_metric_batches_dropped: 0
  pid: 16746
  policy_reward_mean: {}
  time_since_restore: 2211.433019399643
  time_this_iter_s: 8.334526300430298
  time_total_s: 2211.433019399643
  timestamp: 1593885315
  timesteps_since_restore: 750000
  timesteps_this_iter: 3000
  timesteps_total: 750000
  training_iteration: 250
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 33.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=16746], 2211 s, 250 iter, 750000 ts, 736 rew

agent-1: 228.0
agent-2: 252.0
agent-3: 263.0
Sum Reward: 743.0
Avg Reward: 247.66666666666666
Min Reward: 228.0
Gini Coefficient: 0.03140421713772992
20:20 Ratio: 1.1535087719298245
Max-min Ratio: 1.1535087719298245
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_13-55-24
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 928.0
  episode_reward_mean: 735.0
  episode_reward_min: 538.0
  episodes_this_iter: 1
  episodes_total: 250
  experiment_id: 86e053a9c80f439496ed6b19bfe1ab59
  hostname: gpu003
  info:
    apply_time_ms: 2.651
    dispatch_time_ms: 5.578
    learner:
      cur_lr: 0.0013100500218570232
      grad_gnorm: 27.559423446655273
      policy_entropy: 12.748725891113281
      policy_loss: 4.532273769378662
      var_gnorm: 34.15414047241211
      vf_explained_var: 0.35116201639175415
      vf_loss: 11.68421745300293
    num_steps_sampled: 753000
    num_steps_trained: 753000
    wait_time_ms: 68.265
  iterations_since_restore: 251
  node_ip: 172.17.8.3
  num_metric_batches_dropped: 0
  pid: 16746
  policy_reward_mean: {}
  time_since_restore: 2219.855234861374
  time_this_iter_s: 8.422215461730957
  time_total_s: 2219.855234861374
  timestamp: 1593885324
  timesteps_since_restore: 753000
  timesteps_this_iter: 3000
  timesteps_total: 753000
  training_iteration: 251
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 33.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=16746], 2219 s, 251 iter, 753000 ts, 735 rew

agent-1: 168.0
agent-2: 253.0
agent-3: 274.0
Sum Reward: 695.0
Avg Reward: 231.66666666666666
Min Reward: 168.0
Gini Coefficient: 0.10167865707434053
20:20 Ratio: 1.630952380952381
Max-min Ratio: 1.630952380952381
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_13-55-32
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 928.0
  episode_reward_mean: 733.69
  episode_reward_min: 538.0
  episodes_this_iter: 1
  episodes_total: 251
  experiment_id: 86e053a9c80f439496ed6b19bfe1ab59
  hostname: gpu003
  info:
    apply_time_ms: 2.949
    dispatch_time_ms: 9.93
    learner:
      cur_lr: 0.0013098502531647682
      grad_gnorm: 21.019319534301758
      policy_entropy: 17.90875244140625
      policy_loss: -0.8138775825500488
      var_gnorm: 34.19070816040039
      vf_explained_var: 0.23615401983261108
      vf_loss: 18.55396270751953
    num_steps_sampled: 756000
    num_steps_trained: 756000
    wait_time_ms: 68.868
  iterations_since_restore: 252
  node_ip: 172.17.8.3
  num_metric_batches_dropped: 0
  pid: 16746
  policy_reward_mean: {}
  time_since_restore: 2227.996637582779
  time_this_iter_s: 8.14140272140503
  time_total_s: 2227.996637582779
  timestamp: 1593885332
  timesteps_since_restore: 756000
  timesteps_this_iter: 3000
  timesteps_total: 756000
  training_iteration: 252
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 33.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=16746], 2227 s, 252 iter, 756000 ts, 734 rew

agent-1: 304.0
agent-2: 243.0
agent-3: 219.0
Sum Reward: 766.0
Avg Reward: 255.33333333333334
Min Reward: 219.0
Gini Coefficient: 0.07397737162750218
20:20 Ratio: 1.3881278538812785
Max-min Ratio: 1.3881278538812785
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_13-55-41
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 928.0
  episode_reward_mean: 732.5
  episode_reward_min: 538.0
  episodes_this_iter: 1
  episodes_total: 252
  experiment_id: 86e053a9c80f439496ed6b19bfe1ab59
  hostname: gpu003
  info:
    apply_time_ms: 2.678
    dispatch_time_ms: 17.636
    learner:
      cur_lr: 0.0013096503680571914
      grad_gnorm: 40.0
      policy_entropy: 14.814720153808594
      policy_loss: 7.501158237457275
      var_gnorm: 34.20871353149414
      vf_explained_var: -0.07813692092895508
      vf_loss: 30.897354125976562
    num_steps_sampled: 759000
    num_steps_trained: 759000
    wait_time_ms: 63.908
  iterations_since_restore: 253
  node_ip: 172.17.8.3
  num_metric_batches_dropped: 0
  pid: 16746
  policy_reward_mean: {}
  time_since_restore: 2236.53937458992
  time_this_iter_s: 8.542737007141113
  time_total_s: 2236.53937458992
  timestamp: 1593885341
  timesteps_since_restore: 759000
  timesteps_this_iter: 3000
  timesteps_total: 759000
  training_iteration: 253
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 33.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=16746], 2236 s, 253 iter, 759000 ts, 732 rew

agent-1: 193.0
agent-2: 237.0
agent-3: 258.0
Sum Reward: 688.0
Avg Reward: 229.33333333333334
Min Reward: 193.0
Gini Coefficient: 0.06298449612403101
20:20 Ratio: 1.3367875647668395
Max-min Ratio: 1.3367875647668395
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_13-55-50
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 928.0
  episode_reward_mean: 731.88
  episode_reward_min: 538.0
  episodes_this_iter: 1
  episodes_total: 253
  experiment_id: 86e053a9c80f439496ed6b19bfe1ab59
  hostname: gpu003
  info:
    apply_time_ms: 3.002
    dispatch_time_ms: 18.267
    learner:
      cur_lr: 0.0013094505993649364
      grad_gnorm: 16.011592864990234
      policy_entropy: 22.509531021118164
      policy_loss: -1.8790314197540283
      var_gnorm: 34.27079391479492
      vf_explained_var: 0.3129357695579529
      vf_loss: 24.077266693115234
    num_steps_sampled: 762000
    num_steps_trained: 762000
    wait_time_ms: 73.055
  iterations_since_restore: 254
  node_ip: 172.17.8.3
  num_metric_batches_dropped: 0
  pid: 16746
  policy_reward_mean: {}
  time_since_restore: 2245.6485896110535
  time_this_iter_s: 9.109215021133423
  time_total_s: 2245.6485896110535
  timestamp: 1593885350
  timesteps_since_restore: 762000
  timesteps_this_iter: 3000
  timesteps_total: 762000
  training_iteration: 254
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 33.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=16746], 2245 s, 254 iter, 762000 ts, 732 rew

agent-1: 199.0
agent-2: 220.0
agent-3: 196.0
Sum Reward: 615.0
Avg Reward: 205.0
Min Reward: 196.0
Gini Coefficient: 0.026016260162601626
20:20 Ratio: 1.1224489795918366
Max-min Ratio: 1.1224489795918366
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_13-56-02
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 928.0
  episode_reward_mean: 730.05
  episode_reward_min: 538.0
  episodes_this_iter: 1
  episodes_total: 254
  experiment_id: 86e053a9c80f439496ed6b19bfe1ab59
  hostname: gpu003
  info:
    apply_time_ms: 2.686
    dispatch_time_ms: 17.749
    learner:
      cur_lr: 0.0013092508306726813
      grad_gnorm: 37.80464553833008
      policy_entropy: 15.041677474975586
      policy_loss: -4.423810005187988
      var_gnorm: 34.30671310424805
      vf_explained_var: 0.5863763689994812
      vf_loss: 49.224273681640625
    num_steps_sampled: 765000
    num_steps_trained: 765000
    wait_time_ms: 69.924
  iterations_since_restore: 255
  node_ip: 172.17.8.3
  num_metric_batches_dropped: 0
  pid: 16746
  policy_reward_mean: {}
  time_since_restore: 2253.9217476844788
  time_this_iter_s: 8.273158073425293
  time_total_s: 2253.9217476844788
  timestamp: 1593885362
  timesteps_since_restore: 765000
  timesteps_this_iter: 3000
  timesteps_total: 765000
  training_iteration: 255
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 33.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=16746], 2253 s, 255 iter, 765000 ts, 730 rew

agent-1: 196.0
agent-2: 217.0
agent-3: 266.0
Sum Reward: 679.0
Avg Reward: 226.33333333333334
Min Reward: 196.0
Gini Coefficient: 0.06872852233676977
20:20 Ratio: 1.3571428571428572
Max-min Ratio: 1.3571428571428572
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_13-56-11
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 928.0
  episode_reward_mean: 729.37
  episode_reward_min: 538.0
  episodes_this_iter: 1
  episodes_total: 255
  experiment_id: 86e053a9c80f439496ed6b19bfe1ab59
  hostname: gpu003
  info:
    apply_time_ms: 3.258
    dispatch_time_ms: 38.009
    learner:
      cur_lr: 0.0013090509455651045
      grad_gnorm: 40.0
      policy_entropy: 20.921409606933594
      policy_loss: 1.4192514419555664
      var_gnorm: 34.362022399902344
      vf_explained_var: 0.591951310634613
      vf_loss: 35.6838493347168
    num_steps_sampled: 768000
    num_steps_trained: 768000
    wait_time_ms: 47.943
  iterations_since_restore: 256
  node_ip: 172.17.8.3
  num_metric_batches_dropped: 0
  pid: 16746
  policy_reward_mean: {}
  time_since_restore: 2262.8582520484924
  time_this_iter_s: 8.936504364013672
  time_total_s: 2262.8582520484924
  timestamp: 1593885371
  timesteps_since_restore: 768000
  timesteps_this_iter: 3000
  timesteps_total: 768000
  training_iteration: 256
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 33.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=16746], 2262 s, 256 iter, 768000 ts, 729 rew

agent-1: 297.0
agent-2: 239.0
agent-3: 210.0
Sum Reward: 746.0
Avg Reward: 248.66666666666666
Min Reward: 210.0
Gini Coefficient: 0.0777479892761394
20:20 Ratio: 1.4142857142857144
Max-min Ratio: 1.4142857142857144
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_13-56-20
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 928.0
  episode_reward_mean: 729.27
  episode_reward_min: 538.0
  episodes_this_iter: 1
  episodes_total: 256
  experiment_id: 86e053a9c80f439496ed6b19bfe1ab59
  hostname: gpu003
  info:
    apply_time_ms: 3.065
    dispatch_time_ms: 29.051
    learner:
      cur_lr: 0.0013088511768728495
      grad_gnorm: 40.0
      policy_entropy: 16.456579208374023
      policy_loss: 30.919321060180664
      var_gnorm: 34.44502639770508
      vf_explained_var: -1.0
      vf_loss: 61.111244201660156
    num_steps_sampled: 771000
    num_steps_trained: 771000
    wait_time_ms: 62.928
  iterations_since_restore: 257
  node_ip: 172.17.8.3
  num_metric_batches_dropped: 0
  pid: 16746
  policy_reward_mean: {}
  time_since_restore: 2272.37326669693
  time_this_iter_s: 9.5150146484375
  time_total_s: 2272.37326669693
  timestamp: 1593885380
  timesteps_since_restore: 771000
  timesteps_this_iter: 3000
  timesteps_total: 771000
  training_iteration: 257
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 33.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=16746], 2272 s, 257 iter, 771000 ts, 729 rew

agent-1: 179.0
agent-2: 177.0
agent-3: 190.0
Sum Reward: 546.0
Avg Reward: 182.0
Min Reward: 177.0
Gini Coefficient: 0.015873015873015872
20:20 Ratio: 1.073446327683616
Max-min Ratio: 1.073446327683616
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_13-56-29
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 928.0
  episode_reward_mean: 727.5
  episode_reward_min: 538.0
  episodes_this_iter: 1
  episodes_total: 257
  experiment_id: 86e053a9c80f439496ed6b19bfe1ab59
  hostname: gpu003
  info:
    apply_time_ms: 3.192
    dispatch_time_ms: 25.101
    learner:
      cur_lr: 0.0013086514081805944
      grad_gnorm: 40.0
      policy_entropy: 24.286495208740234
      policy_loss: -13.432162284851074
      var_gnorm: 34.50314712524414
      vf_explained_var: 0.33184516429901123
      vf_loss: 10.560720443725586
    num_steps_sampled: 774000
    num_steps_trained: 774000
    wait_time_ms: 62.398
  iterations_since_restore: 258
  node_ip: 172.17.8.3
  num_metric_batches_dropped: 0
  pid: 16746
  policy_reward_mean: {}
  time_since_restore: 2281.2479424476624
  time_this_iter_s: 8.874675750732422
  time_total_s: 2281.2479424476624
  timestamp: 1593885389
  timesteps_since_restore: 774000
  timesteps_this_iter: 3000
  timesteps_total: 774000
  training_iteration: 258
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 33.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=16746], 2281 s, 258 iter, 774000 ts, 728 rew

agent-1: 210.0
agent-2: 275.0
agent-3: 243.0
Sum Reward: 728.0
Avg Reward: 242.66666666666666
Min Reward: 210.0
Gini Coefficient: 0.05952380952380952
20:20 Ratio: 1.3095238095238095
Max-min Ratio: 1.3095238095238095
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_13-56-38
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 928.0
  episode_reward_mean: 725.82
  episode_reward_min: 538.0
  episodes_this_iter: 1
  episodes_total: 258
  experiment_id: 86e053a9c80f439496ed6b19bfe1ab59
  hostname: gpu003
  info:
    apply_time_ms: 2.745
    dispatch_time_ms: 25.769
    learner:
      cur_lr: 0.0013084516394883394
      grad_gnorm: 29.89145278930664
      policy_entropy: 15.651619911193848
      policy_loss: 2.7400550842285156
      var_gnorm: 34.5517463684082
      vf_explained_var: 0.5130549073219299
      vf_loss: 21.38174057006836
    num_steps_sampled: 777000
    num_steps_trained: 777000
    wait_time_ms: 57.867
  iterations_since_restore: 259
  node_ip: 172.17.8.3
  num_metric_batches_dropped: 0
  pid: 16746
  policy_reward_mean: {}
  time_since_restore: 2289.8979444503784
  time_this_iter_s: 8.650002002716064
  time_total_s: 2289.8979444503784
  timestamp: 1593885398
  timesteps_since_restore: 777000
  timesteps_this_iter: 3000
  timesteps_total: 777000
  training_iteration: 259
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 33.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=16746], 2289 s, 259 iter, 777000 ts, 726 rew

agent-1: 208.0
agent-2: 277.0
agent-3: 280.0
Sum Reward: 765.0
Avg Reward: 255.0
Min Reward: 208.0
Gini Coefficient: 0.06274509803921569
20:20 Ratio: 1.3461538461538463
Max-min Ratio: 1.3461538461538463
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_13-56-46
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 928.0
  episode_reward_mean: 725.74
  episode_reward_min: 538.0
  episodes_this_iter: 1
  episodes_total: 259
  experiment_id: 86e053a9c80f439496ed6b19bfe1ab59
  hostname: gpu003
  info:
    apply_time_ms: 3.388
    dispatch_time_ms: 41.606
    learner:
      cur_lr: 0.0013082517543807626
      grad_gnorm: 40.0
      policy_entropy: 16.759811401367188
      policy_loss: -11.28609848022461
      var_gnorm: 34.62085723876953
      vf_explained_var: -0.7111178636550903
      vf_loss: 35.174678802490234
    num_steps_sampled: 780000
    num_steps_trained: 780000
    wait_time_ms: 48.68
  iterations_since_restore: 260
  node_ip: 172.17.8.3
  num_metric_batches_dropped: 0
  pid: 16746
  policy_reward_mean: {}
  time_since_restore: 2298.6932644844055
  time_this_iter_s: 8.7953200340271
  time_total_s: 2298.6932644844055
  timestamp: 1593885406
  timesteps_since_restore: 780000
  timesteps_this_iter: 3000
  timesteps_total: 780000
  training_iteration: 260
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 33.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=16746], 2298 s, 260 iter, 780000 ts, 726 rew

agent-1: 193.0
agent-2: 255.0
agent-3: 251.0
Sum Reward: 699.0
Avg Reward: 233.0
Min Reward: 193.0
Gini Coefficient: 0.05913209346685742
20:20 Ratio: 1.3212435233160622
Max-min Ratio: 1.3212435233160622
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_13-56-56
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 928.0
  episode_reward_mean: 725.15
  episode_reward_min: 538.0
  episodes_this_iter: 1
  episodes_total: 260
  experiment_id: 86e053a9c80f439496ed6b19bfe1ab59
  hostname: gpu003
  info:
    apply_time_ms: 2.588
    dispatch_time_ms: 29.083
    learner:
      cur_lr: 0.0013080519856885076
      grad_gnorm: 40.0
      policy_entropy: 12.302995681762695
      policy_loss: 0.549304723739624
      var_gnorm: 34.64633560180664
      vf_explained_var: 0.5817317366600037
      vf_loss: 44.93263626098633
    num_steps_sampled: 783000
    num_steps_trained: 783000
    wait_time_ms: 67.323
  iterations_since_restore: 261
  node_ip: 172.17.8.3
  num_metric_batches_dropped: 0
  pid: 16746
  policy_reward_mean: {}
  time_since_restore: 2307.642034292221
  time_this_iter_s: 8.948769807815552
  time_total_s: 2307.642034292221
  timestamp: 1593885416
  timesteps_since_restore: 783000
  timesteps_this_iter: 3000
  timesteps_total: 783000
  training_iteration: 261
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 33.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=16746], 2307 s, 261 iter, 783000 ts, 725 rew

agent-1: 198.0
agent-2: 234.0
agent-3: 191.0
Sum Reward: 623.0
Avg Reward: 207.66666666666666
Min Reward: 191.0
Gini Coefficient: 0.04601391118245051
20:20 Ratio: 1.225130890052356
Max-min Ratio: 1.225130890052356
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_13-57-05
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 928.0
  episode_reward_mean: 723.45
  episode_reward_min: 538.0
  episodes_this_iter: 1
  episodes_total: 261
  experiment_id: 86e053a9c80f439496ed6b19bfe1ab59
  hostname: gpu003
  info:
    apply_time_ms: 3.488
    dispatch_time_ms: 6.578
    learner:
      cur_lr: 0.0013078522169962525
      grad_gnorm: 40.0
      policy_entropy: 12.769930839538574
      policy_loss: -5.108237266540527
      var_gnorm: 34.71519470214844
      vf_explained_var: 0.45344996452331543
      vf_loss: 14.730852127075195
    num_steps_sampled: 786000
    num_steps_trained: 786000
    wait_time_ms: 81.121
  iterations_since_restore: 262
  node_ip: 172.17.8.3
  num_metric_batches_dropped: 0
  pid: 16746
  policy_reward_mean: {}
  time_since_restore: 2316.831819295883
  time_this_iter_s: 9.18978500366211
  time_total_s: 2316.831819295883
  timestamp: 1593885425
  timesteps_since_restore: 786000
  timesteps_this_iter: 3000
  timesteps_total: 786000
  training_iteration: 262
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 33.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=16746], 2316 s, 262 iter, 786000 ts, 723 rew

agent-1: 245.0
agent-2: 259.0
agent-3: 211.0
Sum Reward: 715.0
Avg Reward: 238.33333333333334
Min Reward: 211.0
Gini Coefficient: 0.044755244755244755
20:20 Ratio: 1.2274881516587677
Max-min Ratio: 1.2274881516587677
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_13-57-14
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 928.0
  episode_reward_mean: 723.83
  episode_reward_min: 538.0
  episodes_this_iter: 1
  episodes_total: 262
  experiment_id: 86e053a9c80f439496ed6b19bfe1ab59
  hostname: gpu003
  info:
    apply_time_ms: 2.948
    dispatch_time_ms: 8.033
    learner:
      cur_lr: 0.0013076524483039975
      grad_gnorm: 10.798887252807617
      policy_entropy: 11.699764251708984
      policy_loss: 4.5905561447143555
      var_gnorm: 34.74130630493164
      vf_explained_var: 0.39959144592285156
      vf_loss: 9.228846549987793
    num_steps_sampled: 789000
    num_steps_trained: 789000
    wait_time_ms: 68.823
  iterations_since_restore: 263
  node_ip: 172.17.8.3
  num_metric_batches_dropped: 0
  pid: 16746
  policy_reward_mean: {}
  time_since_restore: 2325.5014967918396
  time_this_iter_s: 8.669677495956421
  time_total_s: 2325.5014967918396
  timestamp: 1593885434
  timesteps_since_restore: 789000
  timesteps_this_iter: 3000
  timesteps_total: 789000
  training_iteration: 263
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 33.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=16746], 2325 s, 263 iter, 789000 ts, 724 rew

agent-1: 136.0
agent-2: 189.0
agent-3: 234.0
Sum Reward: 559.0
Avg Reward: 186.33333333333334
Min Reward: 136.0
Gini Coefficient: 0.11687537268932618
20:20 Ratio: 1.7205882352941178
Max-min Ratio: 1.7205882352941178
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_13-57-22
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 928.0
  episode_reward_mean: 721.65
  episode_reward_min: 538.0
  episodes_this_iter: 1
  episodes_total: 263
  experiment_id: 86e053a9c80f439496ed6b19bfe1ab59
  hostname: gpu003
  info:
    apply_time_ms: 3.459
    dispatch_time_ms: 6.746
    learner:
      cur_lr: 0.0013074525631964207
      grad_gnorm: 39.871334075927734
      policy_entropy: 18.793922424316406
      policy_loss: 7.372505187988281
      var_gnorm: 34.75938415527344
      vf_explained_var: 0.7761564254760742
      vf_loss: 20.45066261291504
    num_steps_sampled: 792000
    num_steps_trained: 792000
    wait_time_ms: 73.779
  iterations_since_restore: 264
  node_ip: 172.17.8.3
  num_metric_batches_dropped: 0
  pid: 16746
  policy_reward_mean: {}
  time_since_restore: 2333.76486492157
  time_this_iter_s: 8.263368129730225
  time_total_s: 2333.76486492157
  timestamp: 1593885442
  timesteps_since_restore: 792000
  timesteps_this_iter: 3000
  timesteps_total: 792000
  training_iteration: 264
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 33.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=16746], 2333 s, 264 iter, 792000 ts, 722 rew

agent-1: 235.0
agent-2: 282.0
agent-3: 214.0
Sum Reward: 731.0
Avg Reward: 243.66666666666666
Min Reward: 214.0
Gini Coefficient: 0.06201550387596899
20:20 Ratio: 1.3177570093457944
Max-min Ratio: 1.3177570093457944
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_13-57-30
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 928.0
  episode_reward_mean: 722.74
  episode_reward_min: 538.0
  episodes_this_iter: 1
  episodes_total: 264
  experiment_id: 86e053a9c80f439496ed6b19bfe1ab59
  hostname: gpu003
  info:
    apply_time_ms: 3.782
    dispatch_time_ms: 7.878
    learner:
      cur_lr: 0.0013072527945041656
      grad_gnorm: 40.0
      policy_entropy: 12.028980255126953
      policy_loss: -8.680427551269531
      var_gnorm: 34.74424743652344
      vf_explained_var: 0.6539462804794312
      vf_loss: 52.914615631103516
    num_steps_sampled: 795000
    num_steps_trained: 795000
    wait_time_ms: 70.462
  iterations_since_restore: 265
  node_ip: 172.17.8.3
  num_metric_batches_dropped: 0
  pid: 16746
  policy_reward_mean: {}
  time_since_restore: 2341.8767473697662
  time_this_iter_s: 8.111882448196411
  time_total_s: 2341.8767473697662
  timestamp: 1593885450
  timesteps_since_restore: 795000
  timesteps_this_iter: 3000
  timesteps_total: 795000
  training_iteration: 265
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 33.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=16746], 2341 s, 265 iter, 795000 ts, 723 rew

agent-1: 259.0
agent-2: 273.0
agent-3: 270.0
Sum Reward: 802.0
Avg Reward: 267.3333333333333
Min Reward: 259.0
Gini Coefficient: 0.011637572734829594
20:20 Ratio: 1.054054054054054
Max-min Ratio: 1.054054054054054
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_13-57-38
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 928.0
  episode_reward_mean: 722.95
  episode_reward_min: 538.0
  episodes_this_iter: 1
  episodes_total: 265
  experiment_id: 86e053a9c80f439496ed6b19bfe1ab59
  hostname: gpu003
  info:
    apply_time_ms: 3.151
    dispatch_time_ms: 12.075
    learner:
      cur_lr: 0.0013070530258119106
      grad_gnorm: 40.000003814697266
      policy_entropy: 0.8466895818710327
      policy_loss: 0.13504661619663239
      var_gnorm: 34.77449417114258
      vf_explained_var: -0.020951032638549805
      vf_loss: 18.14246940612793
    num_steps_sampled: 798000
    num_steps_trained: 798000
    wait_time_ms: 65.788
  iterations_since_restore: 266
  node_ip: 172.17.8.3
  num_metric_batches_dropped: 0
  pid: 16746
  policy_reward_mean: {}
  time_since_restore: 2349.837067604065
  time_this_iter_s: 7.960320234298706
  time_total_s: 2349.837067604065
  timestamp: 1593885458
  timesteps_since_restore: 798000
  timesteps_this_iter: 3000
  timesteps_total: 798000
  training_iteration: 266
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 33.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=16746], 2349 s, 266 iter, 798000 ts, 723 rew

agent-1: 242.0
agent-2: 243.0
agent-3: 272.0
Sum Reward: 757.0
Avg Reward: 252.33333333333334
Min Reward: 242.0
Gini Coefficient: 0.026420079260237782
20:20 Ratio: 1.1239669421487604
Max-min Ratio: 1.1239669421487604
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_13-57-46
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 928.0
  episode_reward_mean: 722.96
  episode_reward_min: 538.0
  episodes_this_iter: 1
  episodes_total: 266
  experiment_id: 86e053a9c80f439496ed6b19bfe1ab59
  hostname: gpu003
  info:
    apply_time_ms: 3.851
    dispatch_time_ms: 7.985
    learner:
      cur_lr: 0.0013068532571196556
      grad_gnorm: 39.99999237060547
      policy_entropy: 10.53829288482666
      policy_loss: -3.395411491394043
      var_gnorm: 34.7959098815918
      vf_explained_var: -0.24098408222198486
      vf_loss: 43.056114196777344
    num_steps_sampled: 801000
    num_steps_trained: 801000
    wait_time_ms: 76.715
  iterations_since_restore: 267
  node_ip: 172.17.8.3
  num_metric_batches_dropped: 0
  pid: 16746
  policy_reward_mean: {}
  time_since_restore: 2357.845234155655
  time_this_iter_s: 8.008166551589966
  time_total_s: 2357.845234155655
  timestamp: 1593885466
  timesteps_since_restore: 801000
  timesteps_this_iter: 3000
  timesteps_total: 801000
  training_iteration: 267
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 33.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=16746], 2357 s, 267 iter, 801000 ts, 723 rew

agent-1: 254.0
agent-2: 196.0
agent-3: 220.0
Sum Reward: 670.0
Avg Reward: 223.33333333333334
Min Reward: 196.0
Gini Coefficient: 0.05771144278606965
20:20 Ratio: 1.2959183673469388
Max-min Ratio: 1.2959183673469388
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_13-57-55
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 928.0
  episode_reward_mean: 723.35
  episode_reward_min: 538.0
  episodes_this_iter: 1
  episodes_total: 267
  experiment_id: 86e053a9c80f439496ed6b19bfe1ab59
  hostname: gpu003
  info:
    apply_time_ms: 3.945
    dispatch_time_ms: 8.313
    learner:
      cur_lr: 0.0013066533720120788
      grad_gnorm: 40.0
      policy_entropy: 19.28304100036621
      policy_loss: -8.49977970123291
      var_gnorm: 34.842857360839844
      vf_explained_var: 0.6614347696304321
      vf_loss: 22.0460205078125
    num_steps_sampled: 804000
    num_steps_trained: 804000
    wait_time_ms: 73.251
  iterations_since_restore: 268
  node_ip: 172.17.8.3
  num_metric_batches_dropped: 0
  pid: 16746
  policy_reward_mean: {}
  time_since_restore: 2366.2562217712402
  time_this_iter_s: 8.410987615585327
  time_total_s: 2366.2562217712402
  timestamp: 1593885475
  timesteps_since_restore: 804000
  timesteps_this_iter: 3000
  timesteps_total: 804000
  training_iteration: 268
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 33.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=16746], 2366 s, 268 iter, 804000 ts, 723 rew

agent-1: 276.0
agent-2: 234.0
agent-3: 266.0
Sum Reward: 776.0
Avg Reward: 258.6666666666667
Min Reward: 234.0
Gini Coefficient: 0.03608247422680412
20:20 Ratio: 1.1794871794871795
Max-min Ratio: 1.1794871794871795
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_13-58-03
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 928.0
  episode_reward_mean: 723.73
  episode_reward_min: 538.0
  episodes_this_iter: 1
  episodes_total: 268
  experiment_id: 86e053a9c80f439496ed6b19bfe1ab59
  hostname: gpu003
  info:
    apply_time_ms: 3.498
    dispatch_time_ms: 7.189
    learner:
      cur_lr: 0.0013064536033198237
      grad_gnorm: 39.999996185302734
      policy_entropy: 12.49608039855957
      policy_loss: -7.910066604614258
      var_gnorm: 34.8843994140625
      vf_explained_var: 0.20954447984695435
      vf_loss: 33.81834411621094
    num_steps_sampled: 807000
    num_steps_trained: 807000
    wait_time_ms: 67.77
  iterations_since_restore: 269
  node_ip: 172.17.8.3
  num_metric_batches_dropped: 0
  pid: 16746
  policy_reward_mean: {}
  time_since_restore: 2374.4303336143494
  time_this_iter_s: 8.17411184310913
  time_total_s: 2374.4303336143494
  timestamp: 1593885483
  timesteps_since_restore: 807000
  timesteps_this_iter: 3000
  timesteps_total: 807000
  training_iteration: 269
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 33.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=16746], 2374 s, 269 iter, 807000 ts, 724 rew

agent-1: 219.0
agent-2: 269.0
agent-3: 223.0
Sum Reward: 711.0
Avg Reward: 237.0
Min Reward: 219.0
Gini Coefficient: 0.04688232536333802
20:20 Ratio: 1.2283105022831051
Max-min Ratio: 1.2283105022831051
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_13-58-11
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 928.0
  episode_reward_mean: 721.56
  episode_reward_min: 538.0
  episodes_this_iter: 1
  episodes_total: 269
  experiment_id: 86e053a9c80f439496ed6b19bfe1ab59
  hostname: gpu003
  info:
    apply_time_ms: 3.149
    dispatch_time_ms: 8.792
    learner:
      cur_lr: 0.0013062538346275687
      grad_gnorm: 30.233304977416992
      policy_entropy: 16.97372817993164
      policy_loss: -8.705282211303711
      var_gnorm: 34.90541076660156
      vf_explained_var: 0.855211615562439
      vf_loss: 18.529617309570312
    num_steps_sampled: 810000
    num_steps_trained: 810000
    wait_time_ms: 68.42
  iterations_since_restore: 270
  node_ip: 172.17.8.3
  num_metric_batches_dropped: 0
  pid: 16746
  policy_reward_mean: {}
  time_since_restore: 2382.6658551692963
  time_this_iter_s: 8.2355215549469
  time_total_s: 2382.6658551692963
  timestamp: 1593885491
  timesteps_since_restore: 810000
  timesteps_this_iter: 3000
  timesteps_total: 810000
  training_iteration: 270
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 33.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=16746], 2382 s, 270 iter, 810000 ts, 722 rew

agent-1: 252.0
agent-2: 244.0
agent-3: 291.0
Sum Reward: 787.0
Avg Reward: 262.3333333333333
Min Reward: 244.0
Gini Coefficient: 0.03981363828886065
20:20 Ratio: 1.1926229508196722
Max-min Ratio: 1.1926229508196722
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_13-58-19
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 928.0
  episode_reward_mean: 723.02
  episode_reward_min: 538.0
  episodes_this_iter: 1
  episodes_total: 270
  experiment_id: 86e053a9c80f439496ed6b19bfe1ab59
  hostname: gpu003
  info:
    apply_time_ms: 2.768
    dispatch_time_ms: 8.236
    learner:
      cur_lr: 0.0013060539495199919
      grad_gnorm: 40.0
      policy_entropy: 5.698067665100098
      policy_loss: 3.5559473037719727
      var_gnorm: 34.95550537109375
      vf_explained_var: -0.07066524028778076
      vf_loss: 27.937253952026367
    num_steps_sampled: 813000
    num_steps_trained: 813000
    wait_time_ms: 68.796
  iterations_since_restore: 271
  node_ip: 172.17.8.3
  num_metric_batches_dropped: 0
  pid: 16746
  policy_reward_mean: {}
  time_since_restore: 2390.8416368961334
  time_this_iter_s: 8.175781726837158
  time_total_s: 2390.8416368961334
  timestamp: 1593885499
  timesteps_since_restore: 813000
  timesteps_this_iter: 3000
  timesteps_total: 813000
  training_iteration: 271
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 33.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=16746], 2390 s, 271 iter, 813000 ts, 723 rew

agent-1: 225.0
agent-2: 221.0
agent-3: 173.0
Sum Reward: 619.0
Avg Reward: 206.33333333333334
Min Reward: 173.0
Gini Coefficient: 0.05600430802369413
20:20 Ratio: 1.300578034682081
Max-min Ratio: 1.300578034682081
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_13-58-28
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 928.0
  episode_reward_mean: 721.54
  episode_reward_min: 538.0
  episodes_this_iter: 1
  episodes_total: 271
  experiment_id: 86e053a9c80f439496ed6b19bfe1ab59
  hostname: gpu003
  info:
    apply_time_ms: 3.969
    dispatch_time_ms: 6.067
    learner:
      cur_lr: 0.0013058541808277369
      grad_gnorm: 40.0
      policy_entropy: 19.71977424621582
      policy_loss: -14.36375617980957
      var_gnorm: 35.028541564941406
      vf_explained_var: 0.04776090383529663
      vf_loss: 22.274356842041016
    num_steps_sampled: 816000
    num_steps_trained: 816000
    wait_time_ms: 75.916
  iterations_since_restore: 272
  node_ip: 172.17.8.3
  num_metric_batches_dropped: 0
  pid: 16746
  policy_reward_mean: {}
  time_since_restore: 2399.1976935863495
  time_this_iter_s: 8.356056690216064
  time_total_s: 2399.1976935863495
  timestamp: 1593885508
  timesteps_since_restore: 816000
  timesteps_this_iter: 3000
  timesteps_total: 816000
  training_iteration: 272
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 33.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=16746], 2399 s, 272 iter, 816000 ts, 722 rew

agent-1: 245.0
agent-2: 267.0
agent-3: 243.0
Sum Reward: 755.0
Avg Reward: 251.66666666666666
Min Reward: 243.0
Gini Coefficient: 0.02119205298013245
20:20 Ratio: 1.0987654320987654
Max-min Ratio: 1.0987654320987654
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_13-58-36
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 928.0
  episode_reward_mean: 721.0
  episode_reward_min: 538.0
  episodes_this_iter: 1
  episodes_total: 272
  experiment_id: 86e053a9c80f439496ed6b19bfe1ab59
  hostname: gpu003
  info:
    apply_time_ms: 2.722
    dispatch_time_ms: 9.746
    learner:
      cur_lr: 0.0013056544121354818
      grad_gnorm: 17.987213134765625
      policy_entropy: 16.545127868652344
      policy_loss: -0.2174152135848999
      var_gnorm: 35.083282470703125
      vf_explained_var: 0.29505133628845215
      vf_loss: 12.85911750793457
    num_steps_sampled: 819000
    num_steps_trained: 819000
    wait_time_ms: 70.865
  iterations_since_restore: 273
  node_ip: 172.17.8.3
  num_metric_batches_dropped: 0
  pid: 16746
  policy_reward_mean: {}
  time_since_restore: 2407.219292163849
  time_this_iter_s: 8.02159857749939
  time_total_s: 2407.219292163849
  timestamp: 1593885516
  timesteps_since_restore: 819000
  timesteps_this_iter: 3000
  timesteps_total: 819000
  training_iteration: 273
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 33.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=16746], 2407 s, 273 iter, 819000 ts, 721 rew

agent-1: 326.0
agent-2: 275.0
agent-3: 296.0
Sum Reward: 897.0
Avg Reward: 299.0
Min Reward: 275.0
Gini Coefficient: 0.0379041248606466
20:20 Ratio: 1.1854545454545455
Max-min Ratio: 1.1854545454545455
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_13-58-44
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 928.0
  episode_reward_mean: 722.83
  episode_reward_min: 538.0
  episodes_this_iter: 1
  episodes_total: 273
  experiment_id: 86e053a9c80f439496ed6b19bfe1ab59
  hostname: gpu003
  info:
    apply_time_ms: 4.301
    dispatch_time_ms: 7.339
    learner:
      cur_lr: 0.0013054546434432268
      grad_gnorm: 16.875659942626953
      policy_entropy: 20.6916446685791
      policy_loss: 1.8441728353500366
      var_gnorm: 35.115089416503906
      vf_explained_var: 0.3484712839126587
      vf_loss: 23.642114639282227
    num_steps_sampled: 822000
    num_steps_trained: 822000
    wait_time_ms: 67.01
  iterations_since_restore: 274
  node_ip: 172.17.8.3
  num_metric_batches_dropped: 0
  pid: 16746
  policy_reward_mean: {}
  time_since_restore: 2415.159677505493
  time_this_iter_s: 7.940385341644287
  time_total_s: 2415.159677505493
  timestamp: 1593885524
  timesteps_since_restore: 822000
  timesteps_this_iter: 3000
  timesteps_total: 822000
  training_iteration: 274
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 33.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=16746], 2415 s, 274 iter, 822000 ts, 723 rew

agent-1: 210.0
agent-2: 195.0
agent-3: 245.0
Sum Reward: 650.0
Avg Reward: 216.66666666666666
Min Reward: 195.0
Gini Coefficient: 0.05128205128205128
20:20 Ratio: 1.2564102564102564
Max-min Ratio: 1.2564102564102564
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_13-58-52
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 928.0
  episode_reward_mean: 720.56
  episode_reward_min: 538.0
  episodes_this_iter: 1
  episodes_total: 274
  experiment_id: 86e053a9c80f439496ed6b19bfe1ab59
  hostname: gpu003
  info:
    apply_time_ms: 2.643
    dispatch_time_ms: 8.764
    learner:
      cur_lr: 0.00130525475833565
      grad_gnorm: 40.00000762939453
      policy_entropy: 18.520858764648438
      policy_loss: -0.44967520236968994
      var_gnorm: 35.12396240234375
      vf_explained_var: 0.344570517539978
      vf_loss: 50.085750579833984
    num_steps_sampled: 825000
    num_steps_trained: 825000
    wait_time_ms: 70.228
  iterations_since_restore: 275
  node_ip: 172.17.8.3
  num_metric_batches_dropped: 0
  pid: 16746
  policy_reward_mean: {}
  time_since_restore: 2423.074851989746
  time_this_iter_s: 7.91517448425293
  time_total_s: 2423.074851989746
  timestamp: 1593885532
  timesteps_since_restore: 825000
  timesteps_this_iter: 3000
  timesteps_total: 825000
  training_iteration: 275
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 33.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=16746], 2423 s, 275 iter, 825000 ts, 721 rew

agent-1: 262.0
agent-2: 214.0
agent-3: 176.0
Sum Reward: 652.0
Avg Reward: 217.33333333333334
Min Reward: 176.0
Gini Coefficient: 0.08793456032719836
20:20 Ratio: 1.4886363636363635
Max-min Ratio: 1.4886363636363635
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_13-59-00
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 928.0
  episode_reward_mean: 719.81
  episode_reward_min: 538.0
  episodes_this_iter: 1
  episodes_total: 275
  experiment_id: 86e053a9c80f439496ed6b19bfe1ab59
  hostname: gpu003
  info:
    apply_time_ms: 3.814
    dispatch_time_ms: 8.391
    learner:
      cur_lr: 0.001305054989643395
      grad_gnorm: 31.051855087280273
      policy_entropy: 19.34370231628418
      policy_loss: -8.768668174743652
      var_gnorm: 35.12001037597656
      vf_explained_var: 0.8522218465805054
      vf_loss: 11.113445281982422
    num_steps_sampled: 828000
    num_steps_trained: 828000
    wait_time_ms: 70.394
  iterations_since_restore: 276
  node_ip: 172.17.8.3
  num_metric_batches_dropped: 0
  pid: 16746
  policy_reward_mean: {}
  time_since_restore: 2431.0397684574127
  time_this_iter_s: 7.964916467666626
  time_total_s: 2431.0397684574127
  timestamp: 1593885540
  timesteps_since_restore: 828000
  timesteps_this_iter: 3000
  timesteps_total: 828000
  training_iteration: 276
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 33.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=16746], 2431 s, 276 iter, 828000 ts, 720 rew

agent-1: 237.0
agent-2: 222.0
agent-3: 258.0
Sum Reward: 717.0
Avg Reward: 239.0
Min Reward: 222.0
Gini Coefficient: 0.03347280334728033
20:20 Ratio: 1.162162162162162
Max-min Ratio: 1.162162162162162
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_13-59-08
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 928.0
  episode_reward_mean: 720.34
  episode_reward_min: 538.0
  episodes_this_iter: 1
  episodes_total: 276
  experiment_id: 86e053a9c80f439496ed6b19bfe1ab59
  hostname: gpu003
  info:
    apply_time_ms: 2.632
    dispatch_time_ms: 6.127
    learner:
      cur_lr: 0.00130485522095114
      grad_gnorm: 39.999996185302734
      policy_entropy: 19.631803512573242
      policy_loss: -21.8880672454834
      var_gnorm: 35.187862396240234
      vf_explained_var: -1.0
      vf_loss: 79.91910552978516
    num_steps_sampled: 831000
    num_steps_trained: 831000
    wait_time_ms: 70.077
  iterations_since_restore: 277
  node_ip: 172.17.8.3
  num_metric_batches_dropped: 0
  pid: 16746
  policy_reward_mean: {}
  time_since_restore: 2438.895080089569
  time_this_iter_s: 7.855311632156372
  time_total_s: 2438.895080089569
  timestamp: 1593885548
  timesteps_since_restore: 831000
  timesteps_this_iter: 3000
  timesteps_total: 831000
  training_iteration: 277
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 33.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=16746], 2438 s, 277 iter, 831000 ts, 720 rew

agent-1: 204.0
agent-2: 269.0
agent-3: 184.0
Sum Reward: 657.0
Avg Reward: 219.0
Min Reward: 184.0
Gini Coefficient: 0.08625063419583967
20:20 Ratio: 1.4619565217391304
Max-min Ratio: 1.4619565217391304
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_13-59-15
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 928.0
  episode_reward_mean: 720.95
  episode_reward_min: 538.0
  episodes_this_iter: 1
  episodes_total: 277
  experiment_id: 86e053a9c80f439496ed6b19bfe1ab59
  hostname: gpu003
  info:
    apply_time_ms: 4.026
    dispatch_time_ms: 7.479
    learner:
      cur_lr: 0.001304655452258885
      grad_gnorm: 36.939517974853516
      policy_entropy: 12.045454025268555
      policy_loss: -4.893195152282715
      var_gnorm: 35.16862106323242
      vf_explained_var: 0.5663913488388062
      vf_loss: 22.917884826660156
    num_steps_sampled: 834000
    num_steps_trained: 834000
    wait_time_ms: 68.934
  iterations_since_restore: 278
  node_ip: 172.17.8.3
  num_metric_batches_dropped: 0
  pid: 16746
  policy_reward_mean: {}
  time_since_restore: 2446.7399814128876
  time_this_iter_s: 7.8449013233184814
  time_total_s: 2446.7399814128876
  timestamp: 1593885555
  timesteps_since_restore: 834000
  timesteps_this_iter: 3000
  timesteps_total: 834000
  training_iteration: 278
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 33.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=16746], 2446 s, 278 iter, 834000 ts, 721 rew

agent-1: 226.0
agent-2: 257.0
agent-3: 214.0
Sum Reward: 697.0
Avg Reward: 232.33333333333334
Min Reward: 214.0
Gini Coefficient: 0.041128646580583454
20:20 Ratio: 1.2009345794392523
Max-min Ratio: 1.2009345794392523
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_13-59-23
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 928.0
  episode_reward_mean: 721.71
  episode_reward_min: 538.0
  episodes_this_iter: 1
  episodes_total: 278
  experiment_id: 86e053a9c80f439496ed6b19bfe1ab59
  hostname: gpu003
  info:
    apply_time_ms: 3.413
    dispatch_time_ms: 8.324
    learner:
      cur_lr: 0.001304455567151308
      grad_gnorm: 22.080535888671875
      policy_entropy: 16.649112701416016
      policy_loss: 4.4886155128479
      var_gnorm: 35.22597885131836
      vf_explained_var: 0.766694962978363
      vf_loss: 16.288320541381836
    num_steps_sampled: 837000
    num_steps_trained: 837000
    wait_time_ms: 71.38
  iterations_since_restore: 279
  node_ip: 172.17.8.3
  num_metric_batches_dropped: 0
  pid: 16746
  policy_reward_mean: {}
  time_since_restore: 2454.4215216636658
  time_this_iter_s: 7.681540250778198
  time_total_s: 2454.4215216636658
  timestamp: 1593885563
  timesteps_since_restore: 837000
  timesteps_this_iter: 3000
  timesteps_total: 837000
  training_iteration: 279
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 33.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=16746], 2454 s, 279 iter, 837000 ts, 722 rew

agent-1: 237.0
agent-2: 307.0
agent-3: 258.0
Sum Reward: 802.0
Avg Reward: 267.3333333333333
Min Reward: 237.0
Gini Coefficient: 0.058187863674147966
20:20 Ratio: 1.2953586497890295
Max-min Ratio: 1.2953586497890295
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_13-59-31
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 928.0
  episode_reward_mean: 722.08
  episode_reward_min: 538.0
  episodes_this_iter: 1
  episodes_total: 279
  experiment_id: 86e053a9c80f439496ed6b19bfe1ab59
  hostname: gpu003
  info:
    apply_time_ms: 2.551
    dispatch_time_ms: 6.63
    learner:
      cur_lr: 0.001304255798459053
      grad_gnorm: 40.0
      policy_entropy: 12.94894027709961
      policy_loss: 22.05191993713379
      var_gnorm: 35.21267318725586
      vf_explained_var: -0.006364583969116211
      vf_loss: 40.57987594604492
    num_steps_sampled: 840000
    num_steps_trained: 840000
    wait_time_ms: 74.363
  iterations_since_restore: 280
  node_ip: 172.17.8.3
  num_metric_batches_dropped: 0
  pid: 16746
  policy_reward_mean: {}
  time_since_restore: 2462.663688182831
  time_this_iter_s: 8.242166519165039
  time_total_s: 2462.663688182831
  timestamp: 1593885571
  timesteps_since_restore: 840000
  timesteps_this_iter: 3000
  timesteps_total: 840000
  training_iteration: 280
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 33.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=16746], 2462 s, 280 iter, 840000 ts, 722 rew

agent-1: 266.0
agent-2: 230.0
agent-3: 260.0
Sum Reward: 756.0
Avg Reward: 252.0
Min Reward: 230.0
Gini Coefficient: 0.031746031746031744
20:20 Ratio: 1.1565217391304348
Max-min Ratio: 1.1565217391304348
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_13-59-40
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 928.0
  episode_reward_mean: 722.67
  episode_reward_min: 538.0
  episodes_this_iter: 1
  episodes_total: 280
  experiment_id: 86e053a9c80f439496ed6b19bfe1ab59
  hostname: gpu003
  info:
    apply_time_ms: 2.838
    dispatch_time_ms: 8.493
    learner:
      cur_lr: 0.001304056029766798
      grad_gnorm: 16.482892990112305
      policy_entropy: 12.872368812561035
      policy_loss: 2.67008376121521
      var_gnorm: 35.253379821777344
      vf_explained_var: 0.7236465215682983
      vf_loss: 28.39031219482422
    num_steps_sampled: 843000
    num_steps_trained: 843000
    wait_time_ms: 72.579
  iterations_since_restore: 281
  node_ip: 172.17.8.3
  num_metric_batches_dropped: 0
  pid: 16746
  policy_reward_mean: {}
  time_since_restore: 2470.7883040905
  time_this_iter_s: 8.124615907669067
  time_total_s: 2470.7883040905
  timestamp: 1593885580
  timesteps_since_restore: 843000
  timesteps_this_iter: 3000
  timesteps_total: 843000
  training_iteration: 281
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 33.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=16746], 2470 s, 281 iter, 843000 ts, 723 rew

agent-1: 242.0
agent-2: 251.0
agent-3: 245.0
Sum Reward: 738.0
Avg Reward: 246.0
Min Reward: 242.0
Gini Coefficient: 0.008130081300813009
20:20 Ratio: 1.037190082644628
Max-min Ratio: 1.037190082644628
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_13-59-48
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 928.0
  episode_reward_mean: 722.71
  episode_reward_min: 538.0
  episodes_this_iter: 1
  episodes_total: 281
  experiment_id: 86e053a9c80f439496ed6b19bfe1ab59
  hostname: gpu003
  info:
    apply_time_ms: 3.123
    dispatch_time_ms: 8.106
    learner:
      cur_lr: 0.0013038561446592212
      grad_gnorm: 32.0052375793457
      policy_entropy: 20.69232177734375
      policy_loss: 9.510146141052246
      var_gnorm: 35.32410430908203
      vf_explained_var: 0.47015684843063354
      vf_loss: 25.861591339111328
    num_steps_sampled: 846000
    num_steps_trained: 846000
    wait_time_ms: 79.812
  iterations_since_restore: 282
  node_ip: 172.17.8.3
  num_metric_batches_dropped: 0
  pid: 16746
  policy_reward_mean: {}
  time_since_restore: 2479.4001553058624
  time_this_iter_s: 8.611851215362549
  time_total_s: 2479.4001553058624
  timestamp: 1593885588
  timesteps_since_restore: 846000
  timesteps_this_iter: 3000
  timesteps_total: 846000
  training_iteration: 282
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 33.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=16746], 2479 s, 282 iter, 846000 ts, 723 rew

agent-1: 230.0
agent-2: 236.0
agent-3: 199.0
Sum Reward: 665.0
Avg Reward: 221.66666666666666
Min Reward: 199.0
Gini Coefficient: 0.037092731829573934
20:20 Ratio: 1.185929648241206
Max-min Ratio: 1.185929648241206
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_13-59-57
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 928.0
  episode_reward_mean: 722.64
  episode_reward_min: 538.0
  episodes_this_iter: 1
  episodes_total: 282
  experiment_id: 86e053a9c80f439496ed6b19bfe1ab59
  hostname: gpu003
  info:
    apply_time_ms: 3.091
    dispatch_time_ms: 6.688
    learner:
      cur_lr: 0.0013036563759669662
      grad_gnorm: 40.0
      policy_entropy: 19.521556854248047
      policy_loss: 28.377952575683594
      var_gnorm: 35.352176666259766
      vf_explained_var: -1.0
      vf_loss: 49.895362854003906
    num_steps_sampled: 849000
    num_steps_trained: 849000
    wait_time_ms: 79.791
  iterations_since_restore: 283
  node_ip: 172.17.8.3
  num_metric_batches_dropped: 0
  pid: 16746
  policy_reward_mean: {}
  time_since_restore: 2487.64928483963
  time_this_iter_s: 8.2491295337677
  time_total_s: 2487.64928483963
  timestamp: 1593885597
  timesteps_since_restore: 849000
  timesteps_this_iter: 3000
  timesteps_total: 849000
  training_iteration: 283
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 33.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=16746], 2487 s, 283 iter, 849000 ts, 723 rew

agent-1: 278.0
agent-2: 214.0
agent-3: 194.0
Sum Reward: 686.0
Avg Reward: 228.66666666666666
Min Reward: 194.0
Gini Coefficient: 0.08163265306122448
20:20 Ratio: 1.4329896907216495
Max-min Ratio: 1.4329896907216495
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_14-00-05
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 928.0
  episode_reward_mean: 721.75
  episode_reward_min: 538.0
  episodes_this_iter: 1
  episodes_total: 283
  experiment_id: 86e053a9c80f439496ed6b19bfe1ab59
  hostname: gpu003
  info:
    apply_time_ms: 2.729
    dispatch_time_ms: 5.213
    learner:
      cur_lr: 0.0013034566072747111
      grad_gnorm: 40.0
      policy_entropy: 13.939224243164062
      policy_loss: 19.0864200592041
      var_gnorm: 35.408512115478516
      vf_explained_var: -0.6160277128219604
      vf_loss: 46.77294921875
    num_steps_sampled: 852000
    num_steps_trained: 852000
    wait_time_ms: 69.04
  iterations_since_restore: 284
  node_ip: 172.17.8.3
  num_metric_batches_dropped: 0
  pid: 16746
  policy_reward_mean: {}
  time_since_restore: 2496.26690530777
  time_this_iter_s: 8.617620468139648
  time_total_s: 2496.26690530777
  timestamp: 1593885605
  timesteps_since_restore: 852000
  timesteps_this_iter: 3000
  timesteps_total: 852000
  training_iteration: 284
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 33.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=16746], 2496 s, 284 iter, 852000 ts, 722 rew

agent-1: 255.0
agent-2: 219.0
agent-3: 328.0
Sum Reward: 802.0
Avg Reward: 267.3333333333333
Min Reward: 219.0
Gini Coefficient: 0.09060681629260182
20:20 Ratio: 1.4977168949771689
Max-min Ratio: 1.4977168949771689
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_14-00-14
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 926.0
  episode_reward_mean: 720.49
  episode_reward_min: 538.0
  episodes_this_iter: 1
  episodes_total: 284
  experiment_id: 86e053a9c80f439496ed6b19bfe1ab59
  hostname: gpu003
  info:
    apply_time_ms: 3.812
    dispatch_time_ms: 6.785
    learner:
      cur_lr: 0.0013032568385824561
      grad_gnorm: 38.562339782714844
      policy_entropy: 16.033048629760742
      policy_loss: -9.554328918457031
      var_gnorm: 35.4526252746582
      vf_explained_var: 0.8724057674407959
      vf_loss: 18.562955856323242
    num_steps_sampled: 855000
    num_steps_trained: 855000
    wait_time_ms: 81.335
  iterations_since_restore: 285
  node_ip: 172.17.8.3
  num_metric_batches_dropped: 0
  pid: 16746
  policy_reward_mean: {}
  time_since_restore: 2504.5649580955505
  time_this_iter_s: 8.298052787780762
  time_total_s: 2504.5649580955505
  timestamp: 1593885614
  timesteps_since_restore: 855000
  timesteps_this_iter: 3000
  timesteps_total: 855000
  training_iteration: 285
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 33.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=16746], 2504 s, 285 iter, 855000 ts, 720 rew

agent-1: 239.0
agent-2: 243.0
agent-3: 192.0
Sum Reward: 674.0
Avg Reward: 224.66666666666666
Min Reward: 192.0
Gini Coefficient: 0.050445103857566766
20:20 Ratio: 1.265625
Max-min Ratio: 1.265625
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_14-00-22
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 926.0
  episode_reward_mean: 720.92
  episode_reward_min: 538.0
  episodes_this_iter: 1
  episodes_total: 285
  experiment_id: 86e053a9c80f439496ed6b19bfe1ab59
  hostname: gpu003
  info:
    apply_time_ms: 4.021
    dispatch_time_ms: 6.71
    learner:
      cur_lr: 0.0013030569534748793
      grad_gnorm: 40.0
      policy_entropy: 19.81239891052246
      policy_loss: -15.464315414428711
      var_gnorm: 35.51399612426758
      vf_explained_var: 0.8933918476104736
      vf_loss: 17.602306365966797
    num_steps_sampled: 858000
    num_steps_trained: 858000
    wait_time_ms: 63.015
  iterations_since_restore: 286
  node_ip: 172.17.8.3
  num_metric_batches_dropped: 0
  pid: 16746
  policy_reward_mean: {}
  time_since_restore: 2513.4283998012543
  time_this_iter_s: 8.863441705703735
  time_total_s: 2513.4283998012543
  timestamp: 1593885622
  timesteps_since_restore: 858000
  timesteps_this_iter: 3000
  timesteps_total: 858000
  training_iteration: 286
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 33.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=16746], 2513 s, 286 iter, 858000 ts, 721 rew

agent-1: 251.0
agent-2: 209.0
agent-3: 296.0
Sum Reward: 756.0
Avg Reward: 252.0
Min Reward: 209.0
Gini Coefficient: 0.07671957671957672
20:20 Ratio: 1.4162679425837321
Max-min Ratio: 1.4162679425837321
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_14-00-31
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 926.0
  episode_reward_mean: 720.89
  episode_reward_min: 538.0
  episodes_this_iter: 1
  episodes_total: 286
  experiment_id: 86e053a9c80f439496ed6b19bfe1ab59
  hostname: gpu003
  info:
    apply_time_ms: 2.621
    dispatch_time_ms: 5.382
    learner:
      cur_lr: 0.0013028571847826242
      grad_gnorm: 39.999996185302734
      policy_entropy: 10.088384628295898
      policy_loss: -6.497892379760742
      var_gnorm: 35.52217102050781
      vf_explained_var: 0.6714333295822144
      vf_loss: 15.55729866027832
    num_steps_sampled: 861000
    num_steps_trained: 861000
    wait_time_ms: 71.362
  iterations_since_restore: 287
  node_ip: 172.17.8.3
  num_metric_batches_dropped: 0
  pid: 16746
  policy_reward_mean: {}
  time_since_restore: 2521.542958498001
  time_this_iter_s: 8.114558696746826
  time_total_s: 2521.542958498001
  timestamp: 1593885631
  timesteps_since_restore: 861000
  timesteps_this_iter: 3000
  timesteps_total: 861000
  training_iteration: 287
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 33.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=16746], 2521 s, 287 iter, 861000 ts, 721 rew

agent-1: 258.0
agent-2: 237.0
agent-3: 229.0
Sum Reward: 724.0
Avg Reward: 241.33333333333334
Min Reward: 229.0
Gini Coefficient: 0.026703499079189688
20:20 Ratio: 1.1266375545851528
Max-min Ratio: 1.1266375545851528
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_14-00-39
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 926.0
  episode_reward_mean: 722.75
  episode_reward_min: 546.0
  episodes_this_iter: 1
  episodes_total: 287
  experiment_id: 86e053a9c80f439496ed6b19bfe1ab59
  hostname: gpu003
  info:
    apply_time_ms: 3.855
    dispatch_time_ms: 7.389
    learner:
      cur_lr: 0.0013026574160903692
      grad_gnorm: 40.0
      policy_entropy: 8.268959999084473
      policy_loss: 9.739426612854004
      var_gnorm: 35.548519134521484
      vf_explained_var: 0.2508552074432373
      vf_loss: 30.91495132446289
    num_steps_sampled: 864000
    num_steps_trained: 864000
    wait_time_ms: 66.045
  iterations_since_restore: 288
  node_ip: 172.17.8.3
  num_metric_batches_dropped: 0
  pid: 16746
  policy_reward_mean: {}
  time_since_restore: 2530.1001856327057
  time_this_iter_s: 8.55722713470459
  time_total_s: 2530.1001856327057
  timestamp: 1593885639
  timesteps_since_restore: 864000
  timesteps_this_iter: 3000
  timesteps_total: 864000
  training_iteration: 288
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 33.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=16746], 2530 s, 288 iter, 864000 ts, 723 rew

agent-1: 197.0
agent-2: 281.0
agent-3: 323.0
Sum Reward: 801.0
Avg Reward: 267.0
Min Reward: 197.0
Gini Coefficient: 0.10486891385767791
20:20 Ratio: 1.6395939086294415
Max-min Ratio: 1.6395939086294415
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_14-00-47
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 926.0
  episode_reward_mean: 723.48
  episode_reward_min: 546.0
  episodes_this_iter: 1
  episodes_total: 288
  experiment_id: 86e053a9c80f439496ed6b19bfe1ab59
  hostname: gpu003
  info:
    apply_time_ms: 3.168
    dispatch_time_ms: 6.941
    learner:
      cur_lr: 0.0013024576473981142
      grad_gnorm: 30.249771118164062
      policy_entropy: 16.844675064086914
      policy_loss: 4.681166648864746
      var_gnorm: 35.60099411010742
      vf_explained_var: -0.672374963760376
      vf_loss: 25.653472900390625
    num_steps_sampled: 867000
    num_steps_trained: 867000
    wait_time_ms: 76.915
  iterations_since_restore: 289
  node_ip: 172.17.8.3
  num_metric_batches_dropped: 0
  pid: 16746
  policy_reward_mean: {}
  time_since_restore: 2538.341947078705
  time_this_iter_s: 8.241761445999146
  time_total_s: 2538.341947078705
  timestamp: 1593885647
  timesteps_since_restore: 867000
  timesteps_this_iter: 3000
  timesteps_total: 867000
  training_iteration: 289
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 33.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=16746], 2538 s, 289 iter, 867000 ts, 723 rew

F0704 14:00:50.690258 16738 node_manager.cc:1771]  Check failed: waiting_task_id_set.empty() 
*** Check failure stack trace: ***
    @           0x5b1006  google::LogMessage::Fail()
    @           0x5b0f52  google::LogMessage::SendToLog()
    @           0x5b08d6  google::LogMessage::Flush()
    @           0x5b06e5  google::LogMessage::~LogMessage()
    @           0x5020e8  ray::RayLog::~RayLog()
    @           0x53d9bd  ray::raylet::NodeManager::HandleObjectMissing()
    @           0x55f110  ray::ObjectStoreNotificationManager::ProcessStoreRemove()
    @           0x55fb00  ray::ObjectStoreNotificationManager::ProcessStoreNotification()
    @           0x560c42  boost::asio::detail::read_op<>::operator()()
    @           0x560e33  boost::asio::detail::reactive_socket_recv_op<>::do_complete()
    @           0x4bb41d  boost::asio::detail::scheduler::run()
    @           0x4b1bc7  main
    @     0x7f591a26eb97  __libc_start_main
    @           0x4b7311  (unknown)
WARNING: Logging before InitGoogleLogging() is written to STDERR
F0704 14:00:51.059535 16755 raylet_extension.cc:66]  Check failed: _s.ok() [RayletClient] Failed to get a task from raylet.: IOError: [RayletClient] Raylet connection closed.
WARNING: Logging before InitGoogleLogging() is written to STDERR
F0704 14:00:51.067916 16745 raylet_extension.cc:66]  Check failed: _s.ok() [RayletClient] Failed to get a task from raylet.: IOError: [RayletClient] Raylet connection closed.
*** Check failure stack trace: ***
*** Check failure stack trace: ***
Fatal Python error: Aborted

Stack (most recent call first):
  File "/h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/ray/worker.py"Fatal Python error: Aborted

Stack (most recent call first):
  File "/h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/ray/worker.py", line 944 in _get_next_task_from_local_scheduler
  File "/h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/ray/worker.py", line 961 in main_loop
  File , line 944 in _get_next_task_from_local_scheduler
  File "/h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/ray/worker.py", line 961 in main_loop
"/h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/ray/workers/default_worker.py", line 107 in <module>
  File "/h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/ray/workers/default_worker.py", line 107 in <module>
WARNING: Logging before InitGoogleLogging() is written to STDERR
F0704 14:00:51.783972 16746 raylet_extension.cc:190]  Check failed: _s.ok() [RayletClient] Failed to wait for objects.: IOError: [RayletClient] Raylet connection closed.
*** Check failure stack trace: ***
Fatal Python error: Aborted

Stack (most recent call first):
  File "/h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/ray/worker.py", line 2485 in wait
  File "/h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/ray/rllib/optimizers/async_gradients_optimizer.py", line 46 in step
  File "/h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/ray/rllib/agents/a3c/a3c.py", line 68 in _train
  File "/h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/ray/tune/trainable.py", line 146 in train
  File "/h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/ray/rllib/agents/agent.py", line 279 in train
  File "/h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/ray/function_manager.py", line 713 in actor_method_executor
  File "/h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/ray/worker.py", line 820 in _process_task
  File "/h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/ray/worker.py", line 919 in _wait_for_and_process_task
  File "/h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/ray/worker.py", line 962 in main_loop
  File "/h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/ray/workers/default_worker.py", line 107 in <module>
WARNING: Logging before InitGoogleLogging() is written to STDERR
F0704 14:00:51.817584 16663 raylet_extension.cc:190]  Check failed: _s.ok() [RayletClient] Failed to wait for objects.: IOError: [RayletClient] Raylet connection closed.
*** Check failure stack trace: ***
Fatal Python error: Aborted

Stack (most recent call first):
  File "/h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/ray/worker.py", line 2485 in wait
  File "/h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/ray/tune/ray_trial_executor.py", line 199 in get_next_available_trial
  File "/h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/ray/tune/trial_runner.py", line 259 in _process_events
  File "/h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/ray/tune/trial_runner.py", line 118 in step
  File "/h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/ray/tune/tune.py", line 108 in run_experiments
  File "train_agents.py", line 209 in main
  File "train_agents.py", line 231 in <module>
srun: error: gpu003: task 0: Aborted
