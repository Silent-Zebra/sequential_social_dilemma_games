/h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:523: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint8 = np.dtype([("qint8", np.int8, 1)])
/h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:524: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint8 = np.dtype([("quint8", np.uint8, 1)])
/h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint16 = np.dtype([("qint16", np.int16, 1)])
/h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint16 = np.dtype([("quint16", np.uint16, 1)])
/h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint32 = np.dtype([("qint32", np.int32, 1)])
/h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:532: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  np_resource = np.dtype([("resource", np.ubyte, 1)])
Process STDOUT and STDERR is being redirected to /tmp/ray/session_2020-07-07_14-11-15_10802/logs.
Waiting for redis server at 127.0.0.1:13832 to respond...
Waiting for redis server at 127.0.0.1:10981 to respond...
Warning: Capping object memory store to 20.0GB. To increase this further, specify `object_store_memory` when calling ray.init() or ray start.
Starting the Plasma object store with 20.0 GB memory using /dev/shm.

======================================================================
View the web UI at http://localhost:8889/notebooks/ray_ui.ipynb?token=ebe8f6b4c2bf48a0b6849573b6b5e26db9c120639a4150bd
======================================================================

== Status ==
Using FIFO scheduling algorithm.
Resources requested: 0/2 CPUs, 0/1 GPUs
Memory usage on this node: 11.0/202.5 GB

Created LogSyncer for /h/zhaostep/ray_results/harvest_A3C/A3C_harvest_env_0_2020-07-07_14-11-1557s8d0jy -> 
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 11.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING

/h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:523: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint8 = np.dtype([("qint8", np.int8, 1)])
/h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:524: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint8 = np.dtype([("quint8", np.uint8, 1)])
/h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint16 = np.dtype([("qint16", np.int16, 1)])
/h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint16 = np.dtype([("quint16", np.uint16, 1)])
/h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint32 = np.dtype([("qint32", np.int32, 1)])
/h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:532: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  np_resource = np.dtype([("resource", np.ubyte, 1)])
2020-07-07 14:11:27,839	INFO policy_evaluator.py:262 -- Creating policy evaluation worker 0 on CPU (please ignore any CUDA init errors)
2020-07-07 14:11:27.840481: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
From /h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/ray/rllib/models/lstm.py:59: BasicLSTMCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.
Instructions for updating:
This class is deprecated, please use tf.nn.rnn_cell.LSTMCell, which supports all the feature this cell currently has. Please replace the existing code with tf.nn.rnn_cell.LSTMCell(name='basic_lstm_cell').
/h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:523: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint8 = np.dtype([("qint8", np.int8, 1)])
/h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:524: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint8 = np.dtype([("quint8", np.uint8, 1)])
/h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint16 = np.dtype([("qint16", np.int16, 1)])
/h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint16 = np.dtype([("quint16", np.uint16, 1)])
/h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint32 = np.dtype([("qint32", np.int32, 1)])
/h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:532: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  np_resource = np.dtype([("resource", np.ubyte, 1)])
2020-07-07 14:11:39,165	INFO policy_evaluator.py:262 -- Creating policy evaluation worker 2 on CPU (please ignore any CUDA init errors)
2020-07-07 14:11:39.166455: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
/h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:523: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint8 = np.dtype([("qint8", np.int8, 1)])
/h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:524: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint8 = np.dtype([("quint8", np.uint8, 1)])
/h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint16 = np.dtype([("qint16", np.int16, 1)])
/h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint16 = np.dtype([("quint16", np.uint16, 1)])
/h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint32 = np.dtype([("qint32", np.int32, 1)])
/h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:532: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  np_resource = np.dtype([("resource", np.ubyte, 1)])
2020-07-07 14:11:39,266	INFO policy_evaluator.py:262 -- Creating policy evaluation worker 1 on CPU (please ignore any CUDA init errors)
2020-07-07 14:11:39.267735: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
From /h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/ray/rllib/models/lstm.py:59: BasicLSTMCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.
Instructions for updating:
This class is deprecated, please use tf.nn.rnn_cell.LSTMCell, which supports all the feature this cell currently has. Please replace the existing code with tf.nn.rnn_cell.LSTMCell(name='basic_lstm_cell').
From /h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/ray/rllib/models/lstm.py:59: BasicLSTMCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.
Instructions for updating:
This class is deprecated, please use tf.nn.rnn_cell.LSTMCell, which supports all the feature this cell currently has. Please replace the existing code with tf.nn.rnn_cell.LSTMCell(name='basic_lstm_cell').
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_14-11-46
  done: false
  episode_len_mean: .nan
  episode_reward_max: .nan
  episode_reward_mean: .nan
  episode_reward_min: .nan
  episodes_this_iter: 0
  episodes_total: 0
  experiment_id: cb3a18e0a26e466496590bc0542b68c4
  hostname: gpu020
  info:
    apply_time_ms: 2.661
    dispatch_time_ms: 7.637
    learner:
      cur_lr: 0.0013599999947473407
      grad_gnorm: 15.801801681518555
      policy_entropy: 18.44765853881836
      policy_loss: -10.120023727416992
      var_gnorm: 17.941471099853516
      vf_explained_var: 0.0
      vf_loss: 2.5874695777893066
    num_steps_sampled: 1000
    num_steps_trained: 1000
    wait_time_ms: 35.598
  iterations_since_restore: 1
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 10879
  policy_reward_mean: {}
  time_since_restore: 17.237711668014526
  time_this_iter_s: 17.237711668014526
  time_total_s: 17.237711668014526
  timestamp: 1594145506
  timesteps_since_restore: 1000
  timesteps_this_iter: 1000
  timesteps_total: 1000
  training_iteration: 1
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 11.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10879], 17 s, 1 iter, 1000 ts, nan rew

[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.[0m
agent-1: 54.0
Sum Reward: 54.0
Avg Reward: 54.0
Min Reward: 54.0
Max Reward: 54.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.[0m
agent-1: 61.0
Sum Reward: 61.0
Avg Reward: 61.0
Min Reward: 61.0
Max Reward: 61.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_14-11-55
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 61.0
  episode_reward_mean: 57.5
  episode_reward_min: 54.0
  episodes_this_iter: 2
  episodes_total: 2
  experiment_id: cb3a18e0a26e466496590bc0542b68c4
  hostname: gpu020
  info:
    apply_time_ms: 3.485
    dispatch_time_ms: 5.714
    learner:
      cur_lr: 0.0013599334051832557
      grad_gnorm: 17.829925537109375
      policy_entropy: 12.478114128112793
      policy_loss: -3.542706251144409
      var_gnorm: 18.072837829589844
      vf_explained_var: -0.12881815433502197
      vf_loss: 0.6542440056800842
    num_steps_sampled: 3000
    num_steps_trained: 3000
    wait_time_ms: 39.853
  iterations_since_restore: 2
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 10879
  policy_reward_mean: {}
  time_since_restore: 26.483954191207886
  time_this_iter_s: 9.24624252319336
  time_total_s: 26.483954191207886
  timestamp: 1594145515
  timesteps_since_restore: 3000
  timesteps_this_iter: 2000
  timesteps_total: 3000
  training_iteration: 2
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 12.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10879], 26 s, 2 iter, 3000 ts, 57.5 rew

agent-1: 88.0
Sum Reward: 88.0
Avg Reward: 88.0
Min Reward: 88.0
Max Reward: 88.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
agent-1: 181.0
Sum Reward: 181.0
Avg Reward: 181.0
Min Reward: 181.0
Max Reward: 181.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_14-12-04
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 181.0
  episode_reward_mean: 96.0
  episode_reward_min: 54.0
  episodes_this_iter: 2
  episodes_total: 4
  experiment_id: cb3a18e0a26e466496590bc0542b68c4
  hostname: gpu020
  info:
    apply_time_ms: 4.517
    dispatch_time_ms: 8.208
    learner:
      cur_lr: 0.0013598002260550857
      grad_gnorm: 13.852014541625977
      policy_entropy: 15.08297061920166
      policy_loss: 6.904133319854736
      var_gnorm: 18.29500961303711
      vf_explained_var: -0.1352705955505371
      vf_loss: 1.4061970710754395
    num_steps_sampled: 5000
    num_steps_trained: 5000
    wait_time_ms: 32.418
  iterations_since_restore: 3
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 10879
  policy_reward_mean: {}
  time_since_restore: 35.61336541175842
  time_this_iter_s: 9.129411220550537
  time_total_s: 35.61336541175842
  timestamp: 1594145524
  timesteps_since_restore: 5000
  timesteps_this_iter: 2000
  timesteps_total: 5000
  training_iteration: 3
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 12.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10879], 35 s, 3 iter, 5000 ts, 96 rew

agent-1: 118.0
Sum Reward: 118.0
Avg Reward: 118.0
Min Reward: 118.0
Max Reward: 118.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
agent-1: 154.0
Sum Reward: 154.0
Avg Reward: 154.0
Min Reward: 154.0
Max Reward: 154.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_14-12-14
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 181.0
  episode_reward_mean: 109.33333333333333
  episode_reward_min: 54.0
  episodes_this_iter: 2
  episodes_total: 6
  experiment_id: cb3a18e0a26e466496590bc0542b68c4
  hostname: gpu020
  info:
    apply_time_ms: 2.822
    dispatch_time_ms: 7.202
    learner:
      cur_lr: 0.0013596670469269156
      grad_gnorm: 21.771669387817383
      policy_entropy: 10.705406188964844
      policy_loss: 7.161410331726074
      var_gnorm: 18.515289306640625
      vf_explained_var: -1.9073486328125e-06
      vf_loss: 6.8303937911987305
    num_steps_sampled: 7000
    num_steps_trained: 7000
    wait_time_ms: 36.41
  iterations_since_restore: 4
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 10879
  policy_reward_mean: {}
  time_since_restore: 44.89025926589966
  time_this_iter_s: 9.276893854141235
  time_total_s: 44.89025926589966
  timestamp: 1594145534
  timesteps_since_restore: 7000
  timesteps_this_iter: 2000
  timesteps_total: 7000
  training_iteration: 4
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 12.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10879], 44 s, 4 iter, 7000 ts, 109 rew

agent-1: 216.0
Sum Reward: 216.0
Avg Reward: 216.0
Min Reward: 216.0
Max Reward: 216.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
agent-1: 179.0
Sum Reward: 179.0
Avg Reward: 179.0
Min Reward: 179.0
Max Reward: 179.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_14-12-23
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 216.0
  episode_reward_mean: 131.375
  episode_reward_min: 54.0
  episodes_this_iter: 2
  episodes_total: 8
  experiment_id: cb3a18e0a26e466496590bc0542b68c4
  hostname: gpu020
  info:
    apply_time_ms: 3.105
    dispatch_time_ms: 8.582
    learner:
      cur_lr: 0.0013595337513834238
      grad_gnorm: 26.545848846435547
      policy_entropy: 13.252656936645508
      policy_loss: 7.6864013671875
      var_gnorm: 18.756248474121094
      vf_explained_var: 0.0010308027267456055
      vf_loss: 7.217872619628906
    num_steps_sampled: 9000
    num_steps_trained: 9000
    wait_time_ms: 36.271
  iterations_since_restore: 5
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 10879
  policy_reward_mean: {}
  time_since_restore: 54.27499556541443
  time_this_iter_s: 9.38473629951477
  time_total_s: 54.27499556541443
  timestamp: 1594145543
  timesteps_since_restore: 9000
  timesteps_this_iter: 2000
  timesteps_total: 9000
  training_iteration: 5
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 12.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10879], 54 s, 5 iter, 9000 ts, 131 rew

agent-1: 167.0
Sum Reward: 167.0
Avg Reward: 167.0
Min Reward: 167.0
Max Reward: 167.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
agent-1: 263.0
Sum Reward: 263.0
Avg Reward: 263.0
Min Reward: 263.0
Max Reward: 263.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_14-12-32
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 263.0
  episode_reward_mean: 148.1
  episode_reward_min: 54.0
  episodes_this_iter: 2
  episodes_total: 10
  experiment_id: cb3a18e0a26e466496590bc0542b68c4
  hostname: gpu020
  info:
    apply_time_ms: 2.833
    dispatch_time_ms: 10.572
    learner:
      cur_lr: 0.0013594005722552538
      grad_gnorm: 12.659880638122559
      policy_entropy: 12.972179412841797
      policy_loss: 4.956438064575195
      var_gnorm: 18.95543098449707
      vf_explained_var: -3.0994415283203125e-06
      vf_loss: 2.9439809322357178
    num_steps_sampled: 11000
    num_steps_trained: 11000
    wait_time_ms: 35.313
  iterations_since_restore: 6
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 10879
  policy_reward_mean: {}
  time_since_restore: 63.67442274093628
  time_this_iter_s: 9.39942717552185
  time_total_s: 63.67442274093628
  timestamp: 1594145552
  timesteps_since_restore: 11000
  timesteps_this_iter: 2000
  timesteps_total: 11000
  training_iteration: 6
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 13.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10879], 63 s, 6 iter, 11000 ts, 148 rew

agent-1: 191.0
Sum Reward: 191.0
Avg Reward: 191.0
Min Reward: 191.0
Max Reward: 191.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
agent-1: 181.0
Sum Reward: 181.0
Avg Reward: 181.0
Min Reward: 181.0
Max Reward: 181.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_14-12-42
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 263.0
  episode_reward_mean: 154.41666666666666
  episode_reward_min: 54.0
  episodes_this_iter: 2
  episodes_total: 12
  experiment_id: cb3a18e0a26e466496590bc0542b68c4
  hostname: gpu020
  info:
    apply_time_ms: 2.625
    dispatch_time_ms: 8.549
    learner:
      cur_lr: 0.0013592673931270838
      grad_gnorm: 40.000003814697266
      policy_entropy: 11.030717849731445
      policy_loss: 11.499174118041992
      var_gnorm: 19.08340072631836
      vf_explained_var: 0.0
      vf_loss: 14.190298080444336
    num_steps_sampled: 13000
    num_steps_trained: 13000
    wait_time_ms: 35.356
  iterations_since_restore: 7
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 10879
  policy_reward_mean: {}
  time_since_restore: 73.19284415245056
  time_this_iter_s: 9.518421411514282
  time_total_s: 73.19284415245056
  timestamp: 1594145562
  timesteps_since_restore: 13000
  timesteps_this_iter: 2000
  timesteps_total: 13000
  training_iteration: 7
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 13.3/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10879], 73 s, 7 iter, 13000 ts, 154 rew

agent-1: 169.0
Sum Reward: 169.0
Avg Reward: 169.0
Min Reward: 169.0
Max Reward: 169.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
agent-1: 202.0
Sum Reward: 202.0
Avg Reward: 202.0
Min Reward: 202.0
Max Reward: 202.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_14-12-51
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 263.0
  episode_reward_mean: 158.85714285714286
  episode_reward_min: 54.0
  episodes_this_iter: 2
  episodes_total: 14
  experiment_id: cb3a18e0a26e466496590bc0542b68c4
  hostname: gpu020
  info:
    apply_time_ms: 3.343
    dispatch_time_ms: 7.756
    learner:
      cur_lr: 0.0013591342139989138
      grad_gnorm: 21.306583404541016
      policy_entropy: 4.039646148681641
      policy_loss: -0.6518113613128662
      var_gnorm: 19.101669311523438
      vf_explained_var: 0.0
      vf_loss: 3.2834811210632324
    num_steps_sampled: 15000
    num_steps_trained: 15000
    wait_time_ms: 38.377
  iterations_since_restore: 8
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 10879
  policy_reward_mean: {}
  time_since_restore: 82.37226891517639
  time_this_iter_s: 9.17942476272583
  time_total_s: 82.37226891517639
  timestamp: 1594145571
  timesteps_since_restore: 15000
  timesteps_this_iter: 2000
  timesteps_total: 15000
  training_iteration: 8
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 13.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10879], 82 s, 8 iter, 15000 ts, 159 rew

agent-1: 126.0
Sum Reward: 126.0
Avg Reward: 126.0
Min Reward: 126.0
Max Reward: 126.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
agent-1: 112.0
Sum Reward: 112.0
Avg Reward: 112.0
Min Reward: 112.0
Max Reward: 112.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_14-13-00
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 263.0
  episode_reward_mean: 153.875
  episode_reward_min: 54.0
  episodes_this_iter: 2
  episodes_total: 16
  experiment_id: cb3a18e0a26e466496590bc0542b68c4
  hostname: gpu020
  info:
    apply_time_ms: 3.077
    dispatch_time_ms: 9.658
    learner:
      cur_lr: 0.0013590010348707438
      grad_gnorm: 37.694889068603516
      policy_entropy: 4.030763626098633
      policy_loss: 6.56095552444458
      var_gnorm: 19.187353134155273
      vf_explained_var: 0.0
      vf_loss: 10.018942832946777
    num_steps_sampled: 17000
    num_steps_trained: 17000
    wait_time_ms: 33.909
  iterations_since_restore: 9
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 10879
  policy_reward_mean: {}
  time_since_restore: 91.35640954971313
  time_this_iter_s: 8.984140634536743
  time_total_s: 91.35640954971313
  timestamp: 1594145580
  timesteps_since_restore: 17000
  timesteps_this_iter: 2000
  timesteps_total: 17000
  training_iteration: 9
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 13.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10879], 91 s, 9 iter, 17000 ts, 154 rew

agent-1: 174.0
Sum Reward: 174.0
Avg Reward: 174.0
Min Reward: 174.0
Max Reward: 174.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
agent-1: 124.0
Sum Reward: 124.0
Avg Reward: 124.0
Min Reward: 124.0
Max Reward: 124.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_14-13-09
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 263.0
  episode_reward_mean: 153.33333333333334
  episode_reward_min: 54.0
  episodes_this_iter: 2
  episodes_total: 18
  experiment_id: cb3a18e0a26e466496590bc0542b68c4
  hostname: gpu020
  info:
    apply_time_ms: 3.174
    dispatch_time_ms: 8.53
    learner:
      cur_lr: 0.0013588678557425737
      grad_gnorm: 40.000022888183594
      policy_entropy: 7.048942565917969
      policy_loss: 0.3062129616737366
      var_gnorm: 19.585681915283203
      vf_explained_var: -0.9057241678237915
      vf_loss: 1.0042332410812378
    num_steps_sampled: 19000
    num_steps_trained: 19000
    wait_time_ms: 34.116
  iterations_since_restore: 10
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 10879
  policy_reward_mean: {}
  time_since_restore: 100.34802269935608
  time_this_iter_s: 8.991613149642944
  time_total_s: 100.34802269935608
  timestamp: 1594145589
  timesteps_since_restore: 19000
  timesteps_this_iter: 2000
  timesteps_total: 19000
  training_iteration: 10
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 14.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10879], 100 s, 10 iter, 19000 ts, 153 rew

agent-1: 121.0
Sum Reward: 121.0
Avg Reward: 121.0
Min Reward: 121.0
Max Reward: 121.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
agent-1: 142.0
Sum Reward: 142.0
Avg Reward: 142.0
Min Reward: 142.0
Max Reward: 142.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_14-13-19
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 263.0
  episode_reward_mean: 151.15
  episode_reward_min: 54.0
  episodes_this_iter: 2
  episodes_total: 20
  experiment_id: cb3a18e0a26e466496590bc0542b68c4
  hostname: gpu020
  info:
    apply_time_ms: 3.076
    dispatch_time_ms: 7.913
    learner:
      cur_lr: 0.001358734560199082
      grad_gnorm: 37.784568786621094
      policy_entropy: 4.655867576599121
      policy_loss: 11.497462272644043
      var_gnorm: 19.972856521606445
      vf_explained_var: 0.2574881315231323
      vf_loss: 8.750724792480469
    num_steps_sampled: 21000
    num_steps_trained: 21000
    wait_time_ms: 36.388
  iterations_since_restore: 11
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 10879
  policy_reward_mean: {}
  time_since_restore: 109.6407880783081
  time_this_iter_s: 9.292765378952026
  time_total_s: 109.6407880783081
  timestamp: 1594145599
  timesteps_since_restore: 21000
  timesteps_this_iter: 2000
  timesteps_total: 21000
  training_iteration: 11
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 14.3/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10879], 109 s, 11 iter, 21000 ts, 151 rew

agent-1: 163.0
Sum Reward: 163.0
Avg Reward: 163.0
Min Reward: 163.0
Max Reward: 163.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
agent-1: 269.0
Sum Reward: 269.0
Avg Reward: 269.0
Min Reward: 269.0
Max Reward: 269.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_14-13-28
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 269.0
  episode_reward_mean: 157.04545454545453
  episode_reward_min: 54.0
  episodes_this_iter: 2
  episodes_total: 22
  experiment_id: cb3a18e0a26e466496590bc0542b68c4
  hostname: gpu020
  info:
    apply_time_ms: 2.929
    dispatch_time_ms: 8.373
    learner:
      cur_lr: 0.0013586013810709119
      grad_gnorm: 28.7268123626709
      policy_entropy: 10.5621337890625
      policy_loss: -7.335245132446289
      var_gnorm: 20.209617614746094
      vf_explained_var: -1.0
      vf_loss: 6.312960624694824
    num_steps_sampled: 23000
    num_steps_trained: 23000
    wait_time_ms: 34.414
  iterations_since_restore: 12
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 10879
  policy_reward_mean: {}
  time_since_restore: 118.97589373588562
  time_this_iter_s: 9.335105657577515
  time_total_s: 118.97589373588562
  timestamp: 1594145608
  timesteps_since_restore: 23000
  timesteps_this_iter: 2000
  timesteps_total: 23000
  training_iteration: 12
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 14.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10879], 118 s, 12 iter, 23000 ts, 157 rew

agent-1: 197.0
Sum Reward: 197.0
Avg Reward: 197.0
Min Reward: 197.0
Max Reward: 197.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
agent-1: 158.0
Sum Reward: 158.0
Avg Reward: 158.0
Min Reward: 158.0
Max Reward: 158.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_14-13-37
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 269.0
  episode_reward_mean: 158.75
  episode_reward_min: 54.0
  episodes_this_iter: 2
  episodes_total: 24
  experiment_id: cb3a18e0a26e466496590bc0542b68c4
  hostname: gpu020
  info:
    apply_time_ms: 3.469
    dispatch_time_ms: 6.67
    learner:
      cur_lr: 0.0013584682019427419
      grad_gnorm: 40.0
      policy_entropy: 8.835533142089844
      policy_loss: 7.797462463378906
      var_gnorm: 20.366212844848633
      vf_explained_var: 0.0
      vf_loss: 8.706995010375977
    num_steps_sampled: 25000
    num_steps_trained: 25000
    wait_time_ms: 39.923
  iterations_since_restore: 13
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 10879
  policy_reward_mean: {}
  time_since_restore: 128.43998527526855
  time_this_iter_s: 9.464091539382935
  time_total_s: 128.43998527526855
  timestamp: 1594145617
  timesteps_since_restore: 25000
  timesteps_this_iter: 2000
  timesteps_total: 25000
  training_iteration: 13
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 14.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10879], 128 s, 13 iter, 25000 ts, 159 rew

agent-1: 251.0
Sum Reward: 251.0
Avg Reward: 251.0
Min Reward: 251.0
Max Reward: 251.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
agent-1: 252.0
Sum Reward: 252.0
Avg Reward: 252.0
Min Reward: 252.0
Max Reward: 252.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_14-13-47
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 269.0
  episode_reward_mean: 165.8846153846154
  episode_reward_min: 54.0
  episodes_this_iter: 2
  episodes_total: 26
  experiment_id: cb3a18e0a26e466496590bc0542b68c4
  hostname: gpu020
  info:
    apply_time_ms: 3.343
    dispatch_time_ms: 7.655
    learner:
      cur_lr: 0.0013583350228145719
      grad_gnorm: 40.0
      policy_entropy: 8.839436531066895
      policy_loss: 15.896862030029297
      var_gnorm: 20.701269149780273
      vf_explained_var: -0.008901357650756836
      vf_loss: 18.962387084960938
    num_steps_sampled: 27000
    num_steps_trained: 27000
    wait_time_ms: 35.893
  iterations_since_restore: 14
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 10879
  policy_reward_mean: {}
  time_since_restore: 137.79930186271667
  time_this_iter_s: 9.35931658744812
  time_total_s: 137.79930186271667
  timestamp: 1594145627
  timesteps_since_restore: 27000
  timesteps_this_iter: 2000
  timesteps_total: 27000
  training_iteration: 14
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 15.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10879], 137 s, 14 iter, 27000 ts, 166 rew

agent-1: 319.0
Sum Reward: 319.0
Avg Reward: 319.0
Min Reward: 319.0
Max Reward: 319.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
agent-1: 260.0
Sum Reward: 260.0
Avg Reward: 260.0
Min Reward: 260.0
Max Reward: 260.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_14-13-56
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 319.0
  episode_reward_mean: 174.71428571428572
  episode_reward_min: 54.0
  episodes_this_iter: 2
  episodes_total: 28
  experiment_id: cb3a18e0a26e466496590bc0542b68c4
  hostname: gpu020
  info:
    apply_time_ms: 2.504
    dispatch_time_ms: 7.372
    learner:
      cur_lr: 0.0013582018436864018
      grad_gnorm: 40.000003814697266
      policy_entropy: 7.685629367828369
      policy_loss: 8.595666885375977
      var_gnorm: 20.90467071533203
      vf_explained_var: 0.0
      vf_loss: 22.956880569458008
    num_steps_sampled: 29000
    num_steps_trained: 29000
    wait_time_ms: 39.84
  iterations_since_restore: 15
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 10879
  policy_reward_mean: {}
  time_since_restore: 147.223286151886
  time_this_iter_s: 9.423984289169312
  time_total_s: 147.223286151886
  timestamp: 1594145636
  timesteps_since_restore: 29000
  timesteps_this_iter: 2000
  timesteps_total: 29000
  training_iteration: 15
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 15.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10879], 147 s, 15 iter, 29000 ts, 175 rew

agent-1: 295.0
Sum Reward: 295.0
Avg Reward: 295.0
Min Reward: 295.0
Max Reward: 295.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
agent-1: 265.0
Sum Reward: 265.0
Avg Reward: 265.0
Min Reward: 265.0
Max Reward: 265.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_14-14-06
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 319.0
  episode_reward_mean: 181.73333333333332
  episode_reward_min: 54.0
  episodes_this_iter: 2
  episodes_total: 30
  experiment_id: cb3a18e0a26e466496590bc0542b68c4
  hostname: gpu020
  info:
    apply_time_ms: 3.854
    dispatch_time_ms: 8.435
    learner:
      cur_lr: 0.00135806854814291
      grad_gnorm: 40.000003814697266
      policy_entropy: 8.194515228271484
      policy_loss: 17.96802520751953
      var_gnorm: 21.062244415283203
      vf_explained_var: -1.0
      vf_loss: 27.937551498413086
    num_steps_sampled: 31000
    num_steps_trained: 31000
    wait_time_ms: 35.439
  iterations_since_restore: 16
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 10879
  policy_reward_mean: {}
  time_since_restore: 156.79269766807556
  time_this_iter_s: 9.569411516189575
  time_total_s: 156.79269766807556
  timestamp: 1594145646
  timesteps_since_restore: 31000
  timesteps_this_iter: 2000
  timesteps_total: 31000
  training_iteration: 16
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 15.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10879], 156 s, 16 iter, 31000 ts, 182 rew

agent-1: 294.0
Sum Reward: 294.0
Avg Reward: 294.0
Min Reward: 294.0
Max Reward: 294.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
agent-1: 286.0
Sum Reward: 286.0
Avg Reward: 286.0
Min Reward: 286.0
Max Reward: 286.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_14-14-15
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 319.0
  episode_reward_mean: 188.5
  episode_reward_min: 54.0
  episodes_this_iter: 2
  episodes_total: 32
  experiment_id: cb3a18e0a26e466496590bc0542b68c4
  hostname: gpu020
  info:
    apply_time_ms: 2.6
    dispatch_time_ms: 6.755
    learner:
      cur_lr: 0.00135793536901474
      grad_gnorm: 40.000003814697266
      policy_entropy: 8.182218551635742
      policy_loss: 8.245695114135742
      var_gnorm: 21.3100643157959
      vf_explained_var: 0.0
      vf_loss: 9.322754859924316
    num_steps_sampled: 33000
    num_steps_trained: 33000
    wait_time_ms: 39.677
  iterations_since_restore: 17
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 10879
  policy_reward_mean: {}
  time_since_restore: 166.23536324501038
  time_this_iter_s: 9.442665576934814
  time_total_s: 166.23536324501038
  timestamp: 1594145655
  timesteps_since_restore: 33000
  timesteps_this_iter: 2000
  timesteps_total: 33000
  training_iteration: 17
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 15.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10879], 166 s, 17 iter, 33000 ts, 188 rew

agent-1: 310.0
Sum Reward: 310.0
Avg Reward: 310.0
Min Reward: 310.0
Max Reward: 310.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
agent-1: 329.0
Sum Reward: 329.0
Avg Reward: 329.0
Min Reward: 329.0
Max Reward: 329.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_14-14-25
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 329.0
  episode_reward_mean: 196.2058823529412
  episode_reward_min: 54.0
  episodes_this_iter: 2
  episodes_total: 34
  experiment_id: cb3a18e0a26e466496590bc0542b68c4
  hostname: gpu020
  info:
    apply_time_ms: 3.42
    dispatch_time_ms: 7.838
    learner:
      cur_lr: 0.00135780218988657
      grad_gnorm: 17.805906295776367
      policy_entropy: 8.925063133239746
      policy_loss: 3.9555108547210693
      var_gnorm: 21.503278732299805
      vf_explained_var: 0.0
      vf_loss: 2.1946845054626465
    num_steps_sampled: 35000
    num_steps_trained: 35000
    wait_time_ms: 38.201
  iterations_since_restore: 18
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 10879
  policy_reward_mean: {}
  time_since_restore: 175.89524173736572
  time_this_iter_s: 9.659878492355347
  time_total_s: 175.89524173736572
  timestamp: 1594145665
  timesteps_since_restore: 35000
  timesteps_this_iter: 2000
  timesteps_total: 35000
  training_iteration: 18
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 15.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10879], 175 s, 18 iter, 35000 ts, 196 rew

agent-1: 304.0
Sum Reward: 304.0
Avg Reward: 304.0
Min Reward: 304.0
Max Reward: 304.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
agent-1: 324.0
Sum Reward: 324.0
Avg Reward: 324.0
Min Reward: 324.0
Max Reward: 324.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_14-14-35
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 329.0
  episode_reward_mean: 202.75
  episode_reward_min: 54.0
  episodes_this_iter: 2
  episodes_total: 36
  experiment_id: cb3a18e0a26e466496590bc0542b68c4
  hostname: gpu020
  info:
    apply_time_ms: 3.788
    dispatch_time_ms: 8.082
    learner:
      cur_lr: 0.0013576690107584
      grad_gnorm: 40.00000762939453
      policy_entropy: 6.839643478393555
      policy_loss: 3.7364554405212402
      var_gnorm: 21.709609985351562
      vf_explained_var: -1.0
      vf_loss: 6.61175012588501
    num_steps_sampled: 37000
    num_steps_trained: 37000
    wait_time_ms: 34.445
  iterations_since_restore: 19
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 10879
  policy_reward_mean: {}
  time_since_restore: 185.50533628463745
  time_this_iter_s: 9.610094547271729
  time_total_s: 185.50533628463745
  timestamp: 1594145675
  timesteps_since_restore: 37000
  timesteps_this_iter: 2000
  timesteps_total: 37000
  training_iteration: 19
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 16.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10879], 185 s, 19 iter, 37000 ts, 203 rew

agent-1: 302.0
Sum Reward: 302.0
Avg Reward: 302.0
Min Reward: 302.0
Max Reward: 302.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
agent-1: 298.0
Sum Reward: 298.0
Avg Reward: 298.0
Min Reward: 298.0
Max Reward: 298.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_14-14-44
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 329.0
  episode_reward_mean: 207.8684210526316
  episode_reward_min: 54.0
  episodes_this_iter: 2
  episodes_total: 38
  experiment_id: cb3a18e0a26e466496590bc0542b68c4
  hostname: gpu020
  info:
    apply_time_ms: 3.349
    dispatch_time_ms: 7.936
    learner:
      cur_lr: 0.00135753583163023
      grad_gnorm: 40.0
      policy_entropy: 5.411979675292969
      policy_loss: 6.562711715698242
      var_gnorm: 21.764368057250977
      vf_explained_var: -0.2536203861236572
      vf_loss: 14.302618026733398
    num_steps_sampled: 39000
    num_steps_trained: 39000
    wait_time_ms: 35.869
  iterations_since_restore: 20
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 10879
  policy_reward_mean: {}
  time_since_restore: 194.9442400932312
  time_this_iter_s: 9.43890380859375
  time_total_s: 194.9442400932312
  timestamp: 1594145684
  timesteps_since_restore: 39000
  timesteps_this_iter: 2000
  timesteps_total: 39000
  training_iteration: 20
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 16.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10879], 194 s, 20 iter, 39000 ts, 208 rew

agent-1: 275.0
Sum Reward: 275.0
Avg Reward: 275.0
Min Reward: 275.0
Max Reward: 275.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
agent-1: 329.0
Sum Reward: 329.0
Avg Reward: 329.0
Min Reward: 329.0
Max Reward: 329.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_14-14-54
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 329.0
  episode_reward_mean: 212.575
  episode_reward_min: 54.0
  episodes_this_iter: 2
  episodes_total: 40
  experiment_id: cb3a18e0a26e466496590bc0542b68c4
  hostname: gpu020
  info:
    apply_time_ms: 3.195
    dispatch_time_ms: 7.386
    learner:
      cur_lr: 0.00135740265250206
      grad_gnorm: 27.976274490356445
      policy_entropy: 5.589522838592529
      policy_loss: -4.877488613128662
      var_gnorm: 21.966400146484375
      vf_explained_var: 0.03476560115814209
      vf_loss: 4.746999263763428
    num_steps_sampled: 41000
    num_steps_trained: 41000
    wait_time_ms: 35.212
  iterations_since_restore: 21
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 10879
  policy_reward_mean: {}
  time_since_restore: 204.651508808136
  time_this_iter_s: 9.707268714904785
  time_total_s: 204.651508808136
  timestamp: 1594145694
  timesteps_since_restore: 41000
  timesteps_this_iter: 2000
  timesteps_total: 41000
  training_iteration: 21
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 16.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10879], 204 s, 21 iter, 41000 ts, 213 rew

agent-1: 306.0
Sum Reward: 306.0
Avg Reward: 306.0
Min Reward: 306.0
Max Reward: 306.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
agent-1: 361.0
Sum Reward: 361.0
Avg Reward: 361.0
Min Reward: 361.0
Max Reward: 361.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_14-15-03
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 361.0
  episode_reward_mean: 218.33333333333334
  episode_reward_min: 54.0
  episodes_this_iter: 2
  episodes_total: 42
  experiment_id: cb3a18e0a26e466496590bc0542b68c4
  hostname: gpu020
  info:
    apply_time_ms: 2.665
    dispatch_time_ms: 9.81
    learner:
      cur_lr: 0.001357269356958568
      grad_gnorm: 16.059917449951172
      policy_entropy: 3.445143461227417
      policy_loss: -0.07310009002685547
      var_gnorm: 22.15736961364746
      vf_explained_var: -1.0
      vf_loss: 3.598283290863037
    num_steps_sampled: 43000
    num_steps_trained: 43000
    wait_time_ms: 38.998
  iterations_since_restore: 22
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 10879
  policy_reward_mean: {}
  time_since_restore: 214.21112251281738
  time_this_iter_s: 9.559613704681396
  time_total_s: 214.21112251281738
  timestamp: 1594145703
  timesteps_since_restore: 43000
  timesteps_this_iter: 2000
  timesteps_total: 43000
  training_iteration: 22
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 16.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10879], 214 s, 22 iter, 43000 ts, 218 rew

agent-1: 311.0
Sum Reward: 311.0
Avg Reward: 311.0
Min Reward: 311.0
Max Reward: 311.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
agent-1: 337.0
Sum Reward: 337.0
Avg Reward: 337.0
Min Reward: 337.0
Max Reward: 337.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_14-15-13
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 361.0
  episode_reward_mean: 223.13636363636363
  episode_reward_min: 54.0
  episodes_this_iter: 2
  episodes_total: 44
  experiment_id: cb3a18e0a26e466496590bc0542b68c4
  hostname: gpu020
  info:
    apply_time_ms: 2.985
    dispatch_time_ms: 9.55
    learner:
      cur_lr: 0.001357136177830398
      grad_gnorm: 38.08833694458008
      policy_entropy: 1.6883426904678345
      policy_loss: 0.4223116338253021
      var_gnorm: 22.30475616455078
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 10.1436767578125
    num_steps_sampled: 45000
    num_steps_trained: 45000
    wait_time_ms: 35.615
  iterations_since_restore: 23
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 10879
  policy_reward_mean: {}
  time_since_restore: 223.69762635231018
  time_this_iter_s: 9.486503839492798
  time_total_s: 223.69762635231018
  timestamp: 1594145713
  timesteps_since_restore: 45000
  timesteps_this_iter: 2000
  timesteps_total: 45000
  training_iteration: 23
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 17.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10879], 223 s, 23 iter, 45000 ts, 223 rew

agent-1: 358.0
Sum Reward: 358.0
Avg Reward: 358.0
Min Reward: 358.0
Max Reward: 358.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
agent-1: 388.0
Sum Reward: 388.0
Avg Reward: 388.0
Min Reward: 388.0
Max Reward: 388.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_14-15-22
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 388.0
  episode_reward_mean: 229.65217391304347
  episode_reward_min: 54.0
  episodes_this_iter: 2
  episodes_total: 46
  experiment_id: cb3a18e0a26e466496590bc0542b68c4
  hostname: gpu020
  info:
    apply_time_ms: 2.497
    dispatch_time_ms: 7.091
    learner:
      cur_lr: 0.001357002998702228
      grad_gnorm: 39.99999237060547
      policy_entropy: 1.5178037881851196
      policy_loss: 0.15347285568714142
      var_gnorm: 22.478958129882812
      vf_explained_var: -1.0
      vf_loss: 3.3934457302093506
    num_steps_sampled: 47000
    num_steps_trained: 47000
    wait_time_ms: 37.711
  iterations_since_restore: 24
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 10879
  policy_reward_mean: {}
  time_since_restore: 233.18700695037842
  time_this_iter_s: 9.489380598068237
  time_total_s: 233.18700695037842
  timestamp: 1594145722
  timesteps_since_restore: 47000
  timesteps_this_iter: 2000
  timesteps_total: 47000
  training_iteration: 24
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 17.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10879], 233 s, 24 iter, 47000 ts, 230 rew

agent-1: 356.0
Sum Reward: 356.0
Avg Reward: 356.0
Min Reward: 356.0
Max Reward: 356.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
agent-1: 290.0
Sum Reward: 290.0
Avg Reward: 290.0
Min Reward: 290.0
Max Reward: 290.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_14-15-32
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 388.0
  episode_reward_mean: 233.54166666666666
  episode_reward_min: 54.0
  episodes_this_iter: 2
  episodes_total: 48
  experiment_id: cb3a18e0a26e466496590bc0542b68c4
  hostname: gpu020
  info:
    apply_time_ms: 2.824
    dispatch_time_ms: 6.555
    learner:
      cur_lr: 0.001356869819574058
      grad_gnorm: 39.999996185302734
      policy_entropy: 4.004910469055176
      policy_loss: -2.4141275882720947
      var_gnorm: 22.494009017944336
      vf_explained_var: 0.11178231239318848
      vf_loss: 15.127145767211914
    num_steps_sampled: 49000
    num_steps_trained: 49000
    wait_time_ms: 35.118
  iterations_since_restore: 25
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 10879
  policy_reward_mean: {}
  time_since_restore: 242.4966220855713
  time_this_iter_s: 9.309615135192871
  time_total_s: 242.4966220855713
  timestamp: 1594145732
  timesteps_since_restore: 49000
  timesteps_this_iter: 2000
  timesteps_total: 49000
  training_iteration: 25
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 17.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10879], 242 s, 25 iter, 49000 ts, 234 rew

agent-1: 231.0
Sum Reward: 231.0
Avg Reward: 231.0
Min Reward: 231.0
Max Reward: 231.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
agent-1: 234.0
Sum Reward: 234.0
Avg Reward: 234.0
Min Reward: 234.0
Max Reward: 234.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_14-15-41
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 388.0
  episode_reward_mean: 233.5
  episode_reward_min: 54.0
  episodes_this_iter: 2
  episodes_total: 50
  experiment_id: cb3a18e0a26e466496590bc0542b68c4
  hostname: gpu020
  info:
    apply_time_ms: 3.844
    dispatch_time_ms: 9.652
    learner:
      cur_lr: 0.001356736640445888
      grad_gnorm: 1.7003833055496216
      policy_entropy: 2.0805368423461914
      policy_loss: -0.8675568103790283
      var_gnorm: 22.499393463134766
      vf_explained_var: 0.0
      vf_loss: 0.566175103187561
    num_steps_sampled: 51000
    num_steps_trained: 51000
    wait_time_ms: 32.123
  iterations_since_restore: 26
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 10879
  policy_reward_mean: {}
  time_since_restore: 251.98732137680054
  time_this_iter_s: 9.490699291229248
  time_total_s: 251.98732137680054
  timestamp: 1594145741
  timesteps_since_restore: 51000
  timesteps_this_iter: 2000
  timesteps_total: 51000
  training_iteration: 26
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 17.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10879], 251 s, 26 iter, 51000 ts, 234 rew

agent-1: 225.0
Sum Reward: 225.0
Avg Reward: 225.0
Min Reward: 225.0
Max Reward: 225.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
agent-1: 263.0
Sum Reward: 263.0
Avg Reward: 263.0
Min Reward: 263.0
Max Reward: 263.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_14-15-51
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 388.0
  episode_reward_mean: 233.90384615384616
  episode_reward_min: 54.0
  episodes_this_iter: 2
  episodes_total: 52
  experiment_id: cb3a18e0a26e466496590bc0542b68c4
  hostname: gpu020
  info:
    apply_time_ms: 2.344
    dispatch_time_ms: 6.88
    learner:
      cur_lr: 0.0013566033449023962
      grad_gnorm: 2.0152971744537354
      policy_entropy: 1.947662115097046
      policy_loss: -0.026048246771097183
      var_gnorm: 22.58452033996582
      vf_explained_var: -1.0
      vf_loss: 1.8725006580352783
    num_steps_sampled: 53000
    num_steps_trained: 53000
    wait_time_ms: 37.615
  iterations_since_restore: 27
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 10879
  policy_reward_mean: {}
  time_since_restore: 261.2608006000519
  time_this_iter_s: 9.273479223251343
  time_total_s: 261.2608006000519
  timestamp: 1594145751
  timesteps_since_restore: 53000
  timesteps_this_iter: 2000
  timesteps_total: 53000
  training_iteration: 27
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 18.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10879], 261 s, 27 iter, 53000 ts, 234 rew

agent-1: 306.0
Sum Reward: 306.0
Avg Reward: 306.0
Min Reward: 306.0
Max Reward: 306.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
agent-1: 350.0
Sum Reward: 350.0
Avg Reward: 350.0
Min Reward: 350.0
Max Reward: 350.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_14-16-00
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 388.0
  episode_reward_mean: 237.38888888888889
  episode_reward_min: 54.0
  episodes_this_iter: 2
  episodes_total: 54
  experiment_id: cb3a18e0a26e466496590bc0542b68c4
  hostname: gpu020
  info:
    apply_time_ms: 2.54
    dispatch_time_ms: 6.131
    learner:
      cur_lr: 0.0013564701657742262
      grad_gnorm: 40.0
      policy_entropy: 0.4579029083251953
      policy_loss: -0.09563980996608734
      var_gnorm: 22.78769874572754
      vf_explained_var: 1.1920928955078125e-07
      vf_loss: 11.008514404296875
    num_steps_sampled: 55000
    num_steps_trained: 55000
    wait_time_ms: 41.128
  iterations_since_restore: 28
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 10879
  policy_reward_mean: {}
  time_since_restore: 270.7465934753418
  time_this_iter_s: 9.485792875289917
  time_total_s: 270.7465934753418
  timestamp: 1594145760
  timesteps_since_restore: 55000
  timesteps_this_iter: 2000
  timesteps_total: 55000
  training_iteration: 28
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 18.3/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10879], 270 s, 28 iter, 55000 ts, 237 rew

agent-1: 349.0
Sum Reward: 349.0
Avg Reward: 349.0
Min Reward: 349.0
Max Reward: 349.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
agent-1: 336.0
Sum Reward: 336.0
Avg Reward: 336.0
Min Reward: 336.0
Max Reward: 336.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_14-16-09
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 388.0
  episode_reward_mean: 241.14285714285714
  episode_reward_min: 54.0
  episodes_this_iter: 2
  episodes_total: 56
  experiment_id: cb3a18e0a26e466496590bc0542b68c4
  hostname: gpu020
  info:
    apply_time_ms: 2.453
    dispatch_time_ms: 7.317
    learner:
      cur_lr: 0.0013563369866460562
      grad_gnorm: 40.0
      policy_entropy: 2.5401101112365723
      policy_loss: -17.478059768676758
      var_gnorm: 22.916332244873047
      vf_explained_var: -1.0
      vf_loss: 21.427305221557617
    num_steps_sampled: 57000
    num_steps_trained: 57000
    wait_time_ms: 36.557
  iterations_since_restore: 29
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 10879
  policy_reward_mean: {}
  time_since_restore: 279.9947431087494
  time_this_iter_s: 9.248149633407593
  time_total_s: 279.9947431087494
  timestamp: 1594145769
  timesteps_since_restore: 57000
  timesteps_this_iter: 2000
  timesteps_total: 57000
  training_iteration: 29
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 18.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10879], 279 s, 29 iter, 57000 ts, 241 rew

agent-1: 291.0
Sum Reward: 291.0
Avg Reward: 291.0
Min Reward: 291.0
Max Reward: 291.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
agent-1: 337.0
Sum Reward: 337.0
Avg Reward: 337.0
Min Reward: 337.0
Max Reward: 337.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_14-16-19
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 388.0
  episode_reward_mean: 243.6551724137931
  episode_reward_min: 54.0
  episodes_this_iter: 2
  episodes_total: 58
  experiment_id: cb3a18e0a26e466496590bc0542b68c4
  hostname: gpu020
  info:
    apply_time_ms: 3.092
    dispatch_time_ms: 8.185
    learner:
      cur_lr: 0.0013562038075178862
      grad_gnorm: 40.0
      policy_entropy: 1.31539785861969
      policy_loss: -0.47563084959983826
      var_gnorm: 22.995868682861328
      vf_explained_var: 1.0132789611816406e-06
      vf_loss: 19.321136474609375
    num_steps_sampled: 59000
    num_steps_trained: 59000
    wait_time_ms: 35.862
  iterations_since_restore: 30
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 10879
  policy_reward_mean: {}
  time_since_restore: 289.31681275367737
  time_this_iter_s: 9.322069644927979
  time_total_s: 289.31681275367737
  timestamp: 1594145779
  timesteps_since_restore: 59000
  timesteps_this_iter: 2000
  timesteps_total: 59000
  training_iteration: 30
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 18.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10879], 289 s, 30 iter, 59000 ts, 244 rew

agent-1: 319.0
Sum Reward: 319.0
Avg Reward: 319.0
Min Reward: 319.0
Max Reward: 319.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
agent-1: 360.0
Sum Reward: 360.0
Avg Reward: 360.0
Min Reward: 360.0
Max Reward: 360.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_14-16-28
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 388.0
  episode_reward_mean: 246.85
  episode_reward_min: 54.0
  episodes_this_iter: 2
  episodes_total: 60
  experiment_id: cb3a18e0a26e466496590bc0542b68c4
  hostname: gpu020
  info:
    apply_time_ms: 2.381
    dispatch_time_ms: 7.738
    learner:
      cur_lr: 0.0013560706283897161
      grad_gnorm: 6.464754104614258
      policy_entropy: 0.7770113348960876
      policy_loss: 0.029990404844284058
      var_gnorm: 23.167678833007812
      vf_explained_var: -5.364418029785156e-06
      vf_loss: 1.1692142486572266
    num_steps_sampled: 61000
    num_steps_trained: 61000
    wait_time_ms: 35.666
  iterations_since_restore: 31
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 10879
  policy_reward_mean: {}
  time_since_restore: 298.6132252216339
  time_this_iter_s: 9.296412467956543
  time_total_s: 298.6132252216339
  timestamp: 1594145788
  timesteps_since_restore: 61000
  timesteps_this_iter: 2000
  timesteps_total: 61000
  training_iteration: 31
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 19.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10879], 298 s, 31 iter, 61000 ts, 247 rew

agent-1: 357.0
Sum Reward: 357.0
Avg Reward: 357.0
Min Reward: 357.0
Max Reward: 357.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
agent-1: 363.0
Sum Reward: 363.0
Avg Reward: 363.0
Min Reward: 363.0
Max Reward: 363.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_14-16-38
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 388.0
  episode_reward_mean: 250.5
  episode_reward_min: 54.0
  episodes_this_iter: 2
  episodes_total: 62
  experiment_id: cb3a18e0a26e466496590bc0542b68c4
  hostname: gpu020
  info:
    apply_time_ms: 3.73
    dispatch_time_ms: 7.714
    learner:
      cur_lr: 0.0013559374492615461
      grad_gnorm: 30.491090774536133
      policy_entropy: 0.4672473967075348
      policy_loss: 0.07437512278556824
      var_gnorm: 23.30031394958496
      vf_explained_var: 0.0
      vf_loss: 8.222489356994629
    num_steps_sampled: 63000
    num_steps_trained: 63000
    wait_time_ms: 37.798
  iterations_since_restore: 32
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 10879
  policy_reward_mean: {}
  time_since_restore: 308.01449728012085
  time_this_iter_s: 9.401272058486938
  time_total_s: 308.01449728012085
  timestamp: 1594145798
  timesteps_since_restore: 63000
  timesteps_this_iter: 2000
  timesteps_total: 63000
  training_iteration: 32
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 19.3/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10879], 308 s, 32 iter, 63000 ts, 250 rew

agent-1: 376.0
Sum Reward: 376.0
Avg Reward: 376.0
Min Reward: 376.0
Max Reward: 376.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
agent-1: 379.0
Sum Reward: 379.0
Avg Reward: 379.0
Min Reward: 379.0
Max Reward: 379.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_14-16-47
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 388.0
  episode_reward_mean: 254.46875
  episode_reward_min: 54.0
  episodes_this_iter: 2
  episodes_total: 64
  experiment_id: cb3a18e0a26e466496590bc0542b68c4
  hostname: gpu020
  info:
    apply_time_ms: 2.56
    dispatch_time_ms: 6.903
    learner:
      cur_lr: 0.0013558041537180543
      grad_gnorm: 40.000003814697266
      policy_entropy: 3.525441884994507
      policy_loss: -3.2613415718078613
      var_gnorm: 23.469573974609375
      vf_explained_var: 0.4240242838859558
      vf_loss: 7.674956321716309
    num_steps_sampled: 65000
    num_steps_trained: 65000
    wait_time_ms: 34.579
  iterations_since_restore: 33
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 10879
  policy_reward_mean: {}
  time_since_restore: 317.3277006149292
  time_this_iter_s: 9.31320333480835
  time_total_s: 317.3277006149292
  timestamp: 1594145807
  timesteps_since_restore: 65000
  timesteps_this_iter: 2000
  timesteps_total: 65000
  training_iteration: 33
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 19.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10879], 317 s, 33 iter, 65000 ts, 254 rew

agent-1: 366.0
Sum Reward: 366.0
Avg Reward: 366.0
Min Reward: 366.0
Max Reward: 366.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
agent-1: 331.0
Sum Reward: 331.0
Avg Reward: 331.0
Min Reward: 331.0
Max Reward: 331.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_14-16-56
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 388.0
  episode_reward_mean: 257.3181818181818
  episode_reward_min: 54.0
  episodes_this_iter: 2
  episodes_total: 66
  experiment_id: cb3a18e0a26e466496590bc0542b68c4
  hostname: gpu020
  info:
    apply_time_ms: 2.842
    dispatch_time_ms: 6.573
    learner:
      cur_lr: 0.0013556709745898843
      grad_gnorm: 30.747617721557617
      policy_entropy: 0.18351566791534424
      policy_loss: 0.024394482374191284
      var_gnorm: 23.51662254333496
      vf_explained_var: 0.0
      vf_loss: 6.400301933288574
    num_steps_sampled: 67000
    num_steps_trained: 67000
    wait_time_ms: 40.943
  iterations_since_restore: 34
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 10879
  policy_reward_mean: {}
  time_since_restore: 326.683039188385
  time_this_iter_s: 9.35533857345581
  time_total_s: 326.683039188385
  timestamp: 1594145816
  timesteps_since_restore: 67000
  timesteps_this_iter: 2000
  timesteps_total: 67000
  training_iteration: 34
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 19.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10879], 326 s, 34 iter, 67000 ts, 257 rew

agent-1: 336.0
Sum Reward: 336.0
Avg Reward: 336.0
Min Reward: 336.0
Max Reward: 336.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
agent-1: 348.0
Sum Reward: 348.0
Avg Reward: 348.0
Min Reward: 348.0
Max Reward: 348.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_14-17-06
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 388.0
  episode_reward_mean: 259.80882352941177
  episode_reward_min: 54.0
  episodes_this_iter: 2
  episodes_total: 68
  experiment_id: cb3a18e0a26e466496590bc0542b68c4
  hostname: gpu020
  info:
    apply_time_ms: 2.936
    dispatch_time_ms: 8.539
    learner:
      cur_lr: 0.0013555377954617143
      grad_gnorm: 39.006309509277344
      policy_entropy: 1.0180655717849731
      policy_loss: -1.623099446296692
      var_gnorm: 23.53685188293457
      vf_explained_var: -0.12177848815917969
      vf_loss: 10.700447082519531
    num_steps_sampled: 69000
    num_steps_trained: 69000
    wait_time_ms: 33.608
  iterations_since_restore: 35
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 10879
  policy_reward_mean: {}
  time_since_restore: 335.9678018093109
  time_this_iter_s: 9.284762620925903
  time_total_s: 335.9678018093109
  timestamp: 1594145826
  timesteps_since_restore: 69000
  timesteps_this_iter: 2000
  timesteps_total: 69000
  training_iteration: 35
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 20.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10879], 335 s, 35 iter, 69000 ts, 260 rew

agent-1: 337.0
Sum Reward: 337.0
Avg Reward: 337.0
Min Reward: 337.0
Max Reward: 337.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
agent-1: 333.0
Sum Reward: 333.0
Avg Reward: 333.0
Min Reward: 333.0
Max Reward: 333.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_14-17-15
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 388.0
  episode_reward_mean: 261.95714285714286
  episode_reward_min: 54.0
  episodes_this_iter: 2
  episodes_total: 70
  experiment_id: cb3a18e0a26e466496590bc0542b68c4
  hostname: gpu020
  info:
    apply_time_ms: 2.593
    dispatch_time_ms: 6.578
    learner:
      cur_lr: 0.0013554046163335443
      grad_gnorm: 29.5408992767334
      policy_entropy: 0.33324772119522095
      policy_loss: 0.04871227592229843
      var_gnorm: 23.568796157836914
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 6.0903849601745605
    num_steps_sampled: 71000
    num_steps_trained: 71000
    wait_time_ms: 38.232
  iterations_since_restore: 36
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 10879
  policy_reward_mean: {}
  time_since_restore: 345.22848176956177
  time_this_iter_s: 9.260679960250854
  time_total_s: 345.22848176956177
  timestamp: 1594145835
  timesteps_since_restore: 71000
  timesteps_this_iter: 2000
  timesteps_total: 71000
  training_iteration: 36
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 20.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10879], 345 s, 36 iter, 71000 ts, 262 rew

agent-1: 363.0
Sum Reward: 363.0
Avg Reward: 363.0
Min Reward: 363.0
Max Reward: 363.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
agent-1: 370.0
Sum Reward: 370.0
Avg Reward: 370.0
Min Reward: 370.0
Max Reward: 370.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_14-17-24
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 388.0
  episode_reward_mean: 264.8611111111111
  episode_reward_min: 54.0
  episodes_this_iter: 2
  episodes_total: 72
  experiment_id: cb3a18e0a26e466496590bc0542b68c4
  hostname: gpu020
  info:
    apply_time_ms: 2.705
    dispatch_time_ms: 7.015
    learner:
      cur_lr: 0.0013552714372053742
      grad_gnorm: 5.954834938049316
      policy_entropy: 0.38519036769866943
      policy_loss: -0.0013746742624789476
      var_gnorm: 23.636199951171875
      vf_explained_var: -0.07946491241455078
      vf_loss: 1.367771863937378
    num_steps_sampled: 73000
    num_steps_trained: 73000
    wait_time_ms: 35.828
  iterations_since_restore: 37
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 10879
  policy_reward_mean: {}
  time_since_restore: 354.47464990615845
  time_this_iter_s: 9.24616813659668
  time_total_s: 354.47464990615845
  timestamp: 1594145844
  timesteps_since_restore: 73000
  timesteps_this_iter: 2000
  timesteps_total: 73000
  training_iteration: 37
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 20.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10879], 354 s, 37 iter, 73000 ts, 265 rew

agent-1: 341.0
Sum Reward: 341.0
Avg Reward: 341.0
Min Reward: 341.0
Max Reward: 341.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
agent-1: 328.0
Sum Reward: 328.0
Avg Reward: 328.0
Min Reward: 328.0
Max Reward: 328.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_14-17-33
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 388.0
  episode_reward_mean: 266.7432432432432
  episode_reward_min: 54.0
  episodes_this_iter: 2
  episodes_total: 74
  experiment_id: cb3a18e0a26e466496590bc0542b68c4
  hostname: gpu020
  info:
    apply_time_ms: 2.709
    dispatch_time_ms: 5.64
    learner:
      cur_lr: 0.0013551382580772042
      grad_gnorm: 17.482593536376953
      policy_entropy: 0.8387717008590698
      policy_loss: -0.1647108495235443
      var_gnorm: 23.669340133666992
      vf_explained_var: 0.331340491771698
      vf_loss: 2.785022020339966
    num_steps_sampled: 75000
    num_steps_trained: 75000
    wait_time_ms: 39.447
  iterations_since_restore: 38
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 10879
  policy_reward_mean: {}
  time_since_restore: 363.6978530883789
  time_this_iter_s: 9.223203182220459
  time_total_s: 363.6978530883789
  timestamp: 1594145853
  timesteps_since_restore: 75000
  timesteps_this_iter: 2000
  timesteps_total: 75000
  training_iteration: 38
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 20.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10879], 363 s, 38 iter, 75000 ts, 267 rew

agent-1: 365.0
Sum Reward: 365.0
Avg Reward: 365.0
Min Reward: 365.0
Max Reward: 365.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
agent-1: 412.0
Sum Reward: 412.0
Avg Reward: 412.0
Min Reward: 412.0
Max Reward: 412.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_14-17-43
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 412.0
  episode_reward_mean: 269.94736842105266
  episode_reward_min: 54.0
  episodes_this_iter: 2
  episodes_total: 76
  experiment_id: cb3a18e0a26e466496590bc0542b68c4
  hostname: gpu020
  info:
    apply_time_ms: 3.307
    dispatch_time_ms: 6.954
    learner:
      cur_lr: 0.0013550049625337124
      grad_gnorm: 40.0
      policy_entropy: 0.46882548928260803
      policy_loss: -0.12261577695608139
      var_gnorm: 23.78645133972168
      vf_explained_var: -0.134956955909729
      vf_loss: 26.717636108398438
    num_steps_sampled: 77000
    num_steps_trained: 77000
    wait_time_ms: 35.775
  iterations_since_restore: 39
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 10879
  policy_reward_mean: {}
  time_since_restore: 373.0226242542267
  time_this_iter_s: 9.324771165847778
  time_total_s: 373.0226242542267
  timestamp: 1594145863
  timesteps_since_restore: 77000
  timesteps_this_iter: 2000
  timesteps_total: 77000
  training_iteration: 39
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 21.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10879], 373 s, 39 iter, 77000 ts, 270 rew

agent-1: 339.0
Sum Reward: 339.0
Avg Reward: 339.0
Min Reward: 339.0
Max Reward: 339.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
agent-1: 362.0
Sum Reward: 362.0
Avg Reward: 362.0
Min Reward: 362.0
Max Reward: 362.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_14-17-52
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 412.0
  episode_reward_mean: 272.0128205128205
  episode_reward_min: 54.0
  episodes_this_iter: 2
  episodes_total: 78
  experiment_id: cb3a18e0a26e466496590bc0542b68c4
  hostname: gpu020
  info:
    apply_time_ms: 2.582
    dispatch_time_ms: 7.491
    learner:
      cur_lr: 0.0013548717834055424
      grad_gnorm: 8.292860984802246
      policy_entropy: 0.9830549359321594
      policy_loss: 1.2149444818496704
      var_gnorm: 23.891584396362305
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 1.2535737752914429
    num_steps_sampled: 79000
    num_steps_trained: 79000
    wait_time_ms: 35.808
  iterations_since_restore: 40
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 10879
  policy_reward_mean: {}
  time_since_restore: 382.246000289917
  time_this_iter_s: 9.223376035690308
  time_total_s: 382.246000289917
  timestamp: 1594145872
  timesteps_since_restore: 79000
  timesteps_this_iter: 2000
  timesteps_total: 79000
  training_iteration: 40
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 21.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10879], 382 s, 40 iter, 79000 ts, 272 rew

agent-1: 395.0
Sum Reward: 395.0
Avg Reward: 395.0
Min Reward: 395.0
Max Reward: 395.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
agent-1: 377.0
Sum Reward: 377.0
Avg Reward: 377.0
Min Reward: 377.0
Max Reward: 377.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_14-18-01
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 412.0
  episode_reward_mean: 274.8625
  episode_reward_min: 54.0
  episodes_this_iter: 2
  episodes_total: 80
  experiment_id: cb3a18e0a26e466496590bc0542b68c4
  hostname: gpu020
  info:
    apply_time_ms: 2.441
    dispatch_time_ms: 6.12
    learner:
      cur_lr: 0.0013547386042773724
      grad_gnorm: 20.06305694580078
      policy_entropy: 0.34593465924263
      policy_loss: 0.035092007368803024
      var_gnorm: 23.926158905029297
      vf_explained_var: 1.1920928955078125e-07
      vf_loss: 3.1255979537963867
    num_steps_sampled: 81000
    num_steps_trained: 81000
    wait_time_ms: 36.842
  iterations_since_restore: 41
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 10879
  policy_reward_mean: {}
  time_since_restore: 391.56123542785645
  time_this_iter_s: 9.315235137939453
  time_total_s: 391.56123542785645
  timestamp: 1594145881
  timesteps_since_restore: 81000
  timesteps_this_iter: 2000
  timesteps_total: 81000
  training_iteration: 41
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 21.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10879], 391 s, 41 iter, 81000 ts, 275 rew

agent-1: 321.0
Sum Reward: 321.0
Avg Reward: 321.0
Min Reward: 321.0
Max Reward: 321.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
agent-1: 339.0
Sum Reward: 339.0
Avg Reward: 339.0
Min Reward: 339.0
Max Reward: 339.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_14-18-11
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 412.0
  episode_reward_mean: 276.2073170731707
  episode_reward_min: 54.0
  episodes_this_iter: 2
  episodes_total: 82
  experiment_id: cb3a18e0a26e466496590bc0542b68c4
  hostname: gpu020
  info:
    apply_time_ms: 2.86
    dispatch_time_ms: 7.502
    learner:
      cur_lr: 0.0013546054251492023
      grad_gnorm: 39.99999237060547
      policy_entropy: 1.437936782836914
      policy_loss: -7.833641529083252
      var_gnorm: 24.074710845947266
      vf_explained_var: 0.0
      vf_loss: 11.124359130859375
    num_steps_sampled: 83000
    num_steps_trained: 83000
    wait_time_ms: 37.575
  iterations_since_restore: 42
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 10879
  policy_reward_mean: {}
  time_since_restore: 400.84123826026917
  time_this_iter_s: 9.28000283241272
  time_total_s: 400.84123826026917
  timestamp: 1594145891
  timesteps_since_restore: 83000
  timesteps_this_iter: 2000
  timesteps_total: 83000
  training_iteration: 42
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 21.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10879], 400 s, 42 iter, 83000 ts, 276 rew

agent-1: 384.0
Sum Reward: 384.0
Avg Reward: 384.0
Min Reward: 384.0
Max Reward: 384.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
agent-1: 359.0
Sum Reward: 359.0
Avg Reward: 359.0
Min Reward: 359.0
Max Reward: 359.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_14-18-20
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 412.0
  episode_reward_mean: 278.4761904761905
  episode_reward_min: 54.0
  episodes_this_iter: 2
  episodes_total: 84
  experiment_id: cb3a18e0a26e466496590bc0542b68c4
  hostname: gpu020
  info:
    apply_time_ms: 2.965
    dispatch_time_ms: 8.901
    learner:
      cur_lr: 0.0013544722460210323
      grad_gnorm: 7.641485691070557
      policy_entropy: 2.988123655319214
      policy_loss: 0.1855415403842926
      var_gnorm: 24.223283767700195
      vf_explained_var: 0.23384857177734375
      vf_loss: 2.014580726623535
    num_steps_sampled: 85000
    num_steps_trained: 85000
    wait_time_ms: 36.178
  iterations_since_restore: 43
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 10879
  policy_reward_mean: {}
  time_since_restore: 410.36414337158203
  time_this_iter_s: 9.522905111312866
  time_total_s: 410.36414337158203
  timestamp: 1594145900
  timesteps_since_restore: 85000
  timesteps_this_iter: 2000
  timesteps_total: 85000
  training_iteration: 43
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 21.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10879], 410 s, 43 iter, 85000 ts, 278 rew

agent-1: 360.0
Sum Reward: 360.0
Avg Reward: 360.0
Min Reward: 360.0
Max Reward: 360.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
agent-1: 369.0
Sum Reward: 369.0
Avg Reward: 369.0
Min Reward: 369.0
Max Reward: 369.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_14-18-30
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 412.0
  episode_reward_mean: 280.4767441860465
  episode_reward_min: 54.0
  episodes_this_iter: 2
  episodes_total: 86
  experiment_id: cb3a18e0a26e466496590bc0542b68c4
  hostname: gpu020
  info:
    apply_time_ms: 3.139
    dispatch_time_ms: 7.846
    learner:
      cur_lr: 0.0013543389504775405
      grad_gnorm: 19.558963775634766
      policy_entropy: 0.8504977226257324
      policy_loss: 0.13431955873966217
      var_gnorm: 24.3106632232666
      vf_explained_var: -0.3543570041656494
      vf_loss: 2.7928671836853027
    num_steps_sampled: 87000
    num_steps_trained: 87000
    wait_time_ms: 34.655
  iterations_since_restore: 44
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 10879
  policy_reward_mean: {}
  time_since_restore: 419.8983898162842
  time_this_iter_s: 9.534246444702148
  time_total_s: 419.8983898162842
  timestamp: 1594145910
  timesteps_since_restore: 87000
  timesteps_this_iter: 2000
  timesteps_total: 87000
  training_iteration: 44
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 22.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10879], 419 s, 44 iter, 87000 ts, 280 rew

agent-1: 377.0
Sum Reward: 377.0
Avg Reward: 377.0
Min Reward: 377.0
Max Reward: 377.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
agent-1: 339.0
Sum Reward: 339.0
Avg Reward: 339.0
Min Reward: 339.0
Max Reward: 339.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_14-18-39
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 412.0
  episode_reward_mean: 282.2386363636364
  episode_reward_min: 54.0
  episodes_this_iter: 2
  episodes_total: 88
  experiment_id: cb3a18e0a26e466496590bc0542b68c4
  hostname: gpu020
  info:
    apply_time_ms: 2.764
    dispatch_time_ms: 7.249
    learner:
      cur_lr: 0.0013542057713493705
      grad_gnorm: 37.797019958496094
      policy_entropy: 1.1719343662261963
      policy_loss: -0.2779950797557831
      var_gnorm: 24.36157989501953
      vf_explained_var: -1.0
      vf_loss: 9.512300491333008
    num_steps_sampled: 89000
    num_steps_trained: 89000
    wait_time_ms: 34.98
  iterations_since_restore: 45
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 10879
  policy_reward_mean: {}
  time_since_restore: 429.12235379219055
  time_this_iter_s: 9.223963975906372
  time_total_s: 429.12235379219055
  timestamp: 1594145919
  timesteps_since_restore: 89000
  timesteps_this_iter: 2000
  timesteps_total: 89000
  training_iteration: 45
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 22.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10879], 429 s, 45 iter, 89000 ts, 282 rew

agent-1: 369.0
Sum Reward: 369.0
Avg Reward: 369.0
Min Reward: 369.0
Max Reward: 369.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
agent-1: 345.0
Sum Reward: 345.0
Avg Reward: 345.0
Min Reward: 345.0
Max Reward: 345.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_14-18-49
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 412.0
  episode_reward_mean: 283.9
  episode_reward_min: 54.0
  episodes_this_iter: 2
  episodes_total: 90
  experiment_id: cb3a18e0a26e466496590bc0542b68c4
  hostname: gpu020
  info:
    apply_time_ms: 3.288
    dispatch_time_ms: 8.618
    learner:
      cur_lr: 0.0013540725922212005
      grad_gnorm: 39.999996185302734
      policy_entropy: 5.9078545570373535
      policy_loss: -6.725456714630127
      var_gnorm: 24.342241287231445
      vf_explained_var: -0.49947071075439453
      vf_loss: 11.462984085083008
    num_steps_sampled: 91000
    num_steps_trained: 91000
    wait_time_ms: 34.216
  iterations_since_restore: 46
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 10879
  policy_reward_mean: {}
  time_since_restore: 438.61769247055054
  time_this_iter_s: 9.495338678359985
  time_total_s: 438.61769247055054
  timestamp: 1594145929
  timesteps_since_restore: 91000
  timesteps_this_iter: 2000
  timesteps_total: 91000
  training_iteration: 46
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 22.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10879], 438 s, 46 iter, 91000 ts, 284 rew

agent-1: 303.0
Sum Reward: 303.0
Avg Reward: 303.0
Min Reward: 303.0
Max Reward: 303.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
agent-1: 317.0
Sum Reward: 317.0
Avg Reward: 317.0
Min Reward: 317.0
Max Reward: 317.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_14-18-58
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 412.0
  episode_reward_mean: 284.4673913043478
  episode_reward_min: 54.0
  episodes_this_iter: 2
  episodes_total: 92
  experiment_id: cb3a18e0a26e466496590bc0542b68c4
  hostname: gpu020
  info:
    apply_time_ms: 2.659
    dispatch_time_ms: 7.691
    learner:
      cur_lr: 0.0013539394130930305
      grad_gnorm: 40.00000762939453
      policy_entropy: 6.512720584869385
      policy_loss: -6.961389541625977
      var_gnorm: 24.358760833740234
      vf_explained_var: 0.0
      vf_loss: 16.153207778930664
    num_steps_sampled: 93000
    num_steps_trained: 93000
    wait_time_ms: 36.104
  iterations_since_restore: 47
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 10879
  policy_reward_mean: {}
  time_since_restore: 447.86344146728516
  time_this_iter_s: 9.24574899673462
  time_total_s: 447.86344146728516
  timestamp: 1594145938
  timesteps_since_restore: 93000
  timesteps_this_iter: 2000
  timesteps_total: 93000
  training_iteration: 47
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 22.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10879], 447 s, 47 iter, 93000 ts, 284 rew

agent-1: 217.0
Sum Reward: 217.0
Avg Reward: 217.0
Min Reward: 217.0
Max Reward: 217.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
agent-1: 272.0
Sum Reward: 272.0
Avg Reward: 272.0
Min Reward: 272.0
Max Reward: 272.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_14-19-07
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 412.0
  episode_reward_mean: 283.6170212765957
  episode_reward_min: 54.0
  episodes_this_iter: 2
  episodes_total: 94
  experiment_id: cb3a18e0a26e466496590bc0542b68c4
  hostname: gpu020
  info:
    apply_time_ms: 3.669
    dispatch_time_ms: 7.328
    learner:
      cur_lr: 0.0013538062339648604
      grad_gnorm: 19.677555084228516
      policy_entropy: 2.2974112033843994
      policy_loss: -0.3831820487976074
      var_gnorm: 24.364015579223633
      vf_explained_var: -0.08654189109802246
      vf_loss: 2.3716349601745605
    num_steps_sampled: 95000
    num_steps_trained: 95000
    wait_time_ms: 32.82
  iterations_since_restore: 48
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 10879
  policy_reward_mean: {}
  time_since_restore: 457.2429533004761
  time_this_iter_s: 9.379511833190918
  time_total_s: 457.2429533004761
  timestamp: 1594145947
  timesteps_since_restore: 95000
  timesteps_this_iter: 2000
  timesteps_total: 95000
  training_iteration: 48
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 23.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10879], 457 s, 48 iter, 95000 ts, 284 rew

agent-1: 256.0
Sum Reward: 256.0
Avg Reward: 256.0
Min Reward: 256.0
Max Reward: 256.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
agent-1: 333.0
Sum Reward: 333.0
Avg Reward: 333.0
Min Reward: 333.0
Max Reward: 333.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_14-19-17
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 412.0
  episode_reward_mean: 283.84375
  episode_reward_min: 54.0
  episodes_this_iter: 2
  episodes_total: 96
  experiment_id: cb3a18e0a26e466496590bc0542b68c4
  hostname: gpu020
  info:
    apply_time_ms: 2.371
    dispatch_time_ms: 5.969
    learner:
      cur_lr: 0.0013536730548366904
      grad_gnorm: 40.0
      policy_entropy: 5.76477575302124
      policy_loss: -3.155895948410034
      var_gnorm: 24.436962127685547
      vf_explained_var: 0.35524195432662964
      vf_loss: 4.72930908203125
    num_steps_sampled: 97000
    num_steps_trained: 97000
    wait_time_ms: 43.006
  iterations_since_restore: 49
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 10879
  policy_reward_mean: {}
  time_since_restore: 466.8813831806183
  time_this_iter_s: 9.638429880142212
  time_total_s: 466.8813831806183
  timestamp: 1594145957
  timesteps_since_restore: 97000
  timesteps_this_iter: 2000
  timesteps_total: 97000
  training_iteration: 49
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 23.3/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10879], 466 s, 49 iter, 97000 ts, 284 rew

agent-1: 246.0
Sum Reward: 246.0
Avg Reward: 246.0
Min Reward: 246.0
Max Reward: 246.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
agent-1: 280.0
Sum Reward: 280.0
Avg Reward: 280.0
Min Reward: 280.0
Max Reward: 280.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
agent-1: 243.0
Sum Reward: 243.0
Avg Reward: 243.0
Min Reward: 243.0
Max Reward: 243.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_14-19-27
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 412.0
  episode_reward_mean: 283.4183673469388
  episode_reward_min: 54.0
  episodes_this_iter: 2
  episodes_total: 98
  experiment_id: cb3a18e0a26e466496590bc0542b68c4
  hostname: gpu020
  info:
    apply_time_ms: 2.581
    dispatch_time_ms: 7.294
    learner:
      cur_lr: 0.0013535397592931986
      grad_gnorm: 40.0
      policy_entropy: 3.5535013675689697
      policy_loss: -7.180573463439941
      var_gnorm: 24.432842254638672
      vf_explained_var: -1.0
      vf_loss: 36.92329025268555
    num_steps_sampled: 99000
    num_steps_trained: 99000
    wait_time_ms: 37.397
  iterations_since_restore: 50
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 10879
  policy_reward_mean: {}
  time_since_restore: 476.385950088501
  time_this_iter_s: 9.50456690788269
  time_total_s: 476.385950088501
  timestamp: 1594145967
  timesteps_since_restore: 99000
  timesteps_this_iter: 2000
  timesteps_total: 99000
  training_iteration: 50
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 23.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10879], 476 s, 50 iter, 99000 ts, 283 rew

agent-1: 259.0
Sum Reward: 259.0
Avg Reward: 259.0
Min Reward: 259.0
Max Reward: 259.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_14-19-36
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 412.0
  episode_reward_mean: 282.77
  episode_reward_min: 54.0
  episodes_this_iter: 2
  episodes_total: 100
  experiment_id: cb3a18e0a26e466496590bc0542b68c4
  hostname: gpu020
  info:
    apply_time_ms: 2.626
    dispatch_time_ms: 5.783
    learner:
      cur_lr: 0.0013534065801650286
      grad_gnorm: 27.6812744140625
      policy_entropy: 3.9849705696105957
      policy_loss: 2.9018571376800537
      var_gnorm: 24.567087173461914
      vf_explained_var: -0.8541932106018066
      vf_loss: 7.4243550300598145
    num_steps_sampled: 101000
    num_steps_trained: 101000
    wait_time_ms: 38.077
  iterations_since_restore: 51
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 10879
  policy_reward_mean: {}
  time_since_restore: 485.5409905910492
  time_this_iter_s: 9.155040502548218
  time_total_s: 485.5409905910492
  timestamp: 1594145976
  timesteps_since_restore: 101000
  timesteps_this_iter: 2000
  timesteps_total: 101000
  training_iteration: 51
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 23.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10879], 485 s, 51 iter, 101000 ts, 283 rew

agent-1: 286.0
Sum Reward: 286.0
Avg Reward: 286.0
Min Reward: 286.0
Max Reward: 286.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
agent-1: 335.0
Sum Reward: 335.0
Avg Reward: 335.0
Min Reward: 335.0
Max Reward: 335.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_14-19-45
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 412.0
  episode_reward_mean: 287.83
  episode_reward_min: 88.0
  episodes_this_iter: 2
  episodes_total: 102
  experiment_id: cb3a18e0a26e466496590bc0542b68c4
  hostname: gpu020
  info:
    apply_time_ms: 2.983
    dispatch_time_ms: 7.241
    learner:
      cur_lr: 0.0013532734010368586
      grad_gnorm: 7.19547176361084
      policy_entropy: 1.6132079362869263
      policy_loss: 0.08710803091526031
      var_gnorm: 24.750194549560547
      vf_explained_var: -0.0010315179824829102
      vf_loss: 1.2586307525634766
    num_steps_sampled: 103000
    num_steps_trained: 103000
    wait_time_ms: 38.251
  iterations_since_restore: 52
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 10879
  policy_reward_mean: {}
  time_since_restore: 495.0570435523987
  time_this_iter_s: 9.516052961349487
  time_total_s: 495.0570435523987
  timestamp: 1594145985
  timesteps_since_restore: 103000
  timesteps_this_iter: 2000
  timesteps_total: 103000
  training_iteration: 52
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 24.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10879], 495 s, 52 iter, 103000 ts, 288 rew

agent-1: 307.0
Sum Reward: 307.0
Avg Reward: 307.0
Min Reward: 307.0
Max Reward: 307.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
agent-1: 390.0
Sum Reward: 390.0
Avg Reward: 390.0
Min Reward: 390.0
Max Reward: 390.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
agent-1: 344.0
Sum Reward: 344.0
Avg Reward: 344.0
Min Reward: 344.0
Max Reward: 344.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_14-19-55
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 412.0
  episode_reward_mean: 294.01
  episode_reward_min: 112.0
  episodes_this_iter: 3
  episodes_total: 105
  experiment_id: cb3a18e0a26e466496590bc0542b68c4
  hostname: gpu020
  info:
    apply_time_ms: 3.175
    dispatch_time_ms: 7.121
    learner:
      cur_lr: 0.0013531402219086885
      grad_gnorm: 11.989326477050781
      policy_entropy: 1.3973870277404785
      policy_loss: 0.1831086426973343
      var_gnorm: 24.914098739624023
      vf_explained_var: -1.0
      vf_loss: 11.614850044250488
    num_steps_sampled: 105000
    num_steps_trained: 105000
    wait_time_ms: 37.253
  iterations_since_restore: 53
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 10879
  policy_reward_mean: {}
  time_since_restore: 504.5413565635681
  time_this_iter_s: 9.484313011169434
  time_total_s: 504.5413565635681
  timestamp: 1594145995
  timesteps_since_restore: 105000
  timesteps_this_iter: 2000
  timesteps_total: 105000
  training_iteration: 53
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 24.3/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10879], 504 s, 53 iter, 105000 ts, 294 rew

agent-1: 400.0
Sum Reward: 400.0
Avg Reward: 400.0
Min Reward: 400.0
Max Reward: 400.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
agent-1: 422.0
Sum Reward: 422.0
Avg Reward: 422.0
Min Reward: 422.0
Max Reward: 422.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_14-20-04
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 422.0
  episode_reward_mean: 299.26
  episode_reward_min: 112.0
  episodes_this_iter: 2
  episodes_total: 107
  experiment_id: cb3a18e0a26e466496590bc0542b68c4
  hostname: gpu020
  info:
    apply_time_ms: 3.76
    dispatch_time_ms: 7.461
    learner:
      cur_lr: 0.0013530070427805185
      grad_gnorm: 16.857297897338867
      policy_entropy: 1.0030601024627686
      policy_loss: 0.2687828540802002
      var_gnorm: 25.1385555267334
      vf_explained_var: -1.0
      vf_loss: 13.307292938232422
    num_steps_sampled: 107000
    num_steps_trained: 107000
    wait_time_ms: 35.806
  iterations_since_restore: 54
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 10879
  policy_reward_mean: {}
  time_since_restore: 513.9114460945129
  time_this_iter_s: 9.370089530944824
  time_total_s: 513.9114460945129
  timestamp: 1594146004
  timesteps_since_restore: 107000
  timesteps_this_iter: 2000
  timesteps_total: 107000
  training_iteration: 54
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 24.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10879], 513 s, 54 iter, 107000 ts, 299 rew

agent-1: 366.0
Sum Reward: 366.0
Avg Reward: 366.0
Min Reward: 366.0
Max Reward: 366.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
agent-1: 370.0
Sum Reward: 370.0
Avg Reward: 370.0
Min Reward: 370.0
Max Reward: 370.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_14-20-14
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 422.0
  episode_reward_mean: 300.76
  episode_reward_min: 112.0
  episodes_this_iter: 1
  episodes_total: 108
  experiment_id: cb3a18e0a26e466496590bc0542b68c4
  hostname: gpu020
  info:
    apply_time_ms: 2.379
    dispatch_time_ms: 7.938
    learner:
      cur_lr: 0.0013528737472370267
      grad_gnorm: 39.999996185302734
      policy_entropy: 2.374741315841675
      policy_loss: -1.8293075561523438
      var_gnorm: 25.17838478088379
      vf_explained_var: -1.0
      vf_loss: 22.7094783782959
    num_steps_sampled: 109000
    num_steps_trained: 109000
    wait_time_ms: 37.46
  iterations_since_restore: 55
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 10879
  policy_reward_mean: {}
  time_since_restore: 523.3401093482971
  time_this_iter_s: 9.42866325378418
  time_total_s: 523.3401093482971
  timestamp: 1594146014
  timesteps_since_restore: 109000
  timesteps_this_iter: 2000
  timesteps_total: 109000
  training_iteration: 55
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 24.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10879], 523 s, 55 iter, 109000 ts, 301 rew

agent-1: 425.0
Sum Reward: 425.0
Avg Reward: 425.0
Min Reward: 425.0
Max Reward: 425.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
agent-1: 348.0
Sum Reward: 348.0
Avg Reward: 348.0
Min Reward: 348.0
Max Reward: 348.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_14-20-23
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 425.0
  episode_reward_mean: 306.08
  episode_reward_min: 112.0
  episodes_this_iter: 3
  episodes_total: 111
  experiment_id: cb3a18e0a26e466496590bc0542b68c4
  hostname: gpu020
  info:
    apply_time_ms: 3.991
    dispatch_time_ms: 11.359
    learner:
      cur_lr: 0.0013527405681088567
      grad_gnorm: 40.0
      policy_entropy: 1.1511430740356445
      policy_loss: -16.150100708007812
      var_gnorm: 25.219493865966797
      vf_explained_var: 0.17352604866027832
      vf_loss: 5986.29638671875
    num_steps_sampled: 111000
    num_steps_trained: 111000
    wait_time_ms: 33.422
  iterations_since_restore: 56
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 10879
  policy_reward_mean: {}
  time_since_restore: 532.7710211277008
  time_this_iter_s: 9.430911779403687
  time_total_s: 532.7710211277008
  timestamp: 1594146023
  timesteps_since_restore: 111000
  timesteps_this_iter: 2000
  timesteps_total: 111000
  training_iteration: 56
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10879], 532 s, 56 iter, 111000 ts, 306 rew

agent-1: 429.0
Sum Reward: 429.0
Avg Reward: 429.0
Min Reward: 429.0
Max Reward: 429.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_14-20-33
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 429.0
  episode_reward_mean: 308.46
  episode_reward_min: 112.0
  episodes_this_iter: 1
  episodes_total: 112
  experiment_id: cb3a18e0a26e466496590bc0542b68c4
  hostname: gpu020
  info:
    apply_time_ms: 2.484
    dispatch_time_ms: 7.937
    learner:
      cur_lr: 0.0013526073889806867
      grad_gnorm: 40.0
      policy_entropy: 0.8334473371505737
      policy_loss: -0.08962534368038177
      var_gnorm: 25.421249389648438
      vf_explained_var: -1.0
      vf_loss: 11.734790802001953
    num_steps_sampled: 113000
    num_steps_trained: 113000
    wait_time_ms: 36.811
  iterations_since_restore: 57
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 10879
  policy_reward_mean: {}
  time_since_restore: 542.2424154281616
  time_this_iter_s: 9.471394300460815
  time_total_s: 542.2424154281616
  timestamp: 1594146033
  timesteps_since_restore: 113000
  timesteps_this_iter: 2000
  timesteps_total: 113000
  training_iteration: 57
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10879], 542 s, 57 iter, 113000 ts, 308 rew

agent-1: 438.0
Sum Reward: 438.0
Avg Reward: 438.0
Min Reward: 438.0
Max Reward: 438.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
agent-1: 432.0
Sum Reward: 432.0
Avg Reward: 432.0
Min Reward: 432.0
Max Reward: 432.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_14-20-42
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 438.0
  episode_reward_mean: 313.45
  episode_reward_min: 112.0
  episodes_this_iter: 2
  episodes_total: 114
  experiment_id: cb3a18e0a26e466496590bc0542b68c4
  hostname: gpu020
  info:
    apply_time_ms: 2.618
    dispatch_time_ms: 6.453
    learner:
      cur_lr: 0.0013524742098525167
      grad_gnorm: 39.999996185302734
      policy_entropy: 3.5770013332366943
      policy_loss: -5.389853000640869
      var_gnorm: 25.577655792236328
      vf_explained_var: -0.1955794095993042
      vf_loss: 22.596424102783203
    num_steps_sampled: 115000
    num_steps_trained: 115000
    wait_time_ms: 40.778
  iterations_since_restore: 58
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 10879
  policy_reward_mean: {}
  time_since_restore: 551.854065656662
  time_this_iter_s: 9.611650228500366
  time_total_s: 551.854065656662
  timestamp: 1594146042
  timesteps_since_restore: 115000
  timesteps_this_iter: 2000
  timesteps_total: 115000
  training_iteration: 58
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10879], 551 s, 58 iter, 115000 ts, 313 rew

agent-1: 430.0
Sum Reward: 430.0
Avg Reward: 430.0
Min Reward: 430.0
Max Reward: 430.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
agent-1: 361.0
Sum Reward: 361.0
Avg Reward: 361.0
Min Reward: 361.0
Max Reward: 361.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_14-20-52
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 438.0
  episode_reward_mean: 318.98
  episode_reward_min: 121.0
  episodes_this_iter: 2
  episodes_total: 116
  experiment_id: cb3a18e0a26e466496590bc0542b68c4
  hostname: gpu020
  info:
    apply_time_ms: 2.705
    dispatch_time_ms: 7.112
    learner:
      cur_lr: 0.0013523410307243466
      grad_gnorm: 5.00904655456543
      policy_entropy: 1.1733027696609497
      policy_loss: -0.04088717699050903
      var_gnorm: 25.50002670288086
      vf_explained_var: 0.0
      vf_loss: 0.7238508462905884
    num_steps_sampled: 117000
    num_steps_trained: 117000
    wait_time_ms: 36.767
  iterations_since_restore: 59
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 10879
  policy_reward_mean: {}
  time_since_restore: 561.2942762374878
  time_this_iter_s: 9.440210580825806
  time_total_s: 561.2942762374878
  timestamp: 1594146052
  timesteps_since_restore: 117000
  timesteps_this_iter: 2000
  timesteps_total: 117000
  training_iteration: 59
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10879], 561 s, 59 iter, 117000 ts, 319 rew

agent-1: 398.0
Sum Reward: 398.0
Avg Reward: 398.0
Min Reward: 398.0
Max Reward: 398.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
agent-1: 419.0
Sum Reward: 419.0
Avg Reward: 419.0
Min Reward: 419.0
Max Reward: 419.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_14-21-01
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 438.0
  episode_reward_mean: 324.17
  episode_reward_min: 121.0
  episodes_this_iter: 2
  episodes_total: 118
  experiment_id: cb3a18e0a26e466496590bc0542b68c4
  hostname: gpu020
  info:
    apply_time_ms: 2.421
    dispatch_time_ms: 5.737
    learner:
      cur_lr: 0.0013522078515961766
      grad_gnorm: 15.218132019042969
      policy_entropy: 2.1312921047210693
      policy_loss: -0.6757672429084778
      var_gnorm: 25.61109161376953
      vf_explained_var: 0.2473456859588623
      vf_loss: 3.2097997665405273
    num_steps_sampled: 119000
    num_steps_trained: 119000
    wait_time_ms: 40.165
  iterations_since_restore: 60
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 10879
  policy_reward_mean: {}
  time_since_restore: 570.8807940483093
  time_this_iter_s: 9.586517810821533
  time_total_s: 570.8807940483093
  timestamp: 1594146061
  timesteps_since_restore: 119000
  timesteps_this_iter: 2000
  timesteps_total: 119000
  training_iteration: 60
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10879], 570 s, 60 iter, 119000 ts, 324 rew

agent-1: 427.0
Sum Reward: 427.0
Avg Reward: 427.0
Min Reward: 427.0
Max Reward: 427.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
agent-1: 381.0
Sum Reward: 381.0
Avg Reward: 381.0
Min Reward: 381.0
Max Reward: 381.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_14-21-11
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 438.0
  episode_reward_mean: 329.62
  episode_reward_min: 158.0
  episodes_this_iter: 2
  episodes_total: 120
  experiment_id: cb3a18e0a26e466496590bc0542b68c4
  hostname: gpu020
  info:
    apply_time_ms: 2.839
    dispatch_time_ms: 8.323
    learner:
      cur_lr: 0.0013520745560526848
      grad_gnorm: 2.8332645893096924
      policy_entropy: 4.48442268371582
      policy_loss: -0.9611742496490479
      var_gnorm: 25.637752532958984
      vf_explained_var: -0.7198896408081055
      vf_loss: 1.7258251905441284
    num_steps_sampled: 121000
    num_steps_trained: 121000
    wait_time_ms: 35.729
  iterations_since_restore: 61
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 10879
  policy_reward_mean: {}
  time_since_restore: 580.3031361103058
  time_this_iter_s: 9.42234206199646
  time_total_s: 580.3031361103058
  timestamp: 1594146071
  timesteps_since_restore: 121000
  timesteps_this_iter: 2000
  timesteps_total: 121000
  training_iteration: 61
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10879], 580 s, 61 iter, 121000 ts, 330 rew

agent-1: 380.0
Sum Reward: 380.0
Avg Reward: 380.0
Min Reward: 380.0
Max Reward: 380.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
agent-1: 392.0
Sum Reward: 392.0
Avg Reward: 392.0
Min Reward: 392.0
Max Reward: 392.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_14-21-20
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 438.0
  episode_reward_mean: 333.02
  episode_reward_min: 158.0
  episodes_this_iter: 2
  episodes_total: 122
  experiment_id: cb3a18e0a26e466496590bc0542b68c4
  hostname: gpu020
  info:
    apply_time_ms: 2.676
    dispatch_time_ms: 5.59
    learner:
      cur_lr: 0.0013519413769245148
      grad_gnorm: 40.0
      policy_entropy: 3.4573326110839844
      policy_loss: -6.720895290374756
      var_gnorm: 25.692018508911133
      vf_explained_var: 0.1752747893333435
      vf_loss: 11.685372352600098
    num_steps_sampled: 123000
    num_steps_trained: 123000
    wait_time_ms: 38.812
  iterations_since_restore: 62
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 10879
  policy_reward_mean: {}
  time_since_restore: 589.8603491783142
  time_this_iter_s: 9.557213068008423
  time_total_s: 589.8603491783142
  timestamp: 1594146080
  timesteps_since_restore: 123000
  timesteps_this_iter: 2000
  timesteps_total: 123000
  training_iteration: 62
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10879], 589 s, 62 iter, 123000 ts, 333 rew

agent-1: 369.0
Sum Reward: 369.0
Avg Reward: 369.0
Min Reward: 369.0
Max Reward: 369.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
agent-1: 367.0
Sum Reward: 367.0
Avg Reward: 367.0
Min Reward: 367.0
Max Reward: 367.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_14-21-30
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 438.0
  episode_reward_mean: 336.83
  episode_reward_min: 217.0
  episodes_this_iter: 2
  episodes_total: 124
  experiment_id: cb3a18e0a26e466496590bc0542b68c4
  hostname: gpu020
  info:
    apply_time_ms: 2.979
    dispatch_time_ms: 7.882
    learner:
      cur_lr: 0.0013518081977963448
      grad_gnorm: 39.99999237060547
      policy_entropy: 4.898140907287598
      policy_loss: -12.635560989379883
      var_gnorm: 25.759971618652344
      vf_explained_var: -0.017433881759643555
      vf_loss: 20.232152938842773
    num_steps_sampled: 125000
    num_steps_trained: 125000
    wait_time_ms: 37.05
  iterations_since_restore: 63
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 10879
  policy_reward_mean: {}
  time_since_restore: 599.3980062007904
  time_this_iter_s: 9.537657022476196
  time_total_s: 599.3980062007904
  timestamp: 1594146090
  timesteps_since_restore: 125000
  timesteps_this_iter: 2000
  timesteps_total: 125000
  training_iteration: 63
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10879], 599 s, 63 iter, 125000 ts, 337 rew

agent-1: 360.0
Sum Reward: 360.0
Avg Reward: 360.0
Min Reward: 360.0
Max Reward: 360.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
agent-1: 351.0
Sum Reward: 351.0
Avg Reward: 351.0
Min Reward: 351.0
Max Reward: 351.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_14-21-39
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 438.0
  episode_reward_mean: 338.91
  episode_reward_min: 217.0
  episodes_this_iter: 2
  episodes_total: 126
  experiment_id: cb3a18e0a26e466496590bc0542b68c4
  hostname: gpu020
  info:
    apply_time_ms: 2.689
    dispatch_time_ms: 9.13
    learner:
      cur_lr: 0.0013516750186681747
      grad_gnorm: 39.999996185302734
      policy_entropy: 3.4507064819335938
      policy_loss: -6.9556474685668945
      var_gnorm: 25.719568252563477
      vf_explained_var: 0.10773205757141113
      vf_loss: 20.932880401611328
    num_steps_sampled: 127000
    num_steps_trained: 127000
    wait_time_ms: 36.06
  iterations_since_restore: 64
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 10879
  policy_reward_mean: {}
  time_since_restore: 608.8783273696899
  time_this_iter_s: 9.480321168899536
  time_total_s: 608.8783273696899
  timestamp: 1594146099
  timesteps_since_restore: 127000
  timesteps_this_iter: 2000
  timesteps_total: 127000
  training_iteration: 64
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10879], 608 s, 64 iter, 127000 ts, 339 rew

agent-1: 303.0
Sum Reward: 303.0
Avg Reward: 303.0
Min Reward: 303.0
Max Reward: 303.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
agent-1: 297.0
Sum Reward: 297.0
Avg Reward: 297.0
Min Reward: 297.0
Max Reward: 297.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_14-21-49
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 438.0
  episode_reward_mean: 339.12
  episode_reward_min: 217.0
  episodes_this_iter: 2
  episodes_total: 128
  experiment_id: cb3a18e0a26e466496590bc0542b68c4
  hostname: gpu020
  info:
    apply_time_ms: 3.707
    dispatch_time_ms: 8.16
    learner:
      cur_lr: 0.0013515418395400047
      grad_gnorm: 35.66213607788086
      policy_entropy: 1.3202804327011108
      policy_loss: 0.07180378586053848
      var_gnorm: 25.673595428466797
      vf_explained_var: -0.0260697603225708
      vf_loss: 11.215116500854492
    num_steps_sampled: 129000
    num_steps_trained: 129000
    wait_time_ms: 32.215
  iterations_since_restore: 65
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 10879
  policy_reward_mean: {}
  time_since_restore: 618.2190392017365
  time_this_iter_s: 9.340711832046509
  time_total_s: 618.2190392017365
  timestamp: 1594146109
  timesteps_since_restore: 129000
  timesteps_this_iter: 2000
  timesteps_total: 129000
  training_iteration: 65
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 27.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10879], 618 s, 65 iter, 129000 ts, 339 rew

agent-1: 307.0
Sum Reward: 307.0
Avg Reward: 307.0
Min Reward: 307.0
Max Reward: 307.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
agent-1: 309.0
Sum Reward: 309.0
Avg Reward: 309.0
Min Reward: 309.0
Max Reward: 309.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_14-21-58
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 438.0
  episode_reward_mean: 339.68
  episode_reward_min: 217.0
  episodes_this_iter: 2
  episodes_total: 130
  experiment_id: cb3a18e0a26e466496590bc0542b68c4
  hostname: gpu020
  info:
    apply_time_ms: 2.399
    dispatch_time_ms: 8.094
    learner:
      cur_lr: 0.0013514085439965129
      grad_gnorm: 40.000003814697266
      policy_entropy: 0.9069730043411255
      policy_loss: 0.21514621376991272
      var_gnorm: 25.684158325195312
      vf_explained_var: 0.5216877460479736
      vf_loss: 18.830862045288086
    num_steps_sampled: 131000
    num_steps_trained: 131000
    wait_time_ms: 40.566
  iterations_since_restore: 66
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 10879
  policy_reward_mean: {}
  time_since_restore: 627.6547195911407
  time_this_iter_s: 9.435680389404297
  time_total_s: 627.6547195911407
  timestamp: 1594146118
  timesteps_since_restore: 131000
  timesteps_this_iter: 2000
  timesteps_total: 131000
  training_iteration: 66
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 27.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10879], 627 s, 66 iter, 131000 ts, 340 rew

agent-1: 313.0
Sum Reward: 313.0
Avg Reward: 313.0
Min Reward: 313.0
Max Reward: 313.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
agent-1: 330.0
Sum Reward: 330.0
Avg Reward: 330.0
Min Reward: 330.0
Max Reward: 330.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_14-22-08
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 438.0
  episode_reward_mean: 340.31
  episode_reward_min: 217.0
  episodes_this_iter: 2
  episodes_total: 132
  experiment_id: cb3a18e0a26e466496590bc0542b68c4
  hostname: gpu020
  info:
    apply_time_ms: 2.556
    dispatch_time_ms: 8.021
    learner:
      cur_lr: 0.0013512753648683429
      grad_gnorm: 19.03020668029785
      policy_entropy: 2.218221664428711
      policy_loss: 3.840582847595215
      var_gnorm: 25.804574966430664
      vf_explained_var: -1.0
      vf_loss: 4.443024635314941
    num_steps_sampled: 133000
    num_steps_trained: 133000
    wait_time_ms: 39.183
  iterations_since_restore: 67
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 10879
  policy_reward_mean: {}
  time_since_restore: 637.108635187149
  time_this_iter_s: 9.4539155960083
  time_total_s: 637.108635187149
  timestamp: 1594146128
  timesteps_since_restore: 133000
  timesteps_this_iter: 2000
  timesteps_total: 133000
  training_iteration: 67
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 27.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10879], 637 s, 67 iter, 133000 ts, 340 rew

agent-1: 351.0
Sum Reward: 351.0
Avg Reward: 351.0
Min Reward: 351.0
Max Reward: 351.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
agent-1: 341.0
Sum Reward: 341.0
Avg Reward: 341.0
Min Reward: 341.0
Max Reward: 341.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_14-22-17
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 438.0
  episode_reward_mean: 340.84
  episode_reward_min: 217.0
  episodes_this_iter: 2
  episodes_total: 134
  experiment_id: cb3a18e0a26e466496590bc0542b68c4
  hostname: gpu020
  info:
    apply_time_ms: 2.891
    dispatch_time_ms: 7.523
    learner:
      cur_lr: 0.0013511421857401729
      grad_gnorm: 7.655553817749023
      policy_entropy: 2.1107609272003174
      policy_loss: 0.14424091577529907
      var_gnorm: 25.861021041870117
      vf_explained_var: -0.4243161678314209
      vf_loss: 2.3815577030181885
    num_steps_sampled: 135000
    num_steps_trained: 135000
    wait_time_ms: 35.533
  iterations_since_restore: 68
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 10879
  policy_reward_mean: {}
  time_since_restore: 646.477552652359
  time_this_iter_s: 9.368917465209961
  time_total_s: 646.477552652359
  timestamp: 1594146137
  timesteps_since_restore: 135000
  timesteps_this_iter: 2000
  timesteps_total: 135000
  training_iteration: 68
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 27.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10879], 646 s, 68 iter, 135000 ts, 341 rew

agent-1: 299.0
Sum Reward: 299.0
Avg Reward: 299.0
Min Reward: 299.0
Max Reward: 299.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_14-22-26
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 438.0
  episode_reward_mean: 340.59
  episode_reward_min: 217.0
  episodes_this_iter: 1
  episodes_total: 135
  experiment_id: cb3a18e0a26e466496590bc0542b68c4
  hostname: gpu020
  info:
    apply_time_ms: 3.398
    dispatch_time_ms: 11.664
    learner:
      cur_lr: 0.0013510090066120028
      grad_gnorm: 24.9427547454834
      policy_entropy: 1.0724232196807861
      policy_loss: 0.10343395173549652
      var_gnorm: 25.879928588867188
      vf_explained_var: 0.21841418743133545
      vf_loss: 5.647904396057129
    num_steps_sampled: 136000
    num_steps_trained: 136000
    wait_time_ms: 34.739
  iterations_since_restore: 69
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 10879
  policy_reward_mean: {}
  time_since_restore: 655.3352131843567
  time_this_iter_s: 8.85766053199768
  time_total_s: 655.3352131843567
  timestamp: 1594146146
  timesteps_since_restore: 136000
  timesteps_this_iter: 1000
  timesteps_total: 136000
  training_iteration: 69
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 27.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10879], 655 s, 69 iter, 136000 ts, 341 rew

agent-1: 338.0
Sum Reward: 338.0
Avg Reward: 338.0
Min Reward: 338.0
Max Reward: 338.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
agent-1: 353.0
Sum Reward: 353.0
Avg Reward: 353.0
Min Reward: 353.0
Max Reward: 353.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_14-22-36
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 438.0
  episode_reward_mean: 341.48
  episode_reward_min: 217.0
  episodes_this_iter: 2
  episodes_total: 137
  experiment_id: cb3a18e0a26e466496590bc0542b68c4
  hostname: gpu020
  info:
    apply_time_ms: 3.993
    dispatch_time_ms: 8.362
    learner:
      cur_lr: 0.0013509424170479178
      grad_gnorm: 40.0
      policy_entropy: 0.16511423885822296
      policy_loss: -0.005754728335887194
      var_gnorm: 25.948959350585938
      vf_explained_var: 0.5397944450378418
      vf_loss: 0.6960286498069763
    num_steps_sampled: 138000
    num_steps_trained: 138000
    wait_time_ms: 32.937
  iterations_since_restore: 70
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 10879
  policy_reward_mean: {}
  time_since_restore: 664.8489193916321
  time_this_iter_s: 9.51370620727539
  time_total_s: 664.8489193916321
  timestamp: 1594146156
  timesteps_since_restore: 138000
  timesteps_this_iter: 2000
  timesteps_total: 138000
  training_iteration: 70
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 27.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10879], 664 s, 70 iter, 138000 ts, 341 rew

agent-1: 328.0
Sum Reward: 328.0
Avg Reward: 328.0
Min Reward: 328.0
Max Reward: 328.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
agent-1: 361.0
Sum Reward: 361.0
Avg Reward: 361.0
Min Reward: 361.0
Max Reward: 361.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_14-22-45
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 438.0
  episode_reward_mean: 342.06
  episode_reward_min: 217.0
  episodes_this_iter: 2
  episodes_total: 139
  experiment_id: cb3a18e0a26e466496590bc0542b68c4
  hostname: gpu020
  info:
    apply_time_ms: 2.697
    dispatch_time_ms: 9.175
    learner:
      cur_lr: 0.0013508092379197478
      grad_gnorm: 20.515853881835938
      policy_entropy: 0.8596952557563782
      policy_loss: 0.4283776581287384
      var_gnorm: 25.99392318725586
      vf_explained_var: -1.0
      vf_loss: 3.3000190258026123
    num_steps_sampled: 140000
    num_steps_trained: 140000
    wait_time_ms: 36.319
  iterations_since_restore: 71
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 10879
  policy_reward_mean: {}
  time_since_restore: 674.3742942810059
  time_this_iter_s: 9.52537488937378
  time_total_s: 674.3742942810059
  timestamp: 1594146165
  timesteps_since_restore: 140000
  timesteps_this_iter: 2000
  timesteps_total: 140000
  training_iteration: 71
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 27.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10879], 674 s, 71 iter, 140000 ts, 342 rew

agent-1: 369.0
Sum Reward: 369.0
Avg Reward: 369.0
Min Reward: 369.0
Max Reward: 369.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
agent-1: 392.0
Sum Reward: 392.0
Avg Reward: 392.0
Min Reward: 392.0
Max Reward: 392.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_14-22-55
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 438.0
  episode_reward_mean: 343.31
  episode_reward_min: 217.0
  episodes_this_iter: 2
  episodes_total: 141
  experiment_id: cb3a18e0a26e466496590bc0542b68c4
  hostname: gpu020
  info:
    apply_time_ms: 3.099
    dispatch_time_ms: 8.992
    learner:
      cur_lr: 0.001350675942376256
      grad_gnorm: 7.542896270751953
      policy_entropy: 1.3574918508529663
      policy_loss: -0.027149010449647903
      var_gnorm: 26.099952697753906
      vf_explained_var: 0.3761973977088928
      vf_loss: 1.4803755283355713
    num_steps_sampled: 142000
    num_steps_trained: 142000
    wait_time_ms: 38.538
  iterations_since_restore: 72
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 10879
  policy_reward_mean: {}
  time_since_restore: 684.0891094207764
  time_this_iter_s: 9.714815139770508
  time_total_s: 684.0891094207764
  timestamp: 1594146175
  timesteps_since_restore: 142000
  timesteps_this_iter: 2000
  timesteps_total: 142000
  training_iteration: 72
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 27.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10879], 684 s, 72 iter, 142000 ts, 343 rew

agent-1: 416.0
Sum Reward: 416.0
Avg Reward: 416.0
Min Reward: 416.0
Max Reward: 416.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
agent-1: 416.0
Sum Reward: 416.0
Avg Reward: 416.0
Min Reward: 416.0
Max Reward: 416.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_14-23-05
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 438.0
  episode_reward_mean: 345.2
  episode_reward_min: 217.0
  episodes_this_iter: 2
  episodes_total: 143
  experiment_id: cb3a18e0a26e466496590bc0542b68c4
  hostname: gpu020
  info:
    apply_time_ms: 5.62
    dispatch_time_ms: 9.508
    learner:
      cur_lr: 0.001350542763248086
      grad_gnorm: 7.936270236968994
      policy_entropy: 0.2040192186832428
      policy_loss: 0.008696842938661575
      var_gnorm: 26.157718658447266
      vf_explained_var: 0.0
      vf_loss: 2.046558380126953
    num_steps_sampled: 144000
    num_steps_trained: 144000
    wait_time_ms: 35.426
  iterations_since_restore: 73
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 10879
  policy_reward_mean: {}
  time_since_restore: 693.7388591766357
  time_this_iter_s: 9.649749755859375
  time_total_s: 693.7388591766357
  timestamp: 1594146185
  timesteps_since_restore: 144000
  timesteps_this_iter: 2000
  timesteps_total: 144000
  training_iteration: 73
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 27.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10879], 693 s, 73 iter, 144000 ts, 345 rew

agent-1: 400.0
Sum Reward: 400.0
Avg Reward: 400.0
Min Reward: 400.0
Max Reward: 400.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
agent-1: 434.0
Sum Reward: 434.0
Avg Reward: 434.0
Min Reward: 434.0
Max Reward: 434.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_14-23-15
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 438.0
  episode_reward_mean: 346.55
  episode_reward_min: 217.0
  episodes_this_iter: 2
  episodes_total: 145
  experiment_id: cb3a18e0a26e466496590bc0542b68c4
  hostname: gpu020
  info:
    apply_time_ms: 2.986
    dispatch_time_ms: 8.481
    learner:
      cur_lr: 0.001350409584119916
      grad_gnorm: 3.9795703887939453
      policy_entropy: 0.9631850719451904
      policy_loss: 0.4697730243206024
      var_gnorm: 26.271291732788086
      vf_explained_var: -0.09708249568939209
      vf_loss: 1.6338472366333008
    num_steps_sampled: 146000
    num_steps_trained: 146000
    wait_time_ms: 36.632
  iterations_since_restore: 74
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 10879
  policy_reward_mean: {}
  time_since_restore: 703.61381316185
  time_this_iter_s: 9.874953985214233
  time_total_s: 703.61381316185
  timestamp: 1594146195
  timesteps_since_restore: 146000
  timesteps_this_iter: 2000
  timesteps_total: 146000
  training_iteration: 74
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 27.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10879], 703 s, 74 iter, 146000 ts, 347 rew

agent-1: 418.0
Sum Reward: 418.0
Avg Reward: 418.0
Min Reward: 418.0
Max Reward: 418.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
agent-1: 409.0
Sum Reward: 409.0
Avg Reward: 409.0
Min Reward: 409.0
Max Reward: 409.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_14-23-31
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 438.0
  episode_reward_mean: 348.34
  episode_reward_min: 217.0
  episodes_this_iter: 2
  episodes_total: 147
  experiment_id: cb3a18e0a26e466496590bc0542b68c4
  hostname: gpu020
  info:
    apply_time_ms: 3.499
    dispatch_time_ms: 31.729
    learner:
      cur_lr: 0.001350276404991746
      grad_gnorm: 12.15524673461914
      policy_entropy: 0.7688995003700256
      policy_loss: -0.06626221537590027
      var_gnorm: 26.41019058227539
      vf_explained_var: 0.26742953062057495
      vf_loss: 1.7040081024169922
    num_steps_sampled: 148000
    num_steps_trained: 148000
    wait_time_ms: 23.189
  iterations_since_restore: 75
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 10879
  policy_reward_mean: {}
  time_since_restore: 719.3970849514008
  time_this_iter_s: 15.783271789550781
  time_total_s: 719.3970849514008
  timestamp: 1594146211
  timesteps_since_restore: 148000
  timesteps_this_iter: 2000
  timesteps_total: 148000
  training_iteration: 75
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 27.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10879], 719 s, 75 iter, 148000 ts, 348 rew

agent-1: 413.0
Sum Reward: 413.0
Avg Reward: 413.0
Min Reward: 413.0
Max Reward: 413.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_14-23-37
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 438.0
  episode_reward_mean: 348.91
  episode_reward_min: 217.0
  episodes_this_iter: 1
  episodes_total: 148
  experiment_id: cb3a18e0a26e466496590bc0542b68c4
  hostname: gpu020
  info:
    apply_time_ms: 3.101
    dispatch_time_ms: 33.72
    learner:
      cur_lr: 0.001350143225863576
      grad_gnorm: 23.882963180541992
      policy_entropy: 0.3792213797569275
      policy_loss: 0.05148212984204292
      var_gnorm: 26.447237014770508
      vf_explained_var: 0.0
      vf_loss: 4.04371452331543
    num_steps_sampled: 149000
    num_steps_trained: 149000
    wait_time_ms: 42.632
  iterations_since_restore: 76
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 10879
  policy_reward_mean: {}
  time_since_restore: 725.3898782730103
  time_this_iter_s: 5.992793321609497
  time_total_s: 725.3898782730103
  timestamp: 1594146217
  timesteps_since_restore: 149000
  timesteps_this_iter: 1000
  timesteps_total: 149000
  training_iteration: 76
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 27.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10879], 725 s, 76 iter, 149000 ts, 349 rew

agent-1: 456.0
Sum Reward: 456.0
Avg Reward: 456.0
Min Reward: 456.0
Max Reward: 456.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_14-23-42
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 456.0
  episode_reward_mean: 351.13
  episode_reward_min: 217.0
  episodes_this_iter: 1
  episodes_total: 149
  experiment_id: cb3a18e0a26e466496590bc0542b68c4
  hostname: gpu020
  info:
    apply_time_ms: 3.302
    dispatch_time_ms: 45.05
    learner:
      cur_lr: 0.001350076636299491
      grad_gnorm: 33.528968811035156
      policy_entropy: 0.23011264204978943
      policy_loss: -0.037913501262664795
      var_gnorm: 26.474140167236328
      vf_explained_var: 0.0
      vf_loss: 10.722047805786133
    num_steps_sampled: 150000
    num_steps_trained: 150000
    wait_time_ms: 18.1
  iterations_since_restore: 77
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 10879
  policy_reward_mean: {}
  time_since_restore: 730.6251311302185
  time_this_iter_s: 5.235252857208252
  time_total_s: 730.6251311302185
  timestamp: 1594146222
  timesteps_since_restore: 150000
  timesteps_this_iter: 1000
  timesteps_total: 150000
  training_iteration: 77
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 27.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10879], 730 s, 77 iter, 150000 ts, 351 rew

agent-1: 463.0
Sum Reward: 463.0
Avg Reward: 463.0
Min Reward: 463.0
Max Reward: 463.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_14-23-48
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 463.0
  episode_reward_mean: 353.45
  episode_reward_min: 217.0
  episodes_this_iter: 1
  episodes_total: 150
  experiment_id: cb3a18e0a26e466496590bc0542b68c4
  hostname: gpu020
  info:
    apply_time_ms: 2.493
    dispatch_time_ms: 26.295
    learner:
      cur_lr: 0.001350010046735406
      grad_gnorm: 38.96451950073242
      policy_entropy: 0.3331824541091919
      policy_loss: -0.07405830174684525
      var_gnorm: 26.51992416381836
      vf_explained_var: 0.0
      vf_loss: 9.36091423034668
    num_steps_sampled: 151000
    num_steps_trained: 151000
    wait_time_ms: 27.444
  iterations_since_restore: 78
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 10879
  policy_reward_mean: {}
  time_since_restore: 736.2289991378784
  time_this_iter_s: 5.603868007659912
  time_total_s: 736.2289991378784
  timestamp: 1594146228
  timesteps_since_restore: 151000
  timesteps_this_iter: 1000
  timesteps_total: 151000
  training_iteration: 78
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 27.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10879], 736 s, 78 iter, 151000 ts, 353 rew

agent-1: 430.0
Sum Reward: 430.0
Avg Reward: 430.0
Min Reward: 430.0
Max Reward: 430.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_14-23-54
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 463.0
  episode_reward_mean: 355.12
  episode_reward_min: 217.0
  episodes_this_iter: 1
  episodes_total: 151
  experiment_id: cb3a18e0a26e466496590bc0542b68c4
  hostname: gpu020
  info:
    apply_time_ms: 4.192
    dispatch_time_ms: 52.675
    learner:
      cur_lr: 0.001349943457171321
      grad_gnorm: 11.536595344543457
      policy_entropy: 1.161936640739441
      policy_loss: 0.9200010299682617
      var_gnorm: 26.553743362426758
      vf_explained_var: -0.16515231132507324
      vf_loss: 4.575096607208252
    num_steps_sampled: 152000
    num_steps_trained: 152000
    wait_time_ms: 22.421
  iterations_since_restore: 79
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 10879
  policy_reward_mean: {}
  time_since_restore: 742.2054922580719
  time_this_iter_s: 5.9764931201934814
  time_total_s: 742.2054922580719
  timestamp: 1594146234
  timesteps_since_restore: 152000
  timesteps_this_iter: 1000
  timesteps_total: 152000
  training_iteration: 79
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 27.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10879], 742 s, 79 iter, 152000 ts, 355 rew

agent-1: 458.0
Sum Reward: 458.0
Avg Reward: 458.0
Min Reward: 458.0
Max Reward: 458.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_14-23-59
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 463.0
  episode_reward_mean: 357.45
  episode_reward_min: 217.0
  episodes_this_iter: 1
  episodes_total: 152
  experiment_id: cb3a18e0a26e466496590bc0542b68c4
  hostname: gpu020
  info:
    apply_time_ms: 2.614
    dispatch_time_ms: 27.362
    learner:
      cur_lr: 0.001349876751191914
      grad_gnorm: 6.484889030456543
      policy_entropy: 0.41894757747650146
      policy_loss: -0.00487293116748333
      var_gnorm: 26.572521209716797
      vf_explained_var: 5.960464477539063e-08
      vf_loss: 1.0830581188201904
    num_steps_sampled: 153000
    num_steps_trained: 153000
    wait_time_ms: 25.373
  iterations_since_restore: 80
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 10879
  policy_reward_mean: {}
  time_since_restore: 747.4811940193176
  time_this_iter_s: 5.2757017612457275
  time_total_s: 747.4811940193176
  timestamp: 1594146239
  timesteps_since_restore: 153000
  timesteps_this_iter: 1000
  timesteps_total: 153000
  training_iteration: 80
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 27.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10879], 747 s, 80 iter, 153000 ts, 357 rew

agent-1: 434.0
Sum Reward: 434.0
Avg Reward: 434.0
Min Reward: 434.0
Max Reward: 434.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_14-24-05
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 463.0
  episode_reward_mean: 358.29
  episode_reward_min: 217.0
  episodes_this_iter: 1
  episodes_total: 153
  experiment_id: cb3a18e0a26e466496590bc0542b68c4
  hostname: gpu020
  info:
    apply_time_ms: 3.162
    dispatch_time_ms: 33.773
    learner:
      cur_lr: 0.001349810161627829
      grad_gnorm: 5.1253981590271
      policy_entropy: 0.40311509370803833
      policy_loss: -0.00424706656485796
      var_gnorm: 26.598888397216797
      vf_explained_var: 0.0
      vf_loss: 0.9675664305686951
    num_steps_sampled: 154000
    num_steps_trained: 154000
    wait_time_ms: 11.255
  iterations_since_restore: 81
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 10879
  policy_reward_mean: {}
  time_since_restore: 752.9536266326904
  time_this_iter_s: 5.472432613372803
  time_total_s: 752.9536266326904
  timestamp: 1594146245
  timesteps_since_restore: 154000
  timesteps_this_iter: 1000
  timesteps_total: 154000
  training_iteration: 81
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 27.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10879], 752 s, 81 iter, 154000 ts, 358 rew

agent-1: 425.0
Sum Reward: 425.0
Avg Reward: 425.0
Min Reward: 425.0
Max Reward: 425.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_14-24-11
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 463.0
  episode_reward_mean: 359.48
  episode_reward_min: 217.0
  episodes_this_iter: 1
  episodes_total: 154
  experiment_id: cb3a18e0a26e466496590bc0542b68c4
  hostname: gpu020
  info:
    apply_time_ms: 4.4
    dispatch_time_ms: 29.529
    learner:
      cur_lr: 0.001349743572063744
      grad_gnorm: 5.179916858673096
      policy_entropy: 0.3392365872859955
      policy_loss: 0.011696334928274155
      var_gnorm: 26.574886322021484
      vf_explained_var: -0.8930691480636597
      vf_loss: 2.193646192550659
    num_steps_sampled: 155000
    num_steps_trained: 155000
    wait_time_ms: 14.063
  iterations_since_restore: 82
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 10879
  policy_reward_mean: {}
  time_since_restore: 758.4574279785156
  time_this_iter_s: 5.503801345825195
  time_total_s: 758.4574279785156
  timestamp: 1594146251
  timesteps_since_restore: 155000
  timesteps_this_iter: 1000
  timesteps_total: 155000
  training_iteration: 82
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 27.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10879], 758 s, 82 iter, 155000 ts, 359 rew

agent-1: 390.0
Sum Reward: 390.0
Avg Reward: 390.0
Min Reward: 390.0
Max Reward: 390.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_14-24-16
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 463.0
  episode_reward_mean: 360.02
  episode_reward_min: 217.0
  episodes_this_iter: 1
  episodes_total: 155
  experiment_id: cb3a18e0a26e466496590bc0542b68c4
  hostname: gpu020
  info:
    apply_time_ms: 2.61
    dispatch_time_ms: 31.492
    learner:
      cur_lr: 0.001349676982499659
      grad_gnorm: 40.0
      policy_entropy: 0.8449231386184692
      policy_loss: 0.19020752608776093
      var_gnorm: 26.581201553344727
      vf_explained_var: 0.25934159755706787
      vf_loss: 11.298462867736816
    num_steps_sampled: 156000
    num_steps_trained: 156000
    wait_time_ms: 14.434
  iterations_since_restore: 83
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 10879
  policy_reward_mean: {}
  time_since_restore: 764.0118007659912
  time_this_iter_s: 5.554372787475586
  time_total_s: 764.0118007659912
  timestamp: 1594146256
  timesteps_since_restore: 156000
  timesteps_this_iter: 1000
  timesteps_total: 156000
  training_iteration: 83
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 27.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10879], 764 s, 83 iter, 156000 ts, 360 rew

agent-1: 372.0
Sum Reward: 372.0
Avg Reward: 372.0
Min Reward: 372.0
Max Reward: 372.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_14-24-22
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 463.0
  episode_reward_mean: 360.25
  episode_reward_min: 217.0
  episodes_this_iter: 1
  episodes_total: 156
  experiment_id: cb3a18e0a26e466496590bc0542b68c4
  hostname: gpu020
  info:
    apply_time_ms: 2.79
    dispatch_time_ms: 37.363
    learner:
      cur_lr: 0.001349610392935574
      grad_gnorm: 39.999996185302734
      policy_entropy: 1.2025723457336426
      policy_loss: -0.40844812989234924
      var_gnorm: 26.61771011352539
      vf_explained_var: 0.001831650733947754
      vf_loss: 19.872018814086914
    num_steps_sampled: 157000
    num_steps_trained: 157000
    wait_time_ms: 17.508
  iterations_since_restore: 84
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 10879
  policy_reward_mean: {}
  time_since_restore: 769.7576851844788
  time_this_iter_s: 5.745884418487549
  time_total_s: 769.7576851844788
  timestamp: 1594146262
  timesteps_since_restore: 157000
  timesteps_this_iter: 1000
  timesteps_total: 157000
  training_iteration: 84
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 27.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10879], 769 s, 84 iter, 157000 ts, 360 rew

agent-1: 401.0
Sum Reward: 401.0
Avg Reward: 401.0
Min Reward: 401.0
Max Reward: 401.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_14-24-28
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 463.0
  episode_reward_mean: 360.89
  episode_reward_min: 217.0
  episodes_this_iter: 1
  episodes_total: 157
  experiment_id: cb3a18e0a26e466496590bc0542b68c4
  hostname: gpu020
  info:
    apply_time_ms: 3.347
    dispatch_time_ms: 41.483
    learner:
      cur_lr: 0.001349543803371489
      grad_gnorm: 40.0
      policy_entropy: 2.0854499340057373
      policy_loss: 0.7315424680709839
      var_gnorm: 26.576078414916992
      vf_explained_var: 0.0
      vf_loss: 11.394448280334473
    num_steps_sampled: 158000
    num_steps_trained: 158000
    wait_time_ms: 39.902
  iterations_since_restore: 85
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 10879
  policy_reward_mean: {}
  time_since_restore: 775.5209443569183
  time_this_iter_s: 5.763259172439575
  time_total_s: 775.5209443569183
  timestamp: 1594146268
  timesteps_since_restore: 158000
  timesteps_this_iter: 1000
  timesteps_total: 158000
  training_iteration: 85
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 27.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10879], 775 s, 85 iter, 158000 ts, 361 rew

agent-1: 339.0
Sum Reward: 339.0
Avg Reward: 339.0
Min Reward: 339.0
Max Reward: 339.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
agent-1: 342.0
Sum Reward: 342.0
Avg Reward: 342.0
Min Reward: 342.0
Max Reward: 342.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_14-24-33
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 463.0
  episode_reward_mean: 361.37
  episode_reward_min: 217.0
  episodes_this_iter: 1
  episodes_total: 158
  experiment_id: cb3a18e0a26e466496590bc0542b68c4
  hostname: gpu020
  info:
    apply_time_ms: 2.974
    dispatch_time_ms: 42.365
    learner:
      cur_lr: 0.001349477213807404
      grad_gnorm: 33.22346496582031
      policy_entropy: 2.090867519378662
      policy_loss: -0.6188945174217224
      var_gnorm: 26.560400009155273
      vf_explained_var: 0.0
      vf_loss: 11.694957733154297
    num_steps_sampled: 159000
    num_steps_trained: 159000
    wait_time_ms: 17.378
  iterations_since_restore: 86
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 10879
  policy_reward_mean: {}
  time_since_restore: 781.1181876659393
  time_this_iter_s: 5.597243309020996
  time_total_s: 781.1181876659393
  timestamp: 1594146273
  timesteps_since_restore: 159000
  timesteps_this_iter: 1000
  timesteps_total: 159000
  training_iteration: 86
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 27.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10879], 781 s, 86 iter, 159000 ts, 361 rew

Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_14-24-39
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 463.0
  episode_reward_mean: 361.19
  episode_reward_min: 217.0
  episodes_this_iter: 1
  episodes_total: 159
  experiment_id: cb3a18e0a26e466496590bc0542b68c4
  hostname: gpu020
  info:
    apply_time_ms: 2.863
    dispatch_time_ms: 35.042
    learner:
      cur_lr: 0.001349410624243319
      grad_gnorm: 10.923654556274414
      policy_entropy: 1.5707751512527466
      policy_loss: -1.0283763408660889
      var_gnorm: 26.5111083984375
      vf_explained_var: 0.22191643714904785
      vf_loss: 2.033313274383545
    num_steps_sampled: 160000
    num_steps_trained: 160000
    wait_time_ms: 17.782
  iterations_since_restore: 87
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 10879
  policy_reward_mean: {}
  time_since_restore: 786.9615254402161
  time_this_iter_s: 5.843337774276733
  time_total_s: 786.9615254402161
  timestamp: 1594146279
  timesteps_since_restore: 160000
  timesteps_this_iter: 1000
  timesteps_total: 160000
  training_iteration: 87
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 27.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10879], 786 s, 87 iter, 160000 ts, 361 rew

agent-1: 311.0
Sum Reward: 311.0
Avg Reward: 311.0
Min Reward: 311.0
Max Reward: 311.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_14-24-45
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 463.0
  episode_reward_mean: 361.11
  episode_reward_min: 217.0
  episodes_this_iter: 1
  episodes_total: 160
  experiment_id: cb3a18e0a26e466496590bc0542b68c4
  hostname: gpu020
  info:
    apply_time_ms: 2.748
    dispatch_time_ms: 39.991
    learner:
      cur_lr: 0.001349344034679234
      grad_gnorm: 4.279203414916992
      policy_entropy: 0.8865805864334106
      policy_loss: 0.013473277911543846
      var_gnorm: 26.55430793762207
      vf_explained_var: -0.04329073429107666
      vf_loss: 0.9898176193237305
    num_steps_sampled: 161000
    num_steps_trained: 161000
    wait_time_ms: 13.287
  iterations_since_restore: 88
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 10879
  policy_reward_mean: {}
  time_since_restore: 792.5071225166321
  time_this_iter_s: 5.545597076416016
  time_total_s: 792.5071225166321
  timestamp: 1594146285
  timesteps_since_restore: 161000
  timesteps_this_iter: 1000
  timesteps_total: 161000
  training_iteration: 88
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 27.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10879], 792 s, 88 iter, 161000 ts, 361 rew

agent-1: 341.0
Sum Reward: 341.0
Avg Reward: 341.0
Min Reward: 341.0
Max Reward: 341.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_14-24-50
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 463.0
  episode_reward_mean: 360.89
  episode_reward_min: 217.0
  episodes_this_iter: 1
  episodes_total: 161
  experiment_id: cb3a18e0a26e466496590bc0542b68c4
  hostname: gpu020
  info:
    apply_time_ms: 2.895
    dispatch_time_ms: 22.089
    learner:
      cur_lr: 0.001349277445115149
      grad_gnorm: 35.17893981933594
      policy_entropy: 0.35036325454711914
      policy_loss: -0.05878622457385063
      var_gnorm: 26.660531997680664
      vf_explained_var: 5.960464477539063e-08
      vf_loss: 7.66955041885376
    num_steps_sampled: 162000
    num_steps_trained: 162000
    wait_time_ms: 13.751
  iterations_since_restore: 89
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 10879
  policy_reward_mean: {}
  time_since_restore: 797.8990416526794
  time_this_iter_s: 5.391919136047363
  time_total_s: 797.8990416526794
  timestamp: 1594146290
  timesteps_since_restore: 162000
  timesteps_this_iter: 1000
  timesteps_total: 162000
  training_iteration: 89
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 27.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10879], 797 s, 89 iter, 162000 ts, 361 rew

agent-1: 437.0
Sum Reward: 437.0
Avg Reward: 437.0
Min Reward: 437.0
Max Reward: 437.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
agent-1: 419.0
Sum Reward: 419.0
Avg Reward: 419.0
Min Reward: 419.0
Max Reward: 419.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
  custom_metrics: {}
  date: 2020-07-07_14-24-56
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 463.0
  episode_reward_mean: 361.69
  episode_reward_min: 217.0
  episodes_this_iter: 1
  episodes_total: 162
  experiment_id: cb3a18e0a26e466496590bc0542b68c4
  hostname: gpu020
  info:
    apply_time_ms: 5.36
    dispatch_time_ms: 38.098
    learner:
      cur_lr: 0.001349210855551064
      grad_gnorm: 40.000003814697266
      policy_entropy: 0.5169456005096436
      policy_loss: 0.12593120336532593
      var_gnorm: 26.716371536254883
      vf_explained_var: 0.0
      vf_loss: 14.055708885192871
    num_steps_sampled: 163000
    num_steps_trained: 163000
    wait_time_ms: 17.365
  iterations_since_restore: 90
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 10879
  policy_reward_mean: {}
  time_since_restore: 803.2460927963257
  time_this_iter_s: 5.34705114364624
  time_total_s: 803.2460927963257
  timestamp: 1594146296
  timesteps_since_restore: 163000
  timesteps_this_iter: 1000
  timesteps_total: 163000
  training_iteration: 90
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 27.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10879], 803 s, 90 iter, 163000 ts, 362 rew

Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_14-25-02
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 463.0
  episode_reward_mean: 362.09
  episode_reward_min: 217.0
  episodes_this_iter: 1
  episodes_total: 163
  experiment_id: cb3a18e0a26e466496590bc0542b68c4
  hostname: gpu020
  info:
    apply_time_ms: 2.583
    dispatch_time_ms: 53.105
    learner:
      cur_lr: 0.0013491441495716572
      grad_gnorm: 40.0
      policy_entropy: 0.7691296339035034
      policy_loss: 0.27281761169433594
      var_gnorm: 26.731828689575195
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 23.589553833007812
    num_steps_sampled: 164000
    num_steps_trained: 164000
    wait_time_ms: 33.06
  iterations_since_restore: 91
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 10879
  policy_reward_mean: {}
  time_since_restore: 809.0133016109467
  time_this_iter_s: 5.767208814620972
  time_total_s: 809.0133016109467
  timestamp: 1594146302
  timesteps_since_restore: 164000
  timesteps_this_iter: 1000
  timesteps_total: 164000
  training_iteration: 91
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 27.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10879], 809 s, 91 iter, 164000 ts, 362 rew

agent-1: 403.0
Sum Reward: 403.0
Avg Reward: 403.0
Min Reward: 403.0
Max Reward: 403.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
agent-1: 366.0
Sum Reward: 366.0
Avg Reward: 366.0
Min Reward: 366.0
Max Reward: 366.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_14-25-07
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 463.0
  episode_reward_mean: 362.71
  episode_reward_min: 217.0
  episodes_this_iter: 2
  episodes_total: 165
  experiment_id: cb3a18e0a26e466496590bc0542b68c4
  hostname: gpu020
  info:
    apply_time_ms: 3.246
    dispatch_time_ms: 32.26
    learner:
      cur_lr: 0.0013490775600075722
      grad_gnorm: 40.0
      policy_entropy: 1.4186522960662842
      policy_loss: -0.02614440768957138
      var_gnorm: 26.746185302734375
      vf_explained_var: 0.26511263847351074
      vf_loss: 0.4926019012928009
    num_steps_sampled: 165000
    num_steps_trained: 165000
    wait_time_ms: 23.741
  iterations_since_restore: 92
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 10879
  policy_reward_mean: {}
  time_since_restore: 814.6670982837677
  time_this_iter_s: 5.653796672821045
  time_total_s: 814.6670982837677
  timestamp: 1594146307
  timesteps_since_restore: 165000
  timesteps_this_iter: 1000
  timesteps_total: 165000
  training_iteration: 92
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 27.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10879], 814 s, 92 iter, 165000 ts, 363 rew

Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_14-25-13
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 463.0
  episode_reward_mean: 362.71
  episode_reward_min: 217.0
  episodes_this_iter: 0
  episodes_total: 165
  experiment_id: cb3a18e0a26e466496590bc0542b68c4
  hostname: gpu020
  info:
    apply_time_ms: 3.035
    dispatch_time_ms: 37.879
    learner:
      cur_lr: 0.0013490109704434872
      grad_gnorm: 13.17104434967041
      policy_entropy: 0.7444739937782288
      policy_loss: -0.08130007982254028
      var_gnorm: 26.770809173583984
      vf_explained_var: 0.0
      vf_loss: 1.8257930278778076
    num_steps_sampled: 166000
    num_steps_trained: 166000
    wait_time_ms: 22.698
  iterations_since_restore: 93
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 10879
  policy_reward_mean: {}
  time_since_restore: 820.514034986496
  time_this_iter_s: 5.8469367027282715
  time_total_s: 820.514034986496
  timestamp: 1594146313
  timesteps_since_restore: 166000
  timesteps_this_iter: 1000
  timesteps_total: 166000
  training_iteration: 93
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 27.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10879], 820 s, 93 iter, 166000 ts, 363 rew

agent-1: 375.0
Sum Reward: 375.0
Avg Reward: 375.0
Min Reward: 375.0
Max Reward: 375.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_14-25-19
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 463.0
  episode_reward_mean: 362.8
  episode_reward_min: 217.0
  episodes_this_iter: 1
  episodes_total: 166
  experiment_id: cb3a18e0a26e466496590bc0542b68c4
  hostname: gpu020
  info:
    apply_time_ms: 3.111
    dispatch_time_ms: 20.491
    learner:
      cur_lr: 0.0013489443808794022
      grad_gnorm: 37.40326690673828
      policy_entropy: 0.479535311460495
      policy_loss: 0.10581036657094955
      var_gnorm: 26.774620056152344
      vf_explained_var: 0.0
      vf_loss: 8.947399139404297
    num_steps_sampled: 167000
    num_steps_trained: 167000
    wait_time_ms: 14.371
  iterations_since_restore: 94
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 10879
  policy_reward_mean: {}
  time_since_restore: 825.9434239864349
  time_this_iter_s: 5.429388999938965
  time_total_s: 825.9434239864349
  timestamp: 1594146319
  timesteps_since_restore: 167000
  timesteps_this_iter: 1000
  timesteps_total: 167000
  training_iteration: 94
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 27.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10879], 825 s, 94 iter, 167000 ts, 363 rew

agent-1: 394.0
Sum Reward: 394.0
Avg Reward: 394.0
Min Reward: 394.0
Max Reward: 394.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_14-25-24
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 463.0
  episode_reward_mean: 363.26
  episode_reward_min: 217.0
  episodes_this_iter: 1
  episodes_total: 167
  experiment_id: cb3a18e0a26e466496590bc0542b68c4
  hostname: gpu020
  info:
    apply_time_ms: 2.937
    dispatch_time_ms: 45.348
    learner:
      cur_lr: 0.0013488777913153172
      grad_gnorm: 19.202674865722656
      policy_entropy: 0.8487108945846558
      policy_loss: -0.1037520319223404
      var_gnorm: 26.85112762451172
      vf_explained_var: 0.12083148956298828
      vf_loss: 4.343353271484375
    num_steps_sampled: 168000
    num_steps_trained: 168000
    wait_time_ms: 21.29
  iterations_since_restore: 95
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 10879
  policy_reward_mean: {}
  time_since_restore: 831.5801734924316
  time_this_iter_s: 5.636749505996704
  time_total_s: 831.5801734924316
  timestamp: 1594146324
  timesteps_since_restore: 168000
  timesteps_this_iter: 1000
  timesteps_total: 168000
  training_iteration: 95
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 27.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10879], 831 s, 95 iter, 168000 ts, 363 rew

agent-1: 431.0
Sum Reward: 431.0
Avg Reward: 431.0
Min Reward: 431.0
Max Reward: 431.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
agent-1: 431.0
Sum Reward: 431.0
Avg Reward: 431.0
Min Reward: 431.0
Max Reward: 431.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_14-25-52
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 463.0
  episode_reward_mean: 365.19
  episode_reward_min: 217.0
  episodes_this_iter: 2
  episodes_total: 169
  experiment_id: cb3a18e0a26e466496590bc0542b68c4
  hostname: gpu020
  info:
    apply_time_ms: 2.72
    dispatch_time_ms: 39.825
    learner:
      cur_lr: 0.0013488112017512321
      grad_gnorm: 39.999996185302734
      policy_entropy: 1.5969499349594116
      policy_loss: 3.1516804695129395
      var_gnorm: 26.945085525512695
      vf_explained_var: -0.00017130374908447266
      vf_loss: 3.6714870929718018
    num_steps_sampled: 169000
    num_steps_trained: 169000
    wait_time_ms: 12.018
  iterations_since_restore: 96
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 10879
  policy_reward_mean: {}
  time_since_restore: 859.0483195781708
  time_this_iter_s: 27.468146085739136
  time_total_s: 859.0483195781708
  timestamp: 1594146352
  timesteps_since_restore: 169000
  timesteps_this_iter: 1000
  timesteps_total: 169000
  training_iteration: 96
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 27.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10879], 859 s, 96 iter, 169000 ts, 365 rew

Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_14-25-57
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 463.0
  episode_reward_mean: 365.19
  episode_reward_min: 217.0
  episodes_this_iter: 0
  episodes_total: 169
  experiment_id: cb3a18e0a26e466496590bc0542b68c4
  hostname: gpu020
  info:
    apply_time_ms: 3.113
    dispatch_time_ms: 40.44
    learner:
      cur_lr: 0.0013487446121871471
      grad_gnorm: 22.816814422607422
      policy_entropy: 0.8851889371871948
      policy_loss: 0.14862073957920074
      var_gnorm: 27.077178955078125
      vf_explained_var: -0.04393899440765381
      vf_loss: 4.4492316246032715
    num_steps_sampled: 170000
    num_steps_trained: 170000
    wait_time_ms: 16.096
  iterations_since_restore: 97
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 10879
  policy_reward_mean: {}
  time_since_restore: 864.5792665481567
  time_this_iter_s: 5.530946969985962
  time_total_s: 864.5792665481567
  timestamp: 1594146357
  timesteps_since_restore: 170000
  timesteps_this_iter: 1000
  timesteps_total: 170000
  training_iteration: 97
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 27.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10879], 864 s, 97 iter, 170000 ts, 365 rew

agent-1: 365.0
Sum Reward: 365.0
Avg Reward: 365.0
Min Reward: 365.0
Max Reward: 365.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_14-26-03
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 463.0
  episode_reward_mean: 365.47
  episode_reward_min: 217.0
  episodes_this_iter: 1
  episodes_total: 170
  experiment_id: cb3a18e0a26e466496590bc0542b68c4
  hostname: gpu020
  info:
    apply_time_ms: 2.664
    dispatch_time_ms: 46.404
    learner:
      cur_lr: 0.0013486780226230621
      grad_gnorm: 26.693702697753906
      policy_entropy: 2.507193088531494
      policy_loss: -1.5637327432632446
      var_gnorm: 27.07382583618164
      vf_explained_var: 0.06436628103256226
      vf_loss: 6.870447635650635
    num_steps_sampled: 171000
    num_steps_trained: 171000
    wait_time_ms: 12.341
  iterations_since_restore: 98
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 10879
  policy_reward_mean: {}
  time_since_restore: 870.5194201469421
  time_this_iter_s: 5.9401535987854
  time_total_s: 870.5194201469421
  timestamp: 1594146363
  timesteps_since_restore: 171000
  timesteps_this_iter: 1000
  timesteps_total: 171000
  training_iteration: 98
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 27.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10879], 870 s, 98 iter, 171000 ts, 365 rew

agent-1: 337.0
Sum Reward: 337.0
Avg Reward: 337.0
Min Reward: 337.0
Max Reward: 337.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_14-26-09
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 463.0
  episode_reward_mean: 365.14
  episode_reward_min: 217.0
  episodes_this_iter: 1
  episodes_total: 171
  experiment_id: cb3a18e0a26e466496590bc0542b68c4
  hostname: gpu020
  info:
    apply_time_ms: 3.474
    dispatch_time_ms: 30.247
    learner:
      cur_lr: 0.0013486114330589771
      grad_gnorm: 7.270928382873535
      policy_entropy: 1.2541712522506714
      policy_loss: 0.07565070688724518
      var_gnorm: 27.097307205200195
      vf_explained_var: 1.1920928955078125e-07
      vf_loss: 0.809603214263916
    num_steps_sampled: 172000
    num_steps_trained: 172000
    wait_time_ms: 27.907
  iterations_since_restore: 99
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 10879
  policy_reward_mean: {}
  time_since_restore: 876.2319695949554
  time_this_iter_s: 5.712549448013306
  time_total_s: 876.2319695949554
  timestamp: 1594146369
  timesteps_since_restore: 172000
  timesteps_this_iter: 1000
  timesteps_total: 172000
  training_iteration: 99
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 27.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10879], 876 s, 99 iter, 172000 ts, 365 rew

agent-1: 382.0
Sum Reward: 382.0
Avg Reward: 382.0
Min Reward: 382.0
Max Reward: 382.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_14-26-15
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 463.0
  episode_reward_mean: 365.33
  episode_reward_min: 217.0
  episodes_this_iter: 1
  episodes_total: 172
  experiment_id: cb3a18e0a26e466496590bc0542b68c4
  hostname: gpu020
  info:
    apply_time_ms: 3.356
    dispatch_time_ms: 37.487
    learner:
      cur_lr: 0.0013485448434948921
      grad_gnorm: 40.0
      policy_entropy: 1.841345191001892
      policy_loss: 2.512906312942505
      var_gnorm: 27.109724044799805
      vf_explained_var: -0.2989816665649414
      vf_loss: 16.159669876098633
    num_steps_sampled: 173000
    num_steps_trained: 173000
    wait_time_ms: 14.048
  iterations_since_restore: 100
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 10879
  policy_reward_mean: {}
  time_since_restore: 881.7633152008057
  time_this_iter_s: 5.53134560585022
  time_total_s: 881.7633152008057
  timestamp: 1594146375
  timesteps_since_restore: 173000
  timesteps_this_iter: 1000
  timesteps_total: 173000
  training_iteration: 100
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 27.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10879], 881 s, 100 iter, 173000 ts, 365 rew

agent-1: 357.0
Sum Reward: 357.0
Avg Reward: 357.0
Min Reward: 357.0
Max Reward: 357.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_14-26-20
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 463.0
  episode_reward_mean: 365.62
  episode_reward_min: 217.0
  episodes_this_iter: 1
  episodes_total: 173
  experiment_id: cb3a18e0a26e466496590bc0542b68c4
  hostname: gpu020
  info:
    apply_time_ms: 3.227
    dispatch_time_ms: 28.126
    learner:
      cur_lr: 0.0013484782539308071
      grad_gnorm: 12.67458438873291
      policy_entropy: 4.095931053161621
      policy_loss: -1.0081512928009033
      var_gnorm: 27.16004753112793
      vf_explained_var: 0.4483500123023987
      vf_loss: 2.1995809078216553
    num_steps_sampled: 174000
    num_steps_trained: 174000
    wait_time_ms: 11.626
  iterations_since_restore: 101
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 10879
  policy_reward_mean: {}
  time_since_restore: 887.1924464702606
  time_this_iter_s: 5.429131269454956
  time_total_s: 887.1924464702606
  timestamp: 1594146380
  timesteps_since_restore: 174000
  timesteps_this_iter: 1000
  timesteps_total: 174000
  training_iteration: 101
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 27.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10879], 887 s, 101 iter, 174000 ts, 366 rew

agent-1: 383.0
Sum Reward: 383.0
Avg Reward: 383.0
Min Reward: 383.0
Max Reward: 383.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_14-26-26
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 463.0
  episode_reward_mean: 366.04
  episode_reward_min: 217.0
  episodes_this_iter: 1
  episodes_total: 174
  experiment_id: cb3a18e0a26e466496590bc0542b68c4
  hostname: gpu020
  info:
    apply_time_ms: 2.458
    dispatch_time_ms: 52.028
    learner:
      cur_lr: 0.0013484115479514003
      grad_gnorm: 31.079273223876953
      policy_entropy: 1.5097347497940063
      policy_loss: 0.5115097761154175
      var_gnorm: 27.168134689331055
      vf_explained_var: -0.4109816551208496
      vf_loss: 7.421755790710449
    num_steps_sampled: 175000
    num_steps_trained: 175000
    wait_time_ms: 22.782
  iterations_since_restore: 102
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 10879
  policy_reward_mean: {}
  time_since_restore: 892.9950799942017
  time_this_iter_s: 5.80263352394104
  time_total_s: 892.9950799942017
  timestamp: 1594146386
  timesteps_since_restore: 175000
  timesteps_this_iter: 1000
  timesteps_total: 175000
  training_iteration: 102
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 27.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10879], 892 s, 102 iter, 175000 ts, 366 rew

agent-1: 380.0
Sum Reward: 380.0
Avg Reward: 380.0
Min Reward: 380.0
Max Reward: 380.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_14-26-31
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 463.0
  episode_reward_mean: 365.72
  episode_reward_min: 217.0
  episodes_this_iter: 1
  episodes_total: 175
  experiment_id: cb3a18e0a26e466496590bc0542b68c4
  hostname: gpu020
  info:
    apply_time_ms: 2.24
    dispatch_time_ms: 30.987
    learner:
      cur_lr: 0.0013483449583873153
      grad_gnorm: 13.862261772155762
      policy_entropy: 3.60611629486084
      policy_loss: -0.7399011850357056
      var_gnorm: 27.178802490234375
      vf_explained_var: 0.3623075485229492
      vf_loss: 2.7670681476593018
    num_steps_sampled: 176000
    num_steps_trained: 176000
    wait_time_ms: 29.706
  iterations_since_restore: 103
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 10879
  policy_reward_mean: {}
  time_since_restore: 898.4389235973358
  time_this_iter_s: 5.443843603134155
  time_total_s: 898.4389235973358
  timestamp: 1594146391
  timesteps_since_restore: 176000
  timesteps_this_iter: 1000
  timesteps_total: 176000
  training_iteration: 103
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 27.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10879], 898 s, 103 iter, 176000 ts, 366 rew

agent-1: 309.0
Sum Reward: 309.0
Avg Reward: 309.0
Min Reward: 309.0
Max Reward: 309.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_14-26-38
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 463.0
  episode_reward_mean: 365.16
  episode_reward_min: 217.0
  episodes_this_iter: 1
  episodes_total: 176
  experiment_id: cb3a18e0a26e466496590bc0542b68c4
  hostname: gpu020
  info:
    apply_time_ms: 2.58
    dispatch_time_ms: 42.114
    learner:
      cur_lr: 0.0013482783688232303
      grad_gnorm: 25.59121322631836
      policy_entropy: 0.6458784937858582
      policy_loss: -0.4127069115638733
      var_gnorm: 27.213685989379883
      vf_explained_var: 0.28848135471343994
      vf_loss: 5.487059593200684
    num_steps_sampled: 177000
    num_steps_trained: 177000
    wait_time_ms: 24.497
  iterations_since_restore: 104
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 10879
  policy_reward_mean: {}
  time_since_restore: 904.6269793510437
  time_this_iter_s: 6.188055753707886
  time_total_s: 904.6269793510437
  timestamp: 1594146398
  timesteps_since_restore: 177000
  timesteps_this_iter: 1000
  timesteps_total: 177000
  training_iteration: 104
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 27.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10879], 904 s, 104 iter, 177000 ts, 365 rew

agent-1: 332.0
Sum Reward: 332.0
Avg Reward: 332.0
Min Reward: 332.0
Max Reward: 332.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_14-26-43
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 463.0
  episode_reward_mean: 364.86
  episode_reward_min: 217.0
  episodes_this_iter: 1
  episodes_total: 177
  experiment_id: cb3a18e0a26e466496590bc0542b68c4
  hostname: gpu020
  info:
    apply_time_ms: 3.916
    dispatch_time_ms: 31.769
    learner:
      cur_lr: 0.0013482117792591453
      grad_gnorm: 40.0
      policy_entropy: 0.4095781147480011
      policy_loss: 0.09359526634216309
      var_gnorm: 27.226585388183594
      vf_explained_var: 0.0
      vf_loss: 11.303130149841309
    num_steps_sampled: 178000
    num_steps_trained: 178000
    wait_time_ms: 23.259
  iterations_since_restore: 105
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 10879
  policy_reward_mean: {}
  time_since_restore: 909.995810508728
  time_this_iter_s: 5.368831157684326
  time_total_s: 909.995810508728
  timestamp: 1594146403
  timesteps_since_restore: 178000
  timesteps_this_iter: 1000
  timesteps_total: 178000
  training_iteration: 105
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 27.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10879], 909 s, 105 iter, 178000 ts, 365 rew

agent-1: 337.0
Sum Reward: 337.0
Avg Reward: 337.0
Min Reward: 337.0
Max Reward: 337.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_14-26-49
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 463.0
  episode_reward_mean: 364.84
  episode_reward_min: 217.0
  episodes_this_iter: 1
  episodes_total: 178
  experiment_id: cb3a18e0a26e466496590bc0542b68c4
  hostname: gpu020
  info:
    apply_time_ms: 2.454
    dispatch_time_ms: 26.014
    learner:
      cur_lr: 0.0013481451896950603
      grad_gnorm: 40.0
      policy_entropy: 1.2661092281341553
      policy_loss: -1.6177706718444824
      var_gnorm: 27.210514068603516
      vf_explained_var: 0.5289560556411743
      vf_loss: 15.622496604919434
    num_steps_sampled: 179000
    num_steps_trained: 179000
    wait_time_ms: 24.875
  iterations_since_restore: 106
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 10879
  policy_reward_mean: {}
  time_since_restore: 915.8105537891388
  time_this_iter_s: 5.814743280410767
  time_total_s: 915.8105537891388
  timestamp: 1594146409
  timesteps_since_restore: 179000
  timesteps_this_iter: 1000
  timesteps_total: 179000
  training_iteration: 106
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 27.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10879], 915 s, 106 iter, 179000 ts, 365 rew

agent-1: 358.0
Sum Reward: 358.0
Avg Reward: 358.0
Min Reward: 358.0
Max Reward: 358.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_14-26-54
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 463.0
  episode_reward_mean: 364.65
  episode_reward_min: 217.0
  episodes_this_iter: 1
  episodes_total: 179
  experiment_id: cb3a18e0a26e466496590bc0542b68c4
  hostname: gpu020
  info:
    apply_time_ms: 3.567
    dispatch_time_ms: 29.595
    learner:
      cur_lr: 0.0013480786001309752
      grad_gnorm: 31.9869327545166
      policy_entropy: 3.0635955333709717
      policy_loss: -1.4432973861694336
      var_gnorm: 27.245311737060547
      vf_explained_var: -0.7404049634933472
      vf_loss: 8.75495433807373
    num_steps_sampled: 180000
    num_steps_trained: 180000
    wait_time_ms: 16.641
  iterations_since_restore: 107
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 10879
  policy_reward_mean: {}
  time_since_restore: 921.3374016284943
  time_this_iter_s: 5.526847839355469
  time_total_s: 921.3374016284943
  timestamp: 1594146414
  timesteps_since_restore: 180000
  timesteps_this_iter: 1000
  timesteps_total: 180000
  training_iteration: 107
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 27.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10879], 921 s, 107 iter, 180000 ts, 365 rew

agent-1: 258.0
Sum Reward: 258.0
Avg Reward: 258.0
Min Reward: 258.0
Max Reward: 258.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_14-27-00
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 463.0
  episode_reward_mean: 363.28
  episode_reward_min: 217.0
  episodes_this_iter: 1
  episodes_total: 180
  experiment_id: cb3a18e0a26e466496590bc0542b68c4
  hostname: gpu020
  info:
    apply_time_ms: 3.846
    dispatch_time_ms: 37.66
    learner:
      cur_lr: 0.0013480120105668902
      grad_gnorm: 26.59046745300293
      policy_entropy: 0.09427550435066223
      policy_loss: -0.0193471722304821
      var_gnorm: 27.172100067138672
      vf_explained_var: 0.0
      vf_loss: 7.139562606811523
    num_steps_sampled: 181000
    num_steps_trained: 181000
    wait_time_ms: 15.791
  iterations_since_restore: 108
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 10879
  policy_reward_mean: {}
  time_since_restore: 927.1147835254669
  time_this_iter_s: 5.777381896972656
  time_total_s: 927.1147835254669
  timestamp: 1594146420
  timesteps_since_restore: 181000
  timesteps_this_iter: 1000
  timesteps_total: 181000
  training_iteration: 108
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 27.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10879], 927 s, 108 iter, 181000 ts, 363 rew

agent-1: 188.0
Sum Reward: 188.0
Avg Reward: 188.0
Min Reward: 188.0
Max Reward: 188.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_14-27-13
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 463.0
  episode_reward_mean: 361.77
  episode_reward_min: 188.0
  episodes_this_iter: 1
  episodes_total: 181
  experiment_id: cb3a18e0a26e466496590bc0542b68c4
  hostname: gpu020
  info:
    apply_time_ms: 3.112
    dispatch_time_ms: 22.399
    learner:
      cur_lr: 0.0013479454210028052
      grad_gnorm: 26.806716918945312
      policy_entropy: 0.11713020503520966
      policy_loss: -0.02487638220191002
      var_gnorm: 27.033428192138672
      vf_explained_var: -0.015824437141418457
      vf_loss: 6.0447540283203125
    num_steps_sampled: 182000
    num_steps_trained: 182000
    wait_time_ms: 20.352
  iterations_since_restore: 109
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 10879
  policy_reward_mean: {}
  time_since_restore: 940.1027052402496
  time_this_iter_s: 12.987921714782715
  time_total_s: 940.1027052402496
  timestamp: 1594146433
  timesteps_since_restore: 182000
  timesteps_this_iter: 1000
  timesteps_total: 182000
  training_iteration: 109
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10879], 940 s, 109 iter, 182000 ts, 362 rew

agent-1: 0.0
Sum Reward: 0.0
Avg Reward: 0.0
Min Reward: 0.0
Max Reward: 0.0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_14-27-19
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 463.0
  episode_reward_mean: 358.56
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 182
  experiment_id: cb3a18e0a26e466496590bc0542b68c4
  hostname: gpu020
  info:
    apply_time_ms: 2.933
    dispatch_time_ms: 36.59
    learner:
      cur_lr: 0.0013478788314387202
      grad_gnorm: 22.18093490600586
      policy_entropy: 0.1338277906179428
      policy_loss: -0.021579865366220474
      var_gnorm: 26.941247940063477
      vf_explained_var: -0.03929257392883301
      vf_loss: 4.095154285430908
    num_steps_sampled: 183000
    num_steps_trained: 183000
    wait_time_ms: 21.682
  iterations_since_restore: 110
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 10879
  policy_reward_mean: {}
  time_since_restore: 945.7784385681152
  time_this_iter_s: 5.675733327865601
  time_total_s: 945.7784385681152
  timestamp: 1594146439
  timesteps_since_restore: 183000
  timesteps_this_iter: 1000
  timesteps_total: 183000
  training_iteration: 110
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10879], 945 s, 110 iter, 183000 ts, 359 rew

agent-1: 1.0
Sum Reward: 1.0
Avg Reward: 1.0
Min Reward: 1.0
Max Reward: 1.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_14-27-25
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 463.0
  episode_reward_mean: 354.98
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 183
  experiment_id: cb3a18e0a26e466496590bc0542b68c4
  hostname: gpu020
  info:
    apply_time_ms: 2.753
    dispatch_time_ms: 45.946
    learner:
      cur_lr: 0.0013478122418746352
      grad_gnorm: 31.419301986694336
      policy_entropy: 0.07989601045846939
      policy_loss: -0.01773891970515251
      var_gnorm: 26.881418228149414
      vf_explained_var: -0.4947082996368408
      vf_loss: 6.470362663269043
    num_steps_sampled: 184000
    num_steps_trained: 184000
    wait_time_ms: 34.856
  iterations_since_restore: 111
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 10879
  policy_reward_mean: {}
  time_since_restore: 951.5788824558258
  time_this_iter_s: 5.800443887710571
  time_total_s: 951.5788824558258
  timestamp: 1594146445
  timesteps_since_restore: 184000
  timesteps_this_iter: 1000
  timesteps_total: 184000
  training_iteration: 111
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10879], 951 s, 111 iter, 184000 ts, 355 rew

agent-1: 0.0
Sum Reward: 0.0
Avg Reward: 0.0
Min Reward: 0.0
Max Reward: 0.0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_14-27-30
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 463.0
  episode_reward_mean: 351.14
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 184
  experiment_id: cb3a18e0a26e466496590bc0542b68c4
  hostname: gpu020
  info:
    apply_time_ms: 2.562
    dispatch_time_ms: 37.095
    learner:
      cur_lr: 0.0013477456523105502
      grad_gnorm: 2.5934550762176514
      policy_entropy: 0.06247132271528244
      policy_loss: -0.00604964978992939
      var_gnorm: 26.842323303222656
      vf_explained_var: -0.7872692346572876
      vf_loss: 1.1122008562088013
    num_steps_sampled: 185000
    num_steps_trained: 185000
    wait_time_ms: 25.555
  iterations_since_restore: 112
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 10879
  policy_reward_mean: {}
  time_since_restore: 956.9385738372803
  time_this_iter_s: 5.359691381454468
  time_total_s: 956.9385738372803
  timestamp: 1594146450
  timesteps_since_restore: 185000
  timesteps_this_iter: 1000
  timesteps_total: 185000
  training_iteration: 112
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 27.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10879], 956 s, 112 iter, 185000 ts, 351 rew

agent-1: 0.0
Sum Reward: 0.0
Avg Reward: 0.0
Min Reward: 0.0
Max Reward: 0.0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_14-27-36
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 463.0
  episode_reward_mean: 347.45
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 185
  experiment_id: cb3a18e0a26e466496590bc0542b68c4
  hostname: gpu020
  info:
    apply_time_ms: 4.492
    dispatch_time_ms: 33.578
    learner:
      cur_lr: 0.0013476789463311434
      grad_gnorm: 1.072125792503357
      policy_entropy: 0.06478025764226913
      policy_loss: -0.004722123499959707
      var_gnorm: 26.81956672668457
      vf_explained_var: -1.0
      vf_loss: 0.9984465837478638
    num_steps_sampled: 186000
    num_steps_trained: 186000
    wait_time_ms: 16.448
  iterations_since_restore: 113
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 10879
  policy_reward_mean: {}
  time_since_restore: 963.1206021308899
  time_this_iter_s: 6.182028293609619
  time_total_s: 963.1206021308899
  timestamp: 1594146456
  timesteps_since_restore: 186000
  timesteps_this_iter: 1000
  timesteps_total: 186000
  training_iteration: 113
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 27.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10879], 963 s, 113 iter, 186000 ts, 347 rew

agent-1: 1.0
Sum Reward: 1.0
Avg Reward: 1.0
Min Reward: 1.0
Max Reward: 1.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_14-27-42
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 463.0
  episode_reward_mean: 343.86
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 186
  experiment_id: cb3a18e0a26e466496590bc0542b68c4
  hostname: gpu020
  info:
    apply_time_ms: 2.394
    dispatch_time_ms: 33.552
    learner:
      cur_lr: 0.0013476123567670584
      grad_gnorm: 16.952999114990234
      policy_entropy: 0.07826203852891922
      policy_loss: -0.011158042587339878
      var_gnorm: 26.807411193847656
      vf_explained_var: -1.0
      vf_loss: 2.271233558654785
    num_steps_sampled: 187000
    num_steps_trained: 187000
    wait_time_ms: 25.519
  iterations_since_restore: 114
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 10879
  policy_reward_mean: {}
  time_since_restore: 968.7965450286865
  time_this_iter_s: 5.675942897796631
  time_total_s: 968.7965450286865
  timestamp: 1594146462
  timesteps_since_restore: 187000
  timesteps_this_iter: 1000
  timesteps_total: 187000
  training_iteration: 114
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 27.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10879], 968 s, 114 iter, 187000 ts, 344 rew

agent-1: 0.0
Sum Reward: 0.0
Avg Reward: 0.0
Min Reward: 0.0
Max Reward: 0.0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_14-27-47
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 463.0
  episode_reward_mean: 340.47
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 187
  experiment_id: cb3a18e0a26e466496590bc0542b68c4
  hostname: gpu020
  info:
    apply_time_ms: 2.732
    dispatch_time_ms: 34.371
    learner:
      cur_lr: 0.0013475457672029734
      grad_gnorm: 3.315964698791504
      policy_entropy: 0.11323901265859604
      policy_loss: -0.004940221551805735
      var_gnorm: 26.804744720458984
      vf_explained_var: -0.23468470573425293
      vf_loss: 0.21647517383098602
    num_steps_sampled: 188000
    num_steps_trained: 188000
    wait_time_ms: 18.922
  iterations_since_restore: 115
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 10879
  policy_reward_mean: {}
  time_since_restore: 974.2806177139282
  time_this_iter_s: 5.484072685241699
  time_total_s: 974.2806177139282
  timestamp: 1594146467
  timesteps_since_restore: 188000
  timesteps_this_iter: 1000
  timesteps_total: 188000
  training_iteration: 115
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 27.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10879], 974 s, 115 iter, 188000 ts, 340 rew

agent-1: 0.0
Sum Reward: 0.0
Avg Reward: 0.0
Min Reward: 0.0
Max Reward: 0.0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_14-27-53
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 463.0
  episode_reward_mean: 336.7
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 188
  experiment_id: cb3a18e0a26e466496590bc0542b68c4
  hostname: gpu020
  info:
    apply_time_ms: 3.93
    dispatch_time_ms: 24.906
    learner:
      cur_lr: 0.0013474791776388884
      grad_gnorm: 1.695489764213562
      policy_entropy: 0.12870825827121735
      policy_loss: -0.004086947534233332
      var_gnorm: 26.806228637695312
      vf_explained_var: -0.1873619556427002
      vf_loss: 0.10354901850223541
    num_steps_sampled: 189000
    num_steps_trained: 189000
    wait_time_ms: 18.209
  iterations_since_restore: 116
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 10879
  policy_reward_mean: {}
  time_since_restore: 979.5792620182037
  time_this_iter_s: 5.298644304275513
  time_total_s: 979.5792620182037
  timestamp: 1594146473
  timesteps_since_restore: 189000
  timesteps_this_iter: 1000
  timesteps_total: 189000
  training_iteration: 116
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 27.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10879], 979 s, 116 iter, 189000 ts, 337 rew

agent-1: 0.0
Sum Reward: 0.0
Avg Reward: 0.0
Min Reward: 0.0
Max Reward: 0.0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_14-27-58
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 463.0
  episode_reward_mean: 333.25
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 189
  experiment_id: cb3a18e0a26e466496590bc0542b68c4
  hostname: gpu020
  info:
    apply_time_ms: 3.124
    dispatch_time_ms: 41.664
    learner:
      cur_lr: 0.0013474125880748034
      grad_gnorm: 5.912491798400879
      policy_entropy: 0.08318904042243958
      policy_loss: -0.0018752500182017684
      var_gnorm: 26.81136131286621
      vf_explained_var: -1.0
      vf_loss: 0.574468195438385
    num_steps_sampled: 190000
    num_steps_trained: 190000
    wait_time_ms: 14.662
  iterations_since_restore: 117
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 10879
  policy_reward_mean: {}
  time_since_restore: 985.2142181396484
  time_this_iter_s: 5.634956121444702
  time_total_s: 985.2142181396484
  timestamp: 1594146478
  timesteps_since_restore: 190000
  timesteps_this_iter: 1000
  timesteps_total: 190000
  training_iteration: 117
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 27.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10879], 985 s, 117 iter, 190000 ts, 333 rew

agent-1: 0.0
Sum Reward: 0.0
Avg Reward: 0.0
Min Reward: 0.0
Max Reward: 0.0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_14-28-04
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 463.0
  episode_reward_mean: 329.56
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 190
  experiment_id: cb3a18e0a26e466496590bc0542b68c4
  hostname: gpu020
  info:
    apply_time_ms: 3.085
    dispatch_time_ms: 43.899
    learner:
      cur_lr: 0.0013473459985107183
      grad_gnorm: 6.214822769165039
      policy_entropy: 0.09418255090713501
      policy_loss: -0.001536293886601925
      var_gnorm: 26.82634735107422
      vf_explained_var: -1.0
      vf_loss: 0.5162062048912048
    num_steps_sampled: 191000
    num_steps_trained: 191000
    wait_time_ms: 18.283
  iterations_since_restore: 118
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 10879
  policy_reward_mean: {}
  time_since_restore: 990.9633991718292
  time_this_iter_s: 5.749181032180786
  time_total_s: 990.9633991718292
  timestamp: 1594146484
  timesteps_since_restore: 191000
  timesteps_this_iter: 1000
  timesteps_total: 191000
  training_iteration: 118
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10879], 990 s, 118 iter, 191000 ts, 330 rew

agent-1: 0.0
Sum Reward: 0.0
Avg Reward: 0.0
Min Reward: 0.0
Max Reward: 0.0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_14-28-10
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 463.0
  episode_reward_mean: 326.39
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 191
  experiment_id: cb3a18e0a26e466496590bc0542b68c4
  hostname: gpu020
  info:
    apply_time_ms: 2.677
    dispatch_time_ms: 33.985
    learner:
      cur_lr: 0.0013472794089466333
      grad_gnorm: 7.793789863586426
      policy_entropy: 0.08928324282169342
      policy_loss: -0.0068277642130851746
      var_gnorm: 26.845735549926758
      vf_explained_var: -1.0
      vf_loss: 0.6674920916557312
    num_steps_sampled: 192000
    num_steps_trained: 192000
    wait_time_ms: 20.345
  iterations_since_restore: 119
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 10879
  policy_reward_mean: {}
  time_since_restore: 996.7217156887054
  time_this_iter_s: 5.758316516876221
  time_total_s: 996.7217156887054
  timestamp: 1594146490
  timesteps_since_restore: 192000
  timesteps_this_iter: 1000
  timesteps_total: 192000
  training_iteration: 119
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 27.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10879], 996 s, 119 iter, 192000 ts, 326 rew

agent-1: 0.0
Sum Reward: 0.0
Avg Reward: 0.0
Min Reward: 0.0
Max Reward: 0.0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_14-28-16
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 463.0
  episode_reward_mean: 323.36
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 192
  experiment_id: cb3a18e0a26e466496590bc0542b68c4
  hostname: gpu020
  info:
    apply_time_ms: 2.56
    dispatch_time_ms: 34.384
    learner:
      cur_lr: 0.0013472128193825483
      grad_gnorm: 8.828877449035645
      policy_entropy: 0.08745899796485901
      policy_loss: -0.00565662607550621
      var_gnorm: 26.849899291992188
      vf_explained_var: -1.0
      vf_loss: 0.6602376699447632
    num_steps_sampled: 193000
    num_steps_trained: 193000
    wait_time_ms: 26.85
  iterations_since_restore: 120
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 10879
  policy_reward_mean: {}
  time_since_restore: 1002.2482523918152
  time_this_iter_s: 5.526536703109741
  time_total_s: 1002.2482523918152
  timestamp: 1594146496
  timesteps_since_restore: 193000
  timesteps_this_iter: 1000
  timesteps_total: 193000
  training_iteration: 120
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 27.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10879], 1002 s, 120 iter, 193000 ts, 323 rew

agent-1: 0.0
Sum Reward: 0.0
Avg Reward: 0.0
Min Reward: 0.0
Max Reward: 0.0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_14-28-21
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 463.0
  episode_reward_mean: 320.64
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 193
  experiment_id: cb3a18e0a26e466496590bc0542b68c4
  hostname: gpu020
  info:
    apply_time_ms: 2.795
    dispatch_time_ms: 41.288
    learner:
      cur_lr: 0.0013471462298184633
      grad_gnorm: 14.803668022155762
      policy_entropy: 0.10614233464002609
      policy_loss: -0.0066221957094967365
      var_gnorm: 26.848390579223633
      vf_explained_var: -1.0
      vf_loss: 2.0171914100646973
    num_steps_sampled: 194000
    num_steps_trained: 194000
    wait_time_ms: 15.426
  iterations_since_restore: 121
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 10879
  policy_reward_mean: {}
  time_since_restore: 1007.7928223609924
  time_this_iter_s: 5.544569969177246
  time_total_s: 1007.7928223609924
  timestamp: 1594146501
  timesteps_since_restore: 194000
  timesteps_this_iter: 1000
  timesteps_total: 194000
  training_iteration: 121
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 27.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10879], 1007 s, 121 iter, 194000 ts, 321 rew

agent-1: 0.0
Sum Reward: 0.0
Avg Reward: 0.0
Min Reward: 0.0
Max Reward: 0.0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_14-28-27
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 463.0
  episode_reward_mean: 318.47
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 194
  experiment_id: cb3a18e0a26e466496590bc0542b68c4
  hostname: gpu020
  info:
    apply_time_ms: 2.552
    dispatch_time_ms: 40.187
    learner:
      cur_lr: 0.0013470796402543783
      grad_gnorm: 3.8322486877441406
      policy_entropy: 0.08156231045722961
      policy_loss: 1.0834273780346848e-06
      var_gnorm: 26.84741973876953
      vf_explained_var: -1.0
      vf_loss: 0.18952374160289764
    num_steps_sampled: 195000
    num_steps_trained: 195000
    wait_time_ms: 10.764
  iterations_since_restore: 122
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 10879
  policy_reward_mean: {}
  time_since_restore: 1013.3598864078522
  time_this_iter_s: 5.567064046859741
  time_total_s: 1013.3598864078522
  timestamp: 1594146507
  timesteps_since_restore: 195000
  timesteps_this_iter: 1000
  timesteps_total: 195000
  training_iteration: 122
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 27.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10879], 1013 s, 122 iter, 195000 ts, 318 rew

agent-1: 0.0
Sum Reward: 0.0
Avg Reward: 0.0
Min Reward: 0.0
Max Reward: 0.0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_14-28-33
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 463.0
  episode_reward_mean: 315.14
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 195
  experiment_id: cb3a18e0a26e466496590bc0542b68c4
  hostname: gpu020
  info:
    apply_time_ms: 2.617
    dispatch_time_ms: 21.85
    learner:
      cur_lr: 0.0013470130506902933
      grad_gnorm: 2.9667177200317383
      policy_entropy: 0.1812136173248291
      policy_loss: -0.003494580276310444
      var_gnorm: 26.84912872314453
      vf_explained_var: -1.0
      vf_loss: 0.13411834836006165
    num_steps_sampled: 196000
    num_steps_trained: 196000
    wait_time_ms: 13.736
  iterations_since_restore: 123
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 10879
  policy_reward_mean: {}
  time_since_restore: 1019.5193078517914
  time_this_iter_s: 6.159421443939209
  time_total_s: 1019.5193078517914
  timestamp: 1594146513
  timesteps_since_restore: 196000
  timesteps_this_iter: 1000
  timesteps_total: 196000
  training_iteration: 123
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 27.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10879], 1019 s, 123 iter, 196000 ts, 315 rew

agent-1: 0.0
Sum Reward: 0.0
Avg Reward: 0.0
Min Reward: 0.0
Max Reward: 0.0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_14-28-39
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 463.0
  episode_reward_mean: 312.58
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 196
  experiment_id: cb3a18e0a26e466496590bc0542b68c4
  hostname: gpu020
  info:
    apply_time_ms: 3.85
    dispatch_time_ms: 35.245
    learner:
      cur_lr: 0.0013469463447108865
      grad_gnorm: 0.514636218547821
      policy_entropy: 0.12663881480693817
      policy_loss: 0.00029015555628575385
      var_gnorm: 26.84939193725586
      vf_explained_var: -1.0
      vf_loss: 0.11905547231435776
    num_steps_sampled: 197000
    num_steps_trained: 197000
    wait_time_ms: 19.078
  iterations_since_restore: 124
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 10879
  policy_reward_mean: {}
  time_since_restore: 1025.2134227752686
  time_this_iter_s: 5.694114923477173
  time_total_s: 1025.2134227752686
  timestamp: 1594146519
  timesteps_since_restore: 197000
  timesteps_this_iter: 1000
  timesteps_total: 197000
  training_iteration: 124
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 27.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10879], 1025 s, 124 iter, 197000 ts, 313 rew

agent-1: 0.0
Sum Reward: 0.0
Avg Reward: 0.0
Min Reward: 0.0
Max Reward: 0.0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_14-28-44
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 463.0
  episode_reward_mean: 309.78
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 197
  experiment_id: cb3a18e0a26e466496590bc0542b68c4
  hostname: gpu020
  info:
    apply_time_ms: 2.543
    dispatch_time_ms: 46.085
    learner:
      cur_lr: 0.0013468797551468015
      grad_gnorm: 2.711452007293701
      policy_entropy: 0.20507359504699707
      policy_loss: -0.003255556570366025
      var_gnorm: 26.84891128540039
      vf_explained_var: -1.0
      vf_loss: 0.05579189956188202
    num_steps_sampled: 198000
    num_steps_trained: 198000
    wait_time_ms: 21.022
  iterations_since_restore: 125
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 10879
  policy_reward_mean: {}
  time_since_restore: 1030.8314454555511
  time_this_iter_s: 5.618022680282593
  time_total_s: 1030.8314454555511
  timestamp: 1594146524
  timesteps_since_restore: 198000
  timesteps_this_iter: 1000
  timesteps_total: 198000
  training_iteration: 125
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 27.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10879], 1030 s, 125 iter, 198000 ts, 310 rew

agent-1: 1.0
Sum Reward: 1.0
Avg Reward: 1.0
Min Reward: 1.0
Max Reward: 1.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_14-28-50
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 463.0
  episode_reward_mean: 307.33
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 198
  experiment_id: cb3a18e0a26e466496590bc0542b68c4
  hostname: gpu020
  info:
    apply_time_ms: 3.058
    dispatch_time_ms: 32.289
    learner:
      cur_lr: 0.0013468131655827165
      grad_gnorm: 5.733190536499023
      policy_entropy: 0.2508387565612793
      policy_loss: 0.0013194680213928223
      var_gnorm: 26.846647262573242
      vf_explained_var: -1.0
      vf_loss: 0.5806759595870972
    num_steps_sampled: 199000
    num_steps_trained: 199000
    wait_time_ms: 20.842
  iterations_since_restore: 126
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 10879
  policy_reward_mean: {}
  time_since_restore: 1036.3490595817566
  time_this_iter_s: 5.517614126205444
  time_total_s: 1036.3490595817566
  timestamp: 1594146530
  timesteps_since_restore: 199000
  timesteps_this_iter: 1000
  timesteps_total: 199000
  training_iteration: 126
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10879], 1036 s, 126 iter, 199000 ts, 307 rew

agent-1: 1.0
Sum Reward: 1.0
Avg Reward: 1.0
Min Reward: 1.0
Max Reward: 1.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_14-28-57
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 463.0
  episode_reward_mean: 304.75
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 199
  experiment_id: cb3a18e0a26e466496590bc0542b68c4
  hostname: gpu020
  info:
    apply_time_ms: 3.025
    dispatch_time_ms: 49.252
    learner:
      cur_lr: 0.0013467465760186315
      grad_gnorm: 3.2824366092681885
      policy_entropy: 0.19744709134101868
      policy_loss: 2.899788523791358e-05
      var_gnorm: 26.845169067382812
      vf_explained_var: -1.0
      vf_loss: 0.26454591751098633
    num_steps_sampled: 200000
    num_steps_trained: 200000
    wait_time_ms: 14.849
  iterations_since_restore: 127
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 10879
  policy_reward_mean: {}
  time_since_restore: 1042.2519772052765
  time_this_iter_s: 5.9029176235198975
  time_total_s: 1042.2519772052765
  timestamp: 1594146537
  timesteps_since_restore: 200000
  timesteps_this_iter: 1000
  timesteps_total: 200000
  training_iteration: 127
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10879], 1042 s, 127 iter, 200000 ts, 305 rew

agent-1: 2.0
Sum Reward: 2.0
Avg Reward: 2.0
Min Reward: 2.0
Max Reward: 2.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_14-29-02
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 463.0
  episode_reward_mean: 302.34
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 200
  experiment_id: cb3a18e0a26e466496590bc0542b68c4
  hostname: gpu020
  info:
    apply_time_ms: 2.886
    dispatch_time_ms: 38.747
    learner:
      cur_lr: 0.0013466799864545465
      grad_gnorm: 1.166741967201233
      policy_entropy: 0.8447470664978027
      policy_loss: 0.0026347048114985228
      var_gnorm: 26.84490966796875
      vf_explained_var: -1.0
      vf_loss: 0.008129067718982697
    num_steps_sampled: 201000
    num_steps_trained: 201000
    wait_time_ms: 15.929
  iterations_since_restore: 128
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 10879
  policy_reward_mean: {}
  time_since_restore: 1047.994967699051
  time_this_iter_s: 5.742990493774414
  time_total_s: 1047.994967699051
  timestamp: 1594146542
  timesteps_since_restore: 201000
  timesteps_this_iter: 1000
  timesteps_total: 201000
  training_iteration: 128
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10879], 1047 s, 128 iter, 201000 ts, 302 rew

agent-1: 3.0
Sum Reward: 3.0
Avg Reward: 3.0
Min Reward: 3.0
Max Reward: 3.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_14-29-09
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 463.0
  episode_reward_mean: 299.02
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 201
  experiment_id: cb3a18e0a26e466496590bc0542b68c4
  hostname: gpu020
  info:
    apply_time_ms: 3.597
    dispatch_time_ms: 40.063
    learner:
      cur_lr: 0.0013466133968904614
      grad_gnorm: 11.392468452453613
      policy_entropy: 6.146561622619629
      policy_loss: 0.36876893043518066
      var_gnorm: 26.87540626525879
      vf_explained_var: -0.5414894819259644
      vf_loss: 0.6749172806739807
    num_steps_sampled: 202000
    num_steps_trained: 202000
    wait_time_ms: 8.722
  iterations_since_restore: 129
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 10879
  policy_reward_mean: {}
  time_since_restore: 1054.0285758972168
  time_this_iter_s: 6.0336081981658936
  time_total_s: 1054.0285758972168
  timestamp: 1594146549
  timesteps_since_restore: 202000
  timesteps_this_iter: 1000
  timesteps_total: 202000
  training_iteration: 129
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10879], 1054 s, 129 iter, 202000 ts, 299 rew

agent-1: 135.0
Sum Reward: 135.0
Avg Reward: 135.0
Min Reward: 135.0
Max Reward: 135.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_14-29-14
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 463.0
  episode_reward_mean: 297.51
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 202
  experiment_id: cb3a18e0a26e466496590bc0542b68c4
  hostname: gpu020
  info:
    apply_time_ms: 2.786
    dispatch_time_ms: 42.511
    learner:
      cur_lr: 0.0013465468073263764
      grad_gnorm: 40.0
      policy_entropy: 0.6199488043785095
      policy_loss: 0.325543075799942
      var_gnorm: 26.99483871459961
      vf_explained_var: 0.0
      vf_loss: 36.70603561401367
    num_steps_sampled: 203000
    num_steps_trained: 203000
    wait_time_ms: 16.233
  iterations_since_restore: 130
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 10879
  policy_reward_mean: {}
  time_since_restore: 1059.866384267807
  time_this_iter_s: 5.83780837059021
  time_total_s: 1059.866384267807
  timestamp: 1594146554
  timesteps_since_restore: 203000
  timesteps_this_iter: 1000
  timesteps_total: 203000
  training_iteration: 130
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10879], 1059 s, 130 iter, 203000 ts, 298 rew

agent-1: 214.0
Sum Reward: 214.0
Avg Reward: 214.0
Min Reward: 214.0
Max Reward: 214.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_14-29-20
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 463.0
  episode_reward_mean: 296.21
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 203
  experiment_id: cb3a18e0a26e466496590bc0542b68c4
  hostname: gpu020
  info:
    apply_time_ms: 3.609
    dispatch_time_ms: 35.724
    learner:
      cur_lr: 0.0013464802177622914
      grad_gnorm: 19.553483963012695
      policy_entropy: 1.7585349082946777
      policy_loss: 0.5752512216567993
      var_gnorm: 27.16367530822754
      vf_explained_var: 0.0
      vf_loss: 5.2432403564453125
    num_steps_sampled: 204000
    num_steps_trained: 204000
    wait_time_ms: 18.701
  iterations_since_restore: 131
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 10879
  policy_reward_mean: {}
  time_since_restore: 1065.6003489494324
  time_this_iter_s: 5.733964681625366
  time_total_s: 1065.6003489494324
  timestamp: 1594146560
  timesteps_since_restore: 204000
  timesteps_this_iter: 1000
  timesteps_total: 204000
  training_iteration: 131
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10879], 1065 s, 131 iter, 204000 ts, 296 rew

agent-1: 369.0
Sum Reward: 369.0
Avg Reward: 369.0
Min Reward: 369.0
Max Reward: 369.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_14-29-26
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 463.0
  episode_reward_mean: 296.83
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 204
  experiment_id: cb3a18e0a26e466496590bc0542b68c4
  hostname: gpu020
  info:
    apply_time_ms: 3.125
    dispatch_time_ms: 38.708
    learner:
      cur_lr: 0.0013464136281982064
      grad_gnorm: 24.049917221069336
      policy_entropy: 1.4543009996414185
      policy_loss: 0.6695923805236816
      var_gnorm: 27.366994857788086
      vf_explained_var: 0.23486089706420898
      vf_loss: 6.371985912322998
    num_steps_sampled: 205000
    num_steps_trained: 205000
    wait_time_ms: 21.459
  iterations_since_restore: 132
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 10879
  policy_reward_mean: {}
  time_since_restore: 1071.3977587223053
  time_this_iter_s: 5.797409772872925
  time_total_s: 1071.3977587223053
  timestamp: 1594146566
  timesteps_since_restore: 205000
  timesteps_this_iter: 1000
  timesteps_total: 205000
  training_iteration: 132
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10879], 1071 s, 132 iter, 205000 ts, 297 rew

agent-1: 361.0
Sum Reward: 361.0
Avg Reward: 361.0
Min Reward: 361.0
Max Reward: 361.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_14-29-32
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 463.0
  episode_reward_mean: 296.54
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 205
  experiment_id: cb3a18e0a26e466496590bc0542b68c4
  hostname: gpu020
  info:
    apply_time_ms: 2.826
    dispatch_time_ms: 29.825
    learner:
      cur_lr: 0.0013463470386341214
      grad_gnorm: 12.78770923614502
      policy_entropy: 2.055962324142456
      policy_loss: 0.5272946357727051
      var_gnorm: 27.48989486694336
      vf_explained_var: -0.9410699605941772
      vf_loss: 3.6902341842651367
    num_steps_sampled: 206000
    num_steps_trained: 206000
    wait_time_ms: 19.538
  iterations_since_restore: 133
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 10879
  policy_reward_mean: {}
  time_since_restore: 1076.974693775177
  time_this_iter_s: 5.576935052871704
  time_total_s: 1076.974693775177
  timestamp: 1594146572
  timesteps_since_restore: 206000
  timesteps_this_iter: 1000
  timesteps_total: 206000
  training_iteration: 133
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10879], 1076 s, 133 iter, 206000 ts, 297 rew

agent-1: 323.0
Sum Reward: 323.0
Avg Reward: 323.0
Min Reward: 323.0
Max Reward: 323.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_14-29-38
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 463.0
  episode_reward_mean: 295.77
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 206
  experiment_id: cb3a18e0a26e466496590bc0542b68c4
  hostname: gpu020
  info:
    apply_time_ms: 2.65
    dispatch_time_ms: 45.11
    learner:
      cur_lr: 0.0013462804490700364
      grad_gnorm: 6.001796245574951
      policy_entropy: 2.4983386993408203
      policy_loss: 0.031754761934280396
      var_gnorm: 27.58692169189453
      vf_explained_var: 0.0
      vf_loss: 12.483490943908691
    num_steps_sampled: 207000
    num_steps_trained: 207000
    wait_time_ms: 20.543
  iterations_since_restore: 134
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 10879
  policy_reward_mean: {}
  time_since_restore: 1083.5549466609955
  time_this_iter_s: 6.5802528858184814
  time_total_s: 1083.5549466609955
  timestamp: 1594146578
  timesteps_since_restore: 207000
  timesteps_this_iter: 1000
  timesteps_total: 207000
  training_iteration: 134
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10879], 1083 s, 134 iter, 207000 ts, 296 rew

agent-1: 320.0
Sum Reward: 320.0
Avg Reward: 320.0
Min Reward: 320.0
Max Reward: 320.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_14-29-44
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 463.0
  episode_reward_mean: 294.75
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 207
  experiment_id: cb3a18e0a26e466496590bc0542b68c4
  hostname: gpu020
  info:
    apply_time_ms: 3.478
    dispatch_time_ms: 31.46
    learner:
      cur_lr: 0.0013462137430906296
      grad_gnorm: 8.877618789672852
      policy_entropy: 1.5690830945968628
      policy_loss: 0.1024656817317009
      var_gnorm: 27.714326858520508
      vf_explained_var: -1.0
      vf_loss: 2.483358383178711
    num_steps_sampled: 208000
    num_steps_trained: 208000
    wait_time_ms: 23.955
  iterations_since_restore: 135
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 10879
  policy_reward_mean: {}
  time_since_restore: 1089.2949340343475
  time_this_iter_s: 5.739987373352051
  time_total_s: 1089.2949340343475
  timestamp: 1594146584
  timesteps_since_restore: 208000
  timesteps_this_iter: 1000
  timesteps_total: 208000
  training_iteration: 135
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10879], 1089 s, 135 iter, 208000 ts, 295 rew

agent-1: 367.0
Sum Reward: 367.0
Avg Reward: 367.0
Min Reward: 367.0
Max Reward: 367.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_14-29-50
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 463.0
  episode_reward_mean: 294.76
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 208
  experiment_id: cb3a18e0a26e466496590bc0542b68c4
  hostname: gpu020
  info:
    apply_time_ms: 2.609
    dispatch_time_ms: 34.059
    learner:
      cur_lr: 0.0013461471535265446
      grad_gnorm: 13.8485689163208
      policy_entropy: 2.032888889312744
      policy_loss: 3.0470681190490723
      var_gnorm: 27.9516658782959
      vf_explained_var: -0.3185156583786011
      vf_loss: 1.7744754552841187
    num_steps_sampled: 209000
    num_steps_trained: 209000
    wait_time_ms: 18.477
  iterations_since_restore: 136
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 10879
  policy_reward_mean: {}
  time_since_restore: 1094.9316675662994
  time_this_iter_s: 5.636733531951904
  time_total_s: 1094.9316675662994
  timestamp: 1594146590
  timesteps_since_restore: 209000
  timesteps_this_iter: 1000
  timesteps_total: 209000
  training_iteration: 136
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10879], 1094 s, 136 iter, 209000 ts, 295 rew

agent-1: 329.0
Sum Reward: 329.0
Avg Reward: 329.0
Min Reward: 329.0
Max Reward: 329.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_14-29-55
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 463.0
  episode_reward_mean: 294.57
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 209
  experiment_id: cb3a18e0a26e466496590bc0542b68c4
  hostname: gpu020
  info:
    apply_time_ms: 2.751
    dispatch_time_ms: 29.766
    learner:
      cur_lr: 0.0013460805639624596
      grad_gnorm: 30.969932556152344
      policy_entropy: 4.081475257873535
      policy_loss: 2.833065986633301
      var_gnorm: 28.003311157226562
      vf_explained_var: -0.5525085926055908
      vf_loss: 8.751319885253906
    num_steps_sampled: 210000
    num_steps_trained: 210000
    wait_time_ms: 18.162
  iterations_since_restore: 137
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 10879
  policy_reward_mean: {}
  time_since_restore: 1100.6629345417023
  time_this_iter_s: 5.731266975402832
  time_total_s: 1100.6629345417023
  timestamp: 1594146595
  timesteps_since_restore: 210000
  timesteps_this_iter: 1000
  timesteps_total: 210000
  training_iteration: 137
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10879], 1100 s, 137 iter, 210000 ts, 295 rew

agent-1: 314.0
Sum Reward: 314.0
Avg Reward: 314.0
Min Reward: 314.0
Max Reward: 314.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_14-30-02
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 463.0
  episode_reward_mean: 294.01
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 210
  experiment_id: cb3a18e0a26e466496590bc0542b68c4
  hostname: gpu020
  info:
    apply_time_ms: 2.533
    dispatch_time_ms: 59.169
    learner:
      cur_lr: 0.0013460139743983746
      grad_gnorm: 40.0
      policy_entropy: 2.4562182426452637
      policy_loss: -7.691552639007568
      var_gnorm: 28.052839279174805
      vf_explained_var: 0.6197822690010071
      vf_loss: 4.941330909729004
    num_steps_sampled: 211000
    num_steps_trained: 211000
    wait_time_ms: 54.411
  iterations_since_restore: 138
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 10879
  policy_reward_mean: {}
  time_since_restore: 1107.148593902588
  time_this_iter_s: 6.48565936088562
  time_total_s: 1107.148593902588
  timestamp: 1594146602
  timesteps_since_restore: 211000
  timesteps_this_iter: 1000
  timesteps_total: 211000
  training_iteration: 138
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10879], 1107 s, 138 iter, 211000 ts, 294 rew

agent-1: 320.0
Sum Reward: 320.0
Avg Reward: 320.0
Min Reward: 320.0
Max Reward: 320.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_14-30-08
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 463.0
  episode_reward_mean: 292.96
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 211
  experiment_id: cb3a18e0a26e466496590bc0542b68c4
  hostname: gpu020
  info:
    apply_time_ms: 3.893
    dispatch_time_ms: 35.346
    learner:
      cur_lr: 0.0013459473848342896
      grad_gnorm: 13.190176963806152
      policy_entropy: 1.7239574193954468
      policy_loss: -0.29773715138435364
      var_gnorm: 28.091978073120117
      vf_explained_var: 0.30944186449050903
      vf_loss: 2.063626766204834
    num_steps_sampled: 212000
    num_steps_trained: 212000
    wait_time_ms: 15.795
  iterations_since_restore: 139
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 10879
  policy_reward_mean: {}
  time_since_restore: 1112.714968919754
  time_this_iter_s: 5.566375017166138
  time_total_s: 1112.714968919754
  timestamp: 1594146608
  timesteps_since_restore: 212000
  timesteps_this_iter: 1000
  timesteps_total: 212000
  training_iteration: 139
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10879], 1112 s, 139 iter, 212000 ts, 293 rew

agent-1: 338.0
Sum Reward: 338.0
Avg Reward: 338.0
Min Reward: 338.0
Max Reward: 338.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_14-30-14
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 463.0
  episode_reward_mean: 292.05
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 212
  experiment_id: cb3a18e0a26e466496590bc0542b68c4
  hostname: gpu020
  info:
    apply_time_ms: 3.424
    dispatch_time_ms: 44.08
    learner:
      cur_lr: 0.0013458807952702045
      grad_gnorm: 2.121778964996338
      policy_entropy: 3.8619344234466553
      policy_loss: -0.9459357857704163
      var_gnorm: 28.12750244140625
      vf_explained_var: 0.3292624354362488
      vf_loss: 0.81488037109375
    num_steps_sampled: 213000
    num_steps_trained: 213000
    wait_time_ms: 17.901
  iterations_since_restore: 140
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 10879
  policy_reward_mean: {}
  time_since_restore: 1118.9143979549408
  time_this_iter_s: 6.199429035186768
  time_total_s: 1118.9143979549408
  timestamp: 1594146614
  timesteps_since_restore: 213000
  timesteps_this_iter: 1000
  timesteps_total: 213000
  training_iteration: 140
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10879], 1118 s, 140 iter, 213000 ts, 292 rew

agent-1: 297.0
Sum Reward: 297.0
Avg Reward: 297.0
Min Reward: 297.0
Max Reward: 297.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_14-30-19
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 463.0
  episode_reward_mean: 290.64
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 213
  experiment_id: cb3a18e0a26e466496590bc0542b68c4
  hostname: gpu020
  info:
    apply_time_ms: 2.652
    dispatch_time_ms: 26.522
    learner:
      cur_lr: 0.0013458142057061195
      grad_gnorm: 12.297905921936035
      policy_entropy: 2.4477646350860596
      policy_loss: 0.3639886975288391
      var_gnorm: 28.180498123168945
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 1.709721326828003
    num_steps_sampled: 214000
    num_steps_trained: 214000
    wait_time_ms: 11.443
  iterations_since_restore: 141
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 10879
  policy_reward_mean: {}
  time_since_restore: 1124.6250472068787
  time_this_iter_s: 5.710649251937866
  time_total_s: 1124.6250472068787
  timestamp: 1594146619
  timesteps_since_restore: 214000
  timesteps_this_iter: 1000
  timesteps_total: 214000
  training_iteration: 141
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10879], 1124 s, 141 iter, 214000 ts, 291 rew

agent-1: 296.0
Sum Reward: 296.0
Avg Reward: 296.0
Min Reward: 296.0
Max Reward: 296.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_14-30-25
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 463.0
  episode_reward_mean: 289.28
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 214
  experiment_id: cb3a18e0a26e466496590bc0542b68c4
  hostname: gpu020
  info:
    apply_time_ms: 2.802
    dispatch_time_ms: 20.541
    learner:
      cur_lr: 0.0013457476161420345
      grad_gnorm: 10.139058113098145
      policy_entropy: 1.1046323776245117
      policy_loss: -0.10048515349626541
      var_gnorm: 28.22673797607422
      vf_explained_var: 0.49239832162857056
      vf_loss: 1.6094948053359985
    num_steps_sampled: 215000
    num_steps_trained: 215000
    wait_time_ms: 20.222
  iterations_since_restore: 142
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 10879
  policy_reward_mean: {}
  time_since_restore: 1130.1941244602203
  time_this_iter_s: 5.569077253341675
  time_total_s: 1130.1941244602203
  timestamp: 1594146625
  timesteps_since_restore: 215000
  timesteps_this_iter: 1000
  timesteps_total: 215000
  training_iteration: 142
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10879], 1130 s, 142 iter, 215000 ts, 289 rew

agent-1: 347.0
Sum Reward: 347.0
Avg Reward: 347.0
Min Reward: 347.0
Max Reward: 347.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
W0707 14:30:27.618378 10872 client_connection.cc:255] [worker]ProcessMessage with type 8 took 107 ms.
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_14-30-31
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 463.0
  episode_reward_mean: 288.45
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 215
  experiment_id: cb3a18e0a26e466496590bc0542b68c4
  hostname: gpu020
  info:
    apply_time_ms: 3.441
    dispatch_time_ms: 33.223
    learner:
      cur_lr: 0.0013456810265779495
      grad_gnorm: 40.0
      policy_entropy: 0.819024920463562
      policy_loss: -7.8624091148376465
      var_gnorm: 28.296064376831055
      vf_explained_var: -0.590954065322876
      vf_loss: 13.330601692199707
    num_steps_sampled: 216000
    num_steps_trained: 216000
    wait_time_ms: 14.169
  iterations_since_restore: 143
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 10879
  policy_reward_mean: {}
  time_since_restore: 1136.211627483368
  time_this_iter_s: 6.017503023147583
  time_total_s: 1136.211627483368
  timestamp: 1594146631
  timesteps_since_restore: 216000
  timesteps_this_iter: 1000
  timesteps_total: 216000
  training_iteration: 143
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10879], 1136 s, 143 iter, 216000 ts, 288 rew

agent-1: 395.0
Sum Reward: 395.0
Avg Reward: 395.0
Min Reward: 395.0
Max Reward: 395.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_14-30-44
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 463.0
  episode_reward_mean: 288.79
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 216
  experiment_id: cb3a18e0a26e466496590bc0542b68c4
  hostname: gpu020
  info:
    apply_time_ms: 2.512
    dispatch_time_ms: 27.045
    learner:
      cur_lr: 0.0013456144370138645
      grad_gnorm: 40.0
      policy_entropy: 0.6580796837806702
      policy_loss: 0.26805466413497925
      var_gnorm: 28.404146194458008
      vf_explained_var: 5.960464477539063e-08
      vf_loss: 22.693723678588867
    num_steps_sampled: 217000
    num_steps_trained: 217000
    wait_time_ms: 19.314
  iterations_since_restore: 144
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 10879
  policy_reward_mean: {}
  time_since_restore: 1149.301881313324
  time_this_iter_s: 13.090253829956055
  time_total_s: 1149.301881313324
  timestamp: 1594146644
  timesteps_since_restore: 217000
  timesteps_this_iter: 1000
  timesteps_total: 217000
  training_iteration: 144
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10879], 1149 s, 144 iter, 217000 ts, 289 rew

agent-1: 434.0
Sum Reward: 434.0
Avg Reward: 434.0
Min Reward: 434.0
Max Reward: 434.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
W0707 14:30:49.128242 10872 client_connection.cc:255] [worker]ProcessMessage with type 8 took 121 ms.
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_14-30-50
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 463.0
  episode_reward_mean: 289.15
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 217
  experiment_id: cb3a18e0a26e466496590bc0542b68c4
  hostname: gpu020
  info:
    apply_time_ms: 2.514
    dispatch_time_ms: 36.198
    learner:
      cur_lr: 0.0013455478474497795
      grad_gnorm: 40.0
      policy_entropy: 3.245664596557617
      policy_loss: -4.584563255310059
      var_gnorm: 28.484405517578125
      vf_explained_var: -1.0
      vf_loss: 14.03483772277832
    num_steps_sampled: 218000
    num_steps_trained: 218000
    wait_time_ms: 18.505
  iterations_since_restore: 145
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 10879
  policy_reward_mean: {}
  time_since_restore: 1154.807180404663
  time_this_iter_s: 5.505299091339111
  time_total_s: 1154.807180404663
  timestamp: 1594146650
  timesteps_since_restore: 218000
  timesteps_this_iter: 1000
  timesteps_total: 218000
  training_iteration: 145
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10879], 1154 s, 145 iter, 218000 ts, 289 rew

agent-1: 442.0
Sum Reward: 442.0
Avg Reward: 442.0
Min Reward: 442.0
Max Reward: 442.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_14-30-56
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 463.0
  episode_reward_mean: 289.38
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 218
  experiment_id: cb3a18e0a26e466496590bc0542b68c4
  hostname: gpu020
  info:
    apply_time_ms: 3.009
    dispatch_time_ms: 52.385
    learner:
      cur_lr: 0.0013454812578856945
      grad_gnorm: 40.0
      policy_entropy: 0.8390607833862305
      policy_loss: 0.339557945728302
      var_gnorm: 28.595321655273438
      vf_explained_var: 0.0
      vf_loss: 21.27410888671875
    num_steps_sampled: 219000
    num_steps_trained: 219000
    wait_time_ms: 14.193
  iterations_since_restore: 146
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 10879
  policy_reward_mean: {}
  time_since_restore: 1160.9954869747162
  time_this_iter_s: 6.188306570053101
  time_total_s: 1160.9954869747162
  timestamp: 1594146656
  timesteps_since_restore: 219000
  timesteps_this_iter: 1000
  timesteps_total: 219000
  training_iteration: 146
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10879], 1160 s, 146 iter, 219000 ts, 289 rew

agent-1: 384.0
Sum Reward: 384.0
Avg Reward: 384.0
Min Reward: 384.0
Max Reward: 384.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_14-31-01
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 463.0
  episode_reward_mean: 288.95
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 219
  experiment_id: cb3a18e0a26e466496590bc0542b68c4
  hostname: gpu020
  info:
    apply_time_ms: 3.728
    dispatch_time_ms: 30.48
    learner:
      cur_lr: 0.0013454145519062877
      grad_gnorm: 40.0
      policy_entropy: 0.789682149887085
      policy_loss: 0.23702645301818848
      var_gnorm: 28.662181854248047
      vf_explained_var: 0.0
      vf_loss: 10.258633613586426
    num_steps_sampled: 220000
    num_steps_trained: 220000
    wait_time_ms: 27.368
  iterations_since_restore: 147
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 10879
  policy_reward_mean: {}
  time_since_restore: 1166.0874335765839
  time_this_iter_s: 5.091946601867676
  time_total_s: 1166.0874335765839
  timestamp: 1594146661
  timesteps_since_restore: 220000
  timesteps_this_iter: 1000
  timesteps_total: 220000
  training_iteration: 147
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10879], 1166 s, 147 iter, 220000 ts, 289 rew

agent-1: 426.0
Sum Reward: 426.0
Avg Reward: 426.0
Min Reward: 426.0
Max Reward: 426.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_14-31-07
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 463.0
  episode_reward_mean: 289.4
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 220
  experiment_id: cb3a18e0a26e466496590bc0542b68c4
  hostname: gpu020
  info:
    apply_time_ms: 3.077
    dispatch_time_ms: 45.317
    learner:
      cur_lr: 0.0013453479623422027
      grad_gnorm: 40.0
      policy_entropy: 1.6352919340133667
      policy_loss: -1.36622953414917
      var_gnorm: 28.72405433654785
      vf_explained_var: -0.004663825035095215
      vf_loss: 18.392789840698242
    num_steps_sampled: 221000
    num_steps_trained: 221000
    wait_time_ms: 27.098
  iterations_since_restore: 148
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 10879
  policy_reward_mean: {}
  time_since_restore: 1171.8389377593994
  time_this_iter_s: 5.751504182815552
  time_total_s: 1171.8389377593994
  timestamp: 1594146667
  timesteps_since_restore: 221000
  timesteps_this_iter: 1000
  timesteps_total: 221000
  training_iteration: 148
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10879], 1171 s, 148 iter, 221000 ts, 289 rew

agent-1: 440.0
Sum Reward: 440.0
Avg Reward: 440.0
Min Reward: 440.0
Max Reward: 440.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_14-31-13
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 463.0
  episode_reward_mean: 290.0
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 221
  experiment_id: cb3a18e0a26e466496590bc0542b68c4
  hostname: gpu020
  info:
    apply_time_ms: 3.196
    dispatch_time_ms: 33.565
    learner:
      cur_lr: 0.0013452813727781177
      grad_gnorm: 20.122888565063477
      policy_entropy: 0.6119294762611389
      policy_loss: -0.058094147592782974
      var_gnorm: 28.7568302154541
      vf_explained_var: 0.0
      vf_loss: 3.9789226055145264
    num_steps_sampled: 222000
    num_steps_trained: 222000
    wait_time_ms: 19.952
  iterations_since_restore: 149
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 10879
  policy_reward_mean: {}
  time_since_restore: 1177.8034794330597
  time_this_iter_s: 5.964541673660278
  time_total_s: 1177.8034794330597
  timestamp: 1594146673
  timesteps_since_restore: 222000
  timesteps_this_iter: 1000
  timesteps_total: 222000
  training_iteration: 149
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10879], 1177 s, 149 iter, 222000 ts, 290 rew

agent-1: 407.0
Sum Reward: 407.0
Avg Reward: 407.0
Min Reward: 407.0
Max Reward: 407.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_14-31-19
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 463.0
  episode_reward_mean: 290.15
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 222
  experiment_id: cb3a18e0a26e466496590bc0542b68c4
  hostname: gpu020
  info:
    apply_time_ms: 2.556
    dispatch_time_ms: 37.434
    learner:
      cur_lr: 0.0013452147832140326
      grad_gnorm: 23.047758102416992
      policy_entropy: 1.382609486579895
      policy_loss: -0.4805055260658264
      var_gnorm: 28.79214859008789
      vf_explained_var: -1.0
      vf_loss: 5.47935676574707
    num_steps_sampled: 223000
    num_steps_trained: 223000
    wait_time_ms: 24.511
  iterations_since_restore: 150
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 10879
  policy_reward_mean: {}
  time_since_restore: 1183.5625517368317
  time_this_iter_s: 5.759072303771973
  time_total_s: 1183.5625517368317
  timestamp: 1594146679
  timesteps_since_restore: 223000
  timesteps_this_iter: 1000
  timesteps_total: 223000
  training_iteration: 150
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10879], 1183 s, 150 iter, 223000 ts, 290 rew

agent-1: 411.0
Sum Reward: 411.0
Avg Reward: 411.0
Min Reward: 411.0
Max Reward: 411.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_14-31-24
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 463.0
  episode_reward_mean: 290.57
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 223
  experiment_id: cb3a18e0a26e466496590bc0542b68c4
  hostname: gpu020
  info:
    apply_time_ms: 3.854
    dispatch_time_ms: 28.88
    learner:
      cur_lr: 0.0013451481936499476
      grad_gnorm: 28.27876091003418
      policy_entropy: 0.5368995666503906
      policy_loss: -0.1286991834640503
      var_gnorm: 28.783103942871094
      vf_explained_var: 0.1956697702407837
      vf_loss: 7.410438060760498
    num_steps_sampled: 224000
    num_steps_trained: 224000
    wait_time_ms: 19.792
  iterations_since_restore: 151
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 10879
  policy_reward_mean: {}
  time_since_restore: 1189.2944147586823
  time_this_iter_s: 5.731863021850586
  time_total_s: 1189.2944147586823
  timestamp: 1594146684
  timesteps_since_restore: 224000
  timesteps_this_iter: 1000
  timesteps_total: 224000
  training_iteration: 151
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10879], 1189 s, 151 iter, 224000 ts, 291 rew

agent-1: 414.0
Sum Reward: 414.0
Avg Reward: 414.0
Min Reward: 414.0
Max Reward: 414.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_14-31-30
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 463.0
  episode_reward_mean: 291.04
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 224
  experiment_id: cb3a18e0a26e466496590bc0542b68c4
  hostname: gpu020
  info:
    apply_time_ms: 2.726
    dispatch_time_ms: 21.909
    learner:
      cur_lr: 0.0013450816040858626
      grad_gnorm: 40.0
      policy_entropy: 0.5823902487754822
      policy_loss: -10.92300796508789
      var_gnorm: 28.795320510864258
      vf_explained_var: -0.25327765941619873
      vf_loss: 7.6171770095825195
    num_steps_sampled: 225000
    num_steps_trained: 225000
    wait_time_ms: 19.557
  iterations_since_restore: 152
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 10879
  policy_reward_mean: {}
  time_since_restore: 1194.8491353988647
  time_this_iter_s: 5.554720640182495
  time_total_s: 1194.8491353988647
  timestamp: 1594146690
  timesteps_since_restore: 225000
  timesteps_this_iter: 1000
  timesteps_total: 225000
  training_iteration: 152
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10879], 1194 s, 152 iter, 225000 ts, 291 rew

agent-1: 355.0
Sum Reward: 355.0
Avg Reward: 355.0
Min Reward: 355.0
Max Reward: 355.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_14-31-36
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 463.0
  episode_reward_mean: 290.99
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 225
  experiment_id: cb3a18e0a26e466496590bc0542b68c4
  hostname: gpu020
  info:
    apply_time_ms: 2.966
    dispatch_time_ms: 23.384
    learner:
      cur_lr: 0.0013450150145217776
      grad_gnorm: 13.80611515045166
      policy_entropy: 0.3309374749660492
      policy_loss: 0.03382629528641701
      var_gnorm: 28.847274780273438
      vf_explained_var: 0.31081199645996094
      vf_loss: 1.5993235111236572
    num_steps_sampled: 226000
    num_steps_trained: 226000
    wait_time_ms: 12.114
  iterations_since_restore: 153
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 10879
  policy_reward_mean: {}
  time_since_restore: 1201.1050255298615
  time_this_iter_s: 6.255890130996704
  time_total_s: 1201.1050255298615
  timestamp: 1594146696
  timesteps_since_restore: 226000
  timesteps_this_iter: 1000
  timesteps_total: 226000
  training_iteration: 153
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10879], 1201 s, 153 iter, 226000 ts, 291 rew

agent-1: 405.0
Sum Reward: 405.0
Avg Reward: 405.0
Min Reward: 405.0
Max Reward: 405.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_14-31-42
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 463.0
  episode_reward_mean: 291.53
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 226
  experiment_id: cb3a18e0a26e466496590bc0542b68c4
  hostname: gpu020
  info:
    apply_time_ms: 7.007
    dispatch_time_ms: 37.685
    learner:
      cur_lr: 0.0013449484249576926
      grad_gnorm: 21.39046287536621
      policy_entropy: 0.7415407299995422
      policy_loss: -0.18567430973052979
      var_gnorm: 28.884546279907227
      vf_explained_var: 0.10599994659423828
      vf_loss: 4.8759965896606445
    num_steps_sampled: 227000
    num_steps_trained: 227000
    wait_time_ms: 11.266
  iterations_since_restore: 154
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 10879
  policy_reward_mean: {}
  time_since_restore: 1206.3860347270966
  time_this_iter_s: 5.281009197235107
  time_total_s: 1206.3860347270966
  timestamp: 1594146702
  timesteps_since_restore: 227000
  timesteps_this_iter: 1000
  timesteps_total: 227000
  training_iteration: 154
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10879], 1206 s, 154 iter, 227000 ts, 292 rew

agent-1: 418.0
Sum Reward: 418.0
Avg Reward: 418.0
Min Reward: 418.0
Max Reward: 418.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_14-31-47
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 463.0
  episode_reward_mean: 292.68
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 227
  experiment_id: cb3a18e0a26e466496590bc0542b68c4
  hostname: gpu020
  info:
    apply_time_ms: 2.724
    dispatch_time_ms: 31.73
    learner:
      cur_lr: 0.0013448818353936076
      grad_gnorm: 29.006752014160156
      policy_entropy: 0.898591160774231
      policy_loss: -5.126669883728027
      var_gnorm: 28.940820693969727
      vf_explained_var: 0.5230801701545715
      vf_loss: 4.850193500518799
    num_steps_sampled: 228000
    num_steps_trained: 228000
    wait_time_ms: 20.323
  iterations_since_restore: 155
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 10879
  policy_reward_mean: {}
  time_since_restore: 1211.84689950943
  time_this_iter_s: 5.460864782333374
  time_total_s: 1211.84689950943
  timestamp: 1594146707
  timesteps_since_restore: 228000
  timesteps_this_iter: 1000
  timesteps_total: 228000
  training_iteration: 155
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10879], 1211 s, 155 iter, 228000 ts, 293 rew

agent-1: 430.0
Sum Reward: 430.0
Avg Reward: 430.0
Min Reward: 430.0
Max Reward: 430.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_14-31-53
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 463.0
  episode_reward_mean: 294.01
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 228
  experiment_id: cb3a18e0a26e466496590bc0542b68c4
  hostname: gpu020
  info:
    apply_time_ms: 2.789
    dispatch_time_ms: 31.728
    learner:
      cur_lr: 0.0013448152458295226
      grad_gnorm: 37.09992980957031
      policy_entropy: 1.8593645095825195
      policy_loss: 1.0678870677947998
      var_gnorm: 28.980205535888672
      vf_explained_var: 0.10247623920440674
      vf_loss: 8.251421928405762
    num_steps_sampled: 229000
    num_steps_trained: 229000
    wait_time_ms: 29.906
  iterations_since_restore: 156
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 10879
  policy_reward_mean: {}
  time_since_restore: 1217.311996459961
  time_this_iter_s: 5.465096950531006
  time_total_s: 1217.311996459961
  timestamp: 1594146713
  timesteps_since_restore: 229000
  timesteps_this_iter: 1000
  timesteps_total: 229000
  training_iteration: 156
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10879], 1217 s, 156 iter, 229000 ts, 294 rew

agent-1: 438.0
Sum Reward: 438.0
Avg Reward: 438.0
Min Reward: 438.0
Max Reward: 438.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_14-31-58
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 463.0
  episode_reward_mean: 295.32
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 229
  experiment_id: cb3a18e0a26e466496590bc0542b68c4
  hostname: gpu020
  info:
    apply_time_ms: 2.685
    dispatch_time_ms: 31.125
    learner:
      cur_lr: 0.0013447486562654376
      grad_gnorm: 40.0
      policy_entropy: 1.8149447441101074
      policy_loss: -7.896367073059082
      var_gnorm: 29.026695251464844
      vf_explained_var: 0.0
      vf_loss: 20.37676429748535
    num_steps_sampled: 230000
    num_steps_trained: 230000
    wait_time_ms: 14.098
  iterations_since_restore: 157
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 10879
  policy_reward_mean: {}
  time_since_restore: 1222.629014968872
  time_this_iter_s: 5.317018508911133
  time_total_s: 1222.629014968872
  timestamp: 1594146718
  timesteps_since_restore: 230000
  timesteps_this_iter: 1000
  timesteps_total: 230000
  training_iteration: 157
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10879], 1222 s, 157 iter, 230000 ts, 295 rew

agent-1: 422.0
Sum Reward: 422.0
Avg Reward: 422.0
Min Reward: 422.0
Max Reward: 422.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_14-32-04
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 463.0
  episode_reward_mean: 296.45
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 230
  experiment_id: cb3a18e0a26e466496590bc0542b68c4
  hostname: gpu020
  info:
    apply_time_ms: 2.521
    dispatch_time_ms: 27.64
    learner:
      cur_lr: 0.0013446819502860308
      grad_gnorm: 6.6097092628479
      policy_entropy: 0.629817008972168
      policy_loss: -0.02975476160645485
      var_gnorm: 29.069995880126953
      vf_explained_var: 0.0
      vf_loss: 1.2102513313293457
    num_steps_sampled: 231000
    num_steps_trained: 231000
    wait_time_ms: 19.401
  iterations_since_restore: 158
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 10879
  policy_reward_mean: {}
  time_since_restore: 1228.2438776493073
  time_this_iter_s: 5.614862680435181
  time_total_s: 1228.2438776493073
  timestamp: 1594146724
  timesteps_since_restore: 231000
  timesteps_this_iter: 1000
  timesteps_total: 231000
  training_iteration: 158
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10879], 1228 s, 158 iter, 231000 ts, 296 rew

agent-1: 400.0
Sum Reward: 400.0
Avg Reward: 400.0
Min Reward: 400.0
Max Reward: 400.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_14-32-09
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 463.0
  episode_reward_mean: 297.32
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 231
  experiment_id: cb3a18e0a26e466496590bc0542b68c4
  hostname: gpu020
  info:
    apply_time_ms: 3.456
    dispatch_time_ms: 28.567
    learner:
      cur_lr: 0.0013446153607219458
      grad_gnorm: 12.95848274230957
      policy_entropy: 1.0741915702819824
      policy_loss: -0.11598505824804306
      var_gnorm: 29.057157516479492
      vf_explained_var: 5.960464477539063e-08
      vf_loss: 4.359208106994629
    num_steps_sampled: 232000
    num_steps_trained: 232000
    wait_time_ms: 16.078
  iterations_since_restore: 159
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 10879
  policy_reward_mean: {}
  time_since_restore: 1233.9359426498413
  time_this_iter_s: 5.692065000534058
  time_total_s: 1233.9359426498413
  timestamp: 1594146729
  timesteps_since_restore: 232000
  timesteps_this_iter: 1000
  timesteps_total: 232000
  training_iteration: 159
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10879], 1233 s, 159 iter, 232000 ts, 297 rew

agent-1: 353.0
Sum Reward: 353.0
Avg Reward: 353.0
Min Reward: 353.0
Max Reward: 353.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_14-32-15
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 463.0
  episode_reward_mean: 297.55
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 232
  experiment_id: cb3a18e0a26e466496590bc0542b68c4
  hostname: gpu020
  info:
    apply_time_ms: 3.917
    dispatch_time_ms: 31.926
    learner:
      cur_lr: 0.0013445487711578608
      grad_gnorm: 40.000003814697266
      policy_entropy: 0.496987521648407
      policy_loss: -0.18245945870876312
      var_gnorm: 29.041107177734375
      vf_explained_var: 0.0
      vf_loss: 23.020339965820312
    num_steps_sampled: 233000
    num_steps_trained: 233000
    wait_time_ms: 18.032
  iterations_since_restore: 160
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 10879
  policy_reward_mean: {}
  time_since_restore: 1239.6040148735046
  time_this_iter_s: 5.66807222366333
  time_total_s: 1239.6040148735046
  timestamp: 1594146735
  timesteps_since_restore: 233000
  timesteps_this_iter: 1000
  timesteps_total: 233000
  training_iteration: 160
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10879], 1239 s, 160 iter, 233000 ts, 298 rew

agent-1: 358.0
Sum Reward: 358.0
Avg Reward: 358.0
Min Reward: 358.0
Max Reward: 358.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_14-32-21
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 463.0
  episode_reward_mean: 297.62
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 233
  experiment_id: cb3a18e0a26e466496590bc0542b68c4
  hostname: gpu020
  info:
    apply_time_ms: 2.742
    dispatch_time_ms: 22.928
    learner:
      cur_lr: 0.0013444821815937757
      grad_gnorm: 15.01671314239502
      policy_entropy: 0.34345316886901855
      policy_loss: -0.023342128843069077
      var_gnorm: 29.04405403137207
      vf_explained_var: 0.26292675733566284
      vf_loss: 2.955796241760254
    num_steps_sampled: 234000
    num_steps_trained: 234000
    wait_time_ms: 26.999
  iterations_since_restore: 161
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 10879
  policy_reward_mean: {}
  time_since_restore: 1245.555608034134
  time_this_iter_s: 5.9515931606292725
  time_total_s: 1245.555608034134
  timestamp: 1594146741
  timesteps_since_restore: 234000
  timesteps_this_iter: 1000
  timesteps_total: 234000
  training_iteration: 161
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10879], 1245 s, 161 iter, 234000 ts, 298 rew

agent-1: 376.0
Sum Reward: 376.0
Avg Reward: 376.0
Min Reward: 376.0
Max Reward: 376.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_14-32-27
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 463.0
  episode_reward_mean: 297.97
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 234
  experiment_id: cb3a18e0a26e466496590bc0542b68c4
  hostname: gpu020
  info:
    apply_time_ms: 2.953
    dispatch_time_ms: 48.596
    learner:
      cur_lr: 0.0013444155920296907
      grad_gnorm: 40.0
      policy_entropy: 6.942203044891357
      policy_loss: -14.027122497558594
      var_gnorm: 29.049930572509766
      vf_explained_var: 0.0
      vf_loss: 25.071197509765625
    num_steps_sampled: 235000
    num_steps_trained: 235000
    wait_time_ms: 22.542
  iterations_since_restore: 162
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 10879
  policy_reward_mean: {}
  time_since_restore: 1251.3659300804138
  time_this_iter_s: 5.810322046279907
  time_total_s: 1251.3659300804138
  timestamp: 1594146747
  timesteps_since_restore: 235000
  timesteps_this_iter: 1000
  timesteps_total: 235000
  training_iteration: 162
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10879], 1251 s, 162 iter, 235000 ts, 298 rew

agent-1: 374.0
Sum Reward: 374.0
Avg Reward: 374.0
Min Reward: 374.0
Max Reward: 374.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_14-32-33
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 463.0
  episode_reward_mean: 298.72
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 235
  experiment_id: cb3a18e0a26e466496590bc0542b68c4
  hostname: gpu020
  info:
    apply_time_ms: 3.876
    dispatch_time_ms: 44.209
    learner:
      cur_lr: 0.0013443490024656057
      grad_gnorm: 30.742080688476562
      policy_entropy: 0.03182440251111984
      policy_loss: -0.006328553427010775
      var_gnorm: 28.91970443725586
      vf_explained_var: 0.0
      vf_loss: 9.365514755249023
    num_steps_sampled: 236000
    num_steps_trained: 236000
    wait_time_ms: 14.332
  iterations_since_restore: 163
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 10879
  policy_reward_mean: {}
  time_since_restore: 1257.1599442958832
  time_this_iter_s: 5.79401421546936
  time_total_s: 1257.1599442958832
  timestamp: 1594146753
  timesteps_since_restore: 236000
  timesteps_this_iter: 1000
  timesteps_total: 236000
  training_iteration: 163
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10879], 1257 s, 163 iter, 236000 ts, 299 rew

agent-1: 67.0
Sum Reward: 67.0
Avg Reward: 67.0
Min Reward: 67.0
Max Reward: 67.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_14-32-39
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 463.0
  episode_reward_mean: 295.86
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 236
  experiment_id: cb3a18e0a26e466496590bc0542b68c4
  hostname: gpu020
  info:
    apply_time_ms: 3.443
    dispatch_time_ms: 32.642
    learner:
      cur_lr: 0.0013442824129015207
      grad_gnorm: 32.97665786743164
      policy_entropy: 0.03420037776231766
      policy_loss: -0.005928662605583668
      var_gnorm: 28.761497497558594
      vf_explained_var: 0.0
      vf_loss: 8.656900405883789
    num_steps_sampled: 237000
    num_steps_trained: 237000
    wait_time_ms: 36.825
  iterations_since_restore: 164
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 10879
  policy_reward_mean: {}
  time_since_restore: 1263.138128042221
  time_this_iter_s: 5.978183746337891
  time_total_s: 1263.138128042221
  timestamp: 1594146759
  timesteps_since_restore: 237000
  timesteps_this_iter: 1000
  timesteps_total: 237000
  training_iteration: 164
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10879], 1263 s, 164 iter, 237000 ts, 296 rew

agent-1: 15.0
Sum Reward: 15.0
Avg Reward: 15.0
Min Reward: 15.0
Max Reward: 15.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_14-32-44
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 463.0
  episode_reward_mean: 292.63
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 237
  experiment_id: cb3a18e0a26e466496590bc0542b68c4
  hostname: gpu020
  info:
    apply_time_ms: 2.742
    dispatch_time_ms: 32.211
    learner:
      cur_lr: 0.0013442158233374357
      grad_gnorm: 19.82597541809082
      policy_entropy: 0.023156307637691498
      policy_loss: -0.0029644928872585297
      var_gnorm: 28.662649154663086
      vf_explained_var: 0.0
      vf_loss: 4.038762092590332
    num_steps_sampled: 238000
    num_steps_trained: 238000
    wait_time_ms: 9.823
  iterations_since_restore: 165
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 10879
  policy_reward_mean: {}
  time_since_restore: 1268.782166481018
  time_this_iter_s: 5.644038438796997
  time_total_s: 1268.782166481018
  timestamp: 1594146764
  timesteps_since_restore: 238000
  timesteps_this_iter: 1000
  timesteps_total: 238000
  training_iteration: 165
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10879], 1268 s, 165 iter, 238000 ts, 293 rew

agent-1: 14.0
Sum Reward: 14.0
Avg Reward: 14.0
Min Reward: 14.0
Max Reward: 14.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_14-32-50
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 463.0
  episode_reward_mean: 289.16
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 238
  experiment_id: cb3a18e0a26e466496590bc0542b68c4
  hostname: gpu020
  info:
    apply_time_ms: 3.355
    dispatch_time_ms: 42.76
    learner:
      cur_lr: 0.0013441492337733507
      grad_gnorm: 17.46898651123047
      policy_entropy: 0.024132665246725082
      policy_loss: -0.0025179882068187
      var_gnorm: 28.59193992614746
      vf_explained_var: 0.0
      vf_loss: 2.9098074436187744
    num_steps_sampled: 239000
    num_steps_trained: 239000
    wait_time_ms: 17.122
  iterations_since_restore: 166
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 10879
  policy_reward_mean: {}
  time_since_restore: 1274.6877980232239
  time_this_iter_s: 5.9056315422058105
  time_total_s: 1274.6877980232239
  timestamp: 1594146770
  timesteps_since_restore: 239000
  timesteps_this_iter: 1000
  timesteps_total: 239000
  training_iteration: 166
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10879], 1274 s, 166 iter, 239000 ts, 289 rew

agent-1: 22.0
Sum Reward: 22.0
Avg Reward: 22.0
Min Reward: 22.0
Max Reward: 22.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_14-32-56
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 463.0
  episode_reward_mean: 286.1
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 239
  experiment_id: cb3a18e0a26e466496590bc0542b68c4
  hostname: gpu020
  info:
    apply_time_ms: 2.766
    dispatch_time_ms: 34.313
    learner:
      cur_lr: 0.0013440826442092657
      grad_gnorm: 11.659661293029785
      policy_entropy: 0.02767575904726982
      policy_loss: -0.00235662329941988
      var_gnorm: 28.54551124572754
      vf_explained_var: 0.0
      vf_loss: 1.5533010959625244
    num_steps_sampled: 240000
    num_steps_trained: 240000
    wait_time_ms: 18.558
  iterations_since_restore: 167
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 10879
  policy_reward_mean: {}
  time_since_restore: 1280.217532634735
  time_this_iter_s: 5.5297346115112305
  time_total_s: 1280.217532634735
  timestamp: 1594146776
  timesteps_since_restore: 240000
  timesteps_this_iter: 1000
  timesteps_total: 240000
  training_iteration: 167
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10879], 1280 s, 167 iter, 240000 ts, 286 rew

agent-1: 0.0
Sum Reward: 0.0
Avg Reward: 0.0
Min Reward: 0.0
Max Reward: 0.0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_14-33-01
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 463.0
  episode_reward_mean: 282.18
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 240
  experiment_id: cb3a18e0a26e466496590bc0542b68c4
  hostname: gpu020
  info:
    apply_time_ms: 2.691
    dispatch_time_ms: 33.977
    learner:
      cur_lr: 0.0013440160546451807
      grad_gnorm: 9.144911766052246
      policy_entropy: 0.026004742830991745
      policy_loss: -0.0017996892565861344
      var_gnorm: 28.515295028686523
      vf_explained_var: 0.0
      vf_loss: 0.9948524832725525
    num_steps_sampled: 241000
    num_steps_trained: 241000
    wait_time_ms: 28.231
  iterations_since_restore: 168
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 10879
  policy_reward_mean: {}
  time_since_restore: 1285.8346750736237
  time_this_iter_s: 5.61714243888855
  time_total_s: 1285.8346750736237
  timestamp: 1594146781
  timesteps_since_restore: 241000
  timesteps_this_iter: 1000
  timesteps_total: 241000
  training_iteration: 168
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10879], 1285 s, 168 iter, 241000 ts, 282 rew

agent-1: 0.0
Sum Reward: 0.0
Avg Reward: 0.0
Min Reward: 0.0
Max Reward: 0.0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_14-33-08
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 463.0
  episode_reward_mean: 278.49
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 241
  experiment_id: cb3a18e0a26e466496590bc0542b68c4
  hostname: gpu020
  info:
    apply_time_ms: 3.459
    dispatch_time_ms: 32.816
    learner:
      cur_lr: 0.0013439493486657739
      grad_gnorm: 8.590618133544922
      policy_entropy: 0.026807229965925217
      policy_loss: -0.0014876857167109847
      var_gnorm: 28.496047973632812
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 0.7462576627731323
    num_steps_sampled: 242000
    num_steps_trained: 242000
    wait_time_ms: 27.51
  iterations_since_restore: 169
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 10879
  policy_reward_mean: {}
  time_since_restore: 1292.148904800415
  time_this_iter_s: 6.314229726791382
  time_total_s: 1292.148904800415
  timestamp: 1594146788
  timesteps_since_restore: 242000
  timesteps_this_iter: 1000
  timesteps_total: 242000
  training_iteration: 169
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10879], 1292 s, 169 iter, 242000 ts, 278 rew

agent-1: 0.0
Sum Reward: 0.0
Avg Reward: 0.0
Min Reward: 0.0
Max Reward: 0.0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_14-33-14
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 463.0
  episode_reward_mean: 274.33
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 242
  experiment_id: cb3a18e0a26e466496590bc0542b68c4
  hostname: gpu020
  info:
    apply_time_ms: 3.362
    dispatch_time_ms: 29.341
    learner:
      cur_lr: 0.0013438827591016889
      grad_gnorm: 7.590183258056641
      policy_entropy: 0.034510403871536255
      policy_loss: -0.0016276631504297256
      var_gnorm: 28.484527587890625
      vf_explained_var: 0.0
      vf_loss: 0.5468831062316895
    num_steps_sampled: 243000
    num_steps_trained: 243000
    wait_time_ms: 29.527
  iterations_since_restore: 170
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 10879
  policy_reward_mean: {}
  time_since_restore: 1297.9949913024902
  time_this_iter_s: 5.846086502075195
  time_total_s: 1297.9949913024902
  timestamp: 1594146794
  timesteps_since_restore: 243000
  timesteps_this_iter: 1000
  timesteps_total: 243000
  training_iteration: 170
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10879], 1297 s, 170 iter, 243000 ts, 274 rew

agent-1: 12.0
Sum Reward: 12.0
Avg Reward: 12.0
Min Reward: 12.0
Max Reward: 12.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_14-33-19
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 463.0
  episode_reward_mean: 270.29
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 243
  experiment_id: cb3a18e0a26e466496590bc0542b68c4
  hostname: gpu020
  info:
    apply_time_ms: 3.408
    dispatch_time_ms: 44.466
    learner:
      cur_lr: 0.0013438161695376039
      grad_gnorm: 5.633856296539307
      policy_entropy: 0.04200328141450882
      policy_loss: -0.0016976498300209641
      var_gnorm: 28.476240158081055
      vf_explained_var: 0.0
      vf_loss: 0.31426945328712463
    num_steps_sampled: 244000
    num_steps_trained: 244000
    wait_time_ms: 13.596
  iterations_since_restore: 171
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 10879
  policy_reward_mean: {}
  time_since_restore: 1303.5861761569977
  time_this_iter_s: 5.591184854507446
  time_total_s: 1303.5861761569977
  timestamp: 1594146799
  timesteps_since_restore: 244000
  timesteps_this_iter: 1000
  timesteps_total: 244000
  training_iteration: 171
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10879], 1303 s, 171 iter, 244000 ts, 270 rew

agent-1: 5.0
Sum Reward: 5.0
Avg Reward: 5.0
Min Reward: 5.0
Max Reward: 5.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_14-33-25
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 463.0
  episode_reward_mean: 266.0
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 244
  experiment_id: cb3a18e0a26e466496590bc0542b68c4
  hostname: gpu020
  info:
    apply_time_ms: 3.045
    dispatch_time_ms: 54.302
    learner:
      cur_lr: 0.0013437495799735188
      grad_gnorm: 4.143910884857178
      policy_entropy: 0.03934085741639137
      policy_loss: -0.001189742237329483
      var_gnorm: 28.471467971801758
      vf_explained_var: 0.0
      vf_loss: 0.18615391850471497
    num_steps_sampled: 245000
    num_steps_trained: 245000
    wait_time_ms: 15.361
  iterations_since_restore: 172
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 10879
  policy_reward_mean: {}
  time_since_restore: 1309.606531381607
  time_this_iter_s: 6.020355224609375
  time_total_s: 1309.606531381607
  timestamp: 1594146805
  timesteps_since_restore: 245000
  timesteps_this_iter: 1000
  timesteps_total: 245000
  training_iteration: 172
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10879], 1309 s, 172 iter, 245000 ts, 266 rew

agent-1: 3.0
Sum Reward: 3.0
Avg Reward: 3.0
Min Reward: 3.0
Max Reward: 3.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_14-33-31
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 463.0
  episode_reward_mean: 262.03
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 245
  experiment_id: cb3a18e0a26e466496590bc0542b68c4
  hostname: gpu020
  info:
    apply_time_ms: 2.799
    dispatch_time_ms: 34.942
    learner:
      cur_lr: 0.0013436829904094338
      grad_gnorm: 3.0084023475646973
      policy_entropy: 0.03270314261317253
      policy_loss: -0.0007598701631650329
      var_gnorm: 28.46949577331543
      vf_explained_var: 0.0
      vf_loss: 0.10674025863409042
    num_steps_sampled: 246000
    num_steps_trained: 246000
    wait_time_ms: 21.551
  iterations_since_restore: 173
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 10879
  policy_reward_mean: {}
  time_since_restore: 1315.3660843372345
  time_this_iter_s: 5.759552955627441
  time_total_s: 1315.3660843372345
  timestamp: 1594146811
  timesteps_since_restore: 246000
  timesteps_this_iter: 1000
  timesteps_total: 246000
  training_iteration: 173
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10879], 1315 s, 173 iter, 246000 ts, 262 rew

agent-1: 0.0
Sum Reward: 0.0
Avg Reward: 0.0
Min Reward: 0.0
Max Reward: 0.0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_14-33-37
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 463.0
  episode_reward_mean: 257.94
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 246
  experiment_id: cb3a18e0a26e466496590bc0542b68c4
  hostname: gpu020
  info:
    apply_time_ms: 3.062
    dispatch_time_ms: 27.389
    learner:
      cur_lr: 0.0013436164008453488
      grad_gnorm: 3.2542524337768555
      policy_entropy: 0.03316609188914299
      policy_loss: -0.0006166290258988738
      var_gnorm: 28.46820831298828
      vf_explained_var: 0.0
      vf_loss: 0.09431526064872742
    num_steps_sampled: 247000
    num_steps_trained: 247000
    wait_time_ms: 28.099
  iterations_since_restore: 174
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 10879
  policy_reward_mean: {}
  time_since_restore: 1321.241425037384
  time_this_iter_s: 5.875340700149536
  time_total_s: 1321.241425037384
  timestamp: 1594146817
  timesteps_since_restore: 247000
  timesteps_this_iter: 1000
  timesteps_total: 247000
  training_iteration: 174
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10879], 1321 s, 174 iter, 247000 ts, 258 rew

agent-1: 0.0
Sum Reward: 0.0
Avg Reward: 0.0
Min Reward: 0.0
Max Reward: 0.0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_14-33-42
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 463.0
  episode_reward_mean: 253.76
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 247
  experiment_id: cb3a18e0a26e466496590bc0542b68c4
  hostname: gpu020
  info:
    apply_time_ms: 2.776
    dispatch_time_ms: 22.187
    learner:
      cur_lr: 0.0013435498112812638
      grad_gnorm: 2.3438470363616943
      policy_entropy: 0.03359862044453621
      policy_loss: -0.0005269146058708429
      var_gnorm: 28.468708038330078
      vf_explained_var: 0.0
      vf_loss: 0.05590520799160004
    num_steps_sampled: 248000
    num_steps_trained: 248000
    wait_time_ms: 24.421
  iterations_since_restore: 175
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 10879
  policy_reward_mean: {}
  time_since_restore: 1326.6872944831848
  time_this_iter_s: 5.445869445800781
  time_total_s: 1326.6872944831848
  timestamp: 1594146822
  timesteps_since_restore: 248000
  timesteps_this_iter: 1000
  timesteps_total: 248000
  training_iteration: 175
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10879], 1326 s, 175 iter, 248000 ts, 254 rew

agent-1: 5.0
Sum Reward: 5.0
Avg Reward: 5.0
Min Reward: 5.0
Max Reward: 5.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_14-33-48
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 463.0
  episode_reward_mean: 249.68
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 248
  experiment_id: cb3a18e0a26e466496590bc0542b68c4
  hostname: gpu020
  info:
    apply_time_ms: 2.721
    dispatch_time_ms: 32.128
    learner:
      cur_lr: 0.0013434832217171788
      grad_gnorm: 1.5415717363357544
      policy_entropy: 0.03405468910932541
      policy_loss: -0.0004035145102534443
      var_gnorm: 28.46822738647461
      vf_explained_var: 0.0
      vf_loss: 0.027730606496334076
    num_steps_sampled: 249000
    num_steps_trained: 249000
    wait_time_ms: 21.32
  iterations_since_restore: 176
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 10879
  policy_reward_mean: {}
  time_since_restore: 1332.4582624435425
  time_this_iter_s: 5.770967960357666
  time_total_s: 1332.4582624435425
  timestamp: 1594146828
  timesteps_since_restore: 249000
  timesteps_this_iter: 1000
  timesteps_total: 249000
  training_iteration: 176
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10879], 1332 s, 176 iter, 249000 ts, 250 rew

agent-1: 20.0
Sum Reward: 20.0
Avg Reward: 20.0
Min Reward: 20.0
Max Reward: 20.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_14-33-54
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 463.0
  episode_reward_mean: 245.32
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 249
  experiment_id: cb3a18e0a26e466496590bc0542b68c4
  hostname: gpu020
  info:
    apply_time_ms: 2.565
    dispatch_time_ms: 25.539
    learner:
      cur_lr: 0.0013434166321530938
      grad_gnorm: 0.49667635560035706
      policy_entropy: 0.0344410203397274
      policy_loss: -0.000299462815746665
      var_gnorm: 28.468156814575195
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 0.00929326843470335
    num_steps_sampled: 250000
    num_steps_trained: 250000
    wait_time_ms: 32.247
  iterations_since_restore: 177
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 10879
  policy_reward_mean: {}
  time_since_restore: 1338.224704504013
  time_this_iter_s: 5.766442060470581
  time_total_s: 1338.224704504013
  timestamp: 1594146834
  timesteps_since_restore: 250000
  timesteps_this_iter: 1000
  timesteps_total: 250000
  training_iteration: 177
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10879], 1338 s, 177 iter, 250000 ts, 245 rew

agent-1: 0.0
Sum Reward: 0.0
Avg Reward: 0.0
Min Reward: 0.0
Max Reward: 0.0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_14-34-08
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 458.0
  episode_reward_mean: 240.69
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 250
  experiment_id: cb3a18e0a26e466496590bc0542b68c4
  hostname: gpu020
  info:
    apply_time_ms: 3.563
    dispatch_time_ms: 21.642
    learner:
      cur_lr: 0.0013433500425890088
      grad_gnorm: 1.4266778230667114
      policy_entropy: 0.03469555079936981
      policy_loss: -0.00022266816813498735
      var_gnorm: 28.468294143676758
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 0.015397214330732822
    num_steps_sampled: 251000
    num_steps_trained: 251000
    wait_time_ms: 26.915
  iterations_since_restore: 178
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 10879
  policy_reward_mean: {}
  time_since_restore: 1351.7027287483215
  time_this_iter_s: 13.478024244308472
  time_total_s: 1351.7027287483215
  timestamp: 1594146848
  timesteps_since_restore: 251000
  timesteps_this_iter: 1000
  timesteps_total: 251000
  training_iteration: 178
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10879], 1351 s, 178 iter, 251000 ts, 241 rew

agent-1: 0.0
Sum Reward: 0.0
Avg Reward: 0.0
Min Reward: 0.0
Max Reward: 0.0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_14-34-13
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 458.0
  episode_reward_mean: 236.39
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 251
  experiment_id: cb3a18e0a26e466496590bc0542b68c4
  hostname: gpu020
  info:
    apply_time_ms: 4.197
    dispatch_time_ms: 40.834
    learner:
      cur_lr: 0.0013432834530249238
      grad_gnorm: 0.8481382131576538
      policy_entropy: 0.044872723519802094
      policy_loss: -0.00029192317742854357
      var_gnorm: 28.46744155883789
      vf_explained_var: 0.0
      vf_loss: 0.00805764552205801
    num_steps_sampled: 252000
    num_steps_trained: 252000
    wait_time_ms: 13.7
  iterations_since_restore: 179
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 10879
  policy_reward_mean: {}
  time_since_restore: 1357.3408184051514
  time_this_iter_s: 5.638089656829834
  time_total_s: 1357.3408184051514
  timestamp: 1594146853
  timesteps_since_restore: 252000
  timesteps_this_iter: 1000
  timesteps_total: 252000
  training_iteration: 179
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10879], 1357 s, 179 iter, 252000 ts, 236 rew

agent-1: 16.0
Sum Reward: 16.0
Avg Reward: 16.0
Min Reward: 16.0
Max Reward: 16.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_14-34-19
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 442.0
  episode_reward_mean: 231.97
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 252
  experiment_id: cb3a18e0a26e466496590bc0542b68c4
  hostname: gpu020
  info:
    apply_time_ms: 2.979
    dispatch_time_ms: 24.316
    learner:
      cur_lr: 0.001343216747045517
      grad_gnorm: 2.58823823928833
      policy_entropy: 0.05875643342733383
      policy_loss: -0.00033533546957187355
      var_gnorm: 28.466564178466797
      vf_explained_var: 0.0
      vf_loss: 0.039406269788742065
    num_steps_sampled: 253000
    num_steps_trained: 253000
    wait_time_ms: 29.66
  iterations_since_restore: 180
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 10879
  policy_reward_mean: {}
  time_since_restore: 1363.2688763141632
  time_this_iter_s: 5.928057909011841
  time_total_s: 1363.2688763141632
  timestamp: 1594146859
  timesteps_since_restore: 253000
  timesteps_this_iter: 1000
  timesteps_total: 253000
  training_iteration: 180
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10879], 1363 s, 180 iter, 253000 ts, 232 rew

agent-1: 6.0
Sum Reward: 6.0
Avg Reward: 6.0
Min Reward: 6.0
Max Reward: 6.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_14-34-25
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 442.0
  episode_reward_mean: 227.69
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 253
  experiment_id: cb3a18e0a26e466496590bc0542b68c4
  hostname: gpu020
  info:
    apply_time_ms: 4.062
    dispatch_time_ms: 38.194
    learner:
      cur_lr: 0.001343150157481432
      grad_gnorm: 0.4089621603488922
      policy_entropy: 0.05941157042980194
      policy_loss: -0.0002572016092017293
      var_gnorm: 28.466665267944336
      vf_explained_var: 0.0
      vf_loss: 0.002607263159006834
    num_steps_sampled: 254000
    num_steps_trained: 254000
    wait_time_ms: 11.108
  iterations_since_restore: 181
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 10879
  policy_reward_mean: {}
  time_since_restore: 1368.7210586071014
  time_this_iter_s: 5.452182292938232
  time_total_s: 1368.7210586071014
  timestamp: 1594146865
  timesteps_since_restore: 254000
  timesteps_this_iter: 1000
  timesteps_total: 254000
  training_iteration: 181
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10879], 1368 s, 181 iter, 254000 ts, 228 rew

agent-1: 5.0
Sum Reward: 5.0
Avg Reward: 5.0
Min Reward: 5.0
Max Reward: 5.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_14-34-30
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 442.0
  episode_reward_mean: 223.49
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 254
  experiment_id: cb3a18e0a26e466496590bc0542b68c4
  hostname: gpu020
  info:
    apply_time_ms: 3.91
    dispatch_time_ms: 58.338
    learner:
      cur_lr: 0.001343083567917347
      grad_gnorm: 8.412936210632324
      policy_entropy: 0.059125304222106934
      policy_loss: -0.00019236562366131693
      var_gnorm: 28.46647071838379
      vf_explained_var: 0.0
      vf_loss: 0.38603293895721436
    num_steps_sampled: 255000
    num_steps_trained: 255000
    wait_time_ms: 14.551
  iterations_since_restore: 182
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 10879
  policy_reward_mean: {}
  time_since_restore: 1374.4559216499329
  time_this_iter_s: 5.734863042831421
  time_total_s: 1374.4559216499329
  timestamp: 1594146870
  timesteps_since_restore: 255000
  timesteps_this_iter: 1000
  timesteps_total: 255000
  training_iteration: 182
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10879], 1374 s, 182 iter, 255000 ts, 223 rew

agent-1: 12.0
Sum Reward: 12.0
Avg Reward: 12.0
Min Reward: 12.0
Max Reward: 12.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_14-34-37
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 442.0
  episode_reward_mean: 219.71
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 255
  experiment_id: cb3a18e0a26e466496590bc0542b68c4
  hostname: gpu020
  info:
    apply_time_ms: 2.825
    dispatch_time_ms: 54.268
    learner:
      cur_lr: 0.001343016978353262
      grad_gnorm: 0.44528287649154663
      policy_entropy: 0.059291813522577286
      policy_loss: -0.00023060321109369397
      var_gnorm: 28.467844009399414
      vf_explained_var: 0.0
      vf_loss: 0.0024495557881891727
    num_steps_sampled: 256000
    num_steps_trained: 256000
    wait_time_ms: 27.345
  iterations_since_restore: 183
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 10879
  policy_reward_mean: {}
  time_since_restore: 1380.7915766239166
  time_this_iter_s: 6.335654973983765
  time_total_s: 1380.7915766239166
  timestamp: 1594146877
  timesteps_since_restore: 256000
  timesteps_this_iter: 1000
  timesteps_total: 256000
  training_iteration: 183
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10879], 1380 s, 183 iter, 256000 ts, 220 rew

agent-1: 0.0
Sum Reward: 0.0
Avg Reward: 0.0
Min Reward: 0.0
Max Reward: 0.0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_14-34-42
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 442.0
  episode_reward_mean: 215.99
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 256
  experiment_id: cb3a18e0a26e466496590bc0542b68c4
  hostname: gpu020
  info:
    apply_time_ms: 3.678
    dispatch_time_ms: 37.601
    learner:
      cur_lr: 0.001342950388789177
      grad_gnorm: 0.024305744096636772
      policy_entropy: 0.05977610498666763
      policy_loss: -0.0001831304980441928
      var_gnorm: 28.467851638793945
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 0.0008520419360138476
    num_steps_sampled: 257000
    num_steps_trained: 257000
    wait_time_ms: 12.437
  iterations_since_restore: 184
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 10879
  policy_reward_mean: {}
  time_since_restore: 1386.5031859874725
  time_this_iter_s: 5.711609363555908
  time_total_s: 1386.5031859874725
  timestamp: 1594146882
  timesteps_since_restore: 257000
  timesteps_this_iter: 1000
  timesteps_total: 257000
  training_iteration: 184
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10879], 1386 s, 184 iter, 257000 ts, 216 rew

agent-1: 10.0
Sum Reward: 10.0
Avg Reward: 10.0
Min Reward: 10.0
Max Reward: 10.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_14-34-48
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 442.0
  episode_reward_mean: 212.08
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 257
  experiment_id: cb3a18e0a26e466496590bc0542b68c4
  hostname: gpu020
  info:
    apply_time_ms: 2.927
    dispatch_time_ms: 36.172
    learner:
      cur_lr: 0.001342883799225092
      grad_gnorm: 0.2716607451438904
      policy_entropy: 0.08557648211717606
      policy_loss: -0.00023477735521737486
      var_gnorm: 28.466691970825195
      vf_explained_var: 0.0
      vf_loss: 0.0009251199080608785
    num_steps_sampled: 258000
    num_steps_trained: 258000
    wait_time_ms: 17.407
  iterations_since_restore: 185
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 10879
  policy_reward_mean: {}
  time_since_restore: 1392.0536832809448
  time_this_iter_s: 5.55049729347229
  time_total_s: 1392.0536832809448
  timestamp: 1594146888
  timesteps_since_restore: 258000
  timesteps_this_iter: 1000
  timesteps_total: 258000
  training_iteration: 185
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10879], 1392 s, 185 iter, 258000 ts, 212 rew

agent-1: 1.0
Sum Reward: 1.0
Avg Reward: 1.0
Min Reward: 1.0
Max Reward: 1.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_14-34-54
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 442.0
  episode_reward_mean: 208.7
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 258
  experiment_id: cb3a18e0a26e466496590bc0542b68c4
  hostname: gpu020
  info:
    apply_time_ms: 2.955
    dispatch_time_ms: 42.147
    learner:
      cur_lr: 0.001342817209661007
      grad_gnorm: 0.2569188177585602
      policy_entropy: 0.08593031764030457
      policy_loss: -0.00017186033073812723
      var_gnorm: 28.4666805267334
      vf_explained_var: 0.0
      vf_loss: 0.0006844394956715405
    num_steps_sampled: 259000
    num_steps_trained: 259000
    wait_time_ms: 17.039
  iterations_since_restore: 186
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 10879
  policy_reward_mean: {}
  time_since_restore: 1397.6664288043976
  time_this_iter_s: 5.612745523452759
  time_total_s: 1397.6664288043976
  timestamp: 1594146894
  timesteps_since_restore: 259000
  timesteps_this_iter: 1000
  timesteps_total: 259000
  training_iteration: 186
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10879], 1397 s, 186 iter, 259000 ts, 209 rew

agent-1: 2.0
Sum Reward: 2.0
Avg Reward: 2.0
Min Reward: 2.0
Max Reward: 2.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_14-34-59
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 442.0
  episode_reward_mean: 205.3
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 259
  experiment_id: cb3a18e0a26e466496590bc0542b68c4
  hostname: gpu020
  info:
    apply_time_ms: 2.577
    dispatch_time_ms: 28.247
    learner:
      cur_lr: 0.001342750620096922
      grad_gnorm: 0.4067355692386627
      policy_entropy: 0.08539779484272003
      policy_loss: -0.00025850514066405594
      var_gnorm: 28.466196060180664
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 0.0016466614324599504
    num_steps_sampled: 260000
    num_steps_trained: 260000
    wait_time_ms: 18.848
  iterations_since_restore: 187
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 10879
  policy_reward_mean: {}
  time_since_restore: 1403.1620633602142
  time_this_iter_s: 5.49563455581665
  time_total_s: 1403.1620633602142
  timestamp: 1594146899
  timesteps_since_restore: 260000
  timesteps_this_iter: 1000
  timesteps_total: 260000
  training_iteration: 187
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10879], 1403 s, 187 iter, 260000 ts, 205 rew

agent-1: 5.0
Sum Reward: 5.0
Avg Reward: 5.0
Min Reward: 5.0
Max Reward: 5.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_14-35-05
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 442.0
  episode_reward_mean: 202.24
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 260
  experiment_id: cb3a18e0a26e466496590bc0542b68c4
  hostname: gpu020
  info:
    apply_time_ms: 2.631
    dispatch_time_ms: 26.102
    learner:
      cur_lr: 0.001342684030532837
      grad_gnorm: 1.0209308862686157
      policy_entropy: 0.12269555777311325
      policy_loss: -0.0008394797914661467
      var_gnorm: 28.4686222076416
      vf_explained_var: 0.0
      vf_loss: 0.00907927006483078
    num_steps_sampled: 261000
    num_steps_trained: 261000
    wait_time_ms: 27.395
  iterations_since_restore: 188
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 10879
  policy_reward_mean: {}
  time_since_restore: 1409.131713628769
  time_this_iter_s: 5.9696502685546875
  time_total_s: 1409.131713628769
  timestamp: 1594146905
  timesteps_since_restore: 261000
  timesteps_this_iter: 1000
  timesteps_total: 261000
  training_iteration: 188
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10879], 1409 s, 188 iter, 261000 ts, 202 rew

agent-1: 25.0
Sum Reward: 25.0
Avg Reward: 25.0
Min Reward: 25.0
Max Reward: 25.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_14-35-11
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 442.0
  episode_reward_mean: 199.08
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 261
  experiment_id: cb3a18e0a26e466496590bc0542b68c4
  hostname: gpu020
  info:
    apply_time_ms: 3.89
    dispatch_time_ms: 26.926
    learner:
      cur_lr: 0.001342617440968752
      grad_gnorm: 40.0
      policy_entropy: 2.022907257080078
      policy_loss: 32.014495849609375
      var_gnorm: 28.489849090576172
      vf_explained_var: -1.0
      vf_loss: 83.02851104736328
    num_steps_sampled: 262000
    num_steps_trained: 262000
    wait_time_ms: 26.01
  iterations_since_restore: 189
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 10879
  policy_reward_mean: {}
  time_since_restore: 1414.6655883789062
  time_this_iter_s: 5.533874750137329
  time_total_s: 1414.6655883789062
  timestamp: 1594146911
  timesteps_since_restore: 262000
  timesteps_this_iter: 1000
  timesteps_total: 262000
  training_iteration: 189
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10879], 1414 s, 189 iter, 262000 ts, 199 rew

agent-1: 146.0
Sum Reward: 146.0
Avg Reward: 146.0
Min Reward: 146.0
Max Reward: 146.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_14-35-16
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 442.0
  episode_reward_mean: 196.17
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 262
  experiment_id: cb3a18e0a26e466496590bc0542b68c4
  hostname: gpu020
  info:
    apply_time_ms: 3.372
    dispatch_time_ms: 46.828
    learner:
      cur_lr: 0.001342550851404667
      grad_gnorm: 8.178913116455078
      policy_entropy: 3.2439937591552734
      policy_loss: 0.563115119934082
      var_gnorm: 28.699962615966797
      vf_explained_var: 0.6496120691299438
      vf_loss: 2.300429344177246
    num_steps_sampled: 263000
    num_steps_trained: 263000
    wait_time_ms: 20.16
  iterations_since_restore: 190
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 10879
  policy_reward_mean: {}
  time_since_restore: 1420.208069562912
  time_this_iter_s: 5.542481184005737
  time_total_s: 1420.208069562912
  timestamp: 1594146916
  timesteps_since_restore: 263000
  timesteps_this_iter: 1000
  timesteps_total: 263000
  training_iteration: 190
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10879], 1420 s, 190 iter, 263000 ts, 196 rew

agent-1: 273.0
Sum Reward: 273.0
Avg Reward: 273.0
Min Reward: 273.0
Max Reward: 273.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_14-35-22
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 442.0
  episode_reward_mean: 194.71
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 263
  experiment_id: cb3a18e0a26e466496590bc0542b68c4
  hostname: gpu020
  info:
    apply_time_ms: 2.645
    dispatch_time_ms: 30.097
    learner:
      cur_lr: 0.00134248414542526
      grad_gnorm: 35.56214141845703
      policy_entropy: 1.8596347570419312
      policy_loss: 3.652240037918091
      var_gnorm: 28.871932983398438
      vf_explained_var: -0.7016992568969727
      vf_loss: 11.573124885559082
    num_steps_sampled: 264000
    num_steps_trained: 264000
    wait_time_ms: 17.592
  iterations_since_restore: 191
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 10879
  policy_reward_mean: {}
  time_since_restore: 1425.5611090660095
  time_this_iter_s: 5.353039503097534
  time_total_s: 1425.5611090660095
  timestamp: 1594146922
  timesteps_since_restore: 264000
  timesteps_this_iter: 1000
  timesteps_total: 264000
  training_iteration: 191
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10879], 1425 s, 191 iter, 264000 ts, 195 rew

agent-1: 420.0
Sum Reward: 420.0
Avg Reward: 420.0
Min Reward: 420.0
Max Reward: 420.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_14-35-28
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 442.0
  episode_reward_mean: 195.25
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 264
  experiment_id: cb3a18e0a26e466496590bc0542b68c4
  hostname: gpu020
  info:
    apply_time_ms: 2.752
    dispatch_time_ms: 76.187
    learner:
      cur_lr: 0.001342417555861175
      grad_gnorm: 11.33366584777832
      policy_entropy: 1.2423559427261353
      policy_loss: 0.3051108121871948
      var_gnorm: 29.08402442932129
      vf_explained_var: 0.09365153312683105
      vf_loss: 11.965824127197266
    num_steps_sampled: 265000
    num_steps_trained: 265000
    wait_time_ms: 13.78
  iterations_since_restore: 192
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 10879
  policy_reward_mean: {}
  time_since_restore: 1431.8452348709106
  time_this_iter_s: 6.284125804901123
  time_total_s: 1431.8452348709106
  timestamp: 1594146928
  timesteps_since_restore: 265000
  timesteps_this_iter: 1000
  timesteps_total: 265000
  training_iteration: 192
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10879], 1431 s, 192 iter, 265000 ts, 195 rew

agent-1: 436.0
Sum Reward: 436.0
Avg Reward: 436.0
Min Reward: 436.0
Max Reward: 436.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_14-35-34
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 442.0
  episode_reward_mean: 195.58
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 265
  experiment_id: cb3a18e0a26e466496590bc0542b68c4
  hostname: gpu020
  info:
    apply_time_ms: 2.561
    dispatch_time_ms: 31.517
    learner:
      cur_lr: 0.00134235096629709
      grad_gnorm: 31.131742477416992
      policy_entropy: 2.4004311561584473
      policy_loss: 0.37566331028938293
      var_gnorm: 29.196744918823242
      vf_explained_var: 0.08025217056274414
      vf_loss: 11.241533279418945
    num_steps_sampled: 266000
    num_steps_trained: 266000
    wait_time_ms: 20.538
  iterations_since_restore: 193
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 10879
  policy_reward_mean: {}
  time_since_restore: 1437.5665180683136
  time_this_iter_s: 5.721283197402954
  time_total_s: 1437.5665180683136
  timestamp: 1594146934
  timesteps_since_restore: 266000
  timesteps_this_iter: 1000
  timesteps_total: 266000
  training_iteration: 193
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10879], 1437 s, 193 iter, 266000 ts, 196 rew

agent-1: 327.0
Sum Reward: 327.0
Avg Reward: 327.0
Min Reward: 327.0
Max Reward: 327.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_14-35-40
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 442.0
  episode_reward_mean: 195.1
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 266
  experiment_id: cb3a18e0a26e466496590bc0542b68c4
  hostname: gpu020
  info:
    apply_time_ms: 3.099
    dispatch_time_ms: 35.219
    learner:
      cur_lr: 0.001342284376733005
      grad_gnorm: 28.514375686645508
      policy_entropy: 4.132757186889648
      policy_loss: -3.78402042388916
      var_gnorm: 29.296167373657227
      vf_explained_var: 0.5981096029281616
      vf_loss: 5.325915336608887
    num_steps_sampled: 267000
    num_steps_trained: 267000
    wait_time_ms: 28.01
  iterations_since_restore: 194
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 10879
  policy_reward_mean: {}
  time_since_restore: 1443.3354966640472
  time_this_iter_s: 5.768978595733643
  time_total_s: 1443.3354966640472
  timestamp: 1594146940
  timesteps_since_restore: 267000
  timesteps_this_iter: 1000
  timesteps_total: 267000
  training_iteration: 194
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10879], 1443 s, 194 iter, 267000 ts, 195 rew

agent-1: 359.0
Sum Reward: 359.0
Avg Reward: 359.0
Min Reward: 359.0
Max Reward: 359.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_14-35-45
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 442.0
  episode_reward_mean: 194.75
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 267
  experiment_id: cb3a18e0a26e466496590bc0542b68c4
  hostname: gpu020
  info:
    apply_time_ms: 3.198
    dispatch_time_ms: 38.259
    learner:
      cur_lr: 0.00134221778716892
      grad_gnorm: 9.00080394744873
      policy_entropy: 1.6806138753890991
      policy_loss: -0.025662092491984367
      var_gnorm: 29.459043502807617
      vf_explained_var: 0.3289141058921814
      vf_loss: 1.5005743503570557
    num_steps_sampled: 268000
    num_steps_trained: 268000
    wait_time_ms: 17.029
  iterations_since_restore: 195
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 10879
  policy_reward_mean: {}
  time_since_restore: 1448.8341670036316
  time_this_iter_s: 5.498670339584351
  time_total_s: 1448.8341670036316
  timestamp: 1594146945
  timesteps_since_restore: 268000
  timesteps_this_iter: 1000
  timesteps_total: 268000
  training_iteration: 195
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10879], 1448 s, 195 iter, 268000 ts, 195 rew

agent-1: 396.0
Sum Reward: 396.0
Avg Reward: 396.0
Min Reward: 396.0
Max Reward: 396.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_14-35-51
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 442.0
  episode_reward_mean: 194.4
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 268
  experiment_id: cb3a18e0a26e466496590bc0542b68c4
  hostname: gpu020
  info:
    apply_time_ms: 4.314
    dispatch_time_ms: 38.504
    learner:
      cur_lr: 0.001342151197604835
      grad_gnorm: 40.000003814697266
      policy_entropy: 1.6736640930175781
      policy_loss: -0.7689482569694519
      var_gnorm: 29.57208824157715
      vf_explained_var: -0.08983325958251953
      vf_loss: 13.645072937011719
    num_steps_sampled: 269000
    num_steps_trained: 269000
    wait_time_ms: 16.049
  iterations_since_restore: 196
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 10879
  policy_reward_mean: {}
  time_since_restore: 1454.7303779125214
  time_this_iter_s: 5.8962109088897705
  time_total_s: 1454.7303779125214
  timestamp: 1594146951
  timesteps_since_restore: 269000
  timesteps_this_iter: 1000
  timesteps_total: 269000
  training_iteration: 196
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10879], 1454 s, 196 iter, 269000 ts, 194 rew

agent-1: 436.0
Sum Reward: 436.0
Avg Reward: 436.0
Min Reward: 436.0
Max Reward: 436.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_14-35-57
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 442.0
  episode_reward_mean: 194.45
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 269
  experiment_id: cb3a18e0a26e466496590bc0542b68c4
  hostname: gpu020
  info:
    apply_time_ms: 2.74
    dispatch_time_ms: 20.416
    learner:
      cur_lr: 0.00134208460804075
      grad_gnorm: 15.326079368591309
      policy_entropy: 1.4686006307601929
      policy_loss: -2.0093178749084473
      var_gnorm: 29.638526916503906
      vf_explained_var: 0.5169444680213928
      vf_loss: 1.7777469158172607
    num_steps_sampled: 270000
    num_steps_trained: 270000
    wait_time_ms: 22.599
  iterations_since_restore: 197
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 10879
  policy_reward_mean: {}
  time_since_restore: 1460.326226234436
  time_this_iter_s: 5.595848321914673
  time_total_s: 1460.326226234436
  timestamp: 1594146957
  timesteps_since_restore: 270000
  timesteps_this_iter: 1000
  timesteps_total: 270000
  training_iteration: 197
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10879], 1460 s, 197 iter, 270000 ts, 194 rew

agent-1: 418.0
Sum Reward: 418.0
Avg Reward: 418.0
Min Reward: 418.0
Max Reward: 418.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_14-36-02
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 442.0
  episode_reward_mean: 194.98
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 270
  experiment_id: cb3a18e0a26e466496590bc0542b68c4
  hostname: gpu020
  info:
    apply_time_ms: 3.59
    dispatch_time_ms: 38.169
    learner:
      cur_lr: 0.001342018018476665
      grad_gnorm: 7.688046932220459
      policy_entropy: 2.3845014572143555
      policy_loss: 0.24433761835098267
      var_gnorm: 29.764780044555664
      vf_explained_var: -1.0
      vf_loss: 5.805334091186523
    num_steps_sampled: 271000
    num_steps_trained: 271000
    wait_time_ms: 13.069
  iterations_since_restore: 198
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 10879
  policy_reward_mean: {}
  time_since_restore: 1465.9390845298767
  time_this_iter_s: 5.612858295440674
  time_total_s: 1465.9390845298767
  timestamp: 1594146962
  timesteps_since_restore: 271000
  timesteps_this_iter: 1000
  timesteps_total: 271000
  training_iteration: 198
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10879], 1465 s, 198 iter, 271000 ts, 195 rew

agent-1: 428.0
Sum Reward: 428.0
Avg Reward: 428.0
Min Reward: 428.0
Max Reward: 428.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_14-36-08
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 442.0
  episode_reward_mean: 195.89
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 271
  experiment_id: cb3a18e0a26e466496590bc0542b68c4
  hostname: gpu020
  info:
    apply_time_ms: 2.59
    dispatch_time_ms: 45.077
    learner:
      cur_lr: 0.00134195142891258
      grad_gnorm: 40.0
      policy_entropy: 2.0732791423797607
      policy_loss: 0.7483271360397339
      var_gnorm: 29.844758987426758
      vf_explained_var: 0.0
      vf_loss: 13.469108581542969
    num_steps_sampled: 272000
    num_steps_trained: 272000
    wait_time_ms: 22.71
  iterations_since_restore: 199
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 10879
  policy_reward_mean: {}
  time_since_restore: 1471.6887578964233
  time_this_iter_s: 5.749673366546631
  time_total_s: 1471.6887578964233
  timestamp: 1594146968
  timesteps_since_restore: 272000
  timesteps_this_iter: 1000
  timesteps_total: 272000
  training_iteration: 199
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10879], 1471 s, 199 iter, 272000 ts, 196 rew

agent-1: 383.0
Sum Reward: 383.0
Avg Reward: 383.0
Min Reward: 383.0
Max Reward: 383.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_14-36-13
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 442.0
  episode_reward_mean: 195.9
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 272
  experiment_id: cb3a18e0a26e466496590bc0542b68c4
  hostname: gpu020
  info:
    apply_time_ms: 2.67
    dispatch_time_ms: 21.888
    learner:
      cur_lr: 0.001341884839348495
      grad_gnorm: 23.581645965576172
      policy_entropy: 0.22871218621730804
      policy_loss: 0.03166234865784645
      var_gnorm: 29.90939712524414
      vf_explained_var: 0.0
      vf_loss: 4.452564239501953
    num_steps_sampled: 273000
    num_steps_trained: 273000
    wait_time_ms: 21.631
  iterations_since_restore: 200
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 10879
  policy_reward_mean: {}
  time_since_restore: 1477.0825326442719
  time_this_iter_s: 5.393774747848511
  time_total_s: 1477.0825326442719
  timestamp: 1594146973
  timesteps_since_restore: 273000
  timesteps_this_iter: 1000
  timesteps_total: 273000
  training_iteration: 200
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10879], 1477 s, 200 iter, 273000 ts, 196 rew

agent-1: 358.0
Sum Reward: 358.0
Avg Reward: 358.0
Min Reward: 358.0
Max Reward: 358.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_14-36-19
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 442.0
  episode_reward_mean: 195.91
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 273
  experiment_id: cb3a18e0a26e466496590bc0542b68c4
  hostname: gpu020
  info:
    apply_time_ms: 2.776
    dispatch_time_ms: 26.951
    learner:
      cur_lr: 0.00134181824978441
      grad_gnorm: 5.733837604522705
      policy_entropy: 0.6930209398269653
      policy_loss: 0.018685517832636833
      var_gnorm: 29.879281997680664
      vf_explained_var: 0.07290840148925781
      vf_loss: 0.5314505100250244
    num_steps_sampled: 274000
    num_steps_trained: 274000
    wait_time_ms: 32.275
  iterations_since_restore: 201
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 10879
  policy_reward_mean: {}
  time_since_restore: 1482.9625766277313
  time_this_iter_s: 5.880043983459473
  time_total_s: 1482.9625766277313
  timestamp: 1594146979
  timesteps_since_restore: 274000
  timesteps_this_iter: 1000
  timesteps_total: 274000
  training_iteration: 201
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10879], 1482 s, 201 iter, 274000 ts, 196 rew

agent-1: 336.0
Sum Reward: 336.0
Avg Reward: 336.0
Min Reward: 336.0
Max Reward: 336.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_14-36-25
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 442.0
  episode_reward_mean: 195.44
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 274
  experiment_id: cb3a18e0a26e466496590bc0542b68c4
  hostname: gpu020
  info:
    apply_time_ms: 3.343
    dispatch_time_ms: 38.156
    learner:
      cur_lr: 0.0013417515438050032
      grad_gnorm: 1.6332067251205444
      policy_entropy: 1.2359179258346558
      policy_loss: 0.009180085733532906
      var_gnorm: 29.848236083984375
      vf_explained_var: 0.0
      vf_loss: 0.8294764161109924
    num_steps_sampled: 275000
    num_steps_trained: 275000
    wait_time_ms: 21.712
  iterations_since_restore: 202
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 10879
  policy_reward_mean: {}
  time_since_restore: 1488.5667281150818
  time_this_iter_s: 5.604151487350464
  time_total_s: 1488.5667281150818
  timestamp: 1594146985
  timesteps_since_restore: 275000
  timesteps_this_iter: 1000
  timesteps_total: 275000
  training_iteration: 202
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10879], 1488 s, 202 iter, 275000 ts, 195 rew

agent-1: 343.0
Sum Reward: 343.0
Avg Reward: 343.0
Min Reward: 343.0
Max Reward: 343.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_14-36-31
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 442.0
  episode_reward_mean: 195.07
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 275
  experiment_id: cb3a18e0a26e466496590bc0542b68c4
  hostname: gpu020
  info:
    apply_time_ms: 3.023
    dispatch_time_ms: 47.371
    learner:
      cur_lr: 0.0013416849542409182
      grad_gnorm: 40.00000762939453
      policy_entropy: 0.6942133903503418
      policy_loss: 0.19110417366027832
      var_gnorm: 30.030078887939453
      vf_explained_var: 0.0
      vf_loss: 68.4923095703125
    num_steps_sampled: 276000
    num_steps_trained: 276000
    wait_time_ms: 15.338
  iterations_since_restore: 203
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 10879
  policy_reward_mean: {}
  time_since_restore: 1494.228847503662
  time_this_iter_s: 5.662119388580322
  time_total_s: 1494.228847503662
  timestamp: 1594146991
  timesteps_since_restore: 276000
  timesteps_this_iter: 1000
  timesteps_total: 276000
  training_iteration: 203
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10879], 1494 s, 203 iter, 276000 ts, 195 rew

agent-1: 346.0
Sum Reward: 346.0
Avg Reward: 346.0
Min Reward: 346.0
Max Reward: 346.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_14-36-36
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 442.0
  episode_reward_mean: 195.44
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 276
  experiment_id: cb3a18e0a26e466496590bc0542b68c4
  hostname: gpu020
  info:
    apply_time_ms: 2.74
    dispatch_time_ms: 43.582
    learner:
      cur_lr: 0.0013416183646768332
      grad_gnorm: 31.095333099365234
      policy_entropy: 4.414312362670898
      policy_loss: -2.3032150268554688
      var_gnorm: 30.089996337890625
      vf_explained_var: -0.2324998378753662
      vf_loss: 8.898903846740723
    num_steps_sampled: 277000
    num_steps_trained: 277000
    wait_time_ms: 16.091
  iterations_since_restore: 204
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 10879
  policy_reward_mean: {}
  time_since_restore: 1499.9156641960144
  time_this_iter_s: 5.686816692352295
  time_total_s: 1499.9156641960144
  timestamp: 1594146996
  timesteps_since_restore: 277000
  timesteps_this_iter: 1000
  timesteps_total: 277000
  training_iteration: 204
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10879], 1499 s, 204 iter, 277000 ts, 195 rew

agent-1: 357.0
Sum Reward: 357.0
Avg Reward: 357.0
Min Reward: 357.0
Max Reward: 357.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_14-36-43
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 442.0
  episode_reward_mean: 195.69
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 277
  experiment_id: cb3a18e0a26e466496590bc0542b68c4
  hostname: gpu020
  info:
    apply_time_ms: 5.16
    dispatch_time_ms: 48.944
    learner:
      cur_lr: 0.0013415517751127481
      grad_gnorm: 33.50368881225586
      policy_entropy: 1.52945077419281
      policy_loss: 0.44562363624572754
      var_gnorm: 30.093996047973633
      vf_explained_var: -0.13821399211883545
      vf_loss: 7.030888557434082
    num_steps_sampled: 278000
    num_steps_trained: 278000
    wait_time_ms: 24.523
  iterations_since_restore: 205
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 10879
  policy_reward_mean: {}
  time_since_restore: 1506.0499551296234
  time_this_iter_s: 6.134290933609009
  time_total_s: 1506.0499551296234
  timestamp: 1594147003
  timesteps_since_restore: 278000
  timesteps_this_iter: 1000
  timesteps_total: 278000
  training_iteration: 205
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10879], 1506 s, 205 iter, 278000 ts, 196 rew

agent-1: 337.0
Sum Reward: 337.0
Avg Reward: 337.0
Min Reward: 337.0
Max Reward: 337.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_14-36-48
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 442.0
  episode_reward_mean: 195.69
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 278
  experiment_id: cb3a18e0a26e466496590bc0542b68c4
  hostname: gpu020
  info:
    apply_time_ms: 2.646
    dispatch_time_ms: 36.812
    learner:
      cur_lr: 0.0013414851855486631
      grad_gnorm: 31.863094329833984
      policy_entropy: 2.225060224533081
      policy_loss: 1.3276727199554443
      var_gnorm: 30.121000289916992
      vf_explained_var: -1.0
      vf_loss: 8.437858581542969
    num_steps_sampled: 279000
    num_steps_trained: 279000
    wait_time_ms: 26.533
  iterations_since_restore: 206
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 10879
  policy_reward_mean: {}
  time_since_restore: 1511.830058813095
  time_this_iter_s: 5.78010368347168
  time_total_s: 1511.830058813095
  timestamp: 1594147008
  timesteps_since_restore: 279000
  timesteps_this_iter: 1000
  timesteps_total: 279000
  training_iteration: 206
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10879], 1511 s, 206 iter, 279000 ts, 196 rew

agent-1: 346.0
Sum Reward: 346.0
Avg Reward: 346.0
Min Reward: 346.0
Max Reward: 346.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_14-36-54
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 442.0
  episode_reward_mean: 195.57
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 279
  experiment_id: cb3a18e0a26e466496590bc0542b68c4
  hostname: gpu020
  info:
    apply_time_ms: 3.741
    dispatch_time_ms: 32.821
    learner:
      cur_lr: 0.0013414185959845781
      grad_gnorm: 22.645015716552734
      policy_entropy: 6.520449638366699
      policy_loss: -6.111867427825928
      var_gnorm: 30.15312957763672
      vf_explained_var: 0.0
      vf_loss: 6.183045864105225
    num_steps_sampled: 280000
    num_steps_trained: 280000
    wait_time_ms: 25.964
  iterations_since_restore: 207
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 10879
  policy_reward_mean: {}
  time_since_restore: 1517.6294250488281
  time_this_iter_s: 5.799366235733032
  time_total_s: 1517.6294250488281
  timestamp: 1594147014
  timesteps_since_restore: 280000
  timesteps_this_iter: 1000
  timesteps_total: 280000
  training_iteration: 207
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10879], 1517 s, 207 iter, 280000 ts, 196 rew

agent-1: 305.0
Sum Reward: 305.0
Avg Reward: 305.0
Min Reward: 305.0
Max Reward: 305.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_14-37-00
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 442.0
  episode_reward_mean: 196.04
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 280
  experiment_id: cb3a18e0a26e466496590bc0542b68c4
  hostname: gpu020
  info:
    apply_time_ms: 2.991
    dispatch_time_ms: 40.239
    learner:
      cur_lr: 0.0013413520064204931
      grad_gnorm: 40.00000762939453
      policy_entropy: 0.34421223402023315
      policy_loss: -0.09377122670412064
      var_gnorm: 30.101036071777344
      vf_explained_var: 0.0
      vf_loss: 16.749767303466797
    num_steps_sampled: 281000
    num_steps_trained: 281000
    wait_time_ms: 19.769
  iterations_since_restore: 208
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 10879
  policy_reward_mean: {}
  time_since_restore: 1523.3522653579712
  time_this_iter_s: 5.722840309143066
  time_total_s: 1523.3522653579712
  timestamp: 1594147020
  timesteps_since_restore: 281000
  timesteps_this_iter: 1000
  timesteps_total: 281000
  training_iteration: 208
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10879], 1523 s, 208 iter, 281000 ts, 196 rew

agent-1: 214.0
Sum Reward: 214.0
Avg Reward: 214.0
Min Reward: 214.0
Max Reward: 214.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_14-37-06
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 442.0
  episode_reward_mean: 196.3
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 281
  experiment_id: cb3a18e0a26e466496590bc0542b68c4
  hostname: gpu020
  info:
    apply_time_ms: 3.919
    dispatch_time_ms: 36.608
    learner:
      cur_lr: 0.0013412854168564081
      grad_gnorm: 16.452722549438477
      policy_entropy: 0.3248627185821533
      policy_loss: -0.002658236538991332
      var_gnorm: 29.922100067138672
      vf_explained_var: 0.5775085687637329
      vf_loss: 2.1826226711273193
    num_steps_sampled: 282000
    num_steps_trained: 282000
    wait_time_ms: 17.821
  iterations_since_restore: 209
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 10879
  policy_reward_mean: {}
  time_since_restore: 1529.289413690567
  time_this_iter_s: 5.937148332595825
  time_total_s: 1529.289413690567
  timestamp: 1594147026
  timesteps_since_restore: 282000
  timesteps_this_iter: 1000
  timesteps_total: 282000
  training_iteration: 209
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10879], 1529 s, 209 iter, 282000 ts, 196 rew

agent-1: 125.0
Sum Reward: 125.0
Avg Reward: 125.0
Min Reward: 125.0
Max Reward: 125.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_14-37-12
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 442.0
  episode_reward_mean: 197.55
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 282
  experiment_id: cb3a18e0a26e466496590bc0542b68c4
  hostname: gpu020
  info:
    apply_time_ms: 2.805
    dispatch_time_ms: 28.797
    learner:
      cur_lr: 0.0013412188272923231
      grad_gnorm: 21.181528091430664
      policy_entropy: 1.3580387830734253
      policy_loss: 0.034932829439640045
      var_gnorm: 29.88055992126465
      vf_explained_var: 0.0
      vf_loss: 3.648303747177124
    num_steps_sampled: 283000
    num_steps_trained: 283000
    wait_time_ms: 15.73
  iterations_since_restore: 210
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 10879
  policy_reward_mean: {}
  time_since_restore: 1535.0960454940796
  time_this_iter_s: 5.806631803512573
  time_total_s: 1535.0960454940796
  timestamp: 1594147032
  timesteps_since_restore: 283000
  timesteps_this_iter: 1000
  timesteps_total: 283000
  training_iteration: 210
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10879], 1535 s, 210 iter, 283000 ts, 198 rew

agent-1: 65.0
Sum Reward: 65.0
Avg Reward: 65.0
Min Reward: 65.0
Max Reward: 65.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_14-37-18
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 442.0
  episode_reward_mean: 198.19
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 283
  experiment_id: cb3a18e0a26e466496590bc0542b68c4
  hostname: gpu020
  info:
    apply_time_ms: 2.555
    dispatch_time_ms: 28.966
    learner:
      cur_lr: 0.001341152237728238
      grad_gnorm: 18.931718826293945
      policy_entropy: 0.0002937397512141615
      policy_loss: -2.1056375771877356e-05
      var_gnorm: 29.90115737915039
      vf_explained_var: 0.0
      vf_loss: 3.399099349975586
    num_steps_sampled: 284000
    num_steps_trained: 284000
    wait_time_ms: 29.149
  iterations_since_restore: 211
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 10879
  policy_reward_mean: {}
  time_since_restore: 1541.0103034973145
  time_this_iter_s: 5.914258003234863
  time_total_s: 1541.0103034973145
  timestamp: 1594147038
  timesteps_since_restore: 284000
  timesteps_this_iter: 1000
  timesteps_total: 284000
  training_iteration: 211
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10879], 1541 s, 211 iter, 284000 ts, 198 rew

agent-1: 22.0
Sum Reward: 22.0
Avg Reward: 22.0
Min Reward: 22.0
Max Reward: 22.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_14-37-32
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 442.0
  episode_reward_mean: 198.41
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 284
  experiment_id: cb3a18e0a26e466496590bc0542b68c4
  hostname: gpu020
  info:
    apply_time_ms: 2.518
    dispatch_time_ms: 8.014
    learner:
      cur_lr: 0.001341085648164153
      grad_gnorm: 24.142051696777344
      policy_entropy: 0.0002930777263827622
      policy_loss: -1.559119664307218e-05
      var_gnorm: 29.84160041809082
      vf_explained_var: 0.0
      vf_loss: 4.113682270050049
    num_steps_sampled: 285000
    num_steps_trained: 285000
    wait_time_ms: 33.224
  iterations_since_restore: 212
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 10879
  policy_reward_mean: {}
  time_since_restore: 1554.846809387207
  time_this_iter_s: 13.836505889892578
  time_total_s: 1554.846809387207
  timestamp: 1594147052
  timesteps_since_restore: 285000
  timesteps_this_iter: 1000
  timesteps_total: 285000
  training_iteration: 212
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10879], 1554 s, 212 iter, 285000 ts, 198 rew

agent-1: 0.0
Sum Reward: 0.0
Avg Reward: 0.0
Min Reward: 0.0
Max Reward: 0.0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
agent-1: 0.0
Sum Reward: 0.0
Avg Reward: 0.0
Min Reward: 0.0
Max Reward: 0.0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_14-37-40
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 442.0
  episode_reward_mean: 198.4
  episode_reward_min: 0.0
  episodes_this_iter: 2
  episodes_total: 286
  experiment_id: cb3a18e0a26e466496590bc0542b68c4
  hostname: gpu020
  info:
    apply_time_ms: 3.487
    dispatch_time_ms: 7.994
    learner:
      cur_lr: 0.0013410189421847463
      grad_gnorm: 11.199021339416504
      policy_entropy: 0.0002931587805505842
      policy_loss: -7.369071681750938e-06
      var_gnorm: 29.763105392456055
      vf_explained_var: 0.0
      vf_loss: 0.8852028846740723
    num_steps_sampled: 287000
    num_steps_trained: 287000
    wait_time_ms: 30.231
  iterations_since_restore: 213
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 10879
  policy_reward_mean: {}
  time_since_restore: 1563.3670749664307
  time_this_iter_s: 8.520265579223633
  time_total_s: 1563.3670749664307
  timestamp: 1594147060
  timesteps_since_restore: 287000
  timesteps_this_iter: 2000
  timesteps_total: 287000
  training_iteration: 213
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10879], 1563 s, 213 iter, 287000 ts, 198 rew

agent-1: 0.0
Sum Reward: 0.0
Avg Reward: 0.0
Min Reward: 0.0
Max Reward: 0.0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
agent-1: 0.0
Sum Reward: 0.0
Avg Reward: 0.0
Min Reward: 0.0
Max Reward: 0.0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_14-37-49
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 442.0
  episode_reward_mean: 198.4
  episode_reward_min: 0.0
  episodes_this_iter: 2
  episodes_total: 288
  experiment_id: cb3a18e0a26e466496590bc0542b68c4
  hostname: gpu020
  info:
    apply_time_ms: 3.001
    dispatch_time_ms: 7.104
    learner:
      cur_lr: 0.0013408857630565763
      grad_gnorm: 5.230875492095947
      policy_entropy: 0.0002285717346239835
      policy_loss: -2.7795117603091057e-06
      var_gnorm: 29.743967056274414
      vf_explained_var: 0.0
      vf_loss: 0.19003911316394806
    num_steps_sampled: 289000
    num_steps_trained: 289000
    wait_time_ms: 34.893
  iterations_since_restore: 214
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 10879
  policy_reward_mean: {}
  time_since_restore: 1571.9537317752838
  time_this_iter_s: 8.58665680885315
  time_total_s: 1571.9537317752838
  timestamp: 1594147069
  timesteps_since_restore: 289000
  timesteps_this_iter: 2000
  timesteps_total: 289000
  training_iteration: 214
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10879], 1571 s, 214 iter, 289000 ts, 198 rew

agent-1: 0.0
Sum Reward: 0.0
Avg Reward: 0.0
Min Reward: 0.0
Max Reward: 0.0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
agent-1: 0.0
Sum Reward: 0.0
Avg Reward: 0.0
Min Reward: 0.0
Max Reward: 0.0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_14-37-57
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 442.0
  episode_reward_mean: 198.4
  episode_reward_min: 0.0
  episodes_this_iter: 2
  episodes_total: 290
  experiment_id: cb3a18e0a26e466496590bc0542b68c4
  hostname: gpu020
  info:
    apply_time_ms: 2.923
    dispatch_time_ms: 5.953
    learner:
      cur_lr: 0.0013407525839284062
      grad_gnorm: 2.182331085205078
      policy_entropy: 0.00021005420421715826
      policy_loss: -9.70961536950199e-07
      var_gnorm: 29.74140739440918
      vf_explained_var: 0.0
      vf_loss: 0.03269987553358078
    num_steps_sampled: 291000
    num_steps_trained: 291000
    wait_time_ms: 32.985
  iterations_since_restore: 215
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 10879
  policy_reward_mean: {}
  time_since_restore: 1580.4645109176636
  time_this_iter_s: 8.51077914237976
  time_total_s: 1580.4645109176636
  timestamp: 1594147077
  timesteps_since_restore: 291000
  timesteps_this_iter: 2000
  timesteps_total: 291000
  training_iteration: 215
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10879], 1580 s, 215 iter, 291000 ts, 198 rew

agent-1: 0.0
Sum Reward: 0.0
Avg Reward: 0.0
Min Reward: 0.0
Max Reward: 0.0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
agent-1: 0.0
Sum Reward: 0.0
Avg Reward: 0.0
Min Reward: 0.0
Max Reward: 0.0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_14-38-06
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 442.0
  episode_reward_mean: 198.4
  episode_reward_min: 0.0
  episodes_this_iter: 2
  episodes_total: 292
  experiment_id: cb3a18e0a26e466496590bc0542b68c4
  hostname: gpu020
  info:
    apply_time_ms: 2.711
    dispatch_time_ms: 9.012
    learner:
      cur_lr: 0.0013406194048002362
      grad_gnorm: 2.9883041381835938
      policy_entropy: 0.0007410252001136541
      policy_loss: -5.417433840193553e-06
      var_gnorm: 29.74127769470215
      vf_explained_var: 0.0
      vf_loss: 0.06302760541439056
    num_steps_sampled: 293000
    num_steps_trained: 293000
    wait_time_ms: 31.425
  iterations_since_restore: 216
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 10879
  policy_reward_mean: {}
  time_since_restore: 1589.053813457489
  time_this_iter_s: 8.58930253982544
  time_total_s: 1589.053813457489
  timestamp: 1594147086
  timesteps_since_restore: 293000
  timesteps_this_iter: 2000
  timesteps_total: 293000
  training_iteration: 216
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10879], 1589 s, 216 iter, 293000 ts, 198 rew

agent-1: 0.0
Sum Reward: 0.0
Avg Reward: 0.0
Min Reward: 0.0
Max Reward: 0.0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
agent-1: 0.0
Sum Reward: 0.0
Avg Reward: 0.0
Min Reward: 0.0
Max Reward: 0.0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_14-38-15
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 442.0
  episode_reward_mean: 198.4
  episode_reward_min: 0.0
  episodes_this_iter: 2
  episodes_total: 294
  experiment_id: cb3a18e0a26e466496590bc0542b68c4
  hostname: gpu020
  info:
    apply_time_ms: 2.375
    dispatch_time_ms: 6.811
    learner:
      cur_lr: 0.0013404862256720662
      grad_gnorm: 0.28979018330574036
      policy_entropy: 0.0002100588462781161
      policy_loss: -1.2500125023962028e-07
      var_gnorm: 29.739704132080078
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 0.0005766022368334234
    num_steps_sampled: 295000
    num_steps_trained: 295000
    wait_time_ms: 33.422
  iterations_since_restore: 217
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 10879
  policy_reward_mean: {}
  time_since_restore: 1597.565042257309
  time_this_iter_s: 8.511228799819946
  time_total_s: 1597.565042257309
  timestamp: 1594147095
  timesteps_since_restore: 295000
  timesteps_this_iter: 2000
  timesteps_total: 295000
  training_iteration: 217
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10879], 1597 s, 217 iter, 295000 ts, 198 rew

agent-1: 0.0
Sum Reward: 0.0
Avg Reward: 0.0
Min Reward: 0.0
Max Reward: 0.0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
agent-1: 0.0
Sum Reward: 0.0
Avg Reward: 0.0
Min Reward: 0.0
Max Reward: 0.0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_14-38-23
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 442.0
  episode_reward_mean: 198.4
  episode_reward_min: 0.0
  episodes_this_iter: 2
  episodes_total: 296
  experiment_id: cb3a18e0a26e466496590bc0542b68c4
  hostname: gpu020
  info:
    apply_time_ms: 4.892
    dispatch_time_ms: 8.44
    learner:
      cur_lr: 0.0013403530465438962
      grad_gnorm: 0.7329270839691162
      policy_entropy: 0.00029319224995560944
      policy_loss: 4.699952569353627e-07
      var_gnorm: 29.739316940307617
      vf_explained_var: 1.1920928955078125e-07
      vf_loss: 0.0037914523854851723
    num_steps_sampled: 297000
    num_steps_trained: 297000
    wait_time_ms: 29.428
  iterations_since_restore: 218
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 10879
  policy_reward_mean: {}
  time_since_restore: 1606.0761513710022
  time_this_iter_s: 8.511109113693237
  time_total_s: 1606.0761513710022
  timestamp: 1594147103
  timesteps_since_restore: 297000
  timesteps_this_iter: 2000
  timesteps_total: 297000
  training_iteration: 218
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10879], 1606 s, 218 iter, 297000 ts, 198 rew

agent-1: 0.0
Sum Reward: 0.0
Avg Reward: 0.0
Min Reward: 0.0
Max Reward: 0.0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
agent-1: 0.0
Sum Reward: 0.0
Avg Reward: 0.0
Min Reward: 0.0
Max Reward: 0.0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_14-38-32
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 442.0
  episode_reward_mean: 198.39
  episode_reward_min: 0.0
  episodes_this_iter: 2
  episodes_total: 298
  experiment_id: cb3a18e0a26e466496590bc0542b68c4
  hostname: gpu020
  info:
    apply_time_ms: 3.876
    dispatch_time_ms: 7.873
    learner:
      cur_lr: 0.0013402197510004044
      grad_gnorm: 2.104090452194214
      policy_entropy: 0.0007459113257937133
      policy_loss: -3.928504611394601e-06
      var_gnorm: 29.738903045654297
      vf_explained_var: 0.0
      vf_loss: 0.03124723769724369
    num_steps_sampled: 299000
    num_steps_trained: 299000
    wait_time_ms: 31.107
  iterations_since_restore: 219
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 10879
  policy_reward_mean: {}
  time_since_restore: 1614.5657246112823
  time_this_iter_s: 8.489573240280151
  time_total_s: 1614.5657246112823
  timestamp: 1594147112
  timesteps_since_restore: 299000
  timesteps_this_iter: 2000
  timesteps_total: 299000
  training_iteration: 219
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10879], 1614 s, 219 iter, 299000 ts, 198 rew

agent-1: 0.0
Sum Reward: 0.0
Avg Reward: 0.0
Min Reward: 0.0
Max Reward: 0.0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
agent-1: 0.0
Sum Reward: 0.0
Avg Reward: 0.0
Min Reward: 0.0
Max Reward: 0.0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_14-38-40
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 442.0
  episode_reward_mean: 198.36
  episode_reward_min: 0.0
  episodes_this_iter: 2
  episodes_total: 300
  experiment_id: cb3a18e0a26e466496590bc0542b68c4
  hostname: gpu020
  info:
    apply_time_ms: 3.704
    dispatch_time_ms: 7.724
    learner:
      cur_lr: 0.0013400865718722343
      grad_gnorm: 1.268903136253357
      policy_entropy: 0.0002931992057710886
      policy_loss: 8.250977998613962e-07
      var_gnorm: 29.737123489379883
      vf_explained_var: 0.0
      vf_loss: 0.011364180594682693
    num_steps_sampled: 301000
    num_steps_trained: 301000
    wait_time_ms: 29.961
  iterations_since_restore: 220
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 10879
  policy_reward_mean: {}
  time_since_restore: 1623.116423368454
  time_this_iter_s: 8.55069875717163
  time_total_s: 1623.116423368454
  timestamp: 1594147120
  timesteps_since_restore: 301000
  timesteps_this_iter: 2000
  timesteps_total: 301000
  training_iteration: 220
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10879], 1623 s, 220 iter, 301000 ts, 198 rew

agent-1: 0.0
Sum Reward: 0.0
Avg Reward: 0.0
Min Reward: 0.0
Max Reward: 0.0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
agent-1: 0.0
Sum Reward: 0.0
Avg Reward: 0.0
Min Reward: 0.0
Max Reward: 0.0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_14-38-49
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 442.0
  episode_reward_mean: 196.98
  episode_reward_min: 0.0
  episodes_this_iter: 2
  episodes_total: 302
  experiment_id: cb3a18e0a26e466496590bc0542b68c4
  hostname: gpu020
  info:
    apply_time_ms: 2.505
    dispatch_time_ms: 6.989
    learner:
      cur_lr: 0.0013399533927440643
      grad_gnorm: 0.6222965121269226
      policy_entropy: 0.00029319891473278403
      policy_loss: 3.9696283238299657e-07
      var_gnorm: 29.736425399780273
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 0.0027332217432558537
    num_steps_sampled: 303000
    num_steps_trained: 303000
    wait_time_ms: 35.926
  iterations_since_restore: 221
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 10879
  policy_reward_mean: {}
  time_since_restore: 1631.698825120926
  time_this_iter_s: 8.582401752471924
  time_total_s: 1631.698825120926
  timestamp: 1594147129
  timesteps_since_restore: 303000
  timesteps_this_iter: 2000
  timesteps_total: 303000
  training_iteration: 221
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10879], 1631 s, 221 iter, 303000 ts, 197 rew

agent-1: 0.0
Sum Reward: 0.0
Avg Reward: 0.0
Min Reward: 0.0
Max Reward: 0.0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
agent-1: 0.0
Sum Reward: 0.0
Avg Reward: 0.0
Min Reward: 0.0
Max Reward: 0.0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_14-38-57
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 442.0
  episode_reward_mean: 191.15
  episode_reward_min: 0.0
  episodes_this_iter: 2
  episodes_total: 304
  experiment_id: cb3a18e0a26e466496590bc0542b68c4
  hostname: gpu020
  info:
    apply_time_ms: 4.402
    dispatch_time_ms: 7.414
    learner:
      cur_lr: 0.0013398202136158943
      grad_gnorm: 1.4112071990966797
      policy_entropy: 0.0009970598621293902
      policy_loss: -3.4320416943955934e-06
      var_gnorm: 29.73563575744629
      vf_explained_var: 0.0
      vf_loss: 0.014056006446480751
    num_steps_sampled: 305000
    num_steps_trained: 305000
    wait_time_ms: 31.63
  iterations_since_restore: 222
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 10879
  policy_reward_mean: {}
  time_since_restore: 1640.2377619743347
  time_this_iter_s: 8.538936853408813
  time_total_s: 1640.2377619743347
  timestamp: 1594147137
  timesteps_since_restore: 305000
  timesteps_this_iter: 2000
  timesteps_total: 305000
  training_iteration: 222
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10879], 1640 s, 222 iter, 305000 ts, 191 rew

agent-1: 0.0
Sum Reward: 0.0
Avg Reward: 0.0
Min Reward: 0.0
Max Reward: 0.0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
agent-1: 0.0
Sum Reward: 0.0
Avg Reward: 0.0
Min Reward: 0.0
Max Reward: 0.0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_14-39-06
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 442.0
  episode_reward_mean: 184.31
  episode_reward_min: 0.0
  episodes_this_iter: 2
  episodes_total: 306
  experiment_id: cb3a18e0a26e466496590bc0542b68c4
  hostname: gpu020
  info:
    apply_time_ms: 4.089
    dispatch_time_ms: 8.641
    learner:
      cur_lr: 0.0013396870344877243
      grad_gnorm: 0.12458943575620651
      policy_entropy: 0.00021007122995797545
      policy_loss: 5.389646773323875e-08
      var_gnorm: 29.735076904296875
      vf_explained_var: 0.0
      vf_loss: 0.00010658167593646795
    num_steps_sampled: 307000
    num_steps_trained: 307000
    wait_time_ms: 30.131
  iterations_since_restore: 223
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 10879
  policy_reward_mean: {}
  time_since_restore: 1648.8221192359924
  time_this_iter_s: 8.584357261657715
  time_total_s: 1648.8221192359924
  timestamp: 1594147146
  timesteps_since_restore: 307000
  timesteps_this_iter: 2000
  timesteps_total: 307000
  training_iteration: 223
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10879], 1648 s, 223 iter, 307000 ts, 184 rew

agent-1: 0.0
Sum Reward: 0.0
Avg Reward: 0.0
Min Reward: 0.0
Max Reward: 0.0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
agent-1: 0.0
Sum Reward: 0.0
Avg Reward: 0.0
Min Reward: 0.0
Max Reward: 0.0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_14-39-15
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 442.0
  episode_reward_mean: 177.44
  episode_reward_min: 0.0
  episodes_this_iter: 2
  episodes_total: 308
  experiment_id: cb3a18e0a26e466496590bc0542b68c4
  hostname: gpu020
  info:
    apply_time_ms: 2.708
    dispatch_time_ms: 16.852
    learner:
      cur_lr: 0.0013395538553595543
      grad_gnorm: 0.7383236885070801
      policy_entropy: 0.00029321209876798093
      policy_loss: 9.545830437218683e-08
      var_gnorm: 29.73368263244629
      vf_explained_var: 5.960464477539063e-08
      vf_loss: 0.0032609382178634405
    num_steps_sampled: 309000
    num_steps_trained: 309000
    wait_time_ms: 27.611
  iterations_since_restore: 224
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 10879
  policy_reward_mean: {}
  time_since_restore: 1657.3285279273987
  time_this_iter_s: 8.50640869140625
  time_total_s: 1657.3285279273987
  timestamp: 1594147155
  timesteps_since_restore: 309000
  timesteps_this_iter: 2000
  timesteps_total: 309000
  training_iteration: 224
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10879], 1657 s, 224 iter, 309000 ts, 177 rew

agent-1: 0.0
Sum Reward: 0.0
Avg Reward: 0.0
Min Reward: 0.0
Max Reward: 0.0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
agent-1: 0.0
Sum Reward: 0.0
Avg Reward: 0.0
Min Reward: 0.0
Max Reward: 0.0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_14-39-25
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 442.0
  episode_reward_mean: 171.01
  episode_reward_min: 0.0
  episodes_this_iter: 2
  episodes_total: 310
  experiment_id: cb3a18e0a26e466496590bc0542b68c4
  hostname: gpu020
  info:
    apply_time_ms: 3.378
    dispatch_time_ms: 29.307
    learner:
      cur_lr: 0.0013394205598160625
      grad_gnorm: 0.9489143490791321
      policy_entropy: 0.00022862492187414318
      policy_loss: 2.635381974869233e-07
      var_gnorm: 29.731855392456055
      vf_explained_var: 0.0
      vf_loss: 0.005334376823157072
    num_steps_sampled: 311000
    num_steps_trained: 311000
    wait_time_ms: 21.819
  iterations_since_restore: 225
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 10879
  policy_reward_mean: {}
  time_since_restore: 1667.2874083518982
  time_this_iter_s: 9.958880424499512
  time_total_s: 1667.2874083518982
  timestamp: 1594147165
  timesteps_since_restore: 311000
  timesteps_this_iter: 2000
  timesteps_total: 311000
  training_iteration: 225
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10879], 1667 s, 225 iter, 311000 ts, 171 rew

agent-1: 0.0
Sum Reward: 0.0
Avg Reward: 0.0
Min Reward: 0.0
Max Reward: 0.0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_14-39-30
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 442.0
  episode_reward_mean: 167.81
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 311
  experiment_id: cb3a18e0a26e466496590bc0542b68c4
  hostname: gpu020
  info:
    apply_time_ms: 2.939
    dispatch_time_ms: 42.307
    learner:
      cur_lr: 0.0013392873806878924
      grad_gnorm: 1.283001184463501
      policy_entropy: 0.00029325488139875233
      policy_loss: 9.125967039835814e-07
      var_gnorm: 29.73085594177246
      vf_explained_var: 0.0
      vf_loss: 0.012205047532916069
    num_steps_sampled: 312000
    num_steps_trained: 312000
    wait_time_ms: 20.715
  iterations_since_restore: 226
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 10879
  policy_reward_mean: {}
  time_since_restore: 1672.8552942276
  time_this_iter_s: 5.567885875701904
  time_total_s: 1672.8552942276
  timestamp: 1594147170
  timesteps_since_restore: 312000
  timesteps_this_iter: 1000
  timesteps_total: 312000
  training_iteration: 226
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10879], 1672 s, 226 iter, 312000 ts, 168 rew

agent-1: 0.0
Sum Reward: 0.0
Avg Reward: 0.0
Min Reward: 0.0
Max Reward: 0.0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_14-39-36
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 442.0
  episode_reward_mean: 164.43
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 312
  experiment_id: cb3a18e0a26e466496590bc0542b68c4
  hostname: gpu020
  info:
    apply_time_ms: 2.945
    dispatch_time_ms: 33.861
    learner:
      cur_lr: 0.0013392207911238074
      grad_gnorm: 1.8177028894424438
      policy_entropy: 0.0002932593924924731
      policy_loss: 8.869911312103795e-07
      var_gnorm: 29.729537963867188
      vf_explained_var: 0.0
      vf_loss: 0.02114720642566681
    num_steps_sampled: 313000
    num_steps_trained: 313000
    wait_time_ms: 22.932
  iterations_since_restore: 227
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 10879
  policy_reward_mean: {}
  time_since_restore: 1679.117154598236
  time_this_iter_s: 6.261860370635986
  time_total_s: 1679.117154598236
  timestamp: 1594147176
  timesteps_since_restore: 313000
  timesteps_this_iter: 1000
  timesteps_total: 313000
  training_iteration: 227
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10879], 1679 s, 227 iter, 313000 ts, 164 rew

agent-1: 0.0
Sum Reward: 0.0
Avg Reward: 0.0
Min Reward: 0.0
Max Reward: 0.0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_14-39-42
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 442.0
  episode_reward_mean: 161.46
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 313
  experiment_id: cb3a18e0a26e466496590bc0542b68c4
  hostname: gpu020
  info:
    apply_time_ms: 3.028
    dispatch_time_ms: 33.292
    learner:
      cur_lr: 0.0013391542015597224
      grad_gnorm: 0.0368681475520134
      policy_entropy: 0.00021010529599152505
      policy_loss: -2.3537589655120428e-08
      var_gnorm: 29.7291202545166
      vf_explained_var: 0.0
      vf_loss: 1.16158407763578e-05
    num_steps_sampled: 314000
    num_steps_trained: 314000
    wait_time_ms: 13.485
  iterations_since_restore: 228
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 10879
  policy_reward_mean: {}
  time_since_restore: 1684.738507270813
  time_this_iter_s: 5.621352672576904
  time_total_s: 1684.738507270813
  timestamp: 1594147182
  timesteps_since_restore: 314000
  timesteps_this_iter: 1000
  timesteps_total: 314000
  training_iteration: 228
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10879], 1684 s, 228 iter, 314000 ts, 161 rew

agent-1: 0.0
Sum Reward: 0.0
Avg Reward: 0.0
Min Reward: 0.0
Max Reward: 0.0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_14-39-48
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 442.0
  episode_reward_mean: 158.5
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 314
  experiment_id: cb3a18e0a26e466496590bc0542b68c4
  hostname: gpu020
  info:
    apply_time_ms: 2.764
    dispatch_time_ms: 34.555
    learner:
      cur_lr: 0.0013390876119956374
      grad_gnorm: 0.25674334168434143
      policy_entropy: 0.0002101046993630007
      policy_loss: -3.408714377428623e-08
      var_gnorm: 29.728866577148438
      vf_explained_var: 0.0
      vf_loss: 0.0003674815525300801
    num_steps_sampled: 315000
    num_steps_trained: 315000
    wait_time_ms: 20.461
  iterations_since_restore: 229
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 10879
  policy_reward_mean: {}
  time_since_restore: 1690.1689553260803
  time_this_iter_s: 5.430448055267334
  time_total_s: 1690.1689553260803
  timestamp: 1594147188
  timesteps_since_restore: 315000
  timesteps_this_iter: 1000
  timesteps_total: 315000
  training_iteration: 229
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10879], 1690 s, 229 iter, 315000 ts, 158 rew

agent-1: 0.0
Sum Reward: 0.0
Avg Reward: 0.0
Min Reward: 0.0
Max Reward: 0.0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_14-39-53
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 442.0
  episode_reward_mean: 155.03
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 315
  experiment_id: cb3a18e0a26e466496590bc0542b68c4
  hostname: gpu020
  info:
    apply_time_ms: 3.346
    dispatch_time_ms: 25.238
    learner:
      cur_lr: 0.0013390210224315524
      grad_gnorm: 0.3828276991844177
      policy_entropy: 0.00029325473587960005
      policy_loss: 6.720946430505137e-07
      var_gnorm: 29.728260040283203
      vf_explained_var: 0.0
      vf_loss: 0.0020776144228875637
    num_steps_sampled: 316000
    num_steps_trained: 316000
    wait_time_ms: 19.034
  iterations_since_restore: 230
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 10879
  policy_reward_mean: {}
  time_since_restore: 1695.845696926117
  time_this_iter_s: 5.676741600036621
  time_total_s: 1695.845696926117
  timestamp: 1594147193
  timesteps_since_restore: 316000
  timesteps_this_iter: 1000
  timesteps_total: 316000
  training_iteration: 230
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10879], 1695 s, 230 iter, 316000 ts, 155 rew

agent-1: 0.0
Sum Reward: 0.0
Avg Reward: 0.0
Min Reward: 0.0
Max Reward: 0.0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_14-39-59
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 442.0
  episode_reward_mean: 151.08
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 316
  experiment_id: cb3a18e0a26e466496590bc0542b68c4
  hostname: gpu020
  info:
    apply_time_ms: 2.424
    dispatch_time_ms: 40.444
    learner:
      cur_lr: 0.0013389544328674674
      grad_gnorm: 0.71113520860672
      policy_entropy: 0.0002932506031356752
      policy_loss: 4.046369213028811e-07
      var_gnorm: 29.72780990600586
      vf_explained_var: 0.0
      vf_loss: 0.0034178916830569506
    num_steps_sampled: 317000
    num_steps_trained: 317000
    wait_time_ms: 15.824
  iterations_since_restore: 231
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 10879
  policy_reward_mean: {}
  time_since_restore: 1701.3731000423431
  time_this_iter_s: 5.527403116226196
  time_total_s: 1701.3731000423431
  timestamp: 1594147199
  timesteps_since_restore: 317000
  timesteps_this_iter: 1000
  timesteps_total: 317000
  training_iteration: 231
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10879], 1701 s, 231 iter, 317000 ts, 151 rew

agent-1: 0.0
Sum Reward: 0.0
Avg Reward: 0.0
Min Reward: 0.0
Max Reward: 0.0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_14-40-05
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 442.0
  episode_reward_mean: 146.74
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 317
  experiment_id: cb3a18e0a26e466496590bc0542b68c4
  hostname: gpu020
  info:
    apply_time_ms: 5.086
    dispatch_time_ms: 30.141
    learner:
      cur_lr: 0.0013388878433033824
      grad_gnorm: 1.6923620700836182
      policy_entropy: 0.0006096471915952861
      policy_loss: -3.8031573694752296e-06
      var_gnorm: 29.72593879699707
      vf_explained_var: 0.0
      vf_loss: 0.02605031058192253
    num_steps_sampled: 318000
    num_steps_trained: 318000
    wait_time_ms: 14.174
  iterations_since_restore: 232
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 10879
  policy_reward_mean: {}
  time_since_restore: 1707.9023413658142
  time_this_iter_s: 6.529241323471069
  time_total_s: 1707.9023413658142
  timestamp: 1594147205
  timesteps_since_restore: 318000
  timesteps_this_iter: 1000
  timesteps_total: 318000
  training_iteration: 232
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10879], 1707 s, 232 iter, 318000 ts, 147 rew

agent-1: 0.0
Sum Reward: 0.0
Avg Reward: 0.0
Min Reward: 0.0
Max Reward: 0.0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_14-40-11
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 440.0
  episode_reward_mean: 142.32
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 318
  experiment_id: cb3a18e0a26e466496590bc0542b68c4
  hostname: gpu020
  info:
    apply_time_ms: 4.124
    dispatch_time_ms: 28.799
    learner:
      cur_lr: 0.0013388212537392974
      grad_gnorm: 2.434016227722168
      policy_entropy: 0.00021013111108914018
      policy_loss: -1.1464186400189647e-07
      var_gnorm: 29.72564125061035
      vf_explained_var: 0.0
      vf_loss: 0.032332681119441986
    num_steps_sampled: 319000
    num_steps_trained: 319000
    wait_time_ms: 13.949
  iterations_since_restore: 233
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 10879
  policy_reward_mean: {}
  time_since_restore: 1713.5132162570953
  time_this_iter_s: 5.610874891281128
  time_total_s: 1713.5132162570953
  timestamp: 1594147211
  timesteps_since_restore: 319000
  timesteps_this_iter: 1000
  timesteps_total: 319000
  training_iteration: 233
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10879], 1713 s, 233 iter, 319000 ts, 142 rew

agent-1: 0.0
Sum Reward: 0.0
Avg Reward: 0.0
Min Reward: 0.0
Max Reward: 0.0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
agent-1: 0.0
Sum Reward: 0.0
Avg Reward: 0.0
Min Reward: 0.0
Max Reward: 0.0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_14-40-20
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 440.0
  episode_reward_mean: 134.22
  episode_reward_min: 0.0
  episodes_this_iter: 2
  episodes_total: 320
  experiment_id: cb3a18e0a26e466496590bc0542b68c4
  hostname: gpu020
  info:
    apply_time_ms: 2.739
    dispatch_time_ms: 7.47
    learner:
      cur_lr: 0.0013387545477598906
      grad_gnorm: 0.012460998259484768
      policy_entropy: 0.00021014442609157413
      policy_loss: -3.3857414649673956e-09
      var_gnorm: 29.782743453979492
      vf_explained_var: 0.0
      vf_loss: 1.0658732207957655e-06
    num_steps_sampled: 321000
    num_steps_trained: 321000
    wait_time_ms: 31.266
  iterations_since_restore: 234
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 10879
  policy_reward_mean: {}
  time_since_restore: 1722.2500967979431
  time_this_iter_s: 8.736880540847778
  time_total_s: 1722.2500967979431
  timestamp: 1594147220
  timesteps_since_restore: 321000
  timesteps_this_iter: 2000
  timesteps_total: 321000
  training_iteration: 234
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10879], 1722 s, 234 iter, 321000 ts, 134 rew

agent-1: 0.0
Sum Reward: 0.0
Avg Reward: 0.0
Min Reward: 0.0
Max Reward: 0.0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
agent-1: 0.0
Sum Reward: 0.0
Avg Reward: 0.0
Min Reward: 0.0
Max Reward: 0.0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_14-40-28
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 438.0
  episode_reward_mean: 125.75
  episode_reward_min: 0.0
  episodes_this_iter: 2
  episodes_total: 322
  experiment_id: cb3a18e0a26e466496590bc0542b68c4
  hostname: gpu020
  info:
    apply_time_ms: 2.759
    dispatch_time_ms: 6.454
    learner:
      cur_lr: 0.0013386213686317205
      grad_gnorm: 0.3323558568954468
      policy_entropy: 0.0007404067437164485
      policy_loss: -7.117454288163572e-07
      var_gnorm: 29.779067993164062
      vf_explained_var: 0.0
      vf_loss: 0.0007671836647205055
    num_steps_sampled: 323000
    num_steps_trained: 323000
    wait_time_ms: 33.744
  iterations_since_restore: 235
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 10879
  policy_reward_mean: {}
  time_since_restore: 1730.7868723869324
  time_this_iter_s: 8.536775588989258
  time_total_s: 1730.7868723869324
  timestamp: 1594147228
  timesteps_since_restore: 323000
  timesteps_this_iter: 2000
  timesteps_total: 323000
  training_iteration: 235
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10879], 1730 s, 235 iter, 323000 ts, 126 rew

agent-1: 0.0
Sum Reward: 0.0
Avg Reward: 0.0
Min Reward: 0.0
Max Reward: 0.0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
agent-1: 0.0
Sum Reward: 0.0
Avg Reward: 0.0
Min Reward: 0.0
Max Reward: 0.0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_14-40-37
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 438.0
  episode_reward_mean: 117.5
  episode_reward_min: 0.0
  episodes_this_iter: 2
  episodes_total: 324
  experiment_id: cb3a18e0a26e466496590bc0542b68c4
  hostname: gpu020
  info:
    apply_time_ms: 2.572
    dispatch_time_ms: 6.839
    learner:
      cur_lr: 0.0013384881895035505
      grad_gnorm: 1.5777944326400757
      policy_entropy: 0.00021087692584842443
      policy_loss: 6.824813567618548e-07
      var_gnorm: 29.77889633178711
      vf_explained_var: 0.0
      vf_loss: 0.017092475667595863
    num_steps_sampled: 325000
    num_steps_trained: 325000
    wait_time_ms: 33.1
  iterations_since_restore: 236
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 10879
  policy_reward_mean: {}
  time_since_restore: 1739.3703453540802
  time_this_iter_s: 8.583472967147827
  time_total_s: 1739.3703453540802
  timestamp: 1594147237
  timesteps_since_restore: 325000
  timesteps_this_iter: 2000
  timesteps_total: 325000
  training_iteration: 236
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10879], 1739 s, 236 iter, 325000 ts, 118 rew

agent-1: 0.0
Sum Reward: 0.0
Avg Reward: 0.0
Min Reward: 0.0
Max Reward: 0.0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
agent-1: 0.0
Sum Reward: 0.0
Avg Reward: 0.0
Min Reward: 0.0
Max Reward: 0.0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_14-40-46
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 438.0
  episode_reward_mean: 109.9
  episode_reward_min: 0.0
  episodes_this_iter: 2
  episodes_total: 326
  experiment_id: cb3a18e0a26e466496590bc0542b68c4
  hostname: gpu020
  info:
    apply_time_ms: 2.852
    dispatch_time_ms: 7.05
    learner:
      cur_lr: 0.0013383550103753805
      grad_gnorm: 0.5410551428794861
      policy_entropy: 0.000997229595668614
      policy_loss: -1.350001525679545e-06
      var_gnorm: 29.777324676513672
      vf_explained_var: 5.960464477539063e-08
      vf_loss: 0.0020661833696067333
    num_steps_sampled: 327000
    num_steps_trained: 327000
    wait_time_ms: 32.253
  iterations_since_restore: 237
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 10879
  policy_reward_mean: {}
  time_since_restore: 1747.9594745635986
  time_this_iter_s: 8.589129209518433
  time_total_s: 1747.9594745635986
  timestamp: 1594147246
  timesteps_since_restore: 327000
  timesteps_this_iter: 2000
  timesteps_total: 327000
  training_iteration: 237
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10879], 1747 s, 237 iter, 327000 ts, 110 rew

agent-1: 0.0
Sum Reward: 0.0
Avg Reward: 0.0
Min Reward: 0.0
Max Reward: 0.0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
agent-1: 0.0
Sum Reward: 0.0
Avg Reward: 0.0
Min Reward: 0.0
Max Reward: 0.0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_14-40-54
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 438.0
  episode_reward_mean: 101.42
  episode_reward_min: 0.0
  episodes_this_iter: 2
  episodes_total: 328
  experiment_id: cb3a18e0a26e466496590bc0542b68c4
  hostname: gpu020
  info:
    apply_time_ms: 3.799
    dispatch_time_ms: 8.3
    learner:
      cur_lr: 0.0013382218312472105
      grad_gnorm: 0.009588059969246387
      policy_entropy: 0.00021092122187837958
      policy_loss: -4.278048137962287e-09
      var_gnorm: 29.77692413330078
      vf_explained_var: 0.0
      vf_loss: 6.315939344858634e-07
    num_steps_sampled: 329000
    num_steps_trained: 329000
    wait_time_ms: 31.316
  iterations_since_restore: 238
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 10879
  policy_reward_mean: {}
  time_since_restore: 1756.5455884933472
  time_this_iter_s: 8.586113929748535
  time_total_s: 1756.5455884933472
  timestamp: 1594147254
  timesteps_since_restore: 329000
  timesteps_this_iter: 2000
  timesteps_total: 329000
  training_iteration: 238
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10879], 1756 s, 238 iter, 329000 ts, 101 rew

agent-1: 0.0
Sum Reward: 0.0
Avg Reward: 0.0
Min Reward: 0.0
Max Reward: 0.0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
agent-1: 0.0
Sum Reward: 0.0
Avg Reward: 0.0
Min Reward: 0.0
Max Reward: 0.0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_14-41-03
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 436.0
  episode_reward_mean: 92.82
  episode_reward_min: 0.0
  episodes_this_iter: 2
  episodes_total: 330
  experiment_id: cb3a18e0a26e466496590bc0542b68c4
  hostname: gpu020
  info:
    apply_time_ms: 3.112
    dispatch_time_ms: 9.809
    learner:
      cur_lr: 0.0013380886521190405
      grad_gnorm: 1.058577060699463
      policy_entropy: 0.0007984505500644445
      policy_loss: -2.0962759208487114e-06
      var_gnorm: 29.77534294128418
      vf_explained_var: 0.0
      vf_loss: 0.00778287835419178
    num_steps_sampled: 331000
    num_steps_trained: 331000
    wait_time_ms: 30.49
  iterations_since_restore: 239
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 10879
  policy_reward_mean: {}
  time_since_restore: 1765.117125749588
  time_this_iter_s: 8.571537256240845
  time_total_s: 1765.117125749588
  timestamp: 1594147263
  timesteps_since_restore: 331000
  timesteps_this_iter: 2000
  timesteps_total: 331000
  training_iteration: 239
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10879], 1765 s, 239 iter, 331000 ts, 92.8 rew

agent-1: 0.0
Sum Reward: 0.0
Avg Reward: 0.0
Min Reward: 0.0
Max Reward: 0.0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
agent-1: 0.0
Sum Reward: 0.0
Avg Reward: 0.0
Min Reward: 0.0
Max Reward: 0.0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_14-41-12
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 436.0
  episode_reward_mean: 85.29
  episode_reward_min: 0.0
  episodes_this_iter: 2
  episodes_total: 332
  experiment_id: cb3a18e0a26e466496590bc0542b68c4
  hostname: gpu020
  info:
    apply_time_ms: 4.218
    dispatch_time_ms: 6.498
    learner:
      cur_lr: 0.0013379553565755486
      grad_gnorm: 0.5466073751449585
      policy_entropy: 0.00021111351088620722
      policy_loss: 1.8475971330644825e-07
      var_gnorm: 29.774534225463867
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 0.0020514295902103186
    num_steps_sampled: 333000
    num_steps_trained: 333000
    wait_time_ms: 32.761
  iterations_since_restore: 240
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 10879
  policy_reward_mean: {}
  time_since_restore: 1773.6828835010529
  time_this_iter_s: 8.565757751464844
  time_total_s: 1773.6828835010529
  timestamp: 1594147272
  timesteps_since_restore: 333000
  timesteps_this_iter: 2000
  timesteps_total: 333000
  training_iteration: 240
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10879], 1773 s, 240 iter, 333000 ts, 85.3 rew

agent-1: 0.0
Sum Reward: 0.0
Avg Reward: 0.0
Min Reward: 0.0
Max Reward: 0.0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
agent-1: 0.0
Sum Reward: 0.0
Avg Reward: 0.0
Min Reward: 0.0
Max Reward: 0.0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_14-41-20
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 436.0
  episode_reward_mean: 77.95
  episode_reward_min: 0.0
  episodes_this_iter: 2
  episodes_total: 334
  experiment_id: cb3a18e0a26e466496590bc0542b68c4
  hostname: gpu020
  info:
    apply_time_ms: 2.845
    dispatch_time_ms: 9.454
    learner:
      cur_lr: 0.0013378221774473786
      grad_gnorm: 0.5156453251838684
      policy_entropy: 0.00021209503756836057
      policy_loss: 3.5990035485156113e-07
      var_gnorm: 29.777324676513672
      vf_explained_var: 0.0
      vf_loss: 0.0018255935283377767
    num_steps_sampled: 335000
    num_steps_trained: 335000
    wait_time_ms: 31.743
  iterations_since_restore: 241
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 10879
  policy_reward_mean: {}
  time_since_restore: 1782.0413010120392
  time_this_iter_s: 8.358417510986328
  time_total_s: 1782.0413010120392
  timestamp: 1594147280
  timesteps_since_restore: 335000
  timesteps_this_iter: 2000
  timesteps_total: 335000
  training_iteration: 241
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10879], 1782 s, 241 iter, 335000 ts, 78 rew

agent-1: 0.0
Sum Reward: 0.0
Avg Reward: 0.0
Min Reward: 0.0
Max Reward: 0.0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
agent-1: 0.0
Sum Reward: 0.0
Avg Reward: 0.0
Min Reward: 0.0
Max Reward: 0.0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_14-41-29
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 436.0
  episode_reward_mean: 73.54
  episode_reward_min: 0.0
  episodes_this_iter: 2
  episodes_total: 336
  experiment_id: cb3a18e0a26e466496590bc0542b68c4
  hostname: gpu020
  info:
    apply_time_ms: 2.508
    dispatch_time_ms: 9.774
    learner:
      cur_lr: 0.0013376889983192086
      grad_gnorm: 0.0264865942299366
      policy_entropy: 0.00021209647820796818
      policy_loss: -1.2720439812596851e-08
      var_gnorm: 29.77694320678711
      vf_explained_var: 1.1920928955078125e-07
      vf_loss: 4.816779437533114e-06
    num_steps_sampled: 337000
    num_steps_trained: 337000
    wait_time_ms: 29.951
  iterations_since_restore: 242
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 10879
  policy_reward_mean: {}
  time_since_restore: 1790.6075320243835
  time_this_iter_s: 8.56623101234436
  time_total_s: 1790.6075320243835
  timestamp: 1594147289
  timesteps_since_restore: 337000
  timesteps_this_iter: 2000
  timesteps_total: 337000
  training_iteration: 242
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10879], 1790 s, 242 iter, 337000 ts, 73.5 rew

agent-1: 0.0
Sum Reward: 0.0
Avg Reward: 0.0
Min Reward: 0.0
Max Reward: 0.0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
agent-1: 0.0
Sum Reward: 0.0
Avg Reward: 0.0
Min Reward: 0.0
Max Reward: 0.0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_14-41-37
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 436.0
  episode_reward_mean: 73.25
  episode_reward_min: 0.0
  episodes_this_iter: 2
  episodes_total: 338
  experiment_id: cb3a18e0a26e466496590bc0542b68c4
  hostname: gpu020
  info:
    apply_time_ms: 2.65
    dispatch_time_ms: 7.266
    learner:
      cur_lr: 0.0013375558191910386
      grad_gnorm: 0.19023562967777252
      policy_entropy: 0.0012522522592917085
      policy_loss: -6.367158675857354e-07
      var_gnorm: 29.776941299438477
      vf_explained_var: 0.0
      vf_loss: 0.0002554086095187813
    num_steps_sampled: 339000
    num_steps_trained: 339000
    wait_time_ms: 31.448
  iterations_since_restore: 243
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 10879
  policy_reward_mean: {}
  time_since_restore: 1799.230999469757
  time_this_iter_s: 8.623467445373535
  time_total_s: 1799.230999469757
  timestamp: 1594147297
  timesteps_since_restore: 339000
  timesteps_this_iter: 2000
  timesteps_total: 339000
  training_iteration: 243
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10879], 1799 s, 243 iter, 339000 ts, 73.2 rew

agent-1: 0.0
Sum Reward: 0.0
Avg Reward: 0.0
Min Reward: 0.0
Max Reward: 0.0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
agent-1: 0.0
Sum Reward: 0.0
Avg Reward: 0.0
Min Reward: 0.0
Max Reward: 0.0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_14-41-46
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 436.0
  episode_reward_mean: 73.03
  episode_reward_min: 0.0
  episodes_this_iter: 2
  episodes_total: 340
  experiment_id: cb3a18e0a26e466496590bc0542b68c4
  hostname: gpu020
  info:
    apply_time_ms: 2.624
    dispatch_time_ms: 6.599
    learner:
      cur_lr: 0.0013374226400628686
      grad_gnorm: 0.7555599212646484
      policy_entropy: 0.000999209238216281
      policy_loss: -1.994377498704125e-06
      var_gnorm: 29.776819229125977
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 0.003964862786233425
    num_steps_sampled: 341000
    num_steps_trained: 341000
    wait_time_ms: 32.519
  iterations_since_restore: 244
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 10879
  policy_reward_mean: {}
  time_since_restore: 1807.7573494911194
  time_this_iter_s: 8.526350021362305
  time_total_s: 1807.7573494911194
  timestamp: 1594147306
  timesteps_since_restore: 341000
  timesteps_this_iter: 2000
  timesteps_total: 341000
  training_iteration: 244
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10879], 1807 s, 244 iter, 341000 ts, 73 rew

agent-1: 0.0
Sum Reward: 0.0
Avg Reward: 0.0
Min Reward: 0.0
Max Reward: 0.0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
agent-1: 0.0
Sum Reward: 0.0
Avg Reward: 0.0
Min Reward: 0.0
Max Reward: 0.0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_14-41-54
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 436.0
  episode_reward_mean: 73.03
  episode_reward_min: 0.0
  episodes_this_iter: 2
  episodes_total: 342
  experiment_id: cb3a18e0a26e466496590bc0542b68c4
  hostname: gpu020
  info:
    apply_time_ms: 3.495
    dispatch_time_ms: 8.936
    learner:
      cur_lr: 0.0013372893445193768
      grad_gnorm: 0.11099451780319214
      policy_entropy: 0.0012718599755316973
      policy_loss: 1.5080946695888997e-06
      var_gnorm: 29.77541732788086
      vf_explained_var: 0.0
      vf_loss: 8.695544966030866e-05
    num_steps_sampled: 343000
    num_steps_trained: 343000
    wait_time_ms: 28.088
  iterations_since_restore: 245
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 10879
  policy_reward_mean: {}
  time_since_restore: 1816.3023433685303
  time_this_iter_s: 8.544993877410889
  time_total_s: 1816.3023433685303
  timestamp: 1594147314
  timesteps_since_restore: 343000
  timesteps_this_iter: 2000
  timesteps_total: 343000
  training_iteration: 245
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10879], 1816 s, 245 iter, 343000 ts, 73 rew

agent-1: 0.0
Sum Reward: 0.0
Avg Reward: 0.0
Min Reward: 0.0
Max Reward: 0.0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
agent-1: 0.0
Sum Reward: 0.0
Avg Reward: 0.0
Min Reward: 0.0
Max Reward: 0.0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_14-42-03
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 436.0
  episode_reward_mean: 72.86
  episode_reward_min: 0.0
  episodes_this_iter: 2
  episodes_total: 344
  experiment_id: cb3a18e0a26e466496590bc0542b68c4
  hostname: gpu020
  info:
    apply_time_ms: 2.699
    dispatch_time_ms: 6.564
    learner:
      cur_lr: 0.0013371561653912067
      grad_gnorm: 0.44162577390670776
      policy_entropy: 0.0012815839145332575
      policy_loss: 1.3659828255185857e-06
      var_gnorm: 29.775293350219727
      vf_explained_var: 0.0
      vf_loss: 0.0013765558833256364
    num_steps_sampled: 345000
    num_steps_trained: 345000
    wait_time_ms: 32.631
  iterations_since_restore: 246
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 10879
  policy_reward_mean: {}
  time_since_restore: 1824.8672168254852
  time_this_iter_s: 8.564873456954956
  time_total_s: 1824.8672168254852
  timestamp: 1594147323
  timesteps_since_restore: 345000
  timesteps_this_iter: 2000
  timesteps_total: 345000
  training_iteration: 246
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10879], 1824 s, 246 iter, 345000 ts, 72.9 rew

agent-1: 0.0
Sum Reward: 0.0
Avg Reward: 0.0
Min Reward: 0.0
Max Reward: 0.0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
agent-1: 0.0
Sum Reward: 0.0
Avg Reward: 0.0
Min Reward: 0.0
Max Reward: 0.0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_14-42-12
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 436.0
  episode_reward_mean: 72.83
  episode_reward_min: 0.0
  episodes_this_iter: 2
  episodes_total: 346
  experiment_id: cb3a18e0a26e466496590bc0542b68c4
  hostname: gpu020
  info:
    apply_time_ms: 2.766
    dispatch_time_ms: 7.272
    learner:
      cur_lr: 0.0013370229862630367
      grad_gnorm: 0.052171990275382996
      policy_entropy: 0.0002123419108102098
      policy_loss: 8.132298745522348e-08
      var_gnorm: 29.773639678955078
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 1.8689783246372826e-05
    num_steps_sampled: 347000
    num_steps_trained: 347000
    wait_time_ms: 32.117
  iterations_since_restore: 247
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 10879
  policy_reward_mean: {}
  time_since_restore: 1833.432109117508
  time_this_iter_s: 8.564892292022705
  time_total_s: 1833.432109117508
  timestamp: 1594147332
  timesteps_since_restore: 347000
  timesteps_this_iter: 2000
  timesteps_total: 347000
  training_iteration: 247
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10879], 1833 s, 247 iter, 347000 ts, 72.8 rew

agent-1: 0.0
Sum Reward: 0.0
Avg Reward: 0.0
Min Reward: 0.0
Max Reward: 0.0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
agent-1: 0.0
Sum Reward: 0.0
Avg Reward: 0.0
Min Reward: 0.0
Max Reward: 0.0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_14-42-20
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 436.0
  episode_reward_mean: 72.78
  episode_reward_min: 0.0
  episodes_this_iter: 2
  episodes_total: 348
  experiment_id: cb3a18e0a26e466496590bc0542b68c4
  hostname: gpu020
  info:
    apply_time_ms: 2.908
    dispatch_time_ms: 6.614
    learner:
      cur_lr: 0.0013368898071348667
      grad_gnorm: 0.016138585284352303
      policy_entropy: 0.00021234404994174838
      policy_loss: -1.3239536578169009e-08
      var_gnorm: 29.773530960083008
      vf_explained_var: 0.0
      vf_loss: 1.7894438997245743e-06
    num_steps_sampled: 349000
    num_steps_trained: 349000
    wait_time_ms: 33.707
  iterations_since_restore: 248
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 10879
  policy_reward_mean: {}
  time_since_restore: 1841.9647767543793
  time_this_iter_s: 8.532667636871338
  time_total_s: 1841.9647767543793
  timestamp: 1594147340
  timesteps_since_restore: 349000
  timesteps_this_iter: 2000
  timesteps_total: 349000
  training_iteration: 248
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10879], 1841 s, 248 iter, 349000 ts, 72.8 rew

agent-1: 0.0
Sum Reward: 0.0
Avg Reward: 0.0
Min Reward: 0.0
Max Reward: 0.0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
agent-1: 0.0
Sum Reward: 0.0
Avg Reward: 0.0
Min Reward: 0.0
Max Reward: 0.0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_14-42-29
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 436.0
  episode_reward_mean: 72.58
  episode_reward_min: 0.0
  episodes_this_iter: 2
  episodes_total: 350
  experiment_id: cb3a18e0a26e466496590bc0542b68c4
  hostname: gpu020
  info:
    apply_time_ms: 3.015
    dispatch_time_ms: 7.938
    learner:
      cur_lr: 0.0013367566280066967
      grad_gnorm: 0.008914059028029442
      policy_entropy: 0.0002123377489624545
      policy_loss: -6.818228204252819e-09
      var_gnorm: 29.773414611816406
      vf_explained_var: 0.0
      vf_loss: 5.459439762489637e-07
    num_steps_sampled: 351000
    num_steps_trained: 351000
    wait_time_ms: 32.455
  iterations_since_restore: 249
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 10879
  policy_reward_mean: {}
  time_since_restore: 1850.5336537361145
  time_this_iter_s: 8.56887698173523
  time_total_s: 1850.5336537361145
  timestamp: 1594147349
  timesteps_since_restore: 351000
  timesteps_this_iter: 2000
  timesteps_total: 351000
  training_iteration: 249
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10879], 1850 s, 249 iter, 351000 ts, 72.6 rew

agent-1: 0.0
Sum Reward: 0.0
Avg Reward: 0.0
Min Reward: 0.0
Max Reward: 0.0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
agent-1: 0.0
Sum Reward: 0.0
Avg Reward: 0.0
Min Reward: 0.0
Max Reward: 0.0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_14-42-37
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 436.0
  episode_reward_mean: 72.42
  episode_reward_min: 0.0
  episodes_this_iter: 2
  episodes_total: 352
  experiment_id: cb3a18e0a26e466496590bc0542b68c4
  hostname: gpu020
  info:
    apply_time_ms: 2.57
    dispatch_time_ms: 7.607
    learner:
      cur_lr: 0.0013366234488785267
      grad_gnorm: 0.467933714389801
      policy_entropy: 0.001309816725552082
      policy_loss: 1.4958114888941054e-06
      var_gnorm: 29.772422790527344
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 0.0015454550739377737
    num_steps_sampled: 353000
    num_steps_trained: 353000
    wait_time_ms: 33.633
  iterations_since_restore: 250
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 10879
  policy_reward_mean: {}
  time_since_restore: 1859.0912454128265
  time_this_iter_s: 8.557591676712036
  time_total_s: 1859.0912454128265
  timestamp: 1594147357
  timesteps_since_restore: 353000
  timesteps_this_iter: 2000
  timesteps_total: 353000
  training_iteration: 250
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10879], 1859 s, 250 iter, 353000 ts, 72.4 rew

agent-1: 0.0
Sum Reward: 0.0
Avg Reward: 0.0
Min Reward: 0.0
Max Reward: 0.0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
agent-1: 0.0
Sum Reward: 0.0
Avg Reward: 0.0
Min Reward: 0.0
Max Reward: 0.0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_14-42-46
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 436.0
  episode_reward_mean: 72.31
  episode_reward_min: 0.0
  episodes_this_iter: 2
  episodes_total: 354
  experiment_id: cb3a18e0a26e466496590bc0542b68c4
  hostname: gpu020
  info:
    apply_time_ms: 3.115
    dispatch_time_ms: 8.049
    learner:
      cur_lr: 0.0013364901533350348
      grad_gnorm: 0.003603447461500764
      policy_entropy: 0.00021246858523227274
      policy_loss: -2.997589376718679e-08
      var_gnorm: 29.771690368652344
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 8.92654483664046e-08
    num_steps_sampled: 355000
    num_steps_trained: 355000
    wait_time_ms: 31.779
  iterations_since_restore: 251
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 10879
  policy_reward_mean: {}
  time_since_restore: 1868.081526517868
  time_this_iter_s: 8.990281105041504
  time_total_s: 1868.081526517868
  timestamp: 1594147366
  timesteps_since_restore: 355000
  timesteps_this_iter: 2000
  timesteps_total: 355000
  training_iteration: 251
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10879], 1868 s, 251 iter, 355000 ts, 72.3 rew

agent-1: 0.0
Sum Reward: 0.0
Avg Reward: 0.0
Min Reward: 0.0
Max Reward: 0.0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
agent-1: 0.0
Sum Reward: 0.0
Avg Reward: 0.0
Min Reward: 0.0
Max Reward: 0.0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_14-42-55
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 436.0
  episode_reward_mean: 72.19
  episode_reward_min: 0.0
  episodes_this_iter: 2
  episodes_total: 356
  experiment_id: cb3a18e0a26e466496590bc0542b68c4
  hostname: gpu020
  info:
    apply_time_ms: 2.361
    dispatch_time_ms: 6.567
    learner:
      cur_lr: 0.0013363569742068648
      grad_gnorm: 0.00043625212856568396
      policy_entropy: 0.00021245836978778243
      policy_loss: -3.1266731426171646e-09
      var_gnorm: 29.771522521972656
      vf_explained_var: 1.1920928955078125e-07
      vf_loss: 1.329641619030042e-09
    num_steps_sampled: 357000
    num_steps_trained: 357000
    wait_time_ms: 33.763
  iterations_since_restore: 252
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 10879
  policy_reward_mean: {}
  time_since_restore: 1876.6854400634766
  time_this_iter_s: 8.60391354560852
  time_total_s: 1876.6854400634766
  timestamp: 1594147375
  timesteps_since_restore: 357000
  timesteps_this_iter: 2000
  timesteps_total: 357000
  training_iteration: 252
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10879], 1876 s, 252 iter, 357000 ts, 72.2 rew

agent-1: 0.0
Sum Reward: 0.0
Avg Reward: 0.0
Min Reward: 0.0
Max Reward: 0.0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
agent-1: 0.0
Sum Reward: 0.0
Avg Reward: 0.0
Min Reward: 0.0
Max Reward: 0.0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_14-43-04
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 436.0
  episode_reward_mean: 72.08
  episode_reward_min: 0.0
  episodes_this_iter: 2
  episodes_total: 358
  experiment_id: cb3a18e0a26e466496590bc0542b68c4
  hostname: gpu020
  info:
    apply_time_ms: 3.242
    dispatch_time_ms: 9.414
    learner:
      cur_lr: 0.0013362237950786948
      grad_gnorm: 0.00986725464463234
      policy_entropy: 0.00021244848903734237
      policy_loss: 4.269693931746588e-09
      var_gnorm: 29.77134132385254
      vf_explained_var: 0.0
      vf_loss: 6.685950211249292e-07
    num_steps_sampled: 359000
    num_steps_trained: 359000
    wait_time_ms: 26.602
  iterations_since_restore: 253
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 10879
  policy_reward_mean: {}
  time_since_restore: 1885.2086515426636
  time_this_iter_s: 8.523211479187012
  time_total_s: 1885.2086515426636
  timestamp: 1594147384
  timesteps_since_restore: 359000
  timesteps_this_iter: 2000
  timesteps_total: 359000
  training_iteration: 253
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10879], 1885 s, 253 iter, 359000 ts, 72.1 rew

agent-1: 0.0
Sum Reward: 0.0
Avg Reward: 0.0
Min Reward: 0.0
Max Reward: 0.0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
agent-1: 0.0
Sum Reward: 0.0
Avg Reward: 0.0
Min Reward: 0.0
Max Reward: 0.0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_14-43-12
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 436.0
  episode_reward_mean: 72.01
  episode_reward_min: 0.0
  episodes_this_iter: 2
  episodes_total: 360
  experiment_id: cb3a18e0a26e466496590bc0542b68c4
  hostname: gpu020
  info:
    apply_time_ms: 2.637
    dispatch_time_ms: 6.825
    learner:
      cur_lr: 0.0013360906159505248
      grad_gnorm: 0.5355350375175476
      policy_entropy: 0.00021249217388685793
      policy_loss: 2.4678041654624394e-07
      var_gnorm: 29.77103614807129
      vf_explained_var: 0.0
      vf_loss: 0.0019691670313477516
    num_steps_sampled: 361000
    num_steps_trained: 361000
    wait_time_ms: 36.369
  iterations_since_restore: 254
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 10879
  policy_reward_mean: {}
  time_since_restore: 1893.8441336154938
  time_this_iter_s: 8.6354820728302
  time_total_s: 1893.8441336154938
  timestamp: 1594147392
  timesteps_since_restore: 361000
  timesteps_this_iter: 2000
  timesteps_total: 361000
  training_iteration: 254
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10879], 1893 s, 254 iter, 361000 ts, 72 rew

agent-1: 0.0
Sum Reward: 0.0
Avg Reward: 0.0
Min Reward: 0.0
Max Reward: 0.0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
agent-1: 0.0
Sum Reward: 0.0
Avg Reward: 0.0
Min Reward: 0.0
Max Reward: 0.0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_14-43-21
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 436.0
  episode_reward_mean: 70.3
  episode_reward_min: 0.0
  episodes_this_iter: 2
  episodes_total: 362
  experiment_id: cb3a18e0a26e466496590bc0542b68c4
  hostname: gpu020
  info:
    apply_time_ms: 3.008
    dispatch_time_ms: 7.736
    learner:
      cur_lr: 0.0013359574368223548
      grad_gnorm: 0.8548011779785156
      policy_entropy: 0.009369208477437496
      policy_loss: -2.2701729903928936e-05
      var_gnorm: 29.772512435913086
      vf_explained_var: 5.960464477539063e-08
      vf_loss: 0.005074842367321253
    num_steps_sampled: 363000
    num_steps_trained: 363000
    wait_time_ms: 31.197
  iterations_since_restore: 255
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 10879
  policy_reward_mean: {}
  time_since_restore: 1902.3722109794617
  time_this_iter_s: 8.528077363967896
  time_total_s: 1902.3722109794617
  timestamp: 1594147401
  timesteps_since_restore: 363000
  timesteps_this_iter: 2000
  timesteps_total: 363000
  training_iteration: 255
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10879], 1902 s, 255 iter, 363000 ts, 70.3 rew

agent-1: 0.0
Sum Reward: 0.0
Avg Reward: 0.0
Min Reward: 0.0
Max Reward: 0.0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
agent-1: 0.0
Sum Reward: 0.0
Avg Reward: 0.0
Min Reward: 0.0
Max Reward: 0.0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_14-43-30
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 436.0
  episode_reward_mean: 63.37
  episode_reward_min: 0.0
  episodes_this_iter: 2
  episodes_total: 364
  experiment_id: cb3a18e0a26e466496590bc0542b68c4
  hostname: gpu020
  info:
    apply_time_ms: 2.919
    dispatch_time_ms: 6.704
    learner:
      cur_lr: 0.0013358242576941848
      grad_gnorm: 0.15288573503494263
      policy_entropy: 0.0019099849741905928
      policy_loss: 1.0216253940598108e-06
      var_gnorm: 29.781137466430664
      vf_explained_var: 0.0
      vf_loss: 0.00016498210607096553
    num_steps_sampled: 365000
    num_steps_trained: 365000
    wait_time_ms: 33.389
  iterations_since_restore: 256
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 10879
  policy_reward_mean: {}
  time_since_restore: 1910.9445204734802
  time_this_iter_s: 8.572309494018555
  time_total_s: 1910.9445204734802
  timestamp: 1594147410
  timesteps_since_restore: 365000
  timesteps_this_iter: 2000
  timesteps_total: 365000
  training_iteration: 256
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10879], 1910 s, 256 iter, 365000 ts, 63.4 rew

agent-1: 0.0
Sum Reward: 0.0
Avg Reward: 0.0
Min Reward: 0.0
Max Reward: 0.0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
agent-1: 0.0
Sum Reward: 0.0
Avg Reward: 0.0
Min Reward: 0.0
Max Reward: 0.0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_14-43-38
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 436.0
  episode_reward_mean: 55.74
  episode_reward_min: 0.0
  episodes_this_iter: 2
  episodes_total: 366
  experiment_id: cb3a18e0a26e466496590bc0542b68c4
  hostname: gpu020
  info:
    apply_time_ms: 2.611
    dispatch_time_ms: 9.403
    learner:
      cur_lr: 0.001335690962150693
      grad_gnorm: 0.19319286942481995
      policy_entropy: 0.0015157925663515925
      policy_loss: -7.392424663521524e-07
      var_gnorm: 29.781211853027344
      vf_explained_var: 5.960464477539063e-08
      vf_loss: 0.00025923101929947734
    num_steps_sampled: 367000
    num_steps_trained: 367000
    wait_time_ms: 29.807
  iterations_since_restore: 257
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 10879
  policy_reward_mean: {}
  time_since_restore: 1919.4825313091278
  time_this_iter_s: 8.538010835647583
  time_total_s: 1919.4825313091278
  timestamp: 1594147418
  timesteps_since_restore: 367000
  timesteps_this_iter: 2000
  timesteps_total: 367000
  training_iteration: 257
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10879], 1919 s, 257 iter, 367000 ts, 55.7 rew

agent-1: 0.0
Sum Reward: 0.0
Avg Reward: 0.0
Min Reward: 0.0
Max Reward: 0.0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
agent-1: 0.0
Sum Reward: 0.0
Avg Reward: 0.0
Min Reward: 0.0
Max Reward: 0.0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_14-43-47
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 436.0
  episode_reward_mean: 48.19
  episode_reward_min: 0.0
  episodes_this_iter: 2
  episodes_total: 368
  experiment_id: cb3a18e0a26e466496590bc0542b68c4
  hostname: gpu020
  info:
    apply_time_ms: 3.203
    dispatch_time_ms: 6.601
    learner:
      cur_lr: 0.001335557783022523
      grad_gnorm: 0.15719683468341827
      policy_entropy: 0.0019179636146873236
      policy_loss: 7.733595452918962e-07
      var_gnorm: 29.77964973449707
      vf_explained_var: 0.0
      vf_loss: 0.00017440934607293457
    num_steps_sampled: 369000
    num_steps_trained: 369000
    wait_time_ms: 33.614
  iterations_since_restore: 258
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 10879
  policy_reward_mean: {}
  time_since_restore: 1928.0536155700684
  time_this_iter_s: 8.571084260940552
  time_total_s: 1928.0536155700684
  timestamp: 1594147427
  timesteps_since_restore: 369000
  timesteps_this_iter: 2000
  timesteps_total: 369000
  training_iteration: 258
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10879], 1928 s, 258 iter, 369000 ts, 48.2 rew

agent-1: 0.0
Sum Reward: 0.0
Avg Reward: 0.0
Min Reward: 0.0
Max Reward: 0.0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
agent-1: 0.0
Sum Reward: 0.0
Avg Reward: 0.0
Min Reward: 0.0
Max Reward: 0.0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_14-43-55
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 428.0
  episode_reward_mean: 39.65
  episode_reward_min: 0.0
  episodes_this_iter: 2
  episodes_total: 370
  experiment_id: cb3a18e0a26e466496590bc0542b68c4
  hostname: gpu020
  info:
    apply_time_ms: 3.16
    dispatch_time_ms: 8.152
    learner:
      cur_lr: 0.001335424603894353
      grad_gnorm: 0.4624139368534088
      policy_entropy: 0.013886545784771442
      policy_loss: -2.1951123926555738e-05
      var_gnorm: 29.78565216064453
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 0.0014851161977276206
    num_steps_sampled: 371000
    num_steps_trained: 371000
    wait_time_ms: 33.365
  iterations_since_restore: 259
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 10879
  policy_reward_mean: {}
  time_since_restore: 1936.7060296535492
  time_this_iter_s: 8.652414083480835
  time_total_s: 1936.7060296535492
  timestamp: 1594147435
  timesteps_since_restore: 371000
  timesteps_this_iter: 2000
  timesteps_total: 371000
  training_iteration: 259
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10879], 1936 s, 259 iter, 371000 ts, 39.6 rew

agent-1: 0.0
Sum Reward: 0.0
Avg Reward: 0.0
Min Reward: 0.0
Max Reward: 0.0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
agent-1: 0.0
Sum Reward: 0.0
Avg Reward: 0.0
Min Reward: 0.0
Max Reward: 0.0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_14-44-04
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 358.0
  episode_reward_mean: 31.54
  episode_reward_min: 0.0
  episodes_this_iter: 2
  episodes_total: 372
  experiment_id: cb3a18e0a26e466496590bc0542b68c4
  hostname: gpu020
  info:
    apply_time_ms: 2.527
    dispatch_time_ms: 7.32
    learner:
      cur_lr: 0.001335291424766183
      grad_gnorm: 0.07073361426591873
      policy_entropy: 0.0018617698224261403
      policy_loss: -4.1706564957166847e-07
      var_gnorm: 29.788681030273438
      vf_explained_var: 0.0
      vf_loss: 3.4748594771372154e-05
    num_steps_sampled: 373000
    num_steps_trained: 373000
    wait_time_ms: 29.972
  iterations_since_restore: 260
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 10879
  policy_reward_mean: {}
  time_since_restore: 1945.2537467479706
  time_this_iter_s: 8.547717094421387
  time_total_s: 1945.2537467479706
  timestamp: 1594147444
  timesteps_since_restore: 373000
  timesteps_this_iter: 2000
  timesteps_total: 373000
  training_iteration: 260
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10879], 1945 s, 260 iter, 373000 ts, 31.5 rew

agent-1: 0.0
Sum Reward: 0.0
Avg Reward: 0.0
Min Reward: 0.0
Max Reward: 0.0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
agent-1: 0.0
Sum Reward: 0.0
Avg Reward: 0.0
Min Reward: 0.0
Max Reward: 0.0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_14-44-13
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 357.0
  episode_reward_mean: 24.6
  episode_reward_min: 0.0
  episodes_this_iter: 2
  episodes_total: 374
  experiment_id: cb3a18e0a26e466496590bc0542b68c4
  hostname: gpu020
  info:
    apply_time_ms: 3.124
    dispatch_time_ms: 6.319
    learner:
      cur_lr: 0.0013351582456380129
      grad_gnorm: 0.1639372706413269
      policy_entropy: 0.00022348901256918907
      policy_loss: -7.887683040053162e-08
      var_gnorm: 29.786922454833984
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 0.00018453712982591242
    num_steps_sampled: 375000
    num_steps_trained: 375000
    wait_time_ms: 33.753
  iterations_since_restore: 261
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 10879
  policy_reward_mean: {}
  time_since_restore: 1953.8247101306915
  time_this_iter_s: 8.570963382720947
  time_total_s: 1953.8247101306915
  timestamp: 1594147453
  timesteps_since_restore: 375000
  timesteps_this_iter: 2000
  timesteps_total: 375000
  training_iteration: 261
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10879], 1953 s, 261 iter, 375000 ts, 24.6 rew

agent-1: 0.0
Sum Reward: 0.0
Avg Reward: 0.0
Min Reward: 0.0
Max Reward: 0.0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
agent-1: 0.0
Sum Reward: 0.0
Avg Reward: 0.0
Min Reward: 0.0
Max Reward: 0.0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_14-44-21
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 357.0
  episode_reward_mean: 17.71
  episode_reward_min: 0.0
  episodes_this_iter: 2
  episodes_total: 376
  experiment_id: cb3a18e0a26e466496590bc0542b68c4
  hostname: gpu020
  info:
    apply_time_ms: 2.948
    dispatch_time_ms: 7.511
    learner:
      cur_lr: 0.001335024950094521
      grad_gnorm: 0.023360008373856544
      policy_entropy: 0.00022341875592246652
      policy_loss: 1.1033309377239675e-08
      var_gnorm: 29.786760330200195
      vf_explained_var: 0.0
      vf_loss: 3.7481570416275645e-06
    num_steps_sampled: 377000
    num_steps_trained: 377000
    wait_time_ms: 32.641
  iterations_since_restore: 262
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 10879
  policy_reward_mean: {}
  time_since_restore: 1962.401218175888
  time_this_iter_s: 8.576508045196533
  time_total_s: 1962.401218175888
  timestamp: 1594147461
  timesteps_since_restore: 377000
  timesteps_this_iter: 2000
  timesteps_total: 377000
  training_iteration: 262
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10879], 1962 s, 262 iter, 377000 ts, 17.7 rew

agent-1: 0.0
Sum Reward: 0.0
Avg Reward: 0.0
Min Reward: 0.0
Max Reward: 0.0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
agent-1: 0.0
Sum Reward: 0.0
Avg Reward: 0.0
Min Reward: 0.0
Max Reward: 0.0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_14-44-30
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 346.0
  episode_reward_mean: 10.77
  episode_reward_min: 0.0
  episodes_this_iter: 2
  episodes_total: 378
  experiment_id: cb3a18e0a26e466496590bc0542b68c4
  hostname: gpu020
  info:
    apply_time_ms: 2.569
    dispatch_time_ms: 7.738
    learner:
      cur_lr: 0.001334891770966351
      grad_gnorm: 0.027042455971240997
      policy_entropy: 0.0002233533887192607
      policy_loss: 1.315440911753285e-08
      var_gnorm: 29.786426544189453
      vf_explained_var: 0.0
      vf_loss: 5.021630840928992e-06
    num_steps_sampled: 379000
    num_steps_trained: 379000
    wait_time_ms: 33.532
  iterations_since_restore: 263
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 10879
  policy_reward_mean: {}
  time_since_restore: 1970.9109704494476
  time_this_iter_s: 8.50975227355957
  time_total_s: 1970.9109704494476
  timestamp: 1594147470
  timesteps_since_restore: 379000
  timesteps_this_iter: 2000
  timesteps_total: 379000
  training_iteration: 263
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10879], 1970 s, 263 iter, 379000 ts, 10.8 rew

agent-1: 0.0
Sum Reward: 0.0
Avg Reward: 0.0
Min Reward: 0.0
Max Reward: 0.0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
agent-1: 0.0
Sum Reward: 0.0
Avg Reward: 0.0
Min Reward: 0.0
Max Reward: 0.0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_14-44-38
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 214.0
  episode_reward_mean: 4.26
  episode_reward_min: 0.0
  episodes_this_iter: 2
  episodes_total: 380
  experiment_id: cb3a18e0a26e466496590bc0542b68c4
  hostname: gpu020
  info:
    apply_time_ms: 2.836
    dispatch_time_ms: 8.585
    learner:
      cur_lr: 0.001334758591838181
      grad_gnorm: 0.011565000750124454
      policy_entropy: 0.00022330920910462737
      policy_loss: 5.900992583462994e-09
      var_gnorm: 29.786121368408203
      vf_explained_var: 0.0
      vf_loss: 9.185623071061855e-07
    num_steps_sampled: 381000
    num_steps_trained: 381000
    wait_time_ms: 31.247
  iterations_since_restore: 264
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 10879
  policy_reward_mean: {}
  time_since_restore: 1979.4628446102142
  time_this_iter_s: 8.551874160766602
  time_total_s: 1979.4628446102142
  timestamp: 1594147478
  timesteps_since_restore: 381000
  timesteps_this_iter: 2000
  timesteps_total: 381000
  training_iteration: 264
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10879], 1979 s, 264 iter, 381000 ts, 4.26 rew

agent-1: 0.0
Sum Reward: 0.0
Avg Reward: 0.0
Min Reward: 0.0
Max Reward: 0.0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
agent-1: 0.0
Sum Reward: 0.0
Avg Reward: 0.0
Min Reward: 0.0
Max Reward: 0.0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_14-44-47
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 65.0
  episode_reward_mean: 0.87
  episode_reward_min: 0.0
  episodes_this_iter: 2
  episodes_total: 382
  experiment_id: cb3a18e0a26e466496590bc0542b68c4
  hostname: gpu020
  info:
    apply_time_ms: 3.549
    dispatch_time_ms: 8.774
    learner:
      cur_lr: 0.001334625412710011
      grad_gnorm: 0.06368128955364227
      policy_entropy: 0.00022344241733662784
      policy_loss: -3.163677320117131e-08
      var_gnorm: 29.786151885986328
      vf_explained_var: 0.0
      vf_loss: 2.7844431315315887e-05
    num_steps_sampled: 383000
    num_steps_trained: 383000
    wait_time_ms: 30.782
  iterations_since_restore: 265
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 10879
  policy_reward_mean: {}
  time_since_restore: 1988.047779560089
  time_this_iter_s: 8.584934949874878
  time_total_s: 1988.047779560089
  timestamp: 1594147487
  timesteps_since_restore: 383000
  timesteps_this_iter: 2000
  timesteps_total: 383000
  training_iteration: 265
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10879], 1988 s, 265 iter, 383000 ts, 0.87 rew

agent-1: 0.0
Sum Reward: 0.0
Avg Reward: 0.0
Min Reward: 0.0
Max Reward: 0.0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
agent-1: 0.0
Sum Reward: 0.0
Avg Reward: 0.0
Min Reward: 0.0
Max Reward: 0.0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_14-44-55
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: 0.0
  episode_reward_min: 0.0
  episodes_this_iter: 2
  episodes_total: 384
  experiment_id: cb3a18e0a26e466496590bc0542b68c4
  hostname: gpu020
  info:
    apply_time_ms: 2.911
    dispatch_time_ms: 5.477
    learner:
      cur_lr: 0.001334492233581841
      grad_gnorm: 0.2738916873931885
      policy_entropy: 0.0018194373697042465
      policy_loss: -1.013669248095539e-06
      var_gnorm: 29.785907745361328
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 0.0005210260860621929
    num_steps_sampled: 385000
    num_steps_trained: 385000
    wait_time_ms: 33.079
  iterations_since_restore: 266
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 10879
  policy_reward_mean: {}
  time_since_restore: 1996.5388569831848
  time_this_iter_s: 8.491077423095703
  time_total_s: 1996.5388569831848
  timestamp: 1594147495
  timesteps_since_restore: 385000
  timesteps_this_iter: 2000
  timesteps_total: 385000
  training_iteration: 266
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10879], 1996 s, 266 iter, 385000 ts, 0 rew

agent-1: 0.0
Sum Reward: 0.0
Avg Reward: 0.0
Min Reward: 0.0
Max Reward: 0.0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
agent-1: 0.0
Sum Reward: 0.0
Avg Reward: 0.0
Min Reward: 0.0
Max Reward: 0.0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_14-45-04
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: 0.0
  episode_reward_min: 0.0
  episodes_this_iter: 2
  episodes_total: 386
  experiment_id: cb3a18e0a26e466496590bc0542b68c4
  hostname: gpu020
  info:
    apply_time_ms: 2.564
    dispatch_time_ms: 8.393
    learner:
      cur_lr: 0.001334359054453671
      grad_gnorm: 0.031370118260383606
      policy_entropy: 0.00022424166672863066
      policy_loss: 1.3845518509469912e-08
      var_gnorm: 29.784950256347656
      vf_explained_var: 1.1920928955078125e-07
      vf_loss: 6.757379651389783e-06
    num_steps_sampled: 387000
    num_steps_trained: 387000
    wait_time_ms: 33.73
  iterations_since_restore: 267
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 10879
  policy_reward_mean: {}
  time_since_restore: 2005.1127660274506
  time_this_iter_s: 8.573909044265747
  time_total_s: 2005.1127660274506
  timestamp: 1594147504
  timesteps_since_restore: 387000
  timesteps_this_iter: 2000
  timesteps_total: 387000
  training_iteration: 267
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10879], 2005 s, 267 iter, 387000 ts, 0 rew

agent-1: 0.0
Sum Reward: 0.0
Avg Reward: 0.0
Min Reward: 0.0
Max Reward: 0.0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
agent-1: 0.0
Sum Reward: 0.0
Avg Reward: 0.0
Min Reward: 0.0
Max Reward: 0.0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_14-45-13
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: 0.0
  episode_reward_min: 0.0
  episodes_this_iter: 2
  episodes_total: 388
  experiment_id: cb3a18e0a26e466496590bc0542b68c4
  hostname: gpu020
  info:
    apply_time_ms: 3.166
    dispatch_time_ms: 9.211
    learner:
      cur_lr: 0.0013342257589101791
      grad_gnorm: 0.02205449342727661
      policy_entropy: 0.0022672393824905157
      policy_loss: 1.593226954810234e-07
      var_gnorm: 29.783235549926758
      vf_explained_var: 0.0
      vf_loss: 3.4325589695072267e-06
    num_steps_sampled: 389000
    num_steps_trained: 389000
    wait_time_ms: 31.471
  iterations_since_restore: 268
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 10879
  policy_reward_mean: {}
  time_since_restore: 2014.0673651695251
  time_this_iter_s: 8.954599142074585
  time_total_s: 2014.0673651695251
  timestamp: 1594147513
  timesteps_since_restore: 389000
  timesteps_this_iter: 2000
  timesteps_total: 389000
  training_iteration: 268
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10879], 2014 s, 268 iter, 389000 ts, 0 rew

agent-1: 0.0
Sum Reward: 0.0
Avg Reward: 0.0
Min Reward: 0.0
Max Reward: 0.0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
agent-1: 0.0
Sum Reward: 0.0
Avg Reward: 0.0
Min Reward: 0.0
Max Reward: 0.0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_14-45-22
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: 0.0
  episode_reward_min: 0.0
  episodes_this_iter: 2
  episodes_total: 390
  experiment_id: cb3a18e0a26e466496590bc0542b68c4
  hostname: gpu020
  info:
    apply_time_ms: 3.677
    dispatch_time_ms: 9.327
    learner:
      cur_lr: 0.0013340925797820091
      grad_gnorm: 0.0318928025662899
      policy_entropy: 0.0002239766763523221
      policy_loss: -2.1131473459945482e-08
      var_gnorm: 29.783794403076172
      vf_explained_var: 0.0
      vf_loss: 6.984423635003623e-06
    num_steps_sampled: 391000
    num_steps_trained: 391000
    wait_time_ms: 31.64
  iterations_since_restore: 269
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 10879
  policy_reward_mean: {}
  time_since_restore: 2022.586966753006
  time_this_iter_s: 8.519601583480835
  time_total_s: 2022.586966753006
  timestamp: 1594147522
  timesteps_since_restore: 391000
  timesteps_this_iter: 2000
  timesteps_total: 391000
  training_iteration: 269
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10879], 2022 s, 269 iter, 391000 ts, 0 rew

agent-1: 0.0
Sum Reward: 0.0
Avg Reward: 0.0
Min Reward: 0.0
Max Reward: 0.0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
agent-1: 0.0
Sum Reward: 0.0
Avg Reward: 0.0
Min Reward: 0.0
Max Reward: 0.0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_14-45-30
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: 0.0
  episode_reward_min: 0.0
  episodes_this_iter: 2
  episodes_total: 392
  experiment_id: cb3a18e0a26e466496590bc0542b68c4
  hostname: gpu020
  info:
    apply_time_ms: 3.037
    dispatch_time_ms: 8.584
    learner:
      cur_lr: 0.0013339594006538391
      grad_gnorm: 0.041350897401571274
      policy_entropy: 0.002301991218701005
      policy_loss: 2.654720958616963e-07
      var_gnorm: 29.7838077545166
      vf_explained_var: 0.0
      vf_loss: 1.2066737326676957e-05
    num_steps_sampled: 393000
    num_steps_trained: 393000
    wait_time_ms: 30.74
  iterations_since_restore: 270
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 10879
  policy_reward_mean: {}
  time_since_restore: 2031.1456162929535
  time_this_iter_s: 8.55864953994751
  time_total_s: 2031.1456162929535
  timestamp: 1594147530
  timesteps_since_restore: 393000
  timesteps_this_iter: 2000
  timesteps_total: 393000
  training_iteration: 270
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10879], 2031 s, 270 iter, 393000 ts, 0 rew

agent-1: 0.0
Sum Reward: 0.0
Avg Reward: 0.0
Min Reward: 0.0
Max Reward: 0.0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
agent-1: 0.0
Sum Reward: 0.0
Avg Reward: 0.0
Min Reward: 0.0
Max Reward: 0.0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_14-45-39
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: 0.0
  episode_reward_min: 0.0
  episodes_this_iter: 2
  episodes_total: 394
  experiment_id: cb3a18e0a26e466496590bc0542b68c4
  hostname: gpu020
  info:
    apply_time_ms: 4.135
    dispatch_time_ms: 9.303
    learner:
      cur_lr: 0.001333826221525669
      grad_gnorm: 0.14365814626216888
      policy_entropy: 0.01548561081290245
      policy_loss: -1.0657855455065146e-05
      var_gnorm: 29.7889461517334
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 0.00014169969654176384
    num_steps_sampled: 395000
    num_steps_trained: 395000
    wait_time_ms: 29.82
  iterations_since_restore: 271
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 10879
  policy_reward_mean: {}
  time_since_restore: 2039.679342508316
  time_this_iter_s: 8.533726215362549
  time_total_s: 2039.679342508316
  timestamp: 1594147539
  timesteps_since_restore: 395000
  timesteps_this_iter: 2000
  timesteps_total: 395000
  training_iteration: 271
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10879], 2039 s, 271 iter, 395000 ts, 0 rew

agent-1: 0.0
Sum Reward: 0.0
Avg Reward: 0.0
Min Reward: 0.0
Max Reward: 0.0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
agent-1: 0.0
Sum Reward: 0.0
Avg Reward: 0.0
Min Reward: 0.0
Max Reward: 0.0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_14-45-47
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: 0.0
  episode_reward_min: 0.0
  episodes_this_iter: 2
  episodes_total: 396
  experiment_id: cb3a18e0a26e466496590bc0542b68c4
  hostname: gpu020
  info:
    apply_time_ms: 3.5
    dispatch_time_ms: 8.027
    learner:
      cur_lr: 0.001333693042397499
      grad_gnorm: 0.19804328680038452
      policy_entropy: 0.0022377423010766506
      policy_loss: -1.2872383194917347e-06
      var_gnorm: 29.792316436767578
      vf_explained_var: 0.0
      vf_loss: 0.00027240082272328436
    num_steps_sampled: 397000
    num_steps_trained: 397000
    wait_time_ms: 31.111
  iterations_since_restore: 272
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 10879
  policy_reward_mean: {}
  time_since_restore: 2048.2034623622894
  time_this_iter_s: 8.524119853973389
  time_total_s: 2048.2034623622894
  timestamp: 1594147547
  timesteps_since_restore: 397000
  timesteps_this_iter: 2000
  timesteps_total: 397000
  training_iteration: 272
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10879], 2048 s, 272 iter, 397000 ts, 0 rew

agent-1: 0.0
Sum Reward: 0.0
Avg Reward: 0.0
Min Reward: 0.0
Max Reward: 0.0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
agent-1: 0.0
Sum Reward: 0.0
Avg Reward: 0.0
Min Reward: 0.0
Max Reward: 0.0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_14-45-56
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: 0.0
  episode_reward_min: 0.0
  episodes_this_iter: 2
  episodes_total: 398
  experiment_id: cb3a18e0a26e466496590bc0542b68c4
  hostname: gpu020
  info:
    apply_time_ms: 2.607
    dispatch_time_ms: 9.506
    learner:
      cur_lr: 0.0013335597468540072
      grad_gnorm: 0.003540712408721447
      policy_entropy: 0.00024063719320110977
      policy_loss: -1.828771090117698e-08
      var_gnorm: 29.79436492919922
      vf_explained_var: 0.0
      vf_loss: 8.614976820808806e-08
    num_steps_sampled: 399000
    num_steps_trained: 399000
    wait_time_ms: 32.487
  iterations_since_restore: 273
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 10879
  policy_reward_mean: {}
  time_since_restore: 2056.79443192482
  time_this_iter_s: 8.590969562530518
  time_total_s: 2056.79443192482
  timestamp: 1594147556
  timesteps_since_restore: 399000
  timesteps_this_iter: 2000
  timesteps_total: 399000
  training_iteration: 273
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10879], 2056 s, 273 iter, 399000 ts, 0 rew

agent-1: 0.0
Sum Reward: 0.0
Avg Reward: 0.0
Min Reward: 0.0
Max Reward: 0.0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
agent-1: 0.0
Sum Reward: 0.0
Avg Reward: 0.0
Min Reward: 0.0
Max Reward: 0.0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_14-46-05
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: 0.0
  episode_reward_min: 0.0
  episodes_this_iter: 2
  episodes_total: 400
  experiment_id: cb3a18e0a26e466496590bc0542b68c4
  hostname: gpu020
  info:
    apply_time_ms: 3.249
    dispatch_time_ms: 8.677
    learner:
      cur_lr: 0.0013334265677258372
      grad_gnorm: 0.13394221663475037
      policy_entropy: 0.00023989632609300315
      policy_loss: -7.222032394338385e-08
      var_gnorm: 29.793153762817383
      vf_explained_var: 0.0
      vf_loss: 0.00012318251538090408
    num_steps_sampled: 401000
    num_steps_trained: 401000
    wait_time_ms: 30.587
  iterations_since_restore: 274
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 10879
  policy_reward_mean: {}
  time_since_restore: 2065.365063428879
  time_this_iter_s: 8.570631504058838
  time_total_s: 2065.365063428879
  timestamp: 1594147565
  timesteps_since_restore: 401000
  timesteps_this_iter: 2000
  timesteps_total: 401000
  training_iteration: 274
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10879], 2065 s, 274 iter, 401000 ts, 0 rew

agent-1: 0.0
Sum Reward: 0.0
Avg Reward: 0.0
Min Reward: 0.0
Max Reward: 0.0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
agent-1: 0.0
Sum Reward: 0.0
Avg Reward: 0.0
Min Reward: 0.0
Max Reward: 0.0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_14-46-13
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: 0.0
  episode_reward_min: 0.0
  episodes_this_iter: 2
  episodes_total: 402
  experiment_id: cb3a18e0a26e466496590bc0542b68c4
  hostname: gpu020
  info:
    apply_time_ms: 3.316
    dispatch_time_ms: 8.238
    learner:
      cur_lr: 0.0013332933885976672
      grad_gnorm: 0.022547617554664612
      policy_entropy: 0.00024027949257288128
      policy_loss: 1.152267792292605e-08
      var_gnorm: 29.793088912963867
      vf_explained_var: 0.0
      vf_loss: 3.4901815979537787e-06
    num_steps_sampled: 403000
    num_steps_trained: 403000
    wait_time_ms: 33.748
  iterations_since_restore: 275
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 10879
  policy_reward_mean: {}
  time_since_restore: 2073.910367488861
  time_this_iter_s: 8.5453040599823
  time_total_s: 2073.910367488861
  timestamp: 1594147573
  timesteps_since_restore: 403000
  timesteps_this_iter: 2000
  timesteps_total: 403000
  training_iteration: 275
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10879], 2073 s, 275 iter, 403000 ts, 0 rew

agent-1: 0.0
Sum Reward: 0.0
Avg Reward: 0.0
Min Reward: 0.0
Max Reward: 0.0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
agent-1: 0.0
Sum Reward: 0.0
Avg Reward: 0.0
Min Reward: 0.0
Max Reward: 0.0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_14-46-22
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: 0.0
  episode_reward_min: 0.0
  episodes_this_iter: 2
  episodes_total: 404
  experiment_id: cb3a18e0a26e466496590bc0542b68c4
  hostname: gpu020
  info:
    apply_time_ms: 2.979
    dispatch_time_ms: 7.523
    learner:
      cur_lr: 0.0013331602094694972
      grad_gnorm: 0.180167555809021
      policy_entropy: 0.00024164517526514828
      policy_loss: 6.653615969298698e-08
      var_gnorm: 29.79300880432129
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 0.00022286192688625306
    num_steps_sampled: 405000
    num_steps_trained: 405000
    wait_time_ms: 33.187
  iterations_since_restore: 276
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 10879
  policy_reward_mean: {}
  time_since_restore: 2082.444636106491
  time_this_iter_s: 8.534268617630005
  time_total_s: 2082.444636106491
  timestamp: 1594147582
  timesteps_since_restore: 405000
  timesteps_this_iter: 2000
  timesteps_total: 405000
  training_iteration: 276
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10879], 2082 s, 276 iter, 405000 ts, 0 rew

agent-1: 0.0
Sum Reward: 0.0
Avg Reward: 0.0
Min Reward: 0.0
Max Reward: 0.0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
agent-1: 0.0
Sum Reward: 0.0
Avg Reward: 0.0
Min Reward: 0.0
Max Reward: 0.0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_14-46-30
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: 0.0
  episode_reward_min: 0.0
  episodes_this_iter: 2
  episodes_total: 406
  experiment_id: cb3a18e0a26e466496590bc0542b68c4
  hostname: gpu020
  info:
    apply_time_ms: 3.985
    dispatch_time_ms: 9.456
    learner:
      cur_lr: 0.0013330270303413272
      grad_gnorm: 0.030695291236042976
      policy_entropy: 0.0024617286399006844
      policy_loss: 1.9298822451219166e-07
      var_gnorm: 29.79480743408203
      vf_explained_var: 0.0
      vf_loss: 6.543920790136326e-06
    num_steps_sampled: 407000
    num_steps_trained: 407000
    wait_time_ms: 31.525
  iterations_since_restore: 277
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 10879
  policy_reward_mean: {}
  time_since_restore: 2091.022928237915
  time_this_iter_s: 8.57829213142395
  time_total_s: 2091.022928237915
  timestamp: 1594147590
  timesteps_since_restore: 407000
  timesteps_this_iter: 2000
  timesteps_total: 407000
  training_iteration: 277
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10879], 2091 s, 277 iter, 407000 ts, 0 rew

agent-1: 0.0
Sum Reward: 0.0
Avg Reward: 0.0
Min Reward: 0.0
Max Reward: 0.0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
agent-1: 0.0
Sum Reward: 0.0
Avg Reward: 0.0
Min Reward: 0.0
Max Reward: 0.0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_14-46-39
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: 0.0
  episode_reward_min: 0.0
  episodes_this_iter: 2
  episodes_total: 408
  experiment_id: cb3a18e0a26e466496590bc0542b68c4
  hostname: gpu020
  info:
    apply_time_ms: 2.721
    dispatch_time_ms: 6.419
    learner:
      cur_lr: 0.0013328938512131572
      grad_gnorm: 0.025022447109222412
      policy_entropy: 0.0025865205097943544
      policy_loss: -2.0046235249537858e-07
      var_gnorm: 29.797157287597656
      vf_explained_var: 0.0
      vf_loss: 4.348386937635951e-06
    num_steps_sampled: 409000
    num_steps_trained: 409000
    wait_time_ms: 35.044
  iterations_since_restore: 278
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 10879
  policy_reward_mean: {}
  time_since_restore: 2099.6006813049316
  time_this_iter_s: 8.577753067016602
  time_total_s: 2099.6006813049316
  timestamp: 1594147599
  timesteps_since_restore: 409000
  timesteps_this_iter: 2000
  timesteps_total: 409000
  training_iteration: 278
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10879], 2099 s, 278 iter, 409000 ts, 0 rew

agent-1: 0.0
Sum Reward: 0.0
Avg Reward: 0.0
Min Reward: 0.0
Max Reward: 0.0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
agent-1: 0.0
Sum Reward: 0.0
Avg Reward: 0.0
Min Reward: 0.0
Max Reward: 0.0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_14-46-48
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: 0.0
  episode_reward_min: 0.0
  episodes_this_iter: 2
  episodes_total: 410
  experiment_id: cb3a18e0a26e466496590bc0542b68c4
  hostname: gpu020
  info:
    apply_time_ms: 2.594
    dispatch_time_ms: 7.56
    learner:
      cur_lr: 0.0013327605556696653
      grad_gnorm: 0.0005466412985697389
      policy_entropy: 0.0026244022883474827
      policy_loss: 1.0211098810941621e-07
      var_gnorm: 29.797496795654297
      vf_explained_var: 0.0
      vf_loss: 2.057560122281643e-09
    num_steps_sampled: 411000
    num_steps_trained: 411000
    wait_time_ms: 32.051
  iterations_since_restore: 279
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 10879
  policy_reward_mean: {}
  time_since_restore: 2108.1289505958557
  time_this_iter_s: 8.528269290924072
  time_total_s: 2108.1289505958557
  timestamp: 1594147608
  timesteps_since_restore: 411000
  timesteps_this_iter: 2000
  timesteps_total: 411000
  training_iteration: 279
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10879], 2108 s, 279 iter, 411000 ts, 0 rew

agent-1: 0.0
Sum Reward: 0.0
Avg Reward: 0.0
Min Reward: 0.0
Max Reward: 0.0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
agent-1: 0.0
Sum Reward: 0.0
Avg Reward: 0.0
Min Reward: 0.0
Max Reward: 0.0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_14-46-56
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: 0.0
  episode_reward_min: 0.0
  episodes_this_iter: 2
  episodes_total: 412
  experiment_id: cb3a18e0a26e466496590bc0542b68c4
  hostname: gpu020
  info:
    apply_time_ms: 3.208
    dispatch_time_ms: 8.209
    learner:
      cur_lr: 0.0013326273765414953
      grad_gnorm: 0.0024690476711839437
      policy_entropy: 0.00025160747463814914
      policy_loss: 3.0590488364623525e-08
      var_gnorm: 29.79801368713379
      vf_explained_var: 0.0
      vf_loss: 4.180574819656613e-08
    num_steps_sampled: 413000
    num_steps_trained: 413000
    wait_time_ms: 29.902
  iterations_since_restore: 280
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 10879
  policy_reward_mean: {}
  time_since_restore: 2116.706762075424
  time_this_iter_s: 8.577811479568481
  time_total_s: 2116.706762075424
  timestamp: 1594147616
  timesteps_since_restore: 413000
  timesteps_this_iter: 2000
  timesteps_total: 413000
  training_iteration: 280
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10879], 2116 s, 280 iter, 413000 ts, 0 rew

agent-1: 0.0
Sum Reward: 0.0
Avg Reward: 0.0
Min Reward: 0.0
Max Reward: 0.0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
agent-1: 0.0
Sum Reward: 0.0
Avg Reward: 0.0
Min Reward: 0.0
Max Reward: 0.0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_14-47-05
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: 0.0
  episode_reward_min: 0.0
  episodes_this_iter: 2
  episodes_total: 414
  experiment_id: cb3a18e0a26e466496590bc0542b68c4
  hostname: gpu020
  info:
    apply_time_ms: 2.905
    dispatch_time_ms: 7.748
    learner:
      cur_lr: 0.0013324941974133253
      grad_gnorm: 0.0012070352677255869
      policy_entropy: 0.00024894854868762195
      policy_loss: 2.3070421129034457e-09
      var_gnorm: 29.795413970947266
      vf_explained_var: 0.0
      vf_loss: 1.0015769547067066e-08
    num_steps_sampled: 415000
    num_steps_trained: 415000
    wait_time_ms: 32.581
  iterations_since_restore: 281
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 10879
  policy_reward_mean: {}
  time_since_restore: 2125.2855336666107
  time_this_iter_s: 8.578771591186523
  time_total_s: 2125.2855336666107
  timestamp: 1594147625
  timesteps_since_restore: 415000
  timesteps_this_iter: 2000
  timesteps_total: 415000
  training_iteration: 281
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10879], 2125 s, 281 iter, 415000 ts, 0 rew

agent-1: 0.0
Sum Reward: 0.0
Avg Reward: 0.0
Min Reward: 0.0
Max Reward: 0.0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
agent-1: 0.0
Sum Reward: 0.0
Avg Reward: 0.0
Min Reward: 0.0
Max Reward: 0.0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_14-47-13
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: 0.0
  episode_reward_min: 0.0
  episodes_this_iter: 2
  episodes_total: 416
  experiment_id: cb3a18e0a26e466496590bc0542b68c4
  hostname: gpu020
  info:
    apply_time_ms: 3.188
    dispatch_time_ms: 7.699
    learner:
      cur_lr: 0.0013323610182851553
      grad_gnorm: 0.04593685269355774
      policy_entropy: 0.0025558117777109146
      policy_loss: -2.0821229895773286e-07
      var_gnorm: 29.79473876953125
      vf_explained_var: 0.0
      vf_loss: 1.4659864064014982e-05
    num_steps_sampled: 417000
    num_steps_trained: 417000
    wait_time_ms: 32.692
  iterations_since_restore: 282
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 10879
  policy_reward_mean: {}
  time_since_restore: 2133.862199306488
  time_this_iter_s: 8.57666563987732
  time_total_s: 2133.862199306488
  timestamp: 1594147633
  timesteps_since_restore: 417000
  timesteps_this_iter: 2000
  timesteps_total: 417000
  training_iteration: 282
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10879], 2133 s, 282 iter, 417000 ts, 0 rew

agent-1: 0.0
Sum Reward: 0.0
Avg Reward: 0.0
Min Reward: 0.0
Max Reward: 0.0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
agent-1: 0.0
Sum Reward: 0.0
Avg Reward: 0.0
Min Reward: 0.0
Max Reward: 0.0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_14-47-22
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: 0.0
  episode_reward_min: 0.0
  episodes_this_iter: 2
  episodes_total: 418
  experiment_id: cb3a18e0a26e466496590bc0542b68c4
  hostname: gpu020
  info:
    apply_time_ms: 3.248
    dispatch_time_ms: 8.019
    learner:
      cur_lr: 0.0013322278391569853
      grad_gnorm: 0.018495462834835052
      policy_entropy: 0.0002446458674967289
      policy_loss: 1.0568894204254775e-08
      var_gnorm: 29.792991638183594
      vf_explained_var: 0.0
      vf_loss: 2.348738689761376e-06
    num_steps_sampled: 419000
    num_steps_trained: 419000
    wait_time_ms: 32.653
  iterations_since_restore: 283
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 10879
  policy_reward_mean: {}
  time_since_restore: 2142.4296321868896
  time_this_iter_s: 8.567432880401611
  time_total_s: 2142.4296321868896
  timestamp: 1594147642
  timesteps_since_restore: 419000
  timesteps_this_iter: 2000
  timesteps_total: 419000
  training_iteration: 283
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10879], 2142 s, 283 iter, 419000 ts, 0 rew

agent-1: 0.0
Sum Reward: 0.0
Avg Reward: 0.0
Min Reward: 0.0
Max Reward: 0.0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
agent-1: 0.0
Sum Reward: 0.0
Avg Reward: 0.0
Min Reward: 0.0
Max Reward: 0.0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_14-47-31
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: 0.0
  episode_reward_min: 0.0
  episodes_this_iter: 2
  episodes_total: 420
  experiment_id: cb3a18e0a26e466496590bc0542b68c4
  hostname: gpu020
  info:
    apply_time_ms: 2.777
    dispatch_time_ms: 6.85
    learner:
      cur_lr: 0.0013320945436134934
      grad_gnorm: 0.012665865942835808
      policy_entropy: 0.002464910503476858
      policy_loss: -9.390612376591889e-08
      var_gnorm: 29.792770385742188
      vf_explained_var: 0.0
      vf_loss: 1.1136775128761656e-06
    num_steps_sampled: 421000
    num_steps_trained: 421000
    wait_time_ms: 33.807
  iterations_since_restore: 284
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 10879
  policy_reward_mean: {}
  time_since_restore: 2151.0151908397675
  time_this_iter_s: 8.585558652877808
  time_total_s: 2151.0151908397675
  timestamp: 1594147651
  timesteps_since_restore: 421000
  timesteps_this_iter: 2000
  timesteps_total: 421000
  training_iteration: 284
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10879], 2151 s, 284 iter, 421000 ts, 0 rew

agent-1: 0.0
Sum Reward: 0.0
Avg Reward: 0.0
Min Reward: 0.0
Max Reward: 0.0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_14-47-43
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: 0.0
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 421
  experiment_id: cb3a18e0a26e466496590bc0542b68c4
  hostname: gpu020
  info:
    apply_time_ms: 3.773
    dispatch_time_ms: 6.879
    learner:
      cur_lr: 0.0013319613644853234
      grad_gnorm: 0.09404710680246353
      policy_entropy: 0.0024702884256839752
      policy_loss: -3.082179773628013e-07
      var_gnorm: 29.792573928833008
      vf_explained_var: 0.0
      vf_loss: 6.142876372905448e-05
    num_steps_sampled: 422000
    num_steps_trained: 422000
    wait_time_ms: 879.182
  iterations_since_restore: 285
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 10879
  policy_reward_mean: {}
  time_since_restore: 2163.791375875473
  time_this_iter_s: 12.776185035705566
  time_total_s: 2163.791375875473
  timestamp: 1594147663
  timesteps_since_restore: 422000
  timesteps_this_iter: 1000
  timesteps_total: 422000
  training_iteration: 285
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10879], 2163 s, 285 iter, 422000 ts, 0 rew

agent-1: 0.0
Sum Reward: 0.0
Avg Reward: 0.0
Min Reward: 0.0
Max Reward: 0.0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
agent-1: 0.0
Sum Reward: 0.0
Avg Reward: 0.0
Min Reward: 0.0
Max Reward: 0.0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_14-47-54
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: 0.0
  episode_reward_min: 0.0
  episodes_this_iter: 2
  episodes_total: 423
  experiment_id: cb3a18e0a26e466496590bc0542b68c4
  hostname: gpu020
  info:
    apply_time_ms: 3.018
    dispatch_time_ms: 36.781
    learner:
      cur_lr: 0.0013318947749212384
      grad_gnorm: 0.7250247597694397
      policy_entropy: 0.00024818506790325046
      policy_loss: 2.041767004357098e-07
      var_gnorm: 29.792957305908203
      vf_explained_var: 0.0
      vf_loss: 0.0030873040668666363
    num_steps_sampled: 424000
    num_steps_trained: 424000
    wait_time_ms: 13.258
  iterations_since_restore: 286
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 10879
  policy_reward_mean: {}
  time_since_restore: 2174.143340587616
  time_this_iter_s: 10.351964712142944
  time_total_s: 2174.143340587616
  timestamp: 1594147674
  timesteps_since_restore: 424000
  timesteps_this_iter: 2000
  timesteps_total: 424000
  training_iteration: 286
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10879], 2174 s, 286 iter, 424000 ts, 0 rew

agent-1: 0.0
Sum Reward: 0.0
Avg Reward: 0.0
Min Reward: 0.0
Max Reward: 0.0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_14-48-00
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: 0.0
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 424
  experiment_id: cb3a18e0a26e466496590bc0542b68c4
  hostname: gpu020
  info:
    apply_time_ms: 3.025
    dispatch_time_ms: 40.498
    learner:
      cur_lr: 0.0013317615957930684
      grad_gnorm: 0.017126889899373055
      policy_entropy: 0.00024274748284369707
      policy_loss: 1.2735712573430646e-07
      var_gnorm: 29.791765213012695
      vf_explained_var: 1.1920928955078125e-07
      vf_loss: 9.006637264974415e-05
    num_steps_sampled: 425000
    num_steps_trained: 425000
    wait_time_ms: 15.489
  iterations_since_restore: 287
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 10879
  policy_reward_mean: {}
  time_since_restore: 2180.4290494918823
  time_this_iter_s: 6.285708904266357
  time_total_s: 2180.4290494918823
  timestamp: 1594147680
  timesteps_since_restore: 425000
  timesteps_this_iter: 1000
  timesteps_total: 425000
  training_iteration: 287
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10879], 2180 s, 287 iter, 425000 ts, 0 rew

agent-1: 0.0
Sum Reward: 0.0
Avg Reward: 0.0
Min Reward: 0.0
Max Reward: 0.0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_14-48-06
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: 0.0
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 425
  experiment_id: cb3a18e0a26e466496590bc0542b68c4
  hostname: gpu020
  info:
    apply_time_ms: 2.804
    dispatch_time_ms: 29.158
    learner:
      cur_lr: 0.0013316950062289834
      grad_gnorm: 0.020725203678011894
      policy_entropy: 0.002980968216434121
      policy_loss: 5.5503996918560006e-06
      var_gnorm: 29.791454315185547
      vf_explained_var: 0.0
      vf_loss: 0.000684799044393003
    num_steps_sampled: 426000
    num_steps_trained: 426000
    wait_time_ms: 25.937
  iterations_since_restore: 288
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 10879
  policy_reward_mean: {}
  time_since_restore: 2186.2432107925415
  time_this_iter_s: 5.81416130065918
  time_total_s: 2186.2432107925415
  timestamp: 1594147686
  timesteps_since_restore: 426000
  timesteps_this_iter: 1000
  timesteps_total: 426000
  training_iteration: 288
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10879], 2186 s, 288 iter, 426000 ts, 0 rew

agent-1: 0.0
Sum Reward: 0.0
Avg Reward: 0.0
Min Reward: 0.0
Max Reward: 0.0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_14-48-12
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: 0.0
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 426
  experiment_id: cb3a18e0a26e466496590bc0542b68c4
  hostname: gpu020
  info:
    apply_time_ms: 2.763
    dispatch_time_ms: 33.631
    learner:
      cur_lr: 0.0013316284166648984
      grad_gnorm: 0.08931049704551697
      policy_entropy: 0.00023683423933107406
      policy_loss: 1.5869559888415097e-08
      var_gnorm: 29.79007339477539
      vf_explained_var: 0.0
      vf_loss: 4.4769974920200184e-05
    num_steps_sampled: 427000
    num_steps_trained: 427000
    wait_time_ms: 19.745
  iterations_since_restore: 289
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 10879
  policy_reward_mean: {}
  time_since_restore: 2191.7906925678253
  time_this_iter_s: 5.5474817752838135
  time_total_s: 2191.7906925678253
  timestamp: 1594147692
  timesteps_since_restore: 427000
  timesteps_this_iter: 1000
  timesteps_total: 427000
  training_iteration: 289
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10879], 2191 s, 289 iter, 427000 ts, 0 rew

agent-1: 0.0
Sum Reward: 0.0
Avg Reward: 0.0
Min Reward: 0.0
Max Reward: 0.0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_14-48-17
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: 0.0
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 427
  experiment_id: cb3a18e0a26e466496590bc0542b68c4
  hostname: gpu020
  info:
    apply_time_ms: 3.227
    dispatch_time_ms: 30.148
    learner:
      cur_lr: 0.0013315618271008134
      grad_gnorm: 0.38628262281417847
      policy_entropy: 0.00023293195408768952
      policy_loss: -2.3675905680420328e-08
      var_gnorm: 29.788707733154297
      vf_explained_var: 1.1920928955078125e-07
      vf_loss: 0.0008148744818754494
    num_steps_sampled: 428000
    num_steps_trained: 428000
    wait_time_ms: 21.141
  iterations_since_restore: 290
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 10879
  policy_reward_mean: {}
  time_since_restore: 2197.398181915283
  time_this_iter_s: 5.607489347457886
  time_total_s: 2197.398181915283
  timestamp: 1594147697
  timesteps_since_restore: 428000
  timesteps_this_iter: 1000
  timesteps_total: 428000
  training_iteration: 290
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10879], 2197 s, 290 iter, 428000 ts, 0 rew

agent-1: 0.0
Sum Reward: 0.0
Avg Reward: 0.0
Min Reward: 0.0
Max Reward: 0.0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_14-48-23
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: 0.0
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 428
  experiment_id: cb3a18e0a26e466496590bc0542b68c4
  hostname: gpu020
  info:
    apply_time_ms: 2.613
    dispatch_time_ms: 28.52
    learner:
      cur_lr: 0.0013314952375367284
      grad_gnorm: 0.12103822827339172
      policy_entropy: 0.00023085184511728585
      policy_loss: -2.429104384304992e-08
      var_gnorm: 29.788057327270508
      vf_explained_var: 0.0
      vf_loss: 8.292478742077947e-05
    num_steps_sampled: 429000
    num_steps_trained: 429000
    wait_time_ms: 22.54
  iterations_since_restore: 291
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 10879
  policy_reward_mean: {}
  time_since_restore: 2202.887911081314
  time_this_iter_s: 5.489729166030884
  time_total_s: 2202.887911081314
  timestamp: 1594147703
  timesteps_since_restore: 429000
  timesteps_this_iter: 1000
  timesteps_total: 429000
  training_iteration: 291
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10879], 2202 s, 291 iter, 429000 ts, 0 rew

agent-1: 0.0
Sum Reward: 0.0
Avg Reward: 0.0
Min Reward: 0.0
Max Reward: 0.0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_14-48-28
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: 0.0
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 429
  experiment_id: cb3a18e0a26e466496590bc0542b68c4
  hostname: gpu020
  info:
    apply_time_ms: 3.84
    dispatch_time_ms: 45.957
    learner:
      cur_lr: 0.0013314286479726434
      grad_gnorm: 0.1370992660522461
      policy_entropy: 0.00023143610451370478
      policy_loss: -1.3194354053780444e-08
      var_gnorm: 29.788022994995117
      vf_explained_var: 0.0
      vf_loss: 0.00010321247100364417
    num_steps_sampled: 430000
    num_steps_trained: 430000
    wait_time_ms: 14.327
  iterations_since_restore: 292
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 10879
  policy_reward_mean: {}
  time_since_restore: 2208.3033611774445
  time_this_iter_s: 5.415450096130371
  time_total_s: 2208.3033611774445
  timestamp: 1594147708
  timesteps_since_restore: 430000
  timesteps_this_iter: 1000
  timesteps_total: 430000
  training_iteration: 292
  
agent-1: 0.0
Sum Reward: 0.0
Avg Reward: 0.0
Min Reward: 0.0
Max Reward: 0.0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10879], 2208 s, 292 iter, 430000 ts, 0 rew

Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_14-48-34
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: 0.0
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 430
  experiment_id: cb3a18e0a26e466496590bc0542b68c4
  hostname: gpu020
  info:
    apply_time_ms: 3.628
    dispatch_time_ms: 25.432
    learner:
      cur_lr: 0.0013313619419932365
      grad_gnorm: 0.07828891277313232
      policy_entropy: 0.00023197539849206805
      policy_loss: -1.2064468535299966e-08
      var_gnorm: 29.787992477416992
      vf_explained_var: 0.0
      vf_loss: 3.414025923120789e-05
    num_steps_sampled: 431000
    num_steps_trained: 431000
    wait_time_ms: 18.636
  iterations_since_restore: 293
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 10879
  policy_reward_mean: {}
  time_since_restore: 2213.8567173480988
  time_this_iter_s: 5.553356170654297
  time_total_s: 2213.8567173480988
  timestamp: 1594147714
  timesteps_since_restore: 431000
  timesteps_this_iter: 1000
  timesteps_total: 431000
  training_iteration: 293
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10879], 2213 s, 293 iter, 431000 ts, 0 rew

agent-1: 0.0
Sum Reward: 0.0
Avg Reward: 0.0
Min Reward: 0.0
Max Reward: 0.0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
agent-1: 0.0
Sum Reward: 0.0
Avg Reward: 0.0
Min Reward: 0.0
Max Reward: 0.0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_14-48-43
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: 0.0
  episode_reward_min: 0.0
  episodes_this_iter: 2
  episodes_total: 432
  experiment_id: cb3a18e0a26e466496590bc0542b68c4
  hostname: gpu020
  info:
    apply_time_ms: 2.769
    dispatch_time_ms: 6.581
    learner:
      cur_lr: 0.0013312953524291515
      grad_gnorm: 0.008192107081413269
      policy_entropy: 0.0021662581712007523
      policy_loss: -5.0645372340341055e-08
      var_gnorm: 29.787839889526367
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 4.66446294922207e-07
    num_steps_sampled: 433000
    num_steps_trained: 433000
    wait_time_ms: 32.94
  iterations_since_restore: 294
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 10879
  policy_reward_mean: {}
  time_since_restore: 2222.7113485336304
  time_this_iter_s: 8.854631185531616
  time_total_s: 2222.7113485336304
  timestamp: 1594147723
  timesteps_since_restore: 433000
  timesteps_this_iter: 2000
  timesteps_total: 433000
  training_iteration: 294
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10879], 2222 s, 294 iter, 433000 ts, 0 rew

agent-1: 0.0
Sum Reward: 0.0
Avg Reward: 0.0
Min Reward: 0.0
Max Reward: 0.0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
agent-1: 0.0
Sum Reward: 0.0
Avg Reward: 0.0
Min Reward: 0.0
Max Reward: 0.0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_14-48-51
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: 0.0
  episode_reward_min: 0.0
  episodes_this_iter: 2
  episodes_total: 434
  experiment_id: cb3a18e0a26e466496590bc0542b68c4
  hostname: gpu020
  info:
    apply_time_ms: 2.72
    dispatch_time_ms: 6.572
    learner:
      cur_lr: 0.0013311621733009815
      grad_gnorm: 0.00027996848803013563
      policy_entropy: 0.0002368809946347028
      policy_loss: -1.469988158975255e-10
      var_gnorm: 29.788148880004883
      vf_explained_var: 5.960464477539063e-08
      vf_loss: 5.353006371500157e-10
    num_steps_sampled: 435000
    num_steps_trained: 435000
    wait_time_ms: 35.049
  iterations_since_restore: 295
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 10879
  policy_reward_mean: {}
  time_since_restore: 2231.292108297348
  time_this_iter_s: 8.580759763717651
  time_total_s: 2231.292108297348
  timestamp: 1594147731
  timesteps_since_restore: 435000
  timesteps_this_iter: 2000
  timesteps_total: 435000
  training_iteration: 295
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10879], 2231 s, 295 iter, 435000 ts, 0 rew

agent-1: 0.0
Sum Reward: 0.0
Avg Reward: 0.0
Min Reward: 0.0
Max Reward: 0.0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
agent-1: 0.0
Sum Reward: 0.0
Avg Reward: 0.0
Min Reward: 0.0
Max Reward: 0.0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_14-49-00
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: 0.0
  episode_reward_min: 0.0
  episodes_this_iter: 2
  episodes_total: 436
  experiment_id: cb3a18e0a26e466496590bc0542b68c4
  hostname: gpu020
  info:
    apply_time_ms: 2.958
    dispatch_time_ms: 7.111
    learner:
      cur_lr: 0.0013310289941728115
      grad_gnorm: 0.032932449132204056
      policy_entropy: 0.00024264055537059903
      policy_loss: 1.6846563255512592e-08
      var_gnorm: 29.788789749145508
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 7.4475233304838184e-06
    num_steps_sampled: 437000
    num_steps_trained: 437000
    wait_time_ms: 31.924
  iterations_since_restore: 296
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 10879
  policy_reward_mean: {}
  time_since_restore: 2239.822489976883
  time_this_iter_s: 8.530381679534912
  time_total_s: 2239.822489976883
  timestamp: 1594147740
  timesteps_since_restore: 437000
  timesteps_this_iter: 2000
  timesteps_total: 437000
  training_iteration: 296
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10879], 2239 s, 296 iter, 437000 ts, 0 rew

agent-1: 0.0
Sum Reward: 0.0
Avg Reward: 0.0
Min Reward: 0.0
Max Reward: 0.0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
agent-1: 0.0
Sum Reward: 0.0
Avg Reward: 0.0
Min Reward: 0.0
Max Reward: 0.0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_14-49-06
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: 0.0
  episode_reward_min: 0.0
  episodes_this_iter: 2
  episodes_total: 438
  experiment_id: cb3a18e0a26e466496590bc0542b68c4
  hostname: gpu020
  info:
    apply_time_ms: 2.495
    dispatch_time_ms: 23.708
    learner:
      cur_lr: 0.0013308958150446415
      grad_gnorm: 0.1644020825624466
      policy_entropy: 0.0002485832083038986
      policy_loss: 1.664495563602486e-08
      var_gnorm: 29.789457321166992
      vf_explained_var: 0.0
      vf_loss: 0.00014856028428766876
    num_steps_sampled: 438000
    num_steps_trained: 438000
    wait_time_ms: 29.514
  iterations_since_restore: 297
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 10879
  policy_reward_mean: {}
  time_since_restore: 2245.9524309635162
  time_this_iter_s: 6.129940986633301
  time_total_s: 2245.9524309635162
  timestamp: 1594147746
  timesteps_since_restore: 438000
  timesteps_this_iter: 1000
  timesteps_total: 438000
  training_iteration: 297
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10879], 2245 s, 297 iter, 438000 ts, 0 rew

Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_14-49-12
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: 0.0
  episode_reward_min: 0.0
  episodes_this_iter: 0
  episodes_total: 438
  experiment_id: cb3a18e0a26e466496590bc0542b68c4
  hostname: gpu020
  info:
    apply_time_ms: 2.401
    dispatch_time_ms: 30.301
    learner:
      cur_lr: 0.0013308292254805565
      grad_gnorm: 2.7234325408935547
      policy_entropy: 0.022866463288664818
      policy_loss: 1.0372148608439602e-05
      var_gnorm: 29.79245376586914
      vf_explained_var: 0.0
      vf_loss: 0.04084402322769165
    num_steps_sampled: 439000
    num_steps_trained: 439000
    wait_time_ms: 17.619
  iterations_since_restore: 298
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 10879
  policy_reward_mean: {}
  time_since_restore: 2251.8427097797394
  time_this_iter_s: 5.8902788162231445
  time_total_s: 2251.8427097797394
  timestamp: 1594147752
  timesteps_since_restore: 439000
  timesteps_this_iter: 1000
  timesteps_total: 439000
  training_iteration: 298
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10879], 2251 s, 298 iter, 439000 ts, 0 rew

agent-1: 0.0
Sum Reward: 0.0
Avg Reward: 0.0
Min Reward: 0.0
Max Reward: 0.0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
agent-1: 0.0
Sum Reward: 0.0
Avg Reward: 0.0
Min Reward: 0.0
Max Reward: 0.0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_14-49-17
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: 0.0
  episode_reward_min: 0.0
  episodes_this_iter: 2
  episodes_total: 440
  experiment_id: cb3a18e0a26e466496590bc0542b68c4
  hostname: gpu020
  info:
    apply_time_ms: 3.042
    dispatch_time_ms: 28.21
    learner:
      cur_lr: 0.0013307626359164715
      grad_gnorm: 0.4943876564502716
      policy_entropy: 0.00329646491445601
      policy_loss: -1.965392044667169e-07
      var_gnorm: 29.79463005065918
      vf_explained_var: -1.1920928955078125e-06
      vf_loss: 0.001345842843875289
    num_steps_sampled: 440000
    num_steps_trained: 440000
    wait_time_ms: 15.438
  iterations_since_restore: 299
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 10879
  policy_reward_mean: {}
  time_since_restore: 2257.0115716457367
  time_this_iter_s: 5.1688618659973145
  time_total_s: 2257.0115716457367
  timestamp: 1594147757
  timesteps_since_restore: 440000
  timesteps_this_iter: 1000
  timesteps_total: 440000
  training_iteration: 299
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10879], 2257 s, 299 iter, 440000 ts, 0 rew

Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_14-49-23
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: 0.0
  episode_reward_min: 0.0
  episodes_this_iter: 0
  episodes_total: 440
  experiment_id: cb3a18e0a26e466496590bc0542b68c4
  hostname: gpu020
  info:
    apply_time_ms: 2.886
    dispatch_time_ms: 35.496
    learner:
      cur_lr: 0.0013306960463523865
      grad_gnorm: 5.455097198486328
      policy_entropy: 0.00028729753103107214
      policy_loss: 5.223391141839784e-08
      var_gnorm: 29.793230056762695
      vf_explained_var: -3.5762786865234375e-07
      vf_loss: 0.16191339492797852
    num_steps_sampled: 441000
    num_steps_trained: 441000
    wait_time_ms: 16.708
  iterations_since_restore: 300
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 10879
  policy_reward_mean: {}
  time_since_restore: 2262.602087497711
  time_this_iter_s: 5.590515851974487
  time_total_s: 2262.602087497711
  timestamp: 1594147763
  timesteps_since_restore: 441000
  timesteps_this_iter: 1000
  timesteps_total: 441000
  training_iteration: 300
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10879], 2262 s, 300 iter, 441000 ts, 0 rew

agent-1: 0.0
Sum Reward: 0.0
Avg Reward: 0.0
Min Reward: 0.0
Max Reward: 0.0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
agent-1: 0.0
Sum Reward: 0.0
Avg Reward: 0.0
Min Reward: 0.0
Max Reward: 0.0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_14-49-29
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: 0.0
  episode_reward_min: 0.0
  episodes_this_iter: 2
  episodes_total: 442
  experiment_id: cb3a18e0a26e466496590bc0542b68c4
  hostname: gpu020
  info:
    apply_time_ms: 3.666
    dispatch_time_ms: 54.655
    learner:
      cur_lr: 0.0013306294567883015
      grad_gnorm: 13.088215827941895
      policy_entropy: 0.0030368149746209383
      policy_loss: -4.888468538410962e-06
      var_gnorm: 29.793197631835938
      vf_explained_var: 0.0
      vf_loss: 0.9432642459869385
    num_steps_sampled: 442000
    num_steps_trained: 442000
    wait_time_ms: 17.228
  iterations_since_restore: 301
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 10879
  policy_reward_mean: {}
  time_since_restore: 2268.7512295246124
  time_this_iter_s: 6.149142026901245
  time_total_s: 2268.7512295246124
  timestamp: 1594147769
  timesteps_since_restore: 442000
  timesteps_this_iter: 1000
  timesteps_total: 442000
  training_iteration: 301
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10879], 2268 s, 301 iter, 442000 ts, 0 rew

Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_14-49-35
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: 0.0
  episode_reward_min: 0.0
  episodes_this_iter: 0
  episodes_total: 442
  experiment_id: cb3a18e0a26e466496590bc0542b68c4
  hostname: gpu020
  info:
    apply_time_ms: 4.989
    dispatch_time_ms: 33.164
    learner:
      cur_lr: 0.0013305627508088946
      grad_gnorm: 3.2130064964294434
      policy_entropy: 0.00287606380879879
      policy_loss: -1.3363352309170295e-06
      var_gnorm: 29.792421340942383
      vf_explained_var: 0.0
      vf_loss: 0.05685761570930481
    num_steps_sampled: 443000
    num_steps_trained: 443000
    wait_time_ms: 17.833
  iterations_since_restore: 302
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 10879
  policy_reward_mean: {}
  time_since_restore: 2274.707592725754
  time_this_iter_s: 5.956363201141357
  time_total_s: 2274.707592725754
  timestamp: 1594147775
  timesteps_since_restore: 443000
  timesteps_this_iter: 1000
  timesteps_total: 443000
  training_iteration: 302
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10879], 2274 s, 302 iter, 443000 ts, 0 rew

agent-1: 0.0
Sum Reward: 0.0
Avg Reward: 0.0
Min Reward: 0.0
Max Reward: 0.0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
agent-1: 0.0
Sum Reward: 0.0
Avg Reward: 0.0
Min Reward: 0.0
Max Reward: 0.0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_14-49-41
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: 0.0
  episode_reward_min: 0.0
  episodes_this_iter: 2
  episodes_total: 444
  experiment_id: cb3a18e0a26e466496590bc0542b68c4
  hostname: gpu020
  info:
    apply_time_ms: 3.276
    dispatch_time_ms: 31.207
    learner:
      cur_lr: 0.0013304961612448096
      grad_gnorm: 0.05336533486843109
      policy_entropy: 0.00029420608188956976
      policy_loss: -5.009866299587884e-08
      var_gnorm: 29.79305648803711
      vf_explained_var: 0.0
      vf_loss: 2.453165507176891e-05
    num_steps_sampled: 444000
    num_steps_trained: 444000
    wait_time_ms: 18.942
  iterations_since_restore: 303
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 10879
  policy_reward_mean: {}
  time_since_restore: 2280.418383359909
  time_this_iter_s: 5.710790634155273
  time_total_s: 2280.418383359909
  timestamp: 1594147781
  timesteps_since_restore: 444000
  timesteps_this_iter: 1000
  timesteps_total: 444000
  training_iteration: 303
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10879], 2280 s, 303 iter, 444000 ts, 0 rew

Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_14-49-46
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: 0.0
  episode_reward_min: 0.0
  episodes_this_iter: 0
  episodes_total: 444
  experiment_id: cb3a18e0a26e466496590bc0542b68c4
  hostname: gpu020
  info:
    apply_time_ms: 2.449
    dispatch_time_ms: 31.696
    learner:
      cur_lr: 0.0013304295716807246
      grad_gnorm: 0.7281199097633362
      policy_entropy: 0.00027497680275700986
      policy_loss: -5.838008831915431e-08
      var_gnorm: 29.792009353637695
      vf_explained_var: 0.0
      vf_loss: 0.0028983517549932003
    num_steps_sampled: 445000
    num_steps_trained: 445000
    wait_time_ms: 18.613
  iterations_since_restore: 304
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 10879
  policy_reward_mean: {}
  time_since_restore: 2286.3642024993896
  time_this_iter_s: 5.945819139480591
  time_total_s: 2286.3642024993896
  timestamp: 1594147786
  timesteps_since_restore: 445000
  timesteps_this_iter: 1000
  timesteps_total: 445000
  training_iteration: 304
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10879], 2286 s, 304 iter, 445000 ts, 0 rew

agent-1: 0.0
Sum Reward: 0.0
Avg Reward: 0.0
Min Reward: 0.0
Max Reward: 0.0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
agent-1: 0.0
Sum Reward: 0.0
Avg Reward: 0.0
Min Reward: 0.0
Max Reward: 0.0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_14-49-52
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: 0.0
  episode_reward_min: 0.0
  episodes_this_iter: 2
  episodes_total: 446
  experiment_id: cb3a18e0a26e466496590bc0542b68c4
  hostname: gpu020
  info:
    apply_time_ms: 2.853
    dispatch_time_ms: 33.392
    learner:
      cur_lr: 0.0013303629821166396
      grad_gnorm: 0.5639660954475403
      policy_entropy: 0.00027270655846223235
      policy_loss: -1.9627989900072862e-08
      var_gnorm: 29.79177474975586
      vf_explained_var: 0.0
      vf_loss: 0.001732007716782391
    num_steps_sampled: 446000
    num_steps_trained: 446000
    wait_time_ms: 14.955
  iterations_since_restore: 305
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 10879
  policy_reward_mean: {}
  time_since_restore: 2292.055420398712
  time_this_iter_s: 5.69121789932251
  time_total_s: 2292.055420398712
  timestamp: 1594147792
  timesteps_since_restore: 446000
  timesteps_this_iter: 1000
  timesteps_total: 446000
  training_iteration: 305
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10879], 2292 s, 305 iter, 446000 ts, 0 rew

agent-1: 0.0
Sum Reward: 0.0
Avg Reward: 0.0
Min Reward: 0.0
Max Reward: 0.0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_14-50-01
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: 0.0
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 447
  experiment_id: cb3a18e0a26e466496590bc0542b68c4
  hostname: gpu020
  info:
    apply_time_ms: 2.657
    dispatch_time_ms: 8.301
    learner:
      cur_lr: 0.0013302963925525546
      grad_gnorm: 0.18204008042812347
      policy_entropy: 0.00020122424757573754
      policy_loss: -4.761011140885785e-08
      var_gnorm: 29.78985595703125
      vf_explained_var: 1.1920928955078125e-07
      vf_loss: 0.00022752987570129335
    num_steps_sampled: 448000
    num_steps_trained: 448000
    wait_time_ms: 32.635
  iterations_since_restore: 306
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 10879
  policy_reward_mean: {}
  time_since_restore: 2300.621443271637
  time_this_iter_s: 8.566022872924805
  time_total_s: 2300.621443271637
  timestamp: 1594147801
  timesteps_since_restore: 448000
  timesteps_this_iter: 2000
  timesteps_total: 448000
  training_iteration: 306
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10879], 2300 s, 306 iter, 448000 ts, 0 rew

agent-1: 0.0
Sum Reward: 0.0
Avg Reward: 0.0
Min Reward: 0.0
Max Reward: 0.0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
agent-1: 0.0
Sum Reward: 0.0
Avg Reward: 0.0
Min Reward: 0.0
Max Reward: 0.0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
agent-1: 0.0
Sum Reward: 0.0
Avg Reward: 0.0
Min Reward: 0.0
Max Reward: 0.0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_14-50-09
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: 0.0
  episode_reward_min: 0.0
  episodes_this_iter: 3
  episodes_total: 450
  experiment_id: cb3a18e0a26e466496590bc0542b68c4
  hostname: gpu020
  info:
    apply_time_ms: 2.525
    dispatch_time_ms: 7.993
    learner:
      cur_lr: 0.0013301632134243846
      grad_gnorm: 1.6789698600769043
      policy_entropy: 0.00020666832278948277
      policy_loss: 7.264229111569875e-07
      var_gnorm: 29.789756774902344
      vf_explained_var: -1.0
      vf_loss: 0.015336761251091957
    num_steps_sampled: 450000
    num_steps_trained: 450000
    wait_time_ms: 33.595
  iterations_since_restore: 307
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 10879
  policy_reward_mean: {}
  time_since_restore: 2309.2027316093445
  time_this_iter_s: 8.58128833770752
  time_total_s: 2309.2027316093445
  timestamp: 1594147809
  timesteps_since_restore: 450000
  timesteps_this_iter: 2000
  timesteps_total: 450000
  training_iteration: 307
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10879], 2309 s, 307 iter, 450000 ts, 0 rew

agent-1: 0.0
Sum Reward: 0.0
Avg Reward: 0.0
Min Reward: 0.0
Max Reward: 0.0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_14-50-18
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: 0.0
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 451
  experiment_id: cb3a18e0a26e466496590bc0542b68c4
  hostname: gpu020
  info:
    apply_time_ms: 2.748
    dispatch_time_ms: 7.432
    learner:
      cur_lr: 0.0013300300342962146
      grad_gnorm: 0.14272120594978333
      policy_entropy: 0.00018874947272706777
      policy_loss: -4.425831789944823e-08
      var_gnorm: 29.78931427001953
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 0.00013985905388835818
    num_steps_sampled: 452000
    num_steps_trained: 452000
    wait_time_ms: 33.275
  iterations_since_restore: 308
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 10879
  policy_reward_mean: {}
  time_since_restore: 2317.721525669098
  time_this_iter_s: 8.518794059753418
  time_total_s: 2317.721525669098
  timestamp: 1594147818
  timesteps_since_restore: 452000
  timesteps_this_iter: 2000
  timesteps_total: 452000
  training_iteration: 308
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10879], 2317 s, 308 iter, 452000 ts, 0 rew

agent-1: 0.0
Sum Reward: 0.0
Avg Reward: 0.0
Min Reward: 0.0
Max Reward: 0.0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
agent-1: 0.0
Sum Reward: 0.0
Avg Reward: 0.0
Min Reward: 0.0
Max Reward: 0.0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_14-50-26
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: 0.0
  episode_reward_min: 0.0
  episodes_this_iter: 2
  episodes_total: 453
  experiment_id: cb3a18e0a26e466496590bc0542b68c4
  hostname: gpu020
  info:
    apply_time_ms: 2.547
    dispatch_time_ms: 6.192
    learner:
      cur_lr: 0.0013298968551680446
      grad_gnorm: 0.12040834128856659
      policy_entropy: 0.0020622797310352325
      policy_loss: 6.530748350996873e-07
      var_gnorm: 29.789138793945312
      vf_explained_var: 0.0
      vf_loss: 0.00010232818749500439
    num_steps_sampled: 454000
    num_steps_trained: 454000
    wait_time_ms: 35.316
  iterations_since_restore: 309
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 10879
  policy_reward_mean: {}
  time_since_restore: 2326.1987912654877
  time_this_iter_s: 8.47726559638977
  time_total_s: 2326.1987912654877
  timestamp: 1594147826
  timesteps_since_restore: 454000
  timesteps_this_iter: 2000
  timesteps_total: 454000
  training_iteration: 309
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10879], 2326 s, 309 iter, 454000 ts, 0 rew

agent-1: 0.0
Sum Reward: 0.0
Avg Reward: 0.0
Min Reward: 0.0
Max Reward: 0.0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
agent-1: 0.0
Sum Reward: 0.0
Avg Reward: 0.0
Min Reward: 0.0
Max Reward: 0.0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_14-50-35
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: 0.0
  episode_reward_min: 0.0
  episodes_this_iter: 2
  episodes_total: 455
  experiment_id: cb3a18e0a26e466496590bc0542b68c4
  hostname: gpu020
  info:
    apply_time_ms: 3.498
    dispatch_time_ms: 6.987
    learner:
      cur_lr: 0.0013297635596245527
      grad_gnorm: 0.050747696310281754
      policy_entropy: 0.0002079693367704749
      policy_loss: 3.2631220392431715e-08
      var_gnorm: 29.788915634155273
      vf_explained_var: 0.0
      vf_loss: 1.7679094526101835e-05
    num_steps_sampled: 456000
    num_steps_trained: 456000
    wait_time_ms: 33.46
  iterations_since_restore: 310
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 10879
  policy_reward_mean: {}
  time_since_restore: 2334.7681605815887
  time_this_iter_s: 8.569369316101074
  time_total_s: 2334.7681605815887
  timestamp: 1594147835
  timesteps_since_restore: 456000
  timesteps_this_iter: 2000
  timesteps_total: 456000
  training_iteration: 310
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10879], 2334 s, 310 iter, 456000 ts, 0 rew

agent-1: 0.0
Sum Reward: 0.0
Avg Reward: 0.0
Min Reward: 0.0
Max Reward: 0.0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_14-50-45
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: 0.0
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 456
  experiment_id: cb3a18e0a26e466496590bc0542b68c4
  hostname: gpu020
  info:
    apply_time_ms: 2.613
    dispatch_time_ms: 6.156
    learner:
      cur_lr: 0.0013296303804963827
      grad_gnorm: 0.003704067785292864
      policy_entropy: 0.000205317119252868
      policy_loss: 1.595960585909495e-09
      var_gnorm: 29.78875732421875
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 9.405011525132068e-08
    num_steps_sampled: 457000
    num_steps_trained: 457000
    wait_time_ms: 32.661
  iterations_since_restore: 311
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 10879
  policy_reward_mean: {}
  time_since_restore: 2344.2122979164124
  time_this_iter_s: 9.444137334823608
  time_total_s: 2344.2122979164124
  timestamp: 1594147845
  timesteps_since_restore: 457000
  timesteps_this_iter: 1000
  timesteps_total: 457000
  training_iteration: 311
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10879], 2344 s, 311 iter, 457000 ts, 0 rew

agent-1: 0.0
Sum Reward: 0.0
Avg Reward: 0.0
Min Reward: 0.0
Max Reward: 0.0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
agent-1: 0.0
Sum Reward: 0.0
Avg Reward: 0.0
Min Reward: 0.0
Max Reward: 0.0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_14-50-53
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: 0.0
  episode_reward_min: 0.0
  episodes_this_iter: 2
  episodes_total: 458
  experiment_id: cb3a18e0a26e466496590bc0542b68c4
  hostname: gpu020
  info:
    apply_time_ms: 3.249
    dispatch_time_ms: 5.952
    learner:
      cur_lr: 0.0013295637909322977
      grad_gnorm: 0.021866703405976295
      policy_entropy: 0.003396618412807584
      policy_loss: -2.1015004847413365e-07
      var_gnorm: 29.788684844970703
      vf_explained_var: 0.0
      vf_loss: 3.321392568977899e-06
    num_steps_sampled: 459000
    num_steps_trained: 459000
    wait_time_ms: 35.319
  iterations_since_restore: 312
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 10879
  policy_reward_mean: {}
  time_since_restore: 2352.8304505348206
  time_this_iter_s: 8.618152618408203
  time_total_s: 2352.8304505348206
  timestamp: 1594147853
  timesteps_since_restore: 459000
  timesteps_this_iter: 2000
  timesteps_total: 459000
  training_iteration: 312
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10879], 2352 s, 312 iter, 459000 ts, 0 rew

agent-1: 0.0
Sum Reward: 0.0
Avg Reward: 0.0
Min Reward: 0.0
Max Reward: 0.0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
agent-1: 0.0
Sum Reward: 0.0
Avg Reward: 0.0
Min Reward: 0.0
Max Reward: 0.0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_14-51-02
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: 0.0
  episode_reward_min: 0.0
  episodes_this_iter: 2
  episodes_total: 460
  experiment_id: cb3a18e0a26e466496590bc0542b68c4
  hostname: gpu020
  info:
    apply_time_ms: 2.625
    dispatch_time_ms: 7.161
    learner:
      cur_lr: 0.0013294306118041277
      grad_gnorm: 0.10792515426874161
      policy_entropy: 0.008134212344884872
      policy_loss: 2.603404936962761e-06
      var_gnorm: 29.789113998413086
      vf_explained_var: 5.960464477539063e-08
      vf_loss: 8.220714516937733e-05
    num_steps_sampled: 461000
    num_steps_trained: 461000
    wait_time_ms: 31.224
  iterations_since_restore: 313
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 10879
  policy_reward_mean: {}
  time_since_restore: 2361.377857685089
  time_this_iter_s: 8.547407150268555
  time_total_s: 2361.377857685089
  timestamp: 1594147862
  timesteps_since_restore: 461000
  timesteps_this_iter: 2000
  timesteps_total: 461000
  training_iteration: 313
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10879], 2361 s, 313 iter, 461000 ts, 0 rew

agent-1: 0.0
Sum Reward: 0.0
Avg Reward: 0.0
Min Reward: 0.0
Max Reward: 0.0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
agent-1: 0.0
Sum Reward: 0.0
Avg Reward: 0.0
Min Reward: 0.0
Max Reward: 0.0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_14-51-10
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: 0.0
  episode_reward_min: 0.0
  episodes_this_iter: 2
  episodes_total: 462
  experiment_id: cb3a18e0a26e466496590bc0542b68c4
  hostname: gpu020
  info:
    apply_time_ms: 2.931
    dispatch_time_ms: 6.248
    learner:
      cur_lr: 0.0013292974326759577
      grad_gnorm: 0.10022879391908646
      policy_entropy: 0.0008347281254827976
      policy_loss: -1.9143102747420926e-07
      var_gnorm: 29.787473678588867
      vf_explained_var: 0.0
      vf_loss: 6.897464481880888e-05
    num_steps_sampled: 463000
    num_steps_trained: 463000
    wait_time_ms: 31.621
  iterations_since_restore: 314
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 10879
  policy_reward_mean: {}
  time_since_restore: 2369.941893339157
  time_this_iter_s: 8.564035654067993
  time_total_s: 2369.941893339157
  timestamp: 1594147870
  timesteps_since_restore: 463000
  timesteps_this_iter: 2000
  timesteps_total: 463000
  training_iteration: 314
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10879], 2369 s, 314 iter, 463000 ts, 0 rew

agent-1: 0.0
Sum Reward: 0.0
Avg Reward: 0.0
Min Reward: 0.0
Max Reward: 0.0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
agent-1: 0.0
Sum Reward: 0.0
Avg Reward: 0.0
Min Reward: 0.0
Max Reward: 0.0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_14-51-19
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: 0.0
  episode_reward_min: 0.0
  episodes_this_iter: 2
  episodes_total: 464
  experiment_id: cb3a18e0a26e466496590bc0542b68c4
  hostname: gpu020
  info:
    apply_time_ms: 2.519
    dispatch_time_ms: 7.574
    learner:
      cur_lr: 0.0013291642535477877
      grad_gnorm: 0.1312161237001419
      policy_entropy: 0.0007267171167768538
      policy_loss: 2.2093841778314527e-07
      var_gnorm: 29.79190444946289
      vf_explained_var: 0.0
      vf_loss: 0.00011821941734524444
    num_steps_sampled: 465000
    num_steps_trained: 465000
    wait_time_ms: 33.665
  iterations_since_restore: 315
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 10879
  policy_reward_mean: {}
  time_since_restore: 2378.554881334305
  time_this_iter_s: 8.612987995147705
  time_total_s: 2378.554881334305
  timestamp: 1594147879
  timesteps_since_restore: 465000
  timesteps_this_iter: 2000
  timesteps_total: 465000
  training_iteration: 315
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10879], 2378 s, 315 iter, 465000 ts, 0 rew

agent-1: 0.0
Sum Reward: 0.0
Avg Reward: 0.0
Min Reward: 0.0
Max Reward: 0.0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
agent-1: 0.0
Sum Reward: 0.0
Avg Reward: 0.0
Min Reward: 0.0
Max Reward: 0.0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_14-51-28
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: 0.0
  episode_reward_min: 0.0
  episodes_this_iter: 2
  episodes_total: 466
  experiment_id: cb3a18e0a26e466496590bc0542b68c4
  hostname: gpu020
  info:
    apply_time_ms: 2.727
    dispatch_time_ms: 8.333
    learner:
      cur_lr: 0.0013290309580042958
      grad_gnorm: 0.1054261326789856
      policy_entropy: 0.09567590057849884
      policy_loss: -4.033992809127085e-05
      var_gnorm: 29.796321868896484
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 7.719680434092879e-05
    num_steps_sampled: 467000
    num_steps_trained: 467000
    wait_time_ms: 33.448
  iterations_since_restore: 316
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 10879
  policy_reward_mean: {}
  time_since_restore: 2387.0935609340668
  time_this_iter_s: 8.538679599761963
  time_total_s: 2387.0935609340668
  timestamp: 1594147888
  timesteps_since_restore: 467000
  timesteps_this_iter: 2000
  timesteps_total: 467000
  training_iteration: 316
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10879], 2387 s, 316 iter, 467000 ts, 0 rew

agent-1: 0.0
Sum Reward: 0.0
Avg Reward: 0.0
Min Reward: 0.0
Max Reward: 0.0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
agent-1: 0.0
Sum Reward: 0.0
Avg Reward: 0.0
Min Reward: 0.0
Max Reward: 0.0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_14-51-36
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: 0.0
  episode_reward_min: 0.0
  episodes_this_iter: 2
  episodes_total: 468
  experiment_id: cb3a18e0a26e466496590bc0542b68c4
  hostname: gpu020
  info:
    apply_time_ms: 2.925
    dispatch_time_ms: 8.359
    learner:
      cur_lr: 0.0013288977788761258
      grad_gnorm: 0.00010354213009122759
      policy_entropy: 0.010743888095021248
      policy_loss: 1.0502070324491797e-08
      var_gnorm: 29.817670822143555
      vf_explained_var: 0.0
      vf_loss: 4.994873264996258e-11
    num_steps_sampled: 469000
    num_steps_trained: 469000
    wait_time_ms: 31.695
  iterations_since_restore: 317
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 10879
  policy_reward_mean: {}
  time_since_restore: 2395.6562848091125
  time_this_iter_s: 8.562723875045776
  time_total_s: 2395.6562848091125
  timestamp: 1594147896
  timesteps_since_restore: 469000
  timesteps_this_iter: 2000
  timesteps_total: 469000
  training_iteration: 317
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10879], 2395 s, 317 iter, 469000 ts, 0 rew

agent-1: 0.0
Sum Reward: 0.0
Avg Reward: 0.0
Min Reward: 0.0
Max Reward: 0.0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
agent-1: 0.0
Sum Reward: 0.0
Avg Reward: 0.0
Min Reward: 0.0
Max Reward: 0.0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_14-51-45
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: 0.0
  episode_reward_min: 0.0
  episodes_this_iter: 2
  episodes_total: 470
  experiment_id: cb3a18e0a26e466496590bc0542b68c4
  hostname: gpu020
  info:
    apply_time_ms: 3.999
    dispatch_time_ms: 7.174
    learner:
      cur_lr: 0.0013287645997479558
      grad_gnorm: 0.008646718226373196
      policy_entropy: 0.031111454591155052
      policy_loss: -1.2739691328533809e-06
      var_gnorm: 29.815608978271484
      vf_explained_var: 0.0
      vf_loss: 5.134982075105654e-07
    num_steps_sampled: 471000
    num_steps_trained: 471000
    wait_time_ms: 29.931
  iterations_since_restore: 318
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 10879
  policy_reward_mean: {}
  time_since_restore: 2404.1605331897736
  time_this_iter_s: 8.50424838066101
  time_total_s: 2404.1605331897736
  timestamp: 1594147905
  timesteps_since_restore: 471000
  timesteps_this_iter: 2000
  timesteps_total: 471000
  training_iteration: 318
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10879], 2404 s, 318 iter, 471000 ts, 0 rew

agent-1: 0.0
Sum Reward: 0.0
Avg Reward: 0.0
Min Reward: 0.0
Max Reward: 0.0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
agent-1: 0.0
Sum Reward: 0.0
Avg Reward: 0.0
Min Reward: 0.0
Max Reward: 0.0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_14-51-53
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: 0.0
  episode_reward_min: 0.0
  episodes_this_iter: 2
  episodes_total: 472
  experiment_id: cb3a18e0a26e466496590bc0542b68c4
  hostname: gpu020
  info:
    apply_time_ms: 3.495
    dispatch_time_ms: 8.257
    learner:
      cur_lr: 0.0013286314206197858
      grad_gnorm: 0.27001985907554626
      policy_entropy: 0.006847297307103872
      policy_loss: 5.511813469638582e-06
      var_gnorm: 29.92170524597168
      vf_explained_var: 0.0
      vf_loss: 0.0005006086430512369
    num_steps_sampled: 473000
    num_steps_trained: 473000
    wait_time_ms: 32.43
  iterations_since_restore: 319
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 10879
  policy_reward_mean: {}
  time_since_restore: 2412.7224686145782
  time_this_iter_s: 8.561935424804688
  time_total_s: 2412.7224686145782
  timestamp: 1594147913
  timesteps_since_restore: 473000
  timesteps_this_iter: 2000
  timesteps_total: 473000
  training_iteration: 319
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10879], 2412 s, 319 iter, 473000 ts, 0 rew

agent-1: 0.0
Sum Reward: 0.0
Avg Reward: 0.0
Min Reward: 0.0
Max Reward: 0.0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
agent-1: 0.0
Sum Reward: 0.0
Avg Reward: 0.0
Min Reward: 0.0
Max Reward: 0.0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_14-52-02
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: 0.0
  episode_reward_min: 0.0
  episodes_this_iter: 2
  episodes_total: 474
  experiment_id: cb3a18e0a26e466496590bc0542b68c4
  hostname: gpu020
  info:
    apply_time_ms: 2.714
    dispatch_time_ms: 8.45
    learner:
      cur_lr: 0.0013284982414916158
      grad_gnorm: 0.21065089106559753
      policy_entropy: 0.007272462360560894
      policy_loss: 4.85733426103252e-06
      var_gnorm: 29.92179298400879
      vf_explained_var: 1.1920928955078125e-07
      vf_loss: 0.0003046579658985138
    num_steps_sampled: 475000
    num_steps_trained: 475000
    wait_time_ms: 33.201
  iterations_since_restore: 320
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 10879
  policy_reward_mean: {}
  time_since_restore: 2421.2833898067474
  time_this_iter_s: 8.56092119216919
  time_total_s: 2421.2833898067474
  timestamp: 1594147922
  timesteps_since_restore: 475000
  timesteps_this_iter: 2000
  timesteps_total: 475000
  training_iteration: 320
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10879], 2421 s, 320 iter, 475000 ts, 0 rew

agent-1: 0.0
Sum Reward: 0.0
Avg Reward: 0.0
Min Reward: 0.0
Max Reward: 0.0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
agent-1: 0.0
Sum Reward: 0.0
Avg Reward: 0.0
Min Reward: 0.0
Max Reward: 0.0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_14-52-11
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: 0.0
  episode_reward_min: 0.0
  episodes_this_iter: 2
  episodes_total: 476
  experiment_id: cb3a18e0a26e466496590bc0542b68c4
  hostname: gpu020
  info:
    apply_time_ms: 3.324
    dispatch_time_ms: 7.583
    learner:
      cur_lr: 0.001328364945948124
      grad_gnorm: 0.006607160437852144
      policy_entropy: 0.00762915750965476
      policy_loss: -1.631337909202557e-07
      var_gnorm: 29.92164421081543
      vf_explained_var: 0.0
      vf_loss: 2.998576462687197e-07
    num_steps_sampled: 477000
    num_steps_trained: 477000
    wait_time_ms: 30.733
  iterations_since_restore: 321
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 10879
  policy_reward_mean: {}
  time_since_restore: 2429.825213432312
  time_this_iter_s: 8.541823625564575
  time_total_s: 2429.825213432312
  timestamp: 1594147931
  timesteps_since_restore: 477000
  timesteps_this_iter: 2000
  timesteps_total: 477000
  training_iteration: 321
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10879], 2429 s, 321 iter, 477000 ts, 0 rew

agent-1: 0.0
Sum Reward: 0.0
Avg Reward: 0.0
Min Reward: 0.0
Max Reward: 0.0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
agent-1: 0.0
Sum Reward: 0.0
Avg Reward: 0.0
Min Reward: 0.0
Max Reward: 0.0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_14-52-20
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: 0.0
  episode_reward_min: 0.0
  episodes_this_iter: 2
  episodes_total: 478
  experiment_id: cb3a18e0a26e466496590bc0542b68c4
  hostname: gpu020
  info:
    apply_time_ms: 2.547
    dispatch_time_ms: 38.893
    learner:
      cur_lr: 0.001328231766819954
      grad_gnorm: 32.29218292236328
      policy_entropy: 0.008285670541226864
      policy_loss: 0.0002164900943171233
      var_gnorm: 29.922645568847656
      vf_explained_var: 1.1920928955078125e-06
      vf_loss: 5.675363540649414
    num_steps_sampled: 479000
    num_steps_trained: 479000
    wait_time_ms: 21.35
  iterations_since_restore: 322
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 10879
  policy_reward_mean: {}
  time_since_restore: 2439.5869138240814
  time_this_iter_s: 9.76170039176941
  time_total_s: 2439.5869138240814
  timestamp: 1594147940
  timesteps_since_restore: 479000
  timesteps_this_iter: 2000
  timesteps_total: 479000
  training_iteration: 322
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10879], 2439 s, 322 iter, 479000 ts, 0 rew

agent-1: 0.0
Sum Reward: 0.0
Avg Reward: 0.0
Min Reward: 0.0
Max Reward: 0.0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
agent-1: 0.0
Sum Reward: 0.0
Avg Reward: 0.0
Min Reward: 0.0
Max Reward: 0.0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_14-52-26
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: 0.0
  episode_reward_min: 0.0
  episodes_this_iter: 2
  episodes_total: 480
  experiment_id: cb3a18e0a26e466496590bc0542b68c4
  hostname: gpu020
  info:
    apply_time_ms: 3.496
    dispatch_time_ms: 38.488
    learner:
      cur_lr: 0.001328098587691784
      grad_gnorm: 1.6027051210403442
      policy_entropy: 0.016248133033514023
      policy_loss: -2.588237293821294e-05
      var_gnorm: 29.922733306884766
      vf_explained_var: 0.0
      vf_loss: 0.014329028315842152
    num_steps_sampled: 480000
    num_steps_trained: 480000
    wait_time_ms: 17.69
  iterations_since_restore: 323
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 10879
  policy_reward_mean: {}
  time_since_restore: 2445.4922349452972
  time_this_iter_s: 5.90532112121582
  time_total_s: 2445.4922349452972
  timestamp: 1594147946
  timesteps_since_restore: 480000
  timesteps_this_iter: 1000
  timesteps_total: 480000
  training_iteration: 323
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10879], 2445 s, 323 iter, 480000 ts, 0 rew

Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_14-52-32
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: 0.0
  episode_reward_min: 0.0
  episodes_this_iter: 0
  episodes_total: 480
  experiment_id: cb3a18e0a26e466496590bc0542b68c4
  hostname: gpu020
  info:
    apply_time_ms: 3.265
    dispatch_time_ms: 47.954
    learner:
      cur_lr: 0.001328031998127699
      grad_gnorm: 0.048280466347932816
      policy_entropy: 0.00912463292479515
      policy_loss: -2.3738291474728612e-06
      var_gnorm: 29.923629760742188
      vf_explained_var: 0.0
      vf_loss: 2.284366200910881e-05
    num_steps_sampled: 481000
    num_steps_trained: 481000
    wait_time_ms: 11.862
  iterations_since_restore: 324
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 10879
  policy_reward_mean: {}
  time_since_restore: 2451.5605907440186
  time_this_iter_s: 6.0683557987213135
  time_total_s: 2451.5605907440186
  timestamp: 1594147952
  timesteps_since_restore: 481000
  timesteps_this_iter: 1000
  timesteps_total: 481000
  training_iteration: 324
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10879], 2451 s, 324 iter, 481000 ts, 0 rew

agent-1: 0.0
Sum Reward: 0.0
Avg Reward: 0.0
Min Reward: 0.0
Max Reward: 0.0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
agent-1: 0.0
Sum Reward: 0.0
Avg Reward: 0.0
Min Reward: 0.0
Max Reward: 0.0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_14-52-39
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: 0.0
  episode_reward_min: 0.0
  episodes_this_iter: 2
  episodes_total: 482
  experiment_id: cb3a18e0a26e466496590bc0542b68c4
  hostname: gpu020
  info:
    apply_time_ms: 2.513
    dispatch_time_ms: 27.965
    learner:
      cur_lr: 0.001327965408563614
      grad_gnorm: 0.008125691674649715
      policy_entropy: 0.009001532569527626
      policy_loss: -1.5804798749741167e-06
      var_gnorm: 29.923826217651367
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 5.018730462325038e-06
    num_steps_sampled: 482000
    num_steps_trained: 482000
    wait_time_ms: 29.257
  iterations_since_restore: 325
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 10879
  policy_reward_mean: {}
  time_since_restore: 2458.109356880188
  time_this_iter_s: 6.548766136169434
  time_total_s: 2458.109356880188
  timestamp: 1594147959
  timesteps_since_restore: 482000
  timesteps_this_iter: 1000
  timesteps_total: 482000
  training_iteration: 325
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10879], 2458 s, 325 iter, 482000 ts, 0 rew

Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_14-52-45
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: 0.0
  episode_reward_min: 0.0
  episodes_this_iter: 0
  episodes_total: 482
  experiment_id: cb3a18e0a26e466496590bc0542b68c4
  hostname: gpu020
  info:
    apply_time_ms: 2.563
    dispatch_time_ms: 28.081
    learner:
      cur_lr: 0.0013278988189995289
      grad_gnorm: 0.0894647166132927
      policy_entropy: 0.014842474833130836
      policy_loss: -1.7336753899144242e-06
      var_gnorm: 29.922321319580078
      vf_explained_var: 0.0
      vf_loss: 4.538981738733128e-05
    num_steps_sampled: 483000
    num_steps_trained: 483000
    wait_time_ms: 26.42
  iterations_since_restore: 326
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 10879
  policy_reward_mean: {}
  time_since_restore: 2464.2624113559723
  time_this_iter_s: 6.153054475784302
  time_total_s: 2464.2624113559723
  timestamp: 1594147965
  timesteps_since_restore: 483000
  timesteps_this_iter: 1000
  timesteps_total: 483000
  training_iteration: 326
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10879], 2464 s, 326 iter, 483000 ts, 0 rew

agent-1: 0.0
Sum Reward: 0.0
Avg Reward: 0.0
Min Reward: 0.0
Max Reward: 0.0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
agent-1: 0.0
Sum Reward: 0.0
Avg Reward: 0.0
Min Reward: 0.0
Max Reward: 0.0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_14-52-51
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: 0.0
  episode_reward_min: 0.0
  episodes_this_iter: 2
  episodes_total: 484
  experiment_id: cb3a18e0a26e466496590bc0542b68c4
  hostname: gpu020
  info:
    apply_time_ms: 3.727
    dispatch_time_ms: 43.618
    learner:
      cur_lr: 0.0013278322294354439
      grad_gnorm: 0.07586219906806946
      policy_entropy: 0.014953617937862873
      policy_loss: -1.1108373882962042e-06
      var_gnorm: 29.922687530517578
      vf_explained_var: 0.0
      vf_loss: 3.205817120033316e-05
    num_steps_sampled: 484000
    num_steps_trained: 484000
    wait_time_ms: 14.706
  iterations_since_restore: 327
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 10879
  policy_reward_mean: {}
  time_since_restore: 2470.328032016754
  time_this_iter_s: 6.06562066078186
  time_total_s: 2470.328032016754
  timestamp: 1594147971
  timesteps_since_restore: 484000
  timesteps_this_iter: 1000
  timesteps_total: 484000
  training_iteration: 327
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10879], 2470 s, 327 iter, 484000 ts, 0 rew

Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_14-52-57
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: 0.0
  episode_reward_min: 0.0
  episodes_this_iter: 0
  episodes_total: 484
  experiment_id: cb3a18e0a26e466496590bc0542b68c4
  hostname: gpu020
  info:
    apply_time_ms: 3.005
    dispatch_time_ms: 34.092
    learner:
      cur_lr: 0.0013277656398713589
      grad_gnorm: 0.004991475492715836
      policy_entropy: 0.015185474418103695
      policy_loss: -8.710159704605758e-07
      var_gnorm: 29.92304039001465
      vf_explained_var: 0.0
      vf_loss: 5.810192078570253e-07
    num_steps_sampled: 485000
    num_steps_trained: 485000
    wait_time_ms: 32.895
  iterations_since_restore: 328
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 10879
  policy_reward_mean: {}
  time_since_restore: 2476.2529039382935
  time_this_iter_s: 5.924871921539307
  time_total_s: 2476.2529039382935
  timestamp: 1594147977
  timesteps_since_restore: 485000
  timesteps_this_iter: 1000
  timesteps_total: 485000
  training_iteration: 328
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10879], 2476 s, 328 iter, 485000 ts, 0 rew

agent-1: 0.0
Sum Reward: 0.0
Avg Reward: 0.0
Min Reward: 0.0
Max Reward: 0.0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
agent-1: 0.0
Sum Reward: 0.0
Avg Reward: 0.0
Min Reward: 0.0
Max Reward: 0.0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_14-53-03
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: 0.0
  episode_reward_min: 0.0
  episodes_this_iter: 2
  episodes_total: 486
  experiment_id: cb3a18e0a26e466496590bc0542b68c4
  hostname: gpu020
  info:
    apply_time_ms: 3.753
    dispatch_time_ms: 32.436
    learner:
      cur_lr: 0.0013276990503072739
      grad_gnorm: 0.2827906310558319
      policy_entropy: 0.030204590409994125
      policy_loss: -3.081514660152607e-05
      var_gnorm: 29.92340660095215
      vf_explained_var: 1.1920928955078125e-07
      vf_loss: 0.0005632297252304852
    num_steps_sampled: 486000
    num_steps_trained: 486000
    wait_time_ms: 25.262
  iterations_since_restore: 329
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 10879
  policy_reward_mean: {}
  time_since_restore: 2482.171335697174
  time_this_iter_s: 5.918431758880615
  time_total_s: 2482.171335697174
  timestamp: 1594147983
  timesteps_since_restore: 486000
  timesteps_this_iter: 1000
  timesteps_total: 486000
  training_iteration: 329
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10879], 2482 s, 329 iter, 486000 ts, 0 rew

Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_14-53-09
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: 0.0
  episode_reward_min: 0.0
  episodes_this_iter: 0
  episodes_total: 486
  experiment_id: cb3a18e0a26e466496590bc0542b68c4
  hostname: gpu020
  info:
    apply_time_ms: 5.245
    dispatch_time_ms: 34.091
    learner:
      cur_lr: 0.001327632344327867
      grad_gnorm: 0.012703757733106613
      policy_entropy: 0.07360628247261047
      policy_loss: -6.614061567233875e-05
      var_gnorm: 29.93123435974121
      vf_explained_var: 0.0
      vf_loss: 8.373519813176244e-05
    num_steps_sampled: 487000
    num_steps_trained: 487000
    wait_time_ms: 9.668
  iterations_since_restore: 330
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 10879
  policy_reward_mean: {}
  time_since_restore: 2488.412804365158
  time_this_iter_s: 6.241468667984009
  time_total_s: 2488.412804365158
  timestamp: 1594147989
  timesteps_since_restore: 487000
  timesteps_this_iter: 1000
  timesteps_total: 487000
  training_iteration: 330
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10879], 2488 s, 330 iter, 487000 ts, 0 rew

agent-1: 3.0
Sum Reward: 3.0
Avg Reward: 3.0
Min Reward: 3.0
Max Reward: 3.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
agent-1: 16.0
Sum Reward: 16.0
Avg Reward: 16.0
Min Reward: 16.0
Max Reward: 16.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_14-53-15
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 16.0
  episode_reward_mean: 0.19
  episode_reward_min: 0.0
  episodes_this_iter: 2
  episodes_total: 488
  experiment_id: cb3a18e0a26e466496590bc0542b68c4
  hostname: gpu020
  info:
    apply_time_ms: 2.405
    dispatch_time_ms: 42.005
    learner:
      cur_lr: 0.001327565754763782
      grad_gnorm: 40.000003814697266
      policy_entropy: 3.559053897857666
      policy_loss: 10.66496467590332
      var_gnorm: 30.006351470947266
      vf_explained_var: -0.04216301441192627
      vf_loss: 53.60862350463867
    num_steps_sampled: 488000
    num_steps_trained: 488000
    wait_time_ms: 22.422
  iterations_since_restore: 331
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 10879
  policy_reward_mean: {}
  time_since_restore: 2494.5121166706085
  time_this_iter_s: 6.0993123054504395
  time_total_s: 2494.5121166706085
  timestamp: 1594147995
  timesteps_since_restore: 488000
  timesteps_this_iter: 1000
  timesteps_total: 488000
  training_iteration: 331
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10879], 2494 s, 331 iter, 488000 ts, 0.19 rew

Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_14-53-21
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 16.0
  episode_reward_mean: 0.19
  episode_reward_min: 0.0
  episodes_this_iter: 0
  episodes_total: 488
  experiment_id: cb3a18e0a26e466496590bc0542b68c4
  hostname: gpu020
  info:
    apply_time_ms: 3.819
    dispatch_time_ms: 35.549
    learner:
      cur_lr: 0.001327499165199697
      grad_gnorm: 2.875868558883667
      policy_entropy: 2.279294013977051
      policy_loss: -0.031539201736450195
      var_gnorm: 30.0685977935791
      vf_explained_var: 0.0
      vf_loss: 0.04800034314393997
    num_steps_sampled: 489000
    num_steps_trained: 489000
    wait_time_ms: 18.097
  iterations_since_restore: 332
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 10879
  policy_reward_mean: {}
  time_since_restore: 2500.398886203766
  time_this_iter_s: 5.886769533157349
  time_total_s: 2500.398886203766
  timestamp: 1594148001
  timesteps_since_restore: 489000
  timesteps_this_iter: 1000
  timesteps_total: 489000
  training_iteration: 332
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10879], 2500 s, 332 iter, 489000 ts, 0.19 rew

agent-1: 22.0
Sum Reward: 22.0
Avg Reward: 22.0
Min Reward: 22.0
Max Reward: 22.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_14-53-27
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 22.0
  episode_reward_mean: 0.41
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 489
  experiment_id: cb3a18e0a26e466496590bc0542b68c4
  hostname: gpu020
  info:
    apply_time_ms: 4.736
    dispatch_time_ms: 21.34
    learner:
      cur_lr: 0.001327432575635612
      grad_gnorm: 1.982839822769165
      policy_entropy: 2.2630558013916016
      policy_loss: -0.06008101999759674
      var_gnorm: 30.065406799316406
      vf_explained_var: 0.0
      vf_loss: 0.022400740534067154
    num_steps_sampled: 490000
    num_steps_trained: 490000
    wait_time_ms: 17.185
  iterations_since_restore: 333
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 10879
  policy_reward_mean: {}
  time_since_restore: 2506.2696311473846
  time_this_iter_s: 5.870744943618774
  time_total_s: 2506.2696311473846
  timestamp: 1594148007
  timesteps_since_restore: 490000
  timesteps_this_iter: 1000
  timesteps_total: 490000
  training_iteration: 333
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10879], 2506 s, 333 iter, 490000 ts, 0.41 rew

agent-1: 0.0
Sum Reward: 0.0
Avg Reward: 0.0
Min Reward: 0.0
Max Reward: 0.0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_14-53-33
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 22.0
  episode_reward_mean: 0.41
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 490
  experiment_id: cb3a18e0a26e466496590bc0542b68c4
  hostname: gpu020
  info:
    apply_time_ms: 3.452
    dispatch_time_ms: 7.384
    learner:
      cur_lr: 0.001327365986071527
      grad_gnorm: 0.7288944125175476
      policy_entropy: 1.4127248525619507
      policy_loss: -0.008137589320540428
      var_gnorm: 30.066394805908203
      vf_explained_var: 0.0
      vf_loss: 0.0036094002425670624
    num_steps_sampled: 491000
    num_steps_trained: 491000
    wait_time_ms: 33.119
  iterations_since_restore: 334
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 10879
  policy_reward_mean: {}
  time_since_restore: 2511.882011651993
  time_this_iter_s: 5.612380504608154
  time_total_s: 2511.882011651993
  timestamp: 1594148013
  timesteps_since_restore: 491000
  timesteps_this_iter: 1000
  timesteps_total: 491000
  training_iteration: 334
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10879], 2511 s, 334 iter, 491000 ts, 0.41 rew

agent-1: 0.0
Sum Reward: 0.0
Avg Reward: 0.0
Min Reward: 0.0
Max Reward: 0.0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
agent-1: 8.0
Sum Reward: 8.0
Avg Reward: 8.0
Min Reward: 8.0
Max Reward: 8.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_14-53-41
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 22.0
  episode_reward_mean: 0.49
  episode_reward_min: 0.0
  episodes_this_iter: 2
  episodes_total: 492
  experiment_id: cb3a18e0a26e466496590bc0542b68c4
  hostname: gpu020
  info:
    apply_time_ms: 3.231
    dispatch_time_ms: 7.994
    learner:
      cur_lr: 0.001327299396507442
      grad_gnorm: 0.25262001156806946
      policy_entropy: 1.5985472202301025
      policy_loss: -0.003787197871133685
      var_gnorm: 30.066186904907227
      vf_explained_var: 0.0
      vf_loss: 0.0004278619890101254
    num_steps_sampled: 493000
    num_steps_trained: 493000
    wait_time_ms: 31.537
  iterations_since_restore: 335
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 10879
  policy_reward_mean: {}
  time_since_restore: 2520.448705673218
  time_this_iter_s: 8.566694021224976
  time_total_s: 2520.448705673218
  timestamp: 1594148021
  timesteps_since_restore: 493000
  timesteps_this_iter: 2000
  timesteps_total: 493000
  training_iteration: 335
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10879], 2520 s, 335 iter, 493000 ts, 0.49 rew

agent-1: 10.0
Sum Reward: 10.0
Avg Reward: 10.0
Min Reward: 10.0
Max Reward: 10.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
agent-1: 0.0
Sum Reward: 0.0
Avg Reward: 0.0
Min Reward: 0.0
Max Reward: 0.0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_14-53-50
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 22.0
  episode_reward_mean: 0.59
  episode_reward_min: 0.0
  episodes_this_iter: 2
  episodes_total: 494
  experiment_id: cb3a18e0a26e466496590bc0542b68c4
  hostname: gpu020
  info:
    apply_time_ms: 2.64
    dispatch_time_ms: 6.251
    learner:
      cur_lr: 0.001327166217379272
      grad_gnorm: 0.953271210193634
      policy_entropy: 0.7890688180923462
      policy_loss: -0.0054525332525372505
      var_gnorm: 30.06683349609375
      vf_explained_var: 0.0
      vf_loss: 0.00622214563190937
    num_steps_sampled: 495000
    num_steps_trained: 495000
    wait_time_ms: 35.253
  iterations_since_restore: 336
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 10879
  policy_reward_mean: {}
  time_since_restore: 2529.023244857788
  time_this_iter_s: 8.574539184570312
  time_total_s: 2529.023244857788
  timestamp: 1594148030
  timesteps_since_restore: 495000
  timesteps_this_iter: 2000
  timesteps_total: 495000
  training_iteration: 336
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10879], 2529 s, 336 iter, 495000 ts, 0.59 rew

agent-1: 0.0
Sum Reward: 0.0
Avg Reward: 0.0
Min Reward: 0.0
Max Reward: 0.0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
agent-1: 18.0
Sum Reward: 18.0
Avg Reward: 18.0
Min Reward: 18.0
Max Reward: 18.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_14-53-59
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 22.0
  episode_reward_mean: 0.77
  episode_reward_min: 0.0
  episodes_this_iter: 2
  episodes_total: 496
  experiment_id: cb3a18e0a26e466496590bc0542b68c4
  hostname: gpu020
  info:
    apply_time_ms: 2.676
    dispatch_time_ms: 8.011
    learner:
      cur_lr: 0.001327033038251102
      grad_gnorm: 0.012239580042660236
      policy_entropy: 0.826471209526062
      policy_loss: -6.359476537909359e-05
      var_gnorm: 30.06475830078125
      vf_explained_var: 0.0
      vf_loss: 8.970374665295822e-07
    num_steps_sampled: 497000
    num_steps_trained: 497000
    wait_time_ms: 30.869
  iterations_since_restore: 337
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 10879
  policy_reward_mean: {}
  time_since_restore: 2537.558396100998
  time_this_iter_s: 8.535151243209839
  time_total_s: 2537.558396100998
  timestamp: 1594148039
  timesteps_since_restore: 497000
  timesteps_this_iter: 2000
  timesteps_total: 497000
  training_iteration: 337
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10879], 2537 s, 337 iter, 497000 ts, 0.77 rew

agent-1: 0.0
Sum Reward: 0.0
Avg Reward: 0.0
Min Reward: 0.0
Max Reward: 0.0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
agent-1: 0.0
Sum Reward: 0.0
Avg Reward: 0.0
Min Reward: 0.0
Max Reward: 0.0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_14-54-07
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 22.0
  episode_reward_mean: 0.77
  episode_reward_min: 0.0
  episodes_this_iter: 2
  episodes_total: 498
  experiment_id: cb3a18e0a26e466496590bc0542b68c4
  hostname: gpu020
  info:
    apply_time_ms: 2.594
    dispatch_time_ms: 6.923
    learner:
      cur_lr: 0.0013268997427076101
      grad_gnorm: 0.17503201961517334
      policy_entropy: 0.7263009548187256
      policy_loss: -0.0007957496563903987
      var_gnorm: 30.065044403076172
      vf_explained_var: 0.0
      vf_loss: 0.0002096371608786285
    num_steps_sampled: 499000
    num_steps_trained: 499000
    wait_time_ms: 34.142
  iterations_since_restore: 338
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 10879
  policy_reward_mean: {}
  time_since_restore: 2546.113579273224
  time_this_iter_s: 8.555183172225952
  time_total_s: 2546.113579273224
  timestamp: 1594148047
  timesteps_since_restore: 499000
  timesteps_this_iter: 2000
  timesteps_total: 499000
  training_iteration: 338
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10879], 2546 s, 338 iter, 499000 ts, 0.77 rew

agent-1: 7.0
Sum Reward: 7.0
Avg Reward: 7.0
Min Reward: 7.0
Max Reward: 7.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
agent-1: 0.0
Sum Reward: 0.0
Avg Reward: 0.0
Min Reward: 0.0
Max Reward: 0.0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_14-54-16
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 22.0
  episode_reward_mean: 0.84
  episode_reward_min: 0.0
  episodes_this_iter: 2
  episodes_total: 500
  experiment_id: cb3a18e0a26e466496590bc0542b68c4
  hostname: gpu020
  info:
    apply_time_ms: 4.188
    dispatch_time_ms: 9.517
    learner:
      cur_lr: 0.0013267665635794401
      grad_gnorm: 0.09481780976057053
      policy_entropy: 0.7230589389801025
      policy_loss: -0.00044763865298591554
      var_gnorm: 30.065000534057617
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 6.137204036349431e-05
    num_steps_sampled: 501000
    num_steps_trained: 501000
    wait_time_ms: 28.666
  iterations_since_restore: 339
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 10879
  policy_reward_mean: {}
  time_since_restore: 2554.6761949062347
  time_this_iter_s: 8.562615633010864
  time_total_s: 2554.6761949062347
  timestamp: 1594148056
  timesteps_since_restore: 501000
  timesteps_this_iter: 2000
  timesteps_total: 501000
  training_iteration: 339
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10879], 2554 s, 339 iter, 501000 ts, 0.84 rew

agent-1: 1.0
Sum Reward: 1.0
Avg Reward: 1.0
Min Reward: 1.0
Max Reward: 1.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
agent-1: 1.0
Sum Reward: 1.0
Avg Reward: 1.0
Min Reward: 1.0
Max Reward: 1.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_14-54-24
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 22.0
  episode_reward_mean: 0.86
  episode_reward_min: 0.0
  episodes_this_iter: 2
  episodes_total: 502
  experiment_id: cb3a18e0a26e466496590bc0542b68c4
  hostname: gpu020
  info:
    apply_time_ms: 2.887
    dispatch_time_ms: 7.467
    learner:
      cur_lr: 0.00132663338445127
      grad_gnorm: 0.13858960568904877
      policy_entropy: 0.7312785387039185
      policy_loss: -0.0008179034339264035
      var_gnorm: 30.14293670654297
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 0.00013113788736518472
    num_steps_sampled: 503000
    num_steps_trained: 503000
    wait_time_ms: 32.657
  iterations_since_restore: 340
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 10879
  policy_reward_mean: {}
  time_since_restore: 2563.241617202759
  time_this_iter_s: 8.565422296524048
  time_total_s: 2563.241617202759
  timestamp: 1594148064
  timesteps_since_restore: 503000
  timesteps_this_iter: 2000
  timesteps_total: 503000
  training_iteration: 340
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10879], 2563 s, 340 iter, 503000 ts, 0.86 rew

agent-1: 9.0
Sum Reward: 9.0
Avg Reward: 9.0
Min Reward: 9.0
Max Reward: 9.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
agent-1: 0.0
Sum Reward: 0.0
Avg Reward: 0.0
Min Reward: 0.0
Max Reward: 0.0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_14-54-33
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 22.0
  episode_reward_mean: 0.95
  episode_reward_min: 0.0
  episodes_this_iter: 2
  episodes_total: 504
  experiment_id: cb3a18e0a26e466496590bc0542b68c4
  hostname: gpu020
  info:
    apply_time_ms: 3.513
    dispatch_time_ms: 9.021
    learner:
      cur_lr: 0.0013265002053231
      grad_gnorm: 0.21430450677871704
      policy_entropy: 0.726604700088501
      policy_loss: -0.0010700596030801535
      var_gnorm: 30.22708511352539
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 0.00031425399356521666
    num_steps_sampled: 505000
    num_steps_trained: 505000
    wait_time_ms: 30.453
  iterations_since_restore: 341
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 10879
  policy_reward_mean: {}
  time_since_restore: 2571.840120792389
  time_this_iter_s: 8.598503589630127
  time_total_s: 2571.840120792389
  timestamp: 1594148073
  timesteps_since_restore: 505000
  timesteps_this_iter: 2000
  timesteps_total: 505000
  training_iteration: 341
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10879], 2571 s, 341 iter, 505000 ts, 0.95 rew

agent-1: 3.0
Sum Reward: 3.0
Avg Reward: 3.0
Min Reward: 3.0
Max Reward: 3.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
agent-1: 5.0
Sum Reward: 5.0
Avg Reward: 5.0
Min Reward: 5.0
Max Reward: 5.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_14-54-42
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 22.0
  episode_reward_mean: 1.03
  episode_reward_min: 0.0
  episodes_this_iter: 2
  episodes_total: 506
  experiment_id: cb3a18e0a26e466496590bc0542b68c4
  hostname: gpu020
  info:
    apply_time_ms: 2.547
    dispatch_time_ms: 5.904
    learner:
      cur_lr: 0.00132636702619493
      grad_gnorm: 0.3873860538005829
      policy_entropy: 0.4993918836116791
      policy_loss: -0.09130453318357468
      var_gnorm: 30.228029251098633
      vf_explained_var: 0.0
      vf_loss: 0.0008714711875654757
    num_steps_sampled: 507000
    num_steps_trained: 507000
    wait_time_ms: 35.432
  iterations_since_restore: 342
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 10879
  policy_reward_mean: {}
  time_since_restore: 2580.438138484955
  time_this_iter_s: 8.598017692565918
  time_total_s: 2580.438138484955
  timestamp: 1594148082
  timesteps_since_restore: 507000
  timesteps_this_iter: 2000
  timesteps_total: 507000
  training_iteration: 342
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10879], 2580 s, 342 iter, 507000 ts, 1.03 rew

agent-1: 0.0
Sum Reward: 0.0
Avg Reward: 0.0
Min Reward: 0.0
Max Reward: 0.0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
agent-1: 10.0
Sum Reward: 10.0
Avg Reward: 10.0
Min Reward: 10.0
Max Reward: 10.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_14-54-50
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 22.0
  episode_reward_mean: 1.13
  episode_reward_min: 0.0
  episodes_this_iter: 2
  episodes_total: 508
  experiment_id: cb3a18e0a26e466496590bc0542b68c4
  hostname: gpu020
  info:
    apply_time_ms: 2.558
    dispatch_time_ms: 9.644
    learner:
      cur_lr: 0.00132623384706676
      grad_gnorm: 0.18454131484031677
      policy_entropy: 0.4404730200767517
      policy_loss: -0.0005020747194066644
      var_gnorm: 30.2283992767334
      vf_explained_var: 0.0
      vf_loss: 0.00023354288714472204
    num_steps_sampled: 509000
    num_steps_trained: 509000
    wait_time_ms: 32.582
  iterations_since_restore: 343
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 10879
  policy_reward_mean: {}
  time_since_restore: 2589.0513801574707
  time_this_iter_s: 8.61324167251587
  time_total_s: 2589.0513801574707
  timestamp: 1594148090
  timesteps_since_restore: 509000
  timesteps_this_iter: 2000
  timesteps_total: 509000
  training_iteration: 343
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10879], 2589 s, 343 iter, 509000 ts, 1.13 rew

agent-1: 9.0
Sum Reward: 9.0
Avg Reward: 9.0
Min Reward: 9.0
Max Reward: 9.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
agent-1: 0.0
Sum Reward: 0.0
Avg Reward: 0.0
Min Reward: 0.0
Max Reward: 0.0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_14-54-59
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 22.0
  episode_reward_mean: 1.22
  episode_reward_min: 0.0
  episodes_this_iter: 2
  episodes_total: 510
  experiment_id: cb3a18e0a26e466496590bc0542b68c4
  hostname: gpu020
  info:
    apply_time_ms: 2.569
    dispatch_time_ms: 7.584
    learner:
      cur_lr: 0.0013261005515232682
      grad_gnorm: 0.3909086287021637
      policy_entropy: 1.0298629999160767
      policy_loss: -0.0027578335721045732
      var_gnorm: 30.22627067565918
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 0.0010437911842018366
    num_steps_sampled: 511000
    num_steps_trained: 511000
    wait_time_ms: 30.384
  iterations_since_restore: 344
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 10879
  policy_reward_mean: {}
  time_since_restore: 2597.659572124481
  time_this_iter_s: 8.608191967010498
  time_total_s: 2597.659572124481
  timestamp: 1594148099
  timesteps_since_restore: 511000
  timesteps_this_iter: 2000
  timesteps_total: 511000
  training_iteration: 344
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10879], 2597 s, 344 iter, 511000 ts, 1.22 rew

agent-1: 10.0
Sum Reward: 10.0
Avg Reward: 10.0
Min Reward: 10.0
Max Reward: 10.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
agent-1: 4.0
Sum Reward: 4.0
Avg Reward: 4.0
Min Reward: 4.0
Max Reward: 4.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_14-55-08
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 22.0
  episode_reward_mean: 1.36
  episode_reward_min: 0.0
  episodes_this_iter: 2
  episodes_total: 512
  experiment_id: cb3a18e0a26e466496590bc0542b68c4
  hostname: gpu020
  info:
    apply_time_ms: 3.435
    dispatch_time_ms: 8.928
    learner:
      cur_lr: 0.0013259673723950982
      grad_gnorm: 0.6527034640312195
      policy_entropy: 1.4091180562973022
      policy_loss: -0.03503425419330597
      var_gnorm: 30.22555923461914
      vf_explained_var: 0.0
      vf_loss: 0.002925065578892827
    num_steps_sampled: 513000
    num_steps_trained: 513000
    wait_time_ms: 30.8
  iterations_since_restore: 345
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 10879
  policy_reward_mean: {}
  time_since_restore: 2606.2552919387817
  time_this_iter_s: 8.595719814300537
  time_total_s: 2606.2552919387817
  timestamp: 1594148108
  timesteps_since_restore: 513000
  timesteps_this_iter: 2000
  timesteps_total: 513000
  training_iteration: 345
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10879], 2606 s, 345 iter, 513000 ts, 1.36 rew

agent-1: 0.0
Sum Reward: 0.0
Avg Reward: 0.0
Min Reward: 0.0
Max Reward: 0.0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
agent-1: 14.0
Sum Reward: 14.0
Avg Reward: 14.0
Min Reward: 14.0
Max Reward: 14.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_14-55-16
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 22.0
  episode_reward_mean: 1.5
  episode_reward_min: 0.0
  episodes_this_iter: 2
  episodes_total: 514
  experiment_id: cb3a18e0a26e466496590bc0542b68c4
  hostname: gpu020
  info:
    apply_time_ms: 3.034
    dispatch_time_ms: 7.629
    learner:
      cur_lr: 0.0013258341932669282
      grad_gnorm: 0.008023913018405437
      policy_entropy: 1.6140718460083008
      policy_loss: -4.9499441956868395e-05
      var_gnorm: 30.225404739379883
      vf_explained_var: 0.0
      vf_loss: 6.975401589670582e-08
    num_steps_sampled: 515000
    num_steps_trained: 515000
    wait_time_ms: 30.902
  iterations_since_restore: 346
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 10879
  policy_reward_mean: {}
  time_since_restore: 2614.746757030487
  time_this_iter_s: 8.491465091705322
  time_total_s: 2614.746757030487
  timestamp: 1594148116
  timesteps_since_restore: 515000
  timesteps_this_iter: 2000
  timesteps_total: 515000
  training_iteration: 346
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10879], 2614 s, 346 iter, 515000 ts, 1.5 rew

agent-1: 0.0
Sum Reward: 0.0
Avg Reward: 0.0
Min Reward: 0.0
Max Reward: 0.0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
agent-1: 13.0
Sum Reward: 13.0
Avg Reward: 13.0
Min Reward: 13.0
Max Reward: 13.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_14-55-25
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 22.0
  episode_reward_mean: 1.63
  episode_reward_min: 0.0
  episodes_this_iter: 2
  episodes_total: 516
  experiment_id: cb3a18e0a26e466496590bc0542b68c4
  hostname: gpu020
  info:
    apply_time_ms: 2.438
    dispatch_time_ms: 7.303
    learner:
      cur_lr: 0.0013257010141387582
      grad_gnorm: 1.1605674028396606
      policy_entropy: 0.8668423891067505
      policy_loss: -0.03716330975294113
      var_gnorm: 30.23201560974121
      vf_explained_var: 0.0
      vf_loss: 0.009247291833162308
    num_steps_sampled: 517000
    num_steps_trained: 517000
    wait_time_ms: 35.786
  iterations_since_restore: 347
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 10879
  policy_reward_mean: {}
  time_since_restore: 2623.3276319503784
  time_this_iter_s: 8.580874919891357
  time_total_s: 2623.3276319503784
  timestamp: 1594148125
  timesteps_since_restore: 517000
  timesteps_this_iter: 2000
  timesteps_total: 517000
  training_iteration: 347
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10879], 2623 s, 347 iter, 517000 ts, 1.63 rew

agent-1: 5.0
Sum Reward: 5.0
Avg Reward: 5.0
Min Reward: 5.0
Max Reward: 5.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
agent-1: 8.0
Sum Reward: 8.0
Avg Reward: 8.0
Min Reward: 8.0
Max Reward: 8.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_14-55-33
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 22.0
  episode_reward_mean: 1.76
  episode_reward_min: 0.0
  episodes_this_iter: 2
  episodes_total: 518
  experiment_id: cb3a18e0a26e466496590bc0542b68c4
  hostname: gpu020
  info:
    apply_time_ms: 3.135
    dispatch_time_ms: 6.966
    learner:
      cur_lr: 0.0013255678350105882
      grad_gnorm: 0.6399980783462524
      policy_entropy: 0.40271371603012085
      policy_loss: -0.0015051155351102352
      var_gnorm: 30.233686447143555
      vf_explained_var: 0.0
      vf_loss: 0.0028108274564146996
    num_steps_sampled: 519000
    num_steps_trained: 519000
    wait_time_ms: 33.228
  iterations_since_restore: 348
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 10879
  policy_reward_mean: {}
  time_since_restore: 2631.879602909088
  time_this_iter_s: 8.551970958709717
  time_total_s: 2631.879602909088
  timestamp: 1594148133
  timesteps_since_restore: 519000
  timesteps_this_iter: 2000
  timesteps_total: 519000
  training_iteration: 348
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10879], 2631 s, 348 iter, 519000 ts, 1.76 rew

agent-1: 20.0
Sum Reward: 20.0
Avg Reward: 20.0
Min Reward: 20.0
Max Reward: 20.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
agent-1: 0.0
Sum Reward: 0.0
Avg Reward: 0.0
Min Reward: 0.0
Max Reward: 0.0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_14-55-42
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 22.0
  episode_reward_mean: 1.96
  episode_reward_min: 0.0
  episodes_this_iter: 2
  episodes_total: 520
  experiment_id: cb3a18e0a26e466496590bc0542b68c4
  hostname: gpu020
  info:
    apply_time_ms: 2.783
    dispatch_time_ms: 8.437
    learner:
      cur_lr: 0.0013254346558824182
      grad_gnorm: 0.4743838906288147
      policy_entropy: 0.3100608289241791
      policy_loss: -0.0008161688456311822
      var_gnorm: 30.234386444091797
      vf_explained_var: 0.0
      vf_loss: 0.0015446166507899761
    num_steps_sampled: 521000
    num_steps_trained: 521000
    wait_time_ms: 34.001
  iterations_since_restore: 349
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 10879
  policy_reward_mean: {}
  time_since_restore: 2640.4687299728394
  time_this_iter_s: 8.58912706375122
  time_total_s: 2640.4687299728394
  timestamp: 1594148142
  timesteps_since_restore: 521000
  timesteps_this_iter: 2000
  timesteps_total: 521000
  training_iteration: 349
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10879], 2640 s, 349 iter, 521000 ts, 1.96 rew

agent-1: 5.0
Sum Reward: 5.0
Avg Reward: 5.0
Min Reward: 5.0
Max Reward: 5.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
agent-1: 4.0
Sum Reward: 4.0
Avg Reward: 4.0
Min Reward: 4.0
Max Reward: 4.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_14-55-51
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 22.0
  episode_reward_mean: 2.05
  episode_reward_min: 0.0
  episodes_this_iter: 2
  episodes_total: 522
  experiment_id: cb3a18e0a26e466496590bc0542b68c4
  hostname: gpu020
  info:
    apply_time_ms: 3.114
    dispatch_time_ms: 7.456
    learner:
      cur_lr: 0.0013253013603389263
      grad_gnorm: 0.1493525207042694
      policy_entropy: 0.29518166184425354
      policy_loss: -0.052980296313762665
      var_gnorm: 30.234344482421875
      vf_explained_var: 0.0
      vf_loss: 0.00010910873970715329
    num_steps_sampled: 523000
    num_steps_trained: 523000
    wait_time_ms: 32.737
  iterations_since_restore: 350
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 10879
  policy_reward_mean: {}
  time_since_restore: 2649.0404057502747
  time_this_iter_s: 8.571675777435303
  time_total_s: 2649.0404057502747
  timestamp: 1594148151
  timesteps_since_restore: 523000
  timesteps_this_iter: 2000
  timesteps_total: 523000
  training_iteration: 350
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10879], 2649 s, 350 iter, 523000 ts, 2.05 rew

agent-1: 3.0
Sum Reward: 3.0
Avg Reward: 3.0
Min Reward: 3.0
Max Reward: 3.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
agent-1: 0.0
Sum Reward: 0.0
Avg Reward: 0.0
Min Reward: 0.0
Max Reward: 0.0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_14-56-00
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 22.0
  episode_reward_mean: 2.08
  episode_reward_min: 0.0
  episodes_this_iter: 2
  episodes_total: 524
  experiment_id: cb3a18e0a26e466496590bc0542b68c4
  hostname: gpu020
  info:
    apply_time_ms: 2.904
    dispatch_time_ms: 6.17
    learner:
      cur_lr: 0.0013251681812107563
      grad_gnorm: 0.001528583001345396
      policy_entropy: 0.3006633520126343
      policy_loss: -7.463111160177505e-06
      var_gnorm: 30.234249114990234
      vf_explained_var: 0.0
      vf_loss: 3.3720134240411426e-08
    num_steps_sampled: 525000
    num_steps_trained: 525000
    wait_time_ms: 96.371
  iterations_since_restore: 351
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 10879
  policy_reward_mean: {}
  time_since_restore: 2658.2440071105957
  time_this_iter_s: 9.203601360321045
  time_total_s: 2658.2440071105957
  timestamp: 1594148160
  timesteps_since_restore: 525000
  timesteps_this_iter: 2000
  timesteps_total: 525000
  training_iteration: 351
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10879], 2658 s, 351 iter, 525000 ts, 2.08 rew

agent-1: 0.0
Sum Reward: 0.0
Avg Reward: 0.0
Min Reward: 0.0
Max Reward: 0.0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
agent-1: 0.0
Sum Reward: 0.0
Avg Reward: 0.0
Min Reward: 0.0
Max Reward: 0.0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_14-56-08
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 22.0
  episode_reward_mean: 2.08
  episode_reward_min: 0.0
  episodes_this_iter: 2
  episodes_total: 526
  experiment_id: cb3a18e0a26e466496590bc0542b68c4
  hostname: gpu020
  info:
    apply_time_ms: 2.817
    dispatch_time_ms: 8.653
    learner:
      cur_lr: 0.0013250350020825863
      grad_gnorm: 0.37941160798072815
      policy_entropy: 0.27294906973838806
      policy_loss: -0.0005708582466468215
      var_gnorm: 30.23438835144043
      vf_explained_var: 0.0
      vf_loss: 0.0009880842408165336
    num_steps_sampled: 527000
    num_steps_trained: 527000
    wait_time_ms: 29.751
  iterations_since_restore: 352
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 10879
  policy_reward_mean: {}
  time_since_restore: 2666.5980200767517
  time_this_iter_s: 8.354012966156006
  time_total_s: 2666.5980200767517
  timestamp: 1594148168
  timesteps_since_restore: 527000
  timesteps_this_iter: 2000
  timesteps_total: 527000
  training_iteration: 352
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10879], 2666 s, 352 iter, 527000 ts, 2.08 rew

agent-1: 0.0
Sum Reward: 0.0
Avg Reward: 0.0
Min Reward: 0.0
Max Reward: 0.0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
agent-1: 13.0
Sum Reward: 13.0
Avg Reward: 13.0
Min Reward: 13.0
Max Reward: 13.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_14-56-17
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 22.0
  episode_reward_mean: 2.21
  episode_reward_min: 0.0
  episodes_this_iter: 2
  episodes_total: 528
  experiment_id: cb3a18e0a26e466496590bc0542b68c4
  hostname: gpu020
  info:
    apply_time_ms: 2.632
    dispatch_time_ms: 7.435
    learner:
      cur_lr: 0.0013249018229544163
      grad_gnorm: 0.19468209147453308
      policy_entropy: 0.24691706895828247
      policy_loss: -0.0002616530400700867
      var_gnorm: 30.234649658203125
      vf_explained_var: 0.0
      vf_loss: 0.000260145083302632
    num_steps_sampled: 529000
    num_steps_trained: 529000
    wait_time_ms: 35.018
  iterations_since_restore: 353
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 10879
  policy_reward_mean: {}
  time_since_restore: 2675.1941990852356
  time_this_iter_s: 8.596179008483887
  time_total_s: 2675.1941990852356
  timestamp: 1594148177
  timesteps_since_restore: 529000
  timesteps_this_iter: 2000
  timesteps_total: 529000
  training_iteration: 353
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10879], 2675 s, 353 iter, 529000 ts, 2.21 rew

agent-1: 0.0
Sum Reward: 0.0
Avg Reward: 0.0
Min Reward: 0.0
Max Reward: 0.0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
agent-1: 4.0
Sum Reward: 4.0
Avg Reward: 4.0
Min Reward: 4.0
Max Reward: 4.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_14-56-25
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 22.0
  episode_reward_mean: 2.25
  episode_reward_min: 0.0
  episodes_this_iter: 2
  episodes_total: 530
  experiment_id: cb3a18e0a26e466496590bc0542b68c4
  hostname: gpu020
  info:
    apply_time_ms: 3.157
    dispatch_time_ms: 7.461
    learner:
      cur_lr: 0.0013247686438262463
      grad_gnorm: 0.0012518838047981262
      policy_entropy: 0.2524171471595764
      policy_loss: -2.550848705595854e-07
      var_gnorm: 30.234539031982422
      vf_explained_var: 0.0
      vf_loss: 2.5659840918734744e-10
    num_steps_sampled: 531000
    num_steps_trained: 531000
    wait_time_ms: 34.206
  iterations_since_restore: 354
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 10879
  policy_reward_mean: {}
  time_since_restore: 2683.75026845932
  time_this_iter_s: 8.556069374084473
  time_total_s: 2683.75026845932
  timestamp: 1594148185
  timesteps_since_restore: 531000
  timesteps_this_iter: 2000
  timesteps_total: 531000
  training_iteration: 354
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10879], 2683 s, 354 iter, 531000 ts, 2.25 rew

agent-1: 0.0
Sum Reward: 0.0
Avg Reward: 0.0
Min Reward: 0.0
Max Reward: 0.0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
agent-1: 0.0
Sum Reward: 0.0
Avg Reward: 0.0
Min Reward: 0.0
Max Reward: 0.0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_14-56-34
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 22.0
  episode_reward_mean: 2.25
  episode_reward_min: 0.0
  episodes_this_iter: 2
  episodes_total: 532
  experiment_id: cb3a18e0a26e466496590bc0542b68c4
  hostname: gpu020
  info:
    apply_time_ms: 3.598
    dispatch_time_ms: 6.674
    learner:
      cur_lr: 0.0013246353482827544
      grad_gnorm: 0.003321288153529167
      policy_entropy: 0.2621975243091583
      policy_loss: -4.581898792821448e-06
      var_gnorm: 30.234359741210938
      vf_explained_var: 0.0
      vf_loss: 6.377051420258795e-08
    num_steps_sampled: 533000
    num_steps_trained: 533000
    wait_time_ms: 34.516
  iterations_since_restore: 355
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 10879
  policy_reward_mean: {}
  time_since_restore: 2692.293780565262
  time_this_iter_s: 8.543512105941772
  time_total_s: 2692.293780565262
  timestamp: 1594148194
  timesteps_since_restore: 533000
  timesteps_this_iter: 2000
  timesteps_total: 533000
  training_iteration: 355
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10879], 2692 s, 355 iter, 533000 ts, 2.25 rew

agent-1: 0.0
Sum Reward: 0.0
Avg Reward: 0.0
Min Reward: 0.0
Max Reward: 0.0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
agent-1: 0.0
Sum Reward: 0.0
Avg Reward: 0.0
Min Reward: 0.0
Max Reward: 0.0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_14-56-43
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 22.0
  episode_reward_mean: 2.25
  episode_reward_min: 0.0
  episodes_this_iter: 2
  episodes_total: 534
  experiment_id: cb3a18e0a26e466496590bc0542b68c4
  hostname: gpu020
  info:
    apply_time_ms: 3.197
    dispatch_time_ms: 6.972
    learner:
      cur_lr: 0.0013245021691545844
      grad_gnorm: 0.1851484775543213
      policy_entropy: 0.23521855473518372
      policy_loss: -0.00030387830338440835
      var_gnorm: 30.234560012817383
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 0.00023527334269601852
    num_steps_sampled: 535000
    num_steps_trained: 535000
    wait_time_ms: 32.689
  iterations_since_restore: 356
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 10879
  policy_reward_mean: {}
  time_since_restore: 2700.820895433426
  time_this_iter_s: 8.527114868164062
  time_total_s: 2700.820895433426
  timestamp: 1594148203
  timesteps_since_restore: 535000
  timesteps_this_iter: 2000
  timesteps_total: 535000
  training_iteration: 356
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10879], 2700 s, 356 iter, 535000 ts, 2.25 rew

agent-1: 0.0
Sum Reward: 0.0
Avg Reward: 0.0
Min Reward: 0.0
Max Reward: 0.0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
agent-1: 7.0
Sum Reward: 7.0
Avg Reward: 7.0
Min Reward: 7.0
Max Reward: 7.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_14-56-51
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 22.0
  episode_reward_mean: 2.32
  episode_reward_min: 0.0
  episodes_this_iter: 2
  episodes_total: 536
  experiment_id: cb3a18e0a26e466496590bc0542b68c4
  hostname: gpu020
  info:
    apply_time_ms: 2.683
    dispatch_time_ms: 7.72
    learner:
      cur_lr: 0.0013243689900264144
      grad_gnorm: 0.0024050914216786623
      policy_entropy: 0.24526837468147278
      policy_loss: -2.927138666564133e-06
      var_gnorm: 30.234411239624023
      vf_explained_var: 0.0
      vf_loss: 2.940076093693733e-08
    num_steps_sampled: 537000
    num_steps_trained: 537000
    wait_time_ms: 32.555
  iterations_since_restore: 357
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 10879
  policy_reward_mean: {}
  time_since_restore: 2709.406981229782
  time_this_iter_s: 8.586085796356201
  time_total_s: 2709.406981229782
  timestamp: 1594148211
  timesteps_since_restore: 537000
  timesteps_this_iter: 2000
  timesteps_total: 537000
  training_iteration: 357
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10879], 2709 s, 357 iter, 537000 ts, 2.32 rew

agent-1: 0.0
Sum Reward: 0.0
Avg Reward: 0.0
Min Reward: 0.0
Max Reward: 0.0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
agent-1: 0.0
Sum Reward: 0.0
Avg Reward: 0.0
Min Reward: 0.0
Max Reward: 0.0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_14-57-00
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 22.0
  episode_reward_mean: 2.32
  episode_reward_min: 0.0
  episodes_this_iter: 2
  episodes_total: 538
  experiment_id: cb3a18e0a26e466496590bc0542b68c4
  hostname: gpu020
  info:
    apply_time_ms: 2.771
    dispatch_time_ms: 7.157
    learner:
      cur_lr: 0.0013242358108982444
      grad_gnorm: 0.0012925810879096389
      policy_entropy: 0.2594414949417114
      policy_loss: -4.2425864421602455e-07
      var_gnorm: 30.234167098999023
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 3.864373543382982e-10
    num_steps_sampled: 539000
    num_steps_trained: 539000
    wait_time_ms: 33.209
  iterations_since_restore: 358
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 10879
  policy_reward_mean: {}
  time_since_restore: 2717.961189508438
  time_this_iter_s: 8.554208278656006
  time_total_s: 2717.961189508438
  timestamp: 1594148220
  timesteps_since_restore: 539000
  timesteps_this_iter: 2000
  timesteps_total: 539000
  training_iteration: 358
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10879], 2717 s, 358 iter, 539000 ts, 2.32 rew

agent-1: 0.0
Sum Reward: 0.0
Avg Reward: 0.0
Min Reward: 0.0
Max Reward: 0.0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
agent-1: 0.0
Sum Reward: 0.0
Avg Reward: 0.0
Min Reward: 0.0
Max Reward: 0.0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_14-57-08
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 22.0
  episode_reward_mean: 2.32
  episode_reward_min: 0.0
  episodes_this_iter: 2
  episodes_total: 540
  experiment_id: cb3a18e0a26e466496590bc0542b68c4
  hostname: gpu020
  info:
    apply_time_ms: 2.746
    dispatch_time_ms: 8.248
    learner:
      cur_lr: 0.0013241026317700744
      grad_gnorm: 0.0014651176752522588
      policy_entropy: 0.26809120178222656
      policy_loss: -1.226417111865885e-06
      var_gnorm: 30.2340030670166
      vf_explained_var: 0.0
      vf_loss: 2.8254725226162236e-09
    num_steps_sampled: 541000
    num_steps_trained: 541000
    wait_time_ms: 32.253
  iterations_since_restore: 359
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 10879
  policy_reward_mean: {}
  time_since_restore: 2726.5076627731323
  time_this_iter_s: 8.546473264694214
  time_total_s: 2726.5076627731323
  timestamp: 1594148228
  timesteps_since_restore: 541000
  timesteps_this_iter: 2000
  timesteps_total: 541000
  training_iteration: 359
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10879], 2726 s, 359 iter, 541000 ts, 2.32 rew

agent-1: 0.0
Sum Reward: 0.0
Avg Reward: 0.0
Min Reward: 0.0
Max Reward: 0.0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
agent-1: 0.0
Sum Reward: 0.0
Avg Reward: 0.0
Min Reward: 0.0
Max Reward: 0.0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_14-57-17
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 22.0
  episode_reward_mean: 2.32
  episode_reward_min: 0.0
  episodes_this_iter: 2
  episodes_total: 542
  experiment_id: cb3a18e0a26e466496590bc0542b68c4
  hostname: gpu020
  info:
    apply_time_ms: 2.736
    dispatch_time_ms: 8.134
    learner:
      cur_lr: 0.0013239694526419044
      grad_gnorm: 0.15389001369476318
      policy_entropy: 0.27320703864097595
      policy_loss: -0.0002567345218267292
      var_gnorm: 30.233783721923828
      vf_explained_var: 0.0
      vf_loss: 0.00016252226487267762
    num_steps_sampled: 543000
    num_steps_trained: 543000
    wait_time_ms: 33.979
  iterations_since_restore: 360
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 10879
  policy_reward_mean: {}
  time_since_restore: 2735.0771758556366
  time_this_iter_s: 8.569513082504272
  time_total_s: 2735.0771758556366
  timestamp: 1594148237
  timesteps_since_restore: 543000
  timesteps_this_iter: 2000
  timesteps_total: 543000
  training_iteration: 360
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10879], 2735 s, 360 iter, 543000 ts, 2.32 rew

agent-1: 0.0
Sum Reward: 0.0
Avg Reward: 0.0
Min Reward: 0.0
Max Reward: 0.0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
agent-1: 8.0
Sum Reward: 8.0
Avg Reward: 8.0
Min Reward: 8.0
Max Reward: 8.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_14-57-25
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 22.0
  episode_reward_mean: 2.4
  episode_reward_min: 0.0
  episodes_this_iter: 2
  episodes_total: 544
  experiment_id: cb3a18e0a26e466496590bc0542b68c4
  hostname: gpu020
  info:
    apply_time_ms: 4.224
    dispatch_time_ms: 6.464
    learner:
      cur_lr: 0.0013238361570984125
      grad_gnorm: 0.22984561324119568
      policy_entropy: 0.11533507704734802
      policy_loss: -0.00015960355813149363
      var_gnorm: 30.236160278320312
      vf_explained_var: 0.0
      vf_loss: 0.0003627016267273575
    num_steps_sampled: 545000
    num_steps_trained: 545000
    wait_time_ms: 31.328
  iterations_since_restore: 361
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 10879
  policy_reward_mean: {}
  time_since_restore: 2743.6199412345886
  time_this_iter_s: 8.542765378952026
  time_total_s: 2743.6199412345886
  timestamp: 1594148245
  timesteps_since_restore: 545000
  timesteps_this_iter: 2000
  timesteps_total: 545000
  training_iteration: 361
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10879], 2743 s, 361 iter, 545000 ts, 2.4 rew

agent-1: 20.0
Sum Reward: 20.0
Avg Reward: 20.0
Min Reward: 20.0
Max Reward: 20.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
agent-1: 0.0
Sum Reward: 0.0
Avg Reward: 0.0
Min Reward: 0.0
Max Reward: 0.0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_14-57-34
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 22.0
  episode_reward_mean: 2.6
  episode_reward_min: 0.0
  episodes_this_iter: 2
  episodes_total: 546
  experiment_id: cb3a18e0a26e466496590bc0542b68c4
  hostname: gpu020
  info:
    apply_time_ms: 2.586
    dispatch_time_ms: 6.079
    learner:
      cur_lr: 0.0013237029779702425
      grad_gnorm: 0.00861393567174673
      policy_entropy: 0.12060581147670746
      policy_loss: -5.630932264466537e-06
      var_gnorm: 30.23599624633789
      vf_explained_var: 0.0
      vf_loss: 5.067639108347066e-07
    num_steps_sampled: 547000
    num_steps_trained: 547000
    wait_time_ms: 34.503
  iterations_since_restore: 362
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 10879
  policy_reward_mean: {}
  time_since_restore: 2752.1423859596252
  time_this_iter_s: 8.522444725036621
  time_total_s: 2752.1423859596252
  timestamp: 1594148254
  timesteps_since_restore: 547000
  timesteps_this_iter: 2000
  timesteps_total: 547000
  training_iteration: 362
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10879], 2752 s, 362 iter, 547000 ts, 2.6 rew

agent-1: 1.0
Sum Reward: 1.0
Avg Reward: 1.0
Min Reward: 1.0
Max Reward: 1.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
agent-1: 0.0
Sum Reward: 0.0
Avg Reward: 0.0
Min Reward: 0.0
Max Reward: 0.0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_14-57-43
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 22.0
  episode_reward_mean: 2.61
  episode_reward_min: 0.0
  episodes_this_iter: 2
  episodes_total: 548
  experiment_id: cb3a18e0a26e466496590bc0542b68c4
  hostname: gpu020
  info:
    apply_time_ms: 2.377
    dispatch_time_ms: 7.331
    learner:
      cur_lr: 0.0013235697988420725
      grad_gnorm: 0.11424630880355835
      policy_entropy: 0.16308946907520294
      policy_loss: -9.859120473265648e-05
      var_gnorm: 30.23497200012207
      vf_explained_var: 0.0
      vf_loss: 8.960059494711459e-05
    num_steps_sampled: 549000
    num_steps_trained: 549000
    wait_time_ms: 32.987
  iterations_since_restore: 363
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 10879
  policy_reward_mean: {}
  time_since_restore: 2760.7064888477325
  time_this_iter_s: 8.5641028881073
  time_total_s: 2760.7064888477325
  timestamp: 1594148263
  timesteps_since_restore: 549000
  timesteps_this_iter: 2000
  timesteps_total: 549000
  training_iteration: 363
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10879], 2760 s, 363 iter, 549000 ts, 2.61 rew

agent-1: 0.0
Sum Reward: 0.0
Avg Reward: 0.0
Min Reward: 0.0
Max Reward: 0.0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
agent-1: 3.0
Sum Reward: 3.0
Avg Reward: 3.0
Min Reward: 3.0
Max Reward: 3.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_14-57-51
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 22.0
  episode_reward_mean: 2.64
  episode_reward_min: 0.0
  episodes_this_iter: 2
  episodes_total: 550
  experiment_id: cb3a18e0a26e466496590bc0542b68c4
  hostname: gpu020
  info:
    apply_time_ms: 3.76
    dispatch_time_ms: 8.708
    learner:
      cur_lr: 0.0013234366197139025
      grad_gnorm: 0.07852156460285187
      policy_entropy: 0.1568727344274521
      policy_loss: -6.808270700275898e-05
      var_gnorm: 30.235008239746094
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 4.23208148276899e-05
    num_steps_sampled: 551000
    num_steps_trained: 551000
    wait_time_ms: 30.637
  iterations_since_restore: 364
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 10879
  policy_reward_mean: {}
  time_since_restore: 2769.307891368866
  time_this_iter_s: 8.601402521133423
  time_total_s: 2769.307891368866
  timestamp: 1594148271
  timesteps_since_restore: 551000
  timesteps_this_iter: 2000
  timesteps_total: 551000
  training_iteration: 364
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10879], 2769 s, 364 iter, 551000 ts, 2.64 rew

agent-1: 12.0
Sum Reward: 12.0
Avg Reward: 12.0
Min Reward: 12.0
Max Reward: 12.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
agent-1: 0.0
Sum Reward: 0.0
Avg Reward: 0.0
Min Reward: 0.0
Max Reward: 0.0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_14-58-00
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 22.0
  episode_reward_mean: 2.76
  episode_reward_min: 0.0
  episodes_this_iter: 2
  episodes_total: 552
  experiment_id: cb3a18e0a26e466496590bc0542b68c4
  hostname: gpu020
  info:
    apply_time_ms: 4.212
    dispatch_time_ms: 8.474
    learner:
      cur_lr: 0.0013233034405857325
      grad_gnorm: 1.5934879779815674
      policy_entropy: 0.09008925408124924
      policy_loss: -0.0006411704234778881
      var_gnorm: 30.236661911010742
      vf_explained_var: 5.960464477539063e-08
      vf_loss: 0.017434000968933105
    num_steps_sampled: 553000
    num_steps_trained: 553000
    wait_time_ms: 27.348
  iterations_since_restore: 365
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 10879
  policy_reward_mean: {}
  time_since_restore: 2777.9367554187775
  time_this_iter_s: 8.628864049911499
  time_total_s: 2777.9367554187775
  timestamp: 1594148280
  timesteps_since_restore: 553000
  timesteps_this_iter: 2000
  timesteps_total: 553000
  training_iteration: 365
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10879], 2777 s, 365 iter, 553000 ts, 2.76 rew

agent-1: 22.0
Sum Reward: 22.0
Avg Reward: 22.0
Min Reward: 22.0
Max Reward: 22.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
agent-1: 20.0
Sum Reward: 20.0
Avg Reward: 20.0
Min Reward: 20.0
Max Reward: 20.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_14-58-09
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 22.0
  episode_reward_mean: 3.18
  episode_reward_min: 0.0
  episodes_this_iter: 2
  episodes_total: 554
  experiment_id: cb3a18e0a26e466496590bc0542b68c4
  hostname: gpu020
  info:
    apply_time_ms: 2.642
    dispatch_time_ms: 6.63
    learner:
      cur_lr: 0.0013231701450422406
      grad_gnorm: 0.5445765852928162
      policy_entropy: 0.046319421380758286
      policy_loss: -9.460560977458954e-05
      var_gnorm: 30.238855361938477
      vf_explained_var: 0.0
      vf_loss: 0.002036202000454068
    num_steps_sampled: 555000
    num_steps_trained: 555000
    wait_time_ms: 34.669
  iterations_since_restore: 366
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 10879
  policy_reward_mean: {}
  time_since_restore: 2786.5456070899963
  time_this_iter_s: 8.608851671218872
  time_total_s: 2786.5456070899963
  timestamp: 1594148289
  timesteps_since_restore: 555000
  timesteps_this_iter: 2000
  timesteps_total: 555000
  training_iteration: 366
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10879], 2786 s, 366 iter, 555000 ts, 3.18 rew

agent-1: 5.0
Sum Reward: 5.0
Avg Reward: 5.0
Min Reward: 5.0
Max Reward: 5.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
agent-1: 7.0
Sum Reward: 7.0
Avg Reward: 7.0
Min Reward: 7.0
Max Reward: 7.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_14-58-17
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 22.0
  episode_reward_mean: 3.3
  episode_reward_min: 0.0
  episodes_this_iter: 2
  episodes_total: 556
  experiment_id: cb3a18e0a26e466496590bc0542b68c4
  hostname: gpu020
  info:
    apply_time_ms: 4.042
    dispatch_time_ms: 9.823
    learner:
      cur_lr: 0.0013230369659140706
      grad_gnorm: 0.18817462027072906
      policy_entropy: 0.047958195209503174
      policy_loss: -4.5623190089827403e-05
      var_gnorm: 30.23872947692871
      vf_explained_var: 0.0
      vf_loss: 0.00024312835012096912
    num_steps_sampled: 557000
    num_steps_trained: 557000
    wait_time_ms: 28.047
  iterations_since_restore: 367
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 10879
  policy_reward_mean: {}
  time_since_restore: 2795.0805542469025
  time_this_iter_s: 8.534947156906128
  time_total_s: 2795.0805542469025
  timestamp: 1594148297
  timesteps_since_restore: 557000
  timesteps_this_iter: 2000
  timesteps_total: 557000
  training_iteration: 367
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10879], 2795 s, 367 iter, 557000 ts, 3.3 rew

agent-1: 0.0
Sum Reward: 0.0
Avg Reward: 0.0
Min Reward: 0.0
Max Reward: 0.0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
agent-1: 2.0
Sum Reward: 2.0
Avg Reward: 2.0
Min Reward: 2.0
Max Reward: 2.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_14-58-26
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 22.0
  episode_reward_mean: 3.32
  episode_reward_min: 0.0
  episodes_this_iter: 2
  episodes_total: 558
  experiment_id: cb3a18e0a26e466496590bc0542b68c4
  hostname: gpu020
  info:
    apply_time_ms: 2.849
    dispatch_time_ms: 6.732
    learner:
      cur_lr: 0.0013229037867859006
      grad_gnorm: 0.026519909501075745
      policy_entropy: 0.048561472445726395
      policy_loss: -6.338616913126316e-06
      var_gnorm: 30.23867416381836
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 4.82966879644664e-06
    num_steps_sampled: 559000
    num_steps_trained: 559000
    wait_time_ms: 34.146
  iterations_since_restore: 368
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 10879
  policy_reward_mean: {}
  time_since_restore: 2803.6598420143127
  time_this_iter_s: 8.579287767410278
  time_total_s: 2803.6598420143127
  timestamp: 1594148306
  timesteps_since_restore: 559000
  timesteps_this_iter: 2000
  timesteps_total: 559000
  training_iteration: 368
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10879], 2803 s, 368 iter, 559000 ts, 3.32 rew

agent-1: 1.0
Sum Reward: 1.0
Avg Reward: 1.0
Min Reward: 1.0
Max Reward: 1.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_14-58-34
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 22.0
  episode_reward_mean: 3.33
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 559
  experiment_id: cb3a18e0a26e466496590bc0542b68c4
  hostname: gpu020
  info:
    apply_time_ms: 3.085
    dispatch_time_ms: 6.9
    learner:
      cur_lr: 0.0013227706076577306
      grad_gnorm: 0.013988976366817951
      policy_entropy: 0.04937078058719635
      policy_loss: -2.2891672415426e-06
      var_gnorm: 30.238597869873047
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 1.3419827382676885e-06
    num_steps_sampled: 560000
    num_steps_trained: 560000
    wait_time_ms: 33.135
  iterations_since_restore: 369
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 10879
  policy_reward_mean: {}
  time_since_restore: 2811.9553322792053
  time_this_iter_s: 8.295490264892578
  time_total_s: 2811.9553322792053
  timestamp: 1594148314
  timesteps_since_restore: 560000
  timesteps_this_iter: 1000
  timesteps_total: 560000
  training_iteration: 369
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10879], 2811 s, 369 iter, 560000 ts, 3.33 rew

agent-1: 0.0
Sum Reward: 0.0
Avg Reward: 0.0
Min Reward: 0.0
Max Reward: 0.0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
agent-1: 0.0
Sum Reward: 0.0
Avg Reward: 0.0
Min Reward: 0.0
Max Reward: 0.0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_14-58-43
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 22.0
  episode_reward_mean: 3.33
  episode_reward_min: 0.0
  episodes_this_iter: 2
  episodes_total: 561
  experiment_id: cb3a18e0a26e466496590bc0542b68c4
  hostname: gpu020
  info:
    apply_time_ms: 2.687
    dispatch_time_ms: 8.909
    learner:
      cur_lr: 0.0013227040180936456
      grad_gnorm: 0.04661891981959343
      policy_entropy: 0.03349936753511429
      policy_loss: -6.679248599539278e-06
      var_gnorm: 30.239988327026367
      vf_explained_var: 1.1920928955078125e-07
      vf_loss: 1.492268347647041e-05
    num_steps_sampled: 562000
    num_steps_trained: 562000
    wait_time_ms: 33.777
  iterations_since_restore: 370
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 10879
  policy_reward_mean: {}
  time_since_restore: 2820.5411434173584
  time_this_iter_s: 8.585811138153076
  time_total_s: 2820.5411434173584
  timestamp: 1594148323
  timesteps_since_restore: 562000
  timesteps_this_iter: 2000
  timesteps_total: 562000
  training_iteration: 370
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10879], 2820 s, 370 iter, 562000 ts, 3.33 rew

agent-1: 20.0
Sum Reward: 20.0
Avg Reward: 20.0
Min Reward: 20.0
Max Reward: 20.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
agent-1: 0.0
Sum Reward: 0.0
Avg Reward: 0.0
Min Reward: 0.0
Max Reward: 0.0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_14-58-51
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 22.0
  episode_reward_mean: 3.53
  episode_reward_min: 0.0
  episodes_this_iter: 2
  episodes_total: 563
  experiment_id: cb3a18e0a26e466496590bc0542b68c4
  hostname: gpu020
  info:
    apply_time_ms: 2.7
    dispatch_time_ms: 6.612
    learner:
      cur_lr: 0.0013225708389654756
      grad_gnorm: 1.2719054222106934
      policy_entropy: 0.029683638364076614
      policy_loss: -0.00012804166181012988
      var_gnorm: 30.24032974243164
      vf_explained_var: 0.0
      vf_loss: 0.011107419617474079
    num_steps_sampled: 564000
    num_steps_trained: 564000
    wait_time_ms: 36.355
  iterations_since_restore: 371
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 10879
  policy_reward_mean: {}
  time_since_restore: 2829.126487970352
  time_this_iter_s: 8.585344552993774
  time_total_s: 2829.126487970352
  timestamp: 1594148331
  timesteps_since_restore: 564000
  timesteps_this_iter: 2000
  timesteps_total: 564000
  training_iteration: 371
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10879], 2829 s, 371 iter, 564000 ts, 3.53 rew

agent-1: 1.0
Sum Reward: 1.0
Avg Reward: 1.0
Min Reward: 1.0
Max Reward: 1.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
agent-1: 7.0
Sum Reward: 7.0
Avg Reward: 7.0
Min Reward: 7.0
Max Reward: 7.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_14-59-00
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 22.0
  episode_reward_mean: 3.61
  episode_reward_min: 0.0
  episodes_this_iter: 2
  episodes_total: 565
  experiment_id: cb3a18e0a26e466496590bc0542b68c4
  hostname: gpu020
  info:
    apply_time_ms: 3.008
    dispatch_time_ms: 7.626
    learner:
      cur_lr: 0.0013224375434219837
      grad_gnorm: 1.6580836772918701
      policy_entropy: 0.02922871895134449
      policy_loss: -0.00015220553905237466
      var_gnorm: 30.24039077758789
      vf_explained_var: 0.0
      vf_loss: 0.01887630484998226
    num_steps_sampled: 566000
    num_steps_trained: 566000
    wait_time_ms: 32.409
  iterations_since_restore: 372
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 10879
  policy_reward_mean: {}
  time_since_restore: 2837.666184425354
  time_this_iter_s: 8.539696455001831
  time_total_s: 2837.666184425354
  timestamp: 1594148340
  timesteps_since_restore: 566000
  timesteps_this_iter: 2000
  timesteps_total: 566000
  training_iteration: 372
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10879], 2837 s, 372 iter, 566000 ts, 3.61 rew

agent-1: 8.0
Sum Reward: 8.0
Avg Reward: 8.0
Min Reward: 8.0
Max Reward: 8.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
agent-1: 13.0
Sum Reward: 13.0
Avg Reward: 13.0
Min Reward: 13.0
Max Reward: 13.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_14-59-09
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 22.0
  episode_reward_mean: 3.82
  episode_reward_min: 0.0
  episodes_this_iter: 2
  episodes_total: 567
  experiment_id: cb3a18e0a26e466496590bc0542b68c4
  hostname: gpu020
  info:
    apply_time_ms: 3.199
    dispatch_time_ms: 7.53
    learner:
      cur_lr: 0.0013223043642938137
      grad_gnorm: 1.1209800243377686
      policy_entropy: 0.029868990182876587
      policy_loss: -0.00011335146700730547
      var_gnorm: 30.240102767944336
      vf_explained_var: 0.0
      vf_loss: 0.008627805858850479
    num_steps_sampled: 568000
    num_steps_trained: 568000
    wait_time_ms: 32.334
  iterations_since_restore: 373
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 10879
  policy_reward_mean: {}
  time_since_restore: 2846.323801755905
  time_this_iter_s: 8.657617330551147
  time_total_s: 2846.323801755905
  timestamp: 1594148349
  timesteps_since_restore: 568000
  timesteps_this_iter: 2000
  timesteps_total: 568000
  training_iteration: 373
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10879], 2846 s, 373 iter, 568000 ts, 3.82 rew

agent-1: 5.0
Sum Reward: 5.0
Avg Reward: 5.0
Min Reward: 5.0
Max Reward: 5.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
agent-1: 7.0
Sum Reward: 7.0
Avg Reward: 7.0
Min Reward: 7.0
Max Reward: 7.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_14-59-17
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 22.0
  episode_reward_mean: 3.94
  episode_reward_min: 0.0
  episodes_this_iter: 2
  episodes_total: 569
  experiment_id: cb3a18e0a26e466496590bc0542b68c4
  hostname: gpu020
  info:
    apply_time_ms: 2.604
    dispatch_time_ms: 5.846
    learner:
      cur_lr: 0.0013221711851656437
      grad_gnorm: 2.3986270427703857
      policy_entropy: 0.02722148783504963
      policy_loss: -0.00020405769464559853
      var_gnorm: 30.24081802368164
      vf_explained_var: 0.0
      vf_loss: 0.039503004401922226
    num_steps_sampled: 570000
    num_steps_trained: 570000
    wait_time_ms: 33.622
  iterations_since_restore: 374
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 10879
  policy_reward_mean: {}
  time_since_restore: 2854.9643597602844
  time_this_iter_s: 8.640558004379272
  time_total_s: 2854.9643597602844
  timestamp: 1594148357
  timesteps_since_restore: 570000
  timesteps_this_iter: 2000
  timesteps_total: 570000
  training_iteration: 374
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10879], 2854 s, 374 iter, 570000 ts, 3.94 rew

agent-1: 12.0
Sum Reward: 12.0
Avg Reward: 12.0
Min Reward: 12.0
Max Reward: 12.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
agent-1: 18.0
Sum Reward: 18.0
Avg Reward: 18.0
Min Reward: 18.0
Max Reward: 18.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_14-59-27
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 22.0
  episode_reward_mean: 4.24
  episode_reward_min: 0.0
  episodes_this_iter: 2
  episodes_total: 571
  experiment_id: cb3a18e0a26e466496590bc0542b68c4
  hostname: gpu020
  info:
    apply_time_ms: 2.735
    dispatch_time_ms: 33.365
    learner:
      cur_lr: 0.0013220380060374737
      grad_gnorm: 0.06474567949771881
      policy_entropy: 0.03267695754766464
      policy_loss: -1.1150518730573822e-05
      var_gnorm: 30.23971176147461
      vf_explained_var: 0.0
      vf_loss: 3.581323107937351e-05
    num_steps_sampled: 572000
    num_steps_trained: 572000
    wait_time_ms: 16.601
  iterations_since_restore: 375
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 10879
  policy_reward_mean: {}
  time_since_restore: 2864.50217795372
  time_this_iter_s: 9.537818193435669
  time_total_s: 2864.50217795372
  timestamp: 1594148367
  timesteps_since_restore: 572000
  timesteps_this_iter: 2000
  timesteps_total: 572000
  training_iteration: 375
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10879], 2864 s, 375 iter, 572000 ts, 4.24 rew

agent-1: 0.0
Sum Reward: 0.0
Avg Reward: 0.0
Min Reward: 0.0
Max Reward: 0.0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_14-59-33
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 22.0
  episode_reward_mean: 4.24
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 572
  experiment_id: cb3a18e0a26e466496590bc0542b68c4
  hostname: gpu020
  info:
    apply_time_ms: 2.716
    dispatch_time_ms: 32.313
    learner:
      cur_lr: 0.0013219048269093037
      grad_gnorm: 0.012252822518348694
      policy_entropy: 0.0334622748196125
      policy_loss: -7.479337909899186e-06
      var_gnorm: 30.23961639404297
      vf_explained_var: 0.0
      vf_loss: 6.3654260884504765e-06
    num_steps_sampled: 573000
    num_steps_trained: 573000
    wait_time_ms: 18.3
  iterations_since_restore: 376
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 10879
  policy_reward_mean: {}
  time_since_restore: 2870.6869220733643
  time_this_iter_s: 6.184744119644165
  time_total_s: 2870.6869220733643
  timestamp: 1594148373
  timesteps_since_restore: 573000
  timesteps_this_iter: 1000
  timesteps_total: 573000
  training_iteration: 376
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10879], 2870 s, 376 iter, 573000 ts, 4.24 rew

agent-1: 0.0
Sum Reward: 0.0
Avg Reward: 0.0
Min Reward: 0.0
Max Reward: 0.0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_14-59-39
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 22.0
  episode_reward_mean: 4.24
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 573
  experiment_id: cb3a18e0a26e466496590bc0542b68c4
  hostname: gpu020
  info:
    apply_time_ms: 2.61
    dispatch_time_ms: 21.808
    learner:
      cur_lr: 0.0013218382373452187
      grad_gnorm: 0.061684057116508484
      policy_entropy: 0.034102912992239
      policy_loss: -5.49198512089788e-06
      var_gnorm: 30.23954200744629
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 2.3567292373627424e-05
    num_steps_sampled: 574000
    num_steps_trained: 574000
    wait_time_ms: 19.829
  iterations_since_restore: 377
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 10879
  policy_reward_mean: {}
  time_since_restore: 2876.864158153534
  time_this_iter_s: 6.177236080169678
  time_total_s: 2876.864158153534
  timestamp: 1594148379
  timesteps_since_restore: 574000
  timesteps_this_iter: 1000
  timesteps_total: 574000
  training_iteration: 377
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10879], 2876 s, 377 iter, 574000 ts, 4.24 rew

agent-1: 0.0
Sum Reward: 0.0
Avg Reward: 0.0
Min Reward: 0.0
Max Reward: 0.0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
agent-1: 0.0
Sum Reward: 0.0
Avg Reward: 0.0
Min Reward: 0.0
Max Reward: 0.0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_14-59-48
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 22.0
  episode_reward_mean: 4.24
  episode_reward_min: 0.0
  episodes_this_iter: 2
  episodes_total: 575
  experiment_id: cb3a18e0a26e466496590bc0542b68c4
  hostname: gpu020
  info:
    apply_time_ms: 2.401
    dispatch_time_ms: 7.008
    learner:
      cur_lr: 0.0013217716477811337
      grad_gnorm: 0.27418842911720276
      policy_entropy: 0.03304380550980568
      policy_loss: -3.3352800528518856e-05
      var_gnorm: 30.239511489868164
      vf_explained_var: 0.0
      vf_loss: 0.0005161692388355732
    num_steps_sampled: 576000
    num_steps_trained: 576000
    wait_time_ms: 34.176
  iterations_since_restore: 378
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 10879
  policy_reward_mean: {}
  time_since_restore: 2885.6309695243835
  time_this_iter_s: 8.76681137084961
  time_total_s: 2885.6309695243835
  timestamp: 1594148388
  timesteps_since_restore: 576000
  timesteps_this_iter: 2000
  timesteps_total: 576000
  training_iteration: 378
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10879], 2885 s, 378 iter, 576000 ts, 4.24 rew

agent-1: 1.0
Sum Reward: 1.0
Avg Reward: 1.0
Min Reward: 1.0
Max Reward: 1.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
agent-1: 1.0
Sum Reward: 1.0
Avg Reward: 1.0
Min Reward: 1.0
Max Reward: 1.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_14-59-57
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 22.0
  episode_reward_mean: 4.26
  episode_reward_min: 0.0
  episodes_this_iter: 2
  episodes_total: 577
  experiment_id: cb3a18e0a26e466496590bc0542b68c4
  hostname: gpu020
  info:
    apply_time_ms: 2.494
    dispatch_time_ms: 7.264
    learner:
      cur_lr: 0.0013216383522376418
      grad_gnorm: 0.8136256337165833
      policy_entropy: 0.03227919712662697
      policy_loss: -9.784143912838772e-05
      var_gnorm: 30.239425659179688
      vf_explained_var: 0.0
      vf_loss: 0.004545216914266348
    num_steps_sampled: 578000
    num_steps_trained: 578000
    wait_time_ms: 31.635
  iterations_since_restore: 379
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 10879
  policy_reward_mean: {}
  time_since_restore: 2894.213467359543
  time_this_iter_s: 8.582497835159302
  time_total_s: 2894.213467359543
  timestamp: 1594148397
  timesteps_since_restore: 578000
  timesteps_this_iter: 2000
  timesteps_total: 578000
  training_iteration: 379
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10879], 2894 s, 379 iter, 578000 ts, 4.26 rew

agent-1: 0.0
Sum Reward: 0.0
Avg Reward: 0.0
Min Reward: 0.0
Max Reward: 0.0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
agent-1: 4.0
Sum Reward: 4.0
Avg Reward: 4.0
Min Reward: 4.0
Max Reward: 4.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_15-00-05
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 22.0
  episode_reward_mean: 4.3
  episode_reward_min: 0.0
  episodes_this_iter: 2
  episodes_total: 579
  experiment_id: cb3a18e0a26e466496590bc0542b68c4
  hostname: gpu020
  info:
    apply_time_ms: 2.691
    dispatch_time_ms: 8.75
    learner:
      cur_lr: 0.0013215051731094718
      grad_gnorm: 0.025735661387443542
      policy_entropy: 0.03529026359319687
      policy_loss: -3.896112957590958e-06
      var_gnorm: 30.239126205444336
      vf_explained_var: 0.0
      vf_loss: 4.546697709884029e-06
    num_steps_sampled: 580000
    num_steps_trained: 580000
    wait_time_ms: 32.71
  iterations_since_restore: 380
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 10879
  policy_reward_mean: {}
  time_since_restore: 2902.8549988269806
  time_this_iter_s: 8.641531467437744
  time_total_s: 2902.8549988269806
  timestamp: 1594148405
  timesteps_since_restore: 580000
  timesteps_this_iter: 2000
  timesteps_total: 580000
  training_iteration: 380
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10879], 2902 s, 380 iter, 580000 ts, 4.3 rew

agent-1: 14.0
Sum Reward: 14.0
Avg Reward: 14.0
Min Reward: 14.0
Max Reward: 14.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
agent-1: 0.0
Sum Reward: 0.0
Avg Reward: 0.0
Min Reward: 0.0
Max Reward: 0.0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_15-00-14
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 22.0
  episode_reward_mean: 4.44
  episode_reward_min: 0.0
  episodes_this_iter: 2
  episodes_total: 581
  experiment_id: cb3a18e0a26e466496590bc0542b68c4
  hostname: gpu020
  info:
    apply_time_ms: 2.961
    dispatch_time_ms: 6.449
    learner:
      cur_lr: 0.0013213719939813018
      grad_gnorm: 0.08948615193367004
      policy_entropy: 0.03424367681145668
      policy_loss: -1.1005408850905951e-05
      var_gnorm: 30.239070892333984
      vf_explained_var: 0.0
      vf_loss: 5.49818723811768e-05
    num_steps_sampled: 582000
    num_steps_trained: 582000
    wait_time_ms: 34.795
  iterations_since_restore: 381
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 10879
  policy_reward_mean: {}
  time_since_restore: 2911.4168708324432
  time_this_iter_s: 8.561872005462646
  time_total_s: 2911.4168708324432
  timestamp: 1594148414
  timesteps_since_restore: 582000
  timesteps_this_iter: 2000
  timesteps_total: 582000
  training_iteration: 381
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10879], 2911 s, 381 iter, 582000 ts, 4.44 rew

agent-1: 19.0
Sum Reward: 19.0
Avg Reward: 19.0
Min Reward: 19.0
Max Reward: 19.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
agent-1: 0.0
Sum Reward: 0.0
Avg Reward: 0.0
Min Reward: 0.0
Max Reward: 0.0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_15-00-23
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 22.0
  episode_reward_mean: 4.63
  episode_reward_min: 0.0
  episodes_this_iter: 2
  episodes_total: 583
  experiment_id: cb3a18e0a26e466496590bc0542b68c4
  hostname: gpu020
  info:
    apply_time_ms: 2.554
    dispatch_time_ms: 8.106
    learner:
      cur_lr: 0.0013212388148531318
      grad_gnorm: 0.9467056393623352
      policy_entropy: 0.03045755997300148
      policy_loss: -0.00010776666749734432
      var_gnorm: 30.239200592041016
      vf_explained_var: 0.0
      vf_loss: 0.0061536566354334354
    num_steps_sampled: 584000
    num_steps_trained: 584000
    wait_time_ms: 32.823
  iterations_since_restore: 382
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 10879
  policy_reward_mean: {}
  time_since_restore: 2919.976499080658
  time_this_iter_s: 8.559628248214722
  time_total_s: 2919.976499080658
  timestamp: 1594148423
  timesteps_since_restore: 584000
  timesteps_this_iter: 2000
  timesteps_total: 584000
  training_iteration: 382
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10879], 2919 s, 382 iter, 584000 ts, 4.63 rew

agent-1: 5.0
Sum Reward: 5.0
Avg Reward: 5.0
Min Reward: 5.0
Max Reward: 5.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
agent-1: 7.0
Sum Reward: 7.0
Avg Reward: 7.0
Min Reward: 7.0
Max Reward: 7.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_15-00-31
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 22.0
  episode_reward_mean: 4.75
  episode_reward_min: 0.0
  episodes_this_iter: 2
  episodes_total: 585
  experiment_id: cb3a18e0a26e466496590bc0542b68c4
  hostname: gpu020
  info:
    apply_time_ms: 2.546
    dispatch_time_ms: 6.705
    learner:
      cur_lr: 0.0013211056357249618
      grad_gnorm: 1.0802862644195557
      policy_entropy: 0.030371226370334625
      policy_loss: -0.00013852177653461695
      var_gnorm: 30.23907470703125
      vf_explained_var: 0.0
      vf_loss: 0.00801269244402647
    num_steps_sampled: 586000
    num_steps_trained: 586000
    wait_time_ms: 32.776
  iterations_since_restore: 383
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 10879
  policy_reward_mean: {}
  time_since_restore: 2928.517240524292
  time_this_iter_s: 8.540741443634033
  time_total_s: 2928.517240524292
  timestamp: 1594148431
  timesteps_since_restore: 586000
  timesteps_this_iter: 2000
  timesteps_total: 586000
  training_iteration: 383
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10879], 2928 s, 383 iter, 586000 ts, 4.75 rew

agent-1: 0.0
Sum Reward: 0.0
Avg Reward: 0.0
Min Reward: 0.0
Max Reward: 0.0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
agent-1: 8.0
Sum Reward: 8.0
Avg Reward: 8.0
Min Reward: 8.0
Max Reward: 8.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_15-00-40
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 22.0
  episode_reward_mean: 4.8
  episode_reward_min: 0.0
  episodes_this_iter: 2
  episodes_total: 587
  experiment_id: cb3a18e0a26e466496590bc0542b68c4
  hostname: gpu020
  info:
    apply_time_ms: 2.735
    dispatch_time_ms: 7.94
    learner:
      cur_lr: 0.0013209724565967917
      grad_gnorm: 0.9497877359390259
      policy_entropy: 0.0315222442150116
      policy_loss: -0.00012110007082810625
      var_gnorm: 30.23856544494629
      vf_explained_var: 0.0
      vf_loss: 0.006193747278302908
    num_steps_sampled: 588000
    num_steps_trained: 588000
    wait_time_ms: 29.913
  iterations_since_restore: 384
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 10879
  policy_reward_mean: {}
  time_since_restore: 2937.043626308441
  time_this_iter_s: 8.52638578414917
  time_total_s: 2937.043626308441
  timestamp: 1594148440
  timesteps_since_restore: 588000
  timesteps_this_iter: 2000
  timesteps_total: 588000
  training_iteration: 384
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10879], 2937 s, 384 iter, 588000 ts, 4.8 rew

agent-1: 0.0
Sum Reward: 0.0
Avg Reward: 0.0
Min Reward: 0.0
Max Reward: 0.0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
agent-1: 13.0
Sum Reward: 13.0
Avg Reward: 13.0
Min Reward: 13.0
Max Reward: 13.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_15-00-48
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 22.0
  episode_reward_mean: 4.55
  episode_reward_min: 0.0
  episodes_this_iter: 2
  episodes_total: 589
  experiment_id: cb3a18e0a26e466496590bc0542b68c4
  hostname: gpu020
  info:
    apply_time_ms: 3.07
    dispatch_time_ms: 9.055
    learner:
      cur_lr: 0.0013208391610533
      grad_gnorm: 0.009080407209694386
      policy_entropy: 0.039913322776556015
      policy_loss: -1.4966343542255345e-06
      var_gnorm: 30.237810134887695
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 5.659161956828029e-07
    num_steps_sampled: 590000
    num_steps_trained: 590000
    wait_time_ms: 31.461
  iterations_since_restore: 385
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 10879
  policy_reward_mean: {}
  time_since_restore: 2945.6720428466797
  time_this_iter_s: 8.628416538238525
  time_total_s: 2945.6720428466797
  timestamp: 1594148448
  timesteps_since_restore: 590000
  timesteps_this_iter: 2000
  timesteps_total: 590000
  training_iteration: 385
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10879], 2945 s, 385 iter, 590000 ts, 4.55 rew

agent-1: 0.0
Sum Reward: 0.0
Avg Reward: 0.0
Min Reward: 0.0
Max Reward: 0.0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
agent-1: 0.0
Sum Reward: 0.0
Avg Reward: 0.0
Min Reward: 0.0
Max Reward: 0.0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_15-00-57
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 22.0
  episode_reward_mean: 4.55
  episode_reward_min: 0.0
  episodes_this_iter: 2
  episodes_total: 591
  experiment_id: cb3a18e0a26e466496590bc0542b68c4
  hostname: gpu020
  info:
    apply_time_ms: 2.904
    dispatch_time_ms: 8.144
    learner:
      cur_lr: 0.0013207059819251299
      grad_gnorm: 0.98164302110672
      policy_entropy: 0.03300099074840546
      policy_loss: -0.00012473967217374593
      var_gnorm: 30.238128662109375
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 0.006616225466132164
    num_steps_sampled: 592000
    num_steps_trained: 592000
    wait_time_ms: 31.825
  iterations_since_restore: 386
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 10879
  policy_reward_mean: {}
  time_since_restore: 2954.243378162384
  time_this_iter_s: 8.571335315704346
  time_total_s: 2954.243378162384
  timestamp: 1594148457
  timesteps_since_restore: 592000
  timesteps_this_iter: 2000
  timesteps_total: 592000
  training_iteration: 386
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10879], 2954 s, 386 iter, 592000 ts, 4.55 rew

agent-1: 0.0
Sum Reward: 0.0
Avg Reward: 0.0
Min Reward: 0.0
Max Reward: 0.0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
agent-1: 5.0
Sum Reward: 5.0
Avg Reward: 5.0
Min Reward: 5.0
Max Reward: 5.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_15-01-15
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 22.0
  episode_reward_mean: 4.42
  episode_reward_min: 0.0
  episodes_this_iter: 2
  episodes_total: 593
  experiment_id: cb3a18e0a26e466496590bc0542b68c4
  hostname: gpu020
  info:
    apply_time_ms: 2.577
    dispatch_time_ms: 6.263
    learner:
      cur_lr: 0.0013205728027969599
      grad_gnorm: 0.009094659239053726
      policy_entropy: 0.04263181984424591
      policy_loss: -1.557426230647252e-06
      var_gnorm: 30.237407684326172
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 5.672792440236663e-07
    num_steps_sampled: 594000
    num_steps_trained: 594000
    wait_time_ms: 34.664
  iterations_since_restore: 387
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 10879
  policy_reward_mean: {}
  time_since_restore: 2972.6714811325073
  time_this_iter_s: 18.42810297012329
  time_total_s: 2972.6714811325073
  timestamp: 1594148475
  timesteps_since_restore: 594000
  timesteps_this_iter: 2000
  timesteps_total: 594000
  training_iteration: 387
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10879], 2972 s, 387 iter, 594000 ts, 4.42 rew

agent-1: 1.0
Sum Reward: 1.0
Avg Reward: 1.0
Min Reward: 1.0
Max Reward: 1.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
agent-1: 0.0
Sum Reward: 0.0
Avg Reward: 0.0
Min Reward: 0.0
Max Reward: 0.0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_15-01-24
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 22.0
  episode_reward_mean: 4.43
  episode_reward_min: 0.0
  episodes_this_iter: 2
  episodes_total: 595
  experiment_id: cb3a18e0a26e466496590bc0542b68c4
  hostname: gpu020
  info:
    apply_time_ms: 2.939
    dispatch_time_ms: 6.941
    learner:
      cur_lr: 0.0013204396236687899
      grad_gnorm: 0.10823801904916763
      policy_entropy: 0.04661908745765686
      policy_loss: -2.098900222335942e-05
      var_gnorm: 30.236988067626953
      vf_explained_var: 0.0
      vf_loss: 8.043518027989194e-05
    num_steps_sampled: 596000
    num_steps_trained: 596000
    wait_time_ms: 33.864
  iterations_since_restore: 388
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 10879
  policy_reward_mean: {}
  time_since_restore: 2981.306271314621
  time_this_iter_s: 8.634790182113647
  time_total_s: 2981.306271314621
  timestamp: 1594148484
  timesteps_since_restore: 596000
  timesteps_this_iter: 2000
  timesteps_total: 596000
  training_iteration: 388
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10879], 2981 s, 388 iter, 596000 ts, 4.43 rew

agent-1: 0.0
Sum Reward: 0.0
Avg Reward: 0.0
Min Reward: 0.0
Max Reward: 0.0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
agent-1: 1.0
Sum Reward: 1.0
Avg Reward: 1.0
Min Reward: 1.0
Max Reward: 1.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_15-01-33
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 22.0
  episode_reward_mean: 4.26
  episode_reward_min: 0.0
  episodes_this_iter: 2
  episodes_total: 597
  experiment_id: cb3a18e0a26e466496590bc0542b68c4
  hostname: gpu020
  info:
    apply_time_ms: 5.054
    dispatch_time_ms: 7.472
    learner:
      cur_lr: 0.0013203064445406199
      grad_gnorm: 0.47518619894981384
      policy_entropy: 0.02522403746843338
      policy_loss: -4.520405127550475e-05
      var_gnorm: 30.238510131835938
      vf_explained_var: 0.0
      vf_loss: 0.0015503467293456197
    num_steps_sampled: 598000
    num_steps_trained: 598000
    wait_time_ms: 31.923
  iterations_since_restore: 389
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 10879
  policy_reward_mean: {}
  time_since_restore: 2989.886743783951
  time_this_iter_s: 8.580472469329834
  time_total_s: 2989.886743783951
  timestamp: 1594148493
  timesteps_since_restore: 598000
  timesteps_this_iter: 2000
  timesteps_total: 598000
  training_iteration: 389
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10879], 2989 s, 389 iter, 598000 ts, 4.26 rew

agent-1: 20.0
Sum Reward: 20.0
Avg Reward: 20.0
Min Reward: 20.0
Max Reward: 20.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
agent-1: 3.0
Sum Reward: 3.0
Avg Reward: 3.0
Min Reward: 3.0
Max Reward: 3.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_15-01-41
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 22.0
  episode_reward_mean: 4.42
  episode_reward_min: 0.0
  episodes_this_iter: 2
  episodes_total: 599
  experiment_id: cb3a18e0a26e466496590bc0542b68c4
  hostname: gpu020
  info:
    apply_time_ms: 2.887
    dispatch_time_ms: 8.555
    learner:
      cur_lr: 0.001320173148997128
      grad_gnorm: 0.042365267872810364
      policy_entropy: 0.026790676638484
      policy_loss: -5.727386451326311e-06
      var_gnorm: 30.238300323486328
      vf_explained_var: 0.0
      vf_loss: 1.2324311683187261e-05
    num_steps_sampled: 600000
    num_steps_trained: 600000
    wait_time_ms: 32.41
  iterations_since_restore: 390
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 10879
  policy_reward_mean: {}
  time_since_restore: 2998.4797015190125
  time_this_iter_s: 8.592957735061646
  time_total_s: 2998.4797015190125
  timestamp: 1594148501
  timesteps_since_restore: 600000
  timesteps_this_iter: 2000
  timesteps_total: 600000
  training_iteration: 390
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10879], 2998 s, 390 iter, 600000 ts, 4.42 rew

agent-1: 17.0
Sum Reward: 17.0
Avg Reward: 17.0
Min Reward: 17.0
Max Reward: 17.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
agent-1: 0.0
Sum Reward: 0.0
Avg Reward: 0.0
Min Reward: 0.0
Max Reward: 0.0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_15-01-50
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 22.0
  episode_reward_mean: 4.58
  episode_reward_min: 0.0
  episodes_this_iter: 2
  episodes_total: 601
  experiment_id: cb3a18e0a26e466496590bc0542b68c4
  hostname: gpu020
  info:
    apply_time_ms: 2.551
    dispatch_time_ms: 6.535
    learner:
      cur_lr: 0.001320039969868958
      grad_gnorm: 0.41782358288764954
      policy_entropy: 0.026777688413858414
      policy_loss: -4.245639138389379e-05
      var_gnorm: 30.23813247680664
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 0.0011986554600298405
    num_steps_sampled: 602000
    num_steps_trained: 602000
    wait_time_ms: 32.079
  iterations_since_restore: 391
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 10879
  policy_reward_mean: {}
  time_since_restore: 3007.046222448349
  time_this_iter_s: 8.566520929336548
  time_total_s: 3007.046222448349
  timestamp: 1594148510
  timesteps_since_restore: 602000
  timesteps_this_iter: 2000
  timesteps_total: 602000
  training_iteration: 391
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10879], 3007 s, 391 iter, 602000 ts, 4.58 rew

agent-1: 0.0
Sum Reward: 0.0
Avg Reward: 0.0
Min Reward: 0.0
Max Reward: 0.0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
agent-1: 3.0
Sum Reward: 3.0
Avg Reward: 3.0
Min Reward: 3.0
Max Reward: 3.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_15-01-58
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 22.0
  episode_reward_mean: 4.51
  episode_reward_min: 0.0
  episodes_this_iter: 2
  episodes_total: 603
  experiment_id: cb3a18e0a26e466496590bc0542b68c4
  hostname: gpu020
  info:
    apply_time_ms: 2.837
    dispatch_time_ms: 8.978
    learner:
      cur_lr: 0.001319906790740788
      grad_gnorm: 0.2019941657781601
      policy_entropy: 0.028604090213775635
      policy_loss: -2.837739339156542e-05
      var_gnorm: 30.23783302307129
      vf_explained_var: 5.960464477539063e-08
      vf_loss: 0.0002801353402901441
    num_steps_sampled: 604000
    num_steps_trained: 604000
    wait_time_ms: 29.69
  iterations_since_restore: 392
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 10879
  policy_reward_mean: {}
  time_since_restore: 3015.5732967853546
  time_this_iter_s: 8.527074337005615
  time_total_s: 3015.5732967853546
  timestamp: 1594148518
  timesteps_since_restore: 604000
  timesteps_this_iter: 2000
  timesteps_total: 604000
  training_iteration: 392
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10879], 3015 s, 392 iter, 604000 ts, 4.51 rew

agent-1: 4.0
Sum Reward: 4.0
Avg Reward: 4.0
Min Reward: 4.0
Max Reward: 4.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
agent-1: 1.0
Sum Reward: 1.0
Avg Reward: 1.0
Min Reward: 1.0
Max Reward: 1.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_15-02-07
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 22.0
  episode_reward_mean: 4.53
  episode_reward_min: 0.0
  episodes_this_iter: 2
  episodes_total: 605
  experiment_id: cb3a18e0a26e466496590bc0542b68c4
  hostname: gpu020
  info:
    apply_time_ms: 3.257
    dispatch_time_ms: 8.165
    learner:
      cur_lr: 0.001319773611612618
      grad_gnorm: 0.513358473777771
      policy_entropy: 0.02749679423868656
      policy_loss: -5.437920117401518e-05
      var_gnorm: 30.237796783447266
      vf_explained_var: 0.0
      vf_loss: 0.0018094292609021068
    num_steps_sampled: 606000
    num_steps_trained: 606000
    wait_time_ms: 30.503
  iterations_since_restore: 393
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 10879
  policy_reward_mean: {}
  time_since_restore: 3024.1645407676697
  time_this_iter_s: 8.591243982315063
  time_total_s: 3024.1645407676697
  timestamp: 1594148527
  timesteps_since_restore: 606000
  timesteps_this_iter: 2000
  timesteps_total: 606000
  training_iteration: 393
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10879], 3024 s, 393 iter, 606000 ts, 4.53 rew

agent-1: 0.0
Sum Reward: 0.0
Avg Reward: 0.0
Min Reward: 0.0
Max Reward: 0.0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
agent-1: 4.0
Sum Reward: 4.0
Avg Reward: 4.0
Min Reward: 4.0
Max Reward: 4.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_15-02-16
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 22.0
  episode_reward_mean: 4.52
  episode_reward_min: 0.0
  episodes_this_iter: 2
  episodes_total: 607
  experiment_id: cb3a18e0a26e466496590bc0542b68c4
  hostname: gpu020
  info:
    apply_time_ms: 3.291
    dispatch_time_ms: 10.538
    learner:
      cur_lr: 0.001319640432484448
      grad_gnorm: 0.3853013813495636
      policy_entropy: 0.02409404329955578
      policy_loss: -4.500608338275924e-05
      var_gnorm: 30.238136291503906
      vf_explained_var: 0.0
      vf_loss: 0.001019314513541758
    num_steps_sampled: 608000
    num_steps_trained: 608000
    wait_time_ms: 29.302
  iterations_since_restore: 394
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 10879
  policy_reward_mean: {}
  time_since_restore: 3032.6961755752563
  time_this_iter_s: 8.53163480758667
  time_total_s: 3032.6961755752563
  timestamp: 1594148536
  timesteps_since_restore: 608000
  timesteps_this_iter: 2000
  timesteps_total: 608000
  training_iteration: 394
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10879], 3032 s, 394 iter, 608000 ts, 4.52 rew

agent-1: 7.0
Sum Reward: 7.0
Avg Reward: 7.0
Min Reward: 7.0
Max Reward: 7.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
agent-1: 3.0
Sum Reward: 3.0
Avg Reward: 3.0
Min Reward: 3.0
Max Reward: 3.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_15-02-24
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 22.0
  episode_reward_mean: 4.43
  episode_reward_min: 0.0
  episodes_this_iter: 2
  episodes_total: 609
  experiment_id: cb3a18e0a26e466496590bc0542b68c4
  hostname: gpu020
  info:
    apply_time_ms: 2.95
    dispatch_time_ms: 7.058
    learner:
      cur_lr: 0.001319507253356278
      grad_gnorm: 0.011354082264006138
      policy_entropy: 0.026958415284752846
      policy_loss: -1.2697670399575145e-06
      var_gnorm: 30.23784065246582
      vf_explained_var: 0.0
      vf_loss: 8.849899018059659e-07
    num_steps_sampled: 610000
    num_steps_trained: 610000
    wait_time_ms: 30.716
  iterations_since_restore: 395
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 10879
  policy_reward_mean: {}
  time_since_restore: 3041.236362218857
  time_this_iter_s: 8.540186643600464
  time_total_s: 3041.236362218857
  timestamp: 1594148544
  timesteps_since_restore: 610000
  timesteps_this_iter: 2000
  timesteps_total: 610000
  training_iteration: 395
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10879], 3041 s, 395 iter, 610000 ts, 4.43 rew

agent-1: 9.0
Sum Reward: 9.0
Avg Reward: 9.0
Min Reward: 9.0
Max Reward: 9.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
agent-1: 0.0
Sum Reward: 0.0
Avg Reward: 0.0
Min Reward: 0.0
Max Reward: 0.0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_15-02-33
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 22.0
  episode_reward_mean: 4.42
  episode_reward_min: 0.0
  episodes_this_iter: 2
  episodes_total: 611
  experiment_id: cb3a18e0a26e466496590bc0542b68c4
  hostname: gpu020
  info:
    apply_time_ms: 2.925
    dispatch_time_ms: 8.015
    learner:
      cur_lr: 0.001319373957812786
      grad_gnorm: 1.2285329103469849
      policy_entropy: 0.014679675921797752
      policy_loss: -6.863040471216664e-05
      var_gnorm: 30.23971176147461
      vf_explained_var: 0.0
      vf_loss: 0.010362858884036541
    num_steps_sampled: 612000
    num_steps_trained: 612000
    wait_time_ms: 29.909
  iterations_since_restore: 396
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 10879
  policy_reward_mean: {}
  time_since_restore: 3049.8004715442657
  time_this_iter_s: 8.564109325408936
  time_total_s: 3049.8004715442657
  timestamp: 1594148553
  timesteps_since_restore: 612000
  timesteps_this_iter: 2000
  timesteps_total: 612000
  training_iteration: 396
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10879], 3049 s, 396 iter, 612000 ts, 4.42 rew

agent-1: 11.0
Sum Reward: 11.0
Avg Reward: 11.0
Min Reward: 11.0
Max Reward: 11.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
agent-1: 12.0
Sum Reward: 12.0
Avg Reward: 12.0
Min Reward: 12.0
Max Reward: 12.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_15-02-41
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 22.0
  episode_reward_mean: 4.61
  episode_reward_min: 0.0
  episodes_this_iter: 2
  episodes_total: 613
  experiment_id: cb3a18e0a26e466496590bc0542b68c4
  hostname: gpu020
  info:
    apply_time_ms: 3.326
    dispatch_time_ms: 7.144
    learner:
      cur_lr: 0.001319240778684616
      grad_gnorm: 0.535271167755127
      policy_entropy: 0.016294250264763832
      policy_loss: -2.851832687156275e-05
      var_gnorm: 30.23927116394043
      vf_explained_var: 0.0
      vf_loss: 0.001967209856957197
    num_steps_sampled: 614000
    num_steps_trained: 614000
    wait_time_ms: 31.274
  iterations_since_restore: 397
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 10879
  policy_reward_mean: {}
  time_since_restore: 3058.3802013397217
  time_this_iter_s: 8.579729795455933
  time_total_s: 3058.3802013397217
  timestamp: 1594148561
  timesteps_since_restore: 614000
  timesteps_this_iter: 2000
  timesteps_total: 614000
  training_iteration: 397
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10879], 3058 s, 397 iter, 614000 ts, 4.61 rew

agent-1: 0.0
Sum Reward: 0.0
Avg Reward: 0.0
Min Reward: 0.0
Max Reward: 0.0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
agent-1: 7.0
Sum Reward: 7.0
Avg Reward: 7.0
Min Reward: 7.0
Max Reward: 7.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_15-02-50
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 22.0
  episode_reward_mean: 4.54
  episode_reward_min: 0.0
  episodes_this_iter: 2
  episodes_total: 615
  experiment_id: cb3a18e0a26e466496590bc0542b68c4
  hostname: gpu020
  info:
    apply_time_ms: 2.575
    dispatch_time_ms: 6.099
    learner:
      cur_lr: 0.001319107599556446
      grad_gnorm: 0.18994846940040588
      policy_entropy: 0.012308765202760696
      policy_loss: -8.097168574749958e-06
      var_gnorm: 30.240196228027344
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 0.0002477206289768219
    num_steps_sampled: 616000
    num_steps_trained: 616000
    wait_time_ms: 33.052
  iterations_since_restore: 398
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 10879
  policy_reward_mean: {}
  time_since_restore: 3066.956857919693
  time_this_iter_s: 8.576656579971313
  time_total_s: 3066.956857919693
  timestamp: 1594148570
  timesteps_since_restore: 616000
  timesteps_this_iter: 2000
  timesteps_total: 616000
  training_iteration: 398
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10879], 3066 s, 398 iter, 616000 ts, 4.54 rew

agent-1: 20.0
Sum Reward: 20.0
Avg Reward: 20.0
Min Reward: 20.0
Max Reward: 20.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_15-02-56
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 22.0
  episode_reward_mean: 4.61
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 616
  experiment_id: cb3a18e0a26e466496590bc0542b68c4
  hostname: gpu020
  info:
    apply_time_ms: 4.153
    dispatch_time_ms: 25.416
    learner:
      cur_lr: 0.001318974420428276
      grad_gnorm: 1.8366739749908447
      policy_entropy: 0.011243755929172039
      policy_loss: -5.807497018395225e-06
      var_gnorm: 30.240478515625
      vf_explained_var: 0.0
      vf_loss: 0.018391849473118782
    num_steps_sampled: 617000
    num_steps_trained: 617000
    wait_time_ms: 25.471
  iterations_since_restore: 399
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 10879
  policy_reward_mean: {}
  time_since_restore: 3072.346283197403
  time_this_iter_s: 5.389425277709961
  time_total_s: 3072.346283197403
  timestamp: 1594148576
  timesteps_since_restore: 617000
  timesteps_this_iter: 1000
  timesteps_total: 617000
  training_iteration: 399
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10879], 3072 s, 399 iter, 617000 ts, 4.61 rew

agent-1: 0.0
Sum Reward: 0.0
Avg Reward: 0.0
Min Reward: 0.0
Max Reward: 0.0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_15-03-01
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 22.0
  episode_reward_mean: 4.56
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 617
  experiment_id: cb3a18e0a26e466496590bc0542b68c4
  hostname: gpu020
  info:
    apply_time_ms: 2.579
    dispatch_time_ms: 26.255
    learner:
      cur_lr: 0.001318907830864191
      grad_gnorm: 0.10505582392215729
      policy_entropy: 0.011155731976032257
      policy_loss: -8.954989425546955e-06
      var_gnorm: 30.240495681762695
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 0.00015337909280788153
    num_steps_sampled: 618000
    num_steps_trained: 618000
    wait_time_ms: 22.032
  iterations_since_restore: 400
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 10879
  policy_reward_mean: {}
  time_since_restore: 3078.16309094429
  time_this_iter_s: 5.816807746887207
  time_total_s: 3078.16309094429
  timestamp: 1594148581
  timesteps_since_restore: 618000
  timesteps_this_iter: 1000
  timesteps_total: 618000
  training_iteration: 400
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10879], 3078 s, 400 iter, 618000 ts, 4.56 rew

agent-1: 4.0
Sum Reward: 4.0
Avg Reward: 4.0
Min Reward: 4.0
Max Reward: 4.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_15-03-07
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 22.0
  episode_reward_mean: 4.52
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 618
  experiment_id: cb3a18e0a26e466496590bc0542b68c4
  hostname: gpu020
  info:
    apply_time_ms: 2.979
    dispatch_time_ms: 26.423
    learner:
      cur_lr: 0.001318841241300106
      grad_gnorm: 0.31323304772377014
      policy_entropy: 0.009057696908712387
      policy_loss: -4.13673205912346e-06
      var_gnorm: 30.241655349731445
      vf_explained_var: 0.0
      vf_loss: 0.0005657264264300466
    num_steps_sampled: 619000
    num_steps_trained: 619000
    wait_time_ms: 29.824
  iterations_since_restore: 401
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 10879
  policy_reward_mean: {}
  time_since_restore: 3084.0674262046814
  time_this_iter_s: 5.904335260391235
  time_total_s: 3084.0674262046814
  timestamp: 1594148587
  timesteps_since_restore: 619000
  timesteps_this_iter: 1000
  timesteps_total: 619000
  training_iteration: 401
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10879], 3084 s, 401 iter, 619000 ts, 4.52 rew

agent-1: 2.0
Sum Reward: 2.0
Avg Reward: 2.0
Min Reward: 2.0
Max Reward: 2.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_15-03-13
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 22.0
  episode_reward_mean: 4.34
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 619
  experiment_id: cb3a18e0a26e466496590bc0542b68c4
  hostname: gpu020
  info:
    apply_time_ms: 2.72
    dispatch_time_ms: 27.706
    learner:
      cur_lr: 0.001318774651736021
      grad_gnorm: 0.003052080050110817
      policy_entropy: 0.007916915230453014
      policy_loss: -2.2900078420207137e-06
      var_gnorm: 30.24245262145996
      vf_explained_var: 5.960464477539063e-08
      vf_loss: 1.3302293154993095e-05
    num_steps_sampled: 620000
    num_steps_trained: 620000
    wait_time_ms: 20.393
  iterations_since_restore: 402
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 10879
  policy_reward_mean: {}
  time_since_restore: 3089.98543715477
  time_this_iter_s: 5.918010950088501
  time_total_s: 3089.98543715477
  timestamp: 1594148593
  timesteps_since_restore: 620000
  timesteps_this_iter: 1000
  timesteps_total: 620000
  training_iteration: 402
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10879], 3089 s, 402 iter, 620000 ts, 4.34 rew

agent-1: 0.0
Sum Reward: 0.0
Avg Reward: 0.0
Min Reward: 0.0
Max Reward: 0.0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_15-03-19
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 22.0
  episode_reward_mean: 4.34
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 620
  experiment_id: cb3a18e0a26e466496590bc0542b68c4
  hostname: gpu020
  info:
    apply_time_ms: 2.715
    dispatch_time_ms: 38.265
    learner:
      cur_lr: 0.0013187079457566142
      grad_gnorm: 0.26357969641685486
      policy_entropy: 0.00856565311551094
      policy_loss: -1.7638379858908593e-06
      var_gnorm: 30.2421932220459
      vf_explained_var: 0.0
      vf_loss: 0.00038458668859675527
    num_steps_sampled: 621000
    num_steps_trained: 621000
    wait_time_ms: 16.166
  iterations_since_restore: 403
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 10879
  policy_reward_mean: {}
  time_since_restore: 3095.6327962875366
  time_this_iter_s: 5.647359132766724
  time_total_s: 3095.6327962875366
  timestamp: 1594148599
  timesteps_since_restore: 621000
  timesteps_this_iter: 1000
  timesteps_total: 621000
  training_iteration: 403
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10879], 3095 s, 403 iter, 621000 ts, 4.34 rew

agent-1: 0.0
Sum Reward: 0.0
Avg Reward: 0.0
Min Reward: 0.0
Max Reward: 0.0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_15-03-25
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 22.0
  episode_reward_mean: 4.29
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 621
  experiment_id: cb3a18e0a26e466496590bc0542b68c4
  hostname: gpu020
  info:
    apply_time_ms: 2.576
    dispatch_time_ms: 45.325
    learner:
      cur_lr: 0.0013186413561925292
      grad_gnorm: 8.14322566986084
      policy_entropy: 0.005794302560389042
      policy_loss: -5.072313797427341e-06
      var_gnorm: 30.243236541748047
      vf_explained_var: -2.384185791015625e-07
      vf_loss: 0.36090806126594543
    num_steps_sampled: 622000
    num_steps_trained: 622000
    wait_time_ms: 20.449
  iterations_since_restore: 404
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 10879
  policy_reward_mean: {}
  time_since_restore: 3101.381008386612
  time_this_iter_s: 5.748212099075317
  time_total_s: 3101.381008386612
  timestamp: 1594148605
  timesteps_since_restore: 622000
  timesteps_this_iter: 1000
  timesteps_total: 622000
  training_iteration: 404
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10879], 3101 s, 404 iter, 622000 ts, 4.29 rew

agent-1: 0.0
Sum Reward: 0.0
Avg Reward: 0.0
Min Reward: 0.0
Max Reward: 0.0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_15-03-30
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 22.0
  episode_reward_mean: 4.25
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 622
  experiment_id: cb3a18e0a26e466496590bc0542b68c4
  hostname: gpu020
  info:
    apply_time_ms: 3.437
    dispatch_time_ms: 48.889
    learner:
      cur_lr: 0.0013185747666284442
      grad_gnorm: 0.1090562641620636
      policy_entropy: 0.006770462729036808
      policy_loss: -5.972789494990138e-06
      var_gnorm: 30.24275779724121
      vf_explained_var: 1.1920928955078125e-07
      vf_loss: 0.0001921423536259681
    num_steps_sampled: 623000
    num_steps_trained: 623000
    wait_time_ms: 17.969
  iterations_since_restore: 405
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 10879
  policy_reward_mean: {}
  time_since_restore: 3106.8212711811066
  time_this_iter_s: 5.440262794494629
  time_total_s: 3106.8212711811066
  timestamp: 1594148610
  timesteps_since_restore: 623000
  timesteps_this_iter: 1000
  timesteps_total: 623000
  training_iteration: 405
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10879], 3106 s, 405 iter, 623000 ts, 4.25 rew

agent-1: 17.0
Sum Reward: 17.0
Avg Reward: 17.0
Min Reward: 17.0
Max Reward: 17.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_15-03-36
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 22.0
  episode_reward_mean: 4.39
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 623
  experiment_id: cb3a18e0a26e466496590bc0542b68c4
  hostname: gpu020
  info:
    apply_time_ms: 2.443
    dispatch_time_ms: 24.86
    learner:
      cur_lr: 0.0013185081770643592
      grad_gnorm: 0.963422417640686
      policy_entropy: 0.005974847823381424
      policy_loss: -7.972173989401199e-06
      var_gnorm: 30.24311065673828
      vf_explained_var: 0.0
      vf_loss: 0.0053484258241951466
    num_steps_sampled: 624000
    num_steps_trained: 624000
    wait_time_ms: 14.685
  iterations_since_restore: 406
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 10879
  policy_reward_mean: {}
  time_since_restore: 3113.0513610839844
  time_this_iter_s: 6.230089902877808
  time_total_s: 3113.0513610839844
  timestamp: 1594148616
  timesteps_since_restore: 624000
  timesteps_this_iter: 1000
  timesteps_total: 624000
  training_iteration: 406
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10879], 3113 s, 406 iter, 624000 ts, 4.39 rew

agent-1: 0.0
Sum Reward: 0.0
Avg Reward: 0.0
Min Reward: 0.0
Max Reward: 0.0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_15-03-42
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 22.0
  episode_reward_mean: 4.39
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 624
  experiment_id: cb3a18e0a26e466496590bc0542b68c4
  hostname: gpu020
  info:
    apply_time_ms: 4.0
    dispatch_time_ms: 34.462
    learner:
      cur_lr: 0.0013184415875002742
      grad_gnorm: 0.2141922116279602
      policy_entropy: 0.006983927916735411
      policy_loss: -6.419837518478744e-06
      var_gnorm: 30.242633819580078
      vf_explained_var: 0.0
      vf_loss: 0.0003869284992106259
    num_steps_sampled: 625000
    num_steps_trained: 625000
    wait_time_ms: 18.586
  iterations_since_restore: 407
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 10879
  policy_reward_mean: {}
  time_since_restore: 3118.702493429184
  time_this_iter_s: 5.651132345199585
  time_total_s: 3118.702493429184
  timestamp: 1594148622
  timesteps_since_restore: 625000
  timesteps_this_iter: 1000
  timesteps_total: 625000
  training_iteration: 407
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10879], 3118 s, 407 iter, 625000 ts, 4.39 rew

agent-1: 7.0
Sum Reward: 7.0
Avg Reward: 7.0
Min Reward: 7.0
Max Reward: 7.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_15-03-48
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 22.0
  episode_reward_mean: 4.46
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 625
  experiment_id: cb3a18e0a26e466496590bc0542b68c4
  hostname: gpu020
  info:
    apply_time_ms: 4.179
    dispatch_time_ms: 37.912
    learner:
      cur_lr: 0.0013183749979361892
      grad_gnorm: 0.3668355345726013
      policy_entropy: 0.006827566772699356
      policy_loss: -6.391641363734379e-06
      var_gnorm: 30.242691040039062
      vf_explained_var: 0.0
      vf_loss: 0.0008752390858717263
    num_steps_sampled: 626000
    num_steps_trained: 626000
    wait_time_ms: 13.642
  iterations_since_restore: 408
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 10879
  policy_reward_mean: {}
  time_since_restore: 3124.6267681121826
  time_this_iter_s: 5.924274682998657
  time_total_s: 3124.6267681121826
  timestamp: 1594148628
  timesteps_since_restore: 626000
  timesteps_this_iter: 1000
  timesteps_total: 626000
  training_iteration: 408
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10879], 3124 s, 408 iter, 626000 ts, 4.46 rew

agent-1: 0.0
Sum Reward: 0.0
Avg Reward: 0.0
Min Reward: 0.0
Max Reward: 0.0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_15-03-54
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 22.0
  episode_reward_mean: 4.46
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 626
  experiment_id: cb3a18e0a26e466496590bc0542b68c4
  hostname: gpu020
  info:
    apply_time_ms: 4.12
    dispatch_time_ms: 34.199
    learner:
      cur_lr: 0.0013183084083721042
      grad_gnorm: 0.33382466435432434
      policy_entropy: 0.007930154912173748
      policy_loss: -5.343978500604862e-06
      var_gnorm: 30.242263793945312
      vf_explained_var: 0.0
      vf_loss: 0.0006779850809834898
    num_steps_sampled: 627000
    num_steps_trained: 627000
    wait_time_ms: 15.972
  iterations_since_restore: 409
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 10879
  policy_reward_mean: {}
  time_since_restore: 3130.670874118805
  time_this_iter_s: 6.0441060066223145
  time_total_s: 3130.670874118805
  timestamp: 1594148634
  timesteps_since_restore: 627000
  timesteps_this_iter: 1000
  timesteps_total: 627000
  training_iteration: 409
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10879], 3130 s, 409 iter, 627000 ts, 4.46 rew

agent-1: 4.0
Sum Reward: 4.0
Avg Reward: 4.0
Min Reward: 4.0
Max Reward: 4.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_15-04-10
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 22.0
  episode_reward_mean: 4.5
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 627
  experiment_id: cb3a18e0a26e466496590bc0542b68c4
  hostname: gpu020
  info:
    apply_time_ms: 2.813
    dispatch_time_ms: 1049.58
    learner:
      cur_lr: 0.0013182418188080192
      grad_gnorm: 2.9188787937164307
      policy_entropy: 0.006938811391592026
      policy_loss: -5.857738869963214e-06
      var_gnorm: 30.242565155029297
      vf_explained_var: 5.960464477539063e-08
      vf_loss: 0.04646886885166168
    num_steps_sampled: 628000
    num_steps_trained: 628000
    wait_time_ms: 23.365
  iterations_since_restore: 410
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 10879
  policy_reward_mean: {}
  time_since_restore: 3146.607172012329
  time_this_iter_s: 15.93629789352417
  time_total_s: 3146.607172012329
  timestamp: 1594148650
  timesteps_since_restore: 628000
  timesteps_this_iter: 1000
  timesteps_total: 628000
  training_iteration: 410
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10879], 3146 s, 410 iter, 628000 ts, 4.5 rew

agent-1: 0.0
Sum Reward: 0.0
Avg Reward: 0.0
Min Reward: 0.0
Max Reward: 0.0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
agent-1: 5.0
Sum Reward: 5.0
Avg Reward: 5.0
Min Reward: 5.0
Max Reward: 5.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_15-04-18
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 22.0
  episode_reward_mean: 4.42
  episode_reward_min: 0.0
  episodes_this_iter: 2
  episodes_total: 629
  experiment_id: cb3a18e0a26e466496590bc0542b68c4
  hostname: gpu020
  info:
    apply_time_ms: 2.937
    dispatch_time_ms: 7.366
    learner:
      cur_lr: 0.0013181752292439342
      grad_gnorm: 0.5831868052482605
      policy_entropy: 0.007129454053938389
      policy_loss: -1.3369198313739616e-05
      var_gnorm: 30.242414474487305
      vf_explained_var: 5.960464477539063e-08
      vf_loss: 0.0023351714480668306
    num_steps_sampled: 630000
    num_steps_trained: 630000
    wait_time_ms: 32.021
  iterations_since_restore: 411
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 10879
  policy_reward_mean: {}
  time_since_restore: 3154.8949341773987
  time_this_iter_s: 8.28776216506958
  time_total_s: 3154.8949341773987
  timestamp: 1594148658
  timesteps_since_restore: 630000
  timesteps_this_iter: 2000
  timesteps_total: 630000
  training_iteration: 411
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10879], 3154 s, 411 iter, 630000 ts, 4.42 rew

agent-1: 0.0
Sum Reward: 0.0
Avg Reward: 0.0
Min Reward: 0.0
Max Reward: 0.0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
agent-1: 5.0
Sum Reward: 5.0
Avg Reward: 5.0
Min Reward: 5.0
Max Reward: 5.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_15-04-27
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 22.0
  episode_reward_mean: 4.43
  episode_reward_min: 0.0
  episodes_this_iter: 2
  episodes_total: 631
  experiment_id: cb3a18e0a26e466496590bc0542b68c4
  hostname: gpu020
  info:
    apply_time_ms: 2.431
    dispatch_time_ms: 7.297
    learner:
      cur_lr: 0.0013180420501157641
      grad_gnorm: 0.10525914281606674
      policy_entropy: 0.007569342385977507
      policy_loss: -2.850743612725637e-06
      var_gnorm: 30.242238998413086
      vf_explained_var: 1.1920928955078125e-07
      vf_loss: 7.607400038978085e-05
    num_steps_sampled: 632000
    num_steps_trained: 632000
    wait_time_ms: 33.375
  iterations_since_restore: 412
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 10879
  policy_reward_mean: {}
  time_since_restore: 3163.468356370926
  time_this_iter_s: 8.573422193527222
  time_total_s: 3163.468356370926
  timestamp: 1594148667
  timesteps_since_restore: 632000
  timesteps_this_iter: 2000
  timesteps_total: 632000
  training_iteration: 412
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10879], 3163 s, 412 iter, 632000 ts, 4.43 rew

agent-1: 17.0
Sum Reward: 17.0
Avg Reward: 17.0
Min Reward: 17.0
Max Reward: 17.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
agent-1: 0.0
Sum Reward: 0.0
Avg Reward: 0.0
Min Reward: 0.0
Max Reward: 0.0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_15-04-36
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 22.0
  episode_reward_mean: 4.6
  episode_reward_min: 0.0
  episodes_this_iter: 2
  episodes_total: 633
  experiment_id: cb3a18e0a26e466496590bc0542b68c4
  hostname: gpu020
  info:
    apply_time_ms: 2.509
    dispatch_time_ms: 6.485
    learner:
      cur_lr: 0.0013179087545722723
      grad_gnorm: 0.05545945465564728
      policy_entropy: 0.007532646879553795
      policy_loss: -1.3750835705650388e-06
      var_gnorm: 30.24220848083496
      vf_explained_var: 0.0
      vf_loss: 2.112212314386852e-05
    num_steps_sampled: 634000
    num_steps_trained: 634000
    wait_time_ms: 34.967
  iterations_since_restore: 413
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 10879
  policy_reward_mean: {}
  time_since_restore: 3172.0786397457123
  time_this_iter_s: 8.610283374786377
  time_total_s: 3172.0786397457123
  timestamp: 1594148676
  timesteps_since_restore: 634000
  timesteps_this_iter: 2000
  timesteps_total: 634000
  training_iteration: 413
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10879], 3172 s, 413 iter, 634000 ts, 4.6 rew

agent-1: 7.0
Sum Reward: 7.0
Avg Reward: 7.0
Min Reward: 7.0
Max Reward: 7.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
agent-1: 0.0
Sum Reward: 0.0
Avg Reward: 0.0
Min Reward: 0.0
Max Reward: 0.0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_15-04-44
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 22.0
  episode_reward_mean: 4.6
  episode_reward_min: 0.0
  episodes_this_iter: 2
  episodes_total: 635
  experiment_id: cb3a18e0a26e466496590bc0542b68c4
  hostname: gpu020
  info:
    apply_time_ms: 3.308
    dispatch_time_ms: 6.433
    learner:
      cur_lr: 0.0013177755754441023
      grad_gnorm: 0.0067564561031758785
      policy_entropy: 0.008133158087730408
      policy_loss: -1.7478865288467205e-07
      var_gnorm: 30.242319107055664
      vf_explained_var: 0.0
      vf_loss: 3.1369816611004353e-07
    num_steps_sampled: 636000
    num_steps_trained: 636000
    wait_time_ms: 33.192
  iterations_since_restore: 414
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 10879
  policy_reward_mean: {}
  time_since_restore: 3180.6604537963867
  time_this_iter_s: 8.581814050674438
  time_total_s: 3180.6604537963867
  timestamp: 1594148684
  timesteps_since_restore: 636000
  timesteps_this_iter: 2000
  timesteps_total: 636000
  training_iteration: 414
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10879], 3180 s, 414 iter, 636000 ts, 4.6 rew

agent-1: 1.0
Sum Reward: 1.0
Avg Reward: 1.0
Min Reward: 1.0
Max Reward: 1.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
agent-1: 0.0
Sum Reward: 0.0
Avg Reward: 0.0
Min Reward: 0.0
Max Reward: 0.0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_15-04-53
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 22.0
  episode_reward_mean: 4.61
  episode_reward_min: 0.0
  episodes_this_iter: 2
  episodes_total: 637
  experiment_id: cb3a18e0a26e466496590bc0542b68c4
  hostname: gpu020
  info:
    apply_time_ms: 2.684
    dispatch_time_ms: 8.624
    learner:
      cur_lr: 0.0013176423963159323
      grad_gnorm: 0.24796824157238007
      policy_entropy: 0.00861484557390213
      policy_loss: -6.464596481237095e-06
      var_gnorm: 30.242063522338867
      vf_explained_var: 0.0
      vf_loss: 0.0004221789422444999
    num_steps_sampled: 638000
    num_steps_trained: 638000
    wait_time_ms: 33.109
  iterations_since_restore: 415
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 10879
  policy_reward_mean: {}
  time_since_restore: 3189.2395136356354
  time_this_iter_s: 8.579059839248657
  time_total_s: 3189.2395136356354
  timestamp: 1594148693
  timesteps_since_restore: 638000
  timesteps_this_iter: 2000
  timesteps_total: 638000
  training_iteration: 415
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10879], 3189 s, 415 iter, 638000 ts, 4.61 rew

agent-1: 0.0
Sum Reward: 0.0
Avg Reward: 0.0
Min Reward: 0.0
Max Reward: 0.0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
agent-1: 3.0
Sum Reward: 3.0
Avg Reward: 3.0
Min Reward: 3.0
Max Reward: 3.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_15-05-01
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 22.0
  episode_reward_mean: 4.64
  episode_reward_min: 0.0
  episodes_this_iter: 2
  episodes_total: 639
  experiment_id: cb3a18e0a26e466496590bc0542b68c4
  hostname: gpu020
  info:
    apply_time_ms: 2.906
    dispatch_time_ms: 7.343
    learner:
      cur_lr: 0.0013175092171877623
      grad_gnorm: 0.0033177712466567755
      policy_entropy: 0.008692389354109764
      policy_loss: -1.1060967608500505e-07
      var_gnorm: 30.24323081970215
      vf_explained_var: 0.0
      vf_loss: 7.556567993560748e-08
    num_steps_sampled: 640000
    num_steps_trained: 640000
    wait_time_ms: 34.02
  iterations_since_restore: 416
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 10879
  policy_reward_mean: {}
  time_since_restore: 3197.8642525672913
  time_this_iter_s: 8.624738931655884
  time_total_s: 3197.8642525672913
  timestamp: 1594148701
  timesteps_since_restore: 640000
  timesteps_this_iter: 2000
  timesteps_total: 640000
  training_iteration: 416
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10879], 3197 s, 416 iter, 640000 ts, 4.64 rew

agent-1: 0.0
Sum Reward: 0.0
Avg Reward: 0.0
Min Reward: 0.0
Max Reward: 0.0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
agent-1: 0.0
Sum Reward: 0.0
Avg Reward: 0.0
Min Reward: 0.0
Max Reward: 0.0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_15-05-10
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 22.0
  episode_reward_mean: 4.64
  episode_reward_min: 0.0
  episodes_this_iter: 2
  episodes_total: 641
  experiment_id: cb3a18e0a26e466496590bc0542b68c4
  hostname: gpu020
  info:
    apply_time_ms: 2.834
    dispatch_time_ms: 5.769
    learner:
      cur_lr: 0.0013173760380595922
      grad_gnorm: 0.0035736942663788795
      policy_entropy: 0.012331889010965824
      policy_loss: 1.805027665113812e-07
      var_gnorm: 30.24301528930664
      vf_explained_var: 0.0
      vf_loss: 8.77386341358033e-08
    num_steps_sampled: 642000
    num_steps_trained: 642000
    wait_time_ms: 33.493
  iterations_since_restore: 417
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 10879
  policy_reward_mean: {}
  time_since_restore: 3206.4518830776215
  time_this_iter_s: 8.5876305103302
  time_total_s: 3206.4518830776215
  timestamp: 1594148710
  timesteps_since_restore: 642000
  timesteps_this_iter: 2000
  timesteps_total: 642000
  training_iteration: 417
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10879], 3206 s, 417 iter, 642000 ts, 4.64 rew

agent-1: 0.0
Sum Reward: 0.0
Avg Reward: 0.0
Min Reward: 0.0
Max Reward: 0.0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
agent-1: 0.0
Sum Reward: 0.0
Avg Reward: 0.0
Min Reward: 0.0
Max Reward: 0.0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_15-05-19
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 22.0
  episode_reward_mean: 4.56
  episode_reward_min: 0.0
  episodes_this_iter: 2
  episodes_total: 643
  experiment_id: cb3a18e0a26e466496590bc0542b68c4
  hostname: gpu020
  info:
    apply_time_ms: 3.435
    dispatch_time_ms: 7.749
    learner:
      cur_lr: 0.0013172427425161004
      grad_gnorm: 0.8098281025886536
      policy_entropy: 0.00389015581458807
      policy_loss: -1.1219486623303965e-05
      var_gnorm: 30.242660522460938
      vf_explained_var: 0.0
      vf_loss: 0.004502886440604925
    num_steps_sampled: 644000
    num_steps_trained: 644000
    wait_time_ms: 30.013
  iterations_since_restore: 418
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 10879
  policy_reward_mean: {}
  time_since_restore: 3215.0792253017426
  time_this_iter_s: 8.627342224121094
  time_total_s: 3215.0792253017426
  timestamp: 1594148719
  timesteps_since_restore: 644000
  timesteps_this_iter: 2000
  timesteps_total: 644000
  training_iteration: 418
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10879], 3215 s, 418 iter, 644000 ts, 4.56 rew

agent-1: 0.0
Sum Reward: 0.0
Avg Reward: 0.0
Min Reward: 0.0
Max Reward: 0.0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
agent-1: 12.0
Sum Reward: 12.0
Avg Reward: 12.0
Min Reward: 12.0
Max Reward: 12.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_15-05-27
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 22.0
  episode_reward_mean: 4.68
  episode_reward_min: 0.0
  episodes_this_iter: 2
  episodes_total: 645
  experiment_id: cb3a18e0a26e466496590bc0542b68c4
  hostname: gpu020
  info:
    apply_time_ms: 3.603
    dispatch_time_ms: 8.034
    learner:
      cur_lr: 0.0013171095633879304
      grad_gnorm: 0.007514539174735546
      policy_entropy: 0.005030994303524494
      policy_loss: 1.357798993240067e-07
      var_gnorm: 30.242172241210938
      vf_explained_var: 0.0
      vf_loss: 3.878629684095358e-07
    num_steps_sampled: 646000
    num_steps_trained: 646000
    wait_time_ms: 31.304
  iterations_since_restore: 419
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 10879
  policy_reward_mean: {}
  time_since_restore: 3223.642693758011
  time_this_iter_s: 8.56346845626831
  time_total_s: 3223.642693758011
  timestamp: 1594148727
  timesteps_since_restore: 646000
  timesteps_this_iter: 2000
  timesteps_total: 646000
  training_iteration: 419
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10879], 3223 s, 419 iter, 646000 ts, 4.68 rew

agent-1: 2.0
Sum Reward: 2.0
Avg Reward: 2.0
Min Reward: 2.0
Max Reward: 2.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
agent-1: 0.0
Sum Reward: 0.0
Avg Reward: 0.0
Min Reward: 0.0
Max Reward: 0.0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_15-05-37
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 22.0
  episode_reward_mean: 4.5
  episode_reward_min: 0.0
  episodes_this_iter: 2
  episodes_total: 647
  experiment_id: cb3a18e0a26e466496590bc0542b68c4
  hostname: gpu020
  info:
    apply_time_ms: 2.765
    dispatch_time_ms: 29.757
    learner:
      cur_lr: 0.0013169763842597604
      grad_gnorm: 3.2433013916015625
      policy_entropy: 0.00021100035519339144
      policy_loss: -8.524815484634019e-07
      var_gnorm: 30.26183319091797
      vf_explained_var: 0.0
      vf_loss: 0.0618818923830986
    num_steps_sampled: 648000
    num_steps_trained: 648000
    wait_time_ms: 25.489
  iterations_since_restore: 420
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 10879
  policy_reward_mean: {}
  time_since_restore: 3233.7598860263824
  time_this_iter_s: 10.117192268371582
  time_total_s: 3233.7598860263824
  timestamp: 1594148737
  timesteps_since_restore: 648000
  timesteps_this_iter: 2000
  timesteps_total: 648000
  training_iteration: 420
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10879], 3233 s, 420 iter, 648000 ts, 4.5 rew

agent-1: 9.0
Sum Reward: 9.0
Avg Reward: 9.0
Min Reward: 9.0
Max Reward: 9.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_15-05-44
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 22.0
  episode_reward_mean: 4.58
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 648
  experiment_id: cb3a18e0a26e466496590bc0542b68c4
  hostname: gpu020
  info:
    apply_time_ms: 2.71
    dispatch_time_ms: 35.667
    learner:
      cur_lr: 0.0013168432051315904
      grad_gnorm: 2.725743532180786
      policy_entropy: 0.00016113257152028382
      policy_loss: -4.3609975364233833e-07
      var_gnorm: 30.26473617553711
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 0.04258633404970169
    num_steps_sampled: 649000
    num_steps_trained: 649000
    wait_time_ms: 24.502
  iterations_since_restore: 421
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 10879
  policy_reward_mean: {}
  time_since_restore: 3239.828788995743
  time_this_iter_s: 6.068902969360352
  time_total_s: 3239.828788995743
  timestamp: 1594148744
  timesteps_since_restore: 649000
  timesteps_this_iter: 1000
  timesteps_total: 649000
  training_iteration: 421
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10879], 3239 s, 421 iter, 649000 ts, 4.58 rew

agent-1: 20.0
Sum Reward: 20.0
Avg Reward: 20.0
Min Reward: 20.0
Max Reward: 20.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_15-05-49
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 22.0
  episode_reward_mean: 4.75
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 649
  experiment_id: cb3a18e0a26e466496590bc0542b68c4
  hostname: gpu020
  info:
    apply_time_ms: 2.645
    dispatch_time_ms: 32.808
    learner:
      cur_lr: 0.0013167766155675054
      grad_gnorm: 0.22004354000091553
      policy_entropy: 0.00016309667262248695
      policy_loss: -3.391996301616018e-07
      var_gnorm: 30.264869689941406
      vf_explained_var: 5.960464477539063e-08
      vf_loss: 0.001144462963566184
    num_steps_sampled: 650000
    num_steps_trained: 650000
    wait_time_ms: 34.713
  iterations_since_restore: 422
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 10879
  policy_reward_mean: {}
  time_since_restore: 3245.7219698429108
  time_this_iter_s: 5.893180847167969
  time_total_s: 3245.7219698429108
  timestamp: 1594148749
  timesteps_since_restore: 650000
  timesteps_this_iter: 1000
  timesteps_total: 650000
  training_iteration: 422
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10879], 3245 s, 422 iter, 650000 ts, 4.75 rew

agent-1: 2.0
Sum Reward: 2.0
Avg Reward: 2.0
Min Reward: 2.0
Max Reward: 2.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_15-05-55
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 22.0
  episode_reward_mean: 4.77
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 650
  experiment_id: cb3a18e0a26e466496590bc0542b68c4
  hostname: gpu020
  info:
    apply_time_ms: 2.846
    dispatch_time_ms: 40.736
    learner:
      cur_lr: 0.0013167100260034204
      grad_gnorm: 18.34199333190918
      policy_entropy: 0.0001607607409823686
      policy_loss: -2.2008939026818553e-07
      var_gnorm: 30.264673233032227
      vf_explained_var: 0.0
      vf_loss: 1.8355140686035156
    num_steps_sampled: 651000
    num_steps_trained: 651000
    wait_time_ms: 18.21
  iterations_since_restore: 423
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 10879
  policy_reward_mean: {}
  time_since_restore: 3251.34863448143
  time_this_iter_s: 5.626664638519287
  time_total_s: 3251.34863448143
  timestamp: 1594148755
  timesteps_since_restore: 651000
  timesteps_this_iter: 1000
  timesteps_total: 651000
  training_iteration: 423
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10879], 3251 s, 423 iter, 651000 ts, 4.77 rew

agent-1: 2.0
Sum Reward: 2.0
Avg Reward: 2.0
Min Reward: 2.0
Max Reward: 2.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_15-06-01
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 22.0
  episode_reward_mean: 4.79
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 651
  experiment_id: cb3a18e0a26e466496590bc0542b68c4
  hostname: gpu020
  info:
    apply_time_ms: 2.492
    dispatch_time_ms: 37.923
    learner:
      cur_lr: 0.0013166434364393353
      grad_gnorm: 0.48778098821640015
      policy_entropy: 0.00015980799798853695
      policy_loss: -4.953453753842041e-07
      var_gnorm: 30.264650344848633
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 0.0040868367068469524
    num_steps_sampled: 652000
    num_steps_trained: 652000
    wait_time_ms: 47.07
  iterations_since_restore: 424
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 10879
  policy_reward_mean: {}
  time_since_restore: 3257.6425364017487
  time_this_iter_s: 6.2939019203186035
  time_total_s: 3257.6425364017487
  timestamp: 1594148761
  timesteps_since_restore: 652000
  timesteps_this_iter: 1000
  timesteps_total: 652000
  training_iteration: 424
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10879], 3257 s, 424 iter, 652000 ts, 4.79 rew

agent-1: 20.0
Sum Reward: 20.0
Avg Reward: 20.0
Min Reward: 20.0
Max Reward: 20.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_15-06-07
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 22.0
  episode_reward_mean: 4.87
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 652
  experiment_id: cb3a18e0a26e466496590bc0542b68c4
  hostname: gpu020
  info:
    apply_time_ms: 2.64
    dispatch_time_ms: 27.367
    learner:
      cur_lr: 0.0013165768468752503
      grad_gnorm: 1.0619165897369385
      policy_entropy: 0.00016320451686624438
      policy_loss: -3.111257740329165e-07
      var_gnorm: 30.26487159729004
      vf_explained_var: 0.0
      vf_loss: 0.007236800622195005
    num_steps_sampled: 653000
    num_steps_trained: 653000
    wait_time_ms: 25.413
  iterations_since_restore: 425
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 10879
  policy_reward_mean: {}
  time_since_restore: 3263.553409099579
  time_this_iter_s: 5.9108726978302
  time_total_s: 3263.553409099579
  timestamp: 1594148767
  timesteps_since_restore: 653000
  timesteps_this_iter: 1000
  timesteps_total: 653000
  training_iteration: 425
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10879], 3263 s, 425 iter, 653000 ts, 4.87 rew

agent-1: 14.0
Sum Reward: 14.0
Avg Reward: 14.0
Min Reward: 14.0
Max Reward: 14.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_15-06-13
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 22.0
  episode_reward_mean: 4.81
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 653
  experiment_id: cb3a18e0a26e466496590bc0542b68c4
  hostname: gpu020
  info:
    apply_time_ms: 3.303
    dispatch_time_ms: 36.334
    learner:
      cur_lr: 0.0013165102573111653
      grad_gnorm: 0.18533559143543243
      policy_entropy: 0.00016545626567676663
      policy_loss: -2.2274549849043979e-07
      var_gnorm: 30.265052795410156
      vf_explained_var: 0.0
      vf_loss: 0.000751520215999335
    num_steps_sampled: 654000
    num_steps_trained: 654000
    wait_time_ms: 13.048
  iterations_since_restore: 426
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 10879
  policy_reward_mean: {}
  time_since_restore: 3269.6696588993073
  time_this_iter_s: 6.1162497997283936
  time_total_s: 3269.6696588993073
  timestamp: 1594148773
  timesteps_since_restore: 654000
  timesteps_this_iter: 1000
  timesteps_total: 654000
  training_iteration: 426
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10879], 3269 s, 426 iter, 654000 ts, 4.81 rew

agent-1: 0.0
Sum Reward: 0.0
Avg Reward: 0.0
Min Reward: 0.0
Max Reward: 0.0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_15-06-19
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 20.0
  episode_reward_mean: 4.59
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 654
  experiment_id: cb3a18e0a26e466496590bc0542b68c4
  hostname: gpu020
  info:
    apply_time_ms: 3.57
    dispatch_time_ms: 37.017
    learner:
      cur_lr: 0.0013164435513317585
      grad_gnorm: 8.390416145324707
      policy_entropy: 0.00016316855908371508
      policy_loss: -5.673209102496912e-07
      var_gnorm: 30.308656692504883
      vf_explained_var: 0.0
      vf_loss: 0.38667696714401245
    num_steps_sampled: 655000
    num_steps_trained: 655000
    wait_time_ms: 17.07
  iterations_since_restore: 427
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 10879
  policy_reward_mean: {}
  time_since_restore: 3275.3457572460175
  time_this_iter_s: 5.676098346710205
  time_total_s: 3275.3457572460175
  timestamp: 1594148779
  timesteps_since_restore: 655000
  timesteps_this_iter: 1000
  timesteps_total: 655000
  training_iteration: 427
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10879], 3275 s, 427 iter, 655000 ts, 4.59 rew

agent-1: 1.0
Sum Reward: 1.0
Avg Reward: 1.0
Min Reward: 1.0
Max Reward: 1.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_15-06-25
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 20.0
  episode_reward_mean: 4.53
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 655
  experiment_id: cb3a18e0a26e466496590bc0542b68c4
  hostname: gpu020
  info:
    apply_time_ms: 2.624
    dispatch_time_ms: 34.308
    learner:
      cur_lr: 0.0013163769617676735
      grad_gnorm: 0.238755464553833
      policy_entropy: 0.00016620688256807625
      policy_loss: -2.6514598516769183e-07
      var_gnorm: 30.325927734375
      vf_explained_var: 0.0
      vf_loss: 0.0011101991403847933
    num_steps_sampled: 656000
    num_steps_trained: 656000
    wait_time_ms: 20.418
  iterations_since_restore: 428
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 10879
  policy_reward_mean: {}
  time_since_restore: 3280.9426922798157
  time_this_iter_s: 5.596935033798218
  time_total_s: 3280.9426922798157
  timestamp: 1594148785
  timesteps_since_restore: 656000
  timesteps_this_iter: 1000
  timesteps_total: 656000
  training_iteration: 428
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10879], 3280 s, 428 iter, 656000 ts, 4.53 rew

agent-1: 22.0
Sum Reward: 22.0
Avg Reward: 22.0
Min Reward: 22.0
Max Reward: 22.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_15-06-31
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 22.0
  episode_reward_mean: 4.7
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 656
  experiment_id: cb3a18e0a26e466496590bc0542b68c4
  hostname: gpu020
  info:
    apply_time_ms: 3.2
    dispatch_time_ms: 33.51
    learner:
      cur_lr: 0.0013163103722035885
      grad_gnorm: 0.04890744015574455
      policy_entropy: 0.00016910619160626084
      policy_loss: -1.8034501181318774e-07
      var_gnorm: 30.326190948486328
      vf_explained_var: 1.1920928955078125e-07
      vf_loss: 0.0003831498324871063
    num_steps_sampled: 657000
    num_steps_trained: 657000
    wait_time_ms: 18.449
  iterations_since_restore: 429
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 10879
  policy_reward_mean: {}
  time_since_restore: 3287.014725446701
  time_this_iter_s: 6.072033166885376
  time_total_s: 3287.014725446701
  timestamp: 1594148791
  timesteps_since_restore: 657000
  timesteps_this_iter: 1000
  timesteps_total: 657000
  training_iteration: 429
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10879], 3287 s, 429 iter, 657000 ts, 4.7 rew

agent-1: 1.0
Sum Reward: 1.0
Avg Reward: 1.0
Min Reward: 1.0
Max Reward: 1.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_15-06-38
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 22.0
  episode_reward_mean: 4.69
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 657
  experiment_id: cb3a18e0a26e466496590bc0542b68c4
  hostname: gpu020
  info:
    apply_time_ms: 3.844
    dispatch_time_ms: 27.92
    learner:
      cur_lr: 0.0013162437826395035
      grad_gnorm: 0.312539279460907
      policy_entropy: 0.00017117965035140514
      policy_loss: -1.6066303487605182e-07
      var_gnorm: 30.326480865478516
      vf_explained_var: 0.0
      vf_loss: 0.0008251981344074011
    num_steps_sampled: 658000
    num_steps_trained: 658000
    wait_time_ms: 14.574
  iterations_since_restore: 430
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 10879
  policy_reward_mean: {}
  time_since_restore: 3293.634487390518
  time_this_iter_s: 6.619761943817139
  time_total_s: 3293.634487390518
  timestamp: 1594148798
  timesteps_since_restore: 658000
  timesteps_this_iter: 1000
  timesteps_total: 658000
  training_iteration: 430
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10879], 3293 s, 430 iter, 658000 ts, 4.69 rew

agent-1: 1.0
Sum Reward: 1.0
Avg Reward: 1.0
Min Reward: 1.0
Max Reward: 1.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_15-06-43
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 22.0
  episode_reward_mean: 4.7
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 658
  experiment_id: cb3a18e0a26e466496590bc0542b68c4
  hostname: gpu020
  info:
    apply_time_ms: 2.885
    dispatch_time_ms: 45.726
    learner:
      cur_lr: 0.0013161771930754185
      grad_gnorm: 0.3660737872123718
      policy_entropy: 0.00017384700186084956
      policy_loss: -9.809325973719751e-08
      var_gnorm: 30.32672691345215
      vf_explained_var: 0.0
      vf_loss: 0.000838601088616997
    num_steps_sampled: 659000
    num_steps_trained: 659000
    wait_time_ms: 14.907
  iterations_since_restore: 431
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 10879
  policy_reward_mean: {}
  time_since_restore: 3299.4275839328766
  time_this_iter_s: 5.793096542358398
  time_total_s: 3299.4275839328766
  timestamp: 1594148803
  timesteps_since_restore: 659000
  timesteps_this_iter: 1000
  timesteps_total: 659000
  training_iteration: 431
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10879], 3299 s, 431 iter, 659000 ts, 4.7 rew

agent-1: 2.0
Sum Reward: 2.0
Avg Reward: 2.0
Min Reward: 2.0
Max Reward: 2.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_15-06-49
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 22.0
  episode_reward_mean: 4.71
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 659
  experiment_id: cb3a18e0a26e466496590bc0542b68c4
  hostname: gpu020
  info:
    apply_time_ms: 2.746
    dispatch_time_ms: 31.694
    learner:
      cur_lr: 0.0013161106035113335
      grad_gnorm: 1.8585565090179443
      policy_entropy: 0.0001743269240250811
      policy_loss: -1.6857438822626136e-07
      var_gnorm: 30.3270320892334
      vf_explained_var: 0.0
      vf_loss: 0.019116535782814026
    num_steps_sampled: 660000
    num_steps_trained: 660000
    wait_time_ms: 21.745
  iterations_since_restore: 432
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 10879
  policy_reward_mean: {}
  time_since_restore: 3305.3234989643097
  time_this_iter_s: 5.8959150314331055
  time_total_s: 3305.3234989643097
  timestamp: 1594148809
  timesteps_since_restore: 660000
  timesteps_this_iter: 1000
  timesteps_total: 660000
  training_iteration: 432
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10879], 3305 s, 432 iter, 660000 ts, 4.71 rew

agent-1: 0.0
Sum Reward: 0.0
Avg Reward: 0.0
Min Reward: 0.0
Max Reward: 0.0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_15-06-55
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 22.0
  episode_reward_mean: 4.71
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 660
  experiment_id: cb3a18e0a26e466496590bc0542b68c4
  hostname: gpu020
  info:
    apply_time_ms: 3.688
    dispatch_time_ms: 40.386
    learner:
      cur_lr: 0.0013160440139472485
      grad_gnorm: 0.5203749537467957
      policy_entropy: 0.00017865416884887964
      policy_loss: -1.1291547963310222e-07
      var_gnorm: 30.327287673950195
      vf_explained_var: 0.0
      vf_loss: 0.0015907927881926298
    num_steps_sampled: 661000
    num_steps_trained: 661000
    wait_time_ms: 21.63
  iterations_since_restore: 433
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 10879
  policy_reward_mean: {}
  time_since_restore: 3311.2972507476807
  time_this_iter_s: 5.973751783370972
  time_total_s: 3311.2972507476807
  timestamp: 1594148815
  timesteps_since_restore: 661000
  timesteps_this_iter: 1000
  timesteps_total: 661000
  training_iteration: 433
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10879], 3311 s, 433 iter, 661000 ts, 4.71 rew

agent-1: 7.0
Sum Reward: 7.0
Avg Reward: 7.0
Min Reward: 7.0
Max Reward: 7.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_15-07-01
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 22.0
  episode_reward_mean: 4.78
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 661
  experiment_id: cb3a18e0a26e466496590bc0542b68c4
  hostname: gpu020
  info:
    apply_time_ms: 2.512
    dispatch_time_ms: 31.829
    learner:
      cur_lr: 0.0013159774243831635
      grad_gnorm: 0.09883344173431396
      policy_entropy: 0.0001812108384910971
      policy_loss: -7.174616456495642e-08
      var_gnorm: 30.327499389648438
      vf_explained_var: 0.0
      vf_loss: 9.622414654586464e-05
    num_steps_sampled: 662000
    num_steps_trained: 662000
    wait_time_ms: 30.018
  iterations_since_restore: 434
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 10879
  policy_reward_mean: {}
  time_since_restore: 3317.070112466812
  time_this_iter_s: 5.77286171913147
  time_total_s: 3317.070112466812
  timestamp: 1594148821
  timesteps_since_restore: 662000
  timesteps_this_iter: 1000
  timesteps_total: 662000
  training_iteration: 434
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10879], 3317 s, 434 iter, 662000 ts, 4.78 rew

agent-1: 0.0
Sum Reward: 0.0
Avg Reward: 0.0
Min Reward: 0.0
Max Reward: 0.0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_15-07-16
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 22.0
  episode_reward_mean: 4.58
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 662
  experiment_id: cb3a18e0a26e466496590bc0542b68c4
  hostname: gpu020
  info:
    apply_time_ms: 3.487
    dispatch_time_ms: 7.638
    learner:
      cur_lr: 0.0013159108348190784
      grad_gnorm: 1.6389578580856323
      policy_entropy: 0.0001811600086512044
      policy_loss: -6.558005907209008e-07
      var_gnorm: 30.455211639404297
      vf_explained_var: 0.0
      vf_loss: 0.018443390727043152
    num_steps_sampled: 663000
    num_steps_trained: 663000
    wait_time_ms: 30.54
  iterations_since_restore: 435
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 10879
  policy_reward_mean: {}
  time_since_restore: 3331.5806839466095
  time_this_iter_s: 14.510571479797363
  time_total_s: 3331.5806839466095
  timestamp: 1594148836
  timesteps_since_restore: 663000
  timesteps_this_iter: 1000
  timesteps_total: 663000
  training_iteration: 435
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10879], 3331 s, 435 iter, 663000 ts, 4.58 rew

agent-1: 0.0
Sum Reward: 0.0
Avg Reward: 0.0
Min Reward: 0.0
Max Reward: 0.0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
agent-1: 12.0
Sum Reward: 12.0
Avg Reward: 12.0
Min Reward: 12.0
Max Reward: 12.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_15-07-24
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 22.0
  episode_reward_mean: 4.69
  episode_reward_min: 0.0
  episodes_this_iter: 2
  episodes_total: 664
  experiment_id: cb3a18e0a26e466496590bc0542b68c4
  hostname: gpu020
  info:
    apply_time_ms: 5.227
    dispatch_time_ms: 7.692
    learner:
      cur_lr: 0.0013158442452549934
      grad_gnorm: 0.5631378889083862
      policy_entropy: 0.000185552125913091
      policy_loss: -2.2278643996287428e-07
      var_gnorm: 30.476943969726562
      vf_explained_var: 0.0
      vf_loss: 0.0021773725748062134
    num_steps_sampled: 665000
    num_steps_trained: 665000
    wait_time_ms: 28.1
  iterations_since_restore: 436
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 10879
  policy_reward_mean: {}
  time_since_restore: 3340.154112815857
  time_this_iter_s: 8.573428869247437
  time_total_s: 3340.154112815857
  timestamp: 1594148844
  timesteps_since_restore: 665000
  timesteps_this_iter: 2000
  timesteps_total: 665000
  training_iteration: 436
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10879], 3340 s, 436 iter, 665000 ts, 4.69 rew

agent-1: 4.0
Sum Reward: 4.0
Avg Reward: 4.0
Min Reward: 4.0
Max Reward: 4.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
agent-1: 4.0
Sum Reward: 4.0
Avg Reward: 4.0
Min Reward: 4.0
Max Reward: 4.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_15-07-33
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 22.0
  episode_reward_mean: 4.62
  episode_reward_min: 0.0
  episodes_this_iter: 2
  episodes_total: 666
  experiment_id: cb3a18e0a26e466496590bc0542b68c4
  hostname: gpu020
  info:
    apply_time_ms: 3.554
    dispatch_time_ms: 6.612
    learner:
      cur_lr: 0.0013157109497115016
      grad_gnorm: 1.7874020338058472
      policy_entropy: 0.00018235981406178325
      policy_loss: -6.540471986227203e-07
      var_gnorm: 30.476871490478516
      vf_explained_var: 5.960464477539063e-08
      vf_loss: 0.021935535594820976
    num_steps_sampled: 667000
    num_steps_trained: 667000
    wait_time_ms: 37.335
  iterations_since_restore: 437
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 10879
  policy_reward_mean: {}
  time_since_restore: 3348.792502641678
  time_this_iter_s: 8.638389825820923
  time_total_s: 3348.792502641678
  timestamp: 1594148853
  timesteps_since_restore: 667000
  timesteps_this_iter: 2000
  timesteps_total: 667000
  training_iteration: 437
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10879], 3348 s, 437 iter, 667000 ts, 4.62 rew

agent-1: 0.0
Sum Reward: 0.0
Avg Reward: 0.0
Min Reward: 0.0
Max Reward: 0.0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
agent-1: 14.0
Sum Reward: 14.0
Avg Reward: 14.0
Min Reward: 14.0
Max Reward: 14.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_15-07-41
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 22.0
  episode_reward_mean: 4.58
  episode_reward_min: 0.0
  episodes_this_iter: 2
  episodes_total: 668
  experiment_id: cb3a18e0a26e466496590bc0542b68c4
  hostname: gpu020
  info:
    apply_time_ms: 2.73
    dispatch_time_ms: 6.081
    learner:
      cur_lr: 0.0013155777705833316
      grad_gnorm: 2.5154733657836914
      policy_entropy: 0.00017975848459172994
      policy_loss: -9.024117844091961e-07
      var_gnorm: 30.47730827331543
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 0.04344520345330238
    num_steps_sampled: 669000
    num_steps_trained: 669000
    wait_time_ms: 31.649
  iterations_since_restore: 438
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 10879
  policy_reward_mean: {}
  time_since_restore: 3357.3474173545837
  time_this_iter_s: 8.554914712905884
  time_total_s: 3357.3474173545837
  timestamp: 1594148861
  timesteps_since_restore: 669000
  timesteps_this_iter: 2000
  timesteps_total: 669000
  training_iteration: 438
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10879], 3357 s, 438 iter, 669000 ts, 4.58 rew

agent-1: 0.0
Sum Reward: 0.0
Avg Reward: 0.0
Min Reward: 0.0
Max Reward: 0.0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
agent-1: 19.0
Sum Reward: 19.0
Avg Reward: 19.0
Min Reward: 19.0
Max Reward: 19.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_15-07-50
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 22.0
  episode_reward_mean: 4.58
  episode_reward_min: 0.0
  episodes_this_iter: 2
  episodes_total: 670
  experiment_id: cb3a18e0a26e466496590bc0542b68c4
  hostname: gpu020
  info:
    apply_time_ms: 2.448
    dispatch_time_ms: 5.624
    learner:
      cur_lr: 0.0013154445914551616
      grad_gnorm: 1.0994977951049805
      policy_entropy: 0.00018518099386710674
      policy_loss: -4.338006647230941e-07
      var_gnorm: 30.477319717407227
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 0.008300299756228924
    num_steps_sampled: 671000
    num_steps_trained: 671000
    wait_time_ms: 34.477
  iterations_since_restore: 439
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 10879
  policy_reward_mean: {}
  time_since_restore: 3365.9685854911804
  time_this_iter_s: 8.62116813659668
  time_total_s: 3365.9685854911804
  timestamp: 1594148870
  timesteps_since_restore: 671000
  timesteps_this_iter: 2000
  timesteps_total: 671000
  training_iteration: 439
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10879], 3365 s, 439 iter, 671000 ts, 4.58 rew

agent-1: 12.0
Sum Reward: 12.0
Avg Reward: 12.0
Min Reward: 12.0
Max Reward: 12.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
agent-1: 9.0
Sum Reward: 9.0
Avg Reward: 9.0
Min Reward: 9.0
Max Reward: 9.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_15-07-59
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 22.0
  episode_reward_mean: 4.61
  episode_reward_min: 0.0
  episodes_this_iter: 2
  episodes_total: 672
  experiment_id: cb3a18e0a26e466496590bc0542b68c4
  hostname: gpu020
  info:
    apply_time_ms: 3.406
    dispatch_time_ms: 7.796
    learner:
      cur_lr: 0.0013153114123269916
      grad_gnorm: 2.0548996925354004
      policy_entropy: 0.015673592686653137
      policy_loss: -9.488596697337925e-05
      var_gnorm: 30.592683792114258
      vf_explained_var: 0.0
      vf_loss: 0.028542056679725647
    num_steps_sampled: 673000
    num_steps_trained: 673000
    wait_time_ms: 33.227
  iterations_since_restore: 440
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 10879
  policy_reward_mean: {}
  time_since_restore: 3374.6019234657288
  time_this_iter_s: 8.63333797454834
  time_total_s: 3374.6019234657288
  timestamp: 1594148879
  timesteps_since_restore: 673000
  timesteps_this_iter: 2000
  timesteps_total: 673000
  training_iteration: 440
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10879], 3374 s, 440 iter, 673000 ts, 4.61 rew

agent-1: 5.0
Sum Reward: 5.0
Avg Reward: 5.0
Min Reward: 5.0
Max Reward: 5.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
agent-1: 133.0
Sum Reward: 133.0
Avg Reward: 133.0
Min Reward: 133.0
Max Reward: 133.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_15-08-08
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 133.0
  episode_reward_mean: 5.99
  episode_reward_min: 0.0
  episodes_this_iter: 2
  episodes_total: 674
  experiment_id: cb3a18e0a26e466496590bc0542b68c4
  hostname: gpu020
  info:
    apply_time_ms: 2.581
    dispatch_time_ms: 5.769
    learner:
      cur_lr: 0.0013151782331988215
      grad_gnorm: 13.036805152893066
      policy_entropy: 1.5290894508361816
      policy_loss: -0.15727590024471283
      var_gnorm: 31.020051956176758
      vf_explained_var: 0.0
      vf_loss: 1.136642336845398
    num_steps_sampled: 675000
    num_steps_trained: 675000
    wait_time_ms: 35.426
  iterations_since_restore: 441
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 10879
  policy_reward_mean: {}
  time_since_restore: 3383.5023486614227
  time_this_iter_s: 8.90042519569397
  time_total_s: 3383.5023486614227
  timestamp: 1594148888
  timesteps_since_restore: 675000
  timesteps_this_iter: 2000
  timesteps_total: 675000
  training_iteration: 441
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10879], 3383 s, 441 iter, 675000 ts, 5.99 rew

agent-1: 90.0
Sum Reward: 90.0
Avg Reward: 90.0
Min Reward: 90.0
Max Reward: 90.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
agent-1: 151.0
Sum Reward: 151.0
Avg Reward: 151.0
Min Reward: 151.0
Max Reward: 151.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_15-08-18
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 151.0
  episode_reward_mean: 8.39
  episode_reward_min: 0.0
  episodes_this_iter: 2
  episodes_total: 676
  experiment_id: cb3a18e0a26e466496590bc0542b68c4
  hostname: gpu020
  info:
    apply_time_ms: 2.595
    dispatch_time_ms: 32.886
    learner:
      cur_lr: 0.0013150450540706515
      grad_gnorm: 39.830142974853516
      policy_entropy: 1.2995697259902954
      policy_loss: 2.555605411529541
      var_gnorm: 31.13646697998047
      vf_explained_var: 0.0
      vf_loss: 12.195777893066406
    num_steps_sampled: 677000
    num_steps_trained: 677000
    wait_time_ms: 20.208
  iterations_since_restore: 442
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 10879
  policy_reward_mean: {}
  time_since_restore: 3393.33207821846
  time_this_iter_s: 9.829729557037354
  time_total_s: 3393.33207821846
  timestamp: 1594148898
  timesteps_since_restore: 677000
  timesteps_this_iter: 2000
  timesteps_total: 677000
  training_iteration: 442
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10879], 3393 s, 442 iter, 677000 ts, 8.39 rew

agent-1: 155.0
Sum Reward: 155.0
Avg Reward: 155.0
Min Reward: 155.0
Max Reward: 155.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_15-08-23
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 155.0
  episode_reward_mean: 9.93
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 677
  experiment_id: cb3a18e0a26e466496590bc0542b68c4
  hostname: gpu020
  info:
    apply_time_ms: 3.703
    dispatch_time_ms: 30.559
    learner:
      cur_lr: 0.0013149117585271597
      grad_gnorm: 13.942632675170898
      policy_entropy: 1.9251149892807007
      policy_loss: 1.0438634157180786
      var_gnorm: 31.14533042907715
      vf_explained_var: 5.960464477539063e-08
      vf_loss: 1.5136988162994385
    num_steps_sampled: 678000
    num_steps_trained: 678000
    wait_time_ms: 15.313
  iterations_since_restore: 443
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 10879
  policy_reward_mean: {}
  time_since_restore: 3399.1854231357574
  time_this_iter_s: 5.853344917297363
  time_total_s: 3399.1854231357574
  timestamp: 1594148903
  timesteps_since_restore: 678000
  timesteps_this_iter: 1000
  timesteps_total: 678000
  training_iteration: 443
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10879], 3399 s, 443 iter, 678000 ts, 9.93 rew

agent-1: 231.0
Sum Reward: 231.0
Avg Reward: 231.0
Min Reward: 231.0
Max Reward: 231.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_15-08-29
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 231.0
  episode_reward_mean: 12.24
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 678
  experiment_id: cb3a18e0a26e466496590bc0542b68c4
  hostname: gpu020
  info:
    apply_time_ms: 2.799
    dispatch_time_ms: 33.23
    learner:
      cur_lr: 0.0013148451689630747
      grad_gnorm: 32.10441207885742
      policy_entropy: 0.5742141604423523
      policy_loss: 0.14058849215507507
      var_gnorm: 31.184228897094727
      vf_explained_var: 0.0
      vf_loss: 10.585587501525879
    num_steps_sampled: 679000
    num_steps_trained: 679000
    wait_time_ms: 27.384
  iterations_since_restore: 444
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 10879
  policy_reward_mean: {}
  time_since_restore: 3405.143080472946
  time_this_iter_s: 5.957657337188721
  time_total_s: 3405.143080472946
  timestamp: 1594148909
  timesteps_since_restore: 679000
  timesteps_this_iter: 1000
  timesteps_total: 679000
  training_iteration: 444
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10879], 3405 s, 444 iter, 679000 ts, 12.2 rew

agent-1: 190.0
Sum Reward: 190.0
Avg Reward: 190.0
Min Reward: 190.0
Max Reward: 190.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_15-08-36
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 231.0
  episode_reward_mean: 14.1
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 679
  experiment_id: cb3a18e0a26e466496590bc0542b68c4
  hostname: gpu020
  info:
    apply_time_ms: 3.011
    dispatch_time_ms: 45.581
    learner:
      cur_lr: 0.0013147785793989897
      grad_gnorm: 26.57575225830078
      policy_entropy: 1.014155626296997
      policy_loss: 0.27949556708335876
      var_gnorm: 31.302160263061523
      vf_explained_var: 0.0
      vf_loss: 9.86501693725586
    num_steps_sampled: 680000
    num_steps_trained: 680000
    wait_time_ms: 17.954
  iterations_since_restore: 445
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 10879
  policy_reward_mean: {}
  time_since_restore: 3411.8586463928223
  time_this_iter_s: 6.715565919876099
  time_total_s: 3411.8586463928223
  timestamp: 1594148916
  timesteps_since_restore: 680000
  timesteps_this_iter: 1000
  timesteps_total: 680000
  training_iteration: 445
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10879], 3411 s, 445 iter, 680000 ts, 14.1 rew

agent-1: 337.0
Sum Reward: 337.0
Avg Reward: 337.0
Min Reward: 337.0
Max Reward: 337.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_15-08-42
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 337.0
  episode_reward_mean: 17.33
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 680
  experiment_id: cb3a18e0a26e466496590bc0542b68c4
  hostname: gpu020
  info:
    apply_time_ms: 2.772
    dispatch_time_ms: 44.032
    learner:
      cur_lr: 0.0013147119898349047
      grad_gnorm: 17.3942928314209
      policy_entropy: 5.73398494720459
      policy_loss: 2.816239833831787
      var_gnorm: 31.426177978515625
      vf_explained_var: 0.42642897367477417
      vf_loss: 2.9618704319000244
    num_steps_sampled: 681000
    num_steps_trained: 681000
    wait_time_ms: 15.6
  iterations_since_restore: 446
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 10879
  policy_reward_mean: {}
  time_since_restore: 3417.4567692279816
  time_this_iter_s: 5.598122835159302
  time_total_s: 3417.4567692279816
  timestamp: 1594148922
  timesteps_since_restore: 681000
  timesteps_this_iter: 1000
  timesteps_total: 681000
  training_iteration: 446
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10879], 3417 s, 446 iter, 681000 ts, 17.3 rew

agent-1: 385.0
Sum Reward: 385.0
Avg Reward: 385.0
Min Reward: 385.0
Max Reward: 385.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_15-08-48
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 385.0
  episode_reward_mean: 21.18
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 681
  experiment_id: cb3a18e0a26e466496590bc0542b68c4
  hostname: gpu020
  info:
    apply_time_ms: 4.22
    dispatch_time_ms: 42.15
    learner:
      cur_lr: 0.0013146454002708197
      grad_gnorm: 21.486425399780273
      policy_entropy: 1.553215742111206
      policy_loss: -3.251671075820923
      var_gnorm: 31.485563278198242
      vf_explained_var: 0.0
      vf_loss: 3.283355474472046
    num_steps_sampled: 682000
    num_steps_trained: 682000
    wait_time_ms: 16.098
  iterations_since_restore: 447
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 10879
  policy_reward_mean: {}
  time_since_restore: 3423.8006048202515
  time_this_iter_s: 6.3438355922698975
  time_total_s: 3423.8006048202515
  timestamp: 1594148928
  timesteps_since_restore: 682000
  timesteps_this_iter: 1000
  timesteps_total: 682000
  training_iteration: 447
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10879], 3423 s, 447 iter, 682000 ts, 21.2 rew

agent-1: 348.0
Sum Reward: 348.0
Avg Reward: 348.0
Min Reward: 348.0
Max Reward: 348.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_15-08-54
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 385.0
  episode_reward_mean: 24.47
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 682
  experiment_id: cb3a18e0a26e466496590bc0542b68c4
  hostname: gpu020
  info:
    apply_time_ms: 3.056
    dispatch_time_ms: 27.89
    learner:
      cur_lr: 0.0013145788107067347
      grad_gnorm: 7.31201171875
      policy_entropy: 1.7511181831359863
      policy_loss: 1.1988260746002197
      var_gnorm: 31.558692932128906
      vf_explained_var: -0.866045355796814
      vf_loss: 1.2219170331954956
    num_steps_sampled: 683000
    num_steps_trained: 683000
    wait_time_ms: 29.648
  iterations_since_restore: 448
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 10879
  policy_reward_mean: {}
  time_since_restore: 3429.913758277893
  time_this_iter_s: 6.113153457641602
  time_total_s: 3429.913758277893
  timestamp: 1594148934
  timesteps_since_restore: 683000
  timesteps_this_iter: 1000
  timesteps_total: 683000
  training_iteration: 448
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10879], 3429 s, 448 iter, 683000 ts, 24.5 rew

agent-1: 386.0
Sum Reward: 386.0
Avg Reward: 386.0
Min Reward: 386.0
Max Reward: 386.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_15-09-00
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 386.0
  episode_reward_mean: 28.33
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 683
  experiment_id: cb3a18e0a26e466496590bc0542b68c4
  hostname: gpu020
  info:
    apply_time_ms: 3.581
    dispatch_time_ms: 33.701
    learner:
      cur_lr: 0.0013145122211426497
      grad_gnorm: 4.499451160430908
      policy_entropy: 4.9762420654296875
      policy_loss: 0.9394874572753906
      var_gnorm: 31.678783416748047
      vf_explained_var: 0.7144355177879333
      vf_loss: 0.7521638870239258
    num_steps_sampled: 684000
    num_steps_trained: 684000
    wait_time_ms: 16.577
  iterations_since_restore: 449
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 10879
  policy_reward_mean: {}
  time_since_restore: 3435.947656393051
  time_this_iter_s: 6.033898115158081
  time_total_s: 3435.947656393051
  timestamp: 1594148940
  timesteps_since_restore: 684000
  timesteps_this_iter: 1000
  timesteps_total: 684000
  training_iteration: 449
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10879], 3435 s, 449 iter, 684000 ts, 28.3 rew

agent-1: 347.0
Sum Reward: 347.0
Avg Reward: 347.0
Min Reward: 347.0
Max Reward: 347.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_15-09-07
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 386.0
  episode_reward_mean: 31.75
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 684
  experiment_id: cb3a18e0a26e466496590bc0542b68c4
  hostname: gpu020
  info:
    apply_time_ms: 3.931
    dispatch_time_ms: 33.215
    learner:
      cur_lr: 0.0013144456315785646
      grad_gnorm: 40.000003814697266
      policy_entropy: 1.8566372394561768
      policy_loss: -4.728511333465576
      var_gnorm: 31.739286422729492
      vf_explained_var: 0.32691437005996704
      vf_loss: 13.082579612731934
    num_steps_sampled: 685000
    num_steps_trained: 685000
    wait_time_ms: 16.168
  iterations_since_restore: 450
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 10879
  policy_reward_mean: {}
  time_since_restore: 3442.096926212311
  time_this_iter_s: 6.1492698192596436
  time_total_s: 3442.096926212311
  timestamp: 1594148947
  timesteps_since_restore: 685000
  timesteps_this_iter: 1000
  timesteps_total: 685000
  training_iteration: 450
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10879], 3442 s, 450 iter, 685000 ts, 31.8 rew

agent-1: 349.0
Sum Reward: 349.0
Avg Reward: 349.0
Min Reward: 349.0
Max Reward: 349.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_15-09-13
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 386.0
  episode_reward_mean: 35.17
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 685
  experiment_id: cb3a18e0a26e466496590bc0542b68c4
  hostname: gpu020
  info:
    apply_time_ms: 3.178
    dispatch_time_ms: 30.386
    learner:
      cur_lr: 0.0013143790420144796
      grad_gnorm: 18.787677764892578
      policy_entropy: 1.7928053140640259
      policy_loss: 1.5612263679504395
      var_gnorm: 31.759178161621094
      vf_explained_var: 0.1904282569885254
      vf_loss: 4.061625957489014
    num_steps_sampled: 686000
    num_steps_trained: 686000
    wait_time_ms: 24.285
  iterations_since_restore: 451
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 10879
  policy_reward_mean: {}
  time_since_restore: 3448.0856580734253
  time_this_iter_s: 5.988731861114502
  time_total_s: 3448.0856580734253
  timestamp: 1594148953
  timesteps_since_restore: 686000
  timesteps_this_iter: 1000
  timesteps_total: 686000
  training_iteration: 451
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10879], 3448 s, 451 iter, 686000 ts, 35.2 rew

agent-1: 282.0
Sum Reward: 282.0
Avg Reward: 282.0
Min Reward: 282.0
Max Reward: 282.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_15-09-18
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 386.0
  episode_reward_mean: 37.99
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 686
  experiment_id: cb3a18e0a26e466496590bc0542b68c4
  hostname: gpu020
  info:
    apply_time_ms: 3.021
    dispatch_time_ms: 8.302
    learner:
      cur_lr: 0.0013143124524503946
      grad_gnorm: 19.066640853881836
      policy_entropy: 4.438735485076904
      policy_loss: -1.5312957763671875
      var_gnorm: 31.792463302612305
      vf_explained_var: 0.4763107895851135
      vf_loss: 2.496976137161255
    num_steps_sampled: 687000
    num_steps_trained: 687000
    wait_time_ms: 34.075
  iterations_since_restore: 452
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 10879
  policy_reward_mean: {}
  time_since_restore: 3453.2348606586456
  time_this_iter_s: 5.149202585220337
  time_total_s: 3453.2348606586456
  timestamp: 1594148958
  timesteps_since_restore: 687000
  timesteps_this_iter: 1000
  timesteps_total: 687000
  training_iteration: 452
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10879], 3453 s, 452 iter, 687000 ts, 38 rew

agent-1: 325.0
Sum Reward: 325.0
Avg Reward: 325.0
Min Reward: 325.0
Max Reward: 325.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
agent-1: 361.0
Sum Reward: 361.0
Avg Reward: 361.0
Min Reward: 361.0
Max Reward: 361.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_15-09-27
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 386.0
  episode_reward_mean: 44.77
  episode_reward_min: 0.0
  episodes_this_iter: 2
  episodes_total: 688
  experiment_id: cb3a18e0a26e466496590bc0542b68c4
  hostname: gpu020
  info:
    apply_time_ms: 2.457
    dispatch_time_ms: 6.259
    learner:
      cur_lr: 0.0013142457464709878
      grad_gnorm: 40.0
      policy_entropy: 4.248025417327881
      policy_loss: 11.3408842086792
      var_gnorm: 31.95556640625
      vf_explained_var: -0.8911275863647461
      vf_loss: 21.145658493041992
    num_steps_sampled: 689000
    num_steps_trained: 689000
    wait_time_ms: 36.423
  iterations_since_restore: 453
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 10879
  policy_reward_mean: {}
  time_since_restore: 3462.6645307540894
  time_this_iter_s: 9.429670095443726
  time_total_s: 3462.6645307540894
  timestamp: 1594148967
  timesteps_since_restore: 689000
  timesteps_this_iter: 2000
  timesteps_total: 689000
  training_iteration: 453
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10879], 3462 s, 453 iter, 689000 ts, 44.8 rew

agent-1: 349.0
Sum Reward: 349.0
Avg Reward: 349.0
Min Reward: 349.0
Max Reward: 349.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
agent-1: 388.0
Sum Reward: 388.0
Avg Reward: 388.0
Min Reward: 388.0
Max Reward: 388.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_15-09-37
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 388.0
  episode_reward_mean: 52.01
  episode_reward_min: 0.0
  episodes_this_iter: 2
  episodes_total: 690
  experiment_id: cb3a18e0a26e466496590bc0542b68c4
  hostname: gpu020
  info:
    apply_time_ms: 2.573
    dispatch_time_ms: 7.097
    learner:
      cur_lr: 0.0013141125673428178
      grad_gnorm: 15.413743019104004
      policy_entropy: 0.6768314838409424
      policy_loss: 0.06742465496063232
      var_gnorm: 32.091224670410156
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 3.541691780090332
    num_steps_sampled: 691000
    num_steps_trained: 691000
    wait_time_ms: 34.845
  iterations_since_restore: 454
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 10879
  policy_reward_mean: {}
  time_since_restore: 3472.229564666748
  time_this_iter_s: 9.565033912658691
  time_total_s: 3472.229564666748
  timestamp: 1594148977
  timesteps_since_restore: 691000
  timesteps_this_iter: 2000
  timesteps_total: 691000
  training_iteration: 454
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10879], 3472 s, 454 iter, 691000 ts, 52 rew

agent-1: 348.0
Sum Reward: 348.0
Avg Reward: 348.0
Min Reward: 348.0
Max Reward: 348.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
agent-1: 381.0
Sum Reward: 381.0
Avg Reward: 381.0
Min Reward: 381.0
Max Reward: 381.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_15-09-46
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 388.0
  episode_reward_mean: 59.3
  episode_reward_min: 0.0
  episodes_this_iter: 2
  episodes_total: 692
  experiment_id: cb3a18e0a26e466496590bc0542b68c4
  hostname: gpu020
  info:
    apply_time_ms: 3.332
    dispatch_time_ms: 7.69
    learner:
      cur_lr: 0.0013139793882146478
      grad_gnorm: 39.999996185302734
      policy_entropy: 0.858185887336731
      policy_loss: -10.462116241455078
      var_gnorm: 32.20417022705078
      vf_explained_var: 0.0
      vf_loss: 14.047928810119629
    num_steps_sampled: 693000
    num_steps_trained: 693000
    wait_time_ms: 34.941
  iterations_since_restore: 455
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 10879
  policy_reward_mean: {}
  time_since_restore: 3481.5638217926025
  time_this_iter_s: 9.334257125854492
  time_total_s: 3481.5638217926025
  timestamp: 1594148986
  timesteps_since_restore: 693000
  timesteps_this_iter: 2000
  timesteps_total: 693000
  training_iteration: 455
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10879], 3481 s, 455 iter, 693000 ts, 59.3 rew

agent-1: 393.0
Sum Reward: 393.0
Avg Reward: 393.0
Min Reward: 393.0
Max Reward: 393.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
agent-1: 376.0
Sum Reward: 376.0
Avg Reward: 376.0
Min Reward: 376.0
Max Reward: 376.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_15-09-56
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 393.0
  episode_reward_mean: 66.93
  episode_reward_min: 0.0
  episodes_this_iter: 2
  episodes_total: 694
  experiment_id: cb3a18e0a26e466496590bc0542b68c4
  hostname: gpu020
  info:
    apply_time_ms: 3.887
    dispatch_time_ms: 6.465
    learner:
      cur_lr: 0.0013138462090864778
      grad_gnorm: 16.903467178344727
      policy_entropy: 0.5214539766311646
      policy_loss: 0.05266045778989792
      var_gnorm: 32.26960754394531
      vf_explained_var: 0.0
      vf_loss: 3.321331024169922
    num_steps_sampled: 695000
    num_steps_trained: 695000
    wait_time_ms: 37.42
  iterations_since_restore: 456
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 10879
  policy_reward_mean: {}
  time_since_restore: 3491.033254623413
  time_this_iter_s: 9.469432830810547
  time_total_s: 3491.033254623413
  timestamp: 1594148996
  timesteps_since_restore: 695000
  timesteps_this_iter: 2000
  timesteps_total: 695000
  training_iteration: 456
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10879], 3491 s, 456 iter, 695000 ts, 66.9 rew

agent-1: 362.0
Sum Reward: 362.0
Avg Reward: 362.0
Min Reward: 362.0
Max Reward: 362.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
agent-1: 357.0
Sum Reward: 357.0
Avg Reward: 357.0
Min Reward: 357.0
Max Reward: 357.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_15-10-06
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 393.0
  episode_reward_mean: 74.12
  episode_reward_min: 0.0
  episodes_this_iter: 2
  episodes_total: 696
  experiment_id: cb3a18e0a26e466496590bc0542b68c4
  hostname: gpu020
  info:
    apply_time_ms: 2.766
    dispatch_time_ms: 7.002
    learner:
      cur_lr: 0.0013137130299583077
      grad_gnorm: 39.999996185302734
      policy_entropy: 1.4022904634475708
      policy_loss: 19.66561508178711
      var_gnorm: 32.31888198852539
      vf_explained_var: -1.0
      vf_loss: 20.653419494628906
    num_steps_sampled: 697000
    num_steps_trained: 697000
    wait_time_ms: 37.668
  iterations_since_restore: 457
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 10879
  policy_reward_mean: {}
  time_since_restore: 3500.8950564861298
  time_this_iter_s: 9.861801862716675
  time_total_s: 3500.8950564861298
  timestamp: 1594149006
  timesteps_since_restore: 697000
  timesteps_this_iter: 2000
  timesteps_total: 697000
  training_iteration: 457
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10879], 3500 s, 457 iter, 697000 ts, 74.1 rew

agent-1: 404.0
Sum Reward: 404.0
Avg Reward: 404.0
Min Reward: 404.0
Max Reward: 404.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
agent-1: 357.0
Sum Reward: 357.0
Avg Reward: 357.0
Min Reward: 357.0
Max Reward: 357.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_15-10-15
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 404.0
  episode_reward_mean: 81.52
  episode_reward_min: 0.0
  episodes_this_iter: 2
  episodes_total: 698
  experiment_id: cb3a18e0a26e466496590bc0542b68c4
  hostname: gpu020
  info:
    apply_time_ms: 2.819
    dispatch_time_ms: 8.161
    learner:
      cur_lr: 0.0013135798508301377
      grad_gnorm: 15.803138732910156
      policy_entropy: 0.8469294309616089
      policy_loss: 0.08915083110332489
      var_gnorm: 32.355499267578125
      vf_explained_var: -2.384185791015625e-07
      vf_loss: 3.044191598892212
    num_steps_sampled: 699000
    num_steps_trained: 699000
    wait_time_ms: 35.424
  iterations_since_restore: 458
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 10879
  policy_reward_mean: {}
  time_since_restore: 3510.288293838501
  time_this_iter_s: 9.393237352371216
  time_total_s: 3510.288293838501
  timestamp: 1594149015
  timesteps_since_restore: 699000
  timesteps_this_iter: 2000
  timesteps_total: 699000
  training_iteration: 458
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10879], 3510 s, 458 iter, 699000 ts, 81.5 rew

agent-1: 385.0
Sum Reward: 385.0
Avg Reward: 385.0
Min Reward: 385.0
Max Reward: 385.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
agent-1: 372.0
Sum Reward: 372.0
Avg Reward: 372.0
Min Reward: 372.0
Max Reward: 372.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
agent-1: 374.0
Sum Reward: 374.0
Avg Reward: 374.0
Min Reward: 374.0
Max Reward: 374.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_15-10-25
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 404.0
  episode_reward_mean: 92.63
  episode_reward_min: 0.0
  episodes_this_iter: 3
  episodes_total: 701
  experiment_id: cb3a18e0a26e466496590bc0542b68c4
  hostname: gpu020
  info:
    apply_time_ms: 2.513
    dispatch_time_ms: 7.939
    learner:
      cur_lr: 0.0013134465552866459
      grad_gnorm: 40.0
      policy_entropy: 1.0904011726379395
      policy_loss: -11.16165542602539
      var_gnorm: 32.365909576416016
      vf_explained_var: 0.24429500102996826
      vf_loss: 6020.0048828125
    num_steps_sampled: 701000
    num_steps_trained: 701000
    wait_time_ms: 39.486
  iterations_since_restore: 459
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 10879
  policy_reward_mean: {}
  time_since_restore: 3519.8229575157166
  time_this_iter_s: 9.534663677215576
  time_total_s: 3519.8229575157166
  timestamp: 1594149025
  timesteps_since_restore: 701000
  timesteps_this_iter: 2000
  timesteps_total: 701000
  training_iteration: 459
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10879], 3519 s, 459 iter, 701000 ts, 92.6 rew

agent-1: 355.0
Sum Reward: 355.0
Avg Reward: 355.0
Min Reward: 355.0
Max Reward: 355.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_15-10-34
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 404.0
  episode_reward_mean: 96.18
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 702
  experiment_id: cb3a18e0a26e466496590bc0542b68c4
  hostname: gpu020
  info:
    apply_time_ms: 3.877
    dispatch_time_ms: 8.205
    learner:
      cur_lr: 0.0013133133761584759
      grad_gnorm: 40.00000762939453
      policy_entropy: 2.4008753299713135
      policy_loss: 8.937217712402344
      var_gnorm: 32.357234954833984
      vf_explained_var: 0.14058154821395874
      vf_loss: 15.436662673950195
    num_steps_sampled: 703000
    num_steps_trained: 703000
    wait_time_ms: 34.1
  iterations_since_restore: 460
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 10879
  policy_reward_mean: {}
  time_since_restore: 3529.349266767502
  time_this_iter_s: 9.526309251785278
  time_total_s: 3529.349266767502
  timestamp: 1594149034
  timesteps_since_restore: 703000
  timesteps_this_iter: 2000
  timesteps_total: 703000
  training_iteration: 460
  
agent-1: 374.0
Sum Reward: 374.0
Avg Reward: 374.0
Min Reward: 374.0
Max Reward: 374.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10879], 3529 s, 460 iter, 703000 ts, 96.2 rew

agent-1: 378.0
Sum Reward: 378.0
Avg Reward: 378.0
Min Reward: 378.0
Max Reward: 378.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_15-10-51
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 404.0
  episode_reward_mean: 103.63
  episode_reward_min: 0.0
  episodes_this_iter: 2
  episodes_total: 704
  experiment_id: cb3a18e0a26e466496590bc0542b68c4
  hostname: gpu020
  info:
    apply_time_ms: 3.601
    dispatch_time_ms: 7.916
    learner:
      cur_lr: 0.0013131801970303059
      grad_gnorm: 33.24834060668945
      policy_entropy: 1.0001953840255737
      policy_loss: 0.5062115788459778
      var_gnorm: 32.37976837158203
      vf_explained_var: -0.126082181930542
      vf_loss: 9.379971504211426
    num_steps_sampled: 705000
    num_steps_trained: 705000
    wait_time_ms: 34.421
  iterations_since_restore: 461
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 10879
  policy_reward_mean: {}
  time_since_restore: 3538.966689825058
  time_this_iter_s: 9.617423057556152
  time_total_s: 3538.966689825058
  timestamp: 1594149051
  timesteps_since_restore: 705000
  timesteps_this_iter: 2000
  timesteps_total: 705000
  training_iteration: 461
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10879], 3538 s, 461 iter, 705000 ts, 104 rew

agent-1: 406.0
Sum Reward: 406.0
Avg Reward: 406.0
Min Reward: 406.0
Max Reward: 406.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
agent-1: 413.0
Sum Reward: 413.0
Avg Reward: 413.0
Min Reward: 413.0
Max Reward: 413.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_15-11-00
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 413.0
  episode_reward_mean: 111.81
  episode_reward_min: 0.0
  episodes_this_iter: 2
  episodes_total: 706
  experiment_id: cb3a18e0a26e466496590bc0542b68c4
  hostname: gpu020
  info:
    apply_time_ms: 2.458
    dispatch_time_ms: 6.66
    learner:
      cur_lr: 0.0013130470179021358
      grad_gnorm: 40.0
      policy_entropy: 0.902779221534729
      policy_loss: 1.633086085319519
      var_gnorm: 32.49026107788086
      vf_explained_var: 0.3055686950683594
      vf_loss: 12.323407173156738
    num_steps_sampled: 707000
    num_steps_trained: 707000
    wait_time_ms: 38.185
  iterations_since_restore: 462
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 10879
  policy_reward_mean: {}
  time_since_restore: 3548.434515953064
  time_this_iter_s: 9.467826128005981
  time_total_s: 3548.434515953064
  timestamp: 1594149060
  timesteps_since_restore: 707000
  timesteps_this_iter: 2000
  timesteps_total: 707000
  training_iteration: 462
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10879], 3548 s, 462 iter, 707000 ts, 112 rew

agent-1: 430.0
Sum Reward: 430.0
Avg Reward: 430.0
Min Reward: 430.0
Max Reward: 430.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
agent-1: 397.0
Sum Reward: 397.0
Avg Reward: 397.0
Min Reward: 397.0
Max Reward: 397.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_15-11-10
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 430.0
  episode_reward_mean: 119.97
  episode_reward_min: 0.0
  episodes_this_iter: 2
  episodes_total: 708
  experiment_id: cb3a18e0a26e466496590bc0542b68c4
  hostname: gpu020
  info:
    apply_time_ms: 2.958
    dispatch_time_ms: 5.803
    learner:
      cur_lr: 0.0013129138387739658
      grad_gnorm: 36.25725173950195
      policy_entropy: 1.5784615278244019
      policy_loss: -3.895426034927368
      var_gnorm: 32.45527648925781
      vf_explained_var: 0.13351702690124512
      vf_loss: 11.324772834777832
    num_steps_sampled: 709000
    num_steps_trained: 709000
    wait_time_ms: 39.621
  iterations_since_restore: 463
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 10879
  policy_reward_mean: {}
  time_since_restore: 3557.7178151607513
  time_this_iter_s: 9.283299207687378
  time_total_s: 3557.7178151607513
  timestamp: 1594149070
  timesteps_since_restore: 709000
  timesteps_this_iter: 2000
  timesteps_total: 709000
  training_iteration: 463
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10879], 3557 s, 463 iter, 709000 ts, 120 rew

agent-1: 336.0
Sum Reward: 336.0
Avg Reward: 336.0
Min Reward: 336.0
Max Reward: 336.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
agent-1: 392.0
Sum Reward: 392.0
Avg Reward: 392.0
Min Reward: 392.0
Max Reward: 392.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_15-11-19
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 430.0
  episode_reward_mean: 127.13
  episode_reward_min: 0.0
  episodes_this_iter: 2
  episodes_total: 710
  experiment_id: cb3a18e0a26e466496590bc0542b68c4
  hostname: gpu020
  info:
    apply_time_ms: 2.501
    dispatch_time_ms: 6.82
    learner:
      cur_lr: 0.001312780543230474
      grad_gnorm: 2.0794882774353027
      policy_entropy: 1.0795964002609253
      policy_loss: 0.01636752113699913
      var_gnorm: 32.480648040771484
      vf_explained_var: 0.0
      vf_loss: 1.1017638444900513
    num_steps_sampled: 711000
    num_steps_trained: 711000
    wait_time_ms: 36.955
  iterations_since_restore: 464
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 10879
  policy_reward_mean: {}
  time_since_restore: 3567.236753463745
  time_this_iter_s: 9.518938302993774
  time_total_s: 3567.236753463745
  timestamp: 1594149079
  timesteps_since_restore: 711000
  timesteps_this_iter: 2000
  timesteps_total: 711000
  training_iteration: 464
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10879], 3567 s, 464 iter, 711000 ts, 127 rew

agent-1: 388.0
Sum Reward: 388.0
Avg Reward: 388.0
Min Reward: 388.0
Max Reward: 388.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
agent-1: 363.0
Sum Reward: 363.0
Avg Reward: 363.0
Min Reward: 363.0
Max Reward: 363.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_15-11-29
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 430.0
  episode_reward_mean: 134.53
  episode_reward_min: 0.0
  episodes_this_iter: 2
  episodes_total: 712
  experiment_id: cb3a18e0a26e466496590bc0542b68c4
  hostname: gpu020
  info:
    apply_time_ms: 2.746
    dispatch_time_ms: 7.165
    learner:
      cur_lr: 0.001312647364102304
      grad_gnorm: 25.920988082885742
      policy_entropy: 1.5389313697814941
      policy_loss: -0.41634610295295715
      var_gnorm: 32.53514099121094
      vf_explained_var: -0.20250475406646729
      vf_loss: 5.238833427429199
    num_steps_sampled: 713000
    num_steps_trained: 713000
    wait_time_ms: 35.764
  iterations_since_restore: 465
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 10879
  policy_reward_mean: {}
  time_since_restore: 3576.6585671901703
  time_this_iter_s: 9.421813726425171
  time_total_s: 3576.6585671901703
  timestamp: 1594149089
  timesteps_since_restore: 713000
  timesteps_this_iter: 2000
  timesteps_total: 713000
  training_iteration: 465
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10879], 3576 s, 465 iter, 713000 ts, 135 rew

agent-1: 411.0
Sum Reward: 411.0
Avg Reward: 411.0
Min Reward: 411.0
Max Reward: 411.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
agent-1: 415.0
Sum Reward: 415.0
Avg Reward: 415.0
Min Reward: 415.0
Max Reward: 415.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_15-11-38
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 430.0
  episode_reward_mean: 142.67
  episode_reward_min: 0.0
  episodes_this_iter: 2
  episodes_total: 714
  experiment_id: cb3a18e0a26e466496590bc0542b68c4
  hostname: gpu020
  info:
    apply_time_ms: 2.609
    dispatch_time_ms: 7.548
    learner:
      cur_lr: 0.001312514184974134
      grad_gnorm: 19.546995162963867
      policy_entropy: 1.6838939189910889
      policy_loss: -0.4765523076057434
      var_gnorm: 32.584293365478516
      vf_explained_var: -1.0
      vf_loss: 3.9598352909088135
    num_steps_sampled: 715000
    num_steps_trained: 715000
    wait_time_ms: 36.665
  iterations_since_restore: 466
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 10879
  policy_reward_mean: {}
  time_since_restore: 3586.166792154312
  time_this_iter_s: 9.508224964141846
  time_total_s: 3586.166792154312
  timestamp: 1594149098
  timesteps_since_restore: 715000
  timesteps_this_iter: 2000
  timesteps_total: 715000
  training_iteration: 466
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10879], 3586 s, 466 iter, 715000 ts, 143 rew

agent-1: 421.0
Sum Reward: 421.0
Avg Reward: 421.0
Min Reward: 421.0
Max Reward: 421.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
agent-1: 361.0
Sum Reward: 361.0
Avg Reward: 361.0
Min Reward: 361.0
Max Reward: 361.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_15-11-48
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 430.0
  episode_reward_mean: 150.22
  episode_reward_min: 0.0
  episodes_this_iter: 2
  episodes_total: 716
  experiment_id: cb3a18e0a26e466496590bc0542b68c4
  hostname: gpu020
  info:
    apply_time_ms: 2.947
    dispatch_time_ms: 8.782
    learner:
      cur_lr: 0.001312381005845964
      grad_gnorm: 14.448492050170898
      policy_entropy: 1.4947962760925293
      policy_loss: 0.40164461731910706
      var_gnorm: 32.59282302856445
      vf_explained_var: 0.3482351303100586
      vf_loss: 2.3591864109039307
    num_steps_sampled: 717000
    num_steps_trained: 717000
    wait_time_ms: 32.768
  iterations_since_restore: 467
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 10879
  policy_reward_mean: {}
  time_since_restore: 3595.6761679649353
  time_this_iter_s: 9.509375810623169
  time_total_s: 3595.6761679649353
  timestamp: 1594149108
  timesteps_since_restore: 717000
  timesteps_this_iter: 2000
  timesteps_total: 717000
  training_iteration: 467
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10879], 3595 s, 467 iter, 717000 ts, 150 rew

agent-1: 365.0
Sum Reward: 365.0
Avg Reward: 365.0
Min Reward: 365.0
Max Reward: 365.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
agent-1: 350.0
Sum Reward: 350.0
Avg Reward: 350.0
Min Reward: 350.0
Max Reward: 350.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_15-11-57
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 430.0
  episode_reward_mean: 157.33
  episode_reward_min: 0.0
  episodes_this_iter: 2
  episodes_total: 718
  experiment_id: cb3a18e0a26e466496590bc0542b68c4
  hostname: gpu020
  info:
    apply_time_ms: 2.726
    dispatch_time_ms: 5.865
    learner:
      cur_lr: 0.001312247826717794
      grad_gnorm: 7.774456977844238
      policy_entropy: 0.8719005584716797
      policy_loss: -2.700927972793579
      var_gnorm: 32.703739166259766
      vf_explained_var: 0.0
      vf_loss: 2.0164928436279297
    num_steps_sampled: 719000
    num_steps_trained: 719000
    wait_time_ms: 38.71
  iterations_since_restore: 468
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 10879
  policy_reward_mean: {}
  time_since_restore: 3605.096629858017
  time_this_iter_s: 9.420461893081665
  time_total_s: 3605.096629858017
  timestamp: 1594149117
  timesteps_since_restore: 719000
  timesteps_this_iter: 2000
  timesteps_total: 719000
  training_iteration: 468
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10879], 3605 s, 468 iter, 719000 ts, 157 rew

agent-1: 358.0
Sum Reward: 358.0
Avg Reward: 358.0
Min Reward: 358.0
Max Reward: 358.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
agent-1: 320.0
Sum Reward: 320.0
Avg Reward: 320.0
Min Reward: 320.0
Max Reward: 320.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_15-12-07
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 430.0
  episode_reward_mean: 164.09
  episode_reward_min: 0.0
  episodes_this_iter: 2
  episodes_total: 720
  experiment_id: cb3a18e0a26e466496590bc0542b68c4
  hostname: gpu020
  info:
    apply_time_ms: 2.568
    dispatch_time_ms: 8.74
    learner:
      cur_lr: 0.001312114647589624
      grad_gnorm: 40.000003814697266
      policy_entropy: 1.2323007583618164
      policy_loss: -0.504702091217041
      var_gnorm: 32.69365692138672
      vf_explained_var: 0.0
      vf_loss: 21.358076095581055
    num_steps_sampled: 721000
    num_steps_trained: 721000
    wait_time_ms: 34.63
  iterations_since_restore: 469
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 10879
  policy_reward_mean: {}
  time_since_restore: 3614.3958988189697
  time_this_iter_s: 9.299268960952759
  time_total_s: 3614.3958988189697
  timestamp: 1594149127
  timesteps_since_restore: 721000
  timesteps_this_iter: 2000
  timesteps_total: 721000
  training_iteration: 469
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10879], 3614 s, 469 iter, 721000 ts, 164 rew

agent-1: 299.0
Sum Reward: 299.0
Avg Reward: 299.0
Min Reward: 299.0
Max Reward: 299.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
agent-1: 281.0
Sum Reward: 281.0
Avg Reward: 281.0
Min Reward: 281.0
Max Reward: 281.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_15-12-31
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 430.0
  episode_reward_mean: 169.89
  episode_reward_min: 0.0
  episodes_this_iter: 2
  episodes_total: 722
  experiment_id: cb3a18e0a26e466496590bc0542b68c4
  hostname: gpu020
  info:
    apply_time_ms: 2.656
    dispatch_time_ms: 6.058
    learner:
      cur_lr: 0.001311981352046132
      grad_gnorm: 31.63942527770996
      policy_entropy: 1.867126226425171
      policy_loss: -6.7710652351379395
      var_gnorm: 32.77009201049805
      vf_explained_var: 0.0
      vf_loss: 5.867745399475098
    num_steps_sampled: 723000
    num_steps_trained: 723000
    wait_time_ms: 39.072
  iterations_since_restore: 470
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 10879
  policy_reward_mean: {}
  time_since_restore: 3638.5401043891907
  time_this_iter_s: 24.144205570220947
  time_total_s: 3638.5401043891907
  timestamp: 1594149151
  timesteps_since_restore: 723000
  timesteps_this_iter: 2000
  timesteps_total: 723000
  training_iteration: 470
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10879], 3638 s, 470 iter, 723000 ts, 170 rew

agent-1: 304.0
Sum Reward: 304.0
Avg Reward: 304.0
Min Reward: 304.0
Max Reward: 304.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
agent-1: 309.0
Sum Reward: 309.0
Avg Reward: 309.0
Min Reward: 309.0
Max Reward: 309.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_15-12-40
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 430.0
  episode_reward_mean: 175.85
  episode_reward_min: 0.0
  episodes_this_iter: 2
  episodes_total: 724
  experiment_id: cb3a18e0a26e466496590bc0542b68c4
  hostname: gpu020
  info:
    apply_time_ms: 2.59
    dispatch_time_ms: 6.185
    learner:
      cur_lr: 0.001311848172917962
      grad_gnorm: 34.402706146240234
      policy_entropy: 1.623061180114746
      policy_loss: 0.41296401619911194
      var_gnorm: 32.738895416259766
      vf_explained_var: 0.0
      vf_loss: 9.723020553588867
    num_steps_sampled: 725000
    num_steps_trained: 725000
    wait_time_ms: 36.951
  iterations_since_restore: 471
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 10879
  policy_reward_mean: {}
  time_since_restore: 3647.9617235660553
  time_this_iter_s: 9.421619176864624
  time_total_s: 3647.9617235660553
  timestamp: 1594149160
  timesteps_since_restore: 725000
  timesteps_this_iter: 2000
  timesteps_total: 725000
  training_iteration: 471
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10879], 3647 s, 471 iter, 725000 ts, 176 rew

agent-1: 346.0
Sum Reward: 346.0
Avg Reward: 346.0
Min Reward: 346.0
Max Reward: 346.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
agent-1: 322.0
Sum Reward: 322.0
Avg Reward: 322.0
Min Reward: 322.0
Max Reward: 322.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_15-12-50
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 430.0
  episode_reward_mean: 182.46
  episode_reward_min: 0.0
  episodes_this_iter: 2
  episodes_total: 726
  experiment_id: cb3a18e0a26e466496590bc0542b68c4
  hostname: gpu020
  info:
    apply_time_ms: 2.739
    dispatch_time_ms: 6.841
    learner:
      cur_lr: 0.001311714993789792
      grad_gnorm: 7.857710361480713
      policy_entropy: 4.0506134033203125
      policy_loss: 1.3220072984695435
      var_gnorm: 32.76015853881836
      vf_explained_var: -0.22751307487487793
      vf_loss: 1.1221811771392822
    num_steps_sampled: 727000
    num_steps_trained: 727000
    wait_time_ms: 38.076
  iterations_since_restore: 472
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 10879
  policy_reward_mean: {}
  time_since_restore: 3657.278154373169
  time_this_iter_s: 9.316430807113647
  time_total_s: 3657.278154373169
  timestamp: 1594149170
  timesteps_since_restore: 727000
  timesteps_this_iter: 2000
  timesteps_total: 727000
  training_iteration: 472
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10879], 3657 s, 472 iter, 727000 ts, 182 rew

agent-1: 312.0
Sum Reward: 312.0
Avg Reward: 312.0
Min Reward: 312.0
Max Reward: 312.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
agent-1: 328.0
Sum Reward: 328.0
Avg Reward: 328.0
Min Reward: 328.0
Max Reward: 328.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_15-12-59
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 430.0
  episode_reward_mean: 188.82
  episode_reward_min: 0.0
  episodes_this_iter: 2
  episodes_total: 728
  experiment_id: cb3a18e0a26e466496590bc0542b68c4
  hostname: gpu020
  info:
    apply_time_ms: 3.002
    dispatch_time_ms: 6.779
    learner:
      cur_lr: 0.001311581814661622
      grad_gnorm: 0.36198657751083374
      policy_entropy: 2.013291835784912
      policy_loss: -0.26045751571655273
      var_gnorm: 32.80937576293945
      vf_explained_var: 0.5355266332626343
      vf_loss: 0.7385887503623962
    num_steps_sampled: 729000
    num_steps_trained: 729000
    wait_time_ms: 37.572
  iterations_since_restore: 473
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 10879
  policy_reward_mean: {}
  time_since_restore: 3666.627900123596
  time_this_iter_s: 9.349745750427246
  time_total_s: 3666.627900123596
  timestamp: 1594149179
  timesteps_since_restore: 729000
  timesteps_this_iter: 2000
  timesteps_total: 729000
  training_iteration: 473
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10879], 3666 s, 473 iter, 729000 ts, 189 rew

agent-1: 321.0
Sum Reward: 321.0
Avg Reward: 321.0
Min Reward: 321.0
Max Reward: 321.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
agent-1: 292.0
Sum Reward: 292.0
Avg Reward: 292.0
Min Reward: 292.0
Max Reward: 292.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_15-13-09
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 430.0
  episode_reward_mean: 194.9
  episode_reward_min: 0.0
  episodes_this_iter: 2
  episodes_total: 730
  experiment_id: cb3a18e0a26e466496590bc0542b68c4
  hostname: gpu020
  info:
    apply_time_ms: 7.104
    dispatch_time_ms: 23.045
    learner:
      cur_lr: 0.001311448635533452
      grad_gnorm: 10.820413589477539
      policy_entropy: 3.1275219917297363
      policy_loss: -0.0027974843978881836
      var_gnorm: 32.82560729980469
      vf_explained_var: -0.01451730728149414
      vf_loss: 2.727749824523926
    num_steps_sampled: 731000
    num_steps_trained: 731000
    wait_time_ms: 80.98
  iterations_since_restore: 474
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 10879
  policy_reward_mean: {}
  time_since_restore: 3676.6801042556763
  time_this_iter_s: 10.052204132080078
  time_total_s: 3676.6801042556763
  timestamp: 1594149189
  timesteps_since_restore: 731000
  timesteps_this_iter: 2000
  timesteps_total: 731000
  training_iteration: 474
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10879], 3676 s, 474 iter, 731000 ts, 195 rew

agent-1: 342.0
Sum Reward: 342.0
Avg Reward: 342.0
Min Reward: 342.0
Max Reward: 342.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
agent-1: 353.0
Sum Reward: 353.0
Avg Reward: 353.0
Min Reward: 353.0
Max Reward: 353.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_15-13-19
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 430.0
  episode_reward_mean: 201.63
  episode_reward_min: 0.0
  episodes_this_iter: 2
  episodes_total: 732
  experiment_id: cb3a18e0a26e466496590bc0542b68c4
  hostname: gpu020
  info:
    apply_time_ms: 2.673
    dispatch_time_ms: 7.181
    learner:
      cur_lr: 0.001311315456405282
      grad_gnorm: 39.999996185302734
      policy_entropy: 3.597043037414551
      policy_loss: -17.897220611572266
      var_gnorm: 32.956764221191406
      vf_explained_var: -1.0
      vf_loss: 31.90211296081543
    num_steps_sampled: 733000
    num_steps_trained: 733000
    wait_time_ms: 36.5
  iterations_since_restore: 475
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 10879
  policy_reward_mean: {}
  time_since_restore: 3686.000863313675
  time_this_iter_s: 9.320759057998657
  time_total_s: 3686.000863313675
  timestamp: 1594149199
  timesteps_since_restore: 733000
  timesteps_this_iter: 2000
  timesteps_total: 733000
  training_iteration: 475
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10879], 3686 s, 475 iter, 733000 ts, 202 rew

agent-1: 346.0
Sum Reward: 346.0
Avg Reward: 346.0
Min Reward: 346.0
Max Reward: 346.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
agent-1: 357.0
Sum Reward: 357.0
Avg Reward: 357.0
Min Reward: 357.0
Max Reward: 357.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_15-13-28
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 430.0
  episode_reward_mean: 208.59
  episode_reward_min: 0.0
  episodes_this_iter: 2
  episodes_total: 734
  experiment_id: cb3a18e0a26e466496590bc0542b68c4
  hostname: gpu020
  info:
    apply_time_ms: 2.524
    dispatch_time_ms: 5.99
    learner:
      cur_lr: 0.0013111821608617902
      grad_gnorm: 30.695981979370117
      policy_entropy: 0.9646929502487183
      policy_loss: 0.19329600036144257
      var_gnorm: 33.03118896484375
      vf_explained_var: 0.0
      vf_loss: 7.235493183135986
    num_steps_sampled: 735000
    num_steps_trained: 735000
    wait_time_ms: 42.031
  iterations_since_restore: 476
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 10879
  policy_reward_mean: {}
  time_since_restore: 3695.3550567626953
  time_this_iter_s: 9.354193449020386
  time_total_s: 3695.3550567626953
  timestamp: 1594149208
  timesteps_since_restore: 735000
  timesteps_this_iter: 2000
  timesteps_total: 735000
  training_iteration: 476
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10879], 3695 s, 476 iter, 735000 ts, 209 rew

agent-1: 289.0
Sum Reward: 289.0
Avg Reward: 289.0
Min Reward: 289.0
Max Reward: 289.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
agent-1: 335.0
Sum Reward: 335.0
Avg Reward: 335.0
Min Reward: 335.0
Max Reward: 335.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_15-13-37
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 430.0
  episode_reward_mean: 214.82
  episode_reward_min: 0.0
  episodes_this_iter: 2
  episodes_total: 736
  experiment_id: cb3a18e0a26e466496590bc0542b68c4
  hostname: gpu020
  info:
    apply_time_ms: 2.936
    dispatch_time_ms: 7.117
    learner:
      cur_lr: 0.0013110489817336202
      grad_gnorm: 9.413885116577148
      policy_entropy: 2.845754861831665
      policy_loss: 0.5305100679397583
      var_gnorm: 33.071144104003906
      vf_explained_var: -0.21005678176879883
      vf_loss: 2.4658572673797607
    num_steps_sampled: 737000
    num_steps_trained: 737000
    wait_time_ms: 38.152
  iterations_since_restore: 477
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 10879
  policy_reward_mean: {}
  time_since_restore: 3704.7929928302765
  time_this_iter_s: 9.437936067581177
  time_total_s: 3704.7929928302765
  timestamp: 1594149217
  timesteps_since_restore: 737000
  timesteps_this_iter: 2000
  timesteps_total: 737000
  training_iteration: 477
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10879], 3704 s, 477 iter, 737000 ts, 215 rew

agent-1: 320.0
Sum Reward: 320.0
Avg Reward: 320.0
Min Reward: 320.0
Max Reward: 320.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
agent-1: 324.0
Sum Reward: 324.0
Avg Reward: 324.0
Min Reward: 324.0
Max Reward: 324.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_15-13-47
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 430.0
  episode_reward_mean: 221.26
  episode_reward_min: 0.0
  episodes_this_iter: 2
  episodes_total: 738
  experiment_id: cb3a18e0a26e466496590bc0542b68c4
  hostname: gpu020
  info:
    apply_time_ms: 3.178
    dispatch_time_ms: 8.834
    learner:
      cur_lr: 0.0013109158026054502
      grad_gnorm: 40.0
      policy_entropy: 5.48921012878418
      policy_loss: -13.286150932312012
      var_gnorm: 33.029659271240234
      vf_explained_var: -0.08365857601165771
      vf_loss: 32.47553634643555
    num_steps_sampled: 739000
    num_steps_trained: 739000
    wait_time_ms: 34.35
  iterations_since_restore: 478
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 10879
  policy_reward_mean: {}
  time_since_restore: 3714.0001742839813
  time_this_iter_s: 9.207181453704834
  time_total_s: 3714.0001742839813
  timestamp: 1594149227
  timesteps_since_restore: 739000
  timesteps_this_iter: 2000
  timesteps_total: 739000
  training_iteration: 478
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10879], 3714 s, 478 iter, 739000 ts, 221 rew

agent-1: 264.0
Sum Reward: 264.0
Avg Reward: 264.0
Min Reward: 264.0
Max Reward: 264.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
agent-1: 358.0
Sum Reward: 358.0
Avg Reward: 358.0
Min Reward: 358.0
Max Reward: 358.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_15-13-56
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 430.0
  episode_reward_mean: 227.45
  episode_reward_min: 0.0
  episodes_this_iter: 2
  episodes_total: 740
  experiment_id: cb3a18e0a26e466496590bc0542b68c4
  hostname: gpu020
  info:
    apply_time_ms: 2.713
    dispatch_time_ms: 7.524
    learner:
      cur_lr: 0.0013107826234772801
      grad_gnorm: 39.999996185302734
      policy_entropy: 0.9726735353469849
      policy_loss: -0.25033366680145264
      var_gnorm: 33.11467742919922
      vf_explained_var: -0.45688819885253906
      vf_loss: 11.53952407836914
    num_steps_sampled: 741000
    num_steps_trained: 741000
    wait_time_ms: 36.851
  iterations_since_restore: 479
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 10879
  policy_reward_mean: {}
  time_since_restore: 3723.3141458034515
  time_this_iter_s: 9.313971519470215
  time_total_s: 3723.3141458034515
  timestamp: 1594149236
  timesteps_since_restore: 741000
  timesteps_this_iter: 2000
  timesteps_total: 741000
  training_iteration: 479
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10879], 3723 s, 479 iter, 741000 ts, 227 rew

agent-1: 359.0
Sum Reward: 359.0
Avg Reward: 359.0
Min Reward: 359.0
Max Reward: 359.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
agent-1: 330.0
Sum Reward: 330.0
Avg Reward: 330.0
Min Reward: 330.0
Max Reward: 330.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_15-14-05
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 430.0
  episode_reward_mean: 234.34
  episode_reward_min: 0.0
  episodes_this_iter: 2
  episodes_total: 742
  experiment_id: cb3a18e0a26e466496590bc0542b68c4
  hostname: gpu020
  info:
    apply_time_ms: 2.497
    dispatch_time_ms: 9.063
    learner:
      cur_lr: 0.0013106494443491101
      grad_gnorm: 29.454307556152344
      policy_entropy: 0.714419960975647
      policy_loss: 0.1275361180305481
      var_gnorm: 33.21306228637695
      vf_explained_var: 0.0
      vf_loss: 6.725702285766602
    num_steps_sampled: 743000
    num_steps_trained: 743000
    wait_time_ms: 35.39
  iterations_since_restore: 480
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 10879
  policy_reward_mean: {}
  time_since_restore: 3732.774782896042
  time_this_iter_s: 9.460637092590332
  time_total_s: 3732.774782896042
  timestamp: 1594149245
  timesteps_since_restore: 743000
  timesteps_this_iter: 2000
  timesteps_total: 743000
  training_iteration: 480
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10879], 3732 s, 480 iter, 743000 ts, 234 rew

agent-1: 325.0
Sum Reward: 325.0
Avg Reward: 325.0
Min Reward: 325.0
Max Reward: 325.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
agent-1: 338.0
Sum Reward: 338.0
Avg Reward: 338.0
Min Reward: 338.0
Max Reward: 338.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_15-14-15
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 430.0
  episode_reward_mean: 240.97
  episode_reward_min: 0.0
  episodes_this_iter: 2
  episodes_total: 744
  experiment_id: cb3a18e0a26e466496590bc0542b68c4
  hostname: gpu020
  info:
    apply_time_ms: 3.034
    dispatch_time_ms: 7.55
    learner:
      cur_lr: 0.0013105161488056183
      grad_gnorm: 7.266363620758057
      policy_entropy: 0.5016341805458069
      policy_loss: -0.0203507412225008
      var_gnorm: 33.203609466552734
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 1.0225013494491577
    num_steps_sampled: 745000
    num_steps_trained: 745000
    wait_time_ms: 35.143
  iterations_since_restore: 481
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 10879
  policy_reward_mean: {}
  time_since_restore: 3741.989100933075
  time_this_iter_s: 9.214318037033081
  time_total_s: 3741.989100933075
  timestamp: 1594149255
  timesteps_since_restore: 745000
  timesteps_this_iter: 2000
  timesteps_total: 745000
  training_iteration: 481
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10879], 3741 s, 481 iter, 745000 ts, 241 rew

agent-1: 332.0
Sum Reward: 332.0
Avg Reward: 332.0
Min Reward: 332.0
Max Reward: 332.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
agent-1: 303.0
Sum Reward: 303.0
Avg Reward: 303.0
Min Reward: 303.0
Max Reward: 303.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_15-14-24
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 430.0
  episode_reward_mean: 247.18
  episode_reward_min: 0.0
  episodes_this_iter: 2
  episodes_total: 746
  experiment_id: cb3a18e0a26e466496590bc0542b68c4
  hostname: gpu020
  info:
    apply_time_ms: 2.511
    dispatch_time_ms: 7.584
    learner:
      cur_lr: 0.0013103829696774483
      grad_gnorm: 40.000003814697266
      policy_entropy: 1.014700174331665
      policy_loss: 0.7477590441703796
      var_gnorm: 33.206356048583984
      vf_explained_var: 0.0
      vf_loss: 83.25354766845703
    num_steps_sampled: 747000
    num_steps_trained: 747000
    wait_time_ms: 36.069
  iterations_since_restore: 482
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 10879
  policy_reward_mean: {}
  time_since_restore: 3751.1950345039368
  time_this_iter_s: 9.205933570861816
  time_total_s: 3751.1950345039368
  timestamp: 1594149264
  timesteps_since_restore: 747000
  timesteps_this_iter: 2000
  timesteps_total: 747000
  training_iteration: 482
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10879], 3751 s, 482 iter, 747000 ts, 247 rew

agent-1: 327.0
Sum Reward: 327.0
Avg Reward: 327.0
Min Reward: 327.0
Max Reward: 327.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
agent-1: 369.0
Sum Reward: 369.0
Avg Reward: 369.0
Min Reward: 369.0
Max Reward: 369.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_15-14-33
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 430.0
  episode_reward_mean: 254.05
  episode_reward_min: 0.0
  episodes_this_iter: 2
  episodes_total: 748
  experiment_id: cb3a18e0a26e466496590bc0542b68c4
  hostname: gpu020
  info:
    apply_time_ms: 2.657
    dispatch_time_ms: 6.44
    learner:
      cur_lr: 0.0013102497905492783
      grad_gnorm: 25.743873596191406
      policy_entropy: 1.2322273254394531
      policy_loss: 3.5752694606781006
      var_gnorm: 33.299930572509766
      vf_explained_var: 0.4045369029045105
      vf_loss: 4.370840072631836
    num_steps_sampled: 749000
    num_steps_trained: 749000
    wait_time_ms: 37.731
  iterations_since_restore: 483
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 10879
  policy_reward_mean: {}
  time_since_restore: 3760.634385585785
  time_this_iter_s: 9.439351081848145
  time_total_s: 3760.634385585785
  timestamp: 1594149273
  timesteps_since_restore: 749000
  timesteps_this_iter: 2000
  timesteps_total: 749000
  training_iteration: 483
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10879], 3760 s, 483 iter, 749000 ts, 254 rew

agent-1: 368.0
Sum Reward: 368.0
Avg Reward: 368.0
Min Reward: 368.0
Max Reward: 368.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
agent-1: 344.0
Sum Reward: 344.0
Avg Reward: 344.0
Min Reward: 344.0
Max Reward: 344.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_15-14-43
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 430.0
  episode_reward_mean: 260.95
  episode_reward_min: 0.0
  episodes_this_iter: 2
  episodes_total: 750
  experiment_id: cb3a18e0a26e466496590bc0542b68c4
  hostname: gpu020
  info:
    apply_time_ms: 2.989
    dispatch_time_ms: 7.324
    learner:
      cur_lr: 0.0013101166114211082
      grad_gnorm: 18.991024017333984
      policy_entropy: 1.9793626070022583
      policy_loss: -0.37791454792022705
      var_gnorm: 33.3492431640625
      vf_explained_var: 0.6426011323928833
      vf_loss: 2.2788069248199463
    num_steps_sampled: 751000
    num_steps_trained: 751000
    wait_time_ms: 35.736
  iterations_since_restore: 484
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 10879
  policy_reward_mean: {}
  time_since_restore: 3770.0808753967285
  time_this_iter_s: 9.446489810943604
  time_total_s: 3770.0808753967285
  timestamp: 1594149283
  timesteps_since_restore: 751000
  timesteps_this_iter: 2000
  timesteps_total: 751000
  training_iteration: 484
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10879], 3770 s, 484 iter, 751000 ts, 261 rew

agent-1: 369.0
Sum Reward: 369.0
Avg Reward: 369.0
Min Reward: 369.0
Max Reward: 369.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
agent-1: 350.0
Sum Reward: 350.0
Avg Reward: 350.0
Min Reward: 350.0
Max Reward: 350.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_15-14-52
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 430.0
  episode_reward_mean: 267.92
  episode_reward_min: 0.0
  episodes_this_iter: 2
  episodes_total: 752
  experiment_id: cb3a18e0a26e466496590bc0542b68c4
  hostname: gpu020
  info:
    apply_time_ms: 3.644
    dispatch_time_ms: 7.393
    learner:
      cur_lr: 0.0013099834322929382
      grad_gnorm: 40.000003814697266
      policy_entropy: 3.8850021362304688
      policy_loss: -6.950612545013428
      var_gnorm: 33.40092468261719
      vf_explained_var: -1.0
      vf_loss: 33.5198974609375
    num_steps_sampled: 753000
    num_steps_trained: 753000
    wait_time_ms: 37.345
  iterations_since_restore: 485
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 10879
  policy_reward_mean: {}
  time_since_restore: 3779.456316947937
  time_this_iter_s: 9.375441551208496
  time_total_s: 3779.456316947937
  timestamp: 1594149292
  timesteps_since_restore: 753000
  timesteps_this_iter: 2000
  timesteps_total: 753000
  training_iteration: 485
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10879], 3779 s, 485 iter, 753000 ts, 268 rew

agent-1: 320.0
Sum Reward: 320.0
Avg Reward: 320.0
Min Reward: 320.0
Max Reward: 320.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
agent-1: 343.0
Sum Reward: 343.0
Avg Reward: 343.0
Min Reward: 343.0
Max Reward: 343.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_15-15-02
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 430.0
  episode_reward_mean: 274.41
  episode_reward_min: 0.0
  episodes_this_iter: 2
  episodes_total: 754
  experiment_id: cb3a18e0a26e466496590bc0542b68c4
  hostname: gpu020
  info:
    apply_time_ms: 2.618
    dispatch_time_ms: 6.147
    learner:
      cur_lr: 0.0013098502531647682
      grad_gnorm: 26.311220169067383
      policy_entropy: 2.1038129329681396
      policy_loss: 0.7351309061050415
      var_gnorm: 33.40496826171875
      vf_explained_var: 0.03376734256744385
      vf_loss: 6.252087116241455
    num_steps_sampled: 755000
    num_steps_trained: 755000
    wait_time_ms: 36.472
  iterations_since_restore: 486
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 10879
  policy_reward_mean: {}
  time_since_restore: 3789.0383684635162
  time_this_iter_s: 9.582051515579224
  time_total_s: 3789.0383684635162
  timestamp: 1594149302
  timesteps_since_restore: 755000
  timesteps_this_iter: 2000
  timesteps_total: 755000
  training_iteration: 486
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10879], 3789 s, 486 iter, 755000 ts, 274 rew

agent-1: 342.0
Sum Reward: 342.0
Avg Reward: 342.0
Min Reward: 342.0
Max Reward: 342.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
agent-1: 296.0
Sum Reward: 296.0
Avg Reward: 296.0
Min Reward: 296.0
Max Reward: 296.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_15-15-11
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 430.0
  episode_reward_mean: 280.56
  episode_reward_min: 0.0
  episodes_this_iter: 2
  episodes_total: 756
  experiment_id: cb3a18e0a26e466496590bc0542b68c4
  hostname: gpu020
  info:
    apply_time_ms: 3.596
    dispatch_time_ms: 6.952
    learner:
      cur_lr: 0.0013097169576212764
      grad_gnorm: 40.000003814697266
      policy_entropy: 2.341494560241699
      policy_loss: -5.010358810424805
      var_gnorm: 33.366939544677734
      vf_explained_var: 0.0
      vf_loss: 11.237043380737305
    num_steps_sampled: 757000
    num_steps_trained: 757000
    wait_time_ms: 35.183
  iterations_since_restore: 487
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 10879
  policy_reward_mean: {}
  time_since_restore: 3798.2442338466644
  time_this_iter_s: 9.205865383148193
  time_total_s: 3798.2442338466644
  timestamp: 1594149311
  timesteps_since_restore: 757000
  timesteps_this_iter: 2000
  timesteps_total: 757000
  training_iteration: 487
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10879], 3798 s, 487 iter, 757000 ts, 281 rew

agent-1: 267.0
Sum Reward: 267.0
Avg Reward: 267.0
Min Reward: 267.0
Max Reward: 267.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
agent-1: 189.0
Sum Reward: 189.0
Avg Reward: 189.0
Min Reward: 189.0
Max Reward: 189.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_15-15-20
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 430.0
  episode_reward_mean: 285.1
  episode_reward_min: 0.0
  episodes_this_iter: 2
  episodes_total: 758
  experiment_id: cb3a18e0a26e466496590bc0542b68c4
  hostname: gpu020
  info:
    apply_time_ms: 2.645
    dispatch_time_ms: 8.268
    learner:
      cur_lr: 0.0013095837784931064
      grad_gnorm: 39.999996185302734
      policy_entropy: 1.2499287128448486
      policy_loss: -0.3692682981491089
      var_gnorm: 33.2791748046875
      vf_explained_var: 0.0
      vf_loss: 11.388472557067871
    num_steps_sampled: 759000
    num_steps_trained: 759000
    wait_time_ms: 34.122
  iterations_since_restore: 488
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 10879
  policy_reward_mean: {}
  time_since_restore: 3807.325353384018
  time_this_iter_s: 9.081119537353516
  time_total_s: 3807.325353384018
  timestamp: 1594149320
  timesteps_since_restore: 759000
  timesteps_this_iter: 2000
  timesteps_total: 759000
  training_iteration: 488
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10879], 3807 s, 488 iter, 759000 ts, 285 rew

agent-1: 218.0
Sum Reward: 218.0
Avg Reward: 218.0
Min Reward: 218.0
Max Reward: 218.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
agent-1: 112.0
Sum Reward: 112.0
Avg Reward: 112.0
Min Reward: 112.0
Max Reward: 112.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_15-15-29
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 430.0
  episode_reward_mean: 288.38
  episode_reward_min: 0.0
  episodes_this_iter: 2
  episodes_total: 760
  experiment_id: cb3a18e0a26e466496590bc0542b68c4
  hostname: gpu020
  info:
    apply_time_ms: 2.606
    dispatch_time_ms: 6.29
    learner:
      cur_lr: 0.0013094505993649364
      grad_gnorm: 32.397422790527344
      policy_entropy: 4.659049034118652
      policy_loss: -4.739977836608887
      var_gnorm: 33.18663024902344
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 7.086170196533203
    num_steps_sampled: 761000
    num_steps_trained: 761000
    wait_time_ms: 32.928
  iterations_since_restore: 489
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 10879
  policy_reward_mean: {}
  time_since_restore: 3816.3236894607544
  time_this_iter_s: 8.99833607673645
  time_total_s: 3816.3236894607544
  timestamp: 1594149329
  timesteps_since_restore: 761000
  timesteps_this_iter: 2000
  timesteps_total: 761000
  training_iteration: 489
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10879], 3816 s, 489 iter, 761000 ts, 288 rew

agent-1: 193.0
Sum Reward: 193.0
Avg Reward: 193.0
Min Reward: 193.0
Max Reward: 193.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
agent-1: 156.0
Sum Reward: 156.0
Avg Reward: 156.0
Min Reward: 156.0
Max Reward: 156.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_15-15-38
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 430.0
  episode_reward_mean: 291.8
  episode_reward_min: 0.0
  episodes_this_iter: 2
  episodes_total: 762
  experiment_id: cb3a18e0a26e466496590bc0542b68c4
  hostname: gpu020
  info:
    apply_time_ms: 4.082
    dispatch_time_ms: 7.798
    learner:
      cur_lr: 0.0013093174202367663
      grad_gnorm: 40.0
      policy_entropy: 2.3741328716278076
      policy_loss: 9.148369789123535
      var_gnorm: 33.149478912353516
      vf_explained_var: 0.09538203477859497
      vf_loss: 17.923261642456055
    num_steps_sampled: 763000
    num_steps_trained: 763000
    wait_time_ms: 32.953
  iterations_since_restore: 490
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 10879
  policy_reward_mean: {}
  time_since_restore: 3825.3774604797363
  time_this_iter_s: 9.053771018981934
  time_total_s: 3825.3774604797363
  timestamp: 1594149338
  timesteps_since_restore: 763000
  timesteps_this_iter: 2000
  timesteps_total: 763000
  training_iteration: 490
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10879], 3825 s, 490 iter, 763000 ts, 292 rew

agent-1: 146.0
Sum Reward: 146.0
Avg Reward: 146.0
Min Reward: 146.0
Max Reward: 146.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
agent-1: 190.0
Sum Reward: 190.0
Avg Reward: 190.0
Min Reward: 190.0
Max Reward: 190.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_15-15-47
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 430.0
  episode_reward_mean: 295.04
  episode_reward_min: 0.0
  episodes_this_iter: 2
  episodes_total: 764
  experiment_id: cb3a18e0a26e466496590bc0542b68c4
  hostname: gpu020
  info:
    apply_time_ms: 2.481
    dispatch_time_ms: 6.75
    learner:
      cur_lr: 0.0013091842411085963
      grad_gnorm: 27.295555114746094
      policy_entropy: 3.291511058807373
      policy_loss: -0.9127327799797058
      var_gnorm: 33.137577056884766
      vf_explained_var: 0.0
      vf_loss: 4.65751314163208
    num_steps_sampled: 765000
    num_steps_trained: 765000
    wait_time_ms: 36.431
  iterations_since_restore: 491
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 10879
  policy_reward_mean: {}
  time_since_restore: 3834.392054796219
  time_this_iter_s: 9.014594316482544
  time_total_s: 3834.392054796219
  timestamp: 1594149347
  timesteps_since_restore: 765000
  timesteps_this_iter: 2000
  timesteps_total: 765000
  training_iteration: 491
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10879], 3834 s, 491 iter, 765000 ts, 295 rew

agent-1: 137.0
Sum Reward: 137.0
Avg Reward: 137.0
Min Reward: 137.0
Max Reward: 137.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_15-16-01
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 430.0
  episode_reward_mean: 296.37
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 765
  experiment_id: cb3a18e0a26e466496590bc0542b68c4
  hostname: gpu020
  info:
    apply_time_ms: 2.415
    dispatch_time_ms: 23.269
    learner:
      cur_lr: 0.0013090509455651045
      grad_gnorm: 26.129579544067383
      policy_entropy: 2.734680652618408
      policy_loss: -0.6802769303321838
      var_gnorm: 33.13248062133789
      vf_explained_var: 5.960464477539063e-08
      vf_loss: 4.399228572845459
    num_steps_sampled: 766000
    num_steps_trained: 766000
    wait_time_ms: 23.788
  iterations_since_restore: 492
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 10879
  policy_reward_mean: {}
  time_since_restore: 3848.371209859848
  time_this_iter_s: 13.97915506362915
  time_total_s: 3848.371209859848
  timestamp: 1594149361
  timesteps_since_restore: 766000
  timesteps_this_iter: 1000
  timesteps_total: 766000
  training_iteration: 492
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10879], 3848 s, 492 iter, 766000 ts, 296 rew

agent-1: 203.0
Sum Reward: 203.0
Avg Reward: 203.0
Min Reward: 203.0
Max Reward: 203.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
agent-1: 138.0
Sum Reward: 138.0
Avg Reward: 138.0
Min Reward: 138.0
Max Reward: 138.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_15-16-11
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 430.0
  episode_reward_mean: 299.6
  episode_reward_min: 0.0
  episodes_this_iter: 2
  episodes_total: 767
  experiment_id: cb3a18e0a26e466496590bc0542b68c4
  hostname: gpu020
  info:
    apply_time_ms: 2.946
    dispatch_time_ms: 23.413
    learner:
      cur_lr: 0.0013089843560010195
      grad_gnorm: 24.299001693725586
      policy_entropy: 3.544896125793457
      policy_loss: -0.9643704891204834
      var_gnorm: 33.119632720947266
      vf_explained_var: 0.0
      vf_loss: 3.660024404525757
    num_steps_sampled: 768000
    num_steps_trained: 768000
    wait_time_ms: 27.155
  iterations_since_restore: 493
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 10879
  policy_reward_mean: {}
  time_since_restore: 3857.7304413318634
  time_this_iter_s: 9.35923147201538
  time_total_s: 3857.7304413318634
  timestamp: 1594149371
  timesteps_since_restore: 768000
  timesteps_this_iter: 2000
  timesteps_total: 768000
  training_iteration: 493
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10879], 3857 s, 493 iter, 768000 ts, 300 rew

agent-1: 213.0
Sum Reward: 213.0
Avg Reward: 213.0
Min Reward: 213.0
Max Reward: 213.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_15-16-17
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 430.0
  episode_reward_mean: 301.73
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 768
  experiment_id: cb3a18e0a26e466496590bc0542b68c4
  hostname: gpu020
  info:
    apply_time_ms: 4.109
    dispatch_time_ms: 46.582
    learner:
      cur_lr: 0.0013088511768728495
      grad_gnorm: 7.910070896148682
      policy_entropy: 1.3699613809585571
      policy_loss: 0.07822277396917343
      var_gnorm: 33.129859924316406
      vf_explained_var: 5.960464477539063e-08
      vf_loss: 2.3305864334106445
    num_steps_sampled: 769000
    num_steps_trained: 769000
    wait_time_ms: 13.919
  iterations_since_restore: 494
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 10879
  policy_reward_mean: {}
  time_since_restore: 3863.725138902664
  time_this_iter_s: 5.994697570800781
  time_total_s: 3863.725138902664
  timestamp: 1594149377
  timesteps_since_restore: 769000
  timesteps_this_iter: 1000
  timesteps_total: 769000
  training_iteration: 494
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10879], 3863 s, 494 iter, 769000 ts, 302 rew

agent-1: 128.0
Sum Reward: 128.0
Avg Reward: 128.0
Min Reward: 128.0
Max Reward: 128.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_15-16-23
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 430.0
  episode_reward_mean: 302.82
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 769
  experiment_id: cb3a18e0a26e466496590bc0542b68c4
  hostname: gpu020
  info:
    apply_time_ms: 2.465
    dispatch_time_ms: 39.687
    learner:
      cur_lr: 0.0013087845873087645
      grad_gnorm: 11.965391159057617
      policy_entropy: 3.142127513885498
      policy_loss: -0.2606664299964905
      var_gnorm: 33.10280990600586
      vf_explained_var: 0.0
      vf_loss: 1.0553423166275024
    num_steps_sampled: 770000
    num_steps_trained: 770000
    wait_time_ms: 19.145
  iterations_since_restore: 495
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 10879
  policy_reward_mean: {}
  time_since_restore: 3870.117566347122
  time_this_iter_s: 6.392427444458008
  time_total_s: 3870.117566347122
  timestamp: 1594149383
  timesteps_since_restore: 770000
  timesteps_this_iter: 1000
  timesteps_total: 770000
  training_iteration: 495
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10879], 3870 s, 495 iter, 770000 ts, 303 rew

agent-1: 181.0
Sum Reward: 181.0
Avg Reward: 181.0
Min Reward: 181.0
Max Reward: 181.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_15-16-29
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 430.0
  episode_reward_mean: 304.63
  episode_reward_min: 5.0
  episodes_this_iter: 1
  episodes_total: 770
  experiment_id: cb3a18e0a26e466496590bc0542b68c4
  hostname: gpu020
  info:
    apply_time_ms: 3.823
    dispatch_time_ms: 28.335
    learner:
      cur_lr: 0.0013087179977446795
      grad_gnorm: 2.3716847896575928
      policy_entropy: 2.5673270225524902
      policy_loss: 0.523955225944519
      var_gnorm: 33.12076950073242
      vf_explained_var: 0.0
      vf_loss: 1.0416380167007446
    num_steps_sampled: 771000
    num_steps_trained: 771000
    wait_time_ms: 21.219
  iterations_since_restore: 496
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 10879
  policy_reward_mean: {}
  time_since_restore: 3875.8078870773315
  time_this_iter_s: 5.690320730209351
  time_total_s: 3875.8078870773315
  timestamp: 1594149389
  timesteps_since_restore: 771000
  timesteps_this_iter: 1000
  timesteps_total: 771000
  training_iteration: 496
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10879], 3875 s, 496 iter, 771000 ts, 305 rew

agent-1: 196.0
Sum Reward: 196.0
Avg Reward: 196.0
Min Reward: 196.0
Max Reward: 196.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_15-16-35
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 430.0
  episode_reward_mean: 306.5
  episode_reward_min: 5.0
  episodes_this_iter: 1
  episodes_total: 771
  experiment_id: cb3a18e0a26e466496590bc0542b68c4
  hostname: gpu020
  info:
    apply_time_ms: 2.584
    dispatch_time_ms: 28.351
    learner:
      cur_lr: 0.0013086514081805944
      grad_gnorm: 40.0
      policy_entropy: 4.4318342208862305
      policy_loss: 7.9753241539001465
      var_gnorm: 33.118526458740234
      vf_explained_var: 1.1920928955078125e-07
      vf_loss: 11.105622291564941
    num_steps_sampled: 772000
    num_steps_trained: 772000
    wait_time_ms: 28.931
  iterations_since_restore: 497
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 10879
  policy_reward_mean: {}
  time_since_restore: 3881.833559989929
  time_this_iter_s: 6.025672912597656
  time_total_s: 3881.833559989929
  timestamp: 1594149395
  timesteps_since_restore: 772000
  timesteps_this_iter: 1000
  timesteps_total: 772000
  training_iteration: 497
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10879], 3881 s, 497 iter, 772000 ts, 306 rew

agent-1: 215.0
Sum Reward: 215.0
Avg Reward: 215.0
Min Reward: 215.0
Max Reward: 215.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_15-16-41
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 430.0
  episode_reward_mean: 308.53
  episode_reward_min: 5.0
  episodes_this_iter: 1
  episodes_total: 772
  experiment_id: cb3a18e0a26e466496590bc0542b68c4
  hostname: gpu020
  info:
    apply_time_ms: 2.615
    dispatch_time_ms: 39.739
    learner:
      cur_lr: 0.0013085848186165094
      grad_gnorm: 24.392932891845703
      policy_entropy: 2.0993902683258057
      policy_loss: -0.9624882340431213
      var_gnorm: 33.14214324951172
      vf_explained_var: 0.0
      vf_loss: 4.170505046844482
    num_steps_sampled: 773000
    num_steps_trained: 773000
    wait_time_ms: 24.186
  iterations_since_restore: 498
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 10879
  policy_reward_mean: {}
  time_since_restore: 3887.68825340271
  time_this_iter_s: 5.854693412780762
  time_total_s: 3887.68825340271
  timestamp: 1594149401
  timesteps_since_restore: 773000
  timesteps_this_iter: 1000
  timesteps_total: 773000
  training_iteration: 498
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10879], 3887 s, 498 iter, 773000 ts, 309 rew

agent-1: 179.0
Sum Reward: 179.0
Avg Reward: 179.0
Min Reward: 179.0
Max Reward: 179.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_15-16-47
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 430.0
  episode_reward_mean: 308.99
  episode_reward_min: 5.0
  episodes_this_iter: 1
  episodes_total: 773
  experiment_id: cb3a18e0a26e466496590bc0542b68c4
  hostname: gpu020
  info:
    apply_time_ms: 2.89
    dispatch_time_ms: 27.239
    learner:
      cur_lr: 0.0013085182290524244
      grad_gnorm: 29.008188247680664
      policy_entropy: 3.5585408210754395
      policy_loss: -1.6817251443862915
      var_gnorm: 33.13956069946289
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 5.299011707305908
    num_steps_sampled: 774000
    num_steps_trained: 774000
    wait_time_ms: 18.56
  iterations_since_restore: 499
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 10879
  policy_reward_mean: {}
  time_since_restore: 3893.3000469207764
  time_this_iter_s: 5.611793518066406
  time_total_s: 3893.3000469207764
  timestamp: 1594149407
  timesteps_since_restore: 774000
  timesteps_this_iter: 1000
  timesteps_total: 774000
  training_iteration: 499
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=10879], 3893 s, 499 iter, 774000 ts, 309 rew

agent-1: 225.0
Sum Reward: 225.0
Avg Reward: 225.0
Min Reward: 225.0
Max Reward: 225.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
agent-1: 172.0
Sum Reward: 172.0
Avg Reward: 172.0
Min Reward: 172.0
Max Reward: 172.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_15-16-56
  done: true
  episode_len_mean: 1000.0
  episode_reward_max: 430.0
  episode_reward_mean: 311.4
  episode_reward_min: 90.0
  episodes_this_iter: 2
  episodes_total: 775
  experiment_id: cb3a18e0a26e466496590bc0542b68c4
  hostname: gpu020
  info:
    apply_time_ms: 2.541
    dispatch_time_ms: 6.418
    learner:
      cur_lr: 0.0013084516394883394
      grad_gnorm: 13.656036376953125
      policy_entropy: 2.9840993881225586
      policy_loss: -0.2582080364227295
      var_gnorm: 33.161705017089844
      vf_explained_var: -0.40877509117126465
      vf_loss: 3.1404929161071777
    num_steps_sampled: 776000
    num_steps_trained: 776000
    wait_time_ms: 33.772
  iterations_since_restore: 500
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 10879
  policy_reward_mean: {}
  time_since_restore: 3902.368777513504
  time_this_iter_s: 9.068730592727661
  time_total_s: 3902.368777513504
  timestamp: 1594149416
  timesteps_since_restore: 776000
  timesteps_this_iter: 2000
  timesteps_total: 776000
  training_iteration: 500
  
W0707 15:16:56.423435 10872 client_connection.cc:255] [worker]ProcessMessage with type 7 took 154 ms.
/h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/numpy/core/fromnumeric.py:3335: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/numpy/core/_methods.py:161: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)
[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.[0m
WARNING: Logging before InitGoogleLogging() is written to STDERR
E0707 15:16:57.109268 10904 raylet_client.cc:345] IOError: [RayletClient] Connection closed unexpectedly. [RayletClient] Failed to push profile events.
<string>:74: RuntimeWarning: invalid value encountered in double_scalars
<string>:74: RuntimeWarning: invalid value encountered in double_scalars
WARNING: Logging before InitGoogleLogging() is written to STDERR
E0707 15:16:57.597342 10898 raylet_client.cc:345] IOError: [RayletClient] Connection closed unexpectedly. [RayletClient] Failed to push profile events.
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 0.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
TERMINATED trials:
 - A3C_harvest_env_0:	TERMINATED [pid=10879], 3902 s, 500 iter, 776000 ts, 311 rew

== Status ==
Using FIFO scheduling algorithm.
Resources requested: 0.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
TERMINATED trials:
 - A3C_harvest_env_0:	TERMINATED [pid=10879], 3902 s, 500 iter, 776000 ts, 311 rew

E0707 15:16:58.265283 10904 raylet_client.cc:345] IOError: [RayletClient] Connection closed unexpectedly. [RayletClient] Failed to push profile events.
Commencing experiment harvest_A3C
