/h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:523: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint8 = np.dtype([("qint8", np.int8, 1)])
/h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:524: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint8 = np.dtype([("quint8", np.uint8, 1)])
/h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint16 = np.dtype([("qint16", np.int16, 1)])
/h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint16 = np.dtype([("quint16", np.uint16, 1)])
/h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint32 = np.dtype([("qint32", np.int32, 1)])
/h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:532: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  np_resource = np.dtype([("resource", np.ubyte, 1)])
Process STDOUT and STDERR is being redirected to /tmp/ray/session_2020-07-05_20-06-04_20370/logs.
Waiting for redis server at 127.0.0.1:18378 to respond...
Waiting for redis server at 127.0.0.1:10323 to respond...
Warning: Capping object memory store to 20.0GB. To increase this further, specify `object_store_memory` when calling ray.init() or ray start.
Starting the Plasma object store with 20.0 GB memory using /dev/shm.

======================================================================
View the web UI at http://localhost:8888/notebooks/ray_ui.ipynb?token=cd8fd7325651e2754a7e3908ac9075dcabb3f479b21e0507
======================================================================

== Status ==
Using FIFO scheduling algorithm.
Resources requested: 0/2 CPUs, 0/1 GPUs
Memory usage on this node: 14.7/202.5 GB

Created LogSyncer for /h/zhaostep/ray_results/harvest_A3C/A3C_harvest_env_0_2020-07-05_20-06-05kq_wj8re -> 
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 14.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING

/h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:523: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint8 = np.dtype([("qint8", np.int8, 1)])
/h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:524: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint8 = np.dtype([("quint8", np.uint8, 1)])
/h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint16 = np.dtype([("qint16", np.int16, 1)])
/h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint16 = np.dtype([("quint16", np.uint16, 1)])
/h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint32 = np.dtype([("qint32", np.int32, 1)])
/h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:532: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  np_resource = np.dtype([("resource", np.ubyte, 1)])
2020-07-05 20:06:19,263	INFO policy_evaluator.py:262 -- Creating policy evaluation worker 0 on CPU (please ignore any CUDA init errors)
2020-07-05 20:06:19.264316: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
From /h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/ray/rllib/models/lstm.py:59: BasicLSTMCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.
Instructions for updating:
This class is deprecated, please use tf.nn.rnn_cell.LSTMCell, which supports all the feature this cell currently has. Please replace the existing code with tf.nn.rnn_cell.LSTMCell(name='basic_lstm_cell').
/h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:523: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint8 = np.dtype([("qint8", np.int8, 1)])
/h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:524: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint8 = np.dtype([("quint8", np.uint8, 1)])
/h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint16 = np.dtype([("qint16", np.int16, 1)])
/h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint16 = np.dtype([("quint16", np.uint16, 1)])
/h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint32 = np.dtype([("qint32", np.int32, 1)])
/h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:532: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  np_resource = np.dtype([("resource", np.ubyte, 1)])
2020-07-05 20:06:30,978	INFO policy_evaluator.py:262 -- Creating policy evaluation worker 2 on CPU (please ignore any CUDA init errors)
2020-07-05 20:06:30.979443: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
/h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:523: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint8 = np.dtype([("qint8", np.int8, 1)])
/h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:524: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint8 = np.dtype([("quint8", np.uint8, 1)])
/h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint16 = np.dtype([("qint16", np.int16, 1)])
/h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint16 = np.dtype([("quint16", np.uint16, 1)])
/h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint32 = np.dtype([("qint32", np.int32, 1)])
/h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:532: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  np_resource = np.dtype([("resource", np.ubyte, 1)])
2020-07-05 20:06:31,013	INFO policy_evaluator.py:262 -- Creating policy evaluation worker 1 on CPU (please ignore any CUDA init errors)
2020-07-05 20:06:31.014550: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
From /h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/ray/rllib/models/lstm.py:59: BasicLSTMCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.
Instructions for updating:
This class is deprecated, please use tf.nn.rnn_cell.LSTMCell, which supports all the feature this cell currently has. Please replace the existing code with tf.nn.rnn_cell.LSTMCell(name='basic_lstm_cell').
From /h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/ray/rllib/models/lstm.py:59: BasicLSTMCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.
Instructions for updating:
This class is deprecated, please use tf.nn.rnn_cell.LSTMCell, which supports all the feature this cell currently has. Please replace the existing code with tf.nn.rnn_cell.LSTMCell(name='basic_lstm_cell').
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-06-38
  done: false
  episode_len_mean: .nan
  episode_reward_max: .nan
  episode_reward_mean: .nan
  episode_reward_min: .nan
  episodes_this_iter: 0
  episodes_total: 0
  experiment_id: 325b24caee6c4209bf8cf01af4f33e4d
  hostname: gpu048
  info:
    apply_time_ms: 3.199
    dispatch_time_ms: 7.28
    learner:
      cur_lr: 0.0013599999947473407
      grad_gnorm: 7.577854633331299
      policy_entropy: 16.302120208740234
      policy_loss: -0.8271316885948181
      var_gnorm: 18.037614822387695
      vf_explained_var: -1.0
      vf_loss: 0.08607874065637589
    num_steps_sampled: 1000
    num_steps_trained: 1000
    wait_time_ms: 39.661
  iterations_since_restore: 1
  node_ip: 172.17.8.48
  num_metric_batches_dropped: 0
  pid: 20453
  policy_reward_mean: {}
  time_since_restore: 18.437281608581543
  time_this_iter_s: 18.437281608581543
  time_total_s: 18.437281608581543
  timestamp: 1593993998
  timesteps_since_restore: 1000
  timesteps_this_iter: 1000
  timesteps_total: 1000
  training_iteration: 1
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 15.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=20453], 18 s, 1 iter, 1000 ts, nan rew

[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.[0m
agent-1: 56.0
Sum Reward: 56.0
Avg Reward: 56.0
Min Reward: 56.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-06-44
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 56.0
  episode_reward_mean: 56.0
  episode_reward_min: 56.0
  episodes_this_iter: 1
  episodes_total: 1
  experiment_id: 325b24caee6c4209bf8cf01af4f33e4d
  hostname: gpu048
  info:
    apply_time_ms: 2.516
    dispatch_time_ms: 7.536
    learner:
      cur_lr: 0.0013599334051832557
      grad_gnorm: 14.771663665771484
      policy_entropy: 14.179091453552246
      policy_loss: 3.2272233963012695
      var_gnorm: 18.094139099121094
      vf_explained_var: -9.071826934814453e-05
      vf_loss: 1.5194436311721802
    num_steps_sampled: 2000
    num_steps_trained: 2000
    wait_time_ms: 41.575
  iterations_since_restore: 2
  node_ip: 172.17.8.48
  num_metric_batches_dropped: 0
  pid: 20453
  policy_reward_mean: {}
  time_since_restore: 23.89399218559265
  time_this_iter_s: 5.456710577011108
  time_total_s: 23.89399218559265
  timestamp: 1593994004
  timesteps_since_restore: 2000
  timesteps_this_iter: 1000
  timesteps_total: 2000
  training_iteration: 2
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 15.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=20453], 23 s, 2 iter, 2000 ts, 56 rew

[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.[0m
agent-1: 105.0
Sum Reward: 105.0
Avg Reward: 105.0
Min Reward: 105.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-06-49
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 105.0
  episode_reward_mean: 80.5
  episode_reward_min: 56.0
  episodes_this_iter: 1
  episodes_total: 2
  experiment_id: 325b24caee6c4209bf8cf01af4f33e4d
  hostname: gpu048
  info:
    apply_time_ms: 2.682
    dispatch_time_ms: 9.952
    learner:
      cur_lr: 0.0013598668156191707
      grad_gnorm: 8.411894798278809
      policy_entropy: 10.988116264343262
      policy_loss: -3.7880184650421143
      var_gnorm: 18.11237144470215
      vf_explained_var: 0.0012406706809997559
      vf_loss: 0.4148757755756378
    num_steps_sampled: 3000
    num_steps_trained: 3000
    wait_time_ms: 38.763
  iterations_since_restore: 3
  node_ip: 172.17.8.48
  num_metric_batches_dropped: 0
  pid: 20453
  policy_reward_mean: {}
  time_since_restore: 28.958287954330444
  time_this_iter_s: 5.064295768737793
  time_total_s: 28.958287954330444
  timestamp: 1593994009
  timesteps_since_restore: 3000
  timesteps_this_iter: 1000
  timesteps_total: 3000
  training_iteration: 3
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 16.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=20453], 28 s, 3 iter, 3000 ts, 80.5 rew

agent-1: 104.0
Sum Reward: 104.0
Avg Reward: 104.0
Min Reward: 104.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-06-54
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 105.0
  episode_reward_mean: 88.33333333333333
  episode_reward_min: 56.0
  episodes_this_iter: 1
  episodes_total: 3
  experiment_id: 325b24caee6c4209bf8cf01af4f33e4d
  hostname: gpu048
  info:
    apply_time_ms: 2.375
    dispatch_time_ms: 8.27
    learner:
      cur_lr: 0.0013598002260550857
      grad_gnorm: 6.832648277282715
      policy_entropy: 14.001220703125
      policy_loss: -3.760993242263794
      var_gnorm: 18.18947982788086
      vf_explained_var: -1.0
      vf_loss: 0.6417738795280457
    num_steps_sampled: 4000
    num_steps_trained: 4000
    wait_time_ms: 45.78
  iterations_since_restore: 4
  node_ip: 172.17.8.48
  num_metric_batches_dropped: 0
  pid: 20453
  policy_reward_mean: {}
  time_since_restore: 34.42663908004761
  time_this_iter_s: 5.468351125717163
  time_total_s: 34.42663908004761
  timestamp: 1593994014
  timesteps_since_restore: 4000
  timesteps_this_iter: 1000
  timesteps_total: 4000
  training_iteration: 4
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 16.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=20453], 34 s, 4 iter, 4000 ts, 88.3 rew

agent-1: 117.0
Sum Reward: 117.0
Avg Reward: 117.0
Min Reward: 117.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-07-00
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 117.0
  episode_reward_mean: 95.5
  episode_reward_min: 56.0
  episodes_this_iter: 1
  episodes_total: 4
  experiment_id: 325b24caee6c4209bf8cf01af4f33e4d
  hostname: gpu048
  info:
    apply_time_ms: 3.509
    dispatch_time_ms: 8.612
    learner:
      cur_lr: 0.0013597336364910007
      grad_gnorm: 40.0
      policy_entropy: 12.289928436279297
      policy_loss: 13.203109741210938
      var_gnorm: 18.31650161743164
      vf_explained_var: -0.2262517213821411
      vf_loss: 10.328557968139648
    num_steps_sampled: 5000
    num_steps_trained: 5000
    wait_time_ms: 43.475
  iterations_since_restore: 5
  node_ip: 172.17.8.48
  num_metric_batches_dropped: 0
  pid: 20453
  policy_reward_mean: {}
  time_since_restore: 39.6076226234436
  time_this_iter_s: 5.180983543395996
  time_total_s: 39.6076226234436
  timestamp: 1593994020
  timesteps_since_restore: 5000
  timesteps_this_iter: 1000
  timesteps_total: 5000
  training_iteration: 5
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 16.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=20453], 39 s, 5 iter, 5000 ts, 95.5 rew

agent-1: 176.0
Sum Reward: 176.0
Avg Reward: 176.0
Min Reward: 176.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
agent-1: 184.0
Sum Reward: 184.0
Avg Reward: 184.0
Min Reward: 184.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-07-09
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 184.0
  episode_reward_mean: 123.66666666666667
  episode_reward_min: 56.0
  episodes_this_iter: 2
  episodes_total: 6
  experiment_id: 325b24caee6c4209bf8cf01af4f33e4d
  hostname: gpu048
  info:
    apply_time_ms: 3.501
    dispatch_time_ms: 9.053
    learner:
      cur_lr: 0.0013596670469269156
      grad_gnorm: 16.50711441040039
      policy_entropy: 11.656730651855469
      policy_loss: 5.796520233154297
      var_gnorm: 18.7054443359375
      vf_explained_var: 0.02861618995666504
      vf_loss: 1.763519048690796
    num_steps_sampled: 7000
    num_steps_trained: 7000
    wait_time_ms: 32.912
  iterations_since_restore: 6
  node_ip: 172.17.8.48
  num_metric_batches_dropped: 0
  pid: 20453
  policy_reward_mean: {}
  time_since_restore: 48.7323100566864
  time_this_iter_s: 9.124687433242798
  time_total_s: 48.7323100566864
  timestamp: 1593994029
  timesteps_since_restore: 7000
  timesteps_this_iter: 2000
  timesteps_total: 7000
  training_iteration: 6
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 16.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=20453], 48 s, 6 iter, 7000 ts, 124 rew

agent-1: 215.0
Sum Reward: 215.0
Avg Reward: 215.0
Min Reward: 215.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
agent-1: 201.0
Sum Reward: 201.0
Avg Reward: 201.0
Min Reward: 201.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-07-17
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 215.0
  episode_reward_mean: 144.75
  episode_reward_min: 56.0
  episodes_this_iter: 2
  episodes_total: 8
  experiment_id: 325b24caee6c4209bf8cf01af4f33e4d
  hostname: gpu048
  info:
    apply_time_ms: 3.253
    dispatch_time_ms: 10.367
    learner:
      cur_lr: 0.0013595337513834238
      grad_gnorm: 40.0
      policy_entropy: 9.437908172607422
      policy_loss: -15.147198677062988
      var_gnorm: 19.129179000854492
      vf_explained_var: -1.0
      vf_loss: 10.630620002746582
    num_steps_sampled: 9000
    num_steps_trained: 9000
    wait_time_ms: 29.672
  iterations_since_restore: 7
  node_ip: 172.17.8.48
  num_metric_batches_dropped: 0
  pid: 20453
  policy_reward_mean: {}
  time_since_restore: 57.324222803115845
  time_this_iter_s: 8.591912746429443
  time_total_s: 57.324222803115845
  timestamp: 1593994037
  timesteps_since_restore: 9000
  timesteps_this_iter: 2000
  timesteps_total: 9000
  training_iteration: 7
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 16.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=20453], 57 s, 7 iter, 9000 ts, 145 rew

agent-1: 210.0
Sum Reward: 210.0
Avg Reward: 210.0
Min Reward: 210.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
agent-1: 221.0
Sum Reward: 221.0
Avg Reward: 221.0
Min Reward: 221.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-07-26
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 221.0
  episode_reward_mean: 158.9
  episode_reward_min: 56.0
  episodes_this_iter: 2
  episodes_total: 10
  experiment_id: 325b24caee6c4209bf8cf01af4f33e4d
  hostname: gpu048
  info:
    apply_time_ms: 2.625
    dispatch_time_ms: 8.346
    learner:
      cur_lr: 0.0013594005722552538
      grad_gnorm: 40.000003814697266
      policy_entropy: 6.975691795349121
      policy_loss: -5.211749076843262
      var_gnorm: 19.540651321411133
      vf_explained_var: -0.3246804475784302
      vf_loss: 12.825037956237793
    num_steps_sampled: 11000
    num_steps_trained: 11000
    wait_time_ms: 32.3
  iterations_since_restore: 8
  node_ip: 172.17.8.48
  num_metric_batches_dropped: 0
  pid: 20453
  policy_reward_mean: {}
  time_since_restore: 65.96506452560425
  time_this_iter_s: 8.640841722488403
  time_total_s: 65.96506452560425
  timestamp: 1593994046
  timesteps_since_restore: 11000
  timesteps_this_iter: 2000
  timesteps_total: 11000
  training_iteration: 8
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 17.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=20453], 65 s, 8 iter, 11000 ts, 159 rew

agent-1: 258.0
Sum Reward: 258.0
Avg Reward: 258.0
Min Reward: 258.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
agent-1: 263.0
Sum Reward: 263.0
Avg Reward: 263.0
Min Reward: 263.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-07-35
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 263.0
  episode_reward_mean: 175.83333333333334
  episode_reward_min: 56.0
  episodes_this_iter: 2
  episodes_total: 12
  experiment_id: 325b24caee6c4209bf8cf01af4f33e4d
  hostname: gpu048
  info:
    apply_time_ms: 2.739
    dispatch_time_ms: 7.276
    learner:
      cur_lr: 0.0013592673931270838
      grad_gnorm: 5.313925266265869
      policy_entropy: 6.22471284866333
      policy_loss: 0.4664108455181122
      var_gnorm: 19.806501388549805
      vf_explained_var: -0.15385150909423828
      vf_loss: 3.0590033531188965
    num_steps_sampled: 13000
    num_steps_trained: 13000
    wait_time_ms: 34.579
  iterations_since_restore: 9
  node_ip: 172.17.8.48
  num_metric_batches_dropped: 0
  pid: 20453
  policy_reward_mean: {}
  time_since_restore: 74.56792831420898
  time_this_iter_s: 8.602863788604736
  time_total_s: 74.56792831420898
  timestamp: 1593994055
  timesteps_since_restore: 13000
  timesteps_this_iter: 2000
  timesteps_total: 13000
  training_iteration: 9
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 17.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=20453], 74 s, 9 iter, 13000 ts, 176 rew

agent-1: 306.0
Sum Reward: 306.0
Avg Reward: 306.0
Min Reward: 306.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
agent-1: 311.0
Sum Reward: 311.0
Avg Reward: 311.0
Min Reward: 311.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-07-43
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 311.0
  episode_reward_mean: 194.78571428571428
  episode_reward_min: 56.0
  episodes_this_iter: 2
  episodes_total: 14
  experiment_id: 325b24caee6c4209bf8cf01af4f33e4d
  hostname: gpu048
  info:
    apply_time_ms: 2.979
    dispatch_time_ms: 8.953
    learner:
      cur_lr: 0.0013591342139989138
      grad_gnorm: 19.478092193603516
      policy_entropy: 7.005342483520508
      policy_loss: -4.050616264343262
      var_gnorm: 20.093679428100586
      vf_explained_var: -3.516674041748047e-05
      vf_loss: 3.16031551361084
    num_steps_sampled: 15000
    num_steps_trained: 15000
    wait_time_ms: 30.651
  iterations_since_restore: 10
  node_ip: 172.17.8.48
  num_metric_batches_dropped: 0
  pid: 20453
  policy_reward_mean: {}
  time_since_restore: 83.24549651145935
  time_this_iter_s: 8.677568197250366
  time_total_s: 83.24549651145935
  timestamp: 1593994063
  timesteps_since_restore: 15000
  timesteps_this_iter: 2000
  timesteps_total: 15000
  training_iteration: 10
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 17.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=20453], 83 s, 10 iter, 15000 ts, 195 rew

agent-1: 253.0
Sum Reward: 253.0
Avg Reward: 253.0
Min Reward: 253.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
agent-1: 308.0
Sum Reward: 308.0
Avg Reward: 308.0
Min Reward: 308.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-07-52
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 311.0
  episode_reward_mean: 205.5
  episode_reward_min: 56.0
  episodes_this_iter: 2
  episodes_total: 16
  experiment_id: 325b24caee6c4209bf8cf01af4f33e4d
  hostname: gpu048
  info:
    apply_time_ms: 2.572
    dispatch_time_ms: 7.178
    learner:
      cur_lr: 0.0013590010348707438
      grad_gnorm: 38.79704284667969
      policy_entropy: 5.467000961303711
      policy_loss: -1.2799251079559326
      var_gnorm: 20.322357177734375
      vf_explained_var: -0.5312632322311401
      vf_loss: 4.6687188148498535
    num_steps_sampled: 17000
    num_steps_trained: 17000
    wait_time_ms: 33.52
  iterations_since_restore: 11
  node_ip: 172.17.8.48
  num_metric_batches_dropped: 0
  pid: 20453
  policy_reward_mean: {}
  time_since_restore: 91.93318748474121
  time_this_iter_s: 8.68769097328186
  time_total_s: 91.93318748474121
  timestamp: 1593994072
  timesteps_since_restore: 17000
  timesteps_this_iter: 2000
  timesteps_total: 17000
  training_iteration: 11
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 17.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=20453], 91 s, 11 iter, 17000 ts, 206 rew

agent-1: 246.0
Sum Reward: 246.0
Avg Reward: 246.0
Min Reward: 246.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
agent-1: 275.0
Sum Reward: 275.0
Avg Reward: 275.0
Min Reward: 275.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-08-01
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 311.0
  episode_reward_mean: 211.61111111111111
  episode_reward_min: 56.0
  episodes_this_iter: 2
  episodes_total: 18
  experiment_id: 325b24caee6c4209bf8cf01af4f33e4d
  hostname: gpu048
  info:
    apply_time_ms: 2.42
    dispatch_time_ms: 7.276
    learner:
      cur_lr: 0.0013588678557425737
      grad_gnorm: 40.000003814697266
      policy_entropy: 5.239111423492432
      policy_loss: -4.045337200164795
      var_gnorm: 20.548734664916992
      vf_explained_var: -0.7321257591247559
      vf_loss: 1.3115887641906738
    num_steps_sampled: 19000
    num_steps_trained: 19000
    wait_time_ms: 36.907
  iterations_since_restore: 12
  node_ip: 172.17.8.48
  num_metric_batches_dropped: 0
  pid: 20453
  policy_reward_mean: {}
  time_since_restore: 100.61164164543152
  time_this_iter_s: 8.678454160690308
  time_total_s: 100.61164164543152
  timestamp: 1593994081
  timesteps_since_restore: 19000
  timesteps_this_iter: 2000
  timesteps_total: 19000
  training_iteration: 12
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 17.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=20453], 100 s, 12 iter, 19000 ts, 212 rew

agent-1: 266.0
Sum Reward: 266.0
Avg Reward: 266.0
Min Reward: 266.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
agent-1: 322.0
Sum Reward: 322.0
Avg Reward: 322.0
Min Reward: 322.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-08-10
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 322.0
  episode_reward_mean: 219.85
  episode_reward_min: 56.0
  episodes_this_iter: 2
  episodes_total: 20
  experiment_id: 325b24caee6c4209bf8cf01af4f33e4d
  hostname: gpu048
  info:
    apply_time_ms: 3.282
    dispatch_time_ms: 8.734
    learner:
      cur_lr: 0.001358734560199082
      grad_gnorm: 30.60087013244629
      policy_entropy: 3.909519672393799
      policy_loss: 3.9896204471588135
      var_gnorm: 20.901687622070312
      vf_explained_var: -0.02737259864807129
      vf_loss: 9.405749320983887
    num_steps_sampled: 21000
    num_steps_trained: 21000
    wait_time_ms: 31.517
  iterations_since_restore: 13
  node_ip: 172.17.8.48
  num_metric_batches_dropped: 0
  pid: 20453
  policy_reward_mean: {}
  time_since_restore: 109.3350088596344
  time_this_iter_s: 8.72336721420288
  time_total_s: 109.3350088596344
  timestamp: 1593994090
  timesteps_since_restore: 21000
  timesteps_this_iter: 2000
  timesteps_total: 21000
  training_iteration: 13
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 18.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=20453], 109 s, 13 iter, 21000 ts, 220 rew

agent-1: 338.0
Sum Reward: 338.0
Avg Reward: 338.0
Min Reward: 338.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
agent-1: 324.0
Sum Reward: 324.0
Avg Reward: 324.0
Min Reward: 324.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-08-18
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 338.0
  episode_reward_mean: 229.95454545454547
  episode_reward_min: 56.0
  episodes_this_iter: 2
  episodes_total: 22
  experiment_id: 325b24caee6c4209bf8cf01af4f33e4d
  hostname: gpu048
  info:
    apply_time_ms: 4.116
    dispatch_time_ms: 8.445
    learner:
      cur_lr: 0.0013586013810709119
      grad_gnorm: 39.999996185302734
      policy_entropy: 8.052079200744629
      policy_loss: -14.770097732543945
      var_gnorm: 21.11060905456543
      vf_explained_var: -1.0
      vf_loss: 23.214534759521484
    num_steps_sampled: 23000
    num_steps_trained: 23000
    wait_time_ms: 32.125
  iterations_since_restore: 14
  node_ip: 172.17.8.48
  num_metric_batches_dropped: 0
  pid: 20453
  policy_reward_mean: {}
  time_since_restore: 118.09236645698547
  time_this_iter_s: 8.757357597351074
  time_total_s: 118.09236645698547
  timestamp: 1593994098
  timesteps_since_restore: 23000
  timesteps_this_iter: 2000
  timesteps_total: 23000
  training_iteration: 14
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 18.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=20453], 118 s, 14 iter, 23000 ts, 230 rew

agent-1: 289.0
Sum Reward: 289.0
Avg Reward: 289.0
Min Reward: 289.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
agent-1: 250.0
Sum Reward: 250.0
Avg Reward: 250.0
Min Reward: 250.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-08-27
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 338.0
  episode_reward_mean: 233.25
  episode_reward_min: 56.0
  episodes_this_iter: 2
  episodes_total: 24
  experiment_id: 325b24caee6c4209bf8cf01af4f33e4d
  hostname: gpu048
  info:
    apply_time_ms: 4.429
    dispatch_time_ms: 7.682
    learner:
      cur_lr: 0.0013584682019427419
      grad_gnorm: 39.99998474121094
      policy_entropy: 4.538078784942627
      policy_loss: 1.6047918796539307
      var_gnorm: 21.148351669311523
      vf_explained_var: -0.7076807022094727
      vf_loss: 4.07131814956665
    num_steps_sampled: 25000
    num_steps_trained: 25000
    wait_time_ms: 30.637
  iterations_since_restore: 15
  node_ip: 172.17.8.48
  num_metric_batches_dropped: 0
  pid: 20453
  policy_reward_mean: {}
  time_since_restore: 126.70588111877441
  time_this_iter_s: 8.61351466178894
  time_total_s: 126.70588111877441
  timestamp: 1593994107
  timesteps_since_restore: 25000
  timesteps_this_iter: 2000
  timesteps_total: 25000
  training_iteration: 15
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 18.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=20453], 126 s, 15 iter, 25000 ts, 233 rew

agent-1: 310.0
Sum Reward: 310.0
Avg Reward: 310.0
Min Reward: 310.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
agent-1: 278.0
Sum Reward: 278.0
Avg Reward: 278.0
Min Reward: 278.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-08-36
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 338.0
  episode_reward_mean: 237.92307692307693
  episode_reward_min: 56.0
  episodes_this_iter: 2
  episodes_total: 26
  experiment_id: 325b24caee6c4209bf8cf01af4f33e4d
  hostname: gpu048
  info:
    apply_time_ms: 2.542
    dispatch_time_ms: 9.797
    learner:
      cur_lr: 0.0013583350228145719
      grad_gnorm: 40.0
      policy_entropy: 3.6650617122650146
      policy_loss: 10.500925064086914
      var_gnorm: 21.228378295898438
      vf_explained_var: 0.47148776054382324
      vf_loss: 18.21933364868164
    num_steps_sampled: 27000
    num_steps_trained: 27000
    wait_time_ms: 35.104
  iterations_since_restore: 16
  node_ip: 172.17.8.48
  num_metric_batches_dropped: 0
  pid: 20453
  policy_reward_mean: {}
  time_since_restore: 135.40013480186462
  time_this_iter_s: 8.69425368309021
  time_total_s: 135.40013480186462
  timestamp: 1593994116
  timesteps_since_restore: 27000
  timesteps_this_iter: 2000
  timesteps_total: 27000
  training_iteration: 16
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 18.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=20453], 135 s, 16 iter, 27000 ts, 238 rew

agent-1: 302.0
Sum Reward: 302.0
Avg Reward: 302.0
Min Reward: 302.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
agent-1: 295.0
Sum Reward: 295.0
Avg Reward: 295.0
Min Reward: 295.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-08-45
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 338.0
  episode_reward_mean: 242.25
  episode_reward_min: 56.0
  episodes_this_iter: 2
  episodes_total: 28
  experiment_id: 325b24caee6c4209bf8cf01af4f33e4d
  hostname: gpu048
  info:
    apply_time_ms: 3.895
    dispatch_time_ms: 7.604
    learner:
      cur_lr: 0.0013582018436864018
      grad_gnorm: 27.146034240722656
      policy_entropy: 2.9163661003112793
      policy_loss: 1.265282392501831
      var_gnorm: 21.278297424316406
      vf_explained_var: 0.0
      vf_loss: 3.7114007472991943
    num_steps_sampled: 29000
    num_steps_trained: 29000
    wait_time_ms: 32.762
  iterations_since_restore: 17
  node_ip: 172.17.8.48
  num_metric_batches_dropped: 0
  pid: 20453
  policy_reward_mean: {}
  time_since_restore: 144.08486604690552
  time_this_iter_s: 8.684731245040894
  time_total_s: 144.08486604690552
  timestamp: 1593994125
  timesteps_since_restore: 29000
  timesteps_this_iter: 2000
  timesteps_total: 29000
  training_iteration: 17
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 19.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=20453], 144 s, 17 iter, 29000 ts, 242 rew

agent-1: 286.0
Sum Reward: 286.0
Avg Reward: 286.0
Min Reward: 286.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
agent-1: 245.0
Sum Reward: 245.0
Avg Reward: 245.0
Min Reward: 245.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-08-53
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 338.0
  episode_reward_mean: 243.8
  episode_reward_min: 56.0
  episodes_this_iter: 2
  episodes_total: 30
  experiment_id: 325b24caee6c4209bf8cf01af4f33e4d
  hostname: gpu048
  info:
    apply_time_ms: 2.685
    dispatch_time_ms: 7.309
    learner:
      cur_lr: 0.00135806854814291
      grad_gnorm: 22.709625244140625
      policy_entropy: 3.2103304862976074
      policy_loss: -4.577262878417969
      var_gnorm: 21.27786636352539
      vf_explained_var: 0.0
      vf_loss: 2.5560271739959717
    num_steps_sampled: 31000
    num_steps_trained: 31000
    wait_time_ms: 31.374
  iterations_since_restore: 18
  node_ip: 172.17.8.48
  num_metric_batches_dropped: 0
  pid: 20453
  policy_reward_mean: {}
  time_since_restore: 152.83861351013184
  time_this_iter_s: 8.753747463226318
  time_total_s: 152.83861351013184
  timestamp: 1593994133
  timesteps_since_restore: 31000
  timesteps_this_iter: 2000
  timesteps_total: 31000
  training_iteration: 18
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 19.3/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=20453], 152 s, 18 iter, 31000 ts, 244 rew

agent-1: 249.0
Sum Reward: 249.0
Avg Reward: 249.0
Min Reward: 249.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
agent-1: 218.0
Sum Reward: 218.0
Avg Reward: 218.0
Min Reward: 218.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-09-02
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 338.0
  episode_reward_mean: 243.15625
  episode_reward_min: 56.0
  episodes_this_iter: 2
  episodes_total: 32
  experiment_id: 325b24caee6c4209bf8cf01af4f33e4d
  hostname: gpu048
  info:
    apply_time_ms: 2.864
    dispatch_time_ms: 7.027
    learner:
      cur_lr: 0.00135793536901474
      grad_gnorm: 40.0
      policy_entropy: 3.629342794418335
      policy_loss: 2.7398996353149414
      var_gnorm: 21.208581924438477
      vf_explained_var: -0.2747931480407715
      vf_loss: 19.00248908996582
    num_steps_sampled: 33000
    num_steps_trained: 33000
    wait_time_ms: 33.934
  iterations_since_restore: 19
  node_ip: 172.17.8.48
  num_metric_batches_dropped: 0
  pid: 20453
  policy_reward_mean: {}
  time_since_restore: 161.40764021873474
  time_this_iter_s: 8.569026708602905
  time_total_s: 161.40764021873474
  timestamp: 1593994142
  timesteps_since_restore: 33000
  timesteps_this_iter: 2000
  timesteps_total: 33000
  training_iteration: 19
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 19.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=20453], 161 s, 19 iter, 33000 ts, 243 rew

agent-1: 261.0
Sum Reward: 261.0
Avg Reward: 261.0
Min Reward: 261.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
agent-1: 268.0
Sum Reward: 268.0
Avg Reward: 268.0
Min Reward: 268.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-09-11
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 338.0
  episode_reward_mean: 244.41176470588235
  episode_reward_min: 56.0
  episodes_this_iter: 2
  episodes_total: 34
  experiment_id: 325b24caee6c4209bf8cf01af4f33e4d
  hostname: gpu048
  info:
    apply_time_ms: 2.949
    dispatch_time_ms: 7.564
    learner:
      cur_lr: 0.00135780218988657
      grad_gnorm: 20.659038543701172
      policy_entropy: 1.599143147468567
      policy_loss: -3.599951982498169
      var_gnorm: 21.41328239440918
      vf_explained_var: -0.005933165550231934
      vf_loss: 2.128742218017578
    num_steps_sampled: 35000
    num_steps_trained: 35000
    wait_time_ms: 33.101
  iterations_since_restore: 20
  node_ip: 172.17.8.48
  num_metric_batches_dropped: 0
  pid: 20453
  policy_reward_mean: {}
  time_since_restore: 170.02139687538147
  time_this_iter_s: 8.613756656646729
  time_total_s: 170.02139687538147
  timestamp: 1593994151
  timesteps_since_restore: 35000
  timesteps_this_iter: 2000
  timesteps_total: 35000
  training_iteration: 20
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 19.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=20453], 170 s, 20 iter, 35000 ts, 244 rew

agent-1: 341.0
Sum Reward: 341.0
Avg Reward: 341.0
Min Reward: 341.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
agent-1: 361.0
Sum Reward: 361.0
Avg Reward: 361.0
Min Reward: 361.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-09-19
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 361.0
  episode_reward_mean: 250.33333333333334
  episode_reward_min: 56.0
  episodes_this_iter: 2
  episodes_total: 36
  experiment_id: 325b24caee6c4209bf8cf01af4f33e4d
  hostname: gpu048
  info:
    apply_time_ms: 4.006
    dispatch_time_ms: 8.921
    learner:
      cur_lr: 0.0013576690107584
      grad_gnorm: 30.148345947265625
      policy_entropy: 2.514444351196289
      policy_loss: 10.576496124267578
      var_gnorm: 21.594160079956055
      vf_explained_var: -1.0
      vf_loss: 6.4644341468811035
    num_steps_sampled: 37000
    num_steps_trained: 37000
    wait_time_ms: 30.051
  iterations_since_restore: 21
  node_ip: 172.17.8.48
  num_metric_batches_dropped: 0
  pid: 20453
  policy_reward_mean: {}
  time_since_restore: 178.65703678131104
  time_this_iter_s: 8.635639905929565
  time_total_s: 178.65703678131104
  timestamp: 1593994159
  timesteps_since_restore: 37000
  timesteps_this_iter: 2000
  timesteps_total: 37000
  training_iteration: 21
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 20.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=20453], 178 s, 21 iter, 37000 ts, 250 rew

agent-1: 361.0
Sum Reward: 361.0
Avg Reward: 361.0
Min Reward: 361.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
agent-1: 274.0
Sum Reward: 274.0
Avg Reward: 274.0
Min Reward: 274.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-09-28
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 361.0
  episode_reward_mean: 253.8684210526316
  episode_reward_min: 56.0
  episodes_this_iter: 2
  episodes_total: 38
  experiment_id: 325b24caee6c4209bf8cf01af4f33e4d
  hostname: gpu048
  info:
    apply_time_ms: 3.15
    dispatch_time_ms: 8.887
    learner:
      cur_lr: 0.00135753583163023
      grad_gnorm: 32.90793228149414
      policy_entropy: 4.0939226150512695
      policy_loss: -1.0931320190429688
      var_gnorm: 21.748519897460938
      vf_explained_var: 1.1920928955078125e-07
      vf_loss: 6.1219282150268555
    num_steps_sampled: 39000
    num_steps_trained: 39000
    wait_time_ms: 30.999
  iterations_since_restore: 22
  node_ip: 172.17.8.48
  num_metric_batches_dropped: 0
  pid: 20453
  policy_reward_mean: {}
  time_since_restore: 187.09690046310425
  time_this_iter_s: 8.439863681793213
  time_total_s: 187.09690046310425
  timestamp: 1593994168
  timesteps_since_restore: 39000
  timesteps_this_iter: 2000
  timesteps_total: 39000
  training_iteration: 22
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 20.3/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=20453], 187 s, 22 iter, 39000 ts, 254 rew

agent-1: 153.0
Sum Reward: 153.0
Avg Reward: 153.0
Min Reward: 153.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
agent-1: 84.0
Sum Reward: 84.0
Avg Reward: 84.0
Min Reward: 84.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-09-36
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 361.0
  episode_reward_mean: 247.1
  episode_reward_min: 56.0
  episodes_this_iter: 2
  episodes_total: 40
  experiment_id: 325b24caee6c4209bf8cf01af4f33e4d
  hostname: gpu048
  info:
    apply_time_ms: 2.496
    dispatch_time_ms: 6.087
    learner:
      cur_lr: 0.00135740265250206
      grad_gnorm: 24.68533706665039
      policy_entropy: 2.9496469497680664
      policy_loss: -0.5372994542121887
      var_gnorm: 21.699859619140625
      vf_explained_var: 0.0
      vf_loss: 3.6674551963806152
    num_steps_sampled: 41000
    num_steps_trained: 41000
    wait_time_ms: 32.691
  iterations_since_restore: 23
  node_ip: 172.17.8.48
  num_metric_batches_dropped: 0
  pid: 20453
  policy_reward_mean: {}
  time_since_restore: 195.48364686965942
  time_this_iter_s: 8.386746406555176
  time_total_s: 195.48364686965942
  timestamp: 1593994176
  timesteps_since_restore: 41000
  timesteps_this_iter: 2000
  timesteps_total: 41000
  training_iteration: 23
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 20.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=20453], 195 s, 23 iter, 41000 ts, 247 rew

agent-1: 141.0
Sum Reward: 141.0
Avg Reward: 141.0
Min Reward: 141.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
agent-1: 150.0
Sum Reward: 150.0
Avg Reward: 150.0
Min Reward: 150.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-09-45
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 361.0
  episode_reward_mean: 242.26190476190476
  episode_reward_min: 56.0
  episodes_this_iter: 2
  episodes_total: 42
  experiment_id: 325b24caee6c4209bf8cf01af4f33e4d
  hostname: gpu048
  info:
    apply_time_ms: 3.097
    dispatch_time_ms: 7.962
    learner:
      cur_lr: 0.001357269356958568
      grad_gnorm: 10.46566104888916
      policy_entropy: 0.4575004577636719
      policy_loss: 0.02432667836546898
      var_gnorm: 21.891342163085938
      vf_explained_var: 0.0031616687774658203
      vf_loss: 2.774660348892212
    num_steps_sampled: 43000
    num_steps_trained: 43000
    wait_time_ms: 32.631
  iterations_since_restore: 24
  node_ip: 172.17.8.48
  num_metric_batches_dropped: 0
  pid: 20453
  policy_reward_mean: {}
  time_since_restore: 203.97799634933472
  time_this_iter_s: 8.494349479675293
  time_total_s: 203.97799634933472
  timestamp: 1593994185
  timesteps_since_restore: 43000
  timesteps_this_iter: 2000
  timesteps_total: 43000
  training_iteration: 24
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 20.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=20453], 203 s, 24 iter, 43000 ts, 242 rew

agent-1: 273.0
Sum Reward: 273.0
Avg Reward: 273.0
Min Reward: 273.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
agent-1: 335.0
Sum Reward: 335.0
Avg Reward: 335.0
Min Reward: 335.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-09-53
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 361.0
  episode_reward_mean: 245.0681818181818
  episode_reward_min: 56.0
  episodes_this_iter: 2
  episodes_total: 44
  experiment_id: 325b24caee6c4209bf8cf01af4f33e4d
  hostname: gpu048
  info:
    apply_time_ms: 3.637
    dispatch_time_ms: 9.229
    learner:
      cur_lr: 0.001357136177830398
      grad_gnorm: 7.067488193511963
      policy_entropy: 1.3436079025268555
      policy_loss: 0.47334930300712585
      var_gnorm: 22.18646240234375
      vf_explained_var: -0.6224907636642456
      vf_loss: 2.7017579078674316
    num_steps_sampled: 45000
    num_steps_trained: 45000
    wait_time_ms: 32.742
  iterations_since_restore: 25
  node_ip: 172.17.8.48
  num_metric_batches_dropped: 0
  pid: 20453
  policy_reward_mean: {}
  time_since_restore: 212.58874130249023
  time_this_iter_s: 8.610744953155518
  time_total_s: 212.58874130249023
  timestamp: 1593994193
  timesteps_since_restore: 45000
  timesteps_this_iter: 2000
  timesteps_total: 45000
  training_iteration: 25
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 21.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=20453], 212 s, 25 iter, 45000 ts, 245 rew

agent-1: 319.0
Sum Reward: 319.0
Avg Reward: 319.0
Min Reward: 319.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
agent-1: 329.0
Sum Reward: 329.0
Avg Reward: 329.0
Min Reward: 329.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-10-02
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 361.0
  episode_reward_mean: 248.5
  episode_reward_min: 56.0
  episodes_this_iter: 2
  episodes_total: 46
  experiment_id: 325b24caee6c4209bf8cf01af4f33e4d
  hostname: gpu048
  info:
    apply_time_ms: 3.891
    dispatch_time_ms: 8.62
    learner:
      cur_lr: 0.001357002998702228
      grad_gnorm: 19.88729476928711
      policy_entropy: 3.5391836166381836
      policy_loss: -5.010265350341797
      var_gnorm: 22.333032608032227
      vf_explained_var: -0.49923908710479736
      vf_loss: 3.4294662475585938
    num_steps_sampled: 47000
    num_steps_trained: 47000
    wait_time_ms: 30.01
  iterations_since_restore: 26
  node_ip: 172.17.8.48
  num_metric_batches_dropped: 0
  pid: 20453
  policy_reward_mean: {}
  time_since_restore: 221.1838686466217
  time_this_iter_s: 8.59512734413147
  time_total_s: 221.1838686466217
  timestamp: 1593994202
  timesteps_since_restore: 47000
  timesteps_this_iter: 2000
  timesteps_total: 47000
  training_iteration: 26
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 21.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=20453], 221 s, 26 iter, 47000 ts, 248 rew

agent-1: 289.0
Sum Reward: 289.0
Avg Reward: 289.0
Min Reward: 289.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
agent-1: 288.0
Sum Reward: 288.0
Avg Reward: 288.0
Min Reward: 288.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-10-11
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 361.0
  episode_reward_mean: 250.16666666666666
  episode_reward_min: 56.0
  episodes_this_iter: 2
  episodes_total: 48
  experiment_id: 325b24caee6c4209bf8cf01af4f33e4d
  hostname: gpu048
  info:
    apply_time_ms: 4.511
    dispatch_time_ms: 7.495
    learner:
      cur_lr: 0.001356869819574058
      grad_gnorm: 31.308979034423828
      policy_entropy: 5.644987106323242
      policy_loss: -11.54405403137207
      var_gnorm: 22.420455932617188
      vf_explained_var: -1.0
      vf_loss: 10.174341201782227
    num_steps_sampled: 49000
    num_steps_trained: 49000
    wait_time_ms: 33.971
  iterations_since_restore: 27
  node_ip: 172.17.8.48
  num_metric_batches_dropped: 0
  pid: 20453
  policy_reward_mean: {}
  time_since_restore: 229.9430730342865
  time_this_iter_s: 8.759204387664795
  time_total_s: 229.9430730342865
  timestamp: 1593994211
  timesteps_since_restore: 49000
  timesteps_this_iter: 2000
  timesteps_total: 49000
  training_iteration: 27
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 21.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=20453], 229 s, 27 iter, 49000 ts, 250 rew

agent-1: 274.0
Sum Reward: 274.0
Avg Reward: 274.0
Min Reward: 274.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
agent-1: 205.0
Sum Reward: 205.0
Avg Reward: 205.0
Min Reward: 205.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-10-19
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 361.0
  episode_reward_mean: 249.74
  episode_reward_min: 56.0
  episodes_this_iter: 2
  episodes_total: 50
  experiment_id: 325b24caee6c4209bf8cf01af4f33e4d
  hostname: gpu048
  info:
    apply_time_ms: 3.226
    dispatch_time_ms: 9.567
    learner:
      cur_lr: 0.001356736640445888
      grad_gnorm: 19.970849990844727
      policy_entropy: 2.788956642150879
      policy_loss: -0.40456342697143555
      var_gnorm: 22.273086547851562
      vf_explained_var: 5.960464477539063e-08
      vf_loss: 2.3649818897247314
    num_steps_sampled: 51000
    num_steps_trained: 51000
    wait_time_ms: 30.385
  iterations_since_restore: 28
  node_ip: 172.17.8.48
  num_metric_batches_dropped: 0
  pid: 20453
  policy_reward_mean: {}
  time_since_restore: 238.30241203308105
  time_this_iter_s: 8.359338998794556
  time_total_s: 238.30241203308105
  timestamp: 1593994219
  timesteps_since_restore: 51000
  timesteps_this_iter: 2000
  timesteps_total: 51000
  training_iteration: 28
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 21.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=20453], 238 s, 28 iter, 51000 ts, 250 rew

agent-1: 75.0
Sum Reward: 75.0
Avg Reward: 75.0
Min Reward: 75.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
agent-1: 129.0
Sum Reward: 129.0
Avg Reward: 129.0
Min Reward: 129.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-10-28
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 361.0
  episode_reward_mean: 244.05769230769232
  episode_reward_min: 56.0
  episodes_this_iter: 2
  episodes_total: 52
  experiment_id: 325b24caee6c4209bf8cf01af4f33e4d
  hostname: gpu048
  info:
    apply_time_ms: 3.749
    dispatch_time_ms: 8.198
    learner:
      cur_lr: 0.0013566033449023962
      grad_gnorm: 23.490793228149414
      policy_entropy: 5.2150678634643555
      policy_loss: -4.031641006469727
      var_gnorm: 22.248210906982422
      vf_explained_var: 0.0
      vf_loss: 3.219421625137329
    num_steps_sampled: 53000
    num_steps_trained: 53000
    wait_time_ms: 32.569
  iterations_since_restore: 29
  node_ip: 172.17.8.48
  num_metric_batches_dropped: 0
  pid: 20453
  policy_reward_mean: {}
  time_since_restore: 246.83519291877747
  time_this_iter_s: 8.532780885696411
  time_total_s: 246.83519291877747
  timestamp: 1593994228
  timesteps_since_restore: 53000
  timesteps_this_iter: 2000
  timesteps_total: 53000
  training_iteration: 29
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 22.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=20453], 246 s, 29 iter, 53000 ts, 244 rew

agent-1: 104.0
Sum Reward: 104.0
Avg Reward: 104.0
Min Reward: 104.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
agent-1: 132.0
Sum Reward: 132.0
Avg Reward: 132.0
Min Reward: 132.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-10-36
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 361.0
  episode_reward_mean: 239.38888888888889
  episode_reward_min: 56.0
  episodes_this_iter: 2
  episodes_total: 54
  experiment_id: 325b24caee6c4209bf8cf01af4f33e4d
  hostname: gpu048
  info:
    apply_time_ms: 3.867
    dispatch_time_ms: 7.81
    learner:
      cur_lr: 0.0013564701657742262
      grad_gnorm: 40.0
      policy_entropy: 10.353288650512695
      policy_loss: 18.87021827697754
      var_gnorm: 22.262773513793945
      vf_explained_var: -0.03101181983947754
      vf_loss: 20.3521785736084
    num_steps_sampled: 55000
    num_steps_trained: 55000
    wait_time_ms: 31.883
  iterations_since_restore: 30
  node_ip: 172.17.8.48
  num_metric_batches_dropped: 0
  pid: 20453
  policy_reward_mean: {}
  time_since_restore: 255.2335069179535
  time_this_iter_s: 8.398313999176025
  time_total_s: 255.2335069179535
  timestamp: 1593994236
  timesteps_since_restore: 55000
  timesteps_this_iter: 2000
  timesteps_total: 55000
  training_iteration: 30
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 22.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=20453], 255 s, 30 iter, 55000 ts, 239 rew

agent-1: 195.0
Sum Reward: 195.0
Avg Reward: 195.0
Min Reward: 195.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
agent-1: 286.0
Sum Reward: 286.0
Avg Reward: 286.0
Min Reward: 286.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-10-45
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 361.0
  episode_reward_mean: 239.42857142857142
  episode_reward_min: 56.0
  episodes_this_iter: 2
  episodes_total: 56
  experiment_id: 325b24caee6c4209bf8cf01af4f33e4d
  hostname: gpu048
  info:
    apply_time_ms: 3.604
    dispatch_time_ms: 8.717
    learner:
      cur_lr: 0.0013563369866460562
      grad_gnorm: 25.871315002441406
      policy_entropy: 7.977975368499756
      policy_loss: -1.353982925415039
      var_gnorm: 22.48651885986328
      vf_explained_var: -1.0
      vf_loss: 5.46712589263916
    num_steps_sampled: 57000
    num_steps_trained: 57000
    wait_time_ms: 32.014
  iterations_since_restore: 31
  node_ip: 172.17.8.48
  num_metric_batches_dropped: 0
  pid: 20453
  policy_reward_mean: {}
  time_since_restore: 263.88925337791443
  time_this_iter_s: 8.655746459960938
  time_total_s: 263.88925337791443
  timestamp: 1593994245
  timesteps_since_restore: 57000
  timesteps_this_iter: 2000
  timesteps_total: 57000
  training_iteration: 31
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 22.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=20453], 263 s, 31 iter, 57000 ts, 239 rew

agent-1: 355.0
Sum Reward: 355.0
Avg Reward: 355.0
Min Reward: 355.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
agent-1: 338.0
Sum Reward: 338.0
Avg Reward: 338.0
Min Reward: 338.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-10-54
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 361.0
  episode_reward_mean: 243.1206896551724
  episode_reward_min: 56.0
  episodes_this_iter: 2
  episodes_total: 58
  experiment_id: 325b24caee6c4209bf8cf01af4f33e4d
  hostname: gpu048
  info:
    apply_time_ms: 3.938
    dispatch_time_ms: 8.068
    learner:
      cur_lr: 0.0013562038075178862
      grad_gnorm: 27.57275390625
      policy_entropy: 7.194288730621338
      policy_loss: -2.7093117237091064
      var_gnorm: 22.708024978637695
      vf_explained_var: 0.004903316497802734
      vf_loss: 5.659510135650635
    num_steps_sampled: 59000
    num_steps_trained: 59000
    wait_time_ms: 34.99
  iterations_since_restore: 32
  node_ip: 172.17.8.48
  num_metric_batches_dropped: 0
  pid: 20453
  policy_reward_mean: {}
  time_since_restore: 272.75228929519653
  time_this_iter_s: 8.863035917282104
  time_total_s: 272.75228929519653
  timestamp: 1593994254
  timesteps_since_restore: 59000
  timesteps_this_iter: 2000
  timesteps_total: 59000
  training_iteration: 32
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 22.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=20453], 272 s, 32 iter, 59000 ts, 243 rew

agent-1: 336.0
Sum Reward: 336.0
Avg Reward: 336.0
Min Reward: 336.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
agent-1: 316.0
Sum Reward: 316.0
Avg Reward: 316.0
Min Reward: 316.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-11-02
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 361.0
  episode_reward_mean: 245.88333333333333
  episode_reward_min: 56.0
  episodes_this_iter: 2
  episodes_total: 60
  experiment_id: 325b24caee6c4209bf8cf01af4f33e4d
  hostname: gpu048
  info:
    apply_time_ms: 3.521
    dispatch_time_ms: 5.841
    learner:
      cur_lr: 0.0013560706283897161
      grad_gnorm: 22.001325607299805
      policy_entropy: 4.769972801208496
      policy_loss: -4.712934494018555
      var_gnorm: 22.86958122253418
      vf_explained_var: -1.0
      vf_loss: 5.152780532836914
    num_steps_sampled: 61000
    num_steps_trained: 61000
    wait_time_ms: 35.746
  iterations_since_restore: 33
  node_ip: 172.17.8.48
  num_metric_batches_dropped: 0
  pid: 20453
  policy_reward_mean: {}
  time_since_restore: 281.3947913646698
  time_this_iter_s: 8.642502069473267
  time_total_s: 281.3947913646698
  timestamp: 1593994262
  timesteps_since_restore: 61000
  timesteps_this_iter: 2000
  timesteps_total: 61000
  training_iteration: 33
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 22.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=20453], 281 s, 33 iter, 61000 ts, 246 rew

agent-1: 326.0
Sum Reward: 326.0
Avg Reward: 326.0
Min Reward: 326.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
agent-1: 253.0
Sum Reward: 253.0
Avg Reward: 253.0
Min Reward: 253.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-11-11
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 361.0
  episode_reward_mean: 247.29032258064515
  episode_reward_min: 56.0
  episodes_this_iter: 2
  episodes_total: 62
  experiment_id: 325b24caee6c4209bf8cf01af4f33e4d
  hostname: gpu048
  info:
    apply_time_ms: 2.8
    dispatch_time_ms: 10.282
    learner:
      cur_lr: 0.0013559374492615461
      grad_gnorm: 40.000038146972656
      policy_entropy: 5.950862884521484
      policy_loss: 1.8999528884887695
      var_gnorm: 22.93666648864746
      vf_explained_var: 0.4748119115829468
      vf_loss: 1.6241850852966309
    num_steps_sampled: 63000
    num_steps_trained: 63000
    wait_time_ms: 31.201
  iterations_since_restore: 34
  node_ip: 172.17.8.48
  num_metric_batches_dropped: 0
  pid: 20453
  policy_reward_mean: {}
  time_since_restore: 289.9253466129303
  time_this_iter_s: 8.530555248260498
  time_total_s: 289.9253466129303
  timestamp: 1593994271
  timesteps_since_restore: 63000
  timesteps_this_iter: 2000
  timesteps_total: 63000
  training_iteration: 34
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 23.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=20453], 289 s, 34 iter, 63000 ts, 247 rew

agent-1: 177.0
Sum Reward: 177.0
Avg Reward: 177.0
Min Reward: 177.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
agent-1: 239.0
Sum Reward: 239.0
Avg Reward: 239.0
Min Reward: 239.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-11-19
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 361.0
  episode_reward_mean: 246.0625
  episode_reward_min: 56.0
  episodes_this_iter: 2
  episodes_total: 64
  experiment_id: 325b24caee6c4209bf8cf01af4f33e4d
  hostname: gpu048
  info:
    apply_time_ms: 2.682
    dispatch_time_ms: 7.081
    learner:
      cur_lr: 0.0013558041537180543
      grad_gnorm: 40.0
      policy_entropy: 5.189663887023926
      policy_loss: 15.856417655944824
      var_gnorm: 23.1201229095459
      vf_explained_var: -0.1518162488937378
      vf_loss: 48.76548385620117
    num_steps_sampled: 65000
    num_steps_trained: 65000
    wait_time_ms: 33.296
  iterations_since_restore: 35
  node_ip: 172.17.8.48
  num_metric_batches_dropped: 0
  pid: 20453
  policy_reward_mean: {}
  time_since_restore: 298.4800088405609
  time_this_iter_s: 8.554662227630615
  time_total_s: 298.4800088405609
  timestamp: 1593994279
  timesteps_since_restore: 65000
  timesteps_this_iter: 2000
  timesteps_total: 65000
  training_iteration: 35
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 23.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=20453], 298 s, 35 iter, 65000 ts, 246 rew

agent-1: 191.0
Sum Reward: 191.0
Avg Reward: 191.0
Min Reward: 191.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
agent-1: 197.0
Sum Reward: 197.0
Avg Reward: 197.0
Min Reward: 197.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-11-28
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 361.0
  episode_reward_mean: 244.4848484848485
  episode_reward_min: 56.0
  episodes_this_iter: 2
  episodes_total: 66
  experiment_id: 325b24caee6c4209bf8cf01af4f33e4d
  hostname: gpu048
  info:
    apply_time_ms: 2.648
    dispatch_time_ms: 9.101
    learner:
      cur_lr: 0.0013556709745898843
      grad_gnorm: 40.0
      policy_entropy: 6.413923740386963
      policy_loss: 9.111539840698242
      var_gnorm: 23.202499389648438
      vf_explained_var: 0.10313528776168823
      vf_loss: 12.864814758300781
    num_steps_sampled: 67000
    num_steps_trained: 67000
    wait_time_ms: 35.111
  iterations_since_restore: 36
  node_ip: 172.17.8.48
  num_metric_batches_dropped: 0
  pid: 20453
  policy_reward_mean: {}
  time_since_restore: 307.044429063797
  time_this_iter_s: 8.564420223236084
  time_total_s: 307.044429063797
  timestamp: 1593994288
  timesteps_since_restore: 67000
  timesteps_this_iter: 2000
  timesteps_total: 67000
  training_iteration: 36
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 23.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=20453], 307 s, 36 iter, 67000 ts, 244 rew

agent-1: 134.0
Sum Reward: 134.0
Avg Reward: 134.0
Min Reward: 134.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
agent-1: 172.0
Sum Reward: 172.0
Avg Reward: 172.0
Min Reward: 172.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-11-37
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 361.0
  episode_reward_mean: 241.7941176470588
  episode_reward_min: 56.0
  episodes_this_iter: 2
  episodes_total: 68
  experiment_id: 325b24caee6c4209bf8cf01af4f33e4d
  hostname: gpu048
  info:
    apply_time_ms: 4.143
    dispatch_time_ms: 9.286
    learner:
      cur_lr: 0.0013555377954617143
      grad_gnorm: 40.000003814697266
      policy_entropy: 6.923521041870117
      policy_loss: 9.36596965789795
      var_gnorm: 23.304384231567383
      vf_explained_var: 0.0
      vf_loss: 19.266998291015625
    num_steps_sampled: 69000
    num_steps_trained: 69000
    wait_time_ms: 31.957
  iterations_since_restore: 37
  node_ip: 172.17.8.48
  num_metric_batches_dropped: 0
  pid: 20453
  policy_reward_mean: {}
  time_since_restore: 315.5502071380615
  time_this_iter_s: 8.505778074264526
  time_total_s: 315.5502071380615
  timestamp: 1593994297
  timesteps_since_restore: 69000
  timesteps_this_iter: 2000
  timesteps_total: 69000
  training_iteration: 37
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 23.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=20453], 315 s, 37 iter, 69000 ts, 242 rew

agent-1: 230.0
Sum Reward: 230.0
Avg Reward: 230.0
Min Reward: 230.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
agent-1: 221.0
Sum Reward: 221.0
Avg Reward: 221.0
Min Reward: 221.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-11-45
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 361.0
  episode_reward_mean: 241.32857142857142
  episode_reward_min: 56.0
  episodes_this_iter: 2
  episodes_total: 70
  experiment_id: 325b24caee6c4209bf8cf01af4f33e4d
  hostname: gpu048
  info:
    apply_time_ms: 2.944
    dispatch_time_ms: 9.523
    learner:
      cur_lr: 0.0013554046163335443
      grad_gnorm: 11.876029968261719
      policy_entropy: 5.844167709350586
      policy_loss: 2.8212802410125732
      var_gnorm: 23.45267677307129
      vf_explained_var: 0.0022869110107421875
      vf_loss: 3.3454692363739014
    num_steps_sampled: 71000
    num_steps_trained: 71000
    wait_time_ms: 29.498
  iterations_since_restore: 38
  node_ip: 172.17.8.48
  num_metric_batches_dropped: 0
  pid: 20453
  policy_reward_mean: {}
  time_since_restore: 324.160831451416
  time_this_iter_s: 8.610624313354492
  time_total_s: 324.160831451416
  timestamp: 1593994305
  timesteps_since_restore: 71000
  timesteps_this_iter: 2000
  timesteps_total: 71000
  training_iteration: 38
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 24.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=20453], 324 s, 38 iter, 71000 ts, 241 rew

agent-1: 209.0
Sum Reward: 209.0
Avg Reward: 209.0
Min Reward: 209.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
agent-1: 173.0
Sum Reward: 173.0
Avg Reward: 173.0
Min Reward: 173.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-11-54
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 361.0
  episode_reward_mean: 239.93055555555554
  episode_reward_min: 56.0
  episodes_this_iter: 2
  episodes_total: 72
  experiment_id: 325b24caee6c4209bf8cf01af4f33e4d
  hostname: gpu048
  info:
    apply_time_ms: 3.573
    dispatch_time_ms: 8.52
    learner:
      cur_lr: 0.0013552714372053742
      grad_gnorm: 6.293329238891602
      policy_entropy: 7.172321319580078
      policy_loss: 1.1428046226501465
      var_gnorm: 23.494976043701172
      vf_explained_var: 0.0
      vf_loss: 0.86176997423172
    num_steps_sampled: 73000
    num_steps_trained: 73000
    wait_time_ms: 34.036
  iterations_since_restore: 39
  node_ip: 172.17.8.48
  num_metric_batches_dropped: 0
  pid: 20453
  policy_reward_mean: {}
  time_since_restore: 332.7369029521942
  time_this_iter_s: 8.576071500778198
  time_total_s: 332.7369029521942
  timestamp: 1593994314
  timesteps_since_restore: 73000
  timesteps_this_iter: 2000
  timesteps_total: 73000
  training_iteration: 39
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 24.3/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=20453], 332 s, 39 iter, 73000 ts, 240 rew

agent-1: 168.0
Sum Reward: 168.0
Avg Reward: 168.0
Min Reward: 168.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
agent-1: 186.0
Sum Reward: 186.0
Avg Reward: 186.0
Min Reward: 186.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-12-02
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 361.0
  episode_reward_mean: 238.22972972972974
  episode_reward_min: 56.0
  episodes_this_iter: 2
  episodes_total: 74
  experiment_id: 325b24caee6c4209bf8cf01af4f33e4d
  hostname: gpu048
  info:
    apply_time_ms: 4.947
    dispatch_time_ms: 8.564
    learner:
      cur_lr: 0.0013551382580772042
      grad_gnorm: 40.0
      policy_entropy: 9.470993995666504
      policy_loss: -15.206327438354492
      var_gnorm: 23.512928009033203
      vf_explained_var: -0.29269182682037354
      vf_loss: 18.55512809753418
    num_steps_sampled: 75000
    num_steps_trained: 75000
    wait_time_ms: 29.142
  iterations_since_restore: 40
  node_ip: 172.17.8.48
  num_metric_batches_dropped: 0
  pid: 20453
  policy_reward_mean: {}
  time_since_restore: 341.2397446632385
  time_this_iter_s: 8.502841711044312
  time_total_s: 341.2397446632385
  timestamp: 1593994322
  timesteps_since_restore: 75000
  timesteps_this_iter: 2000
  timesteps_total: 75000
  training_iteration: 40
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 24.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=20453], 341 s, 40 iter, 75000 ts, 238 rew

agent-1: 196.0
Sum Reward: 196.0
Avg Reward: 196.0
Min Reward: 196.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
agent-1: 121.0
Sum Reward: 121.0
Avg Reward: 121.0
Min Reward: 121.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-12-11
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 361.0
  episode_reward_mean: 236.1315789473684
  episode_reward_min: 56.0
  episodes_this_iter: 2
  episodes_total: 76
  experiment_id: 325b24caee6c4209bf8cf01af4f33e4d
  hostname: gpu048
  info:
    apply_time_ms: 3.566
    dispatch_time_ms: 8.07
    learner:
      cur_lr: 0.0013550049625337124
      grad_gnorm: 20.361989974975586
      policy_entropy: 7.971586227416992
      policy_loss: -4.770811080932617
      var_gnorm: 23.61440658569336
      vf_explained_var: 0.10687011480331421
      vf_loss: 7.939239025115967
    num_steps_sampled: 77000
    num_steps_trained: 77000
    wait_time_ms: 32.253
  iterations_since_restore: 41
  node_ip: 172.17.8.48
  num_metric_batches_dropped: 0
  pid: 20453
  policy_reward_mean: {}
  time_since_restore: 349.8671669960022
  time_this_iter_s: 8.627422332763672
  time_total_s: 349.8671669960022
  timestamp: 1593994331
  timesteps_since_restore: 77000
  timesteps_this_iter: 2000
  timesteps_total: 77000
  training_iteration: 41
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 24.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=20453], 349 s, 41 iter, 77000 ts, 236 rew

agent-1: 164.0
Sum Reward: 164.0
Avg Reward: 164.0
Min Reward: 164.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
agent-1: 173.0
Sum Reward: 173.0
Avg Reward: 173.0
Min Reward: 173.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-12-20
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 361.0
  episode_reward_mean: 234.39743589743588
  episode_reward_min: 56.0
  episodes_this_iter: 2
  episodes_total: 78
  experiment_id: 325b24caee6c4209bf8cf01af4f33e4d
  hostname: gpu048
  info:
    apply_time_ms: 3.371
    dispatch_time_ms: 8.145
    learner:
      cur_lr: 0.0013548717834055424
      grad_gnorm: 40.00000762939453
      policy_entropy: 5.875292778015137
      policy_loss: 16.450197219848633
      var_gnorm: 23.62557601928711
      vf_explained_var: -1.0
      vf_loss: 19.095909118652344
    num_steps_sampled: 79000
    num_steps_trained: 79000
    wait_time_ms: 32.716
  iterations_since_restore: 42
  node_ip: 172.17.8.48
  num_metric_batches_dropped: 0
  pid: 20453
  policy_reward_mean: {}
  time_since_restore: 358.3822445869446
  time_this_iter_s: 8.515077590942383
  time_total_s: 358.3822445869446
  timestamp: 1593994340
  timesteps_since_restore: 79000
  timesteps_this_iter: 2000
  timesteps_total: 79000
  training_iteration: 42
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=20453], 358 s, 42 iter, 79000 ts, 234 rew

agent-1: 179.0
Sum Reward: 179.0
Avg Reward: 179.0
Min Reward: 179.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
agent-1: 199.0
Sum Reward: 199.0
Avg Reward: 199.0
Min Reward: 199.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-12-28
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 361.0
  episode_reward_mean: 233.2625
  episode_reward_min: 56.0
  episodes_this_iter: 2
  episodes_total: 80
  experiment_id: 325b24caee6c4209bf8cf01af4f33e4d
  hostname: gpu048
  info:
    apply_time_ms: 3.918
    dispatch_time_ms: 8.6
    learner:
      cur_lr: 0.0013547386042773724
      grad_gnorm: 40.0
      policy_entropy: 5.61057186126709
      policy_loss: 7.515776634216309
      var_gnorm: 23.76468849182129
      vf_explained_var: -0.03866922855377197
      vf_loss: 10.225974082946777
    num_steps_sampled: 81000
    num_steps_trained: 81000
    wait_time_ms: 29.097
  iterations_since_restore: 43
  node_ip: 172.17.8.48
  num_metric_batches_dropped: 0
  pid: 20453
  policy_reward_mean: {}
  time_since_restore: 366.9086563587189
  time_this_iter_s: 8.526411771774292
  time_total_s: 366.9086563587189
  timestamp: 1593994348
  timesteps_since_restore: 81000
  timesteps_this_iter: 2000
  timesteps_total: 81000
  training_iteration: 43
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.3/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=20453], 366 s, 43 iter, 81000 ts, 233 rew

agent-1: 196.0
Sum Reward: 196.0
Avg Reward: 196.0
Min Reward: 196.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
agent-1: 229.0
Sum Reward: 229.0
Avg Reward: 229.0
Min Reward: 229.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-12-37
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 361.0
  episode_reward_mean: 232.7560975609756
  episode_reward_min: 56.0
  episodes_this_iter: 2
  episodes_total: 82
  experiment_id: 325b24caee6c4209bf8cf01af4f33e4d
  hostname: gpu048
  info:
    apply_time_ms: 3.302
    dispatch_time_ms: 7.994
    learner:
      cur_lr: 0.0013546054251492023
      grad_gnorm: 20.525089263916016
      policy_entropy: 5.837654113769531
      policy_loss: -1.1399792432785034
      var_gnorm: 23.849010467529297
      vf_explained_var: -1.0
      vf_loss: 5.088456630706787
    num_steps_sampled: 83000
    num_steps_trained: 83000
    wait_time_ms: 30.831
  iterations_since_restore: 44
  node_ip: 172.17.8.48
  num_metric_batches_dropped: 0
  pid: 20453
  policy_reward_mean: {}
  time_since_restore: 375.3881902694702
  time_this_iter_s: 8.479533910751343
  time_total_s: 375.3881902694702
  timestamp: 1593994357
  timesteps_since_restore: 83000
  timesteps_this_iter: 2000
  timesteps_total: 83000
  training_iteration: 44
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=20453], 375 s, 44 iter, 83000 ts, 233 rew

agent-1: 253.0
Sum Reward: 253.0
Avg Reward: 253.0
Min Reward: 253.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
agent-1: 258.0
Sum Reward: 258.0
Avg Reward: 258.0
Min Reward: 258.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-12-45
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 361.0
  episode_reward_mean: 233.29761904761904
  episode_reward_min: 56.0
  episodes_this_iter: 2
  episodes_total: 84
  experiment_id: 325b24caee6c4209bf8cf01af4f33e4d
  hostname: gpu048
  info:
    apply_time_ms: 2.632
    dispatch_time_ms: 8.255
    learner:
      cur_lr: 0.0013544722460210323
      grad_gnorm: 33.17863082885742
      policy_entropy: 4.923471450805664
      policy_loss: 1.509475827217102
      var_gnorm: 23.97583770751953
      vf_explained_var: 0.0
      vf_loss: 8.120590209960938
    num_steps_sampled: 85000
    num_steps_trained: 85000
    wait_time_ms: 33.573
  iterations_since_restore: 45
  node_ip: 172.17.8.48
  num_metric_batches_dropped: 0
  pid: 20453
  policy_reward_mean: {}
  time_since_restore: 383.96838879585266
  time_this_iter_s: 8.580198526382446
  time_total_s: 383.96838879585266
  timestamp: 1593994365
  timesteps_since_restore: 85000
  timesteps_this_iter: 2000
  timesteps_total: 85000
  training_iteration: 45
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=20453], 383 s, 45 iter, 85000 ts, 233 rew

agent-1: 230.0
Sum Reward: 230.0
Avg Reward: 230.0
Min Reward: 230.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
agent-1: 224.0
Sum Reward: 224.0
Avg Reward: 224.0
Min Reward: 224.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-12-54
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 361.0
  episode_reward_mean: 233.15116279069767
  episode_reward_min: 56.0
  episodes_this_iter: 2
  episodes_total: 86
  experiment_id: 325b24caee6c4209bf8cf01af4f33e4d
  hostname: gpu048
  info:
    apply_time_ms: 3.14
    dispatch_time_ms: 9.646
    learner:
      cur_lr: 0.0013543389504775405
      grad_gnorm: 11.857427597045898
      policy_entropy: 5.619483947753906
      policy_loss: -1.8769128322601318
      var_gnorm: 24.081228256225586
      vf_explained_var: -0.338437557220459
      vf_loss: 1.660840630531311
    num_steps_sampled: 87000
    num_steps_trained: 87000
    wait_time_ms: 32.655
  iterations_since_restore: 46
  node_ip: 172.17.8.48
  num_metric_batches_dropped: 0
  pid: 20453
  policy_reward_mean: {}
  time_since_restore: 392.64344453811646
  time_this_iter_s: 8.675055742263794
  time_total_s: 392.64344453811646
  timestamp: 1593994374
  timesteps_since_restore: 87000
  timesteps_this_iter: 2000
  timesteps_total: 87000
  training_iteration: 46
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=20453], 392 s, 46 iter, 87000 ts, 233 rew

agent-1: 257.0
Sum Reward: 257.0
Avg Reward: 257.0
Min Reward: 257.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
agent-1: 295.0
Sum Reward: 295.0
Avg Reward: 295.0
Min Reward: 295.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-13-03
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 361.0
  episode_reward_mean: 234.125
  episode_reward_min: 56.0
  episodes_this_iter: 2
  episodes_total: 88
  experiment_id: 325b24caee6c4209bf8cf01af4f33e4d
  hostname: gpu048
  info:
    apply_time_ms: 2.851
    dispatch_time_ms: 7.176
    learner:
      cur_lr: 0.0013542057713493705
      grad_gnorm: 40.0
      policy_entropy: 3.5347900390625
      policy_loss: -9.793240547180176
      var_gnorm: 24.220775604248047
      vf_explained_var: 0.0
      vf_loss: 9.013239860534668
    num_steps_sampled: 89000
    num_steps_trained: 89000
    wait_time_ms: 34.042
  iterations_since_restore: 47
  node_ip: 172.17.8.48
  num_metric_batches_dropped: 0
  pid: 20453
  policy_reward_mean: {}
  time_since_restore: 401.3155767917633
  time_this_iter_s: 8.67213225364685
  time_total_s: 401.3155767917633
  timestamp: 1593994383
  timesteps_since_restore: 89000
  timesteps_this_iter: 2000
  timesteps_total: 89000
  training_iteration: 47
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=20453], 401 s, 47 iter, 89000 ts, 234 rew

agent-1: 270.0
Sum Reward: 270.0
Avg Reward: 270.0
Min Reward: 270.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
agent-1: 299.0
Sum Reward: 299.0
Avg Reward: 299.0
Min Reward: 299.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-13-11
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 361.0
  episode_reward_mean: 235.24444444444444
  episode_reward_min: 56.0
  episodes_this_iter: 2
  episodes_total: 90
  experiment_id: 325b24caee6c4209bf8cf01af4f33e4d
  hostname: gpu048
  info:
    apply_time_ms: 2.687
    dispatch_time_ms: 5.749
    learner:
      cur_lr: 0.0013540725922212005
      grad_gnorm: 12.273966789245605
      policy_entropy: 3.958251714706421
      policy_loss: -2.8946733474731445
      var_gnorm: 24.424631118774414
      vf_explained_var: 0.0
      vf_loss: 2.477302312850952
    num_steps_sampled: 91000
    num_steps_trained: 91000
    wait_time_ms: 35.444
  iterations_since_restore: 48
  node_ip: 172.17.8.48
  num_metric_batches_dropped: 0
  pid: 20453
  policy_reward_mean: {}
  time_since_restore: 410.03490138053894
  time_this_iter_s: 8.719324588775635
  time_total_s: 410.03490138053894
  timestamp: 1593994391
  timesteps_since_restore: 91000
  timesteps_this_iter: 2000
  timesteps_total: 91000
  training_iteration: 48
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=20453], 410 s, 48 iter, 91000 ts, 235 rew

agent-1: 259.0
Sum Reward: 259.0
Avg Reward: 259.0
Min Reward: 259.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
agent-1: 290.0
Sum Reward: 290.0
Avg Reward: 290.0
Min Reward: 290.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-13-20
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 361.0
  episode_reward_mean: 236.09782608695653
  episode_reward_min: 56.0
  episodes_this_iter: 2
  episodes_total: 92
  experiment_id: 325b24caee6c4209bf8cf01af4f33e4d
  hostname: gpu048
  info:
    apply_time_ms: 3.131
    dispatch_time_ms: 7.797
    learner:
      cur_lr: 0.0013539394130930305
      grad_gnorm: 37.18006896972656
      policy_entropy: 2.919785499572754
      policy_loss: 2.5174524784088135
      var_gnorm: 24.569120407104492
      vf_explained_var: -0.9559621810913086
      vf_loss: 9.433029174804688
    num_steps_sampled: 93000
    num_steps_trained: 93000
    wait_time_ms: 34.238
  iterations_since_restore: 49
  node_ip: 172.17.8.48
  num_metric_batches_dropped: 0
  pid: 20453
  policy_reward_mean: {}
  time_since_restore: 418.7902846336365
  time_this_iter_s: 8.755383253097534
  time_total_s: 418.7902846336365
  timestamp: 1593994400
  timesteps_since_restore: 93000
  timesteps_this_iter: 2000
  timesteps_total: 93000
  training_iteration: 49
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=20453], 418 s, 49 iter, 93000 ts, 236 rew

agent-1: 321.0
Sum Reward: 321.0
Avg Reward: 321.0
Min Reward: 321.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
agent-1: 285.0
Sum Reward: 285.0
Avg Reward: 285.0
Min Reward: 285.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-13-29
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 361.0
  episode_reward_mean: 237.5212765957447
  episode_reward_min: 56.0
  episodes_this_iter: 2
  episodes_total: 94
  experiment_id: 325b24caee6c4209bf8cf01af4f33e4d
  hostname: gpu048
  info:
    apply_time_ms: 3.951
    dispatch_time_ms: 9.827
    learner:
      cur_lr: 0.0013538062339648604
      grad_gnorm: 8.557065963745117
      policy_entropy: 3.0369515419006348
      policy_loss: -2.4845170974731445
      var_gnorm: 24.63939666748047
      vf_explained_var: -0.8091332912445068
      vf_loss: 1.3582847118377686
    num_steps_sampled: 95000
    num_steps_trained: 95000
    wait_time_ms: 29.028
  iterations_since_restore: 50
  node_ip: 172.17.8.48
  num_metric_batches_dropped: 0
  pid: 20453
  policy_reward_mean: {}
  time_since_restore: 427.4115107059479
  time_this_iter_s: 8.621226072311401
  time_total_s: 427.4115107059479
  timestamp: 1593994409
  timesteps_since_restore: 95000
  timesteps_this_iter: 2000
  timesteps_total: 95000
  training_iteration: 50
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=20453], 427 s, 50 iter, 95000 ts, 238 rew

agent-1: 262.0
Sum Reward: 262.0
Avg Reward: 262.0
Min Reward: 262.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
agent-1: 161.0
Sum Reward: 161.0
Avg Reward: 161.0
Min Reward: 161.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-13-37
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 361.0
  episode_reward_mean: 236.97916666666666
  episode_reward_min: 56.0
  episodes_this_iter: 2
  episodes_total: 96
  experiment_id: 325b24caee6c4209bf8cf01af4f33e4d
  hostname: gpu048
  info:
    apply_time_ms: 3.602
    dispatch_time_ms: 10.907
    learner:
      cur_lr: 0.0013536730548366904
      grad_gnorm: 33.882102966308594
      policy_entropy: 4.983626365661621
      policy_loss: -1.6967201232910156
      var_gnorm: 24.467565536499023
      vf_explained_var: -0.08577680587768555
      vf_loss: 6.429371356964111
    num_steps_sampled: 97000
    num_steps_trained: 97000
    wait_time_ms: 28.704
  iterations_since_restore: 51
  node_ip: 172.17.8.48
  num_metric_batches_dropped: 0
  pid: 20453
  policy_reward_mean: {}
  time_since_restore: 435.93189096450806
  time_this_iter_s: 8.52038025856018
  time_total_s: 435.93189096450806
  timestamp: 1593994417
  timesteps_since_restore: 97000
  timesteps_this_iter: 2000
  timesteps_total: 97000
  training_iteration: 51
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 27.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=20453], 435 s, 51 iter, 97000 ts, 237 rew

agent-1: 157.0
Sum Reward: 157.0
Avg Reward: 157.0
Min Reward: 157.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
agent-1: 99.0
Sum Reward: 99.0
Avg Reward: 99.0
Min Reward: 99.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-13-46
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 361.0
  episode_reward_mean: 234.75510204081633
  episode_reward_min: 56.0
  episodes_this_iter: 2
  episodes_total: 98
  experiment_id: 325b24caee6c4209bf8cf01af4f33e4d
  hostname: gpu048
  info:
    apply_time_ms: 3.634
    dispatch_time_ms: 10.545
    learner:
      cur_lr: 0.0013535397592931986
      grad_gnorm: 17.460115432739258
      policy_entropy: 2.890558958053589
      policy_loss: 0.35577696561813354
      var_gnorm: 24.413293838500977
      vf_explained_var: 0.055336833000183105
      vf_loss: 8.590949058532715
    num_steps_sampled: 99000
    num_steps_trained: 99000
    wait_time_ms: 29.809
  iterations_since_restore: 52
  node_ip: 172.17.8.48
  num_metric_batches_dropped: 0
  pid: 20453
  policy_reward_mean: {}
  time_since_restore: 444.3805134296417
  time_this_iter_s: 8.448622465133667
  time_total_s: 444.3805134296417
  timestamp: 1593994426
  timesteps_since_restore: 99000
  timesteps_this_iter: 2000
  timesteps_total: 99000
  training_iteration: 52
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 27.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=20453], 444 s, 52 iter, 99000 ts, 235 rew

agent-1: 114.0
Sum Reward: 114.0
Avg Reward: 114.0
Min Reward: 114.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
agent-1: 133.0
Sum Reward: 133.0
Avg Reward: 133.0
Min Reward: 133.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-13-54
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 361.0
  episode_reward_mean: 232.53
  episode_reward_min: 56.0
  episodes_this_iter: 2
  episodes_total: 100
  experiment_id: 325b24caee6c4209bf8cf01af4f33e4d
  hostname: gpu048
  info:
    apply_time_ms: 2.67
    dispatch_time_ms: 6.632
    learner:
      cur_lr: 0.0013534065801650286
      grad_gnorm: 23.61989974975586
      policy_entropy: 3.550628662109375
      policy_loss: -0.7620143890380859
      var_gnorm: 24.39150619506836
      vf_explained_var: 0.0
      vf_loss: 3.101973056793213
    num_steps_sampled: 101000
    num_steps_trained: 101000
    wait_time_ms: 33.01
  iterations_since_restore: 53
  node_ip: 172.17.8.48
  num_metric_batches_dropped: 0
  pid: 20453
  policy_reward_mean: {}
  time_since_restore: 452.8396511077881
  time_this_iter_s: 8.459137678146362
  time_total_s: 452.8396511077881
  timestamp: 1593994434
  timesteps_since_restore: 101000
  timesteps_this_iter: 2000
  timesteps_total: 101000
  training_iteration: 53
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 27.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=20453], 452 s, 53 iter, 101000 ts, 233 rew

agent-1: 119.0
Sum Reward: 119.0
Avg Reward: 119.0
Min Reward: 119.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
agent-1: 182.0
Sum Reward: 182.0
Avg Reward: 182.0
Min Reward: 182.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-14-03
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 361.0
  episode_reward_mean: 233.93
  episode_reward_min: 75.0
  episodes_this_iter: 2
  episodes_total: 102
  experiment_id: 325b24caee6c4209bf8cf01af4f33e4d
  hostname: gpu048
  info:
    apply_time_ms: 3.887
    dispatch_time_ms: 8.332
    learner:
      cur_lr: 0.0013532734010368586
      grad_gnorm: 27.351144790649414
      policy_entropy: 3.156301975250244
      policy_loss: -4.722048282623291
      var_gnorm: 24.42449188232422
      vf_explained_var: -0.09617042541503906
      vf_loss: 4.172791004180908
    num_steps_sampled: 103000
    num_steps_trained: 103000
    wait_time_ms: 29.693
  iterations_since_restore: 54
  node_ip: 172.17.8.48
  num_metric_batches_dropped: 0
  pid: 20453
  policy_reward_mean: {}
  time_since_restore: 461.3915205001831
  time_this_iter_s: 8.55186939239502
  time_total_s: 461.3915205001831
  timestamp: 1593994443
  timesteps_since_restore: 103000
  timesteps_this_iter: 2000
  timesteps_total: 103000
  training_iteration: 54
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 27.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=20453], 461 s, 54 iter, 103000 ts, 234 rew

agent-1: 107.0
Sum Reward: 107.0
Avg Reward: 107.0
Min Reward: 107.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
agent-1: 149.0
Sum Reward: 149.0
Avg Reward: 149.0
Min Reward: 149.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-14-12
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 361.0
  episode_reward_mean: 234.28
  episode_reward_min: 75.0
  episodes_this_iter: 2
  episodes_total: 104
  experiment_id: 325b24caee6c4209bf8cf01af4f33e4d
  hostname: gpu048
  info:
    apply_time_ms: 2.9
    dispatch_time_ms: 7.224
    learner:
      cur_lr: 0.0013531402219086885
      grad_gnorm: 22.756826400756836
      policy_entropy: 2.419088125228882
      policy_loss: -0.43406733870506287
      var_gnorm: 24.432857513427734
      vf_explained_var: 0.0
      vf_loss: 3.024890422821045
    num_steps_sampled: 105000
    num_steps_trained: 105000
    wait_time_ms: 34.196
  iterations_since_restore: 55
  node_ip: 172.17.8.48
  num_metric_batches_dropped: 0
  pid: 20453
  policy_reward_mean: {}
  time_since_restore: 469.88258361816406
  time_this_iter_s: 8.491063117980957
  time_total_s: 469.88258361816406
  timestamp: 1593994452
  timesteps_since_restore: 105000
  timesteps_this_iter: 2000
  timesteps_total: 105000
  training_iteration: 55
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=20453], 469 s, 55 iter, 105000 ts, 234 rew

agent-1: 127.0
Sum Reward: 127.0
Avg Reward: 127.0
Min Reward: 127.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
agent-1: 163.0
Sum Reward: 163.0
Avg Reward: 163.0
Min Reward: 163.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-14-20
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 361.0
  episode_reward_mean: 233.58
  episode_reward_min: 75.0
  episodes_this_iter: 2
  episodes_total: 106
  experiment_id: 325b24caee6c4209bf8cf01af4f33e4d
  hostname: gpu048
  info:
    apply_time_ms: 2.784
    dispatch_time_ms: 9.947
    learner:
      cur_lr: 0.0013530070427805185
      grad_gnorm: 40.0
      policy_entropy: 5.143226623535156
      policy_loss: 13.603141784667969
      var_gnorm: 24.476696014404297
      vf_explained_var: -0.20440399646759033
      vf_loss: 29.754467010498047
    num_steps_sampled: 107000
    num_steps_trained: 107000
    wait_time_ms: 29.523
  iterations_since_restore: 56
  node_ip: 172.17.8.48
  num_metric_batches_dropped: 0
  pid: 20453
  policy_reward_mean: {}
  time_since_restore: 478.32698011398315
  time_this_iter_s: 8.444396495819092
  time_total_s: 478.32698011398315
  timestamp: 1593994460
  timesteps_since_restore: 107000
  timesteps_this_iter: 2000
  timesteps_total: 107000
  training_iteration: 56
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=20453], 478 s, 56 iter, 107000 ts, 234 rew

agent-1: 136.0
Sum Reward: 136.0
Avg Reward: 136.0
Min Reward: 136.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
agent-1: 180.0
Sum Reward: 180.0
Avg Reward: 180.0
Min Reward: 180.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-14-28
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 361.0
  episode_reward_mean: 232.58
  episode_reward_min: 75.0
  episodes_this_iter: 2
  episodes_total: 108
  experiment_id: 325b24caee6c4209bf8cf01af4f33e4d
  hostname: gpu048
  info:
    apply_time_ms: 3.229
    dispatch_time_ms: 7.681
    learner:
      cur_lr: 0.0013528737472370267
      grad_gnorm: 39.99999237060547
      policy_entropy: 4.5879807472229
      policy_loss: 4.596659183502197
      var_gnorm: 24.500877380371094
      vf_explained_var: 0.0516241192817688
      vf_loss: 7.447512149810791
    num_steps_sampled: 109000
    num_steps_trained: 109000
    wait_time_ms: 29.314
  iterations_since_restore: 57
  node_ip: 172.17.8.48
  num_metric_batches_dropped: 0
  pid: 20453
  policy_reward_mean: {}
  time_since_restore: 486.73814606666565
  time_this_iter_s: 8.411165952682495
  time_total_s: 486.73814606666565
  timestamp: 1593994468
  timesteps_since_restore: 109000
  timesteps_this_iter: 2000
  timesteps_total: 109000
  training_iteration: 57
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=20453], 486 s, 57 iter, 109000 ts, 233 rew

agent-1: 124.0
Sum Reward: 124.0
Avg Reward: 124.0
Min Reward: 124.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
agent-1: 147.0
Sum Reward: 147.0
Avg Reward: 147.0
Min Reward: 147.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-14-37
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 361.0
  episode_reward_mean: 230.98
  episode_reward_min: 75.0
  episodes_this_iter: 2
  episodes_total: 110
  experiment_id: 325b24caee6c4209bf8cf01af4f33e4d
  hostname: gpu048
  info:
    apply_time_ms: 2.671
    dispatch_time_ms: 8.427
    learner:
      cur_lr: 0.0013527405681088567
      grad_gnorm: 25.439355850219727
      policy_entropy: 3.1555674076080322
      policy_loss: -0.6603693962097168
      var_gnorm: 24.56435775756836
      vf_explained_var: -0.5249062776565552
      vf_loss: 3.993302822113037
    num_steps_sampled: 111000
    num_steps_trained: 111000
    wait_time_ms: 30.166
  iterations_since_restore: 58
  node_ip: 172.17.8.48
  num_metric_batches_dropped: 0
  pid: 20453
  policy_reward_mean: {}
  time_since_restore: 495.1536018848419
  time_this_iter_s: 8.41545581817627
  time_total_s: 495.1536018848419
  timestamp: 1593994477
  timesteps_since_restore: 111000
  timesteps_this_iter: 2000
  timesteps_total: 111000
  training_iteration: 58
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=20453], 495 s, 58 iter, 111000 ts, 231 rew

agent-1: 167.0
Sum Reward: 167.0
Avg Reward: 167.0
Min Reward: 167.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
agent-1: 165.0
Sum Reward: 165.0
Avg Reward: 165.0
Min Reward: 165.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-14-45
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 361.0
  episode_reward_mean: 229.09
  episode_reward_min: 75.0
  episodes_this_iter: 2
  episodes_total: 112
  experiment_id: 325b24caee6c4209bf8cf01af4f33e4d
  hostname: gpu048
  info:
    apply_time_ms: 3.047
    dispatch_time_ms: 12.506
    learner:
      cur_lr: 0.0013526073889806867
      grad_gnorm: 24.586084365844727
      policy_entropy: 4.234201908111572
      policy_loss: -1.0350522994995117
      var_gnorm: 24.636886596679688
      vf_explained_var: 0.0
      vf_loss: 3.3180456161499023
    num_steps_sampled: 113000
    num_steps_trained: 113000
    wait_time_ms: 26.796
  iterations_since_restore: 59
  node_ip: 172.17.8.48
  num_metric_batches_dropped: 0
  pid: 20453
  policy_reward_mean: {}
  time_since_restore: 503.65826058387756
  time_this_iter_s: 8.504658699035645
  time_total_s: 503.65826058387756
  timestamp: 1593994485
  timesteps_since_restore: 113000
  timesteps_this_iter: 2000
  timesteps_total: 113000
  training_iteration: 59
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 29.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=20453], 503 s, 59 iter, 113000 ts, 229 rew

agent-1: 156.0
Sum Reward: 156.0
Avg Reward: 156.0
Min Reward: 156.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
agent-1: 120.0
Sum Reward: 120.0
Avg Reward: 120.0
Min Reward: 120.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-14-54
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 361.0
  episode_reward_mean: 225.68
  episode_reward_min: 75.0
  episodes_this_iter: 2
  episodes_total: 114
  experiment_id: 325b24caee6c4209bf8cf01af4f33e4d
  hostname: gpu048
  info:
    apply_time_ms: 3.925
    dispatch_time_ms: 8.599
    learner:
      cur_lr: 0.0013524742098525167
      grad_gnorm: 11.57355785369873
      policy_entropy: 5.909073829650879
      policy_loss: 0.4616052508354187
      var_gnorm: 24.68709373474121
      vf_explained_var: -0.17419540882110596
      vf_loss: 1.1808972358703613
    num_steps_sampled: 115000
    num_steps_trained: 115000
    wait_time_ms: 31.002
  iterations_since_restore: 60
  node_ip: 172.17.8.48
  num_metric_batches_dropped: 0
  pid: 20453
  policy_reward_mean: {}
  time_since_restore: 512.028128862381
  time_this_iter_s: 8.369868278503418
  time_total_s: 512.028128862381
  timestamp: 1593994494
  timesteps_since_restore: 115000
  timesteps_this_iter: 2000
  timesteps_total: 115000
  training_iteration: 60
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 29.3/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=20453], 512 s, 60 iter, 115000 ts, 226 rew

agent-1: 148.0
Sum Reward: 148.0
Avg Reward: 148.0
Min Reward: 148.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
agent-1: 97.0
Sum Reward: 97.0
Avg Reward: 97.0
Min Reward: 97.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-15-02
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 361.0
  episode_reward_mean: 222.52
  episode_reward_min: 75.0
  episodes_this_iter: 2
  episodes_total: 116
  experiment_id: 325b24caee6c4209bf8cf01af4f33e4d
  hostname: gpu048
  info:
    apply_time_ms: 2.738
    dispatch_time_ms: 7.424
    learner:
      cur_lr: 0.0013523410307243466
      grad_gnorm: 2.0510568618774414
      policy_entropy: 3.1829042434692383
      policy_loss: -0.6343499422073364
      var_gnorm: 24.706464767456055
      vf_explained_var: 0.33736366033554077
      vf_loss: 0.27894264459609985
    num_steps_sampled: 117000
    num_steps_trained: 117000
    wait_time_ms: 33.935
  iterations_since_restore: 61
  node_ip: 172.17.8.48
  num_metric_batches_dropped: 0
  pid: 20453
  policy_reward_mean: {}
  time_since_restore: 520.4046838283539
  time_this_iter_s: 8.3765549659729
  time_total_s: 520.4046838283539
  timestamp: 1593994502
  timesteps_since_restore: 117000
  timesteps_this_iter: 2000
  timesteps_total: 117000
  training_iteration: 61
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 29.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=20453], 520 s, 61 iter, 117000 ts, 223 rew

agent-1: 117.0
Sum Reward: 117.0
Avg Reward: 117.0
Min Reward: 117.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
agent-1: 157.0
Sum Reward: 157.0
Avg Reward: 157.0
Min Reward: 157.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-15-11
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 361.0
  episode_reward_mean: 220.05
  episode_reward_min: 75.0
  episodes_this_iter: 2
  episodes_total: 118
  experiment_id: 325b24caee6c4209bf8cf01af4f33e4d
  hostname: gpu048
  info:
    apply_time_ms: 3.004
    dispatch_time_ms: 7.129
    learner:
      cur_lr: 0.0013522078515961766
      grad_gnorm: 19.906030654907227
      policy_entropy: 4.327217102050781
      policy_loss: -2.5975089073181152
      var_gnorm: 24.74815559387207
      vf_explained_var: 5.960464477539063e-08
      vf_loss: 2.437734842300415
    num_steps_sampled: 119000
    num_steps_trained: 119000
    wait_time_ms: 29.582
  iterations_since_restore: 62
  node_ip: 172.17.8.48
  num_metric_batches_dropped: 0
  pid: 20453
  policy_reward_mean: {}
  time_since_restore: 528.8963010311127
  time_this_iter_s: 8.491617202758789
  time_total_s: 528.8963010311127
  timestamp: 1593994511
  timesteps_since_restore: 119000
  timesteps_this_iter: 2000
  timesteps_total: 119000
  training_iteration: 62
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 29.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=20453], 528 s, 62 iter, 119000 ts, 220 rew

agent-1: 123.0
Sum Reward: 123.0
Avg Reward: 123.0
Min Reward: 123.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
agent-1: 141.0
Sum Reward: 141.0
Avg Reward: 141.0
Min Reward: 141.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-15-19
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 361.0
  episode_reward_mean: 216.81
  episode_reward_min: 75.0
  episodes_this_iter: 2
  episodes_total: 120
  experiment_id: 325b24caee6c4209bf8cf01af4f33e4d
  hostname: gpu048
  info:
    apply_time_ms: 2.452
    dispatch_time_ms: 8.016
    learner:
      cur_lr: 0.0013520745560526848
      grad_gnorm: 19.618228912353516
      policy_entropy: 6.018707752227783
      policy_loss: -3.709444284439087
      var_gnorm: 24.807636260986328
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 2.3120455741882324
    num_steps_sampled: 121000
    num_steps_trained: 121000
    wait_time_ms: 29.938
  iterations_since_restore: 63
  node_ip: 172.17.8.48
  num_metric_batches_dropped: 0
  pid: 20453
  policy_reward_mean: {}
  time_since_restore: 537.3537480831146
  time_this_iter_s: 8.457447052001953
  time_total_s: 537.3537480831146
  timestamp: 1593994519
  timesteps_since_restore: 121000
  timesteps_this_iter: 2000
  timesteps_total: 121000
  training_iteration: 63
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=20453], 537 s, 63 iter, 121000 ts, 217 rew

agent-1: 131.0
Sum Reward: 131.0
Avg Reward: 131.0
Min Reward: 131.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
agent-1: 153.0
Sum Reward: 153.0
Avg Reward: 153.0
Min Reward: 153.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-15-28
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 361.0
  episode_reward_mean: 213.03
  episode_reward_min: 75.0
  episodes_this_iter: 2
  episodes_total: 122
  experiment_id: 325b24caee6c4209bf8cf01af4f33e4d
  hostname: gpu048
  info:
    apply_time_ms: 3.008
    dispatch_time_ms: 8.339
    learner:
      cur_lr: 0.0013519413769245148
      grad_gnorm: 5.401400089263916
      policy_entropy: 4.670915603637695
      policy_loss: 0.653835654258728
      var_gnorm: 24.822307586669922
      vf_explained_var: 0.17766231298446655
      vf_loss: 0.5115348100662231
    num_steps_sampled: 123000
    num_steps_trained: 123000
    wait_time_ms: 31.527
  iterations_since_restore: 64
  node_ip: 172.17.8.48
  num_metric_batches_dropped: 0
  pid: 20453
  policy_reward_mean: {}
  time_since_restore: 545.755125284195
  time_this_iter_s: 8.401377201080322
  time_total_s: 545.755125284195
  timestamp: 1593994528
  timesteps_since_restore: 123000
  timesteps_this_iter: 2000
  timesteps_total: 123000
  training_iteration: 64
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.3/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=20453], 545 s, 64 iter, 123000 ts, 213 rew

agent-1: 138.0
Sum Reward: 138.0
Avg Reward: 138.0
Min Reward: 138.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
agent-1: 148.0
Sum Reward: 148.0
Avg Reward: 148.0
Min Reward: 148.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-15-36
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 361.0
  episode_reward_mean: 210.5
  episode_reward_min: 75.0
  episodes_this_iter: 2
  episodes_total: 124
  experiment_id: 325b24caee6c4209bf8cf01af4f33e4d
  hostname: gpu048
  info:
    apply_time_ms: 3.095
    dispatch_time_ms: 9.703
    learner:
      cur_lr: 0.0013518081977963448
      grad_gnorm: 14.70914363861084
      policy_entropy: 4.786704063415527
      policy_loss: -2.871340036392212
      var_gnorm: 24.894344329833984
      vf_explained_var: -0.05357789993286133
      vf_loss: 2.1472456455230713
    num_steps_sampled: 125000
    num_steps_trained: 125000
    wait_time_ms: 28.64
  iterations_since_restore: 65
  node_ip: 172.17.8.48
  num_metric_batches_dropped: 0
  pid: 20453
  policy_reward_mean: {}
  time_since_restore: 554.2906696796417
  time_this_iter_s: 8.535544395446777
  time_total_s: 554.2906696796417
  timestamp: 1593994536
  timesteps_since_restore: 125000
  timesteps_this_iter: 2000
  timesteps_total: 125000
  training_iteration: 65
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=20453], 554 s, 65 iter, 125000 ts, 210 rew

agent-1: 158.0
Sum Reward: 158.0
Avg Reward: 158.0
Min Reward: 158.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
agent-1: 199.0
Sum Reward: 199.0
Avg Reward: 199.0
Min Reward: 199.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-15-45
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 361.0
  episode_reward_mean: 208.19
  episode_reward_min: 75.0
  episodes_this_iter: 2
  episodes_total: 126
  experiment_id: 325b24caee6c4209bf8cf01af4f33e4d
  hostname: gpu048
  info:
    apply_time_ms: 2.608
    dispatch_time_ms: 8.044
    learner:
      cur_lr: 0.0013516750186681747
      grad_gnorm: 4.452521800994873
      policy_entropy: 6.588906764984131
      policy_loss: -0.7588726878166199
      var_gnorm: 25.053762435913086
      vf_explained_var: -0.4272451400756836
      vf_loss: 0.7769444584846497
    num_steps_sampled: 127000
    num_steps_trained: 127000
    wait_time_ms: 30.827
  iterations_since_restore: 66
  node_ip: 172.17.8.48
  num_metric_batches_dropped: 0
  pid: 20453
  policy_reward_mean: {}
  time_since_restore: 562.8223752975464
  time_this_iter_s: 8.531705617904663
  time_total_s: 562.8223752975464
  timestamp: 1593994545
  timesteps_since_restore: 127000
  timesteps_this_iter: 2000
  timesteps_total: 127000
  training_iteration: 66
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=20453], 562 s, 66 iter, 127000 ts, 208 rew

agent-1: 174.0
Sum Reward: 174.0
Avg Reward: 174.0
Min Reward: 174.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
agent-1: 182.0
Sum Reward: 182.0
Avg Reward: 182.0
Min Reward: 182.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-15-54
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 361.0
  episode_reward_mean: 205.78
  episode_reward_min: 75.0
  episodes_this_iter: 2
  episodes_total: 128
  experiment_id: 325b24caee6c4209bf8cf01af4f33e4d
  hostname: gpu048
  info:
    apply_time_ms: 2.908
    dispatch_time_ms: 10.091
    learner:
      cur_lr: 0.0013515418395400047
      grad_gnorm: 40.0
      policy_entropy: 2.939751148223877
      policy_loss: 3.154376983642578
      var_gnorm: 25.30316162109375
      vf_explained_var: 5.960464477539063e-08
      vf_loss: 12.511152267456055
    num_steps_sampled: 129000
    num_steps_trained: 129000
    wait_time_ms: 28.785
  iterations_since_restore: 67
  node_ip: 172.17.8.48
  num_metric_batches_dropped: 0
  pid: 20453
  policy_reward_mean: {}
  time_since_restore: 571.4484314918518
  time_this_iter_s: 8.62605619430542
  time_total_s: 571.4484314918518
  timestamp: 1593994554
  timesteps_since_restore: 129000
  timesteps_this_iter: 2000
  timesteps_total: 129000
  training_iteration: 67
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=20453], 571 s, 67 iter, 129000 ts, 206 rew

agent-1: 170.0
Sum Reward: 170.0
Avg Reward: 170.0
Min Reward: 170.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
agent-1: 228.0
Sum Reward: 228.0
Avg Reward: 228.0
Min Reward: 228.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-16-02
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 361.0
  episode_reward_mean: 204.45
  episode_reward_min: 75.0
  episodes_this_iter: 2
  episodes_total: 130
  experiment_id: 325b24caee6c4209bf8cf01af4f33e4d
  hostname: gpu048
  info:
    apply_time_ms: 2.722
    dispatch_time_ms: 8.095
    learner:
      cur_lr: 0.0013514085439965129
      grad_gnorm: 5.232850074768066
      policy_entropy: 5.461876392364502
      policy_loss: 0.3739922046661377
      var_gnorm: 25.55438804626465
      vf_explained_var: -1.0
      vf_loss: 1.1871452331542969
    num_steps_sampled: 131000
    num_steps_trained: 131000
    wait_time_ms: 31.703
  iterations_since_restore: 68
  node_ip: 172.17.8.48
  num_metric_batches_dropped: 0
  pid: 20453
  policy_reward_mean: {}
  time_since_restore: 580.0888736248016
  time_this_iter_s: 8.640442132949829
  time_total_s: 580.0888736248016
  timestamp: 1593994562
  timesteps_since_restore: 131000
  timesteps_this_iter: 2000
  timesteps_total: 131000
  training_iteration: 68
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=20453], 580 s, 68 iter, 131000 ts, 204 rew

agent-1: 235.0
Sum Reward: 235.0
Avg Reward: 235.0
Min Reward: 235.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
agent-1: 237.0
Sum Reward: 237.0
Avg Reward: 237.0
Min Reward: 237.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-16-11
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 361.0
  episode_reward_mean: 204.5
  episode_reward_min: 75.0
  episodes_this_iter: 2
  episodes_total: 132
  experiment_id: 325b24caee6c4209bf8cf01af4f33e4d
  hostname: gpu048
  info:
    apply_time_ms: 3.838
    dispatch_time_ms: 10.622
    learner:
      cur_lr: 0.0013512753648683429
      grad_gnorm: 40.0
      policy_entropy: 2.9527535438537598
      policy_loss: 6.503172397613525
      var_gnorm: 25.74800682067871
      vf_explained_var: -0.25569701194763184
      vf_loss: 27.736574172973633
    num_steps_sampled: 133000
    num_steps_trained: 133000
    wait_time_ms: 32.096
  iterations_since_restore: 69
  node_ip: 172.17.8.48
  num_metric_batches_dropped: 0
  pid: 20453
  policy_reward_mean: {}
  time_since_restore: 588.8720860481262
  time_this_iter_s: 8.783212423324585
  time_total_s: 588.8720860481262
  timestamp: 1593994571
  timesteps_since_restore: 133000
  timesteps_this_iter: 2000
  timesteps_total: 133000
  training_iteration: 69
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=20453], 588 s, 69 iter, 133000 ts, 204 rew

agent-1: 281.0
Sum Reward: 281.0
Avg Reward: 281.0
Min Reward: 281.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
W0705 20:16:17.412603 20448 node_manager.cc:250] Last heartbeat was sent 955 ms ago 
W0705 20:16:19.742851 20448 node_manager.cc:250] Last heartbeat was sent 1527 ms ago 
W0705 20:16:29.064134 20448 node_manager.cc:250] Last heartbeat was sent 798 ms ago 
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-16-28
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 361.0
  episode_reward_mean: 204.7
  episode_reward_min: 75.0
  episodes_this_iter: 1
  episodes_total: 133
  experiment_id: 325b24caee6c4209bf8cf01af4f33e4d
  hostname: gpu048
  info:
    apply_time_ms: 2.462
    dispatch_time_ms: 7.053
    learner:
      cur_lr: 0.0013511421857401729
      grad_gnorm: 18.45737648010254
      policy_entropy: 4.841897487640381
      policy_loss: 3.23307466506958
      var_gnorm: 25.813928604125977
      vf_explained_var: 0.3398279547691345
      vf_loss: 1.8580753803253174
    num_steps_sampled: 134000
    num_steps_trained: 134000
    wait_time_ms: 909.11
  iterations_since_restore: 70
  node_ip: 172.17.8.48
  num_metric_batches_dropped: 0
  pid: 20453
  policy_reward_mean: {}
  time_since_restore: 606.3063337802887
  time_this_iter_s: 17.434247732162476
  time_total_s: 606.3063337802887
  timestamp: 1593994588
  timesteps_since_restore: 134000
  timesteps_this_iter: 1000
  timesteps_total: 134000
  training_iteration: 70
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=20453], 606 s, 70 iter, 134000 ts, 205 rew

agent-1: 265.0
Sum Reward: 265.0
Avg Reward: 265.0
Min Reward: 265.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
agent-1: 269.0
Sum Reward: 269.0
Avg Reward: 269.0
Min Reward: 269.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-16-38
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 361.0
  episode_reward_mean: 203.95
  episode_reward_min: 75.0
  episodes_this_iter: 2
  episodes_total: 135
  experiment_id: 325b24caee6c4209bf8cf01af4f33e4d
  hostname: gpu048
  info:
    apply_time_ms: 3.121
    dispatch_time_ms: 9.951
    learner:
      cur_lr: 0.0013510755961760879
      grad_gnorm: 16.877355575561523
      policy_entropy: 4.934391975402832
      policy_loss: 2.8785369396209717
      var_gnorm: 25.992929458618164
      vf_explained_var: 0.0778583288192749
      vf_loss: 3.6298580169677734
    num_steps_sampled: 136000
    num_steps_trained: 136000
    wait_time_ms: 31.09
  iterations_since_restore: 71
  node_ip: 172.17.8.48
  num_metric_batches_dropped: 0
  pid: 20453
  policy_reward_mean: {}
  time_since_restore: 614.8941900730133
  time_this_iter_s: 8.58785629272461
  time_total_s: 614.8941900730133
  timestamp: 1593994598
  timesteps_since_restore: 136000
  timesteps_this_iter: 2000
  timesteps_total: 136000
  training_iteration: 71
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=20453], 614 s, 71 iter, 136000 ts, 204 rew

agent-1: 281.0
Sum Reward: 281.0
Avg Reward: 281.0
Min Reward: 281.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
agent-1: 284.0
Sum Reward: 284.0
Avg Reward: 284.0
Min Reward: 284.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-16-47
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 355.0
  episode_reward_mean: 202.38
  episode_reward_min: 75.0
  episodes_this_iter: 2
  episodes_total: 137
  experiment_id: 325b24caee6c4209bf8cf01af4f33e4d
  hostname: gpu048
  info:
    apply_time_ms: 3.216
    dispatch_time_ms: 10.831
    learner:
      cur_lr: 0.0013509424170479178
      grad_gnorm: 11.957188606262207
      policy_entropy: 1.9011452198028564
      policy_loss: 0.21271419525146484
      var_gnorm: 26.161691665649414
      vf_explained_var: -1.0
      vf_loss: 4.990846157073975
    num_steps_sampled: 138000
    num_steps_trained: 138000
    wait_time_ms: 29.967
  iterations_since_restore: 72
  node_ip: 172.17.8.48
  num_metric_batches_dropped: 0
  pid: 20453
  policy_reward_mean: {}
  time_since_restore: 623.6150071620941
  time_this_iter_s: 8.72081708908081
  time_total_s: 623.6150071620941
  timestamp: 1593994607
  timesteps_since_restore: 138000
  timesteps_this_iter: 2000
  timesteps_total: 138000
  training_iteration: 72
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=20453], 623 s, 72 iter, 138000 ts, 202 rew

agent-1: 328.0
Sum Reward: 328.0
Avg Reward: 328.0
Min Reward: 328.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
agent-1: 302.0
Sum Reward: 302.0
Avg Reward: 302.0
Min Reward: 302.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-16-56
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 355.0
  episode_reward_mean: 204.41
  episode_reward_min: 75.0
  episodes_this_iter: 2
  episodes_total: 139
  experiment_id: 325b24caee6c4209bf8cf01af4f33e4d
  hostname: gpu048
  info:
    apply_time_ms: 3.225
    dispatch_time_ms: 9.483
    learner:
      cur_lr: 0.0013508092379197478
      grad_gnorm: 19.695283889770508
      policy_entropy: 1.597511887550354
      policy_loss: -0.9291131496429443
      var_gnorm: 26.318527221679688
      vf_explained_var: -0.536410927772522
      vf_loss: 5.012245178222656
    num_steps_sampled: 140000
    num_steps_trained: 140000
    wait_time_ms: 31.459
  iterations_since_restore: 73
  node_ip: 172.17.8.48
  num_metric_batches_dropped: 0
  pid: 20453
  policy_reward_mean: {}
  time_since_restore: 632.5153291225433
  time_this_iter_s: 8.900321960449219
  time_total_s: 632.5153291225433
  timestamp: 1593994616
  timesteps_since_restore: 140000
  timesteps_this_iter: 2000
  timesteps_total: 140000
  training_iteration: 73
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=20453], 632 s, 73 iter, 140000 ts, 204 rew

agent-1: 345.0
Sum Reward: 345.0
Avg Reward: 345.0
Min Reward: 345.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
agent-1: 325.0
Sum Reward: 325.0
Avg Reward: 325.0
Min Reward: 325.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-17-05
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 355.0
  episode_reward_mean: 208.86
  episode_reward_min: 75.0
  episodes_this_iter: 2
  episodes_total: 141
  experiment_id: 325b24caee6c4209bf8cf01af4f33e4d
  hostname: gpu048
  info:
    apply_time_ms: 3.941
    dispatch_time_ms: 14.184
    learner:
      cur_lr: 0.001350675942376256
      grad_gnorm: 40.0
      policy_entropy: 1.3031086921691895
      policy_loss: -0.534076452255249
      var_gnorm: 26.53404998779297
      vf_explained_var: -0.062473177909851074
      vf_loss: 21.86239242553711
    num_steps_sampled: 142000
    num_steps_trained: 142000
    wait_time_ms: 22.752
  iterations_since_restore: 74
  node_ip: 172.17.8.48
  num_metric_batches_dropped: 0
  pid: 20453
  policy_reward_mean: {}
  time_since_restore: 641.3795492649078
  time_this_iter_s: 8.864220142364502
  time_total_s: 641.3795492649078
  timestamp: 1593994625
  timesteps_since_restore: 142000
  timesteps_this_iter: 2000
  timesteps_total: 142000
  training_iteration: 74
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=20453], 641 s, 74 iter, 142000 ts, 209 rew

agent-1: 335.0
Sum Reward: 335.0
Avg Reward: 335.0
Min Reward: 335.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
agent-1: 287.0
Sum Reward: 287.0
Avg Reward: 287.0
Min Reward: 287.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-17-14
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 355.0
  episode_reward_mean: 210.85
  episode_reward_min: 75.0
  episodes_this_iter: 2
  episodes_total: 143
  experiment_id: 325b24caee6c4209bf8cf01af4f33e4d
  hostname: gpu048
  info:
    apply_time_ms: 2.596
    dispatch_time_ms: 11.682
    learner:
      cur_lr: 0.001350542763248086
      grad_gnorm: 33.74829864501953
      policy_entropy: 1.6627517938613892
      policy_loss: 0.3825170397758484
      var_gnorm: 26.67066764831543
      vf_explained_var: 0.01391613483428955
      vf_loss: 6.778903961181641
    num_steps_sampled: 144000
    num_steps_trained: 144000
    wait_time_ms: 30.355
  iterations_since_restore: 75
  node_ip: 172.17.8.48
  num_metric_batches_dropped: 0
  pid: 20453
  policy_reward_mean: {}
  time_since_restore: 650.5981662273407
  time_this_iter_s: 9.218616962432861
  time_total_s: 650.5981662273407
  timestamp: 1593994634
  timesteps_since_restore: 144000
  timesteps_this_iter: 2000
  timesteps_total: 144000
  training_iteration: 75
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=20453], 650 s, 75 iter, 144000 ts, 211 rew

agent-1: 323.0
Sum Reward: 323.0
Avg Reward: 323.0
Min Reward: 323.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
agent-1: 333.0
Sum Reward: 333.0
Avg Reward: 333.0
Min Reward: 333.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-17-23
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 355.0
  episode_reward_mean: 210.87
  episode_reward_min: 75.0
  episodes_this_iter: 2
  episodes_total: 145
  experiment_id: 325b24caee6c4209bf8cf01af4f33e4d
  hostname: gpu048
  info:
    apply_time_ms: 3.071
    dispatch_time_ms: 8.947
    learner:
      cur_lr: 0.001350409584119916
      grad_gnorm: 16.95383644104004
      policy_entropy: 2.7828001976013184
      policy_loss: -3.889981985092163
      var_gnorm: 26.91294288635254
      vf_explained_var: -0.6699193716049194
      vf_loss: 3.2678890228271484
    num_steps_sampled: 146000
    num_steps_trained: 146000
    wait_time_ms: 34.114
  iterations_since_restore: 76
  node_ip: 172.17.8.48
  num_metric_batches_dropped: 0
  pid: 20453
  policy_reward_mean: {}
  time_since_restore: 659.6110508441925
  time_this_iter_s: 9.012884616851807
  time_total_s: 659.6110508441925
  timestamp: 1593994643
  timesteps_since_restore: 146000
  timesteps_this_iter: 2000
  timesteps_total: 146000
  training_iteration: 76
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=20453], 659 s, 76 iter, 146000 ts, 211 rew

agent-1: 291.0
Sum Reward: 291.0
Avg Reward: 291.0
Min Reward: 291.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
agent-1: 272.0
Sum Reward: 272.0
Avg Reward: 272.0
Min Reward: 272.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-17-35
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 355.0
  episode_reward_mean: 210.32
  episode_reward_min: 75.0
  episodes_this_iter: 2
  episodes_total: 147
  experiment_id: 325b24caee6c4209bf8cf01af4f33e4d
  hostname: gpu048
  info:
    apply_time_ms: 2.556
    dispatch_time_ms: 7.926
    learner:
      cur_lr: 0.001350276404991746
      grad_gnorm: 32.86928176879883
      policy_entropy: 2.438659191131592
      policy_loss: -0.013688147068023682
      var_gnorm: 27.051279067993164
      vf_explained_var: -0.020419836044311523
      vf_loss: 7.056628227233887
    num_steps_sampled: 148000
    num_steps_trained: 148000
    wait_time_ms: 31.577
  iterations_since_restore: 77
  node_ip: 172.17.8.48
  num_metric_batches_dropped: 0
  pid: 20453
  policy_reward_mean: {}
  time_since_restore: 671.3649561405182
  time_this_iter_s: 11.753905296325684
  time_total_s: 671.3649561405182
  timestamp: 1593994655
  timesteps_since_restore: 148000
  timesteps_this_iter: 2000
  timesteps_total: 148000
  training_iteration: 77
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=20453], 671 s, 77 iter, 148000 ts, 210 rew

agent-1: 290.0
Sum Reward: 290.0
Avg Reward: 290.0
Min Reward: 290.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
agent-1: 305.0
Sum Reward: 305.0
Avg Reward: 305.0
Min Reward: 305.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-17-44
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 355.0
  episode_reward_mean: 210.65
  episode_reward_min: 75.0
  episodes_this_iter: 2
  episodes_total: 149
  experiment_id: 325b24caee6c4209bf8cf01af4f33e4d
  hostname: gpu048
  info:
    apply_time_ms: 3.932
    dispatch_time_ms: 6.963
    learner:
      cur_lr: 0.001350143225863576
      grad_gnorm: 21.005226135253906
      policy_entropy: 4.599292755126953
      policy_loss: -1.0192254781723022
      var_gnorm: 27.15601921081543
      vf_explained_var: -0.6976264715194702
      vf_loss: 4.310810565948486
    num_steps_sampled: 150000
    num_steps_trained: 150000
    wait_time_ms: 32.97
  iterations_since_restore: 78
  node_ip: 172.17.8.48
  num_metric_batches_dropped: 0
  pid: 20453
  policy_reward_mean: {}
  time_since_restore: 679.9432280063629
  time_this_iter_s: 8.578271865844727
  time_total_s: 679.9432280063629
  timestamp: 1593994664
  timesteps_since_restore: 150000
  timesteps_this_iter: 2000
  timesteps_total: 150000
  training_iteration: 78
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=20453], 679 s, 78 iter, 150000 ts, 211 rew

agent-1: 294.0
Sum Reward: 294.0
Avg Reward: 294.0
Min Reward: 294.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
agent-1: 319.0
Sum Reward: 319.0
Avg Reward: 319.0
Min Reward: 319.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-17-52
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 355.0
  episode_reward_mean: 213.98
  episode_reward_min: 97.0
  episodes_this_iter: 2
  episodes_total: 151
  experiment_id: 325b24caee6c4209bf8cf01af4f33e4d
  hostname: gpu048
  info:
    apply_time_ms: 3.62
    dispatch_time_ms: 6.585
    learner:
      cur_lr: 0.001350010046735406
      grad_gnorm: 10.463427543640137
      policy_entropy: 4.72390079498291
      policy_loss: -3.472705602645874
      var_gnorm: 27.295970916748047
      vf_explained_var: 0.2223280668258667
      vf_loss: 1.2046256065368652
    num_steps_sampled: 152000
    num_steps_trained: 152000
    wait_time_ms: 31.748
  iterations_since_restore: 79
  node_ip: 172.17.8.48
  num_metric_batches_dropped: 0
  pid: 20453
  policy_reward_mean: {}
  time_since_restore: 688.5015151500702
  time_this_iter_s: 8.558287143707275
  time_total_s: 688.5015151500702
  timestamp: 1593994672
  timesteps_since_restore: 152000
  timesteps_this_iter: 2000
  timesteps_total: 152000
  training_iteration: 79
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=20453], 688 s, 79 iter, 152000 ts, 214 rew

agent-1: 273.0
Sum Reward: 273.0
Avg Reward: 273.0
Min Reward: 273.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
agent-1: 301.0
Sum Reward: 301.0
Avg Reward: 301.0
Min Reward: 301.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-18-01
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 355.0
  episode_reward_mean: 217.39
  episode_reward_min: 97.0
  episodes_this_iter: 2
  episodes_total: 153
  experiment_id: 325b24caee6c4209bf8cf01af4f33e4d
  hostname: gpu048
  info:
    apply_time_ms: 2.471
    dispatch_time_ms: 5.976
    learner:
      cur_lr: 0.001349876751191914
      grad_gnorm: 39.999996185302734
      policy_entropy: 1.7133524417877197
      policy_loss: 1.7624083757400513
      var_gnorm: 27.452199935913086
      vf_explained_var: -0.3769458532333374
      vf_loss: 9.711750984191895
    num_steps_sampled: 154000
    num_steps_trained: 154000
    wait_time_ms: 31.16
  iterations_since_restore: 80
  node_ip: 172.17.8.48
  num_metric_batches_dropped: 0
  pid: 20453
  policy_reward_mean: {}
  time_since_restore: 697.0917749404907
  time_this_iter_s: 8.590259790420532
  time_total_s: 697.0917749404907
  timestamp: 1593994681
  timesteps_since_restore: 154000
  timesteps_this_iter: 2000
  timesteps_total: 154000
  training_iteration: 80
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=20453], 697 s, 80 iter, 154000 ts, 217 rew

agent-1: 279.0
Sum Reward: 279.0
Avg Reward: 279.0
Min Reward: 279.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
agent-1: 317.0
Sum Reward: 317.0
Avg Reward: 317.0
Min Reward: 317.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-18-10
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 355.0
  episode_reward_mean: 220.08
  episode_reward_min: 97.0
  episodes_this_iter: 2
  episodes_total: 155
  experiment_id: 325b24caee6c4209bf8cf01af4f33e4d
  hostname: gpu048
  info:
    apply_time_ms: 3.553
    dispatch_time_ms: 9.464
    learner:
      cur_lr: 0.001349743572063744
      grad_gnorm: 20.502248764038086
      policy_entropy: 5.707284450531006
      policy_loss: -2.5361952781677246
      var_gnorm: 27.604381561279297
      vf_explained_var: 0.00014913082122802734
      vf_loss: 2.571563720703125
    num_steps_sampled: 156000
    num_steps_trained: 156000
    wait_time_ms: 29.567
  iterations_since_restore: 81
  node_ip: 172.17.8.48
  num_metric_batches_dropped: 0
  pid: 20453
  policy_reward_mean: {}
  time_since_restore: 705.3598721027374
  time_this_iter_s: 8.268097162246704
  time_total_s: 705.3598721027374
  timestamp: 1593994690
  timesteps_since_restore: 156000
  timesteps_this_iter: 2000
  timesteps_total: 156000
  training_iteration: 81
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=20453], 705 s, 81 iter, 156000 ts, 220 rew

agent-1: 270.0
Sum Reward: 270.0
Avg Reward: 270.0
Min Reward: 270.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
agent-1: 267.0
Sum Reward: 267.0
Avg Reward: 267.0
Min Reward: 267.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-18-18
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 345.0
  episode_reward_mean: 219.04
  episode_reward_min: 97.0
  episodes_this_iter: 2
  episodes_total: 157
  experiment_id: 325b24caee6c4209bf8cf01af4f33e4d
  hostname: gpu048
  info:
    apply_time_ms: 3.146
    dispatch_time_ms: 7.191
    learner:
      cur_lr: 0.001349610392935574
      grad_gnorm: 22.282726287841797
      policy_entropy: 4.616739273071289
      policy_loss: -0.6641290187835693
      var_gnorm: 27.728538513183594
      vf_explained_var: -1.0
      vf_loss: 4.645450115203857
    num_steps_sampled: 158000
    num_steps_trained: 158000
    wait_time_ms: 32.596
  iterations_since_restore: 82
  node_ip: 172.17.8.48
  num_metric_batches_dropped: 0
  pid: 20453
  policy_reward_mean: {}
  time_since_restore: 713.7685272693634
  time_this_iter_s: 8.408655166625977
  time_total_s: 713.7685272693634
  timestamp: 1593994698
  timesteps_since_restore: 158000
  timesteps_this_iter: 2000
  timesteps_total: 158000
  training_iteration: 82
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=20453], 713 s, 82 iter, 158000 ts, 219 rew

agent-1: 241.0
Sum Reward: 241.0
Avg Reward: 241.0
Min Reward: 241.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
agent-1: 227.0
Sum Reward: 227.0
Avg Reward: 227.0
Min Reward: 227.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-18-27
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 345.0
  episode_reward_mean: 216.98
  episode_reward_min: 97.0
  episodes_this_iter: 2
  episodes_total: 159
  experiment_id: 325b24caee6c4209bf8cf01af4f33e4d
  hostname: gpu048
  info:
    apply_time_ms: 4.051
    dispatch_time_ms: 7.919
    learner:
      cur_lr: 0.001349477213807404
      grad_gnorm: 22.185409545898438
      policy_entropy: 0.5445877313613892
      policy_loss: 0.050389111042022705
      var_gnorm: 27.778839111328125
      vf_explained_var: 0.06273883581161499
      vf_loss: 2.861384630203247
    num_steps_sampled: 160000
    num_steps_trained: 160000
    wait_time_ms: 30.503
  iterations_since_restore: 83
  node_ip: 172.17.8.48
  num_metric_batches_dropped: 0
  pid: 20453
  policy_reward_mean: {}
  time_since_restore: 722.3991961479187
  time_this_iter_s: 8.630668878555298
  time_total_s: 722.3991961479187
  timestamp: 1593994707
  timesteps_since_restore: 160000
  timesteps_this_iter: 2000
  timesteps_total: 160000
  training_iteration: 83
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=20453], 722 s, 83 iter, 160000 ts, 217 rew

agent-1: 321.0
Sum Reward: 321.0
Avg Reward: 321.0
Min Reward: 321.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
agent-1: 320.0
Sum Reward: 320.0
Avg Reward: 320.0
Min Reward: 320.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-18-35
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 345.0
  episode_reward_mean: 216.97
  episode_reward_min: 97.0
  episodes_this_iter: 2
  episodes_total: 161
  experiment_id: 325b24caee6c4209bf8cf01af4f33e4d
  hostname: gpu048
  info:
    apply_time_ms: 2.568
    dispatch_time_ms: 7.008
    learner:
      cur_lr: 0.001349344034679234
      grad_gnorm: 40.0
      policy_entropy: 1.3257277011871338
      policy_loss: -1.9861834049224854
      var_gnorm: 27.911212921142578
      vf_explained_var: -0.5090240240097046
      vf_loss: 17.31992530822754
    num_steps_sampled: 162000
    num_steps_trained: 162000
    wait_time_ms: 35.006
  iterations_since_restore: 84
  node_ip: 172.17.8.48
  num_metric_batches_dropped: 0
  pid: 20453
  policy_reward_mean: {}
  time_since_restore: 731.0606546401978
  time_this_iter_s: 8.661458492279053
  time_total_s: 731.0606546401978
  timestamp: 1593994715
  timesteps_since_restore: 162000
  timesteps_this_iter: 2000
  timesteps_total: 162000
  training_iteration: 84
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=20453], 731 s, 84 iter, 162000 ts, 217 rew

agent-1: 319.0
Sum Reward: 319.0
Avg Reward: 319.0
Min Reward: 319.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
agent-1: 340.0
Sum Reward: 340.0
Avg Reward: 340.0
Min Reward: 340.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-18-44
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 345.0
  episode_reward_mean: 219.26
  episode_reward_min: 97.0
  episodes_this_iter: 2
  episodes_total: 163
  experiment_id: 325b24caee6c4209bf8cf01af4f33e4d
  hostname: gpu048
  info:
    apply_time_ms: 3.335
    dispatch_time_ms: 8.139
    learner:
      cur_lr: 0.001349210855551064
      grad_gnorm: 6.382905006408691
      policy_entropy: 4.001823425292969
      policy_loss: 0.8468945622444153
      var_gnorm: 27.977182388305664
      vf_explained_var: -0.19508230686187744
      vf_loss: 0.7292468547821045
    num_steps_sampled: 164000
    num_steps_trained: 164000
    wait_time_ms: 31.061
  iterations_since_restore: 85
  node_ip: 172.17.8.48
  num_metric_batches_dropped: 0
  pid: 20453
  policy_reward_mean: {}
  time_since_restore: 739.7203478813171
  time_this_iter_s: 8.659693241119385
  time_total_s: 739.7203478813171
  timestamp: 1593994724
  timesteps_since_restore: 164000
  timesteps_this_iter: 2000
  timesteps_total: 164000
  training_iteration: 85
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=20453], 739 s, 85 iter, 164000 ts, 219 rew

agent-1: 316.0
Sum Reward: 316.0
Avg Reward: 316.0
Min Reward: 316.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
agent-1: 342.0
Sum Reward: 342.0
Avg Reward: 342.0
Min Reward: 342.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-18-53
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 345.0
  episode_reward_mean: 221.54
  episode_reward_min: 97.0
  episodes_this_iter: 2
  episodes_total: 165
  experiment_id: 325b24caee6c4209bf8cf01af4f33e4d
  hostname: gpu048
  info:
    apply_time_ms: 3.125
    dispatch_time_ms: 8.126
    learner:
      cur_lr: 0.0013490775600075722
      grad_gnorm: 39.999996185302734
      policy_entropy: 8.213166236877441
      policy_loss: -20.796875
      var_gnorm: 28.0572452545166
      vf_explained_var: 0.15006935596466064
      vf_loss: 18.971614837646484
    num_steps_sampled: 166000
    num_steps_trained: 166000
    wait_time_ms: 34.24
  iterations_since_restore: 86
  node_ip: 172.17.8.48
  num_metric_batches_dropped: 0
  pid: 20453
  policy_reward_mean: {}
  time_since_restore: 748.2899084091187
  time_this_iter_s: 8.569560527801514
  time_total_s: 748.2899084091187
  timestamp: 1593994733
  timesteps_since_restore: 166000
  timesteps_this_iter: 2000
  timesteps_total: 166000
  training_iteration: 86
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=20453], 748 s, 86 iter, 166000 ts, 222 rew

agent-1: 324.0
Sum Reward: 324.0
Avg Reward: 324.0
Min Reward: 324.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-19-16
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 345.0
  episode_reward_mean: 222.81
  episode_reward_min: 97.0
  episodes_this_iter: 1
  episodes_total: 166
  experiment_id: 325b24caee6c4209bf8cf01af4f33e4d
  hostname: gpu048
  info:
    apply_time_ms: 3.011
    dispatch_time_ms: 8.286
    learner:
      cur_lr: 0.0013489443808794022
      grad_gnorm: 12.033206939697266
      policy_entropy: 4.386333465576172
      policy_loss: -0.5143244862556458
      var_gnorm: 28.084423065185547
      vf_explained_var: -0.33072757720947266
      vf_loss: 1.8801488876342773
    num_steps_sampled: 167000
    num_steps_trained: 167000
    wait_time_ms: 32.397
  iterations_since_restore: 87
  node_ip: 172.17.8.48
  num_metric_batches_dropped: 0
  pid: 20453
  policy_reward_mean: {}
  time_since_restore: 771.7612578868866
  time_this_iter_s: 23.471349477767944
  time_total_s: 771.7612578868866
  timestamp: 1593994756
  timesteps_since_restore: 167000
  timesteps_this_iter: 1000
  timesteps_total: 167000
  training_iteration: 87
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=20453], 771 s, 87 iter, 167000 ts, 223 rew

agent-1: 350.0
Sum Reward: 350.0
Avg Reward: 350.0
Min Reward: 350.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
agent-1: 341.0
Sum Reward: 341.0
Avg Reward: 341.0
Min Reward: 341.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-19-25
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 350.0
  episode_reward_mean: 226.66
  episode_reward_min: 97.0
  episodes_this_iter: 2
  episodes_total: 168
  experiment_id: 325b24caee6c4209bf8cf01af4f33e4d
  hostname: gpu048
  info:
    apply_time_ms: 2.919
    dispatch_time_ms: 7.693
    learner:
      cur_lr: 0.0013488777913153172
      grad_gnorm: 39.9999885559082
      policy_entropy: 6.686020851135254
      policy_loss: 5.138830184936523
      var_gnorm: 28.15496826171875
      vf_explained_var: 0.1760423183441162
      vf_loss: 9.729626655578613
    num_steps_sampled: 169000
    num_steps_trained: 169000
    wait_time_ms: 31.842
  iterations_since_restore: 88
  node_ip: 172.17.8.48
  num_metric_batches_dropped: 0
  pid: 20453
  policy_reward_mean: {}
  time_since_restore: 780.410297870636
  time_this_iter_s: 8.64903998374939
  time_total_s: 780.410297870636
  timestamp: 1593994765
  timesteps_since_restore: 169000
  timesteps_this_iter: 2000
  timesteps_total: 169000
  training_iteration: 88
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=20453], 780 s, 88 iter, 169000 ts, 227 rew

agent-1: 339.0
Sum Reward: 339.0
Avg Reward: 339.0
Min Reward: 339.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
agent-1: 342.0
Sum Reward: 342.0
Avg Reward: 342.0
Min Reward: 342.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-19-34
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 350.0
  episode_reward_mean: 228.96
  episode_reward_min: 97.0
  episodes_this_iter: 2
  episodes_total: 170
  experiment_id: 325b24caee6c4209bf8cf01af4f33e4d
  hostname: gpu048
  info:
    apply_time_ms: 2.878
    dispatch_time_ms: 8.769
    learner:
      cur_lr: 0.0013487446121871471
      grad_gnorm: 14.156139373779297
      policy_entropy: 6.004205703735352
      policy_loss: -2.1037697792053223
      var_gnorm: 28.22980308532715
      vf_explained_var: -0.008480548858642578
      vf_loss: 5.19049072265625
    num_steps_sampled: 171000
    num_steps_trained: 171000
    wait_time_ms: 30.963
  iterations_since_restore: 89
  node_ip: 172.17.8.48
  num_metric_batches_dropped: 0
  pid: 20453
  policy_reward_mean: {}
  time_since_restore: 789.1332569122314
  time_this_iter_s: 8.722959041595459
  time_total_s: 789.1332569122314
  timestamp: 1593994774
  timesteps_since_restore: 171000
  timesteps_this_iter: 2000
  timesteps_total: 171000
  training_iteration: 89
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=20453], 789 s, 89 iter, 171000 ts, 229 rew

agent-1: 313.0
Sum Reward: 313.0
Avg Reward: 313.0
Min Reward: 313.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
agent-1: 294.0
Sum Reward: 294.0
Avg Reward: 294.0
Min Reward: 294.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-19-42
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 350.0
  episode_reward_mean: 231.21
  episode_reward_min: 97.0
  episodes_this_iter: 2
  episodes_total: 172
  experiment_id: 325b24caee6c4209bf8cf01af4f33e4d
  hostname: gpu048
  info:
    apply_time_ms: 3.694
    dispatch_time_ms: 7.774
    learner:
      cur_lr: 0.0013486114330589771
      grad_gnorm: 4.294043064117432
      policy_entropy: 5.999090671539307
      policy_loss: -0.2979349195957184
      var_gnorm: 28.32390594482422
      vf_explained_var: 1.1920928955078125e-07
      vf_loss: 2.906179666519165
    num_steps_sampled: 173000
    num_steps_trained: 173000
    wait_time_ms: 32.442
  iterations_since_restore: 90
  node_ip: 172.17.8.48
  num_metric_batches_dropped: 0
  pid: 20453
  policy_reward_mean: {}
  time_since_restore: 797.7579028606415
  time_this_iter_s: 8.624645948410034
  time_total_s: 797.7579028606415
  timestamp: 1593994782
  timesteps_since_restore: 173000
  timesteps_this_iter: 2000
  timesteps_total: 173000
  training_iteration: 90
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=20453], 797 s, 90 iter, 173000 ts, 231 rew

agent-1: 338.0
Sum Reward: 338.0
Avg Reward: 338.0
Min Reward: 338.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
agent-1: 248.0
Sum Reward: 248.0
Avg Reward: 248.0
Min Reward: 248.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-19-51
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 350.0
  episode_reward_mean: 233.53
  episode_reward_min: 97.0
  episodes_this_iter: 2
  episodes_total: 174
  experiment_id: 325b24caee6c4209bf8cf01af4f33e4d
  hostname: gpu048
  info:
    apply_time_ms: 2.517
    dispatch_time_ms: 8.277
    learner:
      cur_lr: 0.0013484782539308071
      grad_gnorm: 40.000003814697266
      policy_entropy: 4.844829559326172
      policy_loss: 7.137508392333984
      var_gnorm: 28.33185577392578
      vf_explained_var: -0.010944366455078125
      vf_loss: 9.717626571655273
    num_steps_sampled: 175000
    num_steps_trained: 175000
    wait_time_ms: 29.841
  iterations_since_restore: 91
  node_ip: 172.17.8.48
  num_metric_batches_dropped: 0
  pid: 20453
  policy_reward_mean: {}
  time_since_restore: 806.3852865695953
  time_this_iter_s: 8.627383708953857
  time_total_s: 806.3852865695953
  timestamp: 1593994791
  timesteps_since_restore: 175000
  timesteps_this_iter: 2000
  timesteps_total: 175000
  training_iteration: 91
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=20453], 806 s, 91 iter, 175000 ts, 234 rew

agent-1: 286.0
Sum Reward: 286.0
Avg Reward: 286.0
Min Reward: 286.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
agent-1: 305.0
Sum Reward: 305.0
Avg Reward: 305.0
Min Reward: 305.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-20-00
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 350.0
  episode_reward_mean: 236.27
  episode_reward_min: 97.0
  episodes_this_iter: 2
  episodes_total: 176
  experiment_id: 325b24caee6c4209bf8cf01af4f33e4d
  hostname: gpu048
  info:
    apply_time_ms: 2.654
    dispatch_time_ms: 5.677
    learner:
      cur_lr: 0.0013483449583873153
      grad_gnorm: 17.240093231201172
      policy_entropy: 5.035496711730957
      policy_loss: 2.5726237297058105
      var_gnorm: 28.46697425842285
      vf_explained_var: -0.7154873609542847
      vf_loss: 2.739445686340332
    num_steps_sampled: 177000
    num_steps_trained: 177000
    wait_time_ms: 34.059
  iterations_since_restore: 92
  node_ip: 172.17.8.48
  num_metric_batches_dropped: 0
  pid: 20453
  policy_reward_mean: {}
  time_since_restore: 815.0355725288391
  time_this_iter_s: 8.650285959243774
  time_total_s: 815.0355725288391
  timestamp: 1593994800
  timesteps_since_restore: 177000
  timesteps_this_iter: 2000
  timesteps_total: 177000
  training_iteration: 92
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=20453], 815 s, 92 iter, 177000 ts, 236 rew

agent-1: 342.0
Sum Reward: 342.0
Avg Reward: 342.0
Min Reward: 342.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
agent-1: 204.0
Sum Reward: 204.0
Avg Reward: 204.0
Min Reward: 204.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-20-08
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 350.0
  episode_reward_mean: 238.36
  episode_reward_min: 97.0
  episodes_this_iter: 2
  episodes_total: 178
  experiment_id: 325b24caee6c4209bf8cf01af4f33e4d
  hostname: gpu048
  info:
    apply_time_ms: 2.572
    dispatch_time_ms: 5.185
    learner:
      cur_lr: 0.0013482117792591453
      grad_gnorm: 12.095009803771973
      policy_entropy: 4.655778884887695
      policy_loss: 0.33158355951309204
      var_gnorm: 28.390901565551758
      vf_explained_var: 0.05295461416244507
      vf_loss: 1.3611055612564087
    num_steps_sampled: 179000
    num_steps_trained: 179000
    wait_time_ms: 35.649
  iterations_since_restore: 93
  node_ip: 172.17.8.48
  num_metric_batches_dropped: 0
  pid: 20453
  policy_reward_mean: {}
  time_since_restore: 823.4412176609039
  time_this_iter_s: 8.40564513206482
  time_total_s: 823.4412176609039
  timestamp: 1593994808
  timesteps_since_restore: 179000
  timesteps_this_iter: 2000
  timesteps_total: 179000
  training_iteration: 93
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=20453], 823 s, 93 iter, 179000 ts, 238 rew

agent-1: 216.0
Sum Reward: 216.0
Avg Reward: 216.0
Min Reward: 216.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
agent-1: 311.0
Sum Reward: 311.0
Avg Reward: 311.0
Min Reward: 311.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-20-17
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 350.0
  episode_reward_mean: 239.85
  episode_reward_min: 97.0
  episodes_this_iter: 2
  episodes_total: 180
  experiment_id: 325b24caee6c4209bf8cf01af4f33e4d
  hostname: gpu048
  info:
    apply_time_ms: 4.411
    dispatch_time_ms: 7.693
    learner:
      cur_lr: 0.0013480786001309752
      grad_gnorm: 40.0
      policy_entropy: 5.993407726287842
      policy_loss: -5.563844680786133
      var_gnorm: 28.516315460205078
      vf_explained_var: -1.0
      vf_loss: 16.521556854248047
    num_steps_sampled: 181000
    num_steps_trained: 181000
    wait_time_ms: 29.79
  iterations_since_restore: 94
  node_ip: 172.17.8.48
  num_metric_batches_dropped: 0
  pid: 20453
  policy_reward_mean: {}
  time_since_restore: 832.0596654415131
  time_this_iter_s: 8.61844778060913
  time_total_s: 832.0596654415131
  timestamp: 1593994817
  timesteps_since_restore: 181000
  timesteps_this_iter: 2000
  timesteps_total: 181000
  training_iteration: 94
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=20453], 832 s, 94 iter, 181000 ts, 240 rew

agent-1: 274.0
Sum Reward: 274.0
Avg Reward: 274.0
Min Reward: 274.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-20-29
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 350.0
  episode_reward_mean: 240.63
  episode_reward_min: 97.0
  episodes_this_iter: 1
  episodes_total: 181
  experiment_id: 325b24caee6c4209bf8cf01af4f33e4d
  hostname: gpu048
  info:
    apply_time_ms: 3.303
    dispatch_time_ms: 9.426
    learner:
      cur_lr: 0.0013479454210028052
      grad_gnorm: 7.827756881713867
      policy_entropy: 4.124606132507324
      policy_loss: -0.9619714021682739
      var_gnorm: 28.569168090820312
      vf_explained_var: -0.7912691831588745
      vf_loss: 1.8955368995666504
    num_steps_sampled: 182000
    num_steps_trained: 182000
    wait_time_ms: 31.244
  iterations_since_restore: 95
  node_ip: 172.17.8.48
  num_metric_batches_dropped: 0
  pid: 20453
  policy_reward_mean: {}
  time_since_restore: 844.6727254390717
  time_this_iter_s: 12.613059997558594
  time_total_s: 844.6727254390717
  timestamp: 1593994829
  timesteps_since_restore: 182000
  timesteps_this_iter: 1000
  timesteps_total: 182000
  training_iteration: 95
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=20453], 844 s, 95 iter, 182000 ts, 241 rew

agent-1: 283.0
Sum Reward: 283.0
Avg Reward: 283.0
Min Reward: 283.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
agent-1: 296.0
Sum Reward: 296.0
Avg Reward: 296.0
Min Reward: 296.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-20-38
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 350.0
  episode_reward_mean: 241.6
  episode_reward_min: 97.0
  episodes_this_iter: 2
  episodes_total: 183
  experiment_id: 325b24caee6c4209bf8cf01af4f33e4d
  hostname: gpu048
  info:
    apply_time_ms: 3.524
    dispatch_time_ms: 7.509
    learner:
      cur_lr: 0.0013478788314387202
      grad_gnorm: 8.44389820098877
      policy_entropy: 5.673226833343506
      policy_loss: -0.014443254098296165
      var_gnorm: 28.692726135253906
      vf_explained_var: 0.2752501964569092
      vf_loss: 1.881575107574463
    num_steps_sampled: 184000
    num_steps_trained: 184000
    wait_time_ms: 28.066
  iterations_since_restore: 96
  node_ip: 172.17.8.48
  num_metric_batches_dropped: 0
  pid: 20453
  policy_reward_mean: {}
  time_since_restore: 853.2511918544769
  time_this_iter_s: 8.578466415405273
  time_total_s: 853.2511918544769
  timestamp: 1593994838
  timesteps_since_restore: 184000
  timesteps_this_iter: 2000
  timesteps_total: 184000
  training_iteration: 96
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=20453], 853 s, 96 iter, 184000 ts, 242 rew

agent-1: 296.0
Sum Reward: 296.0
Avg Reward: 296.0
Min Reward: 296.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
agent-1: 296.0
Sum Reward: 296.0
Avg Reward: 296.0
Min Reward: 296.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-20-47
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 350.0
  episode_reward_mean: 242.64
  episode_reward_min: 97.0
  episodes_this_iter: 2
  episodes_total: 185
  experiment_id: 325b24caee6c4209bf8cf01af4f33e4d
  hostname: gpu048
  info:
    apply_time_ms: 3.902
    dispatch_time_ms: 8.988
    learner:
      cur_lr: 0.0013477456523105502
      grad_gnorm: 5.903294086456299
      policy_entropy: 1.4145150184631348
      policy_loss: 1.4702163934707642
      var_gnorm: 28.767854690551758
      vf_explained_var: -0.0727154016494751
      vf_loss: 0.7584882974624634
    num_steps_sampled: 186000
    num_steps_trained: 186000
    wait_time_ms: 28.167
  iterations_since_restore: 97
  node_ip: 172.17.8.48
  num_metric_batches_dropped: 0
  pid: 20453
  policy_reward_mean: {}
  time_since_restore: 861.9630126953125
  time_this_iter_s: 8.711820840835571
  time_total_s: 861.9630126953125
  timestamp: 1593994847
  timesteps_since_restore: 186000
  timesteps_this_iter: 2000
  timesteps_total: 186000
  training_iteration: 97
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=20453], 861 s, 97 iter, 186000 ts, 243 rew

agent-1: 333.0
Sum Reward: 333.0
Avg Reward: 333.0
Min Reward: 333.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
agent-1: 325.0
Sum Reward: 325.0
Avg Reward: 325.0
Min Reward: 325.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-20-55
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 350.0
  episode_reward_mean: 244.41
  episode_reward_min: 97.0
  episodes_this_iter: 2
  episodes_total: 187
  experiment_id: 325b24caee6c4209bf8cf01af4f33e4d
  hostname: gpu048
  info:
    apply_time_ms: 3.887
    dispatch_time_ms: 7.484
    learner:
      cur_lr: 0.0013476123567670584
      grad_gnorm: 37.6845588684082
      policy_entropy: 2.5365445613861084
      policy_loss: 1.1128827333450317
      var_gnorm: 28.843116760253906
      vf_explained_var: 0.5254776477813721
      vf_loss: 8.153485298156738
    num_steps_sampled: 188000
    num_steps_trained: 188000
    wait_time_ms: 33.376
  iterations_since_restore: 98
  node_ip: 172.17.8.48
  num_metric_batches_dropped: 0
  pid: 20453
  policy_reward_mean: {}
  time_since_restore: 870.5554871559143
  time_this_iter_s: 8.592474460601807
  time_total_s: 870.5554871559143
  timestamp: 1593994855
  timesteps_since_restore: 188000
  timesteps_this_iter: 2000
  timesteps_total: 188000
  training_iteration: 98
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=20453], 870 s, 98 iter, 188000 ts, 244 rew

agent-1: 284.0
Sum Reward: 284.0
Avg Reward: 284.0
Min Reward: 284.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
agent-1: 279.0
Sum Reward: 279.0
Avg Reward: 279.0
Min Reward: 279.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-21-04
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 350.0
  episode_reward_mean: 244.39
  episode_reward_min: 97.0
  episodes_this_iter: 2
  episodes_total: 189
  experiment_id: 325b24caee6c4209bf8cf01af4f33e4d
  hostname: gpu048
  info:
    apply_time_ms: 2.8
    dispatch_time_ms: 7.807
    learner:
      cur_lr: 0.0013474791776388884
      grad_gnorm: 40.0
      policy_entropy: 1.799974799156189
      policy_loss: 11.49874496459961
      var_gnorm: 28.86676788330078
      vf_explained_var: -0.07572376728057861
      vf_loss: 15.296433448791504
    num_steps_sampled: 190000
    num_steps_trained: 190000
    wait_time_ms: 33.169
  iterations_since_restore: 99
  node_ip: 172.17.8.48
  num_metric_batches_dropped: 0
  pid: 20453
  policy_reward_mean: {}
  time_since_restore: 879.0410323143005
  time_this_iter_s: 8.48554515838623
  time_total_s: 879.0410323143005
  timestamp: 1593994864
  timesteps_since_restore: 190000
  timesteps_this_iter: 2000
  timesteps_total: 190000
  training_iteration: 99
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=20453], 879 s, 99 iter, 190000 ts, 244 rew

agent-1: 281.0
Sum Reward: 281.0
Avg Reward: 281.0
Min Reward: 281.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
agent-1: 320.0
Sum Reward: 320.0
Avg Reward: 320.0
Min Reward: 320.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-21-13
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 350.0
  episode_reward_mean: 244.82
  episode_reward_min: 97.0
  episodes_this_iter: 2
  episodes_total: 191
  experiment_id: 325b24caee6c4209bf8cf01af4f33e4d
  hostname: gpu048
  info:
    apply_time_ms: 2.487
    dispatch_time_ms: 7.345
    learner:
      cur_lr: 0.0013473459985107183
      grad_gnorm: 39.999996185302734
      policy_entropy: 3.790738344192505
      policy_loss: 5.871387004852295
      var_gnorm: 28.98558235168457
      vf_explained_var: 0.29785776138305664
      vf_loss: 14.371003150939941
    num_steps_sampled: 192000
    num_steps_trained: 192000
    wait_time_ms: 32.25
  iterations_since_restore: 100
  node_ip: 172.17.8.48
  num_metric_batches_dropped: 0
  pid: 20453
  policy_reward_mean: {}
  time_since_restore: 887.6628124713898
  time_this_iter_s: 8.621780157089233
  time_total_s: 887.6628124713898
  timestamp: 1593994873
  timesteps_since_restore: 192000
  timesteps_this_iter: 2000
  timesteps_total: 192000
  training_iteration: 100
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=20453], 887 s, 100 iter, 192000 ts, 245 rew

agent-1: 360.0
Sum Reward: 360.0
Avg Reward: 360.0
Min Reward: 360.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
agent-1: 351.0
Sum Reward: 351.0
Avg Reward: 351.0
Min Reward: 351.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-21-21
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 360.0
  episode_reward_mean: 245.82
  episode_reward_min: 97.0
  episodes_this_iter: 2
  episodes_total: 193
  experiment_id: 325b24caee6c4209bf8cf01af4f33e4d
  hostname: gpu048
  info:
    apply_time_ms: 3.401
    dispatch_time_ms: 9.704
    learner:
      cur_lr: 0.0013472128193825483
      grad_gnorm: 40.0
      policy_entropy: 1.7597066164016724
      policy_loss: 1.220432996749878
      var_gnorm: 29.12765121459961
      vf_explained_var: -0.07372176647186279
      vf_loss: 19.458179473876953
    num_steps_sampled: 194000
    num_steps_trained: 194000
    wait_time_ms: 29.52
  iterations_since_restore: 101
  node_ip: 172.17.8.48
  num_metric_batches_dropped: 0
  pid: 20453
  policy_reward_mean: {}
  time_since_restore: 896.2287993431091
  time_this_iter_s: 8.56598687171936
  time_total_s: 896.2287993431091
  timestamp: 1593994881
  timesteps_since_restore: 194000
  timesteps_this_iter: 2000
  timesteps_total: 194000
  training_iteration: 101
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=20453], 896 s, 101 iter, 194000 ts, 246 rew

agent-1: 375.0
Sum Reward: 375.0
Avg Reward: 375.0
Min Reward: 375.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
agent-1: 360.0
Sum Reward: 360.0
Avg Reward: 360.0
Min Reward: 360.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-21-32
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 375.0
  episode_reward_mean: 247.7
  episode_reward_min: 97.0
  episodes_this_iter: 2
  episodes_total: 195
  experiment_id: 325b24caee6c4209bf8cf01af4f33e4d
  hostname: gpu048
  info:
    apply_time_ms: 3.36
    dispatch_time_ms: 27.867
    learner:
      cur_lr: 0.0013470796402543783
      grad_gnorm: 40.000003814697266
      policy_entropy: 2.723153591156006
      policy_loss: -12.392937660217285
      var_gnorm: 29.183874130249023
      vf_explained_var: -0.3917357921600342
      vf_loss: 21.162824630737305
    num_steps_sampled: 196000
    num_steps_trained: 196000
    wait_time_ms: 20.244
  iterations_since_restore: 102
  node_ip: 172.17.8.48
  num_metric_batches_dropped: 0
  pid: 20453
  policy_reward_mean: {}
  time_since_restore: 906.5196530818939
  time_this_iter_s: 10.29085373878479
  time_total_s: 906.5196530818939
  timestamp: 1593994892
  timesteps_since_restore: 196000
  timesteps_this_iter: 2000
  timesteps_total: 196000
  training_iteration: 102
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=20453], 906 s, 102 iter, 196000 ts, 248 rew

agent-1: 355.0
Sum Reward: 355.0
Avg Reward: 355.0
Min Reward: 355.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-21-37
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 375.0
  episode_reward_mean: 249.64
  episode_reward_min: 97.0
  episodes_this_iter: 1
  episodes_total: 196
  experiment_id: 325b24caee6c4209bf8cf01af4f33e4d
  hostname: gpu048
  info:
    apply_time_ms: 4.524
    dispatch_time_ms: 53.547
    learner:
      cur_lr: 0.0013469463447108865
      grad_gnorm: 7.567901134490967
      policy_entropy: 2.3011770248413086
      policy_loss: 1.054978370666504
      var_gnorm: 29.20834732055664
      vf_explained_var: -1.0
      vf_loss: 2.2920868396759033
    num_steps_sampled: 197000
    num_steps_trained: 197000
    wait_time_ms: 11.837
  iterations_since_restore: 103
  node_ip: 172.17.8.48
  num_metric_batches_dropped: 0
  pid: 20453
  policy_reward_mean: {}
  time_since_restore: 912.3708930015564
  time_this_iter_s: 5.851239919662476
  time_total_s: 912.3708930015564
  timestamp: 1593994897
  timesteps_since_restore: 197000
  timesteps_this_iter: 1000
  timesteps_total: 197000
  training_iteration: 103
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=20453], 912 s, 103 iter, 197000 ts, 250 rew

agent-1: 338.0
Sum Reward: 338.0
Avg Reward: 338.0
Min Reward: 338.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-21-43
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 375.0
  episode_reward_mean: 251.45
  episode_reward_min: 97.0
  episodes_this_iter: 1
  episodes_total: 197
  experiment_id: 325b24caee6c4209bf8cf01af4f33e4d
  hostname: gpu048
  info:
    apply_time_ms: 3.515
    dispatch_time_ms: 31.772
    learner:
      cur_lr: 0.0013468797551468015
      grad_gnorm: 40.0
      policy_entropy: 1.5443601608276367
      policy_loss: 0.460681289434433
      var_gnorm: 29.262760162353516
      vf_explained_var: 0.0
      vf_loss: 11.937074661254883
    num_steps_sampled: 198000
    num_steps_trained: 198000
    wait_time_ms: 21.62
  iterations_since_restore: 104
  node_ip: 172.17.8.48
  num_metric_batches_dropped: 0
  pid: 20453
  policy_reward_mean: {}
  time_since_restore: 918.3121974468231
  time_this_iter_s: 5.941304445266724
  time_total_s: 918.3121974468231
  timestamp: 1593994903
  timesteps_since_restore: 198000
  timesteps_this_iter: 1000
  timesteps_total: 198000
  training_iteration: 104
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=20453], 918 s, 104 iter, 198000 ts, 251 rew

agent-1: 351.0
Sum Reward: 351.0
Avg Reward: 351.0
Min Reward: 351.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-21-51
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 375.0
  episode_reward_mean: 253.97
  episode_reward_min: 97.0
  episodes_this_iter: 1
  episodes_total: 198
  experiment_id: 325b24caee6c4209bf8cf01af4f33e4d
  hostname: gpu048
  info:
    apply_time_ms: 2.7
    dispatch_time_ms: 44.46
    learner:
      cur_lr: 0.0013468131655827165
      grad_gnorm: 4.368393421173096
      policy_entropy: 1.077691674232483
      policy_loss: 0.02773200161755085
      var_gnorm: 29.295690536499023
      vf_explained_var: 0.0
      vf_loss: 2.1443164348602295
    num_steps_sampled: 199000
    num_steps_trained: 199000
    wait_time_ms: 28.569
  iterations_since_restore: 105
  node_ip: 172.17.8.48
  num_metric_batches_dropped: 0
  pid: 20453
  policy_reward_mean: {}
  time_since_restore: 926.2498788833618
  time_this_iter_s: 7.937681436538696
  time_total_s: 926.2498788833618
  timestamp: 1593994911
  timesteps_since_restore: 199000
  timesteps_this_iter: 1000
  timesteps_total: 199000
  training_iteration: 105
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=20453], 926 s, 105 iter, 199000 ts, 254 rew

agent-1: 370.0
Sum Reward: 370.0
Avg Reward: 370.0
Min Reward: 370.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-21-59
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 375.0
  episode_reward_mean: 256.53
  episode_reward_min: 97.0
  episodes_this_iter: 1
  episodes_total: 199
  experiment_id: 325b24caee6c4209bf8cf01af4f33e4d
  hostname: gpu048
  info:
    apply_time_ms: 2.831
    dispatch_time_ms: 27.153
    learner:
      cur_lr: 0.0013467465760186315
      grad_gnorm: 13.306215286254883
      policy_entropy: 1.360358715057373
      policy_loss: 0.36825940012931824
      var_gnorm: 29.309419631958008
      vf_explained_var: -0.2512664794921875
      vf_loss: 3.423386573791504
    num_steps_sampled: 200000
    num_steps_trained: 200000
    wait_time_ms: 38.621
  iterations_since_restore: 106
  node_ip: 172.17.8.48
  num_metric_batches_dropped: 0
  pid: 20453
  policy_reward_mean: {}
  time_since_restore: 933.7749326229095
  time_this_iter_s: 7.5250537395477295
  time_total_s: 933.7749326229095
  timestamp: 1593994919
  timesteps_since_restore: 200000
  timesteps_this_iter: 1000
  timesteps_total: 200000
  training_iteration: 106
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=20453], 933 s, 106 iter, 200000 ts, 257 rew

agent-1: 370.0
Sum Reward: 370.0
Avg Reward: 370.0
Min Reward: 370.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-22-06
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 375.0
  episode_reward_mean: 258.9
  episode_reward_min: 97.0
  episodes_this_iter: 1
  episodes_total: 200
  experiment_id: 325b24caee6c4209bf8cf01af4f33e4d
  hostname: gpu048
  info:
    apply_time_ms: 2.868
    dispatch_time_ms: 42.365
    learner:
      cur_lr: 0.0013466799864545465
      grad_gnorm: 14.039678573608398
      policy_entropy: 0.5998492240905762
      policy_loss: 0.05170581117272377
      var_gnorm: 29.336488723754883
      vf_explained_var: 0.05688333511352539
      vf_loss: 2.6135053634643555
    num_steps_sampled: 201000
    num_steps_trained: 201000
    wait_time_ms: 19.796
  iterations_since_restore: 107
  node_ip: 172.17.8.48
  num_metric_batches_dropped: 0
  pid: 20453
  policy_reward_mean: {}
  time_since_restore: 940.655130147934
  time_this_iter_s: 6.880197525024414
  time_total_s: 940.655130147934
  timestamp: 1593994926
  timesteps_since_restore: 201000
  timesteps_this_iter: 1000
  timesteps_total: 201000
  training_iteration: 107
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=20453], 940 s, 107 iter, 201000 ts, 259 rew

agent-1: 376.0
Sum Reward: 376.0
Avg Reward: 376.0
Min Reward: 376.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-22-13
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 376.0
  episode_reward_mean: 261.47
  episode_reward_min: 97.0
  episodes_this_iter: 1
  episodes_total: 201
  experiment_id: 325b24caee6c4209bf8cf01af4f33e4d
  hostname: gpu048
  info:
    apply_time_ms: 2.585
    dispatch_time_ms: 39.258
    learner:
      cur_lr: 0.0013466133968904614
      grad_gnorm: 27.64290428161621
      policy_entropy: 1.1667736768722534
      policy_loss: -0.4900263547897339
      var_gnorm: 29.383235931396484
      vf_explained_var: 0.0372464656829834
      vf_loss: 4.4872307777404785
    num_steps_sampled: 202000
    num_steps_trained: 202000
    wait_time_ms: 30.269
  iterations_since_restore: 108
  node_ip: 172.17.8.48
  num_metric_batches_dropped: 0
  pid: 20453
  policy_reward_mean: {}
  time_since_restore: 947.5440623760223
  time_this_iter_s: 6.888932228088379
  time_total_s: 947.5440623760223
  timestamp: 1593994933
  timesteps_since_restore: 202000
  timesteps_this_iter: 1000
  timesteps_total: 202000
  training_iteration: 108
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=20453], 947 s, 108 iter, 202000 ts, 261 rew

agent-1: 383.0
Sum Reward: 383.0
Avg Reward: 383.0
Min Reward: 383.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-22-19
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 383.0
  episode_reward_mean: 263.48
  episode_reward_min: 97.0
  episodes_this_iter: 1
  episodes_total: 202
  experiment_id: 325b24caee6c4209bf8cf01af4f33e4d
  hostname: gpu048
  info:
    apply_time_ms: 3.844
    dispatch_time_ms: 23.156
    learner:
      cur_lr: 0.0013465468073263764
      grad_gnorm: 4.656002998352051
      policy_entropy: 3.52116322517395
      policy_loss: 1.4777802228927612
      var_gnorm: 29.475427627563477
      vf_explained_var: 0.1704685091972351
      vf_loss: 0.566910982131958
    num_steps_sampled: 203000
    num_steps_trained: 203000
    wait_time_ms: 15.34
  iterations_since_restore: 109
  node_ip: 172.17.8.48
  num_metric_batches_dropped: 0
  pid: 20453
  policy_reward_mean: {}
  time_since_restore: 954.148250579834
  time_this_iter_s: 6.6041882038116455
  time_total_s: 954.148250579834
  timestamp: 1593994939
  timesteps_since_restore: 203000
  timesteps_this_iter: 1000
  timesteps_total: 203000
  training_iteration: 109
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=20453], 954 s, 109 iter, 203000 ts, 263 rew

agent-1: 366.0
Sum Reward: 366.0
Avg Reward: 366.0
Min Reward: 366.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-22-27
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 383.0
  episode_reward_mean: 266.07
  episode_reward_min: 97.0
  episodes_this_iter: 1
  episodes_total: 203
  experiment_id: 325b24caee6c4209bf8cf01af4f33e4d
  hostname: gpu048
  info:
    apply_time_ms: 2.934
    dispatch_time_ms: 30.991
    learner:
      cur_lr: 0.0013464802177622914
      grad_gnorm: 12.604268074035645
      policy_entropy: 4.822546482086182
      policy_loss: -2.2834877967834473
      var_gnorm: 29.498079299926758
      vf_explained_var: -0.9184877872467041
      vf_loss: 2.4880282878875732
    num_steps_sampled: 204000
    num_steps_trained: 204000
    wait_time_ms: 42.14
  iterations_since_restore: 110
  node_ip: 172.17.8.48
  num_metric_batches_dropped: 0
  pid: 20453
  policy_reward_mean: {}
  time_since_restore: 961.3292136192322
  time_this_iter_s: 7.180963039398193
  time_total_s: 961.3292136192322
  timestamp: 1593994947
  timesteps_since_restore: 204000
  timesteps_this_iter: 1000
  timesteps_total: 204000
  training_iteration: 110
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=20453], 961 s, 110 iter, 204000 ts, 266 rew

agent-1: 360.0
Sum Reward: 360.0
Avg Reward: 360.0
Min Reward: 360.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-22-34
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 383.0
  episode_reward_mean: 268.18
  episode_reward_min: 97.0
  episodes_this_iter: 1
  episodes_total: 204
  experiment_id: 325b24caee6c4209bf8cf01af4f33e4d
  hostname: gpu048
  info:
    apply_time_ms: 3.354
    dispatch_time_ms: 49.235
    learner:
      cur_lr: 0.0013464136281982064
      grad_gnorm: 13.761473655700684
      policy_entropy: 0.32815688848495483
      policy_loss: -8.093417167663574
      var_gnorm: 29.504507064819336
      vf_explained_var: 0.08996850252151489
      vf_loss: 2.855785608291626
    num_steps_sampled: 205000
    num_steps_trained: 205000
    wait_time_ms: 28.319
  iterations_since_restore: 111
  node_ip: 172.17.8.48
  num_metric_batches_dropped: 0
  pid: 20453
  policy_reward_mean: {}
  time_since_restore: 968.5393340587616
  time_this_iter_s: 7.210120439529419
  time_total_s: 968.5393340587616
  timestamp: 1593994954
  timesteps_since_restore: 205000
  timesteps_this_iter: 1000
  timesteps_total: 205000
  training_iteration: 111
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=20453], 968 s, 111 iter, 205000 ts, 268 rew

agent-1: 357.0
Sum Reward: 357.0
Avg Reward: 357.0
Min Reward: 357.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-22-41
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 383.0
  episode_reward_mean: 270.48
  episode_reward_min: 97.0
  episodes_this_iter: 1
  episodes_total: 205
  experiment_id: 325b24caee6c4209bf8cf01af4f33e4d
  hostname: gpu048
  info:
    apply_time_ms: 2.857
    dispatch_time_ms: 41.632
    learner:
      cur_lr: 0.0013463470386341214
      grad_gnorm: 40.0
      policy_entropy: 0.9500457048416138
      policy_loss: 0.22182174026966095
      var_gnorm: 29.527254104614258
      vf_explained_var: 6.556510925292969e-07
      vf_loss: 9.231466293334961
    num_steps_sampled: 206000
    num_steps_trained: 206000
    wait_time_ms: 18.085
  iterations_since_restore: 112
  node_ip: 172.17.8.48
  num_metric_batches_dropped: 0
  pid: 20453
  policy_reward_mean: {}
  time_since_restore: 975.7364761829376
  time_this_iter_s: 7.197142124176025
  time_total_s: 975.7364761829376
  timestamp: 1593994961
  timesteps_since_restore: 206000
  timesteps_this_iter: 1000
  timesteps_total: 206000
  training_iteration: 112
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=20453], 975 s, 112 iter, 206000 ts, 270 rew

agent-1: 364.0
Sum Reward: 364.0
Avg Reward: 364.0
Min Reward: 364.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-22-48
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 383.0
  episode_reward_mean: 272.49
  episode_reward_min: 97.0
  episodes_this_iter: 1
  episodes_total: 206
  experiment_id: 325b24caee6c4209bf8cf01af4f33e4d
  hostname: gpu048
  info:
    apply_time_ms: 2.836
    dispatch_time_ms: 40.684
    learner:
      cur_lr: 0.0013462804490700364
      grad_gnorm: 23.526262283325195
      policy_entropy: 0.7421156167984009
      policy_loss: 0.07059963792562485
      var_gnorm: 29.501773834228516
      vf_explained_var: 0.0
      vf_loss: 4.04423189163208
    num_steps_sampled: 207000
    num_steps_trained: 207000
    wait_time_ms: 27.742
  iterations_since_restore: 113
  node_ip: 172.17.8.48
  num_metric_batches_dropped: 0
  pid: 20453
  policy_reward_mean: {}
  time_since_restore: 982.6611926555634
  time_this_iter_s: 6.924716472625732
  time_total_s: 982.6611926555634
  timestamp: 1593994968
  timesteps_since_restore: 207000
  timesteps_this_iter: 1000
  timesteps_total: 207000
  training_iteration: 113
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=20453], 982 s, 113 iter, 207000 ts, 272 rew

agent-1: 346.0
Sum Reward: 346.0
Avg Reward: 346.0
Min Reward: 346.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-22-54
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 383.0
  episode_reward_mean: 274.59
  episode_reward_min: 97.0
  episodes_this_iter: 1
  episodes_total: 207
  experiment_id: 325b24caee6c4209bf8cf01af4f33e4d
  hostname: gpu048
  info:
    apply_time_ms: 3.793
    dispatch_time_ms: 20.012
    learner:
      cur_lr: 0.0013462137430906296
      grad_gnorm: 16.905332565307617
      policy_entropy: 0.7190614938735962
      policy_loss: 0.05346059426665306
      var_gnorm: 29.46397590637207
      vf_explained_var: -0.0006324052810668945
      vf_loss: 3.225999116897583
    num_steps_sampled: 208000
    num_steps_trained: 208000
    wait_time_ms: 13.168
  iterations_since_restore: 114
  node_ip: 172.17.8.48
  num_metric_batches_dropped: 0
  pid: 20453
  policy_reward_mean: {}
  time_since_restore: 988.6832482814789
  time_this_iter_s: 6.022055625915527
  time_total_s: 988.6832482814789
  timestamp: 1593994974
  timesteps_since_restore: 208000
  timesteps_this_iter: 1000
  timesteps_total: 208000
  training_iteration: 114
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=20453], 988 s, 114 iter, 208000 ts, 275 rew

agent-1: 307.0
Sum Reward: 307.0
Avg Reward: 307.0
Min Reward: 307.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
agent-1: 323.0
Sum Reward: 323.0
Avg Reward: 323.0
Min Reward: 323.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-23-03
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 383.0
  episode_reward_mean: 277.85
  episode_reward_min: 97.0
  episodes_this_iter: 2
  episodes_total: 209
  experiment_id: 325b24caee6c4209bf8cf01af4f33e4d
  hostname: gpu048
  info:
    apply_time_ms: 2.409
    dispatch_time_ms: 6.802
    learner:
      cur_lr: 0.0013461471535265446
      grad_gnorm: 18.05242919921875
      policy_entropy: 1.2678204774856567
      policy_loss: -0.1476345658302307
      var_gnorm: 29.39470863342285
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 1.94398033618927
    num_steps_sampled: 210000
    num_steps_trained: 210000
    wait_time_ms: 33.254
  iterations_since_restore: 115
  node_ip: 172.17.8.48
  num_metric_batches_dropped: 0
  pid: 20453
  policy_reward_mean: {}
  time_since_restore: 997.4154889583588
  time_this_iter_s: 8.732240676879883
  time_total_s: 997.4154889583588
  timestamp: 1593994983
  timesteps_since_restore: 210000
  timesteps_this_iter: 2000
  timesteps_total: 210000
  training_iteration: 115
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=20453], 997 s, 115 iter, 210000 ts, 278 rew

agent-1: 215.0
Sum Reward: 215.0
Avg Reward: 215.0
Min Reward: 215.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
agent-1: 188.0
Sum Reward: 188.0
Avg Reward: 188.0
Min Reward: 188.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-23-11
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 383.0
  episode_reward_mean: 278.74
  episode_reward_min: 97.0
  episodes_this_iter: 2
  episodes_total: 211
  experiment_id: 325b24caee6c4209bf8cf01af4f33e4d
  hostname: gpu048
  info:
    apply_time_ms: 4.822
    dispatch_time_ms: 6.907
    learner:
      cur_lr: 0.0013460139743983746
      grad_gnorm: 17.19588851928711
      policy_entropy: 2.068866729736328
      policy_loss: 0.25766053795814514
      var_gnorm: 29.240297317504883
      vf_explained_var: -0.05151259899139404
      vf_loss: 3.123270034790039
    num_steps_sampled: 212000
    num_steps_trained: 212000
    wait_time_ms: 34.807
  iterations_since_restore: 116
  node_ip: 172.17.8.48
  num_metric_batches_dropped: 0
  pid: 20453
  policy_reward_mean: {}
  time_since_restore: 1005.901896238327
  time_this_iter_s: 8.486407279968262
  time_total_s: 1005.901896238327
  timestamp: 1593994991
  timesteps_since_restore: 212000
  timesteps_this_iter: 2000
  timesteps_total: 212000
  training_iteration: 116
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=20453], 1005 s, 116 iter, 212000 ts, 279 rew

agent-1: 259.0
Sum Reward: 259.0
Avg Reward: 259.0
Min Reward: 259.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
agent-1: 259.0
Sum Reward: 259.0
Avg Reward: 259.0
Min Reward: 259.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-23-20
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 383.0
  episode_reward_mean: 280.71
  episode_reward_min: 97.0
  episodes_this_iter: 2
  episodes_total: 213
  experiment_id: 325b24caee6c4209bf8cf01af4f33e4d
  hostname: gpu048
  info:
    apply_time_ms: 2.788
    dispatch_time_ms: 8.35
    learner:
      cur_lr: 0.0013458807952702045
      grad_gnorm: 3.4017443656921387
      policy_entropy: 1.9812698364257812
      policy_loss: -0.21957449615001678
      var_gnorm: 29.326045989990234
      vf_explained_var: 0.07259917259216309
      vf_loss: 2.591111421585083
    num_steps_sampled: 214000
    num_steps_trained: 214000
    wait_time_ms: 32.815
  iterations_since_restore: 117
  node_ip: 172.17.8.48
  num_metric_batches_dropped: 0
  pid: 20453
  policy_reward_mean: {}
  time_since_restore: 1014.5572738647461
  time_this_iter_s: 8.655377626419067
  time_total_s: 1014.5572738647461
  timestamp: 1593995000
  timesteps_since_restore: 214000
  timesteps_this_iter: 2000
  timesteps_total: 214000
  training_iteration: 117
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=20453], 1014 s, 117 iter, 214000 ts, 281 rew

agent-1: 308.0
Sum Reward: 308.0
Avg Reward: 308.0
Min Reward: 308.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
agent-1: 266.0
Sum Reward: 266.0
Avg Reward: 266.0
Min Reward: 266.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
W0705 20:23:28.031563 20448 client_connection.cc:255] [worker]ProcessMessage with type 8 took 110 ms.
W0705 20:23:28.341244 20448 node_manager.cc:250] Last heartbeat was sent 1061 ms ago 
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-23-30
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 383.0
  episode_reward_mean: 283.77
  episode_reward_min: 97.0
  episodes_this_iter: 2
  episodes_total: 215
  experiment_id: 325b24caee6c4209bf8cf01af4f33e4d
  hostname: gpu048
  info:
    apply_time_ms: 2.652
    dispatch_time_ms: 7.443
    learner:
      cur_lr: 0.0013457476161420345
      grad_gnorm: 40.000003814697266
      policy_entropy: 3.3483731746673584
      policy_loss: 4.325674533843994
      var_gnorm: 29.359127044677734
      vf_explained_var: 0.12182873487472534
      vf_loss: 23.014806747436523
    num_steps_sampled: 216000
    num_steps_trained: 216000
    wait_time_ms: 33.692
  iterations_since_restore: 118
  node_ip: 172.17.8.48
  num_metric_batches_dropped: 0
  pid: 20453
  policy_reward_mean: {}
  time_since_restore: 1024.3197271823883
  time_this_iter_s: 9.762453317642212
  time_total_s: 1024.3197271823883
  timestamp: 1593995010
  timesteps_since_restore: 216000
  timesteps_this_iter: 2000
  timesteps_total: 216000
  training_iteration: 118
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=20453], 1024 s, 118 iter, 216000 ts, 284 rew

agent-1: 300.0
Sum Reward: 300.0
Avg Reward: 300.0
Min Reward: 300.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
agent-1: 319.0
Sum Reward: 319.0
Avg Reward: 319.0
Min Reward: 319.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-23-39
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 383.0
  episode_reward_mean: 287.82
  episode_reward_min: 123.0
  episodes_this_iter: 2
  episodes_total: 217
  experiment_id: 325b24caee6c4209bf8cf01af4f33e4d
  hostname: gpu048
  info:
    apply_time_ms: 3.876
    dispatch_time_ms: 8.317
    learner:
      cur_lr: 0.0013456144370138645
      grad_gnorm: 30.84214210510254
      policy_entropy: 4.368818759918213
      policy_loss: -2.6707146167755127
      var_gnorm: 29.41341781616211
      vf_explained_var: -0.35925841331481934
      vf_loss: 7.093556880950928
    num_steps_sampled: 218000
    num_steps_trained: 218000
    wait_time_ms: 31.122
  iterations_since_restore: 119
  node_ip: 172.17.8.48
  num_metric_batches_dropped: 0
  pid: 20453
  policy_reward_mean: {}
  time_since_restore: 1033.5724284648895
  time_this_iter_s: 9.25270128250122
  time_total_s: 1033.5724284648895
  timestamp: 1593995019
  timesteps_since_restore: 218000
  timesteps_this_iter: 2000
  timesteps_total: 218000
  training_iteration: 119
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=20453], 1033 s, 119 iter, 218000 ts, 288 rew

W0705 20:23:40.485925 20448 client_connection.cc:255] [worker]ProcessMessage with type 8 took 114 ms.
agent-1: 228.0
Sum Reward: 228.0
Avg Reward: 228.0
Min Reward: 228.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
agent-1: 273.0
Sum Reward: 273.0
Avg Reward: 273.0
Min Reward: 273.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-23-48
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 383.0
  episode_reward_mean: 290.03
  episode_reward_min: 131.0
  episodes_this_iter: 2
  episodes_total: 219
  experiment_id: 325b24caee6c4209bf8cf01af4f33e4d
  hostname: gpu048
  info:
    apply_time_ms: 2.571
    dispatch_time_ms: 6.188
    learner:
      cur_lr: 0.0013454812578856945
      grad_gnorm: 16.192909240722656
      policy_entropy: 1.8059042692184448
      policy_loss: -0.20535185933113098
      var_gnorm: 29.3282527923584
      vf_explained_var: -0.00030744075775146484
      vf_loss: 2.4313697814941406
    num_steps_sampled: 220000
    num_steps_trained: 220000
    wait_time_ms: 35.338
  iterations_since_restore: 120
  node_ip: 172.17.8.48
  num_metric_batches_dropped: 0
  pid: 20453
  policy_reward_mean: {}
  time_since_restore: 1042.0401394367218
  time_this_iter_s: 8.467710971832275
  time_total_s: 1042.0401394367218
  timestamp: 1593995028
  timesteps_since_restore: 220000
  timesteps_this_iter: 2000
  timesteps_total: 220000
  training_iteration: 120
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=20453], 1042 s, 120 iter, 220000 ts, 290 rew

agent-1: 188.0
Sum Reward: 188.0
Avg Reward: 188.0
Min Reward: 188.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
agent-1: 258.0
Sum Reward: 258.0
Avg Reward: 258.0
Min Reward: 258.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-23-56
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 383.0
  episode_reward_mean: 291.77
  episode_reward_min: 138.0
  episodes_this_iter: 2
  episodes_total: 221
  experiment_id: 325b24caee6c4209bf8cf01af4f33e4d
  hostname: gpu048
  info:
    apply_time_ms: 2.751
    dispatch_time_ms: 7.666
    learner:
      cur_lr: 0.0013453479623422027
      grad_gnorm: 2.8339691162109375
      policy_entropy: 2.5590476989746094
      policy_loss: -0.23454168438911438
      var_gnorm: 29.415210723876953
      vf_explained_var: 0.30966949462890625
      vf_loss: 3.4987189769744873
    num_steps_sampled: 222000
    num_steps_trained: 222000
    wait_time_ms: 32.339
  iterations_since_restore: 121
  node_ip: 172.17.8.48
  num_metric_batches_dropped: 0
  pid: 20453
  policy_reward_mean: {}
  time_since_restore: 1050.6539833545685
  time_this_iter_s: 8.61384391784668
  time_total_s: 1050.6539833545685
  timestamp: 1593995036
  timesteps_since_restore: 222000
  timesteps_this_iter: 2000
  timesteps_total: 222000
  training_iteration: 121
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=20453], 1050 s, 121 iter, 222000 ts, 292 rew

agent-1: 349.0
Sum Reward: 349.0
Avg Reward: 349.0
Min Reward: 349.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
agent-1: 359.0
Sum Reward: 359.0
Avg Reward: 359.0
Min Reward: 359.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-24-05
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 383.0
  episode_reward_mean: 295.94
  episode_reward_min: 148.0
  episodes_this_iter: 2
  episodes_total: 223
  experiment_id: 325b24caee6c4209bf8cf01af4f33e4d
  hostname: gpu048
  info:
    apply_time_ms: 3.06
    dispatch_time_ms: 7.328
    learner:
      cur_lr: 0.0013452147832140326
      grad_gnorm: 40.0
      policy_entropy: 1.7277677059173584
      policy_loss: -0.9501533508300781
      var_gnorm: 29.51597023010254
      vf_explained_var: -0.28362226486206055
      vf_loss: 14.286249160766602
    num_steps_sampled: 224000
    num_steps_trained: 224000
    wait_time_ms: 33.107
  iterations_since_restore: 122
  node_ip: 172.17.8.48
  num_metric_batches_dropped: 0
  pid: 20453
  policy_reward_mean: {}
  time_since_restore: 1059.3008482456207
  time_this_iter_s: 8.646864891052246
  time_total_s: 1059.3008482456207
  timestamp: 1593995045
  timesteps_since_restore: 224000
  timesteps_this_iter: 2000
  timesteps_total: 224000
  training_iteration: 122
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=20453], 1059 s, 122 iter, 224000 ts, 296 rew

agent-1: 292.0
Sum Reward: 292.0
Avg Reward: 292.0
Min Reward: 292.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
agent-1: 177.0
Sum Reward: 177.0
Avg Reward: 177.0
Min Reward: 177.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-24-14
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 383.0
  episode_reward_mean: 297.57
  episode_reward_min: 170.0
  episodes_this_iter: 2
  episodes_total: 225
  experiment_id: 325b24caee6c4209bf8cf01af4f33e4d
  hostname: gpu048
  info:
    apply_time_ms: 3.314
    dispatch_time_ms: 8.941
    learner:
      cur_lr: 0.0013450816040858626
      grad_gnorm: 39.393714904785156
      policy_entropy: 4.568110942840576
      policy_loss: -3.3597002029418945
      var_gnorm: 29.383834838867188
      vf_explained_var: -0.01754128932952881
      vf_loss: 9.381580352783203
    num_steps_sampled: 226000
    num_steps_trained: 226000
    wait_time_ms: 29.481
  iterations_since_restore: 123
  node_ip: 172.17.8.48
  num_metric_batches_dropped: 0
  pid: 20453
  policy_reward_mean: {}
  time_since_restore: 1067.7623426914215
  time_this_iter_s: 8.461494445800781
  time_total_s: 1067.7623426914215
  timestamp: 1593995054
  timesteps_since_restore: 226000
  timesteps_this_iter: 2000
  timesteps_total: 226000
  training_iteration: 123
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=20453], 1067 s, 123 iter, 226000 ts, 298 rew

agent-1: 152.0
Sum Reward: 152.0
Avg Reward: 152.0
Min Reward: 152.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
agent-1: 164.0
Sum Reward: 164.0
Avg Reward: 164.0
Min Reward: 164.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-24-22
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 383.0
  episode_reward_mean: 297.0
  episode_reward_min: 152.0
  episodes_this_iter: 2
  episodes_total: 227
  experiment_id: 325b24caee6c4209bf8cf01af4f33e4d
  hostname: gpu048
  info:
    apply_time_ms: 3.258
    dispatch_time_ms: 7.279
    learner:
      cur_lr: 0.0013449484249576926
      grad_gnorm: 40.0
      policy_entropy: 2.2567758560180664
      policy_loss: 0.8352936506271362
      var_gnorm: 29.34493637084961
      vf_explained_var: 5.960464477539063e-08
      vf_loss: 12.624363899230957
    num_steps_sampled: 228000
    num_steps_trained: 228000
    wait_time_ms: 32.555
  iterations_since_restore: 124
  node_ip: 172.17.8.48
  num_metric_batches_dropped: 0
  pid: 20453
  policy_reward_mean: {}
  time_since_restore: 1076.2379331588745
  time_this_iter_s: 8.475590467453003
  time_total_s: 1076.2379331588745
  timestamp: 1593995062
  timesteps_since_restore: 228000
  timesteps_this_iter: 2000
  timesteps_total: 228000
  training_iteration: 124
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=20453], 1076 s, 124 iter, 228000 ts, 297 rew

agent-1: 202.0
Sum Reward: 202.0
Avg Reward: 202.0
Min Reward: 202.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
agent-1: 267.0
Sum Reward: 267.0
Avg Reward: 267.0
Min Reward: 267.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-24-31
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 383.0
  episode_reward_mean: 298.17
  episode_reward_min: 152.0
  episodes_this_iter: 2
  episodes_total: 229
  experiment_id: 325b24caee6c4209bf8cf01af4f33e4d
  hostname: gpu048
  info:
    apply_time_ms: 3.986
    dispatch_time_ms: 6.934
    learner:
      cur_lr: 0.0013448152458295226
      grad_gnorm: 36.415435791015625
      policy_entropy: 5.2480082511901855
      policy_loss: -2.9688374996185303
      var_gnorm: 29.395580291748047
      vf_explained_var: -0.08289444446563721
      vf_loss: 6.3925652503967285
    num_steps_sampled: 230000
    num_steps_trained: 230000
    wait_time_ms: 33.237
  iterations_since_restore: 125
  node_ip: 172.17.8.48
  num_metric_batches_dropped: 0
  pid: 20453
  policy_reward_mean: {}
  time_since_restore: 1084.9641094207764
  time_this_iter_s: 8.726176261901855
  time_total_s: 1084.9641094207764
  timestamp: 1593995071
  timesteps_since_restore: 230000
  timesteps_this_iter: 2000
  timesteps_total: 230000
  training_iteration: 125
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=20453], 1084 s, 125 iter, 230000 ts, 298 rew

agent-1: 271.0
Sum Reward: 271.0
Avg Reward: 271.0
Min Reward: 271.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
agent-1: 276.0
Sum Reward: 276.0
Avg Reward: 276.0
Min Reward: 276.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-24-40
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 383.0
  episode_reward_mean: 299.01
  episode_reward_min: 152.0
  episodes_this_iter: 2
  episodes_total: 231
  experiment_id: 325b24caee6c4209bf8cf01af4f33e4d
  hostname: gpu048
  info:
    apply_time_ms: 3.214
    dispatch_time_ms: 8.06
    learner:
      cur_lr: 0.0013446819502860308
      grad_gnorm: 39.999996185302734
      policy_entropy: 8.021584510803223
      policy_loss: 12.52928638458252
      var_gnorm: 29.483165740966797
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 23.765153884887695
    num_steps_sampled: 232000
    num_steps_trained: 232000
    wait_time_ms: 32.763
  iterations_since_restore: 126
  node_ip: 172.17.8.48
  num_metric_batches_dropped: 0
  pid: 20453
  policy_reward_mean: {}
  time_since_restore: 1093.619530916214
  time_this_iter_s: 8.655421495437622
  time_total_s: 1093.619530916214
  timestamp: 1593995080
  timesteps_since_restore: 232000
  timesteps_this_iter: 2000
  timesteps_total: 232000
  training_iteration: 126
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=20453], 1093 s, 126 iter, 232000 ts, 299 rew

agent-1: 259.0
Sum Reward: 259.0
Avg Reward: 259.0
Min Reward: 259.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
agent-1: 193.0
Sum Reward: 193.0
Avg Reward: 193.0
Min Reward: 193.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-24-49
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 383.0
  episode_reward_mean: 298.35
  episode_reward_min: 152.0
  episodes_this_iter: 2
  episodes_total: 233
  experiment_id: 325b24caee6c4209bf8cf01af4f33e4d
  hostname: gpu048
  info:
    apply_time_ms: 3.938
    dispatch_time_ms: 8.325
    learner:
      cur_lr: 0.0013445487711578608
      grad_gnorm: 40.0
      policy_entropy: 4.778774738311768
      policy_loss: 9.103912353515625
      var_gnorm: 29.42214012145996
      vf_explained_var: 0.07449233531951904
      vf_loss: 9.424419403076172
    num_steps_sampled: 234000
    num_steps_trained: 234000
    wait_time_ms: 28.197
  iterations_since_restore: 127
  node_ip: 172.17.8.48
  num_metric_batches_dropped: 0
  pid: 20453
  policy_reward_mean: {}
  time_since_restore: 1101.8533191680908
  time_this_iter_s: 8.233788251876831
  time_total_s: 1101.8533191680908
  timestamp: 1593995089
  timesteps_since_restore: 234000
  timesteps_this_iter: 2000
  timesteps_total: 234000
  training_iteration: 127
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=20453], 1101 s, 127 iter, 234000 ts, 298 rew

agent-1: 148.0
Sum Reward: 148.0
Avg Reward: 148.0
Min Reward: 148.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
agent-1: 201.0
Sum Reward: 201.0
Avg Reward: 201.0
Min Reward: 201.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-24-57
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 383.0
  episode_reward_mean: 296.5
  episode_reward_min: 148.0
  episodes_this_iter: 2
  episodes_total: 235
  experiment_id: 325b24caee6c4209bf8cf01af4f33e4d
  hostname: gpu048
  info:
    apply_time_ms: 3.138
    dispatch_time_ms: 7.548
    learner:
      cur_lr: 0.0013444155920296907
      grad_gnorm: 29.680253982543945
      policy_entropy: 8.843305587768555
      policy_loss: -6.796037673950195
      var_gnorm: 29.447206497192383
      vf_explained_var: -0.28043830394744873
      vf_loss: 6.336243629455566
    num_steps_sampled: 236000
    num_steps_trained: 236000
    wait_time_ms: 32.921
  iterations_since_restore: 128
  node_ip: 172.17.8.48
  num_metric_batches_dropped: 0
  pid: 20453
  policy_reward_mean: {}
  time_since_restore: 1110.4725484848022
  time_this_iter_s: 8.619229316711426
  time_total_s: 1110.4725484848022
  timestamp: 1593995097
  timesteps_since_restore: 236000
  timesteps_this_iter: 2000
  timesteps_total: 236000
  training_iteration: 128
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=20453], 1110 s, 128 iter, 236000 ts, 296 rew

agent-1: 246.0
Sum Reward: 246.0
Avg Reward: 246.0
Min Reward: 246.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
agent-1: 155.0
Sum Reward: 155.0
Avg Reward: 155.0
Min Reward: 155.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-25-06
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 383.0
  episode_reward_mean: 294.86
  episode_reward_min: 148.0
  episodes_this_iter: 2
  episodes_total: 237
  experiment_id: 325b24caee6c4209bf8cf01af4f33e4d
  hostname: gpu048
  info:
    apply_time_ms: 3.037
    dispatch_time_ms: 7.368
    learner:
      cur_lr: 0.0013442824129015207
      grad_gnorm: 33.79793930053711
      policy_entropy: 7.846184730529785
      policy_loss: 4.9274468421936035
      var_gnorm: 29.439022064208984
      vf_explained_var: 0.0
      vf_loss: 3.1211097240448
    num_steps_sampled: 238000
    num_steps_trained: 238000
    wait_time_ms: 33.382
  iterations_since_restore: 129
  node_ip: 172.17.8.48
  num_metric_batches_dropped: 0
  pid: 20453
  policy_reward_mean: {}
  time_since_restore: 1119.0194251537323
  time_this_iter_s: 8.546876668930054
  time_total_s: 1119.0194251537323
  timestamp: 1593995106
  timesteps_since_restore: 238000
  timesteps_this_iter: 2000
  timesteps_total: 238000
  training_iteration: 129
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=20453], 1119 s, 129 iter, 238000 ts, 295 rew

agent-1: 154.0
Sum Reward: 154.0
Avg Reward: 154.0
Min Reward: 154.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
agent-1: 115.0
Sum Reward: 115.0
Avg Reward: 115.0
Min Reward: 115.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-25-14
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 383.0
  episode_reward_mean: 291.25
  episode_reward_min: 115.0
  episodes_this_iter: 2
  episodes_total: 239
  experiment_id: 325b24caee6c4209bf8cf01af4f33e4d
  hostname: gpu048
  info:
    apply_time_ms: 2.506
    dispatch_time_ms: 8.369
    learner:
      cur_lr: 0.0013441492337733507
      grad_gnorm: 21.735218048095703
      policy_entropy: 4.547132968902588
      policy_loss: -1.7213441133499146
      var_gnorm: 29.399127960205078
      vf_explained_var: 0.0
      vf_loss: 2.8365066051483154
    num_steps_sampled: 240000
    num_steps_trained: 240000
    wait_time_ms: 30.833
  iterations_since_restore: 130
  node_ip: 172.17.8.48
  num_metric_batches_dropped: 0
  pid: 20453
  policy_reward_mean: {}
  time_since_restore: 1127.3847398757935
  time_this_iter_s: 8.365314722061157
  time_total_s: 1127.3847398757935
  timestamp: 1593995114
  timesteps_since_restore: 240000
  timesteps_this_iter: 2000
  timesteps_total: 240000
  training_iteration: 130
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=20453], 1127 s, 130 iter, 240000 ts, 291 rew

agent-1: 103.0
Sum Reward: 103.0
Avg Reward: 103.0
Min Reward: 103.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
agent-1: 131.0
Sum Reward: 131.0
Avg Reward: 131.0
Min Reward: 131.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-25-23
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 383.0
  episode_reward_mean: 286.89
  episode_reward_min: 103.0
  episodes_this_iter: 2
  episodes_total: 241
  experiment_id: 325b24caee6c4209bf8cf01af4f33e4d
  hostname: gpu048
  info:
    apply_time_ms: 4.037
    dispatch_time_ms: 10.57
    learner:
      cur_lr: 0.0013440160546451807
      grad_gnorm: 10.987249374389648
      policy_entropy: 3.2324233055114746
      policy_loss: 1.3048582077026367
      var_gnorm: 29.390466690063477
      vf_explained_var: 0.0
      vf_loss: 1.1734845638275146
    num_steps_sampled: 242000
    num_steps_trained: 242000
    wait_time_ms: 29.615
  iterations_since_restore: 131
  node_ip: 172.17.8.48
  num_metric_batches_dropped: 0
  pid: 20453
  policy_reward_mean: {}
  time_since_restore: 1135.8180918693542
  time_this_iter_s: 8.433351993560791
  time_total_s: 1135.8180918693542
  timestamp: 1593995123
  timesteps_since_restore: 242000
  timesteps_this_iter: 2000
  timesteps_total: 242000
  training_iteration: 131
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=20453], 1135 s, 131 iter, 242000 ts, 287 rew

agent-1: 119.0
Sum Reward: 119.0
Avg Reward: 119.0
Min Reward: 119.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
agent-1: 118.0
Sum Reward: 118.0
Avg Reward: 118.0
Min Reward: 118.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-25-31
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 383.0
  episode_reward_mean: 283.04
  episode_reward_min: 103.0
  episodes_this_iter: 2
  episodes_total: 243
  experiment_id: 325b24caee6c4209bf8cf01af4f33e4d
  hostname: gpu048
  info:
    apply_time_ms: 2.47
    dispatch_time_ms: 6.573
    learner:
      cur_lr: 0.0013438827591016889
      grad_gnorm: 19.166324615478516
      policy_entropy: 4.422689437866211
      policy_loss: -0.7912485003471375
      var_gnorm: 29.383663177490234
      vf_explained_var: 0.0
      vf_loss: 2.0564749240875244
    num_steps_sampled: 244000
    num_steps_trained: 244000
    wait_time_ms: 32.593
  iterations_since_restore: 132
  node_ip: 172.17.8.48
  num_metric_batches_dropped: 0
  pid: 20453
  policy_reward_mean: {}
  time_since_restore: 1144.2094230651855
  time_this_iter_s: 8.391331195831299
  time_total_s: 1144.2094230651855
  timestamp: 1593995131
  timesteps_since_restore: 244000
  timesteps_this_iter: 2000
  timesteps_total: 244000
  training_iteration: 132
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=20453], 1144 s, 132 iter, 244000 ts, 283 rew

agent-1: 127.0
Sum Reward: 127.0
Avg Reward: 127.0
Min Reward: 127.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
agent-1: 137.0
Sum Reward: 137.0
Avg Reward: 137.0
Min Reward: 137.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-25-40
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 383.0
  episode_reward_mean: 279.12
  episode_reward_min: 103.0
  episodes_this_iter: 2
  episodes_total: 245
  experiment_id: 325b24caee6c4209bf8cf01af4f33e4d
  hostname: gpu048
  info:
    apply_time_ms: 4.059
    dispatch_time_ms: 8.256
    learner:
      cur_lr: 0.0013437495799735188
      grad_gnorm: 39.999996185302734
      policy_entropy: 5.224339485168457
      policy_loss: 9.023914337158203
      var_gnorm: 29.37807846069336
      vf_explained_var: 5.960464477539063e-08
      vf_loss: 23.184452056884766
    num_steps_sampled: 246000
    num_steps_trained: 246000
    wait_time_ms: 32.065
  iterations_since_restore: 133
  node_ip: 172.17.8.48
  num_metric_batches_dropped: 0
  pid: 20453
  policy_reward_mean: {}
  time_since_restore: 1152.5583894252777
  time_this_iter_s: 8.348966360092163
  time_total_s: 1152.5583894252777
  timestamp: 1593995140
  timesteps_since_restore: 246000
  timesteps_this_iter: 2000
  timesteps_total: 246000
  training_iteration: 133
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=20453], 1152 s, 133 iter, 246000 ts, 279 rew

agent-1: 95.0
Sum Reward: 95.0
Avg Reward: 95.0
Min Reward: 95.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
agent-1: 133.0
Sum Reward: 133.0
Avg Reward: 133.0
Min Reward: 133.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-25-48
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 383.0
  episode_reward_mean: 275.77
  episode_reward_min: 95.0
  episodes_this_iter: 2
  episodes_total: 247
  experiment_id: 325b24caee6c4209bf8cf01af4f33e4d
  hostname: gpu048
  info:
    apply_time_ms: 2.67
    dispatch_time_ms: 8.211
    learner:
      cur_lr: 0.0013436164008453488
      grad_gnorm: 17.620412826538086
      policy_entropy: 3.9436352252960205
      policy_loss: -0.6119593381881714
      var_gnorm: 29.37828254699707
      vf_explained_var: 0.0
      vf_loss: 1.793338656425476
    num_steps_sampled: 248000
    num_steps_trained: 248000
    wait_time_ms: 29.165
  iterations_since_restore: 134
  node_ip: 172.17.8.48
  num_metric_batches_dropped: 0
  pid: 20453
  policy_reward_mean: {}
  time_since_restore: 1160.8440704345703
  time_this_iter_s: 8.285681009292603
  time_total_s: 1160.8440704345703
  timestamp: 1593995148
  timesteps_since_restore: 248000
  timesteps_this_iter: 2000
  timesteps_total: 248000
  training_iteration: 134
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=20453], 1160 s, 134 iter, 248000 ts, 276 rew

agent-1: 112.0
Sum Reward: 112.0
Avg Reward: 112.0
Min Reward: 112.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
agent-1: 111.0
Sum Reward: 111.0
Avg Reward: 111.0
Min Reward: 111.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-25-56
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 383.0
  episode_reward_mean: 272.05
  episode_reward_min: 95.0
  episodes_this_iter: 2
  episodes_total: 249
  experiment_id: 325b24caee6c4209bf8cf01af4f33e4d
  hostname: gpu048
  info:
    apply_time_ms: 3.083
    dispatch_time_ms: 7.702
    learner:
      cur_lr: 0.0013434832217171788
      grad_gnorm: 14.361928939819336
      policy_entropy: 1.677673101425171
      policy_loss: -0.155517116189003
      var_gnorm: 29.366907119750977
      vf_explained_var: 1.1920928955078125e-07
      vf_loss: 1.2824287414550781
    num_steps_sampled: 250000
    num_steps_trained: 250000
    wait_time_ms: 32.957
  iterations_since_restore: 135
  node_ip: 172.17.8.48
  num_metric_batches_dropped: 0
  pid: 20453
  policy_reward_mean: {}
  time_since_restore: 1169.1447484493256
  time_this_iter_s: 8.300678014755249
  time_total_s: 1169.1447484493256
  timestamp: 1593995156
  timesteps_since_restore: 250000
  timesteps_this_iter: 2000
  timesteps_total: 250000
  training_iteration: 135
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=20453], 1169 s, 135 iter, 250000 ts, 272 rew

agent-1: 61.0
Sum Reward: 61.0
Avg Reward: 61.0
Min Reward: 61.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
agent-1: 107.0
Sum Reward: 107.0
Avg Reward: 107.0
Min Reward: 107.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-26-05
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 383.0
  episode_reward_mean: 267.6
  episode_reward_min: 61.0
  episodes_this_iter: 2
  episodes_total: 251
  experiment_id: 325b24caee6c4209bf8cf01af4f33e4d
  hostname: gpu048
  info:
    apply_time_ms: 2.799
    dispatch_time_ms: 7.96
    learner:
      cur_lr: 0.0013433500425890088
      grad_gnorm: 3.1457648277282715
      policy_entropy: 2.6542739868164062
      policy_loss: -1.5927858352661133
      var_gnorm: 29.37036895751953
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 0.5006864666938782
    num_steps_sampled: 252000
    num_steps_trained: 252000
    wait_time_ms: 29.406
  iterations_since_restore: 136
  node_ip: 172.17.8.48
  num_metric_batches_dropped: 0
  pid: 20453
  policy_reward_mean: {}
  time_since_restore: 1178.1750557422638
  time_this_iter_s: 9.030307292938232
  time_total_s: 1178.1750557422638
  timestamp: 1593995165
  timesteps_since_restore: 252000
  timesteps_this_iter: 2000
  timesteps_total: 252000
  training_iteration: 136
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=20453], 1178 s, 136 iter, 252000 ts, 268 rew

agent-1: 104.0
Sum Reward: 104.0
Avg Reward: 104.0
Min Reward: 104.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
agent-1: 90.0
Sum Reward: 90.0
Avg Reward: 90.0
Min Reward: 90.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-26-14
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 383.0
  episode_reward_mean: 263.8
  episode_reward_min: 61.0
  episodes_this_iter: 2
  episodes_total: 253
  experiment_id: 325b24caee6c4209bf8cf01af4f33e4d
  hostname: gpu048
  info:
    apply_time_ms: 2.764
    dispatch_time_ms: 7.486
    learner:
      cur_lr: 0.001343216747045517
      grad_gnorm: 9.200668334960938
      policy_entropy: 3.288679838180542
      policy_loss: 1.2190511226654053
      var_gnorm: 29.36080551147461
      vf_explained_var: 0.018094182014465332
      vf_loss: 1.8534108400344849
    num_steps_sampled: 254000
    num_steps_trained: 254000
    wait_time_ms: 31.728
  iterations_since_restore: 137
  node_ip: 172.17.8.48
  num_metric_batches_dropped: 0
  pid: 20453
  policy_reward_mean: {}
  time_since_restore: 1186.4948461055756
  time_this_iter_s: 8.319790363311768
  time_total_s: 1186.4948461055756
  timestamp: 1593995174
  timesteps_since_restore: 254000
  timesteps_this_iter: 2000
  timesteps_total: 254000
  training_iteration: 137
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=20453], 1186 s, 137 iter, 254000 ts, 264 rew

agent-1: 80.0
Sum Reward: 80.0
Avg Reward: 80.0
Min Reward: 80.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
agent-1: 155.0
Sum Reward: 155.0
Avg Reward: 155.0
Min Reward: 155.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-26-22
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 383.0
  episode_reward_mean: 260.19
  episode_reward_min: 61.0
  episodes_this_iter: 2
  episodes_total: 255
  experiment_id: 325b24caee6c4209bf8cf01af4f33e4d
  hostname: gpu048
  info:
    apply_time_ms: 3.437
    dispatch_time_ms: 9.142
    learner:
      cur_lr: 0.001343083567917347
      grad_gnorm: 11.97928524017334
      policy_entropy: 3.809813976287842
      policy_loss: 2.4444820880889893
      var_gnorm: 29.380632400512695
      vf_explained_var: 0.0
      vf_loss: 3.5904855728149414
    num_steps_sampled: 256000
    num_steps_trained: 256000
    wait_time_ms: 29.914
  iterations_since_restore: 138
  node_ip: 172.17.8.48
  num_metric_batches_dropped: 0
  pid: 20453
  policy_reward_mean: {}
  time_since_restore: 1194.7923946380615
  time_this_iter_s: 8.297548532485962
  time_total_s: 1194.7923946380615
  timestamp: 1593995182
  timesteps_since_restore: 256000
  timesteps_this_iter: 2000
  timesteps_total: 256000
  training_iteration: 138
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=20453], 1194 s, 138 iter, 256000 ts, 260 rew

agent-1: 118.0
Sum Reward: 118.0
Avg Reward: 118.0
Min Reward: 118.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
agent-1: 102.0
Sum Reward: 102.0
Avg Reward: 102.0
Min Reward: 102.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-26-30
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 383.0
  episode_reward_mean: 257.02
  episode_reward_min: 61.0
  episodes_this_iter: 2
  episodes_total: 257
  experiment_id: 325b24caee6c4209bf8cf01af4f33e4d
  hostname: gpu048
  info:
    apply_time_ms: 4.107
    dispatch_time_ms: 6.407
    learner:
      cur_lr: 0.001342950388789177
      grad_gnorm: 14.589981079101562
      policy_entropy: 3.4772520065307617
      policy_loss: -0.44324156641960144
      var_gnorm: 29.364015579223633
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 1.251244068145752
    num_steps_sampled: 258000
    num_steps_trained: 258000
    wait_time_ms: 34.974
  iterations_since_restore: 139
  node_ip: 172.17.8.48
  num_metric_batches_dropped: 0
  pid: 20453
  policy_reward_mean: {}
  time_since_restore: 1203.0990772247314
  time_this_iter_s: 8.306682586669922
  time_total_s: 1203.0990772247314
  timestamp: 1593995190
  timesteps_since_restore: 258000
  timesteps_this_iter: 2000
  timesteps_total: 258000
  training_iteration: 139
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=20453], 1203 s, 139 iter, 258000 ts, 257 rew

agent-1: 97.0
Sum Reward: 97.0
Avg Reward: 97.0
Min Reward: 97.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
agent-1: 93.0
Sum Reward: 93.0
Avg Reward: 93.0
Min Reward: 93.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-26-39
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 383.0
  episode_reward_mean: 254.24
  episode_reward_min: 61.0
  episodes_this_iter: 2
  episodes_total: 259
  experiment_id: 325b24caee6c4209bf8cf01af4f33e4d
  hostname: gpu048
  info:
    apply_time_ms: 3.423
    dispatch_time_ms: 7.516
    learner:
      cur_lr: 0.001342817209661007
      grad_gnorm: 16.505470275878906
      policy_entropy: 4.679080009460449
      policy_loss: -2.768730878829956
      var_gnorm: 29.373924255371094
      vf_explained_var: 0.0
      vf_loss: 1.640282154083252
    num_steps_sampled: 260000
    num_steps_trained: 260000
    wait_time_ms: 32.714
  iterations_since_restore: 140
  node_ip: 172.17.8.48
  num_metric_batches_dropped: 0
  pid: 20453
  policy_reward_mean: {}
  time_since_restore: 1211.4195499420166
  time_this_iter_s: 8.320472717285156
  time_total_s: 1211.4195499420166
  timestamp: 1593995199
  timesteps_since_restore: 260000
  timesteps_this_iter: 2000
  timesteps_total: 260000
  training_iteration: 140
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=20453], 1211 s, 140 iter, 260000 ts, 254 rew

agent-1: 138.0
Sum Reward: 138.0
Avg Reward: 138.0
Min Reward: 138.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
agent-1: 154.0
Sum Reward: 154.0
Avg Reward: 154.0
Min Reward: 154.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-26-47
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 383.0
  episode_reward_mean: 250.75
  episode_reward_min: 61.0
  episodes_this_iter: 2
  episodes_total: 261
  experiment_id: 325b24caee6c4209bf8cf01af4f33e4d
  hostname: gpu048
  info:
    apply_time_ms: 3.522
    dispatch_time_ms: 8.464
    learner:
      cur_lr: 0.001342684030532837
      grad_gnorm: 19.040136337280273
      policy_entropy: 2.6136322021484375
      policy_loss: -0.3833238184452057
      var_gnorm: 29.38831901550293
      vf_explained_var: 5.960464477539063e-08
      vf_loss: 2.209639310836792
    num_steps_sampled: 262000
    num_steps_trained: 262000
    wait_time_ms: 30.046
  iterations_since_restore: 141
  node_ip: 172.17.8.48
  num_metric_batches_dropped: 0
  pid: 20453
  policy_reward_mean: {}
  time_since_restore: 1219.7245688438416
  time_this_iter_s: 8.305018901824951
  time_total_s: 1219.7245688438416
  timestamp: 1593995207
  timesteps_since_restore: 262000
  timesteps_this_iter: 2000
  timesteps_total: 262000
  training_iteration: 141
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=20453], 1219 s, 141 iter, 262000 ts, 251 rew

agent-1: 122.0
Sum Reward: 122.0
Avg Reward: 122.0
Min Reward: 122.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
agent-1: 125.0
Sum Reward: 125.0
Avg Reward: 125.0
Min Reward: 125.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-26-55
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 383.0
  episode_reward_mean: 246.63
  episode_reward_min: 61.0
  episodes_this_iter: 2
  episodes_total: 263
  experiment_id: 325b24caee6c4209bf8cf01af4f33e4d
  hostname: gpu048
  info:
    apply_time_ms: 2.732
    dispatch_time_ms: 7.278
    learner:
      cur_lr: 0.001342550851404667
      grad_gnorm: 20.19782829284668
      policy_entropy: 3.857663869857788
      policy_loss: -4.154733180999756
      var_gnorm: 29.38832664489746
      vf_explained_var: 0.0
      vf_loss: 2.0440585613250732
    num_steps_sampled: 264000
    num_steps_trained: 264000
    wait_time_ms: 31.694
  iterations_since_restore: 142
  node_ip: 172.17.8.48
  num_metric_batches_dropped: 0
  pid: 20453
  policy_reward_mean: {}
  time_since_restore: 1228.0779464244843
  time_this_iter_s: 8.3533775806427
  time_total_s: 1228.0779464244843
  timestamp: 1593995215
  timesteps_since_restore: 264000
  timesteps_this_iter: 2000
  timesteps_total: 264000
  training_iteration: 142
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=20453], 1228 s, 142 iter, 264000 ts, 247 rew

agent-1: 136.0
Sum Reward: 136.0
Avg Reward: 136.0
Min Reward: 136.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
agent-1: 63.0
Sum Reward: 63.0
Avg Reward: 63.0
Min Reward: 63.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-27-04
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 383.0
  episode_reward_mean: 242.04
  episode_reward_min: 61.0
  episodes_this_iter: 2
  episodes_total: 265
  experiment_id: 325b24caee6c4209bf8cf01af4f33e4d
  hostname: gpu048
  info:
    apply_time_ms: 3.167
    dispatch_time_ms: 8.198
    learner:
      cur_lr: 0.001342417555861175
      grad_gnorm: 13.27166748046875
      policy_entropy: 3.2817933559417725
      policy_loss: -0.7630677223205566
      var_gnorm: 29.369426727294922
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 1.0780823230743408
    num_steps_sampled: 266000
    num_steps_trained: 266000
    wait_time_ms: 28.899
  iterations_since_restore: 143
  node_ip: 172.17.8.48
  num_metric_batches_dropped: 0
  pid: 20453
  policy_reward_mean: {}
  time_since_restore: 1236.3635821342468
  time_this_iter_s: 8.285635709762573
  time_total_s: 1236.3635821342468
  timestamp: 1593995224
  timesteps_since_restore: 266000
  timesteps_this_iter: 2000
  timesteps_total: 266000
  training_iteration: 143
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=20453], 1236 s, 143 iter, 266000 ts, 242 rew

agent-1: 94.0
Sum Reward: 94.0
Avg Reward: 94.0
Min Reward: 94.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
agent-1: 128.0
Sum Reward: 128.0
Avg Reward: 128.0
Min Reward: 128.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-27-12
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 383.0
  episode_reward_mean: 237.61
  episode_reward_min: 61.0
  episodes_this_iter: 2
  episodes_total: 267
  experiment_id: 325b24caee6c4209bf8cf01af4f33e4d
  hostname: gpu048
  info:
    apply_time_ms: 2.875
    dispatch_time_ms: 7.18
    learner:
      cur_lr: 0.001342284376733005
      grad_gnorm: 17.650388717651367
      policy_entropy: 3.258185863494873
      policy_loss: -1.2549402713775635
      var_gnorm: 29.389751434326172
      vf_explained_var: 0.0
      vf_loss: 1.931887149810791
    num_steps_sampled: 268000
    num_steps_trained: 268000
    wait_time_ms: 32.463
  iterations_since_restore: 144
  node_ip: 172.17.8.48
  num_metric_batches_dropped: 0
  pid: 20453
  policy_reward_mean: {}
  time_since_restore: 1244.6821146011353
  time_this_iter_s: 8.318532466888428
  time_total_s: 1244.6821146011353
  timestamp: 1593995232
  timesteps_since_restore: 268000
  timesteps_this_iter: 2000
  timesteps_total: 268000
  training_iteration: 144
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=20453], 1244 s, 144 iter, 268000 ts, 238 rew

agent-1: 109.0
Sum Reward: 109.0
Avg Reward: 109.0
Min Reward: 109.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
agent-1: 134.0
Sum Reward: 134.0
Avg Reward: 134.0
Min Reward: 134.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-27-21
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 383.0
  episode_reward_mean: 233.12
  episode_reward_min: 61.0
  episodes_this_iter: 2
  episodes_total: 269
  experiment_id: 325b24caee6c4209bf8cf01af4f33e4d
  hostname: gpu048
  info:
    apply_time_ms: 4.074
    dispatch_time_ms: 7.463
    learner:
      cur_lr: 0.001342151197604835
      grad_gnorm: 8.439496040344238
      policy_entropy: 3.835995674133301
      policy_loss: -0.5425400733947754
      var_gnorm: 29.38955307006836
      vf_explained_var: 0.0
      vf_loss: 0.7498323321342468
    num_steps_sampled: 270000
    num_steps_trained: 270000
    wait_time_ms: 32.021
  iterations_since_restore: 145
  node_ip: 172.17.8.48
  num_metric_batches_dropped: 0
  pid: 20453
  policy_reward_mean: {}
  time_since_restore: 1253.0480461120605
  time_this_iter_s: 8.365931510925293
  time_total_s: 1253.0480461120605
  timestamp: 1593995241
  timesteps_since_restore: 270000
  timesteps_this_iter: 2000
  timesteps_total: 270000
  training_iteration: 145
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=20453], 1253 s, 145 iter, 270000 ts, 233 rew

agent-1: 113.0
Sum Reward: 113.0
Avg Reward: 113.0
Min Reward: 113.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
agent-1: 152.0
Sum Reward: 152.0
Avg Reward: 152.0
Min Reward: 152.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-27-29
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 383.0
  episode_reward_mean: 229.44
  episode_reward_min: 61.0
  episodes_this_iter: 2
  episodes_total: 271
  experiment_id: 325b24caee6c4209bf8cf01af4f33e4d
  hostname: gpu048
  info:
    apply_time_ms: 3.908
    dispatch_time_ms: 6.551
    learner:
      cur_lr: 0.001342018018476665
      grad_gnorm: 11.072332382202148
      policy_entropy: 5.802857875823975
      policy_loss: 1.3222111463546753
      var_gnorm: 29.404891967773438
      vf_explained_var: 0.0
      vf_loss: 1.20991051197052
    num_steps_sampled: 272000
    num_steps_trained: 272000
    wait_time_ms: 33.033
  iterations_since_restore: 146
  node_ip: 172.17.8.48
  num_metric_batches_dropped: 0
  pid: 20453
  policy_reward_mean: {}
  time_since_restore: 1261.5042388439178
  time_this_iter_s: 8.4561927318573
  time_total_s: 1261.5042388439178
  timestamp: 1593995249
  timesteps_since_restore: 272000
  timesteps_this_iter: 2000
  timesteps_total: 272000
  training_iteration: 146
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=20453], 1261 s, 146 iter, 272000 ts, 229 rew

agent-1: 183.0
Sum Reward: 183.0
Avg Reward: 183.0
Min Reward: 183.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
agent-1: 124.0
Sum Reward: 124.0
Avg Reward: 124.0
Min Reward: 124.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-27-38
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 383.0
  episode_reward_mean: 226.9
  episode_reward_min: 61.0
  episodes_this_iter: 2
  episodes_total: 273
  experiment_id: 325b24caee6c4209bf8cf01af4f33e4d
  hostname: gpu048
  info:
    apply_time_ms: 2.867
    dispatch_time_ms: 6.31
    learner:
      cur_lr: 0.001341884839348495
      grad_gnorm: 20.931787490844727
      policy_entropy: 2.658069133758545
      policy_loss: -0.8175915479660034
      var_gnorm: 29.407634735107422
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 2.6795296669006348
    num_steps_sampled: 274000
    num_steps_trained: 274000
    wait_time_ms: 31.464
  iterations_since_restore: 147
  node_ip: 172.17.8.48
  num_metric_batches_dropped: 0
  pid: 20453
  policy_reward_mean: {}
  time_since_restore: 1269.9181582927704
  time_this_iter_s: 8.413919448852539
  time_total_s: 1269.9181582927704
  timestamp: 1593995258
  timesteps_since_restore: 274000
  timesteps_this_iter: 2000
  timesteps_total: 274000
  training_iteration: 147
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=20453], 1269 s, 147 iter, 274000 ts, 227 rew

agent-1: 152.0
Sum Reward: 152.0
Avg Reward: 152.0
Min Reward: 152.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
agent-1: 128.0
Sum Reward: 128.0
Avg Reward: 128.0
Min Reward: 128.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-27-46
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 383.0
  episode_reward_mean: 223.27
  episode_reward_min: 61.0
  episodes_this_iter: 2
  episodes_total: 275
  experiment_id: 325b24caee6c4209bf8cf01af4f33e4d
  hostname: gpu048
  info:
    apply_time_ms: 3.689
    dispatch_time_ms: 6.502
    learner:
      cur_lr: 0.0013417515438050032
      grad_gnorm: 19.646133422851562
      policy_entropy: 3.481503486633301
      policy_loss: -0.6599712371826172
      var_gnorm: 29.395843505859375
      vf_explained_var: 5.960464477539063e-08
      vf_loss: 2.223120927810669
    num_steps_sampled: 276000
    num_steps_trained: 276000
    wait_time_ms: 34.809
  iterations_since_restore: 148
  node_ip: 172.17.8.48
  num_metric_batches_dropped: 0
  pid: 20453
  policy_reward_mean: {}
  time_since_restore: 1278.2520246505737
  time_this_iter_s: 8.333866357803345
  time_total_s: 1278.2520246505737
  timestamp: 1593995266
  timesteps_since_restore: 276000
  timesteps_this_iter: 2000
  timesteps_total: 276000
  training_iteration: 148
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=20453], 1278 s, 148 iter, 276000 ts, 223 rew

agent-1: 125.0
Sum Reward: 125.0
Avg Reward: 125.0
Min Reward: 125.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
agent-1: 149.0
Sum Reward: 149.0
Avg Reward: 149.0
Min Reward: 149.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-27-54
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 383.0
  episode_reward_mean: 221.11
  episode_reward_min: 61.0
  episodes_this_iter: 2
  episodes_total: 277
  experiment_id: 325b24caee6c4209bf8cf01af4f33e4d
  hostname: gpu048
  info:
    apply_time_ms: 3.616
    dispatch_time_ms: 6.94
    learner:
      cur_lr: 0.0013416183646768332
      grad_gnorm: 29.23292350769043
      policy_entropy: 1.979113221168518
      policy_loss: -1.192504644393921
      var_gnorm: 29.398151397705078
      vf_explained_var: 5.960464477539063e-08
      vf_loss: 7.763454437255859
    num_steps_sampled: 278000
    num_steps_trained: 278000
    wait_time_ms: 35.046
  iterations_since_restore: 149
  node_ip: 172.17.8.48
  num_metric_batches_dropped: 0
  pid: 20453
  policy_reward_mean: {}
  time_since_restore: 1286.771639585495
  time_this_iter_s: 8.519614934921265
  time_total_s: 1286.771639585495
  timestamp: 1593995274
  timesteps_since_restore: 278000
  timesteps_this_iter: 2000
  timesteps_total: 278000
  training_iteration: 149
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=20453], 1286 s, 149 iter, 278000 ts, 221 rew

agent-1: 124.0
Sum Reward: 124.0
Avg Reward: 124.0
Min Reward: 124.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
agent-1: 93.0
Sum Reward: 93.0
Avg Reward: 93.0
Min Reward: 93.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-28-03
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 383.0
  episode_reward_mean: 216.75
  episode_reward_min: 61.0
  episodes_this_iter: 2
  episodes_total: 279
  experiment_id: 325b24caee6c4209bf8cf01af4f33e4d
  hostname: gpu048
  info:
    apply_time_ms: 3.593
    dispatch_time_ms: 7.526
    learner:
      cur_lr: 0.0013414851855486631
      grad_gnorm: 6.064792633056641
      policy_entropy: 2.580770492553711
      policy_loss: -0.3751809000968933
      var_gnorm: 29.381717681884766
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 0.6270695924758911
    num_steps_sampled: 280000
    num_steps_trained: 280000
    wait_time_ms: 30.453
  iterations_since_restore: 150
  node_ip: 172.17.8.48
  num_metric_batches_dropped: 0
  pid: 20453
  policy_reward_mean: {}
  time_since_restore: 1295.1180181503296
  time_this_iter_s: 8.346378564834595
  time_total_s: 1295.1180181503296
  timestamp: 1593995283
  timesteps_since_restore: 280000
  timesteps_this_iter: 2000
  timesteps_total: 280000
  training_iteration: 150
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=20453], 1295 s, 150 iter, 280000 ts, 217 rew

agent-1: 103.0
Sum Reward: 103.0
Avg Reward: 103.0
Min Reward: 103.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
agent-1: 152.0
Sum Reward: 152.0
Avg Reward: 152.0
Min Reward: 152.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-28-11
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 383.0
  episode_reward_mean: 214.4
  episode_reward_min: 61.0
  episodes_this_iter: 2
  episodes_total: 281
  experiment_id: 325b24caee6c4209bf8cf01af4f33e4d
  hostname: gpu048
  info:
    apply_time_ms: 3.183
    dispatch_time_ms: 7.179
    learner:
      cur_lr: 0.0013413520064204931
      grad_gnorm: 13.071775436401367
      policy_entropy: 4.601147174835205
      policy_loss: 0.1311410814523697
      var_gnorm: 29.45986557006836
      vf_explained_var: 0.0
      vf_loss: 1.5149996280670166
    num_steps_sampled: 282000
    num_steps_trained: 282000
    wait_time_ms: 33.713
  iterations_since_restore: 151
  node_ip: 172.17.8.48
  num_metric_batches_dropped: 0
  pid: 20453
  policy_reward_mean: {}
  time_since_restore: 1303.443158864975
  time_this_iter_s: 8.325140714645386
  time_total_s: 1303.443158864975
  timestamp: 1593995291
  timesteps_since_restore: 282000
  timesteps_this_iter: 2000
  timesteps_total: 282000
  training_iteration: 151
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=20453], 1303 s, 151 iter, 282000 ts, 214 rew

agent-1: 136.0
Sum Reward: 136.0
Avg Reward: 136.0
Min Reward: 136.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
agent-1: 113.0
Sum Reward: 113.0
Avg Reward: 113.0
Min Reward: 113.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-28-20
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 383.0
  episode_reward_mean: 211.1
  episode_reward_min: 61.0
  episodes_this_iter: 2
  episodes_total: 283
  experiment_id: 325b24caee6c4209bf8cf01af4f33e4d
  hostname: gpu048
  info:
    apply_time_ms: 4.19
    dispatch_time_ms: 8.793
    learner:
      cur_lr: 0.0013412188272923231
      grad_gnorm: 19.633914947509766
      policy_entropy: 0.6636592745780945
      policy_loss: -0.0770849883556366
      var_gnorm: 29.581096649169922
      vf_explained_var: 0.0
      vf_loss: 2.412555456161499
    num_steps_sampled: 284000
    num_steps_trained: 284000
    wait_time_ms: 31.473
  iterations_since_restore: 152
  node_ip: 172.17.8.48
  num_metric_batches_dropped: 0
  pid: 20453
  policy_reward_mean: {}
  time_since_restore: 1311.8810498714447
  time_this_iter_s: 8.437891006469727
  time_total_s: 1311.8810498714447
  timestamp: 1593995300
  timesteps_since_restore: 284000
  timesteps_this_iter: 2000
  timesteps_total: 284000
  training_iteration: 152
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=20453], 1311 s, 152 iter, 284000 ts, 211 rew

agent-1: 150.0
Sum Reward: 150.0
Avg Reward: 150.0
Min Reward: 150.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-28-33
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 383.0
  episode_reward_mean: 209.64
  episode_reward_min: 61.0
  episodes_this_iter: 1
  episodes_total: 284
  experiment_id: 325b24caee6c4209bf8cf01af4f33e4d
  hostname: gpu048
  info:
    apply_time_ms: 4.308
    dispatch_time_ms: 31.217
    learner:
      cur_lr: 0.001341085648164153
      grad_gnorm: 13.759195327758789
      policy_entropy: 0.8930145502090454
      policy_loss: -0.08834858238697052
      var_gnorm: 29.567113876342773
      vf_explained_var: 0.00024825334548950195
      vf_loss: 1.342424988746643
    num_steps_sampled: 285000
    num_steps_trained: 285000
    wait_time_ms: 16.557
  iterations_since_restore: 153
  node_ip: 172.17.8.48
  num_metric_batches_dropped: 0
  pid: 20453
  policy_reward_mean: {}
  time_since_restore: 1325.6212105751038
  time_this_iter_s: 13.740160703659058
  time_total_s: 1325.6212105751038
  timestamp: 1593995313
  timesteps_since_restore: 285000
  timesteps_this_iter: 1000
  timesteps_total: 285000
  training_iteration: 153
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=20453], 1325 s, 153 iter, 285000 ts, 210 rew

agent-1: 121.0
Sum Reward: 121.0
Avg Reward: 121.0
Min Reward: 121.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-28-40
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 383.0
  episode_reward_mean: 207.89
  episode_reward_min: 61.0
  episodes_this_iter: 1
  episodes_total: 285
  experiment_id: 325b24caee6c4209bf8cf01af4f33e4d
  hostname: gpu048
  info:
    apply_time_ms: 4.091
    dispatch_time_ms: 36.379
    learner:
      cur_lr: 0.0013410189421847463
      grad_gnorm: 13.770654678344727
      policy_entropy: 1.1592669486999512
      policy_loss: -0.13359251618385315
      var_gnorm: 29.56500816345215
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 1.3186386823654175
    num_steps_sampled: 286000
    num_steps_trained: 286000
    wait_time_ms: 15.995
  iterations_since_restore: 154
  node_ip: 172.17.8.48
  num_metric_batches_dropped: 0
  pid: 20453
  policy_reward_mean: {}
  time_since_restore: 1331.9273917675018
  time_this_iter_s: 6.306181192398071
  time_total_s: 1331.9273917675018
  timestamp: 1593995320
  timesteps_since_restore: 286000
  timesteps_this_iter: 1000
  timesteps_total: 286000
  training_iteration: 154
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=20453], 1331 s, 154 iter, 286000 ts, 208 rew

agent-1: 76.0
Sum Reward: 76.0
Avg Reward: 76.0
Min Reward: 76.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-28-46
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 383.0
  episode_reward_mean: 205.32
  episode_reward_min: 61.0
  episodes_this_iter: 1
  episodes_total: 286
  experiment_id: 325b24caee6c4209bf8cf01af4f33e4d
  hostname: gpu048
  info:
    apply_time_ms: 2.764
    dispatch_time_ms: 44.769
    learner:
      cur_lr: 0.0013409523526206613
      grad_gnorm: 9.492810249328613
      policy_entropy: 2.571030616760254
      policy_loss: -0.6987168788909912
      var_gnorm: 29.669174194335938
      vf_explained_var: -1.0
      vf_loss: 1.2937835454940796
    num_steps_sampled: 287000
    num_steps_trained: 287000
    wait_time_ms: 12.657
  iterations_since_restore: 155
  node_ip: 172.17.8.48
  num_metric_batches_dropped: 0
  pid: 20453
  policy_reward_mean: {}
  time_since_restore: 1338.149245262146
  time_this_iter_s: 6.221853494644165
  time_total_s: 1338.149245262146
  timestamp: 1593995326
  timesteps_since_restore: 287000
  timesteps_this_iter: 1000
  timesteps_total: 287000
  training_iteration: 155
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=20453], 1338 s, 155 iter, 287000 ts, 205 rew

agent-1: 72.0
Sum Reward: 72.0
Avg Reward: 72.0
Min Reward: 72.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-28-53
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 383.0
  episode_reward_mean: 202.79
  episode_reward_min: 61.0
  episodes_this_iter: 1
  episodes_total: 287
  experiment_id: 325b24caee6c4209bf8cf01af4f33e4d
  hostname: gpu048
  info:
    apply_time_ms: 3.225
    dispatch_time_ms: 32.936
    learner:
      cur_lr: 0.0013408857630565763
      grad_gnorm: 8.31640338897705
      policy_entropy: 1.6271893978118896
      policy_loss: 1.4412124156951904
      var_gnorm: 29.661376953125
      vf_explained_var: 5.960464477539063e-08
      vf_loss: 0.5646655559539795
    num_steps_sampled: 288000
    num_steps_trained: 288000
    wait_time_ms: 29.03
  iterations_since_restore: 156
  node_ip: 172.17.8.48
  num_metric_batches_dropped: 0
  pid: 20453
  policy_reward_mean: {}
  time_since_restore: 1344.7612357139587
  time_this_iter_s: 6.611990451812744
  time_total_s: 1344.7612357139587
  timestamp: 1593995333
  timesteps_since_restore: 288000
  timesteps_this_iter: 1000
  timesteps_total: 288000
  training_iteration: 156
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=20453], 1344 s, 156 iter, 288000 ts, 203 rew

agent-1: 63.0
Sum Reward: 63.0
Avg Reward: 63.0
Min Reward: 63.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-28-59
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 383.0
  episode_reward_mean: 200.58
  episode_reward_min: 61.0
  episodes_this_iter: 1
  episodes_total: 288
  experiment_id: 325b24caee6c4209bf8cf01af4f33e4d
  hostname: gpu048
  info:
    apply_time_ms: 4.157
    dispatch_time_ms: 53.99
    learner:
      cur_lr: 0.0013408191734924912
      grad_gnorm: 21.442642211914062
      policy_entropy: 3.362964630126953
      policy_loss: -1.0333411693572998
      var_gnorm: 29.659908294677734
      vf_explained_var: 0.06839156150817871
      vf_loss: 2.5193018913269043
    num_steps_sampled: 289000
    num_steps_trained: 289000
    wait_time_ms: 19.853
  iterations_since_restore: 157
  node_ip: 172.17.8.48
  num_metric_batches_dropped: 0
  pid: 20453
  policy_reward_mean: {}
  time_since_restore: 1351.4664113521576
  time_this_iter_s: 6.7051756381988525
  time_total_s: 1351.4664113521576
  timestamp: 1593995339
  timesteps_since_restore: 289000
  timesteps_this_iter: 1000
  timesteps_total: 289000
  training_iteration: 157
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=20453], 1351 s, 157 iter, 289000 ts, 201 rew

agent-1: 101.0
Sum Reward: 101.0
Avg Reward: 101.0
Min Reward: 101.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-29-05
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 383.0
  episode_reward_mean: 198.8
  episode_reward_min: 61.0
  episodes_this_iter: 1
  episodes_total: 289
  experiment_id: 325b24caee6c4209bf8cf01af4f33e4d
  hostname: gpu048
  info:
    apply_time_ms: 3.206
    dispatch_time_ms: 18.784
    learner:
      cur_lr: 0.0013407525839284062
      grad_gnorm: 40.0
      policy_entropy: 1.2114143371582031
      policy_loss: 0.7759360671043396
      var_gnorm: 29.65726661682129
      vf_explained_var: 0.0
      vf_loss: 60.5210075378418
    num_steps_sampled: 290000
    num_steps_trained: 290000
    wait_time_ms: 23.499
  iterations_since_restore: 158
  node_ip: 172.17.8.48
  num_metric_batches_dropped: 0
  pid: 20453
  policy_reward_mean: {}
  time_since_restore: 1357.4076240062714
  time_this_iter_s: 5.9412126541137695
  time_total_s: 1357.4076240062714
  timestamp: 1593995345
  timesteps_since_restore: 290000
  timesteps_this_iter: 1000
  timesteps_total: 290000
  training_iteration: 158
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=20453], 1357 s, 158 iter, 290000 ts, 199 rew

agent-1: 66.0
Sum Reward: 66.0
Avg Reward: 66.0
Min Reward: 66.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-29-11
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 383.0
  episode_reward_mean: 196.65
  episode_reward_min: 61.0
  episodes_this_iter: 1
  episodes_total: 290
  experiment_id: 325b24caee6c4209bf8cf01af4f33e4d
  hostname: gpu048
  info:
    apply_time_ms: 2.616
    dispatch_time_ms: 25.207
    learner:
      cur_lr: 0.0013406859943643212
      grad_gnorm: 6.923896789550781
      policy_entropy: 1.8523681163787842
      policy_loss: -0.169042706489563
      var_gnorm: 29.65178680419922
      vf_explained_var: 0.0
      vf_loss: 0.40503203868865967
    num_steps_sampled: 291000
    num_steps_trained: 291000
    wait_time_ms: 27.324
  iterations_since_restore: 159
  node_ip: 172.17.8.48
  num_metric_batches_dropped: 0
  pid: 20453
  policy_reward_mean: {}
  time_since_restore: 1362.7509922981262
  time_this_iter_s: 5.343368291854858
  time_total_s: 1362.7509922981262
  timestamp: 1593995351
  timesteps_since_restore: 291000
  timesteps_this_iter: 1000
  timesteps_total: 291000
  training_iteration: 159
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=20453], 1362 s, 159 iter, 291000 ts, 197 rew

agent-1: 79.0
Sum Reward: 79.0
Avg Reward: 79.0
Min Reward: 79.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-29-16
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 383.0
  episode_reward_mean: 194.24
  episode_reward_min: 61.0
  episodes_this_iter: 1
  episodes_total: 291
  experiment_id: 325b24caee6c4209bf8cf01af4f33e4d
  hostname: gpu048
  info:
    apply_time_ms: 3.095
    dispatch_time_ms: 33.254
    learner:
      cur_lr: 0.0013406194048002362
      grad_gnorm: 14.933575630187988
      policy_entropy: 4.04500675201416
      policy_loss: -1.3108659982681274
      var_gnorm: 29.657922744750977
      vf_explained_var: 0.14273959398269653
      vf_loss: 1.3159916400909424
    num_steps_sampled: 292000
    num_steps_trained: 292000
    wait_time_ms: 19.632
  iterations_since_restore: 160
  node_ip: 172.17.8.48
  num_metric_batches_dropped: 0
  pid: 20453
  policy_reward_mean: {}
  time_since_restore: 1368.3208980560303
  time_this_iter_s: 5.569905757904053
  time_total_s: 1368.3208980560303
  timestamp: 1593995356
  timesteps_since_restore: 292000
  timesteps_this_iter: 1000
  timesteps_total: 292000
  training_iteration: 160
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=20453], 1368 s, 160 iter, 292000 ts, 194 rew

agent-1: 115.0
Sum Reward: 115.0
Avg Reward: 115.0
Min Reward: 115.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-29-22
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 383.0
  episode_reward_mean: 191.79
  episode_reward_min: 61.0
  episodes_this_iter: 1
  episodes_total: 292
  experiment_id: 325b24caee6c4209bf8cf01af4f33e4d
  hostname: gpu048
  info:
    apply_time_ms: 3.688
    dispatch_time_ms: 24.924
    learner:
      cur_lr: 0.0013405528152361512
      grad_gnorm: 40.000003814697266
      policy_entropy: 3.1452035903930664
      policy_loss: 12.648082733154297
      var_gnorm: 29.65850830078125
      vf_explained_var: -0.1080319881439209
      vf_loss: 22.213748931884766
    num_steps_sampled: 293000
    num_steps_trained: 293000
    wait_time_ms: 30.431
  iterations_since_restore: 161
  node_ip: 172.17.8.48
  num_metric_batches_dropped: 0
  pid: 20453
  policy_reward_mean: {}
  time_since_restore: 1373.9909768104553
  time_this_iter_s: 5.670078754425049
  time_total_s: 1373.9909768104553
  timestamp: 1593995362
  timesteps_since_restore: 293000
  timesteps_this_iter: 1000
  timesteps_total: 293000
  training_iteration: 161
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=20453], 1373 s, 161 iter, 293000 ts, 192 rew

agent-1: 119.0
Sum Reward: 119.0
Avg Reward: 119.0
Min Reward: 119.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-29-28
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 383.0
  episode_reward_mean: 189.47
  episode_reward_min: 61.0
  episodes_this_iter: 1
  episodes_total: 293
  experiment_id: 325b24caee6c4209bf8cf01af4f33e4d
  hostname: gpu048
  info:
    apply_time_ms: 3.044
    dispatch_time_ms: 23.32
    learner:
      cur_lr: 0.0013404862256720662
      grad_gnorm: 15.673812866210938
      policy_entropy: 2.7906394004821777
      policy_loss: -1.8434187173843384
      var_gnorm: 29.815736770629883
      vf_explained_var: 0.6110705137252808
      vf_loss: 1.3383374214172363
    num_steps_sampled: 294000
    num_steps_trained: 294000
    wait_time_ms: 14.302
  iterations_since_restore: 162
  node_ip: 172.17.8.48
  num_metric_batches_dropped: 0
  pid: 20453
  policy_reward_mean: {}
  time_since_restore: 1379.9152023792267
  time_this_iter_s: 5.924225568771362
  time_total_s: 1379.9152023792267
  timestamp: 1593995368
  timesteps_since_restore: 294000
  timesteps_this_iter: 1000
  timesteps_total: 294000
  training_iteration: 162
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=20453], 1379 s, 162 iter, 294000 ts, 189 rew

agent-1: 101.0
Sum Reward: 101.0
Avg Reward: 101.0
Min Reward: 101.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
agent-1: 126.0
Sum Reward: 126.0
Avg Reward: 126.0
Min Reward: 126.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-29-36
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 383.0
  episode_reward_mean: 184.39
  episode_reward_min: 61.0
  episodes_this_iter: 2
  episodes_total: 295
  experiment_id: 325b24caee6c4209bf8cf01af4f33e4d
  hostname: gpu048
  info:
    apply_time_ms: 3.4
    dispatch_time_ms: 8.637
    learner:
      cur_lr: 0.0013404196361079812
      grad_gnorm: 12.856083869934082
      policy_entropy: 1.190414309501648
      policy_loss: -0.10662030428647995
      var_gnorm: 29.81780242919922
      vf_explained_var: 0.0
      vf_loss: 1.0300281047821045
    num_steps_sampled: 296000
    num_steps_trained: 296000
    wait_time_ms: 27.619
  iterations_since_restore: 163
  node_ip: 172.17.8.48
  num_metric_batches_dropped: 0
  pid: 20453
  policy_reward_mean: {}
  time_since_restore: 1387.9732394218445
  time_this_iter_s: 8.058037042617798
  time_total_s: 1387.9732394218445
  timestamp: 1593995376
  timesteps_since_restore: 296000
  timesteps_this_iter: 2000
  timesteps_total: 296000
  training_iteration: 163
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=20453], 1387 s, 163 iter, 296000 ts, 184 rew

agent-1: 65.0
Sum Reward: 65.0
Avg Reward: 65.0
Min Reward: 65.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
agent-1: 67.0
Sum Reward: 67.0
Avg Reward: 67.0
Min Reward: 67.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-29-44
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 383.0
  episode_reward_mean: 178.78
  episode_reward_min: 61.0
  episodes_this_iter: 2
  episodes_total: 297
  experiment_id: 325b24caee6c4209bf8cf01af4f33e4d
  hostname: gpu048
  info:
    apply_time_ms: 3.089
    dispatch_time_ms: 10.291
    learner:
      cur_lr: 0.0013402864569798112
      grad_gnorm: 15.844531059265137
      policy_entropy: 2.856858015060425
      policy_loss: -3.0628457069396973
      var_gnorm: 29.808908462524414
      vf_explained_var: -0.3389478921890259
      vf_loss: 1.3055193424224854
    num_steps_sampled: 298000
    num_steps_trained: 298000
    wait_time_ms: 26.29
  iterations_since_restore: 164
  node_ip: 172.17.8.48
  num_metric_batches_dropped: 0
  pid: 20453
  policy_reward_mean: {}
  time_since_restore: 1396.189192533493
  time_this_iter_s: 8.21595311164856
  time_total_s: 1396.189192533493
  timestamp: 1593995384
  timesteps_since_restore: 298000
  timesteps_this_iter: 2000
  timesteps_total: 298000
  training_iteration: 164
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=20453], 1396 s, 164 iter, 298000 ts, 179 rew

agent-1: 77.0
Sum Reward: 77.0
Avg Reward: 77.0
Min Reward: 77.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
agent-1: 72.0
Sum Reward: 72.0
Avg Reward: 72.0
Min Reward: 72.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-29-53
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 383.0
  episode_reward_mean: 173.06
  episode_reward_min: 61.0
  episodes_this_iter: 2
  episodes_total: 299
  experiment_id: 325b24caee6c4209bf8cf01af4f33e4d
  hostname: gpu048
  info:
    apply_time_ms: 4.12
    dispatch_time_ms: 31.524
    learner:
      cur_lr: 0.0013401531614363194
      grad_gnorm: 8.287363052368164
      policy_entropy: 1.0899416208267212
      policy_loss: -0.06813637912273407
      var_gnorm: 29.8056583404541
      vf_explained_var: 0.0
      vf_loss: 0.44955021142959595
    num_steps_sampled: 300000
    num_steps_trained: 300000
    wait_time_ms: 19.995
  iterations_since_restore: 165
  node_ip: 172.17.8.48
  num_metric_batches_dropped: 0
  pid: 20453
  policy_reward_mean: {}
  time_since_restore: 1404.7799232006073
  time_this_iter_s: 8.590730667114258
  time_total_s: 1404.7799232006073
  timestamp: 1593995393
  timesteps_since_restore: 300000
  timesteps_this_iter: 2000
  timesteps_total: 300000
  training_iteration: 165
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 29.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=20453], 1404 s, 165 iter, 300000 ts, 173 rew

agent-1: 77.0
Sum Reward: 77.0
Avg Reward: 77.0
Min Reward: 77.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-29-59
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 383.0
  episode_reward_mean: 170.13
  episode_reward_min: 61.0
  episodes_this_iter: 1
  episodes_total: 300
  experiment_id: 325b24caee6c4209bf8cf01af4f33e4d
  hostname: gpu048
  info:
    apply_time_ms: 4.311
    dispatch_time_ms: 36.397
    learner:
      cur_lr: 0.0013400199823081493
      grad_gnorm: 6.971467018127441
      policy_entropy: 1.551328420639038
      policy_loss: -0.09513191878795624
      var_gnorm: 29.80221939086914
      vf_explained_var: 0.0
      vf_loss: 0.33046457171440125
    num_steps_sampled: 301000
    num_steps_trained: 301000
    wait_time_ms: 13.573
  iterations_since_restore: 166
  node_ip: 172.17.8.48
  num_metric_batches_dropped: 0
  pid: 20453
  policy_reward_mean: {}
  time_since_restore: 1411.3933560848236
  time_this_iter_s: 6.613432884216309
  time_total_s: 1411.3933560848236
  timestamp: 1593995399
  timesteps_since_restore: 301000
  timesteps_this_iter: 1000
  timesteps_total: 301000
  training_iteration: 166
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 29.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=20453], 1411 s, 166 iter, 301000 ts, 170 rew

agent-1: 39.0
Sum Reward: 39.0
Avg Reward: 39.0
Min Reward: 39.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-30-05
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 383.0
  episode_reward_mean: 166.76
  episode_reward_min: 39.0
  episodes_this_iter: 1
  episodes_total: 301
  experiment_id: 325b24caee6c4209bf8cf01af4f33e4d
  hostname: gpu048
  info:
    apply_time_ms: 3.42
    dispatch_time_ms: 31.028
    learner:
      cur_lr: 0.0013399533927440643
      grad_gnorm: 24.149112701416016
      policy_entropy: 1.9782538414001465
      policy_loss: 2.990388870239258
      var_gnorm: 29.799957275390625
      vf_explained_var: -0.46995484828948975
      vf_loss: 2.8989272117614746
    num_steps_sampled: 302000
    num_steps_trained: 302000
    wait_time_ms: 26.498
  iterations_since_restore: 167
  node_ip: 172.17.8.48
  num_metric_batches_dropped: 0
  pid: 20453
  policy_reward_mean: {}
  time_since_restore: 1417.0600006580353
  time_this_iter_s: 5.66664457321167
  time_total_s: 1417.0600006580353
  timestamp: 1593995405
  timesteps_since_restore: 302000
  timesteps_this_iter: 1000
  timesteps_total: 302000
  training_iteration: 167
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 29.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=20453], 1417 s, 167 iter, 302000 ts, 167 rew

agent-1: 66.0
Sum Reward: 66.0
Avg Reward: 66.0
Min Reward: 66.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-30-11
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 366.0
  episode_reward_mean: 163.59
  episode_reward_min: 39.0
  episodes_this_iter: 1
  episodes_total: 302
  experiment_id: 325b24caee6c4209bf8cf01af4f33e4d
  hostname: gpu048
  info:
    apply_time_ms: 3.429
    dispatch_time_ms: 42.348
    learner:
      cur_lr: 0.0013398868031799793
      grad_gnorm: 16.868972778320312
      policy_entropy: 3.8083605766296387
      policy_loss: 0.7994914650917053
      var_gnorm: 29.800384521484375
      vf_explained_var: 0.0
      vf_loss: 1.5217671394348145
    num_steps_sampled: 303000
    num_steps_trained: 303000
    wait_time_ms: 12.211
  iterations_since_restore: 168
  node_ip: 172.17.8.48
  num_metric_batches_dropped: 0
  pid: 20453
  policy_reward_mean: {}
  time_since_restore: 1422.815571308136
  time_this_iter_s: 5.755570650100708
  time_total_s: 1422.815571308136
  timestamp: 1593995411
  timesteps_since_restore: 303000
  timesteps_this_iter: 1000
  timesteps_total: 303000
  training_iteration: 168
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 29.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=20453], 1422 s, 168 iter, 303000 ts, 164 rew

agent-1: 66.0
Sum Reward: 66.0
Avg Reward: 66.0
Min Reward: 66.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-30-17
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 364.0
  episode_reward_mean: 160.59
  episode_reward_min: 39.0
  episodes_this_iter: 1
  episodes_total: 303
  experiment_id: 325b24caee6c4209bf8cf01af4f33e4d
  hostname: gpu048
  info:
    apply_time_ms: 3.166
    dispatch_time_ms: 38.562
    learner:
      cur_lr: 0.0013398202136158943
      grad_gnorm: 25.668970108032227
      policy_entropy: 2.464264154434204
      policy_loss: -2.7315056324005127
      var_gnorm: 29.806697845458984
      vf_explained_var: -1.0
      vf_loss: 3.2921595573425293
    num_steps_sampled: 304000
    num_steps_trained: 304000
    wait_time_ms: 25.073
  iterations_since_restore: 169
  node_ip: 172.17.8.48
  num_metric_batches_dropped: 0
  pid: 20453
  policy_reward_mean: {}
  time_since_restore: 1429.063437461853
  time_this_iter_s: 6.247866153717041
  time_total_s: 1429.063437461853
  timestamp: 1593995417
  timesteps_since_restore: 304000
  timesteps_this_iter: 1000
  timesteps_total: 304000
  training_iteration: 169
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 29.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=20453], 1429 s, 169 iter, 304000 ts, 161 rew

agent-1: 124.0
Sum Reward: 124.0
Avg Reward: 124.0
Min Reward: 124.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-30-24
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 364.0
  episode_reward_mean: 158.23
  episode_reward_min: 39.0
  episodes_this_iter: 1
  episodes_total: 304
  experiment_id: 325b24caee6c4209bf8cf01af4f33e4d
  hostname: gpu048
  info:
    apply_time_ms: 2.723
    dispatch_time_ms: 53.899
    learner:
      cur_lr: 0.0013397536240518093
      grad_gnorm: 11.365737915039062
      policy_entropy: 1.7471152544021606
      policy_loss: -0.09838062524795532
      var_gnorm: 29.805728912353516
      vf_explained_var: 0.0
      vf_loss: 0.9694996476173401
    num_steps_sampled: 305000
    num_steps_trained: 305000
    wait_time_ms: 30.159
  iterations_since_restore: 170
  node_ip: 172.17.8.48
  num_metric_batches_dropped: 0
  pid: 20453
  policy_reward_mean: {}
  time_since_restore: 1435.767438173294
  time_this_iter_s: 6.70400071144104
  time_total_s: 1435.767438173294
  timestamp: 1593995424
  timesteps_since_restore: 305000
  timesteps_this_iter: 1000
  timesteps_total: 305000
  training_iteration: 170
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 29.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=20453], 1435 s, 170 iter, 305000 ts, 158 rew

agent-1: 110.0
Sum Reward: 110.0
Avg Reward: 110.0
Min Reward: 110.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-30-31
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 364.0
  episode_reward_mean: 155.76
  episode_reward_min: 39.0
  episodes_this_iter: 1
  episodes_total: 305
  experiment_id: 325b24caee6c4209bf8cf01af4f33e4d
  hostname: gpu048
  info:
    apply_time_ms: 2.647
    dispatch_time_ms: 60.766
    learner:
      cur_lr: 0.0013396870344877243
      grad_gnorm: 14.442577362060547
      policy_entropy: 3.5404129028320312
      policy_loss: -0.7689561247825623
      var_gnorm: 29.8070068359375
      vf_explained_var: -1.0
      vf_loss: 1.5742262601852417
    num_steps_sampled: 306000
    num_steps_trained: 306000
    wait_time_ms: 29.137
  iterations_since_restore: 171
  node_ip: 172.17.8.48
  num_metric_batches_dropped: 0
  pid: 20453
  policy_reward_mean: {}
  time_since_restore: 1442.9644212722778
  time_this_iter_s: 7.196983098983765
  time_total_s: 1442.9644212722778
  timestamp: 1593995431
  timesteps_since_restore: 306000
  timesteps_this_iter: 1000
  timesteps_total: 306000
  training_iteration: 171
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 29.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=20453], 1442 s, 171 iter, 306000 ts, 156 rew

agent-1: 98.0
Sum Reward: 98.0
Avg Reward: 98.0
Min Reward: 98.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-30-38
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 359.0
  episode_reward_mean: 153.1
  episode_reward_min: 39.0
  episodes_this_iter: 1
  episodes_total: 306
  experiment_id: 325b24caee6c4209bf8cf01af4f33e4d
  hostname: gpu048
  info:
    apply_time_ms: 2.427
    dispatch_time_ms: 29.774
    learner:
      cur_lr: 0.0013396204449236393
      grad_gnorm: 14.109787940979004
      policy_entropy: 1.355738878250122
      policy_loss: -0.12597471475601196
      var_gnorm: 29.81330108642578
      vf_explained_var: 0.0
      vf_loss: 1.2116141319274902
    num_steps_sampled: 307000
    num_steps_trained: 307000
    wait_time_ms: 22.385
  iterations_since_restore: 172
  node_ip: 172.17.8.48
  num_metric_batches_dropped: 0
  pid: 20453
  policy_reward_mean: {}
  time_since_restore: 1449.9154682159424
  time_this_iter_s: 6.951046943664551
  time_total_s: 1449.9154682159424
  timestamp: 1593995438
  timesteps_since_restore: 307000
  timesteps_this_iter: 1000
  timesteps_total: 307000
  training_iteration: 172
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 29.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=20453], 1449 s, 172 iter, 307000 ts, 153 rew

agent-1: 105.0
Sum Reward: 105.0
Avg Reward: 105.0
Min Reward: 105.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-30-45
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 359.0
  episode_reward_mean: 150.69
  episode_reward_min: 39.0
  episodes_this_iter: 1
  episodes_total: 307
  experiment_id: 325b24caee6c4209bf8cf01af4f33e4d
  hostname: gpu048
  info:
    apply_time_ms: 3.289
    dispatch_time_ms: 35.838
    learner:
      cur_lr: 0.0013395538553595543
      grad_gnorm: 16.3465518951416
      policy_entropy: 2.0940372943878174
      policy_loss: -1.0080634355545044
      var_gnorm: 29.806255340576172
      vf_explained_var: 0.0
      vf_loss: 3.8545706272125244
    num_steps_sampled: 308000
    num_steps_trained: 308000
    wait_time_ms: 22.817
  iterations_since_restore: 173
  node_ip: 172.17.8.48
  num_metric_batches_dropped: 0
  pid: 20453
  policy_reward_mean: {}
  time_since_restore: 1456.7520532608032
  time_this_iter_s: 6.83658504486084
  time_total_s: 1456.7520532608032
  timestamp: 1593995445
  timesteps_since_restore: 308000
  timesteps_this_iter: 1000
  timesteps_total: 308000
  training_iteration: 173
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 29.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=20453], 1456 s, 173 iter, 308000 ts, 151 rew

agent-1: 107.0
Sum Reward: 107.0
Avg Reward: 107.0
Min Reward: 107.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
agent-1: 88.0
Sum Reward: 88.0
Avg Reward: 88.0
Min Reward: 88.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-30-54
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 359.0
  episode_reward_mean: 146.34
  episode_reward_min: 39.0
  episodes_this_iter: 2
  episodes_total: 309
  experiment_id: 325b24caee6c4209bf8cf01af4f33e4d
  hostname: gpu048
  info:
    apply_time_ms: 3.341
    dispatch_time_ms: 8.53
    learner:
      cur_lr: 0.0013394871493801475
      grad_gnorm: 40.0
      policy_entropy: 2.8042492866516113
      policy_loss: 2.0876169204711914
      var_gnorm: 29.811721801757812
      vf_explained_var: -5.257129669189453e-05
      vf_loss: 34.71746063232422
    num_steps_sampled: 310000
    num_steps_trained: 310000
    wait_time_ms: 32.799
  iterations_since_restore: 174
  node_ip: 172.17.8.48
  num_metric_batches_dropped: 0
  pid: 20453
  policy_reward_mean: {}
  time_since_restore: 1465.4415476322174
  time_this_iter_s: 8.689494371414185
  time_total_s: 1465.4415476322174
  timestamp: 1593995454
  timesteps_since_restore: 310000
  timesteps_this_iter: 2000
  timesteps_total: 310000
  training_iteration: 174
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 29.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=20453], 1465 s, 174 iter, 310000 ts, 146 rew

agent-1: 100.0
Sum Reward: 100.0
Avg Reward: 100.0
Min Reward: 100.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
agent-1: 85.0
Sum Reward: 85.0
Avg Reward: 85.0
Min Reward: 85.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-31-02
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 359.0
  episode_reward_mean: 144.16
  episode_reward_min: 39.0
  episodes_this_iter: 2
  episodes_total: 311
  experiment_id: 325b24caee6c4209bf8cf01af4f33e4d
  hostname: gpu048
  info:
    apply_time_ms: 3.333
    dispatch_time_ms: 9.868
    learner:
      cur_lr: 0.0013393539702519774
      grad_gnorm: 6.157575607299805
      policy_entropy: 2.081686496734619
      policy_loss: 0.08571659028530121
      var_gnorm: 29.802574157714844
      vf_explained_var: 5.4836273193359375e-06
      vf_loss: 1.5644761323928833
    num_steps_sampled: 312000
    num_steps_trained: 312000
    wait_time_ms: 29.765
  iterations_since_restore: 175
  node_ip: 172.17.8.48
  num_metric_batches_dropped: 0
  pid: 20453
  policy_reward_mean: {}
  time_since_restore: 1473.6721665859222
  time_this_iter_s: 8.230618953704834
  time_total_s: 1473.6721665859222
  timestamp: 1593995462
  timesteps_since_restore: 312000
  timesteps_this_iter: 2000
  timesteps_total: 312000
  training_iteration: 175
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 29.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=20453], 1473 s, 175 iter, 312000 ts, 144 rew

agent-1: 93.0
Sum Reward: 93.0
Avg Reward: 93.0
Min Reward: 93.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
agent-1: 83.0
Sum Reward: 83.0
Avg Reward: 83.0
Min Reward: 83.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-31-10
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 359.0
  episode_reward_mean: 140.74
  episode_reward_min: 39.0
  episodes_this_iter: 2
  episodes_total: 313
  experiment_id: 325b24caee6c4209bf8cf01af4f33e4d
  hostname: gpu048
  info:
    apply_time_ms: 2.689
    dispatch_time_ms: 7.085
    learner:
      cur_lr: 0.0013392207911238074
      grad_gnorm: 40.0
      policy_entropy: 1.565327763557434
      policy_loss: 1.0675781965255737
      var_gnorm: 29.793628692626953
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 49.2856559753418
    num_steps_sampled: 314000
    num_steps_trained: 314000
    wait_time_ms: 32.718
  iterations_since_restore: 176
  node_ip: 172.17.8.48
  num_metric_batches_dropped: 0
  pid: 20453
  policy_reward_mean: {}
  time_since_restore: 1481.9307618141174
  time_this_iter_s: 8.25859522819519
  time_total_s: 1481.9307618141174
  timestamp: 1593995470
  timesteps_since_restore: 314000
  timesteps_this_iter: 2000
  timesteps_total: 314000
  training_iteration: 176
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 29.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=20453], 1481 s, 176 iter, 314000 ts, 141 rew

agent-1: 79.0
Sum Reward: 79.0
Avg Reward: 79.0
Min Reward: 79.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
agent-1: 86.0
Sum Reward: 86.0
Avg Reward: 86.0
Min Reward: 86.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-31-19
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 359.0
  episode_reward_mean: 136.65
  episode_reward_min: 39.0
  episodes_this_iter: 2
  episodes_total: 315
  experiment_id: 325b24caee6c4209bf8cf01af4f33e4d
  hostname: gpu048
  info:
    apply_time_ms: 2.88
    dispatch_time_ms: 7.178
    learner:
      cur_lr: 0.0013390876119956374
      grad_gnorm: 4.259933948516846
      policy_entropy: 2.8603949546813965
      policy_loss: 0.13888564705848694
      var_gnorm: 29.79637336730957
      vf_explained_var: 0.41282594203948975
      vf_loss: 0.18660946190357208
    num_steps_sampled: 316000
    num_steps_trained: 316000
    wait_time_ms: 28.922
  iterations_since_restore: 177
  node_ip: 172.17.8.48
  num_metric_batches_dropped: 0
  pid: 20453
  policy_reward_mean: {}
  time_since_restore: 1490.2073094844818
  time_this_iter_s: 8.27654767036438
  time_total_s: 1490.2073094844818
  timestamp: 1593995479
  timesteps_since_restore: 316000
  timesteps_this_iter: 2000
  timesteps_total: 316000
  training_iteration: 177
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 29.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=20453], 1490 s, 177 iter, 316000 ts, 137 rew

agent-1: 88.0
Sum Reward: 88.0
Avg Reward: 88.0
Min Reward: 88.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
agent-1: 90.0
Sum Reward: 90.0
Avg Reward: 90.0
Min Reward: 90.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-31-27
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 359.0
  episode_reward_mean: 132.24
  episode_reward_min: 39.0
  episodes_this_iter: 2
  episodes_total: 317
  experiment_id: 325b24caee6c4209bf8cf01af4f33e4d
  hostname: gpu048
  info:
    apply_time_ms: 4.283
    dispatch_time_ms: 7.374
    learner:
      cur_lr: 0.0013389544328674674
      grad_gnorm: 17.022972106933594
      policy_entropy: 4.7413411140441895
      policy_loss: 3.0854601860046387
      var_gnorm: 29.79805564880371
      vf_explained_var: -0.11392641067504883
      vf_loss: 1.6700834035873413
    num_steps_sampled: 318000
    num_steps_trained: 318000
    wait_time_ms: 28.309
  iterations_since_restore: 178
  node_ip: 172.17.8.48
  num_metric_batches_dropped: 0
  pid: 20453
  policy_reward_mean: {}
  time_since_restore: 1498.5038058757782
  time_this_iter_s: 8.296496391296387
  time_total_s: 1498.5038058757782
  timestamp: 1593995487
  timesteps_since_restore: 318000
  timesteps_this_iter: 2000
  timesteps_total: 318000
  training_iteration: 178
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 29.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=20453], 1498 s, 178 iter, 318000 ts, 132 rew

agent-1: 122.0
Sum Reward: 122.0
Avg Reward: 122.0
Min Reward: 122.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
agent-1: 121.0
Sum Reward: 121.0
Avg Reward: 121.0
Min Reward: 121.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-31-36
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 359.0
  episode_reward_mean: 129.66
  episode_reward_min: 39.0
  episodes_this_iter: 2
  episodes_total: 319
  experiment_id: 325b24caee6c4209bf8cf01af4f33e4d
  hostname: gpu048
  info:
    apply_time_ms: 4.08
    dispatch_time_ms: 8.335
    learner:
      cur_lr: 0.0013388212537392974
      grad_gnorm: 14.28978157043457
      policy_entropy: 0.9115365743637085
      policy_loss: -0.08076443523168564
      var_gnorm: 29.809993743896484
      vf_explained_var: 0.0
      vf_loss: 1.2762922048568726
    num_steps_sampled: 320000
    num_steps_trained: 320000
    wait_time_ms: 26.408
  iterations_since_restore: 179
  node_ip: 172.17.8.48
  num_metric_batches_dropped: 0
  pid: 20453
  policy_reward_mean: {}
  time_since_restore: 1507.0755641460419
  time_this_iter_s: 8.571758270263672
  time_total_s: 1507.0755641460419
  timestamp: 1593995496
  timesteps_since_restore: 320000
  timesteps_this_iter: 2000
  timesteps_total: 320000
  training_iteration: 179
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 29.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=20453], 1507 s, 179 iter, 320000 ts, 130 rew

agent-1: 123.0
Sum Reward: 123.0
Avg Reward: 123.0
Min Reward: 123.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
agent-1: 18.0
Sum Reward: 18.0
Avg Reward: 18.0
Min Reward: 18.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-31-44
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 359.0
  episode_reward_mean: 126.61
  episode_reward_min: 18.0
  episodes_this_iter: 2
  episodes_total: 321
  experiment_id: 325b24caee6c4209bf8cf01af4f33e4d
  hostname: gpu048
  info:
    apply_time_ms: 3.325
    dispatch_time_ms: 7.351
    learner:
      cur_lr: 0.0013386879581958055
      grad_gnorm: 10.158320426940918
      policy_entropy: 0.6014645099639893
      policy_loss: -0.03180117532610893
      var_gnorm: 29.793399810791016
      vf_explained_var: 0.0
      vf_loss: 0.6460974216461182
    num_steps_sampled: 322000
    num_steps_trained: 322000
    wait_time_ms: 30.819
  iterations_since_restore: 180
  node_ip: 172.17.8.48
  num_metric_batches_dropped: 0
  pid: 20453
  policy_reward_mean: {}
  time_since_restore: 1515.1998834609985
  time_this_iter_s: 8.124319314956665
  time_total_s: 1515.1998834609985
  timestamp: 1593995504
  timesteps_since_restore: 322000
  timesteps_this_iter: 2000
  timesteps_total: 322000
  training_iteration: 180
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 29.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=20453], 1515 s, 180 iter, 322000 ts, 127 rew

agent-1: 58.0
Sum Reward: 58.0
Avg Reward: 58.0
Min Reward: 58.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
agent-1: 81.0
Sum Reward: 81.0
Avg Reward: 81.0
Min Reward: 81.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-31-52
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 292.0
  episode_reward_mean: 120.92
  episode_reward_min: 18.0
  episodes_this_iter: 2
  episodes_total: 323
  experiment_id: 325b24caee6c4209bf8cf01af4f33e4d
  hostname: gpu048
  info:
    apply_time_ms: 2.533
    dispatch_time_ms: 7.336
    learner:
      cur_lr: 0.0013385547790676355
      grad_gnorm: 6.955258369445801
      policy_entropy: 0.5549115538597107
      policy_loss: -0.02143903635442257
      var_gnorm: 29.782798767089844
      vf_explained_var: 0.0
      vf_loss: 0.30289292335510254
    num_steps_sampled: 324000
    num_steps_trained: 324000
    wait_time_ms: 31.616
  iterations_since_restore: 181
  node_ip: 172.17.8.48
  num_metric_batches_dropped: 0
  pid: 20453
  policy_reward_mean: {}
  time_since_restore: 1523.4394948482513
  time_this_iter_s: 8.239611387252808
  time_total_s: 1523.4394948482513
  timestamp: 1593995512
  timesteps_since_restore: 324000
  timesteps_this_iter: 2000
  timesteps_total: 324000
  training_iteration: 181
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 29.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=20453], 1523 s, 181 iter, 324000 ts, 121 rew

agent-1: 34.0
Sum Reward: 34.0
Avg Reward: 34.0
Min Reward: 34.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
agent-1: 27.0
Sum Reward: 27.0
Avg Reward: 27.0
Min Reward: 27.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-32-00
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 276.0
  episode_reward_mean: 116.84
  episode_reward_min: 18.0
  episodes_this_iter: 2
  episodes_total: 325
  experiment_id: 325b24caee6c4209bf8cf01af4f33e4d
  hostname: gpu048
  info:
    apply_time_ms: 2.717
    dispatch_time_ms: 8.868
    learner:
      cur_lr: 0.0013384215999394655
      grad_gnorm: 7.162240982055664
      policy_entropy: 1.3146687746047974
      policy_loss: -0.06483953446149826
      var_gnorm: 29.91914939880371
      vf_explained_var: 0.0
      vf_loss: 0.3193545937538147
    num_steps_sampled: 326000
    num_steps_trained: 326000
    wait_time_ms: 29.139
  iterations_since_restore: 182
  node_ip: 172.17.8.48
  num_metric_batches_dropped: 0
  pid: 20453
  policy_reward_mean: {}
  time_since_restore: 1531.5492215156555
  time_this_iter_s: 8.109726667404175
  time_total_s: 1531.5492215156555
  timestamp: 1593995520
  timesteps_since_restore: 326000
  timesteps_this_iter: 2000
  timesteps_total: 326000
  training_iteration: 182
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 29.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=20453], 1531 s, 182 iter, 326000 ts, 117 rew

agent-1: 93.0
Sum Reward: 93.0
Avg Reward: 93.0
Min Reward: 93.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
agent-1: 141.0
Sum Reward: 141.0
Avg Reward: 141.0
Min Reward: 141.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-32-08
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 276.0
  episode_reward_mean: 116.02
  episode_reward_min: 18.0
  episodes_this_iter: 2
  episodes_total: 327
  experiment_id: 325b24caee6c4209bf8cf01af4f33e4d
  hostname: gpu048
  info:
    apply_time_ms: 2.799
    dispatch_time_ms: 8.159
    learner:
      cur_lr: 0.0013382884208112955
      grad_gnorm: 10.79960823059082
      policy_entropy: 4.396220684051514
      policy_loss: 1.8071547746658325
      var_gnorm: 29.943572998046875
      vf_explained_var: 0.1175805926322937
      vf_loss: 0.9352000951766968
    num_steps_sampled: 328000
    num_steps_trained: 328000
    wait_time_ms: 34.122
  iterations_since_restore: 183
  node_ip: 172.17.8.48
  num_metric_batches_dropped: 0
  pid: 20453
  policy_reward_mean: {}
  time_since_restore: 1539.8510529994965
  time_this_iter_s: 8.301831483840942
  time_total_s: 1539.8510529994965
  timestamp: 1593995528
  timesteps_since_restore: 328000
  timesteps_this_iter: 2000
  timesteps_total: 328000
  training_iteration: 183
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 29.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=20453], 1539 s, 183 iter, 328000 ts, 116 rew

agent-1: 135.0
Sum Reward: 135.0
Avg Reward: 135.0
Min Reward: 135.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
agent-1: 164.0
Sum Reward: 164.0
Avg Reward: 164.0
Min Reward: 164.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-32-17
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 276.0
  episode_reward_mean: 114.32
  episode_reward_min: 18.0
  episodes_this_iter: 2
  episodes_total: 329
  experiment_id: 325b24caee6c4209bf8cf01af4f33e4d
  hostname: gpu048
  info:
    apply_time_ms: 2.6
    dispatch_time_ms: 7.773
    learner:
      cur_lr: 0.0013381552416831255
      grad_gnorm: 1.6372445821762085
      policy_entropy: 2.1503207683563232
      policy_loss: -0.6413779258728027
      var_gnorm: 29.9708194732666
      vf_explained_var: 0.006820201873779297
      vf_loss: 0.39719387888908386
    num_steps_sampled: 330000
    num_steps_trained: 330000
    wait_time_ms: 30.41
  iterations_since_restore: 184
  node_ip: 172.17.8.48
  num_metric_batches_dropped: 0
  pid: 20453
  policy_reward_mean: {}
  time_since_restore: 1548.1881947517395
  time_this_iter_s: 8.337141752243042
  time_total_s: 1548.1881947517395
  timestamp: 1593995537
  timesteps_since_restore: 330000
  timesteps_this_iter: 2000
  timesteps_total: 330000
  training_iteration: 184
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 29.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=20453], 1548 s, 184 iter, 330000 ts, 114 rew

agent-1: 127.0
Sum Reward: 127.0
Avg Reward: 127.0
Min Reward: 127.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
agent-1: 134.0
Sum Reward: 134.0
Avg Reward: 134.0
Min Reward: 134.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-32-25
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 259.0
  episode_reward_mean: 111.46
  episode_reward_min: 18.0
  episodes_this_iter: 2
  episodes_total: 331
  experiment_id: 325b24caee6c4209bf8cf01af4f33e4d
  hostname: gpu048
  info:
    apply_time_ms: 3.258
    dispatch_time_ms: 8.526
    learner:
      cur_lr: 0.0013380219461396337
      grad_gnorm: 8.920964241027832
      policy_entropy: 2.6495985984802246
      policy_loss: 2.3712947368621826
      var_gnorm: 29.96316146850586
      vf_explained_var: 0.0
      vf_loss: 1.9377249479293823
    num_steps_sampled: 332000
    num_steps_trained: 332000
    wait_time_ms: 27.737
  iterations_since_restore: 185
  node_ip: 172.17.8.48
  num_metric_batches_dropped: 0
  pid: 20453
  policy_reward_mean: {}
  time_since_restore: 1556.4057796001434
  time_this_iter_s: 8.21758484840393
  time_total_s: 1556.4057796001434
  timestamp: 1593995545
  timesteps_since_restore: 332000
  timesteps_this_iter: 2000
  timesteps_total: 332000
  training_iteration: 185
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 29.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=20453], 1556 s, 185 iter, 332000 ts, 111 rew

agent-1: 135.0
Sum Reward: 135.0
Avg Reward: 135.0
Min Reward: 135.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
agent-1: 146.0
Sum Reward: 146.0
Avg Reward: 146.0
Min Reward: 146.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-32-33
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 246.0
  episode_reward_mean: 109.75
  episode_reward_min: 18.0
  episodes_this_iter: 2
  episodes_total: 333
  experiment_id: 325b24caee6c4209bf8cf01af4f33e4d
  hostname: gpu048
  info:
    apply_time_ms: 4.139
    dispatch_time_ms: 8.91
    learner:
      cur_lr: 0.0013378887670114636
      grad_gnorm: 40.0
      policy_entropy: 1.975296139717102
      policy_loss: 2.955430746078491
      var_gnorm: 29.953880310058594
      vf_explained_var: 0.005138814449310303
      vf_loss: 30.453144073486328
    num_steps_sampled: 334000
    num_steps_trained: 334000
    wait_time_ms: 27.192
  iterations_since_restore: 186
  node_ip: 172.17.8.48
  num_metric_batches_dropped: 0
  pid: 20453
  policy_reward_mean: {}
  time_since_restore: 1564.7468299865723
  time_this_iter_s: 8.341050386428833
  time_total_s: 1564.7468299865723
  timestamp: 1593995553
  timesteps_since_restore: 334000
  timesteps_this_iter: 2000
  timesteps_total: 334000
  training_iteration: 186
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 29.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=20453], 1564 s, 186 iter, 334000 ts, 110 rew

agent-1: 84.0
Sum Reward: 84.0
Avg Reward: 84.0
Min Reward: 84.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
agent-1: 124.0
Sum Reward: 124.0
Avg Reward: 124.0
Min Reward: 124.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-32-42
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 246.0
  episode_reward_mean: 108.34
  episode_reward_min: 18.0
  episodes_this_iter: 2
  episodes_total: 335
  experiment_id: 325b24caee6c4209bf8cf01af4f33e4d
  hostname: gpu048
  info:
    apply_time_ms: 2.988
    dispatch_time_ms: 9.835
    learner:
      cur_lr: 0.0013377555878832936
      grad_gnorm: 35.742435455322266
      policy_entropy: 5.181912422180176
      policy_loss: 6.895375728607178
      var_gnorm: 30.144006729125977
      vf_explained_var: 0.0
      vf_loss: 7.443863391876221
    num_steps_sampled: 336000
    num_steps_trained: 336000
    wait_time_ms: 28.568
  iterations_since_restore: 187
  node_ip: 172.17.8.48
  num_metric_batches_dropped: 0
  pid: 20453
  policy_reward_mean: {}
  time_since_restore: 1572.9496467113495
  time_this_iter_s: 8.202816724777222
  time_total_s: 1572.9496467113495
  timestamp: 1593995562
  timesteps_since_restore: 336000
  timesteps_this_iter: 2000
  timesteps_total: 336000
  training_iteration: 187
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 29.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=20453], 1572 s, 187 iter, 336000 ts, 108 rew

agent-1: 129.0
Sum Reward: 129.0
Avg Reward: 129.0
Min Reward: 129.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
agent-1: 152.0
Sum Reward: 152.0
Avg Reward: 152.0
Min Reward: 152.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-32-50
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 183.0
  episode_reward_mean: 107.14
  episode_reward_min: 18.0
  episodes_this_iter: 2
  episodes_total: 337
  experiment_id: 325b24caee6c4209bf8cf01af4f33e4d
  hostname: gpu048
  info:
    apply_time_ms: 3.8
    dispatch_time_ms: 9.022
    learner:
      cur_lr: 0.0013376224087551236
      grad_gnorm: 18.1366024017334
      policy_entropy: 6.244074821472168
      policy_loss: -3.117809534072876
      var_gnorm: 30.15837287902832
      vf_explained_var: 0.0
      vf_loss: 2.0177791118621826
    num_steps_sampled: 338000
    num_steps_trained: 338000
    wait_time_ms: 28.996
  iterations_since_restore: 188
  node_ip: 172.17.8.48
  num_metric_batches_dropped: 0
  pid: 20453
  policy_reward_mean: {}
  time_since_restore: 1581.385243654251
  time_this_iter_s: 8.435596942901611
  time_total_s: 1581.385243654251
  timestamp: 1593995570
  timesteps_since_restore: 338000
  timesteps_this_iter: 2000
  timesteps_total: 338000
  training_iteration: 188
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 29.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=20453], 1581 s, 188 iter, 338000 ts, 107 rew

agent-1: 131.0
Sum Reward: 131.0
Avg Reward: 131.0
Min Reward: 131.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
agent-1: 129.0
Sum Reward: 129.0
Avg Reward: 129.0
Min Reward: 129.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-32-59
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 183.0
  episode_reward_mean: 107.05
  episode_reward_min: 18.0
  episodes_this_iter: 2
  episodes_total: 339
  experiment_id: 325b24caee6c4209bf8cf01af4f33e4d
  hostname: gpu048
  info:
    apply_time_ms: 2.649
    dispatch_time_ms: 8.664
    learner:
      cur_lr: 0.0013374892296269536
      grad_gnorm: 17.72500991821289
      policy_entropy: 3.2361104488372803
      policy_loss: -0.5030443668365479
      var_gnorm: 30.152164459228516
      vf_explained_var: 0.0
      vf_loss: 1.911747932434082
    num_steps_sampled: 340000
    num_steps_trained: 340000
    wait_time_ms: 27.166
  iterations_since_restore: 189
  node_ip: 172.17.8.48
  num_metric_batches_dropped: 0
  pid: 20453
  policy_reward_mean: {}
  time_since_restore: 1589.7783739566803
  time_this_iter_s: 8.3931303024292
  time_total_s: 1589.7783739566803
  timestamp: 1593995579
  timesteps_since_restore: 340000
  timesteps_this_iter: 2000
  timesteps_total: 340000
  training_iteration: 189
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 29.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=20453], 1589 s, 189 iter, 340000 ts, 107 rew

agent-1: 127.0
Sum Reward: 127.0
Avg Reward: 127.0
Min Reward: 127.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
agent-1: 110.0
Sum Reward: 110.0
Avg Reward: 110.0
Min Reward: 110.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-33-07
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 183.0
  episode_reward_mean: 107.08
  episode_reward_min: 18.0
  episodes_this_iter: 2
  episodes_total: 341
  experiment_id: 325b24caee6c4209bf8cf01af4f33e4d
  hostname: gpu048
  info:
    apply_time_ms: 3.487
    dispatch_time_ms: 7.742
    learner:
      cur_lr: 0.0013373560504987836
      grad_gnorm: 19.15911102294922
      policy_entropy: 3.8496649265289307
      policy_loss: -0.7067428827285767
      var_gnorm: 30.158342361450195
      vf_explained_var: 0.0
      vf_loss: 2.144132614135742
    num_steps_sampled: 342000
    num_steps_trained: 342000
    wait_time_ms: 33.607
  iterations_since_restore: 190
  node_ip: 172.17.8.48
  num_metric_batches_dropped: 0
  pid: 20453
  policy_reward_mean: {}
  time_since_restore: 1598.1125853061676
  time_this_iter_s: 8.334211349487305
  time_total_s: 1598.1125853061676
  timestamp: 1593995587
  timesteps_since_restore: 342000
  timesteps_this_iter: 2000
  timesteps_total: 342000
  training_iteration: 190
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 29.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=20453], 1598 s, 190 iter, 342000 ts, 107 rew

agent-1: 134.0
Sum Reward: 134.0
Avg Reward: 134.0
Min Reward: 134.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
agent-1: 168.0
Sum Reward: 168.0
Avg Reward: 168.0
Min Reward: 168.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-33-15
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 183.0
  episode_reward_mean: 107.73
  episode_reward_min: 18.0
  episodes_this_iter: 2
  episodes_total: 343
  experiment_id: 325b24caee6c4209bf8cf01af4f33e4d
  hostname: gpu048
  info:
    apply_time_ms: 2.696
    dispatch_time_ms: 8.498
    learner:
      cur_lr: 0.0013372227549552917
      grad_gnorm: 17.103036880493164
      policy_entropy: 4.054104804992676
      policy_loss: 3.0349271297454834
      var_gnorm: 30.14856719970703
      vf_explained_var: 0.0
      vf_loss: 2.437446117401123
    num_steps_sampled: 344000
    num_steps_trained: 344000
    wait_time_ms: 30.224
  iterations_since_restore: 191
  node_ip: 172.17.8.48
  num_metric_batches_dropped: 0
  pid: 20453
  policy_reward_mean: {}
  time_since_restore: 1606.4998784065247
  time_this_iter_s: 8.387293100357056
  time_total_s: 1606.4998784065247
  timestamp: 1593995595
  timesteps_since_restore: 344000
  timesteps_this_iter: 2000
  timesteps_total: 344000
  training_iteration: 191
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 29.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=20453], 1606 s, 191 iter, 344000 ts, 108 rew

agent-1: 89.0
Sum Reward: 89.0
Avg Reward: 89.0
Min Reward: 89.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
agent-1: 110.0
Sum Reward: 110.0
Avg Reward: 110.0
Min Reward: 110.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-33-24
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 183.0
  episode_reward_mean: 107.08
  episode_reward_min: 18.0
  episodes_this_iter: 2
  episodes_total: 345
  experiment_id: 325b24caee6c4209bf8cf01af4f33e4d
  hostname: gpu048
  info:
    apply_time_ms: 3.524
    dispatch_time_ms: 7.18
    learner:
      cur_lr: 0.0013370895758271217
      grad_gnorm: 25.156831741333008
      policy_entropy: 1.8026795387268066
      policy_loss: 0.3310266435146332
      var_gnorm: 30.155929565429688
      vf_explained_var: 1.1920928955078125e-07
      vf_loss: 4.665502548217773
    num_steps_sampled: 346000
    num_steps_trained: 346000
    wait_time_ms: 30.622
  iterations_since_restore: 192
  node_ip: 172.17.8.48
  num_metric_batches_dropped: 0
  pid: 20453
  policy_reward_mean: {}
  time_since_restore: 1614.8762893676758
  time_this_iter_s: 8.376410961151123
  time_total_s: 1614.8762893676758
  timestamp: 1593995604
  timesteps_since_restore: 346000
  timesteps_this_iter: 2000
  timesteps_total: 346000
  training_iteration: 192
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 29.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=20453], 1614 s, 192 iter, 346000 ts, 107 rew

agent-1: 114.0
Sum Reward: 114.0
Avg Reward: 114.0
Min Reward: 114.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
agent-1: 98.0
Sum Reward: 98.0
Avg Reward: 98.0
Min Reward: 98.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-33-32
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 183.0
  episode_reward_mean: 106.92
  episode_reward_min: 18.0
  episodes_this_iter: 2
  episodes_total: 347
  experiment_id: 325b24caee6c4209bf8cf01af4f33e4d
  hostname: gpu048
  info:
    apply_time_ms: 3.918
    dispatch_time_ms: 6.516
    learner:
      cur_lr: 0.0013369563966989517
      grad_gnorm: 35.62348556518555
      policy_entropy: 2.6935555934906006
      policy_loss: 0.4035038352012634
      var_gnorm: 30.138845443725586
      vf_explained_var: 0.0
      vf_loss: 9.712865829467773
    num_steps_sampled: 348000
    num_steps_trained: 348000
    wait_time_ms: 32.987
  iterations_since_restore: 193
  node_ip: 172.17.8.48
  num_metric_batches_dropped: 0
  pid: 20453
  policy_reward_mean: {}
  time_since_restore: 1623.201189994812
  time_this_iter_s: 8.32490062713623
  time_total_s: 1623.201189994812
  timestamp: 1593995612
  timesteps_since_restore: 348000
  timesteps_this_iter: 2000
  timesteps_total: 348000
  training_iteration: 193
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 29.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=20453], 1623 s, 193 iter, 348000 ts, 107 rew

agent-1: 79.0
Sum Reward: 79.0
Avg Reward: 79.0
Min Reward: 79.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
agent-1: 131.0
Sum Reward: 131.0
Avg Reward: 131.0
Min Reward: 131.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-33-41
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 183.0
  episode_reward_mean: 106.79
  episode_reward_min: 18.0
  episodes_this_iter: 2
  episodes_total: 349
  experiment_id: 325b24caee6c4209bf8cf01af4f33e4d
  hostname: gpu048
  info:
    apply_time_ms: 4.814
    dispatch_time_ms: 10.751
    learner:
      cur_lr: 0.0013368232175707817
      grad_gnorm: 40.000003814697266
      policy_entropy: 5.4917216300964355
      policy_loss: 2.965416193008423
      var_gnorm: 30.14284896850586
      vf_explained_var: 0.0
      vf_loss: 13.753490447998047
    num_steps_sampled: 350000
    num_steps_trained: 350000
    wait_time_ms: 26.822
  iterations_since_restore: 194
  node_ip: 172.17.8.48
  num_metric_batches_dropped: 0
  pid: 20453
  policy_reward_mean: {}
  time_since_restore: 1631.573617696762
  time_this_iter_s: 8.372427701950073
  time_total_s: 1631.573617696762
  timestamp: 1593995621
  timesteps_since_restore: 350000
  timesteps_this_iter: 2000
  timesteps_total: 350000
  training_iteration: 194
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 29.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=20453], 1631 s, 194 iter, 350000 ts, 107 rew

agent-1: 138.0
Sum Reward: 138.0
Avg Reward: 138.0
Min Reward: 138.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
agent-1: 148.0
Sum Reward: 148.0
Avg Reward: 148.0
Min Reward: 148.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-33-49
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 183.0
  episode_reward_mean: 107.97
  episode_reward_min: 18.0
  episodes_this_iter: 2
  episodes_total: 351
  experiment_id: 325b24caee6c4209bf8cf01af4f33e4d
  hostname: gpu048
  info:
    apply_time_ms: 3.202
    dispatch_time_ms: 8.988
    learner:
      cur_lr: 0.0013366900384426117
      grad_gnorm: 40.000003814697266
      policy_entropy: 2.189911365509033
      policy_loss: 9.743754386901855
      var_gnorm: 30.16524314880371
      vf_explained_var: 0.0
      vf_loss: 27.395309448242188
    num_steps_sampled: 352000
    num_steps_trained: 352000
    wait_time_ms: 26.935
  iterations_since_restore: 195
  node_ip: 172.17.8.48
  num_metric_batches_dropped: 0
  pid: 20453
  policy_reward_mean: {}
  time_since_restore: 1640.00230550766
  time_this_iter_s: 8.428687810897827
  time_total_s: 1640.00230550766
  timestamp: 1593995629
  timesteps_since_restore: 352000
  timesteps_this_iter: 2000
  timesteps_total: 352000
  training_iteration: 195
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 29.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=20453], 1640 s, 195 iter, 352000 ts, 108 rew

agent-1: 131.0
Sum Reward: 131.0
Avg Reward: 131.0
Min Reward: 131.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
agent-1: 133.0
Sum Reward: 133.0
Avg Reward: 133.0
Min Reward: 133.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-34-08
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 183.0
  episode_reward_mean: 108.67
  episode_reward_min: 18.0
  episodes_this_iter: 2
  episodes_total: 353
  experiment_id: 325b24caee6c4209bf8cf01af4f33e4d
  hostname: gpu048
  info:
    apply_time_ms: 3.737
    dispatch_time_ms: 48.633
    learner:
      cur_lr: 0.0013365567428991199
      grad_gnorm: 1.200008749961853
      policy_entropy: 4.732068061828613
      policy_loss: 0.3171348571777344
      var_gnorm: 30.168500900268555
      vf_explained_var: 0.0
      vf_loss: 1.2628586292266846
    num_steps_sampled: 354000
    num_steps_trained: 354000
    wait_time_ms: 22.44
  iterations_since_restore: 196
  node_ip: 172.17.8.48
  num_metric_batches_dropped: 0
  pid: 20453
  policy_reward_mean: {}
  time_since_restore: 1659.4441666603088
  time_this_iter_s: 19.441861152648926
  time_total_s: 1659.4441666603088
  timestamp: 1593995648
  timesteps_since_restore: 354000
  timesteps_this_iter: 2000
  timesteps_total: 354000
  training_iteration: 196
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 29.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=20453], 1659 s, 196 iter, 354000 ts, 109 rew

agent-1: 159.0
Sum Reward: 159.0
Avg Reward: 159.0
Min Reward: 159.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-34-15
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 183.0
  episode_reward_mean: 109.46
  episode_reward_min: 18.0
  episodes_this_iter: 1
  episodes_total: 354
  experiment_id: 325b24caee6c4209bf8cf01af4f33e4d
  hostname: gpu048
  info:
    apply_time_ms: 3.362
    dispatch_time_ms: 32.443
    learner:
      cur_lr: 0.0013364235637709498
      grad_gnorm: 12.466001510620117
      policy_entropy: 1.4356147050857544
      policy_loss: -0.17393574118614197
      var_gnorm: 30.15915298461914
      vf_explained_var: 0.0
      vf_loss: 1.195860743522644
    num_steps_sampled: 355000
    num_steps_trained: 355000
    wait_time_ms: 37.872
  iterations_since_restore: 197
  node_ip: 172.17.8.48
  num_metric_batches_dropped: 0
  pid: 20453
  policy_reward_mean: {}
  time_since_restore: 1666.1683340072632
  time_this_iter_s: 6.724167346954346
  time_total_s: 1666.1683340072632
  timestamp: 1593995655
  timesteps_since_restore: 355000
  timesteps_this_iter: 1000
  timesteps_total: 355000
  training_iteration: 197
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 29.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=20453], 1666 s, 197 iter, 355000 ts, 109 rew

agent-1: 83.0
Sum Reward: 83.0
Avg Reward: 83.0
Min Reward: 83.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-34-22
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 183.0
  episode_reward_mean: 108.74
  episode_reward_min: 18.0
  episodes_this_iter: 1
  episodes_total: 355
  experiment_id: 325b24caee6c4209bf8cf01af4f33e4d
  hostname: gpu048
  info:
    apply_time_ms: 2.975
    dispatch_time_ms: 30.44
    learner:
      cur_lr: 0.0013363569742068648
      grad_gnorm: 29.374269485473633
      policy_entropy: 3.933553695678711
      policy_loss: -0.717150866985321
      var_gnorm: 30.15969467163086
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 4.6067423820495605
    num_steps_sampled: 356000
    num_steps_trained: 356000
    wait_time_ms: 16.397
  iterations_since_restore: 198
  node_ip: 172.17.8.48
  num_metric_batches_dropped: 0
  pid: 20453
  policy_reward_mean: {}
  time_since_restore: 1672.9132182598114
  time_this_iter_s: 6.744884252548218
  time_total_s: 1672.9132182598114
  timestamp: 1593995662
  timesteps_since_restore: 356000
  timesteps_this_iter: 1000
  timesteps_total: 356000
  training_iteration: 198
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 29.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=20453], 1672 s, 198 iter, 356000 ts, 109 rew

agent-1: 110.0
Sum Reward: 110.0
Avg Reward: 110.0
Min Reward: 110.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-34-29
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 183.0
  episode_reward_mean: 108.66
  episode_reward_min: 18.0
  episodes_this_iter: 1
  episodes_total: 356
  experiment_id: 325b24caee6c4209bf8cf01af4f33e4d
  hostname: gpu048
  info:
    apply_time_ms: 3.002
    dispatch_time_ms: 34.895
    learner:
      cur_lr: 0.0013362903846427798
      grad_gnorm: 15.041788101196289
      policy_entropy: 2.3800251483917236
      policy_loss: -2.4269888401031494
      var_gnorm: 30.160297393798828
      vf_explained_var: 0.0
      vf_loss: 1.4867223501205444
    num_steps_sampled: 357000
    num_steps_trained: 357000
    wait_time_ms: 34.678
  iterations_since_restore: 199
  node_ip: 172.17.8.48
  num_metric_batches_dropped: 0
  pid: 20453
  policy_reward_mean: {}
  time_since_restore: 1680.2059481143951
  time_this_iter_s: 7.29272985458374
  time_total_s: 1680.2059481143951
  timestamp: 1593995669
  timesteps_since_restore: 357000
  timesteps_this_iter: 1000
  timesteps_total: 357000
  training_iteration: 199
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 29.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=20453], 1680 s, 199 iter, 357000 ts, 109 rew

agent-1: 166.0
Sum Reward: 166.0
Avg Reward: 166.0
Min Reward: 166.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-34-36
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 183.0
  episode_reward_mean: 109.3
  episode_reward_min: 18.0
  episodes_this_iter: 1
  episodes_total: 357
  experiment_id: 325b24caee6c4209bf8cf01af4f33e4d
  hostname: gpu048
  info:
    apply_time_ms: 3.15
    dispatch_time_ms: 27.412
    learner:
      cur_lr: 0.0013362237950786948
      grad_gnorm: 40.0
      policy_entropy: 5.246360778808594
      policy_loss: 3.891763687133789
      var_gnorm: 30.162315368652344
      vf_explained_var: 0.0
      vf_loss: 29.410076141357422
    num_steps_sampled: 358000
    num_steps_trained: 358000
    wait_time_ms: 5.931
  iterations_since_restore: 200
  node_ip: 172.17.8.48
  num_metric_batches_dropped: 0
  pid: 20453
  policy_reward_mean: {}
  time_since_restore: 1687.2634930610657
  time_this_iter_s: 7.057544946670532
  time_total_s: 1687.2634930610657
  timestamp: 1593995676
  timesteps_since_restore: 358000
  timesteps_this_iter: 1000
  timesteps_total: 358000
  training_iteration: 200
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 29.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=20453], 1687 s, 200 iter, 358000 ts, 109 rew

agent-1: 96.0
Sum Reward: 96.0
Avg Reward: 96.0
Min Reward: 96.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
agent-1: 148.0
Sum Reward: 148.0
Avg Reward: 148.0
Min Reward: 148.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-34-45
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 183.0
  episode_reward_mean: 109.84
  episode_reward_min: 18.0
  episodes_this_iter: 2
  episodes_total: 359
  experiment_id: 325b24caee6c4209bf8cf01af4f33e4d
  hostname: gpu048
  info:
    apply_time_ms: 2.741
    dispatch_time_ms: 7.961
    learner:
      cur_lr: 0.0013361572055146098
      grad_gnorm: 21.5242977142334
      policy_entropy: 4.898235321044922
      policy_loss: -6.584540367126465
      var_gnorm: 30.17262840270996
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 2.280805826187134
    num_steps_sampled: 360000
    num_steps_trained: 360000
    wait_time_ms: 31.456
  iterations_since_restore: 201
  node_ip: 172.17.8.48
  num_metric_batches_dropped: 0
  pid: 20453
  policy_reward_mean: {}
  time_since_restore: 1695.5659461021423
  time_this_iter_s: 8.30245304107666
  time_total_s: 1695.5659461021423
  timestamp: 1593995685
  timesteps_since_restore: 360000
  timesteps_this_iter: 2000
  timesteps_total: 360000
  training_iteration: 201
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 29.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=20453], 1695 s, 201 iter, 360000 ts, 110 rew

agent-1: 158.0
Sum Reward: 158.0
Avg Reward: 158.0
Min Reward: 158.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
agent-1: 101.0
Sum Reward: 101.0
Avg Reward: 101.0
Min Reward: 101.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-34-53
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 183.0
  episode_reward_mean: 109.51
  episode_reward_min: 18.0
  episodes_this_iter: 2
  episodes_total: 361
  experiment_id: 325b24caee6c4209bf8cf01af4f33e4d
  hostname: gpu048
  info:
    apply_time_ms: 2.912
    dispatch_time_ms: 6.994
    learner:
      cur_lr: 0.0013360240263864398
      grad_gnorm: 19.82476806640625
      policy_entropy: 3.678898572921753
      policy_loss: -6.286722660064697
      var_gnorm: 30.15924072265625
      vf_explained_var: 0.0
      vf_loss: 1.8044761419296265
    num_steps_sampled: 362000
    num_steps_trained: 362000
    wait_time_ms: 28.955
  iterations_since_restore: 202
  node_ip: 172.17.8.48
  num_metric_batches_dropped: 0
  pid: 20453
  policy_reward_mean: {}
  time_since_restore: 1703.9256281852722
  time_this_iter_s: 8.359682083129883
  time_total_s: 1703.9256281852722
  timestamp: 1593995693
  timesteps_since_restore: 362000
  timesteps_this_iter: 2000
  timesteps_total: 362000
  training_iteration: 202
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 29.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=20453], 1703 s, 202 iter, 362000 ts, 110 rew

agent-1: 102.0
Sum Reward: 102.0
Avg Reward: 102.0
Min Reward: 102.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
agent-1: 125.0
Sum Reward: 125.0
Avg Reward: 125.0
Min Reward: 125.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-35-02
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 183.0
  episode_reward_mean: 109.31
  episode_reward_min: 18.0
  episodes_this_iter: 2
  episodes_total: 363
  experiment_id: 325b24caee6c4209bf8cf01af4f33e4d
  hostname: gpu048
  info:
    apply_time_ms: 3.311
    dispatch_time_ms: 6.313
    learner:
      cur_lr: 0.0013358908472582698
      grad_gnorm: 1.1558552980422974
      policy_entropy: 3.615553140640259
      policy_loss: 0.03792090341448784
      var_gnorm: 30.163488388061523
      vf_explained_var: 0.0
      vf_loss: 0.41104382276535034
    num_steps_sampled: 364000
    num_steps_trained: 364000
    wait_time_ms: 33.91
  iterations_since_restore: 203
  node_ip: 172.17.8.48
  num_metric_batches_dropped: 0
  pid: 20453
  policy_reward_mean: {}
  time_since_restore: 1712.2873828411102
  time_this_iter_s: 8.361754655838013
  time_total_s: 1712.2873828411102
  timestamp: 1593995702
  timesteps_since_restore: 364000
  timesteps_this_iter: 2000
  timesteps_total: 364000
  training_iteration: 203
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 29.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=20453], 1712 s, 203 iter, 364000 ts, 109 rew

agent-1: 106.0
Sum Reward: 106.0
Avg Reward: 106.0
Min Reward: 106.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
agent-1: 109.0
Sum Reward: 109.0
Avg Reward: 109.0
Min Reward: 109.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-35-12
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 183.0
  episode_reward_mean: 109.47
  episode_reward_min: 18.0
  episodes_this_iter: 2
  episodes_total: 365
  experiment_id: 325b24caee6c4209bf8cf01af4f33e4d
  hostname: gpu048
  info:
    apply_time_ms: 3.117
    dispatch_time_ms: 30.064
    learner:
      cur_lr: 0.001335757551714778
      grad_gnorm: 20.850696563720703
      policy_entropy: 4.614418983459473
      policy_loss: -0.7975760102272034
      var_gnorm: 30.155200958251953
      vf_explained_var: 0.0
      vf_loss: 2.3437068462371826
    num_steps_sampled: 366000
    num_steps_trained: 366000
    wait_time_ms: 31.527
  iterations_since_restore: 204
  node_ip: 172.17.8.48
  num_metric_batches_dropped: 0
  pid: 20453
  policy_reward_mean: {}
  time_since_restore: 1722.7167620658875
  time_this_iter_s: 10.429379224777222
  time_total_s: 1722.7167620658875
  timestamp: 1593995712
  timesteps_since_restore: 366000
  timesteps_this_iter: 2000
  timesteps_total: 366000
  training_iteration: 204
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 29.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=20453], 1722 s, 204 iter, 366000 ts, 109 rew

agent-1: 144.0
Sum Reward: 144.0
Avg Reward: 144.0
Min Reward: 144.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-35-18
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 183.0
  episode_reward_mean: 109.97
  episode_reward_min: 18.0
  episodes_this_iter: 1
  episodes_total: 366
  experiment_id: 325b24caee6c4209bf8cf01af4f33e4d
  hostname: gpu048
  info:
    apply_time_ms: 3.03
    dispatch_time_ms: 34.648
    learner:
      cur_lr: 0.001335624372586608
      grad_gnorm: 40.0
      policy_entropy: 1.786180853843689
      policy_loss: 1.1137617826461792
      var_gnorm: 30.15704345703125
      vf_explained_var: 0.0
      vf_loss: 50.517486572265625
    num_steps_sampled: 367000
    num_steps_trained: 367000
    wait_time_ms: 23.051
  iterations_since_restore: 205
  node_ip: 172.17.8.48
  num_metric_batches_dropped: 0
  pid: 20453
  policy_reward_mean: {}
  time_since_restore: 1728.584388256073
  time_this_iter_s: 5.867626190185547
  time_total_s: 1728.584388256073
  timestamp: 1593995718
  timesteps_since_restore: 367000
  timesteps_this_iter: 1000
  timesteps_total: 367000
  training_iteration: 205
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 29.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=20453], 1728 s, 205 iter, 367000 ts, 110 rew

agent-1: 94.0
Sum Reward: 94.0
Avg Reward: 94.0
Min Reward: 94.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-35-24
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 183.0
  episode_reward_mean: 109.63
  episode_reward_min: 18.0
  episodes_this_iter: 1
  episodes_total: 367
  experiment_id: 325b24caee6c4209bf8cf01af4f33e4d
  hostname: gpu048
  info:
    apply_time_ms: 3.386
    dispatch_time_ms: 47.067
    learner:
      cur_lr: 0.001335557783022523
      grad_gnorm: 17.664840698242188
      policy_entropy: 5.004778861999512
      policy_loss: -1.3637527227401733
      var_gnorm: 30.151485443115234
      vf_explained_var: 0.0
      vf_loss: 1.773258924484253
    num_steps_sampled: 368000
    num_steps_trained: 368000
    wait_time_ms: 13.68
  iterations_since_restore: 206
  node_ip: 172.17.8.48
  num_metric_batches_dropped: 0
  pid: 20453
  policy_reward_mean: {}
  time_since_restore: 1734.8645482063293
  time_this_iter_s: 6.280159950256348
  time_total_s: 1734.8645482063293
  timestamp: 1593995724
  timesteps_since_restore: 368000
  timesteps_this_iter: 1000
  timesteps_total: 368000
  training_iteration: 206
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 29.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=20453], 1734 s, 206 iter, 368000 ts, 110 rew

agent-1: 103.0
Sum Reward: 103.0
Avg Reward: 103.0
Min Reward: 103.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-35-30
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 183.0
  episode_reward_mean: 109.57
  episode_reward_min: 18.0
  episodes_this_iter: 1
  episodes_total: 368
  experiment_id: 325b24caee6c4209bf8cf01af4f33e4d
  hostname: gpu048
  info:
    apply_time_ms: 3.04
    dispatch_time_ms: 32.223
    learner:
      cur_lr: 0.001335491193458438
      grad_gnorm: 20.752304077148438
      policy_entropy: 2.690887451171875
      policy_loss: 0.6664832830429077
      var_gnorm: 30.166606903076172
      vf_explained_var: 1.7881393432617188e-07
      vf_loss: 7.829893112182617
    num_steps_sampled: 369000
    num_steps_trained: 369000
    wait_time_ms: 27.808
  iterations_since_restore: 207
  node_ip: 172.17.8.48
  num_metric_batches_dropped: 0
  pid: 20453
  policy_reward_mean: {}
  time_since_restore: 1741.070434808731
  time_this_iter_s: 6.205886602401733
  time_total_s: 1741.070434808731
  timestamp: 1593995730
  timesteps_since_restore: 369000
  timesteps_this_iter: 1000
  timesteps_total: 369000
  training_iteration: 207
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 29.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=20453], 1741 s, 207 iter, 369000 ts, 110 rew

agent-1: 157.0
Sum Reward: 157.0
Avg Reward: 157.0
Min Reward: 157.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-35-36
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 183.0
  episode_reward_mean: 109.8
  episode_reward_min: 18.0
  episodes_this_iter: 1
  episodes_total: 369
  experiment_id: 325b24caee6c4209bf8cf01af4f33e4d
  hostname: gpu048
  info:
    apply_time_ms: 3.335
    dispatch_time_ms: 17.062
    learner:
      cur_lr: 0.001335424603894353
      grad_gnorm: 14.50581169128418
      policy_entropy: 3.4271745681762695
      policy_loss: -1.354521632194519
      var_gnorm: 30.167348861694336
      vf_explained_var: 0.0
      vf_loss: 1.461936354637146
    num_steps_sampled: 370000
    num_steps_trained: 370000
    wait_time_ms: 8.717
  iterations_since_restore: 208
  node_ip: 172.17.8.48
  num_metric_batches_dropped: 0
  pid: 20453
  policy_reward_mean: {}
  time_since_restore: 1747.129174232483
  time_this_iter_s: 6.058739423751831
  time_total_s: 1747.129174232483
  timestamp: 1593995736
  timesteps_since_restore: 370000
  timesteps_this_iter: 1000
  timesteps_total: 370000
  training_iteration: 208
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 29.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=20453], 1747 s, 208 iter, 370000 ts, 110 rew

agent-1: 178.0
Sum Reward: 178.0
Avg Reward: 178.0
Min Reward: 178.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
agent-1: 112.0
Sum Reward: 112.0
Avg Reward: 112.0
Min Reward: 112.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-35-45
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 183.0
  episode_reward_mean: 110.05
  episode_reward_min: 18.0
  episodes_this_iter: 2
  episodes_total: 371
  experiment_id: 325b24caee6c4209bf8cf01af4f33e4d
  hostname: gpu048
  info:
    apply_time_ms: 3.767
    dispatch_time_ms: 8.55
    learner:
      cur_lr: 0.001335358014330268
      grad_gnorm: 40.0
      policy_entropy: 4.889615535736084
      policy_loss: 10.929947853088379
      var_gnorm: 30.1738338470459
      vf_explained_var: 0.0
      vf_loss: 21.217073440551758
    num_steps_sampled: 372000
    num_steps_trained: 372000
    wait_time_ms: 30.225
  iterations_since_restore: 209
  node_ip: 172.17.8.48
  num_metric_batches_dropped: 0
  pid: 20453
  policy_reward_mean: {}
  time_since_restore: 1755.588523387909
  time_this_iter_s: 8.459349155426025
  time_total_s: 1755.588523387909
  timestamp: 1593995745
  timesteps_since_restore: 372000
  timesteps_this_iter: 2000
  timesteps_total: 372000
  training_iteration: 209
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 29.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=20453], 1755 s, 209 iter, 372000 ts, 110 rew

agent-1: 152.0
Sum Reward: 152.0
Avg Reward: 152.0
Min Reward: 152.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
agent-1: 157.0
Sum Reward: 157.0
Avg Reward: 157.0
Min Reward: 157.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-35-54
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 178.0
  episode_reward_mean: 110.07
  episode_reward_min: 18.0
  episodes_this_iter: 2
  episodes_total: 373
  experiment_id: 325b24caee6c4209bf8cf01af4f33e4d
  hostname: gpu048
  info:
    apply_time_ms: 2.819
    dispatch_time_ms: 8.093
    learner:
      cur_lr: 0.001335224835202098
      grad_gnorm: 20.30198097229004
      policy_entropy: 3.8094699382781982
      policy_loss: -1.0298235416412354
      var_gnorm: 30.18246841430664
      vf_explained_var: 1.1920928955078125e-07
      vf_loss: 2.454479455947876
    num_steps_sampled: 374000
    num_steps_trained: 374000
    wait_time_ms: 31.728
  iterations_since_restore: 210
  node_ip: 172.17.8.48
  num_metric_batches_dropped: 0
  pid: 20453
  policy_reward_mean: {}
  time_since_restore: 1764.099259853363
  time_this_iter_s: 8.510736465454102
  time_total_s: 1764.099259853363
  timestamp: 1593995754
  timesteps_since_restore: 374000
  timesteps_this_iter: 2000
  timesteps_total: 374000
  training_iteration: 210
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 29.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=20453], 1764 s, 210 iter, 374000 ts, 110 rew

agent-1: 117.0
Sum Reward: 117.0
Avg Reward: 117.0
Min Reward: 117.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
agent-1: 135.0
Sum Reward: 135.0
Avg Reward: 135.0
Min Reward: 135.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-36-02
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 178.0
  episode_reward_mean: 109.79
  episode_reward_min: 18.0
  episodes_this_iter: 2
  episodes_total: 375
  experiment_id: 325b24caee6c4209bf8cf01af4f33e4d
  hostname: gpu048
  info:
    apply_time_ms: 3.097
    dispatch_time_ms: 11.018
    learner:
      cur_lr: 0.0013350916560739279
      grad_gnorm: 10.898272514343262
      policy_entropy: 2.942558526992798
      policy_loss: 2.557651996612549
      var_gnorm: 30.178789138793945
      vf_explained_var: 1.1920928955078125e-07
      vf_loss: 2.5785434246063232
    num_steps_sampled: 376000
    num_steps_trained: 376000
    wait_time_ms: 27.649
  iterations_since_restore: 211
  node_ip: 172.17.8.48
  num_metric_batches_dropped: 0
  pid: 20453
  policy_reward_mean: {}
  time_since_restore: 1772.5154733657837
  time_this_iter_s: 8.416213512420654
  time_total_s: 1772.5154733657837
  timestamp: 1593995762
  timesteps_since_restore: 376000
  timesteps_this_iter: 2000
  timesteps_total: 376000
  training_iteration: 211
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 29.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=20453], 1772 s, 211 iter, 376000 ts, 110 rew

agent-1: 127.0
Sum Reward: 127.0
Avg Reward: 127.0
Min Reward: 127.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
agent-1: 126.0
Sum Reward: 126.0
Avg Reward: 126.0
Min Reward: 126.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-36-10
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 178.0
  episode_reward_mean: 109.58
  episode_reward_min: 18.0
  episodes_this_iter: 2
  episodes_total: 377
  experiment_id: 325b24caee6c4209bf8cf01af4f33e4d
  hostname: gpu048
  info:
    apply_time_ms: 3.673
    dispatch_time_ms: 7.44
    learner:
      cur_lr: 0.001334958360530436
      grad_gnorm: 17.73053741455078
      policy_entropy: 5.510054588317871
      policy_loss: -1.2447805404663086
      var_gnorm: 30.172639846801758
      vf_explained_var: 5.960464477539063e-08
      vf_loss: 1.5508698225021362
    num_steps_sampled: 378000
    num_steps_trained: 378000
    wait_time_ms: 30.741
  iterations_since_restore: 212
  node_ip: 172.17.8.48
  num_metric_batches_dropped: 0
  pid: 20453
  policy_reward_mean: {}
  time_since_restore: 1780.8637907505035
  time_this_iter_s: 8.348317384719849
  time_total_s: 1780.8637907505035
  timestamp: 1593995770
  timesteps_since_restore: 378000
  timesteps_this_iter: 2000
  timesteps_total: 378000
  training_iteration: 212
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 29.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=20453], 1780 s, 212 iter, 378000 ts, 110 rew

agent-1: 97.0
Sum Reward: 97.0
Avg Reward: 97.0
Min Reward: 97.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
agent-1: 122.0
Sum Reward: 122.0
Avg Reward: 122.0
Min Reward: 122.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-36-19
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 178.0
  episode_reward_mean: 109.6
  episode_reward_min: 18.0
  episodes_this_iter: 2
  episodes_total: 379
  experiment_id: 325b24caee6c4209bf8cf01af4f33e4d
  hostname: gpu048
  info:
    apply_time_ms: 5.529
    dispatch_time_ms: 7.789
    learner:
      cur_lr: 0.001334825181402266
      grad_gnorm: 8.664148330688477
      policy_entropy: 2.624204158782959
      policy_loss: -0.1977207511663437
      var_gnorm: 30.172330856323242
      vf_explained_var: 0.0
      vf_loss: 0.7765540480613708
    num_steps_sampled: 380000
    num_steps_trained: 380000
    wait_time_ms: 29.284
  iterations_since_restore: 213
  node_ip: 172.17.8.48
  num_metric_batches_dropped: 0
  pid: 20453
  policy_reward_mean: {}
  time_since_restore: 1789.2049307823181
  time_this_iter_s: 8.341140031814575
  time_total_s: 1789.2049307823181
  timestamp: 1593995779
  timesteps_since_restore: 380000
  timesteps_this_iter: 2000
  timesteps_total: 380000
  training_iteration: 213
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 29.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=20453], 1789 s, 213 iter, 380000 ts, 110 rew

agent-1: 128.0
Sum Reward: 128.0
Avg Reward: 128.0
Min Reward: 128.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
agent-1: 136.0
Sum Reward: 136.0
Avg Reward: 136.0
Min Reward: 136.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-36-27
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 178.0
  episode_reward_mean: 109.69
  episode_reward_min: 18.0
  episodes_this_iter: 2
  episodes_total: 381
  experiment_id: 325b24caee6c4209bf8cf01af4f33e4d
  hostname: gpu048
  info:
    apply_time_ms: 3.094
    dispatch_time_ms: 6.192
    learner:
      cur_lr: 0.001334692002274096
      grad_gnorm: 8.465801239013672
      policy_entropy: 3.385507822036743
      policy_loss: -1.587006688117981
      var_gnorm: 30.168899536132812
      vf_explained_var: 0.0
      vf_loss: 0.7342597842216492
    num_steps_sampled: 382000
    num_steps_trained: 382000
    wait_time_ms: 33.046
  iterations_since_restore: 214
  node_ip: 172.17.8.48
  num_metric_batches_dropped: 0
  pid: 20453
  policy_reward_mean: {}
  time_since_restore: 1797.7021234035492
  time_this_iter_s: 8.497192621231079
  time_total_s: 1797.7021234035492
  timestamp: 1593995787
  timesteps_since_restore: 382000
  timesteps_this_iter: 2000
  timesteps_total: 382000
  training_iteration: 214
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 29.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=20453], 1797 s, 214 iter, 382000 ts, 110 rew

agent-1: 109.0
Sum Reward: 109.0
Avg Reward: 109.0
Min Reward: 109.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
agent-1: 164.0
Sum Reward: 164.0
Avg Reward: 164.0
Min Reward: 164.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-36-36
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 178.0
  episode_reward_mean: 109.93
  episode_reward_min: 18.0
  episodes_this_iter: 2
  episodes_total: 383
  experiment_id: 325b24caee6c4209bf8cf01af4f33e4d
  hostname: gpu048
  info:
    apply_time_ms: 3.014
    dispatch_time_ms: 7.916
    learner:
      cur_lr: 0.001334558823145926
      grad_gnorm: 19.18341827392578
      policy_entropy: 4.33327579498291
      policy_loss: -2.358525514602661
      var_gnorm: 30.182754516601562
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 2.3548643589019775
    num_steps_sampled: 384000
    num_steps_trained: 384000
    wait_time_ms: 29.422
  iterations_since_restore: 215
  node_ip: 172.17.8.48
  num_metric_batches_dropped: 0
  pid: 20453
  policy_reward_mean: {}
  time_since_restore: 1806.0938520431519
  time_this_iter_s: 8.391728639602661
  time_total_s: 1806.0938520431519
  timestamp: 1593995796
  timesteps_since_restore: 384000
  timesteps_this_iter: 2000
  timesteps_total: 384000
  training_iteration: 215
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 29.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=20453], 1806 s, 215 iter, 384000 ts, 110 rew

agent-1: 118.0
Sum Reward: 118.0
Avg Reward: 118.0
Min Reward: 118.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
agent-1: 111.0
Sum Reward: 111.0
Avg Reward: 111.0
Min Reward: 111.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-36-44
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 178.0
  episode_reward_mean: 109.51
  episode_reward_min: 18.0
  episodes_this_iter: 2
  episodes_total: 385
  experiment_id: 325b24caee6c4209bf8cf01af4f33e4d
  hostname: gpu048
  info:
    apply_time_ms: 3.299
    dispatch_time_ms: 7.024
    learner:
      cur_lr: 0.001334425644017756
      grad_gnorm: 18.846712112426758
      policy_entropy: 3.280477523803711
      policy_loss: -0.5961559414863586
      var_gnorm: 30.176841735839844
      vf_explained_var: 0.0
      vf_loss: 2.1222050189971924
    num_steps_sampled: 386000
    num_steps_trained: 386000
    wait_time_ms: 31.364
  iterations_since_restore: 216
  node_ip: 172.17.8.48
  num_metric_batches_dropped: 0
  pid: 20453
  policy_reward_mean: {}
  time_since_restore: 1814.3801319599152
  time_this_iter_s: 8.286279916763306
  time_total_s: 1814.3801319599152
  timestamp: 1593995804
  timesteps_since_restore: 386000
  timesteps_this_iter: 2000
  timesteps_total: 386000
  training_iteration: 216
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 29.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=20453], 1814 s, 216 iter, 386000 ts, 110 rew

agent-1: 142.0
Sum Reward: 142.0
Avg Reward: 142.0
Min Reward: 142.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
agent-1: 155.0
Sum Reward: 155.0
Avg Reward: 155.0
Min Reward: 155.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-36-53
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 178.0
  episode_reward_mean: 111.0
  episode_reward_min: 18.0
  episodes_this_iter: 2
  episodes_total: 387
  experiment_id: 325b24caee6c4209bf8cf01af4f33e4d
  hostname: gpu048
  info:
    apply_time_ms: 3.652
    dispatch_time_ms: 9.905
    learner:
      cur_lr: 0.0013342923484742641
      grad_gnorm: 40.0
      policy_entropy: 1.9130020141601562
      policy_loss: 1.1009173393249512
      var_gnorm: 30.17224884033203
      vf_explained_var: 0.0
      vf_loss: 41.85639953613281
    num_steps_sampled: 388000
    num_steps_trained: 388000
    wait_time_ms: 28.974
  iterations_since_restore: 217
  node_ip: 172.17.8.48
  num_metric_batches_dropped: 0
  pid: 20453
  policy_reward_mean: {}
  time_since_restore: 1823.1996734142303
  time_this_iter_s: 8.819541454315186
  time_total_s: 1823.1996734142303
  timestamp: 1593995813
  timesteps_since_restore: 388000
  timesteps_this_iter: 2000
  timesteps_total: 388000
  training_iteration: 217
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 29.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=20453], 1823 s, 217 iter, 388000 ts, 111 rew

agent-1: 75.0
Sum Reward: 75.0
Avg Reward: 75.0
Min Reward: 75.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
agent-1: 145.0
Sum Reward: 145.0
Avg Reward: 145.0
Min Reward: 145.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-37-01
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 178.0
  episode_reward_mean: 111.56
  episode_reward_min: 18.0
  episodes_this_iter: 2
  episodes_total: 389
  experiment_id: 325b24caee6c4209bf8cf01af4f33e4d
  hostname: gpu048
  info:
    apply_time_ms: 3.081
    dispatch_time_ms: 8.348
    learner:
      cur_lr: 0.0013341591693460941
      grad_gnorm: 10.513455390930176
      policy_entropy: 4.450891494750977
      policy_loss: 1.0543749332427979
      var_gnorm: 30.168109893798828
      vf_explained_var: 0.0
      vf_loss: 0.9826830625534058
    num_steps_sampled: 390000
    num_steps_trained: 390000
    wait_time_ms: 28.074
  iterations_since_restore: 218
  node_ip: 172.17.8.48
  num_metric_batches_dropped: 0
  pid: 20453
  policy_reward_mean: {}
  time_since_restore: 1831.5156936645508
  time_this_iter_s: 8.316020250320435
  time_total_s: 1831.5156936645508
  timestamp: 1593995821
  timesteps_since_restore: 390000
  timesteps_this_iter: 2000
  timesteps_total: 390000
  training_iteration: 218
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 29.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=20453], 1831 s, 218 iter, 390000 ts, 112 rew

agent-1: 99.0
Sum Reward: 99.0
Avg Reward: 99.0
Min Reward: 99.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
agent-1: 105.0
Sum Reward: 105.0
Avg Reward: 105.0
Min Reward: 105.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-37-10
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 178.0
  episode_reward_mean: 112.15
  episode_reward_min: 18.0
  episodes_this_iter: 2
  episodes_total: 391
  experiment_id: 325b24caee6c4209bf8cf01af4f33e4d
  hostname: gpu048
  info:
    apply_time_ms: 4.03
    dispatch_time_ms: 7.927
    learner:
      cur_lr: 0.0013340259902179241
      grad_gnorm: 40.0
      policy_entropy: 2.9197072982788086
      policy_loss: 1.6598968505859375
      var_gnorm: 30.161571502685547
      vf_explained_var: 0.0
      vf_loss: 37.3011474609375
    num_steps_sampled: 392000
    num_steps_trained: 392000
    wait_time_ms: 31.328
  iterations_since_restore: 219
  node_ip: 172.17.8.48
  num_metric_batches_dropped: 0
  pid: 20453
  policy_reward_mean: {}
  time_since_restore: 1839.8171281814575
  time_this_iter_s: 8.301434516906738
  time_total_s: 1839.8171281814575
  timestamp: 1593995830
  timesteps_since_restore: 392000
  timesteps_this_iter: 2000
  timesteps_total: 392000
  training_iteration: 219
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 29.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=20453], 1839 s, 219 iter, 392000 ts, 112 rew

agent-1: 110.0
Sum Reward: 110.0
Avg Reward: 110.0
Min Reward: 110.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
agent-1: 118.0
Sum Reward: 118.0
Avg Reward: 118.0
Min Reward: 118.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-37-18
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 178.0
  episode_reward_mean: 112.09
  episode_reward_min: 18.0
  episodes_this_iter: 2
  episodes_total: 393
  experiment_id: 325b24caee6c4209bf8cf01af4f33e4d
  hostname: gpu048
  info:
    apply_time_ms: 2.719
    dispatch_time_ms: 7.254
    learner:
      cur_lr: 0.001333892811089754
      grad_gnorm: 5.424487113952637
      policy_entropy: 3.9060206413269043
      policy_loss: -0.5945562124252319
      var_gnorm: 30.162376403808594
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 3.506809949874878
    num_steps_sampled: 394000
    num_steps_trained: 394000
    wait_time_ms: 33.094
  iterations_since_restore: 220
  node_ip: 172.17.8.48
  num_metric_batches_dropped: 0
  pid: 20453
  policy_reward_mean: {}
  time_since_restore: 1848.1607475280762
  time_this_iter_s: 8.343619346618652
  time_total_s: 1848.1607475280762
  timestamp: 1593995838
  timesteps_since_restore: 394000
  timesteps_this_iter: 2000
  timesteps_total: 394000
  training_iteration: 220
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 29.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=20453], 1848 s, 220 iter, 394000 ts, 112 rew

agent-1: 100.0
Sum Reward: 100.0
Avg Reward: 100.0
Min Reward: 100.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
agent-1: 154.0
Sum Reward: 154.0
Avg Reward: 154.0
Min Reward: 154.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-37-26
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 178.0
  episode_reward_mean: 112.36
  episode_reward_min: 18.0
  episodes_this_iter: 2
  episodes_total: 395
  experiment_id: 325b24caee6c4209bf8cf01af4f33e4d
  hostname: gpu048
  info:
    apply_time_ms: 2.876
    dispatch_time_ms: 8.638
    learner:
      cur_lr: 0.001333759631961584
      grad_gnorm: 9.03510856628418
      policy_entropy: 3.5466527938842773
      policy_loss: -0.297041118144989
      var_gnorm: 30.183185577392578
      vf_explained_var: 1.1920928955078125e-07
      vf_loss: 0.791824221611023
    num_steps_sampled: 396000
    num_steps_trained: 396000
    wait_time_ms: 31.515
  iterations_since_restore: 221
  node_ip: 172.17.8.48
  num_metric_batches_dropped: 0
  pid: 20453
  policy_reward_mean: {}
  time_since_restore: 1856.528512954712
  time_this_iter_s: 8.367765426635742
  time_total_s: 1856.528512954712
  timestamp: 1593995846
  timesteps_since_restore: 396000
  timesteps_this_iter: 2000
  timesteps_total: 396000
  training_iteration: 221
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 29.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=20453], 1856 s, 221 iter, 396000 ts, 112 rew

agent-1: 144.0
Sum Reward: 144.0
Avg Reward: 144.0
Min Reward: 144.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
agent-1: 151.0
Sum Reward: 151.0
Avg Reward: 151.0
Min Reward: 151.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-37-35
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 178.0
  episode_reward_mean: 113.99
  episode_reward_min: 18.0
  episodes_this_iter: 2
  episodes_total: 397
  experiment_id: 325b24caee6c4209bf8cf01af4f33e4d
  hostname: gpu048
  info:
    apply_time_ms: 3.382
    dispatch_time_ms: 7.413
    learner:
      cur_lr: 0.001333626452833414
      grad_gnorm: 16.689424514770508
      policy_entropy: 2.299269199371338
      policy_loss: 0.32217592000961304
      var_gnorm: 30.195907592773438
      vf_explained_var: 0.0
      vf_loss: 1.8248651027679443
    num_steps_sampled: 398000
    num_steps_trained: 398000
    wait_time_ms: 31.568
  iterations_since_restore: 222
  node_ip: 172.17.8.48
  num_metric_batches_dropped: 0
  pid: 20453
  policy_reward_mean: {}
  time_since_restore: 1864.8790392875671
  time_this_iter_s: 8.350526332855225
  time_total_s: 1864.8790392875671
  timestamp: 1593995855
  timesteps_since_restore: 398000
  timesteps_this_iter: 2000
  timesteps_total: 398000
  training_iteration: 222
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 29.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=20453], 1864 s, 222 iter, 398000 ts, 114 rew

agent-1: 130.0
Sum Reward: 130.0
Avg Reward: 130.0
Min Reward: 130.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
agent-1: 103.0
Sum Reward: 103.0
Avg Reward: 103.0
Min Reward: 103.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-37-43
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 178.0
  episode_reward_mean: 114.83
  episode_reward_min: 18.0
  episodes_this_iter: 2
  episodes_total: 399
  experiment_id: 325b24caee6c4209bf8cf01af4f33e4d
  hostname: gpu048
  info:
    apply_time_ms: 3.151
    dispatch_time_ms: 7.808
    learner:
      cur_lr: 0.0013334931572899222
      grad_gnorm: 16.250017166137695
      policy_entropy: 4.966979026794434
      policy_loss: -2.328439474105835
      var_gnorm: 30.170835494995117
      vf_explained_var: 0.0
      vf_loss: 1.6864240169525146
    num_steps_sampled: 400000
    num_steps_trained: 400000
    wait_time_ms: 31.434
  iterations_since_restore: 223
  node_ip: 172.17.8.48
  num_metric_batches_dropped: 0
  pid: 20453
  policy_reward_mean: {}
  time_since_restore: 1873.2490491867065
  time_this_iter_s: 8.370009899139404
  time_total_s: 1873.2490491867065
  timestamp: 1593995863
  timesteps_since_restore: 400000
  timesteps_this_iter: 2000
  timesteps_total: 400000
  training_iteration: 223
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 29.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=20453], 1873 s, 223 iter, 400000 ts, 115 rew

agent-1: 81.0
Sum Reward: 81.0
Avg Reward: 81.0
Min Reward: 81.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
agent-1: 165.0
Sum Reward: 165.0
Avg Reward: 165.0
Min Reward: 165.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-37-51
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 178.0
  episode_reward_mean: 116.13
  episode_reward_min: 18.0
  episodes_this_iter: 2
  episodes_total: 401
  experiment_id: 325b24caee6c4209bf8cf01af4f33e4d
  hostname: gpu048
  info:
    apply_time_ms: 4.937
    dispatch_time_ms: 9.075
    learner:
      cur_lr: 0.0013333599781617522
      grad_gnorm: 19.844680786132812
      policy_entropy: 4.201700687408447
      policy_loss: -4.7796478271484375
      var_gnorm: 30.18470573425293
      vf_explained_var: 0.0
      vf_loss: 1.586882472038269
    num_steps_sampled: 402000
    num_steps_trained: 402000
    wait_time_ms: 26.893
  iterations_since_restore: 224
  node_ip: 172.17.8.48
  num_metric_batches_dropped: 0
  pid: 20453
  policy_reward_mean: {}
  time_since_restore: 1881.5141019821167
  time_this_iter_s: 8.265052795410156
  time_total_s: 1881.5141019821167
  timestamp: 1593995871
  timesteps_since_restore: 402000
  timesteps_this_iter: 2000
  timesteps_total: 402000
  training_iteration: 224
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 29.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=20453], 1881 s, 224 iter, 402000 ts, 116 rew

agent-1: 115.0
Sum Reward: 115.0
Avg Reward: 115.0
Min Reward: 115.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
agent-1: 123.0
Sum Reward: 123.0
Avg Reward: 123.0
Min Reward: 123.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-38-00
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 178.0
  episode_reward_mean: 117.19
  episode_reward_min: 18.0
  episodes_this_iter: 2
  episodes_total: 403
  experiment_id: 325b24caee6c4209bf8cf01af4f33e4d
  hostname: gpu048
  info:
    apply_time_ms: 3.361
    dispatch_time_ms: 9.071
    learner:
      cur_lr: 0.0013332267990335822
      grad_gnorm: 18.059846878051758
      policy_entropy: 1.9490985870361328
      policy_loss: -0.27699151635169983
      var_gnorm: 30.185226440429688
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 2.059224843978882
    num_steps_sampled: 404000
    num_steps_trained: 404000
    wait_time_ms: 26.655
  iterations_since_restore: 225
  node_ip: 172.17.8.48
  num_metric_batches_dropped: 0
  pid: 20453
  policy_reward_mean: {}
  time_since_restore: 1889.825690984726
  time_this_iter_s: 8.311589002609253
  time_total_s: 1889.825690984726
  timestamp: 1593995880
  timesteps_since_restore: 404000
  timesteps_this_iter: 2000
  timesteps_total: 404000
  training_iteration: 225
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 29.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=20453], 1889 s, 225 iter, 404000 ts, 117 rew

agent-1: 133.0
Sum Reward: 133.0
Avg Reward: 133.0
Min Reward: 133.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
agent-1: 136.0
Sum Reward: 136.0
Avg Reward: 136.0
Min Reward: 136.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-38-08
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 178.0
  episode_reward_mean: 117.54
  episode_reward_min: 18.0
  episodes_this_iter: 2
  episodes_total: 405
  experiment_id: 325b24caee6c4209bf8cf01af4f33e4d
  hostname: gpu048
  info:
    apply_time_ms: 2.89
    dispatch_time_ms: 6.075
    learner:
      cur_lr: 0.0013330936199054122
      grad_gnorm: 40.0
      policy_entropy: 2.8458688259124756
      policy_loss: 2.3907949924468994
      var_gnorm: 30.17898941040039
      vf_explained_var: 0.0
      vf_loss: 44.466861724853516
    num_steps_sampled: 406000
    num_steps_trained: 406000
    wait_time_ms: 35.714
  iterations_since_restore: 226
  node_ip: 172.17.8.48
  num_metric_batches_dropped: 0
  pid: 20453
  policy_reward_mean: {}
  time_since_restore: 1898.1629962921143
  time_this_iter_s: 8.337305307388306
  time_total_s: 1898.1629962921143
  timestamp: 1593995888
  timesteps_since_restore: 406000
  timesteps_this_iter: 2000
  timesteps_total: 406000
  training_iteration: 226
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 29.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=20453], 1898 s, 226 iter, 406000 ts, 118 rew

agent-1: 110.0
Sum Reward: 110.0
Avg Reward: 110.0
Min Reward: 110.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
agent-1: 151.0
Sum Reward: 151.0
Avg Reward: 151.0
Min Reward: 151.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-38-17
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 178.0
  episode_reward_mean: 118.12
  episode_reward_min: 18.0
  episodes_this_iter: 2
  episodes_total: 407
  experiment_id: 325b24caee6c4209bf8cf01af4f33e4d
  hostname: gpu048
  info:
    apply_time_ms: 3.53
    dispatch_time_ms: 7.948
    learner:
      cur_lr: 0.0013329604407772422
      grad_gnorm: 6.481782913208008
      policy_entropy: 4.403552532196045
      policy_loss: 1.1329632997512817
      var_gnorm: 30.183015823364258
      vf_explained_var: 0.0
      vf_loss: 0.6281229257583618
    num_steps_sampled: 408000
    num_steps_trained: 408000
    wait_time_ms: 31.14
  iterations_since_restore: 227
  node_ip: 172.17.8.48
  num_metric_batches_dropped: 0
  pid: 20453
  policy_reward_mean: {}
  time_since_restore: 1906.54775929451
  time_this_iter_s: 8.38476300239563
  time_total_s: 1906.54775929451
  timestamp: 1593995897
  timesteps_since_restore: 408000
  timesteps_this_iter: 2000
  timesteps_total: 408000
  training_iteration: 227
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 29.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=20453], 1906 s, 227 iter, 408000 ts, 118 rew

agent-1: 129.0
Sum Reward: 129.0
Avg Reward: 129.0
Min Reward: 129.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
agent-1: 130.0
Sum Reward: 130.0
Avg Reward: 130.0
Min Reward: 130.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-38-25
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 178.0
  episode_reward_mean: 118.76
  episode_reward_min: 18.0
  episodes_this_iter: 2
  episodes_total: 409
  experiment_id: 325b24caee6c4209bf8cf01af4f33e4d
  hostname: gpu048
  info:
    apply_time_ms: 3.103
    dispatch_time_ms: 7.191
    learner:
      cur_lr: 0.0013328271452337503
      grad_gnorm: 4.062382221221924
      policy_entropy: 5.25163459777832
      policy_loss: -0.8573083877563477
      var_gnorm: 30.193647384643555
      vf_explained_var: 0.0
      vf_loss: 0.43741467595100403
    num_steps_sampled: 410000
    num_steps_trained: 410000
    wait_time_ms: 30.551
  iterations_since_restore: 228
  node_ip: 172.17.8.48
  num_metric_batches_dropped: 0
  pid: 20453
  policy_reward_mean: {}
  time_since_restore: 1914.8373520374298
  time_this_iter_s: 8.289592742919922
  time_total_s: 1914.8373520374298
  timestamp: 1593995905
  timesteps_since_restore: 410000
  timesteps_this_iter: 2000
  timesteps_total: 410000
  training_iteration: 228
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 29.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=20453], 1914 s, 228 iter, 410000 ts, 119 rew

agent-1: 136.0
Sum Reward: 136.0
Avg Reward: 136.0
Min Reward: 136.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
agent-1: 168.0
Sum Reward: 168.0
Avg Reward: 168.0
Min Reward: 168.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-38-33
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 178.0
  episode_reward_mean: 119.95
  episode_reward_min: 18.0
  episodes_this_iter: 2
  episodes_total: 411
  experiment_id: 325b24caee6c4209bf8cf01af4f33e4d
  hostname: gpu048
  info:
    apply_time_ms: 2.53
    dispatch_time_ms: 7.215
    learner:
      cur_lr: 0.0013326939661055803
      grad_gnorm: 18.421110153198242
      policy_entropy: 2.578317880630493
      policy_loss: -0.42934390902519226
      var_gnorm: 30.186996459960938
      vf_explained_var: 0.0
      vf_loss: 2.093912124633789
    num_steps_sampled: 412000
    num_steps_trained: 412000
    wait_time_ms: 31.367
  iterations_since_restore: 229
  node_ip: 172.17.8.48
  num_metric_batches_dropped: 0
  pid: 20453
  policy_reward_mean: {}
  time_since_restore: 1923.2156484127045
  time_this_iter_s: 8.378296375274658
  time_total_s: 1923.2156484127045
  timestamp: 1593995913
  timesteps_since_restore: 412000
  timesteps_this_iter: 2000
  timesteps_total: 412000
  training_iteration: 229
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 29.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=20453], 1923 s, 229 iter, 412000 ts, 120 rew

agent-1: 81.0
Sum Reward: 81.0
Avg Reward: 81.0
Min Reward: 81.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
agent-1: 136.0
Sum Reward: 136.0
Avg Reward: 136.0
Min Reward: 136.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-38-42
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 178.0
  episode_reward_mean: 120.36
  episode_reward_min: 18.0
  episodes_this_iter: 2
  episodes_total: 413
  experiment_id: 325b24caee6c4209bf8cf01af4f33e4d
  hostname: gpu048
  info:
    apply_time_ms: 3.626
    dispatch_time_ms: 6.896
    learner:
      cur_lr: 0.0013325607869774103
      grad_gnorm: 40.000003814697266
      policy_entropy: 4.694984436035156
      policy_loss: 7.373281002044678
      var_gnorm: 30.20639419555664
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 20.190807342529297
    num_steps_sampled: 414000
    num_steps_trained: 414000
    wait_time_ms: 32.168
  iterations_since_restore: 230
  node_ip: 172.17.8.48
  num_metric_batches_dropped: 0
  pid: 20453
  policy_reward_mean: {}
  time_since_restore: 1931.5788412094116
  time_this_iter_s: 8.363192796707153
  time_total_s: 1931.5788412094116
  timestamp: 1593995922
  timesteps_since_restore: 414000
  timesteps_this_iter: 2000
  timesteps_total: 414000
  training_iteration: 230
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 29.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=20453], 1931 s, 230 iter, 414000 ts, 120 rew

agent-1: 151.0
Sum Reward: 151.0
Avg Reward: 151.0
Min Reward: 151.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
agent-1: 146.0
Sum Reward: 146.0
Avg Reward: 146.0
Min Reward: 146.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-38-50
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 178.0
  episode_reward_mean: 121.68
  episode_reward_min: 18.0
  episodes_this_iter: 2
  episodes_total: 415
  experiment_id: 325b24caee6c4209bf8cf01af4f33e4d
  hostname: gpu048
  info:
    apply_time_ms: 2.988
    dispatch_time_ms: 6.439
    learner:
      cur_lr: 0.0013324276078492403
      grad_gnorm: 19.524106979370117
      policy_entropy: 3.868046760559082
      policy_loss: -0.8190571665763855
      var_gnorm: 30.193906784057617
      vf_explained_var: 0.0
      vf_loss: 2.15421199798584
    num_steps_sampled: 416000
    num_steps_trained: 416000
    wait_time_ms: 32.435
  iterations_since_restore: 231
  node_ip: 172.17.8.48
  num_metric_batches_dropped: 0
  pid: 20453
  policy_reward_mean: {}
  time_since_restore: 1939.9833319187164
  time_this_iter_s: 8.40449070930481
  time_total_s: 1939.9833319187164
  timestamp: 1593995930
  timesteps_since_restore: 416000
  timesteps_this_iter: 2000
  timesteps_total: 416000
  training_iteration: 231
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 29.3/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=20453], 1939 s, 231 iter, 416000 ts, 122 rew

agent-1: 85.0
Sum Reward: 85.0
Avg Reward: 85.0
Min Reward: 85.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
agent-1: 136.0
Sum Reward: 136.0
Avg Reward: 136.0
Min Reward: 136.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-38-59
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 178.0
  episode_reward_mean: 122.11
  episode_reward_min: 18.0
  episodes_this_iter: 2
  episodes_total: 417
  experiment_id: 325b24caee6c4209bf8cf01af4f33e4d
  hostname: gpu048
  info:
    apply_time_ms: 2.97
    dispatch_time_ms: 9.827
    learner:
      cur_lr: 0.0013322944287210703
      grad_gnorm: 18.344593048095703
      policy_entropy: 2.2720487117767334
      policy_loss: -0.35218948125839233
      var_gnorm: 30.19329261779785
      vf_explained_var: 0.0
      vf_loss: 2.1036152839660645
    num_steps_sampled: 418000
    num_steps_trained: 418000
    wait_time_ms: 32.363
  iterations_since_restore: 232
  node_ip: 172.17.8.48
  num_metric_batches_dropped: 0
  pid: 20453
  policy_reward_mean: {}
  time_since_restore: 1948.6435284614563
  time_this_iter_s: 8.660196542739868
  time_total_s: 1948.6435284614563
  timestamp: 1593995939
  timesteps_since_restore: 418000
  timesteps_this_iter: 2000
  timesteps_total: 418000
  training_iteration: 232
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 29.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=20453], 1948 s, 232 iter, 418000 ts, 122 rew

agent-1: 129.0
Sum Reward: 129.0
Avg Reward: 129.0
Min Reward: 129.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
agent-1: 127.0
Sum Reward: 127.0
Avg Reward: 127.0
Min Reward: 127.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-39-07
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 178.0
  episode_reward_mean: 122.24
  episode_reward_min: 18.0
  episodes_this_iter: 2
  episodes_total: 419
  experiment_id: 325b24caee6c4209bf8cf01af4f33e4d
  hostname: gpu048
  info:
    apply_time_ms: 5.835
    dispatch_time_ms: 10.154
    learner:
      cur_lr: 0.0013321612495929003
      grad_gnorm: 17.052656173706055
      policy_entropy: 2.882509708404541
      policy_loss: -1.6798648834228516
      var_gnorm: 30.186800003051758
      vf_explained_var: 0.0
      vf_loss: 1.867053747177124
    num_steps_sampled: 420000
    num_steps_trained: 420000
    wait_time_ms: 27.006
  iterations_since_restore: 233
  node_ip: 172.17.8.48
  num_metric_batches_dropped: 0
  pid: 20453
  policy_reward_mean: {}
  time_since_restore: 1957.0685184001923
  time_this_iter_s: 8.424989938735962
  time_total_s: 1957.0685184001923
  timestamp: 1593995947
  timesteps_since_restore: 420000
  timesteps_this_iter: 2000
  timesteps_total: 420000
  training_iteration: 233
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 29.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=20453], 1957 s, 233 iter, 420000 ts, 122 rew

agent-1: 101.0
Sum Reward: 101.0
Avg Reward: 101.0
Min Reward: 101.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
agent-1: 108.0
Sum Reward: 108.0
Avg Reward: 108.0
Min Reward: 108.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-39-16
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 178.0
  episode_reward_mean: 122.92
  episode_reward_min: 27.0
  episodes_this_iter: 2
  episodes_total: 421
  experiment_id: 325b24caee6c4209bf8cf01af4f33e4d
  hostname: gpu048
  info:
    apply_time_ms: 2.807
    dispatch_time_ms: 7.365
    learner:
      cur_lr: 0.0013320279540494084
      grad_gnorm: 18.113964080810547
      policy_entropy: 3.529073715209961
      policy_loss: -2.6012980937957764
      var_gnorm: 30.19500732421875
      vf_explained_var: 5.960464477539063e-08
      vf_loss: 2.0675344467163086
    num_steps_sampled: 422000
    num_steps_trained: 422000
    wait_time_ms: 34.455
  iterations_since_restore: 234
  node_ip: 172.17.8.48
  num_metric_batches_dropped: 0
  pid: 20453
  policy_reward_mean: {}
  time_since_restore: 1965.5382862091064
  time_this_iter_s: 8.469767808914185
  time_total_s: 1965.5382862091064
  timestamp: 1593995956
  timesteps_since_restore: 422000
  timesteps_this_iter: 2000
  timesteps_total: 422000
  training_iteration: 234
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 29.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=20453], 1965 s, 234 iter, 422000 ts, 123 rew

agent-1: 154.0
Sum Reward: 154.0
Avg Reward: 154.0
Min Reward: 154.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-39-29
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 178.0
  episode_reward_mean: 123.88
  episode_reward_min: 27.0
  episodes_this_iter: 1
  episodes_total: 422
  experiment_id: 325b24caee6c4209bf8cf01af4f33e4d
  hostname: gpu048
  info:
    apply_time_ms: 2.598
    dispatch_time_ms: 6.507
    learner:
      cur_lr: 0.0013318947749212384
      grad_gnorm: 8.859217643737793
      policy_entropy: 3.3286519050598145
      policy_loss: -2.3330159187316895
      var_gnorm: 30.211061477661133
      vf_explained_var: 0.0
      vf_loss: 0.4559023380279541
    num_steps_sampled: 423000
    num_steps_trained: 423000
    wait_time_ms: 34.836
  iterations_since_restore: 235
  node_ip: 172.17.8.48
  num_metric_batches_dropped: 0
  pid: 20453
  policy_reward_mean: {}
  time_since_restore: 1978.610065460205
  time_this_iter_s: 13.071779251098633
  time_total_s: 1978.610065460205
  timestamp: 1593995969
  timesteps_since_restore: 423000
  timesteps_this_iter: 1000
  timesteps_total: 423000
  training_iteration: 235
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 29.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=20453], 1978 s, 235 iter, 423000 ts, 124 rew

agent-1: 130.0
Sum Reward: 130.0
Avg Reward: 130.0
Min Reward: 130.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
agent-1: 165.0
Sum Reward: 165.0
Avg Reward: 165.0
Min Reward: 165.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-39-37
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 178.0
  episode_reward_mean: 125.68
  episode_reward_min: 27.0
  episodes_this_iter: 2
  episodes_total: 424
  experiment_id: 325b24caee6c4209bf8cf01af4f33e4d
  hostname: gpu048
  info:
    apply_time_ms: 4.026
    dispatch_time_ms: 10.012
    learner:
      cur_lr: 0.0013318281853571534
      grad_gnorm: 7.3392815589904785
      policy_entropy: 2.683666229248047
      policy_loss: 1.935739517211914
      var_gnorm: 30.20661163330078
      vf_explained_var: 0.0
      vf_loss: 0.561091423034668
    num_steps_sampled: 425000
    num_steps_trained: 425000
    wait_time_ms: 28.602
  iterations_since_restore: 236
  node_ip: 172.17.8.48
  num_metric_batches_dropped: 0
  pid: 20453
  policy_reward_mean: {}
  time_since_restore: 1986.954647064209
  time_this_iter_s: 8.344581604003906
  time_total_s: 1986.954647064209
  timestamp: 1593995977
  timesteps_since_restore: 425000
  timesteps_this_iter: 2000
  timesteps_total: 425000
  training_iteration: 236
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 29.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=20453], 1986 s, 236 iter, 425000 ts, 126 rew

agent-1: 166.0
Sum Reward: 166.0
Avg Reward: 166.0
Min Reward: 166.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
agent-1: 132.0
Sum Reward: 132.0
Avg Reward: 132.0
Min Reward: 132.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-39-46
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 178.0
  episode_reward_mean: 127.46
  episode_reward_min: 75.0
  episodes_this_iter: 2
  episodes_total: 426
  experiment_id: 325b24caee6c4209bf8cf01af4f33e4d
  hostname: gpu048
  info:
    apply_time_ms: 2.755
    dispatch_time_ms: 5.995
    learner:
      cur_lr: 0.0013316950062289834
      grad_gnorm: 16.344078063964844
      policy_entropy: 3.504592180252075
      policy_loss: -2.4689252376556396
      var_gnorm: 30.20772361755371
      vf_explained_var: 0.0
      vf_loss: 1.7755869626998901
    num_steps_sampled: 427000
    num_steps_trained: 427000
    wait_time_ms: 31.124
  iterations_since_restore: 237
  node_ip: 172.17.8.48
  num_metric_batches_dropped: 0
  pid: 20453
  policy_reward_mean: {}
  time_since_restore: 1995.3009934425354
  time_this_iter_s: 8.346346378326416
  time_total_s: 1995.3009934425354
  timestamp: 1593995986
  timesteps_since_restore: 427000
  timesteps_this_iter: 2000
  timesteps_total: 427000
  training_iteration: 237
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 29.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=20453], 1995 s, 237 iter, 427000 ts, 127 rew

agent-1: 120.0
Sum Reward: 120.0
Avg Reward: 120.0
Min Reward: 120.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
agent-1: 147.0
Sum Reward: 147.0
Avg Reward: 147.0
Min Reward: 147.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-39-54
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 178.0
  episode_reward_mean: 127.37
  episode_reward_min: 75.0
  episodes_this_iter: 2
  episodes_total: 428
  experiment_id: 325b24caee6c4209bf8cf01af4f33e4d
  hostname: gpu048
  info:
    apply_time_ms: 2.595
    dispatch_time_ms: 5.586
    learner:
      cur_lr: 0.0013315618271008134
      grad_gnorm: 11.275794982910156
      policy_entropy: 3.2336931228637695
      policy_loss: -0.3502040505409241
      var_gnorm: 30.191007614135742
      vf_explained_var: 0.0
      vf_loss: 1.0191905498504639
    num_steps_sampled: 429000
    num_steps_trained: 429000
    wait_time_ms: 32.349
  iterations_since_restore: 238
  node_ip: 172.17.8.48
  num_metric_batches_dropped: 0
  pid: 20453
  policy_reward_mean: {}
  time_since_restore: 2003.5722987651825
  time_this_iter_s: 8.271305322647095
  time_total_s: 2003.5722987651825
  timestamp: 1593995994
  timesteps_since_restore: 429000
  timesteps_this_iter: 2000
  timesteps_total: 429000
  training_iteration: 238
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 29.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=20453], 2003 s, 238 iter, 429000 ts, 127 rew

agent-1: 97.0
Sum Reward: 97.0
Avg Reward: 97.0
Min Reward: 97.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
agent-1: 139.0
Sum Reward: 139.0
Avg Reward: 139.0
Min Reward: 139.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-40-02
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 178.0
  episode_reward_mean: 126.82
  episode_reward_min: 75.0
  episodes_this_iter: 2
  episodes_total: 430
  experiment_id: 325b24caee6c4209bf8cf01af4f33e4d
  hostname: gpu048
  info:
    apply_time_ms: 3.161
    dispatch_time_ms: 6.379
    learner:
      cur_lr: 0.0013314286479726434
      grad_gnorm: 18.85333251953125
      policy_entropy: 3.7029693126678467
      policy_loss: -0.7301493287086487
      var_gnorm: 30.199527740478516
      vf_explained_var: 0.0
      vf_loss: 2.0464725494384766
    num_steps_sampled: 431000
    num_steps_trained: 431000
    wait_time_ms: 31.854
  iterations_since_restore: 239
  node_ip: 172.17.8.48
  num_metric_batches_dropped: 0
  pid: 20453
  policy_reward_mean: {}
  time_since_restore: 2011.928232908249
  time_this_iter_s: 8.355934143066406
  time_total_s: 2011.928232908249
  timestamp: 1593996002
  timesteps_since_restore: 431000
  timesteps_this_iter: 2000
  timesteps_total: 431000
  training_iteration: 239
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 29.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=20453], 2011 s, 239 iter, 431000 ts, 127 rew

agent-1: 111.0
Sum Reward: 111.0
Avg Reward: 111.0
Min Reward: 111.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
agent-1: 177.0
Sum Reward: 177.0
Avg Reward: 177.0
Min Reward: 177.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-40-08
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 178.0
  episode_reward_mean: 127.01
  episode_reward_min: 75.0
  episodes_this_iter: 2
  episodes_total: 432
  experiment_id: 325b24caee6c4209bf8cf01af4f33e4d
  hostname: gpu048
  info:
    apply_time_ms: 3.48
    dispatch_time_ms: 52.925
    learner:
      cur_lr: 0.0013312953524291515
      grad_gnorm: 20.29520034790039
      policy_entropy: 4.345373153686523
      policy_loss: -1.6263998746871948
      var_gnorm: 30.21710968017578
      vf_explained_var: 0.0
      vf_loss: 2.445446491241455
    num_steps_sampled: 432000
    num_steps_trained: 432000
    wait_time_ms: 12.529
  iterations_since_restore: 240
  node_ip: 172.17.8.48
  num_metric_batches_dropped: 0
  pid: 20453
  policy_reward_mean: {}
  time_since_restore: 2017.2931909561157
  time_this_iter_s: 5.364958047866821
  time_total_s: 2017.2931909561157
  timestamp: 1593996008
  timesteps_since_restore: 432000
  timesteps_this_iter: 1000
  timesteps_total: 432000
  training_iteration: 240
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 29.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=20453], 2017 s, 240 iter, 432000 ts, 127 rew

Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-40-14
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 178.0
  episode_reward_mean: 127.01
  episode_reward_min: 75.0
  episodes_this_iter: 0
  episodes_total: 432
  experiment_id: 325b24caee6c4209bf8cf01af4f33e4d
  hostname: gpu048
  info:
    apply_time_ms: 4.231
    dispatch_time_ms: 44.96
    learner:
      cur_lr: 0.0013312287628650665
      grad_gnorm: 11.995258331298828
      policy_entropy: 1.6664516925811768
      policy_loss: -0.25027066469192505
      var_gnorm: 30.218263626098633
      vf_explained_var: 0.0
      vf_loss: 1.2217974662780762
    num_steps_sampled: 433000
    num_steps_trained: 433000
    wait_time_ms: 18.355
  iterations_since_restore: 241
  node_ip: 172.17.8.48
  num_metric_batches_dropped: 0
  pid: 20453
  policy_reward_mean: {}
  time_since_restore: 2023.5559601783752
  time_this_iter_s: 6.2627692222595215
  time_total_s: 2023.5559601783752
  timestamp: 1593996014
  timesteps_since_restore: 433000
  timesteps_this_iter: 1000
  timesteps_total: 433000
  training_iteration: 241
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 29.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=20453], 2023 s, 241 iter, 433000 ts, 127 rew

agent-1: 104.0
Sum Reward: 104.0
Avg Reward: 104.0
Min Reward: 104.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
agent-1: 123.0
Sum Reward: 123.0
Avg Reward: 123.0
Min Reward: 123.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-40-20
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 178.0
  episode_reward_mean: 126.98
  episode_reward_min: 75.0
  episodes_this_iter: 2
  episodes_total: 434
  experiment_id: 325b24caee6c4209bf8cf01af4f33e4d
  hostname: gpu048
  info:
    apply_time_ms: 2.484
    dispatch_time_ms: 35.228
    learner:
      cur_lr: 0.0013311621733009815
      grad_gnorm: 14.815627098083496
      policy_entropy: 3.07889461517334
      policy_loss: -0.5389882326126099
      var_gnorm: 30.200075149536133
      vf_explained_var: 0.0
      vf_loss: 1.4263056516647339
    num_steps_sampled: 434000
    num_steps_trained: 434000
    wait_time_ms: 21.946
  iterations_since_restore: 242
  node_ip: 172.17.8.48
  num_metric_batches_dropped: 0
  pid: 20453
  policy_reward_mean: {}
  time_since_restore: 2029.4904477596283
  time_this_iter_s: 5.934487581253052
  time_total_s: 2029.4904477596283
  timestamp: 1593996020
  timesteps_since_restore: 434000
  timesteps_this_iter: 1000
  timesteps_total: 434000
  training_iteration: 242
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 29.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=20453], 2029 s, 242 iter, 434000 ts, 127 rew

Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-40-27
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 178.0
  episode_reward_mean: 126.98
  episode_reward_min: 75.0
  episodes_this_iter: 0
  episodes_total: 434
  experiment_id: 325b24caee6c4209bf8cf01af4f33e4d
  hostname: gpu048
  info:
    apply_time_ms: 3.887
    dispatch_time_ms: 24.469
    learner:
      cur_lr: 0.0013310955837368965
      grad_gnorm: 40.0
      policy_entropy: 2.141434907913208
      policy_loss: 4.797441482543945
      var_gnorm: 30.213642120361328
      vf_explained_var: 0.0
      vf_loss: 13.17745590209961
    num_steps_sampled: 435000
    num_steps_trained: 435000
    wait_time_ms: 10.639
  iterations_since_restore: 243
  node_ip: 172.17.8.48
  num_metric_batches_dropped: 0
  pid: 20453
  policy_reward_mean: {}
  time_since_restore: 2035.5834650993347
  time_this_iter_s: 6.093017339706421
  time_total_s: 2035.5834650993347
  timestamp: 1593996027
  timesteps_since_restore: 435000
  timesteps_this_iter: 1000
  timesteps_total: 435000
  training_iteration: 243
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 29.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=20453], 2035 s, 243 iter, 435000 ts, 127 rew

agent-1: 139.0
Sum Reward: 139.0
Avg Reward: 139.0
Min Reward: 139.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-40-33
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 178.0
  episode_reward_mean: 127.13
  episode_reward_min: 75.0
  episodes_this_iter: 1
  episodes_total: 435
  experiment_id: 325b24caee6c4209bf8cf01af4f33e4d
  hostname: gpu048
  info:
    apply_time_ms: 3.068
    dispatch_time_ms: 45.704
    learner:
      cur_lr: 0.0013310289941728115
      grad_gnorm: 11.10432243347168
      policy_entropy: 4.144215106964111
      policy_loss: 1.3533731698989868
      var_gnorm: 30.22228240966797
      vf_explained_var: 0.0
      vf_loss: 1.207369089126587
    num_steps_sampled: 436000
    num_steps_trained: 436000
    wait_time_ms: 11.196
  iterations_since_restore: 244
  node_ip: 172.17.8.48
  num_metric_batches_dropped: 0
  pid: 20453
  policy_reward_mean: {}
  time_since_restore: 2042.1413009166718
  time_this_iter_s: 6.557835817337036
  time_total_s: 2042.1413009166718
  timestamp: 1593996033
  timesteps_since_restore: 436000
  timesteps_this_iter: 1000
  timesteps_total: 436000
  training_iteration: 244
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 29.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=20453], 2042 s, 244 iter, 436000 ts, 127 rew

agent-1: 158.0
Sum Reward: 158.0
Avg Reward: 158.0
Min Reward: 158.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-40-39
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 178.0
  episode_reward_mean: 127.42
  episode_reward_min: 75.0
  episodes_this_iter: 1
  episodes_total: 436
  experiment_id: 325b24caee6c4209bf8cf01af4f33e4d
  hostname: gpu048
  info:
    apply_time_ms: 4.771
    dispatch_time_ms: 35.385
    learner:
      cur_lr: 0.0013309624046087265
      grad_gnorm: 33.90932846069336
      policy_entropy: 2.741973638534546
      policy_loss: 2.9624528884887695
      var_gnorm: 30.21957015991211
      vf_explained_var: 5.960464477539063e-08
      vf_loss: 6.366614818572998
    num_steps_sampled: 437000
    num_steps_trained: 437000
    wait_time_ms: 10.588
  iterations_since_restore: 245
  node_ip: 172.17.8.48
  num_metric_batches_dropped: 0
  pid: 20453
  policy_reward_mean: {}
  time_since_restore: 2047.9666075706482
  time_this_iter_s: 5.82530665397644
  time_total_s: 2047.9666075706482
  timestamp: 1593996039
  timesteps_since_restore: 437000
  timesteps_this_iter: 1000
  timesteps_total: 437000
  training_iteration: 245
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 29.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=20453], 2047 s, 245 iter, 437000 ts, 127 rew

agent-1: 128.0
Sum Reward: 128.0
Avg Reward: 128.0
Min Reward: 128.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
agent-1: 131.0
Sum Reward: 131.0
Avg Reward: 131.0
Min Reward: 131.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-40-48
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 178.0
  episode_reward_mean: 127.18
  episode_reward_min: 75.0
  episodes_this_iter: 2
  episodes_total: 438
  experiment_id: 325b24caee6c4209bf8cf01af4f33e4d
  hostname: gpu048
  info:
    apply_time_ms: 2.846
    dispatch_time_ms: 6.529
    learner:
      cur_lr: 0.0013308958150446415
      grad_gnorm: 19.734134674072266
      policy_entropy: 3.3477001190185547
      policy_loss: -0.6634966135025024
      var_gnorm: 30.22368812561035
      vf_explained_var: 0.0
      vf_loss: 2.3023717403411865
    num_steps_sampled: 439000
    num_steps_trained: 439000
    wait_time_ms: 32.225
  iterations_since_restore: 246
  node_ip: 172.17.8.48
  num_metric_batches_dropped: 0
  pid: 20453
  policy_reward_mean: {}
  time_since_restore: 2056.549650669098
  time_this_iter_s: 8.583043098449707
  time_total_s: 2056.549650669098
  timestamp: 1593996048
  timesteps_since_restore: 439000
  timesteps_this_iter: 2000
  timesteps_total: 439000
  training_iteration: 246
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 29.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=20453], 2056 s, 246 iter, 439000 ts, 127 rew

agent-1: 109.0
Sum Reward: 109.0
Avg Reward: 109.0
Min Reward: 109.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
agent-1: 145.0
Sum Reward: 145.0
Avg Reward: 145.0
Min Reward: 145.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-40-56
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 178.0
  episode_reward_mean: 127.16
  episode_reward_min: 75.0
  episodes_this_iter: 2
  episodes_total: 440
  experiment_id: 325b24caee6c4209bf8cf01af4f33e4d
  hostname: gpu048
  info:
    apply_time_ms: 2.92
    dispatch_time_ms: 6.917
    learner:
      cur_lr: 0.0013307626359164715
      grad_gnorm: 20.78038787841797
      policy_entropy: 5.000574588775635
      policy_loss: -1.2865346670150757
      var_gnorm: 30.215957641601562
      vf_explained_var: 0.0
      vf_loss: 2.101278066635132
    num_steps_sampled: 441000
    num_steps_trained: 441000
    wait_time_ms: 31.725
  iterations_since_restore: 247
  node_ip: 172.17.8.48
  num_metric_batches_dropped: 0
  pid: 20453
  policy_reward_mean: {}
  time_since_restore: 2064.947494029999
  time_this_iter_s: 8.397843360900879
  time_total_s: 2064.947494029999
  timestamp: 1593996056
  timesteps_since_restore: 441000
  timesteps_this_iter: 2000
  timesteps_total: 441000
  training_iteration: 247
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 29.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=20453], 2064 s, 247 iter, 441000 ts, 127 rew

agent-1: 139.0
Sum Reward: 139.0
Avg Reward: 139.0
Min Reward: 139.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
agent-1: 129.0
Sum Reward: 129.0
Avg Reward: 129.0
Min Reward: 129.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-41-04
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 178.0
  episode_reward_mean: 127.4
  episode_reward_min: 75.0
  episodes_this_iter: 2
  episodes_total: 442
  experiment_id: 325b24caee6c4209bf8cf01af4f33e4d
  hostname: gpu048
  info:
    apply_time_ms: 2.762
    dispatch_time_ms: 7.421
    learner:
      cur_lr: 0.0013306294567883015
      grad_gnorm: 40.000003814697266
      policy_entropy: 3.4429874420166016
      policy_loss: 2.2368643283843994
      var_gnorm: 30.221416473388672
      vf_explained_var: 0.0
      vf_loss: 22.912824630737305
    num_steps_sampled: 443000
    num_steps_trained: 443000
    wait_time_ms: 32.083
  iterations_since_restore: 248
  node_ip: 172.17.8.48
  num_metric_batches_dropped: 0
  pid: 20453
  policy_reward_mean: {}
  time_since_restore: 2073.353871822357
  time_this_iter_s: 8.406377792358398
  time_total_s: 2073.353871822357
  timestamp: 1593996064
  timesteps_since_restore: 443000
  timesteps_this_iter: 2000
  timesteps_total: 443000
  training_iteration: 248
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 29.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=20453], 2073 s, 248 iter, 443000 ts, 127 rew

agent-1: 134.0
Sum Reward: 134.0
Avg Reward: 134.0
Min Reward: 134.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
agent-1: 138.0
Sum Reward: 138.0
Avg Reward: 138.0
Min Reward: 138.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-41-13
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 178.0
  episode_reward_mean: 127.55
  episode_reward_min: 75.0
  episodes_this_iter: 2
  episodes_total: 444
  experiment_id: 325b24caee6c4209bf8cf01af4f33e4d
  hostname: gpu048
  info:
    apply_time_ms: 2.865
    dispatch_time_ms: 9.785
    learner:
      cur_lr: 0.0013304961612448096
      grad_gnorm: 3.768747329711914
      policy_entropy: 3.5871622562408447
      policy_loss: 0.4133062958717346
      var_gnorm: 30.246095657348633
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 0.51759272813797
    num_steps_sampled: 445000
    num_steps_trained: 445000
    wait_time_ms: 30.907
  iterations_since_restore: 249
  node_ip: 172.17.8.48
  num_metric_batches_dropped: 0
  pid: 20453
  policy_reward_mean: {}
  time_since_restore: 2081.762239217758
  time_this_iter_s: 8.408367395401001
  time_total_s: 2081.762239217758
  timestamp: 1593996073
  timesteps_since_restore: 445000
  timesteps_this_iter: 2000
  timesteps_total: 445000
  training_iteration: 249
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 29.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=20453], 2081 s, 249 iter, 445000 ts, 128 rew

agent-1: 123.0
Sum Reward: 123.0
Avg Reward: 123.0
Min Reward: 123.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
agent-1: 181.0
Sum Reward: 181.0
Avg Reward: 181.0
Min Reward: 181.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-41-21
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 181.0
  episode_reward_mean: 128.35
  episode_reward_min: 75.0
  episodes_this_iter: 2
  episodes_total: 446
  experiment_id: 325b24caee6c4209bf8cf01af4f33e4d
  hostname: gpu048
  info:
    apply_time_ms: 3.071
    dispatch_time_ms: 7.053
    learner:
      cur_lr: 0.0013303629821166396
      grad_gnorm: 22.695913314819336
      policy_entropy: 4.734158039093018
      policy_loss: -2.8173158168792725
      var_gnorm: 30.266826629638672
      vf_explained_var: 0.0
      vf_loss: 3.2377121448516846
    num_steps_sampled: 447000
    num_steps_trained: 447000
    wait_time_ms: 32.539
  iterations_since_restore: 250
  node_ip: 172.17.8.48
  num_metric_batches_dropped: 0
  pid: 20453
  policy_reward_mean: {}
  time_since_restore: 2090.2605724334717
  time_this_iter_s: 8.498333215713501
  time_total_s: 2090.2605724334717
  timestamp: 1593996081
  timesteps_since_restore: 447000
  timesteps_this_iter: 2000
  timesteps_total: 447000
  training_iteration: 250
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 29.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=20453], 2090 s, 250 iter, 447000 ts, 128 rew

agent-1: 136.0
Sum Reward: 136.0
Avg Reward: 136.0
Min Reward: 136.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
agent-1: 147.0
Sum Reward: 147.0
Avg Reward: 147.0
Min Reward: 147.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-41-30
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 181.0
  episode_reward_mean: 129.41
  episode_reward_min: 75.0
  episodes_this_iter: 2
  episodes_total: 448
  experiment_id: 325b24caee6c4209bf8cf01af4f33e4d
  hostname: gpu048
  info:
    apply_time_ms: 3.435
    dispatch_time_ms: 7.607
    learner:
      cur_lr: 0.0013302298029884696
      grad_gnorm: 20.28119659423828
      policy_entropy: 4.531813144683838
      policy_loss: -4.467998504638672
      var_gnorm: 30.243406295776367
      vf_explained_var: 0.0
      vf_loss: 1.9091187715530396
    num_steps_sampled: 449000
    num_steps_trained: 449000
    wait_time_ms: 33.067
  iterations_since_restore: 251
  node_ip: 172.17.8.48
  num_metric_batches_dropped: 0
  pid: 20453
  policy_reward_mean: {}
  time_since_restore: 2098.610194206238
  time_this_iter_s: 8.349621772766113
  time_total_s: 2098.610194206238
  timestamp: 1593996090
  timesteps_since_restore: 449000
  timesteps_this_iter: 2000
  timesteps_total: 449000
  training_iteration: 251
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 29.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=20453], 2098 s, 251 iter, 449000 ts, 129 rew

agent-1: 95.0
Sum Reward: 95.0
Avg Reward: 95.0
Min Reward: 95.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
agent-1: 149.0
Sum Reward: 149.0
Avg Reward: 149.0
Min Reward: 149.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-41-38
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 181.0
  episode_reward_mean: 129.16
  episode_reward_min: 75.0
  episodes_this_iter: 2
  episodes_total: 450
  experiment_id: 325b24caee6c4209bf8cf01af4f33e4d
  hostname: gpu048
  info:
    apply_time_ms: 3.091
    dispatch_time_ms: 8.453
    learner:
      cur_lr: 0.0013300966238602996
      grad_gnorm: 19.34120750427246
      policy_entropy: 2.214005708694458
      policy_loss: -0.36215656995773315
      var_gnorm: 30.239898681640625
      vf_explained_var: 5.960464477539063e-08
      vf_loss: 2.340947389602661
    num_steps_sampled: 451000
    num_steps_trained: 451000
    wait_time_ms: 29.434
  iterations_since_restore: 252
  node_ip: 172.17.8.48
  num_metric_batches_dropped: 0
  pid: 20453
  policy_reward_mean: {}
  time_since_restore: 2107.131397485733
  time_this_iter_s: 8.52120327949524
  time_total_s: 2107.131397485733
  timestamp: 1593996098
  timesteps_since_restore: 451000
  timesteps_this_iter: 2000
  timesteps_total: 451000
  training_iteration: 252
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 29.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=20453], 2107 s, 252 iter, 451000 ts, 129 rew

agent-1: 118.0
Sum Reward: 118.0
Avg Reward: 118.0
Min Reward: 118.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
agent-1: 134.0
Sum Reward: 134.0
Avg Reward: 134.0
Min Reward: 134.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-41-47
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 181.0
  episode_reward_mean: 128.89
  episode_reward_min: 75.0
  episodes_this_iter: 2
  episodes_total: 452
  experiment_id: 325b24caee6c4209bf8cf01af4f33e4d
  hostname: gpu048
  info:
    apply_time_ms: 4.021
    dispatch_time_ms: 7.182
    learner:
      cur_lr: 0.0013299634447321296
      grad_gnorm: 17.977813720703125
      policy_entropy: 3.9049906730651855
      policy_loss: -1.5945994853973389
      var_gnorm: 30.22925567626953
      vf_explained_var: 0.0
      vf_loss: 2.0225419998168945
    num_steps_sampled: 453000
    num_steps_trained: 453000
    wait_time_ms: 32.485
  iterations_since_restore: 253
  node_ip: 172.17.8.48
  num_metric_batches_dropped: 0
  pid: 20453
  policy_reward_mean: {}
  time_since_restore: 2115.528820514679
  time_this_iter_s: 8.397423028945923
  time_total_s: 2115.528820514679
  timestamp: 1593996107
  timesteps_since_restore: 453000
  timesteps_this_iter: 2000
  timesteps_total: 453000
  training_iteration: 253
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 29.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=20453], 2115 s, 253 iter, 453000 ts, 129 rew

agent-1: 119.0
Sum Reward: 119.0
Avg Reward: 119.0
Min Reward: 119.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
agent-1: 197.0
Sum Reward: 197.0
Avg Reward: 197.0
Min Reward: 197.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-41-55
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 197.0
  episode_reward_mean: 129.13
  episode_reward_min: 75.0
  episodes_this_iter: 2
  episodes_total: 454
  experiment_id: 325b24caee6c4209bf8cf01af4f33e4d
  hostname: gpu048
  info:
    apply_time_ms: 2.864
    dispatch_time_ms: 9.373
    learner:
      cur_lr: 0.0013298301491886377
      grad_gnorm: 1.135776400566101
      policy_entropy: 3.963005304336548
      policy_loss: 0.2127353996038437
      var_gnorm: 30.2371826171875
      vf_explained_var: 1.1920928955078125e-07
      vf_loss: 0.3823931813240051
    num_steps_sampled: 455000
    num_steps_trained: 455000
    wait_time_ms: 29.809
  iterations_since_restore: 254
  node_ip: 172.17.8.48
  num_metric_batches_dropped: 0
  pid: 20453
  policy_reward_mean: {}
  time_since_restore: 2124.063607931137
  time_this_iter_s: 8.53478741645813
  time_total_s: 2124.063607931137
  timestamp: 1593996115
  timesteps_since_restore: 455000
  timesteps_this_iter: 2000
  timesteps_total: 455000
  training_iteration: 254
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 29.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=20453], 2124 s, 254 iter, 455000 ts, 129 rew

agent-1: 139.0
Sum Reward: 139.0
Avg Reward: 139.0
Min Reward: 139.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
agent-1: 114.0
Sum Reward: 114.0
Avg Reward: 114.0
Min Reward: 114.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-42-12
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 197.0
  episode_reward_mean: 129.73
  episode_reward_min: 75.0
  episodes_this_iter: 2
  episodes_total: 456
  experiment_id: 325b24caee6c4209bf8cf01af4f33e4d
  hostname: gpu048
  info:
    apply_time_ms: 3.157
    dispatch_time_ms: 9.214
    learner:
      cur_lr: 0.0013296969700604677
      grad_gnorm: 18.091825485229492
      policy_entropy: 3.7749743461608887
      policy_loss: -3.74794340133667
      var_gnorm: 30.22003173828125
      vf_explained_var: 0.0
      vf_loss: 1.7727652788162231
    num_steps_sampled: 457000
    num_steps_trained: 457000
    wait_time_ms: 28.801
  iterations_since_restore: 255
  node_ip: 172.17.8.48
  num_metric_batches_dropped: 0
  pid: 20453
  policy_reward_mean: {}
  time_since_restore: 2140.22550201416
  time_this_iter_s: 16.16189408302307
  time_total_s: 2140.22550201416
  timestamp: 1593996132
  timesteps_since_restore: 457000
  timesteps_this_iter: 2000
  timesteps_total: 457000
  training_iteration: 255
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 29.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=20453], 2140 s, 255 iter, 457000 ts, 130 rew

agent-1: 125.0
Sum Reward: 125.0
Avg Reward: 125.0
Min Reward: 125.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
agent-1: 115.0
Sum Reward: 115.0
Avg Reward: 115.0
Min Reward: 115.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-42-20
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 197.0
  episode_reward_mean: 129.51
  episode_reward_min: 75.0
  episodes_this_iter: 2
  episodes_total: 458
  experiment_id: 325b24caee6c4209bf8cf01af4f33e4d
  hostname: gpu048
  info:
    apply_time_ms: 2.522
    dispatch_time_ms: 5.054
    learner:
      cur_lr: 0.0013295637909322977
      grad_gnorm: 20.79561424255371
      policy_entropy: 3.7978382110595703
      policy_loss: -4.443840980529785
      var_gnorm: 30.23769760131836
      vf_explained_var: 0.0
      vf_loss: 2.0962817668914795
    num_steps_sampled: 459000
    num_steps_trained: 459000
    wait_time_ms: 36.459
  iterations_since_restore: 256
  node_ip: 172.17.8.48
  num_metric_batches_dropped: 0
  pid: 20453
  policy_reward_mean: {}
  time_since_restore: 2148.6186916828156
  time_this_iter_s: 8.393189668655396
  time_total_s: 2148.6186916828156
  timestamp: 1593996140
  timesteps_since_restore: 459000
  timesteps_this_iter: 2000
  timesteps_total: 459000
  training_iteration: 256
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 29.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=20453], 2148 s, 256 iter, 459000 ts, 130 rew

agent-1: 115.0
Sum Reward: 115.0
Avg Reward: 115.0
Min Reward: 115.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
agent-1: 108.0
Sum Reward: 108.0
Avg Reward: 108.0
Min Reward: 108.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-42-28
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 197.0
  episode_reward_mean: 128.68
  episode_reward_min: 75.0
  episodes_this_iter: 2
  episodes_total: 460
  experiment_id: 325b24caee6c4209bf8cf01af4f33e4d
  hostname: gpu048
  info:
    apply_time_ms: 3.034
    dispatch_time_ms: 7.213
    learner:
      cur_lr: 0.0013294306118041277
      grad_gnorm: 9.558934211730957
      policy_entropy: 4.60579776763916
      policy_loss: 1.3003251552581787
      var_gnorm: 30.234079360961914
      vf_explained_var: 0.0
      vf_loss: 0.9126431941986084
    num_steps_sampled: 461000
    num_steps_trained: 461000
    wait_time_ms: 29.927
  iterations_since_restore: 257
  node_ip: 172.17.8.48
  num_metric_batches_dropped: 0
  pid: 20453
  policy_reward_mean: {}
  time_since_restore: 2157.0292336940765
  time_this_iter_s: 8.410542011260986
  time_total_s: 2157.0292336940765
  timestamp: 1593996148
  timesteps_since_restore: 461000
  timesteps_this_iter: 2000
  timesteps_total: 461000
  training_iteration: 257
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 29.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=20453], 2157 s, 257 iter, 461000 ts, 129 rew

agent-1: 152.0
Sum Reward: 152.0
Avg Reward: 152.0
Min Reward: 152.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
agent-1: 146.0
Sum Reward: 146.0
Avg Reward: 146.0
Min Reward: 146.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-42-37
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 197.0
  episode_reward_mean: 129.63
  episode_reward_min: 75.0
  episodes_this_iter: 2
  episodes_total: 462
  experiment_id: 325b24caee6c4209bf8cf01af4f33e4d
  hostname: gpu048
  info:
    apply_time_ms: 2.951
    dispatch_time_ms: 7.105
    learner:
      cur_lr: 0.0013292974326759577
      grad_gnorm: 16.713024139404297
      policy_entropy: 1.8955512046813965
      policy_loss: -0.25964879989624023
      var_gnorm: 30.23751449584961
      vf_explained_var: -2.384185791015625e-07
      vf_loss: 1.7621560096740723
    num_steps_sampled: 463000
    num_steps_trained: 463000
    wait_time_ms: 31.672
  iterations_since_restore: 258
  node_ip: 172.17.8.48
  num_metric_batches_dropped: 0
  pid: 20453
  policy_reward_mean: {}
  time_since_restore: 2165.4016301631927
  time_this_iter_s: 8.372396469116211
  time_total_s: 2165.4016301631927
  timestamp: 1593996157
  timesteps_since_restore: 463000
  timesteps_this_iter: 2000
  timesteps_total: 463000
  training_iteration: 258
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 29.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=20453], 2165 s, 258 iter, 463000 ts, 130 rew

agent-1: 67.0
Sum Reward: 67.0
Avg Reward: 67.0
Min Reward: 67.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
agent-1: 123.0
Sum Reward: 123.0
Avg Reward: 123.0
Min Reward: 123.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-42-45
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 197.0
  episode_reward_mean: 129.22
  episode_reward_min: 67.0
  episodes_this_iter: 2
  episodes_total: 464
  experiment_id: 325b24caee6c4209bf8cf01af4f33e4d
  hostname: gpu048
  info:
    apply_time_ms: 2.399
    dispatch_time_ms: 7.041
    learner:
      cur_lr: 0.0013291642535477877
      grad_gnorm: 18.441120147705078
      policy_entropy: 2.6249165534973145
      policy_loss: -3.053124189376831
      var_gnorm: 30.249202728271484
      vf_explained_var: 0.0
      vf_loss: 1.9918146133422852
    num_steps_sampled: 465000
    num_steps_trained: 465000
    wait_time_ms: 30.816
  iterations_since_restore: 259
  node_ip: 172.17.8.48
  num_metric_batches_dropped: 0
  pid: 20453
  policy_reward_mean: {}
  time_since_restore: 2173.753223180771
  time_this_iter_s: 8.351593017578125
  time_total_s: 2173.753223180771
  timestamp: 1593996165
  timesteps_since_restore: 465000
  timesteps_this_iter: 2000
  timesteps_total: 465000
  training_iteration: 259
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 29.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=20453], 2173 s, 259 iter, 465000 ts, 129 rew

agent-1: 172.0
Sum Reward: 172.0
Avg Reward: 172.0
Min Reward: 172.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
agent-1: 119.0
Sum Reward: 119.0
Avg Reward: 119.0
Min Reward: 119.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-42-54
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 197.0
  episode_reward_mean: 129.6
  episode_reward_min: 67.0
  episodes_this_iter: 2
  episodes_total: 466
  experiment_id: 325b24caee6c4209bf8cf01af4f33e4d
  hostname: gpu048
  info:
    apply_time_ms: 3.409
    dispatch_time_ms: 6.425
    learner:
      cur_lr: 0.0013290309580042958
      grad_gnorm: 11.63268756866455
      policy_entropy: 2.064389228820801
      policy_loss: 0.19957929849624634
      var_gnorm: 30.257972717285156
      vf_explained_var: 1.1920928955078125e-07
      vf_loss: 1.2155463695526123
    num_steps_sampled: 467000
    num_steps_trained: 467000
    wait_time_ms: 33.009
  iterations_since_restore: 260
  node_ip: 172.17.8.48
  num_metric_batches_dropped: 0
  pid: 20453
  policy_reward_mean: {}
  time_since_restore: 2182.201956987381
  time_this_iter_s: 8.448733806610107
  time_total_s: 2182.201956987381
  timestamp: 1593996174
  timesteps_since_restore: 467000
  timesteps_this_iter: 2000
  timesteps_total: 467000
  training_iteration: 260
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 29.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=20453], 2182 s, 260 iter, 467000 ts, 130 rew

agent-1: 135.0
Sum Reward: 135.0
Avg Reward: 135.0
Min Reward: 135.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
agent-1: 148.0
Sum Reward: 148.0
Avg Reward: 148.0
Min Reward: 148.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-43-03
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 197.0
  episode_reward_mean: 130.46
  episode_reward_min: 67.0
  episodes_this_iter: 2
  episodes_total: 468
  experiment_id: 325b24caee6c4209bf8cf01af4f33e4d
  hostname: gpu048
  info:
    apply_time_ms: 2.821
    dispatch_time_ms: 37.622
    learner:
      cur_lr: 0.0013288977788761258
      grad_gnorm: 10.260809898376465
      policy_entropy: 1.525890827178955
      policy_loss: -0.1497831642627716
      var_gnorm: 30.266172409057617
      vf_explained_var: 0.0
      vf_loss: 0.9521482586860657
    num_steps_sampled: 469000
    num_steps_trained: 469000
    wait_time_ms: 30.037
  iterations_since_restore: 261
  node_ip: 172.17.8.48
  num_metric_batches_dropped: 0
  pid: 20453
  policy_reward_mean: {}
  time_since_restore: 2191.481194257736
  time_this_iter_s: 9.279237270355225
  time_total_s: 2191.481194257736
  timestamp: 1593996183
  timesteps_since_restore: 469000
  timesteps_this_iter: 2000
  timesteps_total: 469000
  training_iteration: 261
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=20453], 2191 s, 261 iter, 469000 ts, 130 rew

agent-1: 132.0
Sum Reward: 132.0
Avg Reward: 132.0
Min Reward: 132.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-43-09
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 197.0
  episode_reward_mean: 130.21
  episode_reward_min: 67.0
  episodes_this_iter: 1
  episodes_total: 469
  experiment_id: 325b24caee6c4209bf8cf01af4f33e4d
  hostname: gpu048
  info:
    apply_time_ms: 3.317
    dispatch_time_ms: 36.565
    learner:
      cur_lr: 0.0013287645997479558
      grad_gnorm: 9.605130195617676
      policy_entropy: 3.065206527709961
      policy_loss: 1.4115509986877441
      var_gnorm: 30.250226974487305
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 0.9563161730766296
    num_steps_sampled: 470000
    num_steps_trained: 470000
    wait_time_ms: 18.301
  iterations_since_restore: 262
  node_ip: 172.17.8.48
  num_metric_batches_dropped: 0
  pid: 20453
  policy_reward_mean: {}
  time_since_restore: 2197.0924713611603
  time_this_iter_s: 5.611277103424072
  time_total_s: 2197.0924713611603
  timestamp: 1593996189
  timesteps_since_restore: 470000
  timesteps_this_iter: 1000
  timesteps_total: 470000
  training_iteration: 262
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=20453], 2197 s, 262 iter, 470000 ts, 130 rew

agent-1: 102.0
Sum Reward: 102.0
Avg Reward: 102.0
Min Reward: 102.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-43-15
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 197.0
  episode_reward_mean: 129.45
  episode_reward_min: 67.0
  episodes_this_iter: 1
  episodes_total: 470
  experiment_id: 325b24caee6c4209bf8cf01af4f33e4d
  hostname: gpu048
  info:
    apply_time_ms: 2.715
    dispatch_time_ms: 28.313
    learner:
      cur_lr: 0.0013286980101838708
      grad_gnorm: 2.3552823066711426
      policy_entropy: 2.9617607593536377
      policy_loss: 0.5889760255813599
      var_gnorm: 30.262733459472656
      vf_explained_var: 1.7881393432617188e-07
      vf_loss: 1.4822391271591187
    num_steps_sampled: 471000
    num_steps_trained: 471000
    wait_time_ms: 31.266
  iterations_since_restore: 263
  node_ip: 172.17.8.48
  num_metric_batches_dropped: 0
  pid: 20453
  policy_reward_mean: {}
  time_since_restore: 2202.9691252708435
  time_this_iter_s: 5.8766539096832275
  time_total_s: 2202.9691252708435
  timestamp: 1593996195
  timesteps_since_restore: 471000
  timesteps_this_iter: 1000
  timesteps_total: 471000
  training_iteration: 263
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=20453], 2202 s, 263 iter, 471000 ts, 129 rew

agent-1: 117.0
Sum Reward: 117.0
Avg Reward: 117.0
Min Reward: 117.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-43-22
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 197.0
  episode_reward_mean: 129.5
  episode_reward_min: 67.0
  episodes_this_iter: 1
  episodes_total: 471
  experiment_id: 325b24caee6c4209bf8cf01af4f33e4d
  hostname: gpu048
  info:
    apply_time_ms: 2.869
    dispatch_time_ms: 36.485
    learner:
      cur_lr: 0.0013286314206197858
      grad_gnorm: 26.946680068969727
      policy_entropy: 5.145183086395264
      policy_loss: 4.201807498931885
      var_gnorm: 30.258270263671875
      vf_explained_var: 0.0
      vf_loss: 5.123610019683838
    num_steps_sampled: 472000
    num_steps_trained: 472000
    wait_time_ms: 34.967
  iterations_since_restore: 264
  node_ip: 172.17.8.48
  num_metric_batches_dropped: 0
  pid: 20453
  policy_reward_mean: {}
  time_since_restore: 2209.9023535251617
  time_this_iter_s: 6.933228254318237
  time_total_s: 2209.9023535251617
  timestamp: 1593996202
  timesteps_since_restore: 472000
  timesteps_this_iter: 1000
  timesteps_total: 472000
  training_iteration: 264
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=20453], 2209 s, 264 iter, 472000 ts, 130 rew

agent-1: 174.0
Sum Reward: 174.0
Avg Reward: 174.0
Min Reward: 174.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-43-28
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 197.0
  episode_reward_mean: 129.72
  episode_reward_min: 67.0
  episodes_this_iter: 1
  episodes_total: 472
  experiment_id: 325b24caee6c4209bf8cf01af4f33e4d
  hostname: gpu048
  info:
    apply_time_ms: 2.856
    dispatch_time_ms: 23.984
    learner:
      cur_lr: 0.0013285648310557008
      grad_gnorm: 25.683509826660156
      policy_entropy: 3.1241912841796875
      policy_loss: -4.047628879547119
      var_gnorm: 30.27240753173828
      vf_explained_var: 0.0
      vf_loss: 3.4664337635040283
    num_steps_sampled: 473000
    num_steps_trained: 473000
    wait_time_ms: 27.607
  iterations_since_restore: 265
  node_ip: 172.17.8.48
  num_metric_batches_dropped: 0
  pid: 20453
  policy_reward_mean: {}
  time_since_restore: 2216.776365995407
  time_this_iter_s: 6.874012470245361
  time_total_s: 2216.776365995407
  timestamp: 1593996208
  timesteps_since_restore: 473000
  timesteps_this_iter: 1000
  timesteps_total: 473000
  training_iteration: 265
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=20453], 2216 s, 265 iter, 473000 ts, 130 rew

agent-1: 138.0
Sum Reward: 138.0
Avg Reward: 138.0
Min Reward: 138.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-43-36
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 197.0
  episode_reward_mean: 129.53
  episode_reward_min: 67.0
  episodes_this_iter: 1
  episodes_total: 473
  experiment_id: 325b24caee6c4209bf8cf01af4f33e4d
  hostname: gpu048
  info:
    apply_time_ms: 5.004
    dispatch_time_ms: 41.879
    learner:
      cur_lr: 0.0013284982414916158
      grad_gnorm: 20.889894485473633
      policy_entropy: 4.029483795166016
      policy_loss: -2.8743948936462402
      var_gnorm: 30.270523071289062
      vf_explained_var: 0.0
      vf_loss: 2.657886028289795
    num_steps_sampled: 474000
    num_steps_trained: 474000
    wait_time_ms: 11.22
  iterations_since_restore: 266
  node_ip: 172.17.8.48
  num_metric_batches_dropped: 0
  pid: 20453
  policy_reward_mean: {}
  time_since_restore: 2223.8603472709656
  time_this_iter_s: 7.083981275558472
  time_total_s: 2223.8603472709656
  timestamp: 1593996216
  timesteps_since_restore: 474000
  timesteps_this_iter: 1000
  timesteps_total: 474000
  training_iteration: 266
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=20453], 2223 s, 266 iter, 474000 ts, 130 rew

agent-1: 127.0
Sum Reward: 127.0
Avg Reward: 127.0
Min Reward: 127.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
agent-1: 135.0
Sum Reward: 135.0
Avg Reward: 135.0
Min Reward: 135.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-43-44
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 197.0
  episode_reward_mean: 129.63
  episode_reward_min: 67.0
  episodes_this_iter: 2
  episodes_total: 475
  experiment_id: 325b24caee6c4209bf8cf01af4f33e4d
  hostname: gpu048
  info:
    apply_time_ms: 2.622
    dispatch_time_ms: 7.062
    learner:
      cur_lr: 0.0013284316519275308
      grad_gnorm: 18.34420394897461
      policy_entropy: 3.327125072479248
      policy_loss: -1.5665982961654663
      var_gnorm: 30.267873764038086
      vf_explained_var: 0.0
      vf_loss: 2.147052764892578
    num_steps_sampled: 476000
    num_steps_trained: 476000
    wait_time_ms: 32.793
  iterations_since_restore: 267
  node_ip: 172.17.8.48
  num_metric_batches_dropped: 0
  pid: 20453
  policy_reward_mean: {}
  time_since_restore: 2231.9763190746307
  time_this_iter_s: 8.115971803665161
  time_total_s: 2231.9763190746307
  timestamp: 1593996224
  timesteps_since_restore: 476000
  timesteps_this_iter: 2000
  timesteps_total: 476000
  training_iteration: 267
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=20453], 2231 s, 267 iter, 476000 ts, 130 rew

agent-1: 145.0
Sum Reward: 145.0
Avg Reward: 145.0
Min Reward: 145.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
agent-1: 100.0
Sum Reward: 100.0
Avg Reward: 100.0
Min Reward: 100.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-43-52
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 197.0
  episode_reward_mean: 129.55
  episode_reward_min: 67.0
  episodes_this_iter: 2
  episodes_total: 477
  experiment_id: 325b24caee6c4209bf8cf01af4f33e4d
  hostname: gpu048
  info:
    apply_time_ms: 2.889
    dispatch_time_ms: 7.2
    learner:
      cur_lr: 0.001328298356384039
      grad_gnorm: 18.445777893066406
      policy_entropy: 3.605088949203491
      policy_loss: 2.07627534866333
      var_gnorm: 30.26506996154785
      vf_explained_var: 0.0
      vf_loss: 2.1578762531280518
    num_steps_sampled: 478000
    num_steps_trained: 478000
    wait_time_ms: 35.188
  iterations_since_restore: 268
  node_ip: 172.17.8.48
  num_metric_batches_dropped: 0
  pid: 20453
  policy_reward_mean: {}
  time_since_restore: 2240.368416786194
  time_this_iter_s: 8.39209771156311
  time_total_s: 2240.368416786194
  timestamp: 1593996232
  timesteps_since_restore: 478000
  timesteps_this_iter: 2000
  timesteps_total: 478000
  training_iteration: 268
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=20453], 2240 s, 268 iter, 478000 ts, 130 rew

agent-1: 114.0
Sum Reward: 114.0
Avg Reward: 114.0
Min Reward: 114.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
agent-1: 155.0
Sum Reward: 155.0
Avg Reward: 155.0
Min Reward: 155.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-44-00
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 197.0
  episode_reward_mean: 130.05
  episode_reward_min: 67.0
  episodes_this_iter: 2
  episodes_total: 479
  experiment_id: 325b24caee6c4209bf8cf01af4f33e4d
  hostname: gpu048
  info:
    apply_time_ms: 3.564
    dispatch_time_ms: 6.6
    learner:
      cur_lr: 0.001328165177255869
      grad_gnorm: 18.002635955810547
      policy_entropy: 3.944687604904175
      policy_loss: -0.7793353199958801
      var_gnorm: 30.257646560668945
      vf_explained_var: 1.1920928955078125e-07
      vf_loss: 1.8155274391174316
    num_steps_sampled: 480000
    num_steps_trained: 480000
    wait_time_ms: 30.892
  iterations_since_restore: 269
  node_ip: 172.17.8.48
  num_metric_batches_dropped: 0
  pid: 20453
  policy_reward_mean: {}
  time_since_restore: 2248.7353398799896
  time_this_iter_s: 8.366923093795776
  time_total_s: 2248.7353398799896
  timestamp: 1593996240
  timesteps_since_restore: 480000
  timesteps_this_iter: 2000
  timesteps_total: 480000
  training_iteration: 269
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=20453], 2248 s, 269 iter, 480000 ts, 130 rew

agent-1: 105.0
Sum Reward: 105.0
Avg Reward: 105.0
Min Reward: 105.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
agent-1: 103.0
Sum Reward: 103.0
Avg Reward: 103.0
Min Reward: 103.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-44-09
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 197.0
  episode_reward_mean: 129.49
  episode_reward_min: 67.0
  episodes_this_iter: 2
  episodes_total: 481
  experiment_id: 325b24caee6c4209bf8cf01af4f33e4d
  hostname: gpu048
  info:
    apply_time_ms: 2.845
    dispatch_time_ms: 8.291
    learner:
      cur_lr: 0.001328031998127699
      grad_gnorm: 18.199766159057617
      policy_entropy: 2.189181089401245
      policy_loss: -1.8304157257080078
      var_gnorm: 30.274063110351562
      vf_explained_var: 0.0
      vf_loss: 2.1085152626037598
    num_steps_sampled: 482000
    num_steps_trained: 482000
    wait_time_ms: 30.88
  iterations_since_restore: 270
  node_ip: 172.17.8.48
  num_metric_batches_dropped: 0
  pid: 20453
  policy_reward_mean: {}
  time_since_restore: 2257.183265686035
  time_this_iter_s: 8.447925806045532
  time_total_s: 2257.183265686035
  timestamp: 1593996249
  timesteps_since_restore: 482000
  timesteps_this_iter: 2000
  timesteps_total: 482000
  training_iteration: 270
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=20453], 2257 s, 270 iter, 482000 ts, 129 rew

agent-1: 164.0
Sum Reward: 164.0
Avg Reward: 164.0
Min Reward: 164.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
agent-1: 119.0
Sum Reward: 119.0
Avg Reward: 119.0
Min Reward: 119.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-44-17
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 197.0
  episode_reward_mean: 129.59
  episode_reward_min: 67.0
  episodes_this_iter: 2
  episodes_total: 483
  experiment_id: 325b24caee6c4209bf8cf01af4f33e4d
  hostname: gpu048
  info:
    apply_time_ms: 2.693
    dispatch_time_ms: 6.994
    learner:
      cur_lr: 0.0013278988189995289
      grad_gnorm: 16.697559356689453
      policy_entropy: 1.4747543334960938
      policy_loss: -0.1817515790462494
      var_gnorm: 30.265134811401367
      vf_explained_var: 0.0
      vf_loss: 1.7752560377120972
    num_steps_sampled: 484000
    num_steps_trained: 484000
    wait_time_ms: 31.665
  iterations_since_restore: 271
  node_ip: 172.17.8.48
  num_metric_batches_dropped: 0
  pid: 20453
  policy_reward_mean: {}
  time_since_restore: 2265.5735216140747
  time_this_iter_s: 8.39025592803955
  time_total_s: 2265.5735216140747
  timestamp: 1593996257
  timesteps_since_restore: 484000
  timesteps_this_iter: 2000
  timesteps_total: 484000
  training_iteration: 271
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=20453], 2265 s, 271 iter, 484000 ts, 130 rew

agent-1: 123.0
Sum Reward: 123.0
Avg Reward: 123.0
Min Reward: 123.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
agent-1: 90.0
Sum Reward: 90.0
Avg Reward: 90.0
Min Reward: 90.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-44-26
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 197.0
  episode_reward_mean: 129.43
  episode_reward_min: 67.0
  episodes_this_iter: 2
  episodes_total: 485
  experiment_id: 325b24caee6c4209bf8cf01af4f33e4d
  hostname: gpu048
  info:
    apply_time_ms: 2.996
    dispatch_time_ms: 6.915
    learner:
      cur_lr: 0.0013277656398713589
      grad_gnorm: 16.013046264648438
      policy_entropy: 3.2495689392089844
      policy_loss: -2.322829484939575
      var_gnorm: 30.259126663208008
      vf_explained_var: 0.0
      vf_loss: 1.5985841751098633
    num_steps_sampled: 486000
    num_steps_trained: 486000
    wait_time_ms: 31.489
  iterations_since_restore: 272
  node_ip: 172.17.8.48
  num_metric_batches_dropped: 0
  pid: 20453
  policy_reward_mean: {}
  time_since_restore: 2273.825588464737
  time_this_iter_s: 8.252066850662231
  time_total_s: 2273.825588464737
  timestamp: 1593996266
  timesteps_since_restore: 486000
  timesteps_this_iter: 2000
  timesteps_total: 486000
  training_iteration: 272
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=20453], 2273 s, 272 iter, 486000 ts, 129 rew

agent-1: 139.0
Sum Reward: 139.0
Avg Reward: 139.0
Min Reward: 139.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
agent-1: 138.0
Sum Reward: 138.0
Avg Reward: 138.0
Min Reward: 138.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-44-34
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 197.0
  episode_reward_mean: 129.23
  episode_reward_min: 67.0
  episodes_this_iter: 2
  episodes_total: 487
  experiment_id: 325b24caee6c4209bf8cf01af4f33e4d
  hostname: gpu048
  info:
    apply_time_ms: 3.278
    dispatch_time_ms: 7.088
    learner:
      cur_lr: 0.001327632344327867
      grad_gnorm: 36.66857147216797
      policy_entropy: 4.0818257331848145
      policy_loss: 1.6602001190185547
      var_gnorm: 30.276939392089844
      vf_explained_var: 0.0
      vf_loss: 7.676323413848877
    num_steps_sampled: 488000
    num_steps_trained: 488000
    wait_time_ms: 31.551
  iterations_since_restore: 273
  node_ip: 172.17.8.48
  num_metric_batches_dropped: 0
  pid: 20453
  policy_reward_mean: {}
  time_since_restore: 2282.1704454421997
  time_this_iter_s: 8.344856977462769
  time_total_s: 2282.1704454421997
  timestamp: 1593996274
  timesteps_since_restore: 488000
  timesteps_this_iter: 2000
  timesteps_total: 488000
  training_iteration: 273
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=20453], 2282 s, 273 iter, 488000 ts, 129 rew

agent-1: 104.0
Sum Reward: 104.0
Avg Reward: 104.0
Min Reward: 104.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
agent-1: 130.0
Sum Reward: 130.0
Avg Reward: 130.0
Min Reward: 130.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-44-42
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 197.0
  episode_reward_mean: 129.37
  episode_reward_min: 67.0
  episodes_this_iter: 2
  episodes_total: 489
  experiment_id: 325b24caee6c4209bf8cf01af4f33e4d
  hostname: gpu048
  info:
    apply_time_ms: 2.76
    dispatch_time_ms: 6.389
    learner:
      cur_lr: 0.001327499165199697
      grad_gnorm: 18.079729080200195
      policy_entropy: 4.506980895996094
      policy_loss: -3.437764883041382
      var_gnorm: 30.27750015258789
      vf_explained_var: 0.0
      vf_loss: 1.923004388809204
    num_steps_sampled: 490000
    num_steps_trained: 490000
    wait_time_ms: 31.773
  iterations_since_restore: 274
  node_ip: 172.17.8.48
  num_metric_batches_dropped: 0
  pid: 20453
  policy_reward_mean: {}
  time_since_restore: 2290.5844502449036
  time_this_iter_s: 8.414004802703857
  time_total_s: 2290.5844502449036
  timestamp: 1593996282
  timesteps_since_restore: 490000
  timesteps_this_iter: 2000
  timesteps_total: 490000
  training_iteration: 274
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=20453], 2290 s, 274 iter, 490000 ts, 129 rew

agent-1: 128.0
Sum Reward: 128.0
Avg Reward: 128.0
Min Reward: 128.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
agent-1: 116.0
Sum Reward: 116.0
Avg Reward: 116.0
Min Reward: 116.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-44-51
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 197.0
  episode_reward_mean: 129.77
  episode_reward_min: 67.0
  episodes_this_iter: 2
  episodes_total: 491
  experiment_id: 325b24caee6c4209bf8cf01af4f33e4d
  hostname: gpu048
  info:
    apply_time_ms: 3.349
    dispatch_time_ms: 8.21
    learner:
      cur_lr: 0.001327365986071527
      grad_gnorm: 15.638492584228516
      policy_entropy: 2.8033218383789062
      policy_loss: -0.4120604395866394
      var_gnorm: 30.26059341430664
      vf_explained_var: 5.960464477539063e-08
      vf_loss: 1.492124319076538
    num_steps_sampled: 492000
    num_steps_trained: 492000
    wait_time_ms: 30.142
  iterations_since_restore: 275
  node_ip: 172.17.8.48
  num_metric_batches_dropped: 0
  pid: 20453
  policy_reward_mean: {}
  time_since_restore: 2299.400631904602
  time_this_iter_s: 8.816181659698486
  time_total_s: 2299.400631904602
  timestamp: 1593996291
  timesteps_since_restore: 492000
  timesteps_this_iter: 2000
  timesteps_total: 492000
  training_iteration: 275
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=20453], 2299 s, 275 iter, 492000 ts, 130 rew

agent-1: 115.0
Sum Reward: 115.0
Avg Reward: 115.0
Min Reward: 115.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
agent-1: 159.0
Sum Reward: 159.0
Avg Reward: 159.0
Min Reward: 159.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-45-00
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 197.0
  episode_reward_mean: 130.23
  episode_reward_min: 67.0
  episodes_this_iter: 2
  episodes_total: 493
  experiment_id: 325b24caee6c4209bf8cf01af4f33e4d
  hostname: gpu048
  info:
    apply_time_ms: 2.837
    dispatch_time_ms: 8.511
    learner:
      cur_lr: 0.001327232806943357
      grad_gnorm: 40.0
      policy_entropy: 3.259596347808838
      policy_loss: 8.072281837463379
      var_gnorm: 30.309349060058594
      vf_explained_var: 0.0
      vf_loss: 26.31993865966797
    num_steps_sampled: 494000
    num_steps_trained: 494000
    wait_time_ms: 31.984
  iterations_since_restore: 276
  node_ip: 172.17.8.48
  num_metric_batches_dropped: 0
  pid: 20453
  policy_reward_mean: {}
  time_since_restore: 2307.881858587265
  time_this_iter_s: 8.481226682662964
  time_total_s: 2307.881858587265
  timestamp: 1593996300
  timesteps_since_restore: 494000
  timesteps_this_iter: 2000
  timesteps_total: 494000
  training_iteration: 276
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=20453], 2307 s, 276 iter, 494000 ts, 130 rew

agent-1: 147.0
Sum Reward: 147.0
Avg Reward: 147.0
Min Reward: 147.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
agent-1: 141.0
Sum Reward: 141.0
Avg Reward: 141.0
Min Reward: 141.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-45-08
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 197.0
  episode_reward_mean: 130.57
  episode_reward_min: 67.0
  episodes_this_iter: 2
  episodes_total: 495
  experiment_id: 325b24caee6c4209bf8cf01af4f33e4d
  hostname: gpu048
  info:
    apply_time_ms: 3.04
    dispatch_time_ms: 6.941
    learner:
      cur_lr: 0.001327099627815187
      grad_gnorm: 8.733402252197266
      policy_entropy: 6.162595272064209
      policy_loss: 0.6480717658996582
      var_gnorm: 30.294233322143555
      vf_explained_var: 0.0
      vf_loss: 0.851106584072113
    num_steps_sampled: 496000
    num_steps_trained: 496000
    wait_time_ms: 29.136
  iterations_since_restore: 277
  node_ip: 172.17.8.48
  num_metric_batches_dropped: 0
  pid: 20453
  policy_reward_mean: {}
  time_since_restore: 2316.261297225952
  time_this_iter_s: 8.379438638687134
  time_total_s: 2316.261297225952
  timestamp: 1593996308
  timesteps_since_restore: 496000
  timesteps_this_iter: 2000
  timesteps_total: 496000
  training_iteration: 277
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=20453], 2316 s, 277 iter, 496000 ts, 131 rew

agent-1: 168.0
Sum Reward: 168.0
Avg Reward: 168.0
Min Reward: 168.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
agent-1: 104.0
Sum Reward: 104.0
Avg Reward: 104.0
Min Reward: 104.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-45-23
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 197.0
  episode_reward_mean: 130.34
  episode_reward_min: 67.0
  episodes_this_iter: 2
  episodes_total: 497
  experiment_id: 325b24caee6c4209bf8cf01af4f33e4d
  hostname: gpu048
  info:
    apply_time_ms: 3.578
    dispatch_time_ms: 7.437
    learner:
      cur_lr: 0.001326966448687017
      grad_gnorm: 40.0
      policy_entropy: 2.577662467956543
      policy_loss: 6.9583964347839355
      var_gnorm: 30.32388687133789
      vf_explained_var: 0.0
      vf_loss: 18.564847946166992
    num_steps_sampled: 498000
    num_steps_trained: 498000
    wait_time_ms: 29.753
  iterations_since_restore: 278
  node_ip: 172.17.8.48
  num_metric_batches_dropped: 0
  pid: 20453
  policy_reward_mean: {}
  time_since_restore: 2324.4314699172974
  time_this_iter_s: 8.170172691345215
  time_total_s: 2324.4314699172974
  timestamp: 1593996323
  timesteps_since_restore: 498000
  timesteps_this_iter: 2000
  timesteps_total: 498000
  training_iteration: 278
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=20453], 2324 s, 278 iter, 498000 ts, 130 rew

agent-1: 183.0
Sum Reward: 183.0
Avg Reward: 183.0
Min Reward: 183.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
agent-1: 146.0
Sum Reward: 146.0
Avg Reward: 146.0
Min Reward: 146.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-45-31
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 197.0
  episode_reward_mean: 131.3
  episode_reward_min: 67.0
  episodes_this_iter: 2
  episodes_total: 499
  experiment_id: 325b24caee6c4209bf8cf01af4f33e4d
  hostname: gpu048
  info:
    apply_time_ms: 2.631
    dispatch_time_ms: 6.23
    learner:
      cur_lr: 0.0013268331531435251
      grad_gnorm: 39.70541000366211
      policy_entropy: 2.1640515327453613
      policy_loss: 0.7235719561576843
      var_gnorm: 30.3367977142334
      vf_explained_var: 5.960464477539063e-08
      vf_loss: 14.557106018066406
    num_steps_sampled: 500000
    num_steps_trained: 500000
    wait_time_ms: 36.758
  iterations_since_restore: 279
  node_ip: 172.17.8.48
  num_metric_batches_dropped: 0
  pid: 20453
  policy_reward_mean: {}
  time_since_restore: 2333.021830558777
  time_this_iter_s: 8.590360641479492
  time_total_s: 2333.021830558777
  timestamp: 1593996331
  timesteps_since_restore: 500000
  timesteps_this_iter: 2000
  timesteps_total: 500000
  training_iteration: 279
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=20453], 2333 s, 279 iter, 500000 ts, 131 rew

agent-1: 146.0
Sum Reward: 146.0
Avg Reward: 146.0
Min Reward: 146.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
agent-1: 126.0
Sum Reward: 126.0
Avg Reward: 126.0
Min Reward: 126.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-45-40
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 197.0
  episode_reward_mean: 131.56
  episode_reward_min: 67.0
  episodes_this_iter: 2
  episodes_total: 501
  experiment_id: 325b24caee6c4209bf8cf01af4f33e4d
  hostname: gpu048
  info:
    apply_time_ms: 3.96
    dispatch_time_ms: 6.45
    learner:
      cur_lr: 0.0013266999740153551
      grad_gnorm: 21.45237922668457
      policy_entropy: 2.8411004543304443
      policy_loss: -1.1869014501571655
      var_gnorm: 30.332578659057617
      vf_explained_var: 0.0
      vf_loss: 2.9117774963378906
    num_steps_sampled: 502000
    num_steps_trained: 502000
    wait_time_ms: 33.436
  iterations_since_restore: 280
  node_ip: 172.17.8.48
  num_metric_batches_dropped: 0
  pid: 20453
  policy_reward_mean: {}
  time_since_restore: 2341.50581908226
  time_this_iter_s: 8.483988523483276
  time_total_s: 2341.50581908226
  timestamp: 1593996340
  timesteps_since_restore: 502000
  timesteps_this_iter: 2000
  timesteps_total: 502000
  training_iteration: 280
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=20453], 2341 s, 280 iter, 502000 ts, 132 rew

agent-1: 144.0
Sum Reward: 144.0
Avg Reward: 144.0
Min Reward: 144.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
agent-1: 134.0
Sum Reward: 134.0
Avg Reward: 134.0
Min Reward: 134.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-45-48
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 197.0
  episode_reward_mean: 131.96
  episode_reward_min: 67.0
  episodes_this_iter: 2
  episodes_total: 503
  experiment_id: 325b24caee6c4209bf8cf01af4f33e4d
  hostname: gpu048
  info:
    apply_time_ms: 3.576
    dispatch_time_ms: 9.169
    learner:
      cur_lr: 0.001326566794887185
      grad_gnorm: 19.253662109375
      policy_entropy: 1.5609949827194214
      policy_loss: -0.2265879064798355
      var_gnorm: 30.31574058532715
      vf_explained_var: 0.0
      vf_loss: 2.356828451156616
    num_steps_sampled: 504000
    num_steps_trained: 504000
    wait_time_ms: 29.928
  iterations_since_restore: 281
  node_ip: 172.17.8.48
  num_metric_batches_dropped: 0
  pid: 20453
  policy_reward_mean: {}
  time_since_restore: 2349.8706855773926
  time_this_iter_s: 8.364866495132446
  time_total_s: 2349.8706855773926
  timestamp: 1593996348
  timesteps_since_restore: 504000
  timesteps_this_iter: 2000
  timesteps_total: 504000
  training_iteration: 281
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=20453], 2349 s, 281 iter, 504000 ts, 132 rew

agent-1: 108.0
Sum Reward: 108.0
Avg Reward: 108.0
Min Reward: 108.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
agent-1: 99.0
Sum Reward: 99.0
Avg Reward: 99.0
Min Reward: 99.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-45-57
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 197.0
  episode_reward_mean: 131.34
  episode_reward_min: 67.0
  episodes_this_iter: 2
  episodes_total: 505
  experiment_id: 325b24caee6c4209bf8cf01af4f33e4d
  hostname: gpu048
  info:
    apply_time_ms: 3.897
    dispatch_time_ms: 8.263
    learner:
      cur_lr: 0.001326433615759015
      grad_gnorm: 17.380189895629883
      policy_entropy: 2.028237819671631
      policy_loss: -2.300173044204712
      var_gnorm: 30.30044937133789
      vf_explained_var: 0.0
      vf_loss: 1.856485366821289
    num_steps_sampled: 506000
    num_steps_trained: 506000
    wait_time_ms: 30.407
  iterations_since_restore: 282
  node_ip: 172.17.8.48
  num_metric_batches_dropped: 0
  pid: 20453
  policy_reward_mean: {}
  time_since_restore: 2358.1961040496826
  time_this_iter_s: 8.325418472290039
  time_total_s: 2358.1961040496826
  timestamp: 1593996357
  timesteps_since_restore: 506000
  timesteps_this_iter: 2000
  timesteps_total: 506000
  training_iteration: 282
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=20453], 2358 s, 282 iter, 506000 ts, 131 rew

agent-1: 145.0
Sum Reward: 145.0
Avg Reward: 145.0
Min Reward: 145.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
agent-1: 98.0
Sum Reward: 98.0
Avg Reward: 98.0
Min Reward: 98.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-46-05
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 197.0
  episode_reward_mean: 131.16
  episode_reward_min: 67.0
  episodes_this_iter: 2
  episodes_total: 507
  experiment_id: 325b24caee6c4209bf8cf01af4f33e4d
  hostname: gpu048
  info:
    apply_time_ms: 2.52
    dispatch_time_ms: 8.118
    learner:
      cur_lr: 0.001326300436630845
      grad_gnorm: 18.942747116088867
      policy_entropy: 5.030294418334961
      policy_loss: -2.2091469764709473
      var_gnorm: 30.315319061279297
      vf_explained_var: 5.960464477539063e-08
      vf_loss: 2.15282940864563
    num_steps_sampled: 508000
    num_steps_trained: 508000
    wait_time_ms: 29.495
  iterations_since_restore: 283
  node_ip: 172.17.8.48
  num_metric_batches_dropped: 0
  pid: 20453
  policy_reward_mean: {}
  time_since_restore: 2366.4849462509155
  time_this_iter_s: 8.28884220123291
  time_total_s: 2366.4849462509155
  timestamp: 1593996365
  timesteps_since_restore: 508000
  timesteps_this_iter: 2000
  timesteps_total: 508000
  training_iteration: 283
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=20453], 2366 s, 283 iter, 508000 ts, 131 rew

agent-1: 140.0
Sum Reward: 140.0
Avg Reward: 140.0
Min Reward: 140.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
agent-1: 112.0
Sum Reward: 112.0
Avg Reward: 112.0
Min Reward: 112.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-46-13
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 197.0
  episode_reward_mean: 131.09
  episode_reward_min: 67.0
  episodes_this_iter: 2
  episodes_total: 509
  experiment_id: 325b24caee6c4209bf8cf01af4f33e4d
  hostname: gpu048
  info:
    apply_time_ms: 3.62
    dispatch_time_ms: 8.319
    learner:
      cur_lr: 0.001326167257502675
      grad_gnorm: 15.593545913696289
      policy_entropy: 2.4469261169433594
      policy_loss: -0.3423711359500885
      var_gnorm: 30.289596557617188
      vf_explained_var: 0.0
      vf_loss: 1.5068120956420898
    num_steps_sampled: 510000
    num_steps_trained: 510000
    wait_time_ms: 30.209
  iterations_since_restore: 284
  node_ip: 172.17.8.48
  num_metric_batches_dropped: 0
  pid: 20453
  policy_reward_mean: {}
  time_since_restore: 2374.8785700798035
  time_this_iter_s: 8.39362382888794
  time_total_s: 2374.8785700798035
  timestamp: 1593996373
  timesteps_since_restore: 510000
  timesteps_this_iter: 2000
  timesteps_total: 510000
  training_iteration: 284
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=20453], 2374 s, 284 iter, 510000 ts, 131 rew

agent-1: 105.0
Sum Reward: 105.0
Avg Reward: 105.0
Min Reward: 105.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
agent-1: 119.0
Sum Reward: 119.0
Avg Reward: 119.0
Min Reward: 119.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-46-22
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 197.0
  episode_reward_mean: 130.29
  episode_reward_min: 67.0
  episodes_this_iter: 2
  episodes_total: 511
  experiment_id: 325b24caee6c4209bf8cf01af4f33e4d
  hostname: gpu048
  info:
    apply_time_ms: 2.739
    dispatch_time_ms: 6.46
    learner:
      cur_lr: 0.0013260339619591832
      grad_gnorm: 16.08152961730957
      policy_entropy: 2.4534969329833984
      policy_loss: -0.3461925983428955
      var_gnorm: 30.297574996948242
      vf_explained_var: 0.0
      vf_loss: 1.6049007177352905
    num_steps_sampled: 512000
    num_steps_trained: 512000
    wait_time_ms: 34.715
  iterations_since_restore: 285
  node_ip: 172.17.8.48
  num_metric_batches_dropped: 0
  pid: 20453
  policy_reward_mean: {}
  time_since_restore: 2383.211011648178
  time_this_iter_s: 8.332441568374634
  time_total_s: 2383.211011648178
  timestamp: 1593996382
  timesteps_since_restore: 512000
  timesteps_this_iter: 2000
  timesteps_total: 512000
  training_iteration: 285
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=20453], 2383 s, 285 iter, 512000 ts, 130 rew

agent-1: 106.0
Sum Reward: 106.0
Avg Reward: 106.0
Min Reward: 106.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
agent-1: 180.0
Sum Reward: 180.0
Avg Reward: 180.0
Min Reward: 180.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-46-30
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 197.0
  episode_reward_mean: 130.98
  episode_reward_min: 67.0
  episodes_this_iter: 2
  episodes_total: 513
  experiment_id: 325b24caee6c4209bf8cf01af4f33e4d
  hostname: gpu048
  info:
    apply_time_ms: 3.643
    dispatch_time_ms: 7.569
    learner:
      cur_lr: 0.0013259007828310132
      grad_gnorm: 39.999996185302734
      policy_entropy: 3.0353095531463623
      policy_loss: 1.92001211643219
      var_gnorm: 30.321048736572266
      vf_explained_var: 0.0
      vf_loss: 21.834972381591797
    num_steps_sampled: 514000
    num_steps_trained: 514000
    wait_time_ms: 31.11
  iterations_since_restore: 286
  node_ip: 172.17.8.48
  num_metric_batches_dropped: 0
  pid: 20453
  policy_reward_mean: {}
  time_since_restore: 2391.6260828971863
  time_this_iter_s: 8.415071249008179
  time_total_s: 2391.6260828971863
  timestamp: 1593996390
  timesteps_since_restore: 514000
  timesteps_this_iter: 2000
  timesteps_total: 514000
  training_iteration: 286
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=20453], 2391 s, 286 iter, 514000 ts, 131 rew

agent-1: 95.0
Sum Reward: 95.0
Avg Reward: 95.0
Min Reward: 95.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
agent-1: 116.0
Sum Reward: 116.0
Avg Reward: 116.0
Min Reward: 116.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-46-39
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 197.0
  episode_reward_mean: 130.12
  episode_reward_min: 67.0
  episodes_this_iter: 2
  episodes_total: 515
  experiment_id: 325b24caee6c4209bf8cf01af4f33e4d
  hostname: gpu048
  info:
    apply_time_ms: 4.408
    dispatch_time_ms: 8.786
    learner:
      cur_lr: 0.0013257676037028432
      grad_gnorm: 40.0
      policy_entropy: 3.5646812915802
      policy_loss: 11.475541114807129
      var_gnorm: 30.314855575561523
      vf_explained_var: 0.0
      vf_loss: 42.684532165527344
    num_steps_sampled: 516000
    num_steps_trained: 516000
    wait_time_ms: 28.013
  iterations_since_restore: 287
  node_ip: 172.17.8.48
  num_metric_batches_dropped: 0
  pid: 20453
  policy_reward_mean: {}
  time_since_restore: 2399.9163901805878
  time_this_iter_s: 8.29030728340149
  time_total_s: 2399.9163901805878
  timestamp: 1593996399
  timesteps_since_restore: 516000
  timesteps_this_iter: 2000
  timesteps_total: 516000
  training_iteration: 287
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=20453], 2399 s, 287 iter, 516000 ts, 130 rew

agent-1: 139.0
Sum Reward: 139.0
Avg Reward: 139.0
Min Reward: 139.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
agent-1: 135.0
Sum Reward: 135.0
Avg Reward: 135.0
Min Reward: 135.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-46-47
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 197.0
  episode_reward_mean: 130.65
  episode_reward_min: 67.0
  episodes_this_iter: 2
  episodes_total: 517
  experiment_id: 325b24caee6c4209bf8cf01af4f33e4d
  hostname: gpu048
  info:
    apply_time_ms: 3.026
    dispatch_time_ms: 7.251
    learner:
      cur_lr: 0.0013256344245746732
      grad_gnorm: 15.061076164245605
      policy_entropy: 1.2399072647094727
      policy_loss: -0.13137155771255493
      var_gnorm: 30.306833267211914
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 1.4489867687225342
    num_steps_sampled: 518000
    num_steps_trained: 518000
    wait_time_ms: 29.401
  iterations_since_restore: 288
  node_ip: 172.17.8.48
  num_metric_batches_dropped: 0
  pid: 20453
  policy_reward_mean: {}
  time_since_restore: 2408.1857669353485
  time_this_iter_s: 8.269376754760742
  time_total_s: 2408.1857669353485
  timestamp: 1593996407
  timesteps_since_restore: 518000
  timesteps_this_iter: 2000
  timesteps_total: 518000
  training_iteration: 288
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=20453], 2408 s, 288 iter, 518000 ts, 131 rew

agent-1: 88.0
Sum Reward: 88.0
Avg Reward: 88.0
Min Reward: 88.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
agent-1: 93.0
Sum Reward: 93.0
Avg Reward: 93.0
Min Reward: 93.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-46-55
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 197.0
  episode_reward_mean: 129.9
  episode_reward_min: 67.0
  episodes_this_iter: 2
  episodes_total: 519
  experiment_id: 325b24caee6c4209bf8cf01af4f33e4d
  hostname: gpu048
  info:
    apply_time_ms: 3.184
    dispatch_time_ms: 9.461
    learner:
      cur_lr: 0.0013255012454465032
      grad_gnorm: 40.000003814697266
      policy_entropy: 4.90535831451416
      policy_loss: 4.616585731506348
      var_gnorm: 30.312793731689453
      vf_explained_var: 0.0
      vf_loss: 30.141141891479492
    num_steps_sampled: 520000
    num_steps_trained: 520000
    wait_time_ms: 32.563
  iterations_since_restore: 289
  node_ip: 172.17.8.48
  num_metric_batches_dropped: 0
  pid: 20453
  policy_reward_mean: {}
  time_since_restore: 2416.5510091781616
  time_this_iter_s: 8.36524224281311
  time_total_s: 2416.5510091781616
  timestamp: 1593996415
  timesteps_since_restore: 520000
  timesteps_this_iter: 2000
  timesteps_total: 520000
  training_iteration: 289
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=20453], 2416 s, 289 iter, 520000 ts, 130 rew

agent-1: 129.0
Sum Reward: 129.0
Avg Reward: 129.0
Min Reward: 129.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
agent-1: 145.0
Sum Reward: 145.0
Avg Reward: 145.0
Min Reward: 145.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-47-04
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 197.0
  episode_reward_mean: 130.55
  episode_reward_min: 67.0
  episodes_this_iter: 2
  episodes_total: 521
  experiment_id: 325b24caee6c4209bf8cf01af4f33e4d
  hostname: gpu048
  info:
    apply_time_ms: 3.737
    dispatch_time_ms: 6.459
    learner:
      cur_lr: 0.0013253679499030113
      grad_gnorm: 39.999996185302734
      policy_entropy: 3.117234706878662
      policy_loss: 2.0338134765625
      var_gnorm: 30.35011100769043
      vf_explained_var: 0.0
      vf_loss: 33.11030960083008
    num_steps_sampled: 522000
    num_steps_trained: 522000
    wait_time_ms: 31.571
  iterations_since_restore: 290
  node_ip: 172.17.8.48
  num_metric_batches_dropped: 0
  pid: 20453
  policy_reward_mean: {}
  time_since_restore: 2424.892642736435
  time_this_iter_s: 8.341633558273315
  time_total_s: 2424.892642736435
  timestamp: 1593996424
  timesteps_since_restore: 522000
  timesteps_this_iter: 2000
  timesteps_total: 522000
  training_iteration: 290
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=20453], 2424 s, 290 iter, 522000 ts, 131 rew

agent-1: 143.0
Sum Reward: 143.0
Avg Reward: 143.0
Min Reward: 143.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
agent-1: 110.0
Sum Reward: 110.0
Avg Reward: 110.0
Min Reward: 110.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-47-12
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 197.0
  episode_reward_mean: 130.24
  episode_reward_min: 67.0
  episodes_this_iter: 2
  episodes_total: 523
  experiment_id: 325b24caee6c4209bf8cf01af4f33e4d
  hostname: gpu048
  info:
    apply_time_ms: 3.051
    dispatch_time_ms: 8.583
    learner:
      cur_lr: 0.0013252347707748413
      grad_gnorm: 21.707319259643555
      policy_entropy: 4.221858024597168
      policy_loss: 2.6375479698181152
      var_gnorm: 30.353179931640625
      vf_explained_var: 0.0
      vf_loss: 4.426993370056152
    num_steps_sampled: 524000
    num_steps_trained: 524000
    wait_time_ms: 29.883
  iterations_since_restore: 291
  node_ip: 172.17.8.48
  num_metric_batches_dropped: 0
  pid: 20453
  policy_reward_mean: {}
  time_since_restore: 2433.2907013893127
  time_this_iter_s: 8.398058652877808
  time_total_s: 2433.2907013893127
  timestamp: 1593996432
  timesteps_since_restore: 524000
  timesteps_this_iter: 2000
  timesteps_total: 524000
  training_iteration: 291
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=20453], 2433 s, 291 iter, 524000 ts, 130 rew

agent-1: 150.0
Sum Reward: 150.0
Avg Reward: 150.0
Min Reward: 150.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-47-27
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 197.0
  episode_reward_mean: 130.09
  episode_reward_min: 67.0
  episodes_this_iter: 1
  episodes_total: 524
  experiment_id: 325b24caee6c4209bf8cf01af4f33e4d
  hostname: gpu048
  info:
    apply_time_ms: 3.362
    dispatch_time_ms: 1108.407
    learner:
      cur_lr: 0.0013251015916466713
      grad_gnorm: 18.79670524597168
      policy_entropy: 2.2183213233947754
      policy_loss: -1.2342803478240967
      var_gnorm: 30.355247497558594
      vf_explained_var: 0.0
      vf_loss: 2.2311618328094482
    num_steps_sampled: 525000
    num_steps_trained: 525000
    wait_time_ms: 51.251
  iterations_since_restore: 292
  node_ip: 172.17.8.48
  num_metric_batches_dropped: 0
  pid: 20453
  policy_reward_mean: {}
  time_since_restore: 2448.630663394928
  time_this_iter_s: 15.339962005615234
  time_total_s: 2448.630663394928
  timestamp: 1593996447
  timesteps_since_restore: 525000
  timesteps_this_iter: 1000
  timesteps_total: 525000
  training_iteration: 292
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=20453], 2448 s, 292 iter, 525000 ts, 130 rew

agent-1: 130.0
Sum Reward: 130.0
Avg Reward: 130.0
Min Reward: 130.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
agent-1: 134.0
Sum Reward: 134.0
Avg Reward: 134.0
Min Reward: 134.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-47-38
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 197.0
  episode_reward_mean: 129.75
  episode_reward_min: 67.0
  episodes_this_iter: 2
  episodes_total: 526
  experiment_id: 325b24caee6c4209bf8cf01af4f33e4d
  hostname: gpu048
  info:
    apply_time_ms: 2.159
    dispatch_time_ms: 44.885
    learner:
      cur_lr: 0.0013250350020825863
      grad_gnorm: 21.40338134765625
      policy_entropy: 4.08779239654541
      policy_loss: -2.83182692527771
      var_gnorm: 30.37001609802246
      vf_explained_var: 0.0
      vf_loss: 2.5905532836914062
    num_steps_sampled: 527000
    num_steps_trained: 527000
    wait_time_ms: 28.223
  iterations_since_restore: 293
  node_ip: 172.17.8.48
  num_metric_batches_dropped: 0
  pid: 20453
  policy_reward_mean: {}
  time_since_restore: 2459.0221829414368
  time_this_iter_s: 10.391519546508789
  time_total_s: 2459.0221829414368
  timestamp: 1593996458
  timesteps_since_restore: 527000
  timesteps_this_iter: 2000
  timesteps_total: 527000
  training_iteration: 293
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=20453], 2459 s, 293 iter, 527000 ts, 130 rew

agent-1: 152.0
Sum Reward: 152.0
Avg Reward: 152.0
Min Reward: 152.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-47-45
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 197.0
  episode_reward_mean: 130.07
  episode_reward_min: 67.0
  episodes_this_iter: 1
  episodes_total: 527
  experiment_id: 325b24caee6c4209bf8cf01af4f33e4d
  hostname: gpu048
  info:
    apply_time_ms: 3.009
    dispatch_time_ms: 35.786
    learner:
      cur_lr: 0.0013249018229544163
      grad_gnorm: 40.000003814697266
      policy_entropy: 2.0369467735290527
      policy_loss: 0.9811719059944153
      var_gnorm: 30.362571716308594
      vf_explained_var: 0.0
      vf_loss: 28.85450553894043
    num_steps_sampled: 528000
    num_steps_trained: 528000
    wait_time_ms: 33.898
  iterations_since_restore: 294
  node_ip: 172.17.8.48
  num_metric_batches_dropped: 0
  pid: 20453
  policy_reward_mean: {}
  time_since_restore: 2465.9838728904724
  time_this_iter_s: 6.9616899490356445
  time_total_s: 2465.9838728904724
  timestamp: 1593996465
  timesteps_since_restore: 528000
  timesteps_this_iter: 1000
  timesteps_total: 528000
  training_iteration: 294
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=20453], 2465 s, 294 iter, 528000 ts, 130 rew

agent-1: 122.0
Sum Reward: 122.0
Avg Reward: 122.0
Min Reward: 122.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-47-51
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 197.0
  episode_reward_mean: 129.82
  episode_reward_min: 67.0
  episodes_this_iter: 1
  episodes_total: 528
  experiment_id: 325b24caee6c4209bf8cf01af4f33e4d
  hostname: gpu048
  info:
    apply_time_ms: 2.761
    dispatch_time_ms: 28.876
    learner:
      cur_lr: 0.0013248352333903313
      grad_gnorm: 22.892305374145508
      policy_entropy: 4.1826171875
      policy_loss: -1.5449397563934326
      var_gnorm: 30.377107620239258
      vf_explained_var: 0.0
      vf_loss: 3.0582969188690186
    num_steps_sampled: 529000
    num_steps_trained: 529000
    wait_time_ms: 24.575
  iterations_since_restore: 295
  node_ip: 172.17.8.48
  num_metric_batches_dropped: 0
  pid: 20453
  policy_reward_mean: {}
  time_since_restore: 2471.7261962890625
  time_this_iter_s: 5.742323398590088
  time_total_s: 2471.7261962890625
  timestamp: 1593996471
  timesteps_since_restore: 529000
  timesteps_this_iter: 1000
  timesteps_total: 529000
  training_iteration: 295
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=20453], 2471 s, 295 iter, 529000 ts, 130 rew

agent-1: 143.0
Sum Reward: 143.0
Avg Reward: 143.0
Min Reward: 143.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-47-57
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 197.0
  episode_reward_mean: 130.28
  episode_reward_min: 67.0
  episodes_this_iter: 1
  episodes_total: 529
  experiment_id: 325b24caee6c4209bf8cf01af4f33e4d
  hostname: gpu048
  info:
    apply_time_ms: 2.964
    dispatch_time_ms: 29.151
    learner:
      cur_lr: 0.0013247686438262463
      grad_gnorm: 20.37911605834961
      policy_entropy: 3.6787638664245605
      policy_loss: -2.5217578411102295
      var_gnorm: 30.372657775878906
      vf_explained_var: 5.960464477539063e-08
      vf_loss: 2.587273597717285
    num_steps_sampled: 530000
    num_steps_trained: 530000
    wait_time_ms: 22.025
  iterations_since_restore: 296
  node_ip: 172.17.8.48
  num_metric_batches_dropped: 0
  pid: 20453
  policy_reward_mean: {}
  time_since_restore: 2477.6028106212616
  time_this_iter_s: 5.876614332199097
  time_total_s: 2477.6028106212616
  timestamp: 1593996477
  timesteps_since_restore: 530000
  timesteps_this_iter: 1000
  timesteps_total: 530000
  training_iteration: 296
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=20453], 2477 s, 296 iter, 530000 ts, 130 rew

agent-1: 125.0
Sum Reward: 125.0
Avg Reward: 125.0
Min Reward: 125.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-48-02
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 197.0
  episode_reward_mean: 130.14
  episode_reward_min: 67.0
  episodes_this_iter: 1
  episodes_total: 530
  experiment_id: 325b24caee6c4209bf8cf01af4f33e4d
  hostname: gpu048
  info:
    apply_time_ms: 2.95
    dispatch_time_ms: 43.458
    learner:
      cur_lr: 0.0013247020542621613
      grad_gnorm: 14.877060890197754
      policy_entropy: 1.7476739883422852
      policy_loss: -0.5971677899360657
      var_gnorm: 30.36211585998535
      vf_explained_var: 5.960464477539063e-08
      vf_loss: 1.5605956315994263
    num_steps_sampled: 531000
    num_steps_trained: 531000
    wait_time_ms: 16.575
  iterations_since_restore: 297
  node_ip: 172.17.8.48
  num_metric_batches_dropped: 0
  pid: 20453
  policy_reward_mean: {}
  time_since_restore: 2483.167179584503
  time_this_iter_s: 5.564368963241577
  time_total_s: 2483.167179584503
  timestamp: 1593996482
  timesteps_since_restore: 531000
  timesteps_this_iter: 1000
  timesteps_total: 531000
  training_iteration: 297
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=20453], 2483 s, 297 iter, 531000 ts, 130 rew

agent-1: 109.0
Sum Reward: 109.0
Avg Reward: 109.0
Min Reward: 109.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-48-08
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 197.0
  episode_reward_mean: 130.12
  episode_reward_min: 67.0
  episodes_this_iter: 1
  episodes_total: 531
  experiment_id: 325b24caee6c4209bf8cf01af4f33e4d
  hostname: gpu048
  info:
    apply_time_ms: 2.635
    dispatch_time_ms: 31.267
    learner:
      cur_lr: 0.0013246353482827544
      grad_gnorm: 15.73604965209961
      policy_entropy: 2.329131603240967
      policy_loss: -0.3514057397842407
      var_gnorm: 30.35431480407715
      vf_explained_var: 0.0
      vf_loss: 1.6108686923980713
    num_steps_sampled: 532000
    num_steps_trained: 532000
    wait_time_ms: 23.343
  iterations_since_restore: 298
  node_ip: 172.17.8.48
  num_metric_batches_dropped: 0
  pid: 20453
  policy_reward_mean: {}
  time_since_restore: 2488.838011264801
  time_this_iter_s: 5.670831680297852
  time_total_s: 2488.838011264801
  timestamp: 1593996488
  timesteps_since_restore: 532000
  timesteps_this_iter: 1000
  timesteps_total: 532000
  training_iteration: 298
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=20453], 2488 s, 298 iter, 532000 ts, 130 rew

agent-1: 87.0
Sum Reward: 87.0
Avg Reward: 87.0
Min Reward: 87.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-48-13
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 197.0
  episode_reward_mean: 129.22
  episode_reward_min: 67.0
  episodes_this_iter: 1
  episodes_total: 532
  experiment_id: 325b24caee6c4209bf8cf01af4f33e4d
  hostname: gpu048
  info:
    apply_time_ms: 3.18
    dispatch_time_ms: 30.929
    learner:
      cur_lr: 0.0013245687587186694
      grad_gnorm: 9.53316879272461
      policy_entropy: 2.8888299465179443
      policy_loss: 0.37399938702583313
      var_gnorm: 30.350217819213867
      vf_explained_var: 0.0
      vf_loss: 0.8874743580818176
    num_steps_sampled: 533000
    num_steps_trained: 533000
    wait_time_ms: 17.087
  iterations_since_restore: 299
  node_ip: 172.17.8.48
  num_metric_batches_dropped: 0
  pid: 20453
  policy_reward_mean: {}
  time_since_restore: 2494.417027235031
  time_this_iter_s: 5.5790159702301025
  time_total_s: 2494.417027235031
  timestamp: 1593996493
  timesteps_since_restore: 533000
  timesteps_this_iter: 1000
  timesteps_total: 533000
  training_iteration: 299
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=20453], 2494 s, 299 iter, 533000 ts, 129 rew

agent-1: 126.0
Sum Reward: 126.0
Avg Reward: 126.0
Min Reward: 126.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-48-19
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 197.0
  episode_reward_mean: 129.44
  episode_reward_min: 67.0
  episodes_this_iter: 1
  episodes_total: 533
  experiment_id: 325b24caee6c4209bf8cf01af4f33e4d
  hostname: gpu048
  info:
    apply_time_ms: 3.182
    dispatch_time_ms: 32.686
    learner:
      cur_lr: 0.0013245021691545844
      grad_gnorm: 29.65877914428711
      policy_entropy: 4.980824947357178
      policy_loss: 5.0672101974487305
      var_gnorm: 30.357038497924805
      vf_explained_var: 0.0
      vf_loss: 5.530322551727295
    num_steps_sampled: 534000
    num_steps_trained: 534000
    wait_time_ms: 22.888
  iterations_since_restore: 300
  node_ip: 172.17.8.48
  num_metric_batches_dropped: 0
  pid: 20453
  policy_reward_mean: {}
  time_since_restore: 2500.1650240421295
  time_this_iter_s: 5.747996807098389
  time_total_s: 2500.1650240421295
  timestamp: 1593996499
  timesteps_since_restore: 534000
  timesteps_this_iter: 1000
  timesteps_total: 534000
  training_iteration: 300
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=20453], 2500 s, 300 iter, 534000 ts, 129 rew

agent-1: 151.0
Sum Reward: 151.0
Avg Reward: 151.0
Min Reward: 151.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-48-25
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 197.0
  episode_reward_mean: 129.72
  episode_reward_min: 67.0
  episodes_this_iter: 1
  episodes_total: 534
  experiment_id: 325b24caee6c4209bf8cf01af4f33e4d
  hostname: gpu048
  info:
    apply_time_ms: 2.616
    dispatch_time_ms: 25.416
    learner:
      cur_lr: 0.0013244355795904994
      grad_gnorm: 40.0
      policy_entropy: 3.231989860534668
      policy_loss: 6.190298557281494
      var_gnorm: 30.360980987548828
      vf_explained_var: 0.0
      vf_loss: 13.818113327026367
    num_steps_sampled: 535000
    num_steps_trained: 535000
    wait_time_ms: 23.808
  iterations_since_restore: 301
  node_ip: 172.17.8.48
  num_metric_batches_dropped: 0
  pid: 20453
  policy_reward_mean: {}
  time_since_restore: 2506.1032090187073
  time_this_iter_s: 5.938184976577759
  time_total_s: 2506.1032090187073
  timestamp: 1593996505
  timesteps_since_restore: 535000
  timesteps_this_iter: 1000
  timesteps_total: 535000
  training_iteration: 301
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=20453], 2506 s, 301 iter, 535000 ts, 130 rew

agent-1: 143.0
Sum Reward: 143.0
Avg Reward: 143.0
Min Reward: 143.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-48-31
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 197.0
  episode_reward_mean: 129.76
  episode_reward_min: 67.0
  episodes_this_iter: 1
  episodes_total: 535
  experiment_id: 325b24caee6c4209bf8cf01af4f33e4d
  hostname: gpu048
  info:
    apply_time_ms: 3.071
    dispatch_time_ms: 33.837
    learner:
      cur_lr: 0.0013243689900264144
      grad_gnorm: 13.899774551391602
      policy_entropy: 3.1511693000793457
      policy_loss: 2.1758198738098145
      var_gnorm: 30.365739822387695
      vf_explained_var: 0.0
      vf_loss: 1.4055216312408447
    num_steps_sampled: 536000
    num_steps_trained: 536000
    wait_time_ms: 37.078
  iterations_since_restore: 302
  node_ip: 172.17.8.48
  num_metric_batches_dropped: 0
  pid: 20453
  policy_reward_mean: {}
  time_since_restore: 2512.290426969528
  time_this_iter_s: 6.187217950820923
  time_total_s: 2512.290426969528
  timestamp: 1593996511
  timesteps_since_restore: 536000
  timesteps_this_iter: 1000
  timesteps_total: 536000
  training_iteration: 302
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=20453], 2512 s, 302 iter, 536000 ts, 130 rew

agent-1: 146.0
Sum Reward: 146.0
Avg Reward: 146.0
Min Reward: 146.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-48-37
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 197.0
  episode_reward_mean: 129.64
  episode_reward_min: 67.0
  episodes_this_iter: 1
  episodes_total: 536
  experiment_id: 325b24caee6c4209bf8cf01af4f33e4d
  hostname: gpu048
  info:
    apply_time_ms: 4.558
    dispatch_time_ms: 26.862
    learner:
      cur_lr: 0.0013243024004623294
      grad_gnorm: 12.245722770690918
      policy_entropy: 2.6968228816986084
      policy_loss: -0.4194377064704895
      var_gnorm: 30.355728149414062
      vf_explained_var: 0.0
      vf_loss: 1.063992977142334
    num_steps_sampled: 537000
    num_steps_trained: 537000
    wait_time_ms: 9.36
  iterations_since_restore: 303
  node_ip: 172.17.8.48
  num_metric_batches_dropped: 0
  pid: 20453
  policy_reward_mean: {}
  time_since_restore: 2518.0507023334503
  time_this_iter_s: 5.760275363922119
  time_total_s: 2518.0507023334503
  timestamp: 1593996517
  timesteps_since_restore: 537000
  timesteps_this_iter: 1000
  timesteps_total: 537000
  training_iteration: 303
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=20453], 2518 s, 303 iter, 537000 ts, 130 rew

agent-1: 63.0
Sum Reward: 63.0
Avg Reward: 63.0
Min Reward: 63.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-48-43
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 197.0
  episode_reward_mean: 128.99
  episode_reward_min: 63.0
  episodes_this_iter: 1
  episodes_total: 537
  experiment_id: 325b24caee6c4209bf8cf01af4f33e4d
  hostname: gpu048
  info:
    apply_time_ms: 3.016
    dispatch_time_ms: 35.545
    learner:
      cur_lr: 0.0013242358108982444
      grad_gnorm: 40.000003814697266
      policy_entropy: 2.4212708473205566
      policy_loss: 15.866593360900879
      var_gnorm: 30.366430282592773
      vf_explained_var: 0.0
      vf_loss: 36.21652603149414
    num_steps_sampled: 538000
    num_steps_trained: 538000
    wait_time_ms: 18.132
  iterations_since_restore: 304
  node_ip: 172.17.8.48
  num_metric_batches_dropped: 0
  pid: 20453
  policy_reward_mean: {}
  time_since_restore: 2523.667338371277
  time_this_iter_s: 5.616636037826538
  time_total_s: 2523.667338371277
  timestamp: 1593996523
  timesteps_since_restore: 538000
  timesteps_this_iter: 1000
  timesteps_total: 538000
  training_iteration: 304
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=20453], 2523 s, 304 iter, 538000 ts, 129 rew

agent-1: 111.0
Sum Reward: 111.0
Avg Reward: 111.0
Min Reward: 111.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-48-48
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 197.0
  episode_reward_mean: 128.79
  episode_reward_min: 63.0
  episodes_this_iter: 1
  episodes_total: 538
  experiment_id: 325b24caee6c4209bf8cf01af4f33e4d
  hostname: gpu048
  info:
    apply_time_ms: 3.064
    dispatch_time_ms: 34.638
    learner:
      cur_lr: 0.0013241692213341594
      grad_gnorm: 18.270153045654297
      policy_entropy: 2.374096393585205
      policy_loss: -0.3529388904571533
      var_gnorm: 30.36691665649414
      vf_explained_var: 0.0
      vf_loss: 2.0277535915374756
    num_steps_sampled: 539000
    num_steps_trained: 539000
    wait_time_ms: 13.565
  iterations_since_restore: 305
  node_ip: 172.17.8.48
  num_metric_batches_dropped: 0
  pid: 20453
  policy_reward_mean: {}
  time_since_restore: 2529.260840654373
  time_this_iter_s: 5.5935022830963135
  time_total_s: 2529.260840654373
  timestamp: 1593996528
  timesteps_since_restore: 539000
  timesteps_this_iter: 1000
  timesteps_total: 539000
  training_iteration: 305
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=20453], 2529 s, 305 iter, 539000 ts, 129 rew

agent-1: 153.0
Sum Reward: 153.0
Avg Reward: 153.0
Min Reward: 153.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-48-54
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 197.0
  episode_reward_mean: 129.23
  episode_reward_min: 63.0
  episodes_this_iter: 1
  episodes_total: 539
  experiment_id: 325b24caee6c4209bf8cf01af4f33e4d
  hostname: gpu048
  info:
    apply_time_ms: 4.862
    dispatch_time_ms: 33.29
    learner:
      cur_lr: 0.0013241026317700744
      grad_gnorm: 13.886565208435059
      policy_entropy: 3.510343551635742
      policy_loss: -2.7459921836853027
      var_gnorm: 30.3555908203125
      vf_explained_var: 0.0
      vf_loss: 1.2427362203598022
    num_steps_sampled: 540000
    num_steps_trained: 540000
    wait_time_ms: 21.72
  iterations_since_restore: 306
  node_ip: 172.17.8.48
  num_metric_batches_dropped: 0
  pid: 20453
  policy_reward_mean: {}
  time_since_restore: 2534.9926838874817
  time_this_iter_s: 5.7318432331085205
  time_total_s: 2534.9926838874817
  timestamp: 1593996534
  timesteps_since_restore: 540000
  timesteps_this_iter: 1000
  timesteps_total: 540000
  training_iteration: 306
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=20453], 2534 s, 306 iter, 540000 ts, 129 rew

agent-1: 90.0
Sum Reward: 90.0
Avg Reward: 90.0
Min Reward: 90.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-49-00
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 197.0
  episode_reward_mean: 128.68
  episode_reward_min: 63.0
  episodes_this_iter: 1
  episodes_total: 540
  experiment_id: 325b24caee6c4209bf8cf01af4f33e4d
  hostname: gpu048
  info:
    apply_time_ms: 3.418
    dispatch_time_ms: 49.895
    learner:
      cur_lr: 0.0013240360422059894
      grad_gnorm: 21.564884185791016
      policy_entropy: 3.6470329761505127
      policy_loss: 2.0736494064331055
      var_gnorm: 30.345144271850586
      vf_explained_var: 0.0
      vf_loss: 2.7707056999206543
    num_steps_sampled: 541000
    num_steps_trained: 541000
    wait_time_ms: 12.904
  iterations_since_restore: 307
  node_ip: 172.17.8.48
  num_metric_batches_dropped: 0
  pid: 20453
  policy_reward_mean: {}
  time_since_restore: 2541.1225142478943
  time_this_iter_s: 6.129830360412598
  time_total_s: 2541.1225142478943
  timestamp: 1593996540
  timesteps_since_restore: 541000
  timesteps_this_iter: 1000
  timesteps_total: 541000
  training_iteration: 307
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=20453], 2541 s, 307 iter, 541000 ts, 129 rew

agent-1: 111.0
Sum Reward: 111.0
Avg Reward: 111.0
Min Reward: 111.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-49-06
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 197.0
  episode_reward_mean: 128.4
  episode_reward_min: 63.0
  episodes_this_iter: 1
  episodes_total: 541
  experiment_id: 325b24caee6c4209bf8cf01af4f33e4d
  hostname: gpu048
  info:
    apply_time_ms: 3.771
    dispatch_time_ms: 39.992
    learner:
      cur_lr: 0.0013239694526419044
      grad_gnorm: 16.960235595703125
      policy_entropy: 4.813231945037842
      policy_loss: 4.066845893859863
      var_gnorm: 30.365400314331055
      vf_explained_var: 0.0
      vf_loss: 1.938306212425232
    num_steps_sampled: 542000
    num_steps_trained: 542000
    wait_time_ms: 19.689
  iterations_since_restore: 308
  node_ip: 172.17.8.48
  num_metric_batches_dropped: 0
  pid: 20453
  policy_reward_mean: {}
  time_since_restore: 2546.5917320251465
  time_this_iter_s: 5.469217777252197
  time_total_s: 2546.5917320251465
  timestamp: 1593996546
  timesteps_since_restore: 542000
  timesteps_this_iter: 1000
  timesteps_total: 542000
  training_iteration: 308
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=20453], 2546 s, 308 iter, 542000 ts, 128 rew

agent-1: 148.0
Sum Reward: 148.0
Avg Reward: 148.0
Min Reward: 148.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-49-11
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 197.0
  episode_reward_mean: 128.59
  episode_reward_min: 63.0
  episodes_this_iter: 1
  episodes_total: 542
  experiment_id: 325b24caee6c4209bf8cf01af4f33e4d
  hostname: gpu048
  info:
    apply_time_ms: 3.121
    dispatch_time_ms: 32.856
    learner:
      cur_lr: 0.0013239027466624975
      grad_gnorm: 23.59805679321289
      policy_entropy: 2.3217620849609375
      policy_loss: -0.6547983884811401
      var_gnorm: 30.387800216674805
      vf_explained_var: 0.0
      vf_loss: 3.2369813919067383
    num_steps_sampled: 543000
    num_steps_trained: 543000
    wait_time_ms: 22.767
  iterations_since_restore: 309
  node_ip: 172.17.8.48
  num_metric_batches_dropped: 0
  pid: 20453
  policy_reward_mean: {}
  time_since_restore: 2552.160255432129
  time_this_iter_s: 5.568523406982422
  time_total_s: 2552.160255432129
  timestamp: 1593996551
  timesteps_since_restore: 543000
  timesteps_this_iter: 1000
  timesteps_total: 543000
  training_iteration: 309
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=20453], 2552 s, 309 iter, 543000 ts, 129 rew

agent-1: 146.0
Sum Reward: 146.0
Avg Reward: 146.0
Min Reward: 146.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-49-17
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 197.0
  episode_reward_mean: 128.71
  episode_reward_min: 63.0
  episodes_this_iter: 1
  episodes_total: 543
  experiment_id: 325b24caee6c4209bf8cf01af4f33e4d
  hostname: gpu048
  info:
    apply_time_ms: 3.467
    dispatch_time_ms: 44.712
    learner:
      cur_lr: 0.0013238361570984125
      grad_gnorm: 18.607177734375
      policy_entropy: 1.5789518356323242
      policy_loss: -0.6008248925209045
      var_gnorm: 30.39537811279297
      vf_explained_var: 0.0
      vf_loss: 2.218059778213501
    num_steps_sampled: 544000
    num_steps_trained: 544000
    wait_time_ms: 18.864
  iterations_since_restore: 310
  node_ip: 172.17.8.48
  num_metric_batches_dropped: 0
  pid: 20453
  policy_reward_mean: {}
  time_since_restore: 2557.820102930069
  time_this_iter_s: 5.6598474979400635
  time_total_s: 2557.820102930069
  timestamp: 1593996557
  timesteps_since_restore: 544000
  timesteps_this_iter: 1000
  timesteps_total: 544000
  training_iteration: 310
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=20453], 2557 s, 310 iter, 544000 ts, 129 rew

agent-1: 148.0
Sum Reward: 148.0
Avg Reward: 148.0
Min Reward: 148.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-49-23
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 197.0
  episode_reward_mean: 128.81
  episode_reward_min: 63.0
  episodes_this_iter: 1
  episodes_total: 544
  experiment_id: 325b24caee6c4209bf8cf01af4f33e4d
  hostname: gpu048
  info:
    apply_time_ms: 2.819
    dispatch_time_ms: 46.029
    learner:
      cur_lr: 0.0013237695675343275
      grad_gnorm: 16.624492645263672
      policy_entropy: 2.4065444469451904
      policy_loss: -0.3834545910358429
      var_gnorm: 30.386539459228516
      vf_explained_var: 0.0
      vf_loss: 1.774407148361206
    num_steps_sampled: 545000
    num_steps_trained: 545000
    wait_time_ms: 23.299
  iterations_since_restore: 311
  node_ip: 172.17.8.48
  num_metric_batches_dropped: 0
  pid: 20453
  policy_reward_mean: {}
  time_since_restore: 2563.696452140808
  time_this_iter_s: 5.876349210739136
  time_total_s: 2563.696452140808
  timestamp: 1593996563
  timesteps_since_restore: 545000
  timesteps_this_iter: 1000
  timesteps_total: 545000
  training_iteration: 311
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=20453], 2563 s, 311 iter, 545000 ts, 129 rew

agent-1: 111.0
Sum Reward: 111.0
Avg Reward: 111.0
Min Reward: 111.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-49-29
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 197.0
  episode_reward_mean: 128.69
  episode_reward_min: 63.0
  episodes_this_iter: 1
  episodes_total: 545
  experiment_id: 325b24caee6c4209bf8cf01af4f33e4d
  hostname: gpu048
  info:
    apply_time_ms: 2.801
    dispatch_time_ms: 49.327
    learner:
      cur_lr: 0.0013237029779702425
      grad_gnorm: 16.21048927307129
      policy_entropy: 1.4091415405273438
      policy_loss: -0.17057128250598907
      var_gnorm: 30.376144409179688
      vf_explained_var: 1.1920928955078125e-07
      vf_loss: 1.6919597387313843
    num_steps_sampled: 546000
    num_steps_trained: 546000
    wait_time_ms: 19.211
  iterations_since_restore: 312
  node_ip: 172.17.8.48
  num_metric_batches_dropped: 0
  pid: 20453
  policy_reward_mean: {}
  time_since_restore: 2569.6283831596375
  time_this_iter_s: 5.931931018829346
  time_total_s: 2569.6283831596375
  timestamp: 1593996569
  timesteps_since_restore: 546000
  timesteps_this_iter: 1000
  timesteps_total: 546000
  training_iteration: 312
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=20453], 2569 s, 312 iter, 546000 ts, 129 rew

agent-1: 81.0
Sum Reward: 81.0
Avg Reward: 81.0
Min Reward: 81.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-49-35
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 197.0
  episode_reward_mean: 127.69
  episode_reward_min: 63.0
  episodes_this_iter: 1
  episodes_total: 546
  experiment_id: 325b24caee6c4209bf8cf01af4f33e4d
  hostname: gpu048
  info:
    apply_time_ms: 3.426
    dispatch_time_ms: 40.499
    learner:
      cur_lr: 0.0013236363884061575
      grad_gnorm: 16.300764083862305
      policy_entropy: 4.899693012237549
      policy_loss: -2.0863637924194336
      var_gnorm: 30.362632751464844
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 1.6513962745666504
    num_steps_sampled: 547000
    num_steps_trained: 547000
    wait_time_ms: 20.765
  iterations_since_restore: 313
  node_ip: 172.17.8.48
  num_metric_batches_dropped: 0
  pid: 20453
  policy_reward_mean: {}
  time_since_restore: 2575.714444875717
  time_this_iter_s: 6.086061716079712
  time_total_s: 2575.714444875717
  timestamp: 1593996575
  timesteps_since_restore: 547000
  timesteps_this_iter: 1000
  timesteps_total: 547000
  training_iteration: 313
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=20453], 2575 s, 313 iter, 547000 ts, 128 rew

agent-1: 113.0
Sum Reward: 113.0
Avg Reward: 113.0
Min Reward: 113.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-49-41
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 197.0
  episode_reward_mean: 127.46
  episode_reward_min: 63.0
  episodes_this_iter: 1
  episodes_total: 547
  experiment_id: 325b24caee6c4209bf8cf01af4f33e4d
  hostname: gpu048
  info:
    apply_time_ms: 2.74
    dispatch_time_ms: 30.803
    learner:
      cur_lr: 0.0013235697988420725
      grad_gnorm: 26.4166316986084
      policy_entropy: 4.617549896240234
      policy_loss: -3.5377197265625
      var_gnorm: 30.383695602416992
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 3.7127373218536377
    num_steps_sampled: 548000
    num_steps_trained: 548000
    wait_time_ms: 13.26
  iterations_since_restore: 314
  node_ip: 172.17.8.48
  num_metric_batches_dropped: 0
  pid: 20453
  policy_reward_mean: {}
  time_since_restore: 2581.522276878357
  time_this_iter_s: 5.8078320026397705
  time_total_s: 2581.522276878357
  timestamp: 1593996581
  timesteps_since_restore: 548000
  timesteps_this_iter: 1000
  timesteps_total: 548000
  training_iteration: 314
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=20453], 2581 s, 314 iter, 548000 ts, 127 rew

agent-1: 121.0
Sum Reward: 121.0
Avg Reward: 121.0
Min Reward: 121.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-49-47
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 197.0
  episode_reward_mean: 127.2
  episode_reward_min: 63.0
  episodes_this_iter: 1
  episodes_total: 548
  experiment_id: 325b24caee6c4209bf8cf01af4f33e4d
  hostname: gpu048
  info:
    apply_time_ms: 3.496
    dispatch_time_ms: 27.004
    learner:
      cur_lr: 0.0013235032092779875
      grad_gnorm: 21.75642967224121
      policy_entropy: 2.8802812099456787
      policy_loss: -0.47096794843673706
      var_gnorm: 30.3870849609375
      vf_explained_var: 0.0
      vf_loss: 2.707503080368042
    num_steps_sampled: 549000
    num_steps_trained: 549000
    wait_time_ms: 16.589
  iterations_since_restore: 315
  node_ip: 172.17.8.48
  num_metric_batches_dropped: 0
  pid: 20453
  policy_reward_mean: {}
  time_since_restore: 2587.5774190425873
  time_this_iter_s: 6.055142164230347
  time_total_s: 2587.5774190425873
  timestamp: 1593996587
  timesteps_since_restore: 549000
  timesteps_this_iter: 1000
  timesteps_total: 549000
  training_iteration: 315
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=20453], 2587 s, 315 iter, 549000 ts, 127 rew

agent-1: 139.0
Sum Reward: 139.0
Avg Reward: 139.0
Min Reward: 139.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-49-53
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 197.0
  episode_reward_mean: 127.64
  episode_reward_min: 63.0
  episodes_this_iter: 1
  episodes_total: 549
  experiment_id: 325b24caee6c4209bf8cf01af4f33e4d
  hostname: gpu048
  info:
    apply_time_ms: 2.917
    dispatch_time_ms: 44.715
    learner:
      cur_lr: 0.0013234366197139025
      grad_gnorm: 11.478660583496094
      policy_entropy: 5.830719470977783
      policy_loss: -3.893223524093628
      var_gnorm: 30.374441146850586
      vf_explained_var: 0.0
      vf_loss: 0.7276162505149841
    num_steps_sampled: 550000
    num_steps_trained: 550000
    wait_time_ms: 17.525
  iterations_since_restore: 316
  node_ip: 172.17.8.48
  num_metric_batches_dropped: 0
  pid: 20453
  policy_reward_mean: {}
  time_since_restore: 2593.544246196747
  time_this_iter_s: 5.966827154159546
  time_total_s: 2593.544246196747
  timestamp: 1593996593
  timesteps_since_restore: 550000
  timesteps_this_iter: 1000
  timesteps_total: 550000
  training_iteration: 316
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=20453], 2593 s, 316 iter, 550000 ts, 128 rew

agent-1: 119.0
Sum Reward: 119.0
Avg Reward: 119.0
Min Reward: 119.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-49-59
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 197.0
  episode_reward_mean: 127.34
  episode_reward_min: 63.0
  episodes_this_iter: 1
  episodes_total: 550
  experiment_id: 325b24caee6c4209bf8cf01af4f33e4d
  hostname: gpu048
  info:
    apply_time_ms: 3.261
    dispatch_time_ms: 40.28
    learner:
      cur_lr: 0.0013233700301498175
      grad_gnorm: 40.0
      policy_entropy: 3.6892290115356445
      policy_loss: 1.8359240293502808
      var_gnorm: 30.391260147094727
      vf_explained_var: 5.960464477539063e-08
      vf_loss: 23.63113784790039
    num_steps_sampled: 551000
    num_steps_trained: 551000
    wait_time_ms: 19.807
  iterations_since_restore: 317
  node_ip: 172.17.8.48
  num_metric_batches_dropped: 0
  pid: 20453
  policy_reward_mean: {}
  time_since_restore: 2599.642711877823
  time_this_iter_s: 6.09846568107605
  time_total_s: 2599.642711877823
  timestamp: 1593996599
  timesteps_since_restore: 551000
  timesteps_this_iter: 1000
  timesteps_total: 551000
  training_iteration: 317
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=20453], 2599 s, 317 iter, 551000 ts, 127 rew

agent-1: 136.0
Sum Reward: 136.0
Avg Reward: 136.0
Min Reward: 136.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-50-05
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 197.0
  episode_reward_mean: 127.52
  episode_reward_min: 63.0
  episodes_this_iter: 1
  episodes_total: 551
  experiment_id: 325b24caee6c4209bf8cf01af4f33e4d
  hostname: gpu048
  info:
    apply_time_ms: 3.447
    dispatch_time_ms: 37.536
    learner:
      cur_lr: 0.0013233034405857325
      grad_gnorm: 15.969374656677246
      policy_entropy: 3.4482173919677734
      policy_loss: -2.3594682216644287
      var_gnorm: 30.398834228515625
      vf_explained_var: 1.1920928955078125e-07
      vf_loss: 1.6972604990005493
    num_steps_sampled: 552000
    num_steps_trained: 552000
    wait_time_ms: 16.161
  iterations_since_restore: 318
  node_ip: 172.17.8.48
  num_metric_batches_dropped: 0
  pid: 20453
  policy_reward_mean: {}
  time_since_restore: 2605.472578525543
  time_this_iter_s: 5.829866647720337
  time_total_s: 2605.472578525543
  timestamp: 1593996605
  timesteps_since_restore: 552000
  timesteps_this_iter: 1000
  timesteps_total: 552000
  training_iteration: 318
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=20453], 2605 s, 318 iter, 552000 ts, 128 rew

agent-1: 160.0
Sum Reward: 160.0
Avg Reward: 160.0
Min Reward: 160.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-50-11
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 197.0
  episode_reward_mean: 127.78
  episode_reward_min: 63.0
  episodes_this_iter: 1
  episodes_total: 552
  experiment_id: 325b24caee6c4209bf8cf01af4f33e4d
  hostname: gpu048
  info:
    apply_time_ms: 2.696
    dispatch_time_ms: 39.05
    learner:
      cur_lr: 0.0013232368510216475
      grad_gnorm: 6.825084686279297
      policy_entropy: 4.594166278839111
      policy_loss: 0.8273972272872925
      var_gnorm: 30.41100311279297
      vf_explained_var: 0.0
      vf_loss: 0.67649906873703
    num_steps_sampled: 553000
    num_steps_trained: 553000
    wait_time_ms: 18.214
  iterations_since_restore: 319
  node_ip: 172.17.8.48
  num_metric_batches_dropped: 0
  pid: 20453
  policy_reward_mean: {}
  time_since_restore: 2611.1236362457275
  time_this_iter_s: 5.651057720184326
  time_total_s: 2611.1236362457275
  timestamp: 1593996611
  timesteps_since_restore: 553000
  timesteps_this_iter: 1000
  timesteps_total: 553000
  training_iteration: 319
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=20453], 2611 s, 319 iter, 553000 ts, 128 rew

agent-1: 134.0
Sum Reward: 134.0
Avg Reward: 134.0
Min Reward: 134.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-50-17
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 197.0
  episode_reward_mean: 127.93
  episode_reward_min: 63.0
  episodes_this_iter: 1
  episodes_total: 553
  experiment_id: 325b24caee6c4209bf8cf01af4f33e4d
  hostname: gpu048
  info:
    apply_time_ms: 3.437
    dispatch_time_ms: 24.655
    learner:
      cur_lr: 0.0013231701450422406
      grad_gnorm: 14.336869239807129
      policy_entropy: 2.984025001525879
      policy_loss: -1.33100426197052
      var_gnorm: 30.415550231933594
      vf_explained_var: 0.0
      vf_loss: 1.5007680654525757
    num_steps_sampled: 554000
    num_steps_trained: 554000
    wait_time_ms: 17.384
  iterations_since_restore: 320
  node_ip: 172.17.8.48
  num_metric_batches_dropped: 0
  pid: 20453
  policy_reward_mean: {}
  time_since_restore: 2617.1278705596924
  time_this_iter_s: 6.004234313964844
  time_total_s: 2617.1278705596924
  timestamp: 1593996617
  timesteps_since_restore: 554000
  timesteps_this_iter: 1000
  timesteps_total: 554000
  training_iteration: 320
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=20453], 2617 s, 320 iter, 554000 ts, 128 rew

agent-1: 143.0
Sum Reward: 143.0
Avg Reward: 143.0
Min Reward: 143.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-50-23
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 183.0
  episode_reward_mean: 127.39
  episode_reward_min: 63.0
  episodes_this_iter: 1
  episodes_total: 554
  experiment_id: 325b24caee6c4209bf8cf01af4f33e4d
  hostname: gpu048
  info:
    apply_time_ms: 3.471
    dispatch_time_ms: 37.114
    learner:
      cur_lr: 0.0013231035554781556
      grad_gnorm: 16.869314193725586
      policy_entropy: 2.571166753768921
      policy_loss: -0.4379040002822876
      var_gnorm: 30.415332794189453
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 1.8359167575836182
    num_steps_sampled: 555000
    num_steps_trained: 555000
    wait_time_ms: 25.558
  iterations_since_restore: 321
  node_ip: 172.17.8.48
  num_metric_batches_dropped: 0
  pid: 20453
  policy_reward_mean: {}
  time_since_restore: 2623.1412892341614
  time_this_iter_s: 6.013418674468994
  time_total_s: 2623.1412892341614
  timestamp: 1593996623
  timesteps_since_restore: 555000
  timesteps_this_iter: 1000
  timesteps_total: 555000
  training_iteration: 321
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=20453], 2623 s, 321 iter, 555000 ts, 127 rew

agent-1: 113.0
Sum Reward: 113.0
Avg Reward: 113.0
Min Reward: 113.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-50-29
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 183.0
  episode_reward_mean: 127.13
  episode_reward_min: 63.0
  episodes_this_iter: 1
  episodes_total: 555
  experiment_id: 325b24caee6c4209bf8cf01af4f33e4d
  hostname: gpu048
  info:
    apply_time_ms: 3.634
    dispatch_time_ms: 52.073
    learner:
      cur_lr: 0.0013230369659140706
      grad_gnorm: 17.775470733642578
      policy_entropy: 4.222075462341309
      policy_loss: -0.7581434845924377
      var_gnorm: 30.407445907592773
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 1.8349491357803345
    num_steps_sampled: 556000
    num_steps_trained: 556000
    wait_time_ms: 24.179
  iterations_since_restore: 322
  node_ip: 172.17.8.48
  num_metric_batches_dropped: 0
  pid: 20453
  policy_reward_mean: {}
  time_since_restore: 2629.5243470668793
  time_this_iter_s: 6.3830578327178955
  time_total_s: 2629.5243470668793
  timestamp: 1593996629
  timesteps_since_restore: 556000
  timesteps_this_iter: 1000
  timesteps_total: 556000
  training_iteration: 322
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=20453], 2629 s, 322 iter, 556000 ts, 127 rew

agent-1: 121.0
Sum Reward: 121.0
Avg Reward: 121.0
Min Reward: 121.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-50-35
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 183.0
  episode_reward_mean: 127.2
  episode_reward_min: 63.0
  episodes_this_iter: 1
  episodes_total: 556
  experiment_id: 325b24caee6c4209bf8cf01af4f33e4d
  hostname: gpu048
  info:
    apply_time_ms: 3.635
    dispatch_time_ms: 40.672
    learner:
      cur_lr: 0.0013229703763499856
      grad_gnorm: 19.773128509521484
      policy_entropy: 3.4902336597442627
      policy_loss: -0.6376439929008484
      var_gnorm: 30.399389266967773
      vf_explained_var: 0.0
      vf_loss: 2.2287368774414062
    num_steps_sampled: 557000
    num_steps_trained: 557000
    wait_time_ms: 19.581
  iterations_since_restore: 323
  node_ip: 172.17.8.48
  num_metric_batches_dropped: 0
  pid: 20453
  policy_reward_mean: {}
  time_since_restore: 2635.8769478797913
  time_this_iter_s: 6.352600812911987
  time_total_s: 2635.8769478797913
  timestamp: 1593996635
  timesteps_since_restore: 557000
  timesteps_this_iter: 1000
  timesteps_total: 557000
  training_iteration: 323
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=20453], 2635 s, 323 iter, 557000 ts, 127 rew

agent-1: 97.0
Sum Reward: 97.0
Avg Reward: 97.0
Min Reward: 97.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-50-42
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 183.0
  episode_reward_mean: 126.92
  episode_reward_min: 63.0
  episodes_this_iter: 1
  episodes_total: 557
  experiment_id: 325b24caee6c4209bf8cf01af4f33e4d
  hostname: gpu048
  info:
    apply_time_ms: 3.376
    dispatch_time_ms: 38.545
    learner:
      cur_lr: 0.0013229037867859006
      grad_gnorm: 17.101062774658203
      policy_entropy: 4.3269853591918945
      policy_loss: -0.9195050001144409
      var_gnorm: 30.40098762512207
      vf_explained_var: 0.0
      vf_loss: 1.587924599647522
    num_steps_sampled: 558000
    num_steps_trained: 558000
    wait_time_ms: 22.148
  iterations_since_restore: 324
  node_ip: 172.17.8.48
  num_metric_batches_dropped: 0
  pid: 20453
  policy_reward_mean: {}
  time_since_restore: 2642.389357328415
  time_this_iter_s: 6.512409448623657
  time_total_s: 2642.389357328415
  timestamp: 1593996642
  timesteps_since_restore: 558000
  timesteps_this_iter: 1000
  timesteps_total: 558000
  training_iteration: 324
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=20453], 2642 s, 324 iter, 558000 ts, 127 rew

agent-1: 117.0
Sum Reward: 117.0
Avg Reward: 117.0
Min Reward: 117.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-50-49
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 183.0
  episode_reward_mean: 126.94
  episode_reward_min: 63.0
  episodes_this_iter: 1
  episodes_total: 558
  experiment_id: 325b24caee6c4209bf8cf01af4f33e4d
  hostname: gpu048
  info:
    apply_time_ms: 3.216
    dispatch_time_ms: 37.507
    learner:
      cur_lr: 0.0013228371972218156
      grad_gnorm: 40.0
      policy_entropy: 4.559447288513184
      policy_loss: 9.171244621276855
      var_gnorm: 30.40302848815918
      vf_explained_var: 0.0
      vf_loss: 17.343095779418945
    num_steps_sampled: 559000
    num_steps_trained: 559000
    wait_time_ms: 23.132
  iterations_since_restore: 325
  node_ip: 172.17.8.48
  num_metric_batches_dropped: 0
  pid: 20453
  policy_reward_mean: {}
  time_since_restore: 2648.9425072669983
  time_this_iter_s: 6.553149938583374
  time_total_s: 2648.9425072669983
  timestamp: 1593996649
  timesteps_since_restore: 559000
  timesteps_this_iter: 1000
  timesteps_total: 559000
  training_iteration: 325
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=20453], 2648 s, 325 iter, 559000 ts, 127 rew

agent-1: 124.0
Sum Reward: 124.0
Avg Reward: 124.0
Min Reward: 124.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-51-01
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 183.0
  episode_reward_mean: 127.03
  episode_reward_min: 63.0
  episodes_this_iter: 1
  episodes_total: 559
  experiment_id: 325b24caee6c4209bf8cf01af4f33e4d
  hostname: gpu048
  info:
    apply_time_ms: 3.382
    dispatch_time_ms: 9.095
    learner:
      cur_lr: 0.0013227706076577306
      grad_gnorm: 9.363897323608398
      policy_entropy: 3.298438787460327
      policy_loss: 1.0706430673599243
      var_gnorm: 30.41691780090332
      vf_explained_var: 0.0
      vf_loss: 1.353999376296997
    num_steps_sampled: 560000
    num_steps_trained: 560000
    wait_time_ms: 32.818
  iterations_since_restore: 326
  node_ip: 172.17.8.48
  num_metric_batches_dropped: 0
  pid: 20453
  policy_reward_mean: {}
  time_since_restore: 2661.1442863941193
  time_this_iter_s: 12.201779127120972
  time_total_s: 2661.1442863941193
  timestamp: 1593996661
  timesteps_since_restore: 560000
  timesteps_this_iter: 1000
  timesteps_total: 560000
  training_iteration: 326
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=20453], 2661 s, 326 iter, 560000 ts, 127 rew

agent-1: 147.0
Sum Reward: 147.0
Avg Reward: 147.0
Min Reward: 147.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
agent-1: 143.0
Sum Reward: 143.0
Avg Reward: 143.0
Min Reward: 143.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-51-09
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 183.0
  episode_reward_mean: 127.33
  episode_reward_min: 63.0
  episodes_this_iter: 2
  episodes_total: 561
  experiment_id: 325b24caee6c4209bf8cf01af4f33e4d
  hostname: gpu048
  info:
    apply_time_ms: 3.742
    dispatch_time_ms: 8.298
    learner:
      cur_lr: 0.0013227040180936456
      grad_gnorm: 19.16442108154297
      policy_entropy: 2.440796375274658
      policy_loss: -0.41061246395111084
      var_gnorm: 30.42605972290039
      vf_explained_var: 0.0
      vf_loss: 2.2799997329711914
    num_steps_sampled: 562000
    num_steps_trained: 562000
    wait_time_ms: 31.441
  iterations_since_restore: 327
  node_ip: 172.17.8.48
  num_metric_batches_dropped: 0
  pid: 20453
  policy_reward_mean: {}
  time_since_restore: 2669.5837545394897
  time_this_iter_s: 8.439468145370483
  time_total_s: 2669.5837545394897
  timestamp: 1593996669
  timesteps_since_restore: 562000
  timesteps_this_iter: 2000
  timesteps_total: 562000
  training_iteration: 327
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=20453], 2669 s, 327 iter, 562000 ts, 127 rew

agent-1: 151.0
Sum Reward: 151.0
Avg Reward: 151.0
Min Reward: 151.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
agent-1: 153.0
Sum Reward: 153.0
Avg Reward: 153.0
Min Reward: 153.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-51-18
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 183.0
  episode_reward_mean: 128.24
  episode_reward_min: 63.0
  episodes_this_iter: 2
  episodes_total: 563
  experiment_id: 325b24caee6c4209bf8cf01af4f33e4d
  hostname: gpu048
  info:
    apply_time_ms: 2.629
    dispatch_time_ms: 8.173
    learner:
      cur_lr: 0.0013225708389654756
      grad_gnorm: 21.63395118713379
      policy_entropy: 3.759479284286499
      policy_loss: -0.8750184774398804
      var_gnorm: 30.44489860534668
      vf_explained_var: 5.960464477539063e-08
      vf_loss: 2.667279005050659
    num_steps_sampled: 564000
    num_steps_trained: 564000
    wait_time_ms: 28.42
  iterations_since_restore: 328
  node_ip: 172.17.8.48
  num_metric_batches_dropped: 0
  pid: 20453
  policy_reward_mean: {}
  time_since_restore: 2678.0035083293915
  time_this_iter_s: 8.419753789901733
  time_total_s: 2678.0035083293915
  timestamp: 1593996678
  timesteps_since_restore: 564000
  timesteps_this_iter: 2000
  timesteps_total: 564000
  training_iteration: 328
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=20453], 2678 s, 328 iter, 564000 ts, 128 rew

agent-1: 136.0
Sum Reward: 136.0
Avg Reward: 136.0
Min Reward: 136.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
agent-1: 140.0
Sum Reward: 140.0
Avg Reward: 140.0
Min Reward: 140.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-51-26
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 183.0
  episode_reward_mean: 128.05
  episode_reward_min: 63.0
  episodes_this_iter: 2
  episodes_total: 565
  experiment_id: 325b24caee6c4209bf8cf01af4f33e4d
  hostname: gpu048
  info:
    apply_time_ms: 2.953
    dispatch_time_ms: 9.822
    learner:
      cur_lr: 0.0013224375434219837
      grad_gnorm: 40.0
      policy_entropy: 3.643986940383911
      policy_loss: 8.613941192626953
      var_gnorm: 30.429019927978516
      vf_explained_var: 0.0
      vf_loss: 27.49098777770996
    num_steps_sampled: 566000
    num_steps_trained: 566000
    wait_time_ms: 28.017
  iterations_since_restore: 329
  node_ip: 172.17.8.48
  num_metric_batches_dropped: 0
  pid: 20453
  policy_reward_mean: {}
  time_since_restore: 2686.3634350299835
  time_this_iter_s: 8.359926700592041
  time_total_s: 2686.3634350299835
  timestamp: 1593996686
  timesteps_since_restore: 566000
  timesteps_this_iter: 2000
  timesteps_total: 566000
  training_iteration: 329
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=20453], 2686 s, 329 iter, 566000 ts, 128 rew

agent-1: 131.0
Sum Reward: 131.0
Avg Reward: 131.0
Min Reward: 131.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
agent-1: 134.0
Sum Reward: 134.0
Avg Reward: 134.0
Min Reward: 134.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-51-34
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 183.0
  episode_reward_mean: 128.16
  episode_reward_min: 63.0
  episodes_this_iter: 2
  episodes_total: 567
  experiment_id: 325b24caee6c4209bf8cf01af4f33e4d
  hostname: gpu048
  info:
    apply_time_ms: 3.697
    dispatch_time_ms: 9.017
    learner:
      cur_lr: 0.0013223043642938137
      grad_gnorm: 19.953954696655273
      policy_entropy: 2.7478983402252197
      policy_loss: -0.5138263702392578
      var_gnorm: 30.44163703918457
      vf_explained_var: 0.0
      vf_loss: 2.4348955154418945
    num_steps_sampled: 568000
    num_steps_trained: 568000
    wait_time_ms: 27.332
  iterations_since_restore: 330
  node_ip: 172.17.8.48
  num_metric_batches_dropped: 0
  pid: 20453
  policy_reward_mean: {}
  time_since_restore: 2694.7160918712616
  time_this_iter_s: 8.352656841278076
  time_total_s: 2694.7160918712616
  timestamp: 1593996694
  timesteps_since_restore: 568000
  timesteps_this_iter: 2000
  timesteps_total: 568000
  training_iteration: 330
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=20453], 2694 s, 330 iter, 568000 ts, 128 rew

agent-1: 176.0
Sum Reward: 176.0
Avg Reward: 176.0
Min Reward: 176.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
agent-1: 100.0
Sum Reward: 100.0
Avg Reward: 100.0
Min Reward: 100.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-51-43
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 183.0
  episode_reward_mean: 128.12
  episode_reward_min: 63.0
  episodes_this_iter: 2
  episodes_total: 569
  experiment_id: 325b24caee6c4209bf8cf01af4f33e4d
  hostname: gpu048
  info:
    apply_time_ms: 2.63
    dispatch_time_ms: 6.949
    learner:
      cur_lr: 0.0013221711851656437
      grad_gnorm: 3.3875198364257812
      policy_entropy: 3.6607635021209717
      policy_loss: 0.850635290145874
      var_gnorm: 30.419891357421875
      vf_explained_var: 0.0
      vf_loss: 0.420855849981308
    num_steps_sampled: 570000
    num_steps_trained: 570000
    wait_time_ms: 32.391
  iterations_since_restore: 331
  node_ip: 172.17.8.48
  num_metric_batches_dropped: 0
  pid: 20453
  policy_reward_mean: {}
  time_since_restore: 2703.0288321971893
  time_this_iter_s: 8.312740325927734
  time_total_s: 2703.0288321971893
  timestamp: 1593996703
  timesteps_since_restore: 570000
  timesteps_this_iter: 2000
  timesteps_total: 570000
  training_iteration: 331
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=20453], 2703 s, 331 iter, 570000 ts, 128 rew

agent-1: 112.0
Sum Reward: 112.0
Avg Reward: 112.0
Min Reward: 112.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
agent-1: 148.0
Sum Reward: 148.0
Avg Reward: 148.0
Min Reward: 148.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-51-51
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 183.0
  episode_reward_mean: 128.53
  episode_reward_min: 63.0
  episodes_this_iter: 2
  episodes_total: 571
  experiment_id: 325b24caee6c4209bf8cf01af4f33e4d
  hostname: gpu048
  info:
    apply_time_ms: 4.819
    dispatch_time_ms: 10.18
    learner:
      cur_lr: 0.0013220380060374737
      grad_gnorm: 19.557113647460938
      policy_entropy: 4.241575241088867
      policy_loss: -2.579710006713867
      var_gnorm: 30.450925827026367
      vf_explained_var: 0.0
      vf_loss: 2.4569003582000732
    num_steps_sampled: 572000
    num_steps_trained: 572000
    wait_time_ms: 32.594
  iterations_since_restore: 332
  node_ip: 172.17.8.48
  num_metric_batches_dropped: 0
  pid: 20453
  policy_reward_mean: {}
  time_since_restore: 2711.5103068351746
  time_this_iter_s: 8.48147463798523
  time_total_s: 2711.5103068351746
  timestamp: 1593996711
  timesteps_since_restore: 572000
  timesteps_this_iter: 2000
  timesteps_total: 572000
  training_iteration: 332
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=20453], 2711 s, 332 iter, 572000 ts, 129 rew

agent-1: 133.0
Sum Reward: 133.0
Avg Reward: 133.0
Min Reward: 133.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
agent-1: 118.0
Sum Reward: 118.0
Avg Reward: 118.0
Min Reward: 118.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-52-00
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 183.0
  episode_reward_mean: 127.92
  episode_reward_min: 63.0
  episodes_this_iter: 2
  episodes_total: 573
  experiment_id: 325b24caee6c4209bf8cf01af4f33e4d
  hostname: gpu048
  info:
    apply_time_ms: 2.621
    dispatch_time_ms: 8.044
    learner:
      cur_lr: 0.0013219048269093037
      grad_gnorm: 18.31403350830078
      policy_entropy: 4.425919532775879
      policy_loss: -2.886683464050293
      var_gnorm: 30.443843841552734
      vf_explained_var: 0.0
      vf_loss: 2.148970603942871
    num_steps_sampled: 574000
    num_steps_trained: 574000
    wait_time_ms: 30.663
  iterations_since_restore: 333
  node_ip: 172.17.8.48
  num_metric_batches_dropped: 0
  pid: 20453
  policy_reward_mean: {}
  time_since_restore: 2719.8682432174683
  time_this_iter_s: 8.357936382293701
  time_total_s: 2719.8682432174683
  timestamp: 1593996720
  timesteps_since_restore: 574000
  timesteps_this_iter: 2000
  timesteps_total: 574000
  training_iteration: 333
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=20453], 2719 s, 333 iter, 574000 ts, 128 rew

agent-1: 125.0
Sum Reward: 125.0
Avg Reward: 125.0
Min Reward: 125.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
agent-1: 154.0
Sum Reward: 154.0
Avg Reward: 154.0
Min Reward: 154.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-52-08
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 183.0
  episode_reward_mean: 128.09
  episode_reward_min: 63.0
  episodes_this_iter: 2
  episodes_total: 575
  experiment_id: 325b24caee6c4209bf8cf01af4f33e4d
  hostname: gpu048
  info:
    apply_time_ms: 2.533
    dispatch_time_ms: 6.423
    learner:
      cur_lr: 0.0013217716477811337
      grad_gnorm: 21.121156692504883
      policy_entropy: 4.1547722816467285
      policy_loss: -3.8607118129730225
      var_gnorm: 30.46725845336914
      vf_explained_var: 0.0
      vf_loss: 2.640901803970337
    num_steps_sampled: 576000
    num_steps_trained: 576000
    wait_time_ms: 30.553
  iterations_since_restore: 334
  node_ip: 172.17.8.48
  num_metric_batches_dropped: 0
  pid: 20453
  policy_reward_mean: {}
  time_since_restore: 2728.3432223796844
  time_this_iter_s: 8.474979162216187
  time_total_s: 2728.3432223796844
  timestamp: 1593996728
  timesteps_since_restore: 576000
  timesteps_this_iter: 2000
  timesteps_total: 576000
  training_iteration: 334
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=20453], 2728 s, 334 iter, 576000 ts, 128 rew

agent-1: 124.0
Sum Reward: 124.0
Avg Reward: 124.0
Min Reward: 124.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
agent-1: 141.0
Sum Reward: 141.0
Avg Reward: 141.0
Min Reward: 141.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-52-17
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 183.0
  episode_reward_mean: 128.29
  episode_reward_min: 63.0
  episodes_this_iter: 2
  episodes_total: 577
  experiment_id: 325b24caee6c4209bf8cf01af4f33e4d
  hostname: gpu048
  info:
    apply_time_ms: 2.722
    dispatch_time_ms: 8.247
    learner:
      cur_lr: 0.0013216383522376418
      grad_gnorm: 18.851064682006836
      policy_entropy: 2.9144840240478516
      policy_loss: -0.5248110890388489
      var_gnorm: 30.45344352722168
      vf_explained_var: 0.0
      vf_loss: 2.1554954051971436
    num_steps_sampled: 578000
    num_steps_trained: 578000
    wait_time_ms: 29.633
  iterations_since_restore: 335
  node_ip: 172.17.8.48
  num_metric_batches_dropped: 0
  pid: 20453
  policy_reward_mean: {}
  time_since_restore: 2736.6471779346466
  time_this_iter_s: 8.303955554962158
  time_total_s: 2736.6471779346466
  timestamp: 1593996737
  timesteps_since_restore: 578000
  timesteps_this_iter: 2000
  timesteps_total: 578000
  training_iteration: 335
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=20453], 2736 s, 335 iter, 578000 ts, 128 rew

agent-1: 134.0
Sum Reward: 134.0
Avg Reward: 134.0
Min Reward: 134.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
agent-1: 131.0
Sum Reward: 131.0
Avg Reward: 131.0
Min Reward: 131.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-52-25
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 183.0
  episode_reward_mean: 128.25
  episode_reward_min: 63.0
  episodes_this_iter: 2
  episodes_total: 579
  experiment_id: 325b24caee6c4209bf8cf01af4f33e4d
  hostname: gpu048
  info:
    apply_time_ms: 3.217
    dispatch_time_ms: 8.639
    learner:
      cur_lr: 0.0013215051731094718
      grad_gnorm: 40.0
      policy_entropy: 3.141181468963623
      policy_loss: 6.854904651641846
      var_gnorm: 30.444347381591797
      vf_explained_var: 0.0
      vf_loss: 34.06919860839844
    num_steps_sampled: 580000
    num_steps_trained: 580000
    wait_time_ms: 29.147
  iterations_since_restore: 336
  node_ip: 172.17.8.48
  num_metric_batches_dropped: 0
  pid: 20453
  policy_reward_mean: {}
  time_since_restore: 2744.867922067642
  time_this_iter_s: 8.220744132995605
  time_total_s: 2744.867922067642
  timestamp: 1593996745
  timesteps_since_restore: 580000
  timesteps_this_iter: 2000
  timesteps_total: 580000
  training_iteration: 336
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=20453], 2744 s, 336 iter, 580000 ts, 128 rew

agent-1: 147.0
Sum Reward: 147.0
Avg Reward: 147.0
Min Reward: 147.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
agent-1: 176.0
Sum Reward: 176.0
Avg Reward: 176.0
Min Reward: 176.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-52-33
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 183.0
  episode_reward_mean: 129.4
  episode_reward_min: 63.0
  episodes_this_iter: 2
  episodes_total: 581
  experiment_id: 325b24caee6c4209bf8cf01af4f33e4d
  hostname: gpu048
  info:
    apply_time_ms: 3.187
    dispatch_time_ms: 8.187
    learner:
      cur_lr: 0.0013213719939813018
      grad_gnorm: 21.069557189941406
      policy_entropy: 3.7365293502807617
      policy_loss: -3.8095059394836426
      var_gnorm: 30.4761962890625
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 2.586568832397461
    num_steps_sampled: 582000
    num_steps_trained: 582000
    wait_time_ms: 31.997
  iterations_since_restore: 337
  node_ip: 172.17.8.48
  num_metric_batches_dropped: 0
  pid: 20453
  policy_reward_mean: {}
  time_since_restore: 2753.316498041153
  time_this_iter_s: 8.448575973510742
  time_total_s: 2753.316498041153
  timestamp: 1593996753
  timesteps_since_restore: 582000
  timesteps_this_iter: 2000
  timesteps_total: 582000
  training_iteration: 337
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=20453], 2753 s, 337 iter, 582000 ts, 129 rew

agent-1: 134.0
Sum Reward: 134.0
Avg Reward: 134.0
Min Reward: 134.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
agent-1: 148.0
Sum Reward: 148.0
Avg Reward: 148.0
Min Reward: 148.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-52-43
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 183.0
  episode_reward_mean: 129.39
  episode_reward_min: 63.0
  episodes_this_iter: 2
  episodes_total: 583
  experiment_id: 325b24caee6c4209bf8cf01af4f33e4d
  hostname: gpu048
  info:
    apply_time_ms: 3.196
    dispatch_time_ms: 53.911
    learner:
      cur_lr: 0.0013212388148531318
      grad_gnorm: 40.0
      policy_entropy: 1.938373327255249
      policy_loss: 1.0941429138183594
      var_gnorm: 30.501148223876953
      vf_explained_var: 0.0
      vf_loss: 29.189197540283203
    num_steps_sampled: 584000
    num_steps_trained: 584000
    wait_time_ms: 18.814
  iterations_since_restore: 338
  node_ip: 172.17.8.48
  num_metric_batches_dropped: 0
  pid: 20453
  policy_reward_mean: {}
  time_since_restore: 2763.250386953354
  time_this_iter_s: 9.933888912200928
  time_total_s: 2763.250386953354
  timestamp: 1593996763
  timesteps_since_restore: 584000
  timesteps_this_iter: 2000
  timesteps_total: 584000
  training_iteration: 338
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=20453], 2763 s, 338 iter, 584000 ts, 129 rew

agent-1: 180.0
Sum Reward: 180.0
Avg Reward: 180.0
Min Reward: 180.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
agent-1: 149.0
Sum Reward: 149.0
Avg Reward: 149.0
Min Reward: 149.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-52-50
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 183.0
  episode_reward_mean: 130.55
  episode_reward_min: 63.0
  episodes_this_iter: 2
  episodes_total: 585
  experiment_id: 325b24caee6c4209bf8cf01af4f33e4d
  hostname: gpu048
  info:
    apply_time_ms: 3.775
    dispatch_time_ms: 36.731
    learner:
      cur_lr: 0.0013211056357249618
      grad_gnorm: 14.981215476989746
      policy_entropy: 3.013214111328125
      policy_loss: 3.5896921157836914
      var_gnorm: 30.498123168945312
      vf_explained_var: 0.0
      vf_loss: 2.6224896907806396
    num_steps_sampled: 585000
    num_steps_trained: 585000
    wait_time_ms: 24.275
  iterations_since_restore: 339
  node_ip: 172.17.8.48
  num_metric_batches_dropped: 0
  pid: 20453
  policy_reward_mean: {}
  time_since_restore: 2769.9155642986298
  time_this_iter_s: 6.665177345275879
  time_total_s: 2769.9155642986298
  timestamp: 1593996770
  timesteps_since_restore: 585000
  timesteps_this_iter: 1000
  timesteps_total: 585000
  training_iteration: 339
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=20453], 2769 s, 339 iter, 585000 ts, 131 rew

Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-52-57
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 183.0
  episode_reward_mean: 130.55
  episode_reward_min: 63.0
  episodes_this_iter: 0
  episodes_total: 585
  experiment_id: 325b24caee6c4209bf8cf01af4f33e4d
  hostname: gpu048
  info:
    apply_time_ms: 3.476
    dispatch_time_ms: 35.466
    learner:
      cur_lr: 0.0013210390461608768
      grad_gnorm: 40.0
      policy_entropy: 2.7769079208374023
      policy_loss: 0.8810664415359497
      var_gnorm: 30.500885009765625
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 18.421411514282227
    num_steps_sampled: 586000
    num_steps_trained: 586000
    wait_time_ms: 14.351
  iterations_since_restore: 340
  node_ip: 172.17.8.48
  num_metric_batches_dropped: 0
  pid: 20453
  policy_reward_mean: {}
  time_since_restore: 2776.6341009140015
  time_this_iter_s: 6.718536615371704
  time_total_s: 2776.6341009140015
  timestamp: 1593996777
  timesteps_since_restore: 586000
  timesteps_this_iter: 1000
  timesteps_total: 586000
  training_iteration: 340
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=20453], 2776 s, 340 iter, 586000 ts, 131 rew

agent-1: 173.0
Sum Reward: 173.0
Avg Reward: 173.0
Min Reward: 173.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
agent-1: 114.0
Sum Reward: 114.0
Avg Reward: 114.0
Min Reward: 114.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-53-03
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 183.0
  episode_reward_mean: 130.9
  episode_reward_min: 63.0
  episodes_this_iter: 1
  episodes_total: 586
  experiment_id: 325b24caee6c4209bf8cf01af4f33e4d
  hostname: gpu048
  info:
    apply_time_ms: 3.664
    dispatch_time_ms: 33.28
    learner:
      cur_lr: 0.0013209724565967917
      grad_gnorm: 19.090072631835938
      policy_entropy: 4.364514350891113
      policy_loss: -2.476409435272217
      var_gnorm: 30.495750427246094
      vf_explained_var: 1.1920928955078125e-07
      vf_loss: 2.4455668926239014
    num_steps_sampled: 587000
    num_steps_trained: 587000
    wait_time_ms: 24.668
  iterations_since_restore: 341
  node_ip: 172.17.8.48
  num_metric_batches_dropped: 0
  pid: 20453
  policy_reward_mean: {}
  time_since_restore: 2782.90261220932
  time_this_iter_s: 6.2685112953186035
  time_total_s: 2782.90261220932
  timestamp: 1593996783
  timesteps_since_restore: 587000
  timesteps_this_iter: 1000
  timesteps_total: 587000
  training_iteration: 341
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=20453], 2782 s, 341 iter, 587000 ts, 131 rew

Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-53-09
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 183.0
  episode_reward_mean: 130.65
  episode_reward_min: 63.0
  episodes_this_iter: 1
  episodes_total: 587
  experiment_id: 325b24caee6c4209bf8cf01af4f33e4d
  hostname: gpu048
  info:
    apply_time_ms: 4.85
    dispatch_time_ms: 35.782
    learner:
      cur_lr: 0.001320905750617385
      grad_gnorm: 14.466279983520508
      policy_entropy: 4.480685710906982
      policy_loss: -1.640289545059204
      var_gnorm: 30.498327255249023
      vf_explained_var: 0.0
      vf_loss: 1.240272879600525
    num_steps_sampled: 588000
    num_steps_trained: 588000
    wait_time_ms: 15.052
  iterations_since_restore: 342
  node_ip: 172.17.8.48
  num_metric_batches_dropped: 0
  pid: 20453
  policy_reward_mean: {}
  time_since_restore: 2788.94855594635
  time_this_iter_s: 6.045943737030029
  time_total_s: 2788.94855594635
  timestamp: 1593996789
  timesteps_since_restore: 588000
  timesteps_this_iter: 1000
  timesteps_total: 588000
  training_iteration: 342
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=20453], 2788 s, 342 iter, 588000 ts, 131 rew

agent-1: 137.0
Sum Reward: 137.0
Avg Reward: 137.0
Min Reward: 137.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-53-15
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 183.0
  episode_reward_mean: 130.72
  episode_reward_min: 63.0
  episodes_this_iter: 1
  episodes_total: 588
  experiment_id: 325b24caee6c4209bf8cf01af4f33e4d
  hostname: gpu048
  info:
    apply_time_ms: 2.654
    dispatch_time_ms: 35.241
    learner:
      cur_lr: 0.0013208391610533
      grad_gnorm: 14.148045539855957
      policy_entropy: 3.31152081489563
      policy_loss: -0.7264196276664734
      var_gnorm: 30.486940383911133
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 1.416714072227478
    num_steps_sampled: 589000
    num_steps_trained: 589000
    wait_time_ms: 21.855
  iterations_since_restore: 343
  node_ip: 172.17.8.48
  num_metric_batches_dropped: 0
  pid: 20453
  policy_reward_mean: {}
  time_since_restore: 2795.0724563598633
  time_this_iter_s: 6.123900413513184
  time_total_s: 2795.0724563598633
  timestamp: 1593996795
  timesteps_since_restore: 589000
  timesteps_this_iter: 1000
  timesteps_total: 589000
  training_iteration: 343
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=20453], 2795 s, 343 iter, 589000 ts, 131 rew

agent-1: 136.0
Sum Reward: 136.0
Avg Reward: 136.0
Min Reward: 136.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-53-21
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 183.0
  episode_reward_mean: 131.04
  episode_reward_min: 63.0
  episodes_this_iter: 1
  episodes_total: 589
  experiment_id: 325b24caee6c4209bf8cf01af4f33e4d
  hostname: gpu048
  info:
    apply_time_ms: 3.279
    dispatch_time_ms: 33.115
    learner:
      cur_lr: 0.001320772571489215
      grad_gnorm: 24.723905563354492
      policy_entropy: 2.741258144378662
      policy_loss: 3.8723270893096924
      var_gnorm: 30.47749900817871
      vf_explained_var: 0.0
      vf_loss: 3.427544355392456
    num_steps_sampled: 590000
    num_steps_trained: 590000
    wait_time_ms: 26.632
  iterations_since_restore: 344
  node_ip: 172.17.8.48
  num_metric_batches_dropped: 0
  pid: 20453
  policy_reward_mean: {}
  time_since_restore: 2801.1677210330963
  time_this_iter_s: 6.095264673233032
  time_total_s: 2801.1677210330963
  timestamp: 1593996801
  timesteps_since_restore: 590000
  timesteps_this_iter: 1000
  timesteps_total: 590000
  training_iteration: 344
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=20453], 2801 s, 344 iter, 590000 ts, 131 rew

agent-1: 150.0
Sum Reward: 150.0
Avg Reward: 150.0
Min Reward: 150.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
agent-1: 76.0
Sum Reward: 76.0
Avg Reward: 76.0
Min Reward: 76.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-53-28
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 183.0
  episode_reward_mean: 130.86
  episode_reward_min: 63.0
  episodes_this_iter: 2
  episodes_total: 591
  experiment_id: 325b24caee6c4209bf8cf01af4f33e4d
  hostname: gpu048
  info:
    apply_time_ms: 4.379
    dispatch_time_ms: 39.107
    learner:
      cur_lr: 0.0013207059819251299
      grad_gnorm: 21.936063766479492
      policy_entropy: 5.6711602210998535
      policy_loss: -1.792749047279358
      var_gnorm: 30.470355987548828
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 1.9715871810913086
    num_steps_sampled: 591000
    num_steps_trained: 591000
    wait_time_ms: 16.924
  iterations_since_restore: 345
  node_ip: 172.17.8.48
  num_metric_batches_dropped: 0
  pid: 20453
  policy_reward_mean: {}
  time_since_restore: 2807.395181655884
  time_this_iter_s: 6.227460622787476
  time_total_s: 2807.395181655884
  timestamp: 1593996808
  timesteps_since_restore: 591000
  timesteps_this_iter: 1000
  timesteps_total: 591000
  training_iteration: 345
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=20453], 2807 s, 345 iter, 591000 ts, 131 rew

Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-53-34
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 183.0
  episode_reward_mean: 130.86
  episode_reward_min: 63.0
  episodes_this_iter: 0
  episodes_total: 591
  experiment_id: 325b24caee6c4209bf8cf01af4f33e4d
  hostname: gpu048
  info:
    apply_time_ms: 2.437
    dispatch_time_ms: 43.682
    learner:
      cur_lr: 0.0013206393923610449
      grad_gnorm: 21.404645919799805
      policy_entropy: 1.9709179401397705
      policy_loss: -0.29533281922340393
      var_gnorm: 30.463462829589844
      vf_explained_var: 0.0
      vf_loss: 2.7425730228424072
    num_steps_sampled: 592000
    num_steps_trained: 592000
    wait_time_ms: 19.912
  iterations_since_restore: 346
  node_ip: 172.17.8.48
  num_metric_batches_dropped: 0
  pid: 20453
  policy_reward_mean: {}
  time_since_restore: 2813.6575787067413
  time_this_iter_s: 6.262397050857544
  time_total_s: 2813.6575787067413
  timestamp: 1593996814
  timesteps_since_restore: 592000
  timesteps_this_iter: 1000
  timesteps_total: 592000
  training_iteration: 346
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=20453], 2813 s, 346 iter, 592000 ts, 131 rew

agent-1: 120.0
Sum Reward: 120.0
Avg Reward: 120.0
Min Reward: 120.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
agent-1: 149.0
Sum Reward: 149.0
Avg Reward: 149.0
Min Reward: 149.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-53-40
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 183.0
  episode_reward_mean: 130.81
  episode_reward_min: 63.0
  episodes_this_iter: 2
  episodes_total: 593
  experiment_id: 325b24caee6c4209bf8cf01af4f33e4d
  hostname: gpu048
  info:
    apply_time_ms: 2.412
    dispatch_time_ms: 33.414
    learner:
      cur_lr: 0.0013205728027969599
      grad_gnorm: 7.513451099395752
      policy_entropy: 3.140007972717285
      policy_loss: -2.2622408866882324
      var_gnorm: 30.477676391601562
      vf_explained_var: 0.0
      vf_loss: 0.3787163496017456
    num_steps_sampled: 593000
    num_steps_trained: 593000
    wait_time_ms: 23.983
  iterations_since_restore: 347
  node_ip: 172.17.8.48
  num_metric_batches_dropped: 0
  pid: 20453
  policy_reward_mean: {}
  time_since_restore: 2819.54852437973
  time_this_iter_s: 5.890945672988892
  time_total_s: 2819.54852437973
  timestamp: 1593996820
  timesteps_since_restore: 593000
  timesteps_this_iter: 1000
  timesteps_total: 593000
  training_iteration: 347
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=20453], 2819 s, 347 iter, 593000 ts, 131 rew

Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-53-58
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 183.0
  episode_reward_mean: 130.81
  episode_reward_min: 63.0
  episodes_this_iter: 0
  episodes_total: 593
  experiment_id: 325b24caee6c4209bf8cf01af4f33e4d
  hostname: gpu048
  info:
    apply_time_ms: 3.124
    dispatch_time_ms: 32.262
    learner:
      cur_lr: 0.0013205062132328749
      grad_gnorm: 4.225503921508789
      policy_entropy: 2.4405717849731445
      policy_loss: -0.15290704369544983
      var_gnorm: 30.479602813720703
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 0.45556873083114624
    num_steps_sampled: 594000
    num_steps_trained: 594000
    wait_time_ms: 27.084
  iterations_since_restore: 348
  node_ip: 172.17.8.48
  num_metric_batches_dropped: 0
  pid: 20453
  policy_reward_mean: {}
  time_since_restore: 2838.1590683460236
  time_this_iter_s: 18.610543966293335
  time_total_s: 2838.1590683460236
  timestamp: 1593996838
  timesteps_since_restore: 594000
  timesteps_this_iter: 1000
  timesteps_total: 594000
  training_iteration: 348
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=20453], 2838 s, 348 iter, 594000 ts, 131 rew

agent-1: 135.0
Sum Reward: 135.0
Avg Reward: 135.0
Min Reward: 135.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
agent-1: 126.0
Sum Reward: 126.0
Avg Reward: 126.0
Min Reward: 126.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-54-07
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 183.0
  episode_reward_mean: 130.54
  episode_reward_min: 63.0
  episodes_this_iter: 2
  episodes_total: 595
  experiment_id: 325b24caee6c4209bf8cf01af4f33e4d
  hostname: gpu048
  info:
    apply_time_ms: 2.555
    dispatch_time_ms: 7.614
    learner:
      cur_lr: 0.0013204396236687899
      grad_gnorm: 40.0
      policy_entropy: 5.2013750076293945
      policy_loss: 8.859633445739746
      var_gnorm: 30.4504451751709
      vf_explained_var: 1.1920928955078125e-07
      vf_loss: 7.369561672210693
    num_steps_sampled: 596000
    num_steps_trained: 596000
    wait_time_ms: 31.731
  iterations_since_restore: 349
  node_ip: 172.17.8.48
  num_metric_batches_dropped: 0
  pid: 20453
  policy_reward_mean: {}
  time_since_restore: 2846.4715073108673
  time_this_iter_s: 8.31243896484375
  time_total_s: 2846.4715073108673
  timestamp: 1593996847
  timesteps_since_restore: 596000
  timesteps_this_iter: 2000
  timesteps_total: 596000
  training_iteration: 349
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=20453], 2846 s, 349 iter, 596000 ts, 131 rew

agent-1: 107.0
Sum Reward: 107.0
Avg Reward: 107.0
Min Reward: 107.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
agent-1: 112.0
Sum Reward: 112.0
Avg Reward: 112.0
Min Reward: 112.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-54-15
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 183.0
  episode_reward_mean: 130.01
  episode_reward_min: 63.0
  episodes_this_iter: 2
  episodes_total: 597
  experiment_id: 325b24caee6c4209bf8cf01af4f33e4d
  hostname: gpu048
  info:
    apply_time_ms: 2.683
    dispatch_time_ms: 6.388
    learner:
      cur_lr: 0.0013203064445406199
      grad_gnorm: 8.279385566711426
      policy_entropy: 3.3785815238952637
      policy_loss: 2.2002387046813965
      var_gnorm: 30.46265983581543
      vf_explained_var: 0.0
      vf_loss: 0.4946371018886566
    num_steps_sampled: 598000
    num_steps_trained: 598000
    wait_time_ms: 32.634
  iterations_since_restore: 350
  node_ip: 172.17.8.48
  num_metric_batches_dropped: 0
  pid: 20453
  policy_reward_mean: {}
  time_since_restore: 2854.8733427524567
  time_this_iter_s: 8.401835441589355
  time_total_s: 2854.8733427524567
  timestamp: 1593996855
  timesteps_since_restore: 598000
  timesteps_this_iter: 2000
  timesteps_total: 598000
  training_iteration: 350
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=20453], 2854 s, 350 iter, 598000 ts, 130 rew

agent-1: 131.0
Sum Reward: 131.0
Avg Reward: 131.0
Min Reward: 131.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
agent-1: 145.0
Sum Reward: 145.0
Avg Reward: 145.0
Min Reward: 145.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-54-24
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 180.0
  episode_reward_mean: 129.48
  episode_reward_min: 63.0
  episodes_this_iter: 2
  episodes_total: 599
  experiment_id: 325b24caee6c4209bf8cf01af4f33e4d
  hostname: gpu048
  info:
    apply_time_ms: 4.446
    dispatch_time_ms: 9.547
    learner:
      cur_lr: 0.001320173148997128
      grad_gnorm: 40.0
      policy_entropy: 3.1683566570281982
      policy_loss: 9.1118745803833
      var_gnorm: 30.48403549194336
      vf_explained_var: 0.0
      vf_loss: 35.37009811401367
    num_steps_sampled: 600000
    num_steps_trained: 600000
    wait_time_ms: 29.988
  iterations_since_restore: 351
  node_ip: 172.17.8.48
  num_metric_batches_dropped: 0
  pid: 20453
  policy_reward_mean: {}
  time_since_restore: 2863.3883390426636
  time_this_iter_s: 8.51499629020691
  time_total_s: 2863.3883390426636
  timestamp: 1593996864
  timesteps_since_restore: 600000
  timesteps_this_iter: 2000
  timesteps_total: 600000
  training_iteration: 351
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=20453], 2863 s, 351 iter, 600000 ts, 129 rew

agent-1: 139.0
Sum Reward: 139.0
Avg Reward: 139.0
Min Reward: 139.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
agent-1: 116.0
Sum Reward: 116.0
Avg Reward: 116.0
Min Reward: 116.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-54-33
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 180.0
  episode_reward_mean: 129.31
  episode_reward_min: 63.0
  episodes_this_iter: 2
  episodes_total: 601
  experiment_id: 325b24caee6c4209bf8cf01af4f33e4d
  hostname: gpu048
  info:
    apply_time_ms: 2.601
    dispatch_time_ms: 23.366
    learner:
      cur_lr: 0.001320039969868958
      grad_gnorm: 27.873695373535156
      policy_entropy: 4.993677616119385
      policy_loss: 0.9850741624832153
      var_gnorm: 30.469249725341797
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 6.555393695831299
    num_steps_sampled: 602000
    num_steps_trained: 602000
    wait_time_ms: 20.982
  iterations_since_restore: 352
  node_ip: 172.17.8.48
  num_metric_batches_dropped: 0
  pid: 20453
  policy_reward_mean: {}
  time_since_restore: 2872.6929042339325
  time_this_iter_s: 9.304565191268921
  time_total_s: 2872.6929042339325
  timestamp: 1593996873
  timesteps_since_restore: 602000
  timesteps_this_iter: 2000
  timesteps_total: 602000
  training_iteration: 352
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=20453], 2872 s, 352 iter, 602000 ts, 129 rew

agent-1: 127.0
Sum Reward: 127.0
Avg Reward: 127.0
Min Reward: 127.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
agent-1: 118.0
Sum Reward: 118.0
Avg Reward: 118.0
Min Reward: 118.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-54-38
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 180.0
  episode_reward_mean: 128.98
  episode_reward_min: 63.0
  episodes_this_iter: 2
  episodes_total: 603
  experiment_id: 325b24caee6c4209bf8cf01af4f33e4d
  hostname: gpu048
  info:
    apply_time_ms: 4.424
    dispatch_time_ms: 39.339
    learner:
      cur_lr: 0.001319906790740788
      grad_gnorm: 16.54690933227539
      policy_entropy: 2.7320826053619385
      policy_loss: -2.00105881690979
      var_gnorm: 30.473115921020508
      vf_explained_var: 0.0
      vf_loss: 1.8033759593963623
    num_steps_sampled: 603000
    num_steps_trained: 603000
    wait_time_ms: 14.876
  iterations_since_restore: 353
  node_ip: 172.17.8.48
  num_metric_batches_dropped: 0
  pid: 20453
  policy_reward_mean: {}
  time_since_restore: 2877.9521374702454
  time_this_iter_s: 5.259233236312866
  time_total_s: 2877.9521374702454
  timestamp: 1593996878
  timesteps_since_restore: 603000
  timesteps_this_iter: 1000
  timesteps_total: 603000
  training_iteration: 353
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=20453], 2877 s, 353 iter, 603000 ts, 129 rew

Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-54-44
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 180.0
  episode_reward_mean: 128.98
  episode_reward_min: 63.0
  episodes_this_iter: 0
  episodes_total: 603
  experiment_id: 325b24caee6c4209bf8cf01af4f33e4d
  hostname: gpu048
  info:
    apply_time_ms: 2.914
    dispatch_time_ms: 59.184
    learner:
      cur_lr: 0.001319840201176703
      grad_gnorm: 11.968819618225098
      policy_entropy: 4.04752779006958
      policy_loss: -2.160396099090576
      var_gnorm: 30.468814849853516
      vf_explained_var: 0.0
      vf_loss: 1.140023112297058
    num_steps_sampled: 604000
    num_steps_trained: 604000
    wait_time_ms: 26.267
  iterations_since_restore: 354
  node_ip: 172.17.8.48
  num_metric_batches_dropped: 0
  pid: 20453
  policy_reward_mean: {}
  time_since_restore: 2883.911337852478
  time_this_iter_s: 5.959200382232666
  time_total_s: 2883.911337852478
  timestamp: 1593996884
  timesteps_since_restore: 604000
  timesteps_this_iter: 1000
  timesteps_total: 604000
  training_iteration: 354
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=20453], 2883 s, 354 iter, 604000 ts, 129 rew

agent-1: 92.0
Sum Reward: 92.0
Avg Reward: 92.0
Min Reward: 92.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
agent-1: 162.0
Sum Reward: 162.0
Avg Reward: 162.0
Min Reward: 162.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-54-51
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 180.0
  episode_reward_mean: 129.45
  episode_reward_min: 63.0
  episodes_this_iter: 2
  episodes_total: 605
  experiment_id: 325b24caee6c4209bf8cf01af4f33e4d
  hostname: gpu048
  info:
    apply_time_ms: 2.827
    dispatch_time_ms: 38.811
    learner:
      cur_lr: 0.001319773611612618
      grad_gnorm: 15.446722984313965
      policy_entropy: 3.509249448776245
      policy_loss: 0.375297486782074
      var_gnorm: 30.4715518951416
      vf_explained_var: 0.0
      vf_loss: 2.1021888256073
    num_steps_sampled: 605000
    num_steps_trained: 605000
    wait_time_ms: 26.058
  iterations_since_restore: 355
  node_ip: 172.17.8.48
  num_metric_batches_dropped: 0
  pid: 20453
  policy_reward_mean: {}
  time_since_restore: 2890.633323431015
  time_this_iter_s: 6.721985578536987
  time_total_s: 2890.633323431015
  timestamp: 1593996891
  timesteps_since_restore: 605000
  timesteps_this_iter: 1000
  timesteps_total: 605000
  training_iteration: 355
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=20453], 2890 s, 355 iter, 605000 ts, 129 rew

Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-54-58
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 180.0
  episode_reward_mean: 129.45
  episode_reward_min: 63.0
  episodes_this_iter: 0
  episodes_total: 605
  experiment_id: 325b24caee6c4209bf8cf01af4f33e4d
  hostname: gpu048
  info:
    apply_time_ms: 3.065
    dispatch_time_ms: 37.079
    learner:
      cur_lr: 0.001319707022048533
      grad_gnorm: 39.999996185302734
      policy_entropy: 2.579505205154419
      policy_loss: 8.912322044372559
      var_gnorm: 30.47738265991211
      vf_explained_var: 0.0
      vf_loss: 30.818605422973633
    num_steps_sampled: 606000
    num_steps_trained: 606000
    wait_time_ms: 20.585
  iterations_since_restore: 356
  node_ip: 172.17.8.48
  num_metric_batches_dropped: 0
  pid: 20453
  policy_reward_mean: {}
  time_since_restore: 2897.4354314804077
  time_this_iter_s: 6.8021080493927
  time_total_s: 2897.4354314804077
  timestamp: 1593996898
  timesteps_since_restore: 606000
  timesteps_this_iter: 1000
  timesteps_total: 606000
  training_iteration: 356
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=20453], 2897 s, 356 iter, 606000 ts, 129 rew

agent-1: 103.0
Sum Reward: 103.0
Avg Reward: 103.0
Min Reward: 103.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
agent-1: 136.0
Sum Reward: 136.0
Avg Reward: 136.0
Min Reward: 136.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-55-05
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 180.0
  episode_reward_mean: 129.41
  episode_reward_min: 63.0
  episodes_this_iter: 2
  episodes_total: 607
  experiment_id: 325b24caee6c4209bf8cf01af4f33e4d
  hostname: gpu048
  info:
    apply_time_ms: 2.792
    dispatch_time_ms: 37.903
    learner:
      cur_lr: 0.001319640432484448
      grad_gnorm: 14.000632286071777
      policy_entropy: 2.0760653018951416
      policy_loss: -0.31279802322387695
      var_gnorm: 30.4781436920166
      vf_explained_var: 0.0
      vf_loss: 1.3910651206970215
    num_steps_sampled: 607000
    num_steps_trained: 607000
    wait_time_ms: 20.913
  iterations_since_restore: 357
  node_ip: 172.17.8.48
  num_metric_batches_dropped: 0
  pid: 20453
  policy_reward_mean: {}
  time_since_restore: 2904.127854824066
  time_this_iter_s: 6.692423343658447
  time_total_s: 2904.127854824066
  timestamp: 1593996905
  timesteps_since_restore: 607000
  timesteps_this_iter: 1000
  timesteps_total: 607000
  training_iteration: 357
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=20453], 2904 s, 357 iter, 607000 ts, 129 rew

Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-55-10
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 180.0
  episode_reward_mean: 129.41
  episode_reward_min: 63.0
  episodes_this_iter: 0
  episodes_total: 607
  experiment_id: 325b24caee6c4209bf8cf01af4f33e4d
  hostname: gpu048
  info:
    apply_time_ms: 3.506
    dispatch_time_ms: 8.498
    learner:
      cur_lr: 0.001319573842920363
      grad_gnorm: 23.406038284301758
      policy_entropy: 3.9115805625915527
      policy_loss: 1.010256052017212
      var_gnorm: 30.48591423034668
      vf_explained_var: 5.960464477539063e-08
      vf_loss: 9.521369934082031
    num_steps_sampled: 608000
    num_steps_trained: 608000
    wait_time_ms: 31.504
  iterations_since_restore: 358
  node_ip: 172.17.8.48
  num_metric_batches_dropped: 0
  pid: 20453
  policy_reward_mean: {}
  time_since_restore: 2909.51358127594
  time_this_iter_s: 5.385726451873779
  time_total_s: 2909.51358127594
  timestamp: 1593996910
  timesteps_since_restore: 608000
  timesteps_this_iter: 1000
  timesteps_total: 608000
  training_iteration: 358
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=20453], 2909 s, 358 iter, 608000 ts, 129 rew

agent-1: 89.0
Sum Reward: 89.0
Avg Reward: 89.0
Min Reward: 89.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
agent-1: 143.0
Sum Reward: 143.0
Avg Reward: 143.0
Min Reward: 143.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-55-18
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 180.0
  episode_reward_mean: 129.21
  episode_reward_min: 63.0
  episodes_this_iter: 2
  episodes_total: 609
  experiment_id: 325b24caee6c4209bf8cf01af4f33e4d
  hostname: gpu048
  info:
    apply_time_ms: 3.493
    dispatch_time_ms: 8.499
    learner:
      cur_lr: 0.001319507253356278
      grad_gnorm: 40.0
      policy_entropy: 2.9975736141204834
      policy_loss: 1.2373732328414917
      var_gnorm: 30.4613037109375
      vf_explained_var: 0.0
      vf_loss: 22.24568748474121
    num_steps_sampled: 610000
    num_steps_trained: 610000
    wait_time_ms: 28.66
  iterations_since_restore: 359
  node_ip: 172.17.8.48
  num_metric_batches_dropped: 0
  pid: 20453
  policy_reward_mean: {}
  time_since_restore: 2917.8978548049927
  time_this_iter_s: 8.384273529052734
  time_total_s: 2917.8978548049927
  timestamp: 1593996918
  timesteps_since_restore: 610000
  timesteps_this_iter: 2000
  timesteps_total: 610000
  training_iteration: 359
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=20453], 2917 s, 359 iter, 610000 ts, 129 rew

agent-1: 123.0
Sum Reward: 123.0
Avg Reward: 123.0
Min Reward: 123.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
agent-1: 103.0
Sum Reward: 103.0
Avg Reward: 103.0
Min Reward: 103.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-55-27
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 180.0
  episode_reward_mean: 129.23
  episode_reward_min: 63.0
  episodes_this_iter: 2
  episodes_total: 611
  experiment_id: 325b24caee6c4209bf8cf01af4f33e4d
  hostname: gpu048
  info:
    apply_time_ms: 2.824
    dispatch_time_ms: 6.694
    learner:
      cur_lr: 0.001319373957812786
      grad_gnorm: 18.521146774291992
      policy_entropy: 2.5554232597351074
      policy_loss: -0.4230465292930603
      var_gnorm: 30.49605941772461
      vf_explained_var: 0.0
      vf_loss: 2.119708299636841
    num_steps_sampled: 612000
    num_steps_trained: 612000
    wait_time_ms: 32.251
  iterations_since_restore: 360
  node_ip: 172.17.8.48
  num_metric_batches_dropped: 0
  pid: 20453
  policy_reward_mean: {}
  time_since_restore: 2926.2560884952545
  time_this_iter_s: 8.35823369026184
  time_total_s: 2926.2560884952545
  timestamp: 1593996927
  timesteps_since_restore: 612000
  timesteps_this_iter: 2000
  timesteps_total: 612000
  training_iteration: 360
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=20453], 2926 s, 360 iter, 612000 ts, 129 rew

agent-1: 154.0
Sum Reward: 154.0
Avg Reward: 154.0
Min Reward: 154.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
agent-1: 142.0
Sum Reward: 142.0
Avg Reward: 142.0
Min Reward: 142.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-55-35
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 180.0
  episode_reward_mean: 129.33
  episode_reward_min: 63.0
  episodes_this_iter: 2
  episodes_total: 613
  experiment_id: 325b24caee6c4209bf8cf01af4f33e4d
  hostname: gpu048
  info:
    apply_time_ms: 4.042
    dispatch_time_ms: 8.893
    learner:
      cur_lr: 0.001319240778684616
      grad_gnorm: 31.892288208007812
      policy_entropy: 2.7489218711853027
      policy_loss: 7.7559494972229
      var_gnorm: 30.49846839904785
      vf_explained_var: 1.1920928955078125e-07
      vf_loss: 11.92774772644043
    num_steps_sampled: 614000
    num_steps_trained: 614000
    wait_time_ms: 29.584
  iterations_since_restore: 361
  node_ip: 172.17.8.48
  num_metric_batches_dropped: 0
  pid: 20453
  policy_reward_mean: {}
  time_since_restore: 2934.465218782425
  time_this_iter_s: 8.20913028717041
  time_total_s: 2934.465218782425
  timestamp: 1593996935
  timesteps_since_restore: 614000
  timesteps_this_iter: 2000
  timesteps_total: 614000
  training_iteration: 361
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=20453], 2934 s, 361 iter, 614000 ts, 129 rew

agent-1: 144.0
Sum Reward: 144.0
Avg Reward: 144.0
Min Reward: 144.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
agent-1: 117.0
Sum Reward: 117.0
Avg Reward: 117.0
Min Reward: 117.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-55-43
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 180.0
  episode_reward_mean: 129.83
  episode_reward_min: 63.0
  episodes_this_iter: 2
  episodes_total: 615
  experiment_id: 325b24caee6c4209bf8cf01af4f33e4d
  hostname: gpu048
  info:
    apply_time_ms: 3.9
    dispatch_time_ms: 7.482
    learner:
      cur_lr: 0.001319107599556446
      grad_gnorm: 0.43780800700187683
      policy_entropy: 4.194973945617676
      policy_loss: -0.015374813228845596
      var_gnorm: 30.5043888092041
      vf_explained_var: 0.0
      vf_loss: 0.378229022026062
    num_steps_sampled: 616000
    num_steps_trained: 616000
    wait_time_ms: 29.861
  iterations_since_restore: 362
  node_ip: 172.17.8.48
  num_metric_batches_dropped: 0
  pid: 20453
  policy_reward_mean: {}
  time_since_restore: 2942.8772599697113
  time_this_iter_s: 8.412041187286377
  time_total_s: 2942.8772599697113
  timestamp: 1593996943
  timesteps_since_restore: 616000
  timesteps_this_iter: 2000
  timesteps_total: 616000
  training_iteration: 362
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=20453], 2942 s, 362 iter, 616000 ts, 130 rew

agent-1: 138.0
Sum Reward: 138.0
Avg Reward: 138.0
Min Reward: 138.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
agent-1: 117.0
Sum Reward: 117.0
Avg Reward: 117.0
Min Reward: 117.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-55-52
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 180.0
  episode_reward_mean: 129.64
  episode_reward_min: 63.0
  episodes_this_iter: 2
  episodes_total: 617
  experiment_id: 325b24caee6c4209bf8cf01af4f33e4d
  hostname: gpu048
  info:
    apply_time_ms: 3.199
    dispatch_time_ms: 7.396
    learner:
      cur_lr: 0.001318974420428276
      grad_gnorm: 5.937360763549805
      policy_entropy: 3.2812201976776123
      policy_loss: -0.17944449186325073
      var_gnorm: 30.50465202331543
      vf_explained_var: 0.0
      vf_loss: 1.2465201616287231
    num_steps_sampled: 618000
    num_steps_trained: 618000
    wait_time_ms: 31.093
  iterations_since_restore: 363
  node_ip: 172.17.8.48
  num_metric_batches_dropped: 0
  pid: 20453
  policy_reward_mean: {}
  time_since_restore: 2951.27482008934
  time_this_iter_s: 8.397560119628906
  time_total_s: 2951.27482008934
  timestamp: 1593996952
  timesteps_since_restore: 618000
  timesteps_this_iter: 2000
  timesteps_total: 618000
  training_iteration: 363
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=20453], 2951 s, 363 iter, 618000 ts, 130 rew

agent-1: 132.0
Sum Reward: 132.0
Avg Reward: 132.0
Min Reward: 132.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
agent-1: 145.0
Sum Reward: 145.0
Avg Reward: 145.0
Min Reward: 145.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-56-00
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 180.0
  episode_reward_mean: 130.6
  episode_reward_min: 63.0
  episodes_this_iter: 2
  episodes_total: 619
  experiment_id: 325b24caee6c4209bf8cf01af4f33e4d
  hostname: gpu048
  info:
    apply_time_ms: 3.101
    dispatch_time_ms: 7.127
    learner:
      cur_lr: 0.001318841241300106
      grad_gnorm: 40.0
      policy_entropy: 3.6847524642944336
      policy_loss: 7.209969520568848
      var_gnorm: 30.49018669128418
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 8.875373840332031
    num_steps_sampled: 620000
    num_steps_trained: 620000
    wait_time_ms: 31.795
  iterations_since_restore: 364
  node_ip: 172.17.8.48
  num_metric_batches_dropped: 0
  pid: 20453
  policy_reward_mean: {}
  time_since_restore: 2959.5583970546722
  time_this_iter_s: 8.283576965332031
  time_total_s: 2959.5583970546722
  timestamp: 1593996960
  timesteps_since_restore: 620000
  timesteps_this_iter: 2000
  timesteps_total: 620000
  training_iteration: 364
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=20453], 2959 s, 364 iter, 620000 ts, 131 rew

agent-1: 83.0
Sum Reward: 83.0
Avg Reward: 83.0
Min Reward: 83.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
agent-1: 125.0
Sum Reward: 125.0
Avg Reward: 125.0
Min Reward: 125.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-56-09
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 180.0
  episode_reward_mean: 129.94
  episode_reward_min: 63.0
  episodes_this_iter: 2
  episodes_total: 621
  experiment_id: 325b24caee6c4209bf8cf01af4f33e4d
  hostname: gpu048
  info:
    apply_time_ms: 3.994
    dispatch_time_ms: 7.989
    learner:
      cur_lr: 0.0013187079457566142
      grad_gnorm: 27.226245880126953
      policy_entropy: 3.609361171722412
      policy_loss: 2.0996041297912598
      var_gnorm: 30.488845825195312
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 6.449697017669678
    num_steps_sampled: 622000
    num_steps_trained: 622000
    wait_time_ms: 30.097
  iterations_since_restore: 365
  node_ip: 172.17.8.48
  num_metric_batches_dropped: 0
  pid: 20453
  policy_reward_mean: {}
  time_since_restore: 2967.854872941971
  time_this_iter_s: 8.296475887298584
  time_total_s: 2967.854872941971
  timestamp: 1593996969
  timesteps_since_restore: 622000
  timesteps_this_iter: 2000
  timesteps_total: 622000
  training_iteration: 365
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=20453], 2967 s, 365 iter, 622000 ts, 130 rew

agent-1: 151.0
Sum Reward: 151.0
Avg Reward: 151.0
Min Reward: 151.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
agent-1: 117.0
Sum Reward: 117.0
Avg Reward: 117.0
Min Reward: 117.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-56-19
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 180.0
  episode_reward_mean: 130.09
  episode_reward_min: 63.0
  episodes_this_iter: 2
  episodes_total: 623
  experiment_id: 325b24caee6c4209bf8cf01af4f33e4d
  hostname: gpu048
  info:
    apply_time_ms: 3.1
    dispatch_time_ms: 41.791
    learner:
      cur_lr: 0.0013185747666284442
      grad_gnorm: 11.735976219177246
      policy_entropy: 4.333414554595947
      policy_loss: -1.881644368171692
      var_gnorm: 30.510364532470703
      vf_explained_var: 0.0
      vf_loss: 3.386385679244995
    num_steps_sampled: 624000
    num_steps_trained: 624000
    wait_time_ms: 17.778
  iterations_since_restore: 366
  node_ip: 172.17.8.48
  num_metric_batches_dropped: 0
  pid: 20453
  policy_reward_mean: {}
  time_since_restore: 2978.272983789444
  time_this_iter_s: 10.418110847473145
  time_total_s: 2978.272983789444
  timestamp: 1593996979
  timesteps_since_restore: 624000
  timesteps_this_iter: 2000
  timesteps_total: 624000
  training_iteration: 366
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=20453], 2978 s, 366 iter, 624000 ts, 130 rew

agent-1: 158.0
Sum Reward: 158.0
Avg Reward: 158.0
Min Reward: 158.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-56-26
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 180.0
  episode_reward_mean: 130.17
  episode_reward_min: 63.0
  episodes_this_iter: 1
  episodes_total: 624
  experiment_id: 325b24caee6c4209bf8cf01af4f33e4d
  hostname: gpu048
  info:
    apply_time_ms: 2.778
    dispatch_time_ms: 48.323
    learner:
      cur_lr: 0.0013184415875002742
      grad_gnorm: 20.478899002075195
      policy_entropy: 2.7078464031219482
      policy_loss: 1.6943933963775635
      var_gnorm: 30.52227783203125
      vf_explained_var: 0.0
      vf_loss: 2.4576730728149414
    num_steps_sampled: 625000
    num_steps_trained: 625000
    wait_time_ms: 18.181
  iterations_since_restore: 367
  node_ip: 172.17.8.48
  num_metric_batches_dropped: 0
  pid: 20453
  policy_reward_mean: {}
  time_since_restore: 2985.3016872406006
  time_this_iter_s: 7.028703451156616
  time_total_s: 2985.3016872406006
  timestamp: 1593996986
  timesteps_since_restore: 625000
  timesteps_this_iter: 1000
  timesteps_total: 625000
  training_iteration: 367
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=20453], 2985 s, 367 iter, 625000 ts, 130 rew

agent-1: 142.0
Sum Reward: 142.0
Avg Reward: 142.0
Min Reward: 142.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-56-33
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 180.0
  episode_reward_mean: 130.29
  episode_reward_min: 63.0
  episodes_this_iter: 1
  episodes_total: 625
  experiment_id: 325b24caee6c4209bf8cf01af4f33e4d
  hostname: gpu048
  info:
    apply_time_ms: 4.426
    dispatch_time_ms: 39.456
    learner:
      cur_lr: 0.0013183749979361892
      grad_gnorm: 13.891899108886719
      policy_entropy: 2.137495517730713
      policy_loss: -0.41743820905685425
      var_gnorm: 30.508878707885742
      vf_explained_var: 0.0
      vf_loss: 2.425684928894043
    num_steps_sampled: 626000
    num_steps_trained: 626000
    wait_time_ms: 19.925
  iterations_since_restore: 368
  node_ip: 172.17.8.48
  num_metric_batches_dropped: 0
  pid: 20453
  policy_reward_mean: {}
  time_since_restore: 2992.081323623657
  time_this_iter_s: 6.779636383056641
  time_total_s: 2992.081323623657
  timestamp: 1593996993
  timesteps_since_restore: 626000
  timesteps_this_iter: 1000
  timesteps_total: 626000
  training_iteration: 368
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=20453], 2992 s, 368 iter, 626000 ts, 130 rew

agent-1: 118.0
Sum Reward: 118.0
Avg Reward: 118.0
Min Reward: 118.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-56-40
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 180.0
  episode_reward_mean: 130.13
  episode_reward_min: 63.0
  episodes_this_iter: 1
  episodes_total: 626
  experiment_id: 325b24caee6c4209bf8cf01af4f33e4d
  hostname: gpu048
  info:
    apply_time_ms: 2.578
    dispatch_time_ms: 50.201
    learner:
      cur_lr: 0.0013183084083721042
      grad_gnorm: 39.999996185302734
      policy_entropy: 3.9848718643188477
      policy_loss: 5.019742488861084
      var_gnorm: 30.509077072143555
      vf_explained_var: 0.0
      vf_loss: 14.359538078308105
    num_steps_sampled: 627000
    num_steps_trained: 627000
    wait_time_ms: 26.99
  iterations_since_restore: 369
  node_ip: 172.17.8.48
  num_metric_batches_dropped: 0
  pid: 20453
  policy_reward_mean: {}
  time_since_restore: 2999.0892798900604
  time_this_iter_s: 7.007956266403198
  time_total_s: 2999.0892798900604
  timestamp: 1593997000
  timesteps_since_restore: 627000
  timesteps_this_iter: 1000
  timesteps_total: 627000
  training_iteration: 369
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=20453], 2999 s, 369 iter, 627000 ts, 130 rew

agent-1: 100.0
Sum Reward: 100.0
Avg Reward: 100.0
Min Reward: 100.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-56-58
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 180.0
  episode_reward_mean: 129.61
  episode_reward_min: 63.0
  episodes_this_iter: 1
  episodes_total: 627
  experiment_id: 325b24caee6c4209bf8cf01af4f33e4d
  hostname: gpu048
  info:
    apply_time_ms: 3.742
    dispatch_time_ms: 1144.487
    learner:
      cur_lr: 0.0013182418188080192
      grad_gnorm: 8.316352844238281
      policy_entropy: 3.0624513626098633
      policy_loss: 0.6099476218223572
      var_gnorm: 30.502696990966797
      vf_explained_var: 0.0
      vf_loss: 0.7638793587684631
    num_steps_sampled: 628000
    num_steps_trained: 628000
    wait_time_ms: 26.347
  iterations_since_restore: 370
  node_ip: 172.17.8.48
  num_metric_batches_dropped: 0
  pid: 20453
  policy_reward_mean: {}
  time_since_restore: 3017.21057844162
  time_this_iter_s: 18.12129855155945
  time_total_s: 3017.21057844162
  timestamp: 1593997018
  timesteps_since_restore: 628000
  timesteps_this_iter: 1000
  timesteps_total: 628000
  training_iteration: 370
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=20453], 3017 s, 370 iter, 628000 ts, 130 rew

agent-1: 142.0
Sum Reward: 142.0
Avg Reward: 142.0
Min Reward: 142.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
agent-1: 58.0
Sum Reward: 58.0
Avg Reward: 58.0
Min Reward: 58.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-57-06
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 180.0
  episode_reward_mean: 128.96
  episode_reward_min: 58.0
  episodes_this_iter: 2
  episodes_total: 629
  experiment_id: 325b24caee6c4209bf8cf01af4f33e4d
  hostname: gpu048
  info:
    apply_time_ms: 3.264
    dispatch_time_ms: 7.88
    learner:
      cur_lr: 0.0013181752292439342
      grad_gnorm: 7.775057792663574
      policy_entropy: 3.3561861515045166
      policy_loss: -0.06895554065704346
      var_gnorm: 30.50494956970215
      vf_explained_var: 0.0
      vf_loss: 0.6870037317276001
    num_steps_sampled: 630000
    num_steps_trained: 630000
    wait_time_ms: 28.528
  iterations_since_restore: 371
  node_ip: 172.17.8.48
  num_metric_batches_dropped: 0
  pid: 20453
  policy_reward_mean: {}
  time_since_restore: 3025.3199837207794
  time_this_iter_s: 8.109405279159546
  time_total_s: 3025.3199837207794
  timestamp: 1593997026
  timesteps_since_restore: 630000
  timesteps_this_iter: 2000
  timesteps_total: 630000
  training_iteration: 371
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=20453], 3025 s, 371 iter, 630000 ts, 129 rew

agent-1: 162.0
Sum Reward: 162.0
Avg Reward: 162.0
Min Reward: 162.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
agent-1: 117.0
Sum Reward: 117.0
Avg Reward: 117.0
Min Reward: 117.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-57-15
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 180.0
  episode_reward_mean: 129.41
  episode_reward_min: 58.0
  episodes_this_iter: 2
  episodes_total: 631
  experiment_id: 325b24caee6c4209bf8cf01af4f33e4d
  hostname: gpu048
  info:
    apply_time_ms: 3.225
    dispatch_time_ms: 7.24
    learner:
      cur_lr: 0.0013180420501157641
      grad_gnorm: 17.63800621032715
      policy_entropy: 2.8284265995025635
      policy_loss: -1.4923276901245117
      var_gnorm: 30.517356872558594
      vf_explained_var: 0.0
      vf_loss: 1.9975632429122925
    num_steps_sampled: 632000
    num_steps_trained: 632000
    wait_time_ms: 32.737
  iterations_since_restore: 372
  node_ip: 172.17.8.48
  num_metric_batches_dropped: 0
  pid: 20453
  policy_reward_mean: {}
  time_since_restore: 3033.724624156952
  time_this_iter_s: 8.404640436172485
  time_total_s: 3033.724624156952
  timestamp: 1593997035
  timesteps_since_restore: 632000
  timesteps_this_iter: 2000
  timesteps_total: 632000
  training_iteration: 372
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=20453], 3033 s, 372 iter, 632000 ts, 129 rew

agent-1: 140.0
Sum Reward: 140.0
Avg Reward: 140.0
Min Reward: 140.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
agent-1: 158.0
Sum Reward: 158.0
Avg Reward: 158.0
Min Reward: 158.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-57-23
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 180.0
  episode_reward_mean: 130.26
  episode_reward_min: 58.0
  episodes_this_iter: 2
  episodes_total: 633
  experiment_id: 325b24caee6c4209bf8cf01af4f33e4d
  hostname: gpu048
  info:
    apply_time_ms: 3.976
    dispatch_time_ms: 8.691
    learner:
      cur_lr: 0.0013179087545722723
      grad_gnorm: 19.447675704956055
      policy_entropy: 1.97774076461792
      policy_loss: -1.6632548570632935
      var_gnorm: 30.53838348388672
      vf_explained_var: 0.0
      vf_loss: 2.4190311431884766
    num_steps_sampled: 634000
    num_steps_trained: 634000
    wait_time_ms: 31.595
  iterations_since_restore: 373
  node_ip: 172.17.8.48
  num_metric_batches_dropped: 0
  pid: 20453
  policy_reward_mean: {}
  time_since_restore: 3042.136503458023
  time_this_iter_s: 8.411879301071167
  time_total_s: 3042.136503458023
  timestamp: 1593997043
  timesteps_since_restore: 634000
  timesteps_this_iter: 2000
  timesteps_total: 634000
  training_iteration: 373
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=20453], 3042 s, 373 iter, 634000 ts, 130 rew

agent-1: 115.0
Sum Reward: 115.0
Avg Reward: 115.0
Min Reward: 115.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
agent-1: 129.0
Sum Reward: 129.0
Avg Reward: 129.0
Min Reward: 129.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-57-31
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 180.0
  episode_reward_mean: 129.76
  episode_reward_min: 58.0
  episodes_this_iter: 2
  episodes_total: 635
  experiment_id: 325b24caee6c4209bf8cf01af4f33e4d
  hostname: gpu048
  info:
    apply_time_ms: 4.146
    dispatch_time_ms: 8.367
    learner:
      cur_lr: 0.0013177755754441023
      grad_gnorm: 25.105731964111328
      policy_entropy: 4.2582550048828125
      policy_loss: -5.848691940307617
      var_gnorm: 30.53000831604004
      vf_explained_var: 0.0
      vf_loss: 2.19524884223938
    num_steps_sampled: 636000
    num_steps_trained: 636000
    wait_time_ms: 29.094
  iterations_since_restore: 374
  node_ip: 172.17.8.48
  num_metric_batches_dropped: 0
  pid: 20453
  policy_reward_mean: {}
  time_since_restore: 3050.533101797104
  time_this_iter_s: 8.39659833908081
  time_total_s: 3050.533101797104
  timestamp: 1593997051
  timesteps_since_restore: 636000
  timesteps_this_iter: 2000
  timesteps_total: 636000
  training_iteration: 374
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=20453], 3050 s, 374 iter, 636000 ts, 130 rew

agent-1: 155.0
Sum Reward: 155.0
Avg Reward: 155.0
Min Reward: 155.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
agent-1: 104.0
Sum Reward: 104.0
Avg Reward: 104.0
Min Reward: 104.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-57-40
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 180.0
  episode_reward_mean: 130.26
  episode_reward_min: 58.0
  episodes_this_iter: 2
  episodes_total: 637
  experiment_id: 325b24caee6c4209bf8cf01af4f33e4d
  hostname: gpu048
  info:
    apply_time_ms: 3.17
    dispatch_time_ms: 8.138
    learner:
      cur_lr: 0.0013176423963159323
      grad_gnorm: 39.999996185302734
      policy_entropy: 3.8243331909179688
      policy_loss: 12.02627944946289
      var_gnorm: 30.52309799194336
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 26.43462371826172
    num_steps_sampled: 638000
    num_steps_trained: 638000
    wait_time_ms: 30.517
  iterations_since_restore: 375
  node_ip: 172.17.8.48
  num_metric_batches_dropped: 0
  pid: 20453
  policy_reward_mean: {}
  time_since_restore: 3058.867517709732
  time_this_iter_s: 8.334415912628174
  time_total_s: 3058.867517709732
  timestamp: 1593997060
  timesteps_since_restore: 638000
  timesteps_this_iter: 2000
  timesteps_total: 638000
  training_iteration: 375
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=20453], 3058 s, 375 iter, 638000 ts, 130 rew

agent-1: 116.0
Sum Reward: 116.0
Avg Reward: 116.0
Min Reward: 116.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
agent-1: 174.0
Sum Reward: 174.0
Avg Reward: 174.0
Min Reward: 174.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-57-48
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 180.0
  episode_reward_mean: 130.52
  episode_reward_min: 58.0
  episodes_this_iter: 2
  episodes_total: 639
  experiment_id: 325b24caee6c4209bf8cf01af4f33e4d
  hostname: gpu048
  info:
    apply_time_ms: 3.044
    dispatch_time_ms: 6.362
    learner:
      cur_lr: 0.0013175092171877623
      grad_gnorm: 5.7575459480285645
      policy_entropy: 4.98053503036499
      policy_loss: -0.9980010986328125
      var_gnorm: 30.565217971801758
      vf_explained_var: 1.1920928955078125e-07
      vf_loss: 0.3882896602153778
    num_steps_sampled: 640000
    num_steps_trained: 640000
    wait_time_ms: 31.71
  iterations_since_restore: 376
  node_ip: 172.17.8.48
  num_metric_batches_dropped: 0
  pid: 20453
  policy_reward_mean: {}
  time_since_restore: 3067.0525453090668
  time_this_iter_s: 8.185027599334717
  time_total_s: 3067.0525453090668
  timestamp: 1593997068
  timesteps_since_restore: 640000
  timesteps_this_iter: 2000
  timesteps_total: 640000
  training_iteration: 376
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=20453], 3067 s, 376 iter, 640000 ts, 131 rew

agent-1: 155.0
Sum Reward: 155.0
Avg Reward: 155.0
Min Reward: 155.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
agent-1: 106.0
Sum Reward: 106.0
Avg Reward: 106.0
Min Reward: 106.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-57-57
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 180.0
  episode_reward_mean: 131.12
  episode_reward_min: 58.0
  episodes_this_iter: 2
  episodes_total: 641
  experiment_id: 325b24caee6c4209bf8cf01af4f33e4d
  hostname: gpu048
  info:
    apply_time_ms: 3.215
    dispatch_time_ms: 7.905
    learner:
      cur_lr: 0.0013173760380595922
      grad_gnorm: 40.0
      policy_entropy: 4.6502156257629395
      policy_loss: 8.173154830932617
      var_gnorm: 30.5325927734375
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 12.729986190795898
    num_steps_sampled: 642000
    num_steps_trained: 642000
    wait_time_ms: 32.313
  iterations_since_restore: 377
  node_ip: 172.17.8.48
  num_metric_batches_dropped: 0
  pid: 20453
  policy_reward_mean: {}
  time_since_restore: 3075.508001804352
  time_this_iter_s: 8.455456495285034
  time_total_s: 3075.508001804352
  timestamp: 1593997077
  timesteps_since_restore: 642000
  timesteps_this_iter: 2000
  timesteps_total: 642000
  training_iteration: 377
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=20453], 3075 s, 377 iter, 642000 ts, 131 rew

agent-1: 104.0
Sum Reward: 104.0
Avg Reward: 104.0
Min Reward: 104.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
agent-1: 110.0
Sum Reward: 110.0
Avg Reward: 110.0
Min Reward: 110.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-58-05
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 180.0
  episode_reward_mean: 130.32
  episode_reward_min: 58.0
  episodes_this_iter: 2
  episodes_total: 643
  experiment_id: 325b24caee6c4209bf8cf01af4f33e4d
  hostname: gpu048
  info:
    apply_time_ms: 3.011
    dispatch_time_ms: 8.068
    learner:
      cur_lr: 0.0013172427425161004
      grad_gnorm: 36.70808029174805
      policy_entropy: 3.0939652919769287
      policy_loss: 3.536892890930176
      var_gnorm: 30.532968521118164
      vf_explained_var: 5.960464477539063e-08
      vf_loss: 7.296281814575195
    num_steps_sampled: 644000
    num_steps_trained: 644000
    wait_time_ms: 29.003
  iterations_since_restore: 378
  node_ip: 172.17.8.48
  num_metric_batches_dropped: 0
  pid: 20453
  policy_reward_mean: {}
  time_since_restore: 3083.8013055324554
  time_this_iter_s: 8.293303728103638
  time_total_s: 3083.8013055324554
  timestamp: 1593997085
  timesteps_since_restore: 644000
  timesteps_this_iter: 2000
  timesteps_total: 644000
  training_iteration: 378
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=20453], 3083 s, 378 iter, 644000 ts, 130 rew

agent-1: 133.0
Sum Reward: 133.0
Avg Reward: 133.0
Min Reward: 133.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-58-11
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 180.0
  episode_reward_mean: 130.17
  episode_reward_min: 58.0
  episodes_this_iter: 1
  episodes_total: 644
  experiment_id: 325b24caee6c4209bf8cf01af4f33e4d
  hostname: gpu048
  info:
    apply_time_ms: 2.657
    dispatch_time_ms: 44.119
    learner:
      cur_lr: 0.0013171095633879304
      grad_gnorm: 15.827670097351074
      policy_entropy: 2.394167423248291
      policy_loss: -3.68021297454834
      var_gnorm: 30.533084869384766
      vf_explained_var: 0.0
      vf_loss: 1.3920022249221802
    num_steps_sampled: 645000
    num_steps_trained: 645000
    wait_time_ms: 20.257
  iterations_since_restore: 379
  node_ip: 172.17.8.48
  num_metric_batches_dropped: 0
  pid: 20453
  policy_reward_mean: {}
  time_since_restore: 3089.52715921402
  time_this_iter_s: 5.725853681564331
  time_total_s: 3089.52715921402
  timestamp: 1593997091
  timesteps_since_restore: 645000
  timesteps_this_iter: 1000
  timesteps_total: 645000
  training_iteration: 379
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=20453], 3089 s, 379 iter, 645000 ts, 130 rew

agent-1: 121.0
Sum Reward: 121.0
Avg Reward: 121.0
Min Reward: 121.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-58-17
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 180.0
  episode_reward_mean: 130.27
  episode_reward_min: 58.0
  episodes_this_iter: 1
  episodes_total: 645
  experiment_id: 325b24caee6c4209bf8cf01af4f33e4d
  hostname: gpu048
  info:
    apply_time_ms: 2.616
    dispatch_time_ms: 54.771
    learner:
      cur_lr: 0.0013170429738238454
      grad_gnorm: 14.892754554748535
      policy_entropy: 4.923299789428711
      policy_loss: -2.9810428619384766
      var_gnorm: 30.534814834594727
      vf_explained_var: 0.0
      vf_loss: 1.5437719821929932
    num_steps_sampled: 646000
    num_steps_trained: 646000
    wait_time_ms: 23.492
  iterations_since_restore: 380
  node_ip: 172.17.8.48
  num_metric_batches_dropped: 0
  pid: 20453
  policy_reward_mean: {}
  time_since_restore: 3095.9463918209076
  time_this_iter_s: 6.419232606887817
  time_total_s: 3095.9463918209076
  timestamp: 1593997097
  timesteps_since_restore: 646000
  timesteps_this_iter: 1000
  timesteps_total: 646000
  training_iteration: 380
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=20453], 3095 s, 380 iter, 646000 ts, 130 rew

agent-1: 117.0
Sum Reward: 117.0
Avg Reward: 117.0
Min Reward: 117.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-58-24
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 180.0
  episode_reward_mean: 130.63
  episode_reward_min: 58.0
  episodes_this_iter: 1
  episodes_total: 646
  experiment_id: 325b24caee6c4209bf8cf01af4f33e4d
  hostname: gpu048
  info:
    apply_time_ms: 2.488
    dispatch_time_ms: 54.196
    learner:
      cur_lr: 0.0013169763842597604
      grad_gnorm: 21.557477951049805
      policy_entropy: 2.4661903381347656
      policy_loss: -0.38685178756713867
      var_gnorm: 30.53716468811035
      vf_explained_var: 0.0
      vf_loss: 2.7138102054595947
    num_steps_sampled: 647000
    num_steps_trained: 647000
    wait_time_ms: 18.955
  iterations_since_restore: 381
  node_ip: 172.17.8.48
  num_metric_batches_dropped: 0
  pid: 20453
  policy_reward_mean: {}
  time_since_restore: 3102.72944188118
  time_this_iter_s: 6.783050060272217
  time_total_s: 3102.72944188118
  timestamp: 1593997104
  timesteps_since_restore: 647000
  timesteps_this_iter: 1000
  timesteps_total: 647000
  training_iteration: 381
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=20453], 3102 s, 381 iter, 647000 ts, 131 rew

agent-1: 124.0
Sum Reward: 124.0
Avg Reward: 124.0
Min Reward: 124.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-58-31
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 180.0
  episode_reward_mean: 130.74
  episode_reward_min: 58.0
  episodes_this_iter: 1
  episodes_total: 647
  experiment_id: 325b24caee6c4209bf8cf01af4f33e4d
  hostname: gpu048
  info:
    apply_time_ms: 2.959
    dispatch_time_ms: 58.948
    learner:
      cur_lr: 0.0013169097946956754
      grad_gnorm: 12.804985046386719
      policy_entropy: 1.5614972114562988
      policy_loss: -0.1953721046447754
      var_gnorm: 30.526100158691406
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 1.1848840713500977
    num_steps_sampled: 648000
    num_steps_trained: 648000
    wait_time_ms: 21.54
  iterations_since_restore: 382
  node_ip: 172.17.8.48
  num_metric_batches_dropped: 0
  pid: 20453
  policy_reward_mean: {}
  time_since_restore: 3109.4714879989624
  time_this_iter_s: 6.742046117782593
  time_total_s: 3109.4714879989624
  timestamp: 1593997111
  timesteps_since_restore: 648000
  timesteps_this_iter: 1000
  timesteps_total: 648000
  training_iteration: 382
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=20453], 3109 s, 382 iter, 648000 ts, 131 rew

agent-1: 90.0
Sum Reward: 90.0
Avg Reward: 90.0
Min Reward: 90.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
agent-1: 112.0
Sum Reward: 112.0
Avg Reward: 112.0
Min Reward: 112.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-58-39
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 180.0
  episode_reward_mean: 130.16
  episode_reward_min: 58.0
  episodes_this_iter: 2
  episodes_total: 649
  experiment_id: 325b24caee6c4209bf8cf01af4f33e4d
  hostname: gpu048
  info:
    apply_time_ms: 3.613
    dispatch_time_ms: 10.54
    learner:
      cur_lr: 0.0013168432051315904
      grad_gnorm: 40.0
      policy_entropy: 2.2810041904449463
      policy_loss: 9.29921817779541
      var_gnorm: 30.51528549194336
      vf_explained_var: 0.0
      vf_loss: 9.397192001342773
    num_steps_sampled: 650000
    num_steps_trained: 650000
    wait_time_ms: 26.833
  iterations_since_restore: 383
  node_ip: 172.17.8.48
  num_metric_batches_dropped: 0
  pid: 20453
  policy_reward_mean: {}
  time_since_restore: 3117.63903093338
  time_this_iter_s: 8.167542934417725
  time_total_s: 3117.63903093338
  timestamp: 1593997119
  timesteps_since_restore: 650000
  timesteps_this_iter: 2000
  timesteps_total: 650000
  training_iteration: 383
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=20453], 3117 s, 383 iter, 650000 ts, 130 rew

agent-1: 108.0
Sum Reward: 108.0
Avg Reward: 108.0
Min Reward: 108.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
agent-1: 130.0
Sum Reward: 130.0
Avg Reward: 130.0
Min Reward: 130.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-58-47
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 180.0
  episode_reward_mean: 129.99
  episode_reward_min: 58.0
  episodes_this_iter: 2
  episodes_total: 651
  experiment_id: 325b24caee6c4209bf8cf01af4f33e4d
  hostname: gpu048
  info:
    apply_time_ms: 3.171
    dispatch_time_ms: 7.783
    learner:
      cur_lr: 0.0013167100260034204
      grad_gnorm: 40.0
      policy_entropy: 2.4746930599212646
      policy_loss: 16.463743209838867
      var_gnorm: 30.547887802124023
      vf_explained_var: 0.0
      vf_loss: 21.908506393432617
    num_steps_sampled: 652000
    num_steps_trained: 652000
    wait_time_ms: 30.161
  iterations_since_restore: 384
  node_ip: 172.17.8.48
  num_metric_batches_dropped: 0
  pid: 20453
  policy_reward_mean: {}
  time_since_restore: 3126.0213499069214
  time_this_iter_s: 8.38231897354126
  time_total_s: 3126.0213499069214
  timestamp: 1593997127
  timesteps_since_restore: 652000
  timesteps_this_iter: 2000
  timesteps_total: 652000
  training_iteration: 384
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=20453], 3126 s, 384 iter, 652000 ts, 130 rew

agent-1: 164.0
Sum Reward: 164.0
Avg Reward: 164.0
Min Reward: 164.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
agent-1: 166.0
Sum Reward: 166.0
Avg Reward: 166.0
Min Reward: 166.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-58-57
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 180.0
  episode_reward_mean: 130.35
  episode_reward_min: 58.0
  episodes_this_iter: 2
  episodes_total: 653
  experiment_id: 325b24caee6c4209bf8cf01af4f33e4d
  hostname: gpu048
  info:
    apply_time_ms: 2.751
    dispatch_time_ms: 29.039
    learner:
      cur_lr: 0.0013165768468752503
      grad_gnorm: 40.000003814697266
      policy_entropy: 3.2514488697052
      policy_loss: 8.695100784301758
      var_gnorm: 30.583066940307617
      vf_explained_var: 0.0
      vf_loss: 22.284523010253906
    num_steps_sampled: 654000
    num_steps_trained: 654000
    wait_time_ms: 18.509
  iterations_since_restore: 385
  node_ip: 172.17.8.48
  num_metric_batches_dropped: 0
  pid: 20453
  policy_reward_mean: {}
  time_since_restore: 3135.716284751892
  time_this_iter_s: 9.694934844970703
  time_total_s: 3135.716284751892
  timestamp: 1593997137
  timesteps_since_restore: 654000
  timesteps_this_iter: 2000
  timesteps_total: 654000
  training_iteration: 385
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=20453], 3135 s, 385 iter, 654000 ts, 130 rew

agent-1: 171.0
Sum Reward: 171.0
Avg Reward: 171.0
Min Reward: 171.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
agent-1: 156.0
Sum Reward: 156.0
Avg Reward: 156.0
Min Reward: 156.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-59-06
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 180.0
  episode_reward_mean: 131.06
  episode_reward_min: 58.0
  episodes_this_iter: 2
  episodes_total: 655
  experiment_id: 325b24caee6c4209bf8cf01af4f33e4d
  hostname: gpu048
  info:
    apply_time_ms: 2.313
    dispatch_time_ms: 9.482
    learner:
      cur_lr: 0.0013164435513317585
      grad_gnorm: 20.440629959106445
      policy_entropy: 5.0930280685424805
      policy_loss: -3.428506851196289
      var_gnorm: 30.57073211669922
      vf_explained_var: 0.0
      vf_loss: 2.6819183826446533
    num_steps_sampled: 656000
    num_steps_trained: 656000
    wait_time_ms: 27.602
  iterations_since_restore: 386
  node_ip: 172.17.8.48
  num_metric_batches_dropped: 0
  pid: 20453
  policy_reward_mean: {}
  time_since_restore: 3144.7873492240906
  time_this_iter_s: 9.071064472198486
  time_total_s: 3144.7873492240906
  timestamp: 1593997146
  timesteps_since_restore: 656000
  timesteps_this_iter: 2000
  timesteps_total: 656000
  training_iteration: 386
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=20453], 3144 s, 386 iter, 656000 ts, 131 rew

agent-1: 130.0
Sum Reward: 130.0
Avg Reward: 130.0
Min Reward: 130.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
agent-1: 137.0
Sum Reward: 137.0
Avg Reward: 137.0
Min Reward: 137.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-59-15
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 180.0
  episode_reward_mean: 131.55
  episode_reward_min: 58.0
  episodes_this_iter: 2
  episodes_total: 657
  experiment_id: 325b24caee6c4209bf8cf01af4f33e4d
  hostname: gpu048
  info:
    apply_time_ms: 3.312
    dispatch_time_ms: 26.902
    learner:
      cur_lr: 0.0013163103722035885
      grad_gnorm: 40.0
      policy_entropy: 2.675192356109619
      policy_loss: 1.4828028678894043
      var_gnorm: 30.5685977935791
      vf_explained_var: 5.960464477539063e-08
      vf_loss: 27.73077392578125
    num_steps_sampled: 658000
    num_steps_trained: 658000
    wait_time_ms: 18.661
  iterations_since_restore: 387
  node_ip: 172.17.8.48
  num_metric_batches_dropped: 0
  pid: 20453
  policy_reward_mean: {}
  time_since_restore: 3153.6417768001556
  time_this_iter_s: 8.854427576065063
  time_total_s: 3153.6417768001556
  timestamp: 1593997155
  timesteps_since_restore: 658000
  timesteps_this_iter: 2000
  timesteps_total: 658000
  training_iteration: 387
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=20453], 3153 s, 387 iter, 658000 ts, 132 rew

agent-1: 157.0
Sum Reward: 157.0
Avg Reward: 157.0
Min Reward: 157.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
agent-1: 88.0
Sum Reward: 88.0
Avg Reward: 88.0
Min Reward: 88.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-59-24
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 180.0
  episode_reward_mean: 131.59
  episode_reward_min: 58.0
  episodes_this_iter: 2
  episodes_total: 659
  experiment_id: 325b24caee6c4209bf8cf01af4f33e4d
  hostname: gpu048
  info:
    apply_time_ms: 2.668
    dispatch_time_ms: 23.632
    learner:
      cur_lr: 0.0013161771930754185
      grad_gnorm: 40.0
      policy_entropy: 3.510463237762451
      policy_loss: 1.4626027345657349
      var_gnorm: 30.557472229003906
      vf_explained_var: 0.0
      vf_loss: 10.872249603271484
    num_steps_sampled: 660000
    num_steps_trained: 660000
    wait_time_ms: 17.176
  iterations_since_restore: 388
  node_ip: 172.17.8.48
  num_metric_batches_dropped: 0
  pid: 20453
  policy_reward_mean: {}
  time_since_restore: 3162.7880136966705
  time_this_iter_s: 9.146236896514893
  time_total_s: 3162.7880136966705
  timestamp: 1593997164
  timesteps_since_restore: 660000
  timesteps_this_iter: 2000
  timesteps_total: 660000
  training_iteration: 388
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=20453], 3162 s, 388 iter, 660000 ts, 132 rew

agent-1: 133.0
Sum Reward: 133.0
Avg Reward: 133.0
Min Reward: 133.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
agent-1: 134.0
Sum Reward: 134.0
Avg Reward: 134.0
Min Reward: 134.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-59-34
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 180.0
  episode_reward_mean: 131.36
  episode_reward_min: 58.0
  episodes_this_iter: 2
  episodes_total: 661
  experiment_id: 325b24caee6c4209bf8cf01af4f33e4d
  hostname: gpu048
  info:
    apply_time_ms: 3.832
    dispatch_time_ms: 24.494
    learner:
      cur_lr: 0.0013160440139472485
      grad_gnorm: 15.310416221618652
      policy_entropy: 2.586935043334961
      policy_loss: -0.466804176568985
      var_gnorm: 30.569055557250977
      vf_explained_var: 1.1920928955078125e-07
      vf_loss: 1.6239293813705444
    num_steps_sampled: 662000
    num_steps_trained: 662000
    wait_time_ms: 18.223
  iterations_since_restore: 389
  node_ip: 172.17.8.48
  num_metric_batches_dropped: 0
  pid: 20453
  policy_reward_mean: {}
  time_since_restore: 3172.4353132247925
  time_this_iter_s: 9.647299528121948
  time_total_s: 3172.4353132247925
  timestamp: 1593997174
  timesteps_since_restore: 662000
  timesteps_this_iter: 2000
  timesteps_total: 662000
  training_iteration: 389
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=20453], 3172 s, 389 iter, 662000 ts, 131 rew

agent-1: 146.0
Sum Reward: 146.0
Avg Reward: 146.0
Min Reward: 146.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-59-44
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 180.0
  episode_reward_mean: 131.29
  episode_reward_min: 58.0
  episodes_this_iter: 1
  episodes_total: 662
  experiment_id: 325b24caee6c4209bf8cf01af4f33e4d
  hostname: gpu048
  info:
    apply_time_ms: 3.664
    dispatch_time_ms: 6.928
    learner:
      cur_lr: 0.0013159108348190784
      grad_gnorm: 19.880186080932617
      policy_entropy: 3.1721913814544678
      policy_loss: -1.159135341644287
      var_gnorm: 30.571014404296875
      vf_explained_var: 0.0
      vf_loss: 2.4687767028808594
    num_steps_sampled: 663000
    num_steps_trained: 663000
    wait_time_ms: 31.253
  iterations_since_restore: 390
  node_ip: 172.17.8.48
  num_metric_batches_dropped: 0
  pid: 20453
  policy_reward_mean: {}
  time_since_restore: 3182.163969516754
  time_this_iter_s: 9.72865629196167
  time_total_s: 3182.163969516754
  timestamp: 1593997184
  timesteps_since_restore: 663000
  timesteps_this_iter: 1000
  timesteps_total: 663000
  training_iteration: 390
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=20453], 3182 s, 390 iter, 663000 ts, 131 rew

agent-1: 127.0
Sum Reward: 127.0
Avg Reward: 127.0
Min Reward: 127.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
agent-1: 110.0
Sum Reward: 110.0
Avg Reward: 110.0
Min Reward: 110.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_20-59-52
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 180.0
  episode_reward_mean: 130.75
  episode_reward_min: 58.0
  episodes_this_iter: 2
  episodes_total: 664
  experiment_id: 325b24caee6c4209bf8cf01af4f33e4d
  hostname: gpu048
  info:
    apply_time_ms: 2.801
    dispatch_time_ms: 13.475
    learner:
      cur_lr: 0.0013158442452549934
      grad_gnorm: 32.572750091552734
      policy_entropy: 5.92055082321167
      policy_loss: 4.235328674316406
      var_gnorm: 30.560426712036133
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 5.534423828125
    num_steps_sampled: 665000
    num_steps_trained: 665000
    wait_time_ms: 25.17
  iterations_since_restore: 391
  node_ip: 172.17.8.48
  num_metric_batches_dropped: 0
  pid: 20453
  policy_reward_mean: {}
  time_since_restore: 3190.651714324951
  time_this_iter_s: 8.487744808197021
  time_total_s: 3190.651714324951
  timestamp: 1593997192
  timesteps_since_restore: 665000
  timesteps_this_iter: 2000
  timesteps_total: 665000
  training_iteration: 391
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=20453], 3190 s, 391 iter, 665000 ts, 131 rew

agent-1: 145.0
Sum Reward: 145.0
Avg Reward: 145.0
Min Reward: 145.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
agent-1: 99.0
Sum Reward: 99.0
Avg Reward: 99.0
Min Reward: 99.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_21-00-01
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 180.0
  episode_reward_mean: 130.49
  episode_reward_min: 58.0
  episodes_this_iter: 2
  episodes_total: 666
  experiment_id: 325b24caee6c4209bf8cf01af4f33e4d
  hostname: gpu048
  info:
    apply_time_ms: 3.239
    dispatch_time_ms: 23.853
    learner:
      cur_lr: 0.0013157109497115016
      grad_gnorm: 20.784690856933594
      policy_entropy: 3.334200382232666
      policy_loss: -0.6731835007667542
      var_gnorm: 30.57134246826172
      vf_explained_var: 0.0
      vf_loss: 2.5302605628967285
    num_steps_sampled: 667000
    num_steps_trained: 667000
    wait_time_ms: 19.956
  iterations_since_restore: 392
  node_ip: 172.17.8.48
  num_metric_batches_dropped: 0
  pid: 20453
  policy_reward_mean: {}
  time_since_restore: 3199.6768805980682
  time_this_iter_s: 9.025166273117065
  time_total_s: 3199.6768805980682
  timestamp: 1593997201
  timesteps_since_restore: 667000
  timesteps_this_iter: 2000
  timesteps_total: 667000
  training_iteration: 392
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=20453], 3199 s, 392 iter, 667000 ts, 130 rew

agent-1: 140.0
Sum Reward: 140.0
Avg Reward: 140.0
Min Reward: 140.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
agent-1: 129.0
Sum Reward: 129.0
Avg Reward: 129.0
Min Reward: 129.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_21-00-11
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 180.0
  episode_reward_mean: 130.87
  episode_reward_min: 58.0
  episodes_this_iter: 2
  episodes_total: 668
  experiment_id: 325b24caee6c4209bf8cf01af4f33e4d
  hostname: gpu048
  info:
    apply_time_ms: 3.574
    dispatch_time_ms: 28.127
    learner:
      cur_lr: 0.0013155777705833316
      grad_gnorm: 27.02048683166504
      policy_entropy: 3.3302621841430664
      policy_loss: -5.3185882568359375
      var_gnorm: 30.585735321044922
      vf_explained_var: 0.0
      vf_loss: 3.407926321029663
    num_steps_sampled: 669000
    num_steps_trained: 669000
    wait_time_ms: 17.267
  iterations_since_restore: 393
  node_ip: 172.17.8.48
  num_metric_batches_dropped: 0
  pid: 20453
  policy_reward_mean: {}
  time_since_restore: 3209.0409157276154
  time_this_iter_s: 9.36403512954712
  time_total_s: 3209.0409157276154
  timestamp: 1593997211
  timesteps_since_restore: 669000
  timesteps_this_iter: 2000
  timesteps_total: 669000
  training_iteration: 393
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=20453], 3209 s, 393 iter, 669000 ts, 131 rew

agent-1: 204.0
Sum Reward: 204.0
Avg Reward: 204.0
Min Reward: 204.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
agent-1: 116.0
Sum Reward: 116.0
Avg Reward: 116.0
Min Reward: 116.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_21-00-20
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 204.0
  episode_reward_mean: 130.83
  episode_reward_min: 58.0
  episodes_this_iter: 2
  episodes_total: 670
  experiment_id: 325b24caee6c4209bf8cf01af4f33e4d
  hostname: gpu048
  info:
    apply_time_ms: 3.049
    dispatch_time_ms: 23.09
    learner:
      cur_lr: 0.0013154445914551616
      grad_gnorm: 39.999996185302734
      policy_entropy: 3.095921516418457
      policy_loss: 1.1269632577896118
      var_gnorm: 30.572704315185547
      vf_explained_var: 0.0
      vf_loss: 12.829327583312988
    num_steps_sampled: 671000
    num_steps_trained: 671000
    wait_time_ms: 13.395
  iterations_since_restore: 394
  node_ip: 172.17.8.48
  num_metric_batches_dropped: 0
  pid: 20453
  policy_reward_mean: {}
  time_since_restore: 3218.6352713108063
  time_this_iter_s: 9.594355583190918
  time_total_s: 3218.6352713108063
  timestamp: 1593997220
  timesteps_since_restore: 671000
  timesteps_this_iter: 2000
  timesteps_total: 671000
  training_iteration: 394
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=20453], 3218 s, 394 iter, 671000 ts, 131 rew

agent-1: 117.0
Sum Reward: 117.0
Avg Reward: 117.0
Min Reward: 117.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
agent-1: 137.0
Sum Reward: 137.0
Avg Reward: 137.0
Min Reward: 137.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_21-00-29
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 204.0
  episode_reward_mean: 131.07
  episode_reward_min: 58.0
  episodes_this_iter: 2
  episodes_total: 672
  experiment_id: 325b24caee6c4209bf8cf01af4f33e4d
  hostname: gpu048
  info:
    apply_time_ms: 2.898
    dispatch_time_ms: 5.721
    learner:
      cur_lr: 0.0013153114123269916
      grad_gnorm: 23.376638412475586
      policy_entropy: 3.9801666736602783
      policy_loss: 0.33058202266693115
      var_gnorm: 30.58115005493164
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 5.908822059631348
    num_steps_sampled: 673000
    num_steps_trained: 673000
    wait_time_ms: 34.126
  iterations_since_restore: 395
  node_ip: 172.17.8.48
  num_metric_batches_dropped: 0
  pid: 20453
  policy_reward_mean: {}
  time_since_restore: 3227.28666472435
  time_this_iter_s: 8.651393413543701
  time_total_s: 3227.28666472435
  timestamp: 1593997229
  timesteps_since_restore: 673000
  timesteps_this_iter: 2000
  timesteps_total: 673000
  training_iteration: 395
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=20453], 3227 s, 395 iter, 673000 ts, 131 rew

agent-1: 119.0
Sum Reward: 119.0
Avg Reward: 119.0
Min Reward: 119.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
agent-1: 127.0
Sum Reward: 127.0
Avg Reward: 127.0
Min Reward: 127.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_21-00-37
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 204.0
  episode_reward_mean: 130.66
  episode_reward_min: 58.0
  episodes_this_iter: 2
  episodes_total: 674
  experiment_id: 325b24caee6c4209bf8cf01af4f33e4d
  hostname: gpu048
  info:
    apply_time_ms: 2.674
    dispatch_time_ms: 7.401
    learner:
      cur_lr: 0.0013151782331988215
      grad_gnorm: 7.233512878417969
      policy_entropy: 2.7773916721343994
      policy_loss: 0.10947650671005249
      var_gnorm: 30.56735610961914
      vf_explained_var: 0.0
      vf_loss: 0.6675260066986084
    num_steps_sampled: 675000
    num_steps_trained: 675000
    wait_time_ms: 34.364
  iterations_since_restore: 396
  node_ip: 172.17.8.48
  num_metric_batches_dropped: 0
  pid: 20453
  policy_reward_mean: {}
  time_since_restore: 3235.593975543976
  time_this_iter_s: 8.307310819625854
  time_total_s: 3235.593975543976
  timestamp: 1593997237
  timesteps_since_restore: 675000
  timesteps_this_iter: 2000
  timesteps_total: 675000
  training_iteration: 396
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=20453], 3235 s, 396 iter, 675000 ts, 131 rew

agent-1: 113.0
Sum Reward: 113.0
Avg Reward: 113.0
Min Reward: 113.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
agent-1: 90.0
Sum Reward: 90.0
Avg Reward: 90.0
Min Reward: 90.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_21-00-46
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 204.0
  episode_reward_mean: 130.03
  episode_reward_min: 58.0
  episodes_this_iter: 2
  episodes_total: 676
  experiment_id: 325b24caee6c4209bf8cf01af4f33e4d
  hostname: gpu048
  info:
    apply_time_ms: 3.062
    dispatch_time_ms: 9.893
    learner:
      cur_lr: 0.0013150450540706515
      grad_gnorm: 40.000003814697266
      policy_entropy: 2.323984146118164
      policy_loss: 1.5286976099014282
      var_gnorm: 30.559940338134766
      vf_explained_var: 0.0
      vf_loss: 35.99054718017578
    num_steps_sampled: 677000
    num_steps_trained: 677000
    wait_time_ms: 29.741
  iterations_since_restore: 397
  node_ip: 172.17.8.48
  num_metric_batches_dropped: 0
  pid: 20453
  policy_reward_mean: {}
  time_since_restore: 3243.89639043808
  time_this_iter_s: 8.302414894104004
  time_total_s: 3243.89639043808
  timestamp: 1593997246
  timesteps_since_restore: 677000
  timesteps_this_iter: 2000
  timesteps_total: 677000
  training_iteration: 397
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=20453], 3243 s, 397 iter, 677000 ts, 130 rew

agent-1: 139.0
Sum Reward: 139.0
Avg Reward: 139.0
Min Reward: 139.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
agent-1: 140.0
Sum Reward: 140.0
Avg Reward: 140.0
Min Reward: 140.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_21-00-54
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 204.0
  episode_reward_mean: 130.27
  episode_reward_min: 58.0
  episodes_this_iter: 2
  episodes_total: 678
  experiment_id: 325b24caee6c4209bf8cf01af4f33e4d
  hostname: gpu048
  info:
    apply_time_ms: 2.641
    dispatch_time_ms: 8.926
    learner:
      cur_lr: 0.0013149117585271597
      grad_gnorm: 3.455620765686035
      policy_entropy: 3.3234691619873047
      policy_loss: -0.37228530645370483
      var_gnorm: 30.5836238861084
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 0.43400153517723083
    num_steps_sampled: 679000
    num_steps_trained: 679000
    wait_time_ms: 29.412
  iterations_since_restore: 398
  node_ip: 172.17.8.48
  num_metric_batches_dropped: 0
  pid: 20453
  policy_reward_mean: {}
  time_since_restore: 3252.1560328006744
  time_this_iter_s: 8.259642362594604
  time_total_s: 3252.1560328006744
  timestamp: 1593997254
  timesteps_since_restore: 679000
  timesteps_this_iter: 2000
  timesteps_total: 679000
  training_iteration: 398
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=20453], 3252 s, 398 iter, 679000 ts, 130 rew

agent-1: 124.0
Sum Reward: 124.0
Avg Reward: 124.0
Min Reward: 124.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
agent-1: 148.0
Sum Reward: 148.0
Avg Reward: 148.0
Min Reward: 148.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_21-01-02
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 204.0
  episode_reward_mean: 129.89
  episode_reward_min: 58.0
  episodes_this_iter: 2
  episodes_total: 680
  experiment_id: 325b24caee6c4209bf8cf01af4f33e4d
  hostname: gpu048
  info:
    apply_time_ms: 3.695
    dispatch_time_ms: 7.345
    learner:
      cur_lr: 0.0013147785793989897
      grad_gnorm: 10.526297569274902
      policy_entropy: 2.6881484985351562
      policy_loss: -0.2705501914024353
      var_gnorm: 30.59419059753418
      vf_explained_var: 0.0
      vf_loss: 0.9300732016563416
    num_steps_sampled: 681000
    num_steps_trained: 681000
    wait_time_ms: 31.469
  iterations_since_restore: 399
  node_ip: 172.17.8.48
  num_metric_batches_dropped: 0
  pid: 20453
  policy_reward_mean: {}
  time_since_restore: 3260.4377405643463
  time_this_iter_s: 8.281707763671875
  time_total_s: 3260.4377405643463
  timestamp: 1593997262
  timesteps_since_restore: 681000
  timesteps_this_iter: 2000
  timesteps_total: 681000
  training_iteration: 399
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=20453], 3260 s, 399 iter, 681000 ts, 130 rew

agent-1: 148.0
Sum Reward: 148.0
Avg Reward: 148.0
Min Reward: 148.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
agent-1: 122.0
Sum Reward: 122.0
Avg Reward: 122.0
Min Reward: 122.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_21-01-11
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 204.0
  episode_reward_mean: 129.64
  episode_reward_min: 58.0
  episodes_this_iter: 2
  episodes_total: 682
  experiment_id: 325b24caee6c4209bf8cf01af4f33e4d
  hostname: gpu048
  info:
    apply_time_ms: 2.983
    dispatch_time_ms: 7.402
    learner:
      cur_lr: 0.0013146454002708197
      grad_gnorm: 20.000823974609375
      policy_entropy: 3.640907049179077
      policy_loss: -0.7592139840126038
      var_gnorm: 30.58921241760254
      vf_explained_var: 0.0
      vf_loss: 2.3125903606414795
    num_steps_sampled: 683000
    num_steps_trained: 683000
    wait_time_ms: 31.256
  iterations_since_restore: 400
  node_ip: 172.17.8.48
  num_metric_batches_dropped: 0
  pid: 20453
  policy_reward_mean: {}
  time_since_restore: 3268.6774547100067
  time_this_iter_s: 8.2397141456604
  time_total_s: 3268.6774547100067
  timestamp: 1593997271
  timesteps_since_restore: 683000
  timesteps_this_iter: 2000
  timesteps_total: 683000
  training_iteration: 400
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=20453], 3268 s, 400 iter, 683000 ts, 130 rew

agent-1: 154.0
Sum Reward: 154.0
Avg Reward: 154.0
Min Reward: 154.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
agent-1: 124.0
Sum Reward: 124.0
Avg Reward: 124.0
Min Reward: 124.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_21-01-19
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 204.0
  episode_reward_mean: 129.59
  episode_reward_min: 58.0
  episodes_this_iter: 2
  episodes_total: 684
  experiment_id: 325b24caee6c4209bf8cf01af4f33e4d
  hostname: gpu048
  info:
    apply_time_ms: 3.428
    dispatch_time_ms: 7.643
    learner:
      cur_lr: 0.0013145122211426497
      grad_gnorm: 26.912565231323242
      policy_entropy: 2.9370455741882324
      policy_loss: -7.069540023803711
      var_gnorm: 30.58087730407715
      vf_explained_var: 5.960464477539063e-08
      vf_loss: 2.0111711025238037
    num_steps_sampled: 685000
    num_steps_trained: 685000
    wait_time_ms: 33.839
  iterations_since_restore: 401
  node_ip: 172.17.8.48
  num_metric_batches_dropped: 0
  pid: 20453
  policy_reward_mean: {}
  time_since_restore: 3277.021253347397
  time_this_iter_s: 8.343798637390137
  time_total_s: 3277.021253347397
  timestamp: 1593997279
  timesteps_since_restore: 685000
  timesteps_this_iter: 2000
  timesteps_total: 685000
  training_iteration: 401
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=20453], 3277 s, 401 iter, 685000 ts, 130 rew

agent-1: 115.0
Sum Reward: 115.0
Avg Reward: 115.0
Min Reward: 115.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
agent-1: 137.0
Sum Reward: 137.0
Avg Reward: 137.0
Min Reward: 137.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_21-01-27
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 204.0
  episode_reward_mean: 128.58
  episode_reward_min: 58.0
  episodes_this_iter: 2
  episodes_total: 686
  experiment_id: 325b24caee6c4209bf8cf01af4f33e4d
  hostname: gpu048
  info:
    apply_time_ms: 3.715
    dispatch_time_ms: 9.184
    learner:
      cur_lr: 0.0013143790420144796
      grad_gnorm: 19.7078857421875
      policy_entropy: 1.8892186880111694
      policy_loss: -0.2961306869983673
      var_gnorm: 30.598339080810547
      vf_explained_var: 0.0
      vf_loss: 2.453214645385742
    num_steps_sampled: 687000
    num_steps_trained: 687000
    wait_time_ms: 29.052
  iterations_since_restore: 402
  node_ip: 172.17.8.48
  num_metric_batches_dropped: 0
  pid: 20453
  policy_reward_mean: {}
  time_since_restore: 3285.423702955246
  time_this_iter_s: 8.402449607849121
  time_total_s: 3285.423702955246
  timestamp: 1593997287
  timesteps_since_restore: 687000
  timesteps_this_iter: 2000
  timesteps_total: 687000
  training_iteration: 402
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=20453], 3285 s, 402 iter, 687000 ts, 129 rew

agent-1: 142.0
Sum Reward: 142.0
Avg Reward: 142.0
Min Reward: 142.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
agent-1: 150.0
Sum Reward: 150.0
Avg Reward: 150.0
Min Reward: 150.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_21-01-36
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 204.0
  episode_reward_mean: 128.99
  episode_reward_min: 58.0
  episodes_this_iter: 2
  episodes_total: 688
  experiment_id: 325b24caee6c4209bf8cf01af4f33e4d
  hostname: gpu048
  info:
    apply_time_ms: 2.75
    dispatch_time_ms: 10.165
    learner:
      cur_lr: 0.0013142457464709878
      grad_gnorm: 8.613083839416504
      policy_entropy: 2.127218246459961
      policy_loss: 1.6448026895523071
      var_gnorm: 30.594867706298828
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 0.8119322657585144
    num_steps_sampled: 689000
    num_steps_trained: 689000
    wait_time_ms: 28.908
  iterations_since_restore: 403
  node_ip: 172.17.8.48
  num_metric_batches_dropped: 0
  pid: 20453
  policy_reward_mean: {}
  time_since_restore: 3293.7712590694427
  time_this_iter_s: 8.347556114196777
  time_total_s: 3293.7712590694427
  timestamp: 1593997296
  timesteps_since_restore: 689000
  timesteps_this_iter: 2000
  timesteps_total: 689000
  training_iteration: 403
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=20453], 3293 s, 403 iter, 689000 ts, 129 rew

agent-1: 121.0
Sum Reward: 121.0
Avg Reward: 121.0
Min Reward: 121.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
agent-1: 115.0
Sum Reward: 115.0
Avg Reward: 115.0
Min Reward: 115.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_21-01-44
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 204.0
  episode_reward_mean: 129.23
  episode_reward_min: 58.0
  episodes_this_iter: 2
  episodes_total: 690
  experiment_id: 325b24caee6c4209bf8cf01af4f33e4d
  hostname: gpu048
  info:
    apply_time_ms: 2.529
    dispatch_time_ms: 7.124
    learner:
      cur_lr: 0.0013141125673428178
      grad_gnorm: 11.321540832519531
      policy_entropy: 3.5592200756073
      policy_loss: -2.4255855083465576
      var_gnorm: 30.59748649597168
      vf_explained_var: 0.0
      vf_loss: 0.8776738047599792
    num_steps_sampled: 691000
    num_steps_trained: 691000
    wait_time_ms: 33.207
  iterations_since_restore: 404
  node_ip: 172.17.8.48
  num_metric_batches_dropped: 0
  pid: 20453
  policy_reward_mean: {}
  time_since_restore: 3302.1790692806244
  time_this_iter_s: 8.40781021118164
  time_total_s: 3302.1790692806244
  timestamp: 1593997304
  timesteps_since_restore: 691000
  timesteps_this_iter: 2000
  timesteps_total: 691000
  training_iteration: 404
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=20453], 3302 s, 404 iter, 691000 ts, 129 rew

agent-1: 162.0
Sum Reward: 162.0
Avg Reward: 162.0
Min Reward: 162.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
agent-1: 157.0
Sum Reward: 157.0
Avg Reward: 157.0
Min Reward: 157.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_21-01-53
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 204.0
  episode_reward_mean: 129.43
  episode_reward_min: 58.0
  episodes_this_iter: 2
  episodes_total: 692
  experiment_id: 325b24caee6c4209bf8cf01af4f33e4d
  hostname: gpu048
  info:
    apply_time_ms: 2.836
    dispatch_time_ms: 8.291
    learner:
      cur_lr: 0.0013139793882146478
      grad_gnorm: 8.331379890441895
      policy_entropy: 3.121072769165039
      policy_loss: -0.43430086970329285
      var_gnorm: 30.614744186401367
      vf_explained_var: 0.0
      vf_loss: 1.3416178226470947
    num_steps_sampled: 693000
    num_steps_trained: 693000
    wait_time_ms: 31.306
  iterations_since_restore: 405
  node_ip: 172.17.8.48
  num_metric_batches_dropped: 0
  pid: 20453
  policy_reward_mean: {}
  time_since_restore: 3310.541497707367
  time_this_iter_s: 8.362428426742554
  time_total_s: 3310.541497707367
  timestamp: 1593997313
  timesteps_since_restore: 693000
  timesteps_this_iter: 2000
  timesteps_total: 693000
  training_iteration: 405
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=20453], 3310 s, 405 iter, 693000 ts, 129 rew

agent-1: 147.0
Sum Reward: 147.0
Avg Reward: 147.0
Min Reward: 147.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
agent-1: 106.0
Sum Reward: 106.0
Avg Reward: 106.0
Min Reward: 106.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_21-02-01
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 204.0
  episode_reward_mean: 129.5
  episode_reward_min: 58.0
  episodes_this_iter: 2
  episodes_total: 694
  experiment_id: 325b24caee6c4209bf8cf01af4f33e4d
  hostname: gpu048
  info:
    apply_time_ms: 3.084
    dispatch_time_ms: 10.427
    learner:
      cur_lr: 0.0013138462090864778
      grad_gnorm: 18.27863311767578
      policy_entropy: 3.256640911102295
      policy_loss: -3.3836236000061035
      var_gnorm: 30.61277961730957
      vf_explained_var: 0.0
      vf_loss: 1.948904037475586
    num_steps_sampled: 695000
    num_steps_trained: 695000
    wait_time_ms: 29.003
  iterations_since_restore: 406
  node_ip: 172.17.8.48
  num_metric_batches_dropped: 0
  pid: 20453
  policy_reward_mean: {}
  time_since_restore: 3318.973814725876
  time_this_iter_s: 8.432317018508911
  time_total_s: 3318.973814725876
  timestamp: 1593997321
  timesteps_since_restore: 695000
  timesteps_this_iter: 2000
  timesteps_total: 695000
  training_iteration: 406
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=20453], 3318 s, 406 iter, 695000 ts, 130 rew

agent-1: 158.0
Sum Reward: 158.0
Avg Reward: 158.0
Min Reward: 158.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
agent-1: 119.0
Sum Reward: 119.0
Avg Reward: 119.0
Min Reward: 119.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_21-02-18
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 204.0
  episode_reward_mean: 129.8
  episode_reward_min: 58.0
  episodes_this_iter: 2
  episodes_total: 696
  experiment_id: 325b24caee6c4209bf8cf01af4f33e4d
  hostname: gpu048
  info:
    apply_time_ms: 3.435
    dispatch_time_ms: 8.817
    learner:
      cur_lr: 0.0013137130299583077
      grad_gnorm: 39.999996185302734
      policy_entropy: 4.739136219024658
      policy_loss: 9.85263729095459
      var_gnorm: 30.609621047973633
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 23.443147659301758
    num_steps_sampled: 697000
    num_steps_trained: 697000
    wait_time_ms: 31.193
  iterations_since_restore: 407
  node_ip: 172.17.8.48
  num_metric_batches_dropped: 0
  pid: 20453
  policy_reward_mean: {}
  time_since_restore: 3335.792024374008
  time_this_iter_s: 16.818209648132324
  time_total_s: 3335.792024374008
  timestamp: 1593997338
  timesteps_since_restore: 697000
  timesteps_this_iter: 2000
  timesteps_total: 697000
  training_iteration: 407
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=20453], 3335 s, 407 iter, 697000 ts, 130 rew

agent-1: 157.0
Sum Reward: 157.0
Avg Reward: 157.0
Min Reward: 157.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
agent-1: 114.0
Sum Reward: 114.0
Avg Reward: 114.0
Min Reward: 114.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_21-02-26
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 204.0
  episode_reward_mean: 129.99
  episode_reward_min: 58.0
  episodes_this_iter: 2
  episodes_total: 698
  experiment_id: 325b24caee6c4209bf8cf01af4f33e4d
  hostname: gpu048
  info:
    apply_time_ms: 3.861
    dispatch_time_ms: 7.844
    learner:
      cur_lr: 0.0013135798508301377
      grad_gnorm: 20.95302963256836
      policy_entropy: 3.1036996841430664
      policy_loss: -0.6326171159744263
      var_gnorm: 30.61531639099121
      vf_explained_var: 0.0
      vf_loss: 2.636906862258911
    num_steps_sampled: 699000
    num_steps_trained: 699000
    wait_time_ms: 30.096
  iterations_since_restore: 408
  node_ip: 172.17.8.48
  num_metric_batches_dropped: 0
  pid: 20453
  policy_reward_mean: {}
  time_since_restore: 3344.182090997696
  time_this_iter_s: 8.390066623687744
  time_total_s: 3344.182090997696
  timestamp: 1593997346
  timesteps_since_restore: 699000
  timesteps_this_iter: 2000
  timesteps_total: 699000
  training_iteration: 408
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=20453], 3344 s, 408 iter, 699000 ts, 130 rew

agent-1: 124.0
Sum Reward: 124.0
Avg Reward: 124.0
Min Reward: 124.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
agent-1: 176.0
Sum Reward: 176.0
Avg Reward: 176.0
Min Reward: 176.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_21-02-35
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 204.0
  episode_reward_mean: 130.52
  episode_reward_min: 58.0
  episodes_this_iter: 2
  episodes_total: 700
  experiment_id: 325b24caee6c4209bf8cf01af4f33e4d
  hostname: gpu048
  info:
    apply_time_ms: 2.927
    dispatch_time_ms: 8.973
    learner:
      cur_lr: 0.0013134465552866459
      grad_gnorm: 19.895605087280273
      policy_entropy: 2.247222423553467
      policy_loss: -2.6158199310302734
      var_gnorm: 30.609811782836914
      vf_explained_var: 0.0
      vf_loss: 2.4462759494781494
    num_steps_sampled: 701000
    num_steps_trained: 701000
    wait_time_ms: 29.494
  iterations_since_restore: 409
  node_ip: 172.17.8.48
  num_metric_batches_dropped: 0
  pid: 20453
  policy_reward_mean: {}
  time_since_restore: 3352.5147573947906
  time_this_iter_s: 8.332666397094727
  time_total_s: 3352.5147573947906
  timestamp: 1593997355
  timesteps_since_restore: 701000
  timesteps_this_iter: 2000
  timesteps_total: 701000
  training_iteration: 409
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=20453], 3352 s, 409 iter, 701000 ts, 131 rew

agent-1: 81.0
Sum Reward: 81.0
Avg Reward: 81.0
Min Reward: 81.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
agent-1: 129.0
Sum Reward: 129.0
Avg Reward: 129.0
Min Reward: 129.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_21-02-43
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 204.0
  episode_reward_mean: 130.05
  episode_reward_min: 58.0
  episodes_this_iter: 2
  episodes_total: 702
  experiment_id: 325b24caee6c4209bf8cf01af4f33e4d
  hostname: gpu048
  info:
    apply_time_ms: 2.783
    dispatch_time_ms: 7.534
    learner:
      cur_lr: 0.0013133133761584759
      grad_gnorm: 18.3284854888916
      policy_entropy: 2.890897274017334
      policy_loss: -0.5004792213439941
      var_gnorm: 30.59733009338379
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 2.0420854091644287
    num_steps_sampled: 703000
    num_steps_trained: 703000
    wait_time_ms: 35.356
  iterations_since_restore: 410
  node_ip: 172.17.8.48
  num_metric_batches_dropped: 0
  pid: 20453
  policy_reward_mean: {}
  time_since_restore: 3360.923768520355
  time_this_iter_s: 8.409011125564575
  time_total_s: 3360.923768520355
  timestamp: 1593997363
  timesteps_since_restore: 703000
  timesteps_this_iter: 2000
  timesteps_total: 703000
  training_iteration: 410
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=20453], 3360 s, 410 iter, 703000 ts, 130 rew

agent-1: 104.0
Sum Reward: 104.0
Avg Reward: 104.0
Min Reward: 104.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
agent-1: 135.0
Sum Reward: 135.0
Avg Reward: 135.0
Min Reward: 135.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_21-02-52
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 204.0
  episode_reward_mean: 129.55
  episode_reward_min: 58.0
  episodes_this_iter: 2
  episodes_total: 704
  experiment_id: 325b24caee6c4209bf8cf01af4f33e4d
  hostname: gpu048
  info:
    apply_time_ms: 3.228
    dispatch_time_ms: 33.739
    learner:
      cur_lr: 0.0013131801970303059
      grad_gnorm: 13.205514907836914
      policy_entropy: 3.000901222229004
      policy_loss: -0.4193710684776306
      var_gnorm: 30.593490600585938
      vf_explained_var: 0.0
      vf_loss: 1.2298672199249268
    num_steps_sampled: 705000
    num_steps_trained: 705000
    wait_time_ms: 13.192
  iterations_since_restore: 411
  node_ip: 172.17.8.48
  num_metric_batches_dropped: 0
  pid: 20453
  policy_reward_mean: {}
  time_since_restore: 3369.50554394722
  time_this_iter_s: 8.581775426864624
  time_total_s: 3369.50554394722
  timestamp: 1593997372
  timesteps_since_restore: 705000
  timesteps_this_iter: 2000
  timesteps_total: 705000
  training_iteration: 411
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=20453], 3369 s, 411 iter, 705000 ts, 130 rew

agent-1: 135.0
Sum Reward: 135.0
Avg Reward: 135.0
Min Reward: 135.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
agent-1: 97.0
Sum Reward: 97.0
Avg Reward: 97.0
Min Reward: 97.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_21-03-00
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 204.0
  episode_reward_mean: 129.59
  episode_reward_min: 58.0
  episodes_this_iter: 2
  episodes_total: 706
  experiment_id: 325b24caee6c4209bf8cf01af4f33e4d
  hostname: gpu048
  info:
    apply_time_ms: 3.574
    dispatch_time_ms: 9.229
    learner:
      cur_lr: 0.0013130470179021358
      grad_gnorm: 18.319934844970703
      policy_entropy: 2.0762414932250977
      policy_loss: -1.2579996585845947
      var_gnorm: 30.611101150512695
      vf_explained_var: 0.0
      vf_loss: 2.15647554397583
    num_steps_sampled: 707000
    num_steps_trained: 707000
    wait_time_ms: 29.058
  iterations_since_restore: 412
  node_ip: 172.17.8.48
  num_metric_batches_dropped: 0
  pid: 20453
  policy_reward_mean: {}
  time_since_restore: 3378.0500614643097
  time_this_iter_s: 8.544517517089844
  time_total_s: 3378.0500614643097
  timestamp: 1593997380
  timesteps_since_restore: 707000
  timesteps_this_iter: 2000
  timesteps_total: 707000
  training_iteration: 412
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=20453], 3378 s, 412 iter, 707000 ts, 130 rew

agent-1: 133.0
Sum Reward: 133.0
Avg Reward: 133.0
Min Reward: 133.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
agent-1: 108.0
Sum Reward: 108.0
Avg Reward: 108.0
Min Reward: 108.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_21-03-09
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 204.0
  episode_reward_mean: 129.54
  episode_reward_min: 58.0
  episodes_this_iter: 2
  episodes_total: 708
  experiment_id: 325b24caee6c4209bf8cf01af4f33e4d
  hostname: gpu048
  info:
    apply_time_ms: 3.892
    dispatch_time_ms: 7.568
    learner:
      cur_lr: 0.0013129138387739658
      grad_gnorm: 4.755468368530273
      policy_entropy: 4.527270793914795
      policy_loss: 1.0728590488433838
      var_gnorm: 30.60502052307129
      vf_explained_var: 0.0
      vf_loss: 0.48093467950820923
    num_steps_sampled: 709000
    num_steps_trained: 709000
    wait_time_ms: 32.18
  iterations_since_restore: 413
  node_ip: 172.17.8.48
  num_metric_batches_dropped: 0
  pid: 20453
  policy_reward_mean: {}
  time_since_restore: 3386.3317284584045
  time_this_iter_s: 8.281666994094849
  time_total_s: 3386.3317284584045
  timestamp: 1593997389
  timesteps_since_restore: 709000
  timesteps_this_iter: 2000
  timesteps_total: 709000
  training_iteration: 413
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=20453], 3386 s, 413 iter, 709000 ts, 130 rew

agent-1: 176.0
Sum Reward: 176.0
Avg Reward: 176.0
Min Reward: 176.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
agent-1: 142.0
Sum Reward: 142.0
Avg Reward: 142.0
Min Reward: 142.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_21-03-17
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 204.0
  episode_reward_mean: 130.8
  episode_reward_min: 58.0
  episodes_this_iter: 2
  episodes_total: 710
  experiment_id: 325b24caee6c4209bf8cf01af4f33e4d
  hostname: gpu048
  info:
    apply_time_ms: 2.726
    dispatch_time_ms: 9.048
    learner:
      cur_lr: 0.001312780543230474
      grad_gnorm: 19.51786231994629
      policy_entropy: 1.5744102001190186
      policy_loss: -0.2346823811531067
      var_gnorm: 30.62853240966797
      vf_explained_var: 0.0
      vf_loss: 2.4208269119262695
    num_steps_sampled: 711000
    num_steps_trained: 711000
    wait_time_ms: 28.639
  iterations_since_restore: 414
  node_ip: 172.17.8.48
  num_metric_batches_dropped: 0
  pid: 20453
  policy_reward_mean: {}
  time_since_restore: 3394.6684136390686
  time_this_iter_s: 8.336685180664062
  time_total_s: 3394.6684136390686
  timestamp: 1593997397
  timesteps_since_restore: 711000
  timesteps_this_iter: 2000
  timesteps_total: 711000
  training_iteration: 414
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=20453], 3394 s, 414 iter, 711000 ts, 131 rew

agent-1: 124.0
Sum Reward: 124.0
Avg Reward: 124.0
Min Reward: 124.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
agent-1: 97.0
Sum Reward: 97.0
Avg Reward: 97.0
Min Reward: 97.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_21-03-25
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 204.0
  episode_reward_mean: 130.24
  episode_reward_min: 58.0
  episodes_this_iter: 2
  episodes_total: 712
  experiment_id: 325b24caee6c4209bf8cf01af4f33e4d
  hostname: gpu048
  info:
    apply_time_ms: 2.801
    dispatch_time_ms: 9.225
    learner:
      cur_lr: 0.001312647364102304
      grad_gnorm: 16.79214096069336
      policy_entropy: 4.081161022186279
      policy_loss: -1.5046724081039429
      var_gnorm: 30.60670280456543
      vf_explained_var: 0.0
      vf_loss: 1.7464407682418823
    num_steps_sampled: 713000
    num_steps_trained: 713000
    wait_time_ms: 30.176
  iterations_since_restore: 415
  node_ip: 172.17.8.48
  num_metric_batches_dropped: 0
  pid: 20453
  policy_reward_mean: {}
  time_since_restore: 3402.9597976207733
  time_this_iter_s: 8.291383981704712
  time_total_s: 3402.9597976207733
  timestamp: 1593997405
  timesteps_since_restore: 713000
  timesteps_this_iter: 2000
  timesteps_total: 713000
  training_iteration: 415
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=20453], 3402 s, 415 iter, 713000 ts, 130 rew

agent-1: 156.0
Sum Reward: 156.0
Avg Reward: 156.0
Min Reward: 156.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
agent-1: 132.0
Sum Reward: 132.0
Avg Reward: 132.0
Min Reward: 132.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_21-03-34
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 204.0
  episode_reward_mean: 130.26
  episode_reward_min: 58.0
  episodes_this_iter: 2
  episodes_total: 714
  experiment_id: 325b24caee6c4209bf8cf01af4f33e4d
  hostname: gpu048
  info:
    apply_time_ms: 2.721
    dispatch_time_ms: 6.041
    learner:
      cur_lr: 0.001312514184974134
      grad_gnorm: 22.358823776245117
      policy_entropy: 2.135739803314209
      policy_loss: 3.80143666267395
      var_gnorm: 30.62921142578125
      vf_explained_var: 0.0
      vf_loss: 6.060779571533203
    num_steps_sampled: 715000
    num_steps_trained: 715000
    wait_time_ms: 31.53
  iterations_since_restore: 416
  node_ip: 172.17.8.48
  num_metric_batches_dropped: 0
  pid: 20453
  policy_reward_mean: {}
  time_since_restore: 3411.3692898750305
  time_this_iter_s: 8.409492254257202
  time_total_s: 3411.3692898750305
  timestamp: 1593997414
  timesteps_since_restore: 715000
  timesteps_this_iter: 2000
  timesteps_total: 715000
  training_iteration: 416
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=20453], 3411 s, 416 iter, 715000 ts, 130 rew

agent-1: 154.0
Sum Reward: 154.0
Avg Reward: 154.0
Min Reward: 154.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
agent-1: 108.0
Sum Reward: 108.0
Avg Reward: 108.0
Min Reward: 108.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_21-03-43
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 204.0
  episode_reward_mean: 130.33
  episode_reward_min: 58.0
  episodes_this_iter: 2
  episodes_total: 716
  experiment_id: 325b24caee6c4209bf8cf01af4f33e4d
  hostname: gpu048
  info:
    apply_time_ms: 3.576
    dispatch_time_ms: 19.429
    learner:
      cur_lr: 0.001312381005845964
      grad_gnorm: 16.68378257751465
      policy_entropy: 3.5340964794158936
      policy_loss: -0.6058076620101929
      var_gnorm: 30.606229782104492
      vf_explained_var: 0.0
      vf_loss: 1.6232585906982422
    num_steps_sampled: 717000
    num_steps_trained: 717000
    wait_time_ms: 21.501
  iterations_since_restore: 417
  node_ip: 172.17.8.48
  num_metric_batches_dropped: 0
  pid: 20453
  policy_reward_mean: {}
  time_since_restore: 3420.0706038475037
  time_this_iter_s: 8.701313972473145
  time_total_s: 3420.0706038475037
  timestamp: 1593997423
  timesteps_since_restore: 717000
  timesteps_this_iter: 2000
  timesteps_total: 717000
  training_iteration: 417
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=20453], 3420 s, 417 iter, 717000 ts, 130 rew

agent-1: 99.0
Sum Reward: 99.0
Avg Reward: 99.0
Min Reward: 99.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
agent-1: 109.0
Sum Reward: 109.0
Avg Reward: 109.0
Min Reward: 109.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_21-03-51
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 204.0
  episode_reward_mean: 129.92
  episode_reward_min: 58.0
  episodes_this_iter: 2
  episodes_total: 718
  experiment_id: 325b24caee6c4209bf8cf01af4f33e4d
  hostname: gpu048
  info:
    apply_time_ms: 3.46
    dispatch_time_ms: 23.597
    learner:
      cur_lr: 0.001312247826717794
      grad_gnorm: 10.924898147583008
      policy_entropy: 2.8777260780334473
      policy_loss: 1.781650424003601
      var_gnorm: 30.615222930908203
      vf_explained_var: 0.0
      vf_loss: 0.9830434322357178
    num_steps_sampled: 719000
    num_steps_trained: 719000
    wait_time_ms: 25.531
  iterations_since_restore: 418
  node_ip: 172.17.8.48
  num_metric_batches_dropped: 0
  pid: 20453
  policy_reward_mean: {}
  time_since_restore: 3428.966756105423
  time_this_iter_s: 8.896152257919312
  time_total_s: 3428.966756105423
  timestamp: 1593997431
  timesteps_since_restore: 719000
  timesteps_this_iter: 2000
  timesteps_total: 719000
  training_iteration: 418
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=20453], 3428 s, 418 iter, 719000 ts, 130 rew

agent-1: 139.0
Sum Reward: 139.0
Avg Reward: 139.0
Min Reward: 139.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
agent-1: 131.0
Sum Reward: 131.0
Avg Reward: 131.0
Min Reward: 131.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_21-04-00
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 204.0
  episode_reward_mean: 130.34
  episode_reward_min: 58.0
  episodes_this_iter: 2
  episodes_total: 720
  experiment_id: 325b24caee6c4209bf8cf01af4f33e4d
  hostname: gpu048
  info:
    apply_time_ms: 3.751
    dispatch_time_ms: 7.582
    learner:
      cur_lr: 0.001312114647589624
      grad_gnorm: 11.887133598327637
      policy_entropy: 3.5105576515197754
      policy_loss: 1.5715140104293823
      var_gnorm: 30.628305435180664
      vf_explained_var: 0.0
      vf_loss: 1.2372606992721558
    num_steps_sampled: 721000
    num_steps_trained: 721000
    wait_time_ms: 29.112
  iterations_since_restore: 419
  node_ip: 172.17.8.48
  num_metric_batches_dropped: 0
  pid: 20453
  policy_reward_mean: {}
  time_since_restore: 3437.5353837013245
  time_this_iter_s: 8.56862759590149
  time_total_s: 3437.5353837013245
  timestamp: 1593997440
  timesteps_since_restore: 721000
  timesteps_this_iter: 2000
  timesteps_total: 721000
  training_iteration: 419
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=20453], 3437 s, 419 iter, 721000 ts, 130 rew

agent-1: 107.0
Sum Reward: 107.0
Avg Reward: 107.0
Min Reward: 107.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
agent-1: 145.0
Sum Reward: 145.0
Avg Reward: 145.0
Min Reward: 145.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_21-04-08
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 204.0
  episode_reward_mean: 130.1
  episode_reward_min: 58.0
  episodes_this_iter: 2
  episodes_total: 722
  experiment_id: 325b24caee6c4209bf8cf01af4f33e4d
  hostname: gpu048
  info:
    apply_time_ms: 3.138
    dispatch_time_ms: 8.753
    learner:
      cur_lr: 0.001311981352046132
      grad_gnorm: 4.729563236236572
      policy_entropy: 4.379958152770996
      policy_loss: 1.0567885637283325
      var_gnorm: 30.62738609313965
      vf_explained_var: 1.1920928955078125e-07
      vf_loss: 0.3942556381225586
    num_steps_sampled: 723000
    num_steps_trained: 723000
    wait_time_ms: 30.812
  iterations_since_restore: 420
  node_ip: 172.17.8.48
  num_metric_batches_dropped: 0
  pid: 20453
  policy_reward_mean: {}
  time_since_restore: 3445.8039979934692
  time_this_iter_s: 8.268614292144775
  time_total_s: 3445.8039979934692
  timestamp: 1593997448
  timesteps_since_restore: 723000
  timesteps_this_iter: 2000
  timesteps_total: 723000
  training_iteration: 420
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=20453], 3445 s, 420 iter, 723000 ts, 130 rew

agent-1: 138.0
Sum Reward: 138.0
Avg Reward: 138.0
Min Reward: 138.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
agent-1: 142.0
Sum Reward: 142.0
Avg Reward: 142.0
Min Reward: 142.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_21-04-22
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 204.0
  episode_reward_mean: 130.15
  episode_reward_min: 58.0
  episodes_this_iter: 2
  episodes_total: 724
  experiment_id: 325b24caee6c4209bf8cf01af4f33e4d
  hostname: gpu048
  info:
    apply_time_ms: 3.06
    dispatch_time_ms: 7.181
    learner:
      cur_lr: 0.001311848172917962
      grad_gnorm: 19.146495819091797
      policy_entropy: 2.291604518890381
      policy_loss: -0.698737621307373
      var_gnorm: 30.641510009765625
      vf_explained_var: 0.0
      vf_loss: 2.320530891418457
    num_steps_sampled: 725000
    num_steps_trained: 725000
    wait_time_ms: 31.46
  iterations_since_restore: 421
  node_ip: 172.17.8.48
  num_metric_batches_dropped: 0
  pid: 20453
  policy_reward_mean: {}
  time_since_restore: 3458.8163788318634
  time_this_iter_s: 13.012380838394165
  time_total_s: 3458.8163788318634
  timestamp: 1593997462
  timesteps_since_restore: 725000
  timesteps_this_iter: 2000
  timesteps_total: 725000
  training_iteration: 421
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=20453], 3458 s, 421 iter, 725000 ts, 130 rew

agent-1: 133.0
Sum Reward: 133.0
Avg Reward: 133.0
Min Reward: 133.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
agent-1: 123.0
Sum Reward: 123.0
Avg Reward: 123.0
Min Reward: 123.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_21-04-30
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 204.0
  episode_reward_mean: 130.11
  episode_reward_min: 58.0
  episodes_this_iter: 2
  episodes_total: 726
  experiment_id: 325b24caee6c4209bf8cf01af4f33e4d
  hostname: gpu048
  info:
    apply_time_ms: 2.8
    dispatch_time_ms: 6.963
    learner:
      cur_lr: 0.001311714993789792
      grad_gnorm: 18.748558044433594
      policy_entropy: 2.894460916519165
      policy_loss: -0.5125004053115845
      var_gnorm: 30.636394500732422
      vf_explained_var: 5.960464477539063e-08
      vf_loss: 2.13653564453125
    num_steps_sampled: 727000
    num_steps_trained: 727000
    wait_time_ms: 31.949
  iterations_since_restore: 422
  node_ip: 172.17.8.48
  num_metric_batches_dropped: 0
  pid: 20453
  policy_reward_mean: {}
  time_since_restore: 3467.1149966716766
  time_this_iter_s: 8.298617839813232
  time_total_s: 3467.1149966716766
  timestamp: 1593997470
  timesteps_since_restore: 727000
  timesteps_this_iter: 2000
  timesteps_total: 727000
  training_iteration: 422
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=20453], 3467 s, 422 iter, 727000 ts, 130 rew

agent-1: 119.0
Sum Reward: 119.0
Avg Reward: 119.0
Min Reward: 119.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
agent-1: 118.0
Sum Reward: 118.0
Avg Reward: 118.0
Min Reward: 118.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_21-04-38
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 204.0
  episode_reward_mean: 130.06
  episode_reward_min: 58.0
  episodes_this_iter: 2
  episodes_total: 728
  experiment_id: 325b24caee6c4209bf8cf01af4f33e4d
  hostname: gpu048
  info:
    apply_time_ms: 2.425
    dispatch_time_ms: 6.203
    learner:
      cur_lr: 0.001311581814661622
      grad_gnorm: 39.999996185302734
      policy_entropy: 2.897184371948242
      policy_loss: 6.686402320861816
      var_gnorm: 30.63339614868164
      vf_explained_var: 0.0
      vf_loss: 18.400901794433594
    num_steps_sampled: 729000
    num_steps_trained: 729000
    wait_time_ms: 33.316
  iterations_since_restore: 423
  node_ip: 172.17.8.48
  num_metric_batches_dropped: 0
  pid: 20453
  policy_reward_mean: {}
  time_since_restore: 3475.4265801906586
  time_this_iter_s: 8.311583518981934
  time_total_s: 3475.4265801906586
  timestamp: 1593997478
  timesteps_since_restore: 729000
  timesteps_this_iter: 2000
  timesteps_total: 729000
  training_iteration: 423
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=20453], 3475 s, 423 iter, 729000 ts, 130 rew

agent-1: 116.0
Sum Reward: 116.0
Avg Reward: 116.0
Min Reward: 116.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
agent-1: 139.0
Sum Reward: 139.0
Avg Reward: 139.0
Min Reward: 139.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_21-04-57
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 204.0
  episode_reward_mean: 130.41
  episode_reward_min: 81.0
  episodes_this_iter: 2
  episodes_total: 730
  experiment_id: 325b24caee6c4209bf8cf01af4f33e4d
  hostname: gpu048
  info:
    apply_time_ms: 2.554
    dispatch_time_ms: 1021.589
    learner:
      cur_lr: 0.001311448635533452
      grad_gnorm: 24.02996063232422
      policy_entropy: 4.067285060882568
      policy_loss: -2.306476593017578
      var_gnorm: 30.650392532348633
      vf_explained_var: 0.0
      vf_loss: 3.414945125579834
    num_steps_sampled: 731000
    num_steps_trained: 731000
    wait_time_ms: 22.172
  iterations_since_restore: 424
  node_ip: 172.17.8.48
  num_metric_batches_dropped: 0
  pid: 20453
  policy_reward_mean: {}
  time_since_restore: 3493.839126586914
  time_this_iter_s: 18.412546396255493
  time_total_s: 3493.839126586914
  timestamp: 1593997497
  timesteps_since_restore: 731000
  timesteps_this_iter: 2000
  timesteps_total: 731000
  training_iteration: 424
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=20453], 3493 s, 424 iter, 731000 ts, 130 rew

agent-1: 161.0
Sum Reward: 161.0
Avg Reward: 161.0
Min Reward: 161.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
agent-1: 78.0
Sum Reward: 78.0
Avg Reward: 78.0
Min Reward: 78.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_21-05-05
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 204.0
  episode_reward_mean: 130.23
  episode_reward_min: 78.0
  episodes_this_iter: 2
  episodes_total: 732
  experiment_id: 325b24caee6c4209bf8cf01af4f33e4d
  hostname: gpu048
  info:
    apply_time_ms: 2.663
    dispatch_time_ms: 10.803
    learner:
      cur_lr: 0.001311315456405282
      grad_gnorm: 40.0
      policy_entropy: 4.170210361480713
      policy_loss: 5.407989501953125
      var_gnorm: 30.653427124023438
      vf_explained_var: 0.0
      vf_loss: 12.871053695678711
    num_steps_sampled: 733000
    num_steps_trained: 733000
    wait_time_ms: 31.342
  iterations_since_restore: 425
  node_ip: 172.17.8.48
  num_metric_batches_dropped: 0
  pid: 20453
  policy_reward_mean: {}
  time_since_restore: 3502.084451675415
  time_this_iter_s: 8.245325088500977
  time_total_s: 3502.084451675415
  timestamp: 1593997505
  timesteps_since_restore: 733000
  timesteps_this_iter: 2000
  timesteps_total: 733000
  training_iteration: 425
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=20453], 3502 s, 425 iter, 733000 ts, 130 rew

agent-1: 139.0
Sum Reward: 139.0
Avg Reward: 139.0
Min Reward: 139.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
agent-1: 154.0
Sum Reward: 154.0
Avg Reward: 154.0
Min Reward: 154.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_21-05-14
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 204.0
  episode_reward_mean: 130.43
  episode_reward_min: 78.0
  episodes_this_iter: 2
  episodes_total: 734
  experiment_id: 325b24caee6c4209bf8cf01af4f33e4d
  hostname: gpu048
  info:
    apply_time_ms: 3.261
    dispatch_time_ms: 35.47
    learner:
      cur_lr: 0.0013111821608617902
      grad_gnorm: 19.557863235473633
      policy_entropy: 3.3439645767211914
      policy_loss: -3.049056053161621
      var_gnorm: 30.644954681396484
      vf_explained_var: 0.0
      vf_loss: 2.2318146228790283
    num_steps_sampled: 735000
    num_steps_trained: 735000
    wait_time_ms: 22.597
  iterations_since_restore: 426
  node_ip: 172.17.8.48
  num_metric_batches_dropped: 0
  pid: 20453
  policy_reward_mean: {}
  time_since_restore: 3511.3685698509216
  time_this_iter_s: 9.284118175506592
  time_total_s: 3511.3685698509216
  timestamp: 1593997514
  timesteps_since_restore: 735000
  timesteps_this_iter: 2000
  timesteps_total: 735000
  training_iteration: 426
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=20453], 3511 s, 426 iter, 735000 ts, 130 rew

agent-1: 121.0
Sum Reward: 121.0
Avg Reward: 121.0
Min Reward: 121.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
agent-1: 134.0
Sum Reward: 134.0
Avg Reward: 134.0
Min Reward: 134.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_21-05-23
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 204.0
  episode_reward_mean: 130.14
  episode_reward_min: 78.0
  episodes_this_iter: 2
  episodes_total: 736
  experiment_id: 325b24caee6c4209bf8cf01af4f33e4d
  hostname: gpu048
  info:
    apply_time_ms: 2.901
    dispatch_time_ms: 9.517
    learner:
      cur_lr: 0.0013110489817336202
      grad_gnorm: 17.71421241760254
      policy_entropy: 2.8457565307617188
      policy_loss: -0.4846010208129883
      var_gnorm: 30.641468048095703
      vf_explained_var: 1.1920928955078125e-07
      vf_loss: 1.9068630933761597
    num_steps_sampled: 737000
    num_steps_trained: 737000
    wait_time_ms: 29.42
  iterations_since_restore: 427
  node_ip: 172.17.8.48
  num_metric_batches_dropped: 0
  pid: 20453
  policy_reward_mean: {}
  time_since_restore: 3520.4314980506897
  time_this_iter_s: 9.062928199768066
  time_total_s: 3520.4314980506897
  timestamp: 1593997523
  timesteps_since_restore: 737000
  timesteps_this_iter: 2000
  timesteps_total: 737000
  training_iteration: 427
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=20453], 3520 s, 427 iter, 737000 ts, 130 rew

agent-1: 132.0
Sum Reward: 132.0
Avg Reward: 132.0
Min Reward: 132.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
agent-1: 104.0
Sum Reward: 104.0
Avg Reward: 104.0
Min Reward: 104.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_21-05-32
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 204.0
  episode_reward_mean: 130.3
  episode_reward_min: 78.0
  episodes_this_iter: 2
  episodes_total: 738
  experiment_id: 325b24caee6c4209bf8cf01af4f33e4d
  hostname: gpu048
  info:
    apply_time_ms: 3.441
    dispatch_time_ms: 6.876
    learner:
      cur_lr: 0.0013109158026054502
      grad_gnorm: 17.5707950592041
      policy_entropy: 2.930692434310913
      policy_loss: -0.4928712248802185
      var_gnorm: 30.64313507080078
      vf_explained_var: 1.1920928955078125e-07
      vf_loss: 1.8710098266601562
    num_steps_sampled: 739000
    num_steps_trained: 739000
    wait_time_ms: 30.087
  iterations_since_restore: 428
  node_ip: 172.17.8.48
  num_metric_batches_dropped: 0
  pid: 20453
  policy_reward_mean: {}
  time_since_restore: 3528.8222844600677
  time_this_iter_s: 8.390786409378052
  time_total_s: 3528.8222844600677
  timestamp: 1593997532
  timesteps_since_restore: 739000
  timesteps_this_iter: 2000
  timesteps_total: 739000
  training_iteration: 428
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=20453], 3528 s, 428 iter, 739000 ts, 130 rew

agent-1: 104.0
Sum Reward: 104.0
Avg Reward: 104.0
Min Reward: 104.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
agent-1: 151.0
Sum Reward: 151.0
Avg Reward: 151.0
Min Reward: 151.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_21-05-40
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 204.0
  episode_reward_mean: 129.56
  episode_reward_min: 78.0
  episodes_this_iter: 2
  episodes_total: 740
  experiment_id: 325b24caee6c4209bf8cf01af4f33e4d
  hostname: gpu048
  info:
    apply_time_ms: 2.573
    dispatch_time_ms: 7.243
    learner:
      cur_lr: 0.0013107826234772801
      grad_gnorm: 4.557323932647705
      policy_entropy: 4.959918975830078
      policy_loss: 0.7037537097930908
      var_gnorm: 30.64039421081543
      vf_explained_var: 0.0
      vf_loss: 0.5190240740776062
    num_steps_sampled: 741000
    num_steps_trained: 741000
    wait_time_ms: 31.619
  iterations_since_restore: 429
  node_ip: 172.17.8.48
  num_metric_batches_dropped: 0
  pid: 20453
  policy_reward_mean: {}
  time_since_restore: 3537.133754968643
  time_this_iter_s: 8.31147050857544
  time_total_s: 3537.133754968643
  timestamp: 1593997540
  timesteps_since_restore: 741000
  timesteps_this_iter: 2000
  timesteps_total: 741000
  training_iteration: 429
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=20453], 3537 s, 429 iter, 741000 ts, 130 rew

agent-1: 133.0
Sum Reward: 133.0
Avg Reward: 133.0
Min Reward: 133.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
agent-1: 105.0
Sum Reward: 105.0
Avg Reward: 105.0
Min Reward: 105.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_21-05-48
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 204.0
  episode_reward_mean: 129.84
  episode_reward_min: 78.0
  episodes_this_iter: 2
  episodes_total: 742
  experiment_id: 325b24caee6c4209bf8cf01af4f33e4d
  hostname: gpu048
  info:
    apply_time_ms: 3.399
    dispatch_time_ms: 7.038
    learner:
      cur_lr: 0.0013106494443491101
      grad_gnorm: 17.47007179260254
      policy_entropy: 3.370712995529175
      policy_loss: -1.4937251806259155
      var_gnorm: 30.64876937866211
      vf_explained_var: 0.0
      vf_loss: 1.9454498291015625
    num_steps_sampled: 743000
    num_steps_trained: 743000
    wait_time_ms: 31.4
  iterations_since_restore: 430
  node_ip: 172.17.8.48
  num_metric_batches_dropped: 0
  pid: 20453
  policy_reward_mean: {}
  time_since_restore: 3545.490222454071
  time_this_iter_s: 8.356467485427856
  time_total_s: 3545.490222454071
  timestamp: 1593997548
  timesteps_since_restore: 743000
  timesteps_this_iter: 2000
  timesteps_total: 743000
  training_iteration: 430
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=20453], 3545 s, 430 iter, 743000 ts, 130 rew

agent-1: 142.0
Sum Reward: 142.0
Avg Reward: 142.0
Min Reward: 142.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
agent-1: 133.0
Sum Reward: 133.0
Avg Reward: 133.0
Min Reward: 133.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_21-05-57
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 204.0
  episode_reward_mean: 130.16
  episode_reward_min: 78.0
  episodes_this_iter: 2
  episodes_total: 744
  experiment_id: 325b24caee6c4209bf8cf01af4f33e4d
  hostname: gpu048
  info:
    apply_time_ms: 3.218
    dispatch_time_ms: 8.34
    learner:
      cur_lr: 0.0013105161488056183
      grad_gnorm: 18.596466064453125
      policy_entropy: 3.3062796592712402
      policy_loss: -1.097427248954773
      var_gnorm: 30.657487869262695
      vf_explained_var: 0.0
      vf_loss: 2.15061616897583
    num_steps_sampled: 745000
    num_steps_trained: 745000
    wait_time_ms: 32.042
  iterations_since_restore: 431
  node_ip: 172.17.8.48
  num_metric_batches_dropped: 0
  pid: 20453
  policy_reward_mean: {}
  time_since_restore: 3553.902745962143
  time_this_iter_s: 8.4125235080719
  time_total_s: 3553.902745962143
  timestamp: 1593997557
  timesteps_since_restore: 745000
  timesteps_this_iter: 2000
  timesteps_total: 745000
  training_iteration: 431
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=20453], 3553 s, 431 iter, 745000 ts, 130 rew

agent-1: 133.0
Sum Reward: 133.0
Avg Reward: 133.0
Min Reward: 133.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
agent-1: 145.0
Sum Reward: 145.0
Avg Reward: 145.0
Min Reward: 145.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_21-06-06
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 204.0
  episode_reward_mean: 130.56
  episode_reward_min: 78.0
  episodes_this_iter: 2
  episodes_total: 746
  experiment_id: 325b24caee6c4209bf8cf01af4f33e4d
  hostname: gpu048
  info:
    apply_time_ms: 3.137
    dispatch_time_ms: 7.979
    learner:
      cur_lr: 0.0013103829696774483
      grad_gnorm: 29.159282684326172
      policy_entropy: 3.143461227416992
      policy_loss: 5.166905879974365
      var_gnorm: 30.68337059020996
      vf_explained_var: 0.0
      vf_loss: 4.818855285644531
    num_steps_sampled: 747000
    num_steps_trained: 747000
    wait_time_ms: 31.375
  iterations_since_restore: 432
  node_ip: 172.17.8.48
  num_metric_batches_dropped: 0
  pid: 20453
  policy_reward_mean: {}
  time_since_restore: 3562.46461558342
  time_this_iter_s: 8.561869621276855
  time_total_s: 3562.46461558342
  timestamp: 1593997566
  timesteps_since_restore: 747000
  timesteps_this_iter: 2000
  timesteps_total: 747000
  training_iteration: 432
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=20453], 3562 s, 432 iter, 747000 ts, 131 rew

agent-1: 138.0
Sum Reward: 138.0
Avg Reward: 138.0
Min Reward: 138.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
agent-1: 152.0
Sum Reward: 152.0
Avg Reward: 152.0
Min Reward: 152.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_21-06-14
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 204.0
  episode_reward_mean: 131.32
  episode_reward_min: 78.0
  episodes_this_iter: 2
  episodes_total: 748
  experiment_id: 325b24caee6c4209bf8cf01af4f33e4d
  hostname: gpu048
  info:
    apply_time_ms: 3.261
    dispatch_time_ms: 6.952
    learner:
      cur_lr: 0.0013102497905492783
      grad_gnorm: 40.00000762939453
      policy_entropy: 3.973318576812744
      policy_loss: 3.5330498218536377
      var_gnorm: 30.66778564453125
      vf_explained_var: 1.1920928955078125e-07
      vf_loss: 37.35880661010742
    num_steps_sampled: 749000
    num_steps_trained: 749000
    wait_time_ms: 32.947
  iterations_since_restore: 433
  node_ip: 172.17.8.48
  num_metric_batches_dropped: 0
  pid: 20453
  policy_reward_mean: {}
  time_since_restore: 3570.8335506916046
  time_this_iter_s: 8.368935108184814
  time_total_s: 3570.8335506916046
  timestamp: 1593997574
  timesteps_since_restore: 749000
  timesteps_this_iter: 2000
  timesteps_total: 749000
  training_iteration: 433
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=20453], 3570 s, 433 iter, 749000 ts, 131 rew

agent-1: 124.0
Sum Reward: 124.0
Avg Reward: 124.0
Min Reward: 124.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
agent-1: 119.0
Sum Reward: 119.0
Avg Reward: 119.0
Min Reward: 119.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_21-06-22
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 204.0
  episode_reward_mean: 131.55
  episode_reward_min: 78.0
  episodes_this_iter: 2
  episodes_total: 750
  experiment_id: 325b24caee6c4209bf8cf01af4f33e4d
  hostname: gpu048
  info:
    apply_time_ms: 3.194
    dispatch_time_ms: 7.621
    learner:
      cur_lr: 0.0013101166114211082
      grad_gnorm: 40.0
      policy_entropy: 4.023022651672363
      policy_loss: 2.7466018199920654
      var_gnorm: 30.67266082763672
      vf_explained_var: 0.0
      vf_loss: 24.921138763427734
    num_steps_sampled: 751000
    num_steps_trained: 751000
    wait_time_ms: 32.885
  iterations_since_restore: 434
  node_ip: 172.17.8.48
  num_metric_batches_dropped: 0
  pid: 20453
  policy_reward_mean: {}
  time_since_restore: 3579.1837844848633
  time_this_iter_s: 8.350233793258667
  time_total_s: 3579.1837844848633
  timestamp: 1593997582
  timesteps_since_restore: 751000
  timesteps_this_iter: 2000
  timesteps_total: 751000
  training_iteration: 434
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=20453], 3579 s, 434 iter, 751000 ts, 132 rew

agent-1: 139.0
Sum Reward: 139.0
Avg Reward: 139.0
Min Reward: 139.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
agent-1: 136.0
Sum Reward: 136.0
Avg Reward: 136.0
Min Reward: 136.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_21-06-31
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 204.0
  episode_reward_mean: 131.36
  episode_reward_min: 78.0
  episodes_this_iter: 2
  episodes_total: 752
  experiment_id: 325b24caee6c4209bf8cf01af4f33e4d
  hostname: gpu048
  info:
    apply_time_ms: 3.735
    dispatch_time_ms: 7.587
    learner:
      cur_lr: 0.0013099834322929382
      grad_gnorm: 17.80528450012207
      policy_entropy: 1.3249177932739258
      policy_loss: -0.17047972977161407
      var_gnorm: 30.670467376708984
      vf_explained_var: 0.0
      vf_loss: 2.02272367477417
    num_steps_sampled: 753000
    num_steps_trained: 753000
    wait_time_ms: 31.158
  iterations_since_restore: 435
  node_ip: 172.17.8.48
  num_metric_batches_dropped: 0
  pid: 20453
  policy_reward_mean: {}
  time_since_restore: 3587.6348843574524
  time_this_iter_s: 8.451099872589111
  time_total_s: 3587.6348843574524
  timestamp: 1593997591
  timesteps_since_restore: 753000
  timesteps_this_iter: 2000
  timesteps_total: 753000
  training_iteration: 435
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=20453], 3587 s, 435 iter, 753000 ts, 131 rew

agent-1: 77.0
Sum Reward: 77.0
Avg Reward: 77.0
Min Reward: 77.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
agent-1: 106.0
Sum Reward: 106.0
Avg Reward: 106.0
Min Reward: 106.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_21-06-39
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 204.0
  episode_reward_mean: 129.82
  episode_reward_min: 77.0
  episodes_this_iter: 2
  episodes_total: 754
  experiment_id: 325b24caee6c4209bf8cf01af4f33e4d
  hostname: gpu048
  info:
    apply_time_ms: 3.802
    dispatch_time_ms: 10.169
    learner:
      cur_lr: 0.0013098502531647682
      grad_gnorm: 1.399394154548645
      policy_entropy: 3.5512475967407227
      policy_loss: -0.05316566675901413
      var_gnorm: 30.643985748291016
      vf_explained_var: 0.0
      vf_loss: 0.5108787417411804
    num_steps_sampled: 755000
    num_steps_trained: 755000
    wait_time_ms: 27.27
  iterations_since_restore: 436
  node_ip: 172.17.8.48
  num_metric_batches_dropped: 0
  pid: 20453
  policy_reward_mean: {}
  time_since_restore: 3595.864584207535
  time_this_iter_s: 8.229699850082397
  time_total_s: 3595.864584207535
  timestamp: 1593997599
  timesteps_since_restore: 755000
  timesteps_this_iter: 2000
  timesteps_total: 755000
  training_iteration: 436
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=20453], 3595 s, 436 iter, 755000 ts, 130 rew

agent-1: 90.0
Sum Reward: 90.0
Avg Reward: 90.0
Min Reward: 90.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
agent-1: 130.0
Sum Reward: 130.0
Avg Reward: 130.0
Min Reward: 130.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_21-06-47
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 204.0
  episode_reward_mean: 129.16
  episode_reward_min: 77.0
  episodes_this_iter: 2
  episodes_total: 756
  experiment_id: 325b24caee6c4209bf8cf01af4f33e4d
  hostname: gpu048
  info:
    apply_time_ms: 3.818
    dispatch_time_ms: 8.119
    learner:
      cur_lr: 0.0013097169576212764
      grad_gnorm: 15.98804759979248
      policy_entropy: 3.0546813011169434
      policy_loss: -2.160886526107788
      var_gnorm: 30.6596622467041
      vf_explained_var: 0.0
      vf_loss: 1.606132984161377
    num_steps_sampled: 757000
    num_steps_trained: 757000
    wait_time_ms: 30.189
  iterations_since_restore: 437
  node_ip: 172.17.8.48
  num_metric_batches_dropped: 0
  pid: 20453
  policy_reward_mean: {}
  time_since_restore: 3604.2553617954254
  time_this_iter_s: 8.390777587890625
  time_total_s: 3604.2553617954254
  timestamp: 1593997607
  timesteps_since_restore: 757000
  timesteps_this_iter: 2000
  timesteps_total: 757000
  training_iteration: 437
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=20453], 3604 s, 437 iter, 757000 ts, 129 rew

agent-1: 122.0
Sum Reward: 122.0
Avg Reward: 122.0
Min Reward: 122.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
agent-1: 115.0
Sum Reward: 115.0
Avg Reward: 115.0
Min Reward: 115.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_21-06-56
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 204.0
  episode_reward_mean: 128.59
  episode_reward_min: 77.0
  episodes_this_iter: 2
  episodes_total: 758
  experiment_id: 325b24caee6c4209bf8cf01af4f33e4d
  hostname: gpu048
  info:
    apply_time_ms: 3.414
    dispatch_time_ms: 27.505
    learner:
      cur_lr: 0.0013095837784931064
      grad_gnorm: 40.000003814697266
      policy_entropy: 3.3915350437164307
      policy_loss: 11.548670768737793
      var_gnorm: 30.670448303222656
      vf_explained_var: 0.0
      vf_loss: 43.505062103271484
    num_steps_sampled: 759000
    num_steps_trained: 759000
    wait_time_ms: 23.784
  iterations_since_restore: 438
  node_ip: 172.17.8.48
  num_metric_batches_dropped: 0
  pid: 20453
  policy_reward_mean: {}
  time_since_restore: 3612.7623629570007
  time_this_iter_s: 8.507001161575317
  time_total_s: 3612.7623629570007
  timestamp: 1593997616
  timesteps_since_restore: 759000
  timesteps_this_iter: 2000
  timesteps_total: 759000
  training_iteration: 438
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=20453], 3612 s, 438 iter, 759000 ts, 129 rew

agent-1: 180.0
Sum Reward: 180.0
Avg Reward: 180.0
Min Reward: 180.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
agent-1: 145.0
Sum Reward: 145.0
Avg Reward: 145.0
Min Reward: 145.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_21-07-03
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 204.0
  episode_reward_mean: 129.63
  episode_reward_min: 77.0
  episodes_this_iter: 2
  episodes_total: 760
  experiment_id: 325b24caee6c4209bf8cf01af4f33e4d
  hostname: gpu048
  info:
    apply_time_ms: 2.621
    dispatch_time_ms: 49.657
    learner:
      cur_lr: 0.0013094505993649364
      grad_gnorm: 39.999996185302734
      policy_entropy: 3.0608506202697754
      policy_loss: -10.207032203674316
      var_gnorm: 30.684412002563477
      vf_explained_var: -1.0
      vf_loss: 596.9304809570312
    num_steps_sampled: 760000
    num_steps_trained: 760000
    wait_time_ms: 27.687
  iterations_since_restore: 439
  node_ip: 172.17.8.48
  num_metric_batches_dropped: 0
  pid: 20453
  policy_reward_mean: {}
  time_since_restore: 3619.819258451462
  time_this_iter_s: 7.05689549446106
  time_total_s: 3619.819258451462
  timestamp: 1593997623
  timesteps_since_restore: 760000
  timesteps_this_iter: 1000
  timesteps_total: 760000
  training_iteration: 439
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=20453], 3619 s, 439 iter, 760000 ts, 130 rew

Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_21-07-10
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 204.0
  episode_reward_mean: 129.63
  episode_reward_min: 77.0
  episodes_this_iter: 0
  episodes_total: 760
  experiment_id: 325b24caee6c4209bf8cf01af4f33e4d
  hostname: gpu048
  info:
    apply_time_ms: 2.65
    dispatch_time_ms: 39.116
    learner:
      cur_lr: 0.0013093840098008513
      grad_gnorm: 25.696847915649414
      policy_entropy: 3.936422348022461
      policy_loss: -3.327014923095703
      var_gnorm: 30.695484161376953
      vf_explained_var: 0.0
      vf_loss: 3.7454071044921875
    num_steps_sampled: 761000
    num_steps_trained: 761000
    wait_time_ms: 15.485
  iterations_since_restore: 440
  node_ip: 172.17.8.48
  num_metric_batches_dropped: 0
  pid: 20453
  policy_reward_mean: {}
  time_since_restore: 3626.714357852936
  time_this_iter_s: 6.895099401473999
  time_total_s: 3626.714357852936
  timestamp: 1593997630
  timesteps_since_restore: 761000
  timesteps_this_iter: 1000
  timesteps_total: 761000
  training_iteration: 440
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=20453], 3626 s, 440 iter, 761000 ts, 130 rew

agent-1: 173.0
Sum Reward: 173.0
Avg Reward: 173.0
Min Reward: 173.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
agent-1: 181.0
Sum Reward: 181.0
Avg Reward: 181.0
Min Reward: 181.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_21-07-17
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 204.0
  episode_reward_mean: 130.37
  episode_reward_min: 77.0
  episodes_this_iter: 2
  episodes_total: 762
  experiment_id: 325b24caee6c4209bf8cf01af4f33e4d
  hostname: gpu048
  info:
    apply_time_ms: 4.355
    dispatch_time_ms: 44.987
    learner:
      cur_lr: 0.0013093174202367663
      grad_gnorm: 6.106540679931641
      policy_entropy: 2.700716495513916
      policy_loss: -1.1695654392242432
      var_gnorm: 30.71035385131836
      vf_explained_var: -1.0
      vf_loss: 1.9673978090286255
    num_steps_sampled: 762000
    num_steps_trained: 762000
    wait_time_ms: 47.631
  iterations_since_restore: 441
  node_ip: 172.17.8.48
  num_metric_batches_dropped: 0
  pid: 20453
  policy_reward_mean: {}
  time_since_restore: 3633.8983533382416
  time_this_iter_s: 7.183995485305786
  time_total_s: 3633.8983533382416
  timestamp: 1593997637
  timesteps_since_restore: 762000
  timesteps_this_iter: 1000
  timesteps_total: 762000
  training_iteration: 441
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=20453], 3633 s, 441 iter, 762000 ts, 130 rew

Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_21-07-24
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 204.0
  episode_reward_mean: 130.37
  episode_reward_min: 77.0
  episodes_this_iter: 0
  episodes_total: 762
  experiment_id: 325b24caee6c4209bf8cf01af4f33e4d
  hostname: gpu048
  info:
    apply_time_ms: 2.779
    dispatch_time_ms: 31.902
    learner:
      cur_lr: 0.0013092508306726813
      grad_gnorm: 13.060837745666504
      policy_entropy: 2.255718946456909
      policy_loss: -0.4040527641773224
      var_gnorm: 30.707563400268555
      vf_explained_var: 0.0
      vf_loss: 1.3752310276031494
    num_steps_sampled: 763000
    num_steps_trained: 763000
    wait_time_ms: 27.038
  iterations_since_restore: 442
  node_ip: 172.17.8.48
  num_metric_batches_dropped: 0
  pid: 20453
  policy_reward_mean: {}
  time_since_restore: 3640.556426048279
  time_this_iter_s: 6.6580727100372314
  time_total_s: 3640.556426048279
  timestamp: 1593997644
  timesteps_since_restore: 763000
  timesteps_this_iter: 1000
  timesteps_total: 763000
  training_iteration: 442
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=20453], 3640 s, 442 iter, 763000 ts, 130 rew

agent-1: 106.0
Sum Reward: 106.0
Avg Reward: 106.0
Min Reward: 106.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
agent-1: 151.0
Sum Reward: 151.0
Avg Reward: 151.0
Min Reward: 151.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_21-07-30
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 204.0
  episode_reward_mean: 130.57
  episode_reward_min: 77.0
  episodes_this_iter: 2
  episodes_total: 764
  experiment_id: 325b24caee6c4209bf8cf01af4f33e4d
  hostname: gpu048
  info:
    apply_time_ms: 4.363
    dispatch_time_ms: 31.246
    learner:
      cur_lr: 0.0013091842411085963
      grad_gnorm: 40.0
      policy_entropy: 3.9920129776000977
      policy_loss: -30.312416076660156
      var_gnorm: 30.70435333251953
      vf_explained_var: -7.152557373046875e-07
      vf_loss: 479.0557861328125
    num_steps_sampled: 764000
    num_steps_trained: 764000
    wait_time_ms: 11.512
  iterations_since_restore: 443
  node_ip: 172.17.8.48
  num_metric_batches_dropped: 0
  pid: 20453
  policy_reward_mean: {}
  time_since_restore: 3646.8937406539917
  time_this_iter_s: 6.337314605712891
  time_total_s: 3646.8937406539917
  timestamp: 1593997650
  timesteps_since_restore: 764000
  timesteps_this_iter: 1000
  timesteps_total: 764000
  training_iteration: 443
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=20453], 3646 s, 443 iter, 764000 ts, 131 rew

agent-1: 128.0
Sum Reward: 128.0
Avg Reward: 128.0
Min Reward: 128.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
agent-1: 154.0
Sum Reward: 154.0
Avg Reward: 154.0
Min Reward: 154.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_21-07-52
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 204.0
  episode_reward_mean: 130.95
  episode_reward_min: 77.0
  episodes_this_iter: 2
  episodes_total: 766
  experiment_id: 325b24caee6c4209bf8cf01af4f33e4d
  hostname: gpu048
  info:
    apply_time_ms: 3.15
    dispatch_time_ms: 10.244
    learner:
      cur_lr: 0.0013091176515445113
      grad_gnorm: 40.0
      policy_entropy: 3.3531622886657715
      policy_loss: -45.803436279296875
      var_gnorm: 30.70197868347168
      vf_explained_var: 1.7881393432617188e-07
      vf_loss: 427.4949035644531
    num_steps_sampled: 766000
    num_steps_trained: 766000
    wait_time_ms: 31.435
  iterations_since_restore: 444
  node_ip: 172.17.8.48
  num_metric_batches_dropped: 0
  pid: 20453
  policy_reward_mean: {}
  time_since_restore: 3668.9846346378326
  time_this_iter_s: 22.090893983840942
  time_total_s: 3668.9846346378326
  timestamp: 1593997672
  timesteps_since_restore: 766000
  timesteps_this_iter: 2000
  timesteps_total: 766000
  training_iteration: 444
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=20453], 3668 s, 444 iter, 766000 ts, 131 rew

agent-1: 108.0
Sum Reward: 108.0
Avg Reward: 108.0
Min Reward: 108.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
agent-1: 114.0
Sum Reward: 114.0
Avg Reward: 114.0
Min Reward: 114.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_21-08-01
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 204.0
  episode_reward_mean: 130.48
  episode_reward_min: 77.0
  episodes_this_iter: 2
  episodes_total: 768
  experiment_id: 325b24caee6c4209bf8cf01af4f33e4d
  hostname: gpu048
  info:
    apply_time_ms: 3.347
    dispatch_time_ms: 13.367
    learner:
      cur_lr: 0.0013089843560010195
      grad_gnorm: 40.0
      policy_entropy: 4.26326322555542
      policy_loss: -76.32040405273438
      var_gnorm: 30.696495056152344
      vf_explained_var: -1.0
      vf_loss: 628.9447631835938
    num_steps_sampled: 768000
    num_steps_trained: 768000
    wait_time_ms: 18.541
  iterations_since_restore: 445
  node_ip: 172.17.8.48
  num_metric_batches_dropped: 0
  pid: 20453
  policy_reward_mean: {}
  time_since_restore: 3677.4717075824738
  time_this_iter_s: 8.487072944641113
  time_total_s: 3677.4717075824738
  timestamp: 1593997681
  timesteps_since_restore: 768000
  timesteps_this_iter: 2000
  timesteps_total: 768000
  training_iteration: 445
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=20453], 3677 s, 445 iter, 768000 ts, 130 rew

agent-1: 92.0
Sum Reward: 92.0
Avg Reward: 92.0
Min Reward: 92.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
agent-1: 145.0
Sum Reward: 145.0
Avg Reward: 145.0
Min Reward: 145.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_21-08-10
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 181.0
  episode_reward_mean: 129.65
  episode_reward_min: 77.0
  episodes_this_iter: 2
  episodes_total: 770
  experiment_id: 325b24caee6c4209bf8cf01af4f33e4d
  hostname: gpu048
  info:
    apply_time_ms: 2.876
    dispatch_time_ms: 53.474
    learner:
      cur_lr: 0.0013088511768728495
      grad_gnorm: 19.09795570373535
      policy_entropy: 2.8197145462036133
      policy_loss: -1.477764368057251
      var_gnorm: 30.68968391418457
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 2.2674436569213867
    num_steps_sampled: 770000
    num_steps_trained: 770000
    wait_time_ms: 26.025
  iterations_since_restore: 446
  node_ip: 172.17.8.48
  num_metric_batches_dropped: 0
  pid: 20453
  policy_reward_mean: {}
  time_since_restore: 3686.4917347431183
  time_this_iter_s: 9.020027160644531
  time_total_s: 3686.4917347431183
  timestamp: 1593997690
  timesteps_since_restore: 770000
  timesteps_this_iter: 2000
  timesteps_total: 770000
  training_iteration: 446
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=20453], 3686 s, 446 iter, 770000 ts, 130 rew

Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_21-08-15
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 181.0
  episode_reward_mean: 129.65
  episode_reward_min: 77.0
  episodes_this_iter: 0
  episodes_total: 770
  experiment_id: 325b24caee6c4209bf8cf01af4f33e4d
  hostname: gpu048
  info:
    apply_time_ms: 4.678
    dispatch_time_ms: 16.968
    learner:
      cur_lr: 0.0013087179977446795
      grad_gnorm: 5.213481426239014
      policy_entropy: 5.007784843444824
      policy_loss: 0.8462425470352173
      var_gnorm: 30.70144271850586
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 0.5670677423477173
    num_steps_sampled: 771000
    num_steps_trained: 771000
    wait_time_ms: 22.754
  iterations_since_restore: 447
  node_ip: 172.17.8.48
  num_metric_batches_dropped: 0
  pid: 20453
  policy_reward_mean: {}
  time_since_restore: 3691.5623457431793
  time_this_iter_s: 5.070611000061035
  time_total_s: 3691.5623457431793
  timestamp: 1593997695
  timesteps_since_restore: 771000
  timesteps_this_iter: 1000
  timesteps_total: 771000
  training_iteration: 447
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=20453], 3691 s, 447 iter, 771000 ts, 130 rew

agent-1: 143.0
Sum Reward: 143.0
Avg Reward: 143.0
Min Reward: 143.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
agent-1: 133.0
Sum Reward: 133.0
Avg Reward: 133.0
Min Reward: 133.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_21-08-26
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 181.0
  episode_reward_mean: 129.87
  episode_reward_min: 77.0
  episodes_this_iter: 2
  episodes_total: 772
  experiment_id: 325b24caee6c4209bf8cf01af4f33e4d
  hostname: gpu048
  info:
    apply_time_ms: 2.418
    dispatch_time_ms: 45.36
    learner:
      cur_lr: 0.0013086514081805944
      grad_gnorm: 40.0
      policy_entropy: 3.529477596282959
      policy_loss: 10.196971893310547
      var_gnorm: 30.708654403686523
      vf_explained_var: 0.0
      vf_loss: 33.155067443847656
    num_steps_sampled: 773000
    num_steps_trained: 773000
    wait_time_ms: 23.377
  iterations_since_restore: 448
  node_ip: 172.17.8.48
  num_metric_batches_dropped: 0
  pid: 20453
  policy_reward_mean: {}
  time_since_restore: 3702.0241465568542
  time_this_iter_s: 10.461800813674927
  time_total_s: 3702.0241465568542
  timestamp: 1593997706
  timesteps_since_restore: 773000
  timesteps_this_iter: 2000
  timesteps_total: 773000
  training_iteration: 448
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=20453], 3702 s, 448 iter, 773000 ts, 130 rew

agent-1: 156.0
Sum Reward: 156.0
Avg Reward: 156.0
Min Reward: 156.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
agent-1: 157.0
Sum Reward: 157.0
Avg Reward: 157.0
Min Reward: 157.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_21-08-31
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 181.0
  episode_reward_mean: 130.54
  episode_reward_min: 77.0
  episodes_this_iter: 2
  episodes_total: 774
  experiment_id: 325b24caee6c4209bf8cf01af4f33e4d
  hostname: gpu048
  info:
    apply_time_ms: 3.475
    dispatch_time_ms: 30.555
    learner:
      cur_lr: 0.0013085182290524244
      grad_gnorm: 7.999576091766357
      policy_entropy: 3.386945962905884
      policy_loss: -1.1812928915023804
      var_gnorm: 30.71558380126953
      vf_explained_var: 0.0
      vf_loss: 0.6350757479667664
    num_steps_sampled: 774000
    num_steps_trained: 774000
    wait_time_ms: 28.687
  iterations_since_restore: 449
  node_ip: 172.17.8.48
  num_metric_batches_dropped: 0
  pid: 20453
  policy_reward_mean: {}
  time_since_restore: 3707.9201362133026
  time_this_iter_s: 5.895989656448364
  time_total_s: 3707.9201362133026
  timestamp: 1593997711
  timesteps_since_restore: 774000
  timesteps_this_iter: 1000
  timesteps_total: 774000
  training_iteration: 449
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=20453], 3707 s, 449 iter, 774000 ts, 131 rew

Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_21-08-38
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 181.0
  episode_reward_mean: 130.54
  episode_reward_min: 77.0
  episodes_this_iter: 0
  episodes_total: 774
  experiment_id: 325b24caee6c4209bf8cf01af4f33e4d
  hostname: gpu048
  info:
    apply_time_ms: 3.421
    dispatch_time_ms: 39.368
    learner:
      cur_lr: 0.0013084516394883394
      grad_gnorm: 18.94540023803711
      policy_entropy: 2.133488893508911
      policy_loss: -5.522892951965332
      var_gnorm: 30.709394454956055
      vf_explained_var: 0.0
      vf_loss: 1.4633580446243286
    num_steps_sampled: 775000
    num_steps_trained: 775000
    wait_time_ms: 15.875
  iterations_since_restore: 450
  node_ip: 172.17.8.48
  num_metric_batches_dropped: 0
  pid: 20453
  policy_reward_mean: {}
  time_since_restore: 3714.06481218338
  time_this_iter_s: 6.144675970077515
  time_total_s: 3714.06481218338
  timestamp: 1593997718
  timesteps_since_restore: 775000
  timesteps_this_iter: 1000
  timesteps_total: 775000
  training_iteration: 450
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=20453], 3714 s, 450 iter, 775000 ts, 131 rew

agent-1: 115.0
Sum Reward: 115.0
Avg Reward: 115.0
Min Reward: 115.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
agent-1: 104.0
Sum Reward: 104.0
Avg Reward: 104.0
Min Reward: 104.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_21-08-44
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 181.0
  episode_reward_mean: 130.7
  episode_reward_min: 77.0
  episodes_this_iter: 2
  episodes_total: 776
  experiment_id: 325b24caee6c4209bf8cf01af4f33e4d
  hostname: gpu048
  info:
    apply_time_ms: 3.787
    dispatch_time_ms: 33.9
    learner:
      cur_lr: 0.0013083850499242544
      grad_gnorm: 6.45576286315918
      policy_entropy: 3.660536289215088
      policy_loss: -0.7355952858924866
      var_gnorm: 30.703075408935547
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 0.49031007289886475
    num_steps_sampled: 776000
    num_steps_trained: 776000
    wait_time_ms: 16.506
  iterations_since_restore: 451
  node_ip: 172.17.8.48
  num_metric_batches_dropped: 0
  pid: 20453
  policy_reward_mean: {}
  time_since_restore: 3720.0055367946625
  time_this_iter_s: 5.940724611282349
  time_total_s: 3720.0055367946625
  timestamp: 1593997724
  timesteps_since_restore: 776000
  timesteps_this_iter: 1000
  timesteps_total: 776000
  training_iteration: 451
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=20453], 3720 s, 451 iter, 776000 ts, 131 rew

Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_21-08-50
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 181.0
  episode_reward_mean: 130.7
  episode_reward_min: 77.0
  episodes_this_iter: 0
  episodes_total: 776
  experiment_id: 325b24caee6c4209bf8cf01af4f33e4d
  hostname: gpu048
  info:
    apply_time_ms: 2.889
    dispatch_time_ms: 42.645
    learner:
      cur_lr: 0.0013083183439448476
      grad_gnorm: 25.99746322631836
      policy_entropy: 4.021770477294922
      policy_loss: -1.1332865953445435
      var_gnorm: 30.714176177978516
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 3.7219114303588867
    num_steps_sampled: 777000
    num_steps_trained: 777000
    wait_time_ms: 27.619
  iterations_since_restore: 452
  node_ip: 172.17.8.48
  num_metric_batches_dropped: 0
  pid: 20453
  policy_reward_mean: {}
  time_since_restore: 3726.0769517421722
  time_this_iter_s: 6.071414947509766
  time_total_s: 3726.0769517421722
  timestamp: 1593997730
  timesteps_since_restore: 777000
  timesteps_this_iter: 1000
  timesteps_total: 777000
  training_iteration: 452
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=20453], 3726 s, 452 iter, 777000 ts, 131 rew

agent-1: 127.0
Sum Reward: 127.0
Avg Reward: 127.0
Min Reward: 127.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
agent-1: 131.0
Sum Reward: 131.0
Avg Reward: 131.0
Min Reward: 131.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_21-08-55
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 181.0
  episode_reward_mean: 130.49
  episode_reward_min: 77.0
  episodes_this_iter: 2
  episodes_total: 778
  experiment_id: 325b24caee6c4209bf8cf01af4f33e4d
  hostname: gpu048
  info:
    apply_time_ms: 3.047
    dispatch_time_ms: 20.883
    learner:
      cur_lr: 0.0013082517543807626
      grad_gnorm: 20.604442596435547
      policy_entropy: 2.9655587673187256
      policy_loss: -3.3598098754882812
      var_gnorm: 30.70719337463379
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 2.4466750621795654
    num_steps_sampled: 778000
    num_steps_trained: 778000
    wait_time_ms: 25.156
  iterations_since_restore: 453
  node_ip: 172.17.8.48
  num_metric_batches_dropped: 0
  pid: 20453
  policy_reward_mean: {}
  time_since_restore: 3731.768942594528
  time_this_iter_s: 5.691990852355957
  time_total_s: 3731.768942594528
  timestamp: 1593997735
  timesteps_since_restore: 778000
  timesteps_this_iter: 1000
  timesteps_total: 778000
  training_iteration: 453
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=20453], 3731 s, 453 iter, 778000 ts, 130 rew

Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_21-09-02
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 181.0
  episode_reward_mean: 130.49
  episode_reward_min: 77.0
  episodes_this_iter: 0
  episodes_total: 778
  experiment_id: 325b24caee6c4209bf8cf01af4f33e4d
  hostname: gpu048
  info:
    apply_time_ms: 3.704
    dispatch_time_ms: 34.968
    learner:
      cur_lr: 0.0013081851648166776
      grad_gnorm: 4.868709087371826
      policy_entropy: 3.7907485961914062
      policy_loss: 0.4265103340148926
      var_gnorm: 30.700332641601562
      vf_explained_var: 0.0
      vf_loss: 0.5221521258354187
    num_steps_sampled: 779000
    num_steps_trained: 779000
    wait_time_ms: 25.167
  iterations_since_restore: 454
  node_ip: 172.17.8.48
  num_metric_batches_dropped: 0
  pid: 20453
  policy_reward_mean: {}
  time_since_restore: 3737.9249589443207
  time_this_iter_s: 6.1560163497924805
  time_total_s: 3737.9249589443207
  timestamp: 1593997742
  timesteps_since_restore: 779000
  timesteps_this_iter: 1000
  timesteps_total: 779000
  training_iteration: 454
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=20453], 3737 s, 454 iter, 779000 ts, 130 rew

agent-1: 129.0
Sum Reward: 129.0
Avg Reward: 129.0
Min Reward: 129.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
agent-1: 119.0
Sum Reward: 119.0
Avg Reward: 119.0
Min Reward: 119.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_21-09-11
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 181.0
  episode_reward_mean: 130.25
  episode_reward_min: 77.0
  episodes_this_iter: 2
  episodes_total: 780
  experiment_id: 325b24caee6c4209bf8cf01af4f33e4d
  hostname: gpu048
  info:
    apply_time_ms: 5.667
    dispatch_time_ms: 23.342
    learner:
      cur_lr: 0.0013081185752525926
      grad_gnorm: 19.18553352355957
      policy_entropy: 4.2179107666015625
      policy_loss: -0.936469316482544
      var_gnorm: 30.70379638671875
      vf_explained_var: 0.0
      vf_loss: 2.012373208999634
    num_steps_sampled: 781000
    num_steps_trained: 781000
    wait_time_ms: 18.693
  iterations_since_restore: 455
  node_ip: 172.17.8.48
  num_metric_batches_dropped: 0
  pid: 20453
  policy_reward_mean: {}
  time_since_restore: 3747.2569708824158
  time_this_iter_s: 9.332011938095093
  time_total_s: 3747.2569708824158
  timestamp: 1593997751
  timesteps_since_restore: 781000
  timesteps_this_iter: 2000
  timesteps_total: 781000
  training_iteration: 455
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=20453], 3747 s, 455 iter, 781000 ts, 130 rew

agent-1: 94.0
Sum Reward: 94.0
Avg Reward: 94.0
Min Reward: 94.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_21-09-16
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 181.0
  episode_reward_mean: 129.97
  episode_reward_min: 77.0
  episodes_this_iter: 1
  episodes_total: 781
  experiment_id: 325b24caee6c4209bf8cf01af4f33e4d
  hostname: gpu048
  info:
    apply_time_ms: 3.842
    dispatch_time_ms: 10.071
    learner:
      cur_lr: 0.0013079853961244226
      grad_gnorm: 39.999996185302734
      policy_entropy: 3.372769594192505
      policy_loss: 1.37059485912323
      var_gnorm: 30.710033416748047
      vf_explained_var: 0.0
      vf_loss: 8.070158004760742
    num_steps_sampled: 782000
    num_steps_trained: 782000
    wait_time_ms: 31.089
  iterations_since_restore: 456
  node_ip: 172.17.8.48
  num_metric_batches_dropped: 0
  pid: 20453
  policy_reward_mean: {}
  time_since_restore: 3752.3354489803314
  time_this_iter_s: 5.078478097915649
  time_total_s: 3752.3354489803314
  timestamp: 1593997756
  timesteps_since_restore: 782000
  timesteps_this_iter: 1000
  timesteps_total: 782000
  training_iteration: 456
  
agent-1: 170.0
Sum Reward: 170.0
Avg Reward: 170.0
Min Reward: 170.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=20453], 3752 s, 456 iter, 782000 ts, 130 rew

agent-1: 145.0
Sum Reward: 145.0
Avg Reward: 145.0
Min Reward: 145.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
agent-1: 122.0
Sum Reward: 122.0
Avg Reward: 122.0
Min Reward: 122.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_21-09-24
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 181.0
  episode_reward_mean: 130.08
  episode_reward_min: 77.0
  episodes_this_iter: 3
  episodes_total: 784
  experiment_id: 325b24caee6c4209bf8cf01af4f33e4d
  hostname: gpu048
  info:
    apply_time_ms: 2.949
    dispatch_time_ms: 9.574
    learner:
      cur_lr: 0.0013079188065603375
      grad_gnorm: 40.0
      policy_entropy: 1.5167019367218018
      policy_loss: -3.8997409343719482
      var_gnorm: 30.710189819335938
      vf_explained_var: -1.0
      vf_loss: 599.5562133789062
    num_steps_sampled: 784000
    num_steps_trained: 784000
    wait_time_ms: 31.713
  iterations_since_restore: 457
  node_ip: 172.17.8.48
  num_metric_batches_dropped: 0
  pid: 20453
  policy_reward_mean: {}
  time_since_restore: 3760.619125843048
  time_this_iter_s: 8.283676862716675
  time_total_s: 3760.619125843048
  timestamp: 1593997764
  timesteps_since_restore: 784000
  timesteps_this_iter: 2000
  timesteps_total: 784000
  training_iteration: 457
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=20453], 3760 s, 457 iter, 784000 ts, 130 rew

agent-1: 105.0
Sum Reward: 105.0
Avg Reward: 105.0
Min Reward: 105.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
agent-1: 126.0
Sum Reward: 126.0
Avg Reward: 126.0
Min Reward: 126.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_21-09-34
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 181.0
  episode_reward_mean: 129.87
  episode_reward_min: 77.0
  episodes_this_iter: 2
  episodes_total: 786
  experiment_id: 325b24caee6c4209bf8cf01af4f33e4d
  hostname: gpu048
  info:
    apply_time_ms: 3.843
    dispatch_time_ms: 35.695
    learner:
      cur_lr: 0.0013077856274321675
      grad_gnorm: 39.999996185302734
      policy_entropy: 4.332413673400879
      policy_loss: -14.483508110046387
      var_gnorm: 30.69753646850586
      vf_explained_var: -2.384185791015625e-07
      vf_loss: 376.7672119140625
    num_steps_sampled: 786000
    num_steps_trained: 786000
    wait_time_ms: 18.865
  iterations_since_restore: 458
  node_ip: 172.17.8.48
  num_metric_batches_dropped: 0
  pid: 20453
  policy_reward_mean: {}
  time_since_restore: 3770.0129387378693
  time_this_iter_s: 9.393812894821167
  time_total_s: 3770.0129387378693
  timestamp: 1593997774
  timesteps_since_restore: 786000
  timesteps_this_iter: 2000
  timesteps_total: 786000
  training_iteration: 458
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=20453], 3770 s, 458 iter, 786000 ts, 130 rew

agent-1: 96.0
Sum Reward: 96.0
Avg Reward: 96.0
Min Reward: 96.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_21-09-42
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 181.0
  episode_reward_mean: 129.33
  episode_reward_min: 77.0
  episodes_this_iter: 1
  episodes_total: 787
  experiment_id: 325b24caee6c4209bf8cf01af4f33e4d
  hostname: gpu048
  info:
    apply_time_ms: 3.308
    dispatch_time_ms: 11.008
    learner:
      cur_lr: 0.0013076524483039975
      grad_gnorm: 15.080118179321289
      policy_entropy: 4.166136264801025
      policy_loss: -2.228088617324829
      var_gnorm: 30.710920333862305
      vf_explained_var: 0.0
      vf_loss: 1.575178861618042
    num_steps_sampled: 788000
    num_steps_trained: 788000
    wait_time_ms: 27.296
  iterations_since_restore: 459
  node_ip: 172.17.8.48
  num_metric_batches_dropped: 0
  pid: 20453
  policy_reward_mean: {}
  time_since_restore: 3778.7207980155945
  time_this_iter_s: 8.70785927772522
  time_total_s: 3778.7207980155945
  timestamp: 1593997782
  timesteps_since_restore: 788000
  timesteps_this_iter: 2000
  timesteps_total: 788000
  training_iteration: 459
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=20453], 3778 s, 459 iter, 788000 ts, 129 rew

agent-1: 185.0
Sum Reward: 185.0
Avg Reward: 185.0
Min Reward: 185.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
agent-1: 119.0
Sum Reward: 119.0
Avg Reward: 119.0
Min Reward: 119.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_21-09-51
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 185.0
  episode_reward_mean: 129.8
  episode_reward_min: 77.0
  episodes_this_iter: 2
  episodes_total: 789
  experiment_id: 325b24caee6c4209bf8cf01af4f33e4d
  hostname: gpu048
  info:
    apply_time_ms: 2.689
    dispatch_time_ms: 8.029
    learner:
      cur_lr: 0.0013075191527605057
      grad_gnorm: 6.115163803100586
      policy_entropy: 3.632843494415283
      policy_loss: -1.0989551544189453
      var_gnorm: 30.715547561645508
      vf_explained_var: 0.0
      vf_loss: 0.5663371086120605
    num_steps_sampled: 790000
    num_steps_trained: 790000
    wait_time_ms: 30.069
  iterations_since_restore: 460
  node_ip: 172.17.8.48
  num_metric_batches_dropped: 0
  pid: 20453
  policy_reward_mean: {}
  time_since_restore: 3787.100167989731
  time_this_iter_s: 8.379369974136353
  time_total_s: 3787.100167989731
  timestamp: 1593997791
  timesteps_since_restore: 790000
  timesteps_this_iter: 2000
  timesteps_total: 790000
  training_iteration: 460
  
agent-1: 143.0
Sum Reward: 143.0
Avg Reward: 143.0
Min Reward: 143.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=20453], 3787 s, 460 iter, 790000 ts, 130 rew

agent-1: 101.0
Sum Reward: 101.0
Avg Reward: 101.0
Min Reward: 101.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
agent-1: 148.0
Sum Reward: 148.0
Avg Reward: 148.0
Min Reward: 148.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_21-09-59
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 185.0
  episode_reward_mean: 129.32
  episode_reward_min: 77.0
  episodes_this_iter: 3
  episodes_total: 792
  experiment_id: 325b24caee6c4209bf8cf01af4f33e4d
  hostname: gpu048
  info:
    apply_time_ms: 3.486
    dispatch_time_ms: 6.72
    learner:
      cur_lr: 0.0013073859736323357
      grad_gnorm: 40.0
      policy_entropy: 3.635547637939453
      policy_loss: -32.29477310180664
      var_gnorm: 30.71704864501953
      vf_explained_var: 2.384185791015625e-07
      vf_loss: 520.887939453125
    num_steps_sampled: 792000
    num_steps_trained: 792000
    wait_time_ms: 33.915
  iterations_since_restore: 461
  node_ip: 172.17.8.48
  num_metric_batches_dropped: 0
  pid: 20453
  policy_reward_mean: {}
  time_since_restore: 3795.323154449463
  time_this_iter_s: 8.222986459732056
  time_total_s: 3795.323154449463
  timestamp: 1593997799
  timesteps_since_restore: 792000
  timesteps_this_iter: 2000
  timesteps_total: 792000
  training_iteration: 461
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=20453], 3795 s, 461 iter, 792000 ts, 129 rew

agent-1: 99.0
Sum Reward: 99.0
Avg Reward: 99.0
Min Reward: 99.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_21-10-08
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 185.0
  episode_reward_mean: 129.25
  episode_reward_min: 77.0
  episodes_this_iter: 1
  episodes_total: 793
  experiment_id: 325b24caee6c4209bf8cf01af4f33e4d
  hostname: gpu048
  info:
    apply_time_ms: 3.427
    dispatch_time_ms: 8.727
    learner:
      cur_lr: 0.0013072527945041656
      grad_gnorm: 32.64739990234375
      policy_entropy: 3.188645601272583
      policy_loss: 2.8076984882354736
      var_gnorm: 30.725399017333984
      vf_explained_var: 0.0
      vf_loss: 6.556335926055908
    num_steps_sampled: 794000
    num_steps_trained: 794000
    wait_time_ms: 30.506
  iterations_since_restore: 462
  node_ip: 172.17.8.48
  num_metric_batches_dropped: 0
  pid: 20453
  policy_reward_mean: {}
  time_since_restore: 3803.659729719162
  time_this_iter_s: 8.336575269699097
  time_total_s: 3803.659729719162
  timestamp: 1593997808
  timesteps_since_restore: 794000
  timesteps_this_iter: 2000
  timesteps_total: 794000
  training_iteration: 462
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=20453], 3803 s, 462 iter, 794000 ts, 129 rew

agent-1: 179.0
Sum Reward: 179.0
Avg Reward: 179.0
Min Reward: 179.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
agent-1: 143.0
Sum Reward: 143.0
Avg Reward: 143.0
Min Reward: 143.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_21-10-16
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 185.0
  episode_reward_mean: 129.81
  episode_reward_min: 77.0
  episodes_this_iter: 2
  episodes_total: 795
  experiment_id: 325b24caee6c4209bf8cf01af4f33e4d
  hostname: gpu048
  info:
    apply_time_ms: 2.956
    dispatch_time_ms: 5.776
    learner:
      cur_lr: 0.0013071196153759956
      grad_gnorm: 6.911282539367676
      policy_entropy: 2.9871678352355957
      policy_loss: 0.18893963098526
      var_gnorm: 30.72012710571289
      vf_explained_var: 0.0
      vf_loss: 0.6504780054092407
    num_steps_sampled: 796000
    num_steps_trained: 796000
    wait_time_ms: 33.167
  iterations_since_restore: 463
  node_ip: 172.17.8.48
  num_metric_batches_dropped: 0
  pid: 20453
  policy_reward_mean: {}
  time_since_restore: 3812.0871500968933
  time_this_iter_s: 8.427420377731323
  time_total_s: 3812.0871500968933
  timestamp: 1593997816
  timesteps_since_restore: 796000
  timesteps_this_iter: 2000
  timesteps_total: 796000
  training_iteration: 463
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=20453], 3812 s, 463 iter, 796000 ts, 130 rew

agent-1: 106.0
Sum Reward: 106.0
Avg Reward: 106.0
Min Reward: 106.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
agent-1: 123.0
Sum Reward: 123.0
Avg Reward: 123.0
Min Reward: 123.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_21-10-24
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 185.0
  episode_reward_mean: 129.38
  episode_reward_min: 77.0
  episodes_this_iter: 2
  episodes_total: 797
  experiment_id: 325b24caee6c4209bf8cf01af4f33e4d
  hostname: gpu048
  info:
    apply_time_ms: 3.264
    dispatch_time_ms: 6.389
    learner:
      cur_lr: 0.0013069864362478256
      grad_gnorm: 19.19318962097168
      policy_entropy: 2.5974817276000977
      policy_loss: -4.884243011474609
      var_gnorm: 30.71934700012207
      vf_explained_var: 0.0
      vf_loss: 1.4412851333618164
    num_steps_sampled: 798000
    num_steps_trained: 798000
    wait_time_ms: 31.476
  iterations_since_restore: 464
  node_ip: 172.17.8.48
  num_metric_batches_dropped: 0
  pid: 20453
  policy_reward_mean: {}
  time_since_restore: 3820.387838602066
  time_this_iter_s: 8.30068850517273
  time_total_s: 3820.387838602066
  timestamp: 1593997824
  timesteps_since_restore: 798000
  timesteps_this_iter: 2000
  timesteps_total: 798000
  training_iteration: 464
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=20453], 3820 s, 464 iter, 798000 ts, 129 rew

agent-1: 110.0
Sum Reward: 110.0
Avg Reward: 110.0
Min Reward: 110.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
agent-1: 100.0
Sum Reward: 100.0
Avg Reward: 100.0
Min Reward: 100.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_21-10-40
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 185.0
  episode_reward_mean: 128.15
  episode_reward_min: 77.0
  episodes_this_iter: 2
  episodes_total: 799
  experiment_id: 325b24caee6c4209bf8cf01af4f33e4d
  hostname: gpu048
  info:
    apply_time_ms: 3.999
    dispatch_time_ms: 16.551
    learner:
      cur_lr: 0.0013068532571196556
      grad_gnorm: 8.521653175354004
      policy_entropy: 3.0726096630096436
      policy_loss: -1.0603914260864258
      var_gnorm: 30.704212188720703
      vf_explained_var: 5.960464477539063e-08
      vf_loss: 0.787773609161377
    num_steps_sampled: 800000
    num_steps_trained: 800000
    wait_time_ms: 19.394
  iterations_since_restore: 465
  node_ip: 172.17.8.48
  num_metric_batches_dropped: 0
  pid: 20453
  policy_reward_mean: {}
  time_since_restore: 3836.347223520279
  time_this_iter_s: 15.95938491821289
  time_total_s: 3836.347223520279
  timestamp: 1593997840
  timesteps_since_restore: 800000
  timesteps_this_iter: 2000
  timesteps_total: 800000
  training_iteration: 465
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=20453], 3836 s, 465 iter, 800000 ts, 128 rew

agent-1: 83.0
Sum Reward: 83.0
Avg Reward: 83.0
Min Reward: 83.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
agent-1: 146.0
Sum Reward: 146.0
Avg Reward: 146.0
Min Reward: 146.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_21-10-49
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 185.0
  episode_reward_mean: 127.91
  episode_reward_min: 77.0
  episodes_this_iter: 2
  episodes_total: 801
  experiment_id: 325b24caee6c4209bf8cf01af4f33e4d
  hostname: gpu048
  info:
    apply_time_ms: 2.7
    dispatch_time_ms: 14.007
    learner:
      cur_lr: 0.0013067199615761638
      grad_gnorm: 39.99999237060547
      policy_entropy: 4.516759395599365
      policy_loss: 8.69479751586914
      var_gnorm: 30.707563400268555
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 30.1567325592041
    num_steps_sampled: 802000
    num_steps_trained: 802000
    wait_time_ms: 29.308
  iterations_since_restore: 466
  node_ip: 172.17.8.48
  num_metric_batches_dropped: 0
  pid: 20453
  policy_reward_mean: {}
  time_since_restore: 3845.104989528656
  time_this_iter_s: 8.757766008377075
  time_total_s: 3845.104989528656
  timestamp: 1593997849
  timesteps_since_restore: 802000
  timesteps_this_iter: 2000
  timesteps_total: 802000
  training_iteration: 466
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=20453], 3845 s, 466 iter, 802000 ts, 128 rew

agent-1: 85.0
Sum Reward: 85.0
Avg Reward: 85.0
Min Reward: 85.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
agent-1: 149.0
Sum Reward: 149.0
Avg Reward: 149.0
Min Reward: 149.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
agent-1: 153.0
Sum Reward: 153.0
Avg Reward: 153.0
Min Reward: 153.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_21-10-59
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 185.0
  episode_reward_mean: 128.58
  episode_reward_min: 77.0
  episodes_this_iter: 3
  episodes_total: 804
  experiment_id: 325b24caee6c4209bf8cf01af4f33e4d
  hostname: gpu048
  info:
    apply_time_ms: 2.79
    dispatch_time_ms: 29.755
    learner:
      cur_lr: 0.0013065867824479938
      grad_gnorm: 7.892366409301758
      policy_entropy: 2.558349370956421
      policy_loss: 0.45879626274108887
      var_gnorm: 30.726102828979492
      vf_explained_var: 0.0
      vf_loss: 0.9957854747772217
    num_steps_sampled: 804000
    num_steps_trained: 804000
    wait_time_ms: 24.749
  iterations_since_restore: 467
  node_ip: 172.17.8.48
  num_metric_batches_dropped: 0
  pid: 20453
  policy_reward_mean: {}
  time_since_restore: 3855.1598160266876
  time_this_iter_s: 10.054826498031616
  time_total_s: 3855.1598160266876
  timestamp: 1593997859
  timesteps_since_restore: 804000
  timesteps_this_iter: 2000
  timesteps_total: 804000
  training_iteration: 467
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=20453], 3855 s, 467 iter, 804000 ts, 129 rew

agent-1: 110.0
Sum Reward: 110.0
Avg Reward: 110.0
Min Reward: 110.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_21-11-08
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 185.0
  episode_reward_mean: 128.71
  episode_reward_min: 77.0
  episodes_this_iter: 1
  episodes_total: 805
  experiment_id: 325b24caee6c4209bf8cf01af4f33e4d
  hostname: gpu048
  info:
    apply_time_ms: 2.739
    dispatch_time_ms: 17.248
    learner:
      cur_lr: 0.0013064536033198237
      grad_gnorm: 17.89557456970215
      policy_entropy: 4.684240818023682
      policy_loss: -3.8173024654388428
      var_gnorm: 30.71953582763672
      vf_explained_var: 0.0
      vf_loss: 1.6772305965423584
    num_steps_sampled: 806000
    num_steps_trained: 806000
    wait_time_ms: 22.65
  iterations_since_restore: 468
  node_ip: 172.17.8.48
  num_metric_batches_dropped: 0
  pid: 20453
  policy_reward_mean: {}
  time_since_restore: 3863.936356782913
  time_this_iter_s: 8.776540756225586
  time_total_s: 3863.936356782913
  timestamp: 1593997868
  timesteps_since_restore: 806000
  timesteps_this_iter: 2000
  timesteps_total: 806000
  training_iteration: 468
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=20453], 3863 s, 468 iter, 806000 ts, 129 rew

agent-1: 97.0
Sum Reward: 97.0
Avg Reward: 97.0
Min Reward: 97.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
agent-1: 78.0
Sum Reward: 78.0
Avg Reward: 78.0
Min Reward: 78.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_21-11-17
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 185.0
  episode_reward_mean: 128.03
  episode_reward_min: 77.0
  episodes_this_iter: 2
  episodes_total: 807
  experiment_id: 325b24caee6c4209bf8cf01af4f33e4d
  hostname: gpu048
  info:
    apply_time_ms: 2.445
    dispatch_time_ms: 10.289
    learner:
      cur_lr: 0.0013063204241916537
      grad_gnorm: 16.420757293701172
      policy_entropy: 3.769174814224243
      policy_loss: -0.659146249294281
      var_gnorm: 30.7137451171875
      vf_explained_var: 0.0
      vf_loss: 1.5395087003707886
    num_steps_sampled: 808000
    num_steps_trained: 808000
    wait_time_ms: 29.732
  iterations_since_restore: 469
  node_ip: 172.17.8.48
  num_metric_batches_dropped: 0
  pid: 20453
  policy_reward_mean: {}
  time_since_restore: 3872.6653821468353
  time_this_iter_s: 8.72902536392212
  time_total_s: 3872.6653821468353
  timestamp: 1593997877
  timesteps_since_restore: 808000
  timesteps_this_iter: 2000
  timesteps_total: 808000
  training_iteration: 469
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=20453], 3872 s, 469 iter, 808000 ts, 128 rew

agent-1: 134.0
Sum Reward: 134.0
Avg Reward: 134.0
Min Reward: 134.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
agent-1: 141.0
Sum Reward: 141.0
Avg Reward: 141.0
Min Reward: 141.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_21-11-26
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 185.0
  episode_reward_mean: 128.03
  episode_reward_min: 77.0
  episodes_this_iter: 2
  episodes_total: 809
  experiment_id: 325b24caee6c4209bf8cf01af4f33e4d
  hostname: gpu048
  info:
    apply_time_ms: 3.905
    dispatch_time_ms: 38.099
    learner:
      cur_lr: 0.0013061872450634837
      grad_gnorm: 18.275245666503906
      policy_entropy: 4.543669700622559
      policy_loss: -1.059841275215149
      var_gnorm: 30.729461669921875
      vf_explained_var: 0.0
      vf_loss: 1.7539054155349731
    num_steps_sampled: 810000
    num_steps_trained: 810000
    wait_time_ms: 25.454
  iterations_since_restore: 470
  node_ip: 172.17.8.48
  num_metric_batches_dropped: 0
  pid: 20453
  policy_reward_mean: {}
  time_since_restore: 3881.873331785202
  time_this_iter_s: 9.2079496383667
  time_total_s: 3881.873331785202
  timestamp: 1593997886
  timesteps_since_restore: 810000
  timesteps_this_iter: 2000
  timesteps_total: 810000
  training_iteration: 470
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=20453], 3881 s, 470 iter, 810000 ts, 128 rew

agent-1: 150.0
Sum Reward: 150.0
Avg Reward: 150.0
Min Reward: 150.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_21-11-32
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 185.0
  episode_reward_mean: 127.77
  episode_reward_min: 77.0
  episodes_this_iter: 1
  episodes_total: 810
  experiment_id: 325b24caee6c4209bf8cf01af4f33e4d
  hostname: gpu048
  info:
    apply_time_ms: 2.657
    dispatch_time_ms: 33.305
    learner:
      cur_lr: 0.0013060539495199919
      grad_gnorm: 20.355623245239258
      policy_entropy: 3.3156747817993164
      policy_loss: -0.9226076602935791
      var_gnorm: 30.7430477142334
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 2.501398801803589
    num_steps_sampled: 811000
    num_steps_trained: 811000
    wait_time_ms: 23.975
  iterations_since_restore: 471
  node_ip: 172.17.8.48
  num_metric_batches_dropped: 0
  pid: 20453
  policy_reward_mean: {}
  time_since_restore: 3888.04829454422
  time_this_iter_s: 6.174962759017944
  time_total_s: 3888.04829454422
  timestamp: 1593997892
  timesteps_since_restore: 811000
  timesteps_this_iter: 1000
  timesteps_total: 811000
  training_iteration: 471
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=20453], 3888 s, 471 iter, 811000 ts, 128 rew

agent-1: 144.0
Sum Reward: 144.0
Avg Reward: 144.0
Min Reward: 144.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_21-11-38
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 185.0
  episode_reward_mean: 128.24
  episode_reward_min: 77.0
  episodes_this_iter: 1
  episodes_total: 811
  experiment_id: 325b24caee6c4209bf8cf01af4f33e4d
  hostname: gpu048
  info:
    apply_time_ms: 2.821
    dispatch_time_ms: 26.073
    learner:
      cur_lr: 0.0013059873599559069
      grad_gnorm: 36.36302947998047
      policy_entropy: 1.7720907926559448
      policy_loss: 4.312994003295898
      var_gnorm: 30.743669509887695
      vf_explained_var: 0.0
      vf_loss: 7.607412815093994
    num_steps_sampled: 812000
    num_steps_trained: 812000
    wait_time_ms: 11.256
  iterations_since_restore: 472
  node_ip: 172.17.8.48
  num_metric_batches_dropped: 0
  pid: 20453
  policy_reward_mean: {}
  time_since_restore: 3893.8734138011932
  time_this_iter_s: 5.825119256973267
  time_total_s: 3893.8734138011932
  timestamp: 1593997898
  timesteps_since_restore: 812000
  timesteps_this_iter: 1000
  timesteps_total: 812000
  training_iteration: 472
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=20453], 3893 s, 472 iter, 812000 ts, 128 rew

agent-1: 160.0
Sum Reward: 160.0
Avg Reward: 160.0
Min Reward: 160.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
agent-1: 142.0
Sum Reward: 142.0
Avg Reward: 142.0
Min Reward: 142.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_21-11-47
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 185.0
  episode_reward_mean: 128.7
  episode_reward_min: 77.0
  episodes_this_iter: 2
  episodes_total: 813
  experiment_id: 325b24caee6c4209bf8cf01af4f33e4d
  hostname: gpu048
  info:
    apply_time_ms: 3.554
    dispatch_time_ms: 35.443
    learner:
      cur_lr: 0.0013059207703918219
      grad_gnorm: 19.368270874023438
      policy_entropy: 3.230353593826294
      policy_loss: -1.6353662014007568
      var_gnorm: 30.734222412109375
      vf_explained_var: 0.0
      vf_loss: 2.3442749977111816
    num_steps_sampled: 814000
    num_steps_trained: 814000
    wait_time_ms: 15.923
  iterations_since_restore: 473
  node_ip: 172.17.8.48
  num_metric_batches_dropped: 0
  pid: 20453
  policy_reward_mean: {}
  time_since_restore: 3902.661643266678
  time_this_iter_s: 8.78822946548462
  time_total_s: 3902.661643266678
  timestamp: 1593997907
  timesteps_since_restore: 814000
  timesteps_this_iter: 2000
  timesteps_total: 814000
  training_iteration: 473
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=20453], 3902 s, 473 iter, 814000 ts, 129 rew

agent-1: 112.0
Sum Reward: 112.0
Avg Reward: 112.0
Min Reward: 112.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
agent-1: 109.0
Sum Reward: 109.0
Avg Reward: 109.0
Min Reward: 109.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_21-11-56
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 185.0
  episode_reward_mean: 128.27
  episode_reward_min: 77.0
  episodes_this_iter: 2
  episodes_total: 815
  experiment_id: 325b24caee6c4209bf8cf01af4f33e4d
  hostname: gpu048
  info:
    apply_time_ms: 4.755
    dispatch_time_ms: 23.537
    learner:
      cur_lr: 0.0013057875912636518
      grad_gnorm: 17.18031120300293
      policy_entropy: 2.419396162033081
      policy_loss: -0.3510744273662567
      var_gnorm: 30.72287940979004
      vf_explained_var: 0.0
      vf_loss: 1.8078632354736328
    num_steps_sampled: 816000
    num_steps_trained: 816000
    wait_time_ms: 20.095
  iterations_since_restore: 474
  node_ip: 172.17.8.48
  num_metric_batches_dropped: 0
  pid: 20453
  policy_reward_mean: {}
  time_since_restore: 3911.2664079666138
  time_this_iter_s: 8.604764699935913
  time_total_s: 3911.2664079666138
  timestamp: 1593997916
  timesteps_since_restore: 816000
  timesteps_this_iter: 2000
  timesteps_total: 816000
  training_iteration: 474
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=20453], 3911 s, 474 iter, 816000 ts, 128 rew

agent-1: 87.0
Sum Reward: 87.0
Avg Reward: 87.0
Min Reward: 87.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
agent-1: 126.0
Sum Reward: 126.0
Avg Reward: 126.0
Min Reward: 126.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_21-12-05
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 185.0
  episode_reward_mean: 127.77
  episode_reward_min: 77.0
  episodes_this_iter: 2
  episodes_total: 817
  experiment_id: 325b24caee6c4209bf8cf01af4f33e4d
  hostname: gpu048
  info:
    apply_time_ms: 3.269
    dispatch_time_ms: 23.404
    learner:
      cur_lr: 0.0013056544121354818
      grad_gnorm: 13.522234916687012
      policy_entropy: 3.893599033355713
      policy_loss: -0.01789705455303192
      var_gnorm: 30.711030960083008
      vf_explained_var: 1.1920928955078125e-07
      vf_loss: 5.694239139556885
    num_steps_sampled: 818000
    num_steps_trained: 818000
    wait_time_ms: 15.211
  iterations_since_restore: 475
  node_ip: 172.17.8.48
  num_metric_batches_dropped: 0
  pid: 20453
  policy_reward_mean: {}
  time_since_restore: 3920.3244676589966
  time_this_iter_s: 9.058059692382812
  time_total_s: 3920.3244676589966
  timestamp: 1593997925
  timesteps_since_restore: 818000
  timesteps_this_iter: 2000
  timesteps_total: 818000
  training_iteration: 475
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=20453], 3920 s, 475 iter, 818000 ts, 128 rew

agent-1: 92.0
Sum Reward: 92.0
Avg Reward: 92.0
Min Reward: 92.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
agent-1: 137.0
Sum Reward: 137.0
Avg Reward: 137.0
Min Reward: 137.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_21-12-14
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 185.0
  episode_reward_mean: 127.76
  episode_reward_min: 77.0
  episodes_this_iter: 2
  episodes_total: 819
  experiment_id: 325b24caee6c4209bf8cf01af4f33e4d
  hostname: gpu048
  info:
    apply_time_ms: 2.628
    dispatch_time_ms: 40.67
    learner:
      cur_lr: 0.0013055212330073118
      grad_gnorm: 17.44550323486328
      policy_entropy: 2.7263712882995605
      policy_loss: -3.675339460372925
      var_gnorm: 30.73235511779785
      vf_explained_var: 0.0
      vf_loss: 1.6362067461013794
    num_steps_sampled: 820000
    num_steps_trained: 820000
    wait_time_ms: 24.881
  iterations_since_restore: 476
  node_ip: 172.17.8.48
  num_metric_batches_dropped: 0
  pid: 20453
  policy_reward_mean: {}
  time_since_restore: 3929.5363590717316
  time_this_iter_s: 9.211891412734985
  time_total_s: 3929.5363590717316
  timestamp: 1593997934
  timesteps_since_restore: 820000
  timesteps_this_iter: 2000
  timesteps_total: 820000
  training_iteration: 476
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=20453], 3929 s, 476 iter, 820000 ts, 128 rew

agent-1: 125.0
Sum Reward: 125.0
Avg Reward: 125.0
Min Reward: 125.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_21-12-20
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 185.0
  episode_reward_mean: 127.62
  episode_reward_min: 77.0
  episodes_this_iter: 1
  episodes_total: 820
  experiment_id: 325b24caee6c4209bf8cf01af4f33e4d
  hostname: gpu048
  info:
    apply_time_ms: 4.584
    dispatch_time_ms: 42.711
    learner:
      cur_lr: 0.0013053880538791418
      grad_gnorm: 8.934168815612793
      policy_entropy: 4.221481800079346
      policy_loss: 1.7377147674560547
      var_gnorm: 30.727764129638672
      vf_explained_var: 0.0
      vf_loss: 0.816221296787262
    num_steps_sampled: 821000
    num_steps_trained: 821000
    wait_time_ms: 18.389
  iterations_since_restore: 477
  node_ip: 172.17.8.48
  num_metric_batches_dropped: 0
  pid: 20453
  policy_reward_mean: {}
  time_since_restore: 3935.504242658615
  time_this_iter_s: 5.967883586883545
  time_total_s: 3935.504242658615
  timestamp: 1593997940
  timesteps_since_restore: 821000
  timesteps_this_iter: 1000
  timesteps_total: 821000
  training_iteration: 477
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=20453], 3935 s, 477 iter, 821000 ts, 128 rew

agent-1: 155.0
Sum Reward: 155.0
Avg Reward: 155.0
Min Reward: 155.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
agent-1: 132.0
Sum Reward: 132.0
Avg Reward: 132.0
Min Reward: 132.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_21-12-28
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 185.0
  episode_reward_mean: 127.97
  episode_reward_min: 77.0
  episodes_this_iter: 2
  episodes_total: 822
  experiment_id: 325b24caee6c4209bf8cf01af4f33e4d
  hostname: gpu048
  info:
    apply_time_ms: 2.921
    dispatch_time_ms: 8.893
    learner:
      cur_lr: 0.001305321347899735
      grad_gnorm: 19.768739700317383
      policy_entropy: 5.113786697387695
      policy_loss: -1.2767133712768555
      var_gnorm: 30.731403350830078
      vf_explained_var: 0.0
      vf_loss: 1.8548065423965454
    num_steps_sampled: 823000
    num_steps_trained: 823000
    wait_time_ms: 29.88
  iterations_since_restore: 478
  node_ip: 172.17.8.48
  num_metric_batches_dropped: 0
  pid: 20453
  policy_reward_mean: {}
  time_since_restore: 3943.8093841075897
  time_this_iter_s: 8.30514144897461
  time_total_s: 3943.8093841075897
  timestamp: 1593997948
  timesteps_since_restore: 823000
  timesteps_this_iter: 2000
  timesteps_total: 823000
  training_iteration: 478
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=20453], 3943 s, 478 iter, 823000 ts, 128 rew

agent-1: 121.0
Sum Reward: 121.0
Avg Reward: 121.0
Min Reward: 121.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
agent-1: 124.0
Sum Reward: 124.0
Avg Reward: 124.0
Min Reward: 124.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_21-12-37
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 185.0
  episode_reward_mean: 127.62
  episode_reward_min: 77.0
  episodes_this_iter: 2
  episodes_total: 824
  experiment_id: 325b24caee6c4209bf8cf01af4f33e4d
  hostname: gpu048
  info:
    apply_time_ms: 3.817
    dispatch_time_ms: 9.1
    learner:
      cur_lr: 0.001305188168771565
      grad_gnorm: 18.46315574645996
      policy_entropy: 2.519080400466919
      policy_loss: -1.276220440864563
      var_gnorm: 30.746047973632812
      vf_explained_var: 0.0
      vf_loss: 2.1868085861206055
    num_steps_sampled: 825000
    num_steps_trained: 825000
    wait_time_ms: 29.713
  iterations_since_restore: 479
  node_ip: 172.17.8.48
  num_metric_batches_dropped: 0
  pid: 20453
  policy_reward_mean: {}
  time_since_restore: 3952.2075412273407
  time_this_iter_s: 8.398157119750977
  time_total_s: 3952.2075412273407
  timestamp: 1593997957
  timesteps_since_restore: 825000
  timesteps_this_iter: 2000
  timesteps_total: 825000
  training_iteration: 479
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=20453], 3952 s, 479 iter, 825000 ts, 128 rew

agent-1: 126.0
Sum Reward: 126.0
Avg Reward: 126.0
Min Reward: 126.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
agent-1: 116.0
Sum Reward: 116.0
Avg Reward: 116.0
Min Reward: 116.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_21-12-45
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 185.0
  episode_reward_mean: 127.48
  episode_reward_min: 77.0
  episodes_this_iter: 2
  episodes_total: 826
  experiment_id: 325b24caee6c4209bf8cf01af4f33e4d
  hostname: gpu048
  info:
    apply_time_ms: 3.723
    dispatch_time_ms: 9.689
    learner:
      cur_lr: 0.001305054989643395
      grad_gnorm: 8.796469688415527
      policy_entropy: 4.061244010925293
      policy_loss: 0.00482487678527832
      var_gnorm: 30.736722946166992
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 0.6953403949737549
    num_steps_sampled: 827000
    num_steps_trained: 827000
    wait_time_ms: 29.962
  iterations_since_restore: 480
  node_ip: 172.17.8.48
  num_metric_batches_dropped: 0
  pid: 20453
  policy_reward_mean: {}
  time_since_restore: 3960.4806752204895
  time_this_iter_s: 8.273133993148804
  time_total_s: 3960.4806752204895
  timestamp: 1593997965
  timesteps_since_restore: 827000
  timesteps_this_iter: 2000
  timesteps_total: 827000
  training_iteration: 480
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=20453], 3960 s, 480 iter, 827000 ts, 127 rew

agent-1: 130.0
Sum Reward: 130.0
Avg Reward: 130.0
Min Reward: 130.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
agent-1: 110.0
Sum Reward: 110.0
Avg Reward: 110.0
Min Reward: 110.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_21-12-53
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 185.0
  episode_reward_mean: 127.51
  episode_reward_min: 77.0
  episodes_this_iter: 2
  episodes_total: 828
  experiment_id: 325b24caee6c4209bf8cf01af4f33e4d
  hostname: gpu048
  info:
    apply_time_ms: 4.921
    dispatch_time_ms: 7.306
    learner:
      cur_lr: 0.001304921810515225
      grad_gnorm: 5.662631988525391
      policy_entropy: 3.857595682144165
      policy_loss: 0.8814254403114319
      var_gnorm: 30.73164176940918
      vf_explained_var: 0.0
      vf_loss: 0.5863487720489502
    num_steps_sampled: 829000
    num_steps_trained: 829000
    wait_time_ms: 30.772
  iterations_since_restore: 481
  node_ip: 172.17.8.48
  num_metric_batches_dropped: 0
  pid: 20453
  policy_reward_mean: {}
  time_since_restore: 3968.7928738594055
  time_this_iter_s: 8.312198638916016
  time_total_s: 3968.7928738594055
  timestamp: 1593997973
  timesteps_since_restore: 829000
  timesteps_this_iter: 2000
  timesteps_total: 829000
  training_iteration: 481
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=20453], 3968 s, 481 iter, 829000 ts, 128 rew

agent-1: 117.0
Sum Reward: 117.0
Avg Reward: 117.0
Min Reward: 117.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
agent-1: 124.0
Sum Reward: 124.0
Avg Reward: 124.0
Min Reward: 124.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_21-13-02
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 185.0
  episode_reward_mean: 127.37
  episode_reward_min: 77.0
  episodes_this_iter: 2
  episodes_total: 830
  experiment_id: 325b24caee6c4209bf8cf01af4f33e4d
  hostname: gpu048
  info:
    apply_time_ms: 3.972
    dispatch_time_ms: 10.883
    learner:
      cur_lr: 0.001304788631387055
      grad_gnorm: 18.06800079345703
      policy_entropy: 3.8860044479370117
      policy_loss: -0.7579010128974915
      var_gnorm: 30.741741180419922
      vf_explained_var: 0.0
      vf_loss: 1.8442373275756836
    num_steps_sampled: 831000
    num_steps_trained: 831000
    wait_time_ms: 30.745
  iterations_since_restore: 482
  node_ip: 172.17.8.48
  num_metric_batches_dropped: 0
  pid: 20453
  policy_reward_mean: {}
  time_since_restore: 3977.111156463623
  time_this_iter_s: 8.31828260421753
  time_total_s: 3977.111156463623
  timestamp: 1593997982
  timesteps_since_restore: 831000
  timesteps_this_iter: 2000
  timesteps_total: 831000
  training_iteration: 482
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=20453], 3977 s, 482 iter, 831000 ts, 127 rew

agent-1: 135.0
Sum Reward: 135.0
Avg Reward: 135.0
Min Reward: 135.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
agent-1: 116.0
Sum Reward: 116.0
Avg Reward: 116.0
Min Reward: 116.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_21-13-10
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 185.0
  episode_reward_mean: 127.49
  episode_reward_min: 77.0
  episodes_this_iter: 2
  episodes_total: 832
  experiment_id: 325b24caee6c4209bf8cf01af4f33e4d
  hostname: gpu048
  info:
    apply_time_ms: 3.233
    dispatch_time_ms: 9.046
    learner:
      cur_lr: 0.001304655452258885
      grad_gnorm: 17.680971145629883
      policy_entropy: 2.6927649974823
      policy_loss: -2.6569552421569824
      var_gnorm: 30.745378494262695
      vf_explained_var: 0.0
      vf_loss: 1.899208903312683
    num_steps_sampled: 833000
    num_steps_trained: 833000
    wait_time_ms: 27.813
  iterations_since_restore: 483
  node_ip: 172.17.8.48
  num_metric_batches_dropped: 0
  pid: 20453
  policy_reward_mean: {}
  time_since_restore: 3985.4230151176453
  time_this_iter_s: 8.311858654022217
  time_total_s: 3985.4230151176453
  timestamp: 1593997990
  timesteps_since_restore: 833000
  timesteps_this_iter: 2000
  timesteps_total: 833000
  training_iteration: 483
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=20453], 3985 s, 483 iter, 833000 ts, 127 rew

agent-1: 137.0
Sum Reward: 137.0
Avg Reward: 137.0
Min Reward: 137.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_21-13-22
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 185.0
  episode_reward_mean: 127.32
  episode_reward_min: 77.0
  episodes_this_iter: 1
  episodes_total: 833
  experiment_id: 325b24caee6c4209bf8cf01af4f33e4d
  hostname: gpu048
  info:
    apply_time_ms: 2.677
    dispatch_time_ms: 797.954
    learner:
      cur_lr: 0.001304522156715393
      grad_gnorm: 40.0
      policy_entropy: 2.3628199100494385
      policy_loss: 9.402364730834961
      var_gnorm: 30.733684539794922
      vf_explained_var: 0.0
      vf_loss: 37.584354400634766
    num_steps_sampled: 834000
    num_steps_trained: 834000
    wait_time_ms: 34.091
  iterations_since_restore: 484
  node_ip: 172.17.8.48
  num_metric_batches_dropped: 0
  pid: 20453
  policy_reward_mean: {}
  time_since_restore: 3997.547420024872
  time_this_iter_s: 12.124404907226562
  time_total_s: 3997.547420024872
  timestamp: 1593998002
  timesteps_since_restore: 834000
  timesteps_this_iter: 1000
  timesteps_total: 834000
  training_iteration: 484
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=20453], 3997 s, 484 iter, 834000 ts, 127 rew

agent-1: 81.0
Sum Reward: 81.0
Avg Reward: 81.0
Min Reward: 81.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_21-13-28
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 185.0
  episode_reward_mean: 126.74
  episode_reward_min: 77.0
  episodes_this_iter: 1
  episodes_total: 834
  experiment_id: 325b24caee6c4209bf8cf01af4f33e4d
  hostname: gpu048
  info:
    apply_time_ms: 3.846
    dispatch_time_ms: 36.816
    learner:
      cur_lr: 0.001304455567151308
      grad_gnorm: 40.0
      policy_entropy: 1.992028832435608
      policy_loss: 0.7955023050308228
      var_gnorm: 30.73530387878418
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 18.09221839904785
    num_steps_sampled: 835000
    num_steps_trained: 835000
    wait_time_ms: 21.762
  iterations_since_restore: 485
  node_ip: 172.17.8.48
  num_metric_batches_dropped: 0
  pid: 20453
  policy_reward_mean: {}
  time_since_restore: 4003.563952445984
  time_this_iter_s: 6.0165324211120605
  time_total_s: 4003.563952445984
  timestamp: 1593998008
  timesteps_since_restore: 835000
  timesteps_this_iter: 1000
  timesteps_total: 835000
  training_iteration: 485
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=20453], 4003 s, 485 iter, 835000 ts, 127 rew

agent-1: 98.0
Sum Reward: 98.0
Avg Reward: 98.0
Min Reward: 98.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_21-13-34
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 185.0
  episode_reward_mean: 126.38
  episode_reward_min: 77.0
  episodes_this_iter: 1
  episodes_total: 835
  experiment_id: 325b24caee6c4209bf8cf01af4f33e4d
  hostname: gpu048
  info:
    apply_time_ms: 4.584
    dispatch_time_ms: 30.488
    learner:
      cur_lr: 0.001304388977587223
      grad_gnorm: 40.0
      policy_entropy: 2.382591724395752
      policy_loss: 1.1233906745910645
      var_gnorm: 30.723487854003906
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 20.20046615600586
    num_steps_sampled: 836000
    num_steps_trained: 836000
    wait_time_ms: 17.975
  iterations_since_restore: 486
  node_ip: 172.17.8.48
  num_metric_batches_dropped: 0
  pid: 20453
  policy_reward_mean: {}
  time_since_restore: 4009.21586894989
  time_this_iter_s: 5.65191650390625
  time_total_s: 4009.21586894989
  timestamp: 1593998014
  timesteps_since_restore: 836000
  timesteps_this_iter: 1000
  timesteps_total: 836000
  training_iteration: 486
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=20453], 4009 s, 486 iter, 836000 ts, 126 rew

agent-1: 84.0
Sum Reward: 84.0
Avg Reward: 84.0
Min Reward: 84.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_21-13-40
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 185.0
  episode_reward_mean: 126.01
  episode_reward_min: 77.0
  episodes_this_iter: 1
  episodes_total: 836
  experiment_id: 325b24caee6c4209bf8cf01af4f33e4d
  hostname: gpu048
  info:
    apply_time_ms: 3.536
    dispatch_time_ms: 37.706
    learner:
      cur_lr: 0.001304322388023138
      grad_gnorm: 7.751867294311523
      policy_entropy: 5.041738510131836
      policy_loss: -2.428554058074951
      var_gnorm: 30.719898223876953
      vf_explained_var: 0.0
      vf_loss: 0.5219512581825256
    num_steps_sampled: 837000
    num_steps_trained: 837000
    wait_time_ms: 27.85
  iterations_since_restore: 487
  node_ip: 172.17.8.48
  num_metric_batches_dropped: 0
  pid: 20453
  policy_reward_mean: {}
  time_since_restore: 4015.3534083366394
  time_this_iter_s: 6.137539386749268
  time_total_s: 4015.3534083366394
  timestamp: 1593998020
  timesteps_since_restore: 837000
  timesteps_this_iter: 1000
  timesteps_total: 837000
  training_iteration: 487
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=20453], 4015 s, 487 iter, 837000 ts, 126 rew

agent-1: 74.0
Sum Reward: 74.0
Avg Reward: 74.0
Min Reward: 74.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_21-13-46
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 185.0
  episode_reward_mean: 125.71
  episode_reward_min: 74.0
  episodes_this_iter: 1
  episodes_total: 837
  experiment_id: 325b24caee6c4209bf8cf01af4f33e4d
  hostname: gpu048
  info:
    apply_time_ms: 3.126
    dispatch_time_ms: 34.91
    learner:
      cur_lr: 0.001304255798459053
      grad_gnorm: 9.733123779296875
      policy_entropy: 1.3912022113800049
      policy_loss: -0.12969312071800232
      var_gnorm: 30.721515655517578
      vf_explained_var: 0.0
      vf_loss: 0.694103479385376
    num_steps_sampled: 838000
    num_steps_trained: 838000
    wait_time_ms: 12.593
  iterations_since_restore: 488
  node_ip: 172.17.8.48
  num_metric_batches_dropped: 0
  pid: 20453
  policy_reward_mean: {}
  time_since_restore: 4021.000964641571
  time_this_iter_s: 5.647556304931641
  time_total_s: 4021.000964641571
  timestamp: 1593998026
  timesteps_since_restore: 838000
  timesteps_this_iter: 1000
  timesteps_total: 838000
  training_iteration: 488
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=20453], 4021 s, 488 iter, 838000 ts, 126 rew

agent-1: 74.0
Sum Reward: 74.0
Avg Reward: 74.0
Min Reward: 74.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_21-13-51
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 185.0
  episode_reward_mean: 125.13
  episode_reward_min: 74.0
  episodes_this_iter: 1
  episodes_total: 838
  experiment_id: 325b24caee6c4209bf8cf01af4f33e4d
  hostname: gpu048
  info:
    apply_time_ms: 3.519
    dispatch_time_ms: 38.986
    learner:
      cur_lr: 0.001304189208894968
      grad_gnorm: 8.85019302368164
      policy_entropy: 4.721240520477295
      policy_loss: 2.2614095211029053
      var_gnorm: 30.72359275817871
      vf_explained_var: 0.0
      vf_loss: 3.1326143741607666
    num_steps_sampled: 839000
    num_steps_trained: 839000
    wait_time_ms: 11.657
  iterations_since_restore: 489
  node_ip: 172.17.8.48
  num_metric_batches_dropped: 0
  pid: 20453
  policy_reward_mean: {}
  time_since_restore: 4026.580693244934
  time_this_iter_s: 5.579728603363037
  time_total_s: 4026.580693244934
  timestamp: 1593998031
  timesteps_since_restore: 839000
  timesteps_this_iter: 1000
  timesteps_total: 839000
  training_iteration: 489
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=20453], 4026 s, 489 iter, 839000 ts, 125 rew

agent-1: 130.0
Sum Reward: 130.0
Avg Reward: 130.0
Min Reward: 130.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_21-13-58
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 185.0
  episode_reward_mean: 124.92
  episode_reward_min: 74.0
  episodes_this_iter: 1
  episodes_total: 839
  experiment_id: 325b24caee6c4209bf8cf01af4f33e4d
  hostname: gpu048
  info:
    apply_time_ms: 3.343
    dispatch_time_ms: 45.895
    learner:
      cur_lr: 0.001304122619330883
      grad_gnorm: 6.56791877746582
      policy_entropy: 2.388925790786743
      policy_loss: 1.6497611999511719
      var_gnorm: 30.74665069580078
      vf_explained_var: 0.0
      vf_loss: 0.7191141843795776
    num_steps_sampled: 840000
    num_steps_trained: 840000
    wait_time_ms: 20.828
  iterations_since_restore: 490
  node_ip: 172.17.8.48
  num_metric_batches_dropped: 0
  pid: 20453
  policy_reward_mean: {}
  time_since_restore: 4032.594514608383
  time_this_iter_s: 6.013821363449097
  time_total_s: 4032.594514608383
  timestamp: 1593998038
  timesteps_since_restore: 840000
  timesteps_this_iter: 1000
  timesteps_total: 840000
  training_iteration: 490
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=20453], 4032 s, 490 iter, 840000 ts, 125 rew

agent-1: 155.0
Sum Reward: 155.0
Avg Reward: 155.0
Min Reward: 155.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_21-14-04
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 185.0
  episode_reward_mean: 125.43
  episode_reward_min: 74.0
  episodes_this_iter: 1
  episodes_total: 840
  experiment_id: 325b24caee6c4209bf8cf01af4f33e4d
  hostname: gpu048
  info:
    apply_time_ms: 3.376
    dispatch_time_ms: 39.368
    learner:
      cur_lr: 0.001304056029766798
      grad_gnorm: 40.000003814697266
      policy_entropy: 3.3952560424804688
      policy_loss: 1.9125412702560425
      var_gnorm: 30.751358032226562
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 10.133024215698242
    num_steps_sampled: 841000
    num_steps_trained: 841000
    wait_time_ms: 21.116
  iterations_since_restore: 491
  node_ip: 172.17.8.48
  num_metric_batches_dropped: 0
  pid: 20453
  policy_reward_mean: {}
  time_since_restore: 4038.7355110645294
  time_this_iter_s: 6.14099645614624
  time_total_s: 4038.7355110645294
  timestamp: 1593998044
  timesteps_since_restore: 841000
  timesteps_this_iter: 1000
  timesteps_total: 841000
  training_iteration: 491
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=20453], 4038 s, 491 iter, 841000 ts, 125 rew

agent-1: 161.0
Sum Reward: 161.0
Avg Reward: 161.0
Min Reward: 161.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_21-14-10
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 185.0
  episode_reward_mean: 125.99
  episode_reward_min: 74.0
  episodes_this_iter: 1
  episodes_total: 841
  experiment_id: 325b24caee6c4209bf8cf01af4f33e4d
  hostname: gpu048
  info:
    apply_time_ms: 2.777
    dispatch_time_ms: 19.47
    learner:
      cur_lr: 0.001303989440202713
      grad_gnorm: 20.043779373168945
      policy_entropy: 5.592409133911133
      policy_loss: -1.5794882774353027
      var_gnorm: 30.7522029876709
      vf_explained_var: 0.0
      vf_loss: 1.6930123567581177
    num_steps_sampled: 842000
    num_steps_trained: 842000
    wait_time_ms: 24.398
  iterations_since_restore: 492
  node_ip: 172.17.8.48
  num_metric_batches_dropped: 0
  pid: 20453
  policy_reward_mean: {}
  time_since_restore: 4044.7472467422485
  time_this_iter_s: 6.011735677719116
  time_total_s: 4044.7472467422485
  timestamp: 1593998050
  timesteps_since_restore: 842000
  timesteps_this_iter: 1000
  timesteps_total: 842000
  training_iteration: 492
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=20453], 4044 s, 492 iter, 842000 ts, 126 rew

agent-1: 118.0
Sum Reward: 118.0
Avg Reward: 118.0
Min Reward: 118.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
agent-1: 127.0
Sum Reward: 127.0
Avg Reward: 127.0
Min Reward: 127.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_21-14-18
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 185.0
  episode_reward_mean: 125.78
  episode_reward_min: 74.0
  episodes_this_iter: 2
  episodes_total: 843
  experiment_id: 325b24caee6c4209bf8cf01af4f33e4d
  hostname: gpu048
  info:
    apply_time_ms: 3.361
    dispatch_time_ms: 6.986
    learner:
      cur_lr: 0.001303922850638628
      grad_gnorm: 1.4281796216964722
      policy_entropy: 1.7484099864959717
      policy_loss: -0.020602978765964508
      var_gnorm: 30.75279426574707
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 0.42756524682044983
    num_steps_sampled: 844000
    num_steps_trained: 844000
    wait_time_ms: 34.72
  iterations_since_restore: 493
  node_ip: 172.17.8.48
  num_metric_batches_dropped: 0
  pid: 20453
  policy_reward_mean: {}
  time_since_restore: 4053.0643668174744
  time_this_iter_s: 8.31712007522583
  time_total_s: 4053.0643668174744
  timestamp: 1593998058
  timesteps_since_restore: 844000
  timesteps_this_iter: 2000
  timesteps_total: 844000
  training_iteration: 493
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=20453], 4053 s, 493 iter, 844000 ts, 126 rew

agent-1: 90.0
Sum Reward: 90.0
Avg Reward: 90.0
Min Reward: 90.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
agent-1: 110.0
Sum Reward: 110.0
Avg Reward: 110.0
Min Reward: 110.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_21-14-26
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 185.0
  episode_reward_mean: 124.91
  episode_reward_min: 74.0
  episodes_this_iter: 2
  episodes_total: 845
  experiment_id: 325b24caee6c4209bf8cf01af4f33e4d
  hostname: gpu048
  info:
    apply_time_ms: 2.527
    dispatch_time_ms: 6.354
    learner:
      cur_lr: 0.0013037895550951362
      grad_gnorm: 18.21823501586914
      policy_entropy: 2.6116580963134766
      policy_loss: -2.3244035243988037
      var_gnorm: 30.76108741760254
      vf_explained_var: 0.0
      vf_loss: 2.0799050331115723
    num_steps_sampled: 846000
    num_steps_trained: 846000
    wait_time_ms: 31.282
  iterations_since_restore: 494
  node_ip: 172.17.8.48
  num_metric_batches_dropped: 0
  pid: 20453
  policy_reward_mean: {}
  time_since_restore: 4061.4635467529297
  time_this_iter_s: 8.399179935455322
  time_total_s: 4061.4635467529297
  timestamp: 1593998066
  timesteps_since_restore: 846000
  timesteps_this_iter: 2000
  timesteps_total: 846000
  training_iteration: 494
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=20453], 4061 s, 494 iter, 846000 ts, 125 rew

agent-1: 146.0
Sum Reward: 146.0
Avg Reward: 146.0
Min Reward: 146.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
agent-1: 112.0
Sum Reward: 112.0
Avg Reward: 112.0
Min Reward: 112.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_21-14-35
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 185.0
  episode_reward_mean: 124.64
  episode_reward_min: 74.0
  episodes_this_iter: 2
  episodes_total: 847
  experiment_id: 325b24caee6c4209bf8cf01af4f33e4d
  hostname: gpu048
  info:
    apply_time_ms: 3.783
    dispatch_time_ms: 7.718
    learner:
      cur_lr: 0.0013036563759669662
      grad_gnorm: 16.77458953857422
      policy_entropy: 4.1071457862854
      policy_loss: -0.7701348662376404
      var_gnorm: 30.746509552001953
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 1.549940824508667
    num_steps_sampled: 848000
    num_steps_trained: 848000
    wait_time_ms: 32.485
  iterations_since_restore: 495
  node_ip: 172.17.8.48
  num_metric_batches_dropped: 0
  pid: 20453
  policy_reward_mean: {}
  time_since_restore: 4069.7641870975494
  time_this_iter_s: 8.300640344619751
  time_total_s: 4069.7641870975494
  timestamp: 1593998075
  timesteps_since_restore: 848000
  timesteps_this_iter: 2000
  timesteps_total: 848000
  training_iteration: 495
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=20453], 4069 s, 495 iter, 848000 ts, 125 rew

agent-1: 94.0
Sum Reward: 94.0
Avg Reward: 94.0
Min Reward: 94.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
agent-1: 153.0
Sum Reward: 153.0
Avg Reward: 153.0
Min Reward: 153.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_21-14-47
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 185.0
  episode_reward_mean: 124.54
  episode_reward_min: 74.0
  episodes_this_iter: 2
  episodes_total: 849
  experiment_id: 325b24caee6c4209bf8cf01af4f33e4d
  hostname: gpu048
  info:
    apply_time_ms: 2.601
    dispatch_time_ms: 52.567
    learner:
      cur_lr: 0.0013035231968387961
      grad_gnorm: 22.707910537719727
      policy_entropy: 5.258517265319824
      policy_loss: -4.4379143714904785
      var_gnorm: 30.764575958251953
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 2.609426975250244
    num_steps_sampled: 850000
    num_steps_trained: 850000
    wait_time_ms: 38.807
  iterations_since_restore: 496
  node_ip: 172.17.8.48
  num_metric_batches_dropped: 0
  pid: 20453
  policy_reward_mean: {}
  time_since_restore: 4081.7003741264343
  time_this_iter_s: 11.936187028884888
  time_total_s: 4081.7003741264343
  timestamp: 1593998087
  timesteps_since_restore: 850000
  timesteps_this_iter: 2000
  timesteps_total: 850000
  training_iteration: 496
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=20453], 4081 s, 496 iter, 850000 ts, 125 rew

agent-1: 131.0
Sum Reward: 131.0
Avg Reward: 131.0
Min Reward: 131.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_21-14-54
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 185.0
  episode_reward_mean: 124.61
  episode_reward_min: 74.0
  episodes_this_iter: 1
  episodes_total: 850
  experiment_id: 325b24caee6c4209bf8cf01af4f33e4d
  hostname: gpu048
  info:
    apply_time_ms: 3.434
    dispatch_time_ms: 38.633
    learner:
      cur_lr: 0.0013033900177106261
      grad_gnorm: 38.40337371826172
      policy_entropy: 3.551909923553467
      policy_loss: 5.755194187164307
      var_gnorm: 30.76485252380371
      vf_explained_var: 0.0
      vf_loss: 10.213203430175781
    num_steps_sampled: 851000
    num_steps_trained: 851000
    wait_time_ms: 24.246
  iterations_since_restore: 497
  node_ip: 172.17.8.48
  num_metric_batches_dropped: 0
  pid: 20453
  policy_reward_mean: {}
  time_since_restore: 4088.7100598812103
  time_this_iter_s: 7.009685754776001
  time_total_s: 4088.7100598812103
  timestamp: 1593998094
  timesteps_since_restore: 851000
  timesteps_this_iter: 1000
  timesteps_total: 851000
  training_iteration: 497
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=20453], 4088 s, 497 iter, 851000 ts, 125 rew

agent-1: 146.0
Sum Reward: 146.0
Avg Reward: 146.0
Min Reward: 146.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_21-15-01
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 185.0
  episode_reward_mean: 124.71
  episode_reward_min: 74.0
  episodes_this_iter: 1
  episodes_total: 851
  experiment_id: 325b24caee6c4209bf8cf01af4f33e4d
  hostname: gpu048
  info:
    apply_time_ms: 3.564
    dispatch_time_ms: 55.736
    learner:
      cur_lr: 0.0013033234281465411
      grad_gnorm: 10.718513488769531
      policy_entropy: 4.9072675704956055
      policy_loss: -2.7520089149475098
      var_gnorm: 30.769384384155273
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 0.8940834403038025
    num_steps_sampled: 852000
    num_steps_trained: 852000
    wait_time_ms: 20.016
  iterations_since_restore: 498
  node_ip: 172.17.8.48
  num_metric_batches_dropped: 0
  pid: 20453
  policy_reward_mean: {}
  time_since_restore: 4096.2287929058075
  time_this_iter_s: 7.518733024597168
  time_total_s: 4096.2287929058075
  timestamp: 1593998101
  timesteps_since_restore: 852000
  timesteps_this_iter: 1000
  timesteps_total: 852000
  training_iteration: 498
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=20453], 4096 s, 498 iter, 852000 ts, 125 rew

agent-1: 154.0
Sum Reward: 154.0
Avg Reward: 154.0
Min Reward: 154.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_21-15-07
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 185.0
  episode_reward_mean: 124.86
  episode_reward_min: 74.0
  episodes_this_iter: 1
  episodes_total: 852
  experiment_id: 325b24caee6c4209bf8cf01af4f33e4d
  hostname: gpu048
  info:
    apply_time_ms: 3.178
    dispatch_time_ms: 26.869
    learner:
      cur_lr: 0.0013032568385824561
      grad_gnorm: 1.8276548385620117
      policy_entropy: 3.6291799545288086
      policy_loss: -0.8516462445259094
      var_gnorm: 30.771255493164062
      vf_explained_var: 0.0
      vf_loss: 0.36989259719848633
    num_steps_sampled: 853000
    num_steps_trained: 853000
    wait_time_ms: 13.725
  iterations_since_restore: 499
  node_ip: 172.17.8.48
  num_metric_batches_dropped: 0
  pid: 20453
  policy_reward_mean: {}
  time_since_restore: 4102.055939912796
  time_this_iter_s: 5.827147006988525
  time_total_s: 4102.055939912796
  timestamp: 1593998107
  timesteps_since_restore: 853000
  timesteps_this_iter: 1000
  timesteps_total: 853000
  training_iteration: 499
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=20453], 4102 s, 499 iter, 853000 ts, 125 rew

agent-1: 154.0
Sum Reward: 154.0
Avg Reward: 154.0
Min Reward: 154.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
agent-1: 115.0
Sum Reward: 115.0
Avg Reward: 115.0
Min Reward: 115.0
Gini Coefficient: 0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_21-15-16
  done: true
  episode_len_mean: 1000.0
  episode_reward_max: 185.0
  episode_reward_mean: 125.72
  episode_reward_min: 74.0
  episodes_this_iter: 2
  episodes_total: 854
  experiment_id: 325b24caee6c4209bf8cf01af4f33e4d
  hostname: gpu048
  info:
    apply_time_ms: 3.353
    dispatch_time_ms: 11.223
    learner:
      cur_lr: 0.001303190249018371
      grad_gnorm: 16.267202377319336
      policy_entropy: 5.023865222930908
      policy_loss: 0.9909590482711792
      var_gnorm: 30.778240203857422
      vf_explained_var: 0.0
      vf_loss: 6.801610469818115
    num_steps_sampled: 855000
    num_steps_trained: 855000
    wait_time_ms: 27.665
  iterations_since_restore: 500
  node_ip: 172.17.8.48
  num_metric_batches_dropped: 0
  pid: 20453
  policy_reward_mean: {}
  time_since_restore: 4110.582853794098
  time_this_iter_s: 8.52691388130188
  time_total_s: 4110.582853794098
  timestamp: 1593998116
  timesteps_since_restore: 855000
  timesteps_this_iter: 2000
  timesteps_total: 855000
  training_iteration: 500
  
/h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/numpy/core/fromnumeric.py:3335: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/numpy/core/_methods.py:161: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)
[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.[0m
W0705 21:15:18.653180 20448 client_connection.cc:255] [worker]ProcessMessage with type 7 took 632 ms.
W0705 21:15:18.668176 20448 node_manager.cc:250] Last heartbeat was sent 684 ms ago 
W0705 21:15:18.844907 20448 client_connection.cc:255] [worker]ProcessMessage with type 7 took 161 ms.
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 0.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
TERMINATED trials:
 - A3C_harvest_env_0:	TERMINATED [pid=20453], 4110 s, 500 iter, 855000 ts, 126 rew

== Status ==
Using FIFO scheduling algorithm.
Resources requested: 0.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
TERMINATED trials:
 - A3C_harvest_env_0:	TERMINATED [pid=20453], 4110 s, 500 iter, 855000 ts, 126 rew

Commencing experiment harvest_A3C
WARNING: Logging before InitGoogleLogging() is written to STDERR
E0705 21:15:20.081485 20477 raylet_client.cc:345] IOError: [RayletClient] Connection closed unexpectedly. [RayletClient] Failed to push profile events.
WARNING: Logging before InitGoogleLogging() is written to STDERR
E0705 21:15:20.348847 20479 raylet_client.cc:345] IOError: [RayletClient] Connection closed unexpectedly. [RayletClient] Failed to push profile events.
W0705 21:15:21.950599 20448 node_manager.cc:250] Last heartbeat was sent 1431 ms ago 
