/h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:523: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint8 = np.dtype([("qint8", np.int8, 1)])
/h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:524: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint8 = np.dtype([("quint8", np.uint8, 1)])
/h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint16 = np.dtype([("qint16", np.int16, 1)])
/h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint16 = np.dtype([("quint16", np.uint16, 1)])
/h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint32 = np.dtype([("qint32", np.int32, 1)])
/h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:532: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  np_resource = np.dtype([("resource", np.ubyte, 1)])
Process STDOUT and STDERR is being redirected to /tmp/ray/session_2020-07-07_00-05-39_13475/logs.
Waiting for redis server at 127.0.0.1:63957 to respond...
Waiting for redis server at 127.0.0.1:58630 to respond...
Warning: Capping object memory store to 20.0GB. To increase this further, specify `object_store_memory` when calling ray.init() or ray start.
Starting the Plasma object store with 20.0 GB memory using /dev/shm.

======================================================================
View the web UI at http://localhost:8888/notebooks/ray_ui.ipynb?token=db424f381ec83201ccd87771081529b4c4788986462b4a82
======================================================================

== Status ==
Using FIFO scheduling algorithm.
Resources requested: 0/2 CPUs, 0/1 GPUs
Memory usage on this node: 9.2/202.5 GB

Created LogSyncer for /h/zhaostep/ray_results/harvest_A3C/A3C_harvest_env_0_2020-07-07_00-05-40knjqq3dh -> 
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 9.3/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING

/h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:523: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint8 = np.dtype([("qint8", np.int8, 1)])
/h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:524: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint8 = np.dtype([("quint8", np.uint8, 1)])
/h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint16 = np.dtype([("qint16", np.int16, 1)])
/h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint16 = np.dtype([("quint16", np.uint16, 1)])
/h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint32 = np.dtype([("qint32", np.int32, 1)])
/h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:532: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  np_resource = np.dtype([("resource", np.ubyte, 1)])
2020-07-07 00:05:53,194	INFO policy_evaluator.py:262 -- Creating policy evaluation worker 0 on CPU (please ignore any CUDA init errors)
2020-07-07 00:05:53.195116: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
From /h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/ray/rllib/models/lstm.py:59: BasicLSTMCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.
Instructions for updating:
This class is deprecated, please use tf.nn.rnn_cell.LSTMCell, which supports all the feature this cell currently has. Please replace the existing code with tf.nn.rnn_cell.LSTMCell(name='basic_lstm_cell').
/h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:523: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint8 = np.dtype([("qint8", np.int8, 1)])
/h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:524: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint8 = np.dtype([("quint8", np.uint8, 1)])
/h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint16 = np.dtype([("qint16", np.int16, 1)])
/h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint16 = np.dtype([("quint16", np.uint16, 1)])
/h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint32 = np.dtype([("qint32", np.int32, 1)])
/h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:532: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  np_resource = np.dtype([("resource", np.ubyte, 1)])
2020-07-07 00:06:04,975	INFO policy_evaluator.py:262 -- Creating policy evaluation worker 2 on CPU (please ignore any CUDA init errors)
/h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:523: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint8 = np.dtype([("qint8", np.int8, 1)])
/h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:524: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint8 = np.dtype([("quint8", np.uint8, 1)])
/h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint16 = np.dtype([("qint16", np.int16, 1)])
/h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint16 = np.dtype([("quint16", np.uint16, 1)])
/h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint32 = np.dtype([("qint32", np.int32, 1)])
/h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:532: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  np_resource = np.dtype([("resource", np.ubyte, 1)])
2020-07-07 00:06:04,975	INFO policy_evaluator.py:262 -- Creating policy evaluation worker 1 on CPU (please ignore any CUDA init errors)
2020-07-07 00:06:04.976337: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
2020-07-07 00:06:04.976337: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
From /h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/ray/rllib/models/lstm.py:59: BasicLSTMCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.
Instructions for updating:
This class is deprecated, please use tf.nn.rnn_cell.LSTMCell, which supports all the feature this cell currently has. Please replace the existing code with tf.nn.rnn_cell.LSTMCell(name='basic_lstm_cell').
From /h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/ray/rllib/models/lstm.py:59: BasicLSTMCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.
Instructions for updating:
This class is deprecated, please use tf.nn.rnn_cell.LSTMCell, which supports all the feature this cell currently has. Please replace the existing code with tf.nn.rnn_cell.LSTMCell(name='basic_lstm_cell').
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_00-06-27
  done: false
  episode_len_mean: .nan
  episode_reward_max: .nan
  episode_reward_mean: .nan
  episode_reward_min: .nan
  episodes_this_iter: 0
  episodes_total: 0
  experiment_id: a3942a9886f24694ab1b58ca8d1ab856
  hostname: gpu006
  info:
    apply_time_ms: 6.525
    dispatch_time_ms: 12.924
    learner:
      cur_lr: 0.0013599999947473407
      grad_gnorm: 40.0
      policy_entropy: 111.48625946044922
      policy_loss: 97.04467010498047
      var_gnorm: 18.06483268737793
      vf_explained_var: 0.08638936281204224
      vf_loss: 72.99099731445312
    num_steps_sampled: 10000
    num_steps_trained: 10000
    wait_time_ms: 195.856
  iterations_since_restore: 1
  node_ip: 172.17.8.6
  num_metric_batches_dropped: 0
  pid: 13557
  policy_reward_mean: {}
  time_since_restore: 32.58636975288391
  time_this_iter_s: 32.58636975288391
  time_total_s: 32.58636975288391
  timestamp: 1594094787
  timesteps_since_restore: 10000
  timesteps_this_iter: 10000
  timesteps_total: 10000
  training_iteration: 1
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 10.3/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=13557], 32 s, 1 iter, 10000 ts, nan rew

[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.[0m
agent-1: -732.0
agent-2: -124.0
agent-3: -66.0
agent-4: -194.0
agent-5: 110.0
agent-6: 97.0
agent-7: -220.0
agent-8: 96.0
agent-9: 36.0
agent-10: -572.0
Sum Reward: -1569.0
Avg Reward: -156.9
Min Reward: -732.0
Max Reward: 110.0
Gini Coefficient: -0.9298279158699809
20:20 Ratio: -0.15874233128834356
Max-min Ratio: -0.15027322404371585
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_00-06-46
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -1569.0
  episode_reward_mean: -1569.0
  episode_reward_min: -1569.0
  episodes_this_iter: 1
  episodes_total: 1
  experiment_id: a3942a9886f24694ab1b58ca8d1ab856
  hostname: gpu006
  info:
    apply_time_ms: 3.272
    dispatch_time_ms: 8.702
    learner:
      cur_lr: 0.0013593339826911688
      grad_gnorm: 40.0
      policy_entropy: 98.54239654541016
      policy_loss: 18.11751937866211
      var_gnorm: 18.10577964782715
      vf_explained_var: 0.013350963592529297
      vf_loss: 68.03366088867188
    num_steps_sampled: 20000
    num_steps_trained: 20000
    wait_time_ms: 192.607
  iterations_since_restore: 2
  node_ip: 172.17.8.6
  num_metric_batches_dropped: 0
  pid: 13557
  policy_reward_mean: {}
  time_since_restore: 52.21431612968445
  time_this_iter_s: 19.627946376800537
  time_total_s: 52.21431612968445
  timestamp: 1594094806
  timesteps_since_restore: 20000
  timesteps_this_iter: 10000
  timesteps_total: 20000
  training_iteration: 2
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 10.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=13557], 52 s, 2 iter, 20000 ts, -1.57e+03 rew

[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.[0m
agent-1: -5.0
agent-2: -123.0
agent-3: -185.0
agent-4: -128.0
agent-5: -152.0
agent-6: -126.0
agent-7: 14.0
agent-8: -345.0
agent-9: 10.0
agent-10: 85.0
Sum Reward: -955.0
Avg Reward: -95.5
Min Reward: -345.0
Max Reward: 85.0
Gini Coefficient: -0.6748691099476439
20:20 Ratio: -0.18679245283018867
Max-min Ratio: -0.2463768115942029
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_00-07-06
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -955.0
  episode_reward_mean: -1262.0
  episode_reward_min: -1569.0
  episodes_this_iter: 1
  episodes_total: 2
  experiment_id: a3942a9886f24694ab1b58ca8d1ab856
  hostname: gpu006
  info:
    apply_time_ms: 2.905
    dispatch_time_ms: 8.362
    learner:
      cur_lr: 0.0013586679706349969
      grad_gnorm: 39.99999237060547
      policy_entropy: 122.81436157226562
      policy_loss: -5.163524150848389
      var_gnorm: 18.344758987426758
      vf_explained_var: 0.3857564926147461
      vf_loss: 41.2633056640625
    num_steps_sampled: 30000
    num_steps_trained: 30000
    wait_time_ms: 184.507
  iterations_since_restore: 3
  node_ip: 172.17.8.6
  num_metric_batches_dropped: 0
  pid: 13557
  policy_reward_mean: {}
  time_since_restore: 71.32416462898254
  time_this_iter_s: 19.109848499298096
  time_total_s: 71.32416462898254
  timestamp: 1594094826
  timesteps_since_restore: 30000
  timesteps_this_iter: 10000
  timesteps_total: 30000
  training_iteration: 3
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 10.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=13557], 71 s, 3 iter, 30000 ts, -1.26e+03 rew

agent-1: 53.0
agent-2: 132.0
agent-3: 136.0
agent-4: 99.0
agent-5: 161.0
agent-6: 106.0
agent-7: 109.0
agent-8: 109.0
agent-9: 166.0
agent-10: 121.0
Sum Reward: 1192.0
Avg Reward: 119.2
Min Reward: 53.0
Max Reward: 166.0
Gini Coefficient: 0.14110738255033556
20:20 Ratio: 2.151315789473684
Max-min Ratio: 3.1320754716981134
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_00-07-26
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1192.0
  episode_reward_mean: -444.0
  episode_reward_min: -1569.0
  episodes_this_iter: 1
  episodes_total: 3
  experiment_id: a3942a9886f24694ab1b58ca8d1ab856
  hostname: gpu006
  info:
    apply_time_ms: 3.304
    dispatch_time_ms: 6.529
    learner:
      cur_lr: 0.001358001958578825
      grad_gnorm: 40.0
      policy_entropy: 104.29683685302734
      policy_loss: 52.43721389770508
      var_gnorm: 18.601318359375
      vf_explained_var: 0.10176753997802734
      vf_loss: 138.5014190673828
    num_steps_sampled: 40000
    num_steps_trained: 40000
    wait_time_ms: 191.288
  iterations_since_restore: 4
  node_ip: 172.17.8.6
  num_metric_batches_dropped: 0
  pid: 13557
  policy_reward_mean: {}
  time_since_restore: 91.9923050403595
  time_this_iter_s: 20.668140411376953
  time_total_s: 91.9923050403595
  timestamp: 1594094846
  timesteps_since_restore: 40000
  timesteps_this_iter: 10000
  timesteps_total: 40000
  training_iteration: 4
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 11.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=13557], 91 s, 4 iter, 40000 ts, -444 rew

agent-1: 152.0
agent-2: 142.0
agent-3: 77.0
agent-4: 132.0
agent-5: 138.0
agent-6: 90.0
agent-7: 140.0
agent-8: 173.0
agent-9: 170.0
agent-10: 172.0
Sum Reward: 1386.0
Avg Reward: 138.6
Min Reward: 77.0
Max Reward: 173.0
Gini Coefficient: 0.12063492063492064
20:20 Ratio: 2.065868263473054
Max-min Ratio: 2.2467532467532467
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_00-07-47
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1386.0
  episode_reward_mean: 13.5
  episode_reward_min: -1569.0
  episodes_this_iter: 1
  episodes_total: 4
  experiment_id: a3942a9886f24694ab1b58ca8d1ab856
  hostname: gpu006
  info:
    apply_time_ms: 2.675
    dispatch_time_ms: 5.912
    learner:
      cur_lr: 0.001357335946522653
      grad_gnorm: 39.99993896484375
      policy_entropy: 104.11441802978516
      policy_loss: 34.22465133666992
      var_gnorm: 19.04374122619629
      vf_explained_var: 0.47872620820999146
      vf_loss: 50.835968017578125
    num_steps_sampled: 50000
    num_steps_trained: 50000
    wait_time_ms: 215.427
  iterations_since_restore: 5
  node_ip: 172.17.8.6
  num_metric_batches_dropped: 0
  pid: 13557
  policy_reward_mean: {}
  time_since_restore: 112.85791873931885
  time_this_iter_s: 20.86561369895935
  time_total_s: 112.85791873931885
  timestamp: 1594094867
  timesteps_since_restore: 50000
  timesteps_this_iter: 10000
  timesteps_total: 50000
  training_iteration: 5
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 11.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=13557], 112 s, 5 iter, 50000 ts, 13.5 rew

agent-1: 43.0
agent-2: 154.0
agent-3: 80.0
agent-4: 123.0
agent-5: 65.0
agent-6: 121.0
agent-7: 134.0
agent-8: 158.0
agent-9: 148.0
agent-10: 142.0
Sum Reward: 1168.0
Avg Reward: 116.8
Min Reward: 43.0
Max Reward: 158.0
Gini Coefficient: 0.1773972602739726
20:20 Ratio: 2.888888888888889
Max-min Ratio: 3.6744186046511627
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_00-08-11
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1386.0
  episode_reward_mean: 244.4
  episode_reward_min: -1569.0
  episodes_this_iter: 1
  episodes_total: 5
  experiment_id: a3942a9886f24694ab1b58ca8d1ab856
  hostname: gpu006
  info:
    apply_time_ms: 2.813
    dispatch_time_ms: 8.171
    learner:
      cur_lr: 0.001356670050881803
      grad_gnorm: 40.0
      policy_entropy: 121.92695617675781
      policy_loss: 24.147022247314453
      var_gnorm: 19.891000747680664
      vf_explained_var: 0.7673407196998596
      vf_loss: 60.157470703125
    num_steps_sampled: 60000
    num_steps_trained: 60000
    wait_time_ms: 222.642
  iterations_since_restore: 6
  node_ip: 172.17.8.6
  num_metric_batches_dropped: 0
  pid: 13557
  policy_reward_mean: {}
  time_since_restore: 136.55396556854248
  time_this_iter_s: 23.696046829223633
  time_total_s: 136.55396556854248
  timestamp: 1594094891
  timesteps_since_restore: 60000
  timesteps_this_iter: 10000
  timesteps_total: 60000
  training_iteration: 6
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 11.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=13557], 136 s, 6 iter, 60000 ts, 244 rew

agent-1: 172.0
agent-2: 168.0
agent-3: 156.0
agent-4: 88.0
agent-5: 156.0
agent-6: 155.0
agent-7: 150.0
agent-8: 174.0
agent-9: 154.0
agent-10: 134.0
Sum Reward: 1507.0
Avg Reward: 150.7
Min Reward: 88.0
Max Reward: 174.0
Gini Coefficient: 0.0754479097544791
20:20 Ratio: 1.5585585585585586
Max-min Ratio: 1.9772727272727273
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_00-08-32
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1507.0
  episode_reward_mean: 454.8333333333333
  episode_reward_min: -1569.0
  episodes_this_iter: 1
  episodes_total: 6
  experiment_id: a3942a9886f24694ab1b58ca8d1ab856
  hostname: gpu006
  info:
    apply_time_ms: 4.018
    dispatch_time_ms: 9.287
    learner:
      cur_lr: 0.0013560040388256311
      grad_gnorm: 39.99999237060547
      policy_entropy: 84.15636444091797
      policy_loss: -27.716732025146484
      var_gnorm: 20.407222747802734
      vf_explained_var: 0.9048017859458923
      vf_loss: 50.157203674316406
    num_steps_sampled: 70000
    num_steps_trained: 70000
    wait_time_ms: 216.668
  iterations_since_restore: 7
  node_ip: 172.17.8.6
  num_metric_batches_dropped: 0
  pid: 13557
  policy_reward_mean: {}
  time_since_restore: 157.7045555114746
  time_this_iter_s: 21.15058994293213
  time_total_s: 157.7045555114746
  timestamp: 1594094912
  timesteps_since_restore: 70000
  timesteps_this_iter: 10000
  timesteps_total: 70000
  training_iteration: 7
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 11.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=13557], 157 s, 7 iter, 70000 ts, 455 rew

agent-1: 136.0
agent-2: 124.0
agent-3: 109.0
agent-4: 53.0
agent-5: 190.0
agent-6: 128.0
agent-7: 77.0
agent-8: 175.0
agent-9: 130.0
agent-10: 138.0
Sum Reward: 1260.0
Avg Reward: 126.0
Min Reward: 53.0
Max Reward: 190.0
Gini Coefficient: 0.16682539682539682
20:20 Ratio: 2.8076923076923075
Max-min Ratio: 3.5849056603773586
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_00-08-56
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1507.0
  episode_reward_mean: 569.8571428571429
  episode_reward_min: -1569.0
  episodes_this_iter: 1
  episodes_total: 7
  experiment_id: a3942a9886f24694ab1b58ca8d1ab856
  hostname: gpu006
  info:
    apply_time_ms: 2.773
    dispatch_time_ms: 6.971
    learner:
      cur_lr: 0.0013553380267694592
      grad_gnorm: 40.0
      policy_entropy: 78.41111755371094
      policy_loss: 229.4328155517578
      var_gnorm: 20.86654281616211
      vf_explained_var: 0.40075188875198364
      vf_loss: 471.9905700683594
    num_steps_sampled: 80000
    num_steps_trained: 80000
    wait_time_ms: 231.141
  iterations_since_restore: 8
  node_ip: 172.17.8.6
  num_metric_batches_dropped: 0
  pid: 13557
  policy_reward_mean: {}
  time_since_restore: 181.70782947540283
  time_this_iter_s: 24.003273963928223
  time_total_s: 181.70782947540283
  timestamp: 1594094936
  timesteps_since_restore: 80000
  timesteps_this_iter: 10000
  timesteps_total: 80000
  training_iteration: 8
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 12.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=13557], 181 s, 8 iter, 80000 ts, 570 rew

agent-1: 135.0
agent-2: 153.0
agent-3: 199.0
agent-4: 105.0
agent-5: 231.0
agent-6: 117.0
agent-7: 128.0
agent-8: 200.0
agent-9: 202.0
agent-10: 211.0
Sum Reward: 1681.0
Avg Reward: 168.1
Min Reward: 105.0
Max Reward: 231.0
Gini Coefficient: 0.1429506246281975
20:20 Ratio: 1.990990990990991
Max-min Ratio: 2.2
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_00-09-17
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1681.0
  episode_reward_mean: 708.75
  episode_reward_min: -1569.0
  episodes_this_iter: 1
  episodes_total: 8
  experiment_id: a3942a9886f24694ab1b58ca8d1ab856
  hostname: gpu006
  info:
    apply_time_ms: 2.934
    dispatch_time_ms: 6.414
    learner:
      cur_lr: 0.0013546720147132874
      grad_gnorm: 39.99996566772461
      policy_entropy: 52.850643157958984
      policy_loss: -33.880699157714844
      var_gnorm: 21.1200008392334
      vf_explained_var: 0.8300811052322388
      vf_loss: 120.95902252197266
    num_steps_sampled: 90000
    num_steps_trained: 90000
    wait_time_ms: 219.738
  iterations_since_restore: 9
  node_ip: 172.17.8.6
  num_metric_batches_dropped: 0
  pid: 13557
  policy_reward_mean: {}
  time_since_restore: 202.95588779449463
  time_this_iter_s: 21.248058319091797
  time_total_s: 202.95588779449463
  timestamp: 1594094957
  timesteps_since_restore: 90000
  timesteps_this_iter: 10000
  timesteps_total: 90000
  training_iteration: 9
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 12.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=13557], 202 s, 9 iter, 90000 ts, 709 rew

agent-1: 177.0
agent-2: 167.0
agent-3: 161.0
agent-4: 137.0
agent-5: 156.0
agent-6: 106.0
agent-7: 137.0
agent-8: 186.0
agent-9: 130.0
agent-10: 154.0
Sum Reward: 1511.0
Avg Reward: 151.1
Min Reward: 106.0
Max Reward: 186.0
Gini Coefficient: 0.0842488418266049
20:20 Ratio: 1.5381355932203389
Max-min Ratio: 1.7547169811320755
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_00-09-43
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1681.0
  episode_reward_mean: 797.8888888888889
  episode_reward_min: -1569.0
  episodes_this_iter: 1
  episodes_total: 9
  experiment_id: a3942a9886f24694ab1b58ca8d1ab856
  hostname: gpu006
  info:
    apply_time_ms: 2.66
    dispatch_time_ms: 6.003
    learner:
      cur_lr: 0.0013540060026571155
      grad_gnorm: 39.999996185302734
      policy_entropy: 44.79896545410156
      policy_loss: 45.626007080078125
      var_gnorm: 21.96590232849121
      vf_explained_var: -0.09330189228057861
      vf_loss: 268.8177185058594
    num_steps_sampled: 100000
    num_steps_trained: 100000
    wait_time_ms: 237.153
  iterations_since_restore: 10
  node_ip: 172.17.8.6
  num_metric_batches_dropped: 0
  pid: 13557
  policy_reward_mean: {}
  time_since_restore: 228.43012738227844
  time_this_iter_s: 25.474239587783813
  time_total_s: 228.43012738227844
  timestamp: 1594094983
  timesteps_since_restore: 100000
  timesteps_this_iter: 10000
  timesteps_total: 100000
  training_iteration: 10
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 12.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=13557], 228 s, 10 iter, 100000 ts, 798 rew

agent-1: 134.0
agent-2: 134.0
agent-3: 129.0
agent-4: 149.0
agent-5: 121.0
agent-6: 126.0
agent-7: 98.0
agent-8: 113.0
agent-9: 116.0
agent-10: 128.0
Sum Reward: 1248.0
Avg Reward: 124.8
Min Reward: 98.0
Max Reward: 149.0
Gini Coefficient: 0.057852564102564105
20:20 Ratio: 1.3412322274881516
Max-min Ratio: 1.5204081632653061
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_00-10-05
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1681.0
  episode_reward_mean: 842.9
  episode_reward_min: -1569.0
  episodes_this_iter: 1
  episodes_total: 10
  experiment_id: a3942a9886f24694ab1b58ca8d1ab856
  hostname: gpu006
  info:
    apply_time_ms: 2.899
    dispatch_time_ms: 5.968
    learner:
      cur_lr: 0.0013533399906009436
      grad_gnorm: 40.000003814697266
      policy_entropy: 53.311859130859375
      policy_loss: 11.116639137268066
      var_gnorm: 22.372804641723633
      vf_explained_var: 0.9463420510292053
      vf_loss: 78.5357437133789
    num_steps_sampled: 110000
    num_steps_trained: 110000
    wait_time_ms: 228.235
  iterations_since_restore: 11
  node_ip: 172.17.8.6
  num_metric_batches_dropped: 0
  pid: 13557
  policy_reward_mean: {}
  time_since_restore: 250.0838508605957
  time_this_iter_s: 21.65372347831726
  time_total_s: 250.0838508605957
  timestamp: 1594095005
  timesteps_since_restore: 110000
  timesteps_this_iter: 10000
  timesteps_total: 110000
  training_iteration: 11
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 12.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=13557], 250 s, 11 iter, 110000 ts, 843 rew

agent-1: 122.0
agent-2: 101.0
agent-3: 118.0
agent-4: 145.0
agent-5: 124.0
agent-6: 142.0
agent-7: 137.0
agent-8: 115.0
agent-9: 111.0
agent-10: 148.0
Sum Reward: 1263.0
Avg Reward: 126.3
Min Reward: 101.0
Max Reward: 148.0
Gini Coefficient: 0.06769596199524941
20:20 Ratio: 1.3820754716981132
Max-min Ratio: 1.4653465346534653
agent-1: 135.0
agent-2: 186.0
agent-3: 145.0
agent-4: 127.0
agent-5: 77.0
agent-6: 134.0
agent-7: 91.0
agent-8: 160.0
agent-9: 121.0
agent-10: 157.0
Sum Reward: 1333.0
Avg Reward: 133.3
Min Reward: 77.0
Max Reward: 186.0
Gini Coefficient: 0.127456864216054
20:20 Ratio: 2.0595238095238093
Max-min Ratio: 2.4155844155844157
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_00-10-30
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1681.0
  episode_reward_mean: 918.75
  episode_reward_min: -1569.0
  episodes_this_iter: 2
  episodes_total: 12
  experiment_id: a3942a9886f24694ab1b58ca8d1ab856
  hostname: gpu006
  info:
    apply_time_ms: 2.854
    dispatch_time_ms: 6.223
    learner:
      cur_lr: 0.0013526739785447717
      grad_gnorm: 39.999996185302734
      policy_entropy: 123.95738220214844
      policy_loss: 43.64707565307617
      var_gnorm: 22.89898109436035
      vf_explained_var: -1.0
      vf_loss: 53.94922637939453
    num_steps_sampled: 120000
    num_steps_trained: 120000
    wait_time_ms: 256.976
  iterations_since_restore: 12
  node_ip: 172.17.8.6
  num_metric_batches_dropped: 0
  pid: 13557
  policy_reward_mean: {}
  time_since_restore: 275.86950755119324
  time_this_iter_s: 25.785656690597534
  time_total_s: 275.86950755119324
  timestamp: 1594095030
  timesteps_since_restore: 120000
  timesteps_this_iter: 10000
  timesteps_total: 120000
  training_iteration: 12
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 12.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=13557], 275 s, 12 iter, 120000 ts, 919 rew

Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_00-10-52
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1681.0
  episode_reward_mean: 918.75
  episode_reward_min: -1569.0
  episodes_this_iter: 0
  episodes_total: 12
  experiment_id: a3942a9886f24694ab1b58ca8d1ab856
  hostname: gpu006
  info:
    apply_time_ms: 3.384
    dispatch_time_ms: 6.846
    learner:
      cur_lr: 0.0013520079664885998
      grad_gnorm: 39.99999237060547
      policy_entropy: 55.58702850341797
      policy_loss: -10.84388256072998
      var_gnorm: 23.164196014404297
      vf_explained_var: 0.7664067149162292
      vf_loss: 314.5280456542969
    num_steps_sampled: 130000
    num_steps_trained: 130000
    wait_time_ms: 237.017
  iterations_since_restore: 13
  node_ip: 172.17.8.6
  num_metric_batches_dropped: 0
  pid: 13557
  policy_reward_mean: {}
  time_since_restore: 297.94041657447815
  time_this_iter_s: 22.070909023284912
  time_total_s: 297.94041657447815
  timestamp: 1594095052
  timesteps_since_restore: 130000
  timesteps_this_iter: 10000
  timesteps_total: 130000
  training_iteration: 13
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 13.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=13557], 297 s, 13 iter, 130000 ts, 919 rew

agent-1: 167.0
agent-2: 161.0
agent-3: 183.0
agent-4: 148.0
agent-5: 135.0
agent-6: 160.0
agent-7: 199.0
agent-8: 132.0
agent-9: 175.0
agent-10: 176.0
Sum Reward: 1636.0
Avg Reward: 163.6
Min Reward: 132.0
Max Reward: 199.0
Gini Coefficient: 0.06907090464547677
20:20 Ratio: 1.4307116104868913
Max-min Ratio: 1.5075757575757576
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_00-11-16
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1681.0
  episode_reward_mean: 973.9230769230769
  episode_reward_min: -1569.0
  episodes_this_iter: 1
  episodes_total: 13
  experiment_id: a3942a9886f24694ab1b58ca8d1ab856
  hostname: gpu006
  info:
    apply_time_ms: 3.378
    dispatch_time_ms: 6.569
    learner:
      cur_lr: 0.0013513419544324279
      grad_gnorm: 40.000003814697266
      policy_entropy: 22.03558349609375
      policy_loss: 14.356293678283691
      var_gnorm: 23.430803298950195
      vf_explained_var: 0.10299819707870483
      vf_loss: 105.40200805664062
    num_steps_sampled: 140000
    num_steps_trained: 140000
    wait_time_ms: 210.529
  iterations_since_restore: 14
  node_ip: 172.17.8.6
  num_metric_batches_dropped: 0
  pid: 13557
  policy_reward_mean: {}
  time_since_restore: 321.9201326370239
  time_this_iter_s: 23.979716062545776
  time_total_s: 321.9201326370239
  timestamp: 1594095076
  timesteps_since_restore: 140000
  timesteps_this_iter: 10000
  timesteps_total: 140000
  training_iteration: 14
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 13.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=13557], 321 s, 14 iter, 140000 ts, 974 rew

agent-1: 83.0
agent-2: 214.0
agent-3: 100.0
agent-4: 73.0
agent-5: 74.0
agent-6: 169.0
agent-7: 73.0
agent-8: 108.0
agent-9: 98.0
agent-10: 80.0
Sum Reward: 1072.0
Avg Reward: 107.2
Min Reward: 73.0
Max Reward: 214.0
Gini Coefficient: 0.2039179104477612
20:20 Ratio: 2.6232876712328768
Max-min Ratio: 2.9315068493150687
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_00-11-39
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1681.0
  episode_reward_mean: 980.9285714285714
  episode_reward_min: -1569.0
  episodes_this_iter: 1
  episodes_total: 14
  experiment_id: a3942a9886f24694ab1b58ca8d1ab856
  hostname: gpu006
  info:
    apply_time_ms: 3.342
    dispatch_time_ms: 7.529
    learner:
      cur_lr: 0.001350675942376256
      grad_gnorm: 40.00001525878906
      policy_entropy: 56.58982849121094
      policy_loss: -34.40908432006836
      var_gnorm: 23.64777946472168
      vf_explained_var: 0.6314015984535217
      vf_loss: 92.69668579101562
    num_steps_sampled: 150000
    num_steps_trained: 150000
    wait_time_ms: 229.154
  iterations_since_restore: 15
  node_ip: 172.17.8.6
  num_metric_batches_dropped: 0
  pid: 13557
  policy_reward_mean: {}
  time_since_restore: 343.90620279312134
  time_this_iter_s: 21.986070156097412
  time_total_s: 343.90620279312134
  timestamp: 1594095099
  timesteps_since_restore: 150000
  timesteps_this_iter: 10000
  timesteps_total: 150000
  training_iteration: 15
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 13.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=13557], 343 s, 15 iter, 150000 ts, 981 rew

agent-1: 98.0
agent-2: 141.0
agent-3: 138.0
agent-4: 179.0
agent-5: 152.0
agent-6: 150.0
agent-7: 125.0
agent-8: 179.0
agent-9: 158.0
agent-10: 122.0
Sum Reward: 1442.0
Avg Reward: 144.2
Min Reward: 98.0
Max Reward: 179.0
Gini Coefficient: 0.09320388349514563
20:20 Ratio: 1.6272727272727272
Max-min Ratio: 1.8265306122448979
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_00-12-03
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1681.0
  episode_reward_mean: 1011.6666666666666
  episode_reward_min: -1569.0
  episodes_this_iter: 1
  episodes_total: 15
  experiment_id: a3942a9886f24694ab1b58ca8d1ab856
  hostname: gpu006
  info:
    apply_time_ms: 2.793
    dispatch_time_ms: 6.594
    learner:
      cur_lr: 0.001350010046735406
      grad_gnorm: 40.00000762939453
      policy_entropy: 99.87804412841797
      policy_loss: 2.6274468898773193
      var_gnorm: 24.180458068847656
      vf_explained_var: 0.7264405488967896
      vf_loss: 21.550207138061523
    num_steps_sampled: 160000
    num_steps_trained: 160000
    wait_time_ms: 207.969
  iterations_since_restore: 16
  node_ip: 172.17.8.6
  num_metric_batches_dropped: 0
  pid: 13557
  policy_reward_mean: {}
  time_since_restore: 368.627210855484
  time_this_iter_s: 24.72100806236267
  time_total_s: 368.627210855484
  timestamp: 1594095123
  timesteps_since_restore: 160000
  timesteps_this_iter: 10000
  timesteps_total: 160000
  training_iteration: 16
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 13.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=13557], 368 s, 16 iter, 160000 ts, 1.01e+03 rew

agent-1: 124.0
agent-2: 140.0
agent-3: 129.0
agent-4: 148.0
agent-5: 141.0
agent-6: 161.0
agent-7: 122.0
agent-8: 127.0
agent-9: 117.0
agent-10: 146.0
Sum Reward: 1355.0
Avg Reward: 135.5
Min Reward: 117.0
Max Reward: 161.0
Gini Coefficient: 0.054686346863468634
20:20 Ratio: 1.292887029288703
Max-min Ratio: 1.376068376068376
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_00-12-26
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1681.0
  episode_reward_mean: 1033.125
  episode_reward_min: -1569.0
  episodes_this_iter: 1
  episodes_total: 16
  experiment_id: a3942a9886f24694ab1b58ca8d1ab856
  hostname: gpu006
  info:
    apply_time_ms: 2.627
    dispatch_time_ms: 6.257
    learner:
      cur_lr: 0.001349344034679234
      grad_gnorm: 39.99998474121094
      policy_entropy: 71.01914978027344
      policy_loss: 46.307857513427734
      var_gnorm: 24.25294303894043
      vf_explained_var: 0.6981828212738037
      vf_loss: 198.98410034179688
    num_steps_sampled: 170000
    num_steps_trained: 170000
    wait_time_ms: 250.628
  iterations_since_restore: 17
  node_ip: 172.17.8.6
  num_metric_batches_dropped: 0
  pid: 13557
  policy_reward_mean: {}
  time_since_restore: 391.0056347846985
  time_this_iter_s: 22.378423929214478
  time_total_s: 391.0056347846985
  timestamp: 1594095146
  timesteps_since_restore: 170000
  timesteps_this_iter: 10000
  timesteps_total: 170000
  training_iteration: 17
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 14.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=13557], 391 s, 17 iter, 170000 ts, 1.03e+03 rew

agent-1: 121.0
agent-2: 92.0
agent-3: 94.0
agent-4: 129.0
agent-5: 95.0
agent-6: 108.0
agent-7: 109.0
agent-8: 86.0
agent-9: 68.0
agent-10: 130.0
Sum Reward: 1032.0
Avg Reward: 103.2
Min Reward: 68.0
Max Reward: 130.0
Gini Coefficient: 0.10290697674418604
20:20 Ratio: 1.6818181818181819
Max-min Ratio: 1.911764705882353
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_00-12-51
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1681.0
  episode_reward_mean: 1033.0588235294117
  episode_reward_min: -1569.0
  episodes_this_iter: 1
  episodes_total: 17
  experiment_id: a3942a9886f24694ab1b58ca8d1ab856
  hostname: gpu006
  info:
    apply_time_ms: 3.439
    dispatch_time_ms: 10.068
    learner:
      cur_lr: 0.0013486780226230621
      grad_gnorm: 39.99999237060547
      policy_entropy: 116.86443328857422
      policy_loss: 30.558279037475586
      var_gnorm: 24.6335391998291
      vf_explained_var: 0.8363479971885681
      vf_loss: 27.312406539916992
    num_steps_sampled: 180000
    num_steps_trained: 180000
    wait_time_ms: 207.435
  iterations_since_restore: 18
  node_ip: 172.17.8.6
  num_metric_batches_dropped: 0
  pid: 13557
  policy_reward_mean: {}
  time_since_restore: 416.11228227615356
  time_this_iter_s: 25.106647491455078
  time_total_s: 416.11228227615356
  timestamp: 1594095171
  timesteps_since_restore: 180000
  timesteps_this_iter: 10000
  timesteps_total: 180000
  training_iteration: 18
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 14.3/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=13557], 416 s, 18 iter, 180000 ts, 1.03e+03 rew

agent-1: 128.0
agent-2: 112.0
agent-3: 132.0
agent-4: 139.0
agent-5: 110.0
agent-6: 145.0
agent-7: 143.0
agent-8: 110.0
agent-9: 175.0
agent-10: 127.0
Sum Reward: 1321.0
Avg Reward: 132.1
Min Reward: 110.0
Max Reward: 175.0
Gini Coefficient: 0.07759273277819834
20:20 Ratio: 1.4545454545454546
Max-min Ratio: 1.5909090909090908
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_00-13-14
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1681.0
  episode_reward_mean: 1049.0555555555557
  episode_reward_min: -1569.0
  episodes_this_iter: 1
  episodes_total: 18
  experiment_id: a3942a9886f24694ab1b58ca8d1ab856
  hostname: gpu006
  info:
    apply_time_ms: 2.84
    dispatch_time_ms: 6.628
    learner:
      cur_lr: 0.0013480120105668902
      grad_gnorm: 40.00000762939453
      policy_entropy: 97.46134948730469
      policy_loss: 16.31521224975586
      var_gnorm: 24.803546905517578
      vf_explained_var: -0.002118825912475586
      vf_loss: 55.551841735839844
    num_steps_sampled: 190000
    num_steps_trained: 190000
    wait_time_ms: 249.778
  iterations_since_restore: 19
  node_ip: 172.17.8.6
  num_metric_batches_dropped: 0
  pid: 13557
  policy_reward_mean: {}
  time_since_restore: 438.8241777420044
  time_this_iter_s: 22.71189546585083
  time_total_s: 438.8241777420044
  timestamp: 1594095194
  timesteps_since_restore: 190000
  timesteps_this_iter: 10000
  timesteps_total: 190000
  training_iteration: 19
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 14.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=13557], 438 s, 19 iter, 190000 ts, 1.05e+03 rew

agent-1: 111.0
agent-2: 95.0
agent-3: 98.0
agent-4: 98.0
agent-5: 120.0
agent-6: 111.0
agent-7: 96.0
agent-8: 118.0
agent-9: 102.0
agent-10: 105.0
Sum Reward: 1054.0
Avg Reward: 105.4
Min Reward: 95.0
Max Reward: 120.0
Gini Coefficient: 0.04611005692599621
20:20 Ratio: 1.2460732984293195
Max-min Ratio: 1.263157894736842
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_00-13-38
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1681.0
  episode_reward_mean: 1049.3157894736842
  episode_reward_min: -1569.0
  episodes_this_iter: 1
  episodes_total: 19
  experiment_id: a3942a9886f24694ab1b58ca8d1ab856
  hostname: gpu006
  info:
    apply_time_ms: 3.954
    dispatch_time_ms: 6.982
    learner:
      cur_lr: 0.0013473459985107183
      grad_gnorm: 40.00003433227539
      policy_entropy: 64.2497329711914
      policy_loss: 6.050402641296387
      var_gnorm: 25.024585723876953
      vf_explained_var: 0.8299223184585571
      vf_loss: 66.61668395996094
    num_steps_sampled: 200000
    num_steps_trained: 200000
    wait_time_ms: 213.519
  iterations_since_restore: 20
  node_ip: 172.17.8.6
  num_metric_batches_dropped: 0
  pid: 13557
  policy_reward_mean: {}
  time_since_restore: 463.2345039844513
  time_this_iter_s: 24.4103262424469
  time_total_s: 463.2345039844513
  timestamp: 1594095218
  timesteps_since_restore: 200000
  timesteps_this_iter: 10000
  timesteps_total: 200000
  training_iteration: 20
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 14.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=13557], 463 s, 20 iter, 200000 ts, 1.05e+03 rew

agent-1: 169.0
agent-2: 133.0
agent-3: 157.0
agent-4: 164.0
agent-5: 126.0
agent-6: 137.0
agent-7: 154.0
agent-8: 146.0
agent-9: 156.0
agent-10: 154.0
Sum Reward: 1496.0
Avg Reward: 149.6
Min Reward: 126.0
Max Reward: 169.0
Gini Coefficient: 0.04906417112299465
20:20 Ratio: 1.2857142857142858
Max-min Ratio: 1.3412698412698412
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_00-14-00
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1681.0
  episode_reward_mean: 1071.65
  episode_reward_min: -1569.0
  episodes_this_iter: 1
  episodes_total: 20
  experiment_id: a3942a9886f24694ab1b58ca8d1ab856
  hostname: gpu006
  info:
    apply_time_ms: 2.625
    dispatch_time_ms: 6.451
    learner:
      cur_lr: 0.0013466799864545465
      grad_gnorm: 40.00001907348633
      policy_entropy: 66.32577514648438
      policy_loss: -52.574951171875
      var_gnorm: 25.09403419494629
      vf_explained_var: 0.18411725759506226
      vf_loss: 95.90636444091797
    num_steps_sampled: 210000
    num_steps_trained: 210000
    wait_time_ms: 225.857
  iterations_since_restore: 21
  node_ip: 172.17.8.6
  num_metric_batches_dropped: 0
  pid: 13557
  policy_reward_mean: {}
  time_since_restore: 484.87625074386597
  time_this_iter_s: 21.641746759414673
  time_total_s: 484.87625074386597
  timestamp: 1594095240
  timesteps_since_restore: 210000
  timesteps_this_iter: 10000
  timesteps_total: 210000
  training_iteration: 21
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 15.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=13557], 484 s, 21 iter, 210000 ts, 1.07e+03 rew

agent-1: 174.0
agent-2: 196.0
agent-3: 151.0
agent-4: 138.0
agent-5: 162.0
agent-6: 147.0
agent-7: 144.0
agent-8: 171.0
agent-9: 150.0
agent-10: 144.0
Sum Reward: 1577.0
Avg Reward: 157.7
Min Reward: 138.0
Max Reward: 196.0
Gini Coefficient: 0.05789473684210526
20:20 Ratio: 1.3120567375886525
Max-min Ratio: 1.4202898550724639
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_00-14-25
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1681.0
  episode_reward_mean: 1095.7142857142858
  episode_reward_min: -1569.0
  episodes_this_iter: 1
  episodes_total: 21
  experiment_id: a3942a9886f24694ab1b58ca8d1ab856
  hostname: gpu006
  info:
    apply_time_ms: 3.354
    dispatch_time_ms: 6.739
    learner:
      cur_lr: 0.0013460139743983746
      grad_gnorm: 39.99998092651367
      policy_entropy: 62.91522216796875
      policy_loss: 29.494556427001953
      var_gnorm: 25.377634048461914
      vf_explained_var: 0.12735944986343384
      vf_loss: 64.51333618164062
    num_steps_sampled: 220000
    num_steps_trained: 220000
    wait_time_ms: 200.744
  iterations_since_restore: 22
  node_ip: 172.17.8.6
  num_metric_batches_dropped: 0
  pid: 13557
  policy_reward_mean: {}
  time_since_restore: 509.9271125793457
  time_this_iter_s: 25.050861835479736
  time_total_s: 509.9271125793457
  timestamp: 1594095265
  timesteps_since_restore: 220000
  timesteps_this_iter: 10000
  timesteps_total: 220000
  training_iteration: 22
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 15.3/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=13557], 509 s, 22 iter, 220000 ts, 1.1e+03 rew

agent-1: 127.0
agent-2: 98.0
agent-3: 108.0
agent-4: 94.0
agent-5: 119.0
agent-6: 126.0
agent-7: 106.0
agent-8: 107.0
agent-9: 118.0
agent-10: 136.0
Sum Reward: 1139.0
Avg Reward: 113.9
Min Reward: 94.0
Max Reward: 136.0
Gini Coefficient: 0.06382791922739245
20:20 Ratio: 1.3697916666666667
Max-min Ratio: 1.446808510638298
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_00-14-47
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1681.0
  episode_reward_mean: 1097.6818181818182
  episode_reward_min: -1569.0
  episodes_this_iter: 1
  episodes_total: 22
  experiment_id: a3942a9886f24694ab1b58ca8d1ab856
  hostname: gpu006
  info:
    apply_time_ms: 2.7
    dispatch_time_ms: 6.834
    learner:
      cur_lr: 0.0013453479623422027
      grad_gnorm: 40.00000762939453
      policy_entropy: 50.90884780883789
      policy_loss: -54.22428894042969
      var_gnorm: 25.487957000732422
      vf_explained_var: 0.6690051555633545
      vf_loss: 164.11061096191406
    num_steps_sampled: 230000
    num_steps_trained: 230000
    wait_time_ms: 226.173
  iterations_since_restore: 23
  node_ip: 172.17.8.6
  num_metric_batches_dropped: 0
  pid: 13557
  policy_reward_mean: {}
  time_since_restore: 532.5117120742798
  time_this_iter_s: 22.584599494934082
  time_total_s: 532.5117120742798
  timestamp: 1594095287
  timesteps_since_restore: 230000
  timesteps_this_iter: 10000
  timesteps_total: 230000
  training_iteration: 23
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 15.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=13557], 532 s, 23 iter, 230000 ts, 1.1e+03 rew

agent-1: 122.0
agent-2: 115.0
agent-3: 82.0
agent-4: 147.0
agent-5: 115.0
agent-6: 117.0
agent-7: 80.0
agent-8: 113.0
agent-9: 91.0
agent-10: 104.0
Sum Reward: 1086.0
Avg Reward: 108.6
Min Reward: 80.0
Max Reward: 147.0
Gini Coefficient: 0.09650092081031307
20:20 Ratio: 1.6604938271604939
Max-min Ratio: 1.8375
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_00-15-13
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1681.0
  episode_reward_mean: 1097.1739130434783
  episode_reward_min: -1569.0
  episodes_this_iter: 1
  episodes_total: 23
  experiment_id: a3942a9886f24694ab1b58ca8d1ab856
  hostname: gpu006
  info:
    apply_time_ms: 2.901
    dispatch_time_ms: 6.682
    learner:
      cur_lr: 0.0013446819502860308
      grad_gnorm: 40.0
      policy_entropy: 30.766948699951172
      policy_loss: 17.942827224731445
      var_gnorm: 25.853483200073242
      vf_explained_var: -0.031546831130981445
      vf_loss: 141.3982696533203
    num_steps_sampled: 240000
    num_steps_trained: 240000
    wait_time_ms: 203.369
  iterations_since_restore: 24
  node_ip: 172.17.8.6
  num_metric_batches_dropped: 0
  pid: 13557
  policy_reward_mean: {}
  time_since_restore: 558.2868595123291
  time_this_iter_s: 25.775147438049316
  time_total_s: 558.2868595123291
  timestamp: 1594095313
  timesteps_since_restore: 240000
  timesteps_this_iter: 10000
  timesteps_total: 240000
  training_iteration: 24
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 15.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=13557], 558 s, 24 iter, 240000 ts, 1.1e+03 rew

agent-1: 135.0
agent-2: 164.0
agent-3: 135.0
agent-4: 139.0
agent-5: 101.0
agent-6: 115.0
agent-7: 122.0
agent-8: 132.0
agent-9: 101.0
agent-10: 131.0
Sum Reward: 1275.0
Avg Reward: 127.5
Min Reward: 101.0
Max Reward: 164.0
Gini Coefficient: 0.07631372549019608
20:20 Ratio: 1.5
Max-min Ratio: 1.6237623762376239
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_00-15-36
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1681.0
  episode_reward_mean: 1104.5833333333333
  episode_reward_min: -1569.0
  episodes_this_iter: 1
  episodes_total: 24
  experiment_id: a3942a9886f24694ab1b58ca8d1ab856
  hostname: gpu006
  info:
    apply_time_ms: 3.669
    dispatch_time_ms: 6.406
    learner:
      cur_lr: 0.0013440160546451807
      grad_gnorm: 40.0
      policy_entropy: 63.82851028442383
      policy_loss: 1.4052965641021729
      var_gnorm: 25.996885299682617
      vf_explained_var: 0.7162795066833496
      vf_loss: 425.26617431640625
    num_steps_sampled: 250000
    num_steps_trained: 250000
    wait_time_ms: 243.63
  iterations_since_restore: 25
  node_ip: 172.17.8.6
  num_metric_batches_dropped: 0
  pid: 13557
  policy_reward_mean: {}
  time_since_restore: 580.9551501274109
  time_this_iter_s: 22.668290615081787
  time_total_s: 580.9551501274109
  timestamp: 1594095336
  timesteps_since_restore: 250000
  timesteps_this_iter: 10000
  timesteps_total: 250000
  training_iteration: 25
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 16.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=13557], 580 s, 25 iter, 250000 ts, 1.1e+03 rew

agent-1: 105.0
agent-2: 91.0
agent-3: 90.0
agent-4: 103.0
agent-5: 111.0
agent-6: 95.0
agent-7: 81.0
agent-8: 101.0
agent-9: 106.0
agent-10: 90.0
Sum Reward: 973.0
Avg Reward: 97.3
Min Reward: 81.0
Max Reward: 111.0
Gini Coefficient: 0.051284686536485095
20:20 Ratio: 1.2690058479532165
Max-min Ratio: 1.3703703703703705
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_00-16-01
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1681.0
  episode_reward_mean: 1099.32
  episode_reward_min: -1569.0
  episodes_this_iter: 1
  episodes_total: 25
  experiment_id: a3942a9886f24694ab1b58ca8d1ab856
  hostname: gpu006
  info:
    apply_time_ms: 4.063
    dispatch_time_ms: 6.183
    learner:
      cur_lr: 0.0013433500425890088
      grad_gnorm: 39.9999885559082
      policy_entropy: 53.55263137817383
      policy_loss: -24.756507873535156
      var_gnorm: 26.35029411315918
      vf_explained_var: 0.1932956576347351
      vf_loss: 61.5233039855957
    num_steps_sampled: 260000
    num_steps_trained: 260000
    wait_time_ms: 224.667
  iterations_since_restore: 26
  node_ip: 172.17.8.6
  num_metric_batches_dropped: 0
  pid: 13557
  policy_reward_mean: {}
  time_since_restore: 606.4548211097717
  time_this_iter_s: 25.49967098236084
  time_total_s: 606.4548211097717
  timestamp: 1594095361
  timesteps_since_restore: 260000
  timesteps_this_iter: 10000
  timesteps_total: 260000
  training_iteration: 26
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 16.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=13557], 606 s, 26 iter, 260000 ts, 1.1e+03 rew

agent-1: 103.0
agent-2: 156.0
agent-3: 154.0
agent-4: 143.0
agent-5: 127.0
agent-6: 137.0
agent-7: 146.0
agent-8: 132.0
agent-9: 148.0
agent-10: 155.0
Sum Reward: 1401.0
Avg Reward: 140.1
Min Reward: 103.0
Max Reward: 156.0
Gini Coefficient: 0.058458244111349034
20:20 Ratio: 1.3521739130434782
Max-min Ratio: 1.5145631067961165
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_00-16-24
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1681.0
  episode_reward_mean: 1110.923076923077
  episode_reward_min: -1569.0
  episodes_this_iter: 1
  episodes_total: 26
  experiment_id: a3942a9886f24694ab1b58ca8d1ab856
  hostname: gpu006
  info:
    apply_time_ms: 2.782
    dispatch_time_ms: 6.621
    learner:
      cur_lr: 0.001342684030532837
      grad_gnorm: 40.00000762939453
      policy_entropy: 34.48822784423828
      policy_loss: 1.43902587890625
      var_gnorm: 26.392427444458008
      vf_explained_var: -0.5877385139465332
      vf_loss: 79.20382690429688
    num_steps_sampled: 270000
    num_steps_trained: 270000
    wait_time_ms: 232.894
  iterations_since_restore: 27
  node_ip: 172.17.8.6
  num_metric_batches_dropped: 0
  pid: 13557
  policy_reward_mean: {}
  time_since_restore: 628.6231672763824
  time_this_iter_s: 22.168346166610718
  time_total_s: 628.6231672763824
  timestamp: 1594095384
  timesteps_since_restore: 270000
  timesteps_this_iter: 10000
  timesteps_total: 270000
  training_iteration: 27
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 16.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=13557], 628 s, 27 iter, 270000 ts, 1.11e+03 rew

agent-1: 163.0
agent-2: 149.0
agent-3: 167.0
agent-4: 129.0
agent-5: 138.0
agent-6: 198.0
agent-7: 167.0
agent-8: 153.0
agent-9: 170.0
agent-10: 146.0
Sum Reward: 1580.0
Avg Reward: 158.0
Min Reward: 129.0
Max Reward: 198.0
Gini Coefficient: 0.06417721518987342
20:20 Ratio: 1.3782771535580525
Max-min Ratio: 1.5348837209302326
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_00-16-48
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1681.0
  episode_reward_mean: 1128.2962962962963
  episode_reward_min: -1569.0
  episodes_this_iter: 1
  episodes_total: 27
  experiment_id: a3942a9886f24694ab1b58ca8d1ab856
  hostname: gpu006
  info:
    apply_time_ms: 2.729
    dispatch_time_ms: 7.147
    learner:
      cur_lr: 0.001342018018476665
      grad_gnorm: 22.48741340637207
      policy_entropy: 72.50711059570312
      policy_loss: 5.576209545135498
      var_gnorm: 26.741552352905273
      vf_explained_var: 0.9820323586463928
      vf_loss: 0.5101712346076965
    num_steps_sampled: 280000
    num_steps_trained: 280000
    wait_time_ms: 202.942
  iterations_since_restore: 28
  node_ip: 172.17.8.6
  num_metric_batches_dropped: 0
  pid: 13557
  policy_reward_mean: {}
  time_since_restore: 653.4324889183044
  time_this_iter_s: 24.809321641921997
  time_total_s: 653.4324889183044
  timestamp: 1594095408
  timesteps_since_restore: 280000
  timesteps_this_iter: 10000
  timesteps_total: 280000
  training_iteration: 28
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 16.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=13557], 653 s, 28 iter, 280000 ts, 1.13e+03 rew

agent-1: 103.0
agent-2: 110.0
agent-3: 97.0
agent-4: 102.0
agent-5: 102.0
agent-6: 123.0
agent-7: 134.0
agent-8: 95.0
agent-9: 106.0
agent-10: 103.0
Sum Reward: 1075.0
Avg Reward: 107.5
Min Reward: 95.0
Max Reward: 134.0
Gini Coefficient: 0.05441860465116279
20:20 Ratio: 1.3385416666666667
Max-min Ratio: 1.4105263157894736
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_00-17-11
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1681.0
  episode_reward_mean: 1126.392857142857
  episode_reward_min: -1569.0
  episodes_this_iter: 1
  episodes_total: 28
  experiment_id: a3942a9886f24694ab1b58ca8d1ab856
  hostname: gpu006
  info:
    apply_time_ms: 2.7
    dispatch_time_ms: 6.334
    learner:
      cur_lr: 0.0013413520064204931
      grad_gnorm: 40.000003814697266
      policy_entropy: 69.23066711425781
      policy_loss: -14.388463020324707
      var_gnorm: 26.808292388916016
      vf_explained_var: -0.3394976854324341
      vf_loss: 125.12483978271484
    num_steps_sampled: 290000
    num_steps_trained: 290000
    wait_time_ms: 254.94
  iterations_since_restore: 29
  node_ip: 172.17.8.6
  num_metric_batches_dropped: 0
  pid: 13557
  policy_reward_mean: {}
  time_since_restore: 675.8229873180389
  time_this_iter_s: 22.390498399734497
  time_total_s: 675.8229873180389
  timestamp: 1594095431
  timesteps_since_restore: 290000
  timesteps_this_iter: 10000
  timesteps_total: 290000
  training_iteration: 29
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 16.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=13557], 675 s, 29 iter, 290000 ts, 1.13e+03 rew

agent-1: 105.0
agent-2: 113.0
agent-3: 125.0
agent-4: 81.0
agent-5: 88.0
agent-6: 118.0
agent-7: 105.0
agent-8: 97.0
agent-9: 101.0
agent-10: 111.0
Sum Reward: 1044.0
Avg Reward: 104.4
Min Reward: 81.0
Max Reward: 125.0
Gini Coefficient: 0.0685823754789272
20:20 Ratio: 1.4378698224852071
Max-min Ratio: 1.5432098765432098
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_00-17-36
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1681.0
  episode_reward_mean: 1123.551724137931
  episode_reward_min: -1569.0
  episodes_this_iter: 1
  episodes_total: 29
  experiment_id: a3942a9886f24694ab1b58ca8d1ab856
  hostname: gpu006
  info:
    apply_time_ms: 2.83
    dispatch_time_ms: 7.918
    learner:
      cur_lr: 0.0013406859943643212
      grad_gnorm: 27.28023910522461
      policy_entropy: 62.248863220214844
      policy_loss: -4.114556312561035
      var_gnorm: 27.074785232543945
      vf_explained_var: 0.8350237607955933
      vf_loss: 1.0790579319000244
    num_steps_sampled: 300000
    num_steps_trained: 300000
    wait_time_ms: 210.02
  iterations_since_restore: 30
  node_ip: 172.17.8.6
  num_metric_batches_dropped: 0
  pid: 13557
  policy_reward_mean: {}
  time_since_restore: 700.8982002735138
  time_this_iter_s: 25.075212955474854
  time_total_s: 700.8982002735138
  timestamp: 1594095456
  timesteps_since_restore: 300000
  timesteps_this_iter: 10000
  timesteps_total: 300000
  training_iteration: 30
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 17.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=13557], 700 s, 30 iter, 300000 ts, 1.12e+03 rew

agent-1: 156.0
agent-2: 131.0
agent-3: 112.0
agent-4: 131.0
agent-5: 176.0
agent-6: 145.0
agent-7: 143.0
agent-8: 135.0
agent-9: 113.0
agent-10: 124.0
Sum Reward: 1366.0
Avg Reward: 136.6
Min Reward: 112.0
Max Reward: 176.0
Gini Coefficient: 0.07481698389458272
20:20 Ratio: 1.4755555555555555
Max-min Ratio: 1.5714285714285714
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_00-17-59
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1681.0
  episode_reward_mean: 1131.6333333333334
  episode_reward_min: -1569.0
  episodes_this_iter: 1
  episodes_total: 30
  experiment_id: a3942a9886f24694ab1b58ca8d1ab856
  hostname: gpu006
  info:
    apply_time_ms: 2.801
    dispatch_time_ms: 6.613
    learner:
      cur_lr: 0.0013400199823081493
      grad_gnorm: 40.0
      policy_entropy: 46.121299743652344
      policy_loss: -4.19429874420166
      var_gnorm: 27.225664138793945
      vf_explained_var: 0.6778655052185059
      vf_loss: 213.1693115234375
    num_steps_sampled: 310000
    num_steps_trained: 310000
    wait_time_ms: 242.953
  iterations_since_restore: 31
  node_ip: 172.17.8.6
  num_metric_batches_dropped: 0
  pid: 13557
  policy_reward_mean: {}
  time_since_restore: 723.5251259803772
  time_this_iter_s: 22.626925706863403
  time_total_s: 723.5251259803772
  timestamp: 1594095479
  timesteps_since_restore: 310000
  timesteps_this_iter: 10000
  timesteps_total: 310000
  training_iteration: 31
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 17.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=13557], 723 s, 31 iter, 310000 ts, 1.13e+03 rew

agent-1: 78.0
agent-2: 119.0
agent-3: 99.0
agent-4: 102.0
agent-5: 148.0
agent-6: 147.0
agent-7: 128.0
agent-8: 120.0
agent-9: 135.0
agent-10: 96.0
Sum Reward: 1172.0
Avg Reward: 117.2
Min Reward: 78.0
Max Reward: 148.0
Gini Coefficient: 0.10631399317406143
20:20 Ratio: 1.6954022988505748
Max-min Ratio: 1.8974358974358974
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_00-18-23
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1681.0
  episode_reward_mean: 1132.9354838709678
  episode_reward_min: -1569.0
  episodes_this_iter: 1
  episodes_total: 31
  experiment_id: a3942a9886f24694ab1b58ca8d1ab856
  hostname: gpu006
  info:
    apply_time_ms: 2.666
    dispatch_time_ms: 8.414
    learner:
      cur_lr: 0.0013393539702519774
      grad_gnorm: 40.000003814697266
      policy_entropy: 37.7580451965332
      policy_loss: 23.695846557617188
      var_gnorm: 27.463451385498047
      vf_explained_var: 0.1796426773071289
      vf_loss: 81.46858215332031
    num_steps_sampled: 320000
    num_steps_trained: 320000
    wait_time_ms: 229.596
  iterations_since_restore: 32
  node_ip: 172.17.8.6
  num_metric_batches_dropped: 0
  pid: 13557
  policy_reward_mean: {}
  time_since_restore: 747.8697733879089
  time_this_iter_s: 24.34464740753174
  time_total_s: 747.8697733879089
  timestamp: 1594095503
  timesteps_since_restore: 320000
  timesteps_this_iter: 10000
  timesteps_total: 320000
  training_iteration: 32
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 17.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=13557], 747 s, 32 iter, 320000 ts, 1.13e+03 rew

agent-1: 182.0
agent-2: 204.0
agent-3: 188.0
agent-4: 165.0
agent-5: 159.0
agent-6: 171.0
agent-7: 208.0
agent-8: 186.0
agent-9: 191.0
agent-10: 182.0
Sum Reward: 1836.0
Avg Reward: 183.6
Min Reward: 159.0
Max Reward: 208.0
Gini Coefficient: 0.04553376906318083
20:20 Ratio: 1.271604938271605
Max-min Ratio: 1.3081761006289307
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_00-18-45
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1836.0
  episode_reward_mean: 1154.90625
  episode_reward_min: -1569.0
  episodes_this_iter: 1
  episodes_total: 32
  experiment_id: a3942a9886f24694ab1b58ca8d1ab856
  hostname: gpu006
  info:
    apply_time_ms: 2.724
    dispatch_time_ms: 6.368
    learner:
      cur_lr: 0.0013386879581958055
      grad_gnorm: 40.0000114440918
      policy_entropy: 46.9644889831543
      policy_loss: 3.144474744796753
      var_gnorm: 27.53497314453125
      vf_explained_var: 0.19893622398376465
      vf_loss: 176.81312561035156
    num_steps_sampled: 330000
    num_steps_trained: 330000
    wait_time_ms: 229.308
  iterations_since_restore: 33
  node_ip: 172.17.8.6
  num_metric_batches_dropped: 0
  pid: 13557
  policy_reward_mean: {}
  time_since_restore: 769.8916172981262
  time_this_iter_s: 22.021843910217285
  time_total_s: 769.8916172981262
  timestamp: 1594095525
  timesteps_since_restore: 330000
  timesteps_this_iter: 10000
  timesteps_total: 330000
  training_iteration: 33
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 17.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=13557], 769 s, 33 iter, 330000 ts, 1.15e+03 rew

agent-1: 133.0
agent-2: 139.0
agent-3: 114.0
agent-4: 138.0
agent-5: 116.0
agent-6: 127.0
agent-7: 124.0
agent-8: 99.0
agent-9: 96.0
agent-10: 136.0
Sum Reward: 1222.0
Avg Reward: 122.2
Min Reward: 96.0
Max Reward: 139.0
Gini Coefficient: 0.06743044189852701
20:20 Ratio: 1.4205128205128206
Max-min Ratio: 1.4479166666666667
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_00-19-11
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1836.0
  episode_reward_mean: 1156.939393939394
  episode_reward_min: -1569.0
  episodes_this_iter: 1
  episodes_total: 33
  experiment_id: a3942a9886f24694ab1b58ca8d1ab856
  hostname: gpu006
  info:
    apply_time_ms: 2.601
    dispatch_time_ms: 6.648
    learner:
      cur_lr: 0.0013380219461396337
      grad_gnorm: 28.760719299316406
      policy_entropy: 73.31809997558594
      policy_loss: -3.319699287414551
      var_gnorm: 27.802335739135742
      vf_explained_var: 0.68984055519104
      vf_loss: 1.7998615503311157
    num_steps_sampled: 340000
    num_steps_trained: 340000
    wait_time_ms: 212.865
  iterations_since_restore: 34
  node_ip: 172.17.8.6
  num_metric_batches_dropped: 0
  pid: 13557
  policy_reward_mean: {}
  time_since_restore: 795.6597781181335
  time_this_iter_s: 25.768160820007324
  time_total_s: 795.6597781181335
  timestamp: 1594095551
  timesteps_since_restore: 340000
  timesteps_this_iter: 10000
  timesteps_total: 340000
  training_iteration: 34
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 18.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=13557], 795 s, 34 iter, 340000 ts, 1.16e+03 rew

agent-1: 90.0
agent-2: 105.0
agent-3: 128.0
agent-4: 117.0
agent-5: 121.0
agent-6: 126.0
agent-7: 101.0
agent-8: 156.0
agent-9: 121.0
agent-10: 126.0
Sum Reward: 1191.0
Avg Reward: 119.1
Min Reward: 90.0
Max Reward: 156.0
Gini Coefficient: 0.07682619647355164
20:20 Ratio: 1.486910994764398
Max-min Ratio: 1.7333333333333334
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_00-19-33
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1836.0
  episode_reward_mean: 1157.9411764705883
  episode_reward_min: -1569.0
  episodes_this_iter: 1
  episodes_total: 34
  experiment_id: a3942a9886f24694ab1b58ca8d1ab856
  hostname: gpu006
  info:
    apply_time_ms: 3.519
    dispatch_time_ms: 7.02
    learner:
      cur_lr: 0.0013373560504987836
      grad_gnorm: 40.0
      policy_entropy: 45.98379135131836
      policy_loss: 50.86378479003906
      var_gnorm: 27.949691772460938
      vf_explained_var: 0.31938380002975464
      vf_loss: 252.75027465820312
    num_steps_sampled: 350000
    num_steps_trained: 350000
    wait_time_ms: 240.775
  iterations_since_restore: 35
  node_ip: 172.17.8.6
  num_metric_batches_dropped: 0
  pid: 13557
  policy_reward_mean: {}
  time_since_restore: 818.0607740879059
  time_this_iter_s: 22.40099596977234
  time_total_s: 818.0607740879059
  timestamp: 1594095573
  timesteps_since_restore: 350000
  timesteps_this_iter: 10000
  timesteps_total: 350000
  training_iteration: 35
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 18.3/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=13557], 818 s, 35 iter, 350000 ts, 1.16e+03 rew

agent-1: 107.0
agent-2: 116.0
agent-3: 110.0
agent-4: 106.0
agent-5: 118.0
agent-6: 103.0
agent-7: 116.0
agent-8: 105.0
agent-9: 97.0
agent-10: 105.0
Sum Reward: 1083.0
Avg Reward: 108.3
Min Reward: 97.0
Max Reward: 118.0
Gini Coefficient: 0.032409972299168976
20:20 Ratio: 1.17
Max-min Ratio: 1.2164948453608246
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_00-19-59
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1836.0
  episode_reward_mean: 1155.8
  episode_reward_min: -1569.0
  episodes_this_iter: 1
  episodes_total: 35
  experiment_id: a3942a9886f24694ab1b58ca8d1ab856
  hostname: gpu006
  info:
    apply_time_ms: 2.819
    dispatch_time_ms: 6.269
    learner:
      cur_lr: 0.0013366900384426117
      grad_gnorm: 40.00001525878906
      policy_entropy: 46.564430236816406
      policy_loss: -24.466716766357422
      var_gnorm: 28.248735427856445
      vf_explained_var: 0.5570969581604004
      vf_loss: 119.02314758300781
    num_steps_sampled: 360000
    num_steps_trained: 360000
    wait_time_ms: 206.675
  iterations_since_restore: 36
  node_ip: 172.17.8.6
  num_metric_batches_dropped: 0
  pid: 13557
  policy_reward_mean: {}
  time_since_restore: 843.3122391700745
  time_this_iter_s: 25.25146508216858
  time_total_s: 843.3122391700745
  timestamp: 1594095599
  timesteps_since_restore: 360000
  timesteps_this_iter: 10000
  timesteps_total: 360000
  training_iteration: 36
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 18.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=13557], 843 s, 36 iter, 360000 ts, 1.16e+03 rew

agent-1: 137.0
agent-2: 111.0
agent-3: 106.0
agent-4: 114.0
agent-5: 109.0
agent-6: 107.0
agent-7: 121.0
agent-8: 155.0
agent-9: 106.0
agent-10: 138.0
Sum Reward: 1204.0
Avg Reward: 120.4
Min Reward: 106.0
Max Reward: 155.0
Gini Coefficient: 0.07093023255813953
20:20 Ratio: 1.3820754716981132
Max-min Ratio: 1.4622641509433962
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_00-20-20
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1836.0
  episode_reward_mean: 1157.138888888889
  episode_reward_min: -1569.0
  episodes_this_iter: 1
  episodes_total: 36
  experiment_id: a3942a9886f24694ab1b58ca8d1ab856
  hostname: gpu006
  info:
    apply_time_ms: 3.142
    dispatch_time_ms: 8.217
    learner:
      cur_lr: 0.0013360240263864398
      grad_gnorm: 39.999996185302734
      policy_entropy: 62.065006256103516
      policy_loss: -10.805449485778809
      var_gnorm: 28.277118682861328
      vf_explained_var: -0.35124802589416504
      vf_loss: 51.9559440612793
    num_steps_sampled: 370000
    num_steps_trained: 370000
    wait_time_ms: 226.006
  iterations_since_restore: 37
  node_ip: 172.17.8.6
  num_metric_batches_dropped: 0
  pid: 13557
  policy_reward_mean: {}
  time_since_restore: 864.9077596664429
  time_this_iter_s: 21.595520496368408
  time_total_s: 864.9077596664429
  timestamp: 1594095620
  timesteps_since_restore: 370000
  timesteps_this_iter: 10000
  timesteps_total: 370000
  training_iteration: 37
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 18.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=13557], 864 s, 37 iter, 370000 ts, 1.16e+03 rew

agent-1: 152.0
agent-2: 164.0
agent-3: 176.0
agent-4: 183.0
agent-5: 158.0
agent-6: 178.0
agent-7: 149.0
agent-8: 147.0
agent-9: 169.0
agent-10: 175.0
Sum Reward: 1651.0
Avg Reward: 165.1
Min Reward: 147.0
Max Reward: 183.0
Gini Coefficient: 0.042580254391278015
20:20 Ratio: 1.2195945945945945
Max-min Ratio: 1.2448979591836735
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_00-20-44
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1836.0
  episode_reward_mean: 1170.4864864864865
  episode_reward_min: -1569.0
  episodes_this_iter: 1
  episodes_total: 37
  experiment_id: a3942a9886f24694ab1b58ca8d1ab856
  hostname: gpu006
  info:
    apply_time_ms: 2.762
    dispatch_time_ms: 6.913
    learner:
      cur_lr: 0.001335358014330268
      grad_gnorm: 40.00000762939453
      policy_entropy: 45.90972900390625
      policy_loss: 9.322419166564941
      var_gnorm: 28.388412475585938
      vf_explained_var: 0.21665501594543457
      vf_loss: 113.12201690673828
    num_steps_sampled: 380000
    num_steps_trained: 380000
    wait_time_ms: 197.691
  iterations_since_restore: 38
  node_ip: 172.17.8.6
  num_metric_batches_dropped: 0
  pid: 13557
  policy_reward_mean: {}
  time_since_restore: 888.2589676380157
  time_this_iter_s: 23.351207971572876
  time_total_s: 888.2589676380157
  timestamp: 1594095644
  timesteps_since_restore: 380000
  timesteps_this_iter: 10000
  timesteps_total: 380000
  training_iteration: 38
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 19.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=13557], 888 s, 38 iter, 380000 ts, 1.17e+03 rew

agent-1: 160.0
agent-2: 194.0
agent-3: 118.0
agent-4: 138.0
agent-5: 169.0
agent-6: 148.0
agent-7: 160.0
agent-8: 146.0
agent-9: 169.0
agent-10: 161.0
Sum Reward: 1563.0
Avg Reward: 156.3
Min Reward: 118.0
Max Reward: 194.0
Gini Coefficient: 0.06749840051183621
20:20 Ratio: 1.41796875
Max-min Ratio: 1.6440677966101696
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_00-21-06
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1836.0
  episode_reward_mean: 1180.8157894736842
  episode_reward_min: -1569.0
  episodes_this_iter: 1
  episodes_total: 38
  experiment_id: a3942a9886f24694ab1b58ca8d1ab856
  hostname: gpu006
  info:
    apply_time_ms: 2.882
    dispatch_time_ms: 6.632
    learner:
      cur_lr: 0.001334692002274096
      grad_gnorm: 40.00002670288086
      policy_entropy: 24.13532066345215
      policy_loss: 14.719079971313477
      var_gnorm: 28.50757598876953
      vf_explained_var: 0.6049708127975464
      vf_loss: 155.48414611816406
    num_steps_sampled: 390000
    num_steps_trained: 390000
    wait_time_ms: 235.024
  iterations_since_restore: 39
  node_ip: 172.17.8.6
  num_metric_batches_dropped: 0
  pid: 13557
  policy_reward_mean: {}
  time_since_restore: 910.3156909942627
  time_this_iter_s: 22.05672335624695
  time_total_s: 910.3156909942627
  timestamp: 1594095666
  timesteps_since_restore: 390000
  timesteps_this_iter: 10000
  timesteps_total: 390000
  training_iteration: 39
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 19.3/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=13557], 910 s, 39 iter, 390000 ts, 1.18e+03 rew

agent-1: 138.0
agent-2: 143.0
agent-3: 157.0
agent-4: 148.0
agent-5: 140.0
agent-6: 144.0
agent-7: 139.0
agent-8: 129.0
agent-9: 135.0
agent-10: 134.0
Sum Reward: 1407.0
Avg Reward: 140.7
Min Reward: 129.0
Max Reward: 157.0
Gini Coefficient: 0.029211087420042643
20:20 Ratio: 1.1596958174904943
Max-min Ratio: 1.2170542635658914
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_00-21-31
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1836.0
  episode_reward_mean: 1186.6153846153845
  episode_reward_min: -1569.0
  episodes_this_iter: 1
  episodes_total: 39
  experiment_id: a3942a9886f24694ab1b58ca8d1ab856
  hostname: gpu006
  info:
    apply_time_ms: 2.761
    dispatch_time_ms: 7.459
    learner:
      cur_lr: 0.0013340259902179241
      grad_gnorm: 4.853315830230713
      policy_entropy: 70.15845489501953
      policy_loss: 1.115338683128357
      var_gnorm: 28.781864166259766
      vf_explained_var: 0.8665623068809509
      vf_loss: 0.5703384280204773
    num_steps_sampled: 400000
    num_steps_trained: 400000
    wait_time_ms: 221.964
  iterations_since_restore: 40
  node_ip: 172.17.8.6
  num_metric_batches_dropped: 0
  pid: 13557
  policy_reward_mean: {}
  time_since_restore: 935.7898662090302
  time_this_iter_s: 25.474175214767456
  time_total_s: 935.7898662090302
  timestamp: 1594095691
  timesteps_since_restore: 400000
  timesteps_this_iter: 10000
  timesteps_total: 400000
  training_iteration: 40
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 19.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=13557], 935 s, 40 iter, 400000 ts, 1.19e+03 rew

agent-1: 122.0
agent-2: 102.0
agent-3: 119.0
agent-4: 116.0
agent-5: 112.0
agent-6: 85.0
agent-7: 122.0
agent-8: 93.0
agent-9: 124.0
agent-10: 136.0
Sum Reward: 1131.0
Avg Reward: 113.1
Min Reward: 85.0
Max Reward: 136.0
Gini Coefficient: 0.07152961980548188
20:20 Ratio: 1.4606741573033708
Max-min Ratio: 1.6
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_00-21-54
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1836.0
  episode_reward_mean: 1185.225
  episode_reward_min: -1569.0
  episodes_this_iter: 1
  episodes_total: 40
  experiment_id: a3942a9886f24694ab1b58ca8d1ab856
  hostname: gpu006
  info:
    apply_time_ms: 2.583
    dispatch_time_ms: 5.815
    learner:
      cur_lr: 0.0013333599781617522
      grad_gnorm: 40.0
      policy_entropy: 30.181652069091797
      policy_loss: -7.471974849700928
      var_gnorm: 28.81304931640625
      vf_explained_var: 0.9009358882904053
      vf_loss: 98.8550033569336
    num_steps_sampled: 410000
    num_steps_trained: 410000
    wait_time_ms: 232.518
  iterations_since_restore: 41
  node_ip: 172.17.8.6
  num_metric_batches_dropped: 0
  pid: 13557
  policy_reward_mean: {}
  time_since_restore: 958.4351789951324
  time_this_iter_s: 22.645312786102295
  time_total_s: 958.4351789951324
  timestamp: 1594095714
  timesteps_since_restore: 410000
  timesteps_this_iter: 10000
  timesteps_total: 410000
  training_iteration: 41
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 19.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=13557], 958 s, 41 iter, 410000 ts, 1.19e+03 rew

agent-1: 135.0
agent-2: 123.0
agent-3: 149.0
agent-4: 115.0
agent-5: 124.0
agent-6: 121.0
agent-7: 111.0
agent-8: 102.0
agent-9: 115.0
agent-10: 122.0
Sum Reward: 1217.0
Avg Reward: 121.7
Min Reward: 102.0
Max Reward: 149.0
Gini Coefficient: 0.054313886606409206
20:20 Ratio: 1.3333333333333333
Max-min Ratio: 1.4607843137254901
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_00-22-19
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1836.0
  episode_reward_mean: 1186.0
  episode_reward_min: -1569.0
  episodes_this_iter: 1
  episodes_total: 41
  experiment_id: a3942a9886f24694ab1b58ca8d1ab856
  hostname: gpu006
  info:
    apply_time_ms: 2.71
    dispatch_time_ms: 7.314
    learner:
      cur_lr: 0.0013326939661055803
      grad_gnorm: 40.0
      policy_entropy: 20.620155334472656
      policy_loss: 9.509963989257812
      var_gnorm: 29.114145278930664
      vf_explained_var: 0.16131269931793213
      vf_loss: 96.44613647460938
    num_steps_sampled: 420000
    num_steps_trained: 420000
    wait_time_ms: 215.518
  iterations_since_restore: 42
  node_ip: 172.17.8.6
  num_metric_batches_dropped: 0
  pid: 13557
  policy_reward_mean: {}
  time_since_restore: 983.2105085849762
  time_this_iter_s: 24.77532958984375
  time_total_s: 983.2105085849762
  timestamp: 1594095739
  timesteps_since_restore: 420000
  timesteps_this_iter: 10000
  timesteps_total: 420000
  training_iteration: 42
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 20.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=13557], 983 s, 42 iter, 420000 ts, 1.19e+03 rew

agent-1: 168.0
agent-2: 155.0
agent-3: 124.0
agent-4: 126.0
agent-5: 147.0
agent-6: 113.0
agent-7: 164.0
agent-8: 120.0
agent-9: 159.0
agent-10: 102.0
Sum Reward: 1378.0
Avg Reward: 137.8
Min Reward: 102.0
Max Reward: 168.0
Gini Coefficient: 0.09143686502177069
20:20 Ratio: 1.544186046511628
Max-min Ratio: 1.6470588235294117
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_00-22-42
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1836.0
  episode_reward_mean: 1190.5714285714287
  episode_reward_min: -1569.0
  episodes_this_iter: 1
  episodes_total: 42
  experiment_id: a3942a9886f24694ab1b58ca8d1ab856
  hostname: gpu006
  info:
    apply_time_ms: 2.718
    dispatch_time_ms: 7.069
    learner:
      cur_lr: 0.0013320279540494084
      grad_gnorm: 40.0
      policy_entropy: 57.87262725830078
      policy_loss: -10.365107536315918
      var_gnorm: 29.241029739379883
      vf_explained_var: -0.6773343086242676
      vf_loss: 15.513712882995605
    num_steps_sampled: 430000
    num_steps_trained: 430000
    wait_time_ms: 248.681
  iterations_since_restore: 43
  node_ip: 172.17.8.6
  num_metric_batches_dropped: 0
  pid: 13557
  policy_reward_mean: {}
  time_since_restore: 1006.4789237976074
  time_this_iter_s: 23.268415212631226
  time_total_s: 1006.4789237976074
  timestamp: 1594095762
  timesteps_since_restore: 430000
  timesteps_this_iter: 10000
  timesteps_total: 430000
  training_iteration: 43
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 20.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=13557], 1006 s, 43 iter, 430000 ts, 1.19e+03 rew

agent-1: 96.0
agent-2: 101.0
agent-3: 110.0
agent-4: 101.0
agent-5: 98.0
agent-6: 90.0
agent-7: 85.0
agent-8: 117.0
agent-9: 110.0
agent-10: 102.0
Sum Reward: 1010.0
Avg Reward: 101.0
Min Reward: 85.0
Max Reward: 117.0
Gini Coefficient: 0.0504950495049505
20:20 Ratio: 1.2971428571428572
Max-min Ratio: 1.3764705882352941
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_00-23-07
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1836.0
  episode_reward_mean: 1186.3720930232557
  episode_reward_min: -1569.0
  episodes_this_iter: 1
  episodes_total: 43
  experiment_id: a3942a9886f24694ab1b58ca8d1ab856
  hostname: gpu006
  info:
    apply_time_ms: 2.795
    dispatch_time_ms: 6.831
    learner:
      cur_lr: 0.0013313619419932365
      grad_gnorm: 32.107635498046875
      policy_entropy: 71.77154541015625
      policy_loss: -4.161640167236328
      var_gnorm: 29.404788970947266
      vf_explained_var: -0.1327883005142212
      vf_loss: 0.3384593725204468
    num_steps_sampled: 440000
    num_steps_trained: 440000
    wait_time_ms: 207.961
  iterations_since_restore: 44
  node_ip: 172.17.8.6
  num_metric_batches_dropped: 0
  pid: 13557
  policy_reward_mean: {}
  time_since_restore: 1031.5647900104523
  time_this_iter_s: 25.08586621284485
  time_total_s: 1031.5647900104523
  timestamp: 1594095787
  timesteps_since_restore: 440000
  timesteps_this_iter: 10000
  timesteps_total: 440000
  training_iteration: 44
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 20.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=13557], 1031 s, 44 iter, 440000 ts, 1.19e+03 rew

agent-1: 141.0
agent-2: 153.0
agent-3: 149.0
agent-4: 110.0
agent-5: 154.0
agent-6: 152.0
agent-7: 120.0
agent-8: 133.0
agent-9: 138.0
agent-10: 137.0
Sum Reward: 1387.0
Avg Reward: 138.7
Min Reward: 110.0
Max Reward: 154.0
Gini Coefficient: 0.05486661860129777
20:20 Ratio: 1.3347826086956522
Max-min Ratio: 1.4
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_00-23-29
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1836.0
  episode_reward_mean: 1190.9318181818182
  episode_reward_min: -1569.0
  episodes_this_iter: 1
  episodes_total: 44
  experiment_id: a3942a9886f24694ab1b58ca8d1ab856
  hostname: gpu006
  info:
    apply_time_ms: 2.65
    dispatch_time_ms: 7.033
    learner:
      cur_lr: 0.0013306960463523865
      grad_gnorm: 40.00000762939453
      policy_entropy: 27.82380485534668
      policy_loss: 16.66411781311035
      var_gnorm: 29.540037155151367
      vf_explained_var: 0.14179110527038574
      vf_loss: 86.10626983642578
    num_steps_sampled: 450000
    num_steps_trained: 450000
    wait_time_ms: 224.573
  iterations_since_restore: 45
  node_ip: 172.17.8.6
  num_metric_batches_dropped: 0
  pid: 13557
  policy_reward_mean: {}
  time_since_restore: 1053.7327828407288
  time_this_iter_s: 22.16799283027649
  time_total_s: 1053.7327828407288
  timestamp: 1594095809
  timesteps_since_restore: 450000
  timesteps_this_iter: 10000
  timesteps_total: 450000
  training_iteration: 45
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 20.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=13557], 1053 s, 45 iter, 450000 ts, 1.19e+03 rew

agent-1: 138.0
agent-2: 167.0
agent-3: 138.0
agent-4: 148.0
agent-5: 158.0
agent-6: 170.0
agent-7: 145.0
agent-8: 155.0
agent-9: 171.0
agent-10: 168.0
Sum Reward: 1558.0
Avg Reward: 155.8
Min Reward: 138.0
Max Reward: 171.0
Gini Coefficient: 0.04467265725288832
20:20 Ratio: 1.2355072463768115
Max-min Ratio: 1.2391304347826086
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_00-23-54
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1836.0
  episode_reward_mean: 1199.088888888889
  episode_reward_min: -1569.0
  episodes_this_iter: 1
  episodes_total: 45
  experiment_id: a3942a9886f24694ab1b58ca8d1ab856
  hostname: gpu006
  info:
    apply_time_ms: 2.557
    dispatch_time_ms: 7.361
    learner:
      cur_lr: 0.0013300300342962146
      grad_gnorm: 10.633246421813965
      policy_entropy: 79.3111343383789
      policy_loss: -2.6545543670654297
      var_gnorm: 29.793010711669922
      vf_explained_var: -0.3326592445373535
      vf_loss: 0.11837060749530792
    num_steps_sampled: 460000
    num_steps_trained: 460000
    wait_time_ms: 206.891
  iterations_since_restore: 46
  node_ip: 172.17.8.6
  num_metric_batches_dropped: 0
  pid: 13557
  policy_reward_mean: {}
  time_since_restore: 1077.9458675384521
  time_this_iter_s: 24.21308469772339
  time_total_s: 1077.9458675384521
  timestamp: 1594095834
  timesteps_since_restore: 460000
  timesteps_this_iter: 10000
  timesteps_total: 460000
  training_iteration: 46
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 21.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=13557], 1077 s, 46 iter, 460000 ts, 1.2e+03 rew

agent-1: 140.0
agent-2: 163.0
agent-3: 137.0
agent-4: 144.0
agent-5: 153.0
agent-6: 152.0
agent-7: 159.0
agent-8: 160.0
agent-9: 141.0
agent-10: 154.0
Sum Reward: 1503.0
Avg Reward: 150.3
Min Reward: 137.0
Max Reward: 163.0
Gini Coefficient: 0.03293413173652695
20:20 Ratio: 1.1660649819494584
Max-min Ratio: 1.1897810218978102
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_00-24-17
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1836.0
  episode_reward_mean: 1205.695652173913
  episode_reward_min: -1569.0
  episodes_this_iter: 1
  episodes_total: 46
  experiment_id: a3942a9886f24694ab1b58ca8d1ab856
  hostname: gpu006
  info:
    apply_time_ms: 3.163
    dispatch_time_ms: 6.807
    learner:
      cur_lr: 0.0013293640222400427
      grad_gnorm: 39.99999237060547
      policy_entropy: 28.807336807250977
      policy_loss: 5.824412822723389
      var_gnorm: 29.8958740234375
      vf_explained_var: -0.18232762813568115
      vf_loss: 121.1512680053711
    num_steps_sampled: 470000
    num_steps_trained: 470000
    wait_time_ms: 228.646
  iterations_since_restore: 47
  node_ip: 172.17.8.6
  num_metric_batches_dropped: 0
  pid: 13557
  policy_reward_mean: {}
  time_since_restore: 1100.960388660431
  time_this_iter_s: 23.01452112197876
  time_total_s: 1100.960388660431
  timestamp: 1594095857
  timesteps_since_restore: 470000
  timesteps_this_iter: 10000
  timesteps_total: 470000
  training_iteration: 47
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 21.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=13557], 1100 s, 47 iter, 470000 ts, 1.21e+03 rew

agent-1: 100.0
agent-2: 91.0
agent-3: 136.0
agent-4: 121.0
agent-5: 122.0
agent-6: 114.0
agent-7: 140.0
agent-8: 114.0
agent-9: 112.0
agent-10: 115.0
Sum Reward: 1165.0
Avg Reward: 116.5
Min Reward: 91.0
Max Reward: 140.0
Gini Coefficient: 0.06566523605150215
20:20 Ratio: 1.4450261780104712
Max-min Ratio: 1.5384615384615385
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_00-24-42
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1836.0
  episode_reward_mean: 1204.8297872340424
  episode_reward_min: -1569.0
  episodes_this_iter: 1
  episodes_total: 47
  experiment_id: a3942a9886f24694ab1b58ca8d1ab856
  hostname: gpu006
  info:
    apply_time_ms: 2.602
    dispatch_time_ms: 6.461
    learner:
      cur_lr: 0.0013286980101838708
      grad_gnorm: 40.0
      policy_entropy: 24.52865219116211
      policy_loss: 8.948522567749023
      var_gnorm: 30.14764976501465
      vf_explained_var: 0.4034368395805359
      vf_loss: 69.99493408203125
    num_steps_sampled: 480000
    num_steps_trained: 480000
    wait_time_ms: 213.184
  iterations_since_restore: 48
  node_ip: 172.17.8.6
  num_metric_batches_dropped: 0
  pid: 13557
  policy_reward_mean: {}
  time_since_restore: 1126.3539423942566
  time_this_iter_s: 25.393553733825684
  time_total_s: 1126.3539423942566
  timestamp: 1594095882
  timesteps_since_restore: 480000
  timesteps_this_iter: 10000
  timesteps_total: 480000
  training_iteration: 48
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 21.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=13557], 1126 s, 48 iter, 480000 ts, 1.2e+03 rew

agent-1: 123.0
agent-2: 95.0
agent-3: 114.0
agent-4: 111.0
agent-5: 121.0
agent-6: 122.0
agent-7: 136.0
agent-8: 150.0
agent-9: 148.0
agent-10: 117.0
Sum Reward: 1237.0
Avg Reward: 123.7
Min Reward: 95.0
Max Reward: 150.0
Gini Coefficient: 0.0713823767178658
20:20 Ratio: 1.4466019417475728
Max-min Ratio: 1.5789473684210527
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_00-25-05
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1836.0
  episode_reward_mean: 1205.5
  episode_reward_min: -1569.0
  episodes_this_iter: 1
  episodes_total: 48
  experiment_id: a3942a9886f24694ab1b58ca8d1ab856
  hostname: gpu006
  info:
    apply_time_ms: 2.703
    dispatch_time_ms: 6.142
    learner:
      cur_lr: 0.001328031998127699
      grad_gnorm: 40.0
      policy_entropy: 25.851852416992188
      policy_loss: 40.88095474243164
      var_gnorm: 30.27593421936035
      vf_explained_var: 0.4651961326599121
      vf_loss: 183.56101989746094
    num_steps_sampled: 490000
    num_steps_trained: 490000
    wait_time_ms: 222.577
  iterations_since_restore: 49
  node_ip: 172.17.8.6
  num_metric_batches_dropped: 0
  pid: 13557
  policy_reward_mean: {}
  time_since_restore: 1149.171463251114
  time_this_iter_s: 22.8175208568573
  time_total_s: 1149.171463251114
  timestamp: 1594095905
  timesteps_since_restore: 490000
  timesteps_this_iter: 10000
  timesteps_total: 490000
  training_iteration: 49
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 21.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=13557], 1149 s, 49 iter, 490000 ts, 1.21e+03 rew

agent-1: 135.0
agent-2: 104.0
agent-3: 121.0
agent-4: 116.0
agent-5: 101.0
agent-6: 126.0
agent-7: 106.0
agent-8: 129.0
agent-9: 121.0
agent-10: 109.0
Sum Reward: 1168.0
Avg Reward: 116.8
Min Reward: 101.0
Max Reward: 135.0
Gini Coefficient: 0.05325342465753425
20:20 Ratio: 1.2878048780487805
Max-min Ratio: 1.3366336633663367
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_00-25-30
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1836.0
  episode_reward_mean: 1204.734693877551
  episode_reward_min: -1569.0
  episodes_this_iter: 1
  episodes_total: 49
  experiment_id: a3942a9886f24694ab1b58ca8d1ab856
  hostname: gpu006
  info:
    apply_time_ms: 3.923
    dispatch_time_ms: 6.824
    learner:
      cur_lr: 0.001327365986071527
      grad_gnorm: 6.0032572746276855
      policy_entropy: 74.13549041748047
      policy_loss: -0.3286411166191101
      var_gnorm: 30.399612426757812
      vf_explained_var: -0.47557616233825684
      vf_loss: 0.16682708263397217
    num_steps_sampled: 500000
    num_steps_trained: 500000
    wait_time_ms: 218.063
  iterations_since_restore: 50
  node_ip: 172.17.8.6
  num_metric_batches_dropped: 0
  pid: 13557
  policy_reward_mean: {}
  time_since_restore: 1174.1091756820679
  time_this_iter_s: 24.93771243095398
  time_total_s: 1174.1091756820679
  timestamp: 1594095930
  timesteps_since_restore: 500000
  timesteps_this_iter: 10000
  timesteps_total: 500000
  training_iteration: 50
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 21.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=13557], 1174 s, 50 iter, 500000 ts, 1.2e+03 rew

agent-1: 154.0
agent-2: 154.0
agent-3: 132.0
agent-4: 148.0
agent-5: 148.0
agent-6: 147.0
agent-7: 138.0
agent-8: 137.0
agent-9: 146.0
agent-10: 178.0
Sum Reward: 1482.0
Avg Reward: 148.2
Min Reward: 132.0
Max Reward: 178.0
Gini Coefficient: 0.04183535762483131
20:20 Ratio: 1.2342007434944238
Max-min Ratio: 1.3484848484848484
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_00-25-53
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1836.0
  episode_reward_mean: 1210.28
  episode_reward_min: -1569.0
  episodes_this_iter: 1
  episodes_total: 50
  experiment_id: a3942a9886f24694ab1b58ca8d1ab856
  hostname: gpu006
  info:
    apply_time_ms: 2.635
    dispatch_time_ms: 6.498
    learner:
      cur_lr: 0.0013266999740153551
      grad_gnorm: 40.000003814697266
      policy_entropy: 61.16096115112305
      policy_loss: 23.201377868652344
      var_gnorm: 30.570539474487305
      vf_explained_var: 0.8196994662284851
      vf_loss: 55.996482849121094
    num_steps_sampled: 510000
    num_steps_trained: 510000
    wait_time_ms: 249.362
  iterations_since_restore: 51
  node_ip: 172.17.8.6
  num_metric_batches_dropped: 0
  pid: 13557
  policy_reward_mean: {}
  time_since_restore: 1197.1754076480865
  time_this_iter_s: 23.066231966018677
  time_total_s: 1197.1754076480865
  timestamp: 1594095953
  timesteps_since_restore: 510000
  timesteps_this_iter: 10000
  timesteps_total: 510000
  training_iteration: 51
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 22.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=13557], 1197 s, 51 iter, 510000 ts, 1.21e+03 rew

agent-1: 117.0
agent-2: 102.0
agent-3: 102.0
agent-4: 99.0
agent-5: 118.0
agent-6: 107.0
agent-7: 111.0
agent-8: 126.0
agent-9: 131.0
agent-10: 120.0
Sum Reward: 1133.0
Avg Reward: 113.3
Min Reward: 99.0
Max Reward: 131.0
Gini Coefficient: 0.05163283318623124
20:20 Ratio: 1.2786069651741294
Max-min Ratio: 1.3232323232323233
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_00-26-19
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1836.0
  episode_reward_mean: 1208.764705882353
  episode_reward_min: -1569.0
  episodes_this_iter: 1
  episodes_total: 51
  experiment_id: a3942a9886f24694ab1b58ca8d1ab856
  hostname: gpu006
  info:
    apply_time_ms: 2.629
    dispatch_time_ms: 7.382
    learner:
      cur_lr: 0.0013260339619591832
      grad_gnorm: 19.76355743408203
      policy_entropy: 30.312471389770508
      policy_loss: -4.562206268310547
      var_gnorm: 30.727745056152344
      vf_explained_var: 0.9139004945755005
      vf_loss: 3.204956531524658
    num_steps_sampled: 520000
    num_steps_trained: 520000
    wait_time_ms: 225.145
  iterations_since_restore: 52
  node_ip: 172.17.8.6
  num_metric_batches_dropped: 0
  pid: 13557
  policy_reward_mean: {}
  time_since_restore: 1222.7026734352112
  time_this_iter_s: 25.527265787124634
  time_total_s: 1222.7026734352112
  timestamp: 1594095979
  timesteps_since_restore: 520000
  timesteps_this_iter: 10000
  timesteps_total: 520000
  training_iteration: 52
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 22.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=13557], 1222 s, 52 iter, 520000 ts, 1.21e+03 rew

agent-1: 144.0
agent-2: 118.0
agent-3: 120.0
agent-4: 122.0
agent-5: 113.0
agent-6: 88.0
agent-7: 86.0
agent-8: 110.0
agent-9: 86.0
agent-10: 117.0
Sum Reward: 1104.0
Avg Reward: 110.4
Min Reward: 86.0
Max Reward: 144.0
Gini Coefficient: 0.08713768115942029
20:20 Ratio: 1.5465116279069768
Max-min Ratio: 1.6744186046511629
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_00-26-42
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1836.0
  episode_reward_mean: 1206.75
  episode_reward_min: -1569.0
  episodes_this_iter: 1
  episodes_total: 52
  experiment_id: a3942a9886f24694ab1b58ca8d1ab856
  hostname: gpu006
  info:
    apply_time_ms: 2.83
    dispatch_time_ms: 6.452
    learner:
      cur_lr: 0.0013253679499030113
      grad_gnorm: 40.0
      policy_entropy: 24.35515785217285
      policy_loss: -7.4375
      var_gnorm: 30.84968376159668
      vf_explained_var: 0.9098079204559326
      vf_loss: 101.04120635986328
    num_steps_sampled: 530000
    num_steps_trained: 530000
    wait_time_ms: 246.077
  iterations_since_restore: 53
  node_ip: 172.17.8.6
  num_metric_batches_dropped: 0
  pid: 13557
  policy_reward_mean: {}
  time_since_restore: 1246.2298836708069
  time_this_iter_s: 23.527210235595703
  time_total_s: 1246.2298836708069
  timestamp: 1594096002
  timesteps_since_restore: 530000
  timesteps_this_iter: 10000
  timesteps_total: 530000
  training_iteration: 53
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 22.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=13557], 1246 s, 53 iter, 530000 ts, 1.21e+03 rew

agent-1: 102.0
agent-2: 122.0
agent-3: 94.0
agent-4: 123.0
agent-5: 93.0
agent-6: 112.0
agent-7: 97.0
agent-8: 99.0
agent-9: 119.0
agent-10: 117.0
Sum Reward: 1078.0
Avg Reward: 107.8
Min Reward: 93.0
Max Reward: 123.0
Gini Coefficient: 0.059369202226345084
20:20 Ratio: 1.3101604278074865
Max-min Ratio: 1.3225806451612903
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_00-27-08
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1836.0
  episode_reward_mean: 1204.3207547169811
  episode_reward_min: -1569.0
  episodes_this_iter: 1
  episodes_total: 53
  experiment_id: a3942a9886f24694ab1b58ca8d1ab856
  hostname: gpu006
  info:
    apply_time_ms: 2.695
    dispatch_time_ms: 6.748
    learner:
      cur_lr: 0.0013247020542621613
      grad_gnorm: 40.000003814697266
      policy_entropy: 42.71818542480469
      policy_loss: -3.610154151916504
      var_gnorm: 30.986705780029297
      vf_explained_var: 0.6267342567443848
      vf_loss: 104.45294189453125
    num_steps_sampled: 540000
    num_steps_trained: 540000
    wait_time_ms: 226.461
  iterations_since_restore: 54
  node_ip: 172.17.8.6
  num_metric_batches_dropped: 0
  pid: 13557
  policy_reward_mean: {}
  time_since_restore: 1271.6079456806183
  time_this_iter_s: 25.3780620098114
  time_total_s: 1271.6079456806183
  timestamp: 1594096028
  timesteps_since_restore: 540000
  timesteps_this_iter: 10000
  timesteps_total: 540000
  training_iteration: 54
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 22.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=13557], 1271 s, 54 iter, 540000 ts, 1.2e+03 rew

agent-1: 94.0
agent-2: 147.0
agent-3: 139.0
agent-4: 120.0
agent-5: 84.0
agent-6: 109.0
agent-7: 102.0
agent-8: 117.0
agent-9: 84.0
agent-10: 102.0
Sum Reward: 1098.0
Avg Reward: 109.8
Min Reward: 84.0
Max Reward: 147.0
Gini Coefficient: 0.10327868852459017
20:20 Ratio: 1.7023809523809523
Max-min Ratio: 1.75
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_00-27-31
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1836.0
  episode_reward_mean: 1202.351851851852
  episode_reward_min: -1569.0
  episodes_this_iter: 1
  episodes_total: 54
  experiment_id: a3942a9886f24694ab1b58ca8d1ab856
  hostname: gpu006
  info:
    apply_time_ms: 3.046
    dispatch_time_ms: 6.724
    learner:
      cur_lr: 0.0013240360422059894
      grad_gnorm: 40.0000114440918
      policy_entropy: 53.95630645751953
      policy_loss: 32.72975158691406
      var_gnorm: 31.09914207458496
      vf_explained_var: -0.14149832725524902
      vf_loss: 63.8464241027832
    num_steps_sampled: 550000
    num_steps_trained: 550000
    wait_time_ms: 234.272
  iterations_since_restore: 55
  node_ip: 172.17.8.6
  num_metric_batches_dropped: 0
  pid: 13557
  policy_reward_mean: {}
  time_since_restore: 1294.7925412654877
  time_this_iter_s: 23.184595584869385
  time_total_s: 1294.7925412654877
  timestamp: 1594096051
  timesteps_since_restore: 550000
  timesteps_this_iter: 10000
  timesteps_total: 550000
  training_iteration: 55
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 23.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=13557], 1294 s, 55 iter, 550000 ts, 1.2e+03 rew

agent-1: 100.0
agent-2: 118.0
agent-3: 124.0
agent-4: 113.0
agent-5: 109.0
agent-6: 123.0
agent-7: 126.0
agent-8: 108.0
agent-9: 115.0
agent-10: 114.0
Sum Reward: 1150.0
Avg Reward: 115.0
Min Reward: 100.0
Max Reward: 126.0
Gini Coefficient: 0.03756521739130435
20:20 Ratio: 1.2019230769230769
Max-min Ratio: 1.26
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_00-27-56
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1836.0
  episode_reward_mean: 1201.4
  episode_reward_min: -1569.0
  episodes_this_iter: 1
  episodes_total: 55
  experiment_id: a3942a9886f24694ab1b58ca8d1ab856
  hostname: gpu006
  info:
    apply_time_ms: 2.956
    dispatch_time_ms: 6.145
    learner:
      cur_lr: 0.0013233700301498175
      grad_gnorm: 19.802858352661133
      policy_entropy: 78.4464340209961
      policy_loss: -11.834905624389648
      var_gnorm: 31.199247360229492
      vf_explained_var: 0.9625260829925537
      vf_loss: 1.6459649801254272
    num_steps_sampled: 560000
    num_steps_trained: 560000
    wait_time_ms: 210.641
  iterations_since_restore: 56
  node_ip: 172.17.8.6
  num_metric_batches_dropped: 0
  pid: 13557
  policy_reward_mean: {}
  time_since_restore: 1320.189546585083
  time_this_iter_s: 25.397005319595337
  time_total_s: 1320.189546585083
  timestamp: 1594096076
  timesteps_since_restore: 560000
  timesteps_this_iter: 10000
  timesteps_total: 560000
  training_iteration: 56
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 23.3/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=13557], 1320 s, 56 iter, 560000 ts, 1.2e+03 rew

agent-1: 108.0
agent-2: 88.0
agent-3: 107.0
agent-4: 125.0
agent-5: 96.0
agent-6: 100.0
agent-7: 78.0
agent-8: 110.0
agent-9: 114.0
agent-10: 108.0
Sum Reward: 1034.0
Avg Reward: 103.4
Min Reward: 78.0
Max Reward: 125.0
Gini Coefficient: 0.06769825918762089
20:20 Ratio: 1.4397590361445782
Max-min Ratio: 1.6025641025641026
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_00-28-20
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1836.0
  episode_reward_mean: 1198.4107142857142
  episode_reward_min: -1569.0
  episodes_this_iter: 1
  episodes_total: 56
  experiment_id: a3942a9886f24694ab1b58ca8d1ab856
  hostname: gpu006
  info:
    apply_time_ms: 2.587
    dispatch_time_ms: 7.269
    learner:
      cur_lr: 0.0013227040180936456
      grad_gnorm: 40.000003814697266
      policy_entropy: 20.55311393737793
      policy_loss: -53.81216049194336
      var_gnorm: 31.326066970825195
      vf_explained_var: 0.5634137988090515
      vf_loss: 294.5076904296875
    num_steps_sampled: 570000
    num_steps_trained: 570000
    wait_time_ms: 250.366
  iterations_since_restore: 57
  node_ip: 172.17.8.6
  num_metric_batches_dropped: 0
  pid: 13557
  policy_reward_mean: {}
  time_since_restore: 1344.2095584869385
  time_this_iter_s: 24.02001190185547
  time_total_s: 1344.2095584869385
  timestamp: 1594096100
  timesteps_since_restore: 570000
  timesteps_this_iter: 10000
  timesteps_total: 570000
  training_iteration: 57
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 23.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=13557], 1344 s, 57 iter, 570000 ts, 1.2e+03 rew

agent-1: 125.0
agent-2: 115.0
agent-3: 98.0
agent-4: 78.0
agent-5: 116.0
agent-6: 105.0
agent-7: 93.0
agent-8: 102.0
agent-9: 126.0
agent-10: 93.0
Sum Reward: 1051.0
Avg Reward: 105.1
Min Reward: 78.0
Max Reward: 126.0
Gini Coefficient: 0.07849666983824928
20:20 Ratio: 1.4678362573099415
Max-min Ratio: 1.6153846153846154
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_00-28-46
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1836.0
  episode_reward_mean: 1195.8245614035088
  episode_reward_min: -1569.0
  episodes_this_iter: 1
  episodes_total: 57
  experiment_id: a3942a9886f24694ab1b58ca8d1ab856
  hostname: gpu006
  info:
    apply_time_ms: 2.841
    dispatch_time_ms: 6.962
    learner:
      cur_lr: 0.0013220380060374737
      grad_gnorm: 40.0000114440918
      policy_entropy: 83.30571746826172
      policy_loss: -27.445980072021484
      var_gnorm: 31.479211807250977
      vf_explained_var: -0.03893566131591797
      vf_loss: 123.7138671875
    num_steps_sampled: 580000
    num_steps_trained: 580000
    wait_time_ms: 222.356
  iterations_since_restore: 58
  node_ip: 172.17.8.6
  num_metric_batches_dropped: 0
  pid: 13557
  policy_reward_mean: {}
  time_since_restore: 1369.4858539104462
  time_this_iter_s: 25.27629542350769
  time_total_s: 1369.4858539104462
  timestamp: 1594096126
  timesteps_since_restore: 580000
  timesteps_this_iter: 10000
  timesteps_total: 580000
  training_iteration: 58
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 23.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=13557], 1369 s, 58 iter, 580000 ts, 1.2e+03 rew

agent-1: 69.0
agent-2: 88.0
agent-3: 94.0
agent-4: 72.0
agent-5: 71.0
agent-6: 77.0
agent-7: 73.0
agent-8: 87.0
agent-9: 84.0
agent-10: 84.0
Sum Reward: 799.0
Avg Reward: 79.9
Min Reward: 69.0
Max Reward: 94.0
Gini Coefficient: 0.0574468085106383
20:20 Ratio: 1.3
Max-min Ratio: 1.3623188405797102
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_00-29-09
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1836.0
  episode_reward_mean: 1188.9827586206898
  episode_reward_min: -1569.0
  episodes_this_iter: 1
  episodes_total: 58
  experiment_id: a3942a9886f24694ab1b58ca8d1ab856
  hostname: gpu006
  info:
    apply_time_ms: 3.091
    dispatch_time_ms: 8.216
    learner:
      cur_lr: 0.0013213719939813018
      grad_gnorm: 40.00000762939453
      policy_entropy: 34.22195053100586
      policy_loss: 0.9491967558860779
      var_gnorm: 31.53509521484375
      vf_explained_var: 0.5093902349472046
      vf_loss: 173.4979705810547
    num_steps_sampled: 590000
    num_steps_trained: 590000
    wait_time_ms: 232.025
  iterations_since_restore: 59
  node_ip: 172.17.8.6
  num_metric_batches_dropped: 0
  pid: 13557
  policy_reward_mean: {}
  time_since_restore: 1392.8292665481567
  time_this_iter_s: 23.34341263771057
  time_total_s: 1392.8292665481567
  timestamp: 1594096149
  timesteps_since_restore: 590000
  timesteps_this_iter: 10000
  timesteps_total: 590000
  training_iteration: 59
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 24.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=13557], 1392 s, 59 iter, 590000 ts, 1.19e+03 rew

agent-1: 89.0
agent-2: 118.0
agent-3: 109.0
agent-4: 136.0
agent-5: 106.0
agent-6: 111.0
agent-7: 115.0
agent-8: 152.0
agent-9: 99.0
agent-10: 178.0
Sum Reward: 1213.0
Avg Reward: 121.3
Min Reward: 89.0
Max Reward: 178.0
Gini Coefficient: 0.11154163231657048
20:20 Ratio: 1.7553191489361701
Max-min Ratio: 2.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_00-29-34
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1836.0
  episode_reward_mean: 1189.3898305084747
  episode_reward_min: -1569.0
  episodes_this_iter: 1
  episodes_total: 59
  experiment_id: a3942a9886f24694ab1b58ca8d1ab856
  hostname: gpu006
  info:
    apply_time_ms: 2.797
    dispatch_time_ms: 6.347
    learner:
      cur_lr: 0.0013207059819251299
      grad_gnorm: 14.629271507263184
      policy_entropy: 61.90035629272461
      policy_loss: -2.635155439376831
      var_gnorm: 31.750526428222656
      vf_explained_var: 0.9128081202507019
      vf_loss: 0.6273621320724487
    num_steps_sampled: 600000
    num_steps_trained: 600000
    wait_time_ms: 235.086
  iterations_since_restore: 60
  node_ip: 172.17.8.6
  num_metric_batches_dropped: 0
  pid: 13557
  policy_reward_mean: {}
  time_since_restore: 1417.6125557422638
  time_this_iter_s: 24.783289194107056
  time_total_s: 1417.6125557422638
  timestamp: 1594096174
  timesteps_since_restore: 600000
  timesteps_this_iter: 10000
  timesteps_total: 600000
  training_iteration: 60
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 24.3/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=13557], 1417 s, 60 iter, 600000 ts, 1.19e+03 rew

agent-1: 106.0
agent-2: 105.0
agent-3: 87.0
agent-4: 76.0
agent-5: 86.0
agent-6: 97.0
agent-7: 89.0
agent-8: 82.0
agent-9: 117.0
agent-10: 99.0
Sum Reward: 944.0
Avg Reward: 94.4
Min Reward: 76.0
Max Reward: 117.0
Gini Coefficient: 0.07161016949152542
20:20 Ratio: 1.4113924050632911
Max-min Ratio: 1.5394736842105263
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_00-29-57
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1836.0
  episode_reward_mean: 1185.3
  episode_reward_min: -1569.0
  episodes_this_iter: 1
  episodes_total: 60
  experiment_id: a3942a9886f24694ab1b58ca8d1ab856
  hostname: gpu006
  info:
    apply_time_ms: 2.912
    dispatch_time_ms: 6.079
    learner:
      cur_lr: 0.001320039969868958
      grad_gnorm: 40.00000762939453
      policy_entropy: 41.11679458618164
      policy_loss: 24.177507400512695
      var_gnorm: 31.876813888549805
      vf_explained_var: 0.37655001878738403
      vf_loss: 88.6359634399414
    num_steps_sampled: 610000
    num_steps_trained: 610000
    wait_time_ms: 220.996
  iterations_since_restore: 61
  node_ip: 172.17.8.6
  num_metric_batches_dropped: 0
  pid: 13557
  policy_reward_mean: {}
  time_since_restore: 1441.0839395523071
  time_this_iter_s: 23.471383810043335
  time_total_s: 1441.0839395523071
  timestamp: 1594096197
  timesteps_since_restore: 610000
  timesteps_this_iter: 10000
  timesteps_total: 610000
  training_iteration: 61
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 24.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=13557], 1441 s, 61 iter, 610000 ts, 1.19e+03 rew

agent-1: 101.0
agent-2: 117.0
agent-3: 109.0
agent-4: 86.0
agent-5: 118.0
agent-6: 116.0
agent-7: 128.0
agent-8: 133.0
agent-9: 111.0
agent-10: 103.0
Sum Reward: 1122.0
Avg Reward: 112.2
Min Reward: 86.0
Max Reward: 133.0
Gini Coefficient: 0.06381461675579322
20:20 Ratio: 1.3957219251336899
Max-min Ratio: 1.5465116279069768
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_00-30-22
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1836.0
  episode_reward_mean: 1184.2622950819673
  episode_reward_min: -1569.0
  episodes_this_iter: 1
  episodes_total: 61
  experiment_id: a3942a9886f24694ab1b58ca8d1ab856
  hostname: gpu006
  info:
    apply_time_ms: 2.593
    dispatch_time_ms: 6.098
    learner:
      cur_lr: 0.001319373957812786
      grad_gnorm: 40.0
      policy_entropy: 31.612834930419922
      policy_loss: 13.51025390625
      var_gnorm: 31.953086853027344
      vf_explained_var: 0.12950414419174194
      vf_loss: 183.4210205078125
    num_steps_sampled: 620000
    num_steps_trained: 620000
    wait_time_ms: 246.379
  iterations_since_restore: 62
  node_ip: 172.17.8.6
  num_metric_batches_dropped: 0
  pid: 13557
  policy_reward_mean: {}
  time_since_restore: 1466.1077768802643
  time_this_iter_s: 25.023837327957153
  time_total_s: 1466.1077768802643
  timestamp: 1594096222
  timesteps_since_restore: 620000
  timesteps_this_iter: 10000
  timesteps_total: 620000
  training_iteration: 62
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 24.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=13557], 1466 s, 62 iter, 620000 ts, 1.18e+03 rew

agent-1: 103.0
agent-2: 103.0
agent-3: 103.0
agent-4: 112.0
agent-5: 136.0
agent-6: 92.0
agent-7: 119.0
agent-8: 102.0
agent-9: 93.0
agent-10: 112.0
Sum Reward: 1075.0
Avg Reward: 107.5
Min Reward: 92.0
Max Reward: 136.0
Gini Coefficient: 0.060930232558139535
20:20 Ratio: 1.3783783783783783
Max-min Ratio: 1.4782608695652173
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_00-30-47
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1836.0
  episode_reward_mean: 1182.5
  episode_reward_min: -1569.0
  episodes_this_iter: 1
  episodes_total: 62
  experiment_id: a3942a9886f24694ab1b58ca8d1ab856
  hostname: gpu006
  info:
    apply_time_ms: 2.64
    dispatch_time_ms: 6.501
    learner:
      cur_lr: 0.0013187079457566142
      grad_gnorm: 40.000003814697266
      policy_entropy: 52.33792495727539
      policy_loss: 16.04971694946289
      var_gnorm: 32.06059646606445
      vf_explained_var: 0.9513511061668396
      vf_loss: 162.3120574951172
    num_steps_sampled: 630000
    num_steps_trained: 630000
    wait_time_ms: 249.444
  iterations_since_restore: 63
  node_ip: 172.17.8.6
  num_metric_batches_dropped: 0
  pid: 13557
  policy_reward_mean: {}
  time_since_restore: 1490.4002017974854
  time_this_iter_s: 24.29242491722107
  time_total_s: 1490.4002017974854
  timestamp: 1594096247
  timesteps_since_restore: 630000
  timesteps_this_iter: 10000
  timesteps_total: 630000
  training_iteration: 63
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=13557], 1490 s, 63 iter, 630000 ts, 1.18e+03 rew

agent-1: 93.0
agent-2: 107.0
agent-3: 104.0
agent-4: 95.0
agent-5: 106.0
agent-6: 89.0
agent-7: 75.0
agent-8: 113.0
agent-9: 84.0
agent-10: 97.0
Sum Reward: 963.0
Avg Reward: 96.3
Min Reward: 75.0
Max Reward: 113.0
Gini Coefficient: 0.06469366562824506
20:20 Ratio: 1.3836477987421383
Max-min Ratio: 1.5066666666666666
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_00-31-12
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1836.0
  episode_reward_mean: 1179.015873015873
  episode_reward_min: -1569.0
  episodes_this_iter: 1
  episodes_total: 63
  experiment_id: a3942a9886f24694ab1b58ca8d1ab856
  hostname: gpu006
  info:
    apply_time_ms: 2.996
    dispatch_time_ms: 5.991
    learner:
      cur_lr: 0.0013180420501157641
      grad_gnorm: 5.399813175201416
      policy_entropy: 76.0957260131836
      policy_loss: -1.0688657760620117
      var_gnorm: 32.104034423828125
      vf_explained_var: 0.8890472650527954
      vf_loss: 0.35914847254753113
    num_steps_sampled: 640000
    num_steps_trained: 640000
    wait_time_ms: 238.871
  iterations_since_restore: 64
  node_ip: 172.17.8.6
  num_metric_batches_dropped: 0
  pid: 13557
  policy_reward_mean: {}
  time_since_restore: 1515.4274129867554
  time_this_iter_s: 25.02721118927002
  time_total_s: 1515.4274129867554
  timestamp: 1594096272
  timesteps_since_restore: 640000
  timesteps_this_iter: 10000
  timesteps_total: 640000
  training_iteration: 64
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=13557], 1515 s, 64 iter, 640000 ts, 1.18e+03 rew

agent-1: 115.0
agent-2: 99.0
agent-3: 65.0
agent-4: 106.0
agent-5: 109.0
agent-6: 102.0
agent-7: 77.0
agent-8: 107.0
agent-9: 94.0
agent-10: 70.0
Sum Reward: 944.0
Avg Reward: 94.4
Min Reward: 65.0
Max Reward: 115.0
Gini Coefficient: 0.09661016949152543
20:20 Ratio: 1.6592592592592592
Max-min Ratio: 1.7692307692307692
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_00-31-36
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1836.0
  episode_reward_mean: 1175.34375
  episode_reward_min: -1569.0
  episodes_this_iter: 1
  episodes_total: 64
  experiment_id: a3942a9886f24694ab1b58ca8d1ab856
  hostname: gpu006
  info:
    apply_time_ms: 2.975
    dispatch_time_ms: 7.27
    learner:
      cur_lr: 0.0013173760380595922
      grad_gnorm: 8.277990341186523
      policy_entropy: 78.21954345703125
      policy_loss: -0.0013222619891166687
      var_gnorm: 32.20633316040039
      vf_explained_var: 0.6026626229286194
      vf_loss: 0.24840447306632996
    num_steps_sampled: 650000
    num_steps_trained: 650000
    wait_time_ms: 254.408
  iterations_since_restore: 65
  node_ip: 172.17.8.6
  num_metric_batches_dropped: 0
  pid: 13557
  policy_reward_mean: {}
  time_since_restore: 1539.6709089279175
  time_this_iter_s: 24.24349594116211
  time_total_s: 1539.6709089279175
  timestamp: 1594096296
  timesteps_since_restore: 650000
  timesteps_this_iter: 10000
  timesteps_total: 650000
  training_iteration: 65
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=13557], 1539 s, 65 iter, 650000 ts, 1.18e+03 rew

agent-1: 104.0
agent-2: 81.0
agent-3: 105.0
agent-4: 91.0
agent-5: 87.0
agent-6: 91.0
agent-7: 109.0
agent-8: 111.0
agent-9: 115.0
agent-10: 101.0
Sum Reward: 995.0
Avg Reward: 99.5
Min Reward: 81.0
Max Reward: 115.0
Gini Coefficient: 0.06120603015075377
20:20 Ratio: 1.3452380952380953
Max-min Ratio: 1.4197530864197532
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_00-32-01
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1836.0
  episode_reward_mean: 1172.5692307692307
  episode_reward_min: -1569.0
  episodes_this_iter: 1
  episodes_total: 65
  experiment_id: a3942a9886f24694ab1b58ca8d1ab856
  hostname: gpu006
  info:
    apply_time_ms: 3.39
    dispatch_time_ms: 7.233
    learner:
      cur_lr: 0.0013167100260034204
      grad_gnorm: 13.421266555786133
      policy_entropy: 71.52213287353516
      policy_loss: -3.132859945297241
      var_gnorm: 32.3668098449707
      vf_explained_var: 0.9383088946342468
      vf_loss: 0.28910455107688904
    num_steps_sampled: 660000
    num_steps_trained: 660000
    wait_time_ms: 216.354
  iterations_since_restore: 66
  node_ip: 172.17.8.6
  num_metric_batches_dropped: 0
  pid: 13557
  policy_reward_mean: {}
  time_since_restore: 1564.5682849884033
  time_this_iter_s: 24.89737606048584
  time_total_s: 1564.5682849884033
  timestamp: 1594096321
  timesteps_since_restore: 660000
  timesteps_this_iter: 10000
  timesteps_total: 660000
  training_iteration: 66
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=13557], 1564 s, 66 iter, 660000 ts, 1.17e+03 rew

agent-1: 113.0
agent-2: 84.0
agent-3: 123.0
agent-4: 87.0
agent-5: 99.0
agent-6: 100.0
agent-7: 109.0
agent-8: 106.0
agent-9: 88.0
agent-10: 98.0
Sum Reward: 1007.0
Avg Reward: 100.7
Min Reward: 84.0
Max Reward: 123.0
Gini Coefficient: 0.06583912611717974
20:20 Ratio: 1.3801169590643274
Max-min Ratio: 1.4642857142857142
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_00-32-26
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1836.0
  episode_reward_mean: 1170.060606060606
  episode_reward_min: -1569.0
  episodes_this_iter: 1
  episodes_total: 66
  experiment_id: a3942a9886f24694ab1b58ca8d1ab856
  hostname: gpu006
  info:
    apply_time_ms: 2.814
    dispatch_time_ms: 6.742
    learner:
      cur_lr: 0.0013160440139472485
      grad_gnorm: 27.12252426147461
      policy_entropy: 73.92432403564453
      policy_loss: 4.812067985534668
      var_gnorm: 32.51506042480469
      vf_explained_var: -1.0
      vf_loss: 0.6422684192657471
    num_steps_sampled: 670000
    num_steps_trained: 670000
    wait_time_ms: 252.307
  iterations_since_restore: 67
  node_ip: 172.17.8.6
  num_metric_batches_dropped: 0
  pid: 13557
  policy_reward_mean: {}
  time_since_restore: 1589.3661243915558
  time_this_iter_s: 24.797839403152466
  time_total_s: 1589.3661243915558
  timestamp: 1594096346
  timesteps_since_restore: 670000
  timesteps_this_iter: 10000
  timesteps_total: 670000
  training_iteration: 67
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=13557], 1589 s, 67 iter, 670000 ts, 1.17e+03 rew

agent-1: 94.0
agent-2: 122.0
agent-3: 109.0
agent-4: 94.0
agent-5: 65.0
agent-6: 110.0
agent-7: 90.0
agent-8: 121.0
agent-9: 111.0
agent-10: 93.0
Sum Reward: 1009.0
Avg Reward: 100.9
Min Reward: 65.0
Max Reward: 122.0
Gini Coefficient: 0.08751238850346878
20:20 Ratio: 1.5677419354838709
Max-min Ratio: 1.876923076923077
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_00-32-51
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1836.0
  episode_reward_mean: 1167.6567164179105
  episode_reward_min: -1569.0
  episodes_this_iter: 1
  episodes_total: 67
  experiment_id: a3942a9886f24694ab1b58ca8d1ab856
  hostname: gpu006
  info:
    apply_time_ms: 3.019
    dispatch_time_ms: 7.389
    learner:
      cur_lr: 0.0013153780018910766
      grad_gnorm: 40.000003814697266
      policy_entropy: 45.678977966308594
      policy_loss: 47.404640197753906
      var_gnorm: 32.647727966308594
      vf_explained_var: 0.7311578989028931
      vf_loss: 358.9380187988281
    num_steps_sampled: 680000
    num_steps_trained: 680000
    wait_time_ms: 252.718
  iterations_since_restore: 68
  node_ip: 172.17.8.6
  num_metric_batches_dropped: 0
  pid: 13557
  policy_reward_mean: {}
  time_since_restore: 1614.5099468231201
  time_this_iter_s: 25.14382243156433
  time_total_s: 1614.5099468231201
  timestamp: 1594096371
  timesteps_since_restore: 680000
  timesteps_this_iter: 10000
  timesteps_total: 680000
  training_iteration: 68
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=13557], 1614 s, 68 iter, 680000 ts, 1.17e+03 rew

W0707 00:32:54.544035 13553 node_manager.cc:250] Last heartbeat was sent 701 ms ago 
W0707 00:33:13.150566 13553 node_manager.cc:250] Last heartbeat was sent 670 ms ago 
W0707 00:33:23.297312 13553 node_manager.cc:250] Last heartbeat was sent 974 ms ago 
W0707 00:33:23.755625 13553 node_manager.cc:250] Last heartbeat was sent 1191 ms ago 
W0707 00:33:28.661870 13553 node_manager.cc:250] Last heartbeat was sent 770 ms ago 
W0707 00:33:38.508445 13553 client_connection.cc:255] [worker]ProcessMessage with type 1 took 102 ms.
agent-1: 73.0
agent-2: 94.0
agent-3: 88.0
agent-4: 109.0
agent-5: 86.0
agent-6: 74.0
agent-7: 84.0
agent-8: 85.0
agent-9: 63.0
agent-10: 108.0
Sum Reward: 864.0
Avg Reward: 86.4
Min Reward: 63.0
Max Reward: 109.0
Gini Coefficient: 0.08935185185185185
20:20 Ratio: 1.5955882352941178
Max-min Ratio: 1.7301587301587302
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_00-34-03
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1836.0
  episode_reward_mean: 1163.1911764705883
  episode_reward_min: -1569.0
  episodes_this_iter: 1
  episodes_total: 68
  experiment_id: a3942a9886f24694ab1b58ca8d1ab856
  hostname: gpu006
  info:
    apply_time_ms: 3.526
    dispatch_time_ms: 7.78
    learner:
      cur_lr: 0.0013147119898349047
      grad_gnorm: 40.0
      policy_entropy: 46.7524528503418
      policy_loss: 56.50184631347656
      var_gnorm: 32.69414138793945
      vf_explained_var: 0.49568355083465576
      vf_loss: 398.0101318359375
    num_steps_sampled: 690000
    num_steps_trained: 690000
    wait_time_ms: 250.146
  iterations_since_restore: 69
  node_ip: 172.17.8.6
  num_metric_batches_dropped: 0
  pid: 13557
  policy_reward_mean: {}
  time_since_restore: 1686.425886631012
  time_this_iter_s: 71.91593980789185
  time_total_s: 1686.425886631012
  timestamp: 1594096443
  timesteps_since_restore: 690000
  timesteps_this_iter: 10000
  timesteps_total: 690000
  training_iteration: 69
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=13557], 1686 s, 69 iter, 690000 ts, 1.16e+03 rew

agent-1: 74.0
agent-2: 97.0
agent-3: 78.0
agent-4: 92.0
agent-5: 80.0
agent-6: 93.0
agent-7: 84.0
agent-8: 91.0
agent-9: 73.0
agent-10: 97.0
Sum Reward: 859.0
Avg Reward: 85.9
Min Reward: 73.0
Max Reward: 97.0
Gini Coefficient: 0.057625145518044235
20:20 Ratio: 1.3197278911564625
Max-min Ratio: 1.3287671232876712
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_00-34-33
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1836.0
  episode_reward_mean: 1158.7826086956522
  episode_reward_min: -1569.0
  episodes_this_iter: 1
  episodes_total: 69
  experiment_id: a3942a9886f24694ab1b58ca8d1ab856
  hostname: gpu006
  info:
    apply_time_ms: 3.136
    dispatch_time_ms: 10.569
    learner:
      cur_lr: 0.0013140459777787328
      grad_gnorm: 39.999977111816406
      policy_entropy: 52.492061614990234
      policy_loss: -26.746496200561523
      var_gnorm: 32.84199142456055
      vf_explained_var: -0.26934516429901123
      vf_loss: 469.0545654296875
    num_steps_sampled: 700000
    num_steps_trained: 700000
    wait_time_ms: 209.412
  iterations_since_restore: 70
  node_ip: 172.17.8.6
  num_metric_batches_dropped: 0
  pid: 13557
  policy_reward_mean: {}
  time_since_restore: 1708.9299263954163
  time_this_iter_s: 22.504039764404297
  time_total_s: 1708.9299263954163
  timestamp: 1594096473
  timesteps_since_restore: 700000
  timesteps_this_iter: 10000
  timesteps_total: 700000
  training_iteration: 70
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=13557], 1708 s, 70 iter, 700000 ts, 1.16e+03 rew

agent-1: 99.0
agent-2: 106.0
agent-3: 94.0
agent-4: 115.0
agent-5: 99.0
agent-6: 108.0
agent-7: 116.0
agent-8: 105.0
agent-9: 95.0
agent-10: 122.0
Sum Reward: 1059.0
Avg Reward: 105.9
Min Reward: 94.0
Max Reward: 122.0
Gini Coefficient: 0.047875354107648725
20:20 Ratio: 1.2592592592592593
Max-min Ratio: 1.297872340425532
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_00-34-57
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1836.0
  episode_reward_mean: 1157.357142857143
  episode_reward_min: -1569.0
  episodes_this_iter: 1
  episodes_total: 70
  experiment_id: a3942a9886f24694ab1b58ca8d1ab856
  hostname: gpu006
  info:
    apply_time_ms: 3.967
    dispatch_time_ms: 6.344
    learner:
      cur_lr: 0.0013133799657225609
      grad_gnorm: 40.0000114440918
      policy_entropy: 87.16295623779297
      policy_loss: 34.17034912109375
      var_gnorm: 32.95259094238281
      vf_explained_var: 0.41353410482406616
      vf_loss: 105.69721984863281
    num_steps_sampled: 710000
    num_steps_trained: 710000
    wait_time_ms: 245.649
  iterations_since_restore: 71
  node_ip: 172.17.8.6
  num_metric_batches_dropped: 0
  pid: 13557
  policy_reward_mean: {}
  time_since_restore: 1732.8721432685852
  time_this_iter_s: 23.942216873168945
  time_total_s: 1732.8721432685852
  timestamp: 1594096497
  timesteps_since_restore: 710000
  timesteps_this_iter: 10000
  timesteps_total: 710000
  training_iteration: 71
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=13557], 1732 s, 71 iter, 710000 ts, 1.16e+03 rew

agent-1: 130.0
agent-2: 146.0
agent-3: 127.0
agent-4: 126.0
agent-5: 127.0
agent-6: 110.0
agent-7: 132.0
agent-8: 114.0
agent-9: 100.0
agent-10: 117.0
Sum Reward: 1229.0
Avg Reward: 122.9
Min Reward: 100.0
Max Reward: 146.0
Gini Coefficient: 0.05524816924328722
20:20 Ratio: 1.3238095238095238
Max-min Ratio: 1.46
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_00-35-21
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1836.0
  episode_reward_mean: 1158.3661971830986
  episode_reward_min: -1569.0
  episodes_this_iter: 1
  episodes_total: 71
  experiment_id: a3942a9886f24694ab1b58ca8d1ab856
  hostname: gpu006
  info:
    apply_time_ms: 3.012
    dispatch_time_ms: 6.751
    learner:
      cur_lr: 0.001312713953666389
      grad_gnorm: 40.0000114440918
      policy_entropy: 74.44854736328125
      policy_loss: -26.357585906982422
      var_gnorm: 33.000457763671875
      vf_explained_var: 0.6499950885772705
      vf_loss: 118.51986694335938
    num_steps_sampled: 720000
    num_steps_trained: 720000
    wait_time_ms: 222.212
  iterations_since_restore: 72
  node_ip: 172.17.8.6
  num_metric_batches_dropped: 0
  pid: 13557
  policy_reward_mean: {}
  time_since_restore: 1757.1790997982025
  time_this_iter_s: 24.30695652961731
  time_total_s: 1757.1790997982025
  timestamp: 1594096521
  timesteps_since_restore: 720000
  timesteps_this_iter: 10000
  timesteps_total: 720000
  training_iteration: 72
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=13557], 1757 s, 72 iter, 720000 ts, 1.16e+03 rew

agent-1: 112.0
agent-2: 108.0
agent-3: 124.0
agent-4: 96.0
agent-5: 100.0
agent-6: 116.0
agent-7: 101.0
agent-8: 81.0
agent-9: 107.0
agent-10: 118.0
Sum Reward: 1063.0
Avg Reward: 106.3
Min Reward: 81.0
Max Reward: 124.0
Gini Coefficient: 0.061618062088428974
20:20 Ratio: 1.3672316384180792
Max-min Ratio: 1.5308641975308641
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_00-35-45
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1836.0
  episode_reward_mean: 1157.0416666666667
  episode_reward_min: -1569.0
  episodes_this_iter: 1
  episodes_total: 72
  experiment_id: a3942a9886f24694ab1b58ca8d1ab856
  hostname: gpu006
  info:
    apply_time_ms: 2.709
    dispatch_time_ms: 8.71
    learner:
      cur_lr: 0.001312048058025539
      grad_gnorm: 39.999996185302734
      policy_entropy: 106.03205108642578
      policy_loss: 12.053886413574219
      var_gnorm: 33.150482177734375
      vf_explained_var: 0.39395350217819214
      vf_loss: 7.455469608306885
    num_steps_sampled: 730000
    num_steps_trained: 730000
    wait_time_ms: 225.932
  iterations_since_restore: 73
  node_ip: 172.17.8.6
  num_metric_batches_dropped: 0
  pid: 13557
  policy_reward_mean: {}
  time_since_restore: 1781.1171128749847
  time_this_iter_s: 23.938013076782227
  time_total_s: 1781.1171128749847
  timestamp: 1594096545
  timesteps_since_restore: 730000
  timesteps_this_iter: 10000
  timesteps_total: 730000
  training_iteration: 73
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=13557], 1781 s, 73 iter, 730000 ts, 1.16e+03 rew

agent-1: 132.0
agent-2: 122.0
agent-3: 152.0
agent-4: 126.0
agent-5: 109.0
agent-6: 124.0
agent-7: 98.0
agent-8: 108.0
agent-9: 90.0
agent-10: 98.0
Sum Reward: 1159.0
Avg Reward: 115.9
Min Reward: 90.0
Max Reward: 152.0
Gini Coefficient: 0.08602243313201036
20:20 Ratio: 1.5106382978723405
Max-min Ratio: 1.6888888888888889
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_00-36-10
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1836.0
  episode_reward_mean: 1157.0684931506848
  episode_reward_min: -1569.0
  episodes_this_iter: 1
  episodes_total: 73
  experiment_id: a3942a9886f24694ab1b58ca8d1ab856
  hostname: gpu006
  info:
    apply_time_ms: 3.023
    dispatch_time_ms: 20.993
    learner:
      cur_lr: 0.001311382045969367
      grad_gnorm: 40.000022888183594
      policy_entropy: 56.80765914916992
      policy_loss: 14.648298263549805
      var_gnorm: 33.303279876708984
      vf_explained_var: 0.6648038625717163
      vf_loss: 254.27197265625
    num_steps_sampled: 740000
    num_steps_trained: 740000
    wait_time_ms: 163.939
  iterations_since_restore: 74
  node_ip: 172.17.8.6
  num_metric_batches_dropped: 0
  pid: 13557
  policy_reward_mean: {}
  time_since_restore: 1806.0286812782288
  time_this_iter_s: 24.91156840324402
  time_total_s: 1806.0286812782288
  timestamp: 1594096570
  timesteps_since_restore: 740000
  timesteps_this_iter: 10000
  timesteps_total: 740000
  training_iteration: 74
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=13557], 1806 s, 74 iter, 740000 ts, 1.16e+03 rew

agent-1: 116.0
agent-2: 99.0
agent-3: 120.0
agent-4: 131.0
agent-5: 98.0
agent-6: 110.0
agent-7: 103.0
agent-8: 128.0
agent-9: 109.0
agent-10: 105.0
Sum Reward: 1119.0
Avg Reward: 111.9
Min Reward: 98.0
Max Reward: 131.0
Gini Coefficient: 0.055317247542448614
20:20 Ratio: 1.3147208121827412
Max-min Ratio: 1.336734693877551
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_00-36-35
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1836.0
  episode_reward_mean: 1156.554054054054
  episode_reward_min: -1569.0
  episodes_this_iter: 1
  episodes_total: 74
  experiment_id: a3942a9886f24694ab1b58ca8d1ab856
  hostname: gpu006
  info:
    apply_time_ms: 2.582
    dispatch_time_ms: 18.948
    learner:
      cur_lr: 0.0013107160339131951
      grad_gnorm: 39.999996185302734
      policy_entropy: 48.974525451660156
      policy_loss: -34.26029968261719
      var_gnorm: 33.34909439086914
      vf_explained_var: 0.0037667155265808105
      vf_loss: 107.65155029296875
    num_steps_sampled: 750000
    num_steps_trained: 750000
    wait_time_ms: 216.473
  iterations_since_restore: 75
  node_ip: 172.17.8.6
  num_metric_batches_dropped: 0
  pid: 13557
  policy_reward_mean: {}
  time_since_restore: 1830.978734254837
  time_this_iter_s: 24.950052976608276
  time_total_s: 1830.978734254837
  timestamp: 1594096595
  timesteps_since_restore: 750000
  timesteps_this_iter: 10000
  timesteps_total: 750000
  training_iteration: 75
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=13557], 1830 s, 75 iter, 750000 ts, 1.16e+03 rew

agent-1: 116.0
agent-2: 103.0
agent-3: 85.0
agent-4: 94.0
agent-5: 99.0
agent-6: 102.0
agent-7: 105.0
agent-8: 68.0
agent-9: 108.0
agent-10: 105.0
Sum Reward: 985.0
Avg Reward: 98.5
Min Reward: 68.0
Max Reward: 116.0
Gini Coefficient: 0.06771573604060914
20:20 Ratio: 1.4640522875816993
Max-min Ratio: 1.7058823529411764
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_00-36-59
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1836.0
  episode_reward_mean: 1154.2666666666667
  episode_reward_min: -1569.0
  episodes_this_iter: 1
  episodes_total: 75
  experiment_id: a3942a9886f24694ab1b58ca8d1ab856
  hostname: gpu006
  info:
    apply_time_ms: 4.057
    dispatch_time_ms: 24.069
    learner:
      cur_lr: 0.0013100500218570232
      grad_gnorm: 40.00002670288086
      policy_entropy: 56.65198516845703
      policy_loss: 10.174827575683594
      var_gnorm: 33.55201721191406
      vf_explained_var: 0.7338635921478271
      vf_loss: 56.64999771118164
    num_steps_sampled: 760000
    num_steps_trained: 760000
    wait_time_ms: 203.697
  iterations_since_restore: 76
  node_ip: 172.17.8.6
  num_metric_batches_dropped: 0
  pid: 13557
  policy_reward_mean: {}
  time_since_restore: 1855.265255689621
  time_this_iter_s: 24.286521434783936
  time_total_s: 1855.265255689621
  timestamp: 1594096619
  timesteps_since_restore: 760000
  timesteps_this_iter: 10000
  timesteps_total: 760000
  training_iteration: 76
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=13557], 1855 s, 76 iter, 760000 ts, 1.15e+03 rew

agent-1: 85.0
agent-2: 142.0
agent-3: 124.0
agent-4: 142.0
agent-5: 103.0
agent-6: 151.0
agent-7: 132.0
agent-8: 116.0
agent-9: 123.0
agent-10: 106.0
Sum Reward: 1224.0
Avg Reward: 122.4
Min Reward: 85.0
Max Reward: 151.0
Gini Coefficient: 0.08954248366013072
20:20 Ratio: 1.5585106382978724
Max-min Ratio: 1.776470588235294
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_00-37-24
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1836.0
  episode_reward_mean: 1155.1842105263158
  episode_reward_min: -1569.0
  episodes_this_iter: 1
  episodes_total: 76
  experiment_id: a3942a9886f24694ab1b58ca8d1ab856
  hostname: gpu006
  info:
    apply_time_ms: 4.009
    dispatch_time_ms: 28.407
    learner:
      cur_lr: 0.0013093840098008513
      grad_gnorm: 31.667993545532227
      policy_entropy: 68.28862762451172
      policy_loss: -1.1692482233047485
      var_gnorm: 33.601905822753906
      vf_explained_var: 0.22670602798461914
      vf_loss: 0.616538941860199
    num_steps_sampled: 770000
    num_steps_trained: 770000
    wait_time_ms: 208.093
  iterations_since_restore: 77
  node_ip: 172.17.8.6
  num_metric_batches_dropped: 0
  pid: 13557
  policy_reward_mean: {}
  time_since_restore: 1879.8788692951202
  time_this_iter_s: 24.613613605499268
  time_total_s: 1879.8788692951202
  timestamp: 1594096644
  timesteps_since_restore: 770000
  timesteps_this_iter: 10000
  timesteps_total: 770000
  training_iteration: 77
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=13557], 1879 s, 77 iter, 770000 ts, 1.16e+03 rew

agent-1: 97.0
agent-2: 137.0
agent-3: 108.0
agent-4: 106.0
agent-5: 109.0
agent-6: 122.0
agent-7: 118.0
agent-8: 98.0
agent-9: 108.0
agent-10: 90.0
Sum Reward: 1093.0
Avg Reward: 109.3
Min Reward: 90.0
Max Reward: 137.0
Gini Coefficient: 0.06468435498627631
20:20 Ratio: 1.3850267379679144
Max-min Ratio: 1.5222222222222221
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_00-37-49
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1836.0
  episode_reward_mean: 1154.3766233766235
  episode_reward_min: -1569.0
  episodes_this_iter: 1
  episodes_total: 77
  experiment_id: a3942a9886f24694ab1b58ca8d1ab856
  hostname: gpu006
  info:
    apply_time_ms: 3.56
    dispatch_time_ms: 26.135
    learner:
      cur_lr: 0.0013087179977446795
      grad_gnorm: 20.429908752441406
      policy_entropy: 62.16086959838867
      policy_loss: -3.9250290393829346
      var_gnorm: 33.728782653808594
      vf_explained_var: 0.6775078177452087
      vf_loss: 0.37022632360458374
    num_steps_sampled: 780000
    num_steps_trained: 780000
    wait_time_ms: 218.64
  iterations_since_restore: 78
  node_ip: 172.17.8.6
  num_metric_batches_dropped: 0
  pid: 13557
  policy_reward_mean: {}
  time_since_restore: 1904.7444458007812
  time_this_iter_s: 24.86557650566101
  time_total_s: 1904.7444458007812
  timestamp: 1594096669
  timesteps_since_restore: 780000
  timesteps_this_iter: 10000
  timesteps_total: 780000
  training_iteration: 78
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=13557], 1904 s, 78 iter, 780000 ts, 1.15e+03 rew

agent-1: 115.0
agent-2: 110.0
agent-3: 125.0
agent-4: 108.0
agent-5: 126.0
agent-6: 126.0
agent-7: 120.0
agent-8: 126.0
agent-9: 103.0
agent-10: 122.0
Sum Reward: 1181.0
Avg Reward: 118.1
Min Reward: 103.0
Max Reward: 126.0
Gini Coefficient: 0.03767993226079593
20:20 Ratio: 1.1943127962085307
Max-min Ratio: 1.2233009708737863
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_00-38-15
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1836.0
  episode_reward_mean: 1154.7179487179487
  episode_reward_min: -1569.0
  episodes_this_iter: 1
  episodes_total: 78
  experiment_id: a3942a9886f24694ab1b58ca8d1ab856
  hostname: gpu006
  info:
    apply_time_ms: 3.232
    dispatch_time_ms: 16.982
    learner:
      cur_lr: 0.0013080519856885076
      grad_gnorm: 8.66493034362793
      policy_entropy: 78.49637603759766
      policy_loss: -2.3991599082946777
      var_gnorm: 33.8448371887207
      vf_explained_var: 0.024135231971740723
      vf_loss: 0.03781576827168465
    num_steps_sampled: 790000
    num_steps_trained: 790000
    wait_time_ms: 219.443
  iterations_since_restore: 79
  node_ip: 172.17.8.6
  num_metric_batches_dropped: 0
  pid: 13557
  policy_reward_mean: {}
  time_since_restore: 1930.461365699768
  time_this_iter_s: 25.716919898986816
  time_total_s: 1930.461365699768
  timestamp: 1594096695
  timesteps_since_restore: 790000
  timesteps_this_iter: 10000
  timesteps_total: 790000
  training_iteration: 79
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=13557], 1930 s, 79 iter, 790000 ts, 1.15e+03 rew

agent-1: 124.0
agent-2: 100.0
agent-3: 117.0
agent-4: 142.0
agent-5: 130.0
agent-6: 104.0
agent-7: 114.0
agent-8: 122.0
agent-9: 127.0
agent-10: 112.0
Sum Reward: 1192.0
Avg Reward: 119.2
Min Reward: 100.0
Max Reward: 142.0
Gini Coefficient: 0.05620805369127517
20:20 Ratio: 1.3333333333333333
Max-min Ratio: 1.42
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_00-38-39
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1836.0
  episode_reward_mean: 1155.1898734177216
  episode_reward_min: -1569.0
  episodes_this_iter: 1
  episodes_total: 79
  experiment_id: a3942a9886f24694ab1b58ca8d1ab856
  hostname: gpu006
  info:
    apply_time_ms: 3.029
    dispatch_time_ms: 31.199
    learner:
      cur_lr: 0.0013073859736323357
      grad_gnorm: 30.53616714477539
      policy_entropy: 86.2824478149414
      policy_loss: -4.805060863494873
      var_gnorm: 33.970298767089844
      vf_explained_var: 0.9400272369384766
      vf_loss: 0.1518094539642334
    num_steps_sampled: 800000
    num_steps_trained: 800000
    wait_time_ms: 204.407
  iterations_since_restore: 80
  node_ip: 172.17.8.6
  num_metric_batches_dropped: 0
  pid: 13557
  policy_reward_mean: {}
  time_since_restore: 1955.1351408958435
  time_this_iter_s: 24.67377519607544
  time_total_s: 1955.1351408958435
  timestamp: 1594096719
  timesteps_since_restore: 800000
  timesteps_this_iter: 10000
  timesteps_total: 800000
  training_iteration: 80
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=13557], 1955 s, 80 iter, 800000 ts, 1.16e+03 rew

agent-1: 115.0
agent-2: 116.0
agent-3: 127.0
agent-4: 109.0
agent-5: 114.0
agent-6: 108.0
agent-7: 127.0
agent-8: 114.0
agent-9: 129.0
agent-10: 141.0
Sum Reward: 1200.0
Avg Reward: 120.0
Min Reward: 108.0
Max Reward: 141.0
Gini Coefficient: 0.04516666666666667
20:20 Ratio: 1.2442396313364055
Max-min Ratio: 1.3055555555555556
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_00-39-04
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1836.0
  episode_reward_mean: 1155.75
  episode_reward_min: -1569.0
  episodes_this_iter: 1
  episodes_total: 80
  experiment_id: a3942a9886f24694ab1b58ca8d1ab856
  hostname: gpu006
  info:
    apply_time_ms: 3.65
    dispatch_time_ms: 38.708
    learner:
      cur_lr: 0.0013067199615761638
      grad_gnorm: 7.678500175476074
      policy_entropy: 90.21322631835938
      policy_loss: -1.0928528308868408
      var_gnorm: 34.05319595336914
      vf_explained_var: 0.694645345211029
      vf_loss: 0.07684744894504547
    num_steps_sampled: 810000
    num_steps_trained: 810000
    wait_time_ms: 189.573
  iterations_since_restore: 81
  node_ip: 172.17.8.6
  num_metric_batches_dropped: 0
  pid: 13557
  policy_reward_mean: {}
  time_since_restore: 1978.66068649292
  time_this_iter_s: 23.525545597076416
  time_total_s: 1978.66068649292
  timestamp: 1594096744
  timesteps_since_restore: 810000
  timesteps_this_iter: 10000
  timesteps_total: 810000
  training_iteration: 81
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=13557], 1978 s, 81 iter, 810000 ts, 1.16e+03 rew

agent-1: 131.0
agent-2: 124.0
agent-3: 97.0
agent-4: 106.0
agent-5: 131.0
agent-6: 114.0
agent-7: 139.0
agent-8: 104.0
agent-9: 126.0
agent-10: 108.0
Sum Reward: 1180.0
Avg Reward: 118.0
Min Reward: 97.0
Max Reward: 139.0
Gini Coefficient: 0.0640677966101695
20:20 Ratio: 1.3432835820895523
Max-min Ratio: 1.4329896907216495
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_00-39-29
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1836.0
  episode_reward_mean: 1156.0493827160494
  episode_reward_min: -1569.0
  episodes_this_iter: 1
  episodes_total: 81
  experiment_id: a3942a9886f24694ab1b58ca8d1ab856
  hostname: gpu006
  info:
    apply_time_ms: 2.818
    dispatch_time_ms: 28.465
    learner:
      cur_lr: 0.0013060539495199919
      grad_gnorm: 6.044785976409912
      policy_entropy: 88.22139739990234
      policy_loss: -1.6403143405914307
      var_gnorm: 34.27016830444336
      vf_explained_var: -0.00011110305786132812
      vf_loss: 0.020757297053933144
    num_steps_sampled: 820000
    num_steps_trained: 820000
    wait_time_ms: 218.851
  iterations_since_restore: 82
  node_ip: 172.17.8.6
  num_metric_batches_dropped: 0
  pid: 13557
  policy_reward_mean: {}
  time_since_restore: 2003.5366854667664
  time_this_iter_s: 24.875998973846436
  time_total_s: 2003.5366854667664
  timestamp: 1594096769
  timesteps_since_restore: 820000
  timesteps_this_iter: 10000
  timesteps_total: 820000
  training_iteration: 82
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=13557], 2003 s, 82 iter, 820000 ts, 1.16e+03 rew

agent-1: 125.0
agent-2: 87.0
agent-3: 89.0
agent-4: 106.0
agent-5: 115.0
agent-6: 131.0
agent-7: 100.0
agent-8: 141.0
agent-9: 113.0
agent-10: 105.0
Sum Reward: 1112.0
Avg Reward: 111.2
Min Reward: 87.0
Max Reward: 141.0
Gini Coefficient: 0.08471223021582734
20:20 Ratio: 1.5454545454545454
Max-min Ratio: 1.6206896551724137
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_00-39-55
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1836.0
  episode_reward_mean: 1155.5121951219512
  episode_reward_min: -1569.0
  episodes_this_iter: 1
  episodes_total: 82
  experiment_id: a3942a9886f24694ab1b58ca8d1ab856
  hostname: gpu006
  info:
    apply_time_ms: 2.906
    dispatch_time_ms: 24.678
    learner:
      cur_lr: 0.0013053880538791418
      grad_gnorm: 25.169357299804688
      policy_entropy: 72.10751342773438
      policy_loss: -2.693186044692993
      var_gnorm: 34.41790008544922
      vf_explained_var: -0.2636454105377197
      vf_loss: 0.49237772822380066
    num_steps_sampled: 830000
    num_steps_trained: 830000
    wait_time_ms: 236.167
  iterations_since_restore: 83
  node_ip: 172.17.8.6
  num_metric_batches_dropped: 0
  pid: 13557
  policy_reward_mean: {}
  time_since_restore: 2028.8929159641266
  time_this_iter_s: 25.35623049736023
  time_total_s: 2028.8929159641266
  timestamp: 1594096795
  timesteps_since_restore: 830000
  timesteps_this_iter: 10000
  timesteps_total: 830000
  training_iteration: 83
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=13557], 2028 s, 83 iter, 830000 ts, 1.16e+03 rew

agent-1: 94.0
agent-2: 113.0
agent-3: 107.0
agent-4: 119.0
agent-5: 96.0
agent-6: 75.0
agent-7: 114.0
agent-8: 100.0
agent-9: 107.0
agent-10: 70.0
Sum Reward: 995.0
Avg Reward: 99.5
Min Reward: 70.0
Max Reward: 119.0
Gini Coefficient: 0.08532663316582914
20:20 Ratio: 1.606896551724138
Max-min Ratio: 1.7
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_00-40-19
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1836.0
  episode_reward_mean: 1153.578313253012
  episode_reward_min: -1569.0
  episodes_this_iter: 1
  episodes_total: 83
  experiment_id: a3942a9886f24694ab1b58ca8d1ab856
  hostname: gpu006
  info:
    apply_time_ms: 2.594
    dispatch_time_ms: 27.026
    learner:
      cur_lr: 0.00130472204182297
      grad_gnorm: 40.00003433227539
      policy_entropy: 31.470272064208984
      policy_loss: -21.99871826171875
      var_gnorm: 34.61902618408203
      vf_explained_var: 0.7379688620567322
      vf_loss: 163.2602081298828
    num_steps_sampled: 840000
    num_steps_trained: 840000
    wait_time_ms: 216.087
  iterations_since_restore: 84
  node_ip: 172.17.8.6
  num_metric_batches_dropped: 0
  pid: 13557
  policy_reward_mean: {}
  time_since_restore: 2053.441967010498
  time_this_iter_s: 24.54905104637146
  time_total_s: 2053.441967010498
  timestamp: 1594096819
  timesteps_since_restore: 840000
  timesteps_this_iter: 10000
  timesteps_total: 840000
  training_iteration: 84
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=13557], 2053 s, 84 iter, 840000 ts, 1.15e+03 rew

agent-1: 99.0
agent-2: 131.0
agent-3: 118.0
agent-4: 118.0
agent-5: 95.0
agent-6: 139.0
agent-7: 157.0
agent-8: 146.0
agent-9: 113.0
agent-10: 115.0
Sum Reward: 1231.0
Avg Reward: 123.1
Min Reward: 95.0
Max Reward: 157.0
Gini Coefficient: 0.08651502843216897
20:20 Ratio: 1.5618556701030928
Max-min Ratio: 1.6526315789473685
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_00-40-45
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1836.0
  episode_reward_mean: 1154.5
  episode_reward_min: -1569.0
  episodes_this_iter: 1
  episodes_total: 84
  experiment_id: a3942a9886f24694ab1b58ca8d1ab856
  hostname: gpu006
  info:
    apply_time_ms: 2.984
    dispatch_time_ms: 22.276
    learner:
      cur_lr: 0.001304056029766798
      grad_gnorm: 39.999996185302734
      policy_entropy: 18.73870277404785
      policy_loss: 0.5060958862304688
      var_gnorm: 34.7220344543457
      vf_explained_var: 0.6321438550949097
      vf_loss: 293.5091552734375
    num_steps_sampled: 850000
    num_steps_trained: 850000
    wait_time_ms: 232.115
  iterations_since_restore: 85
  node_ip: 172.17.8.6
  num_metric_batches_dropped: 0
  pid: 13557
  policy_reward_mean: {}
  time_since_restore: 2078.975452899933
  time_this_iter_s: 25.533485889434814
  time_total_s: 2078.975452899933
  timestamp: 1594096845
  timesteps_since_restore: 850000
  timesteps_this_iter: 10000
  timesteps_total: 850000
  training_iteration: 85
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=13557], 2078 s, 85 iter, 850000 ts, 1.15e+03 rew

agent-1: 96.0
agent-2: 119.0
agent-3: 98.0
agent-4: 107.0
agent-5: 113.0
agent-6: 91.0
agent-7: 97.0
agent-8: 117.0
agent-9: 104.0
agent-10: 111.0
Sum Reward: 1053.0
Avg Reward: 105.3
Min Reward: 91.0
Max Reward: 119.0
Gini Coefficient: 0.049477682811016145
20:20 Ratio: 1.2620320855614973
Max-min Ratio: 1.3076923076923077
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_00-41-10
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1836.0
  episode_reward_mean: 1153.3058823529411
  episode_reward_min: -1569.0
  episodes_this_iter: 1
  episodes_total: 85
  experiment_id: a3942a9886f24694ab1b58ca8d1ab856
  hostname: gpu006
  info:
    apply_time_ms: 3.327
    dispatch_time_ms: 26.276
    learner:
      cur_lr: 0.0013033900177106261
      grad_gnorm: 40.0000114440918
      policy_entropy: 75.15745544433594
      policy_loss: 6.984807014465332
      var_gnorm: 34.8995475769043
      vf_explained_var: 0.8968489170074463
      vf_loss: 29.93726348876953
    num_steps_sampled: 860000
    num_steps_trained: 860000
    wait_time_ms: 214.925
  iterations_since_restore: 86
  node_ip: 172.17.8.6
  num_metric_batches_dropped: 0
  pid: 13557
  policy_reward_mean: {}
  time_since_restore: 2103.5443494319916
  time_this_iter_s: 24.568896532058716
  time_total_s: 2103.5443494319916
  timestamp: 1594096870
  timesteps_since_restore: 860000
  timesteps_this_iter: 10000
  timesteps_total: 860000
  training_iteration: 86
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=13557], 2103 s, 86 iter, 860000 ts, 1.15e+03 rew

agent-1: 123.0
agent-2: 101.0
agent-3: 135.0
agent-4: 99.0
agent-5: 133.0
agent-6: 134.0
agent-7: 122.0
agent-8: 113.0
agent-9: 114.0
agent-10: 97.0
Sum Reward: 1171.0
Avg Reward: 117.1
Min Reward: 97.0
Max Reward: 135.0
Gini Coefficient: 0.06703672075149444
20:20 Ratio: 1.3724489795918366
Max-min Ratio: 1.3917525773195876
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_00-41-34
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1836.0
  episode_reward_mean: 1153.5116279069769
  episode_reward_min: -1569.0
  episodes_this_iter: 1
  episodes_total: 86
  experiment_id: a3942a9886f24694ab1b58ca8d1ab856
  hostname: gpu006
  info:
    apply_time_ms: 2.972
    dispatch_time_ms: 27.28
    learner:
      cur_lr: 0.0013027240056544542
      grad_gnorm: 40.000003814697266
      policy_entropy: 52.39661407470703
      policy_loss: 18.894506454467773
      var_gnorm: 34.95463943481445
      vf_explained_var: 0.0561375617980957
      vf_loss: 181.6193389892578
    num_steps_sampled: 870000
    num_steps_trained: 870000
    wait_time_ms: 221.593
  iterations_since_restore: 87
  node_ip: 172.17.8.6
  num_metric_batches_dropped: 0
  pid: 13557
  policy_reward_mean: {}
  time_since_restore: 2128.0849754810333
  time_this_iter_s: 24.540626049041748
  time_total_s: 2128.0849754810333
  timestamp: 1594096894
  timesteps_since_restore: 870000
  timesteps_this_iter: 10000
  timesteps_total: 870000
  training_iteration: 87
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=13557], 2128 s, 87 iter, 870000 ts, 1.15e+03 rew

agent-1: 118.0
agent-2: 119.0
agent-3: 143.0
agent-4: 104.0
agent-5: 110.0
agent-6: 155.0
agent-7: 102.0
agent-8: 107.0
agent-9: 135.0
agent-10: 133.0
Sum Reward: 1226.0
Avg Reward: 122.6
Min Reward: 102.0
Max Reward: 155.0
Gini Coefficient: 0.07830342577487764
20:20 Ratio: 1.4466019417475728
Max-min Ratio: 1.5196078431372548
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_00-41-58
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1836.0
  episode_reward_mean: 1154.344827586207
  episode_reward_min: -1569.0
  episodes_this_iter: 1
  episodes_total: 87
  experiment_id: a3942a9886f24694ab1b58ca8d1ab856
  hostname: gpu006
  info:
    apply_time_ms: 4.087
    dispatch_time_ms: 25.494
    learner:
      cur_lr: 0.0013020579935982823
      grad_gnorm: 40.0000114440918
      policy_entropy: 56.05940246582031
      policy_loss: -43.436912536621094
      var_gnorm: 35.040428161621094
      vf_explained_var: 0.8240807056427002
      vf_loss: 202.71934509277344
    num_steps_sampled: 880000
    num_steps_trained: 880000
    wait_time_ms: 222.399
  iterations_since_restore: 88
  node_ip: 172.17.8.6
  num_metric_batches_dropped: 0
  pid: 13557
  policy_reward_mean: {}
  time_since_restore: 2151.8992624282837
  time_this_iter_s: 23.814286947250366
  time_total_s: 2151.8992624282837
  timestamp: 1594096918
  timesteps_since_restore: 880000
  timesteps_this_iter: 10000
  timesteps_total: 880000
  training_iteration: 88
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=13557], 2151 s, 88 iter, 880000 ts, 1.15e+03 rew

agent-1: 121.0
agent-2: 149.0
agent-3: 131.0
agent-4: 155.0
agent-5: 145.0
agent-6: 172.0
agent-7: 136.0
agent-8: 120.0
agent-9: 151.0
agent-10: 150.0
Sum Reward: 1430.0
Avg Reward: 143.0
Min Reward: 120.0
Max Reward: 172.0
Gini Coefficient: 0.05958041958041958
20:20 Ratio: 1.3568464730290457
Max-min Ratio: 1.4333333333333333
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_00-42-22
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1836.0
  episode_reward_mean: 1157.4772727272727
  episode_reward_min: -1569.0
  episodes_this_iter: 1
  episodes_total: 88
  experiment_id: a3942a9886f24694ab1b58ca8d1ab856
  hostname: gpu006
  info:
    apply_time_ms: 4.014
    dispatch_time_ms: 20.809
    learner:
      cur_lr: 0.0013013919815421104
      grad_gnorm: 40.000003814697266
      policy_entropy: 80.52458190917969
      policy_loss: -13.19968032836914
      var_gnorm: 35.24601364135742
      vf_explained_var: 0.5433375239372253
      vf_loss: 99.45765686035156
    num_steps_sampled: 890000
    num_steps_trained: 890000
    wait_time_ms: 208.039
  iterations_since_restore: 89
  node_ip: 172.17.8.6
  num_metric_batches_dropped: 0
  pid: 13557
  policy_reward_mean: {}
  time_since_restore: 2176.036013364792
  time_this_iter_s: 24.13675093650818
  time_total_s: 2176.036013364792
  timestamp: 1594096942
  timesteps_since_restore: 890000
  timesteps_this_iter: 10000
  timesteps_total: 890000
  training_iteration: 89
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=13557], 2176 s, 89 iter, 890000 ts, 1.16e+03 rew

agent-1: 157.0
agent-2: 127.0
agent-3: 99.0
agent-4: 148.0
agent-5: 144.0
agent-6: 141.0
agent-7: 116.0
agent-8: 121.0
agent-9: 168.0
agent-10: 152.0
Sum Reward: 1373.0
Avg Reward: 137.3
Min Reward: 99.0
Max Reward: 168.0
Gini Coefficient: 0.08222869628550619
20:20 Ratio: 1.5116279069767442
Max-min Ratio: 1.696969696969697
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_00-42-46
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1836.0
  episode_reward_mean: 1159.8988764044943
  episode_reward_min: -1569.0
  episodes_this_iter: 1
  episodes_total: 89
  experiment_id: a3942a9886f24694ab1b58ca8d1ab856
  hostname: gpu006
  info:
    apply_time_ms: 2.572
    dispatch_time_ms: 24.984
    learner:
      cur_lr: 0.0013007259694859385
      grad_gnorm: 40.000003814697266
      policy_entropy: 51.7276496887207
      policy_loss: 23.662797927856445
      var_gnorm: 35.32373809814453
      vf_explained_var: 0.13822782039642334
      vf_loss: 72.46895599365234
    num_steps_sampled: 900000
    num_steps_trained: 900000
    wait_time_ms: 195.73
  iterations_since_restore: 90
  node_ip: 172.17.8.6
  num_metric_batches_dropped: 0
  pid: 13557
  policy_reward_mean: {}
  time_since_restore: 2199.3529300689697
  time_this_iter_s: 23.316916704177856
  time_total_s: 2199.3529300689697
  timestamp: 1594096966
  timesteps_since_restore: 900000
  timesteps_this_iter: 10000
  timesteps_total: 900000
  training_iteration: 90
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=13557], 2199 s, 90 iter, 900000 ts, 1.16e+03 rew

agent-1: 150.0
agent-2: 204.0
agent-3: 157.0
agent-4: 144.0
agent-5: 119.0
agent-6: 204.0
agent-7: 156.0
agent-8: 132.0
agent-9: 123.0
agent-10: 145.0
Sum Reward: 1534.0
Avg Reward: 153.4
Min Reward: 119.0
Max Reward: 204.0
Gini Coefficient: 0.09765319426336376
20:20 Ratio: 1.6859504132231404
Max-min Ratio: 1.7142857142857142
W0707 00:43:11.382212 13553 node_manager.cc:250] Last heartbeat was sent 2090 ms ago 
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_00-43-14
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1836.0
  episode_reward_mean: 1164.0555555555557
  episode_reward_min: -1569.0
  episodes_this_iter: 1
  episodes_total: 90
  experiment_id: a3942a9886f24694ab1b58ca8d1ab856
  hostname: gpu006
  info:
    apply_time_ms: 2.611
    dispatch_time_ms: 28.773
    learner:
      cur_lr: 0.0013000599574297667
      grad_gnorm: 39.99999237060547
      policy_entropy: 71.53472900390625
      policy_loss: 36.2261962890625
      var_gnorm: 35.482818603515625
      vf_explained_var: 0.41946518421173096
      vf_loss: 164.74375915527344
    num_steps_sampled: 910000
    num_steps_trained: 910000
    wait_time_ms: 578.755
  iterations_since_restore: 91
  node_ip: 172.17.8.6
  num_metric_batches_dropped: 0
  pid: 13557
  policy_reward_mean: {}
  time_since_restore: 2227.486563682556
  time_this_iter_s: 28.133633613586426
  time_total_s: 2227.486563682556
  timestamp: 1594096994
  timesteps_since_restore: 910000
  timesteps_this_iter: 10000
  timesteps_total: 910000
  training_iteration: 91
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=13557], 2227 s, 91 iter, 910000 ts, 1.16e+03 rew

agent-1: 128.0
agent-2: 141.0
agent-3: 161.0
agent-4: 152.0
agent-5: 124.0
agent-6: 175.0
agent-7: 134.0
agent-8: 153.0
agent-9: 154.0
agent-10: 149.0
Sum Reward: 1471.0
Avg Reward: 147.1
Min Reward: 124.0
Max Reward: 175.0
Gini Coefficient: 0.05635622025832767
20:20 Ratio: 1.3333333333333333
Max-min Ratio: 1.4112903225806452
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_00-43-37
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1836.0
  episode_reward_mean: 1167.4285714285713
  episode_reward_min: -1569.0
  episodes_this_iter: 1
  episodes_total: 91
  experiment_id: a3942a9886f24694ab1b58ca8d1ab856
  hostname: gpu006
  info:
    apply_time_ms: 3.032
    dispatch_time_ms: 23.92
    learner:
      cur_lr: 0.0012993939453735948
      grad_gnorm: 8.81570053100586
      policy_entropy: 110.0499038696289
      policy_loss: -4.20797061920166
      var_gnorm: 35.693145751953125
      vf_explained_var: 0.9947900176048279
      vf_loss: 0.07090744376182556
    num_steps_sampled: 920000
    num_steps_trained: 920000
    wait_time_ms: 244.762
  iterations_since_restore: 92
  node_ip: 172.17.8.6
  num_metric_batches_dropped: 0
  pid: 13557
  policy_reward_mean: {}
  time_since_restore: 2250.778891324997
  time_this_iter_s: 23.292327642440796
  time_total_s: 2250.778891324997
  timestamp: 1594097017
  timesteps_since_restore: 920000
  timesteps_this_iter: 10000
  timesteps_total: 920000
  training_iteration: 92
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=13557], 2250 s, 92 iter, 920000 ts, 1.17e+03 rew

agent-1: 90.0
agent-2: 101.0
agent-3: 115.0
agent-4: 111.0
agent-5: 92.0
agent-6: 98.0
agent-7: 108.0
agent-8: 86.0
agent-9: 113.0
agent-10: 88.0
Sum Reward: 1002.0
Avg Reward: 100.2
Min Reward: 86.0
Max Reward: 115.0
Gini Coefficient: 0.05908183632734531
20:20 Ratio: 1.3103448275862069
Max-min Ratio: 1.3372093023255813
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_00-44-03
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1836.0
  episode_reward_mean: 1165.6304347826087
  episode_reward_min: -1569.0
  episodes_this_iter: 1
  episodes_total: 92
  experiment_id: a3942a9886f24694ab1b58ca8d1ab856
  hostname: gpu006
  info:
    apply_time_ms: 3.533
    dispatch_time_ms: 27.696
    learner:
      cur_lr: 0.0012987280497327447
      grad_gnorm: 12.354045867919922
      policy_entropy: 110.62828826904297
      policy_loss: -4.773108959197998
      var_gnorm: 35.81877136230469
      vf_explained_var: 0.7508153915405273
      vf_loss: 0.08199013024568558
    num_steps_sampled: 930000
    num_steps_trained: 930000
    wait_time_ms: 242.671
  iterations_since_restore: 93
  node_ip: 172.17.8.6
  num_metric_batches_dropped: 0
  pid: 13557
  policy_reward_mean: {}
  time_since_restore: 2276.328393936157
  time_this_iter_s: 25.54950261116028
  time_total_s: 2276.328393936157
  timestamp: 1594097043
  timesteps_since_restore: 930000
  timesteps_this_iter: 10000
  timesteps_total: 930000
  training_iteration: 93
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=13557], 2276 s, 93 iter, 930000 ts, 1.17e+03 rew

agent-1: 99.0
agent-2: 129.0
agent-3: 111.0
agent-4: 122.0
agent-5: 109.0
agent-6: 114.0
agent-7: 100.0
agent-8: 98.0
agent-9: 134.0
agent-10: 118.0
Sum Reward: 1134.0
Avg Reward: 113.4
Min Reward: 98.0
Max Reward: 134.0
Gini Coefficient: 0.05943562610229277
20:20 Ratio: 1.3350253807106598
Max-min Ratio: 1.3673469387755102
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_00-44-27
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1836.0
  episode_reward_mean: 1165.2903225806451
  episode_reward_min: -1569.0
  episodes_this_iter: 1
  episodes_total: 93
  experiment_id: a3942a9886f24694ab1b58ca8d1ab856
  hostname: gpu006
  info:
    apply_time_ms: 3.075
    dispatch_time_ms: 26.199
    learner:
      cur_lr: 0.0012980620376765728
      grad_gnorm: 40.000003814697266
      policy_entropy: 14.923260688781738
      policy_loss: 10.03520679473877
      var_gnorm: 35.97327423095703
      vf_explained_var: 0.6641238331794739
      vf_loss: 176.60704040527344
    num_steps_sampled: 940000
    num_steps_trained: 940000
    wait_time_ms: 216.451
  iterations_since_restore: 94
  node_ip: 172.17.8.6
  num_metric_batches_dropped: 0
  pid: 13557
  policy_reward_mean: {}
  time_since_restore: 2300.6759581565857
  time_this_iter_s: 24.347564220428467
  time_total_s: 2300.6759581565857
  timestamp: 1594097067
  timesteps_since_restore: 940000
  timesteps_this_iter: 10000
  timesteps_total: 940000
  training_iteration: 94
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=13557], 2300 s, 94 iter, 940000 ts, 1.17e+03 rew

agent-1: 114.0
agent-2: 98.0
agent-3: 108.0
agent-4: 104.0
agent-5: 119.0
agent-6: 103.0
agent-7: 121.0
agent-8: 131.0
agent-9: 108.0
agent-10: 110.0
Sum Reward: 1116.0
Avg Reward: 111.6
Min Reward: 98.0
Max Reward: 131.0
Gini Coefficient: 0.04641577060931899
20:20 Ratio: 1.2537313432835822
Max-min Ratio: 1.336734693877551
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_00-44-53
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1836.0
  episode_reward_mean: 1164.7659574468084
  episode_reward_min: -1569.0
  episodes_this_iter: 1
  episodes_total: 94
  experiment_id: a3942a9886f24694ab1b58ca8d1ab856
  hostname: gpu006
  info:
    apply_time_ms: 3.495
    dispatch_time_ms: 19.876
    learner:
      cur_lr: 0.001297396025620401
      grad_gnorm: 39.999996185302734
      policy_entropy: 99.20620727539062
      policy_loss: -6.047327041625977
      var_gnorm: 36.121116638183594
      vf_explained_var: 0.9869535565376282
      vf_loss: 0.29052191972732544
    num_steps_sampled: 950000
    num_steps_trained: 950000
    wait_time_ms: 222.184
  iterations_since_restore: 95
  node_ip: 172.17.8.6
  num_metric_batches_dropped: 0
  pid: 13557
  policy_reward_mean: {}
  time_since_restore: 2326.221690416336
  time_this_iter_s: 25.545732259750366
  time_total_s: 2326.221690416336
  timestamp: 1594097093
  timesteps_since_restore: 950000
  timesteps_this_iter: 10000
  timesteps_total: 950000
  training_iteration: 95
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=13557], 2326 s, 95 iter, 950000 ts, 1.16e+03 rew

agent-1: 110.0
agent-2: 122.0
agent-3: 109.0
agent-4: 119.0
agent-5: 105.0
agent-6: 126.0
agent-7: 137.0
agent-8: 127.0
agent-9: 136.0
agent-10: 115.0
Sum Reward: 1206.0
Avg Reward: 120.6
Min Reward: 105.0
Max Reward: 137.0
Gini Coefficient: 0.04958540630182421
20:20 Ratio: 1.2757009345794392
Max-min Ratio: 1.3047619047619048
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_00-45-17
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1836.0
  episode_reward_mean: 1165.2
  episode_reward_min: -1569.0
  episodes_this_iter: 1
  episodes_total: 95
  experiment_id: a3942a9886f24694ab1b58ca8d1ab856
  hostname: gpu006
  info:
    apply_time_ms: 3.211
    dispatch_time_ms: 27.018
    learner:
      cur_lr: 0.001296730013564229
      grad_gnorm: 40.00000762939453
      policy_entropy: 17.15594482421875
      policy_loss: 2.3185999393463135
      var_gnorm: 36.24705505371094
      vf_explained_var: 0.7158101797103882
      vf_loss: 163.5356903076172
    num_steps_sampled: 960000
    num_steps_trained: 960000
    wait_time_ms: 213.375
  iterations_since_restore: 96
  node_ip: 172.17.8.6
  num_metric_batches_dropped: 0
  pid: 13557
  policy_reward_mean: {}
  time_since_restore: 2350.7870993614197
  time_this_iter_s: 24.565408945083618
  time_total_s: 2350.7870993614197
  timestamp: 1594097117
  timesteps_since_restore: 960000
  timesteps_this_iter: 10000
  timesteps_total: 960000
  training_iteration: 96
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=13557], 2350 s, 96 iter, 960000 ts, 1.17e+03 rew

agent-1: 109.0
agent-2: 97.0
agent-3: 122.0
agent-4: 115.0
agent-5: 102.0
agent-6: 103.0
agent-7: 100.0
agent-8: 129.0
agent-9: 120.0
agent-10: 102.0
Sum Reward: 1099.0
Avg Reward: 109.9
Min Reward: 97.0
Max Reward: 129.0
Gini Coefficient: 0.05250227479526843
20:20 Ratio: 1.2741116751269035
Max-min Ratio: 1.3298969072164948
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_00-45-43
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1836.0
  episode_reward_mean: 1164.5104166666667
  episode_reward_min: -1569.0
  episodes_this_iter: 1
  episodes_total: 96
  experiment_id: a3942a9886f24694ab1b58ca8d1ab856
  hostname: gpu006
  info:
    apply_time_ms: 2.815
    dispatch_time_ms: 34.597
    learner:
      cur_lr: 0.0012960640015080571
      grad_gnorm: 13.889019012451172
      policy_entropy: 103.08177185058594
      policy_loss: -4.301799774169922
      var_gnorm: 36.29274368286133
      vf_explained_var: 0.5983796119689941
      vf_loss: 0.10721885412931442
    num_steps_sampled: 970000
    num_steps_trained: 970000
    wait_time_ms: 212.361
  iterations_since_restore: 97
  node_ip: 172.17.8.6
  num_metric_batches_dropped: 0
  pid: 13557
  policy_reward_mean: {}
  time_since_restore: 2376.8224029541016
  time_this_iter_s: 26.035303592681885
  time_total_s: 2376.8224029541016
  timestamp: 1594097143
  timesteps_since_restore: 970000
  timesteps_this_iter: 10000
  timesteps_total: 970000
  training_iteration: 97
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=13557], 2376 s, 97 iter, 970000 ts, 1.16e+03 rew

agent-1: 107.0
agent-2: 108.0
agent-3: 99.0
agent-4: 118.0
agent-5: 108.0
agent-6: 89.0
agent-7: 105.0
agent-8: 105.0
agent-9: 103.0
agent-10: 109.0
Sum Reward: 1051.0
Avg Reward: 105.1
Min Reward: 89.0
Max Reward: 118.0
Gini Coefficient: 0.03491912464319696
20:20 Ratio: 1.2074468085106382
Max-min Ratio: 1.3258426966292134
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_00-46-07
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1836.0
  episode_reward_mean: 1163.340206185567
  episode_reward_min: -1569.0
  episodes_this_iter: 1
  episodes_total: 97
  experiment_id: a3942a9886f24694ab1b58ca8d1ab856
  hostname: gpu006
  info:
    apply_time_ms: 3.489
    dispatch_time_ms: 25.817
    learner:
      cur_lr: 0.0012953979894518852
      grad_gnorm: 39.99998474121094
      policy_entropy: 71.37287902832031
      policy_loss: 6.986827373504639
      var_gnorm: 36.49158477783203
      vf_explained_var: 0.15118306875228882
      vf_loss: 17.496383666992188
    num_steps_sampled: 980000
    num_steps_trained: 980000
    wait_time_ms: 220.936
  iterations_since_restore: 98
  node_ip: 172.17.8.6
  num_metric_batches_dropped: 0
  pid: 13557
  policy_reward_mean: {}
  time_since_restore: 2400.970145702362
  time_this_iter_s: 24.147742748260498
  time_total_s: 2400.970145702362
  timestamp: 1594097167
  timesteps_since_restore: 980000
  timesteps_this_iter: 10000
  timesteps_total: 980000
  training_iteration: 98
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=13557], 2400 s, 98 iter, 980000 ts, 1.16e+03 rew

agent-1: 88.0
agent-2: 111.0
agent-3: 95.0
agent-4: 124.0
agent-5: 92.0
agent-6: 117.0
agent-7: 97.0
agent-8: 126.0
agent-9: 111.0
agent-10: 98.0
Sum Reward: 1059.0
Avg Reward: 105.9
Min Reward: 88.0
Max Reward: 126.0
Gini Coefficient: 0.06902738432483475
20:20 Ratio: 1.3888888888888888
Max-min Ratio: 1.4318181818181819
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_00-46-33
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1836.0
  episode_reward_mean: 1162.2755102040817
  episode_reward_min: -1569.0
  episodes_this_iter: 1
  episodes_total: 98
  experiment_id: a3942a9886f24694ab1b58ca8d1ab856
  hostname: gpu006
  info:
    apply_time_ms: 4.144
    dispatch_time_ms: 29.677
    learner:
      cur_lr: 0.0012947319773957133
      grad_gnorm: 40.00000762939453
      policy_entropy: 87.02447509765625
      policy_loss: 62.822044372558594
      var_gnorm: 36.63573455810547
      vf_explained_var: 0.35256725549697876
      vf_loss: 156.65525817871094
    num_steps_sampled: 990000
    num_steps_trained: 990000
    wait_time_ms: 194.546
  iterations_since_restore: 99
  node_ip: 172.17.8.6
  num_metric_batches_dropped: 0
  pid: 13557
  policy_reward_mean: {}
  time_since_restore: 2426.1104366779327
  time_this_iter_s: 25.14029097557068
  time_total_s: 2426.1104366779327
  timestamp: 1594097193
  timesteps_since_restore: 990000
  timesteps_this_iter: 10000
  timesteps_total: 990000
  training_iteration: 99
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=13557], 2426 s, 99 iter, 990000 ts, 1.16e+03 rew

agent-1: 101.0
agent-2: 154.0
agent-3: 91.0
agent-4: 121.0
agent-5: 121.0
agent-6: 130.0
agent-7: 92.0
agent-8: 145.0
agent-9: 129.0
agent-10: 114.0
Sum Reward: 1198.0
Avg Reward: 119.8
Min Reward: 91.0
Max Reward: 154.0
Gini Coefficient: 0.09415692821368948
20:20 Ratio: 1.633879781420765
Max-min Ratio: 1.6923076923076923
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_00-46-56
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1836.0
  episode_reward_mean: 1162.6363636363637
  episode_reward_min: -1569.0
  episodes_this_iter: 1
  episodes_total: 99
  experiment_id: a3942a9886f24694ab1b58ca8d1ab856
  hostname: gpu006
  info:
    apply_time_ms: 2.839
    dispatch_time_ms: 34.309
    learner:
      cur_lr: 0.0012940659653395414
      grad_gnorm: 39.999996185302734
      policy_entropy: 51.64486312866211
      policy_loss: -41.69819259643555
      var_gnorm: 36.70771026611328
      vf_explained_var: 0.20759379863739014
      vf_loss: 375.1005859375
    num_steps_sampled: 1000000
    num_steps_trained: 1000000
    wait_time_ms: 217.581
  iterations_since_restore: 100
  node_ip: 172.17.8.6
  num_metric_batches_dropped: 0
  pid: 13557
  policy_reward_mean: {}
  time_since_restore: 2449.431523323059
  time_this_iter_s: 23.321086645126343
  time_total_s: 2449.431523323059
  timestamp: 1594097216
  timesteps_since_restore: 1000000
  timesteps_this_iter: 10000
  timesteps_total: 1000000
  training_iteration: 100
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=13557], 2449 s, 100 iter, 1000000 ts, 1.16e+03 rew

agent-1: 115.0
agent-2: 149.0
agent-3: 127.0
agent-4: 125.0
agent-5: 179.0
agent-6: 123.0
agent-7: 131.0
agent-8: 140.0
agent-9: 174.0
agent-10: 163.0
Sum Reward: 1426.0
Avg Reward: 142.6
Min Reward: 115.0
Max Reward: 179.0
Gini Coefficient: 0.08401122019635343
20:20 Ratio: 1.4831932773109244
Max-min Ratio: 1.5565217391304347
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_00-47-21
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1836.0
  episode_reward_mean: 1165.27
  episode_reward_min: -1569.0
  episodes_this_iter: 1
  episodes_total: 100
  experiment_id: a3942a9886f24694ab1b58ca8d1ab856
  hostname: gpu006
  info:
    apply_time_ms: 2.701
    dispatch_time_ms: 37.486
    learner:
      cur_lr: 0.0012933999532833695
      grad_gnorm: 40.0
      policy_entropy: 85.75947570800781
      policy_loss: -6.922492980957031
      var_gnorm: 36.88108444213867
      vf_explained_var: 0.4224150776863098
      vf_loss: 7.805379390716553
    num_steps_sampled: 1010000
    num_steps_trained: 1010000
    wait_time_ms: 216.641
  iterations_since_restore: 101
  node_ip: 172.17.8.6
  num_metric_batches_dropped: 0
  pid: 13557
  policy_reward_mean: {}
  time_since_restore: 2474.4354832172394
  time_this_iter_s: 25.003959894180298
  time_total_s: 2474.4354832172394
  timestamp: 1594097241
  timesteps_since_restore: 1010000
  timesteps_this_iter: 10000
  timesteps_total: 1010000
  training_iteration: 101
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=13557], 2474 s, 101 iter, 1010000 ts, 1.17e+03 rew

agent-1: 111.0
agent-2: 131.0
agent-3: 137.0
agent-4: 116.0
agent-5: 109.0
agent-6: 162.0
agent-7: 166.0
agent-8: 146.0
agent-9: 118.0
agent-10: 126.0
Sum Reward: 1322.0
Avg Reward: 132.2
Min Reward: 109.0
Max Reward: 166.0
Gini Coefficient: 0.08184568835098335
20:20 Ratio: 1.490909090909091
Max-min Ratio: 1.5229357798165137
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_00-47-46
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1836.0
  episode_reward_mean: 1194.18
  episode_reward_min: -955.0
  episodes_this_iter: 1
  episodes_total: 101
  experiment_id: a3942a9886f24694ab1b58ca8d1ab856
  hostname: gpu006
  info:
    apply_time_ms: 3.901
    dispatch_time_ms: 17.592
    learner:
      cur_lr: 0.0012927340576425195
      grad_gnorm: 40.0
      policy_entropy: 43.28912353515625
      policy_loss: 7.604092121124268
      var_gnorm: 36.96013641357422
      vf_explained_var: 0.7737136483192444
      vf_loss: 212.06089782714844
    num_steps_sampled: 1020000
    num_steps_trained: 1020000
    wait_time_ms: 241.808
  iterations_since_restore: 102
  node_ip: 172.17.8.6
  num_metric_batches_dropped: 0
  pid: 13557
  policy_reward_mean: {}
  time_since_restore: 2498.9725563526154
  time_this_iter_s: 24.537073135375977
  time_total_s: 2498.9725563526154
  timestamp: 1594097266
  timesteps_since_restore: 1020000
  timesteps_this_iter: 10000
  timesteps_total: 1020000
  training_iteration: 102
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=13557], 2498 s, 102 iter, 1020000 ts, 1.19e+03 rew

agent-1: 128.0
agent-2: 142.0
agent-3: 89.0
agent-4: 116.0
agent-5: 123.0
agent-6: 140.0
agent-7: 128.0
agent-8: 118.0
agent-9: 120.0
agent-10: 122.0
Sum Reward: 1226.0
Avg Reward: 122.6
Min Reward: 89.0
Max Reward: 142.0
Gini Coefficient: 0.05872756933115824
20:20 Ratio: 1.3756097560975609
Max-min Ratio: 1.595505617977528
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_00-48-12
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1836.0
  episode_reward_mean: 1215.99
  episode_reward_min: 799.0
  episodes_this_iter: 1
  episodes_total: 102
  experiment_id: a3942a9886f24694ab1b58ca8d1ab856
  hostname: gpu006
  info:
    apply_time_ms: 2.639
    dispatch_time_ms: 21.275
    learner:
      cur_lr: 0.0012920680455863476
      grad_gnorm: 9.996927261352539
      policy_entropy: 101.70236206054688
      policy_loss: -3.339736223220825
      var_gnorm: 37.07368850708008
      vf_explained_var: 0.9207702279090881
      vf_loss: 0.06873025000095367
    num_steps_sampled: 1030000
    num_steps_trained: 1030000
    wait_time_ms: 238.315
  iterations_since_restore: 103
  node_ip: 172.17.8.6
  num_metric_batches_dropped: 0
  pid: 13557
  policy_reward_mean: {}
  time_since_restore: 2525.113258600235
  time_this_iter_s: 26.14070224761963
  time_total_s: 2525.113258600235
  timestamp: 1594097292
  timesteps_since_restore: 1030000
  timesteps_this_iter: 10000
  timesteps_total: 1030000
  training_iteration: 103
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=13557], 2525 s, 103 iter, 1030000 ts, 1.22e+03 rew

agent-1: 94.0
agent-2: 113.0
agent-3: 130.0
agent-4: 92.0
agent-5: 97.0
agent-6: 114.0
agent-7: 86.0
agent-8: 88.0
agent-9: 86.0
agent-10: 76.0
Sum Reward: 976.0
Avg Reward: 97.6
Min Reward: 76.0
Max Reward: 130.0
Gini Coefficient: 0.08668032786885246
20:20 Ratio: 1.5061728395061729
Max-min Ratio: 1.7105263157894737
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_00-48-36
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1836.0
  episode_reward_mean: 1213.83
  episode_reward_min: 799.0
  episodes_this_iter: 1
  episodes_total: 103
  experiment_id: a3942a9886f24694ab1b58ca8d1ab856
  hostname: gpu006
  info:
    apply_time_ms: 3.365
    dispatch_time_ms: 31.978
    learner:
      cur_lr: 0.0012914020335301757
      grad_gnorm: 40.000003814697266
      policy_entropy: 81.71321105957031
      policy_loss: 0.2277413159608841
      var_gnorm: 37.20331573486328
      vf_explained_var: 0.5631511211395264
      vf_loss: 61.12840270996094
    num_steps_sampled: 1040000
    num_steps_trained: 1040000
    wait_time_ms: 237.716
  iterations_since_restore: 104
  node_ip: 172.17.8.6
  num_metric_batches_dropped: 0
  pid: 13557
  policy_reward_mean: {}
  time_since_restore: 2549.612177848816
  time_this_iter_s: 24.498919248580933
  time_total_s: 2549.612177848816
  timestamp: 1594097316
  timesteps_since_restore: 1040000
  timesteps_this_iter: 10000
  timesteps_total: 1040000
  training_iteration: 104
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=13557], 2549 s, 104 iter, 1040000 ts, 1.21e+03 rew

agent-1: 83.0
agent-2: 123.0
agent-3: 125.0
agent-4: 158.0
agent-5: 107.0
agent-6: 104.0
agent-7: 92.0
agent-8: 146.0
agent-9: 100.0
agent-10: 120.0
Sum Reward: 1158.0
Avg Reward: 115.8
Min Reward: 83.0
Max Reward: 158.0
Gini Coefficient: 0.1077720207253886
20:20 Ratio: 1.737142857142857
Max-min Ratio: 1.9036144578313252
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_00-49-01
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1836.0
  episode_reward_mean: 1211.55
  episode_reward_min: 799.0
  episodes_this_iter: 1
  episodes_total: 104
  experiment_id: a3942a9886f24694ab1b58ca8d1ab856
  hostname: gpu006
  info:
    apply_time_ms: 2.701
    dispatch_time_ms: 23.744
    learner:
      cur_lr: 0.0012907360214740038
      grad_gnorm: 40.0
      policy_entropy: 82.37158203125
      policy_loss: 5.023841381072998
      var_gnorm: 37.36001205444336
      vf_explained_var: 0.9037317633628845
      vf_loss: 30.89658546447754
    num_steps_sampled: 1050000
    num_steps_trained: 1050000
    wait_time_ms: 235.803
  iterations_since_restore: 105
  node_ip: 172.17.8.6
  num_metric_batches_dropped: 0
  pid: 13557
  policy_reward_mean: {}
  time_since_restore: 2574.5489645004272
  time_this_iter_s: 24.936786651611328
  time_total_s: 2574.5489645004272
  timestamp: 1594097341
  timesteps_since_restore: 1050000
  timesteps_this_iter: 10000
  timesteps_total: 1050000
  training_iteration: 105
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=13557], 2574 s, 105 iter, 1050000 ts, 1.21e+03 rew

agent-1: 113.0
agent-2: 167.0
agent-3: 115.0
agent-4: 127.0
agent-5: 124.0
agent-6: 140.0
agent-7: 139.0
agent-8: 112.0
agent-9: 142.0
agent-10: 99.0
Sum Reward: 1278.0
Avg Reward: 127.8
Min Reward: 99.0
Max Reward: 167.0
Gini Coefficient: 0.08075117370892018
20:20 Ratio: 1.4644549763033174
Max-min Ratio: 1.6868686868686869
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_00-49-26
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1836.0
  episode_reward_mean: 1212.65
  episode_reward_min: 799.0
  episodes_this_iter: 1
  episodes_total: 105
  experiment_id: a3942a9886f24694ab1b58ca8d1ab856
  hostname: gpu006
  info:
    apply_time_ms: 3.55
    dispatch_time_ms: 21.868
    learner:
      cur_lr: 0.001290070009417832
      grad_gnorm: 40.0
      policy_entropy: 84.3749008178711
      policy_loss: 5.7278151512146
      var_gnorm: 37.41937255859375
      vf_explained_var: 0.8581694960594177
      vf_loss: 29.572933197021484
    num_steps_sampled: 1060000
    num_steps_trained: 1060000
    wait_time_ms: 242.941
  iterations_since_restore: 106
  node_ip: 172.17.8.6
  num_metric_batches_dropped: 0
  pid: 13557
  policy_reward_mean: {}
  time_since_restore: 2598.9598989486694
  time_this_iter_s: 24.410934448242188
  time_total_s: 2598.9598989486694
  timestamp: 1594097366
  timesteps_since_restore: 1060000
  timesteps_this_iter: 10000
  timesteps_total: 1060000
  training_iteration: 106
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=13557], 2598 s, 106 iter, 1060000 ts, 1.21e+03 rew

agent-1: 88.0
agent-2: 129.0
agent-3: 85.0
agent-4: 95.0
agent-5: 96.0
agent-6: 112.0
agent-7: 78.0
agent-8: 96.0
agent-9: 116.0
agent-10: 105.0
Sum Reward: 1000.0
Avg Reward: 100.0
Min Reward: 78.0
Max Reward: 129.0
Gini Coefficient: 0.0826
20:20 Ratio: 1.5030674846625767
Max-min Ratio: 1.6538461538461537
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_00-49-52
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1836.0
  episode_reward_mean: 1207.58
  episode_reward_min: 799.0
  episodes_this_iter: 1
  episodes_total: 106
  experiment_id: a3942a9886f24694ab1b58ca8d1ab856
  hostname: gpu006
  info:
    apply_time_ms: 2.813
    dispatch_time_ms: 37.532
    learner:
      cur_lr: 0.00128940399736166
      grad_gnorm: 4.406984806060791
      policy_entropy: 100.567626953125
      policy_loss: -1.080561637878418
      var_gnorm: 37.50361633300781
      vf_explained_var: 0.9333662986755371
      vf_loss: 0.04237213730812073
    num_steps_sampled: 1070000
    num_steps_trained: 1070000
    wait_time_ms: 181.715
  iterations_since_restore: 107
  node_ip: 172.17.8.6
  num_metric_batches_dropped: 0
  pid: 13557
  policy_reward_mean: {}
  time_since_restore: 2624.8429403305054
  time_this_iter_s: 25.883041381835938
  time_total_s: 2624.8429403305054
  timestamp: 1594097392
  timesteps_since_restore: 1070000
  timesteps_this_iter: 10000
  timesteps_total: 1070000
  training_iteration: 107
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=13557], 2624 s, 107 iter, 1070000 ts, 1.21e+03 rew

W0707 00:49:55.854487 13553 client_connection.cc:255] [worker]ProcessMessage with type 8 took 234 ms.
agent-1: 99.0
agent-2: 87.0
agent-3: 97.0
agent-4: 108.0
agent-5: 89.0
agent-6: 99.0
agent-7: 101.0
agent-8: 88.0
agent-9: 108.0
agent-10: 87.0
Sum Reward: 963.0
Avg Reward: 96.3
Min Reward: 87.0
Max Reward: 108.0
Gini Coefficient: 0.04496365524402907
20:20 Ratio: 1.2413793103448276
Max-min Ratio: 1.2413793103448276
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_00-50-16
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1836.0
  episode_reward_mean: 1204.61
  episode_reward_min: 799.0
  episodes_this_iter: 1
  episodes_total: 107
  experiment_id: a3942a9886f24694ab1b58ca8d1ab856
  hostname: gpu006
  info:
    apply_time_ms: 3.188
    dispatch_time_ms: 32.85
    learner:
      cur_lr: 0.0012887379853054881
      grad_gnorm: 39.99998474121094
      policy_entropy: 32.45548629760742
      policy_loss: -4.651607036590576
      var_gnorm: 37.58086013793945
      vf_explained_var: 0.5535416603088379
      vf_loss: 118.50804901123047
    num_steps_sampled: 1080000
    num_steps_trained: 1080000
    wait_time_ms: 203.281
  iterations_since_restore: 108
  node_ip: 172.17.8.6
  num_metric_batches_dropped: 0
  pid: 13557
  policy_reward_mean: {}
  time_since_restore: 2648.983031988144
  time_this_iter_s: 24.14009165763855
  time_total_s: 2648.983031988144
  timestamp: 1594097416
  timesteps_since_restore: 1080000
  timesteps_this_iter: 10000
  timesteps_total: 1080000
  training_iteration: 108
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=13557], 2648 s, 108 iter, 1080000 ts, 1.2e+03 rew

agent-1: 115.0
agent-2: 129.0
agent-3: 146.0
agent-4: 114.0
agent-5: 121.0
agent-6: 122.0
agent-7: 123.0
agent-8: 115.0
agent-9: 120.0
agent-10: 132.0
Sum Reward: 1237.0
Avg Reward: 123.7
Min Reward: 114.0
Max Reward: 146.0
Gini Coefficient: 0.03936944219886823
20:20 Ratio: 1.2139737991266375
Max-min Ratio: 1.280701754385965
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_00-50-42
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1836.0
  episode_reward_mean: 1200.17
  episode_reward_min: 799.0
  episodes_this_iter: 1
  episodes_total: 108
  experiment_id: a3942a9886f24694ab1b58ca8d1ab856
  hostname: gpu006
  info:
    apply_time_ms: 2.56
    dispatch_time_ms: 31.346
    learner:
      cur_lr: 0.0012880719732493162
      grad_gnorm: 39.999996185302734
      policy_entropy: 50.972076416015625
      policy_loss: -24.150991439819336
      var_gnorm: 37.69059753417969
      vf_explained_var: 0.3460097908973694
      vf_loss: 235.7628173828125
    num_steps_sampled: 1090000
    num_steps_trained: 1090000
    wait_time_ms: 191.645
  iterations_since_restore: 109
  node_ip: 172.17.8.6
  num_metric_batches_dropped: 0
  pid: 13557
  policy_reward_mean: {}
  time_since_restore: 2675.2995145320892
  time_this_iter_s: 26.316482543945312
  time_total_s: 2675.2995145320892
  timestamp: 1594097442
  timesteps_since_restore: 1090000
  timesteps_this_iter: 10000
  timesteps_total: 1090000
  training_iteration: 109
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=13557], 2675 s, 109 iter, 1090000 ts, 1.2e+03 rew

agent-1: 114.0
agent-2: 97.0
agent-3: 91.0
agent-4: 110.0
agent-5: 122.0
agent-6: 120.0
agent-7: 109.0
agent-8: 91.0
agent-9: 111.0
agent-10: 108.0
Sum Reward: 1073.0
Avg Reward: 107.3
Min Reward: 91.0
Max Reward: 122.0
Gini Coefficient: 0.0537744641192917
20:20 Ratio: 1.3296703296703296
Max-min Ratio: 1.3406593406593406
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_00-51-07
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1836.0
  episode_reward_mean: 1195.79
  episode_reward_min: 799.0
  episodes_this_iter: 1
  episodes_total: 109
  experiment_id: a3942a9886f24694ab1b58ca8d1ab856
  hostname: gpu006
  info:
    apply_time_ms: 2.961
    dispatch_time_ms: 24.407
    learner:
      cur_lr: 0.0012874059611931443
      grad_gnorm: 40.00001525878906
      policy_entropy: 25.49280548095703
      policy_loss: -38.4211311340332
      var_gnorm: 37.77532958984375
      vf_explained_var: 0.11392778158187866
      vf_loss: 325.23907470703125
    num_steps_sampled: 1100000
    num_steps_trained: 1100000
    wait_time_ms: 237.763
  iterations_since_restore: 110
  node_ip: 172.17.8.6
  num_metric_batches_dropped: 0
  pid: 13557
  policy_reward_mean: {}
  time_since_restore: 2699.831675052643
  time_this_iter_s: 24.53216052055359
  time_total_s: 2699.831675052643
  timestamp: 1594097467
  timesteps_since_restore: 1100000
  timesteps_this_iter: 10000
  timesteps_total: 1100000
  training_iteration: 110
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=13557], 2699 s, 110 iter, 1100000 ts, 1.2e+03 rew

agent-1: 125.0
agent-2: 135.0
agent-3: 104.0
agent-4: 115.0
agent-5: 140.0
agent-6: 83.0
agent-7: 117.0
agent-8: 109.0
agent-9: 135.0
agent-10: 125.0
Sum Reward: 1188.0
Avg Reward: 118.8
Min Reward: 83.0
Max Reward: 140.0
Gini Coefficient: 0.0755892255892256
20:20 Ratio: 1.4705882352941178
Max-min Ratio: 1.6867469879518073
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_00-51-33
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1836.0
  episode_reward_mean: 1195.19
  episode_reward_min: 799.0
  episodes_this_iter: 1
  episodes_total: 110
  experiment_id: a3942a9886f24694ab1b58ca8d1ab856
  hostname: gpu006
  info:
    apply_time_ms: 2.685
    dispatch_time_ms: 29.462
    learner:
      cur_lr: 0.0012867399491369724
      grad_gnorm: 40.00001525878906
      policy_entropy: 100.45112609863281
      policy_loss: -13.571196556091309
      var_gnorm: 37.827457427978516
      vf_explained_var: 0.4492282271385193
      vf_loss: 2.509124517440796
    num_steps_sampled: 1110000
    num_steps_trained: 1110000
    wait_time_ms: 224.355
  iterations_since_restore: 111
  node_ip: 172.17.8.6
  num_metric_batches_dropped: 0
  pid: 13557
  policy_reward_mean: {}
  time_since_restore: 2725.6667470932007
  time_this_iter_s: 25.83507204055786
  time_total_s: 2725.6667470932007
  timestamp: 1594097493
  timesteps_since_restore: 1110000
  timesteps_this_iter: 10000
  timesteps_total: 1110000
  training_iteration: 111
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=13557], 2725 s, 111 iter, 1110000 ts, 1.2e+03 rew

agent-1: 107.0
agent-2: 119.0
agent-3: 101.0
agent-4: 85.0
agent-5: 111.0
agent-6: 123.0
agent-7: 99.0
agent-8: 103.0
agent-9: 132.0
agent-10: 106.0
Sum Reward: 1086.0
Avg Reward: 108.6
Min Reward: 85.0
Max Reward: 132.0
Gini Coefficient: 0.06500920810313075
20:20 Ratio: 1.3858695652173914
Max-min Ratio: 1.5529411764705883
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_00-51-57
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1836.0
  episode_reward_mean: 1192.72
  episode_reward_min: 799.0
  episodes_this_iter: 1
  episodes_total: 111
  experiment_id: a3942a9886f24694ab1b58ca8d1ab856
  hostname: gpu006
  info:
    apply_time_ms: 2.698
    dispatch_time_ms: 23.999
    learner:
      cur_lr: 0.0012860740534961224
      grad_gnorm: 40.000003814697266
      policy_entropy: 19.08805274963379
      policy_loss: 26.403236389160156
      var_gnorm: 37.83096694946289
      vf_explained_var: 0.4493093490600586
      vf_loss: 249.13902282714844
    num_steps_sampled: 1120000
    num_steps_trained: 1120000
    wait_time_ms: 218.007
  iterations_since_restore: 112
  node_ip: 172.17.8.6
  num_metric_batches_dropped: 0
  pid: 13557
  policy_reward_mean: {}
  time_since_restore: 2749.856207370758
  time_this_iter_s: 24.189460277557373
  time_total_s: 2749.856207370758
  timestamp: 1594097517
  timesteps_since_restore: 1120000
  timesteps_this_iter: 10000
  timesteps_total: 1120000
  training_iteration: 112
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=13557], 2749 s, 112 iter, 1120000 ts, 1.19e+03 rew

agent-1: 86.0
agent-2: 113.0
agent-3: 112.0
agent-4: 120.0
agent-5: 104.0
agent-6: 102.0
agent-7: 116.0
agent-8: 104.0
agent-9: 116.0
agent-10: 138.0
Sum Reward: 1111.0
Avg Reward: 111.1
Min Reward: 86.0
Max Reward: 138.0
Gini Coefficient: 0.062196219621962194
20:20 Ratio: 1.372340425531915
Max-min Ratio: 1.6046511627906976
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_00-52-23
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1836.0
  episode_reward_mean: 1191.2
  episode_reward_min: 799.0
  episodes_this_iter: 1
  episodes_total: 112
  experiment_id: a3942a9886f24694ab1b58ca8d1ab856
  hostname: gpu006
  info:
    apply_time_ms: 3.22
    dispatch_time_ms: 27.065
    learner:
      cur_lr: 0.0012854080414399505
      grad_gnorm: 7.323846817016602
      policy_entropy: 106.9931640625
      policy_loss: -1.2705202102661133
      var_gnorm: 37.95408248901367
      vf_explained_var: 0.8831952214241028
      vf_loss: 0.19360001385211945
    num_steps_sampled: 1130000
    num_steps_trained: 1130000
    wait_time_ms: 199.643
  iterations_since_restore: 113
  node_ip: 172.17.8.6
  num_metric_batches_dropped: 0
  pid: 13557
  policy_reward_mean: {}
  time_since_restore: 2776.0320403575897
  time_this_iter_s: 26.175832986831665
  time_total_s: 2776.0320403575897
  timestamp: 1594097543
  timesteps_since_restore: 1130000
  timesteps_this_iter: 10000
  timesteps_total: 1130000
  training_iteration: 113
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=13557], 2776 s, 113 iter, 1130000 ts, 1.19e+03 rew

agent-1: 96.0
agent-2: 127.0
agent-3: 114.0
agent-4: 76.0
agent-5: 125.0
agent-6: 126.0
agent-7: 119.0
agent-8: 127.0
agent-9: 74.0
agent-10: 100.0
Sum Reward: 1084.0
Avg Reward: 108.4
Min Reward: 74.0
Max Reward: 127.0
Gini Coefficient: 0.0981549815498155
20:20 Ratio: 1.6933333333333334
Max-min Ratio: 1.7162162162162162
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_00-52-47
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1836.0
  episode_reward_mean: 1185.68
  episode_reward_min: 799.0
  episodes_this_iter: 1
  episodes_total: 113
  experiment_id: a3942a9886f24694ab1b58ca8d1ab856
  hostname: gpu006
  info:
    apply_time_ms: 3.19
    dispatch_time_ms: 21.787
    learner:
      cur_lr: 0.0012847420293837786
      grad_gnorm: 39.99999237060547
      policy_entropy: 35.81595993041992
      policy_loss: -27.34581756591797
      var_gnorm: 38.02512741088867
      vf_explained_var: 0.4296165108680725
      vf_loss: 237.7855224609375
    num_steps_sampled: 1140000
    num_steps_trained: 1140000
    wait_time_ms: 232.86
  iterations_since_restore: 114
  node_ip: 172.17.8.6
  num_metric_batches_dropped: 0
  pid: 13557
  policy_reward_mean: {}
  time_since_restore: 2799.9620740413666
  time_this_iter_s: 23.930033683776855
  time_total_s: 2799.9620740413666
  timestamp: 1594097567
  timesteps_since_restore: 1140000
  timesteps_this_iter: 10000
  timesteps_total: 1140000
  training_iteration: 114
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=13557], 2799 s, 114 iter, 1140000 ts, 1.19e+03 rew

agent-1: 77.0
agent-2: 103.0
agent-3: 96.0
agent-4: 117.0
agent-5: 103.0
agent-6: 99.0
agent-7: 99.0
agent-8: 90.0
agent-9: 101.0
agent-10: 92.0
Sum Reward: 977.0
Avg Reward: 97.7
Min Reward: 77.0
Max Reward: 117.0
Gini Coefficient: 0.053326509723643806
20:20 Ratio: 1.3173652694610778
Max-min Ratio: 1.5194805194805194
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_00-53-13
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1836.0
  episode_reward_mean: 1184.73
  episode_reward_min: 799.0
  episodes_this_iter: 1
  episodes_total: 114
  experiment_id: a3942a9886f24694ab1b58ca8d1ab856
  hostname: gpu006
  info:
    apply_time_ms: 2.752
    dispatch_time_ms: 25.187
    learner:
      cur_lr: 0.0012840760173276067
      grad_gnorm: 40.00000762939453
      policy_entropy: 54.289085388183594
      policy_loss: -16.177295684814453
      var_gnorm: 38.182796478271484
      vf_explained_var: 0.1638668179512024
      vf_loss: 45.34017562866211
    num_steps_sampled: 1150000
    num_steps_trained: 1150000
    wait_time_ms: 198.213
  iterations_since_restore: 115
  node_ip: 172.17.8.6
  num_metric_batches_dropped: 0
  pid: 13557
  policy_reward_mean: {}
  time_since_restore: 2825.345154762268
  time_this_iter_s: 25.38308072090149
  time_total_s: 2825.345154762268
  timestamp: 1594097593
  timesteps_since_restore: 1150000
  timesteps_this_iter: 10000
  timesteps_total: 1150000
  training_iteration: 115
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=13557], 2825 s, 115 iter, 1150000 ts, 1.18e+03 rew

agent-1: 130.0
agent-2: 170.0
agent-3: 99.0
agent-4: 154.0
agent-5: 163.0
agent-6: 158.0
agent-7: 156.0
agent-8: 128.0
agent-9: 131.0
agent-10: 139.0
Sum Reward: 1428.0
Avg Reward: 142.8
Min Reward: 99.0
Max Reward: 170.0
Gini Coefficient: 0.07801120448179272
20:20 Ratio: 1.4669603524229076
Max-min Ratio: 1.7171717171717171
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_00-53-34
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1836.0
  episode_reward_mean: 1184.59
  episode_reward_min: 799.0
  episodes_this_iter: 1
  episodes_total: 115
  experiment_id: a3942a9886f24694ab1b58ca8d1ab856
  hostname: gpu006
  info:
    apply_time_ms: 3.16
    dispatch_time_ms: 26.611
    learner:
      cur_lr: 0.0012834100052714348
      grad_gnorm: 40.00000762939453
      policy_entropy: 44.7082405090332
      policy_loss: -6.489123821258545
      var_gnorm: 38.2914924621582
      vf_explained_var: 0.9489133954048157
      vf_loss: 22.61898422241211
    num_steps_sampled: 1160000
    num_steps_trained: 1160000
    wait_time_ms: 211.095
  iterations_since_restore: 116
  node_ip: 172.17.8.6
  num_metric_batches_dropped: 0
  pid: 13557
  policy_reward_mean: {}
  time_since_restore: 2846.454025745392
  time_this_iter_s: 21.10887098312378
  time_total_s: 2846.454025745392
  timestamp: 1594097614
  timesteps_since_restore: 1160000
  timesteps_this_iter: 10000
  timesteps_total: 1160000
  training_iteration: 116
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=13557], 2846 s, 116 iter, 1160000 ts, 1.18e+03 rew

agent-1: 131.0
agent-2: 144.0
agent-3: 155.0
agent-4: 146.0
agent-5: 121.0
agent-6: 117.0
agent-7: 123.0
agent-8: 136.0
agent-9: 121.0
agent-10: 115.0
Sum Reward: 1309.0
Avg Reward: 130.9
Min Reward: 115.0
Max Reward: 155.0
Gini Coefficient: 0.05584415584415584
20:20 Ratio: 1.2974137931034482
Max-min Ratio: 1.3478260869565217
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_00-53-59
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1836.0
  episode_reward_mean: 1184.13
  episode_reward_min: 799.0
  episodes_this_iter: 1
  episodes_total: 116
  experiment_id: a3942a9886f24694ab1b58ca8d1ab856
  hostname: gpu006
  info:
    apply_time_ms: 2.755
    dispatch_time_ms: 27.385
    learner:
      cur_lr: 0.0012827439932152629
      grad_gnorm: 40.0
      policy_entropy: 68.23181915283203
      policy_loss: 6.450496673583984
      var_gnorm: 38.37289810180664
      vf_explained_var: 0.5246216058731079
      vf_loss: 64.16697692871094
    num_steps_sampled: 1170000
    num_steps_trained: 1170000
    wait_time_ms: 203.792
  iterations_since_restore: 117
  node_ip: 172.17.8.6
  num_metric_batches_dropped: 0
  pid: 13557
  policy_reward_mean: {}
  time_since_restore: 2871.4895632267
  time_this_iter_s: 25.035537481307983
  time_total_s: 2871.4895632267
  timestamp: 1594097639
  timesteps_since_restore: 1170000
  timesteps_this_iter: 10000
  timesteps_total: 1170000
  training_iteration: 117
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=13557], 2871 s, 117 iter, 1170000 ts, 1.18e+03 rew

agent-1: 120.0
agent-2: 145.0
agent-3: 111.0
agent-4: 121.0
agent-5: 137.0
agent-6: 131.0
agent-7: 109.0
agent-8: 119.0
agent-9: 144.0
agent-10: 147.0
Sum Reward: 1284.0
Avg Reward: 128.4
Min Reward: 109.0
Max Reward: 147.0
Gini Coefficient: 0.05965732087227414
20:20 Ratio: 1.3272727272727274
Max-min Ratio: 1.348623853211009
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_00-54-23
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1836.0
  episode_reward_mean: 1186.65
  episode_reward_min: 799.0
  episodes_this_iter: 1
  episodes_total: 117
  experiment_id: a3942a9886f24694ab1b58ca8d1ab856
  hostname: gpu006
  info:
    apply_time_ms: 3.256
    dispatch_time_ms: 21.562
    learner:
      cur_lr: 0.001282077981159091
      grad_gnorm: 39.99999237060547
      policy_entropy: 104.24827575683594
      policy_loss: 14.673677444458008
      var_gnorm: 38.45140075683594
      vf_explained_var: 0.1049395203590393
      vf_loss: 17.69243621826172
    num_steps_sampled: 1180000
    num_steps_trained: 1180000
    wait_time_ms: 245.962
  iterations_since_restore: 118
  node_ip: 172.17.8.6
  num_metric_batches_dropped: 0
  pid: 13557
  policy_reward_mean: {}
  time_since_restore: 2895.9901807308197
  time_this_iter_s: 24.500617504119873
  time_total_s: 2895.9901807308197
  timestamp: 1594097663
  timesteps_since_restore: 1180000
  timesteps_this_iter: 10000
  timesteps_total: 1180000
  training_iteration: 118
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=13557], 2895 s, 118 iter, 1180000 ts, 1.19e+03 rew

agent-1: 113.0
agent-2: 110.0
agent-3: 94.0
agent-4: 103.0
agent-5: 98.0
agent-6: 105.0
agent-7: 111.0
agent-8: 95.0
agent-9: 103.0
agent-10: 93.0
Sum Reward: 1025.0
Avg Reward: 102.5
Min Reward: 93.0
Max Reward: 113.0
Gini Coefficient: 0.03853658536585366
20:20 Ratio: 1.1978609625668448
Max-min Ratio: 1.2150537634408602
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_00-54-50
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1836.0
  episode_reward_mean: 1183.69
  episode_reward_min: 799.0
  episodes_this_iter: 1
  episodes_total: 118
  experiment_id: a3942a9886f24694ab1b58ca8d1ab856
  hostname: gpu006
  info:
    apply_time_ms: 2.875
    dispatch_time_ms: 22.635
    learner:
      cur_lr: 0.001281411969102919
      grad_gnorm: 0.8037785291671753
      policy_entropy: 83.9120864868164
      policy_loss: -0.12103749811649323
      var_gnorm: 38.503360748291016
      vf_explained_var: 0.9957678318023682
      vf_loss: 0.0019991700537502766
    num_steps_sampled: 1190000
    num_steps_trained: 1190000
    wait_time_ms: 223.411
  iterations_since_restore: 119
  node_ip: 172.17.8.6
  num_metric_batches_dropped: 0
  pid: 13557
  policy_reward_mean: {}
  time_since_restore: 2922.377877473831
  time_this_iter_s: 26.387696743011475
  time_total_s: 2922.377877473831
  timestamp: 1594097690
  timesteps_since_restore: 1190000
  timesteps_this_iter: 10000
  timesteps_total: 1190000
  training_iteration: 119
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=13557], 2922 s, 119 iter, 1190000 ts, 1.18e+03 rew

agent-1: 107.0
agent-2: 106.0
agent-3: 86.0
agent-4: 104.0
agent-5: 111.0
agent-6: 91.0
agent-7: 99.0
agent-8: 94.0
agent-9: 109.0
agent-10: 138.0
Sum Reward: 1045.0
Avg Reward: 104.5
Min Reward: 86.0
Max Reward: 138.0
Gini Coefficient: 0.06784688995215311
20:20 Ratio: 1.4067796610169492
Max-min Ratio: 1.6046511627906976
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_00-55-14
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1836.0
  episode_reward_mean: 1183.6
  episode_reward_min: 799.0
  episodes_this_iter: 1
  episodes_total: 119
  experiment_id: a3942a9886f24694ab1b58ca8d1ab856
  hostname: gpu006
  info:
    apply_time_ms: 3.408
    dispatch_time_ms: 17.984
    learner:
      cur_lr: 0.0012807459570467472
      grad_gnorm: 39.99999237060547
      policy_entropy: 22.12877655029297
      policy_loss: -15.843753814697266
      var_gnorm: 38.54987335205078
      vf_explained_var: 0.7998785972595215
      vf_loss: 130.475341796875
    num_steps_sampled: 1200000
    num_steps_trained: 1200000
    wait_time_ms: 223.324
  iterations_since_restore: 120
  node_ip: 172.17.8.6
  num_metric_batches_dropped: 0
  pid: 13557
  policy_reward_mean: {}
  time_since_restore: 2946.3499126434326
  time_this_iter_s: 23.97203516960144
  time_total_s: 2946.3499126434326
  timestamp: 1594097714
  timesteps_since_restore: 1200000
  timesteps_this_iter: 10000
  timesteps_total: 1200000
  training_iteration: 120
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=13557], 2946 s, 120 iter, 1200000 ts, 1.18e+03 rew

agent-1: 110.0
agent-2: 111.0
agent-3: 143.0
agent-4: 108.0
agent-5: 117.0
agent-6: 104.0
agent-7: 96.0
agent-8: 92.0
agent-9: 118.0
agent-10: 99.0
Sum Reward: 1098.0
Avg Reward: 109.8
Min Reward: 92.0
Max Reward: 143.0
Gini Coefficient: 0.06612021857923497
20:20 Ratio: 1.3882978723404256
Max-min Ratio: 1.5543478260869565
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_00-55-40
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1836.0
  episode_reward_mean: 1179.62
  episode_reward_min: 799.0
  episodes_this_iter: 1
  episodes_total: 120
  experiment_id: a3942a9886f24694ab1b58ca8d1ab856
  hostname: gpu006
  info:
    apply_time_ms: 2.734
    dispatch_time_ms: 23.458
    learner:
      cur_lr: 0.0012800799449905753
      grad_gnorm: 40.0
      policy_entropy: 9.992535591125488
      policy_loss: 18.820964813232422
      var_gnorm: 38.67324447631836
      vf_explained_var: 0.37383055686950684
      vf_loss: 88.48409271240234
    num_steps_sampled: 1210000
    num_steps_trained: 1210000
    wait_time_ms: 201.157
  iterations_since_restore: 121
  node_ip: 172.17.8.6
  num_metric_batches_dropped: 0
  pid: 13557
  policy_reward_mean: {}
  time_since_restore: 2972.5098354816437
  time_this_iter_s: 26.15992283821106
  time_total_s: 2972.5098354816437
  timestamp: 1594097740
  timesteps_since_restore: 1210000
  timesteps_this_iter: 10000
  timesteps_total: 1210000
  training_iteration: 121
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=13557], 2972 s, 121 iter, 1210000 ts, 1.18e+03 rew

agent-1: 131.0
agent-2: 98.0
agent-3: 119.0
agent-4: 119.0
agent-5: 103.0
agent-6: 79.0
agent-7: 78.0
agent-8: 105.0
agent-9: 114.0
agent-10: 96.0
Sum Reward: 1042.0
Avg Reward: 104.2
Min Reward: 78.0
Max Reward: 131.0
Gini Coefficient: 0.08848368522072937
20:20 Ratio: 1.5923566878980893
Max-min Ratio: 1.6794871794871795
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_00-56-05
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1836.0
  episode_reward_mean: 1174.27
  episode_reward_min: 799.0
  episodes_this_iter: 1
  episodes_total: 121
  experiment_id: a3942a9886f24694ab1b58ca8d1ab856
  hostname: gpu006
  info:
    apply_time_ms: 2.955
    dispatch_time_ms: 31.058
    learner:
      cur_lr: 0.0012794140493497252
      grad_gnorm: 40.000003814697266
      policy_entropy: 22.749082565307617
      policy_loss: 4.315063953399658
      var_gnorm: 38.71755599975586
      vf_explained_var: 0.7751606702804565
      vf_loss: 288.9566955566406
    num_steps_sampled: 1220000
    num_steps_trained: 1220000
    wait_time_ms: 217.75
  iterations_since_restore: 122
  node_ip: 172.17.8.6
  num_metric_batches_dropped: 0
  pid: 13557
  policy_reward_mean: {}
  time_since_restore: 2996.963939666748
  time_this_iter_s: 24.45410418510437
  time_total_s: 2996.963939666748
  timestamp: 1594097765
  timesteps_since_restore: 1220000
  timesteps_this_iter: 10000
  timesteps_total: 1220000
  training_iteration: 122
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=13557], 2996 s, 122 iter, 1220000 ts, 1.17e+03 rew

agent-1: 94.0
agent-2: 105.0
agent-3: 90.0
agent-4: 103.0
agent-5: 109.0
agent-6: 73.0
agent-7: 103.0
agent-8: 116.0
agent-9: 115.0
agent-10: 94.0
Sum Reward: 1002.0
Avg Reward: 100.2
Min Reward: 73.0
Max Reward: 116.0
Gini Coefficient: 0.06686626746506986
20:20 Ratio: 1.4171779141104295
Max-min Ratio: 1.5890410958904109
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_00-56-31
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1836.0
  episode_reward_mean: 1172.9
  episode_reward_min: 799.0
  episodes_this_iter: 1
  episodes_total: 122
  experiment_id: a3942a9886f24694ab1b58ca8d1ab856
  hostname: gpu006
  info:
    apply_time_ms: 2.559
    dispatch_time_ms: 25.399
    learner:
      cur_lr: 0.0012787480372935534
      grad_gnorm: 34.0302734375
      policy_entropy: 70.91484832763672
      policy_loss: -2.3372998237609863
      var_gnorm: 38.78690719604492
      vf_explained_var: 0.5893235206604004
      vf_loss: 0.5816622376441956
    num_steps_sampled: 1230000
    num_steps_trained: 1230000
    wait_time_ms: 230.221
  iterations_since_restore: 123
  node_ip: 172.17.8.6
  num_metric_batches_dropped: 0
  pid: 13557
  policy_reward_mean: {}
  time_since_restore: 3023.364277601242
  time_this_iter_s: 26.40033793449402
  time_total_s: 3023.364277601242
  timestamp: 1594097791
  timesteps_since_restore: 1230000
  timesteps_this_iter: 10000
  timesteps_total: 1230000
  training_iteration: 123
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=13557], 3023 s, 123 iter, 1230000 ts, 1.17e+03 rew

agent-1: 88.0
agent-2: 111.0
agent-3: 94.0
agent-4: 114.0
agent-5: 111.0
agent-6: 102.0
agent-7: 96.0
agent-8: 103.0
agent-9: 104.0
agent-10: 103.0
Sum Reward: 1026.0
Avg Reward: 102.6
Min Reward: 88.0
Max Reward: 114.0
Gini Coefficient: 0.04230019493177388
20:20 Ratio: 1.2362637362637363
Max-min Ratio: 1.2954545454545454
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_00-56-56
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1836.0
  episode_reward_mean: 1172.3
  episode_reward_min: 799.0
  episodes_this_iter: 1
  episodes_total: 123
  experiment_id: a3942a9886f24694ab1b58ca8d1ab856
  hostname: gpu006
  info:
    apply_time_ms: 3.229
    dispatch_time_ms: 33.272
    learner:
      cur_lr: 0.0012780820252373815
      grad_gnorm: 9.091658592224121
      policy_entropy: 61.62446212768555
      policy_loss: -1.7343999147415161
      var_gnorm: 38.96025848388672
      vf_explained_var: 0.9882392883300781
      vf_loss: 0.0799761414527893
    num_steps_sampled: 1240000
    num_steps_trained: 1240000
    wait_time_ms: 245.645
  iterations_since_restore: 124
  node_ip: 172.17.8.6
  num_metric_batches_dropped: 0
  pid: 13557
  policy_reward_mean: {}
  time_since_restore: 3048.057952642441
  time_this_iter_s: 24.69367504119873
  time_total_s: 3048.057952642441
  timestamp: 1594097816
  timesteps_since_restore: 1240000
  timesteps_this_iter: 10000
  timesteps_total: 1240000
  training_iteration: 124
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=13557], 3048 s, 124 iter, 1240000 ts, 1.17e+03 rew

agent-1: 54.0
agent-2: 63.0
agent-3: 82.0
agent-4: 89.0
agent-5: 74.0
agent-6: 102.0
agent-7: 60.0
agent-8: 76.0
agent-9: 64.0
agent-10: 60.0
Sum Reward: 724.0
Avg Reward: 72.4
Min Reward: 54.0
Max Reward: 102.0
Gini Coefficient: 0.10966850828729281
20:20 Ratio: 1.6754385964912282
Max-min Ratio: 1.8888888888888888
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_00-57-22
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1836.0
  episode_reward_mean: 1166.79
  episode_reward_min: 724.0
  episodes_this_iter: 1
  episodes_total: 124
  experiment_id: a3942a9886f24694ab1b58ca8d1ab856
  hostname: gpu006
  info:
    apply_time_ms: 2.772
    dispatch_time_ms: 34.095
    learner:
      cur_lr: 0.0012774160131812096
      grad_gnorm: 40.00001907348633
      policy_entropy: 92.58655548095703
      policy_loss: 27.848480224609375
      var_gnorm: 39.044639587402344
      vf_explained_var: 0.5059645175933838
      vf_loss: 73.88963317871094
    num_steps_sampled: 1250000
    num_steps_trained: 1250000
    wait_time_ms: 197.652
  iterations_since_restore: 125
  node_ip: 172.17.8.6
  num_metric_batches_dropped: 0
  pid: 13557
  policy_reward_mean: {}
  time_since_restore: 3074.5644013881683
  time_this_iter_s: 26.50644874572754
  time_total_s: 3074.5644013881683
  timestamp: 1594097842
  timesteps_since_restore: 1250000
  timesteps_this_iter: 10000
  timesteps_total: 1250000
  training_iteration: 125
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=13557], 3074 s, 125 iter, 1250000 ts, 1.17e+03 rew

agent-1: 121.0
agent-2: 117.0
agent-3: 109.0
agent-4: 127.0
agent-5: 111.0
agent-6: 87.0
agent-7: 91.0
agent-8: 127.0
agent-9: 138.0
agent-10: 126.0
Sum Reward: 1154.0
Avg Reward: 115.4
Min Reward: 87.0
Max Reward: 138.0
Gini Coefficient: 0.07365684575389948
20:20 Ratio: 1.4887640449438202
Max-min Ratio: 1.5862068965517242
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_00-57-47
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1836.0
  episode_reward_mean: 1168.6
  episode_reward_min: 724.0
  episodes_this_iter: 1
  episodes_total: 125
  experiment_id: a3942a9886f24694ab1b58ca8d1ab856
  hostname: gpu006
  info:
    apply_time_ms: 3.002
    dispatch_time_ms: 24.516
    learner:
      cur_lr: 0.0012767500011250377
      grad_gnorm: 40.0000114440918
      policy_entropy: 28.34720230102539
      policy_loss: 5.314912796020508
      var_gnorm: 39.163055419921875
      vf_explained_var: 0.4742942452430725
      vf_loss: 293.8814392089844
    num_steps_sampled: 1260000
    num_steps_trained: 1260000
    wait_time_ms: 210.334
  iterations_since_restore: 126
  node_ip: 172.17.8.6
  num_metric_batches_dropped: 0
  pid: 13557
  policy_reward_mean: {}
  time_since_restore: 3098.8063197135925
  time_this_iter_s: 24.241918325424194
  time_total_s: 3098.8063197135925
  timestamp: 1594097867
  timesteps_since_restore: 1260000
  timesteps_this_iter: 10000
  timesteps_total: 1260000
  training_iteration: 126
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=13557], 3098 s, 126 iter, 1260000 ts, 1.17e+03 rew

agent-1: 130.0
agent-2: 126.0
agent-3: 135.0
agent-4: 149.0
agent-5: 154.0
agent-6: 135.0
agent-7: 152.0
agent-8: 151.0
agent-9: 150.0
agent-10: 145.0
Sum Reward: 1427.0
Avg Reward: 142.7
Min Reward: 126.0
Max Reward: 154.0
Gini Coefficient: 0.03749124036440084
20:20 Ratio: 1.1953125
Max-min Ratio: 1.2222222222222223
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_00-58-13
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1836.0
  episode_reward_mean: 1168.86
  episode_reward_min: 724.0
  episodes_this_iter: 1
  episodes_total: 126
  experiment_id: a3942a9886f24694ab1b58ca8d1ab856
  hostname: gpu006
  info:
    apply_time_ms: 2.996
    dispatch_time_ms: 30.183
    learner:
      cur_lr: 0.0012760839890688658
      grad_gnorm: 8.311405181884766
      policy_entropy: 73.18151092529297
      policy_loss: -2.4411919116973877
      var_gnorm: 39.262420654296875
      vf_explained_var: 0.9924549460411072
      vf_loss: 0.05491526797413826
    num_steps_sampled: 1270000
    num_steps_trained: 1270000
    wait_time_ms: 203.236
  iterations_since_restore: 127
  node_ip: 172.17.8.6
  num_metric_batches_dropped: 0
  pid: 13557
  policy_reward_mean: {}
  time_since_restore: 3123.918716907501
  time_this_iter_s: 25.11239719390869
  time_total_s: 3123.918716907501
  timestamp: 1594097893
  timesteps_since_restore: 1270000
  timesteps_this_iter: 10000
  timesteps_total: 1270000
  training_iteration: 127
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=13557], 3123 s, 127 iter, 1270000 ts, 1.17e+03 rew

agent-1: 129.0
agent-2: 141.0
agent-3: 98.0
agent-4: 124.0
agent-5: 152.0
agent-6: 143.0
agent-7: 116.0
agent-8: 101.0
agent-9: 144.0
agent-10: 115.0
Sum Reward: 1263.0
Avg Reward: 126.3
Min Reward: 98.0
Max Reward: 152.0
Gini Coefficient: 0.07973079968329375
20:20 Ratio: 1.4874371859296482
Max-min Ratio: 1.5510204081632653
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_00-58-37
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1836.0
  episode_reward_mean: 1165.69
  episode_reward_min: 724.0
  episodes_this_iter: 1
  episodes_total: 127
  experiment_id: a3942a9886f24694ab1b58ca8d1ab856
  hostname: gpu006
  info:
    apply_time_ms: 3.855
    dispatch_time_ms: 51.694
    learner:
      cur_lr: 0.0012754179770126939
      grad_gnorm: 23.48232650756836
      policy_entropy: 56.85844039916992
      policy_loss: -2.23456072807312
      var_gnorm: 39.34142303466797
      vf_explained_var: 0.21946007013320923
      vf_loss: 1.1170884370803833
    num_steps_sampled: 1280000
    num_steps_trained: 1280000
    wait_time_ms: 226.161
  iterations_since_restore: 128
  node_ip: 172.17.8.6
  num_metric_batches_dropped: 0
  pid: 13557
  policy_reward_mean: {}
  time_since_restore: 3148.2328655719757
  time_this_iter_s: 24.314148664474487
  time_total_s: 3148.2328655719757
  timestamp: 1594097917
  timesteps_since_restore: 1280000
  timesteps_this_iter: 10000
  timesteps_total: 1280000
  training_iteration: 128
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=13557], 3148 s, 128 iter, 1280000 ts, 1.17e+03 rew

agent-1: 75.0
agent-2: 94.0
agent-3: 121.0
agent-4: 117.0
agent-5: 98.0
agent-6: 112.0
agent-7: 105.0
agent-8: 83.0
agent-9: 111.0
agent-10: 79.0
Sum Reward: 995.0
Avg Reward: 99.5
Min Reward: 75.0
Max Reward: 121.0
Gini Coefficient: 0.08874371859296483
20:20 Ratio: 1.5454545454545454
Max-min Ratio: 1.6133333333333333
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_00-59-04
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1836.0
  episode_reward_mean: 1164.89
  episode_reward_min: 724.0
  episodes_this_iter: 1
  episodes_total: 128
  experiment_id: a3942a9886f24694ab1b58ca8d1ab856
  hostname: gpu006
  info:
    apply_time_ms: 3.701
    dispatch_time_ms: 26.805
    learner:
      cur_lr: 0.001274751964956522
      grad_gnorm: 39.999996185302734
      policy_entropy: 5.828085899353027
      policy_loss: 1.8888112306594849
      var_gnorm: 39.41093826293945
      vf_explained_var: -0.5148230791091919
      vf_loss: 98.63541412353516
    num_steps_sampled: 1290000
    num_steps_trained: 1290000
    wait_time_ms: 188.7
  iterations_since_restore: 129
  node_ip: 172.17.8.6
  num_metric_batches_dropped: 0
  pid: 13557
  policy_reward_mean: {}
  time_since_restore: 3174.8216021060944
  time_this_iter_s: 26.588736534118652
  time_total_s: 3174.8216021060944
  timestamp: 1594097944
  timesteps_since_restore: 1290000
  timesteps_this_iter: 10000
  timesteps_total: 1290000
  training_iteration: 129
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=13557], 3174 s, 129 iter, 1290000 ts, 1.16e+03 rew

agent-1: 84.0
agent-2: 109.0
agent-3: 65.0
agent-4: 98.0
agent-5: 105.0
agent-6: 64.0
agent-7: 72.0
agent-8: 93.0
agent-9: 89.0
agent-10: 80.0
Sum Reward: 859.0
Avg Reward: 85.9
Min Reward: 64.0
Max Reward: 109.0
Gini Coefficient: 0.1
20:20 Ratio: 1.6589147286821706
Max-min Ratio: 1.703125
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_00-59-28
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1836.0
  episode_reward_mean: 1163.04
  episode_reward_min: 724.0
  episodes_this_iter: 1
  episodes_total: 129
  experiment_id: a3942a9886f24694ab1b58ca8d1ab856
  hostname: gpu006
  info:
    apply_time_ms: 2.977
    dispatch_time_ms: 16.297
    learner:
      cur_lr: 0.00127408595290035
      grad_gnorm: 13.945364952087402
      policy_entropy: 87.81954193115234
      policy_loss: -0.5680264234542847
      var_gnorm: 39.61241912841797
      vf_explained_var: 0.778518795967102
      vf_loss: 4.144566059112549
    num_steps_sampled: 1300000
    num_steps_trained: 1300000
    wait_time_ms: 245.965
  iterations_since_restore: 130
  node_ip: 172.17.8.6
  num_metric_batches_dropped: 0
  pid: 13557
  policy_reward_mean: {}
  time_since_restore: 3199.006287574768
  time_this_iter_s: 24.184685468673706
  time_total_s: 3199.006287574768
  timestamp: 1594097968
  timesteps_since_restore: 1300000
  timesteps_this_iter: 10000
  timesteps_total: 1300000
  training_iteration: 130
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=13557], 3199 s, 130 iter, 1300000 ts, 1.16e+03 rew

agent-1: 81.0
agent-2: 93.0
agent-3: 85.0
agent-4: 104.0
agent-5: 105.0
agent-6: 67.0
agent-7: 85.0
agent-8: 84.0
agent-9: 68.0
agent-10: 105.0
Sum Reward: 877.0
Avg Reward: 87.7
Min Reward: 67.0
Max Reward: 105.0
Gini Coefficient: 0.0847206385404789
20:20 Ratio: 1.5555555555555556
Max-min Ratio: 1.5671641791044777
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_00-59-55
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1836.0
  episode_reward_mean: 1158.15
  episode_reward_min: 724.0
  episodes_this_iter: 1
  episodes_total: 130
  experiment_id: a3942a9886f24694ab1b58ca8d1ab856
  hostname: gpu006
  info:
    apply_time_ms: 3.7
    dispatch_time_ms: 33.494
    learner:
      cur_lr: 0.0012734200572595
      grad_gnorm: 40.000003814697266
      policy_entropy: 29.550926208496094
      policy_loss: -9.392701148986816
      var_gnorm: 39.693294525146484
      vf_explained_var: 0.27890461683273315
      vf_loss: 124.66293334960938
    num_steps_sampled: 1310000
    num_steps_trained: 1310000
    wait_time_ms: 176.756
  iterations_since_restore: 131
  node_ip: 172.17.8.6
  num_metric_batches_dropped: 0
  pid: 13557
  policy_reward_mean: {}
  time_since_restore: 3225.791538476944
  time_this_iter_s: 26.785250902175903
  time_total_s: 3225.791538476944
  timestamp: 1594097995
  timesteps_since_restore: 1310000
  timesteps_this_iter: 10000
  timesteps_total: 1310000
  training_iteration: 131
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=13557], 3225 s, 131 iter, 1310000 ts, 1.16e+03 rew

agent-1: 119.0
agent-2: 94.0
agent-3: 94.0
agent-4: 110.0
agent-5: 140.0
agent-6: 96.0
agent-7: 101.0
agent-8: 107.0
agent-9: 100.0
agent-10: 110.0
Sum Reward: 1071.0
Avg Reward: 107.1
Min Reward: 94.0
Max Reward: 140.0
Gini Coefficient: 0.06489262371615313
20:20 Ratio: 1.377659574468085
Max-min Ratio: 1.4893617021276595
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_01-00-18
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1836.0
  episode_reward_mean: 1157.14
  episode_reward_min: 724.0
  episodes_this_iter: 1
  episodes_total: 131
  experiment_id: a3942a9886f24694ab1b58ca8d1ab856
  hostname: gpu006
  info:
    apply_time_ms: 2.703
    dispatch_time_ms: 28.895
    learner:
      cur_lr: 0.0012727540452033281
      grad_gnorm: 40.00000762939453
      policy_entropy: 73.0639419555664
      policy_loss: -26.555139541625977
      var_gnorm: 39.78727722167969
      vf_explained_var: -1.0
      vf_loss: 53.18939971923828
    num_steps_sampled: 1320000
    num_steps_trained: 1320000
    wait_time_ms: 234.607
  iterations_since_restore: 132
  node_ip: 172.17.8.6
  num_metric_batches_dropped: 0
  pid: 13557
  policy_reward_mean: {}
  time_since_restore: 3249.343347787857
  time_this_iter_s: 23.551809310913086
  time_total_s: 3249.343347787857
  timestamp: 1594098018
  timesteps_since_restore: 1320000
  timesteps_this_iter: 10000
  timesteps_total: 1320000
  training_iteration: 132
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=13557], 3249 s, 132 iter, 1320000 ts, 1.16e+03 rew

agent-1: 94.0
agent-2: 95.0
agent-3: 109.0
agent-4: 121.0
agent-5: 111.0
agent-6: 103.0
agent-7: 107.0
agent-8: 147.0
agent-9: 118.0
agent-10: 119.0
Sum Reward: 1124.0
Avg Reward: 112.4
Min Reward: 94.0
Max Reward: 147.0
Gini Coefficient: 0.0688612099644128
20:20 Ratio: 1.417989417989418
Max-min Ratio: 1.5638297872340425
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_01-00-45
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1651.0
  episode_reward_mean: 1150.02
  episode_reward_min: 724.0
  episodes_this_iter: 1
  episodes_total: 132
  experiment_id: a3942a9886f24694ab1b58ca8d1ab856
  hostname: gpu006
  info:
    apply_time_ms: 2.648
    dispatch_time_ms: 25.205
    learner:
      cur_lr: 0.0012720880331471562
      grad_gnorm: 4.741355895996094
      policy_entropy: 77.70431518554688
      policy_loss: 4.509926795959473
      var_gnorm: 39.84761047363281
      vf_explained_var: 0.9961926341056824
      vf_loss: 0.008966033346951008
    num_steps_sampled: 1330000
    num_steps_trained: 1330000
    wait_time_ms: 190.907
  iterations_since_restore: 133
  node_ip: 172.17.8.6
  num_metric_batches_dropped: 0
  pid: 13557
  policy_reward_mean: {}
  time_since_restore: 3276.1056871414185
  time_this_iter_s: 26.7623393535614
  time_total_s: 3276.1056871414185
  timestamp: 1594098045
  timesteps_since_restore: 1330000
  timesteps_this_iter: 10000
  timesteps_total: 1330000
  training_iteration: 133
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=13557], 3276 s, 133 iter, 1330000 ts, 1.15e+03 rew

agent-1: 101.0
agent-2: 107.0
agent-3: 90.0
agent-4: 79.0
agent-5: 121.0
agent-6: 120.0
agent-7: 114.0
agent-8: 99.0
agent-9: 115.0
agent-10: 82.0
Sum Reward: 1028.0
Avg Reward: 102.8
Min Reward: 79.0
Max Reward: 121.0
Gini Coefficient: 0.07976653696498054
20:20 Ratio: 1.4968944099378882
Max-min Ratio: 1.5316455696202531
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_01-01-09
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1651.0
  episode_reward_mean: 1148.08
  episode_reward_min: 724.0
  episodes_this_iter: 1
  episodes_total: 133
  experiment_id: a3942a9886f24694ab1b58ca8d1ab856
  hostname: gpu006
  info:
    apply_time_ms: 2.842
    dispatch_time_ms: 25.515
    learner:
      cur_lr: 0.0012714220210909843
      grad_gnorm: 40.0
      policy_entropy: 29.399805068969727
      policy_loss: -56.392478942871094
      var_gnorm: 40.01220703125
      vf_explained_var: -0.9233214855194092
      vf_loss: 406.1986389160156
    num_steps_sampled: 1340000
    num_steps_trained: 1340000
    wait_time_ms: 233.038
  iterations_since_restore: 134
  node_ip: 172.17.8.6
  num_metric_batches_dropped: 0
  pid: 13557
  policy_reward_mean: {}
  time_since_restore: 3299.9718947410583
  time_this_iter_s: 23.866207599639893
  time_total_s: 3299.9718947410583
  timestamp: 1594098069
  timesteps_since_restore: 1340000
  timesteps_this_iter: 10000
  timesteps_total: 1340000
  training_iteration: 134
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=13557], 3299 s, 134 iter, 1340000 ts, 1.15e+03 rew

agent-1: 125.0
agent-2: 111.0
agent-3: 112.0
agent-4: 119.0
agent-5: 127.0
agent-6: 118.0
agent-7: 113.0
agent-8: 78.0
agent-9: 107.0
agent-10: 118.0
Sum Reward: 1128.0
Avg Reward: 112.8
Min Reward: 78.0
Max Reward: 127.0
Gini Coefficient: 0.05585106382978723
20:20 Ratio: 1.3621621621621622
Max-min Ratio: 1.6282051282051282
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_01-01-36
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1651.0
  episode_reward_mean: 1147.45
  episode_reward_min: 724.0
  episodes_this_iter: 1
  episodes_total: 134
  experiment_id: a3942a9886f24694ab1b58ca8d1ab856
  hostname: gpu006
  info:
    apply_time_ms: 3.082
    dispatch_time_ms: 32.377
    learner:
      cur_lr: 0.0012707560090348125
      grad_gnorm: 40.0
      policy_entropy: 14.506070137023926
      policy_loss: 4.382289886474609
      var_gnorm: 40.099037170410156
      vf_explained_var: -0.22323167324066162
      vf_loss: 114.68952941894531
    num_steps_sampled: 1350000
    num_steps_trained: 1350000
    wait_time_ms: 201.431
  iterations_since_restore: 135
  node_ip: 172.17.8.6
  num_metric_batches_dropped: 0
  pid: 13557
  policy_reward_mean: {}
  time_since_restore: 3326.4843049049377
  time_this_iter_s: 26.512410163879395
  time_total_s: 3326.4843049049377
  timestamp: 1594098096
  timesteps_since_restore: 1350000
  timesteps_this_iter: 10000
  timesteps_total: 1350000
  training_iteration: 135
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=13557], 3326 s, 135 iter, 1350000 ts, 1.15e+03 rew

agent-1: 110.0
agent-2: 106.0
agent-3: 93.0
agent-4: 73.0
agent-5: 119.0
agent-6: 118.0
agent-7: 86.0
agent-8: 134.0
agent-9: 129.0
agent-10: 91.0
Sum Reward: 1059.0
Avg Reward: 105.9
Min Reward: 73.0
Max Reward: 134.0
Gini Coefficient: 0.10094428706326723
20:20 Ratio: 1.6540880503144655
Max-min Ratio: 1.8356164383561644
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_01-01-58
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1651.0
  episode_reward_mean: 1147.21
  episode_reward_min: 724.0
  episodes_this_iter: 1
  episodes_total: 135
  experiment_id: a3942a9886f24694ab1b58ca8d1ab856
  hostname: gpu006
  info:
    apply_time_ms: 3.428
    dispatch_time_ms: 24.652
    learner:
      cur_lr: 0.0012700899969786406
      grad_gnorm: 40.0
      policy_entropy: 14.59798812866211
      policy_loss: -5.915423393249512
      var_gnorm: 40.13290786743164
      vf_explained_var: 0.5932862162590027
      vf_loss: 120.48939514160156
    num_steps_sampled: 1360000
    num_steps_trained: 1360000
    wait_time_ms: 201.065
  iterations_since_restore: 136
  node_ip: 172.17.8.6
  num_metric_batches_dropped: 0
  pid: 13557
  policy_reward_mean: {}
  time_since_restore: 3348.8590495586395
  time_this_iter_s: 22.374744653701782
  time_total_s: 3348.8590495586395
  timestamp: 1594098118
  timesteps_since_restore: 1360000
  timesteps_this_iter: 10000
  timesteps_total: 1360000
  training_iteration: 136
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=13557], 3348 s, 136 iter, 1360000 ts, 1.15e+03 rew

agent-1: 132.0
agent-2: 130.0
agent-3: 125.0
agent-4: 110.0
agent-5: 215.0
agent-6: 174.0
agent-7: 145.0
agent-8: 148.0
agent-9: 164.0
agent-10: 116.0
Sum Reward: 1459.0
Avg Reward: 145.9
Min Reward: 110.0
Max Reward: 215.0
Gini Coefficient: 0.11055517477724469
20:20 Ratio: 1.7212389380530972
Max-min Ratio: 1.9545454545454546
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_01-02-24
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1651.0
  episode_reward_mean: 1149.76
  episode_reward_min: 724.0
  episodes_this_iter: 1
  episodes_total: 136
  experiment_id: a3942a9886f24694ab1b58ca8d1ab856
  hostname: gpu006
  info:
    apply_time_ms: 2.968
    dispatch_time_ms: 22.36
    learner:
      cur_lr: 0.0012694239849224687
      grad_gnorm: 9.655317306518555
      policy_entropy: 56.985347747802734
      policy_loss: 0.7618751525878906
      var_gnorm: 40.234580993652344
      vf_explained_var: -1.0
      vf_loss: 0.20436932146549225
    num_steps_sampled: 1370000
    num_steps_trained: 1370000
    wait_time_ms: 203.993
  iterations_since_restore: 137
  node_ip: 172.17.8.6
  num_metric_batches_dropped: 0
  pid: 13557
  policy_reward_mean: {}
  time_since_restore: 3374.5098192691803
  time_this_iter_s: 25.65076971054077
  time_total_s: 3374.5098192691803
  timestamp: 1594098144
  timesteps_since_restore: 1370000
  timesteps_this_iter: 10000
  timesteps_total: 1370000
  training_iteration: 137
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=13557], 3374 s, 137 iter, 1370000 ts, 1.15e+03 rew

agent-1: 125.0
agent-2: 142.0
agent-3: 110.0
agent-4: 158.0
agent-5: 172.0
agent-6: 110.0
agent-7: 122.0
agent-8: 99.0
agent-9: 138.0
agent-10: 161.0
Sum Reward: 1337.0
Avg Reward: 133.7
Min Reward: 99.0
Max Reward: 172.0
Gini Coefficient: 0.09925205684367988
20:20 Ratio: 1.5933014354066986
Max-min Ratio: 1.7373737373737375
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_01-02-46
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1563.0
  episode_reward_mean: 1146.62
  episode_reward_min: 724.0
  episodes_this_iter: 1
  episodes_total: 137
  experiment_id: a3942a9886f24694ab1b58ca8d1ab856
  hostname: gpu006
  info:
    apply_time_ms: 2.737
    dispatch_time_ms: 29.04
    learner:
      cur_lr: 0.0012687579728662968
      grad_gnorm: 39.999996185302734
      policy_entropy: 47.59713363647461
      policy_loss: 10.127099990844727
      var_gnorm: 40.36372375488281
      vf_explained_var: 0.1881207823753357
      vf_loss: 77.68041229248047
    num_steps_sampled: 1380000
    num_steps_trained: 1380000
    wait_time_ms: 192.932
  iterations_since_restore: 138
  node_ip: 172.17.8.6
  num_metric_batches_dropped: 0
  pid: 13557
  policy_reward_mean: {}
  time_since_restore: 3396.9018080234528
  time_this_iter_s: 22.39198875427246
  time_total_s: 3396.9018080234528
  timestamp: 1594098166
  timesteps_since_restore: 1380000
  timesteps_this_iter: 10000
  timesteps_total: 1380000
  training_iteration: 138
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=13557], 3396 s, 138 iter, 1380000 ts, 1.15e+03 rew

agent-1: 146.0
agent-2: 118.0
agent-3: 120.0
agent-4: 143.0
agent-5: 131.0
agent-6: 139.0
agent-7: 150.0
agent-8: 129.0
agent-9: 129.0
agent-10: 142.0
Sum Reward: 1347.0
Avg Reward: 134.7
Min Reward: 118.0
Max Reward: 150.0
Gini Coefficient: 0.04357832219747587
20:20 Ratio: 1.2436974789915967
Max-min Ratio: 1.271186440677966
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_01-03-11
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1558.0
  episode_reward_mean: 1144.46
  episode_reward_min: 724.0
  episodes_this_iter: 1
  episodes_total: 138
  experiment_id: a3942a9886f24694ab1b58ca8d1ab856
  hostname: gpu006
  info:
    apply_time_ms: 2.996
    dispatch_time_ms: 29.419
    learner:
      cur_lr: 0.0012680919608101249
      grad_gnorm: 40.0
      policy_entropy: 42.06195831298828
      policy_loss: 0.6355175971984863
      var_gnorm: 40.452762603759766
      vf_explained_var: 0.05635863542556763
      vf_loss: 153.4414825439453
    num_steps_sampled: 1390000
    num_steps_trained: 1390000
    wait_time_ms: 197.58
  iterations_since_restore: 139
  node_ip: 172.17.8.6
  num_metric_batches_dropped: 0
  pid: 13557
  policy_reward_mean: {}
  time_since_restore: 3421.8835875988007
  time_this_iter_s: 24.9817795753479
  time_total_s: 3421.8835875988007
  timestamp: 1594098191
  timesteps_since_restore: 1390000
  timesteps_this_iter: 10000
  timesteps_total: 1390000
  training_iteration: 139
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=13557], 3421 s, 139 iter, 1390000 ts, 1.14e+03 rew

agent-1: 149.0
agent-2: 124.0
agent-3: 149.0
agent-4: 104.0
agent-5: 194.0
agent-6: 100.0
agent-7: 123.0
agent-8: 170.0
agent-9: 153.0
agent-10: 166.0
Sum Reward: 1432.0
Avg Reward: 143.2
Min Reward: 100.0
Max Reward: 194.0
Gini Coefficient: 0.11243016759776536
20:20 Ratio: 1.7843137254901962
Max-min Ratio: 1.94
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_01-03-35
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1558.0
  episode_reward_mean: 1144.71
  episode_reward_min: 724.0
  episodes_this_iter: 1
  episodes_total: 139
  experiment_id: a3942a9886f24694ab1b58ca8d1ab856
  hostname: gpu006
  info:
    apply_time_ms: 4.013
    dispatch_time_ms: 27.379
    learner:
      cur_lr: 0.001267425948753953
      grad_gnorm: 40.00000762939453
      policy_entropy: 56.116920471191406
      policy_loss: 3.190335273742676
      var_gnorm: 40.53285598754883
      vf_explained_var: 0.8800560832023621
      vf_loss: 17.369728088378906
    num_steps_sampled: 1400000
    num_steps_trained: 1400000
    wait_time_ms: 208.524
  iterations_since_restore: 140
  node_ip: 172.17.8.6
  num_metric_batches_dropped: 0
  pid: 13557
  policy_reward_mean: {}
  time_since_restore: 3445.5670804977417
  time_this_iter_s: 23.68349289894104
  time_total_s: 3445.5670804977417
  timestamp: 1594098215
  timesteps_since_restore: 1400000
  timesteps_this_iter: 10000
  timesteps_total: 1400000
  training_iteration: 140
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=13557], 3445 s, 140 iter, 1400000 ts, 1.14e+03 rew

agent-1: 110.0
agent-2: 124.0
agent-3: 102.0
agent-4: 123.0
agent-5: 101.0
agent-6: 115.0
agent-7: 123.0
agent-8: 114.0
agent-9: 111.0
agent-10: 118.0
Sum Reward: 1141.0
Avg Reward: 114.1
Min Reward: 101.0
Max Reward: 124.0
Gini Coefficient: 0.03865030674846626
20:20 Ratio: 1.2167487684729064
Max-min Ratio: 1.2277227722772277
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_01-04-02
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1558.0
  episode_reward_mean: 1144.81
  episode_reward_min: 724.0
  episodes_this_iter: 1
  episodes_total: 140
  experiment_id: a3942a9886f24694ab1b58ca8d1ab856
  hostname: gpu006
  info:
    apply_time_ms: 3.349
    dispatch_time_ms: 29.135
    learner:
      cur_lr: 0.001266760053113103
      grad_gnorm: 1.4029905796051025
      policy_entropy: 47.149906158447266
      policy_loss: 0.22727347910404205
      var_gnorm: 40.61222839355469
      vf_explained_var: 0.9246416091918945
      vf_loss: 0.010388399474322796
    num_steps_sampled: 1410000
    num_steps_trained: 1410000
    wait_time_ms: 187.259
  iterations_since_restore: 141
  node_ip: 172.17.8.6
  num_metric_batches_dropped: 0
  pid: 13557
  policy_reward_mean: {}
  time_since_restore: 3472.54851102829
  time_this_iter_s: 26.981430530548096
  time_total_s: 3472.54851102829
  timestamp: 1594098242
  timesteps_since_restore: 1410000
  timesteps_this_iter: 10000
  timesteps_total: 1410000
  training_iteration: 141
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=13557], 3472 s, 141 iter, 1410000 ts, 1.14e+03 rew

agent-1: 89.0
agent-2: 108.0
agent-3: 98.0
agent-4: 86.0
agent-5: 91.0
agent-6: 94.0
agent-7: 101.0
agent-8: 85.0
agent-9: 120.0
agent-10: 100.0
Sum Reward: 972.0
Avg Reward: 97.2
Min Reward: 85.0
Max Reward: 120.0
Gini Coefficient: 0.05761316872427984
20:20 Ratio: 1.3333333333333333
Max-min Ratio: 1.411764705882353
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_01-04-26
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1558.0
  episode_reward_mean: 1142.36
  episode_reward_min: 724.0
  episodes_this_iter: 1
  episodes_total: 141
  experiment_id: a3942a9886f24694ab1b58ca8d1ab856
  hostname: gpu006
  info:
    apply_time_ms: 2.722
    dispatch_time_ms: 27.737
    learner:
      cur_lr: 0.001266094041056931
      grad_gnorm: 40.000003814697266
      policy_entropy: 42.783424377441406
      policy_loss: 16.3924503326416
      var_gnorm: 40.71440887451172
      vf_explained_var: 0.7326700091362
      vf_loss: 148.0299530029297
    num_steps_sampled: 1420000
    num_steps_trained: 1420000
    wait_time_ms: 226.398
  iterations_since_restore: 142
  node_ip: 172.17.8.6
  num_metric_batches_dropped: 0
  pid: 13557
  policy_reward_mean: {}
  time_since_restore: 3496.584131002426
  time_this_iter_s: 24.035619974136353
  time_total_s: 3496.584131002426
  timestamp: 1594098266
  timesteps_since_restore: 1420000
  timesteps_this_iter: 10000
  timesteps_total: 1420000
  training_iteration: 142
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=13557], 3496 s, 142 iter, 1420000 ts, 1.14e+03 rew

agent-1: 123.0
agent-2: 110.0
agent-3: 117.0
agent-4: 82.0
agent-5: 103.0
agent-6: 100.0
agent-7: 110.0
agent-8: 98.0
agent-9: 121.0
agent-10: 88.0
Sum Reward: 1052.0
Avg Reward: 105.2
Min Reward: 82.0
Max Reward: 123.0
Gini Coefficient: 0.06958174904942965
20:20 Ratio: 1.4352941176470588
Max-min Ratio: 1.5
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_01-04-53
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1558.0
  episode_reward_mean: 1139.1
  episode_reward_min: 724.0
  episodes_this_iter: 1
  episodes_total: 142
  experiment_id: a3942a9886f24694ab1b58ca8d1ab856
  hostname: gpu006
  info:
    apply_time_ms: 3.274
    dispatch_time_ms: 6.356
    learner:
      cur_lr: 0.0012654280290007591
      grad_gnorm: 40.00002670288086
      policy_entropy: 16.994421005249023
      policy_loss: 5.102297782897949
      var_gnorm: 40.7918701171875
      vf_explained_var: -0.14257681369781494
      vf_loss: 138.79136657714844
    num_steps_sampled: 1430000
    num_steps_trained: 1430000
    wait_time_ms: 214.918
  iterations_since_restore: 143
  node_ip: 172.17.8.6
  num_metric_batches_dropped: 0
  pid: 13557
  policy_reward_mean: {}
  time_since_restore: 3523.577381134033
  time_this_iter_s: 26.993250131607056
  time_total_s: 3523.577381134033
  timestamp: 1594098293
  timesteps_since_restore: 1430000
  timesteps_this_iter: 10000
  timesteps_total: 1430000
  training_iteration: 143
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=13557], 3523 s, 143 iter, 1430000 ts, 1.14e+03 rew

agent-1: 81.0
agent-2: 101.0
agent-3: 85.0
agent-4: 100.0
agent-5: 115.0
agent-6: 89.0
agent-7: 94.0
agent-8: 106.0
agent-9: 96.0
agent-10: 112.0
Sum Reward: 979.0
Avg Reward: 97.9
Min Reward: 81.0
Max Reward: 115.0
Gini Coefficient: 0.06179775280898876
20:20 Ratio: 1.3674698795180722
Max-min Ratio: 1.4197530864197532
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_01-05-14
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1558.0
  episode_reward_mean: 1138.79
  episode_reward_min: 724.0
  episodes_this_iter: 1
  episodes_total: 143
  experiment_id: a3942a9886f24694ab1b58ca8d1ab856
  hostname: gpu006
  info:
    apply_time_ms: 3.201
    dispatch_time_ms: 5.814
    learner:
      cur_lr: 0.0012647620169445872
      grad_gnorm: 40.0
      policy_entropy: 29.89545249938965
      policy_loss: -17.245296478271484
      var_gnorm: 40.85043716430664
      vf_explained_var: 0.38123035430908203
      vf_loss: 75.35440826416016
    num_steps_sampled: 1440000
    num_steps_trained: 1440000
    wait_time_ms: 212.553
  iterations_since_restore: 144
  node_ip: 172.17.8.6
  num_metric_batches_dropped: 0
  pid: 13557
  policy_reward_mean: {}
  time_since_restore: 3544.647739648819
  time_this_iter_s: 21.070358514785767
  time_total_s: 3544.647739648819
  timestamp: 1594098314
  timesteps_since_restore: 1440000
  timesteps_this_iter: 10000
  timesteps_total: 1440000
  training_iteration: 144
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=13557], 3544 s, 144 iter, 1440000 ts, 1.14e+03 rew

agent-1: 128.0
agent-2: 122.0
agent-3: 169.0
agent-4: 160.0
agent-5: 154.0
agent-6: 135.0
agent-7: 160.0
agent-8: 182.0
agent-9: 163.0
agent-10: 145.0
Sum Reward: 1518.0
Avg Reward: 151.8
Min Reward: 122.0
Max Reward: 182.0
Gini Coefficient: 0.06706192358366271
20:20 Ratio: 1.404
Max-min Ratio: 1.4918032786885247
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_01-05-39
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1558.0
  episode_reward_mean: 1140.1
  episode_reward_min: 724.0
  episodes_this_iter: 1
  episodes_total: 144
  experiment_id: a3942a9886f24694ab1b58ca8d1ab856
  hostname: gpu006
  info:
    apply_time_ms: 2.633
    dispatch_time_ms: 6.248
    learner:
      cur_lr: 0.0012640960048884153
      grad_gnorm: 40.00000762939453
      policy_entropy: 47.99673080444336
      policy_loss: 3.6587400436401367
      var_gnorm: 41.01069641113281
      vf_explained_var: 0.5135172009468079
      vf_loss: 143.03237915039062
    num_steps_sampled: 1450000
    num_steps_trained: 1450000
    wait_time_ms: 216.186
  iterations_since_restore: 145
  node_ip: 172.17.8.6
  num_metric_batches_dropped: 0
  pid: 13557
  policy_reward_mean: {}
  time_since_restore: 3569.319597005844
  time_this_iter_s: 24.671857357025146
  time_total_s: 3569.319597005844
  timestamp: 1594098339
  timesteps_since_restore: 1450000
  timesteps_this_iter: 10000
  timesteps_total: 1450000
  training_iteration: 145
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=13557], 3569 s, 145 iter, 1450000 ts, 1.14e+03 rew

agent-1: 173.0
agent-2: 175.0
agent-3: 166.0
agent-4: 142.0
agent-5: 156.0
agent-6: 145.0
agent-7: 152.0
agent-8: 166.0
agent-9: 134.0
agent-10: 147.0
Sum Reward: 1556.0
Avg Reward: 155.6
Min Reward: 134.0
Max Reward: 175.0
Gini Coefficient: 0.04832904884318766
20:20 Ratio: 1.2608695652173914
Max-min Ratio: 1.3059701492537314
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_01-06-02
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1556.0
  episode_reward_mean: 1140.08
  episode_reward_min: 724.0
  episodes_this_iter: 1
  episodes_total: 145
  experiment_id: a3942a9886f24694ab1b58ca8d1ab856
  hostname: gpu006
  info:
    apply_time_ms: 2.562
    dispatch_time_ms: 6.013
    learner:
      cur_lr: 0.0012634299928322434
      grad_gnorm: 40.000003814697266
      policy_entropy: 71.04966735839844
      policy_loss: -0.6408970355987549
      var_gnorm: 41.094078063964844
      vf_explained_var: 0.6520325541496277
      vf_loss: 17.46201515197754
    num_steps_sampled: 1460000
    num_steps_trained: 1460000
    wait_time_ms: 252.188
  iterations_since_restore: 146
  node_ip: 172.17.8.6
  num_metric_batches_dropped: 0
  pid: 13557
  policy_reward_mean: {}
  time_since_restore: 3592.180593729019
  time_this_iter_s: 22.86099672317505
  time_total_s: 3592.180593729019
  timestamp: 1594098362
  timesteps_since_restore: 1460000
  timesteps_this_iter: 10000
  timesteps_total: 1460000
  training_iteration: 146
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=13557], 3592 s, 146 iter, 1460000 ts, 1.14e+03 rew

agent-1: 104.0
agent-2: 119.0
agent-3: 118.0
agent-4: 123.0
agent-5: 95.0
agent-6: 96.0
agent-7: 100.0
agent-8: 84.0
agent-9: 119.0
agent-10: 133.0
Sum Reward: 1091.0
Avg Reward: 109.1
Min Reward: 84.0
Max Reward: 133.0
Gini Coefficient: 0.07543538038496791
20:20 Ratio: 1.4301675977653632
Max-min Ratio: 1.5833333333333333
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_01-06-28
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1556.0
  episode_reward_mean: 1135.96
  episode_reward_min: 724.0
  episodes_this_iter: 1
  episodes_total: 146
  experiment_id: a3942a9886f24694ab1b58ca8d1ab856
  hostname: gpu006
  info:
    apply_time_ms: 2.813
    dispatch_time_ms: 6.184
    learner:
      cur_lr: 0.0012627639807760715
      grad_gnorm: 2.883890151977539
      policy_entropy: 99.18428802490234
      policy_loss: 1.366166114807129
      var_gnorm: 41.16108322143555
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 0.005182414781302214
    num_steps_sampled: 1470000
    num_steps_trained: 1470000
    wait_time_ms: 215.601
  iterations_since_restore: 147
  node_ip: 172.17.8.6
  num_metric_batches_dropped: 0
  pid: 13557
  policy_reward_mean: {}
  time_since_restore: 3618.167676925659
  time_this_iter_s: 25.987083196640015
  time_total_s: 3618.167676925659
  timestamp: 1594098388
  timesteps_since_restore: 1470000
  timesteps_this_iter: 10000
  timesteps_total: 1470000
  training_iteration: 147
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=13557], 3618 s, 147 iter, 1470000 ts, 1.14e+03 rew

agent-1: 95.0
agent-2: 105.0
agent-3: 94.0
agent-4: 118.0
agent-5: 94.0
agent-6: 87.0
agent-7: 105.0
agent-8: 112.0
agent-9: 103.0
agent-10: 95.0
Sum Reward: 1008.0
Avg Reward: 100.8
Min Reward: 87.0
Max Reward: 118.0
Gini Coefficient: 0.0494047619047619
20:20 Ratio: 1.270718232044199
Max-min Ratio: 1.3563218390804597
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_01-06-51
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1556.0
  episode_reward_mean: 1134.39
  episode_reward_min: 724.0
  episodes_this_iter: 1
  episodes_total: 147
  experiment_id: a3942a9886f24694ab1b58ca8d1ab856
  hostname: gpu006
  info:
    apply_time_ms: 4.565
    dispatch_time_ms: 6.428
    learner:
      cur_lr: 0.0012620979687198997
      grad_gnorm: 39.826473236083984
      policy_entropy: 51.077247619628906
      policy_loss: -1.9406815767288208
      var_gnorm: 41.20680236816406
      vf_explained_var: 0.7973513603210449
      vf_loss: 20.682632446289062
    num_steps_sampled: 1480000
    num_steps_trained: 1480000
    wait_time_ms: 248.304
  iterations_since_restore: 148
  node_ip: 172.17.8.6
  num_metric_batches_dropped: 0
  pid: 13557
  policy_reward_mean: {}
  time_since_restore: 3640.9815349578857
  time_this_iter_s: 22.813858032226562
  time_total_s: 3640.9815349578857
  timestamp: 1594098411
  timesteps_since_restore: 1480000
  timesteps_this_iter: 10000
  timesteps_total: 1480000
  training_iteration: 148
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=13557], 3640 s, 148 iter, 1480000 ts, 1.13e+03 rew

agent-1: 102.0
agent-2: 110.0
agent-3: 118.0
agent-4: 111.0
agent-5: 111.0
agent-6: 112.0
agent-7: 109.0
agent-8: 94.0
agent-9: 125.0
agent-10: 90.0
Sum Reward: 1082.0
Avg Reward: 108.2
Min Reward: 90.0
Max Reward: 125.0
Gini Coefficient: 0.04990757855822551
20:20 Ratio: 1.3206521739130435
Max-min Ratio: 1.3888888888888888
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_01-07-18
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1556.0
  episode_reward_mean: 1132.84
  episode_reward_min: 724.0
  episodes_this_iter: 1
  episodes_total: 148
  experiment_id: a3942a9886f24694ab1b58ca8d1ab856
  hostname: gpu006
  info:
    apply_time_ms: 3.325
    dispatch_time_ms: 6.683
    learner:
      cur_lr: 0.0012614319566637278
      grad_gnorm: 0.75791335105896
      policy_entropy: 83.43551635742188
      policy_loss: -0.23056446015834808
      var_gnorm: 41.294071197509766
      vf_explained_var: 0.8167733550071716
      vf_loss: 0.026141906157135963
    num_steps_sampled: 1490000
    num_steps_trained: 1490000
    wait_time_ms: 256.825
  iterations_since_restore: 149
  node_ip: 172.17.8.6
  num_metric_batches_dropped: 0
  pid: 13557
  policy_reward_mean: {}
  time_since_restore: 3667.783472776413
  time_this_iter_s: 26.80193781852722
  time_total_s: 3667.783472776413
  timestamp: 1594098438
  timesteps_since_restore: 1490000
  timesteps_this_iter: 10000
  timesteps_total: 1490000
  training_iteration: 149
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=13557], 3667 s, 149 iter, 1490000 ts, 1.13e+03 rew

agent-1: 109.0
agent-2: 109.0
agent-3: 107.0
agent-4: 90.0
agent-5: 138.0
agent-6: 125.0
agent-7: 116.0
agent-8: 114.0
agent-9: 102.0
agent-10: 126.0
Sum Reward: 1136.0
Avg Reward: 113.6
Min Reward: 90.0
Max Reward: 138.0
Gini Coefficient: 0.0630281690140845
20:20 Ratio: 1.375
Max-min Ratio: 1.5333333333333334
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_01-07-40
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1556.0
  episode_reward_mean: 1132.52
  episode_reward_min: 724.0
  episodes_this_iter: 1
  episodes_total: 149
  experiment_id: a3942a9886f24694ab1b58ca8d1ab856
  hostname: gpu006
  info:
    apply_time_ms: 2.728
    dispatch_time_ms: 5.8
    learner:
      cur_lr: 0.0012607659446075559
      grad_gnorm: 40.0
      policy_entropy: 46.97119903564453
      policy_loss: -13.208251953125
      var_gnorm: 41.46542739868164
      vf_explained_var: 0.8801203966140747
      vf_loss: 24.226783752441406
    num_steps_sampled: 1500000
    num_steps_trained: 1500000
    wait_time_ms: 239.534
  iterations_since_restore: 150
  node_ip: 172.17.8.6
  num_metric_batches_dropped: 0
  pid: 13557
  policy_reward_mean: {}
  time_since_restore: 3690.585227251053
  time_this_iter_s: 22.801754474639893
  time_total_s: 3690.585227251053
  timestamp: 1594098460
  timesteps_since_restore: 1500000
  timesteps_this_iter: 10000
  timesteps_total: 1500000
  training_iteration: 150
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=13557], 3690 s, 150 iter, 1500000 ts, 1.13e+03 rew

agent-1: 105.0
agent-2: 93.0
agent-3: 100.0
agent-4: 110.0
agent-5: 87.0
agent-6: 110.0
agent-7: 106.0
agent-8: 97.0
agent-9: 88.0
agent-10: 107.0
Sum Reward: 1003.0
Avg Reward: 100.3
Min Reward: 87.0
Max Reward: 110.0
Gini Coefficient: 0.046161515453639085
20:20 Ratio: 1.2571428571428571
Max-min Ratio: 1.264367816091954
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_01-08-07
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1556.0
  episode_reward_mean: 1127.73
  episode_reward_min: 724.0
  episodes_this_iter: 1
  episodes_total: 150
  experiment_id: a3942a9886f24694ab1b58ca8d1ab856
  hostname: gpu006
  info:
    apply_time_ms: 2.654
    dispatch_time_ms: 5.789
    learner:
      cur_lr: 0.0012601000489667058
      grad_gnorm: 40.0
      policy_entropy: 8.628057479858398
      policy_loss: 13.632156372070312
      var_gnorm: 41.52797317504883
      vf_explained_var: 0.22365796566009521
      vf_loss: 351.0623779296875
    num_steps_sampled: 1510000
    num_steps_trained: 1510000
    wait_time_ms: 240.986
  iterations_since_restore: 151
  node_ip: 172.17.8.6
  num_metric_batches_dropped: 0
  pid: 13557
  policy_reward_mean: {}
  time_since_restore: 3717.119449853897
  time_this_iter_s: 26.53422260284424
  time_total_s: 3717.119449853897
  timestamp: 1594098487
  timesteps_since_restore: 1510000
  timesteps_this_iter: 10000
  timesteps_total: 1510000
  training_iteration: 151
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=13557], 3717 s, 151 iter, 1510000 ts, 1.13e+03 rew

agent-1: 89.0
agent-2: 81.0
agent-3: 106.0
agent-4: 126.0
agent-5: 119.0
agent-6: 91.0
agent-7: 116.0
agent-8: 82.0
agent-9: 81.0
agent-10: 130.0
Sum Reward: 1021.0
Avg Reward: 102.1
Min Reward: 81.0
Max Reward: 130.0
Gini Coefficient: 0.10156709108716944
20:20 Ratio: 1.5802469135802468
Max-min Ratio: 1.6049382716049383
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_01-08-29
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1556.0
  episode_reward_mean: 1126.61
  episode_reward_min: 724.0
  episodes_this_iter: 1
  episodes_total: 151
  experiment_id: a3942a9886f24694ab1b58ca8d1ab856
  hostname: gpu006
  info:
    apply_time_ms: 2.807
    dispatch_time_ms: 6.841
    learner:
      cur_lr: 0.001259434036910534
      grad_gnorm: 39.999996185302734
      policy_entropy: 32.789520263671875
      policy_loss: 8.826526641845703
      var_gnorm: 41.61880874633789
      vf_explained_var: 0.7555359601974487
      vf_loss: 155.7893524169922
    num_steps_sampled: 1520000
    num_steps_trained: 1520000
    wait_time_ms: 233.256
  iterations_since_restore: 152
  node_ip: 172.17.8.6
  num_metric_batches_dropped: 0
  pid: 13557
  policy_reward_mean: {}
  time_since_restore: 3739.4922256469727
  time_this_iter_s: 22.37277579307556
  time_total_s: 3739.4922256469727
  timestamp: 1594098509
  timesteps_since_restore: 1520000
  timesteps_this_iter: 10000
  timesteps_total: 1520000
  training_iteration: 152
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=13557], 3739 s, 152 iter, 1520000 ts, 1.13e+03 rew

agent-1: 133.0
agent-2: 148.0
agent-3: 111.0
agent-4: 128.0
agent-5: 143.0
agent-6: 100.0
agent-7: 115.0
agent-8: 105.0
agent-9: 129.0
agent-10: 155.0
Sum Reward: 1267.0
Avg Reward: 126.7
Min Reward: 100.0
Max Reward: 155.0
Gini Coefficient: 0.0797947908445146
20:20 Ratio: 1.4780487804878049
Max-min Ratio: 1.55
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_01-08-55
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1556.0
  episode_reward_mean: 1128.24
  episode_reward_min: 724.0
  episodes_this_iter: 1
  episodes_total: 152
  experiment_id: a3942a9886f24694ab1b58ca8d1ab856
  hostname: gpu006
  info:
    apply_time_ms: 2.946
    dispatch_time_ms: 5.788
    learner:
      cur_lr: 0.001258768024854362
      grad_gnorm: 0.37590736150741577
      policy_entropy: 37.5158805847168
      policy_loss: 0.15755373239517212
      var_gnorm: 41.7050895690918
      vf_explained_var: 0.8660051226615906
      vf_loss: 0.0035170980263501406
    num_steps_sampled: 1530000
    num_steps_trained: 1530000
    wait_time_ms: 257.305
  iterations_since_restore: 153
  node_ip: 172.17.8.6
  num_metric_batches_dropped: 0
  pid: 13557
  policy_reward_mean: {}
  time_since_restore: 3765.3997342586517
  time_this_iter_s: 25.907508611679077
  time_total_s: 3765.3997342586517
  timestamp: 1594098535
  timesteps_since_restore: 1530000
  timesteps_this_iter: 10000
  timesteps_total: 1530000
  training_iteration: 153
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=13557], 3765 s, 153 iter, 1530000 ts, 1.13e+03 rew

agent-1: 112.0
agent-2: 103.0
agent-3: 117.0
agent-4: 135.0
agent-5: 93.0
agent-6: 131.0
agent-7: 131.0
agent-8: 87.0
agent-9: 88.0
agent-10: 98.0
Sum Reward: 1095.0
Avg Reward: 109.5
Min Reward: 87.0
Max Reward: 135.0
Gini Coefficient: 0.09031963470319634
20:20 Ratio: 1.52
Max-min Ratio: 1.5517241379310345
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_01-09-17
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1556.0
  episode_reward_mean: 1128.41
  episode_reward_min: 724.0
  episodes_this_iter: 1
  episodes_total: 153
  experiment_id: a3942a9886f24694ab1b58ca8d1ab856
  hostname: gpu006
  info:
    apply_time_ms: 2.602
    dispatch_time_ms: 5.721
    learner:
      cur_lr: 0.0012581020127981901
      grad_gnorm: 40.0
      policy_entropy: 37.170188903808594
      policy_loss: -4.463226318359375
      var_gnorm: 41.785560607910156
      vf_explained_var: 0.8717477321624756
      vf_loss: 143.6945343017578
    num_steps_sampled: 1540000
    num_steps_trained: 1540000
    wait_time_ms: 218.879
  iterations_since_restore: 154
  node_ip: 172.17.8.6
  num_metric_batches_dropped: 0
  pid: 13557
  policy_reward_mean: {}
  time_since_restore: 3787.3919270038605
  time_this_iter_s: 21.99219274520874
  time_total_s: 3787.3919270038605
  timestamp: 1594098557
  timesteps_since_restore: 1540000
  timesteps_this_iter: 10000
  timesteps_total: 1540000
  training_iteration: 154
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=13557], 3787 s, 154 iter, 1540000 ts, 1.13e+03 rew

agent-1: 120.0
agent-2: 155.0
agent-3: 134.0
agent-4: 145.0
agent-5: 175.0
agent-6: 147.0
agent-7: 129.0
agent-8: 150.0
agent-9: 145.0
agent-10: 158.0
Sum Reward: 1458.0
Avg Reward: 145.8
Min Reward: 120.0
Max Reward: 175.0
Gini Coefficient: 0.056241426611796985
20:20 Ratio: 1.3373493975903614
Max-min Ratio: 1.4583333333333333
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_01-09-44
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1556.0
  episode_reward_mean: 1132.01
  episode_reward_min: 724.0
  episodes_this_iter: 1
  episodes_total: 154
  experiment_id: a3942a9886f24694ab1b58ca8d1ab856
  hostname: gpu006
  info:
    apply_time_ms: 2.715
    dispatch_time_ms: 32.55
    learner:
      cur_lr: 0.0012574360007420182
      grad_gnorm: 39.99999237060547
      policy_entropy: 31.75235366821289
      policy_loss: -0.7798928618431091
      var_gnorm: 41.91239547729492
      vf_explained_var: -0.7112264633178711
      vf_loss: 213.1031951904297
    num_steps_sampled: 1550000
    num_steps_trained: 1550000
    wait_time_ms: 202.946
  iterations_since_restore: 155
  node_ip: 172.17.8.6
  num_metric_batches_dropped: 0
  pid: 13557
  policy_reward_mean: {}
  time_since_restore: 3813.7242710590363
  time_this_iter_s: 26.33234405517578
  time_total_s: 3813.7242710590363
  timestamp: 1594098584
  timesteps_since_restore: 1550000
  timesteps_this_iter: 10000
  timesteps_total: 1550000
  training_iteration: 155
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=13557], 3813 s, 155 iter, 1550000 ts, 1.13e+03 rew

agent-1: 99.0
agent-2: 118.0
agent-3: 111.0
agent-4: 132.0
agent-5: 98.0
agent-6: 123.0
agent-7: 98.0
agent-8: 98.0
agent-9: 100.0
agent-10: 122.0
Sum Reward: 1099.0
Avg Reward: 109.9
Min Reward: 98.0
Max Reward: 132.0
Gini Coefficient: 0.06087352138307552
20:20 Ratio: 1.3010204081632653
Max-min Ratio: 1.346938775510204
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_01-10-06
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1556.0
  episode_reward_mean: 1131.5
  episode_reward_min: 724.0
  episodes_this_iter: 1
  episodes_total: 155
  experiment_id: a3942a9886f24694ab1b58ca8d1ab856
  hostname: gpu006
  info:
    apply_time_ms: 3.237
    dispatch_time_ms: 29.212
    learner:
      cur_lr: 0.0012567699886858463
      grad_gnorm: 39.99998474121094
      policy_entropy: 26.338956832885742
      policy_loss: 5.571152687072754
      var_gnorm: 41.94607925415039
      vf_explained_var: 0.6030218601226807
      vf_loss: 212.79759216308594
    num_steps_sampled: 1560000
    num_steps_trained: 1560000
    wait_time_ms: 221.813
  iterations_since_restore: 156
  node_ip: 172.17.8.6
  num_metric_batches_dropped: 0
  pid: 13557
  policy_reward_mean: {}
  time_since_restore: 3835.9552047252655
  time_this_iter_s: 22.230933666229248
  time_total_s: 3835.9552047252655
  timestamp: 1594098606
  timesteps_since_restore: 1560000
  timesteps_this_iter: 10000
  timesteps_total: 1560000
  training_iteration: 156
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=13557], 3835 s, 156 iter, 1560000 ts, 1.13e+03 rew

agent-1: 117.0
agent-2: 107.0
agent-3: 139.0
agent-4: 126.0
agent-5: 124.0
agent-6: 100.0
agent-7: 137.0
agent-8: 108.0
agent-9: 138.0
agent-10: 120.0
Sum Reward: 1216.0
Avg Reward: 121.6
Min Reward: 100.0
Max Reward: 139.0
Gini Coefficient: 0.06118421052631579
20:20 Ratio: 1.3381642512077294
Max-min Ratio: 1.39
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_01-10-33
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1556.0
  episode_reward_mean: 1133.32
  episode_reward_min: 724.0
  episodes_this_iter: 1
  episodes_total: 156
  experiment_id: a3942a9886f24694ab1b58ca8d1ab856
  hostname: gpu006
  info:
    apply_time_ms: 2.68
    dispatch_time_ms: 40.796
    learner:
      cur_lr: 0.0012561039766296744
      grad_gnorm: 5.880892276763916
      policy_entropy: 72.40708923339844
      policy_loss: 0.3093738257884979
      var_gnorm: 42.0311393737793
      vf_explained_var: 0.9122206568717957
      vf_loss: 0.0264500193297863
    num_steps_sampled: 1570000
    num_steps_trained: 1570000
    wait_time_ms: 226.447
  iterations_since_restore: 157
  node_ip: 172.17.8.6
  num_metric_batches_dropped: 0
  pid: 13557
  policy_reward_mean: {}
  time_since_restore: 3863.147005558014
  time_this_iter_s: 27.191800832748413
  time_total_s: 3863.147005558014
  timestamp: 1594098633
  timesteps_since_restore: 1570000
  timesteps_this_iter: 10000
  timesteps_total: 1570000
  training_iteration: 157
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=13557], 3863 s, 157 iter, 1570000 ts, 1.13e+03 rew

agent-1: 131.0
agent-2: 113.0
agent-3: 120.0
agent-4: 138.0
agent-5: 154.0
agent-6: 121.0
agent-7: 110.0
agent-8: 138.0
agent-9: 133.0
agent-10: 117.0
Sum Reward: 1275.0
Avg Reward: 127.5
Min Reward: 110.0
Max Reward: 154.0
Gini Coefficient: 0.056862745098039215
20:20 Ratio: 1.3094170403587444
Max-min Ratio: 1.4
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_01-10-57
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1556.0
  episode_reward_mean: 1135.56
  episode_reward_min: 724.0
  episodes_this_iter: 1
  episodes_total: 157
  experiment_id: a3942a9886f24694ab1b58ca8d1ab856
  hostname: gpu006
  info:
    apply_time_ms: 3.769
    dispatch_time_ms: 30.174
    learner:
      cur_lr: 0.0012554379645735025
      grad_gnorm: 39.99999237060547
      policy_entropy: 45.385536193847656
      policy_loss: -3.3635096549987793
      var_gnorm: 42.11482620239258
      vf_explained_var: 0.815864086151123
      vf_loss: 127.4315185546875
    num_steps_sampled: 1580000
    num_steps_trained: 1580000
    wait_time_ms: 214.361
  iterations_since_restore: 158
  node_ip: 172.17.8.6
  num_metric_batches_dropped: 0
  pid: 13557
  policy_reward_mean: {}
  time_since_restore: 3886.43061709404
  time_this_iter_s: 23.283611536026
  time_total_s: 3886.43061709404
  timestamp: 1594098657
  timesteps_since_restore: 1580000
  timesteps_this_iter: 10000
  timesteps_total: 1580000
  training_iteration: 158
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=13557], 3886 s, 158 iter, 1580000 ts, 1.14e+03 rew

agent-1: 119.0
agent-2: 119.0
agent-3: 108.0
agent-4: 103.0
agent-5: 138.0
agent-6: 120.0
agent-7: 119.0
agent-8: 106.0
agent-9: 132.0
agent-10: 120.0
Sum Reward: 1184.0
Avg Reward: 118.4
Min Reward: 103.0
Max Reward: 138.0
Gini Coefficient: 0.0472972972972973
20:20 Ratio: 1.291866028708134
Max-min Ratio: 1.3398058252427185
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_01-11-25
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1556.0
  episode_reward_mean: 1139.41
  episode_reward_min: 724.0
  episodes_this_iter: 1
  episodes_total: 158
  experiment_id: a3942a9886f24694ab1b58ca8d1ab856
  hostname: gpu006
  info:
    apply_time_ms: 4.772
    dispatch_time_ms: 28.174
    learner:
      cur_lr: 0.0012547719525173306
      grad_gnorm: 40.0
      policy_entropy: 34.520389556884766
      policy_loss: -5.496579170227051
      var_gnorm: 42.18238830566406
      vf_explained_var: -0.13463854789733887
      vf_loss: 128.48870849609375
    num_steps_sampled: 1590000
    num_steps_trained: 1590000
    wait_time_ms: 213.995
  iterations_since_restore: 159
  node_ip: 172.17.8.6
  num_metric_batches_dropped: 0
  pid: 13557
  policy_reward_mean: {}
  time_since_restore: 3911.4432802200317
  time_this_iter_s: 25.01266312599182
  time_total_s: 3911.4432802200317
  timestamp: 1594098685
  timesteps_since_restore: 1590000
  timesteps_this_iter: 10000
  timesteps_total: 1590000
  training_iteration: 159
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=13557], 3911 s, 159 iter, 1590000 ts, 1.14e+03 rew

agent-1: 125.0
agent-2: 98.0
agent-3: 91.0
agent-4: 101.0
agent-5: 118.0
agent-6: 118.0
agent-7: 123.0
agent-8: 117.0
agent-9: 97.0
agent-10: 118.0
Sum Reward: 1106.0
Avg Reward: 110.6
Min Reward: 91.0
Max Reward: 125.0
Gini Coefficient: 0.05786618444846293
20:20 Ratio: 1.3191489361702127
Max-min Ratio: 1.3736263736263736
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_01-11-48
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1556.0
  episode_reward_mean: 1138.34
  episode_reward_min: 724.0
  episodes_this_iter: 1
  episodes_total: 159
  experiment_id: a3942a9886f24694ab1b58ca8d1ab856
  hostname: gpu006
  info:
    apply_time_ms: 2.678
    dispatch_time_ms: 6.402
    learner:
      cur_lr: 0.0012541060568764806
      grad_gnorm: 39.99999237060547
      policy_entropy: 43.77510452270508
      policy_loss: 36.39685821533203
      var_gnorm: 42.197959899902344
      vf_explained_var: 0.7717126607894897
      vf_loss: 86.82267761230469
    num_steps_sampled: 1600000
    num_steps_trained: 1600000
    wait_time_ms: 244.824
  iterations_since_restore: 160
  node_ip: 172.17.8.6
  num_metric_batches_dropped: 0
  pid: 13557
  policy_reward_mean: {}
  time_since_restore: 3934.786180973053
  time_this_iter_s: 23.34290075302124
  time_total_s: 3934.786180973053
  timestamp: 1594098708
  timesteps_since_restore: 1600000
  timesteps_this_iter: 10000
  timesteps_total: 1600000
  training_iteration: 160
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=13557], 3934 s, 160 iter, 1600000 ts, 1.14e+03 rew

agent-1: 89.0
agent-2: 123.0
agent-3: 88.0
agent-4: 128.0
agent-5: 107.0
agent-6: 109.0
agent-7: 108.0
agent-8: 96.0
agent-9: 110.0
agent-10: 132.0
Sum Reward: 1090.0
Avg Reward: 109.0
Min Reward: 88.0
Max Reward: 132.0
Gini Coefficient: 0.0746788990825688
20:20 Ratio: 1.4689265536723164
Max-min Ratio: 1.5
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_01-12-15
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1556.0
  episode_reward_mean: 1139.8
  episode_reward_min: 724.0
  episodes_this_iter: 1
  episodes_total: 160
  experiment_id: a3942a9886f24694ab1b58ca8d1ab856
  hostname: gpu006
  info:
    apply_time_ms: 2.843
    dispatch_time_ms: 7.17
    learner:
      cur_lr: 0.0012534400448203087
      grad_gnorm: 40.0
      policy_entropy: 18.648679733276367
      policy_loss: 3.7941787242889404
      var_gnorm: 42.28410339355469
      vf_explained_var: -0.23492276668548584
      vf_loss: 96.85022735595703
    num_steps_sampled: 1610000
    num_steps_trained: 1610000
    wait_time_ms: 216.356
  iterations_since_restore: 161
  node_ip: 172.17.8.6
  num_metric_batches_dropped: 0
  pid: 13557
  policy_reward_mean: {}
  time_since_restore: 3960.8604481220245
  time_this_iter_s: 26.074267148971558
  time_total_s: 3960.8604481220245
  timestamp: 1594098735
  timesteps_since_restore: 1610000
  timesteps_this_iter: 10000
  timesteps_total: 1610000
  training_iteration: 161
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=13557], 3960 s, 161 iter, 1610000 ts, 1.14e+03 rew

agent-1: 107.0
agent-2: 134.0
agent-3: 102.0
agent-4: 121.0
agent-5: 111.0
agent-6: 95.0
agent-7: 85.0
agent-8: 99.0
agent-9: 143.0
agent-10: 98.0
Sum Reward: 1095.0
Avg Reward: 109.5
Min Reward: 85.0
Max Reward: 143.0
Gini Coefficient: 0.08684931506849315
20:20 Ratio: 1.538888888888889
Max-min Ratio: 1.6823529411764706
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_01-12-36
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1556.0
  episode_reward_mean: 1139.53
  episode_reward_min: 724.0
  episodes_this_iter: 1
  episodes_total: 161
  experiment_id: a3942a9886f24694ab1b58ca8d1ab856
  hostname: gpu006
  info:
    apply_time_ms: 2.553
    dispatch_time_ms: 6.098
    learner:
      cur_lr: 0.0012527740327641368
      grad_gnorm: 40.0
      policy_entropy: 34.084224700927734
      policy_loss: 0.535784125328064
      var_gnorm: 42.29163360595703
      vf_explained_var: 0.5196584463119507
      vf_loss: 188.96987915039062
    num_steps_sampled: 1620000
    num_steps_trained: 1620000
    wait_time_ms: 223.134
  iterations_since_restore: 162
  node_ip: 172.17.8.6
  num_metric_batches_dropped: 0
  pid: 13557
  policy_reward_mean: {}
  time_since_restore: 3982.6095774173737
  time_this_iter_s: 21.74912929534912
  time_total_s: 3982.6095774173737
  timestamp: 1594098756
  timesteps_since_restore: 1620000
  timesteps_this_iter: 10000
  timesteps_total: 1620000
  training_iteration: 162
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=13557], 3982 s, 162 iter, 1620000 ts, 1.14e+03 rew

agent-1: 152.0
agent-2: 150.0
agent-3: 136.0
agent-4: 181.0
agent-5: 144.0
agent-6: 152.0
agent-7: 143.0
agent-8: 127.0
agent-9: 145.0
agent-10: 154.0
Sum Reward: 1484.0
Avg Reward: 148.4
Min Reward: 127.0
Max Reward: 181.0
Gini Coefficient: 0.04622641509433962
20:20 Ratio: 1.273764258555133
Max-min Ratio: 1.4251968503937007
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_01-13-02
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1556.0
  episode_reward_mean: 1143.62
  episode_reward_min: 724.0
  episodes_this_iter: 1
  episodes_total: 162
  experiment_id: a3942a9886f24694ab1b58ca8d1ab856
  hostname: gpu006
  info:
    apply_time_ms: 3.036
    dispatch_time_ms: 6.546
    learner:
      cur_lr: 0.001252108020707965
      grad_gnorm: 3.5106260776519775
      policy_entropy: 96.38125610351562
      policy_loss: 1.3061171770095825
      var_gnorm: 42.40780258178711
      vf_explained_var: 0.0
      vf_loss: 0.006295798346400261
    num_steps_sampled: 1630000
    num_steps_trained: 1630000
    wait_time_ms: 220.131
  iterations_since_restore: 163
  node_ip: 172.17.8.6
  num_metric_batches_dropped: 0
  pid: 13557
  policy_reward_mean: {}
  time_since_restore: 4008.050796031952
  time_this_iter_s: 25.441218614578247
  time_total_s: 4008.050796031952
  timestamp: 1594098782
  timesteps_since_restore: 1630000
  timesteps_this_iter: 10000
  timesteps_total: 1630000
  training_iteration: 163
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=13557], 4008 s, 163 iter, 1630000 ts, 1.14e+03 rew

agent-1: 140.0
agent-2: 131.0
agent-3: 130.0
agent-4: 123.0
agent-5: 139.0
agent-6: 127.0
agent-7: 139.0
agent-8: 114.0
agent-9: 130.0
agent-10: 130.0
Sum Reward: 1303.0
Avg Reward: 130.3
Min Reward: 114.0
Max Reward: 140.0
Gini Coefficient: 0.03138910207214121
20:20 Ratio: 1.1772151898734178
Max-min Ratio: 1.2280701754385965
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_01-13-25
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1556.0
  episode_reward_mean: 1147.02
  episode_reward_min: 724.0
  episodes_this_iter: 1
  episodes_total: 163
  experiment_id: a3942a9886f24694ab1b58ca8d1ab856
  hostname: gpu006
  info:
    apply_time_ms: 2.721
    dispatch_time_ms: 6.342
    learner:
      cur_lr: 0.001251442008651793
      grad_gnorm: 39.99999237060547
      policy_entropy: 62.30044174194336
      policy_loss: 20.465837478637695
      var_gnorm: 42.46613311767578
      vf_explained_var: 0.15742290019989014
      vf_loss: 81.07799530029297
    num_steps_sampled: 1640000
    num_steps_trained: 1640000
    wait_time_ms: 247.096
  iterations_since_restore: 164
  node_ip: 172.17.8.6
  num_metric_batches_dropped: 0
  pid: 13557
  policy_reward_mean: {}
  time_since_restore: 4031.0579178333282
  time_this_iter_s: 23.007121801376343
  time_total_s: 4031.0579178333282
  timestamp: 1594098805
  timesteps_since_restore: 1640000
  timesteps_this_iter: 10000
  timesteps_total: 1640000
  training_iteration: 164
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=13557], 4031 s, 164 iter, 1640000 ts, 1.15e+03 rew

agent-1: 108.0
agent-2: 113.0
agent-3: 126.0
agent-4: 116.0
agent-5: 128.0
agent-6: 120.0
agent-7: 124.0
agent-8: 120.0
agent-9: 146.0
agent-10: 157.0
Sum Reward: 1258.0
Avg Reward: 125.8
Min Reward: 108.0
Max Reward: 157.0
Gini Coefficient: 0.05993640699523053
20:20 Ratio: 1.3710407239819005
Max-min Ratio: 1.4537037037037037
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_01-13-51
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1556.0
  episode_reward_mean: 1150.16
  episode_reward_min: 724.0
  episodes_this_iter: 1
  episodes_total: 164
  experiment_id: a3942a9886f24694ab1b58ca8d1ab856
  hostname: gpu006
  info:
    apply_time_ms: 2.787
    dispatch_time_ms: 8.837
    learner:
      cur_lr: 0.0012507759965956211
      grad_gnorm: 39.999996185302734
      policy_entropy: 23.268491744995117
      policy_loss: 6.772062301635742
      var_gnorm: 42.5389518737793
      vf_explained_var: 0.41324537992477417
      vf_loss: 188.3212432861328
    num_steps_sampled: 1650000
    num_steps_trained: 1650000
    wait_time_ms: 219.849
  iterations_since_restore: 165
  node_ip: 172.17.8.6
  num_metric_batches_dropped: 0
  pid: 13557
  policy_reward_mean: {}
  time_since_restore: 4056.7713334560394
  time_this_iter_s: 25.71341562271118
  time_total_s: 4056.7713334560394
  timestamp: 1594098831
  timesteps_since_restore: 1650000
  timesteps_this_iter: 10000
  timesteps_total: 1650000
  training_iteration: 165
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=13557], 4056 s, 165 iter, 1650000 ts, 1.15e+03 rew

agent-1: 93.0
agent-2: 104.0
agent-3: 115.0
agent-4: 100.0
agent-5: 97.0
agent-6: 83.0
agent-7: 98.0
agent-8: 82.0
agent-9: 87.0
agent-10: 102.0
Sum Reward: 961.0
Avg Reward: 96.1
Min Reward: 82.0
Max Reward: 115.0
Gini Coefficient: 0.05629552549427679
20:20 Ratio: 1.3272727272727274
Max-min Ratio: 1.4024390243902438
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_01-14-14
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1556.0
  episode_reward_mean: 1149.82
  episode_reward_min: 724.0
  episodes_this_iter: 1
  episodes_total: 165
  experiment_id: a3942a9886f24694ab1b58ca8d1ab856
  hostname: gpu006
  info:
    apply_time_ms: 2.698
    dispatch_time_ms: 6.527
    learner:
      cur_lr: 0.0012501099845394492
      grad_gnorm: 39.99999237060547
      policy_entropy: 44.36811065673828
      policy_loss: -9.9368896484375
      var_gnorm: 42.63988494873047
      vf_explained_var: -0.27671217918395996
      vf_loss: 373.17431640625
    num_steps_sampled: 1660000
    num_steps_trained: 1660000
    wait_time_ms: 240.14
  iterations_since_restore: 166
  node_ip: 172.17.8.6
  num_metric_batches_dropped: 0
  pid: 13557
  policy_reward_mean: {}
  time_since_restore: 4080.045482635498
  time_this_iter_s: 23.274149179458618
  time_total_s: 4080.045482635498
  timestamp: 1594098854
  timesteps_since_restore: 1660000
  timesteps_this_iter: 10000
  timesteps_total: 1660000
  training_iteration: 166
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=13557], 4080 s, 166 iter, 1660000 ts, 1.15e+03 rew

agent-1: 102.0
agent-2: 80.0
agent-3: 112.0
agent-4: 100.0
agent-5: 137.0
agent-6: 101.0
agent-7: 93.0
agent-8: 98.0
agent-9: 104.0
agent-10: 121.0
Sum Reward: 1048.0
Avg Reward: 104.8
Min Reward: 80.0
Max Reward: 137.0
Gini Coefficient: 0.07557251908396946
20:20 Ratio: 1.4913294797687862
Max-min Ratio: 1.7125
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_01-14-39
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1556.0
  episode_reward_mean: 1150.23
  episode_reward_min: 724.0
  episodes_this_iter: 1
  episodes_total: 166
  experiment_id: a3942a9886f24694ab1b58ca8d1ab856
  hostname: gpu006
  info:
    apply_time_ms: 3.355
    dispatch_time_ms: 6.744
    learner:
      cur_lr: 0.0012494439724832773
      grad_gnorm: 40.0
      policy_entropy: 22.738752365112305
      policy_loss: 13.431703567504883
      var_gnorm: 42.698368072509766
      vf_explained_var: 0.1997554898262024
      vf_loss: 170.87477111816406
    num_steps_sampled: 1670000
    num_steps_trained: 1670000
    wait_time_ms: 221.189
  iterations_since_restore: 167
  node_ip: 172.17.8.6
  num_metric_batches_dropped: 0
  pid: 13557
  policy_reward_mean: {}
  time_since_restore: 4105.423330783844
  time_this_iter_s: 25.377848148345947
  time_total_s: 4105.423330783844
  timestamp: 1594098879
  timesteps_since_restore: 1670000
  timesteps_this_iter: 10000
  timesteps_total: 1670000
  training_iteration: 167
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=13557], 4105 s, 167 iter, 1670000 ts, 1.15e+03 rew

agent-1: 108.0
agent-2: 103.0
agent-3: 137.0
agent-4: 109.0
agent-5: 135.0
agent-6: 115.0
agent-7: 135.0
agent-8: 123.0
agent-9: 141.0
agent-10: 128.0
Sum Reward: 1234.0
Avg Reward: 123.4
Min Reward: 103.0
Max Reward: 141.0
Gini Coefficient: 0.059967585089141004
20:20 Ratio: 1.3175355450236967
Max-min Ratio: 1.3689320388349515
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_01-15-02
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1556.0
  episode_reward_mean: 1152.48
  episode_reward_min: 724.0
  episodes_this_iter: 1
  episodes_total: 167
  experiment_id: a3942a9886f24694ab1b58ca8d1ab856
  hostname: gpu006
  info:
    apply_time_ms: 2.634
    dispatch_time_ms: 5.856
    learner:
      cur_lr: 0.0012487779604271054
      grad_gnorm: 40.0
      policy_entropy: 43.93775177001953
      policy_loss: -14.00698471069336
      var_gnorm: 42.754608154296875
      vf_explained_var: 0.6921113729476929
      vf_loss: 73.12211608886719
    num_steps_sampled: 1680000
    num_steps_trained: 1680000
    wait_time_ms: 212.79
  iterations_since_restore: 168
  node_ip: 172.17.8.6
  num_metric_batches_dropped: 0
  pid: 13557
  policy_reward_mean: {}
  time_since_restore: 4128.104077339172
  time_this_iter_s: 22.68074655532837
  time_total_s: 4128.104077339172
  timestamp: 1594098902
  timesteps_since_restore: 1680000
  timesteps_this_iter: 10000
  timesteps_total: 1680000
  training_iteration: 168
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=13557], 4128 s, 168 iter, 1680000 ts, 1.15e+03 rew

agent-1: 130.0
agent-2: 109.0
agent-3: 129.0
agent-4: 134.0
agent-5: 96.0
agent-6: 103.0
agent-7: 95.0
agent-8: 133.0
agent-9: 130.0
agent-10: 141.0
Sum Reward: 1200.0
Avg Reward: 120.0
Min Reward: 95.0
Max Reward: 141.0
Gini Coefficient: 0.0745
20:20 Ratio: 1.4397905759162304
Max-min Ratio: 1.4842105263157894
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_01-15-27
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1556.0
  episode_reward_mean: 1155.84
  episode_reward_min: 724.0
  episodes_this_iter: 1
  episodes_total: 168
  experiment_id: a3942a9886f24694ab1b58ca8d1ab856
  hostname: gpu006
  info:
    apply_time_ms: 2.617
    dispatch_time_ms: 5.635
    learner:
      cur_lr: 0.0012481119483709335
      grad_gnorm: 39.99999237060547
      policy_entropy: 106.30964660644531
      policy_loss: 17.19563102722168
      var_gnorm: 42.91400146484375
      vf_explained_var: 0.44164711236953735
      vf_loss: 12.67652416229248
    num_steps_sampled: 1690000
    num_steps_trained: 1690000
    wait_time_ms: 214.256
  iterations_since_restore: 169
  node_ip: 172.17.8.6
  num_metric_batches_dropped: 0
  pid: 13557
  policy_reward_mean: {}
  time_since_restore: 4153.159698009491
  time_this_iter_s: 25.055620670318604
  time_total_s: 4153.159698009491
  timestamp: 1594098927
  timesteps_since_restore: 1690000
  timesteps_this_iter: 10000
  timesteps_total: 1690000
  training_iteration: 169
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=13557], 4153 s, 169 iter, 1690000 ts, 1.16e+03 rew

agent-1: 151.0
agent-2: 151.0
agent-3: 156.0
agent-4: 171.0
agent-5: 127.0
agent-6: 130.0
agent-7: 137.0
agent-8: 141.0
agent-9: 128.0
agent-10: 123.0
Sum Reward: 1415.0
Avg Reward: 141.5
Min Reward: 123.0
Max Reward: 171.0
Gini Coefficient: 0.05773851590106007
20:20 Ratio: 1.308
Max-min Ratio: 1.3902439024390243
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_01-15-50
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1556.0
  episode_reward_mean: 1161.4
  episode_reward_min: 724.0
  episodes_this_iter: 1
  episodes_total: 169
  experiment_id: a3942a9886f24694ab1b58ca8d1ab856
  hostname: gpu006
  info:
    apply_time_ms: 3.086
    dispatch_time_ms: 5.974
    learner:
      cur_lr: 0.0012474460527300835
      grad_gnorm: 40.0
      policy_entropy: 61.80885314941406
      policy_loss: -10.73814868927002
      var_gnorm: 42.91627883911133
      vf_explained_var: 0.5989393591880798
      vf_loss: 318.2688903808594
    num_steps_sampled: 1700000
    num_steps_trained: 1700000
    wait_time_ms: 227.515
  iterations_since_restore: 170
  node_ip: 172.17.8.6
  num_metric_batches_dropped: 0
  pid: 13557
  policy_reward_mean: {}
  time_since_restore: 4176.142284631729
  time_this_iter_s: 22.98258662223816
  time_total_s: 4176.142284631729
  timestamp: 1594098950
  timesteps_since_restore: 1700000
  timesteps_this_iter: 10000
  timesteps_total: 1700000
  training_iteration: 170
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=13557], 4176 s, 170 iter, 1700000 ts, 1.16e+03 rew

agent-1: 146.0
agent-2: 134.0
agent-3: 99.0
agent-4: 105.0
agent-5: 135.0
agent-6: 114.0
agent-7: 131.0
agent-8: 118.0
agent-9: 123.0
agent-10: 116.0
Sum Reward: 1221.0
Avg Reward: 122.1
Min Reward: 99.0
Max Reward: 146.0
Gini Coefficient: 0.06412776412776412
20:20 Ratio: 1.3774509803921569
Max-min Ratio: 1.4747474747474747
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_01-16-16
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1556.0
  episode_reward_mean: 1163.02
  episode_reward_min: 724.0
  episodes_this_iter: 1
  episodes_total: 170
  experiment_id: a3942a9886f24694ab1b58ca8d1ab856
  hostname: gpu006
  info:
    apply_time_ms: 2.791
    dispatch_time_ms: 7.209
    learner:
      cur_lr: 0.0012467800406739116
      grad_gnorm: 40.0
      policy_entropy: 33.013160705566406
      policy_loss: -11.136042594909668
      var_gnorm: 43.05780792236328
      vf_explained_var: -0.34362876415252686
      vf_loss: 128.74603271484375
    num_steps_sampled: 1710000
    num_steps_trained: 1710000
    wait_time_ms: 221.446
  iterations_since_restore: 171
  node_ip: 172.17.8.6
  num_metric_batches_dropped: 0
  pid: 13557
  policy_reward_mean: {}
  time_since_restore: 4201.615864276886
  time_this_iter_s: 25.47357964515686
  time_total_s: 4201.615864276886
  timestamp: 1594098976
  timesteps_since_restore: 1710000
  timesteps_this_iter: 10000
  timesteps_total: 1710000
  training_iteration: 171
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=13557], 4201 s, 171 iter, 1710000 ts, 1.16e+03 rew

agent-1: 102.0
agent-2: 114.0
agent-3: 118.0
agent-4: 108.0
agent-5: 145.0
agent-6: 104.0
agent-7: 95.0
agent-8: 103.0
agent-9: 99.0
agent-10: 135.0
Sum Reward: 1123.0
Avg Reward: 112.3
Min Reward: 95.0
Max Reward: 145.0
Gini Coefficient: 0.07292965271593944
20:20 Ratio: 1.443298969072165
Max-min Ratio: 1.5263157894736843
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_01-16-39
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1556.0
  episode_reward_mean: 1161.96
  episode_reward_min: 724.0
  episodes_this_iter: 1
  episodes_total: 171
  experiment_id: a3942a9886f24694ab1b58ca8d1ab856
  hostname: gpu006
  info:
    apply_time_ms: 3.455
    dispatch_time_ms: 6.986
    learner:
      cur_lr: 0.0012461140286177397
      grad_gnorm: 40.000003814697266
      policy_entropy: 78.09202575683594
      policy_loss: -8.151410102844238
      var_gnorm: 43.159690856933594
      vf_explained_var: 0.8689054250717163
      vf_loss: 47.0786247253418
    num_steps_sampled: 1720000
    num_steps_trained: 1720000
    wait_time_ms: 244.876
  iterations_since_restore: 172
  node_ip: 172.17.8.6
  num_metric_batches_dropped: 0
  pid: 13557
  policy_reward_mean: {}
  time_since_restore: 4224.875781536102
  time_this_iter_s: 23.25991725921631
  time_total_s: 4224.875781536102
  timestamp: 1594098999
  timesteps_since_restore: 1720000
  timesteps_this_iter: 10000
  timesteps_total: 1720000
  training_iteration: 172
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=13557], 4224 s, 172 iter, 1720000 ts, 1.16e+03 rew

agent-1: 128.0
agent-2: 113.0
agent-3: 140.0
agent-4: 115.0
agent-5: 143.0
agent-6: 143.0
agent-7: 143.0
agent-8: 113.0
agent-9: 160.0
agent-10: 140.0
Sum Reward: 1338.0
Avg Reward: 133.8
Min Reward: 113.0
Max Reward: 160.0
Gini Coefficient: 0.06113602391629298
20:20 Ratio: 1.3407079646017699
Max-min Ratio: 1.415929203539823
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_01-17-05
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1556.0
  episode_reward_mean: 1164.71
  episode_reward_min: 724.0
  episodes_this_iter: 1
  episodes_total: 172
  experiment_id: a3942a9886f24694ab1b58ca8d1ab856
  hostname: gpu006
  info:
    apply_time_ms: 3.188
    dispatch_time_ms: 6.313
    learner:
      cur_lr: 0.0012454480165615678
      grad_gnorm: 5.563276767730713
      policy_entropy: 93.93357849121094
      policy_loss: -0.9436349272727966
      var_gnorm: 43.21992874145508
      vf_explained_var: 0.7771167159080505
      vf_loss: 0.020265936851501465
    num_steps_sampled: 1730000
    num_steps_trained: 1730000
    wait_time_ms: 213.458
  iterations_since_restore: 173
  node_ip: 172.17.8.6
  num_metric_batches_dropped: 0
  pid: 13557
  policy_reward_mean: {}
  time_since_restore: 4250.4262154102325
  time_this_iter_s: 25.55043387413025
  time_total_s: 4250.4262154102325
  timestamp: 1594099025
  timesteps_since_restore: 1730000
  timesteps_this_iter: 10000
  timesteps_total: 1730000
  training_iteration: 173
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=13557], 4250 s, 173 iter, 1730000 ts, 1.16e+03 rew

agent-1: 109.0
agent-2: 101.0
agent-3: 95.0
agent-4: 70.0
agent-5: 78.0
agent-6: 84.0
agent-7: 81.0
agent-8: 69.0
agent-9: 86.0
agent-10: 69.0
Sum Reward: 842.0
Avg Reward: 84.2
Min Reward: 69.0
Max Reward: 109.0
Gini Coefficient: 0.08741092636579573
20:20 Ratio: 1.5217391304347827
Max-min Ratio: 1.5797101449275361
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_01-17-28
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1556.0
  episode_reward_mean: 1161.54
  episode_reward_min: 724.0
  episodes_this_iter: 1
  episodes_total: 173
  experiment_id: a3942a9886f24694ab1b58ca8d1ab856
  hostname: gpu006
  info:
    apply_time_ms: 2.793
    dispatch_time_ms: 6.224
    learner:
      cur_lr: 0.0012447820045053959
      grad_gnorm: 40.0
      policy_entropy: 23.7081356048584
      policy_loss: 13.455792427062988
      var_gnorm: 43.262020111083984
      vf_explained_var: 0.4227323532104492
      vf_loss: 63.77471923828125
    num_steps_sampled: 1740000
    num_steps_trained: 1740000
    wait_time_ms: 236.001
  iterations_since_restore: 174
  node_ip: 172.17.8.6
  num_metric_batches_dropped: 0
  pid: 13557
  policy_reward_mean: {}
  time_since_restore: 4274.303906917572
  time_this_iter_s: 23.877691507339478
  time_total_s: 4274.303906917572
  timestamp: 1594099048
  timesteps_since_restore: 1740000
  timesteps_this_iter: 10000
  timesteps_total: 1740000
  training_iteration: 174
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=13557], 4274 s, 174 iter, 1740000 ts, 1.16e+03 rew

agent-1: 128.0
agent-2: 91.0
agent-3: 99.0
agent-4: 118.0
agent-5: 107.0
agent-6: 112.0
agent-7: 79.0
agent-8: 117.0
agent-9: 101.0
agent-10: 122.0
Sum Reward: 1074.0
Avg Reward: 107.4
Min Reward: 79.0
Max Reward: 128.0
Gini Coefficient: 0.0750465549348231
20:20 Ratio: 1.4705882352941178
Max-min Ratio: 1.620253164556962
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_01-17-54
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1556.0
  episode_reward_mean: 1161.09
  episode_reward_min: 724.0
  episodes_this_iter: 1
  episodes_total: 174
  experiment_id: a3942a9886f24694ab1b58ca8d1ab856
  hostname: gpu006
  info:
    apply_time_ms: 2.717
    dispatch_time_ms: 8.143
    learner:
      cur_lr: 0.001244115992449224
      grad_gnorm: 7.68809175491333
      policy_entropy: 102.00102233886719
      policy_loss: -1.05965256690979
      var_gnorm: 43.3177375793457
      vf_explained_var: 0.9846112728118896
      vf_loss: 0.01518238428980112
    num_steps_sampled: 1750000
    num_steps_trained: 1750000
    wait_time_ms: 227.904
  iterations_since_restore: 175
  node_ip: 172.17.8.6
  num_metric_batches_dropped: 0
  pid: 13557
  policy_reward_mean: {}
  time_since_restore: 4299.8077480793
  time_this_iter_s: 25.503841161727905
  time_total_s: 4299.8077480793
  timestamp: 1594099074
  timesteps_since_restore: 1750000
  timesteps_this_iter: 10000
  timesteps_total: 1750000
  training_iteration: 175
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=13557], 4299 s, 175 iter, 1750000 ts, 1.16e+03 rew

agent-1: 139.0
agent-2: 99.0
agent-3: 134.0
agent-4: 130.0
agent-5: 94.0
agent-6: 86.0
agent-7: 117.0
agent-8: 110.0
agent-9: 118.0
agent-10: 92.0
Sum Reward: 1119.0
Avg Reward: 111.9
Min Reward: 86.0
Max Reward: 139.0
Gini Coefficient: 0.09070598748882931
20:20 Ratio: 1.5337078651685394
Max-min Ratio: 1.6162790697674418
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_01-18-18
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1556.0
  episode_reward_mean: 1162.43
  episode_reward_min: 724.0
  episodes_this_iter: 1
  episodes_total: 175
  experiment_id: a3942a9886f24694ab1b58ca8d1ab856
  hostname: gpu006
  info:
    apply_time_ms: 2.927
    dispatch_time_ms: 6.262
    learner:
      cur_lr: 0.001243449980393052
      grad_gnorm: 40.0
      policy_entropy: 64.82032012939453
      policy_loss: -19.398597717285156
      var_gnorm: 43.38834762573242
      vf_explained_var: 0.6555585861206055
      vf_loss: 548.0982055664062
    num_steps_sampled: 1760000
    num_steps_trained: 1760000
    wait_time_ms: 246.966
  iterations_since_restore: 176
  node_ip: 172.17.8.6
  num_metric_batches_dropped: 0
  pid: 13557
  policy_reward_mean: {}
  time_since_restore: 4323.624491214752
  time_this_iter_s: 23.81674313545227
  time_total_s: 4323.624491214752
  timestamp: 1594099098
  timesteps_since_restore: 1760000
  timesteps_this_iter: 10000
  timesteps_total: 1760000
  training_iteration: 176
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=13557], 4323 s, 176 iter, 1760000 ts, 1.16e+03 rew

agent-1: 83.0
agent-2: 98.0
agent-3: 88.0
agent-4: 99.0
agent-5: 117.0
agent-6: 126.0
agent-7: 105.0
agent-8: 95.0
agent-9: 111.0
agent-10: 107.0
Sum Reward: 1029.0
Avg Reward: 102.9
Min Reward: 83.0
Max Reward: 126.0
Gini Coefficient: 0.06831875607385811
20:20 Ratio: 1.4210526315789473
Max-min Ratio: 1.5180722891566265
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_01-18-44
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1556.0
  episode_reward_mean: 1160.48
  episode_reward_min: 724.0
  episodes_this_iter: 1
  episodes_total: 176
  experiment_id: a3942a9886f24694ab1b58ca8d1ab856
  hostname: gpu006
  info:
    apply_time_ms: 2.741
    dispatch_time_ms: 6.006
    learner:
      cur_lr: 0.0012427839683368802
      grad_gnorm: 14.74832534790039
      policy_entropy: 95.66348266601562
      policy_loss: -3.1288013458251953
      var_gnorm: 43.4620475769043
      vf_explained_var: 0.9779852032661438
      vf_loss: 0.05442182347178459
    num_steps_sampled: 1770000
    num_steps_trained: 1770000
    wait_time_ms: 246.596
  iterations_since_restore: 177
  node_ip: 172.17.8.6
  num_metric_batches_dropped: 0
  pid: 13557
  policy_reward_mean: {}
  time_since_restore: 4349.576072216034
  time_this_iter_s: 25.95158100128174
  time_total_s: 4349.576072216034
  timestamp: 1594099124
  timesteps_since_restore: 1770000
  timesteps_this_iter: 10000
  timesteps_total: 1770000
  training_iteration: 177
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=13557], 4349 s, 177 iter, 1770000 ts, 1.16e+03 rew

agent-1: 95.0
agent-2: 76.0
agent-3: 89.0
agent-4: 99.0
agent-5: 78.0
agent-6: 88.0
agent-7: 89.0
agent-8: 88.0
agent-9: 85.0
agent-10: 84.0
Sum Reward: 871.0
Avg Reward: 87.1
Min Reward: 76.0
Max Reward: 99.0
Gini Coefficient: 0.041676234213547644
20:20 Ratio: 1.2597402597402598
Max-min Ratio: 1.3026315789473684
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_01-19-08
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1556.0
  episode_reward_mean: 1158.26
  episode_reward_min: 724.0
  episodes_this_iter: 1
  episodes_total: 177
  experiment_id: a3942a9886f24694ab1b58ca8d1ab856
  hostname: gpu006
  info:
    apply_time_ms: 2.582
    dispatch_time_ms: 6.886
    learner:
      cur_lr: 0.0012421179562807083
      grad_gnorm: 11.46180248260498
      policy_entropy: 107.13238525390625
      policy_loss: -4.370542526245117
      var_gnorm: 43.58490753173828
      vf_explained_var: 0.9834490418434143
      vf_loss: 0.08700908720493317
    num_steps_sampled: 1780000
    num_steps_trained: 1780000
    wait_time_ms: 251.835
  iterations_since_restore: 178
  node_ip: 172.17.8.6
  num_metric_batches_dropped: 0
  pid: 13557
  policy_reward_mean: {}
  time_since_restore: 4373.567079305649
  time_this_iter_s: 23.991007089614868
  time_total_s: 4373.567079305649
  timestamp: 1594099148
  timesteps_since_restore: 1780000
  timesteps_this_iter: 10000
  timesteps_total: 1780000
  training_iteration: 178
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=13557], 4373 s, 178 iter, 1780000 ts, 1.16e+03 rew

agent-1: 90.0
agent-2: 105.0
agent-3: 113.0
agent-4: 101.0
agent-5: 108.0
agent-6: 94.0
agent-7: 92.0
agent-8: 97.0
agent-9: 84.0
agent-10: 97.0
Sum Reward: 981.0
Avg Reward: 98.1
Min Reward: 84.0
Max Reward: 113.0
Gini Coefficient: 0.048216106014271155
20:20 Ratio: 1.2701149425287357
Max-min Ratio: 1.3452380952380953
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_01-19-33
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1556.0
  episode_reward_mean: 1156.26
  episode_reward_min: 724.0
  episodes_this_iter: 1
  episodes_total: 178
  experiment_id: a3942a9886f24694ab1b58ca8d1ab856
  hostname: gpu006
  info:
    apply_time_ms: 2.863
    dispatch_time_ms: 6.114
    learner:
      cur_lr: 0.0012414519442245364
      grad_gnorm: 40.000003814697266
      policy_entropy: 10.891809463500977
      policy_loss: 14.747030258178711
      var_gnorm: 43.627723693847656
      vf_explained_var: 0.6480547189712524
      vf_loss: 96.528564453125
    num_steps_sampled: 1790000
    num_steps_trained: 1790000
    wait_time_ms: 225.734
  iterations_since_restore: 179
  node_ip: 172.17.8.6
  num_metric_batches_dropped: 0
  pid: 13557
  policy_reward_mean: {}
  time_since_restore: 4398.687354803085
  time_this_iter_s: 25.120275497436523
  time_total_s: 4398.687354803085
  timestamp: 1594099173
  timesteps_since_restore: 1790000
  timesteps_this_iter: 10000
  timesteps_total: 1790000
  training_iteration: 179
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=13557], 4398 s, 179 iter, 1790000 ts, 1.16e+03 rew

agent-1: 104.0
agent-2: 121.0
agent-3: 104.0
agent-4: 109.0
agent-5: 107.0
agent-6: 107.0
agent-7: 68.0
agent-8: 94.0
agent-9: 95.0
agent-10: 111.0
Sum Reward: 1020.0
Avg Reward: 102.0
Min Reward: 68.0
Max Reward: 121.0
Gini Coefficient: 0.06647058823529411
20:20 Ratio: 1.4320987654320987
Max-min Ratio: 1.7794117647058822
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_01-19-56
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1556.0
  episode_reward_mean: 1154.54
  episode_reward_min: 724.0
  episodes_this_iter: 1
  episodes_total: 179
  experiment_id: a3942a9886f24694ab1b58ca8d1ab856
  hostname: gpu006
  info:
    apply_time_ms: 2.702
    dispatch_time_ms: 6.919
    learner:
      cur_lr: 0.0012407860485836864
      grad_gnorm: 40.000003814697266
      policy_entropy: 25.990650177001953
      policy_loss: 9.075742721557617
      var_gnorm: 43.71976089477539
      vf_explained_var: 0.8139386177062988
      vf_loss: 110.8156509399414
    num_steps_sampled: 1800000
    num_steps_trained: 1800000
    wait_time_ms: 219.534
  iterations_since_restore: 180
  node_ip: 172.17.8.6
  num_metric_batches_dropped: 0
  pid: 13557
  policy_reward_mean: {}
  time_since_restore: 4421.5792446136475
  time_this_iter_s: 22.891889810562134
  time_total_s: 4421.5792446136475
  timestamp: 1594099196
  timesteps_since_restore: 1800000
  timesteps_this_iter: 10000
  timesteps_total: 1800000
  training_iteration: 180
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=13557], 4421 s, 180 iter, 1800000 ts, 1.15e+03 rew

agent-1: 96.0
agent-2: 143.0
agent-3: 148.0
agent-4: 119.0
agent-5: 148.0
agent-6: 140.0
agent-7: 142.0
agent-8: 128.0
agent-9: 108.0
agent-10: 160.0
Sum Reward: 1332.0
Avg Reward: 133.2
Min Reward: 96.0
Max Reward: 160.0
Gini Coefficient: 0.07867867867867868
20:20 Ratio: 1.5098039215686274
Max-min Ratio: 1.6666666666666667
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_01-20-21
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1556.0
  episode_reward_mean: 1155.86
  episode_reward_min: 724.0
  episodes_this_iter: 1
  episodes_total: 180
  experiment_id: a3942a9886f24694ab1b58ca8d1ab856
  hostname: gpu006
  info:
    apply_time_ms: 2.64
    dispatch_time_ms: 7.417
    learner:
      cur_lr: 0.0012401200365275145
      grad_gnorm: 40.0
      policy_entropy: 8.32813549041748
      policy_loss: 6.246252536773682
      var_gnorm: 43.76670837402344
      vf_explained_var: 0.407678484916687
      vf_loss: 149.02374267578125
    num_steps_sampled: 1810000
    num_steps_trained: 1810000
    wait_time_ms: 232.063
  iterations_since_restore: 181
  node_ip: 172.17.8.6
  num_metric_batches_dropped: 0
  pid: 13557
  policy_reward_mean: {}
  time_since_restore: 4446.42068529129
  time_this_iter_s: 24.841440677642822
  time_total_s: 4446.42068529129
  timestamp: 1594099221
  timesteps_since_restore: 1810000
  timesteps_this_iter: 10000
  timesteps_total: 1810000
  training_iteration: 181
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=13557], 4446 s, 181 iter, 1810000 ts, 1.16e+03 rew

agent-1: 130.0
agent-2: 107.0
agent-3: 109.0
agent-4: 90.0
agent-5: 107.0
agent-6: 134.0
agent-7: 116.0
agent-8: 137.0
agent-9: 113.0
agent-10: 137.0
Sum Reward: 1180.0
Avg Reward: 118.0
Min Reward: 90.0
Max Reward: 137.0
Gini Coefficient: 0.07067796610169491
20:20 Ratio: 1.3908629441624365
Max-min Ratio: 1.5222222222222221
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_01-20-45
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1556.0
  episode_reward_mean: 1155.86
  episode_reward_min: 724.0
  episodes_this_iter: 1
  episodes_total: 181
  experiment_id: a3942a9886f24694ab1b58ca8d1ab856
  hostname: gpu006
  info:
    apply_time_ms: 3.444
    dispatch_time_ms: 6.385
    learner:
      cur_lr: 0.0012394540244713426
      grad_gnorm: 40.0
      policy_entropy: 44.12228012084961
      policy_loss: 3.6014211177825928
      var_gnorm: 43.82267761230469
      vf_explained_var: 0.369529128074646
      vf_loss: 52.991050720214844
    num_steps_sampled: 1820000
    num_steps_trained: 1820000
    wait_time_ms: 229.969
  iterations_since_restore: 182
  node_ip: 172.17.8.6
  num_metric_batches_dropped: 0
  pid: 13557
  policy_reward_mean: {}
  time_since_restore: 4470.088044881821
  time_this_iter_s: 23.667359590530396
  time_total_s: 4470.088044881821
  timestamp: 1594099245
  timesteps_since_restore: 1820000
  timesteps_this_iter: 10000
  timesteps_total: 1820000
  training_iteration: 182
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=13557], 4470 s, 182 iter, 1820000 ts, 1.16e+03 rew

W0707 01:21:23.912923 13553 client_connection.cc:255] [worker]ProcessMessage with type 1 took 7374 ms.
W0707 01:21:23.921844 13553 node_manager.cc:250] Last heartbeat was sent 7576 ms ago 
agent-1: 129.0
agent-2: 114.0
agent-3: 166.0
agent-4: 160.0
agent-5: 109.0
agent-6: 131.0
agent-7: 127.0
agent-8: 153.0
agent-9: 128.0
agent-10: 142.0
Sum Reward: 1359.0
Avg Reward: 135.9
Min Reward: 109.0
Max Reward: 166.0
Gini Coefficient: 0.0742457689477557
20:20 Ratio: 1.4618834080717489
Max-min Ratio: 1.5229357798165137
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_01-21-36
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1556.0
  episode_reward_mean: 1158.33
  episode_reward_min: 724.0
  episodes_this_iter: 1
  episodes_total: 182
  experiment_id: a3942a9886f24694ab1b58ca8d1ab856
  hostname: gpu006
  info:
    apply_time_ms: 2.898
    dispatch_time_ms: 6.901
    learner:
      cur_lr: 0.0012387880124151707
      grad_gnorm: 7.980783939361572
      policy_entropy: 74.23339080810547
      policy_loss: -1.5347425937652588
      var_gnorm: 43.96072006225586
      vf_explained_var: 0.8554208278656006
      vf_loss: 0.11169670522212982
    num_steps_sampled: 1830000
    num_steps_trained: 1830000
    wait_time_ms: 242.673
  iterations_since_restore: 183
  node_ip: 172.17.8.6
  num_metric_batches_dropped: 0
  pid: 13557
  policy_reward_mean: {}
  time_since_restore: 4521.858769416809
  time_this_iter_s: 51.7707245349884
  time_total_s: 4521.858769416809
  timestamp: 1594099296
  timesteps_since_restore: 1830000
  timesteps_this_iter: 10000
  timesteps_total: 1830000
  training_iteration: 183
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=13557], 4521 s, 183 iter, 1830000 ts, 1.16e+03 rew

agent-1: 102.0
agent-2: 86.0
agent-3: 94.0
agent-4: 97.0
agent-5: 78.0
agent-6: 94.0
agent-7: 108.0
agent-8: 107.0
agent-9: 91.0
agent-10: 93.0
Sum Reward: 950.0
Avg Reward: 95.0
Min Reward: 78.0
Max Reward: 108.0
Gini Coefficient: 0.05094736842105263
20:20 Ratio: 1.3109756097560976
Max-min Ratio: 1.3846153846153846
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_01-22-01
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1556.0
  episode_reward_mean: 1157.88
  episode_reward_min: 724.0
  episodes_this_iter: 1
  episodes_total: 183
  experiment_id: a3942a9886f24694ab1b58ca8d1ab856
  hostname: gpu006
  info:
    apply_time_ms: 2.767
    dispatch_time_ms: 5.914
    learner:
      cur_lr: 0.0012381220003589988
      grad_gnorm: 39.99999237060547
      policy_entropy: 32.17341232299805
      policy_loss: -11.198477745056152
      var_gnorm: 44.02327346801758
      vf_explained_var: 0.6774916648864746
      vf_loss: 137.8218994140625
    num_steps_sampled: 1840000
    num_steps_trained: 1840000
    wait_time_ms: 224.624
  iterations_since_restore: 184
  node_ip: 172.17.8.6
  num_metric_batches_dropped: 0
  pid: 13557
  policy_reward_mean: {}
  time_since_restore: 4546.321232318878
  time_this_iter_s: 24.462462902069092
  time_total_s: 4546.321232318878
  timestamp: 1594099321
  timesteps_since_restore: 1840000
  timesteps_this_iter: 10000
  timesteps_total: 1840000
  training_iteration: 184
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=13557], 4546 s, 184 iter, 1840000 ts, 1.16e+03 rew

agent-1: 96.0
agent-2: 116.0
agent-3: 103.0
agent-4: 107.0
agent-5: 108.0
agent-6: 108.0
agent-7: 92.0
agent-8: 79.0
agent-9: 94.0
agent-10: 112.0
Sum Reward: 1015.0
Avg Reward: 101.5
Min Reward: 79.0
Max Reward: 116.0
Gini Coefficient: 0.057438423645320195
20:20 Ratio: 1.3333333333333333
Max-min Ratio: 1.4683544303797469
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_01-22-25
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1556.0
  episode_reward_mean: 1155.72
  episode_reward_min: 724.0
  episodes_this_iter: 1
  episodes_total: 184
  experiment_id: a3942a9886f24694ab1b58ca8d1ab856
  hostname: gpu006
  info:
    apply_time_ms: 2.926
    dispatch_time_ms: 7.834
    learner:
      cur_lr: 0.0012374559883028269
      grad_gnorm: 40.00000762939453
      policy_entropy: 33.59426498413086
      policy_loss: 0.047900181263685226
      var_gnorm: 44.13529968261719
      vf_explained_var: -0.5259355306625366
      vf_loss: 3.7884092330932617
    num_steps_sampled: 1850000
    num_steps_trained: 1850000
    wait_time_ms: 214.111
  iterations_since_restore: 185
  node_ip: 172.17.8.6
  num_metric_batches_dropped: 0
  pid: 13557
  policy_reward_mean: {}
  time_since_restore: 4570.652386426926
  time_this_iter_s: 24.331154108047485
  time_total_s: 4570.652386426926
  timestamp: 1594099345
  timesteps_since_restore: 1850000
  timesteps_this_iter: 10000
  timesteps_total: 1850000
  training_iteration: 185
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=13557], 4570 s, 185 iter, 1850000 ts, 1.16e+03 rew

agent-1: 86.0
agent-2: 123.0
agent-3: 128.0
agent-4: 102.0
agent-5: 123.0
agent-6: 126.0
agent-7: 133.0
agent-8: 120.0
agent-9: 107.0
agent-10: 145.0
Sum Reward: 1193.0
Avg Reward: 119.3
Min Reward: 86.0
Max Reward: 145.0
Gini Coefficient: 0.0730092204526404
20:20 Ratio: 1.4787234042553192
Max-min Ratio: 1.686046511627907
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_01-22-49
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1556.0
  episode_reward_mean: 1157.12
  episode_reward_min: 724.0
  episodes_this_iter: 1
  episodes_total: 185
  experiment_id: a3942a9886f24694ab1b58ca8d1ab856
  hostname: gpu006
  info:
    apply_time_ms: 2.808
    dispatch_time_ms: 6.822
    learner:
      cur_lr: 0.001236789976246655
      grad_gnorm: 40.00000762939453
      policy_entropy: 46.941688537597656
      policy_loss: 19.031156539916992
      var_gnorm: 44.151702880859375
      vf_explained_var: 0.6789849996566772
      vf_loss: 103.40943908691406
    num_steps_sampled: 1860000
    num_steps_trained: 1860000
    wait_time_ms: 238.436
  iterations_since_restore: 186
  node_ip: 172.17.8.6
  num_metric_batches_dropped: 0
  pid: 13557
  policy_reward_mean: {}
  time_since_restore: 4594.2658569812775
  time_this_iter_s: 23.613470554351807
  time_total_s: 4594.2658569812775
  timestamp: 1594099369
  timesteps_since_restore: 1860000
  timesteps_this_iter: 10000
  timesteps_total: 1860000
  training_iteration: 186
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=13557], 4594 s, 186 iter, 1860000 ts, 1.16e+03 rew

agent-1: 134.0
agent-2: 155.0
agent-3: 145.0
agent-4: 98.0
agent-5: 104.0
agent-6: 157.0
agent-7: 120.0
agent-8: 137.0
agent-9: 128.0
agent-10: 109.0
Sum Reward: 1287.0
Avg Reward: 128.7
Min Reward: 98.0
Max Reward: 157.0
Gini Coefficient: 0.08741258741258741
20:20 Ratio: 1.5445544554455446
Max-min Ratio: 1.6020408163265305
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_01-23-13
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1556.0
  episode_reward_mean: 1158.28
  episode_reward_min: 724.0
  episodes_this_iter: 1
  episodes_total: 186
  experiment_id: a3942a9886f24694ab1b58ca8d1ab856
  hostname: gpu006
  info:
    apply_time_ms: 2.689
    dispatch_time_ms: 5.77
    learner:
      cur_lr: 0.001236123964190483
      grad_gnorm: 40.00000762939453
      policy_entropy: 76.56220245361328
      policy_loss: -3.4481475353240967
      var_gnorm: 44.2728271484375
      vf_explained_var: 0.30871397256851196
      vf_loss: 2.588653087615967
    num_steps_sampled: 1870000
    num_steps_trained: 1870000
    wait_time_ms: 256.43
  iterations_since_restore: 187
  node_ip: 172.17.8.6
  num_metric_batches_dropped: 0
  pid: 13557
  policy_reward_mean: {}
  time_since_restore: 4618.67091178894
  time_this_iter_s: 24.405054807662964
  time_total_s: 4618.67091178894
  timestamp: 1594099393
  timesteps_since_restore: 1870000
  timesteps_this_iter: 10000
  timesteps_total: 1870000
  training_iteration: 187
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=13557], 4618 s, 187 iter, 1870000 ts, 1.16e+03 rew

agent-1: 109.0
agent-2: 106.0
agent-3: 135.0
agent-4: 122.0
agent-5: 141.0
agent-6: 142.0
agent-7: 111.0
agent-8: 115.0
agent-9: 123.0
agent-10: 118.0
Sum Reward: 1222.0
Avg Reward: 122.2
Min Reward: 106.0
Max Reward: 142.0
Gini Coefficient: 0.05695581014729951
20:20 Ratio: 1.3162790697674418
Max-min Ratio: 1.3396226415094339
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_01-23-37
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1556.0
  episode_reward_mean: 1158.24
  episode_reward_min: 724.0
  episodes_this_iter: 1
  episodes_total: 187
  experiment_id: a3942a9886f24694ab1b58ca8d1ab856
  hostname: gpu006
  info:
    apply_time_ms: 2.715
    dispatch_time_ms: 7.367
    learner:
      cur_lr: 0.0012354579521343112
      grad_gnorm: 40.0
      policy_entropy: 26.563291549682617
      policy_loss: 9.980669021606445
      var_gnorm: 44.38734436035156
      vf_explained_var: 0.3352869153022766
      vf_loss: 167.84487915039062
    num_steps_sampled: 1880000
    num_steps_trained: 1880000
    wait_time_ms: 216.818
  iterations_since_restore: 188
  node_ip: 172.17.8.6
  num_metric_batches_dropped: 0
  pid: 13557
  policy_reward_mean: {}
  time_since_restore: 4642.568179130554
  time_this_iter_s: 23.89726734161377
  time_total_s: 4642.568179130554
  timestamp: 1594099417
  timesteps_since_restore: 1880000
  timesteps_this_iter: 10000
  timesteps_total: 1880000
  training_iteration: 188
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=13557], 4642 s, 188 iter, 1880000 ts, 1.16e+03 rew

agent-1: 99.0
agent-2: 138.0
agent-3: 93.0
agent-4: 123.0
agent-5: 139.0
agent-6: 138.0
agent-7: 119.0
agent-8: 124.0
agent-9: 133.0
agent-10: 129.0
Sum Reward: 1235.0
Avg Reward: 123.5
Min Reward: 93.0
Max Reward: 139.0
Gini Coefficient: 0.06615384615384616
20:20 Ratio: 1.4427083333333333
Max-min Ratio: 1.4946236559139785
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_01-24-02
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1556.0
  episode_reward_mean: 1156.29
  episode_reward_min: 724.0
  episodes_this_iter: 1
  episodes_total: 188
  experiment_id: a3942a9886f24694ab1b58ca8d1ab856
  hostname: gpu006
  info:
    apply_time_ms: 3.518
    dispatch_time_ms: 7.071
    learner:
      cur_lr: 0.0012347920564934611
      grad_gnorm: 40.0
      policy_entropy: 35.30802536010742
      policy_loss: -0.788447916507721
      var_gnorm: 44.47767639160156
      vf_explained_var: 0.49356377124786377
      vf_loss: 43.84864044189453
    num_steps_sampled: 1890000
    num_steps_trained: 1890000
    wait_time_ms: 231.581
  iterations_since_restore: 189
  node_ip: 172.17.8.6
  num_metric_batches_dropped: 0
  pid: 13557
  policy_reward_mean: {}
  time_since_restore: 4666.881069421768
  time_this_iter_s: 24.31289029121399
  time_total_s: 4666.881069421768
  timestamp: 1594099442
  timesteps_since_restore: 1890000
  timesteps_this_iter: 10000
  timesteps_total: 1890000
  training_iteration: 189
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=13557], 4666 s, 189 iter, 1890000 ts, 1.16e+03 rew

agent-1: 99.0
agent-2: 89.0
agent-3: 120.0
agent-4: 108.0
agent-5: 127.0
agent-6: 104.0
agent-7: 108.0
agent-8: 121.0
agent-9: 122.0
agent-10: 100.0
Sum Reward: 1098.0
Avg Reward: 109.8
Min Reward: 89.0
Max Reward: 127.0
Gini Coefficient: 0.05974499089253188
20:20 Ratio: 1.324468085106383
Max-min Ratio: 1.4269662921348314
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_01-24-26
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1556.0
  episode_reward_mean: 1153.54
  episode_reward_min: 724.0
  episodes_this_iter: 1
  episodes_total: 189
  experiment_id: a3942a9886f24694ab1b58ca8d1ab856
  hostname: gpu006
  info:
    apply_time_ms: 2.594
    dispatch_time_ms: 6.829
    learner:
      cur_lr: 0.0012341260444372892
      grad_gnorm: 39.999961853027344
      policy_entropy: 56.71356964111328
      policy_loss: 5.660284042358398
      var_gnorm: 44.56320571899414
      vf_explained_var: 0.8044390678405762
      vf_loss: 27.27033042907715
    num_steps_sampled: 1900000
    num_steps_trained: 1900000
    wait_time_ms: 218.622
  iterations_since_restore: 190
  node_ip: 172.17.8.6
  num_metric_batches_dropped: 0
  pid: 13557
  policy_reward_mean: {}
  time_since_restore: 4690.716814517975
  time_this_iter_s: 23.835745096206665
  time_total_s: 4690.716814517975
  timestamp: 1594099466
  timesteps_since_restore: 1900000
  timesteps_this_iter: 10000
  timesteps_total: 1900000
  training_iteration: 190
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=13557], 4690 s, 190 iter, 1900000 ts, 1.15e+03 rew

agent-1: 125.0
agent-2: 140.0
agent-3: 103.0
agent-4: 123.0
agent-5: 109.0
agent-6: 156.0
agent-7: 153.0
agent-8: 141.0
agent-9: 159.0
agent-10: 145.0
Sum Reward: 1354.0
Avg Reward: 135.4
Min Reward: 103.0
Max Reward: 159.0
Gini Coefficient: 0.07710487444608567
20:20 Ratio: 1.4858490566037736
Max-min Ratio: 1.5436893203883495
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_01-24-49
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1556.0
  episode_reward_mean: 1151.74
  episode_reward_min: 724.0
  episodes_this_iter: 1
  episodes_total: 190
  experiment_id: a3942a9886f24694ab1b58ca8d1ab856
  hostname: gpu006
  info:
    apply_time_ms: 2.672
    dispatch_time_ms: 7.901
    learner:
      cur_lr: 0.0012334600323811173
      grad_gnorm: 40.0
      policy_entropy: 39.5871696472168
      policy_loss: -6.229204177856445
      var_gnorm: 44.665771484375
      vf_explained_var: 0.4412815570831299
      vf_loss: 83.33000946044922
    num_steps_sampled: 1910000
    num_steps_trained: 1910000
    wait_time_ms: 241.339
  iterations_since_restore: 191
  node_ip: 172.17.8.6
  num_metric_batches_dropped: 0
  pid: 13557
  policy_reward_mean: {}
  time_since_restore: 4714.448091745377
  time_this_iter_s: 23.731277227401733
  time_total_s: 4714.448091745377
  timestamp: 1594099489
  timesteps_since_restore: 1910000
  timesteps_this_iter: 10000
  timesteps_total: 1910000
  training_iteration: 191
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=13557], 4714 s, 191 iter, 1910000 ts, 1.15e+03 rew

agent-1: 115.0
agent-2: 143.0
agent-3: 143.0
agent-4: 115.0
agent-5: 122.0
agent-6: 116.0
agent-7: 134.0
agent-8: 105.0
agent-9: 132.0
agent-10: 124.0
Sum Reward: 1249.0
Avg Reward: 124.9
Min Reward: 105.0
Max Reward: 143.0
Gini Coefficient: 0.05468374699759808
20:20 Ratio: 1.3
Max-min Ratio: 1.361904761904762
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_01-25-13
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1556.0
  episode_reward_mean: 1149.52
  episode_reward_min: 724.0
  episodes_this_iter: 1
  episodes_total: 191
  experiment_id: a3942a9886f24694ab1b58ca8d1ab856
  hostname: gpu006
  info:
    apply_time_ms: 2.776
    dispatch_time_ms: 6.789
    learner:
      cur_lr: 0.0012327940203249454
      grad_gnorm: 39.999996185302734
      policy_entropy: 20.290977478027344
      policy_loss: 2.0614733695983887
      var_gnorm: 44.78089141845703
      vf_explained_var: -0.08079278469085693
      vf_loss: 19.289382934570312
    num_steps_sampled: 1920000
    num_steps_trained: 1920000
    wait_time_ms: 226.268
  iterations_since_restore: 192
  node_ip: 172.17.8.6
  num_metric_batches_dropped: 0
  pid: 13557
  policy_reward_mean: {}
  time_since_restore: 4738.5558252334595
  time_this_iter_s: 24.107733488082886
  time_total_s: 4738.5558252334595
  timestamp: 1594099513
  timesteps_since_restore: 1920000
  timesteps_this_iter: 10000
  timesteps_total: 1920000
  training_iteration: 192
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=13557], 4738 s, 192 iter, 1920000 ts, 1.15e+03 rew

agent-1: 152.0
agent-2: 116.0
agent-3: 145.0
agent-4: 153.0
agent-5: 164.0
agent-6: 148.0
agent-7: 114.0
agent-8: 157.0
agent-9: 137.0
agent-10: 135.0
Sum Reward: 1421.0
Avg Reward: 142.1
Min Reward: 114.0
Max Reward: 164.0
Gini Coefficient: 0.06157635467980296
20:20 Ratio: 1.3956521739130434
Max-min Ratio: 1.4385964912280702
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_01-25-37
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1556.0
  episode_reward_mean: 1153.71
  episode_reward_min: 724.0
  episodes_this_iter: 1
  episodes_total: 192
  experiment_id: a3942a9886f24694ab1b58ca8d1ab856
  hostname: gpu006
  info:
    apply_time_ms: 2.914
    dispatch_time_ms: 7.178
    learner:
      cur_lr: 0.0012321280082687736
      grad_gnorm: 40.000003814697266
      policy_entropy: 40.18610763549805
      policy_loss: 13.560325622558594
      var_gnorm: 44.86355209350586
      vf_explained_var: 0.7526444792747498
      vf_loss: 26.704225540161133
    num_steps_sampled: 1930000
    num_steps_trained: 1930000
    wait_time_ms: 241.301
  iterations_since_restore: 193
  node_ip: 172.17.8.6
  num_metric_batches_dropped: 0
  pid: 13557
  policy_reward_mean: {}
  time_since_restore: 4762.086732387543
  time_this_iter_s: 23.530907154083252
  time_total_s: 4762.086732387543
  timestamp: 1594099537
  timesteps_since_restore: 1930000
  timesteps_this_iter: 10000
  timesteps_total: 1930000
  training_iteration: 193
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=13557], 4762 s, 193 iter, 1930000 ts, 1.15e+03 rew

agent-1: 126.0
agent-2: 127.0
agent-3: 129.0
agent-4: 148.0
agent-5: 125.0
agent-6: 136.0
agent-7: 140.0
agent-8: 122.0
agent-9: 130.0
agent-10: 117.0
Sum Reward: 1300.0
Avg Reward: 130.0
Min Reward: 117.0
Max Reward: 148.0
Gini Coefficient: 0.03646153846153846
20:20 Ratio: 1.205020920502092
Max-min Ratio: 1.264957264957265
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_01-26-02
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1556.0
  episode_reward_mean: 1155.37
  episode_reward_min: 724.0
  episodes_this_iter: 1
  episodes_total: 193
  experiment_id: a3942a9886f24694ab1b58ca8d1ab856
  hostname: gpu006
  info:
    apply_time_ms: 2.836
    dispatch_time_ms: 6.219
    learner:
      cur_lr: 0.0012314619962126017
      grad_gnorm: 40.0
      policy_entropy: 18.114978790283203
      policy_loss: 25.005950927734375
      var_gnorm: 44.906070709228516
      vf_explained_var: 0.41417020559310913
      vf_loss: 256.61004638671875
    num_steps_sampled: 1940000
    num_steps_trained: 1940000
    wait_time_ms: 230.933
  iterations_since_restore: 194
  node_ip: 172.17.8.6
  num_metric_batches_dropped: 0
  pid: 13557
  policy_reward_mean: {}
  time_since_restore: 4786.620124101639
  time_this_iter_s: 24.53339171409607
  time_total_s: 4786.620124101639
  timestamp: 1594099562
  timesteps_since_restore: 1940000
  timesteps_this_iter: 10000
  timesteps_total: 1940000
  training_iteration: 194
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=13557], 4786 s, 194 iter, 1940000 ts, 1.16e+03 rew

agent-1: 146.0
agent-2: 126.0
agent-3: 129.0
agent-4: 137.0
agent-5: 123.0
agent-6: 125.0
agent-7: 120.0
agent-8: 117.0
agent-9: 122.0
agent-10: 104.0
Sum Reward: 1249.0
Avg Reward: 124.9
Min Reward: 104.0
Max Reward: 146.0
Gini Coefficient: 0.04619695756605284
20:20 Ratio: 1.2805429864253393
Max-min Ratio: 1.4038461538461537
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_01-26-26
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1556.0
  episode_reward_mean: 1156.7
  episode_reward_min: 724.0
  episodes_this_iter: 1
  episodes_total: 194
  experiment_id: a3942a9886f24694ab1b58ca8d1ab856
  hostname: gpu006
  info:
    apply_time_ms: 2.761
    dispatch_time_ms: 6.271
    learner:
      cur_lr: 0.0012307959841564298
      grad_gnorm: 7.975447177886963
      policy_entropy: 50.78617477416992
      policy_loss: -0.5314769148826599
      var_gnorm: 44.97041320800781
      vf_explained_var: 0.9102694988250732
      vf_loss: 0.015424856916069984
    num_steps_sampled: 1950000
    num_steps_trained: 1950000
    wait_time_ms: 245.411
  iterations_since_restore: 195
  node_ip: 172.17.8.6
  num_metric_batches_dropped: 0
  pid: 13557
  policy_reward_mean: {}
  time_since_restore: 4811.091308832169
  time_this_iter_s: 24.471184730529785
  time_total_s: 4811.091308832169
  timestamp: 1594099586
  timesteps_since_restore: 1950000
  timesteps_this_iter: 10000
  timesteps_total: 1950000
  training_iteration: 195
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=13557], 4811 s, 195 iter, 1950000 ts, 1.16e+03 rew

agent-1: 94.0
agent-2: 90.0
agent-3: 88.0
agent-4: 90.0
agent-5: 78.0
agent-6: 93.0
agent-7: 92.0
agent-8: 103.0
agent-9: 97.0
agent-10: 98.0
Sum Reward: 923.0
Avg Reward: 92.3
Min Reward: 78.0
Max Reward: 103.0
Gini Coefficient: 0.0371614301191766
20:20 Ratio: 1.2108433734939759
Max-min Ratio: 1.3205128205128205
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_01-26-52
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1556.0
  episode_reward_mean: 1153.87
  episode_reward_min: 724.0
  episodes_this_iter: 1
  episodes_total: 195
  experiment_id: a3942a9886f24694ab1b58ca8d1ab856
  hostname: gpu006
  info:
    apply_time_ms: 2.767
    dispatch_time_ms: 6.962
    learner:
      cur_lr: 0.0012301299721002579
      grad_gnorm: 18.608667373657227
      policy_entropy: 91.16008758544922
      policy_loss: -1.0593315362930298
      var_gnorm: 44.99980926513672
      vf_explained_var: 0.4676870107650757
      vf_loss: 0.04882608354091644
    num_steps_sampled: 1960000
    num_steps_trained: 1960000
    wait_time_ms: 249.852
  iterations_since_restore: 196
  node_ip: 172.17.8.6
  num_metric_batches_dropped: 0
  pid: 13557
  policy_reward_mean: {}
  time_since_restore: 4836.48891210556
  time_this_iter_s: 25.397603273391724
  time_total_s: 4836.48891210556
  timestamp: 1594099612
  timesteps_since_restore: 1960000
  timesteps_this_iter: 10000
  timesteps_total: 1960000
  training_iteration: 196
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=13557], 4836 s, 196 iter, 1960000 ts, 1.15e+03 rew

agent-1: 86.0
agent-2: 110.0
agent-3: 81.0
agent-4: 98.0
agent-5: 113.0
agent-6: 97.0
agent-7: 105.0
agent-8: 98.0
agent-9: 89.0
agent-10: 101.0
Sum Reward: 978.0
Avg Reward: 97.8
Min Reward: 81.0
Max Reward: 113.0
Gini Coefficient: 0.05603271983640082
20:20 Ratio: 1.3353293413173652
Max-min Ratio: 1.3950617283950617
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_01-27-16
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1556.0
  episode_reward_mean: 1152.66
  episode_reward_min: 724.0
  episodes_this_iter: 1
  episodes_total: 196
  experiment_id: a3942a9886f24694ab1b58ca8d1ab856
  hostname: gpu006
  info:
    apply_time_ms: 2.945
    dispatch_time_ms: 8.259
    learner:
      cur_lr: 0.001229463960044086
      grad_gnorm: 18.321962356567383
      policy_entropy: 89.9554443359375
      policy_loss: -2.1201674938201904
      var_gnorm: 45.10536193847656
      vf_explained_var: 0.9904730916023254
      vf_loss: 0.053270500153303146
    num_steps_sampled: 1970000
    num_steps_trained: 1970000
    wait_time_ms: 234.228
  iterations_since_restore: 197
  node_ip: 172.17.8.6
  num_metric_batches_dropped: 0
  pid: 13557
  policy_reward_mean: {}
  time_since_restore: 4860.563319683075
  time_this_iter_s: 24.07440757751465
  time_total_s: 4860.563319683075
  timestamp: 1594099636
  timesteps_since_restore: 1970000
  timesteps_this_iter: 10000
  timesteps_total: 1970000
  training_iteration: 197
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 29.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=13557], 4860 s, 197 iter, 1970000 ts, 1.15e+03 rew

agent-1: 75.0
agent-2: 65.0
agent-3: 96.0
agent-4: 105.0
agent-5: 90.0
agent-6: 70.0
agent-7: 99.0
agent-8: 97.0
agent-9: 59.0
agent-10: 107.0
Sum Reward: 863.0
Avg Reward: 86.3
Min Reward: 59.0
Max Reward: 107.0
Gini Coefficient: 0.10764774044032445
20:20 Ratio: 1.7096774193548387
Max-min Ratio: 1.8135593220338984
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_01-27-41
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1556.0
  episode_reward_mean: 1150.78
  episode_reward_min: 724.0
  episodes_this_iter: 1
  episodes_total: 197
  experiment_id: a3942a9886f24694ab1b58ca8d1ab856
  hostname: gpu006
  info:
    apply_time_ms: 2.938
    dispatch_time_ms: 7.807
    learner:
      cur_lr: 0.001228797947987914
      grad_gnorm: 24.433135986328125
      policy_entropy: 99.20569610595703
      policy_loss: -1.2536667585372925
      var_gnorm: 45.14449691772461
      vf_explained_var: -0.1313645839691162
      vf_loss: 0.021519994363188744
    num_steps_sampled: 1980000
    num_steps_trained: 1980000
    wait_time_ms: 206.849
  iterations_since_restore: 198
  node_ip: 172.17.8.6
  num_metric_batches_dropped: 0
  pid: 13557
  policy_reward_mean: {}
  time_since_restore: 4885.570643663406
  time_this_iter_s: 25.00732398033142
  time_total_s: 4885.570643663406
  timestamp: 1594099661
  timesteps_since_restore: 1980000
  timesteps_this_iter: 10000
  timesteps_total: 1980000
  training_iteration: 198
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 29.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=13557], 4885 s, 198 iter, 1980000 ts, 1.15e+03 rew

agent-1: 117.0
agent-2: 138.0
agent-3: 154.0
agent-4: 130.0
agent-5: 135.0
agent-6: 92.0
agent-7: 129.0
agent-8: 117.0
agent-9: 110.0
agent-10: 117.0
Sum Reward: 1239.0
Avg Reward: 123.9
Min Reward: 92.0
Max Reward: 154.0
Gini Coefficient: 0.07223567393058919
20:20 Ratio: 1.4455445544554455
Max-min Ratio: 1.673913043478261
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_01-28-05
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1556.0
  episode_reward_mean: 1152.58
  episode_reward_min: 724.0
  episodes_this_iter: 1
  episodes_total: 198
  experiment_id: a3942a9886f24694ab1b58ca8d1ab856
  hostname: gpu006
  info:
    apply_time_ms: 3.094
    dispatch_time_ms: 6.416
    learner:
      cur_lr: 0.001228132052347064
      grad_gnorm: 20.605693817138672
      policy_entropy: 112.21591186523438
      policy_loss: -4.868589401245117
      var_gnorm: 45.213191986083984
      vf_explained_var: 0.7730340361595154
      vf_loss: 0.997613251209259
    num_steps_sampled: 1990000
    num_steps_trained: 1990000
    wait_time_ms: 260.815
  iterations_since_restore: 199
  node_ip: 172.17.8.6
  num_metric_batches_dropped: 0
  pid: 13557
  policy_reward_mean: {}
  time_since_restore: 4909.6970891952515
  time_this_iter_s: 24.126445531845093
  time_total_s: 4909.6970891952515
  timestamp: 1594099685
  timesteps_since_restore: 1990000
  timesteps_this_iter: 10000
  timesteps_total: 1990000
  training_iteration: 199
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 29.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=13557], 4909 s, 199 iter, 1990000 ts, 1.15e+03 rew

agent-1: 94.0
agent-2: 108.0
agent-3: 100.0
agent-4: 116.0
agent-5: 97.0
agent-6: 98.0
agent-7: 99.0
agent-8: 101.0
agent-9: 120.0
agent-10: 117.0
Sum Reward: 1050.0
Avg Reward: 105.0
Min Reward: 94.0
Max Reward: 120.0
Gini Coefficient: 0.046857142857142854
20:20 Ratio: 1.2408376963350785
Max-min Ratio: 1.2765957446808511
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_01-28-31
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1556.0
  episode_reward_mean: 1151.1
  episode_reward_min: 724.0
  episodes_this_iter: 1
  episodes_total: 199
  experiment_id: a3942a9886f24694ab1b58ca8d1ab856
  hostname: gpu006
  info:
    apply_time_ms: 2.727
    dispatch_time_ms: 6.995
    learner:
      cur_lr: 0.0012274660402908921
      grad_gnorm: 14.405564308166504
      policy_entropy: 117.51685333251953
      policy_loss: -0.8733208179473877
      var_gnorm: 45.289154052734375
      vf_explained_var: 0.931318998336792
      vf_loss: 0.012347347103059292
    num_steps_sampled: 2000000
    num_steps_trained: 2000000
    wait_time_ms: 227.252
  iterations_since_restore: 200
  node_ip: 172.17.8.6
  num_metric_batches_dropped: 0
  pid: 13557
  policy_reward_mean: {}
  time_since_restore: 4935.326349020004
  time_this_iter_s: 25.629259824752808
  time_total_s: 4935.326349020004
  timestamp: 1594099711
  timesteps_since_restore: 2000000
  timesteps_this_iter: 10000
  timesteps_total: 2000000
  training_iteration: 200
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 29.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=13557], 4935 s, 200 iter, 2000000 ts, 1.15e+03 rew

agent-1: 109.0
agent-2: 85.0
agent-3: 92.0
agent-4: 91.0
agent-5: 121.0
agent-6: 70.0
agent-7: 93.0
agent-8: 89.0
agent-9: 92.0
agent-10: 109.0
Sum Reward: 951.0
Avg Reward: 95.1
Min Reward: 70.0
Max Reward: 121.0
Gini Coefficient: 0.07707676130389064
20:20 Ratio: 1.4838709677419355
Max-min Ratio: 1.7285714285714286
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_01-28-54
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1556.0
  episode_reward_mean: 1146.35
  episode_reward_min: 724.0
  episodes_this_iter: 1
  episodes_total: 200
  experiment_id: a3942a9886f24694ab1b58ca8d1ab856
  hostname: gpu006
  info:
    apply_time_ms: 2.756
    dispatch_time_ms: 5.752
    learner:
      cur_lr: 0.0012268000282347202
      grad_gnorm: 22.9965877532959
      policy_entropy: 96.10053253173828
      policy_loss: -7.182394981384277
      var_gnorm: 45.35939407348633
      vf_explained_var: 0.7035171985626221
      vf_loss: 1.390762209892273
    num_steps_sampled: 2010000
    num_steps_trained: 2010000
    wait_time_ms: 259.362
  iterations_since_restore: 201
  node_ip: 172.17.8.6
  num_metric_batches_dropped: 0
  pid: 13557
  policy_reward_mean: {}
  time_since_restore: 4958.9127378463745
  time_this_iter_s: 23.58638882637024
  time_total_s: 4958.9127378463745
  timestamp: 1594099734
  timesteps_since_restore: 2010000
  timesteps_this_iter: 10000
  timesteps_total: 2010000
  training_iteration: 201
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 29.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=13557], 4958 s, 201 iter, 2010000 ts, 1.15e+03 rew

agent-1: 137.0
agent-2: 94.0
agent-3: 129.0
agent-4: 91.0
agent-5: 116.0
agent-6: 101.0
agent-7: 102.0
agent-8: 115.0
agent-9: 103.0
agent-10: 124.0
Sum Reward: 1112.0
Avg Reward: 111.2
Min Reward: 91.0
Max Reward: 137.0
Gini Coefficient: 0.07446043165467627
20:20 Ratio: 1.4378378378378378
Max-min Ratio: 1.5054945054945055
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_01-29-20
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1556.0
  episode_reward_mean: 1144.25
  episode_reward_min: 724.0
  episodes_this_iter: 1
  episodes_total: 201
  experiment_id: a3942a9886f24694ab1b58ca8d1ab856
  hostname: gpu006
  info:
    apply_time_ms: 2.704
    dispatch_time_ms: 8.06
    learner:
      cur_lr: 0.0012261340161785483
      grad_gnorm: 39.99997329711914
      policy_entropy: 14.618377685546875
      policy_loss: 19.60588836669922
      var_gnorm: 45.37984848022461
      vf_explained_var: 0.6574158668518066
      vf_loss: 111.07891845703125
    num_steps_sampled: 2020000
    num_steps_trained: 2020000
    wait_time_ms: 222.525
  iterations_since_restore: 202
  node_ip: 172.17.8.6
  num_metric_batches_dropped: 0
  pid: 13557
  policy_reward_mean: {}
  time_since_restore: 4984.368954658508
  time_this_iter_s: 25.45621681213379
  time_total_s: 4984.368954658508
  timestamp: 1594099760
  timesteps_since_restore: 2020000
  timesteps_this_iter: 10000
  timesteps_total: 2020000
  training_iteration: 202
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 29.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=13557], 4984 s, 202 iter, 2020000 ts, 1.14e+03 rew

agent-1: 100.0
agent-2: 127.0
agent-3: 89.0
agent-4: 107.0
agent-5: 126.0
agent-6: 122.0
agent-7: 95.0
agent-8: 136.0
agent-9: 121.0
agent-10: 106.0
Sum Reward: 1129.0
Avg Reward: 112.9
Min Reward: 89.0
Max Reward: 136.0
Gini Coefficient: 0.07431355181576617
20:20 Ratio: 1.4293478260869565
Max-min Ratio: 1.5280898876404494
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_01-29-44
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1556.0
  episode_reward_mean: 1143.28
  episode_reward_min: 724.0
  episodes_this_iter: 1
  episodes_total: 202
  experiment_id: a3942a9886f24694ab1b58ca8d1ab856
  hostname: gpu006
  info:
    apply_time_ms: 3.431
    dispatch_time_ms: 7.851
    learner:
      cur_lr: 0.0012254680041223764
      grad_gnorm: 3.4143941402435303
      policy_entropy: 95.55941009521484
      policy_loss: -0.8578289747238159
      var_gnorm: 45.42449188232422
      vf_explained_var: -0.12206923961639404
      vf_loss: 0.004984623286873102
    num_steps_sampled: 2030000
    num_steps_trained: 2030000
    wait_time_ms: 249.786
  iterations_since_restore: 203
  node_ip: 172.17.8.6
  num_metric_batches_dropped: 0
  pid: 13557
  policy_reward_mean: {}
  time_since_restore: 5008.390604019165
  time_this_iter_s: 24.02164936065674
  time_total_s: 5008.390604019165
  timestamp: 1594099784
  timesteps_since_restore: 2030000
  timesteps_this_iter: 10000
  timesteps_total: 2030000
  training_iteration: 203
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 29.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=13557], 5008 s, 203 iter, 2030000 ts, 1.14e+03 rew

agent-1: 92.0
agent-2: 97.0
agent-3: 108.0
agent-4: 111.0
agent-5: 87.0
agent-6: 113.0
agent-7: 91.0
agent-8: 94.0
agent-9: 106.0
agent-10: 84.0
Sum Reward: 983.0
Avg Reward: 98.3
Min Reward: 84.0
Max Reward: 113.0
Gini Coefficient: 0.05686673448626653
20:20 Ratio: 1.3099415204678362
Max-min Ratio: 1.3452380952380953
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_01-30-10
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1556.0
  episode_reward_mean: 1143.35
  episode_reward_min: 724.0
  episodes_this_iter: 1
  episodes_total: 203
  experiment_id: a3942a9886f24694ab1b58ca8d1ab856
  hostname: gpu006
  info:
    apply_time_ms: 3.069
    dispatch_time_ms: 8.375
    learner:
      cur_lr: 0.0012248019920662045
      grad_gnorm: 6.606658935546875
      policy_entropy: 90.26146697998047
      policy_loss: -0.9787721037864685
      var_gnorm: 45.47947311401367
      vf_explained_var: 0.9713222980499268
      vf_loss: 0.01633499749004841
    num_steps_sampled: 2040000
    num_steps_trained: 2040000
    wait_time_ms: 239.62
  iterations_since_restore: 204
  node_ip: 172.17.8.6
  num_metric_batches_dropped: 0
  pid: 13557
  policy_reward_mean: {}
  time_since_restore: 5034.194319963455
  time_this_iter_s: 25.80371594429016
  time_total_s: 5034.194319963455
  timestamp: 1594099810
  timesteps_since_restore: 2040000
  timesteps_this_iter: 10000
  timesteps_total: 2040000
  training_iteration: 204
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 29.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=13557], 5034 s, 204 iter, 2040000 ts, 1.14e+03 rew

agent-1: 112.0
agent-2: 84.0
agent-3: 103.0
agent-4: 88.0
agent-5: 79.0
agent-6: 106.0
agent-7: 70.0
agent-8: 85.0
agent-9: 87.0
agent-10: 88.0
Sum Reward: 902.0
Avg Reward: 90.2
Min Reward: 70.0
Max Reward: 112.0
Gini Coefficient: 0.07450110864745012
20:20 Ratio: 1.4630872483221478
Max-min Ratio: 1.6
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_01-30-33
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1556.0
  episode_reward_mean: 1140.79
  episode_reward_min: 724.0
  episodes_this_iter: 1
  episodes_total: 204
  experiment_id: a3942a9886f24694ab1b58ca8d1ab856
  hostname: gpu006
  info:
    apply_time_ms: 2.854
    dispatch_time_ms: 6.439
    learner:
      cur_lr: 0.0012241359800100327
      grad_gnorm: 40.00000762939453
      policy_entropy: 99.31169128417969
      policy_loss: -3.705548048019409
      var_gnorm: 45.51223373413086
      vf_explained_var: 0.9863744378089905
      vf_loss: 0.07543154805898666
    num_steps_sampled: 2050000
    num_steps_trained: 2050000
    wait_time_ms: 245.997
  iterations_since_restore: 205
  node_ip: 172.17.8.6
  num_metric_batches_dropped: 0
  pid: 13557
  policy_reward_mean: {}
  time_since_restore: 5057.954655885696
  time_this_iter_s: 23.76033592224121
  time_total_s: 5057.954655885696
  timestamp: 1594099833
  timesteps_since_restore: 2050000
  timesteps_this_iter: 10000
  timesteps_total: 2050000
  training_iteration: 205
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 29.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=13557], 5057 s, 205 iter, 2050000 ts, 1.14e+03 rew

agent-1: 125.0
agent-2: 88.0
agent-3: 109.0
agent-4: 93.0
agent-5: 82.0
agent-6: 96.0
agent-7: 108.0
agent-8: 86.0
agent-9: 98.0
agent-10: 94.0
Sum Reward: 979.0
Avg Reward: 97.9
Min Reward: 82.0
Max Reward: 125.0
Gini Coefficient: 0.067926455566905
20:20 Ratio: 1.3928571428571428
Max-min Ratio: 1.524390243902439
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_01-30-59
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1556.0
  episode_reward_mean: 1137.8
  episode_reward_min: 724.0
  episodes_this_iter: 1
  episodes_total: 205
  experiment_id: a3942a9886f24694ab1b58ca8d1ab856
  hostname: gpu006
  info:
    apply_time_ms: 2.598
    dispatch_time_ms: 7.148
    learner:
      cur_lr: 0.0012234699679538608
      grad_gnorm: 40.0
      policy_entropy: 12.003617286682129
      policy_loss: -9.14559555053711
      var_gnorm: 45.56404113769531
      vf_explained_var: 0.9151021838188171
      vf_loss: 261.86846923828125
    num_steps_sampled: 2060000
    num_steps_trained: 2060000
    wait_time_ms: 230.63
  iterations_since_restore: 206
  node_ip: 172.17.8.6
  num_metric_batches_dropped: 0
  pid: 13557
  policy_reward_mean: {}
  time_since_restore: 5083.740817785263
  time_this_iter_s: 25.78616189956665
  time_total_s: 5083.740817785263
  timestamp: 1594099859
  timesteps_since_restore: 2060000
  timesteps_this_iter: 10000
  timesteps_total: 2060000
  training_iteration: 206
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 29.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=13557], 5083 s, 206 iter, 2060000 ts, 1.14e+03 rew

agent-1: 91.0
agent-2: 128.0
agent-3: 88.0
agent-4: 110.0
agent-5: 71.0
agent-6: 88.0
agent-7: 107.0
agent-8: 99.0
agent-9: 71.0
agent-10: 78.0
Sum Reward: 931.0
Avg Reward: 93.1
Min Reward: 71.0
Max Reward: 128.0
Gini Coefficient: 0.10386680988184747
20:20 Ratio: 1.676056338028169
Max-min Ratio: 1.8028169014084507
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_01-31-23
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1556.0
  episode_reward_mean: 1137.11
  episode_reward_min: 724.0
  episodes_this_iter: 1
  episodes_total: 206
  experiment_id: a3942a9886f24694ab1b58ca8d1ab856
  hostname: gpu006
  info:
    apply_time_ms: 2.67
    dispatch_time_ms: 6.776
    learner:
      cur_lr: 0.0012228039558976889
      grad_gnorm: 39.99998474121094
      policy_entropy: 49.967620849609375
      policy_loss: 8.37610149383545
      var_gnorm: 45.66794204711914
      vf_explained_var: 0.5825856924057007
      vf_loss: 105.56600952148438
    num_steps_sampled: 2070000
    num_steps_trained: 2070000
    wait_time_ms: 254.349
  iterations_since_restore: 207
  node_ip: 172.17.8.6
  num_metric_batches_dropped: 0
  pid: 13557
  policy_reward_mean: {}
  time_since_restore: 5107.401385784149
  time_this_iter_s: 23.66056799888611
  time_total_s: 5107.401385784149
  timestamp: 1594099883
  timesteps_since_restore: 2070000
  timesteps_this_iter: 10000
  timesteps_total: 2070000
  training_iteration: 207
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 29.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=13557], 5107 s, 207 iter, 2070000 ts, 1.14e+03 rew

agent-1: 83.0
agent-2: 76.0
agent-3: 80.0
agent-4: 88.0
agent-5: 89.0
agent-6: 85.0
agent-7: 106.0
agent-8: 122.0
agent-9: 103.0
agent-10: 110.0
Sum Reward: 942.0
Avg Reward: 94.2
Min Reward: 76.0
Max Reward: 122.0
Gini Coefficient: 0.08428874734607218
20:20 Ratio: 1.4871794871794872
Max-min Ratio: 1.605263157894737
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_01-31-48
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1556.0
  episode_reward_mean: 1136.9
  episode_reward_min: 724.0
  episodes_this_iter: 1
  episodes_total: 207
  experiment_id: a3942a9886f24694ab1b58ca8d1ab856
  hostname: gpu006
  info:
    apply_time_ms: 3.375
    dispatch_time_ms: 6.179
    learner:
      cur_lr: 0.001222137943841517
      grad_gnorm: 39.99999237060547
      policy_entropy: 25.301584243774414
      policy_loss: 18.48497772216797
      var_gnorm: 45.69565200805664
      vf_explained_var: 0.3002915382385254
      vf_loss: 233.22071838378906
    num_steps_sampled: 2080000
    num_steps_trained: 2080000
    wait_time_ms: 226.211
  iterations_since_restore: 208
  node_ip: 172.17.8.6
  num_metric_batches_dropped: 0
  pid: 13557
  policy_reward_mean: {}
  time_since_restore: 5132.860842704773
  time_this_iter_s: 25.45945692062378
  time_total_s: 5132.860842704773
  timestamp: 1594099908
  timesteps_since_restore: 2080000
  timesteps_this_iter: 10000
  timesteps_total: 2080000
  training_iteration: 208
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 29.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=13557], 5132 s, 208 iter, 2080000 ts, 1.14e+03 rew

agent-1: 147.0
agent-2: 106.0
agent-3: 105.0
agent-4: 98.0
agent-5: 90.0
agent-6: 89.0
agent-7: 85.0
agent-8: 122.0
agent-9: 79.0
agent-10: 113.0
Sum Reward: 1034.0
Avg Reward: 103.4
Min Reward: 79.0
Max Reward: 147.0
Gini Coefficient: 0.1011605415860735
20:20 Ratio: 1.6402439024390243
Max-min Ratio: 1.860759493670886
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_01-32-12
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1556.0
  episode_reward_mean: 1134.87
  episode_reward_min: 724.0
  episodes_this_iter: 1
  episodes_total: 208
  experiment_id: a3942a9886f24694ab1b58ca8d1ab856
  hostname: gpu006
  info:
    apply_time_ms: 2.666
    dispatch_time_ms: 6.534
    learner:
      cur_lr: 0.001221472048200667
      grad_gnorm: 40.0
      policy_entropy: 37.33769226074219
      policy_loss: -0.6777184009552002
      var_gnorm: 45.806846618652344
      vf_explained_var: 0.6134402751922607
      vf_loss: 133.19288635253906
    num_steps_sampled: 2090000
    num_steps_trained: 2090000
    wait_time_ms: 254.741
  iterations_since_restore: 209
  node_ip: 172.17.8.6
  num_metric_batches_dropped: 0
  pid: 13557
  policy_reward_mean: {}
  time_since_restore: 5156.129725933075
  time_this_iter_s: 23.268883228302002
  time_total_s: 5156.129725933075
  timestamp: 1594099932
  timesteps_since_restore: 2090000
  timesteps_this_iter: 10000
  timesteps_total: 2090000
  training_iteration: 209
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 29.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=13557], 5156 s, 209 iter, 2090000 ts, 1.13e+03 rew

agent-1: 139.0
agent-2: 127.0
agent-3: 166.0
agent-4: 120.0
agent-5: 141.0
agent-6: 142.0
agent-7: 156.0
agent-8: 127.0
agent-9: 153.0
agent-10: 138.0
Sum Reward: 1409.0
Avg Reward: 140.9
Min Reward: 120.0
Max Reward: 166.0
Gini Coefficient: 0.054009936124911284
20:20 Ratio: 1.3036437246963564
Max-min Ratio: 1.3833333333333333
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_01-32-37
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1556.0
  episode_reward_mean: 1138.23
  episode_reward_min: 724.0
  episodes_this_iter: 1
  episodes_total: 209
  experiment_id: a3942a9886f24694ab1b58ca8d1ab856
  hostname: gpu006
  info:
    apply_time_ms: 2.953
    dispatch_time_ms: 5.957
    learner:
      cur_lr: 0.001220806036144495
      grad_gnorm: 40.0
      policy_entropy: 24.13433074951172
      policy_loss: -30.127290725708008
      var_gnorm: 45.884422302246094
      vf_explained_var: 0.8291307687759399
      vf_loss: 156.09461975097656
    num_steps_sampled: 2100000
    num_steps_trained: 2100000
    wait_time_ms: 205.379
  iterations_since_restore: 210
  node_ip: 172.17.8.6
  num_metric_batches_dropped: 0
  pid: 13557
  policy_reward_mean: {}
  time_since_restore: 5181.610348939896
  time_this_iter_s: 25.48062300682068
  time_total_s: 5181.610348939896
  timestamp: 1594099957
  timesteps_since_restore: 2100000
  timesteps_this_iter: 10000
  timesteps_total: 2100000
  training_iteration: 210
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 29.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=13557], 5181 s, 210 iter, 2100000 ts, 1.14e+03 rew

agent-1: 99.0
agent-2: 90.0
agent-3: 96.0
agent-4: 86.0
agent-5: 83.0
agent-6: 70.0
agent-7: 92.0
agent-8: 111.0
agent-9: 94.0
agent-10: 90.0
Sum Reward: 911.0
Avg Reward: 91.1
Min Reward: 70.0
Max Reward: 111.0
Gini Coefficient: 0.05982436882546652
20:20 Ratio: 1.3725490196078431
Max-min Ratio: 1.5857142857142856
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_01-33-01
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1556.0
  episode_reward_mean: 1135.46
  episode_reward_min: 724.0
  episodes_this_iter: 1
  episodes_total: 210
  experiment_id: a3942a9886f24694ab1b58ca8d1ab856
  hostname: gpu006
  info:
    apply_time_ms: 2.778
    dispatch_time_ms: 6.303
    learner:
      cur_lr: 0.0012201400240883231
      grad_gnorm: 29.255491256713867
      policy_entropy: 107.14749908447266
      policy_loss: -10.20148754119873
      var_gnorm: 45.93770217895508
      vf_explained_var: -1.0
      vf_loss: 2.85205078125
    num_steps_sampled: 2110000
    num_steps_trained: 2110000
    wait_time_ms: 241.127
  iterations_since_restore: 211
  node_ip: 172.17.8.6
  num_metric_batches_dropped: 0
  pid: 13557
  policy_reward_mean: {}
  time_since_restore: 5205.389898300171
  time_this_iter_s: 23.77954936027527
  time_total_s: 5205.389898300171
  timestamp: 1594099981
  timesteps_since_restore: 2110000
  timesteps_this_iter: 10000
  timesteps_total: 2110000
  training_iteration: 211
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 29.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=13557], 5205 s, 211 iter, 2110000 ts, 1.14e+03 rew

agent-1: 129.0
agent-2: 108.0
agent-3: 96.0
agent-4: 122.0
agent-5: 112.0
agent-6: 107.0
agent-7: 99.0
agent-8: 106.0
agent-9: 107.0
agent-10: 98.0
Sum Reward: 1084.0
Avg Reward: 108.4
Min Reward: 96.0
Max Reward: 129.0
Gini Coefficient: 0.04944649446494465
20:20 Ratio: 1.2938144329896908
Max-min Ratio: 1.34375
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_01-33-29
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1556.0
  episode_reward_mean: 1135.44
  episode_reward_min: 724.0
  episodes_this_iter: 1
  episodes_total: 211
  experiment_id: a3942a9886f24694ab1b58ca8d1ab856
  hostname: gpu006
  info:
    apply_time_ms: 2.605
    dispatch_time_ms: 17.425
    learner:
      cur_lr: 0.0012194740120321512
      grad_gnorm: 40.0
      policy_entropy: 35.7626838684082
      policy_loss: 2.891653060913086
      var_gnorm: 46.023902893066406
      vf_explained_var: 0.35362863540649414
      vf_loss: 88.70006561279297
    num_steps_sampled: 2120000
    num_steps_trained: 2120000
    wait_time_ms: 229.896
  iterations_since_restore: 212
  node_ip: 172.17.8.6
  num_metric_batches_dropped: 0
  pid: 13557
  policy_reward_mean: {}
  time_since_restore: 5232.969051361084
  time_this_iter_s: 27.579153060913086
  time_total_s: 5232.969051361084
  timestamp: 1594100009
  timesteps_since_restore: 2120000
  timesteps_this_iter: 10000
  timesteps_total: 2120000
  training_iteration: 212
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 29.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=13557], 5232 s, 212 iter, 2120000 ts, 1.14e+03 rew

agent-1: 109.0
agent-2: 113.0
agent-3: 128.0
agent-4: 118.0
agent-5: 108.0
agent-6: 135.0
agent-7: 113.0
agent-8: 92.0
agent-9: 122.0
agent-10: 105.0
Sum Reward: 1143.0
Avg Reward: 114.3
Min Reward: 92.0
Max Reward: 135.0
Gini Coefficient: 0.05643044619422572
20:20 Ratio: 1.3350253807106598
Max-min Ratio: 1.4673913043478262
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_01-33-52
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1556.0
  episode_reward_mean: 1135.76
  episode_reward_min: 724.0
  episodes_this_iter: 1
  episodes_total: 212
  experiment_id: a3942a9886f24694ab1b58ca8d1ab856
  hostname: gpu006
  info:
    apply_time_ms: 2.557
    dispatch_time_ms: 15.519
    learner:
      cur_lr: 0.0012188079999759793
      grad_gnorm: 40.0
      policy_entropy: 53.0892219543457
      policy_loss: 24.214445114135742
      var_gnorm: 46.10663986206055
      vf_explained_var: 0.4378083348274231
      vf_loss: 208.92250061035156
    num_steps_sampled: 2130000
    num_steps_trained: 2130000
    wait_time_ms: 247.369
  iterations_since_restore: 213
  node_ip: 172.17.8.6
  num_metric_batches_dropped: 0
  pid: 13557
  policy_reward_mean: {}
  time_since_restore: 5256.43660569191
  time_this_iter_s: 23.467554330825806
  time_total_s: 5256.43660569191
  timestamp: 1594100032
  timesteps_since_restore: 2130000
  timesteps_this_iter: 10000
  timesteps_total: 2130000
  training_iteration: 213
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 29.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=13557], 5256 s, 213 iter, 2130000 ts, 1.14e+03 rew

agent-1: 122.0
agent-2: 103.0
agent-3: 133.0
agent-4: 115.0
agent-5: 129.0
agent-6: 126.0
agent-7: 112.0
agent-8: 110.0
agent-9: 90.0
agent-10: 136.0
Sum Reward: 1176.0
Avg Reward: 117.6
Min Reward: 90.0
Max Reward: 136.0
Gini Coefficient: 0.0653061224489796
20:20 Ratio: 1.3937823834196892
Max-min Ratio: 1.511111111111111
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_01-34-18
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1556.0
  episode_reward_mean: 1136.68
  episode_reward_min: 724.0
  episodes_this_iter: 1
  episodes_total: 213
  experiment_id: a3942a9886f24694ab1b58ca8d1ab856
  hostname: gpu006
  info:
    apply_time_ms: 3.39
    dispatch_time_ms: 23.495
    learner:
      cur_lr: 0.0012181419879198074
      grad_gnorm: 40.0
      policy_entropy: 15.88953685760498
      policy_loss: 7.482814788818359
      var_gnorm: 46.17070770263672
      vf_explained_var: 0.6316350698471069
      vf_loss: 69.61734008789062
    num_steps_sampled: 2140000
    num_steps_trained: 2140000
    wait_time_ms: 219.201
  iterations_since_restore: 214
  node_ip: 172.17.8.6
  num_metric_batches_dropped: 0
  pid: 13557
  policy_reward_mean: {}
  time_since_restore: 5282.6380043029785
  time_this_iter_s: 26.201398611068726
  time_total_s: 5282.6380043029785
  timestamp: 1594100058
  timesteps_since_restore: 2140000
  timesteps_this_iter: 10000
  timesteps_total: 2140000
  training_iteration: 214
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 29.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=13557], 5282 s, 214 iter, 2140000 ts, 1.14e+03 rew

agent-1: 138.0
agent-2: 110.0
agent-3: 125.0
agent-4: 111.0
agent-5: 116.0
agent-6: 111.0
agent-7: 131.0
agent-8: 102.0
agent-9: 103.0
agent-10: 101.0
Sum Reward: 1148.0
Avg Reward: 114.8
Min Reward: 101.0
Max Reward: 138.0
Gini Coefficient: 0.0578397212543554
20:20 Ratio: 1.3251231527093597
Max-min Ratio: 1.3663366336633664
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_01-34-43
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1556.0
  episode_reward_mean: 1138.39
  episode_reward_min: 724.0
  episodes_this_iter: 1
  episodes_total: 214
  experiment_id: a3942a9886f24694ab1b58ca8d1ab856
  hostname: gpu006
  info:
    apply_time_ms: 3.222
    dispatch_time_ms: 20.874
    learner:
      cur_lr: 0.0012174759758636355
      grad_gnorm: 39.99999237060547
      policy_entropy: 59.81722640991211
      policy_loss: 10.396512985229492
      var_gnorm: 46.232208251953125
      vf_explained_var: 0.7388100028038025
      vf_loss: 51.56110382080078
    num_steps_sampled: 2150000
    num_steps_trained: 2150000
    wait_time_ms: 251.881
  iterations_since_restore: 215
  node_ip: 172.17.8.6
  num_metric_batches_dropped: 0
  pid: 13557
  policy_reward_mean: {}
  time_since_restore: 5306.731678724289
  time_this_iter_s: 24.093674421310425
  time_total_s: 5306.731678724289
  timestamp: 1594100083
  timesteps_since_restore: 2150000
  timesteps_this_iter: 10000
  timesteps_total: 2150000
  training_iteration: 215
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 29.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=13557], 5306 s, 215 iter, 2150000 ts, 1.14e+03 rew

agent-1: 109.0
agent-2: 118.0
agent-3: 138.0
agent-4: 109.0
agent-5: 134.0
agent-6: 94.0
agent-7: 119.0
agent-8: 99.0
agent-9: 127.0
agent-10: 133.0
Sum Reward: 1180.0
Avg Reward: 118.0
Min Reward: 94.0
Max Reward: 138.0
Gini Coefficient: 0.06915254237288136
20:20 Ratio: 1.4093264248704662
Max-min Ratio: 1.4680851063829787
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_01-35-08
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1556.0
  episode_reward_mean: 1135.91
  episode_reward_min: 724.0
  episodes_this_iter: 1
  episodes_total: 215
  experiment_id: a3942a9886f24694ab1b58ca8d1ab856
  hostname: gpu006
  info:
    apply_time_ms: 2.736
    dispatch_time_ms: 6.3
    learner:
      cur_lr: 0.0012168099638074636
      grad_gnorm: 40.0
      policy_entropy: 40.18587112426758
      policy_loss: -23.17438507080078
      var_gnorm: 46.368751525878906
      vf_explained_var: 0.503498911857605
      vf_loss: 202.0404510498047
    num_steps_sampled: 2160000
    num_steps_trained: 2160000
    wait_time_ms: 214.142
  iterations_since_restore: 216
  node_ip: 172.17.8.6
  num_metric_batches_dropped: 0
  pid: 13557
  policy_reward_mean: {}
  time_since_restore: 5332.622057437897
  time_this_iter_s: 25.890378713607788
  time_total_s: 5332.622057437897
  timestamp: 1594100108
  timesteps_since_restore: 2160000
  timesteps_this_iter: 10000
  timesteps_total: 2160000
  training_iteration: 216
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 29.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=13557], 5332 s, 216 iter, 2160000 ts, 1.14e+03 rew

agent-1: 100.0
agent-2: 138.0
agent-3: 124.0
agent-4: 109.0
agent-5: 121.0
agent-6: 117.0
agent-7: 120.0
agent-8: 121.0
agent-9: 157.0
agent-10: 134.0
Sum Reward: 1241.0
Avg Reward: 124.1
Min Reward: 100.0
Max Reward: 157.0
Gini Coefficient: 0.06551168412570507
20:20 Ratio: 1.4114832535885167
Max-min Ratio: 1.57
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_01-35-32
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1556.0
  episode_reward_mean: 1135.23
  episode_reward_min: 724.0
  episodes_this_iter: 1
  episodes_total: 216
  experiment_id: a3942a9886f24694ab1b58ca8d1ab856
  hostname: gpu006
  info:
    apply_time_ms: 2.789
    dispatch_time_ms: 6.264
    learner:
      cur_lr: 0.0012161439517512918
      grad_gnorm: 40.00000762939453
      policy_entropy: 43.434776306152344
      policy_loss: -9.46837329864502
      var_gnorm: 46.411827087402344
      vf_explained_var: 0.6322126388549805
      vf_loss: 184.107421875
    num_steps_sampled: 2170000
    num_steps_trained: 2170000
    wait_time_ms: 255.887
  iterations_since_restore: 217
  node_ip: 172.17.8.6
  num_metric_batches_dropped: 0
  pid: 13557
  policy_reward_mean: {}
  time_since_restore: 5355.602142095566
  time_this_iter_s: 22.980084657669067
  time_total_s: 5355.602142095566
  timestamp: 1594100132
  timesteps_since_restore: 2170000
  timesteps_this_iter: 10000
  timesteps_total: 2170000
  training_iteration: 217
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 29.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=13557], 5355 s, 217 iter, 2170000 ts, 1.14e+03 rew

agent-1: 104.0
agent-2: 130.0
agent-3: 136.0
agent-4: 131.0
agent-5: 126.0
agent-6: 123.0
agent-7: 130.0
agent-8: 108.0
agent-9: 97.0
agent-10: 113.0
Sum Reward: 1198.0
Avg Reward: 119.8
Min Reward: 97.0
Max Reward: 136.0
Gini Coefficient: 0.05876460767946578
20:20 Ratio: 1.328358208955224
Max-min Ratio: 1.402061855670103
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_01-35-57
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1556.0
  episode_reward_mean: 1134.37
  episode_reward_min: 724.0
  episodes_this_iter: 1
  episodes_total: 217
  experiment_id: a3942a9886f24694ab1b58ca8d1ab856
  hostname: gpu006
  info:
    apply_time_ms: 2.804
    dispatch_time_ms: 6.469
    learner:
      cur_lr: 0.0012154780561104417
      grad_gnorm: 40.0
      policy_entropy: 9.873167037963867
      policy_loss: 16.27874183654785
      var_gnorm: 46.47893142700195
      vf_explained_var: 0.8919932842254639
      vf_loss: 196.84457397460938
    num_steps_sampled: 2180000
    num_steps_trained: 2180000
    wait_time_ms: 229.143
  iterations_since_restore: 218
  node_ip: 172.17.8.6
  num_metric_batches_dropped: 0
  pid: 13557
  policy_reward_mean: {}
  time_since_restore: 5381.232313871384
  time_this_iter_s: 25.63017177581787
  time_total_s: 5381.232313871384
  timestamp: 1594100157
  timesteps_since_restore: 2180000
  timesteps_this_iter: 10000
  timesteps_total: 2180000
  training_iteration: 218
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 29.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=13557], 5381 s, 218 iter, 2180000 ts, 1.13e+03 rew

agent-1: 99.0
agent-2: 119.0
agent-3: 110.0
agent-4: 121.0
agent-5: 96.0
agent-6: 134.0
agent-7: 123.0
agent-8: 100.0
agent-9: 97.0
agent-10: 87.0
Sum Reward: 1086.0
Avg Reward: 108.6
Min Reward: 87.0
Max Reward: 134.0
Gini Coefficient: 0.07384898710865562
20:20 Ratio: 1.4043715846994536
Max-min Ratio: 1.5402298850574712
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_01-36-21
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1556.0
  episode_reward_mean: 1134.98
  episode_reward_min: 724.0
  episodes_this_iter: 1
  episodes_total: 218
  experiment_id: a3942a9886f24694ab1b58ca8d1ab856
  hostname: gpu006
  info:
    apply_time_ms: 2.812
    dispatch_time_ms: 23.715
    learner:
      cur_lr: 0.0012148120440542698
      grad_gnorm: 39.9999885559082
      policy_entropy: 33.03288269042969
      policy_loss: -6.98770809173584
      var_gnorm: 46.56167984008789
      vf_explained_var: 0.8887165784835815
      vf_loss: 47.73078918457031
    num_steps_sampled: 2190000
    num_steps_trained: 2190000
    wait_time_ms: 232.282
  iterations_since_restore: 219
  node_ip: 172.17.8.6
  num_metric_batches_dropped: 0
  pid: 13557
  policy_reward_mean: {}
  time_since_restore: 5405.154942512512
  time_this_iter_s: 23.92262864112854
  time_total_s: 5405.154942512512
  timestamp: 1594100181
  timesteps_since_restore: 2190000
  timesteps_this_iter: 10000
  timesteps_total: 2190000
  training_iteration: 219
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 29.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=13557], 5405 s, 219 iter, 2190000 ts, 1.13e+03 rew

agent-1: 113.0
agent-2: 122.0
agent-3: 105.0
agent-4: 100.0
agent-5: 95.0
agent-6: 112.0
agent-7: 92.0
agent-8: 96.0
agent-9: 111.0
agent-10: 100.0
Sum Reward: 1046.0
Avg Reward: 104.6
Min Reward: 92.0
Max Reward: 122.0
Gini Coefficient: 0.0491395793499044
20:20 Ratio: 1.2566844919786095
Max-min Ratio: 1.326086956521739
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_01-36-48
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1556.0
  episode_reward_mean: 1134.99
  episode_reward_min: 724.0
  episodes_this_iter: 1
  episodes_total: 219
  experiment_id: a3942a9886f24694ab1b58ca8d1ab856
  hostname: gpu006
  info:
    apply_time_ms: 3.259
    dispatch_time_ms: 19.766
    learner:
      cur_lr: 0.001214146031998098
      grad_gnorm: 3.8347437381744385
      policy_entropy: 113.70768737792969
      policy_loss: -0.5675208568572998
      var_gnorm: 46.592559814453125
      vf_explained_var: 0.8713457584381104
      vf_loss: 0.022288981825113297
    num_steps_sampled: 2200000
    num_steps_trained: 2200000
    wait_time_ms: 221.501
  iterations_since_restore: 220
  node_ip: 172.17.8.6
  num_metric_batches_dropped: 0
  pid: 13557
  policy_reward_mean: {}
  time_since_restore: 5431.921742200851
  time_this_iter_s: 26.766799688339233
  time_total_s: 5431.921742200851
  timestamp: 1594100208
  timesteps_since_restore: 2200000
  timesteps_this_iter: 10000
  timesteps_total: 2200000
  training_iteration: 220
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 29.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=13557], 5431 s, 220 iter, 2200000 ts, 1.13e+03 rew

agent-1: 108.0
agent-2: 96.0
agent-3: 105.0
agent-4: 85.0
agent-5: 92.0
agent-6: 89.0
agent-7: 112.0
agent-8: 117.0
agent-9: 120.0
agent-10: 86.0
Sum Reward: 1010.0
Avg Reward: 101.0
Min Reward: 85.0
Max Reward: 120.0
Gini Coefficient: 0.06970297029702971
20:20 Ratio: 1.3859649122807018
Max-min Ratio: 1.411764705882353
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_01-37-13
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1556.0
  episode_reward_mean: 1134.11
  episode_reward_min: 724.0
  episodes_this_iter: 1
  episodes_total: 220
  experiment_id: a3942a9886f24694ab1b58ca8d1ab856
  hostname: gpu006
  info:
    apply_time_ms: 2.852
    dispatch_time_ms: 25.162
    learner:
      cur_lr: 0.001213480019941926
      grad_gnorm: 17.465471267700195
      policy_entropy: 100.34029388427734
      policy_loss: -1.7286502122879028
      var_gnorm: 46.65410614013672
      vf_explained_var: 0.0490913987159729
      vf_loss: 5.704192161560059
    num_steps_sampled: 2210000
    num_steps_trained: 2210000
    wait_time_ms: 236.283
  iterations_since_restore: 221
  node_ip: 172.17.8.6
  num_metric_batches_dropped: 0
  pid: 13557
  policy_reward_mean: {}
  time_since_restore: 5456.849445819855
  time_this_iter_s: 24.927703619003296
  time_total_s: 5456.849445819855
  timestamp: 1594100233
  timesteps_since_restore: 2210000
  timesteps_this_iter: 10000
  timesteps_total: 2210000
  training_iteration: 221
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 29.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=13557], 5456 s, 221 iter, 2210000 ts, 1.13e+03 rew

agent-1: 94.0
agent-2: 111.0
agent-3: 98.0
agent-4: 88.0
agent-5: 104.0
agent-6: 115.0
agent-7: 113.0
agent-8: 109.0
agent-9: 101.0
agent-10: 72.0
Sum Reward: 1005.0
Avg Reward: 100.5
Min Reward: 72.0
Max Reward: 115.0
Gini Coefficient: 0.06796019900497513
20:20 Ratio: 1.425
Max-min Ratio: 1.5972222222222223
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_01-37-43
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1556.0
  episode_reward_mean: 1133.74
  episode_reward_min: 724.0
  episodes_this_iter: 1
  episodes_total: 221
  experiment_id: a3942a9886f24694ab1b58ca8d1ab856
  hostname: gpu006
  info:
    apply_time_ms: 2.883
    dispatch_time_ms: 21.853
    learner:
      cur_lr: 0.0012128140078857541
      grad_gnorm: 40.000003814697266
      policy_entropy: 100.28643798828125
      policy_loss: 24.387855529785156
      var_gnorm: 46.72868728637695
      vf_explained_var: 0.3146480321884155
      vf_loss: 11.841729164123535
    num_steps_sampled: 2220000
    num_steps_trained: 2220000
    wait_time_ms: 222.79
  iterations_since_restore: 222
  node_ip: 172.17.8.6
  num_metric_batches_dropped: 0
  pid: 13557
  policy_reward_mean: {}
  time_since_restore: 5480.532572507858
  time_this_iter_s: 23.68312668800354
  time_total_s: 5480.532572507858
  timestamp: 1594100263
  timesteps_since_restore: 2220000
  timesteps_this_iter: 10000
  timesteps_total: 2220000
  training_iteration: 222
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 29.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=13557], 5480 s, 222 iter, 2220000 ts, 1.13e+03 rew

agent-1: 115.0
agent-2: 107.0
agent-3: 98.0
agent-4: 111.0
agent-5: 82.0
agent-6: 81.0
agent-7: 116.0
agent-8: 116.0
agent-9: 106.0
agent-10: 97.0
Sum Reward: 1029.0
Avg Reward: 102.9
Min Reward: 81.0
Max Reward: 116.0
Gini Coefficient: 0.06637512147716229
20:20 Ratio: 1.4233128834355828
Max-min Ratio: 1.4320987654320987
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_01-38-07
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1556.0
  episode_reward_mean: 1134.01
  episode_reward_min: 724.0
  episodes_this_iter: 1
  episodes_total: 222
  experiment_id: a3942a9886f24694ab1b58ca8d1ab856
  hostname: gpu006
  info:
    apply_time_ms: 2.91
    dispatch_time_ms: 19.437
    learner:
      cur_lr: 0.0012121479958295822
      grad_gnorm: 40.00001525878906
      policy_entropy: 37.00288391113281
      policy_loss: 12.920308113098145
      var_gnorm: 46.82482147216797
      vf_explained_var: 0.7384519577026367
      vf_loss: 104.09920501708984
    num_steps_sampled: 2230000
    num_steps_trained: 2230000
    wait_time_ms: 211.437
  iterations_since_restore: 223
  node_ip: 172.17.8.6
  num_metric_batches_dropped: 0
  pid: 13557
  policy_reward_mean: {}
  time_since_restore: 5503.674904346466
  time_this_iter_s: 23.142331838607788
  time_total_s: 5503.674904346466
  timestamp: 1594100287
  timesteps_since_restore: 2230000
  timesteps_this_iter: 10000
  timesteps_total: 2230000
  training_iteration: 223
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 29.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=13557], 5503 s, 223 iter, 2230000 ts, 1.13e+03 rew

agent-1: 144.0
agent-2: 133.0
agent-3: 147.0
agent-4: 144.0
agent-5: 136.0
agent-6: 114.0
agent-7: 86.0
agent-8: 164.0
agent-9: 109.0
agent-10: 151.0
Sum Reward: 1328.0
Avg Reward: 132.8
Min Reward: 86.0
Max Reward: 164.0
Gini Coefficient: 0.09051204819277109
20:20 Ratio: 1.6153846153846154
Max-min Ratio: 1.9069767441860466
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_01-38-32
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1556.0
  episode_reward_mean: 1137.03
  episode_reward_min: 724.0
  episodes_this_iter: 1
  episodes_total: 223
  experiment_id: a3942a9886f24694ab1b58ca8d1ab856
  hostname: gpu006
  info:
    apply_time_ms: 2.668
    dispatch_time_ms: 6.861
    learner:
      cur_lr: 0.0012114819837734103
      grad_gnorm: 40.0
      policy_entropy: 32.54061508178711
      policy_loss: 21.07954978942871
      var_gnorm: 46.8688850402832
      vf_explained_var: 0.1762353777885437
      vf_loss: 105.69914245605469
    num_steps_sampled: 2240000
    num_steps_trained: 2240000
    wait_time_ms: 218.176
  iterations_since_restore: 224
  node_ip: 172.17.8.6
  num_metric_batches_dropped: 0
  pid: 13557
  policy_reward_mean: {}
  time_since_restore: 5528.793901205063
  time_this_iter_s: 25.1189968585968
  time_total_s: 5528.793901205063
  timestamp: 1594100312
  timesteps_since_restore: 2240000
  timesteps_this_iter: 10000
  timesteps_total: 2240000
  training_iteration: 224
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 29.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=13557], 5528 s, 224 iter, 2240000 ts, 1.14e+03 rew

agent-1: 145.0
agent-2: 151.0
agent-3: 127.0
agent-4: 156.0
agent-5: 137.0
agent-6: 185.0
agent-7: 136.0
agent-8: 146.0
agent-9: 135.0
agent-10: 165.0
Sum Reward: 1483.0
Avg Reward: 148.3
Min Reward: 127.0
Max Reward: 185.0
Gini Coefficient: 0.059002022926500336
20:20 Ratio: 1.3358778625954197
Max-min Ratio: 1.4566929133858268
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_01-38-55
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1556.0
  episode_reward_mean: 1144.62
  episode_reward_min: 842.0
  episodes_this_iter: 1
  episodes_total: 224
  experiment_id: a3942a9886f24694ab1b58ca8d1ab856
  hostname: gpu006
  info:
    apply_time_ms: 3.635
    dispatch_time_ms: 11.629
    learner:
      cur_lr: 0.0012108159717172384
      grad_gnorm: 40.0
      policy_entropy: 42.362525939941406
      policy_loss: -14.897256851196289
      var_gnorm: 46.87940979003906
      vf_explained_var: 0.33617258071899414
      vf_loss: 124.45089721679688
    num_steps_sampled: 2250000
    num_steps_trained: 2250000
    wait_time_ms: 240.469
  iterations_since_restore: 225
  node_ip: 172.17.8.6
  num_metric_batches_dropped: 0
  pid: 13557
  policy_reward_mean: {}
  time_since_restore: 5551.793184041977
  time_this_iter_s: 22.999282836914062
  time_total_s: 5551.793184041977
  timestamp: 1594100335
  timesteps_since_restore: 2250000
  timesteps_this_iter: 10000
  timesteps_total: 2250000
  training_iteration: 225
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 29.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=13557], 5551 s, 225 iter, 2250000 ts, 1.14e+03 rew

agent-1: 168.0
agent-2: 120.0
agent-3: 140.0
agent-4: 119.0
agent-5: 169.0
agent-6: 127.0
agent-7: 100.0
agent-8: 117.0
agent-9: 120.0
agent-10: 134.0
Sum Reward: 1314.0
Avg Reward: 131.4
Min Reward: 100.0
Max Reward: 169.0
Gini Coefficient: 0.08614916286149163
20:20 Ratio: 1.5529953917050692
Max-min Ratio: 1.69
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_01-39-21
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1556.0
  episode_reward_mean: 1146.22
  episode_reward_min: 842.0
  episodes_this_iter: 1
  episodes_total: 225
  experiment_id: a3942a9886f24694ab1b58ca8d1ab856
  hostname: gpu006
  info:
    apply_time_ms: 3.507
    dispatch_time_ms: 6.264
    learner:
      cur_lr: 0.0012101499596610665
      grad_gnorm: 39.999996185302734
      policy_entropy: 14.40207576751709
      policy_loss: 13.62716293334961
      var_gnorm: 46.96017074584961
      vf_explained_var: -0.04108703136444092
      vf_loss: 199.2230987548828
    num_steps_sampled: 2260000
    num_steps_trained: 2260000
    wait_time_ms: 211.442
  iterations_since_restore: 226
  node_ip: 172.17.8.6
  num_metric_batches_dropped: 0
  pid: 13557
  policy_reward_mean: {}
  time_since_restore: 5577.554866313934
  time_this_iter_s: 25.761682271957397
  time_total_s: 5577.554866313934
  timestamp: 1594100361
  timesteps_since_restore: 2260000
  timesteps_this_iter: 10000
  timesteps_total: 2260000
  training_iteration: 226
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 29.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=13557], 5577 s, 226 iter, 2260000 ts, 1.15e+03 rew

agent-1: 106.0
agent-2: 95.0
agent-3: 97.0
agent-4: 98.0
agent-5: 79.0
agent-6: 106.0
agent-7: 121.0
agent-8: 110.0
agent-9: 94.0
agent-10: 114.0
Sum Reward: 1020.0
Avg Reward: 102.0
Min Reward: 79.0
Max Reward: 121.0
Gini Coefficient: 0.06156862745098039
20:20 Ratio: 1.3583815028901733
Max-min Ratio: 1.5316455696202531
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_01-39-44
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1556.0
  episode_reward_mean: 1142.15
  episode_reward_min: 842.0
  episodes_this_iter: 1
  episodes_total: 226
  experiment_id: a3942a9886f24694ab1b58ca8d1ab856
  hostname: gpu006
  info:
    apply_time_ms: 2.87
    dispatch_time_ms: 6.111
    learner:
      cur_lr: 0.0012094839476048946
      grad_gnorm: 40.00000762939453
      policy_entropy: 64.4301528930664
      policy_loss: 11.88652229309082
      var_gnorm: 46.97415542602539
      vf_explained_var: 0.8736753463745117
      vf_loss: 26.052370071411133
    num_steps_sampled: 2270000
    num_steps_trained: 2270000
    wait_time_ms: 241.283
  iterations_since_restore: 227
  node_ip: 172.17.8.6
  num_metric_batches_dropped: 0
  pid: 13557
  policy_reward_mean: {}
  time_since_restore: 5601.263633728027
  time_this_iter_s: 23.708767414093018
  time_total_s: 5601.263633728027
  timestamp: 1594100384
  timesteps_since_restore: 2270000
  timesteps_this_iter: 10000
  timesteps_total: 2270000
  training_iteration: 227
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 29.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=13557], 5601 s, 227 iter, 2270000 ts, 1.14e+03 rew

agent-1: 120.0
agent-2: 85.0
agent-3: 107.0
agent-4: 102.0
agent-5: 94.0
agent-6: 86.0
agent-7: 97.0
agent-8: 115.0
agent-9: 114.0
agent-10: 119.0
Sum Reward: 1039.0
Avg Reward: 103.9
Min Reward: 85.0
Max Reward: 120.0
Gini Coefficient: 0.06804619826756497
20:20 Ratio: 1.3976608187134503
Max-min Ratio: 1.411764705882353
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_01-40-10
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1556.0
  episode_reward_mean: 1139.91
  episode_reward_min: 842.0
  episodes_this_iter: 1
  episodes_total: 227
  experiment_id: a3942a9886f24694ab1b58ca8d1ab856
  hostname: gpu006
  info:
    apply_time_ms: 2.713
    dispatch_time_ms: 6.153
    learner:
      cur_lr: 0.0012088180519640446
      grad_gnorm: 2.929628610610962
      policy_entropy: 90.59650421142578
      policy_loss: -0.18323156237602234
      var_gnorm: 47.04917526245117
      vf_explained_var: 0.9155481457710266
      vf_loss: 0.004880048800259829
    num_steps_sampled: 2280000
    num_steps_trained: 2280000
    wait_time_ms: 212.367
  iterations_since_restore: 228
  node_ip: 172.17.8.6
  num_metric_batches_dropped: 0
  pid: 13557
  policy_reward_mean: {}
  time_since_restore: 5627.0892996788025
  time_this_iter_s: 25.825665950775146
  time_total_s: 5627.0892996788025
  timestamp: 1594100410
  timesteps_since_restore: 2280000
  timesteps_this_iter: 10000
  timesteps_total: 2280000
  training_iteration: 228
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 29.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=13557], 5627 s, 228 iter, 2280000 ts, 1.14e+03 rew

agent-1: 93.0
agent-2: 103.0
agent-3: 96.0
agent-4: 92.0
agent-5: 115.0
agent-6: 111.0
agent-7: 131.0
agent-8: 111.0
agent-9: 116.0
agent-10: 103.0
Sum Reward: 1071.0
Avg Reward: 107.1
Min Reward: 92.0
Max Reward: 131.0
Gini Coefficient: 0.05966386554621849
20:20 Ratio: 1.335135135135135
Max-min Ratio: 1.423913043478261
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_01-40-35
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1556.0
  episode_reward_mean: 1140.67
  episode_reward_min: 842.0
  episodes_this_iter: 1
  episodes_total: 228
  experiment_id: a3942a9886f24694ab1b58ca8d1ab856
  hostname: gpu006
  info:
    apply_time_ms: 2.579
    dispatch_time_ms: 8.22
    learner:
      cur_lr: 0.0012081520399078727
      grad_gnorm: 40.00000762939453
      policy_entropy: 72.93891906738281
      policy_loss: -0.6584640145301819
      var_gnorm: 47.14688491821289
      vf_explained_var: 0.9152318835258484
      vf_loss: 5.335686206817627
    num_steps_sampled: 2290000
    num_steps_trained: 2290000
    wait_time_ms: 250.247
  iterations_since_restore: 229
  node_ip: 172.17.8.6
  num_metric_batches_dropped: 0
  pid: 13557
  policy_reward_mean: {}
  time_since_restore: 5652.185369253159
  time_this_iter_s: 25.09606957435608
  time_total_s: 5652.185369253159
  timestamp: 1594100435
  timesteps_since_restore: 2290000
  timesteps_this_iter: 10000
  timesteps_total: 2290000
  training_iteration: 229
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 29.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=13557], 5652 s, 229 iter, 2290000 ts, 1.14e+03 rew

agent-1: 140.0
agent-2: 117.0
agent-3: 126.0
agent-4: 103.0
agent-5: 116.0
agent-6: 130.0
agent-7: 146.0
agent-8: 126.0
agent-9: 108.0
agent-10: 110.0
Sum Reward: 1222.0
Avg Reward: 122.2
Min Reward: 103.0
Max Reward: 146.0
Gini Coefficient: 0.06137479541734861
20:20 Ratio: 1.3554502369668247
Max-min Ratio: 1.4174757281553398
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_01-41-01
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1556.0
  episode_reward_mean: 1144.3
  episode_reward_min: 842.0
  episodes_this_iter: 1
  episodes_total: 229
  experiment_id: a3942a9886f24694ab1b58ca8d1ab856
  hostname: gpu006
  info:
    apply_time_ms: 2.797
    dispatch_time_ms: 6.458
    learner:
      cur_lr: 0.0012074860278517008
      grad_gnorm: 1.2377264499664307
      policy_entropy: 58.13197326660156
      policy_loss: -0.16948793828487396
      var_gnorm: 47.19459915161133
      vf_explained_var: 0.08636409044265747
      vf_loss: 0.0009109613602049649
    num_steps_sampled: 2300000
    num_steps_trained: 2300000
    wait_time_ms: 225.626
  iterations_since_restore: 230
  node_ip: 172.17.8.6
  num_metric_batches_dropped: 0
  pid: 13557
  policy_reward_mean: {}
  time_since_restore: 5678.186262845993
  time_this_iter_s: 26.000893592834473
  time_total_s: 5678.186262845993
  timestamp: 1594100461
  timesteps_since_restore: 2300000
  timesteps_this_iter: 10000
  timesteps_total: 2300000
  training_iteration: 230
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 29.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=13557], 5678 s, 230 iter, 2300000 ts, 1.14e+03 rew

agent-1: 65.0
agent-2: 71.0
agent-3: 85.0
agent-4: 100.0
agent-5: 84.0
agent-6: 80.0
agent-7: 85.0
agent-8: 89.0
agent-9: 90.0
agent-10: 92.0
Sum Reward: 841.0
Avg Reward: 84.1
Min Reward: 65.0
Max Reward: 100.0
Gini Coefficient: 0.06266349583828776
20:20 Ratio: 1.411764705882353
Max-min Ratio: 1.5384615384615385
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_01-41-25
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1556.0
  episode_reward_mean: 1143.94
  episode_reward_min: 841.0
  episodes_this_iter: 1
  episodes_total: 230
  experiment_id: a3942a9886f24694ab1b58ca8d1ab856
  hostname: gpu006
  info:
    apply_time_ms: 2.691
    dispatch_time_ms: 6.957
    learner:
      cur_lr: 0.0012068200157955289
      grad_gnorm: 40.00000762939453
      policy_entropy: 69.97196960449219
      policy_loss: 4.036810874938965
      var_gnorm: 47.22075271606445
      vf_explained_var: 0.41860586404800415
      vf_loss: 5.583897113800049
    num_steps_sampled: 2310000
    num_steps_trained: 2310000
    wait_time_ms: 251.247
  iterations_since_restore: 231
  node_ip: 172.17.8.6
  num_metric_batches_dropped: 0
  pid: 13557
  policy_reward_mean: {}
  time_since_restore: 5702.035238027573
  time_this_iter_s: 23.84897518157959
  time_total_s: 5702.035238027573
  timestamp: 1594100485
  timesteps_since_restore: 2310000
  timesteps_this_iter: 10000
  timesteps_total: 2310000
  training_iteration: 231
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 29.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=13557], 5702 s, 231 iter, 2310000 ts, 1.14e+03 rew

agent-1: 75.0
agent-2: 100.0
agent-3: 92.0
agent-4: 99.0
agent-5: 93.0
agent-6: 89.0
agent-7: 129.0
agent-8: 103.0
agent-9: 100.0
agent-10: 103.0
Sum Reward: 983.0
Avg Reward: 98.3
Min Reward: 75.0
Max Reward: 129.0
Gini Coefficient: 0.06724313326551373
20:20 Ratio: 1.4146341463414633
Max-min Ratio: 1.72
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_01-41-51
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1556.0
  episode_reward_mean: 1143.06
  episode_reward_min: 841.0
  episodes_this_iter: 1
  episodes_total: 231
  experiment_id: a3942a9886f24694ab1b58ca8d1ab856
  hostname: gpu006
  info:
    apply_time_ms: 2.645
    dispatch_time_ms: 5.616
    learner:
      cur_lr: 0.001206154003739357
      grad_gnorm: 2.3292202949523926
      policy_entropy: 84.1722640991211
      policy_loss: -0.5503902435302734
      var_gnorm: 47.24510955810547
      vf_explained_var: 0.9150996804237366
      vf_loss: 0.036817118525505066
    num_steps_sampled: 2320000
    num_steps_trained: 2320000
    wait_time_ms: 226.248
  iterations_since_restore: 232
  node_ip: 172.17.8.6
  num_metric_batches_dropped: 0
  pid: 13557
  policy_reward_mean: {}
  time_since_restore: 5727.791209459305
  time_this_iter_s: 25.755971431732178
  time_total_s: 5727.791209459305
  timestamp: 1594100511
  timesteps_since_restore: 2320000
  timesteps_this_iter: 10000
  timesteps_total: 2320000
  training_iteration: 232
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 29.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=13557], 5727 s, 232 iter, 2320000 ts, 1.14e+03 rew

agent-1: 94.0
agent-2: 99.0
agent-3: 94.0
agent-4: 75.0
agent-5: 98.0
agent-6: 76.0
agent-7: 83.0
agent-8: 159.0
agent-9: 91.0
agent-10: 87.0
Sum Reward: 956.0
Avg Reward: 95.6
Min Reward: 75.0
Max Reward: 159.0
Gini Coefficient: 0.10627615062761506
20:20 Ratio: 1.7086092715231789
Max-min Ratio: 2.12
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_01-42-14
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1556.0
  episode_reward_mean: 1141.38
  episode_reward_min: 841.0
  episodes_this_iter: 1
  episodes_total: 232
  experiment_id: a3942a9886f24694ab1b58ca8d1ab856
  hostname: gpu006
  info:
    apply_time_ms: 2.641
    dispatch_time_ms: 7.247
    learner:
      cur_lr: 0.001205487991683185
      grad_gnorm: 40.0
      policy_entropy: 45.00472640991211
      policy_loss: -11.403487205505371
      var_gnorm: 47.37001037597656
      vf_explained_var: 0.9535706043243408
      vf_loss: 62.88527297973633
    num_steps_sampled: 2330000
    num_steps_trained: 2330000
    wait_time_ms: 244.495
  iterations_since_restore: 233
  node_ip: 172.17.8.6
  num_metric_batches_dropped: 0
  pid: 13557
  policy_reward_mean: {}
  time_since_restore: 5750.808862686157
  time_this_iter_s: 23.017653226852417
  time_total_s: 5750.808862686157
  timestamp: 1594100534
  timesteps_since_restore: 2330000
  timesteps_this_iter: 10000
  timesteps_total: 2330000
  training_iteration: 233
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 29.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=13557], 5750 s, 233 iter, 2330000 ts, 1.14e+03 rew

agent-1: 145.0
agent-2: 104.0
agent-3: 114.0
agent-4: 134.0
agent-5: 126.0
agent-6: 118.0
agent-7: 136.0
agent-8: 127.0
agent-9: 82.0
agent-10: 84.0
Sum Reward: 1170.0
Avg Reward: 117.0
Min Reward: 82.0
Max Reward: 145.0
Gini Coefficient: 0.09641025641025641
20:20 Ratio: 1.6927710843373494
Max-min Ratio: 1.7682926829268293
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_01-42-40
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1556.0
  episode_reward_mean: 1142.8
  episode_reward_min: 841.0
  episodes_this_iter: 1
  episodes_total: 233
  experiment_id: a3942a9886f24694ab1b58ca8d1ab856
  hostname: gpu006
  info:
    apply_time_ms: 2.643
    dispatch_time_ms: 5.911
    learner:
      cur_lr: 0.0012048219796270132
      grad_gnorm: 40.0
      policy_entropy: 20.591182708740234
      policy_loss: 3.9685721397399902
      var_gnorm: 47.40323257446289
      vf_explained_var: 0.4065369963645935
      vf_loss: 106.18655395507812
    num_steps_sampled: 2340000
    num_steps_trained: 2340000
    wait_time_ms: 212.996
  iterations_since_restore: 234
  node_ip: 172.17.8.6
  num_metric_batches_dropped: 0
  pid: 13557
  policy_reward_mean: {}
  time_since_restore: 5776.444780349731
  time_this_iter_s: 25.63591766357422
  time_total_s: 5776.444780349731
  timestamp: 1594100560
  timesteps_since_restore: 2340000
  timesteps_this_iter: 10000
  timesteps_total: 2340000
  training_iteration: 234
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 29.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=13557], 5776 s, 234 iter, 2340000 ts, 1.14e+03 rew

agent-1: 98.0
agent-2: 114.0
agent-3: 126.0
agent-4: 115.0
agent-5: 117.0
agent-6: 131.0
agent-7: 101.0
agent-8: 115.0
agent-9: 140.0
agent-10: 113.0
Sum Reward: 1170.0
Avg Reward: 117.0
Min Reward: 98.0
Max Reward: 140.0
Gini Coefficient: 0.056581196581196584
20:20 Ratio: 1.3618090452261307
Max-min Ratio: 1.4285714285714286
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_01-43-03
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1556.0
  episode_reward_mean: 1143.22
  episode_reward_min: 841.0
  episodes_this_iter: 1
  episodes_total: 234
  experiment_id: a3942a9886f24694ab1b58ca8d1ab856
  hostname: gpu006
  info:
    apply_time_ms: 3.703
    dispatch_time_ms: 6.021
    learner:
      cur_lr: 0.0012041559675708413
      grad_gnorm: 40.0
      policy_entropy: 53.742008209228516
      policy_loss: 1.9998468160629272
      var_gnorm: 47.444705963134766
      vf_explained_var: 0.8096634745597839
      vf_loss: 38.87824630737305
    num_steps_sampled: 2350000
    num_steps_trained: 2350000
    wait_time_ms: 252.716
  iterations_since_restore: 235
  node_ip: 172.17.8.6
  num_metric_batches_dropped: 0
  pid: 13557
  policy_reward_mean: {}
  time_since_restore: 5799.4017651081085
  time_this_iter_s: 22.956984758377075
  time_total_s: 5799.4017651081085
  timestamp: 1594100583
  timesteps_since_restore: 2350000
  timesteps_this_iter: 10000
  timesteps_total: 2350000
  training_iteration: 235
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 29.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=13557], 5799 s, 235 iter, 2350000 ts, 1.14e+03 rew

agent-1: 117.0
agent-2: 123.0
agent-3: 165.0
agent-4: 127.0
agent-5: 156.0
agent-6: 163.0
agent-7: 115.0
agent-8: 137.0
agent-9: 126.0
agent-10: 98.0
Sum Reward: 1327.0
Avg Reward: 132.7
Min Reward: 98.0
Max Reward: 165.0
Gini Coefficient: 0.08869630746043708
20:20 Ratio: 1.539906103286385
Max-min Ratio: 1.683673469387755
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_01-43-28
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1556.0
  episode_reward_mean: 1145.9
  episode_reward_min: 841.0
  episodes_this_iter: 1
  episodes_total: 235
  experiment_id: a3942a9886f24694ab1b58ca8d1ab856
  hostname: gpu006
  info:
    apply_time_ms: 2.946
    dispatch_time_ms: 5.673
    learner:
      cur_lr: 0.0012034899555146694
      grad_gnorm: 2.009310722351074
      policy_entropy: 109.94277954101562
      policy_loss: 0.7882044315338135
      var_gnorm: 47.531429290771484
      vf_explained_var: 0.6672593355178833
      vf_loss: 0.028660239651799202
    num_steps_sampled: 2360000
    num_steps_trained: 2360000
    wait_time_ms: 206.595
  iterations_since_restore: 236
  node_ip: 172.17.8.6
  num_metric_batches_dropped: 0
  pid: 13557
  policy_reward_mean: {}
  time_since_restore: 5824.983444929123
  time_this_iter_s: 25.581679821014404
  time_total_s: 5824.983444929123
  timestamp: 1594100608
  timesteps_since_restore: 2360000
  timesteps_this_iter: 10000
  timesteps_total: 2360000
  training_iteration: 236
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 29.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=13557], 5824 s, 236 iter, 2360000 ts, 1.15e+03 rew

agent-1: 110.0
agent-2: 119.0
agent-3: 108.0
agent-4: 114.0
agent-5: 125.0
agent-6: 114.0
agent-7: 109.0
agent-8: 111.0
agent-9: 135.0
agent-10: 108.0
Sum Reward: 1153.0
Avg Reward: 115.3
Min Reward: 108.0
Max Reward: 135.0
Gini Coefficient: 0.037033824804856896
20:20 Ratio: 1.2037037037037037
Max-min Ratio: 1.25
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_01-43-53
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1556.0
  episode_reward_mean: 1142.84
  episode_reward_min: 841.0
  episodes_this_iter: 1
  episodes_total: 236
  experiment_id: a3942a9886f24694ab1b58ca8d1ab856
  hostname: gpu006
  info:
    apply_time_ms: 3.03
    dispatch_time_ms: 7.549
    learner:
      cur_lr: 0.0012028239434584975
      grad_gnorm: 40.00000762939453
      policy_entropy: 74.31641387939453
      policy_loss: -18.789182662963867
      var_gnorm: 47.6696662902832
      vf_explained_var: 0.5150387287139893
      vf_loss: 93.9299545288086
    num_steps_sampled: 2370000
    num_steps_trained: 2370000
    wait_time_ms: 235.789
  iterations_since_restore: 237
  node_ip: 172.17.8.6
  num_metric_batches_dropped: 0
  pid: 13557
  policy_reward_mean: {}
  time_since_restore: 5848.964375972748
  time_this_iter_s: 23.980931043624878
  time_total_s: 5848.964375972748
  timestamp: 1594100633
  timesteps_since_restore: 2370000
  timesteps_this_iter: 10000
  timesteps_total: 2370000
  training_iteration: 237
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 29.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=13557], 5848 s, 237 iter, 2370000 ts, 1.14e+03 rew

agent-1: 87.0
agent-2: 81.0
agent-3: 93.0
agent-4: 76.0
agent-5: 80.0
agent-6: 106.0
agent-7: 108.0
agent-8: 117.0
agent-9: 113.0
agent-10: 110.0
Sum Reward: 971.0
Avg Reward: 97.1
Min Reward: 76.0
Max Reward: 117.0
Gini Coefficient: 0.08455200823892894
20:20 Ratio: 1.4743589743589745
Max-min Ratio: 1.5394736842105263
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_01-44-18
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1556.0
  episode_reward_mean: 1139.18
  episode_reward_min: 841.0
  episodes_this_iter: 1
  episodes_total: 237
  experiment_id: a3942a9886f24694ab1b58ca8d1ab856
  hostname: gpu006
  info:
    apply_time_ms: 2.75
    dispatch_time_ms: 6.342
    learner:
      cur_lr: 0.0012021580478176475
      grad_gnorm: 40.0
      policy_entropy: 101.8950424194336
      policy_loss: 17.300365447998047
      var_gnorm: 47.707462310791016
      vf_explained_var: 0.6290605068206787
      vf_loss: 29.10455322265625
    num_steps_sampled: 2380000
    num_steps_trained: 2380000
    wait_time_ms: 203.392
  iterations_since_restore: 238
  node_ip: 172.17.8.6
  num_metric_batches_dropped: 0
  pid: 13557
  policy_reward_mean: {}
  time_since_restore: 5874.514623641968
  time_this_iter_s: 25.55024766921997
  time_total_s: 5874.514623641968
  timestamp: 1594100658
  timesteps_since_restore: 2380000
  timesteps_this_iter: 10000
  timesteps_total: 2380000
  training_iteration: 238
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 29.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=13557], 5874 s, 238 iter, 2380000 ts, 1.14e+03 rew

agent-1: 116.0
agent-2: 159.0
agent-3: 127.0
agent-4: 130.0
agent-5: 142.0
agent-6: 100.0
agent-7: 86.0
agent-8: 89.0
agent-9: 161.0
agent-10: 121.0
Sum Reward: 1231.0
Avg Reward: 123.1
Min Reward: 86.0
Max Reward: 161.0
Gini Coefficient: 0.11559707554833469
20:20 Ratio: 1.8285714285714285
Max-min Ratio: 1.872093023255814
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_01-44-41
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1556.0
  episode_reward_mean: 1138.02
  episode_reward_min: 841.0
  episodes_this_iter: 1
  episodes_total: 238
  experiment_id: a3942a9886f24694ab1b58ca8d1ab856
  hostname: gpu006
  info:
    apply_time_ms: 3.948
    dispatch_time_ms: 10.623
    learner:
      cur_lr: 0.0012014920357614756
      grad_gnorm: 39.99999237060547
      policy_entropy: 72.31820678710938
      policy_loss: -60.08946990966797
      var_gnorm: 47.83810043334961
      vf_explained_var: 0.4130200743675232
      vf_loss: 89.59615325927734
    num_steps_sampled: 2390000
    num_steps_trained: 2390000
    wait_time_ms: 227.347
  iterations_since_restore: 239
  node_ip: 172.17.8.6
  num_metric_batches_dropped: 0
  pid: 13557
  policy_reward_mean: {}
  time_since_restore: 5896.931005239487
  time_this_iter_s: 22.41638159751892
  time_total_s: 5896.931005239487
  timestamp: 1594100681
  timesteps_since_restore: 2390000
  timesteps_this_iter: 10000
  timesteps_total: 2390000
  training_iteration: 239
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 29.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=13557], 5896 s, 239 iter, 2390000 ts, 1.14e+03 rew

agent-1: 168.0
agent-2: 128.0
agent-3: 147.0
agent-4: 126.0
agent-5: 114.0
agent-6: 149.0
agent-7: 131.0
agent-8: 128.0
agent-9: 119.0
agent-10: 169.0
Sum Reward: 1379.0
Avg Reward: 137.9
Min Reward: 114.0
Max Reward: 169.0
Gini Coefficient: 0.0734590282813633
20:20 Ratio: 1.446351931330472
Max-min Ratio: 1.4824561403508771
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_01-45-06
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1556.0
  episode_reward_mean: 1137.49
  episode_reward_min: 841.0
  episodes_this_iter: 1
  episodes_total: 239
  experiment_id: a3942a9886f24694ab1b58ca8d1ab856
  hostname: gpu006
  info:
    apply_time_ms: 2.85
    dispatch_time_ms: 26.519
    learner:
      cur_lr: 0.0012008260237053037
      grad_gnorm: 39.99999237060547
      policy_entropy: 92.09459686279297
      policy_loss: 12.759963989257812
      var_gnorm: 47.87970733642578
      vf_explained_var: 0.8762953281402588
      vf_loss: 97.0002212524414
    num_steps_sampled: 2400000
    num_steps_trained: 2400000
    wait_time_ms: 243.948
  iterations_since_restore: 240
  node_ip: 172.17.8.6
  num_metric_batches_dropped: 0
  pid: 13557
  policy_reward_mean: {}
  time_since_restore: 5922.584990024567
  time_this_iter_s: 25.653984785079956
  time_total_s: 5922.584990024567
  timestamp: 1594100706
  timesteps_since_restore: 2400000
  timesteps_this_iter: 10000
  timesteps_total: 2400000
  training_iteration: 240
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 29.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=13557], 5922 s, 240 iter, 2400000 ts, 1.14e+03 rew

agent-1: 109.0
agent-2: 145.0
agent-3: 150.0
agent-4: 147.0
agent-5: 153.0
agent-6: 135.0
agent-7: 184.0
agent-8: 174.0
agent-9: 107.0
agent-10: 116.0
Sum Reward: 1420.0
Avg Reward: 142.0
Min Reward: 107.0
Max Reward: 184.0
Gini Coefficient: 0.09718309859154929
20:20 Ratio: 1.6574074074074074
Max-min Ratio: 1.719626168224299
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_01-45-30
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1556.0
  episode_reward_mean: 1140.28
  episode_reward_min: 841.0
  episodes_this_iter: 1
  episodes_total: 240
  experiment_id: a3942a9886f24694ab1b58ca8d1ab856
  hostname: gpu006
  info:
    apply_time_ms: 3.622
    dispatch_time_ms: 30.792
    learner:
      cur_lr: 0.0012001600116491318
      grad_gnorm: 39.9999885559082
      policy_entropy: 87.9398422241211
      policy_loss: 2.0600500106811523
      var_gnorm: 47.93690490722656
      vf_explained_var: 0.6394579410552979
      vf_loss: 25.182470321655273
    num_steps_sampled: 2410000
    num_steps_trained: 2410000
    wait_time_ms: 235.071
  iterations_since_restore: 241
  node_ip: 172.17.8.6
  num_metric_batches_dropped: 0
  pid: 13557
  policy_reward_mean: {}
  time_since_restore: 5946.072976112366
  time_this_iter_s: 23.487986087799072
  time_total_s: 5946.072976112366
  timestamp: 1594100730
  timesteps_since_restore: 2410000
  timesteps_this_iter: 10000
  timesteps_total: 2410000
  training_iteration: 241
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 29.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=13557], 5946 s, 241 iter, 2410000 ts, 1.14e+03 rew

agent-1: 117.0
agent-2: 128.0
agent-3: 101.0
agent-4: 127.0
agent-5: 110.0
agent-6: 125.0
agent-7: 114.0
agent-8: 120.0
agent-9: 95.0
agent-10: 127.0
Sum Reward: 1164.0
Avg Reward: 116.4
Min Reward: 95.0
Max Reward: 128.0
Gini Coefficient: 0.05154639175257732
20:20 Ratio: 1.3010204081632653
Max-min Ratio: 1.3473684210526315
W0707 01:45:57.706383 13553 client_connection.cc:255] [worker]ProcessMessage with type 1 took 1734 ms.
W0707 01:45:57.711411 13553 node_manager.cc:250] Last heartbeat was sent 1784 ms ago 
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_01-45-58
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1556.0
  episode_reward_mean: 1142.2
  episode_reward_min: 841.0
  episodes_this_iter: 1
  episodes_total: 241
  experiment_id: a3942a9886f24694ab1b58ca8d1ab856
  hostname: gpu006
  info:
    apply_time_ms: 2.603
    dispatch_time_ms: 49.636
    learner:
      cur_lr: 0.0011994939995929599
      grad_gnorm: 40.000003814697266
      policy_entropy: 51.10702896118164
      policy_loss: -5.085248947143555
      var_gnorm: 47.970123291015625
      vf_explained_var: 0.4684915542602539
      vf_loss: 111.05351257324219
    num_steps_sampled: 2420000
    num_steps_trained: 2420000
    wait_time_ms: 311.545
  iterations_since_restore: 242
  node_ip: 172.17.8.6
  num_metric_batches_dropped: 0
  pid: 13557
  policy_reward_mean: {}
  time_since_restore: 5974.122019290924
  time_this_iter_s: 28.04904317855835
  time_total_s: 5974.122019290924
  timestamp: 1594100758
  timesteps_since_restore: 2420000
  timesteps_this_iter: 10000
  timesteps_total: 2420000
  training_iteration: 242
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 29.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=13557], 5974 s, 242 iter, 2420000 ts, 1.14e+03 rew

agent-1: 114.0
agent-2: 109.0
agent-3: 100.0
agent-4: 122.0
agent-5: 104.0
agent-6: 95.0
agent-7: 127.0
agent-8: 104.0
agent-9: 126.0
agent-10: 109.0
Sum Reward: 1110.0
Avg Reward: 111.0
Min Reward: 95.0
Max Reward: 127.0
Gini Coefficient: 0.05315315315315315
20:20 Ratio: 1.2974358974358975
Max-min Ratio: 1.3368421052631578
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_01-46-21
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1556.0
  episode_reward_mean: 1142.78
  episode_reward_min: 841.0
  episodes_this_iter: 1
  episodes_total: 242
  experiment_id: a3942a9886f24694ab1b58ca8d1ab856
  hostname: gpu006
  info:
    apply_time_ms: 2.848
    dispatch_time_ms: 25.028
    learner:
      cur_lr: 0.001198827987536788
      grad_gnorm: 40.0
      policy_entropy: 67.9901123046875
      policy_loss: 31.179594039916992
      var_gnorm: 47.99551773071289
      vf_explained_var: 0.7953339219093323
      vf_loss: 99.34728240966797
    num_steps_sampled: 2430000
    num_steps_trained: 2430000
    wait_time_ms: 226.607
  iterations_since_restore: 243
  node_ip: 172.17.8.6
  num_metric_batches_dropped: 0
  pid: 13557
  policy_reward_mean: {}
  time_since_restore: 5996.940735816956
  time_this_iter_s: 22.818716526031494
  time_total_s: 5996.940735816956
  timestamp: 1594100781
  timesteps_since_restore: 2430000
  timesteps_this_iter: 10000
  timesteps_total: 2430000
  training_iteration: 243
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 29.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=13557], 5996 s, 243 iter, 2430000 ts, 1.14e+03 rew

agent-1: 109.0
agent-2: 123.0
agent-3: 126.0
agent-4: 106.0
agent-5: 133.0
agent-6: 132.0
agent-7: 96.0
agent-8: 100.0
agent-9: 97.0
agent-10: 120.0
Sum Reward: 1142.0
Avg Reward: 114.2
Min Reward: 96.0
Max Reward: 133.0
Gini Coefficient: 0.06742556917688267
20:20 Ratio: 1.3730569948186528
Max-min Ratio: 1.3854166666666667
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_01-46-48
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1556.0
  episode_reward_mean: 1144.41
  episode_reward_min: 841.0
  episodes_this_iter: 1
  episodes_total: 243
  experiment_id: a3942a9886f24694ab1b58ca8d1ab856
  hostname: gpu006
  info:
    apply_time_ms: 3.411
    dispatch_time_ms: 24.149
    learner:
      cur_lr: 0.001198161975480616
      grad_gnorm: 39.999996185302734
      policy_entropy: 24.702594757080078
      policy_loss: 7.475912570953369
      var_gnorm: 48.01789093017578
      vf_explained_var: 0.495344340801239
      vf_loss: 92.56050872802734
    num_steps_sampled: 2440000
    num_steps_trained: 2440000
    wait_time_ms: 215.738
  iterations_since_restore: 244
  node_ip: 172.17.8.6
  num_metric_batches_dropped: 0
  pid: 13557
  policy_reward_mean: {}
  time_since_restore: 6023.95999455452
  time_this_iter_s: 27.019258737564087
  time_total_s: 6023.95999455452
  timestamp: 1594100808
  timesteps_since_restore: 2440000
  timesteps_this_iter: 10000
  timesteps_total: 2440000
  training_iteration: 244
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 29.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=13557], 6023 s, 244 iter, 2440000 ts, 1.14e+03 rew

agent-1: 127.0
agent-2: 105.0
agent-3: 110.0
agent-4: 101.0
agent-5: 121.0
agent-6: 101.0
agent-7: 112.0
agent-8: 83.0
agent-9: 122.0
agent-10: 111.0
Sum Reward: 1093.0
Avg Reward: 109.3
Min Reward: 83.0
Max Reward: 127.0
Gini Coefficient: 0.060841720036596526
20:20 Ratio: 1.3532608695652173
Max-min Ratio: 1.5301204819277108
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_01-47-09
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1556.0
  episode_reward_mean: 1140.16
  episode_reward_min: 841.0
  episodes_this_iter: 1
  episodes_total: 244
  experiment_id: a3942a9886f24694ab1b58ca8d1ab856
  hostname: gpu006
  info:
    apply_time_ms: 2.856
    dispatch_time_ms: 25.771
    learner:
      cur_lr: 0.0011974959634244442
      grad_gnorm: 39.99998474121094
      policy_entropy: 52.235904693603516
      policy_loss: 32.56635665893555
      var_gnorm: 48.09184265136719
      vf_explained_var: 0.8125635385513306
      vf_loss: 79.23951721191406
    num_steps_sampled: 2450000
    num_steps_trained: 2450000
    wait_time_ms: 213.913
  iterations_since_restore: 245
  node_ip: 172.17.8.6
  num_metric_batches_dropped: 0
  pid: 13557
  policy_reward_mean: {}
  time_since_restore: 6045.515591144562
  time_this_iter_s: 21.555596590042114
  time_total_s: 6045.515591144562
  timestamp: 1594100829
  timesteps_since_restore: 2450000
  timesteps_this_iter: 10000
  timesteps_total: 2450000
  training_iteration: 245
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 29.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=13557], 6045 s, 245 iter, 2450000 ts, 1.14e+03 rew

agent-1: 150.0
agent-2: 172.0
agent-3: 159.0
agent-4: 172.0
agent-5: 142.0
agent-6: 142.0
agent-7: 187.0
agent-8: 142.0
agent-9: 144.0
agent-10: 137.0
Sum Reward: 1547.0
Avg Reward: 154.7
Min Reward: 137.0
Max Reward: 187.0
Gini Coefficient: 0.056043956043956046
20:20 Ratio: 1.2867383512544803
Max-min Ratio: 1.364963503649635
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_01-47-35
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1547.0
  episode_reward_mean: 1140.07
  episode_reward_min: 841.0
  episodes_this_iter: 1
  episodes_total: 245
  experiment_id: a3942a9886f24694ab1b58ca8d1ab856
  hostname: gpu006
  info:
    apply_time_ms: 2.832
    dispatch_time_ms: 7.2
    learner:
      cur_lr: 0.0011968299513682723
      grad_gnorm: 39.99998474121094
      policy_entropy: 95.97746276855469
      policy_loss: -8.185003280639648
      var_gnorm: 48.174808502197266
      vf_explained_var: 0.42422378063201904
      vf_loss: 3.1653223037719727
    num_steps_sampled: 2460000
    num_steps_trained: 2460000
    wait_time_ms: 260.214
  iterations_since_restore: 246
  node_ip: 172.17.8.6
  num_metric_batches_dropped: 0
  pid: 13557
  policy_reward_mean: {}
  time_since_restore: 6071.330364942551
  time_this_iter_s: 25.81477379798889
  time_total_s: 6071.330364942551
  timestamp: 1594100855
  timesteps_since_restore: 2460000
  timesteps_this_iter: 10000
  timesteps_total: 2460000
  training_iteration: 246
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 29.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=13557], 6071 s, 246 iter, 2460000 ts, 1.14e+03 rew

agent-1: 158.0
agent-2: 169.0
agent-3: 156.0
agent-4: 154.0
agent-5: 144.0
agent-6: 143.0
agent-7: 113.0
agent-8: 134.0
agent-9: 145.0
agent-10: 122.0
Sum Reward: 1438.0
Avg Reward: 143.8
Min Reward: 113.0
Max Reward: 169.0
Gini Coefficient: 0.06258692628650904
20:20 Ratio: 1.3914893617021276
Max-min Ratio: 1.4955752212389382
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_01-47-58
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1547.0
  episode_reward_mean: 1143.54
  episode_reward_min: 841.0
  episodes_this_iter: 1
  episodes_total: 246
  experiment_id: a3942a9886f24694ab1b58ca8d1ab856
  hostname: gpu006
  info:
    apply_time_ms: 3.243
    dispatch_time_ms: 7.606
    learner:
      cur_lr: 0.0011961640557274222
      grad_gnorm: 40.0
      policy_entropy: 77.78629302978516
      policy_loss: -2.7492964267730713
      var_gnorm: 48.22431945800781
      vf_explained_var: 0.6931564807891846
      vf_loss: 11.196748733520508
    num_steps_sampled: 2470000
    num_steps_trained: 2470000
    wait_time_ms: 256.236
  iterations_since_restore: 247
  node_ip: 172.17.8.6
  num_metric_batches_dropped: 0
  pid: 13557
  policy_reward_mean: {}
  time_since_restore: 6094.432178258896
  time_this_iter_s: 23.101813316345215
  time_total_s: 6094.432178258896
  timestamp: 1594100878
  timesteps_since_restore: 2470000
  timesteps_this_iter: 10000
  timesteps_total: 2470000
  training_iteration: 247
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 29.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=13557], 6094 s, 247 iter, 2470000 ts, 1.14e+03 rew

agent-1: 83.0
agent-2: 112.0
agent-3: 105.0
agent-4: 95.0
agent-5: 94.0
agent-6: 93.0
agent-7: 102.0
agent-8: 95.0
agent-9: 89.0
agent-10: 123.0
Sum Reward: 991.0
Avg Reward: 99.1
Min Reward: 83.0
Max Reward: 123.0
Gini Coefficient: 0.06104944500504541
20:20 Ratio: 1.3662790697674418
Max-min Ratio: 1.4819277108433735
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_01-48-25
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1547.0
  episode_reward_mean: 1143.37
  episode_reward_min: 841.0
  episodes_this_iter: 1
  episodes_total: 247
  experiment_id: a3942a9886f24694ab1b58ca8d1ab856
  hostname: gpu006
  info:
    apply_time_ms: 2.673
    dispatch_time_ms: 6.772
    learner:
      cur_lr: 0.0011954980436712503
      grad_gnorm: 5.834813594818115
      policy_entropy: 104.00688171386719
      policy_loss: -1.1948692798614502
      var_gnorm: 48.2537841796875
      vf_explained_var: 0.995918869972229
      vf_loss: 0.23485183715820312
    num_steps_sampled: 2480000
    num_steps_trained: 2480000
    wait_time_ms: 243.712
  iterations_since_restore: 248
  node_ip: 172.17.8.6
  num_metric_batches_dropped: 0
  pid: 13557
  policy_reward_mean: {}
  time_since_restore: 6120.918811798096
  time_this_iter_s: 26.48663353919983
  time_total_s: 6120.918811798096
  timestamp: 1594100905
  timesteps_since_restore: 2480000
  timesteps_this_iter: 10000
  timesteps_total: 2480000
  training_iteration: 248
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 29.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=13557], 6120 s, 248 iter, 2480000 ts, 1.14e+03 rew

agent-1: 73.0
agent-2: 107.0
agent-3: 81.0
agent-4: 98.0
agent-5: 71.0
agent-6: 96.0
agent-7: 78.0
agent-8: 99.0
agent-9: 97.0
agent-10: 86.0
Sum Reward: 886.0
Avg Reward: 88.6
Min Reward: 71.0
Max Reward: 107.0
Gini Coefficient: 0.07494356659142212
20:20 Ratio: 1.4305555555555556
Max-min Ratio: 1.5070422535211268
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_01-48-48
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1547.0
  episode_reward_mean: 1141.41
  episode_reward_min: 841.0
  episodes_this_iter: 1
  episodes_total: 248
  experiment_id: a3942a9886f24694ab1b58ca8d1ab856
  hostname: gpu006
  info:
    apply_time_ms: 2.728
    dispatch_time_ms: 5.522
    learner:
      cur_lr: 0.0011948320316150784
      grad_gnorm: 39.999996185302734
      policy_entropy: 97.57351684570312
      policy_loss: -14.289661407470703
      var_gnorm: 48.25844955444336
      vf_explained_var: 0.6733579635620117
      vf_loss: 6.626486778259277
    num_steps_sampled: 2490000
    num_steps_trained: 2490000
    wait_time_ms: 246.682
  iterations_since_restore: 249
  node_ip: 172.17.8.6
  num_metric_batches_dropped: 0
  pid: 13557
  policy_reward_mean: {}
  time_since_restore: 6143.888643741608
  time_this_iter_s: 22.969831943511963
  time_total_s: 6143.888643741608
  timestamp: 1594100928
  timesteps_since_restore: 2490000
  timesteps_this_iter: 10000
  timesteps_total: 2490000
  training_iteration: 249
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 29.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=13557], 6143 s, 249 iter, 2490000 ts, 1.14e+03 rew

agent-1: 88.0
agent-2: 112.0
agent-3: 129.0
agent-4: 100.0
agent-5: 109.0
agent-6: 83.0
agent-7: 96.0
agent-8: 95.0
agent-9: 83.0
agent-10: 85.0
Sum Reward: 980.0
Avg Reward: 98.0
Min Reward: 83.0
Max Reward: 129.0
Gini Coefficient: 0.0789795918367347
20:20 Ratio: 1.4518072289156627
Max-min Ratio: 1.5542168674698795
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_01-49-15
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1547.0
  episode_reward_mean: 1139.85
  episode_reward_min: 841.0
  episodes_this_iter: 1
  episodes_total: 249
  experiment_id: a3942a9886f24694ab1b58ca8d1ab856
  hostname: gpu006
  info:
    apply_time_ms: 2.574
    dispatch_time_ms: 6.41
    learner:
      cur_lr: 0.0011941660195589066
      grad_gnorm: 40.000003814697266
      policy_entropy: 23.559968948364258
      policy_loss: 72.98301696777344
      var_gnorm: 48.30345916748047
      vf_explained_var: 0.3408319354057312
      vf_loss: 604.800048828125
    num_steps_sampled: 2500000
    num_steps_trained: 2500000
    wait_time_ms: 242.169
  iterations_since_restore: 250
  node_ip: 172.17.8.6
  num_metric_batches_dropped: 0
  pid: 13557
  policy_reward_mean: {}
  time_since_restore: 6170.497689008713
  time_this_iter_s: 26.609045267105103
  time_total_s: 6170.497689008713
  timestamp: 1594100955
  timesteps_since_restore: 2500000
  timesteps_this_iter: 10000
  timesteps_total: 2500000
  training_iteration: 250
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 29.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=13557], 6170 s, 250 iter, 2500000 ts, 1.14e+03 rew

agent-1: 96.0
agent-2: 83.0
agent-3: 91.0
agent-4: 101.0
agent-5: 102.0
agent-6: 118.0
agent-7: 98.0
agent-8: 97.0
agent-9: 116.0
agent-10: 98.0
Sum Reward: 1000.0
Avg Reward: 100.0
Min Reward: 83.0
Max Reward: 118.0
Gini Coefficient: 0.0532
20:20 Ratio: 1.3448275862068966
Max-min Ratio: 1.4216867469879517
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_01-49-37
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1547.0
  episode_reward_mean: 1139.82
  episode_reward_min: 841.0
  episodes_this_iter: 1
  episodes_total: 250
  experiment_id: a3942a9886f24694ab1b58ca8d1ab856
  hostname: gpu006
  info:
    apply_time_ms: 2.782
    dispatch_time_ms: 6.804
    learner:
      cur_lr: 0.0011935000075027347
      grad_gnorm: 39.999996185302734
      policy_entropy: 102.65414428710938
      policy_loss: -12.852896690368652
      var_gnorm: 48.314735412597656
      vf_explained_var: 0.6668013334274292
      vf_loss: 19.078554153442383
    num_steps_sampled: 2510000
    num_steps_trained: 2510000
    wait_time_ms: 258.369
  iterations_since_restore: 251
  node_ip: 172.17.8.6
  num_metric_batches_dropped: 0
  pid: 13557
  policy_reward_mean: {}
  time_since_restore: 6193.212616443634
  time_this_iter_s: 22.714927434921265
  time_total_s: 6193.212616443634
  timestamp: 1594100977
  timesteps_since_restore: 2510000
  timesteps_this_iter: 10000
  timesteps_total: 2510000
  training_iteration: 251
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 29.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=13557], 6193 s, 251 iter, 2510000 ts, 1.14e+03 rew

agent-1: 132.0
agent-2: 136.0
agent-3: 149.0
agent-4: 136.0
agent-5: 103.0
agent-6: 137.0
agent-7: 107.0
agent-8: 134.0
agent-9: 139.0
agent-10: 133.0
Sum Reward: 1306.0
Avg Reward: 130.6
Min Reward: 103.0
Max Reward: 149.0
Gini Coefficient: 0.05160796324655437
20:20 Ratio: 1.3714285714285714
Max-min Ratio: 1.4466019417475728
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_01-50-04
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1547.0
  episode_reward_mean: 1142.67
  episode_reward_min: 841.0
  episodes_this_iter: 1
  episodes_total: 251
  experiment_id: a3942a9886f24694ab1b58ca8d1ab856
  hostname: gpu006
  info:
    apply_time_ms: 2.852
    dispatch_time_ms: 7.564
    learner:
      cur_lr: 0.0011928339954465628
      grad_gnorm: 2.8875064849853516
      policy_entropy: 100.72635650634766
      policy_loss: 1.0661017894744873
      var_gnorm: 48.378013610839844
      vf_explained_var: 0.966507077217102
      vf_loss: 0.004984551575034857
    num_steps_sampled: 2520000
    num_steps_trained: 2520000
    wait_time_ms: 258.879
  iterations_since_restore: 252
  node_ip: 172.17.8.6
  num_metric_batches_dropped: 0
  pid: 13557
  policy_reward_mean: {}
  time_since_restore: 6219.60585474968
  time_this_iter_s: 26.393238306045532
  time_total_s: 6219.60585474968
  timestamp: 1594101004
  timesteps_since_restore: 2520000
  timesteps_this_iter: 10000
  timesteps_total: 2520000
  training_iteration: 252
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 29.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=13557], 6219 s, 252 iter, 2520000 ts, 1.14e+03 rew

agent-1: 104.0
agent-2: 78.0
agent-3: 86.0
agent-4: 100.0
agent-5: 100.0
agent-6: 104.0
agent-7: 103.0
agent-8: 121.0
agent-9: 105.0
agent-10: 59.0
Sum Reward: 960.0
Avg Reward: 96.0
Min Reward: 59.0
Max Reward: 121.0
Gini Coefficient: 0.08875
20:20 Ratio: 1.6496350364963503
Max-min Ratio: 2.0508474576271185
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_01-50-27
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1547.0
  episode_reward_mean: 1139.6
  episode_reward_min: 841.0
  episodes_this_iter: 1
  episodes_total: 252
  experiment_id: a3942a9886f24694ab1b58ca8d1ab856
  hostname: gpu006
  info:
    apply_time_ms: 2.837
    dispatch_time_ms: 6.626
    learner:
      cur_lr: 0.0011921679833903909
      grad_gnorm: 39.999996185302734
      policy_entropy: 62.06106948852539
      policy_loss: 6.0141801834106445
      var_gnorm: 48.515625
      vf_explained_var: 0.25245195627212524
      vf_loss: 100.06782531738281
    num_steps_sampled: 2530000
    num_steps_trained: 2530000
    wait_time_ms: 251.572
  iterations_since_restore: 253
  node_ip: 172.17.8.6
  num_metric_batches_dropped: 0
  pid: 13557
  policy_reward_mean: {}
  time_since_restore: 6242.5825362205505
  time_this_iter_s: 22.97668147087097
  time_total_s: 6242.5825362205505
  timestamp: 1594101027
  timesteps_since_restore: 2530000
  timesteps_this_iter: 10000
  timesteps_total: 2530000
  training_iteration: 253
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 29.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=13557], 6242 s, 253 iter, 2530000 ts, 1.14e+03 rew

agent-1: 111.0
agent-2: 127.0
agent-3: 108.0
agent-4: 123.0
agent-5: 120.0
agent-6: 129.0
agent-7: 113.0
agent-8: 106.0
agent-9: 113.0
agent-10: 80.0
Sum Reward: 1130.0
Avg Reward: 113.0
Min Reward: 80.0
Max Reward: 129.0
Gini Coefficient: 0.061061946902654866
20:20 Ratio: 1.3763440860215055
Max-min Ratio: 1.6125
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_01-50-53
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1547.0
  episode_reward_mean: 1139.95
  episode_reward_min: 841.0
  episodes_this_iter: 1
  episodes_total: 253
  experiment_id: a3942a9886f24694ab1b58ca8d1ab856
  hostname: gpu006
  info:
    apply_time_ms: 2.896
    dispatch_time_ms: 7.12
    learner:
      cur_lr: 0.001191501971334219
      grad_gnorm: 40.0
      policy_entropy: 28.751567840576172
      policy_loss: 31.336835861206055
      var_gnorm: 48.55897903442383
      vf_explained_var: 0.20487111806869507
      vf_loss: 76.28302001953125
    num_steps_sampled: 2540000
    num_steps_trained: 2540000
    wait_time_ms: 220.952
  iterations_since_restore: 254
  node_ip: 172.17.8.6
  num_metric_batches_dropped: 0
  pid: 13557
  policy_reward_mean: {}
  time_since_restore: 6268.4613881111145
  time_this_iter_s: 25.878851890563965
  time_total_s: 6268.4613881111145
  timestamp: 1594101053
  timesteps_since_restore: 2540000
  timesteps_this_iter: 10000
  timesteps_total: 2540000
  training_iteration: 254
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 29.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=13557], 6268 s, 254 iter, 2540000 ts, 1.14e+03 rew

agent-1: 90.0
agent-2: 90.0
agent-3: 108.0
agent-4: 86.0
agent-5: 117.0
agent-6: 111.0
agent-7: 98.0
agent-8: 108.0
agent-9: 80.0
agent-10: 98.0
Sum Reward: 986.0
Avg Reward: 98.6
Min Reward: 80.0
Max Reward: 117.0
Gini Coefficient: 0.06612576064908722
20:20 Ratio: 1.3734939759036144
Max-min Ratio: 1.4625
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_01-51-17
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1547.0
  episode_reward_mean: 1135.23
  episode_reward_min: 841.0
  episodes_this_iter: 1
  episodes_total: 254
  experiment_id: a3942a9886f24694ab1b58ca8d1ab856
  hostname: gpu006
  info:
    apply_time_ms: 2.547
    dispatch_time_ms: 5.963
    learner:
      cur_lr: 0.001190835959278047
      grad_gnorm: 39.9999885559082
      policy_entropy: 106.67598724365234
      policy_loss: -1.6482739448547363
      var_gnorm: 48.60786437988281
      vf_explained_var: 0.8036434650421143
      vf_loss: 5.153579235076904
    num_steps_sampled: 2550000
    num_steps_trained: 2550000
    wait_time_ms: 260.425
  iterations_since_restore: 255
  node_ip: 172.17.8.6
  num_metric_batches_dropped: 0
  pid: 13557
  policy_reward_mean: {}
  time_since_restore: 6292.439365148544
  time_this_iter_s: 23.97797703742981
  time_total_s: 6292.439365148544
  timestamp: 1594101077
  timesteps_since_restore: 2550000
  timesteps_this_iter: 10000
  timesteps_total: 2550000
  training_iteration: 255
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 29.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=13557], 6292 s, 255 iter, 2550000 ts, 1.14e+03 rew

agent-1: 87.0
agent-2: 86.0
agent-3: 102.0
agent-4: 81.0
agent-5: 95.0
agent-6: 79.0
agent-7: 80.0
agent-8: 70.0
agent-9: 81.0
agent-10: 102.0
Sum Reward: 863.0
Avg Reward: 86.3
Min Reward: 70.0
Max Reward: 102.0
Gini Coefficient: 0.06338354577056779
20:20 Ratio: 1.3691275167785235
Max-min Ratio: 1.457142857142857
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_01-51-43
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1547.0
  episode_reward_mean: 1132.87
  episode_reward_min: 841.0
  episodes_this_iter: 1
  episodes_total: 255
  experiment_id: a3942a9886f24694ab1b58ca8d1ab856
  hostname: gpu006
  info:
    apply_time_ms: 2.847
    dispatch_time_ms: 6.405
    learner:
      cur_lr: 0.0011901699472218752
      grad_gnorm: 4.5920796394348145
      policy_entropy: 112.30370330810547
      policy_loss: 2.0071377754211426
      var_gnorm: 48.627471923828125
      vf_explained_var: 0.7862962484359741
      vf_loss: 0.1418112963438034
    num_steps_sampled: 2560000
    num_steps_trained: 2560000
    wait_time_ms: 209.769
  iterations_since_restore: 256
  node_ip: 172.17.8.6
  num_metric_batches_dropped: 0
  pid: 13557
  policy_reward_mean: {}
  time_since_restore: 6318.441771745682
  time_this_iter_s: 26.00240659713745
  time_total_s: 6318.441771745682
  timestamp: 1594101103
  timesteps_since_restore: 2560000
  timesteps_this_iter: 10000
  timesteps_total: 2560000
  training_iteration: 256
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 29.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=13557], 6318 s, 256 iter, 2560000 ts, 1.13e+03 rew

agent-1: 102.0
agent-2: 86.0
agent-3: 66.0
agent-4: 92.0
agent-5: 92.0
agent-6: 93.0
agent-7: 87.0
agent-8: 96.0
agent-9: 71.0
agent-10: 85.0
Sum Reward: 870.0
Avg Reward: 87.0
Min Reward: 66.0
Max Reward: 102.0
Gini Coefficient: 0.06459770114942529
20:20 Ratio: 1.4452554744525548
Max-min Ratio: 1.5454545454545454
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_01-52-06
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1547.0
  episode_reward_mean: 1129.41
  episode_reward_min: 841.0
  episodes_this_iter: 1
  episodes_total: 256
  experiment_id: a3942a9886f24694ab1b58ca8d1ab856
  hostname: gpu006
  info:
    apply_time_ms: 2.749
    dispatch_time_ms: 6.313
    learner:
      cur_lr: 0.0011895040515810251
      grad_gnorm: 40.0
      policy_entropy: 46.54759979248047
      policy_loss: -6.495340824127197
      var_gnorm: 48.616981506347656
      vf_explained_var: 0.8764823079109192
      vf_loss: 104.76630401611328
    num_steps_sampled: 2570000
    num_steps_trained: 2570000
    wait_time_ms: 243.846
  iterations_since_restore: 257
  node_ip: 172.17.8.6
  num_metric_batches_dropped: 0
  pid: 13557
  policy_reward_mean: {}
  time_since_restore: 6341.482818603516
  time_this_iter_s: 23.041046857833862
  time_total_s: 6341.482818603516
  timestamp: 1594101126
  timesteps_since_restore: 2570000
  timesteps_this_iter: 10000
  timesteps_total: 2570000
  training_iteration: 257
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 29.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=13557], 6341 s, 257 iter, 2570000 ts, 1.13e+03 rew

agent-1: 116.0
agent-2: 110.0
agent-3: 91.0
agent-4: 87.0
agent-5: 104.0
agent-6: 100.0
agent-7: 88.0
agent-8: 105.0
agent-9: 113.0
agent-10: 138.0
Sum Reward: 1052.0
Avg Reward: 105.2
Min Reward: 87.0
Max Reward: 138.0
Gini Coefficient: 0.07566539923954373
20:20 Ratio: 1.4514285714285715
Max-min Ratio: 1.5862068965517242
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_01-52-32
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1547.0
  episode_reward_mean: 1127.18
  episode_reward_min: 841.0
  episodes_this_iter: 1
  episodes_total: 257
  experiment_id: a3942a9886f24694ab1b58ca8d1ab856
  hostname: gpu006
  info:
    apply_time_ms: 3.088
    dispatch_time_ms: 8.741
    learner:
      cur_lr: 0.0011888380395248532
      grad_gnorm: 40.0
      policy_entropy: 28.827919006347656
      policy_loss: 18.469898223876953
      var_gnorm: 48.731361389160156
      vf_explained_var: 0.4834012985229492
      vf_loss: 49.971275329589844
    num_steps_sampled: 2580000
    num_steps_trained: 2580000
    wait_time_ms: 199.038
  iterations_since_restore: 258
  node_ip: 172.17.8.6
  num_metric_batches_dropped: 0
  pid: 13557
  policy_reward_mean: {}
  time_since_restore: 6367.301829338074
  time_this_iter_s: 25.819010734558105
  time_total_s: 6367.301829338074
  timestamp: 1594101152
  timesteps_since_restore: 2580000
  timesteps_this_iter: 10000
  timesteps_total: 2580000
  training_iteration: 258
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 29.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=13557], 6367 s, 258 iter, 2580000 ts, 1.13e+03 rew

agent-1: 100.0
agent-2: 111.0
agent-3: 123.0
agent-4: 114.0
agent-5: 84.0
agent-6: 108.0
agent-7: 119.0
agent-8: 125.0
agent-9: 117.0
agent-10: 112.0
Sum Reward: 1113.0
Avg Reward: 111.3
Min Reward: 84.0
Max Reward: 125.0
Gini Coefficient: 0.05435759209344115
20:20 Ratio: 1.3478260869565217
Max-min Ratio: 1.4880952380952381
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_01-52-55
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1547.0
  episode_reward_mean: 1126.47
  episode_reward_min: 841.0
  episodes_this_iter: 1
  episodes_total: 258
  experiment_id: a3942a9886f24694ab1b58ca8d1ab856
  hostname: gpu006
  info:
    apply_time_ms: 2.662
    dispatch_time_ms: 6.112
    learner:
      cur_lr: 0.0011881720274686813
      grad_gnorm: 39.99998474121094
      policy_entropy: 44.73079299926758
      policy_loss: 56.472412109375
      var_gnorm: 48.74768829345703
      vf_explained_var: 0.8703381419181824
      vf_loss: 184.5690155029297
    num_steps_sampled: 2590000
    num_steps_trained: 2590000
    wait_time_ms: 246.607
  iterations_since_restore: 259
  node_ip: 172.17.8.6
  num_metric_batches_dropped: 0
  pid: 13557
  policy_reward_mean: {}
  time_since_restore: 6390.069668769836
  time_this_iter_s: 22.767839431762695
  time_total_s: 6390.069668769836
  timestamp: 1594101175
  timesteps_since_restore: 2590000
  timesteps_this_iter: 10000
  timesteps_total: 2590000
  training_iteration: 259
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 29.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=13557], 6390 s, 259 iter, 2590000 ts, 1.13e+03 rew

agent-1: 80.0
agent-2: 169.0
agent-3: 121.0
agent-4: 116.0
agent-5: 119.0
agent-6: 126.0
agent-7: 132.0
agent-8: 113.0
agent-9: 118.0
agent-10: 118.0
Sum Reward: 1212.0
Avg Reward: 121.2
Min Reward: 80.0
Max Reward: 169.0
Gini Coefficient: 0.08201320132013201
20:20 Ratio: 1.5595854922279793
Max-min Ratio: 2.1125
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_01-53-21
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1547.0
  episode_reward_mean: 1127.53
  episode_reward_min: 841.0
  episodes_this_iter: 1
  episodes_total: 259
  experiment_id: a3942a9886f24694ab1b58ca8d1ab856
  hostname: gpu006
  info:
    apply_time_ms: 4.2
    dispatch_time_ms: 6.651
    learner:
      cur_lr: 0.0011875060154125094
      grad_gnorm: 2.0028185844421387
      policy_entropy: 107.06212615966797
      policy_loss: 1.1934924125671387
      var_gnorm: 48.852622985839844
      vf_explained_var: 0.9530761241912842
      vf_loss: 0.021050501614809036
    num_steps_sampled: 2600000
    num_steps_trained: 2600000
    wait_time_ms: 221.638
  iterations_since_restore: 260
  node_ip: 172.17.8.6
  num_metric_batches_dropped: 0
  pid: 13557
  policy_reward_mean: {}
  time_since_restore: 6415.993960618973
  time_this_iter_s: 25.924291849136353
  time_total_s: 6415.993960618973
  timestamp: 1594101201
  timesteps_since_restore: 2600000
  timesteps_this_iter: 10000
  timesteps_total: 2600000
  training_iteration: 260
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 29.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=13557], 6415 s, 260 iter, 2600000 ts, 1.13e+03 rew

agent-1: 91.0
agent-2: 115.0
agent-3: 87.0
agent-4: 115.0
agent-5: 111.0
agent-6: 115.0
agent-7: 105.0
agent-8: 132.0
agent-9: 101.0
agent-10: 94.0
Sum Reward: 1066.0
Avg Reward: 106.6
Min Reward: 87.0
Max Reward: 132.0
Gini Coefficient: 0.06810506566604127
20:20 Ratio: 1.3876404494382022
Max-min Ratio: 1.5172413793103448
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_01-53-44
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1547.0
  episode_reward_mean: 1127.29
  episode_reward_min: 841.0
  episodes_this_iter: 1
  episodes_total: 260
  experiment_id: a3942a9886f24694ab1b58ca8d1ab856
  hostname: gpu006
  info:
    apply_time_ms: 2.916
    dispatch_time_ms: 5.652
    learner:
      cur_lr: 0.0011868400033563375
      grad_gnorm: 2.6634442806243896
      policy_entropy: 110.79444122314453
      policy_loss: 1.1847991943359375
      var_gnorm: 48.916908264160156
      vf_explained_var: 0.000908195972442627
      vf_loss: 0.004204115830361843
    num_steps_sampled: 2610000
    num_steps_trained: 2610000
    wait_time_ms: 251.243
  iterations_since_restore: 261
  node_ip: 172.17.8.6
  num_metric_batches_dropped: 0
  pid: 13557
  policy_reward_mean: {}
  time_since_restore: 6439.435894489288
  time_this_iter_s: 23.44193387031555
  time_total_s: 6439.435894489288
  timestamp: 1594101224
  timesteps_since_restore: 2610000
  timesteps_this_iter: 10000
  timesteps_total: 2610000
  training_iteration: 261
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 29.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=13557], 6439 s, 261 iter, 2610000 ts, 1.13e+03 rew

agent-1: 91.0
agent-2: 85.0
agent-3: 86.0
agent-4: 94.0
agent-5: 104.0
agent-6: 92.0
agent-7: 93.0
agent-8: 88.0
agent-9: 97.0
agent-10: 82.0
Sum Reward: 912.0
Avg Reward: 91.2
Min Reward: 82.0
Max Reward: 104.0
Gini Coefficient: 0.03706140350877193
20:20 Ratio: 1.2035928143712575
Max-min Ratio: 1.2682926829268293
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_01-54-10
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1547.0
  episode_reward_mean: 1125.46
  episode_reward_min: 841.0
  episodes_this_iter: 1
  episodes_total: 261
  experiment_id: a3942a9886f24694ab1b58ca8d1ab856
  hostname: gpu006
  info:
    apply_time_ms: 2.592
    dispatch_time_ms: 6.104
    learner:
      cur_lr: 0.0011861739913001657
      grad_gnorm: 39.999996185302734
      policy_entropy: 89.67383575439453
      policy_loss: -3.889246940612793
      var_gnorm: 48.92322540283203
      vf_explained_var: -1.0
      vf_loss: 10.518129348754883
    num_steps_sampled: 2620000
    num_steps_trained: 2620000
    wait_time_ms: 209.55
  iterations_since_restore: 262
  node_ip: 172.17.8.6
  num_metric_batches_dropped: 0
  pid: 13557
  policy_reward_mean: {}
  time_since_restore: 6464.763773202896
  time_this_iter_s: 25.327878713607788
  time_total_s: 6464.763773202896
  timestamp: 1594101250
  timesteps_since_restore: 2620000
  timesteps_this_iter: 10000
  timesteps_total: 2620000
  training_iteration: 262
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 29.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=13557], 6464 s, 262 iter, 2620000 ts, 1.13e+03 rew

agent-1: 148.0
agent-2: 98.0
agent-3: 107.0
agent-4: 136.0
agent-5: 120.0
agent-6: 134.0
agent-7: 156.0
agent-8: 122.0
agent-9: 141.0
agent-10: 147.0
Sum Reward: 1309.0
Avg Reward: 130.9
Min Reward: 98.0
Max Reward: 156.0
Gini Coefficient: 0.07662337662337662
20:20 Ratio: 1.4829268292682927
Max-min Ratio: 1.5918367346938775
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_01-54-33
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1547.0
  episode_reward_mean: 1123.71
  episode_reward_min: 841.0
  episodes_this_iter: 1
  episodes_total: 262
  experiment_id: a3942a9886f24694ab1b58ca8d1ab856
  hostname: gpu006
  info:
    apply_time_ms: 3.0
    dispatch_time_ms: 8.049
    learner:
      cur_lr: 0.0011855079792439938
      grad_gnorm: 39.999996185302734
      policy_entropy: 66.00334167480469
      policy_loss: -23.84906768798828
      var_gnorm: 49.03300094604492
      vf_explained_var: -0.9116297960281372
      vf_loss: 176.79217529296875
    num_steps_sampled: 2630000
    num_steps_trained: 2630000
    wait_time_ms: 246.238
  iterations_since_restore: 263
  node_ip: 172.17.8.6
  num_metric_batches_dropped: 0
  pid: 13557
  policy_reward_mean: {}
  time_since_restore: 6488.351765394211
  time_this_iter_s: 23.587992191314697
  time_total_s: 6488.351765394211
  timestamp: 1594101273
  timesteps_since_restore: 2630000
  timesteps_this_iter: 10000
  timesteps_total: 2630000
  training_iteration: 263
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 29.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=13557], 6488 s, 263 iter, 2630000 ts, 1.12e+03 rew

agent-1: 124.0
agent-2: 120.0
agent-3: 133.0
agent-4: 109.0
agent-5: 143.0
agent-6: 102.0
agent-7: 93.0
agent-8: 87.0
agent-9: 131.0
agent-10: 121.0
Sum Reward: 1163.0
Avg Reward: 116.3
Min Reward: 87.0
Max Reward: 143.0
Gini Coefficient: 0.08383490971625107
20:20 Ratio: 1.5333333333333334
Max-min Ratio: 1.6436781609195403
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_01-54-59
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1547.0
  episode_reward_mean: 1122.31
  episode_reward_min: 841.0
  episodes_this_iter: 1
  episodes_total: 263
  experiment_id: a3942a9886f24694ab1b58ca8d1ab856
  hostname: gpu006
  info:
    apply_time_ms: 2.608
    dispatch_time_ms: 6.447
    learner:
      cur_lr: 0.0011848419671878219
      grad_gnorm: 31.048709869384766
      policy_entropy: 86.6645278930664
      policy_loss: -2.2780070304870605
      var_gnorm: 49.041481018066406
      vf_explained_var: -1.0
      vf_loss: 0.406821072101593
    num_steps_sampled: 2640000
    num_steps_trained: 2640000
    wait_time_ms: 212.261
  iterations_since_restore: 264
  node_ip: 172.17.8.6
  num_metric_batches_dropped: 0
  pid: 13557
  policy_reward_mean: {}
  time_since_restore: 6514.005797863007
  time_this_iter_s: 25.654032468795776
  time_total_s: 6514.005797863007
  timestamp: 1594101299
  timesteps_since_restore: 2640000
  timesteps_this_iter: 10000
  timesteps_total: 2640000
  training_iteration: 264
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 29.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=13557], 6514 s, 264 iter, 2640000 ts, 1.12e+03 rew

agent-1: 85.0
agent-2: 87.0
agent-3: 88.0
agent-4: 89.0
agent-5: 98.0
agent-6: 101.0
agent-7: 78.0
agent-8: 81.0
agent-9: 89.0
agent-10: 103.0
Sum Reward: 899.0
Avg Reward: 89.9
Min Reward: 78.0
Max Reward: 103.0
Gini Coefficient: 0.04860956618464961
20:20 Ratio: 1.2830188679245282
Max-min Ratio: 1.3205128205128205
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_01-55-22
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1547.0
  episode_reward_mean: 1118.72
  episode_reward_min: 841.0
  episodes_this_iter: 1
  episodes_total: 264
  experiment_id: a3942a9886f24694ab1b58ca8d1ab856
  hostname: gpu006
  info:
    apply_time_ms: 2.806
    dispatch_time_ms: 5.664
    learner:
      cur_lr: 0.00118417595513165
      grad_gnorm: 39.999996185302734
      policy_entropy: 43.71518325805664
      policy_loss: -2.3320600986480713
      var_gnorm: 49.10930633544922
      vf_explained_var: 0.2736509442329407
      vf_loss: 142.35572814941406
    num_steps_sampled: 2650000
    num_steps_trained: 2650000
    wait_time_ms: 242.268
  iterations_since_restore: 265
  node_ip: 172.17.8.6
  num_metric_batches_dropped: 0
  pid: 13557
  policy_reward_mean: {}
  time_since_restore: 6537.2074728012085
  time_this_iter_s: 23.201674938201904
  time_total_s: 6537.2074728012085
  timestamp: 1594101322
  timesteps_since_restore: 2650000
  timesteps_this_iter: 10000
  timesteps_total: 2650000
  training_iteration: 265
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 29.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=13557], 6537 s, 265 iter, 2650000 ts, 1.12e+03 rew

agent-1: 132.0
agent-2: 124.0
agent-3: 124.0
agent-4: 137.0
agent-5: 109.0
agent-6: 115.0
agent-7: 127.0
agent-8: 96.0
agent-9: 106.0
agent-10: 134.0
Sum Reward: 1204.0
Avg Reward: 120.4
Min Reward: 96.0
Max Reward: 137.0
Gini Coefficient: 0.05946843853820598
20:20 Ratio: 1.3415841584158417
Max-min Ratio: 1.4270833333333333
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_01-55-48
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1547.0
  episode_reward_mean: 1121.15
  episode_reward_min: 841.0
  episodes_this_iter: 1
  episodes_total: 265
  experiment_id: a3942a9886f24694ab1b58ca8d1ab856
  hostname: gpu006
  info:
    apply_time_ms: 3.185
    dispatch_time_ms: 6.415
    learner:
      cur_lr: 0.001183509943075478
      grad_gnorm: 3.8696112632751465
      policy_entropy: 73.56305694580078
      policy_loss: -0.7412109971046448
      var_gnorm: 49.185081481933594
      vf_explained_var: 0.9699957966804504
      vf_loss: 0.009442959912121296
    num_steps_sampled: 2660000
    num_steps_trained: 2660000
    wait_time_ms: 216.278
  iterations_since_restore: 266
  node_ip: 172.17.8.6
  num_metric_batches_dropped: 0
  pid: 13557
  policy_reward_mean: {}
  time_since_restore: 6562.703813314438
  time_this_iter_s: 25.49634051322937
  time_total_s: 6562.703813314438
  timestamp: 1594101348
  timesteps_since_restore: 2660000
  timesteps_this_iter: 10000
  timesteps_total: 2660000
  training_iteration: 266
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 29.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=13557], 6562 s, 266 iter, 2660000 ts, 1.12e+03 rew

agent-1: 106.0
agent-2: 108.0
agent-3: 103.0
agent-4: 76.0
agent-5: 96.0
agent-6: 105.0
agent-7: 82.0
agent-8: 101.0
agent-9: 91.0
agent-10: 113.0
Sum Reward: 981.0
Avg Reward: 98.1
Min Reward: 76.0
Max Reward: 113.0
Gini Coefficient: 0.06309887869520897
20:20 Ratio: 1.3987341772151898
Max-min Ratio: 1.486842105263158
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_01-56-10
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1547.0
  episode_reward_mean: 1120.48
  episode_reward_min: 841.0
  episodes_this_iter: 1
  episodes_total: 266
  experiment_id: a3942a9886f24694ab1b58ca8d1ab856
  hostname: gpu006
  info:
    apply_time_ms: 2.85
    dispatch_time_ms: 6.225
    learner:
      cur_lr: 0.001182844047434628
      grad_gnorm: 40.0
      policy_entropy: 25.51255989074707
      policy_loss: -1.109942078590393
      var_gnorm: 49.18311309814453
      vf_explained_var: 0.6981117725372314
      vf_loss: 220.3250274658203
    num_steps_sampled: 2670000
    num_steps_trained: 2670000
    wait_time_ms: 221.811
  iterations_since_restore: 267
  node_ip: 172.17.8.6
  num_metric_batches_dropped: 0
  pid: 13557
  policy_reward_mean: {}
  time_since_restore: 6585.111372947693
  time_this_iter_s: 22.407559633255005
  time_total_s: 6585.111372947693
  timestamp: 1594101370
  timesteps_since_restore: 2670000
  timesteps_this_iter: 10000
  timesteps_total: 2670000
  training_iteration: 267
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 29.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=13557], 6585 s, 267 iter, 2670000 ts, 1.12e+03 rew

agent-1: 156.0
agent-2: 173.0
agent-3: 119.0
agent-4: 97.0
agent-5: 145.0
agent-6: 134.0
agent-7: 153.0
agent-8: 134.0
agent-9: 130.0
agent-10: 125.0
Sum Reward: 1366.0
Avg Reward: 136.6
Min Reward: 97.0
Max Reward: 173.0
Gini Coefficient: 0.08257686676427525
20:20 Ratio: 1.5231481481481481
Max-min Ratio: 1.7835051546391754
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_01-56-35
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1547.0
  episode_reward_mean: 1121.8
  episode_reward_min: 841.0
  episodes_this_iter: 1
  episodes_total: 267
  experiment_id: a3942a9886f24694ab1b58ca8d1ab856
  hostname: gpu006
  info:
    apply_time_ms: 2.68
    dispatch_time_ms: 6.07
    learner:
      cur_lr: 0.0011821780353784561
      grad_gnorm: 40.0
      policy_entropy: 18.141847610473633
      policy_loss: 7.829494476318359
      var_gnorm: 49.21355056762695
      vf_explained_var: 0.19019341468811035
      vf_loss: 106.4650650024414
    num_steps_sampled: 2680000
    num_steps_trained: 2680000
    wait_time_ms: 227.176
  iterations_since_restore: 268
  node_ip: 172.17.8.6
  num_metric_batches_dropped: 0
  pid: 13557
  policy_reward_mean: {}
  time_since_restore: 6609.885656833649
  time_this_iter_s: 24.77428388595581
  time_total_s: 6609.885656833649
  timestamp: 1594101395
  timesteps_since_restore: 2680000
  timesteps_this_iter: 10000
  timesteps_total: 2680000
  training_iteration: 268
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 29.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=13557], 6609 s, 268 iter, 2680000 ts, 1.12e+03 rew

agent-1: 142.0
agent-2: 145.0
agent-3: 117.0
agent-4: 129.0
agent-5: 152.0
agent-6: 136.0
agent-7: 155.0
agent-8: 148.0
agent-9: 117.0
agent-10: 118.0
Sum Reward: 1359.0
Avg Reward: 135.9
Min Reward: 117.0
Max Reward: 155.0
Gini Coefficient: 0.058204562178072114
20:20 Ratio: 1.311965811965812
Max-min Ratio: 1.3247863247863247
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_01-56-58
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1547.0
  episode_reward_mean: 1123.39
  episode_reward_min: 841.0
  episodes_this_iter: 1
  episodes_total: 268
  experiment_id: a3942a9886f24694ab1b58ca8d1ab856
  hostname: gpu006
  info:
    apply_time_ms: 3.318
    dispatch_time_ms: 5.3
    learner:
      cur_lr: 0.0011815120233222842
      grad_gnorm: 40.00000762939453
      policy_entropy: 25.4298095703125
      policy_loss: -3.8358583450317383
      var_gnorm: 49.356868743896484
      vf_explained_var: 0.7336848974227905
      vf_loss: 90.38735961914062
    num_steps_sampled: 2690000
    num_steps_trained: 2690000
    wait_time_ms: 230.82
  iterations_since_restore: 269
  node_ip: 172.17.8.6
  num_metric_batches_dropped: 0
  pid: 13557
  policy_reward_mean: {}
  time_since_restore: 6633.190106868744
  time_this_iter_s: 23.304450035095215
  time_total_s: 6633.190106868744
  timestamp: 1594101418
  timesteps_since_restore: 2690000
  timesteps_this_iter: 10000
  timesteps_total: 2690000
  training_iteration: 269
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 29.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=13557], 6633 s, 269 iter, 2690000 ts, 1.12e+03 rew

agent-1: 130.0
agent-2: 111.0
agent-3: 103.0
agent-4: 118.0
agent-5: 83.0
agent-6: 121.0
agent-7: 119.0
agent-8: 106.0
agent-9: 122.0
agent-10: 116.0
Sum Reward: 1129.0
Avg Reward: 112.9
Min Reward: 83.0
Max Reward: 130.0
Gini Coefficient: 0.05819309123117803
20:20 Ratio: 1.3548387096774193
Max-min Ratio: 1.5662650602409638
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_01-57-23
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1547.0
  episode_reward_mean: 1120.53
  episode_reward_min: 841.0
  episodes_this_iter: 1
  episodes_total: 269
  experiment_id: a3942a9886f24694ab1b58ca8d1ab856
  hostname: gpu006
  info:
    apply_time_ms: 3.555
    dispatch_time_ms: 5.492
    learner:
      cur_lr: 0.0011808460112661123
      grad_gnorm: 40.0
      policy_entropy: 6.409228324890137
      policy_loss: 2.5638060569763184
      var_gnorm: 49.322547912597656
      vf_explained_var: 0.04689514636993408
      vf_loss: 132.29344177246094
    num_steps_sampled: 2700000
    num_steps_trained: 2700000
    wait_time_ms: 224.047
  iterations_since_restore: 270
  node_ip: 172.17.8.6
  num_metric_batches_dropped: 0
  pid: 13557
  policy_reward_mean: {}
  time_since_restore: 6657.576324701309
  time_this_iter_s: 24.386217832565308
  time_total_s: 6657.576324701309
  timestamp: 1594101443
  timesteps_since_restore: 2700000
  timesteps_this_iter: 10000
  timesteps_total: 2700000
  training_iteration: 270
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 29.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=13557], 6657 s, 270 iter, 2700000 ts, 1.12e+03 rew

agent-1: 136.0
agent-2: 114.0
agent-3: 98.0
agent-4: 124.0
agent-5: 91.0
agent-6: 139.0
agent-7: 159.0
agent-8: 142.0
agent-9: 147.0
agent-10: 115.0
Sum Reward: 1265.0
Avg Reward: 126.5
Min Reward: 91.0
Max Reward: 159.0
Gini Coefficient: 0.09320158102766798
20:20 Ratio: 1.619047619047619
Max-min Ratio: 1.7472527472527473
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_01-57-46
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1547.0
  episode_reward_mean: 1120.97
  episode_reward_min: 841.0
  episodes_this_iter: 1
  episodes_total: 270
  experiment_id: a3942a9886f24694ab1b58ca8d1ab856
  hostname: gpu006
  info:
    apply_time_ms: 3.156
    dispatch_time_ms: 6.528
    learner:
      cur_lr: 0.0011801799992099404
      grad_gnorm: 39.99997329711914
      policy_entropy: 40.21708679199219
      policy_loss: -5.714996814727783
      var_gnorm: 49.367374420166016
      vf_explained_var: 0.9226431250572205
      vf_loss: 51.2799186706543
    num_steps_sampled: 2710000
    num_steps_trained: 2710000
    wait_time_ms: 235.44
  iterations_since_restore: 271
  node_ip: 172.17.8.6
  num_metric_batches_dropped: 0
  pid: 13557
  policy_reward_mean: {}
  time_since_restore: 6680.665954113007
  time_this_iter_s: 23.089629411697388
  time_total_s: 6680.665954113007
  timestamp: 1594101466
  timesteps_since_restore: 2710000
  timesteps_this_iter: 10000
  timesteps_total: 2710000
  training_iteration: 271
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 29.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=13557], 6680 s, 271 iter, 2710000 ts, 1.12e+03 rew

agent-1: 106.0
agent-2: 140.0
agent-3: 118.0
agent-4: 111.0
agent-5: 130.0
agent-6: 164.0
agent-7: 130.0
agent-8: 106.0
agent-9: 125.0
agent-10: 149.0
Sum Reward: 1279.0
Avg Reward: 127.9
Min Reward: 106.0
Max Reward: 164.0
Gini Coefficient: 0.07888975762314308
20:20 Ratio: 1.4764150943396226
Max-min Ratio: 1.5471698113207548
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_01-58-11
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1547.0
  episode_reward_mean: 1122.53
  episode_reward_min: 841.0
  episodes_this_iter: 1
  episodes_total: 271
  experiment_id: a3942a9886f24694ab1b58ca8d1ab856
  hostname: gpu006
  info:
    apply_time_ms: 2.992
    dispatch_time_ms: 5.714
    learner:
      cur_lr: 0.0011795139871537685
      grad_gnorm: 15.292742729187012
      policy_entropy: 68.2780990600586
      policy_loss: -2.9601104259490967
      var_gnorm: 49.487937927246094
      vf_explained_var: -1.0
      vf_loss: 0.1747521162033081
    num_steps_sampled: 2720000
    num_steps_trained: 2720000
    wait_time_ms: 242.913
  iterations_since_restore: 272
  node_ip: 172.17.8.6
  num_metric_batches_dropped: 0
  pid: 13557
  policy_reward_mean: {}
  time_since_restore: 6705.437522888184
  time_this_iter_s: 24.771568775177002
  time_total_s: 6705.437522888184
  timestamp: 1594101491
  timesteps_since_restore: 2720000
  timesteps_this_iter: 10000
  timesteps_total: 2720000
  training_iteration: 272
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 29.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=13557], 6705 s, 272 iter, 2720000 ts, 1.12e+03 rew

agent-1: 166.0
agent-2: 115.0
agent-3: 117.0
agent-4: 121.0
agent-5: 139.0
agent-6: 134.0
agent-7: 94.0
agent-8: 119.0
agent-9: 105.0
agent-10: 100.0
Sum Reward: 1210.0
Avg Reward: 121.0
Min Reward: 94.0
Max Reward: 166.0
Gini Coefficient: 0.08975206611570248
20:20 Ratio: 1.5721649484536082
Max-min Ratio: 1.7659574468085106
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_01-58-35
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1547.0
  episode_reward_mean: 1121.25
  episode_reward_min: 841.0
  episodes_this_iter: 1
  episodes_total: 272
  experiment_id: a3942a9886f24694ab1b58ca8d1ab856
  hostname: gpu006
  info:
    apply_time_ms: 2.648
    dispatch_time_ms: 5.511
    learner:
      cur_lr: 0.0011788479750975966
      grad_gnorm: 7.033306121826172
      policy_entropy: 73.35750579833984
      policy_loss: -1.4406476020812988
      var_gnorm: 49.536903381347656
      vf_explained_var: 5.960464477539063e-08
      vf_loss: 0.02797778509557247
    num_steps_sampled: 2730000
    num_steps_trained: 2730000
    wait_time_ms: 258.26
  iterations_since_restore: 273
  node_ip: 172.17.8.6
  num_metric_batches_dropped: 0
  pid: 13557
  policy_reward_mean: {}
  time_since_restore: 6729.427043199539
  time_this_iter_s: 23.98952031135559
  time_total_s: 6729.427043199539
  timestamp: 1594101515
  timesteps_since_restore: 2730000
  timesteps_this_iter: 10000
  timesteps_total: 2730000
  training_iteration: 273
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 29.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=13557], 6729 s, 273 iter, 2730000 ts, 1.12e+03 rew

agent-1: 91.0
agent-2: 87.0
agent-3: 107.0
agent-4: 88.0
agent-5: 101.0
agent-6: 111.0
agent-7: 102.0
agent-8: 106.0
agent-9: 107.0
agent-10: 119.0
Sum Reward: 1019.0
Avg Reward: 101.9
Min Reward: 87.0
Max Reward: 119.0
Gini Coefficient: 0.05407262021589794
20:20 Ratio: 1.3142857142857143
Max-min Ratio: 1.367816091954023
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_01-59-00
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1547.0
  episode_reward_mean: 1123.02
  episode_reward_min: 841.0
  episodes_this_iter: 1
  episodes_total: 273
  experiment_id: a3942a9886f24694ab1b58ca8d1ab856
  hostname: gpu006
  info:
    apply_time_ms: 2.693
    dispatch_time_ms: 6.314
    learner:
      cur_lr: 0.0011781819630414248
      grad_gnorm: 40.000003814697266
      policy_entropy: 17.79185676574707
      policy_loss: -9.96649169921875
      var_gnorm: 49.56025314331055
      vf_explained_var: 0.42233651876449585
      vf_loss: 188.67820739746094
    num_steps_sampled: 2740000
    num_steps_trained: 2740000
    wait_time_ms: 224.063
  iterations_since_restore: 274
  node_ip: 172.17.8.6
  num_metric_batches_dropped: 0
  pid: 13557
  policy_reward_mean: {}
  time_since_restore: 6754.436505317688
  time_this_iter_s: 25.009462118148804
  time_total_s: 6754.436505317688
  timestamp: 1594101540
  timesteps_since_restore: 2740000
  timesteps_this_iter: 10000
  timesteps_total: 2740000
  training_iteration: 274
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 29.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=13557], 6754 s, 274 iter, 2740000 ts, 1.12e+03 rew

agent-1: 96.0
agent-2: 110.0
agent-3: 101.0
agent-4: 102.0
agent-5: 120.0
agent-6: 87.0
agent-7: 98.0
agent-8: 118.0
agent-9: 98.0
agent-10: 91.0
Sum Reward: 1021.0
Avg Reward: 102.1
Min Reward: 87.0
Max Reward: 120.0
Gini Coefficient: 0.05592556317335945
20:20 Ratio: 1.3370786516853932
Max-min Ratio: 1.3793103448275863
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_01-59-24
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1547.0
  episode_reward_mean: 1122.49
  episode_reward_min: 841.0
  episodes_this_iter: 1
  episodes_total: 274
  experiment_id: a3942a9886f24694ab1b58ca8d1ab856
  hostname: gpu006
  info:
    apply_time_ms: 2.681
    dispatch_time_ms: 6.835
    learner:
      cur_lr: 0.0011775159509852529
      grad_gnorm: 40.000003814697266
      policy_entropy: 37.58872985839844
      policy_loss: 6.113978862762451
      var_gnorm: 49.64500045776367
      vf_explained_var: 0.4597049951553345
      vf_loss: 158.32090759277344
    num_steps_sampled: 2750000
    num_steps_trained: 2750000
    wait_time_ms: 246.268
  iterations_since_restore: 275
  node_ip: 172.17.8.6
  num_metric_batches_dropped: 0
  pid: 13557
  policy_reward_mean: {}
  time_since_restore: 6778.849214792252
  time_this_iter_s: 24.4127094745636
  time_total_s: 6778.849214792252
  timestamp: 1594101564
  timesteps_since_restore: 2750000
  timesteps_this_iter: 10000
  timesteps_total: 2750000
  training_iteration: 275
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 29.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=13557], 6778 s, 275 iter, 2750000 ts, 1.12e+03 rew

agent-1: 114.0
agent-2: 97.0
agent-3: 67.0
agent-4: 86.0
agent-5: 104.0
agent-6: 109.0
agent-7: 102.0
agent-8: 88.0
agent-9: 91.0
agent-10: 90.0
Sum Reward: 948.0
Avg Reward: 94.8
Min Reward: 67.0
Max Reward: 114.0
Gini Coefficient: 0.07447257383966245
20:20 Ratio: 1.457516339869281
Max-min Ratio: 1.7014925373134329
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_01-59-49
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1547.0
  episode_reward_mean: 1120.78
  episode_reward_min: 841.0
  episodes_this_iter: 1
  episodes_total: 275
  experiment_id: a3942a9886f24694ab1b58ca8d1ab856
  hostname: gpu006
  info:
    apply_time_ms: 2.631
    dispatch_time_ms: 5.951
    learner:
      cur_lr: 0.0011768500553444028
      grad_gnorm: 40.0
      policy_entropy: 17.945369720458984
      policy_loss: 5.847306251525879
      var_gnorm: 49.64107131958008
      vf_explained_var: 0.1582445502281189
      vf_loss: 92.62986755371094
    num_steps_sampled: 2760000
    num_steps_trained: 2760000
    wait_time_ms: 218.012
  iterations_since_restore: 276
  node_ip: 172.17.8.6
  num_metric_batches_dropped: 0
  pid: 13557
  policy_reward_mean: {}
  time_since_restore: 6803.962999820709
  time_this_iter_s: 25.11378502845764
  time_total_s: 6803.962999820709
  timestamp: 1594101589
  timesteps_since_restore: 2760000
  timesteps_this_iter: 10000
  timesteps_total: 2760000
  training_iteration: 276
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 29.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=13557], 6803 s, 276 iter, 2760000 ts, 1.12e+03 rew

agent-1: 83.0
agent-2: 78.0
agent-3: 95.0
agent-4: 93.0
agent-5: 90.0
agent-6: 118.0
agent-7: 99.0
agent-8: 85.0
agent-9: 82.0
agent-10: 102.0
Sum Reward: 925.0
Avg Reward: 92.5
Min Reward: 78.0
Max Reward: 118.0
Gini Coefficient: 0.06627027027027027
20:20 Ratio: 1.375
Max-min Ratio: 1.5128205128205128
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_02-00-13
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1547.0
  episode_reward_mean: 1119.74
  episode_reward_min: 841.0
  episodes_this_iter: 1
  episodes_total: 276
  experiment_id: a3942a9886f24694ab1b58ca8d1ab856
  hostname: gpu006
  info:
    apply_time_ms: 2.747
    dispatch_time_ms: 6.24
    learner:
      cur_lr: 0.001176184043288231
      grad_gnorm: 19.58700180053711
      policy_entropy: 73.34162139892578
      policy_loss: -4.415750980377197
      var_gnorm: 49.68513488769531
      vf_explained_var: -1.0
      vf_loss: 0.31913596391677856
    num_steps_sampled: 2770000
    num_steps_trained: 2770000
    wait_time_ms: 240.54
  iterations_since_restore: 277
  node_ip: 172.17.8.6
  num_metric_batches_dropped: 0
  pid: 13557
  policy_reward_mean: {}
  time_since_restore: 6828.076345920563
  time_this_iter_s: 24.113346099853516
  time_total_s: 6828.076345920563
  timestamp: 1594101613
  timesteps_since_restore: 2770000
  timesteps_this_iter: 10000
  timesteps_total: 2770000
  training_iteration: 277
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 29.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=13557], 6828 s, 277 iter, 2770000 ts, 1.12e+03 rew

agent-1: 108.0
agent-2: 112.0
agent-3: 85.0
agent-4: 128.0
agent-5: 109.0
agent-6: 106.0
agent-7: 95.0
agent-8: 99.0
agent-9: 107.0
agent-10: 105.0
Sum Reward: 1054.0
Avg Reward: 105.4
Min Reward: 85.0
Max Reward: 128.0
Gini Coefficient: 0.053700189753320686
20:20 Ratio: 1.3333333333333333
Max-min Ratio: 1.5058823529411764
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_02-00-39
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1547.0
  episode_reward_mean: 1121.57
  episode_reward_min: 841.0
  episodes_this_iter: 1
  episodes_total: 277
  experiment_id: a3942a9886f24694ab1b58ca8d1ab856
  hostname: gpu006
  info:
    apply_time_ms: 2.616
    dispatch_time_ms: 5.895
    learner:
      cur_lr: 0.001175518031232059
      grad_gnorm: 39.999996185302734
      policy_entropy: 16.268465042114258
      policy_loss: 3.5203373432159424
      var_gnorm: 49.801246643066406
      vf_explained_var: 0.8126077651977539
      vf_loss: 235.00672912597656
    num_steps_sampled: 2780000
    num_steps_trained: 2780000
    wait_time_ms: 228.062
  iterations_since_restore: 278
  node_ip: 172.17.8.6
  num_metric_batches_dropped: 0
  pid: 13557
  policy_reward_mean: {}
  time_since_restore: 6853.3172817230225
  time_this_iter_s: 25.240935802459717
  time_total_s: 6853.3172817230225
  timestamp: 1594101639
  timesteps_since_restore: 2780000
  timesteps_this_iter: 10000
  timesteps_total: 2780000
  training_iteration: 278
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 29.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=13557], 6853 s, 278 iter, 2780000 ts, 1.12e+03 rew

agent-1: 91.0
agent-2: 93.0
agent-3: 92.0
agent-4: 99.0
agent-5: 91.0
agent-6: 110.0
agent-7: 119.0
agent-8: 77.0
agent-9: 93.0
agent-10: 97.0
Sum Reward: 962.0
Avg Reward: 96.2
Min Reward: 77.0
Max Reward: 119.0
Gini Coefficient: 0.05883575883575884
20:20 Ratio: 1.3630952380952381
Max-min Ratio: 1.5454545454545454
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_02-01-03
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1547.0
  episode_reward_mean: 1121.38
  episode_reward_min: 841.0
  episodes_this_iter: 1
  episodes_total: 278
  experiment_id: a3942a9886f24694ab1b58ca8d1ab856
  hostname: gpu006
  info:
    apply_time_ms: 2.837
    dispatch_time_ms: 6.297
    learner:
      cur_lr: 0.001174852019175887
      grad_gnorm: 12.896158218383789
      policy_entropy: 67.65609741210938
      policy_loss: -2.840100049972534
      var_gnorm: 49.838539123535156
      vf_explained_var: 0.9574509859085083
      vf_loss: 0.10253957659006119
    num_steps_sampled: 2790000
    num_steps_trained: 2790000
    wait_time_ms: 256.679
  iterations_since_restore: 279
  node_ip: 172.17.8.6
  num_metric_batches_dropped: 0
  pid: 13557
  policy_reward_mean: {}
  time_since_restore: 6877.563982009888
  time_this_iter_s: 24.246700286865234
  time_total_s: 6877.563982009888
  timestamp: 1594101663
  timesteps_since_restore: 2790000
  timesteps_this_iter: 10000
  timesteps_total: 2790000
  training_iteration: 279
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 29.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=13557], 6877 s, 279 iter, 2790000 ts, 1.12e+03 rew

agent-1: 104.0
agent-2: 107.0
agent-3: 74.0
agent-4: 112.0
agent-5: 96.0
agent-6: 90.0
agent-7: 110.0
agent-8: 99.0
agent-9: 103.0
agent-10: 112.0
Sum Reward: 1007.0
Avg Reward: 100.7
Min Reward: 74.0
Max Reward: 112.0
Gini Coefficient: 0.05868917576961271
20:20 Ratio: 1.3658536585365855
Max-min Ratio: 1.5135135135135136
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_02-01-28
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1547.0
  episode_reward_mean: 1121.25
  episode_reward_min: 841.0
  episodes_this_iter: 1
  episodes_total: 279
  experiment_id: a3942a9886f24694ab1b58ca8d1ab856
  hostname: gpu006
  info:
    apply_time_ms: 3.386
    dispatch_time_ms: 96.21
    learner:
      cur_lr: 0.0011741860071197152
      grad_gnorm: 7.421607971191406
      policy_entropy: 66.45625305175781
      policy_loss: -1.1188132762908936
      var_gnorm: 49.870643615722656
      vf_explained_var: 0.9832651019096375
      vf_loss: 0.0520542673766613
    num_steps_sampled: 2800000
    num_steps_trained: 2800000
    wait_time_ms: 164.862
  iterations_since_restore: 280
  node_ip: 172.17.8.6
  num_metric_batches_dropped: 0
  pid: 13557
  policy_reward_mean: {}
  time_since_restore: 6902.779691457748
  time_this_iter_s: 25.215709447860718
  time_total_s: 6902.779691457748
  timestamp: 1594101688
  timesteps_since_restore: 2800000
  timesteps_this_iter: 10000
  timesteps_total: 2800000
  training_iteration: 280
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 29.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=13557], 6902 s, 280 iter, 2800000 ts, 1.12e+03 rew

agent-1: 109.0
agent-2: 101.0
agent-3: 87.0
agent-4: 105.0
agent-5: 132.0
agent-6: 122.0
agent-7: 106.0
agent-8: 71.0
agent-9: 128.0
agent-10: 119.0
Sum Reward: 1080.0
Avg Reward: 108.0
Min Reward: 71.0
Max Reward: 132.0
Gini Coefficient: 0.09129629629629629
20:20 Ratio: 1.6455696202531647
Max-min Ratio: 1.8591549295774648
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_02-01-52
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1547.0
  episode_reward_mean: 1118.73
  episode_reward_min: 841.0
  episodes_this_iter: 1
  episodes_total: 280
  experiment_id: a3942a9886f24694ab1b58ca8d1ab856
  hostname: gpu006
  info:
    apply_time_ms: 3.705
    dispatch_time_ms: 6.726
    learner:
      cur_lr: 0.0011735199950635433
      grad_gnorm: 40.0
      policy_entropy: 27.038707733154297
      policy_loss: 24.704055786132812
      var_gnorm: 49.93651580810547
      vf_explained_var: -0.0048416852951049805
      vf_loss: 142.7685546875
    num_steps_sampled: 2810000
    num_steps_trained: 2810000
    wait_time_ms: 225.374
  iterations_since_restore: 281
  node_ip: 172.17.8.6
  num_metric_batches_dropped: 0
  pid: 13557
  policy_reward_mean: {}
  time_since_restore: 6926.421032190323
  time_this_iter_s: 23.641340732574463
  time_total_s: 6926.421032190323
  timestamp: 1594101712
  timesteps_since_restore: 2810000
  timesteps_this_iter: 10000
  timesteps_total: 2810000
  training_iteration: 281
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 29.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=13557], 6926 s, 281 iter, 2810000 ts, 1.12e+03 rew

agent-1: 117.0
agent-2: 121.0
agent-3: 145.0
agent-4: 125.0
agent-5: 143.0
agent-6: 115.0
agent-7: 117.0
agent-8: 125.0
agent-9: 117.0
agent-10: 121.0
Sum Reward: 1246.0
Avg Reward: 124.6
Min Reward: 115.0
Max Reward: 145.0
Gini Coefficient: 0.041412520064205455
20:20 Ratio: 1.2413793103448276
Max-min Ratio: 1.2608695652173914
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_02-02-17
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1547.0
  episode_reward_mean: 1119.39
  episode_reward_min: 841.0
  episodes_this_iter: 1
  episodes_total: 281
  experiment_id: a3942a9886f24694ab1b58ca8d1ab856
  hostname: gpu006
  info:
    apply_time_ms: 2.712
    dispatch_time_ms: 5.947
    learner:
      cur_lr: 0.0011728539830073714
      grad_gnorm: 40.000003814697266
      policy_entropy: 20.364421844482422
      policy_loss: -37.52157211303711
      var_gnorm: 50.006492614746094
      vf_explained_var: 0.4836769104003906
      vf_loss: 236.87828063964844
    num_steps_sampled: 2820000
    num_steps_trained: 2820000
    wait_time_ms: 228.685
  iterations_since_restore: 282
  node_ip: 172.17.8.6
  num_metric_batches_dropped: 0
  pid: 13557
  policy_reward_mean: {}
  time_since_restore: 6951.343967199326
  time_this_iter_s: 24.922935009002686
  time_total_s: 6951.343967199326
  timestamp: 1594101737
  timesteps_since_restore: 2820000
  timesteps_this_iter: 10000
  timesteps_total: 2820000
  training_iteration: 282
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 29.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=13557], 6951 s, 282 iter, 2820000 ts, 1.12e+03 rew

agent-1: 121.0
agent-2: 122.0
agent-3: 104.0
agent-4: 104.0
agent-5: 138.0
agent-6: 118.0
agent-7: 108.0
agent-8: 126.0
agent-9: 143.0
agent-10: 109.0
Sum Reward: 1193.0
Avg Reward: 119.3
Min Reward: 104.0
Max Reward: 143.0
Gini Coefficient: 0.06043587594300084
20:20 Ratio: 1.3509615384615385
Max-min Ratio: 1.375
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_02-02-41
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1547.0
  episode_reward_mean: 1117.73
  episode_reward_min: 841.0
  episodes_this_iter: 1
  episodes_total: 282
  experiment_id: a3942a9886f24694ab1b58ca8d1ab856
  hostname: gpu006
  info:
    apply_time_ms: 2.751
    dispatch_time_ms: 6.334
    learner:
      cur_lr: 0.0011721879709511995
      grad_gnorm: 39.999996185302734
      policy_entropy: 37.28092956542969
      policy_loss: -43.999996185302734
      var_gnorm: 50.09614181518555
      vf_explained_var: 0.8085691332817078
      vf_loss: 197.78292846679688
    num_steps_sampled: 2830000
    num_steps_trained: 2830000
    wait_time_ms: 230.325
  iterations_since_restore: 283
  node_ip: 172.17.8.6
  num_metric_batches_dropped: 0
  pid: 13557
  policy_reward_mean: {}
  time_since_restore: 6975.826721906662
  time_this_iter_s: 24.482754707336426
  time_total_s: 6975.826721906662
  timestamp: 1594101761
  timesteps_since_restore: 2830000
  timesteps_this_iter: 10000
  timesteps_total: 2830000
  training_iteration: 283
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 29.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=13557], 6975 s, 283 iter, 2830000 ts, 1.12e+03 rew

agent-1: 80.0
agent-2: 90.0
agent-3: 104.0
agent-4: 91.0
agent-5: 94.0
agent-6: 87.0
agent-7: 80.0
agent-8: 110.0
agent-9: 101.0
agent-10: 89.0
Sum Reward: 926.0
Avg Reward: 92.6
Min Reward: 80.0
Max Reward: 110.0
Gini Coefficient: 0.05658747300215983
20:20 Ratio: 1.3375
Max-min Ratio: 1.375
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_02-03-06
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1547.0
  episode_reward_mean: 1117.49
  episode_reward_min: 841.0
  episodes_this_iter: 1
  episodes_total: 283
  experiment_id: a3942a9886f24694ab1b58ca8d1ab856
  hostname: gpu006
  info:
    apply_time_ms: 2.613
    dispatch_time_ms: 5.542
    learner:
      cur_lr: 0.0011715219588950276
      grad_gnorm: 39.9999885559082
      policy_entropy: 64.59918212890625
      policy_loss: -3.844973564147949
      var_gnorm: 50.09822463989258
      vf_explained_var: 0.3434077501296997
      vf_loss: 10.235776901245117
    num_steps_sampled: 2840000
    num_steps_trained: 2840000
    wait_time_ms: 232.942
  iterations_since_restore: 284
  node_ip: 172.17.8.6
  num_metric_batches_dropped: 0
  pid: 13557
  policy_reward_mean: {}
  time_since_restore: 7000.47674036026
  time_this_iter_s: 24.650018453598022
  time_total_s: 7000.47674036026
  timestamp: 1594101786
  timesteps_since_restore: 2840000
  timesteps_this_iter: 10000
  timesteps_total: 2840000
  training_iteration: 284
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 29.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=13557], 7000 s, 284 iter, 2840000 ts, 1.12e+03 rew

agent-1: 137.0
agent-2: 124.0
agent-3: 113.0
agent-4: 123.0
agent-5: 101.0
agent-6: 151.0
agent-7: 135.0
agent-8: 112.0
agent-9: 148.0
agent-10: 154.0
Sum Reward: 1298.0
Avg Reward: 129.8
Min Reward: 101.0
Max Reward: 154.0
Gini Coefficient: 0.07534668721109399
20:20 Ratio: 1.431924882629108
Max-min Ratio: 1.5247524752475248
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_02-03-29
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1547.0
  episode_reward_mean: 1120.32
  episode_reward_min: 841.0
  episodes_this_iter: 1
  episodes_total: 284
  experiment_id: a3942a9886f24694ab1b58ca8d1ab856
  hostname: gpu006
  info:
    apply_time_ms: 3.014
    dispatch_time_ms: 7.229
    learner:
      cur_lr: 0.0011708559468388557
      grad_gnorm: 40.00002670288086
      policy_entropy: 34.05117416381836
      policy_loss: 2.322544574737549
      var_gnorm: 50.191036224365234
      vf_explained_var: 0.794437050819397
      vf_loss: 190.60801696777344
    num_steps_sampled: 2850000
    num_steps_trained: 2850000
    wait_time_ms: 233.484
  iterations_since_restore: 285
  node_ip: 172.17.8.6
  num_metric_batches_dropped: 0
  pid: 13557
  policy_reward_mean: {}
  time_since_restore: 7023.497345209122
  time_this_iter_s: 23.020604848861694
  time_total_s: 7023.497345209122
  timestamp: 1594101809
  timesteps_since_restore: 2850000
  timesteps_this_iter: 10000
  timesteps_total: 2850000
  training_iteration: 285
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 29.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=13557], 7023 s, 285 iter, 2850000 ts, 1.12e+03 rew

agent-1: 179.0
agent-2: 152.0
agent-3: 125.0
agent-4: 141.0
agent-5: 152.0
agent-6: 134.0
agent-7: 152.0
agent-8: 126.0
agent-9: 169.0
agent-10: 137.0
Sum Reward: 1467.0
Avg Reward: 146.7
Min Reward: 125.0
Max Reward: 179.0
Gini Coefficient: 0.06359918200408998
20:20 Ratio: 1.3864541832669324
Max-min Ratio: 1.432
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_02-03-54
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1547.0
  episode_reward_mean: 1123.06
  episode_reward_min: 841.0
  episodes_this_iter: 1
  episodes_total: 285
  experiment_id: a3942a9886f24694ab1b58ca8d1ab856
  hostname: gpu006
  info:
    apply_time_ms: 2.732
    dispatch_time_ms: 6.662
    learner:
      cur_lr: 0.0011701900511980057
      grad_gnorm: 40.00001525878906
      policy_entropy: 18.83341407775879
      policy_loss: -5.6001667976379395
      var_gnorm: 50.294708251953125
      vf_explained_var: 0.8776914477348328
      vf_loss: 58.079994201660156
    num_steps_sampled: 2860000
    num_steps_trained: 2860000
    wait_time_ms: 224.649
  iterations_since_restore: 286
  node_ip: 172.17.8.6
  num_metric_batches_dropped: 0
  pid: 13557
  policy_reward_mean: {}
  time_since_restore: 7048.518351554871
  time_this_iter_s: 25.0210063457489
  time_total_s: 7048.518351554871
  timestamp: 1594101834
  timesteps_since_restore: 2860000
  timesteps_this_iter: 10000
  timesteps_total: 2860000
  training_iteration: 286
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 29.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=13557], 7048 s, 286 iter, 2860000 ts, 1.12e+03 rew

agent-1: 133.0
agent-2: 105.0
agent-3: 88.0
agent-4: 94.0
agent-5: 95.0
agent-6: 100.0
agent-7: 100.0
agent-8: 85.0
agent-9: 86.0
agent-10: 107.0
Sum Reward: 993.0
Avg Reward: 99.3
Min Reward: 85.0
Max Reward: 133.0
Gini Coefficient: 0.06918429003021148
20:20 Ratio: 1.4035087719298245
Max-min Ratio: 1.5647058823529412
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_02-04-18
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1547.0
  episode_reward_mean: 1120.12
  episode_reward_min: 841.0
  episodes_this_iter: 1
  episodes_total: 286
  experiment_id: a3942a9886f24694ab1b58ca8d1ab856
  hostname: gpu006
  info:
    apply_time_ms: 2.777
    dispatch_time_ms: 6.13
    learner:
      cur_lr: 0.0011695240391418338
      grad_gnorm: 39.999996185302734
      policy_entropy: 20.988496780395508
      policy_loss: 32.37481689453125
      var_gnorm: 50.35906219482422
      vf_explained_var: 0.4653405547142029
      vf_loss: 128.6957550048828
    num_steps_sampled: 2870000
    num_steps_trained: 2870000
    wait_time_ms: 220.986
  iterations_since_restore: 287
  node_ip: 172.17.8.6
  num_metric_batches_dropped: 0
  pid: 13557
  policy_reward_mean: {}
  time_since_restore: 7072.256476163864
  time_this_iter_s: 23.73812460899353
  time_total_s: 7072.256476163864
  timestamp: 1594101858
  timesteps_since_restore: 2870000
  timesteps_this_iter: 10000
  timesteps_total: 2870000
  training_iteration: 287
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 29.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=13557], 7072 s, 287 iter, 2870000 ts, 1.12e+03 rew

agent-1: 94.0
agent-2: 138.0
agent-3: 110.0
agent-4: 117.0
agent-5: 130.0
agent-6: 148.0
agent-7: 119.0
agent-8: 85.0
agent-9: 111.0
agent-10: 137.0
Sum Reward: 1189.0
Avg Reward: 118.9
Min Reward: 85.0
Max Reward: 148.0
Gini Coefficient: 0.08990748528174937
20:20 Ratio: 1.5977653631284916
Max-min Ratio: 1.7411764705882353
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_02-04-40
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1547.0
  episode_reward_mean: 1119.79
  episode_reward_min: 841.0
  episodes_this_iter: 1
  episodes_total: 287
  experiment_id: a3942a9886f24694ab1b58ca8d1ab856
  hostname: gpu006
  info:
    apply_time_ms: 2.816
    dispatch_time_ms: 6.795
    learner:
      cur_lr: 0.0011688580270856619
      grad_gnorm: 40.0
      policy_entropy: 30.662805557250977
      policy_loss: 27.899456024169922
      var_gnorm: 50.394065856933594
      vf_explained_var: 0.416908860206604
      vf_loss: 75.29222106933594
    num_steps_sampled: 2880000
    num_steps_trained: 2880000
    wait_time_ms: 183.038
  iterations_since_restore: 288
  node_ip: 172.17.8.6
  num_metric_batches_dropped: 0
  pid: 13557
  policy_reward_mean: {}
  time_since_restore: 7094.245445251465
  time_this_iter_s: 21.988969087600708
  time_total_s: 7094.245445251465
  timestamp: 1594101880
  timesteps_since_restore: 2880000
  timesteps_this_iter: 10000
  timesteps_total: 2880000
  training_iteration: 288
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 29.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=13557], 7094 s, 288 iter, 2880000 ts, 1.12e+03 rew

agent-1: 163.0
agent-2: 156.0
agent-3: 151.0
agent-4: 155.0
agent-5: 143.0
agent-6: 140.0
agent-7: 155.0
agent-8: 146.0
agent-9: 151.0
agent-10: 117.0
Sum Reward: 1477.0
Avg Reward: 147.7
Min Reward: 117.0
Max Reward: 163.0
Gini Coefficient: 0.04150304671631686
20:20 Ratio: 1.2412451361867705
Max-min Ratio: 1.393162393162393
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_02-05-01
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1547.0
  episode_reward_mean: 1122.21
  episode_reward_min: 841.0
  episodes_this_iter: 1
  episodes_total: 288
  experiment_id: a3942a9886f24694ab1b58ca8d1ab856
  hostname: gpu006
  info:
    apply_time_ms: 3.728
    dispatch_time_ms: 6.004
    learner:
      cur_lr: 0.00116819201502949
      grad_gnorm: 40.000003814697266
      policy_entropy: 59.81756591796875
      policy_loss: -2.4028801918029785
      var_gnorm: 50.45746612548828
      vf_explained_var: 0.9368630051612854
      vf_loss: 36.82651901245117
    num_steps_sampled: 2890000
    num_steps_trained: 2890000
    wait_time_ms: 221.714
  iterations_since_restore: 289
  node_ip: 172.17.8.6
  num_metric_batches_dropped: 0
  pid: 13557
  policy_reward_mean: {}
  time_since_restore: 7115.413076162338
  time_this_iter_s: 21.167630910873413
  time_total_s: 7115.413076162338
  timestamp: 1594101901
  timesteps_since_restore: 2890000
  timesteps_this_iter: 10000
  timesteps_total: 2890000
  training_iteration: 289
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 29.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=13557], 7115 s, 289 iter, 2890000 ts, 1.12e+03 rew

agent-1: 163.0
agent-2: 150.0
agent-3: 130.0
agent-4: 146.0
agent-5: 153.0
agent-6: 151.0
agent-7: 177.0
agent-8: 126.0
agent-9: 182.0
agent-10: 183.0
Sum Reward: 1561.0
Avg Reward: 156.1
Min Reward: 126.0
Max Reward: 183.0
Gini Coefficient: 0.06873798846893017
20:20 Ratio: 1.42578125
Max-min Ratio: 1.4523809523809523
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_02-05-23
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1561.0
  episode_reward_mean: 1126.84
  episode_reward_min: 841.0
  episodes_this_iter: 1
  episodes_total: 289
  experiment_id: a3942a9886f24694ab1b58ca8d1ab856
  hostname: gpu006
  info:
    apply_time_ms: 2.587
    dispatch_time_ms: 6.81
    learner:
      cur_lr: 0.001167526002973318
      grad_gnorm: 39.99997329711914
      policy_entropy: 46.05232238769531
      policy_loss: -19.215490341186523
      var_gnorm: 50.48384094238281
      vf_explained_var: 0.7012649774551392
      vf_loss: 47.99615478515625
    num_steps_sampled: 2900000
    num_steps_trained: 2900000
    wait_time_ms: 206.955
  iterations_since_restore: 290
  node_ip: 172.17.8.6
  num_metric_batches_dropped: 0
  pid: 13557
  policy_reward_mean: {}
  time_since_restore: 7137.645181179047
  time_this_iter_s: 22.232105016708374
  time_total_s: 7137.645181179047
  timestamp: 1594101923
  timesteps_since_restore: 2900000
  timesteps_this_iter: 10000
  timesteps_total: 2900000
  training_iteration: 290
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 29.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=13557], 7137 s, 290 iter, 2900000 ts, 1.13e+03 rew

agent-1: 191.0
agent-2: 226.0
agent-3: 178.0
agent-4: 168.0
agent-5: 147.0
agent-6: 148.0
agent-7: 159.0
agent-8: 159.0
agent-9: 165.0
agent-10: 161.0
Sum Reward: 1702.0
Avg Reward: 170.2
Min Reward: 147.0
Max Reward: 226.0
Gini Coefficient: 0.06686251468860165
20:20 Ratio: 1.4135593220338982
Max-min Ratio: 1.5374149659863945
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_02-05-45
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1702.0
  episode_reward_mean: 1130.32
  episode_reward_min: 841.0
  episodes_this_iter: 1
  episodes_total: 290
  experiment_id: a3942a9886f24694ab1b58ca8d1ab856
  hostname: gpu006
  info:
    apply_time_ms: 2.678
    dispatch_time_ms: 6.553
    learner:
      cur_lr: 0.0011668599909171462
      grad_gnorm: 39.999996185302734
      policy_entropy: 40.64716339111328
      policy_loss: -29.74224853515625
      var_gnorm: 50.39020919799805
      vf_explained_var: 0.40243393182754517
      vf_loss: 106.28059387207031
    num_steps_sampled: 2910000
    num_steps_trained: 2910000
    wait_time_ms: 217.563
  iterations_since_restore: 291
  node_ip: 172.17.8.6
  num_metric_batches_dropped: 0
  pid: 13557
  policy_reward_mean: {}
  time_since_restore: 7159.41490483284
  time_this_iter_s: 21.769723653793335
  time_total_s: 7159.41490483284
  timestamp: 1594101945
  timesteps_since_restore: 2910000
  timesteps_this_iter: 10000
  timesteps_total: 2910000
  training_iteration: 291
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 29.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=13557], 7159 s, 291 iter, 2910000 ts, 1.13e+03 rew

agent-1: 133.0
agent-2: 127.0
agent-3: 141.0
agent-4: 130.0
agent-5: 133.0
agent-6: 141.0
agent-7: 153.0
agent-8: 141.0
agent-9: 155.0
agent-10: 138.0
Sum Reward: 1392.0
Avg Reward: 139.2
Min Reward: 127.0
Max Reward: 155.0
Gini Coefficient: 0.034482758620689655
20:20 Ratio: 1.198443579766537
Max-min Ratio: 1.220472440944882
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_02-06-09
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1702.0
  episode_reward_mean: 1131.75
  episode_reward_min: 841.0
  episodes_this_iter: 1
  episodes_total: 291
  experiment_id: a3942a9886f24694ab1b58ca8d1ab856
  hostname: gpu006
  info:
    apply_time_ms: 2.707
    dispatch_time_ms: 7.296
    learner:
      cur_lr: 0.0011661939788609743
      grad_gnorm: 40.0
      policy_entropy: 54.77985763549805
      policy_loss: -10.017462730407715
      var_gnorm: 50.47865676879883
      vf_explained_var: -0.4773263931274414
      vf_loss: 20.458362579345703
    num_steps_sampled: 2920000
    num_steps_trained: 2920000
    wait_time_ms: 247.729
  iterations_since_restore: 292
  node_ip: 172.17.8.6
  num_metric_batches_dropped: 0
  pid: 13557
  policy_reward_mean: {}
  time_since_restore: 7183.53627705574
  time_this_iter_s: 24.12137222290039
  time_total_s: 7183.53627705574
  timestamp: 1594101969
  timesteps_since_restore: 2920000
  timesteps_this_iter: 10000
  timesteps_total: 2920000
  training_iteration: 292
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 29.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=13557], 7183 s, 292 iter, 2920000 ts, 1.13e+03 rew

agent-1: 143.0
agent-2: 146.0
agent-3: 134.0
agent-4: 119.0
agent-5: 155.0
agent-6: 162.0
agent-7: 130.0
agent-8: 132.0
agent-9: 161.0
agent-10: 135.0
Sum Reward: 1417.0
Avg Reward: 141.7
Min Reward: 119.0
Max Reward: 162.0
Gini Coefficient: 0.05384615384615385
20:20 Ratio: 1.2971887550200802
Max-min Ratio: 1.361344537815126
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_02-06-32
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1702.0
  episode_reward_mean: 1131.71
  episode_reward_min: 841.0
  episodes_this_iter: 1
  episodes_total: 292
  experiment_id: a3942a9886f24694ab1b58ca8d1ab856
  hostname: gpu006
  info:
    apply_time_ms: 2.699
    dispatch_time_ms: 6.456
    learner:
      cur_lr: 0.0011655279668048024
      grad_gnorm: 40.00002670288086
      policy_entropy: 46.38585662841797
      policy_loss: -24.67967987060547
      var_gnorm: 50.493831634521484
      vf_explained_var: 0.6432290077209473
      vf_loss: 186.59645080566406
    num_steps_sampled: 2930000
    num_steps_trained: 2930000
    wait_time_ms: 229.37
  iterations_since_restore: 293
  node_ip: 172.17.8.6
  num_metric_batches_dropped: 0
  pid: 13557
  policy_reward_mean: {}
  time_since_restore: 7206.331639051437
  time_this_iter_s: 22.79536199569702
  time_total_s: 7206.331639051437
  timestamp: 1594101992
  timesteps_since_restore: 2930000
  timesteps_this_iter: 10000
  timesteps_total: 2930000
  training_iteration: 293
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 29.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=13557], 7206 s, 293 iter, 2930000 ts, 1.13e+03 rew

agent-1: 126.0
agent-2: 134.0
agent-3: 114.0
agent-4: 132.0
agent-5: 120.0
agent-6: 140.0
agent-7: 112.0
agent-8: 121.0
agent-9: 129.0
agent-10: 164.0
Sum Reward: 1292.0
Avg Reward: 129.2
Min Reward: 112.0
Max Reward: 164.0
Gini Coefficient: 0.05851393188854489
20:20 Ratio: 1.345132743362832
Max-min Ratio: 1.4642857142857142
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_02-06-57
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1702.0
  episode_reward_mean: 1131.63
  episode_reward_min: 841.0
  episodes_this_iter: 1
  episodes_total: 293
  experiment_id: a3942a9886f24694ab1b58ca8d1ab856
  hostname: gpu006
  info:
    apply_time_ms: 3.461
    dispatch_time_ms: 6.458
    learner:
      cur_lr: 0.0011648619547486305
      grad_gnorm: 40.0000114440918
      policy_entropy: 24.8433895111084
      policy_loss: -7.801356792449951
      var_gnorm: 50.55406951904297
      vf_explained_var: 0.13033050298690796
      vf_loss: 210.7899932861328
    num_steps_sampled: 2940000
    num_steps_trained: 2940000
    wait_time_ms: 232.006
  iterations_since_restore: 294
  node_ip: 172.17.8.6
  num_metric_batches_dropped: 0
  pid: 13557
  policy_reward_mean: {}
  time_since_restore: 7231.532960891724
  time_this_iter_s: 25.201321840286255
  time_total_s: 7231.532960891724
  timestamp: 1594102017
  timesteps_since_restore: 2940000
  timesteps_this_iter: 10000
  timesteps_total: 2940000
  training_iteration: 294
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 29.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=13557], 7231 s, 294 iter, 2940000 ts, 1.13e+03 rew

agent-1: 130.0
agent-2: 100.0
agent-3: 102.0
agent-4: 94.0
agent-5: 122.0
agent-6: 109.0
agent-7: 134.0
agent-8: 109.0
agent-9: 113.0
agent-10: 102.0
Sum Reward: 1115.0
Avg Reward: 111.5
Min Reward: 94.0
Max Reward: 134.0
Gini Coefficient: 0.0630493273542601
20:20 Ratio: 1.3608247422680413
Max-min Ratio: 1.425531914893617
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_02-07-21
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1702.0
  episode_reward_mean: 1130.29
  episode_reward_min: 841.0
  episodes_this_iter: 1
  episodes_total: 294
  experiment_id: a3942a9886f24694ab1b58ca8d1ab856
  hostname: gpu006
  info:
    apply_time_ms: 2.714
    dispatch_time_ms: 5.925
    learner:
      cur_lr: 0.0011641959426924586
      grad_gnorm: 40.00001907348633
      policy_entropy: 62.95458984375
      policy_loss: -5.01586389541626
      var_gnorm: 50.646995544433594
      vf_explained_var: 0.8546634912490845
      vf_loss: 15.162107467651367
    num_steps_sampled: 2950000
    num_steps_trained: 2950000
    wait_time_ms: 243.425
  iterations_since_restore: 295
  node_ip: 172.17.8.6
  num_metric_batches_dropped: 0
  pid: 13557
  policy_reward_mean: {}
  time_since_restore: 7255.2796404361725
  time_this_iter_s: 23.746679544448853
  time_total_s: 7255.2796404361725
  timestamp: 1594102041
  timesteps_since_restore: 2950000
  timesteps_this_iter: 10000
  timesteps_total: 2950000
  training_iteration: 295
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 29.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=13557], 7255 s, 295 iter, 2950000 ts, 1.13e+03 rew

agent-1: 100.0
agent-2: 123.0
agent-3: 129.0
agent-4: 102.0
agent-5: 140.0
agent-6: 126.0
agent-7: 126.0
agent-8: 109.0
agent-9: 128.0
agent-10: 129.0
Sum Reward: 1212.0
Avg Reward: 121.2
Min Reward: 100.0
Max Reward: 140.0
Gini Coefficient: 0.05478547854785479
20:20 Ratio: 1.3316831683168318
Max-min Ratio: 1.4
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_02-07-45
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1702.0
  episode_reward_mean: 1133.18
  episode_reward_min: 841.0
  episodes_this_iter: 1
  episodes_total: 295
  experiment_id: a3942a9886f24694ab1b58ca8d1ab856
  hostname: gpu006
  info:
    apply_time_ms: 2.864
    dispatch_time_ms: 5.942
    learner:
      cur_lr: 0.0011635300470516086
      grad_gnorm: 39.999996185302734
      policy_entropy: 44.738059997558594
      policy_loss: -4.571211338043213
      var_gnorm: 50.66725540161133
      vf_explained_var: 0.8297321796417236
      vf_loss: 72.02570343017578
    num_steps_sampled: 2960000
    num_steps_trained: 2960000
    wait_time_ms: 213.224
  iterations_since_restore: 296
  node_ip: 172.17.8.6
  num_metric_batches_dropped: 0
  pid: 13557
  policy_reward_mean: {}
  time_since_restore: 7279.089617490768
  time_this_iter_s: 23.809977054595947
  time_total_s: 7279.089617490768
  timestamp: 1594102065
  timesteps_since_restore: 2960000
  timesteps_this_iter: 10000
  timesteps_total: 2960000
  training_iteration: 296
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 29.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=13557], 7279 s, 296 iter, 2960000 ts, 1.13e+03 rew

agent-1: 171.0
agent-2: 172.0
agent-3: 154.0
agent-4: 180.0
agent-5: 185.0
agent-6: 176.0
agent-7: 182.0
agent-8: 164.0
agent-9: 143.0
agent-10: 151.0
Sum Reward: 1678.0
Avg Reward: 167.8
Min Reward: 143.0
Max Reward: 185.0
Gini Coefficient: 0.04541120381406436
20:20 Ratio: 1.248299319727891
Max-min Ratio: 1.2937062937062938
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_02-08-08
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1702.0
  episode_reward_mean: 1140.18
  episode_reward_min: 841.0
  episodes_this_iter: 1
  episodes_total: 296
  experiment_id: a3942a9886f24694ab1b58ca8d1ab856
  hostname: gpu006
  info:
    apply_time_ms: 2.516
    dispatch_time_ms: 6.442
    learner:
      cur_lr: 0.0011628640349954367
      grad_gnorm: 40.0
      policy_entropy: 40.144927978515625
      policy_loss: 20.638694763183594
      var_gnorm: 50.799102783203125
      vf_explained_var: 0.7587659358978271
      vf_loss: 143.3678741455078
    num_steps_sampled: 2970000
    num_steps_trained: 2970000
    wait_time_ms: 214.048
  iterations_since_restore: 297
  node_ip: 172.17.8.6
  num_metric_batches_dropped: 0
  pid: 13557
  policy_reward_mean: {}
  time_since_restore: 7301.604941368103
  time_this_iter_s: 22.515323877334595
  time_total_s: 7301.604941368103
  timestamp: 1594102088
  timesteps_since_restore: 2970000
  timesteps_this_iter: 10000
  timesteps_total: 2970000
  training_iteration: 297
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 29.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=13557], 7301 s, 297 iter, 2970000 ts, 1.14e+03 rew

agent-1: 155.0
agent-2: 154.0
agent-3: 140.0
agent-4: 150.0
agent-5: 201.0
agent-6: 143.0
agent-7: 178.0
agent-8: 148.0
agent-9: 149.0
agent-10: 158.0
Sum Reward: 1576.0
Avg Reward: 157.6
Min Reward: 140.0
Max Reward: 201.0
Gini Coefficient: 0.054949238578680205
20:20 Ratio: 1.3392226148409894
Max-min Ratio: 1.4357142857142857
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_02-08-32
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1702.0
  episode_reward_mean: 1147.31
  episode_reward_min: 841.0
  episodes_this_iter: 1
  episodes_total: 297
  experiment_id: a3942a9886f24694ab1b58ca8d1ab856
  hostname: gpu006
  info:
    apply_time_ms: 2.79
    dispatch_time_ms: 6.166
    learner:
      cur_lr: 0.0011621980229392648
      grad_gnorm: 40.0
      policy_entropy: 46.44744873046875
      policy_loss: -7.123216152191162
      var_gnorm: 50.76340866088867
      vf_explained_var: 0.7474163770675659
      vf_loss: 63.0289421081543
    num_steps_sampled: 2980000
    num_steps_trained: 2980000
    wait_time_ms: 217.321
  iterations_since_restore: 298
  node_ip: 172.17.8.6
  num_metric_batches_dropped: 0
  pid: 13557
  policy_reward_mean: {}
  time_since_restore: 7326.289235830307
  time_this_iter_s: 24.68429446220398
  time_total_s: 7326.289235830307
  timestamp: 1594102112
  timesteps_since_restore: 2980000
  timesteps_this_iter: 10000
  timesteps_total: 2980000
  training_iteration: 298
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 29.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=13557], 7326 s, 298 iter, 2980000 ts, 1.15e+03 rew

agent-1: 131.0
agent-2: 160.0
agent-3: 125.0
agent-4: 143.0
agent-5: 149.0
agent-6: 163.0
agent-7: 132.0
agent-8: 146.0
agent-9: 147.0
agent-10: 146.0
Sum Reward: 1442.0
Avg Reward: 144.2
Min Reward: 125.0
Max Reward: 163.0
Gini Coefficient: 0.044521497919556174
20:20 Ratio: 1.26171875
Max-min Ratio: 1.304
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_02-08-56
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1702.0
  episode_reward_mean: 1149.34
  episode_reward_min: 841.0
  episodes_this_iter: 1
  episodes_total: 298
  experiment_id: a3942a9886f24694ab1b58ca8d1ab856
  hostname: gpu006
  info:
    apply_time_ms: 2.781
    dispatch_time_ms: 6.601
    learner:
      cur_lr: 0.0011615320108830929
      grad_gnorm: 39.999996185302734
      policy_entropy: 38.05530548095703
      policy_loss: 3.4140427112579346
      var_gnorm: 50.754493713378906
      vf_explained_var: 0.5908041000366211
      vf_loss: 232.2324981689453
    num_steps_sampled: 2990000
    num_steps_trained: 2990000
    wait_time_ms: 225.233
  iterations_since_restore: 299
  node_ip: 172.17.8.6
  num_metric_batches_dropped: 0
  pid: 13557
  policy_reward_mean: {}
  time_since_restore: 7349.402770757675
  time_this_iter_s: 23.113534927368164
  time_total_s: 7349.402770757675
  timestamp: 1594102136
  timesteps_since_restore: 2990000
  timesteps_this_iter: 10000
  timesteps_total: 2990000
  training_iteration: 299
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 29.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=13557], 7349 s, 299 iter, 2990000 ts, 1.15e+03 rew

agent-1: 134.0
agent-2: 125.0
agent-3: 123.0
agent-4: 140.0
agent-5: 128.0
agent-6: 158.0
agent-7: 129.0
agent-8: 131.0
agent-9: 137.0
agent-10: 95.0
Sum Reward: 1300.0
Avg Reward: 130.0
Min Reward: 95.0
Max Reward: 158.0
Gini Coefficient: 0.058923076923076925
20:20 Ratio: 1.3669724770642202
Max-min Ratio: 1.6631578947368422
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_02-09-20
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1702.0
  episode_reward_mean: 1151.84
  episode_reward_min: 841.0
  episodes_this_iter: 1
  episodes_total: 299
  experiment_id: a3942a9886f24694ab1b58ca8d1ab856
  hostname: gpu006
  info:
    apply_time_ms: 2.665
    dispatch_time_ms: 6.424
    learner:
      cur_lr: 0.001160865998826921
      grad_gnorm: 22.334476470947266
      policy_entropy: 74.84934997558594
      policy_loss: -4.131832599639893
      var_gnorm: 50.9129524230957
      vf_explained_var: 0.9215102195739746
      vf_loss: 0.496857613325119
    num_steps_sampled: 3000000
    num_steps_trained: 3000000
    wait_time_ms: 249.94
  iterations_since_restore: 300
  node_ip: 172.17.8.6
  num_metric_batches_dropped: 0
  pid: 13557
  policy_reward_mean: {}
  time_since_restore: 7374.325292110443
  time_this_iter_s: 24.922521352767944
  time_total_s: 7374.325292110443
  timestamp: 1594102160
  timesteps_since_restore: 3000000
  timesteps_this_iter: 10000
  timesteps_total: 3000000
  training_iteration: 300
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 29.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=13557], 7374 s, 300 iter, 3000000 ts, 1.15e+03 rew

agent-1: 112.0
agent-2: 108.0
agent-3: 94.0
agent-4: 111.0
agent-5: 134.0
agent-6: 130.0
agent-7: 83.0
agent-8: 114.0
agent-9: 88.0
agent-10: 115.0
Sum Reward: 1089.0
Avg Reward: 108.9
Min Reward: 83.0
Max Reward: 134.0
Gini Coefficient: 0.0805325987144169
20:20 Ratio: 1.543859649122807
Max-min Ratio: 1.6144578313253013
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_02-09-43
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1702.0
  episode_reward_mean: 1153.22
  episode_reward_min: 841.0
  episodes_this_iter: 1
  episodes_total: 300
  experiment_id: a3942a9886f24694ab1b58ca8d1ab856
  hostname: gpu006
  info:
    apply_time_ms: 2.936
    dispatch_time_ms: 6.918
    learner:
      cur_lr: 0.001160199986770749
      grad_gnorm: 39.9999885559082
      policy_entropy: 51.787540435791016
      policy_loss: 13.59385871887207
      var_gnorm: 50.971534729003906
      vf_explained_var: 0.7352578639984131
      vf_loss: 131.1601104736328
    num_steps_sampled: 3010000
    num_steps_trained: 3010000
    wait_time_ms: 212.083
  iterations_since_restore: 301
  node_ip: 172.17.8.6
  num_metric_batches_dropped: 0
  pid: 13557
  policy_reward_mean: {}
  time_since_restore: 7397.101457595825
  time_this_iter_s: 22.77616548538208
  time_total_s: 7397.101457595825
  timestamp: 1594102183
  timesteps_since_restore: 3010000
  timesteps_this_iter: 10000
  timesteps_total: 3010000
  training_iteration: 301
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 29.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=13557], 7397 s, 301 iter, 3010000 ts, 1.15e+03 rew

agent-1: 194.0
agent-2: 192.0
agent-3: 135.0
agent-4: 179.0
agent-5: 138.0
agent-6: 135.0
agent-7: 142.0
agent-8: 141.0
agent-9: 126.0
agent-10: 118.0
Sum Reward: 1500.0
Avg Reward: 150.0
Min Reward: 118.0
Max Reward: 194.0
Gini Coefficient: 0.09266666666666666
20:20 Ratio: 1.5819672131147542
Max-min Ratio: 1.6440677966101696
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_02-10-07
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1702.0
  episode_reward_mean: 1157.1
  episode_reward_min: 841.0
  episodes_this_iter: 1
  episodes_total: 301
  experiment_id: a3942a9886f24694ab1b58ca8d1ab856
  hostname: gpu006
  info:
    apply_time_ms: 2.613
    dispatch_time_ms: 6.258
    learner:
      cur_lr: 0.0011595339747145772
      grad_gnorm: 39.99998092651367
      policy_entropy: 59.253684997558594
      policy_loss: -1.8428070545196533
      var_gnorm: 51.01852035522461
      vf_explained_var: 0.8516237735748291
      vf_loss: 61.55220413208008
    num_steps_sampled: 3020000
    num_steps_trained: 3020000
    wait_time_ms: 228.585
  iterations_since_restore: 302
  node_ip: 172.17.8.6
  num_metric_batches_dropped: 0
  pid: 13557
  policy_reward_mean: {}
  time_since_restore: 7420.79043841362
  time_this_iter_s: 23.6889808177948
  time_total_s: 7420.79043841362
  timestamp: 1594102207
  timesteps_since_restore: 3020000
  timesteps_this_iter: 10000
  timesteps_total: 3020000
  training_iteration: 302
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 29.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=13557], 7420 s, 302 iter, 3020000 ts, 1.16e+03 rew

agent-1: 164.0
agent-2: 122.0
agent-3: 166.0
agent-4: 123.0
agent-5: 150.0
agent-6: 197.0
agent-7: 194.0
agent-8: 154.0
agent-9: 170.0
agent-10: 152.0
Sum Reward: 1592.0
Avg Reward: 159.2
Min Reward: 122.0
Max Reward: 197.0
Gini Coefficient: 0.08316582914572865
20:20 Ratio: 1.5959183673469388
Max-min Ratio: 1.6147540983606556
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_02-10-31
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1702.0
  episode_reward_mean: 1161.73
  episode_reward_min: 841.0
  episodes_this_iter: 1
  episodes_total: 302
  experiment_id: a3942a9886f24694ab1b58ca8d1ab856
  hostname: gpu006
  info:
    apply_time_ms: 2.694
    dispatch_time_ms: 5.779
    learner:
      cur_lr: 0.0011588679626584053
      grad_gnorm: 39.99998474121094
      policy_entropy: 58.410099029541016
      policy_loss: -6.000815391540527
      var_gnorm: 51.021419525146484
      vf_explained_var: -1.0
      vf_loss: 1.1693384647369385
    num_steps_sampled: 3030000
    num_steps_trained: 3030000
    wait_time_ms: 245.91
  iterations_since_restore: 303
  node_ip: 172.17.8.6
  num_metric_batches_dropped: 0
  pid: 13557
  policy_reward_mean: {}
  time_since_restore: 7444.5048978328705
  time_this_iter_s: 23.71445941925049
  time_total_s: 7444.5048978328705
  timestamp: 1594102231
  timesteps_since_restore: 3030000
  timesteps_this_iter: 10000
  timesteps_total: 3030000
  training_iteration: 303
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 29.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=13557], 7444 s, 303 iter, 3030000 ts, 1.16e+03 rew

agent-1: 116.0
agent-2: 127.0
agent-3: 122.0
agent-4: 97.0
agent-5: 111.0
agent-6: 98.0
agent-7: 116.0
agent-8: 117.0
agent-9: 139.0
agent-10: 111.0
Sum Reward: 1154.0
Avg Reward: 115.4
Min Reward: 97.0
Max Reward: 139.0
Gini Coefficient: 0.05667244367417678
20:20 Ratio: 1.3641025641025641
Max-min Ratio: 1.4329896907216495
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_02-10-56
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1702.0
  episode_reward_mean: 1163.44
  episode_reward_min: 841.0
  episodes_this_iter: 1
  episodes_total: 303
  experiment_id: a3942a9886f24694ab1b58ca8d1ab856
  hostname: gpu006
  info:
    apply_time_ms: 2.727
    dispatch_time_ms: 6.863
    learner:
      cur_lr: 0.0011582019506022334
      grad_gnorm: 40.0
      policy_entropy: 29.342449188232422
      policy_loss: -11.959505081176758
      var_gnorm: 51.09848403930664
      vf_explained_var: 0.4257502555847168
      vf_loss: 87.78945922851562
    num_steps_sampled: 3040000
    num_steps_trained: 3040000
    wait_time_ms: 230.842
  iterations_since_restore: 304
  node_ip: 172.17.8.6
  num_metric_batches_dropped: 0
  pid: 13557
  policy_reward_mean: {}
  time_since_restore: 7469.923255205154
  time_this_iter_s: 25.418357372283936
  time_total_s: 7469.923255205154
  timestamp: 1594102256
  timesteps_since_restore: 3040000
  timesteps_this_iter: 10000
  timesteps_total: 3040000
  training_iteration: 304
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 29.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=13557], 7469 s, 304 iter, 3040000 ts, 1.16e+03 rew

agent-1: 82.0
agent-2: 94.0
agent-3: 81.0
agent-4: 89.0
agent-5: 92.0
agent-6: 94.0
agent-7: 98.0
agent-8: 93.0
agent-9: 82.0
agent-10: 97.0
Sum Reward: 902.0
Avg Reward: 90.2
Min Reward: 81.0
Max Reward: 98.0
Gini Coefficient: 0.03702882483370288
20:20 Ratio: 1.196319018404908
Max-min Ratio: 1.2098765432098766
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_02-11-21
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1702.0
  episode_reward_mean: 1163.44
  episode_reward_min: 841.0
  episodes_this_iter: 1
  episodes_total: 304
  experiment_id: a3942a9886f24694ab1b58ca8d1ab856
  hostname: gpu006
  info:
    apply_time_ms: 2.504
    dispatch_time_ms: 5.834
    learner:
      cur_lr: 0.0011575360549613833
      grad_gnorm: 40.000003814697266
      policy_entropy: 31.20574188232422
      policy_loss: -9.81767463684082
      var_gnorm: 51.14131546020508
      vf_explained_var: 0.6583415269851685
      vf_loss: 171.14202880859375
    num_steps_sampled: 3050000
    num_steps_trained: 3050000
    wait_time_ms: 235.301
  iterations_since_restore: 305
  node_ip: 172.17.8.6
  num_metric_batches_dropped: 0
  pid: 13557
  policy_reward_mean: {}
  time_since_restore: 7494.30389714241
  time_this_iter_s: 24.38064193725586
  time_total_s: 7494.30389714241
  timestamp: 1594102281
  timesteps_since_restore: 3050000
  timesteps_this_iter: 10000
  timesteps_total: 3050000
  training_iteration: 305
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 29.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=13557], 7494 s, 305 iter, 3050000 ts, 1.16e+03 rew

agent-1: 88.0
agent-2: 100.0
agent-3: 97.0
agent-4: 101.0
agent-5: 99.0
agent-6: 105.0
agent-7: 97.0
agent-8: 100.0
agent-9: 99.0
agent-10: 95.0
Sum Reward: 981.0
Avg Reward: 98.1
Min Reward: 88.0
Max Reward: 105.0
Gini Coefficient: 0.022324159021406727
20:20 Ratio: 1.1256830601092895
Max-min Ratio: 1.1931818181818181
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_02-11-45
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1702.0
  episode_reward_mean: 1163.46
  episode_reward_min: 841.0
  episodes_this_iter: 1
  episodes_total: 305
  experiment_id: a3942a9886f24694ab1b58ca8d1ab856
  hostname: gpu006
  info:
    apply_time_ms: 2.816
    dispatch_time_ms: 6.22
    learner:
      cur_lr: 0.0011568700429052114
      grad_gnorm: 40.0
      policy_entropy: 28.498355865478516
      policy_loss: -21.240917205810547
      var_gnorm: 51.19910430908203
      vf_explained_var: 0.27655965089797974
      vf_loss: 189.89065551757812
    num_steps_sampled: 3060000
    num_steps_trained: 3060000
    wait_time_ms: 216.187
  iterations_since_restore: 306
  node_ip: 172.17.8.6
  num_metric_batches_dropped: 0
  pid: 13557
  policy_reward_mean: {}
  time_since_restore: 7519.059895992279
  time_this_iter_s: 24.755998849868774
  time_total_s: 7519.059895992279
  timestamp: 1594102305
  timesteps_since_restore: 3060000
  timesteps_this_iter: 10000
  timesteps_total: 3060000
  training_iteration: 306
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 29.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=13557], 7519 s, 306 iter, 3060000 ts, 1.16e+03 rew

agent-1: 91.0
agent-2: 114.0
agent-3: 86.0
agent-4: 94.0
agent-5: 97.0
agent-6: 80.0
agent-7: 121.0
agent-8: 104.0
agent-9: 135.0
agent-10: 115.0
Sum Reward: 1037.0
Avg Reward: 103.7
Min Reward: 80.0
Max Reward: 135.0
Gini Coefficient: 0.08939247830279654
20:20 Ratio: 1.5421686746987953
Max-min Ratio: 1.6875
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_02-12-10
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1702.0
  episode_reward_mean: 1164.52
  episode_reward_min: 841.0
  episodes_this_iter: 1
  episodes_total: 306
  experiment_id: a3942a9886f24694ab1b58ca8d1ab856
  hostname: gpu006
  info:
    apply_time_ms: 2.525
    dispatch_time_ms: 5.992
    learner:
      cur_lr: 0.0011562040308490396
      grad_gnorm: 40.00001525878906
      policy_entropy: 28.718242645263672
      policy_loss: 26.315031051635742
      var_gnorm: 51.1422119140625
      vf_explained_var: 0.9354353547096252
      vf_loss: 165.34243774414062
    num_steps_sampled: 3070000
    num_steps_trained: 3070000
    wait_time_ms: 228.402
  iterations_since_restore: 307
  node_ip: 172.17.8.6
  num_metric_batches_dropped: 0
  pid: 13557
  policy_reward_mean: {}
  time_since_restore: 7543.509210586548
  time_this_iter_s: 24.4493145942688
  time_total_s: 7543.509210586548
  timestamp: 1594102330
  timesteps_since_restore: 3070000
  timesteps_this_iter: 10000
  timesteps_total: 3070000
  training_iteration: 307
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 29.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=13557], 7543 s, 307 iter, 3070000 ts, 1.16e+03 rew

agent-1: 90.0
agent-2: 107.0
agent-3: 97.0
agent-4: 91.0
agent-5: 73.0
agent-6: 99.0
agent-7: 114.0
agent-8: 87.0
agent-9: 77.0
agent-10: 125.0
Sum Reward: 960.0
Avg Reward: 96.0
Min Reward: 73.0
Max Reward: 125.0
Gini Coefficient: 0.08958333333333333
20:20 Ratio: 1.5933333333333333
Max-min Ratio: 1.7123287671232876
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_02-12-34
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1702.0
  episode_reward_mean: 1164.7
  episode_reward_min: 841.0
  episodes_this_iter: 1
  episodes_total: 307
  experiment_id: a3942a9886f24694ab1b58ca8d1ab856
  hostname: gpu006
  info:
    apply_time_ms: 2.725
    dispatch_time_ms: 6.098
    learner:
      cur_lr: 0.0011555380187928677
      grad_gnorm: 40.0
      policy_entropy: 23.33267593383789
      policy_loss: 18.8637638092041
      var_gnorm: 51.23894500732422
      vf_explained_var: 0.10549360513687134
      vf_loss: 194.39492797851562
    num_steps_sampled: 3080000
    num_steps_trained: 3080000
    wait_time_ms: 224.92
  iterations_since_restore: 308
  node_ip: 172.17.8.6
  num_metric_batches_dropped: 0
  pid: 13557
  policy_reward_mean: {}
  time_since_restore: 7567.562623023987
  time_this_iter_s: 24.053412437438965
  time_total_s: 7567.562623023987
  timestamp: 1594102354
  timesteps_since_restore: 3080000
  timesteps_this_iter: 10000
  timesteps_total: 3080000
  training_iteration: 308
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 29.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=13557], 7567 s, 308 iter, 3080000 ts, 1.16e+03 rew

agent-1: 149.0
agent-2: 131.0
agent-3: 185.0
agent-4: 129.0
agent-5: 130.0
agent-6: 161.0
agent-7: 120.0
agent-8: 126.0
agent-9: 149.0
agent-10: 116.0
Sum Reward: 1396.0
Avg Reward: 139.6
Min Reward: 116.0
Max Reward: 185.0
Gini Coefficient: 0.07765042979942693
20:20 Ratio: 1.4661016949152543
Max-min Ratio: 1.5948275862068966
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_02-12-57
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1702.0
  episode_reward_mean: 1168.32
  episode_reward_min: 841.0
  episodes_this_iter: 1
  episodes_total: 308
  experiment_id: a3942a9886f24694ab1b58ca8d1ab856
  hostname: gpu006
  info:
    apply_time_ms: 3.033
    dispatch_time_ms: 32.235
    learner:
      cur_lr: 0.0011548720067366958
      grad_gnorm: 40.000003814697266
      policy_entropy: 50.405181884765625
      policy_loss: 10.532438278198242
      var_gnorm: 51.310203552246094
      vf_explained_var: 0.6618970632553101
      vf_loss: 101.11994934082031
    num_steps_sampled: 3090000
    num_steps_trained: 3090000
    wait_time_ms: 190.662
  iterations_since_restore: 309
  node_ip: 172.17.8.6
  num_metric_batches_dropped: 0
  pid: 13557
  policy_reward_mean: {}
  time_since_restore: 7591.0264003276825
  time_this_iter_s: 23.46377730369568
  time_total_s: 7591.0264003276825
  timestamp: 1594102377
  timesteps_since_restore: 3090000
  timesteps_this_iter: 10000
  timesteps_total: 3090000
  training_iteration: 309
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 29.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=13557], 7591 s, 309 iter, 3090000 ts, 1.17e+03 rew

agent-1: 147.0
agent-2: 148.0
agent-3: 194.0
agent-4: 137.0
agent-5: 166.0
agent-6: 142.0
agent-7: 124.0
agent-8: 120.0
agent-9: 156.0
agent-10: 158.0
Sum Reward: 1492.0
Avg Reward: 149.2
Min Reward: 120.0
Max Reward: 194.0
Gini Coefficient: 0.0742627345844504
20:20 Ratio: 1.4754098360655739
Max-min Ratio: 1.6166666666666667
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_02-13-23
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1702.0
  episode_reward_mean: 1169.15
  episode_reward_min: 841.0
  episodes_this_iter: 1
  episodes_total: 309
  experiment_id: a3942a9886f24694ab1b58ca8d1ab856
  hostname: gpu006
  info:
    apply_time_ms: 3.44
    dispatch_time_ms: 26.309
    learner:
      cur_lr: 0.0011542059946805239
      grad_gnorm: 40.0
      policy_entropy: 50.103607177734375
      policy_loss: -5.925907135009766
      var_gnorm: 51.344181060791016
      vf_explained_var: -0.19910311698913574
      vf_loss: 1.1707959175109863
    num_steps_sampled: 3100000
    num_steps_trained: 3100000
    wait_time_ms: 220.803
  iterations_since_restore: 310
  node_ip: 172.17.8.6
  num_metric_batches_dropped: 0
  pid: 13557
  policy_reward_mean: {}
  time_since_restore: 7616.388271570206
  time_this_iter_s: 25.361871242523193
  time_total_s: 7616.388271570206
  timestamp: 1594102403
  timesteps_since_restore: 3100000
  timesteps_this_iter: 10000
  timesteps_total: 3100000
  training_iteration: 310
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 29.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=13557], 7616 s, 310 iter, 3100000 ts, 1.17e+03 rew

agent-1: 111.0
agent-2: 147.0
agent-3: 141.0
agent-4: 136.0
agent-5: 148.0
agent-6: 140.0
agent-7: 111.0
agent-8: 142.0
agent-9: 116.0
agent-10: 139.0
Sum Reward: 1331.0
Avg Reward: 133.1
Min Reward: 111.0
Max Reward: 148.0
Gini Coefficient: 0.054921111945905335
20:20 Ratio: 1.3288288288288288
Max-min Ratio: 1.3333333333333333
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_02-13-48
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1702.0
  episode_reward_mean: 1173.35
  episode_reward_min: 841.0
  episodes_this_iter: 1
  episodes_total: 310
  experiment_id: a3942a9886f24694ab1b58ca8d1ab856
  hostname: gpu006
  info:
    apply_time_ms: 4.277
    dispatch_time_ms: 26.959
    learner:
      cur_lr: 0.001153539982624352
      grad_gnorm: 40.0
      policy_entropy: 26.55462074279785
      policy_loss: -42.70619583129883
      var_gnorm: 51.36247634887695
      vf_explained_var: 0.8805626630783081
      vf_loss: 191.3143768310547
    num_steps_sampled: 3110000
    num_steps_trained: 3110000
    wait_time_ms: 221.88
  iterations_since_restore: 311
  node_ip: 172.17.8.6
  num_metric_batches_dropped: 0
  pid: 13557
  policy_reward_mean: {}
  time_since_restore: 7641.593376874924
  time_this_iter_s: 25.205105304718018
  time_total_s: 7641.593376874924
  timestamp: 1594102428
  timesteps_since_restore: 3110000
  timesteps_this_iter: 10000
  timesteps_total: 3110000
  training_iteration: 311
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 29.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=13557], 7641 s, 311 iter, 3110000 ts, 1.17e+03 rew

agent-1: 110.0
agent-2: 100.0
agent-3: 105.0
agent-4: 94.0
agent-5: 97.0
agent-6: 104.0
agent-7: 90.0
agent-8: 100.0
agent-9: 118.0
agent-10: 82.0
Sum Reward: 1000.0
Avg Reward: 100.0
Min Reward: 82.0
Max Reward: 118.0
Gini Coefficient: 0.054
20:20 Ratio: 1.3255813953488371
Max-min Ratio: 1.4390243902439024
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_02-14-14
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1702.0
  episode_reward_mean: 1172.51
  episode_reward_min: 841.0
  episodes_this_iter: 1
  episodes_total: 311
  experiment_id: a3942a9886f24694ab1b58ca8d1ab856
  hostname: gpu006
  info:
    apply_time_ms: 2.769
    dispatch_time_ms: 36.173
    learner:
      cur_lr: 0.00115287397056818
      grad_gnorm: 26.513473510742188
      policy_entropy: 60.57801055908203
      policy_loss: -3.8556442260742188
      var_gnorm: 51.466468811035156
      vf_explained_var: 0.5676171779632568
      vf_loss: 0.7805934548377991
    num_steps_sampled: 3120000
    num_steps_trained: 3120000
    wait_time_ms: 212.933
  iterations_since_restore: 312
  node_ip: 172.17.8.6
  num_metric_batches_dropped: 0
  pid: 13557
  policy_reward_mean: {}
  time_since_restore: 7667.331073284149
  time_this_iter_s: 25.737696409225464
  time_total_s: 7667.331073284149
  timestamp: 1594102454
  timesteps_since_restore: 3120000
  timesteps_this_iter: 10000
  timesteps_total: 3120000
  training_iteration: 312
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 29.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=13557], 7667 s, 312 iter, 3120000 ts, 1.17e+03 rew

agent-1: 108.0
agent-2: 100.0
agent-3: 115.0
agent-4: 103.0
agent-5: 105.0
agent-6: 99.0
agent-7: 103.0
agent-8: 116.0
agent-9: 106.0
agent-10: 111.0
Sum Reward: 1066.0
Avg Reward: 106.6
Min Reward: 99.0
Max Reward: 116.0
Gini Coefficient: 0.02945590994371482
20:20 Ratio: 1.1608040201005025
Max-min Ratio: 1.1717171717171717
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_02-14-40
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1702.0
  episode_reward_mean: 1171.74
  episode_reward_min: 841.0
  episodes_this_iter: 1
  episodes_total: 312
  experiment_id: a3942a9886f24694ab1b58ca8d1ab856
  hostname: gpu006
  info:
    apply_time_ms: 2.832
    dispatch_time_ms: 27.505
    learner:
      cur_lr: 0.0011522079585120082
      grad_gnorm: 14.675647735595703
      policy_entropy: 68.97696685791016
      policy_loss: -3.2675163745880127
      var_gnorm: 51.50174331665039
      vf_explained_var: 0.9266937971115112
      vf_loss: 0.2622012197971344
    num_steps_sampled: 3130000
    num_steps_trained: 3130000
    wait_time_ms: 244.487
  iterations_since_restore: 313
  node_ip: 172.17.8.6
  num_metric_batches_dropped: 0
  pid: 13557
  policy_reward_mean: {}
  time_since_restore: 7692.85324883461
  time_this_iter_s: 25.522175550460815
  time_total_s: 7692.85324883461
  timestamp: 1594102480
  timesteps_since_restore: 3130000
  timesteps_this_iter: 10000
  timesteps_total: 3130000
  training_iteration: 313
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 29.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=13557], 7692 s, 313 iter, 3130000 ts, 1.17e+03 rew

agent-1: 105.0
agent-2: 102.0
agent-3: 100.0
agent-4: 94.0
agent-5: 99.0
agent-6: 119.0
agent-7: 89.0
agent-8: 113.0
agent-9: 118.0
agent-10: 99.0
Sum Reward: 1038.0
Avg Reward: 103.8
Min Reward: 89.0
Max Reward: 119.0
Gini Coefficient: 0.05086705202312139
20:20 Ratio: 1.2950819672131149
Max-min Ratio: 1.3370786516853932
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_02-15-05
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1702.0
  episode_reward_mean: 1170.36
  episode_reward_min: 841.0
  episodes_this_iter: 1
  episodes_total: 313
  experiment_id: a3942a9886f24694ab1b58ca8d1ab856
  hostname: gpu006
  info:
    apply_time_ms: 4.797
    dispatch_time_ms: 24.843
    learner:
      cur_lr: 0.0011515419464558363
      grad_gnorm: 40.000003814697266
      policy_entropy: 27.707406997680664
      policy_loss: -39.15033721923828
      var_gnorm: 51.47642517089844
      vf_explained_var: -0.6737819910049438
      vf_loss: 175.5160675048828
    num_steps_sampled: 3140000
    num_steps_trained: 3140000
    wait_time_ms: 204.158
  iterations_since_restore: 314
  node_ip: 172.17.8.6
  num_metric_batches_dropped: 0
  pid: 13557
  policy_reward_mean: {}
  time_since_restore: 7718.590459108353
  time_this_iter_s: 25.737210273742676
  time_total_s: 7718.590459108353
  timestamp: 1594102505
  timesteps_since_restore: 3140000
  timesteps_this_iter: 10000
  timesteps_total: 3140000
  training_iteration: 314
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 29.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=13557], 7718 s, 314 iter, 3140000 ts, 1.17e+03 rew

agent-1: 98.0
agent-2: 94.0
agent-3: 80.0
agent-4: 98.0
agent-5: 86.0
agent-6: 95.0
agent-7: 89.0
agent-8: 116.0
agent-9: 99.0
agent-10: 84.0
Sum Reward: 939.0
Avg Reward: 93.9
Min Reward: 80.0
Max Reward: 116.0
Gini Coefficient: 0.05505857294994675
20:20 Ratio: 1.3109756097560976
Max-min Ratio: 1.45
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_02-15-33
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1702.0
  episode_reward_mean: 1168.27
  episode_reward_min: 841.0
  episodes_this_iter: 1
  episodes_total: 314
  experiment_id: a3942a9886f24694ab1b58ca8d1ab856
  hostname: gpu006
  info:
    apply_time_ms: 2.481
    dispatch_time_ms: 6.715
    learner:
      cur_lr: 0.0011508760508149862
      grad_gnorm: 9.462784767150879
      policy_entropy: 70.47513580322266
      policy_loss: -2.062645435333252
      var_gnorm: 51.498653411865234
      vf_explained_var: -1.0
      vf_loss: 0.08040882647037506
    num_steps_sampled: 3150000
    num_steps_trained: 3150000
    wait_time_ms: 247.013
  iterations_since_restore: 315
  node_ip: 172.17.8.6
  num_metric_batches_dropped: 0
  pid: 13557
  policy_reward_mean: {}
  time_since_restore: 7745.942573547363
  time_this_iter_s: 27.35211443901062
  time_total_s: 7745.942573547363
  timestamp: 1594102533
  timesteps_since_restore: 3150000
  timesteps_this_iter: 10000
  timesteps_total: 3150000
  training_iteration: 315
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 29.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=13557], 7745 s, 315 iter, 3150000 ts, 1.17e+03 rew

agent-1: 92.0
agent-2: 134.0
agent-3: 128.0
agent-4: 106.0
agent-5: 117.0
agent-6: 119.0
agent-7: 91.0
agent-8: 107.0
agent-9: 106.0
agent-10: 120.0
Sum Reward: 1120.0
Avg Reward: 112.0
Min Reward: 91.0
Max Reward: 134.0
Gini Coefficient: 0.06767857142857144
20:20 Ratio: 1.4316939890710383
Max-min Ratio: 1.4725274725274726
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_02-15-57
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1702.0
  episode_reward_mean: 1167.67
  episode_reward_min: 841.0
  episodes_this_iter: 1
  episodes_total: 315
  experiment_id: a3942a9886f24694ab1b58ca8d1ab856
  hostname: gpu006
  info:
    apply_time_ms: 2.779
    dispatch_time_ms: 7.909
    learner:
      cur_lr: 0.0011502100387588143
      grad_gnorm: 39.99999237060547
      policy_entropy: 19.636302947998047
      policy_loss: 6.8882155418396
      var_gnorm: 51.56504821777344
      vf_explained_var: 0.5843746066093445
      vf_loss: 77.50338745117188
    num_steps_sampled: 3160000
    num_steps_trained: 3160000
    wait_time_ms: 237.809
  iterations_since_restore: 316
  node_ip: 172.17.8.6
  num_metric_batches_dropped: 0
  pid: 13557
  policy_reward_mean: {}
  time_since_restore: 7770.352944850922
  time_this_iter_s: 24.41037130355835
  time_total_s: 7770.352944850922
  timestamp: 1594102557
  timesteps_since_restore: 3160000
  timesteps_this_iter: 10000
  timesteps_total: 3160000
  training_iteration: 316
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 29.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=13557], 7770 s, 316 iter, 3160000 ts, 1.17e+03 rew

agent-1: 112.0
agent-2: 112.0
agent-3: 104.0
agent-4: 105.0
agent-5: 110.0
agent-6: 77.0
agent-7: 129.0
agent-8: 111.0
agent-9: 116.0
agent-10: 119.0
Sum Reward: 1095.0
Avg Reward: 109.5
Min Reward: 77.0
Max Reward: 129.0
Gini Coefficient: 0.05799086757990868
20:20 Ratio: 1.3701657458563536
Max-min Ratio: 1.6753246753246753
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_02-16-21
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1702.0
  episode_reward_mean: 1166.21
  episode_reward_min: 841.0
  episodes_this_iter: 1
  episodes_total: 316
  experiment_id: a3942a9886f24694ab1b58ca8d1ab856
  hostname: gpu006
  info:
    apply_time_ms: 2.809
    dispatch_time_ms: 6.825
    learner:
      cur_lr: 0.0011495440267026424
      grad_gnorm: 13.175847053527832
      policy_entropy: 68.3140640258789
      policy_loss: -3.3862452507019043
      var_gnorm: 51.67208480834961
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 0.10141494870185852
    num_steps_sampled: 3170000
    num_steps_trained: 3170000
    wait_time_ms: 222.346
  iterations_since_restore: 317
  node_ip: 172.17.8.6
  num_metric_batches_dropped: 0
  pid: 13557
  policy_reward_mean: {}
  time_since_restore: 7794.704973936081
  time_this_iter_s: 24.3520290851593
  time_total_s: 7794.704973936081
  timestamp: 1594102581
  timesteps_since_restore: 3170000
  timesteps_this_iter: 10000
  timesteps_total: 3170000
  training_iteration: 317
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 29.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=13557], 7794 s, 317 iter, 3170000 ts, 1.17e+03 rew

agent-1: 112.0
agent-2: 119.0
agent-3: 140.0
agent-4: 140.0
agent-5: 124.0
agent-6: 116.0
agent-7: 132.0
agent-8: 157.0
agent-9: 134.0
agent-10: 116.0
Sum Reward: 1290.0
Avg Reward: 129.0
Min Reward: 112.0
Max Reward: 157.0
Gini Coefficient: 0.057829457364341086
20:20 Ratio: 1.3026315789473684
Max-min Ratio: 1.4017857142857142
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_02-16-46
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1702.0
  episode_reward_mean: 1167.13
  episode_reward_min: 841.0
  episodes_this_iter: 1
  episodes_total: 317
  experiment_id: a3942a9886f24694ab1b58ca8d1ab856
  hostname: gpu006
  info:
    apply_time_ms: 2.609
    dispatch_time_ms: 5.864
    learner:
      cur_lr: 0.0011488780146464705
      grad_gnorm: 13.11427116394043
      policy_entropy: 68.02823638916016
      policy_loss: -2.443321466445923
      var_gnorm: 51.792396545410156
      vf_explained_var: 0.92967289686203
      vf_loss: 0.19455598294734955
    num_steps_sampled: 3180000
    num_steps_trained: 3180000
    wait_time_ms: 260.458
  iterations_since_restore: 318
  node_ip: 172.17.8.6
  num_metric_batches_dropped: 0
  pid: 13557
  policy_reward_mean: {}
  time_since_restore: 7819.366027832031
  time_this_iter_s: 24.661053895950317
  time_total_s: 7819.366027832031
  timestamp: 1594102606
  timesteps_since_restore: 3180000
  timesteps_this_iter: 10000
  timesteps_total: 3180000
  training_iteration: 318
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 29.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=13557], 7819 s, 318 iter, 3180000 ts, 1.17e+03 rew

agent-1: 108.0
agent-2: 83.0
agent-3: 132.0
agent-4: 122.0
agent-5: 103.0
agent-6: 88.0
agent-7: 100.0
agent-8: 99.0
agent-9: 110.0
agent-10: 97.0
Sum Reward: 1042.0
Avg Reward: 104.2
Min Reward: 83.0
Max Reward: 132.0
Gini Coefficient: 0.07428023032629559
20:20 Ratio: 1.4853801169590644
Max-min Ratio: 1.5903614457831325
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_02-17-11
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1702.0
  episode_reward_mean: 1166.69
  episode_reward_min: 841.0
  episodes_this_iter: 1
  episodes_total: 318
  experiment_id: a3942a9886f24694ab1b58ca8d1ab856
  hostname: gpu006
  info:
    apply_time_ms: 2.639
    dispatch_time_ms: 7.284
    learner:
      cur_lr: 0.0011482120025902987
      grad_gnorm: 32.38138961791992
      policy_entropy: 45.70756149291992
      policy_loss: -4.71992826461792
      var_gnorm: 51.84421920776367
      vf_explained_var: 0.6102993488311768
      vf_loss: 1.1199088096618652
    num_steps_sampled: 3190000
    num_steps_trained: 3190000
    wait_time_ms: 229.654
  iterations_since_restore: 319
  node_ip: 172.17.8.6
  num_metric_batches_dropped: 0
  pid: 13557
  policy_reward_mean: {}
  time_since_restore: 7843.819828987122
  time_this_iter_s: 24.453801155090332
  time_total_s: 7843.819828987122
  timestamp: 1594102631
  timesteps_since_restore: 3190000
  timesteps_this_iter: 10000
  timesteps_total: 3190000
  training_iteration: 319
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 29.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=13557], 7843 s, 319 iter, 3190000 ts, 1.17e+03 rew

agent-1: 94.0
agent-2: 113.0
agent-3: 117.0
agent-4: 132.0
agent-5: 107.0
agent-6: 105.0
agent-7: 125.0
agent-8: 115.0
agent-9: 103.0
agent-10: 99.0
Sum Reward: 1110.0
Avg Reward: 111.0
Min Reward: 94.0
Max Reward: 132.0
Gini Coefficient: 0.05675675675675676
20:20 Ratio: 1.3316062176165804
Max-min Ratio: 1.4042553191489362
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_02-17-33
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1702.0
  episode_reward_mean: 1167.33
  episode_reward_min: 841.0
  episodes_this_iter: 1
  episodes_total: 319
  experiment_id: a3942a9886f24694ab1b58ca8d1ab856
  hostname: gpu006
  info:
    apply_time_ms: 2.712
    dispatch_time_ms: 5.759
    learner:
      cur_lr: 0.0011475459905341268
      grad_gnorm: 40.0000114440918
      policy_entropy: 52.86167907714844
      policy_loss: 2.7414467334747314
      var_gnorm: 51.99348831176758
      vf_explained_var: 0.5845732688903809
      vf_loss: 106.83700561523438
    num_steps_sampled: 3200000
    num_steps_trained: 3200000
    wait_time_ms: 193.23
  iterations_since_restore: 320
  node_ip: 172.17.8.6
  num_metric_batches_dropped: 0
  pid: 13557
  policy_reward_mean: {}
  time_since_restore: 7866.423448562622
  time_this_iter_s: 22.60361957550049
  time_total_s: 7866.423448562622
  timestamp: 1594102653
  timesteps_since_restore: 3200000
  timesteps_this_iter: 10000
  timesteps_total: 3200000
  training_iteration: 320
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 29.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=13557], 7866 s, 320 iter, 3200000 ts, 1.17e+03 rew

agent-1: 131.0
agent-2: 143.0
agent-3: 162.0
agent-4: 180.0
agent-5: 144.0
agent-6: 175.0
agent-7: 155.0
agent-8: 179.0
agent-9: 154.0
agent-10: 152.0
Sum Reward: 1575.0
Avg Reward: 157.5
Min Reward: 131.0
Max Reward: 180.0
Gini Coefficient: 0.05580952380952381
20:20 Ratio: 1.3102189781021898
Max-min Ratio: 1.3740458015267176
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_02-17-55
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1702.0
  episode_reward_mean: 1172.98
  episode_reward_min: 841.0
  episodes_this_iter: 1
  episodes_total: 320
  experiment_id: a3942a9886f24694ab1b58ca8d1ab856
  hostname: gpu006
  info:
    apply_time_ms: 2.748
    dispatch_time_ms: 5.279
    learner:
      cur_lr: 0.0011468799784779549
      grad_gnorm: 40.0
      policy_entropy: 52.1594123840332
      policy_loss: 24.98135757446289
      var_gnorm: 52.03638458251953
      vf_explained_var: 0.6453660726547241
      vf_loss: 185.58485412597656
    num_steps_sampled: 3210000
    num_steps_trained: 3210000
    wait_time_ms: 192.771
  iterations_since_restore: 321
  node_ip: 172.17.8.6
  num_metric_batches_dropped: 0
  pid: 13557
  policy_reward_mean: {}
  time_since_restore: 7887.5527975559235
  time_this_iter_s: 21.12934899330139
  time_total_s: 7887.5527975559235
  timestamp: 1594102675
  timesteps_since_restore: 3210000
  timesteps_this_iter: 10000
  timesteps_total: 3210000
  training_iteration: 321
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 29.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=13557], 7887 s, 321 iter, 3210000 ts, 1.17e+03 rew

agent-1: 174.0
agent-2: 175.0
agent-3: 179.0
agent-4: 195.0
agent-5: 161.0
agent-6: 169.0
agent-7: 167.0
agent-8: 171.0
agent-9: 157.0
agent-10: 142.0
Sum Reward: 1690.0
Avg Reward: 169.0
Min Reward: 142.0
Max Reward: 195.0
Gini Coefficient: 0.04284023668639053
20:20 Ratio: 1.2508361204013378
Max-min Ratio: 1.3732394366197183
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_02-18-16
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1702.0
  episode_reward_mean: 1179.83
  episode_reward_min: 841.0
  episodes_this_iter: 1
  episodes_total: 321
  experiment_id: a3942a9886f24694ab1b58ca8d1ab856
  hostname: gpu006
  info:
    apply_time_ms: 2.684
    dispatch_time_ms: 27.865
    learner:
      cur_lr: 0.001146213966421783
      grad_gnorm: 40.0
      policy_entropy: 44.97713088989258
      policy_loss: 25.44098663330078
      var_gnorm: 52.0721435546875
      vf_explained_var: 0.5964523553848267
      vf_loss: 90.38256072998047
    num_steps_sampled: 3220000
    num_steps_trained: 3220000
    wait_time_ms: 190.214
  iterations_since_restore: 322
  node_ip: 172.17.8.6
  num_metric_batches_dropped: 0
  pid: 13557
  policy_reward_mean: {}
  time_since_restore: 7908.895005226135
  time_this_iter_s: 21.342207670211792
  time_total_s: 7908.895005226135
  timestamp: 1594102696
  timesteps_since_restore: 3220000
  timesteps_this_iter: 10000
  timesteps_total: 3220000
  training_iteration: 322
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 29.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=13557], 7908 s, 322 iter, 3220000 ts, 1.18e+03 rew

agent-1: 172.0
agent-2: 183.0
agent-3: 157.0
agent-4: 152.0
agent-5: 168.0
agent-6: 162.0
agent-7: 143.0
agent-8: 184.0
agent-9: 161.0
agent-10: 161.0
Sum Reward: 1643.0
Avg Reward: 164.3
Min Reward: 143.0
Max Reward: 184.0
Gini Coefficient: 0.04157029823493609
20:20 Ratio: 1.2440677966101694
Max-min Ratio: 1.2867132867132867
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_02-18-39
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1702.0
  episode_reward_mean: 1185.97
  episode_reward_min: 841.0
  episodes_this_iter: 1
  episodes_total: 322
  experiment_id: a3942a9886f24694ab1b58ca8d1ab856
  hostname: gpu006
  info:
    apply_time_ms: 3.874
    dispatch_time_ms: 24.501
    learner:
      cur_lr: 0.001145547954365611
      grad_gnorm: 40.00000762939453
      policy_entropy: 34.34529495239258
      policy_loss: -13.615970611572266
      var_gnorm: 52.08469772338867
      vf_explained_var: 0.7109321355819702
      vf_loss: 95.4974594116211
    num_steps_sampled: 3230000
    num_steps_trained: 3230000
    wait_time_ms: 197.584
  iterations_since_restore: 323
  node_ip: 172.17.8.6
  num_metric_batches_dropped: 0
  pid: 13557
  policy_reward_mean: {}
  time_since_restore: 7932.130617141724
  time_this_iter_s: 23.23561191558838
  time_total_s: 7932.130617141724
  timestamp: 1594102719
  timesteps_since_restore: 3230000
  timesteps_this_iter: 10000
  timesteps_total: 3230000
  training_iteration: 323
  
W0707 02:18:59.658133 13553 node_manager.cc:250] Last heartbeat was sent 11184 ms ago 
W0707 02:19:00.261474 13553 node_manager.cc:250] Last heartbeat was sent 604 ms ago 
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=13557], 7932 s, 323 iter, 3230000 ts, 1.19e+03 rew

agent-1: 166.0
agent-2: 181.0
agent-3: 174.0
agent-4: 176.0
agent-5: 217.0
agent-6: 192.0
agent-7: 202.0
agent-8: 175.0
agent-9: 178.0
agent-10: 200.0
Sum Reward: 1861.0
Avg Reward: 186.1
Min Reward: 166.0
Max Reward: 217.0
Gini Coefficient: 0.0446534121440086
20:20 Ratio: 1.2323529411764707
Max-min Ratio: 1.3072289156626506
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_02-19-20
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1861.0
  episode_reward_mean: 1191.3
  episode_reward_min: 841.0
  episodes_this_iter: 1
  episodes_total: 323
  experiment_id: a3942a9886f24694ab1b58ca8d1ab856
  hostname: gpu006
  info:
    apply_time_ms: 2.717
    dispatch_time_ms: 18.028
    learner:
      cur_lr: 0.0011448819423094392
      grad_gnorm: 40.000003814697266
      policy_entropy: 46.667884826660156
      policy_loss: -36.31333541870117
      var_gnorm: 52.164615631103516
      vf_explained_var: 0.376456618309021
      vf_loss: 124.35738372802734
    num_steps_sampled: 3240000
    num_steps_trained: 3240000
    wait_time_ms: 213.701
  iterations_since_restore: 324
  node_ip: 172.17.8.6
  num_metric_batches_dropped: 0
  pid: 13557
  policy_reward_mean: {}
  time_since_restore: 7951.7550168037415
  time_this_iter_s: 19.624399662017822
  time_total_s: 7951.7550168037415
  timestamp: 1594102760
  timesteps_since_restore: 3240000
  timesteps_this_iter: 10000
  timesteps_total: 3240000
  training_iteration: 324
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 29.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=13557], 7951 s, 324 iter, 3240000 ts, 1.19e+03 rew

agent-1: 182.0
agent-2: 183.0
agent-3: 163.0
agent-4: 195.0
agent-5: 179.0
agent-6: 199.0
agent-7: 167.0
agent-8: 187.0
agent-9: 195.0
agent-10: 195.0
Sum Reward: 1845.0
Avg Reward: 184.5
Min Reward: 163.0
Max Reward: 199.0
Gini Coefficient: 0.03485094850948509
20:20 Ratio: 1.1939393939393939
Max-min Ratio: 1.2208588957055215
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_02-19-43
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1861.0
  episode_reward_mean: 1194.92
  episode_reward_min: 841.0
  episodes_this_iter: 1
  episodes_total: 324
  experiment_id: a3942a9886f24694ab1b58ca8d1ab856
  hostname: gpu006
  info:
    apply_time_ms: 2.926
    dispatch_time_ms: 15.76
    learner:
      cur_lr: 0.0011442160466685891
      grad_gnorm: 40.0
      policy_entropy: 42.372833251953125
      policy_loss: -7.5798749923706055
      var_gnorm: 52.18387985229492
      vf_explained_var: 0.905397891998291
      vf_loss: 61.84716033935547
    num_steps_sampled: 3250000
    num_steps_trained: 3250000
    wait_time_ms: 218.208
  iterations_since_restore: 325
  node_ip: 172.17.8.6
  num_metric_batches_dropped: 0
  pid: 13557
  policy_reward_mean: {}
  time_since_restore: 7975.386898994446
  time_this_iter_s: 23.631882190704346
  time_total_s: 7975.386898994446
  timestamp: 1594102783
  timesteps_since_restore: 3250000
  timesteps_this_iter: 10000
  timesteps_total: 3250000
  training_iteration: 325
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 29.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=13557], 7975 s, 325 iter, 3250000 ts, 1.19e+03 rew

agent-1: 127.0
agent-2: 107.0
agent-3: 171.0
agent-4: 134.0
agent-5: 162.0
agent-6: 136.0
agent-7: 147.0
agent-8: 155.0
agent-9: 162.0
agent-10: 139.0
Sum Reward: 1440.0
Avg Reward: 144.0
Min Reward: 107.0
Max Reward: 171.0
Gini Coefficient: 0.07125
20:20 Ratio: 1.4230769230769231
Max-min Ratio: 1.5981308411214954
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_02-20-06
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1861.0
  episode_reward_mean: 1196.18
  episode_reward_min: 841.0
  episodes_this_iter: 1
  episodes_total: 325
  experiment_id: a3942a9886f24694ab1b58ca8d1ab856
  hostname: gpu006
  info:
    apply_time_ms: 2.59
    dispatch_time_ms: 24.662
    learner:
      cur_lr: 0.0011435500346124172
      grad_gnorm: 40.0
      policy_entropy: 32.36466598510742
      policy_loss: 11.599199295043945
      var_gnorm: 52.14400863647461
      vf_explained_var: 0.7111560106277466
      vf_loss: 65.35436248779297
    num_steps_sampled: 3260000
    num_steps_trained: 3260000
    wait_time_ms: 206.003
  iterations_since_restore: 326
  node_ip: 172.17.8.6
  num_metric_batches_dropped: 0
  pid: 13557
  policy_reward_mean: {}
  time_since_restore: 7998.203689575195
  time_this_iter_s: 22.81679058074951
  time_total_s: 7998.203689575195
  timestamp: 1594102806
  timesteps_since_restore: 3260000
  timesteps_this_iter: 10000
  timesteps_total: 3260000
  training_iteration: 326
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 29.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=13557], 7998 s, 326 iter, 3260000 ts, 1.2e+03 rew

agent-1: 183.0
agent-2: 157.0
agent-3: 158.0
agent-4: 130.0
agent-5: 164.0
agent-6: 131.0
agent-7: 143.0
agent-8: 153.0
agent-9: 138.0
agent-10: 142.0
Sum Reward: 1499.0
Avg Reward: 149.9
Min Reward: 130.0
Max Reward: 183.0
Gini Coefficient: 0.057571714476317544
20:20 Ratio: 1.3295019157088122
Max-min Ratio: 1.4076923076923078
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_02-20-31
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1861.0
  episode_reward_mean: 1200.97
  episode_reward_min: 841.0
  episodes_this_iter: 1
  episodes_total: 326
  experiment_id: a3942a9886f24694ab1b58ca8d1ab856
  hostname: gpu006
  info:
    apply_time_ms: 2.557
    dispatch_time_ms: 7.463
    learner:
      cur_lr: 0.0011428840225562453
      grad_gnorm: 2.2648932933807373
      policy_entropy: 51.5795783996582
      policy_loss: -0.32804757356643677
      var_gnorm: 52.124202728271484
      vf_explained_var: 0.6516523361206055
      vf_loss: 0.07865742594003677
    num_steps_sampled: 3270000
    num_steps_trained: 3270000
    wait_time_ms: 214.22
  iterations_since_restore: 327
  node_ip: 172.17.8.6
  num_metric_batches_dropped: 0
  pid: 13557
  policy_reward_mean: {}
  time_since_restore: 8023.240610837936
  time_this_iter_s: 25.03692126274109
  time_total_s: 8023.240610837936
  timestamp: 1594102831
  timesteps_since_restore: 3270000
  timesteps_this_iter: 10000
  timesteps_total: 3270000
  training_iteration: 327
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 29.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=13557], 8023 s, 327 iter, 3270000 ts, 1.2e+03 rew

agent-1: 83.0
agent-2: 99.0
agent-3: 90.0
agent-4: 100.0
agent-5: 100.0
agent-6: 132.0
agent-7: 103.0
agent-8: 106.0
agent-9: 129.0
agent-10: 84.0
Sum Reward: 1026.0
Avg Reward: 102.6
Min Reward: 83.0
Max Reward: 132.0
Gini Coefficient: 0.08265107212475634
20:20 Ratio: 1.562874251497006
Max-min Ratio: 1.5903614457831325
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_02-20-55
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1861.0
  episode_reward_mean: 1200.84
  episode_reward_min: 841.0
  episodes_this_iter: 1
  episodes_total: 327
  experiment_id: a3942a9886f24694ab1b58ca8d1ab856
  hostname: gpu006
  info:
    apply_time_ms: 4.216
    dispatch_time_ms: 6.41
    learner:
      cur_lr: 0.0011422180105000734
      grad_gnorm: 40.0
      policy_entropy: 21.034130096435547
      policy_loss: 19.401121139526367
      var_gnorm: 52.11940002441406
      vf_explained_var: 0.8838315606117249
      vf_loss: 114.44866943359375
    num_steps_sampled: 3280000
    num_steps_trained: 3280000
    wait_time_ms: 215.15
  iterations_since_restore: 328
  node_ip: 172.17.8.6
  num_metric_batches_dropped: 0
  pid: 13557
  policy_reward_mean: {}
  time_since_restore: 8046.890784263611
  time_this_iter_s: 23.65017342567444
  time_total_s: 8046.890784263611
  timestamp: 1594102855
  timesteps_since_restore: 3280000
  timesteps_this_iter: 10000
  timesteps_total: 3280000
  training_iteration: 328
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 29.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=13557], 8046 s, 328 iter, 3280000 ts, 1.2e+03 rew

agent-1: 120.0
agent-2: 109.0
agent-3: 111.0
agent-4: 98.0
agent-5: 102.0
agent-6: 107.0
agent-7: 78.0
agent-8: 104.0
agent-9: 87.0
agent-10: 89.0
Sum Reward: 1005.0
Avg Reward: 100.5
Min Reward: 78.0
Max Reward: 120.0
Gini Coefficient: 0.06716417910447761
20:20 Ratio: 1.4
Max-min Ratio: 1.5384615384615385
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_02-21-20
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1861.0
  episode_reward_mean: 1200.18
  episode_reward_min: 841.0
  episodes_this_iter: 1
  episodes_total: 328
  experiment_id: a3942a9886f24694ab1b58ca8d1ab856
  hostname: gpu006
  info:
    apply_time_ms: 2.772
    dispatch_time_ms: 7.453
    learner:
      cur_lr: 0.0011415519984439015
      grad_gnorm: 39.999996185302734
      policy_entropy: 26.638208389282227
      policy_loss: 23.551185607910156
      var_gnorm: 52.15177917480469
      vf_explained_var: 0.8629633188247681
      vf_loss: 136.97837829589844
    num_steps_sampled: 3290000
    num_steps_trained: 3290000
    wait_time_ms: 209.503
  iterations_since_restore: 329
  node_ip: 172.17.8.6
  num_metric_batches_dropped: 0
  pid: 13557
  policy_reward_mean: {}
  time_since_restore: 8072.177438259125
  time_this_iter_s: 25.286653995513916
  time_total_s: 8072.177438259125
  timestamp: 1594102880
  timesteps_since_restore: 3290000
  timesteps_this_iter: 10000
  timesteps_total: 3290000
  training_iteration: 329
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 29.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=13557], 8072 s, 329 iter, 3290000 ts, 1.2e+03 rew

agent-1: 126.0
agent-2: 112.0
agent-3: 152.0
agent-4: 107.0
agent-5: 113.0
agent-6: 118.0
agent-7: 123.0
agent-8: 114.0
agent-9: 111.0
agent-10: 120.0
Sum Reward: 1196.0
Avg Reward: 119.6
Min Reward: 107.0
Max Reward: 152.0
Gini Coefficient: 0.04933110367892977
20:20 Ratio: 1.275229357798165
Max-min Ratio: 1.4205607476635513
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_02-21-44
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1861.0
  episode_reward_mean: 1199.92
  episode_reward_min: 841.0
  episodes_this_iter: 1
  episodes_total: 329
  experiment_id: a3942a9886f24694ab1b58ca8d1ab856
  hostname: gpu006
  info:
    apply_time_ms: 2.605
    dispatch_time_ms: 6.279
    learner:
      cur_lr: 0.0011408859863877296
      grad_gnorm: 40.0
      policy_entropy: 33.56379699707031
      policy_loss: -27.290014266967773
      var_gnorm: 52.14133834838867
      vf_explained_var: -0.01254117488861084
      vf_loss: 200.0187530517578
    num_steps_sampled: 3300000
    num_steps_trained: 3300000
    wait_time_ms: 247.442
  iterations_since_restore: 330
  node_ip: 172.17.8.6
  num_metric_batches_dropped: 0
  pid: 13557
  policy_reward_mean: {}
  time_since_restore: 8095.934212684631
  time_this_iter_s: 23.756774425506592
  time_total_s: 8095.934212684631
  timestamp: 1594102904
  timesteps_since_restore: 3300000
  timesteps_this_iter: 10000
  timesteps_total: 3300000
  training_iteration: 330
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 29.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=13557], 8095 s, 330 iter, 3300000 ts, 1.2e+03 rew

agent-1: 99.0
agent-2: 92.0
agent-3: 89.0
agent-4: 61.0
agent-5: 105.0
agent-6: 90.0
agent-7: 95.0
agent-8: 100.0
agent-9: 123.0
agent-10: 79.0
Sum Reward: 933.0
Avg Reward: 93.3
Min Reward: 61.0
Max Reward: 123.0
Gini Coefficient: 0.08842443729903537
20:20 Ratio: 1.6285714285714286
Max-min Ratio: 2.0163934426229506
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_02-22-09
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1861.0
  episode_reward_mean: 1200.84
  episode_reward_min: 863.0
  episodes_this_iter: 1
  episodes_total: 330
  experiment_id: a3942a9886f24694ab1b58ca8d1ab856
  hostname: gpu006
  info:
    apply_time_ms: 2.839
    dispatch_time_ms: 6.107
    learner:
      cur_lr: 0.0011402199743315578
      grad_gnorm: 7.973909378051758
      policy_entropy: 63.021705627441406
      policy_loss: -1.426326870918274
      var_gnorm: 52.19719696044922
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 0.03760671615600586
    num_steps_sampled: 3310000
    num_steps_trained: 3310000
    wait_time_ms: 207.746
  iterations_since_restore: 331
  node_ip: 172.17.8.6
  num_metric_batches_dropped: 0
  pid: 13557
  policy_reward_mean: {}
  time_since_restore: 8120.831662893295
  time_this_iter_s: 24.89745020866394
  time_total_s: 8120.831662893295
  timestamp: 1594102929
  timesteps_since_restore: 3310000
  timesteps_this_iter: 10000
  timesteps_total: 3310000
  training_iteration: 331
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 29.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=13557], 8120 s, 331 iter, 3310000 ts, 1.2e+03 rew

agent-1: 146.0
agent-2: 135.0
agent-3: 153.0
agent-4: 140.0
agent-5: 123.0
agent-6: 140.0
agent-7: 135.0
agent-8: 131.0
agent-9: 127.0
agent-10: 136.0
Sum Reward: 1366.0
Avg Reward: 136.6
Min Reward: 123.0
Max Reward: 153.0
Gini Coefficient: 0.03396778916544656
20:20 Ratio: 1.196
Max-min Ratio: 1.2439024390243902
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_02-22-35
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1861.0
  episode_reward_mean: 1204.67
  episode_reward_min: 863.0
  episodes_this_iter: 1
  episodes_total: 331
  experiment_id: a3942a9886f24694ab1b58ca8d1ab856
  hostname: gpu006
  info:
    apply_time_ms: 2.782
    dispatch_time_ms: 7.827
    learner:
      cur_lr: 0.0011395539622753859
      grad_gnorm: 40.00000762939453
      policy_entropy: 17.03765106201172
      policy_loss: -43.720802307128906
      var_gnorm: 52.34654998779297
      vf_explained_var: 0.7742011547088623
      vf_loss: 209.11737060546875
    num_steps_sampled: 3320000
    num_steps_trained: 3320000
    wait_time_ms: 237.393
  iterations_since_restore: 332
  node_ip: 172.17.8.6
  num_metric_batches_dropped: 0
  pid: 13557
  policy_reward_mean: {}
  time_since_restore: 8146.393161058426
  time_this_iter_s: 25.561498165130615
  time_total_s: 8146.393161058426
  timestamp: 1594102955
  timesteps_since_restore: 3320000
  timesteps_this_iter: 10000
  timesteps_total: 3320000
  training_iteration: 332
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 29.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=13557], 8146 s, 332 iter, 3320000 ts, 1.2e+03 rew

agent-1: 92.0
agent-2: 103.0
agent-3: 98.0
agent-4: 80.0
agent-5: 110.0
agent-6: 116.0
agent-7: 94.0
agent-8: 93.0
agent-9: 98.0
agent-10: 84.0
Sum Reward: 968.0
Avg Reward: 96.8
Min Reward: 80.0
Max Reward: 116.0
Gini Coefficient: 0.05991735537190083
20:20 Ratio: 1.3780487804878048
Max-min Ratio: 1.45
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_02-23-00
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1861.0
  episode_reward_mean: 1204.79
  episode_reward_min: 863.0
  episodes_this_iter: 1
  episodes_total: 332
  experiment_id: a3942a9886f24694ab1b58ca8d1ab856
  hostname: gpu006
  info:
    apply_time_ms: 2.689
    dispatch_time_ms: 6.912
    learner:
      cur_lr: 0.001138887950219214
      grad_gnorm: 39.99999237060547
      policy_entropy: 26.37149429321289
      policy_loss: -1.1939395666122437
      var_gnorm: 52.42728805541992
      vf_explained_var: 0.6763169765472412
      vf_loss: 127.6538314819336
    num_steps_sampled: 3330000
    num_steps_trained: 3330000
    wait_time_ms: 230.461
  iterations_since_restore: 333
  node_ip: 172.17.8.6
  num_metric_batches_dropped: 0
  pid: 13557
  policy_reward_mean: {}
  time_since_restore: 8171.959286928177
  time_this_iter_s: 25.566125869750977
  time_total_s: 8171.959286928177
  timestamp: 1594102980
  timesteps_since_restore: 3330000
  timesteps_this_iter: 10000
  timesteps_total: 3330000
  training_iteration: 333
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 29.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=13557], 8171 s, 333 iter, 3330000 ts, 1.2e+03 rew

agent-1: 109.0
agent-2: 91.0
agent-3: 104.0
agent-4: 97.0
agent-5: 128.0
agent-6: 120.0
agent-7: 107.0
agent-8: 137.0
agent-9: 136.0
agent-10: 98.0
Sum Reward: 1127.0
Avg Reward: 112.7
Min Reward: 91.0
Max Reward: 137.0
Gini Coefficient: 0.07870452528837622
20:20 Ratio: 1.452127659574468
Max-min Ratio: 1.5054945054945055
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_02-23-25
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1861.0
  episode_reward_mean: 1204.36
  episode_reward_min: 863.0
  episodes_this_iter: 1
  episodes_total: 333
  experiment_id: a3942a9886f24694ab1b58ca8d1ab856
  hostname: gpu006
  info:
    apply_time_ms: 2.79
    dispatch_time_ms: 10.393
    learner:
      cur_lr: 0.001138222054578364
      grad_gnorm: 6.559498310089111
      policy_entropy: 35.6524772644043
      policy_loss: -0.8414834141731262
      var_gnorm: 52.530235290527344
      vf_explained_var: 0.9896867871284485
      vf_loss: 0.02986166998744011
    num_steps_sampled: 3340000
    num_steps_trained: 3340000
    wait_time_ms: 248.214
  iterations_since_restore: 334
  node_ip: 172.17.8.6
  num_metric_batches_dropped: 0
  pid: 13557
  policy_reward_mean: {}
  time_since_restore: 8196.287554740906
  time_this_iter_s: 24.328267812728882
  time_total_s: 8196.287554740906
  timestamp: 1594103005
  timesteps_since_restore: 3340000
  timesteps_this_iter: 10000
  timesteps_total: 3340000
  training_iteration: 334
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 29.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=13557], 8196 s, 334 iter, 3340000 ts, 1.2e+03 rew

agent-1: 88.0
agent-2: 111.0
agent-3: 75.0
agent-4: 110.0
agent-5: 92.0
agent-6: 129.0
agent-7: 85.0
agent-8: 140.0
agent-9: 106.0
agent-10: 101.0
Sum Reward: 1037.0
Avg Reward: 103.7
Min Reward: 75.0
Max Reward: 140.0
Gini Coefficient: 0.10289296046287368
20:20 Ratio: 1.68125
Max-min Ratio: 1.8666666666666667
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_02-23-50
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1861.0
  episode_reward_mean: 1203.03
  episode_reward_min: 863.0
  episodes_this_iter: 1
  episodes_total: 334
  experiment_id: a3942a9886f24694ab1b58ca8d1ab856
  hostname: gpu006
  info:
    apply_time_ms: 3.119
    dispatch_time_ms: 20.297
    learner:
      cur_lr: 0.001137556042522192
      grad_gnorm: 7.674037933349609
      policy_entropy: 45.83543014526367
      policy_loss: -0.8457831740379333
      var_gnorm: 52.51559066772461
      vf_explained_var: 0.0
      vf_loss: 0.035147566348314285
    num_steps_sampled: 3350000
    num_steps_trained: 3350000
    wait_time_ms: 220.476
  iterations_since_restore: 335
  node_ip: 172.17.8.6
  num_metric_batches_dropped: 0
  pid: 13557
  policy_reward_mean: {}
  time_since_restore: 8222.030067205429
  time_this_iter_s: 25.742512464523315
  time_total_s: 8222.030067205429
  timestamp: 1594103030
  timesteps_since_restore: 3350000
  timesteps_this_iter: 10000
  timesteps_total: 3350000
  training_iteration: 335
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 29.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=13557], 8222 s, 335 iter, 3350000 ts, 1.2e+03 rew

agent-1: 89.0
agent-2: 89.0
agent-3: 84.0
agent-4: 81.0
agent-5: 69.0
agent-6: 85.0
agent-7: 87.0
agent-8: 85.0
agent-9: 72.0
agent-10: 80.0
Sum Reward: 821.0
Avg Reward: 82.1
Min Reward: 69.0
Max Reward: 89.0
Gini Coefficient: 0.04226552984165652
20:20 Ratio: 1.2624113475177305
Max-min Ratio: 1.289855072463768
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_02-24-15
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1861.0
  episode_reward_mean: 1197.97
  episode_reward_min: 821.0
  episodes_this_iter: 1
  episodes_total: 335
  experiment_id: a3942a9886f24694ab1b58ca8d1ab856
  hostname: gpu006
  info:
    apply_time_ms: 2.57
    dispatch_time_ms: 21.432
    learner:
      cur_lr: 0.00113689003046602
      grad_gnorm: 40.0
      policy_entropy: 52.569793701171875
      policy_loss: -2.361801862716675
      var_gnorm: 52.5235595703125
      vf_explained_var: -0.284332275390625
      vf_loss: 12.575654029846191
    num_steps_sampled: 3360000
    num_steps_trained: 3360000
    wait_time_ms: 240.3
  iterations_since_restore: 336
  node_ip: 172.17.8.6
  num_metric_batches_dropped: 0
  pid: 13557
  policy_reward_mean: {}
  time_since_restore: 8246.963275671005
  time_this_iter_s: 24.933208465576172
  time_total_s: 8246.963275671005
  timestamp: 1594103055
  timesteps_since_restore: 3360000
  timesteps_this_iter: 10000
  timesteps_total: 3360000
  training_iteration: 336
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 29.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=13557], 8246 s, 336 iter, 3360000 ts, 1.2e+03 rew

agent-1: 90.0
agent-2: 99.0
agent-3: 65.0
agent-4: 88.0
agent-5: 121.0
agent-6: 101.0
agent-7: 111.0
agent-8: 101.0
agent-9: 106.0
agent-10: 99.0
Sum Reward: 981.0
Avg Reward: 98.1
Min Reward: 65.0
Max Reward: 121.0
Gini Coefficient: 0.07675840978593272
20:20 Ratio: 1.5163398692810457
Max-min Ratio: 1.8615384615384616
W0707 02:24:41.393537 13553 client_connection.cc:255] [worker]ProcessMessage with type 8 took 563 ms.
W0707 02:24:41.767273 13553 node_manager.cc:250] Last heartbeat was sent 947 ms ago 
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_02-24-43
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1861.0
  episode_reward_mean: 1196.25
  episode_reward_min: 821.0
  episodes_this_iter: 1
  episodes_total: 336
  experiment_id: a3942a9886f24694ab1b58ca8d1ab856
  hostname: gpu006
  info:
    apply_time_ms: 2.805
    dispatch_time_ms: 117.449
    learner:
      cur_lr: 0.0011362240184098482
      grad_gnorm: 40.0
      policy_entropy: 15.21977424621582
      policy_loss: -2.874473810195923
      var_gnorm: 52.559165954589844
      vf_explained_var: 0.7973574995994568
      vf_loss: 100.36309051513672
    num_steps_sampled: 3370000
    num_steps_trained: 3370000
    wait_time_ms: 218.531
  iterations_since_restore: 337
  node_ip: 172.17.8.6
  num_metric_batches_dropped: 0
  pid: 13557
  policy_reward_mean: {}
  time_since_restore: 8274.644968509674
  time_this_iter_s: 27.681692838668823
  time_total_s: 8274.644968509674
  timestamp: 1594103083
  timesteps_since_restore: 3370000
  timesteps_this_iter: 10000
  timesteps_total: 3370000
  training_iteration: 337
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 29.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=13557], 8274 s, 337 iter, 3370000 ts, 1.2e+03 rew

agent-1: 50.0
agent-2: 93.0
agent-3: 75.0
agent-4: 98.0
agent-5: 112.0
agent-6: 101.0
agent-7: 94.0
agent-8: 78.0
agent-9: 84.0
agent-10: 75.0
Sum Reward: 860.0
Avg Reward: 86.0
Min Reward: 50.0
Max Reward: 112.0
Gini Coefficient: 0.10604651162790697
20:20 Ratio: 1.704
Max-min Ratio: 2.24
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_02-25-07
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1861.0
  episode_reward_mean: 1195.14
  episode_reward_min: 821.0
  episodes_this_iter: 1
  episodes_total: 337
  experiment_id: a3942a9886f24694ab1b58ca8d1ab856
  hostname: gpu006
  info:
    apply_time_ms: 2.958
    dispatch_time_ms: 26.877
    learner:
      cur_lr: 0.0011355580063536763
      grad_gnorm: 3.3056066036224365
      policy_entropy: 18.83979034423828
      policy_loss: -0.2064976990222931
      var_gnorm: 52.57033157348633
      vf_explained_var: 0.991111695766449
      vf_loss: 0.007821337319910526
    num_steps_sampled: 3380000
    num_steps_trained: 3380000
    wait_time_ms: 243.669
  iterations_since_restore: 338
  node_ip: 172.17.8.6
  num_metric_batches_dropped: 0
  pid: 13557
  policy_reward_mean: {}
  time_since_restore: 8298.944694757462
  time_this_iter_s: 24.299726247787476
  time_total_s: 8298.944694757462
  timestamp: 1594103107
  timesteps_since_restore: 3380000
  timesteps_this_iter: 10000
  timesteps_total: 3380000
  training_iteration: 338
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 29.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=13557], 8298 s, 338 iter, 3380000 ts, 1.2e+03 rew

W0707 02:25:16.942947 13553 client_connection.cc:255] [worker]ProcessMessage with type 16 took 102 ms.
agent-1: 76.0
agent-2: 86.0
agent-3: 88.0
agent-4: 153.0
agent-5: 95.0
agent-6: 78.0
agent-7: 106.0
agent-8: 86.0
agent-9: 74.0
agent-10: 80.0
Sum Reward: 922.0
Avg Reward: 92.2
Min Reward: 74.0
Max Reward: 153.0
Gini Coefficient: 0.11171366594360087
20:20 Ratio: 1.7266666666666666
Max-min Ratio: 2.0675675675675675
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_02-25-40
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1861.0
  episode_reward_mean: 1192.05
  episode_reward_min: 821.0
  episodes_this_iter: 1
  episodes_total: 338
  experiment_id: a3942a9886f24694ab1b58ca8d1ab856
  hostname: gpu006
  info:
    apply_time_ms: 2.539
    dispatch_time_ms: 5.386
    learner:
      cur_lr: 0.0011348919942975044
      grad_gnorm: 6.245632171630859
      policy_entropy: 14.106401443481445
      policy_loss: -0.23744191229343414
      var_gnorm: 52.652381896972656
      vf_explained_var: -1.0
      vf_loss: 0.06569724529981613
    num_steps_sampled: 3390000
    num_steps_trained: 3390000
    wait_time_ms: 228.918
  iterations_since_restore: 339
  node_ip: 172.17.8.6
  num_metric_batches_dropped: 0
  pid: 13557
  policy_reward_mean: {}
  time_since_restore: 8322.799254179
  time_this_iter_s: 23.854559421539307
  time_total_s: 8322.799254179
  timestamp: 1594103140
  timesteps_since_restore: 3390000
  timesteps_this_iter: 10000
  timesteps_total: 3390000
  training_iteration: 339
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 29.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=13557], 8322 s, 339 iter, 3390000 ts, 1.19e+03 rew

agent-1: 115.0
agent-2: 93.0
agent-3: 106.0
agent-4: 81.0
agent-5: 117.0
agent-6: 99.0
agent-7: 90.0
agent-8: 116.0
agent-9: 111.0
agent-10: 116.0
Sum Reward: 1044.0
Avg Reward: 104.4
Min Reward: 81.0
Max Reward: 117.0
Gini Coefficient: 0.06455938697318007
20:20 Ratio: 1.3625730994152048
Max-min Ratio: 1.4444444444444444
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_02-26-04
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1861.0
  episode_reward_mean: 1188.7
  episode_reward_min: 821.0
  episodes_this_iter: 1
  episodes_total: 339
  experiment_id: a3942a9886f24694ab1b58ca8d1ab856
  hostname: gpu006
  info:
    apply_time_ms: 2.49
    dispatch_time_ms: 8.424
    learner:
      cur_lr: 0.0011342259822413325
      grad_gnorm: 40.00001907348633
      policy_entropy: 25.75495147705078
      policy_loss: 2.4385218620300293
      var_gnorm: 52.6700553894043
      vf_explained_var: -0.9069632291793823
      vf_loss: 323.8722229003906
    num_steps_sampled: 3400000
    num_steps_trained: 3400000
    wait_time_ms: 235.86
  iterations_since_restore: 340
  node_ip: 172.17.8.6
  num_metric_batches_dropped: 0
  pid: 13557
  policy_reward_mean: {}
  time_since_restore: 8346.019021987915
  time_this_iter_s: 23.219767808914185
  time_total_s: 8346.019021987915
  timestamp: 1594103164
  timesteps_since_restore: 3400000
  timesteps_this_iter: 10000
  timesteps_total: 3400000
  training_iteration: 340
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 29.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=13557], 8346 s, 340 iter, 3400000 ts, 1.19e+03 rew

agent-1: 82.0
agent-2: 99.0
agent-3: 157.0
agent-4: 104.0
agent-5: 106.0
agent-6: 114.0
agent-7: 92.0
agent-8: 106.0
agent-9: 99.0
agent-10: 111.0
Sum Reward: 1070.0
Avg Reward: 107.0
Min Reward: 82.0
Max Reward: 157.0
Gini Coefficient: 0.08523364485981308
20:20 Ratio: 1.5574712643678161
Max-min Ratio: 1.9146341463414633
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_02-26-29
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1861.0
  episode_reward_mean: 1185.2
  episode_reward_min: 821.0
  episodes_this_iter: 1
  episodes_total: 340
  experiment_id: a3942a9886f24694ab1b58ca8d1ab856
  hostname: gpu006
  info:
    apply_time_ms: 2.562
    dispatch_time_ms: 6.5
    learner:
      cur_lr: 0.0011335599701851606
      grad_gnorm: 2.3330655097961426
      policy_entropy: 27.244686126708984
      policy_loss: -0.089238740503788
      var_gnorm: 52.714656829833984
      vf_explained_var: 0.9503894448280334
      vf_loss: 0.013980120420455933
    num_steps_sampled: 3410000
    num_steps_trained: 3410000
    wait_time_ms: 203.726
  iterations_since_restore: 341
  node_ip: 172.17.8.6
  num_metric_batches_dropped: 0
  pid: 13557
  policy_reward_mean: {}
  time_since_restore: 8371.490200996399
  time_this_iter_s: 25.471179008483887
  time_total_s: 8371.490200996399
  timestamp: 1594103189
  timesteps_since_restore: 3410000
  timesteps_this_iter: 10000
  timesteps_total: 3410000
  training_iteration: 341
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 29.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=13557], 8371 s, 341 iter, 3410000 ts, 1.19e+03 rew

agent-1: 107.0
agent-2: 97.0
agent-3: 127.0
agent-4: 122.0
agent-5: 113.0
agent-6: 121.0
agent-7: 92.0
agent-8: 129.0
agent-9: 108.0
agent-10: 116.0
Sum Reward: 1132.0
Avg Reward: 113.2
Min Reward: 92.0
Max Reward: 129.0
Gini Coefficient: 0.05830388692579505
20:20 Ratio: 1.3544973544973544
Max-min Ratio: 1.4021739130434783
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_02-26-52
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1861.0
  episode_reward_mean: 1184.88
  episode_reward_min: 821.0
  episodes_this_iter: 1
  episodes_total: 341
  experiment_id: a3942a9886f24694ab1b58ca8d1ab856
  hostname: gpu006
  info:
    apply_time_ms: 3.717
    dispatch_time_ms: 5.634
    learner:
      cur_lr: 0.0011328939581289887
      grad_gnorm: 40.00003433227539
      policy_entropy: 43.209564208984375
      policy_loss: -6.0908708572387695
      var_gnorm: 52.89069366455078
      vf_explained_var: 0.976002037525177
      vf_loss: 18.11189079284668
    num_steps_sampled: 3420000
    num_steps_trained: 3420000
    wait_time_ms: 237.388
  iterations_since_restore: 342
  node_ip: 172.17.8.6
  num_metric_batches_dropped: 0
  pid: 13557
  policy_reward_mean: {}
  time_since_restore: 8394.003096818924
  time_this_iter_s: 22.512895822525024
  time_total_s: 8394.003096818924
  timestamp: 1594103212
  timesteps_since_restore: 3420000
  timesteps_this_iter: 10000
  timesteps_total: 3420000
  training_iteration: 342
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 29.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=13557], 8394 s, 342 iter, 3420000 ts, 1.18e+03 rew

agent-1: 105.0
agent-2: 111.0
agent-3: 101.0
agent-4: 129.0
agent-5: 159.0
agent-6: 105.0
agent-7: 121.0
agent-8: 169.0
agent-9: 92.0
agent-10: 131.0
Sum Reward: 1223.0
Avg Reward: 122.3
Min Reward: 92.0
Max Reward: 169.0
Gini Coefficient: 0.10719542109566639
20:20 Ratio: 1.6994818652849741
Max-min Ratio: 1.8369565217391304
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_02-27-17
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1861.0
  episode_reward_mean: 1186.01
  episode_reward_min: 821.0
  episodes_this_iter: 1
  episodes_total: 342
  experiment_id: a3942a9886f24694ab1b58ca8d1ab856
  hostname: gpu006
  info:
    apply_time_ms: 3.058
    dispatch_time_ms: 8.371
    learner:
      cur_lr: 0.0011322279460728168
      grad_gnorm: 19.64501190185547
      policy_entropy: 37.65470886230469
      policy_loss: 2.5852103233337402
      var_gnorm: 52.975250244140625
      vf_explained_var: 0.12520581483840942
      vf_loss: 2.9020533561706543
    num_steps_sampled: 3430000
    num_steps_trained: 3430000
    wait_time_ms: 204.087
  iterations_since_restore: 343
  node_ip: 172.17.8.6
  num_metric_batches_dropped: 0
  pid: 13557
  policy_reward_mean: {}
  time_since_restore: 8418.903921604156
  time_this_iter_s: 24.900824785232544
  time_total_s: 8418.903921604156
  timestamp: 1594103237
  timesteps_since_restore: 3430000
  timesteps_this_iter: 10000
  timesteps_total: 3430000
  training_iteration: 343
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 29.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=13557], 8418 s, 343 iter, 3430000 ts, 1.19e+03 rew

agent-1: 181.0
agent-2: 186.0
agent-3: 145.0
agent-4: 178.0
agent-5: 150.0
agent-6: 172.0
agent-7: 180.0
agent-8: 139.0
agent-9: 121.0
agent-10: 156.0
Sum Reward: 1608.0
Avg Reward: 160.8
Min Reward: 121.0
Max Reward: 186.0
Gini Coefficient: 0.07176616915422886
20:20 Ratio: 1.4115384615384616
Max-min Ratio: 1.537190082644628
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_02-27-39
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1861.0
  episode_reward_mean: 1190.67
  episode_reward_min: 821.0
  episodes_this_iter: 1
  episodes_total: 343
  experiment_id: a3942a9886f24694ab1b58ca8d1ab856
  hostname: gpu006
  info:
    apply_time_ms: 2.771
    dispatch_time_ms: 6.367
    learner:
      cur_lr: 0.0011315620504319668
      grad_gnorm: 40.0
      policy_entropy: 25.436525344848633
      policy_loss: -5.611222267150879
      var_gnorm: 52.97087478637695
      vf_explained_var: 0.8300877213478088
      vf_loss: 58.7788200378418
    num_steps_sampled: 3440000
    num_steps_trained: 3440000
    wait_time_ms: 244.939
  iterations_since_restore: 344
  node_ip: 172.17.8.6
  num_metric_batches_dropped: 0
  pid: 13557
  policy_reward_mean: {}
  time_since_restore: 8441.623117685318
  time_this_iter_s: 22.7191960811615
  time_total_s: 8441.623117685318
  timestamp: 1594103259
  timesteps_since_restore: 3440000
  timesteps_this_iter: 10000
  timesteps_total: 3440000
  training_iteration: 344
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 29.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=13557], 8441 s, 344 iter, 3440000 ts, 1.19e+03 rew

agent-1: 107.0
agent-2: 166.0
agent-3: 105.0
agent-4: 119.0
agent-5: 105.0
agent-6: 114.0
agent-7: 115.0
agent-8: 167.0
agent-9: 131.0
agent-10: 99.0
Sum Reward: 1228.0
Avg Reward: 122.8
Min Reward: 99.0
Max Reward: 167.0
Gini Coefficient: 0.09820846905537459
20:20 Ratio: 1.6323529411764706
Max-min Ratio: 1.6868686868686869
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_02-28-05
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1861.0
  episode_reward_mean: 1192.02
  episode_reward_min: 821.0
  episodes_this_iter: 1
  episodes_total: 344
  experiment_id: a3942a9886f24694ab1b58ca8d1ab856
  hostname: gpu006
  info:
    apply_time_ms: 2.59
    dispatch_time_ms: 8.978
    learner:
      cur_lr: 0.0011308960383757949
      grad_gnorm: 40.000003814697266
      policy_entropy: 20.736597061157227
      policy_loss: 6.48924446105957
      var_gnorm: 53.06199264526367
      vf_explained_var: 0.6099066138267517
      vf_loss: 79.00527954101562
    num_steps_sampled: 3450000
    num_steps_trained: 3450000
    wait_time_ms: 212.421
  iterations_since_restore: 345
  node_ip: 172.17.8.6
  num_metric_batches_dropped: 0
  pid: 13557
  policy_reward_mean: {}
  time_since_restore: 8466.940421104431
  time_this_iter_s: 25.31730341911316
  time_total_s: 8466.940421104431
  timestamp: 1594103285
  timesteps_since_restore: 3450000
  timesteps_this_iter: 10000
  timesteps_total: 3450000
  training_iteration: 345
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 29.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=13557], 8466 s, 345 iter, 3450000 ts, 1.19e+03 rew

agent-1: 135.0
agent-2: 129.0
agent-3: 133.0
agent-4: 115.0
agent-5: 146.0
agent-6: 157.0
agent-7: 125.0
agent-8: 165.0
agent-9: 130.0
agent-10: 120.0
Sum Reward: 1355.0
Avg Reward: 135.5
Min Reward: 115.0
Max Reward: 165.0
Gini Coefficient: 0.06162361623616236
20:20 Ratio: 1.3702127659574468
Max-min Ratio: 1.434782608695652
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_02-28-27
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1861.0
  episode_reward_mean: 1190.1
  episode_reward_min: 821.0
  episodes_this_iter: 1
  episodes_total: 345
  experiment_id: a3942a9886f24694ab1b58ca8d1ab856
  hostname: gpu006
  info:
    apply_time_ms: 2.84
    dispatch_time_ms: 5.589
    learner:
      cur_lr: 0.001130230026319623
      grad_gnorm: 40.0000114440918
      policy_entropy: 41.049598693847656
      policy_loss: -1.1757091283798218
      var_gnorm: 53.03495407104492
      vf_explained_var: 0.548591136932373
      vf_loss: 13.324912071228027
    num_steps_sampled: 3460000
    num_steps_trained: 3460000
    wait_time_ms: 246.392
  iterations_since_restore: 346
  node_ip: 172.17.8.6
  num_metric_batches_dropped: 0
  pid: 13557
  policy_reward_mean: {}
  time_since_restore: 8489.558513641357
  time_this_iter_s: 22.61809253692627
  time_total_s: 8489.558513641357
  timestamp: 1594103307
  timesteps_since_restore: 3460000
  timesteps_this_iter: 10000
  timesteps_total: 3460000
  training_iteration: 346
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 29.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=13557], 8489 s, 346 iter, 3460000 ts, 1.19e+03 rew

agent-1: 126.0
agent-2: 106.0
agent-3: 106.0
agent-4: 131.0
agent-5: 142.0
agent-6: 125.0
agent-7: 88.0
agent-8: 121.0
agent-9: 120.0
agent-10: 135.0
Sum Reward: 1200.0
Avg Reward: 120.0
Min Reward: 88.0
Max Reward: 142.0
Gini Coefficient: 0.06966666666666667
20:20 Ratio: 1.4278350515463918
Max-min Ratio: 1.6136363636363635
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_02-28-53
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1861.0
  episode_reward_mean: 1187.72
  episode_reward_min: 821.0
  episodes_this_iter: 1
  episodes_total: 346
  experiment_id: a3942a9886f24694ab1b58ca8d1ab856
  hostname: gpu006
  info:
    apply_time_ms: 2.709
    dispatch_time_ms: 7.526
    learner:
      cur_lr: 0.001129564014263451
      grad_gnorm: 3.307812452316284
      policy_entropy: 48.05792999267578
      policy_loss: -0.5054097175598145
      var_gnorm: 53.09987258911133
      vf_explained_var: 0.9925459027290344
      vf_loss: 0.021153084933757782
    num_steps_sampled: 3470000
    num_steps_trained: 3470000
    wait_time_ms: 250.058
  iterations_since_restore: 347
  node_ip: 172.17.8.6
  num_metric_batches_dropped: 0
  pid: 13557
  policy_reward_mean: {}
  time_since_restore: 8515.514783620834
  time_this_iter_s: 25.95626997947693
  time_total_s: 8515.514783620834
  timestamp: 1594103333
  timesteps_since_restore: 3470000
  timesteps_this_iter: 10000
  timesteps_total: 3470000
  training_iteration: 347
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 29.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=13557], 8515 s, 347 iter, 3470000 ts, 1.19e+03 rew

agent-1: 196.0
agent-2: 132.0
agent-3: 133.0
agent-4: 105.0
agent-5: 113.0
agent-6: 111.0
agent-7: 98.0
agent-8: 117.0
agent-9: 128.0
agent-10: 128.0
Sum Reward: 1261.0
Avg Reward: 126.1
Min Reward: 98.0
Max Reward: 196.0
Gini Coefficient: 0.09825535289452815
20:20 Ratio: 1.6206896551724137
Max-min Ratio: 2.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_02-29-16
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1861.0
  episode_reward_mean: 1190.42
  episode_reward_min: 821.0
  episodes_this_iter: 1
  episodes_total: 347
  experiment_id: a3942a9886f24694ab1b58ca8d1ab856
  hostname: gpu006
  info:
    apply_time_ms: 2.711
    dispatch_time_ms: 6.503
    learner:
      cur_lr: 0.0011288980022072792
      grad_gnorm: 40.000003814697266
      policy_entropy: 42.20197677612305
      policy_loss: 1.2308707237243652
      var_gnorm: 53.212974548339844
      vf_explained_var: 0.9109634757041931
      vf_loss: 43.69453048706055
    num_steps_sampled: 3480000
    num_steps_trained: 3480000
    wait_time_ms: 260.652
  iterations_since_restore: 348
  node_ip: 172.17.8.6
  num_metric_batches_dropped: 0
  pid: 13557
  policy_reward_mean: {}
  time_since_restore: 8537.902762413025
  time_this_iter_s: 22.38797879219055
  time_total_s: 8537.902762413025
  timestamp: 1594103356
  timesteps_since_restore: 3480000
  timesteps_this_iter: 10000
  timesteps_total: 3480000
  training_iteration: 348
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 29.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=13557], 8537 s, 348 iter, 3480000 ts, 1.19e+03 rew

agent-1: 137.0
agent-2: 123.0
agent-3: 139.0
agent-4: 115.0
agent-5: 133.0
agent-6: 119.0
agent-7: 96.0
agent-8: 116.0
agent-9: 115.0
agent-10: 110.0
Sum Reward: 1203.0
Avg Reward: 120.3
Min Reward: 96.0
Max Reward: 139.0
Gini Coefficient: 0.057605985037406486
20:20 Ratio: 1.3398058252427185
Max-min Ratio: 1.4479166666666667
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_02-29-42
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1861.0
  episode_reward_mean: 1193.59
  episode_reward_min: 821.0
  episodes_this_iter: 1
  episodes_total: 348
  experiment_id: a3942a9886f24694ab1b58ca8d1ab856
  hostname: gpu006
  info:
    apply_time_ms: 3.344
    dispatch_time_ms: 6.907
    learner:
      cur_lr: 0.0011282319901511073
      grad_gnorm: 3.85843563079834
      policy_entropy: 36.82075119018555
      policy_loss: 0.8253304362297058
      var_gnorm: 53.273834228515625
      vf_explained_var: 0.977658212184906
      vf_loss: 0.0090750427916646
    num_steps_sampled: 3490000
    num_steps_trained: 3490000
    wait_time_ms: 206.952
  iterations_since_restore: 349
  node_ip: 172.17.8.6
  num_metric_batches_dropped: 0
  pid: 13557
  policy_reward_mean: {}
  time_since_restore: 8564.191769123077
  time_this_iter_s: 26.28900671005249
  time_total_s: 8564.191769123077
  timestamp: 1594103382
  timesteps_since_restore: 3490000
  timesteps_this_iter: 10000
  timesteps_total: 3490000
  training_iteration: 349
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 29.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=13557], 8564 s, 349 iter, 3490000 ts, 1.19e+03 rew

agent-1: 106.0
agent-2: 108.0
agent-3: 114.0
agent-4: 100.0
agent-5: 133.0
agent-6: 133.0
agent-7: 125.0
agent-8: 97.0
agent-9: 112.0
agent-10: 102.0
Sum Reward: 1130.0
Avg Reward: 113.0
Min Reward: 97.0
Max Reward: 133.0
Gini Coefficient: 0.061769911504424777
20:20 Ratio: 1.350253807106599
Max-min Ratio: 1.3711340206185567
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_02-30-05
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1861.0
  episode_reward_mean: 1195.09
  episode_reward_min: 821.0
  episodes_this_iter: 1
  episodes_total: 349
  experiment_id: a3942a9886f24694ab1b58ca8d1ab856
  hostname: gpu006
  info:
    apply_time_ms: 2.63
    dispatch_time_ms: 6.127
    learner:
      cur_lr: 0.0011275659780949354
      grad_gnorm: 40.00002670288086
      policy_entropy: 68.15142822265625
      policy_loss: -5.426731586456299
      var_gnorm: 53.31398010253906
      vf_explained_var: -1.0
      vf_loss: 1.4930530786514282
    num_steps_sampled: 3500000
    num_steps_trained: 3500000
    wait_time_ms: 244.551
  iterations_since_restore: 350
  node_ip: 172.17.8.6
  num_metric_batches_dropped: 0
  pid: 13557
  policy_reward_mean: {}
  time_since_restore: 8586.944976329803
  time_this_iter_s: 22.753207206726074
  time_total_s: 8586.944976329803
  timestamp: 1594103405
  timesteps_since_restore: 3500000
  timesteps_this_iter: 10000
  timesteps_total: 3500000
  training_iteration: 350
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 29.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=13557], 8586 s, 350 iter, 3500000 ts, 1.2e+03 rew

agent-1: 133.0
agent-2: 103.0
agent-3: 115.0
agent-4: 109.0
agent-5: 112.0
agent-6: 102.0
agent-7: 92.0
agent-8: 108.0
agent-9: 90.0
agent-10: 101.0
Sum Reward: 1065.0
Avg Reward: 106.5
Min Reward: 90.0
Max Reward: 133.0
Gini Coefficient: 0.05906103286384976
20:20 Ratio: 1.3626373626373627
Max-min Ratio: 1.4777777777777779
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_02-30-31
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1861.0
  episode_reward_mean: 1195.74
  episode_reward_min: 821.0
  episodes_this_iter: 1
  episodes_total: 350
  experiment_id: a3942a9886f24694ab1b58ca8d1ab856
  hostname: gpu006
  info:
    apply_time_ms: 2.728
    dispatch_time_ms: 6.003
    learner:
      cur_lr: 0.0011268999660387635
      grad_gnorm: 8.109046936035156
      policy_entropy: 66.62454986572266
      policy_loss: -1.6371057033538818
      var_gnorm: 53.336978912353516
      vf_explained_var: 0.37224268913269043
      vf_loss: 0.31334084272384644
    num_steps_sampled: 3510000
    num_steps_trained: 3510000
    wait_time_ms: 229.934
  iterations_since_restore: 351
  node_ip: 172.17.8.6
  num_metric_batches_dropped: 0
  pid: 13557
  policy_reward_mean: {}
  time_since_restore: 8613.186085700989
  time_this_iter_s: 26.241109371185303
  time_total_s: 8613.186085700989
  timestamp: 1594103431
  timesteps_since_restore: 3510000
  timesteps_this_iter: 10000
  timesteps_total: 3510000
  training_iteration: 351
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 29.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=13557], 8613 s, 351 iter, 3510000 ts, 1.2e+03 rew

agent-1: 131.0
agent-2: 128.0
agent-3: 114.0
agent-4: 144.0
agent-5: 108.0
agent-6: 116.0
agent-7: 112.0
agent-8: 108.0
agent-9: 97.0
agent-10: 119.0
Sum Reward: 1177.0
Avg Reward: 117.7
Min Reward: 97.0
Max Reward: 144.0
Gini Coefficient: 0.06006796941376381
20:20 Ratio: 1.3414634146341464
Max-min Ratio: 1.4845360824742269
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_02-30-54
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1861.0
  episode_reward_mean: 1194.45
  episode_reward_min: 821.0
  episodes_this_iter: 1
  episodes_total: 351
  experiment_id: a3942a9886f24694ab1b58ca8d1ab856
  hostname: gpu006
  info:
    apply_time_ms: 3.356
    dispatch_time_ms: 8.184
    learner:
      cur_lr: 0.0011262339539825916
      grad_gnorm: 40.000003814697266
      policy_entropy: 50.26832580566406
      policy_loss: 12.906754493713379
      var_gnorm: 53.42816162109375
      vf_explained_var: 0.5895868539810181
      vf_loss: 120.82701873779297
    num_steps_sampled: 3520000
    num_steps_trained: 3520000
    wait_time_ms: 251.932
  iterations_since_restore: 352
  node_ip: 172.17.8.6
  num_metric_batches_dropped: 0
  pid: 13557
  policy_reward_mean: {}
  time_since_restore: 8636.223870515823
  time_this_iter_s: 23.037784814834595
  time_total_s: 8636.223870515823
  timestamp: 1594103454
  timesteps_since_restore: 3520000
  timesteps_this_iter: 10000
  timesteps_total: 3520000
  training_iteration: 352
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 29.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=13557], 8636 s, 352 iter, 3520000 ts, 1.19e+03 rew

agent-1: 87.0
agent-2: 77.0
agent-3: 107.0
agent-4: 114.0
agent-5: 102.0
agent-6: 97.0
agent-7: 114.0
agent-8: 108.0
agent-9: 105.0
agent-10: 107.0
Sum Reward: 1018.0
Avg Reward: 101.8
Min Reward: 77.0
Max Reward: 114.0
Gini Coefficient: 0.05834970530451866
20:20 Ratio: 1.3902439024390243
Max-min Ratio: 1.4805194805194806
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_02-31-21
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1861.0
  episode_reward_mean: 1195.03
  episode_reward_min: 821.0
  episodes_this_iter: 1
  episodes_total: 352
  experiment_id: a3942a9886f24694ab1b58ca8d1ab856
  hostname: gpu006
  info:
    apply_time_ms: 2.997
    dispatch_time_ms: 7.962
    learner:
      cur_lr: 0.0011255679419264197
      grad_gnorm: 40.0
      policy_entropy: 59.54496383666992
      policy_loss: -4.267479419708252
      var_gnorm: 53.44673538208008
      vf_explained_var: 0.6145493388175964
      vf_loss: 33.89404296875
    num_steps_sampled: 3530000
    num_steps_trained: 3530000
    wait_time_ms: 252.995
  iterations_since_restore: 353
  node_ip: 172.17.8.6
  num_metric_batches_dropped: 0
  pid: 13557
  policy_reward_mean: {}
  time_since_restore: 8662.537905931473
  time_this_iter_s: 26.314035415649414
  time_total_s: 8662.537905931473
  timestamp: 1594103481
  timesteps_since_restore: 3530000
  timesteps_this_iter: 10000
  timesteps_total: 3530000
  training_iteration: 353
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 29.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=13557], 8662 s, 353 iter, 3530000 ts, 1.2e+03 rew

agent-1: 77.0
agent-2: 124.0
agent-3: 110.0
agent-4: 106.0
agent-5: 88.0
agent-6: 87.0
agent-7: 78.0
agent-8: 99.0
agent-9: 87.0
agent-10: 69.0
Sum Reward: 925.0
Avg Reward: 92.5
Min Reward: 69.0
Max Reward: 124.0
Gini Coefficient: 0.09762162162162162
20:20 Ratio: 1.6027397260273972
Max-min Ratio: 1.7971014492753623
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_02-31-43
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1861.0
  episode_reward_mean: 1192.98
  episode_reward_min: 821.0
  episodes_this_iter: 1
  episodes_total: 353
  experiment_id: a3942a9886f24694ab1b58ca8d1ab856
  hostname: gpu006
  info:
    apply_time_ms: 2.802
    dispatch_time_ms: 6.892
    learner:
      cur_lr: 0.0011249020462855697
      grad_gnorm: 40.0
      policy_entropy: 33.610206604003906
      policy_loss: -26.847936630249023
      var_gnorm: 53.350563049316406
      vf_explained_var: 0.734621524810791
      vf_loss: 486.91668701171875
    num_steps_sampled: 3540000
    num_steps_trained: 3540000
    wait_time_ms: 235.148
  iterations_since_restore: 354
  node_ip: 172.17.8.6
  num_metric_batches_dropped: 0
  pid: 13557
  policy_reward_mean: {}
  time_since_restore: 8684.65647983551
  time_this_iter_s: 22.118573904037476
  time_total_s: 8684.65647983551
  timestamp: 1594103503
  timesteps_since_restore: 3540000
  timesteps_this_iter: 10000
  timesteps_total: 3540000
  training_iteration: 354
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 29.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=13557], 8684 s, 354 iter, 3540000 ts, 1.19e+03 rew

agent-1: 108.0
agent-2: 128.0
agent-3: 138.0
agent-4: 125.0
agent-5: 154.0
agent-6: 98.0
agent-7: 112.0
agent-8: 101.0
agent-9: 128.0
agent-10: 99.0
Sum Reward: 1191.0
Avg Reward: 119.1
Min Reward: 98.0
Max Reward: 154.0
Gini Coefficient: 0.08270361041141898
20:20 Ratio: 1.482233502538071
Max-min Ratio: 1.5714285714285714
agent-1: 108.0
agent-2: 125.0
agent-3: 117.0
agent-4: 129.0
agent-5: 120.0
agent-6: 108.0
agent-7: 124.0
agent-8: 130.0
agent-9: 141.0
agent-10: 131.0
Sum Reward: 1233.0
Avg Reward: 123.3
Min Reward: 108.0
Max Reward: 141.0
Gini Coefficient: 0.04468775344687753
20:20 Ratio: 1.2592592592592593
Max-min Ratio: 1.3055555555555556
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_02-32-09
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1861.0
  episode_reward_mean: 1198.73
  episode_reward_min: 821.0
  episodes_this_iter: 2
  episodes_total: 355
  experiment_id: a3942a9886f24694ab1b58ca8d1ab856
  hostname: gpu006
  info:
    apply_time_ms: 2.623
    dispatch_time_ms: 7.927
    learner:
      cur_lr: 0.0011242360342293978
      grad_gnorm: 40.000003814697266
      policy_entropy: 48.75941848754883
      policy_loss: 11.916387557983398
      var_gnorm: 53.46308135986328
      vf_explained_var: -1.0
      vf_loss: 4.135863304138184
    num_steps_sampled: 3550000
    num_steps_trained: 3550000
    wait_time_ms: 252.355
  iterations_since_restore: 355
  node_ip: 172.17.8.6
  num_metric_batches_dropped: 0
  pid: 13557
  policy_reward_mean: {}
  time_since_restore: 8711.069412708282
  time_this_iter_s: 26.412932872772217
  time_total_s: 8711.069412708282
  timestamp: 1594103529
  timesteps_since_restore: 3550000
  timesteps_this_iter: 10000
  timesteps_total: 3550000
  training_iteration: 355
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 29.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=13557], 8711 s, 355 iter, 3550000 ts, 1.2e+03 rew

Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_02-32-32
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1861.0
  episode_reward_mean: 1198.73
  episode_reward_min: 821.0
  episodes_this_iter: 0
  episodes_total: 355
  experiment_id: a3942a9886f24694ab1b58ca8d1ab856
  hostname: gpu006
  info:
    apply_time_ms: 2.683
    dispatch_time_ms: 6.686
    learner:
      cur_lr: 0.0011235700221732259
      grad_gnorm: 39.9999885559082
      policy_entropy: 58.24433517456055
      policy_loss: -2.2175686359405518
      var_gnorm: 53.41219711303711
      vf_explained_var: -1.0
      vf_loss: 34.980289459228516
    num_steps_sampled: 3560000
    num_steps_trained: 3560000
    wait_time_ms: 253.883
  iterations_since_restore: 356
  node_ip: 172.17.8.6
  num_metric_batches_dropped: 0
  pid: 13557
  policy_reward_mean: {}
  time_since_restore: 8733.498019695282
  time_this_iter_s: 22.42860698699951
  time_total_s: 8733.498019695282
  timestamp: 1594103552
  timesteps_since_restore: 3560000
  timesteps_this_iter: 10000
  timesteps_total: 3560000
  training_iteration: 356
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 29.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=13557], 8733 s, 356 iter, 3560000 ts, 1.2e+03 rew

agent-1: 134.0
agent-2: 151.0
agent-3: 121.0
agent-4: 134.0
agent-5: 128.0
agent-6: 119.0
agent-7: 119.0
agent-8: 124.0
agent-9: 114.0
agent-10: 92.0
Sum Reward: 1236.0
Avg Reward: 123.6
Min Reward: 92.0
Max Reward: 151.0
Gini Coefficient: 0.0627831715210356
20:20 Ratio: 1.383495145631068
Max-min Ratio: 1.641304347826087
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_02-32-58
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1861.0
  episode_reward_mean: 1202.39
  episode_reward_min: 821.0
  episodes_this_iter: 1
  episodes_total: 356
  experiment_id: a3942a9886f24694ab1b58ca8d1ab856
  hostname: gpu006
  info:
    apply_time_ms: 2.782
    dispatch_time_ms: 6.387
    learner:
      cur_lr: 0.001122904010117054
      grad_gnorm: 40.000003814697266
      policy_entropy: 15.201156616210938
      policy_loss: 1.7219310998916626
      var_gnorm: 53.558807373046875
      vf_explained_var: 0.588401198387146
      vf_loss: 105.66656494140625
    num_steps_sampled: 3570000
    num_steps_trained: 3570000
    wait_time_ms: 229.458
  iterations_since_restore: 357
  node_ip: 172.17.8.6
  num_metric_batches_dropped: 0
  pid: 13557
  policy_reward_mean: {}
  time_since_restore: 8759.695836544037
  time_this_iter_s: 26.197816848754883
  time_total_s: 8759.695836544037
  timestamp: 1594103578
  timesteps_since_restore: 3570000
  timesteps_this_iter: 10000
  timesteps_total: 3570000
  training_iteration: 357
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 29.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=13557], 8759 s, 357 iter, 3570000 ts, 1.2e+03 rew

agent-1: 98.0
agent-2: 104.0
agent-3: 96.0
agent-4: 88.0
agent-5: 118.0
agent-6: 110.0
agent-7: 104.0
agent-8: 98.0
agent-9: 102.0
agent-10: 97.0
Sum Reward: 1015.0
Avg Reward: 101.5
Min Reward: 88.0
Max Reward: 118.0
Gini Coefficient: 0.04187192118226601
20:20 Ratio: 1.2391304347826086
Max-min Ratio: 1.3409090909090908
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_02-33-20
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1861.0
  episode_reward_mean: 1202.02
  episode_reward_min: 821.0
  episodes_this_iter: 1
  episodes_total: 357
  experiment_id: a3942a9886f24694ab1b58ca8d1ab856
  hostname: gpu006
  info:
    apply_time_ms: 2.549
    dispatch_time_ms: 5.713
    learner:
      cur_lr: 0.001122237998060882
      grad_gnorm: 39.999996185302734
      policy_entropy: 39.661888122558594
      policy_loss: 26.536352157592773
      var_gnorm: 53.728599548339844
      vf_explained_var: 0.5048869252204895
      vf_loss: 123.26866912841797
    num_steps_sampled: 3580000
    num_steps_trained: 3580000
    wait_time_ms: 248.946
  iterations_since_restore: 358
  node_ip: 172.17.8.6
  num_metric_batches_dropped: 0
  pid: 13557
  policy_reward_mean: {}
  time_since_restore: 8782.173778057098
  time_this_iter_s: 22.477941513061523
  time_total_s: 8782.173778057098
  timestamp: 1594103600
  timesteps_since_restore: 3580000
  timesteps_this_iter: 10000
  timesteps_total: 3580000
  training_iteration: 358
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 29.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=13557], 8782 s, 358 iter, 3580000 ts, 1.2e+03 rew

agent-1: 90.0
agent-2: 95.0
agent-3: 105.0
agent-4: 114.0
agent-5: 117.0
agent-6: 104.0
agent-7: 130.0
agent-8: 115.0
agent-9: 140.0
agent-10: 129.0
Sum Reward: 1139.0
Avg Reward: 113.9
Min Reward: 90.0
Max Reward: 140.0
Gini Coefficient: 0.0752414398595259
20:20 Ratio: 1.4594594594594594
Max-min Ratio: 1.5555555555555556
agent-1: 103.0
agent-2: 132.0
agent-3: 108.0
agent-4: 110.0
agent-5: 117.0
agent-6: 103.0
agent-7: 103.0
agent-8: 132.0
agent-9: 108.0
agent-10: 109.0
Sum Reward: 1125.0
Avg Reward: 112.5
Min Reward: 103.0
Max Reward: 132.0
Gini Coefficient: 0.04808888888888889
20:20 Ratio: 1.2815533980582525
Max-min Ratio: 1.2815533980582525
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_02-33-47
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1861.0
  episode_reward_mean: 1201.41
  episode_reward_min: 821.0
  episodes_this_iter: 2
  episodes_total: 359
  experiment_id: a3942a9886f24694ab1b58ca8d1ab856
  hostname: gpu006
  info:
    apply_time_ms: 2.779
    dispatch_time_ms: 7.231
    learner:
      cur_lr: 0.0011215719860047102
      grad_gnorm: 27.079469680786133
      policy_entropy: 62.32899856567383
      policy_loss: 4.988424777984619
      var_gnorm: 53.75913619995117
      vf_explained_var: -1.0
      vf_loss: 0.35845598578453064
    num_steps_sampled: 3590000
    num_steps_trained: 3590000
    wait_time_ms: 260.271
  iterations_since_restore: 359
  node_ip: 172.17.8.6
  num_metric_batches_dropped: 0
  pid: 13557
  policy_reward_mean: {}
  time_since_restore: 8808.88007068634
  time_this_iter_s: 26.706292629241943
  time_total_s: 8808.88007068634
  timestamp: 1594103627
  timesteps_since_restore: 3590000
  timesteps_this_iter: 10000
  timesteps_total: 3590000
  training_iteration: 359
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 29.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=13557], 8808 s, 359 iter, 3590000 ts, 1.2e+03 rew

Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_02-34-10
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1861.0
  episode_reward_mean: 1201.41
  episode_reward_min: 821.0
  episodes_this_iter: 0
  episodes_total: 359
  experiment_id: a3942a9886f24694ab1b58ca8d1ab856
  hostname: gpu006
  info:
    apply_time_ms: 2.622
    dispatch_time_ms: 5.441
    learner:
      cur_lr: 0.0011209059739485383
      grad_gnorm: 40.0
      policy_entropy: 50.1832160949707
      policy_loss: -5.232675075531006
      var_gnorm: 53.821571350097656
      vf_explained_var: 0.9085842967033386
      vf_loss: 30.57612419128418
    num_steps_sampled: 3600000
    num_steps_trained: 3600000
    wait_time_ms: 250.915
  iterations_since_restore: 360
  node_ip: 172.17.8.6
  num_metric_batches_dropped: 0
  pid: 13557
  policy_reward_mean: {}
  time_since_restore: 8831.419716835022
  time_this_iter_s: 22.53964614868164
  time_total_s: 8831.419716835022
  timestamp: 1594103650
  timesteps_since_restore: 3600000
  timesteps_this_iter: 10000
  timesteps_total: 3600000
  training_iteration: 360
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 29.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=13557], 8831 s, 360 iter, 3600000 ts, 1.2e+03 rew

agent-1: 121.0
agent-2: 103.0
agent-3: 107.0
agent-4: 142.0
agent-5: 110.0
agent-6: 94.0
agent-7: 78.0
agent-8: 92.0
agent-9: 102.0
agent-10: 144.0
Sum Reward: 1093.0
Avg Reward: 109.3
Min Reward: 78.0
Max Reward: 144.0
Gini Coefficient: 0.10128087831655992
20:20 Ratio: 1.6823529411764706
Max-min Ratio: 1.8461538461538463
agent-1: 106.0
agent-2: 124.0
agent-3: 87.0
agent-4: 97.0
agent-5: 111.0
agent-6: 91.0
agent-7: 89.0
agent-8: 122.0
agent-9: 109.0
agent-10: 98.0
Sum Reward: 1034.0
Avg Reward: 103.4
Min Reward: 87.0
Max Reward: 124.0
Gini Coefficient: 0.06847195357833656
20:20 Ratio: 1.3977272727272727
Max-min Ratio: 1.4252873563218391
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_02-34-36
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1861.0
  episode_reward_mean: 1202.9
  episode_reward_min: 821.0
  episodes_this_iter: 2
  episodes_total: 361
  experiment_id: a3942a9886f24694ab1b58ca8d1ab856
  hostname: gpu006
  info:
    apply_time_ms: 2.887
    dispatch_time_ms: 6.377
    learner:
      cur_lr: 0.0011202399618923664
      grad_gnorm: 10.158833503723145
      policy_entropy: 61.090450286865234
      policy_loss: 1.7076671123504639
      var_gnorm: 53.87056350708008
      vf_explained_var: -1.0
      vf_loss: 0.06522731482982635
    num_steps_sampled: 3610000
    num_steps_trained: 3610000
    wait_time_ms: 260.202
  iterations_since_restore: 361
  node_ip: 172.17.8.6
  num_metric_batches_dropped: 0
  pid: 13557
  policy_reward_mean: {}
  time_since_restore: 8857.87220454216
  time_this_iter_s: 26.45248770713806
  time_total_s: 8857.87220454216
  timestamp: 1594103676
  timesteps_since_restore: 3610000
  timesteps_this_iter: 10000
  timesteps_total: 3610000
  training_iteration: 361
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 29.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=13557], 8857 s, 361 iter, 3610000 ts, 1.2e+03 rew

Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_02-34-58
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1861.0
  episode_reward_mean: 1202.9
  episode_reward_min: 821.0
  episodes_this_iter: 0
  episodes_total: 361
  experiment_id: a3942a9886f24694ab1b58ca8d1ab856
  hostname: gpu006
  info:
    apply_time_ms: 2.769
    dispatch_time_ms: 5.734
    learner:
      cur_lr: 0.0011195739498361945
      grad_gnorm: 39.9999885559082
      policy_entropy: 23.31270980834961
      policy_loss: 20.414398193359375
      var_gnorm: 54.06722640991211
      vf_explained_var: 0.7380443215370178
      vf_loss: 71.62407684326172
    num_steps_sampled: 3620000
    num_steps_trained: 3620000
    wait_time_ms: 234.717
  iterations_since_restore: 362
  node_ip: 172.17.8.6
  num_metric_batches_dropped: 0
  pid: 13557
  policy_reward_mean: {}
  time_since_restore: 8879.85219669342
  time_this_iter_s: 21.979992151260376
  time_total_s: 8879.85219669342
  timestamp: 1594103698
  timesteps_since_restore: 3620000
  timesteps_this_iter: 10000
  timesteps_total: 3620000
  training_iteration: 362
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 29.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=13557], 8879 s, 362 iter, 3620000 ts, 1.2e+03 rew

agent-1: 117.0
agent-2: 93.0
agent-3: 121.0
agent-4: 118.0
agent-5: 107.0
agent-6: 100.0
agent-7: 110.0
agent-8: 107.0
agent-9: 109.0
agent-10: 113.0
Sum Reward: 1095.0
Avg Reward: 109.5
Min Reward: 93.0
Max Reward: 121.0
Gini Coefficient: 0.04082191780821918
20:20 Ratio: 1.238341968911917
Max-min Ratio: 1.3010752688172043
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_02-35-25
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1861.0
  episode_reward_mean: 1200.76
  episode_reward_min: 821.0
  episodes_this_iter: 1
  episodes_total: 362
  experiment_id: a3942a9886f24694ab1b58ca8d1ab856
  hostname: gpu006
  info:
    apply_time_ms: 2.88
    dispatch_time_ms: 7.215
    learner:
      cur_lr: 0.0011189080541953444
      grad_gnorm: 0.9358046650886536
      policy_entropy: 66.70589447021484
      policy_loss: 0.2421133816242218
      var_gnorm: 54.0933723449707
      vf_explained_var: 0.9926280379295349
      vf_loss: 0.0006577065214514732
    num_steps_sampled: 3630000
    num_steps_trained: 3630000
    wait_time_ms: 248.32
  iterations_since_restore: 363
  node_ip: 172.17.8.6
  num_metric_batches_dropped: 0
  pid: 13557
  policy_reward_mean: {}
  time_since_restore: 8906.042093753815
  time_this_iter_s: 26.189897060394287
  time_total_s: 8906.042093753815
  timestamp: 1594103725
  timesteps_since_restore: 3630000
  timesteps_this_iter: 10000
  timesteps_total: 3630000
  training_iteration: 363
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 29.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=13557], 8906 s, 363 iter, 3630000 ts, 1.2e+03 rew

agent-1: 127.0
agent-2: 102.0
agent-3: 126.0
agent-4: 111.0
agent-5: 156.0
agent-6: 130.0
agent-7: 118.0
agent-8: 145.0
agent-9: 116.0
agent-10: 136.0
Sum Reward: 1267.0
Avg Reward: 126.7
Min Reward: 102.0
Max Reward: 156.0
Gini Coefficient: 0.06795580110497237
20:20 Ratio: 1.4131455399061033
Max-min Ratio: 1.5294117647058822
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_02-35-47
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1861.0
  episode_reward_mean: 1201.8
  episode_reward_min: 821.0
  episodes_this_iter: 1
  episodes_total: 363
  experiment_id: a3942a9886f24694ab1b58ca8d1ab856
  hostname: gpu006
  info:
    apply_time_ms: 2.645
    dispatch_time_ms: 6.337
    learner:
      cur_lr: 0.0011182420421391726
      grad_gnorm: 40.000030517578125
      policy_entropy: 39.190940856933594
      policy_loss: 5.752841949462891
      var_gnorm: 54.00837707519531
      vf_explained_var: 0.4887944459915161
      vf_loss: 136.12664794921875
    num_steps_sampled: 3640000
    num_steps_trained: 3640000
    wait_time_ms: 252.287
  iterations_since_restore: 364
  node_ip: 172.17.8.6
  num_metric_batches_dropped: 0
  pid: 13557
  policy_reward_mean: {}
  time_since_restore: 8928.840878009796
  time_this_iter_s: 22.798784255981445
  time_total_s: 8928.840878009796
  timestamp: 1594103747
  timesteps_since_restore: 3640000
  timesteps_this_iter: 10000
  timesteps_total: 3640000
  training_iteration: 364
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 29.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=13557], 8928 s, 364 iter, 3640000 ts, 1.2e+03 rew

agent-1: 92.0
agent-2: 79.0
agent-3: 83.0
agent-4: 73.0
agent-5: 102.0
agent-6: 83.0
agent-7: 118.0
agent-8: 131.0
agent-9: 84.0
agent-10: 117.0
Sum Reward: 962.0
Avg Reward: 96.2
Min Reward: 73.0
Max Reward: 131.0
Gini Coefficient: 0.10706860706860707
20:20 Ratio: 1.638157894736842
Max-min Ratio: 1.7945205479452055
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_02-36-14
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1861.0
  episode_reward_mean: 1202.43
  episode_reward_min: 821.0
  episodes_this_iter: 1
  episodes_total: 364
  experiment_id: a3942a9886f24694ab1b58ca8d1ab856
  hostname: gpu006
  info:
    apply_time_ms: 2.903
    dispatch_time_ms: 5.526
    learner:
      cur_lr: 0.0011175760300830007
      grad_gnorm: 40.000003814697266
      policy_entropy: 6.397825241088867
      policy_loss: 3.3243844509124756
      var_gnorm: 54.01893615722656
      vf_explained_var: 0.7591676712036133
      vf_loss: 67.66551971435547
    num_steps_sampled: 3650000
    num_steps_trained: 3650000
    wait_time_ms: 238.853
  iterations_since_restore: 365
  node_ip: 172.17.8.6
  num_metric_batches_dropped: 0
  pid: 13557
  policy_reward_mean: {}
  time_since_restore: 8955.217338562012
  time_this_iter_s: 26.376460552215576
  time_total_s: 8955.217338562012
  timestamp: 1594103774
  timesteps_since_restore: 3650000
  timesteps_this_iter: 10000
  timesteps_total: 3650000
  training_iteration: 365
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 29.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=13557], 8955 s, 365 iter, 3650000 ts, 1.2e+03 rew

agent-1: 111.0
agent-2: 106.0
agent-3: 109.0
agent-4: 106.0
agent-5: 114.0
agent-6: 89.0
agent-7: 106.0
agent-8: 96.0
agent-9: 121.0
agent-10: 105.0
Sum Reward: 1063.0
Avg Reward: 106.3
Min Reward: 89.0
Max Reward: 121.0
Gini Coefficient: 0.042615239887111946
20:20 Ratio: 1.2702702702702702
Max-min Ratio: 1.3595505617977528
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_02-36-37
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1861.0
  episode_reward_mean: 1201.02
  episode_reward_min: 821.0
  episodes_this_iter: 1
  episodes_total: 365
  experiment_id: a3942a9886f24694ab1b58ca8d1ab856
  hostname: gpu006
  info:
    apply_time_ms: 3.889
    dispatch_time_ms: 7.085
    learner:
      cur_lr: 0.0011169100180268288
      grad_gnorm: 39.99998474121094
      policy_entropy: 28.94065284729004
      policy_loss: 11.605502128601074
      var_gnorm: 54.13312530517578
      vf_explained_var: -0.10332512855529785
      vf_loss: 167.64735412597656
    num_steps_sampled: 3660000
    num_steps_trained: 3660000
    wait_time_ms: 253.637
  iterations_since_restore: 366
  node_ip: 172.17.8.6
  num_metric_batches_dropped: 0
  pid: 13557
  policy_reward_mean: {}
  time_since_restore: 8978.13953924179
  time_this_iter_s: 22.922200679779053
  time_total_s: 8978.13953924179
  timestamp: 1594103797
  timesteps_since_restore: 3660000
  timesteps_this_iter: 10000
  timesteps_total: 3660000
  training_iteration: 366
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 29.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=13557], 8978 s, 366 iter, 3660000 ts, 1.2e+03 rew

agent-1: 128.0
agent-2: 110.0
agent-3: 116.0
agent-4: 135.0
agent-5: 120.0
agent-6: 115.0
agent-7: 154.0
agent-8: 117.0
agent-9: 112.0
agent-10: 128.0
Sum Reward: 1235.0
Avg Reward: 123.5
Min Reward: 110.0
Max Reward: 154.0
Gini Coefficient: 0.053522267206477736
20:20 Ratio: 1.3018018018018018
Max-min Ratio: 1.4
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_02-37-03
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1861.0
  episode_reward_mean: 1203.56
  episode_reward_min: 821.0
  episodes_this_iter: 1
  episodes_total: 366
  experiment_id: a3942a9886f24694ab1b58ca8d1ab856
  hostname: gpu006
  info:
    apply_time_ms: 2.725
    dispatch_time_ms: 5.968
    learner:
      cur_lr: 0.0011162440059706569
      grad_gnorm: 0.4015272259712219
      policy_entropy: 73.5597152709961
      policy_loss: 0.4376429319381714
      var_gnorm: 54.20118713378906
      vf_explained_var: 0.9948418736457825
      vf_loss: 4.584253110806458e-05
    num_steps_sampled: 3670000
    num_steps_trained: 3670000
    wait_time_ms: 247.783
  iterations_since_restore: 367
  node_ip: 172.17.8.6
  num_metric_batches_dropped: 0
  pid: 13557
  policy_reward_mean: {}
  time_since_restore: 9004.346975564957
  time_this_iter_s: 26.207436323165894
  time_total_s: 9004.346975564957
  timestamp: 1594103823
  timesteps_since_restore: 3670000
  timesteps_this_iter: 10000
  timesteps_total: 3670000
  training_iteration: 367
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 29.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=13557], 9004 s, 367 iter, 3670000 ts, 1.2e+03 rew

agent-1: 140.0
agent-2: 101.0
agent-3: 90.0
agent-4: 109.0
agent-5: 124.0
agent-6: 104.0
agent-7: 94.0
agent-8: 104.0
agent-9: 120.0
agent-10: 93.0
Sum Reward: 1079.0
Avg Reward: 107.9
Min Reward: 90.0
Max Reward: 140.0
Gini Coefficient: 0.07608897126969416
20:20 Ratio: 1.4426229508196722
Max-min Ratio: 1.5555555555555556
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_02-37-26
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1861.0
  episode_reward_mean: 1200.69
  episode_reward_min: 821.0
  episodes_this_iter: 1
  episodes_total: 367
  experiment_id: a3942a9886f24694ab1b58ca8d1ab856
  hostname: gpu006
  info:
    apply_time_ms: 2.699
    dispatch_time_ms: 5.788
    learner:
      cur_lr: 0.001115577993914485
      grad_gnorm: 40.0000114440918
      policy_entropy: 72.11425018310547
      policy_loss: -4.088876724243164
      var_gnorm: 54.23870849609375
      vf_explained_var: 0.3172984719276428
      vf_loss: 31.014326095581055
    num_steps_sampled: 3680000
    num_steps_trained: 3680000
    wait_time_ms: 254.753
  iterations_since_restore: 368
  node_ip: 172.17.8.6
  num_metric_batches_dropped: 0
  pid: 13557
  policy_reward_mean: {}
  time_since_restore: 9027.67038154602
  time_this_iter_s: 23.323405981063843
  time_total_s: 9027.67038154602
  timestamp: 1594103846
  timesteps_since_restore: 3680000
  timesteps_this_iter: 10000
  timesteps_total: 3680000
  training_iteration: 368
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 29.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=13557], 9027 s, 368 iter, 3680000 ts, 1.2e+03 rew

agent-1: 88.0
agent-2: 85.0
agent-3: 101.0
agent-4: 99.0
agent-5: 126.0
agent-6: 121.0
agent-7: 95.0
agent-8: 120.0
agent-9: 113.0
agent-10: 114.0
Sum Reward: 1062.0
Avg Reward: 106.2
Min Reward: 85.0
Max Reward: 126.0
Gini Coefficient: 0.07363465160075329
20:20 Ratio: 1.4277456647398843
Max-min Ratio: 1.4823529411764707
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_02-37-53
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1861.0
  episode_reward_mean: 1197.72
  episode_reward_min: 821.0
  episodes_this_iter: 1
  episodes_total: 368
  experiment_id: a3942a9886f24694ab1b58ca8d1ab856
  hostname: gpu006
  info:
    apply_time_ms: 2.798
    dispatch_time_ms: 8.238
    learner:
      cur_lr: 0.001114911981858313
      grad_gnorm: 2.1940152645111084
      policy_entropy: 73.21846771240234
      policy_loss: -0.017839131876826286
      var_gnorm: 54.24795913696289
      vf_explained_var: -1.0
      vf_loss: 0.04511106759309769
    num_steps_sampled: 3690000
    num_steps_trained: 3690000
    wait_time_ms: 210.671
  iterations_since_restore: 369
  node_ip: 172.17.8.6
  num_metric_batches_dropped: 0
  pid: 13557
  policy_reward_mean: {}
  time_since_restore: 9054.0436565876
  time_this_iter_s: 26.3732750415802
  time_total_s: 9054.0436565876
  timestamp: 1594103873
  timesteps_since_restore: 3690000
  timesteps_this_iter: 10000
  timesteps_total: 3690000
  training_iteration: 369
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 29.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=13557], 9054 s, 369 iter, 3690000 ts, 1.2e+03 rew

agent-1: 89.0
agent-2: 76.0
agent-3: 95.0
agent-4: 86.0
agent-5: 97.0
agent-6: 72.0
agent-7: 71.0
agent-8: 108.0
agent-9: 88.0
agent-10: 86.0
Sum Reward: 868.0
Avg Reward: 86.8
Min Reward: 71.0
Max Reward: 108.0
Gini Coefficient: 0.07073732718894009
20:20 Ratio: 1.4335664335664335
Max-min Ratio: 1.5211267605633803
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_02-38-16
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1861.0
  episode_reward_mean: 1195.11
  episode_reward_min: 821.0
  episodes_this_iter: 1
  episodes_total: 369
  experiment_id: a3942a9886f24694ab1b58ca8d1ab856
  hostname: gpu006
  info:
    apply_time_ms: 2.604
    dispatch_time_ms: 6.276
    learner:
      cur_lr: 0.0011142459698021412
      grad_gnorm: 39.99999237060547
      policy_entropy: 18.17500877380371
      policy_loss: 6.499980926513672
      var_gnorm: 54.365814208984375
      vf_explained_var: 0.7692575454711914
      vf_loss: 64.63980865478516
    num_steps_sampled: 3700000
    num_steps_trained: 3700000
    wait_time_ms: 252.939
  iterations_since_restore: 370
  node_ip: 172.17.8.6
  num_metric_batches_dropped: 0
  pid: 13557
  policy_reward_mean: {}
  time_since_restore: 9077.045345544815
  time_this_iter_s: 23.001688957214355
  time_total_s: 9077.045345544815
  timestamp: 1594103896
  timesteps_since_restore: 3700000
  timesteps_this_iter: 10000
  timesteps_total: 3700000
  training_iteration: 370
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 29.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=13557], 9077 s, 370 iter, 3700000 ts, 1.2e+03 rew

agent-1: 74.0
agent-2: 86.0
agent-3: 118.0
agent-4: 79.0
agent-5: 89.0
agent-6: 97.0
agent-7: 75.0
agent-8: 86.0
agent-9: 64.0
agent-10: 83.0
Sum Reward: 851.0
Avg Reward: 85.1
Min Reward: 64.0
Max Reward: 118.0
Gini Coefficient: 0.08707403055229142
20:20 Ratio: 1.5579710144927537
Max-min Ratio: 1.84375
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_02-38-42
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1861.0
  episode_reward_mean: 1190.97
  episode_reward_min: 821.0
  episodes_this_iter: 1
  episodes_total: 370
  experiment_id: a3942a9886f24694ab1b58ca8d1ab856
  hostname: gpu006
  info:
    apply_time_ms: 2.572
    dispatch_time_ms: 5.638
    learner:
      cur_lr: 0.0011135799577459693
      grad_gnorm: 0.49404194951057434
      policy_entropy: 69.73579406738281
      policy_loss: 0.09432801604270935
      var_gnorm: 54.374267578125
      vf_explained_var: 0.735655665397644
      vf_loss: 0.001049292040988803
    num_steps_sampled: 3710000
    num_steps_trained: 3710000
    wait_time_ms: 207.528
  iterations_since_restore: 371
  node_ip: 172.17.8.6
  num_metric_batches_dropped: 0
  pid: 13557
  policy_reward_mean: {}
  time_since_restore: 9103.030198812485
  time_this_iter_s: 25.984853267669678
  time_total_s: 9103.030198812485
  timestamp: 1594103922
  timesteps_since_restore: 3710000
  timesteps_this_iter: 10000
  timesteps_total: 3710000
  training_iteration: 371
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 29.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=13557], 9103 s, 371 iter, 3710000 ts, 1.19e+03 rew

agent-1: 135.0
agent-2: 101.0
agent-3: 126.0
agent-4: 108.0
agent-5: 123.0
agent-6: 101.0
agent-7: 131.0
agent-8: 97.0
agent-9: 98.0
agent-10: 110.0
Sum Reward: 1130.0
Avg Reward: 113.0
Min Reward: 97.0
Max Reward: 135.0
Gini Coefficient: 0.06778761061946903
20:20 Ratio: 1.3641025641025641
Max-min Ratio: 1.3917525773195876
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_02-39-05
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1861.0
  episode_reward_mean: 1189.48
  episode_reward_min: 821.0
  episodes_this_iter: 1
  episodes_total: 371
  experiment_id: a3942a9886f24694ab1b58ca8d1ab856
  hostname: gpu006
  info:
    apply_time_ms: 2.695
    dispatch_time_ms: 6.938
    learner:
      cur_lr: 0.0011129139456897974
      grad_gnorm: 39.999996185302734
      policy_entropy: 43.82392883300781
      policy_loss: 4.242426872253418
      var_gnorm: 54.50136947631836
      vf_explained_var: 0.9063593745231628
      vf_loss: 31.682476043701172
    num_steps_sampled: 3720000
    num_steps_trained: 3720000
    wait_time_ms: 247.209
  iterations_since_restore: 372
  node_ip: 172.17.8.6
  num_metric_batches_dropped: 0
  pid: 13557
  policy_reward_mean: {}
  time_since_restore: 9126.471541643143
  time_this_iter_s: 23.44134283065796
  time_total_s: 9126.471541643143
  timestamp: 1594103945
  timesteps_since_restore: 3720000
  timesteps_this_iter: 10000
  timesteps_total: 3720000
  training_iteration: 372
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 29.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=13557], 9126 s, 372 iter, 3720000 ts, 1.19e+03 rew

agent-1: 107.0
agent-2: 116.0
agent-3: 79.0
agent-4: 87.0
agent-5: 91.0
agent-6: 130.0
agent-7: 122.0
agent-8: 88.0
agent-9: 103.0
agent-10: 101.0
Sum Reward: 1024.0
Avg Reward: 102.4
Min Reward: 79.0
Max Reward: 130.0
Gini Coefficient: 0.0873046875
20:20 Ratio: 1.5180722891566265
Max-min Ratio: 1.6455696202531647
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_02-39-31
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1861.0
  episode_reward_mean: 1187.62
  episode_reward_min: 821.0
  episodes_this_iter: 1
  episodes_total: 372
  experiment_id: a3942a9886f24694ab1b58ca8d1ab856
  hostname: gpu006
  info:
    apply_time_ms: 2.652
    dispatch_time_ms: 6.32
    learner:
      cur_lr: 0.0011122480500489473
      grad_gnorm: 10.350272178649902
      policy_entropy: 69.53568267822266
      policy_loss: -1.9422633647918701
      var_gnorm: 54.53498840332031
      vf_explained_var: -1.0
      vf_loss: 0.9396923780441284
    num_steps_sampled: 3730000
    num_steps_trained: 3730000
    wait_time_ms: 219.417
  iterations_since_restore: 373
  node_ip: 172.17.8.6
  num_metric_batches_dropped: 0
  pid: 13557
  policy_reward_mean: {}
  time_since_restore: 9152.335701465607
  time_this_iter_s: 25.86415982246399
  time_total_s: 9152.335701465607
  timestamp: 1594103971
  timesteps_since_restore: 3730000
  timesteps_this_iter: 10000
  timesteps_total: 3730000
  training_iteration: 373
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 29.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=13557], 9152 s, 373 iter, 3730000 ts, 1.19e+03 rew

agent-1: 115.0
agent-2: 137.0
agent-3: 130.0
agent-4: 110.0
agent-5: 105.0
agent-6: 106.0
agent-7: 109.0
agent-8: 99.0
agent-9: 115.0
agent-10: 132.0
Sum Reward: 1158.0
Avg Reward: 115.8
Min Reward: 99.0
Max Reward: 137.0
Gini Coefficient: 0.05820379965457686
20:20 Ratio: 1.3186274509803921
Max-min Ratio: 1.3838383838383839
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_02-39-55
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1861.0
  episode_reward_mean: 1189.01
  episode_reward_min: 821.0
  episodes_this_iter: 1
  episodes_total: 373
  experiment_id: a3942a9886f24694ab1b58ca8d1ab856
  hostname: gpu006
  info:
    apply_time_ms: 2.618
    dispatch_time_ms: 6.45
    learner:
      cur_lr: 0.0011115820379927754
      grad_gnorm: 40.0000114440918
      policy_entropy: 55.42887496948242
      policy_loss: -14.405569076538086
      var_gnorm: 54.461631774902344
      vf_explained_var: 0.9480528235435486
      vf_loss: 8.44215202331543
    num_steps_sampled: 3740000
    num_steps_trained: 3740000
    wait_time_ms: 260.436
  iterations_since_restore: 374
  node_ip: 172.17.8.6
  num_metric_batches_dropped: 0
  pid: 13557
  policy_reward_mean: {}
  time_since_restore: 9175.582082748413
  time_this_iter_s: 23.246381282806396
  time_total_s: 9175.582082748413
  timestamp: 1594103995
  timesteps_since_restore: 3740000
  timesteps_this_iter: 10000
  timesteps_total: 3740000
  training_iteration: 374
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 29.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=13557], 9175 s, 374 iter, 3740000 ts, 1.19e+03 rew

agent-1: 114.0
agent-2: 95.0
agent-3: 108.0
agent-4: 85.0
agent-5: 105.0
agent-6: 90.0
agent-7: 116.0
agent-8: 96.0
agent-9: 102.0
agent-10: 118.0
Sum Reward: 1029.0
Avg Reward: 102.9
Min Reward: 85.0
Max Reward: 118.0
Gini Coefficient: 0.059572400388726916
20:20 Ratio: 1.3371428571428572
Max-min Ratio: 1.388235294117647
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_02-40-21
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1861.0
  episode_reward_mean: 1189.09
  episode_reward_min: 821.0
  episodes_this_iter: 1
  episodes_total: 374
  experiment_id: a3942a9886f24694ab1b58ca8d1ab856
  hostname: gpu006
  info:
    apply_time_ms: 3.3
    dispatch_time_ms: 6.851
    learner:
      cur_lr: 0.0011109160259366035
      grad_gnorm: 39.999996185302734
      policy_entropy: 8.031526565551758
      policy_loss: 9.514192581176758
      var_gnorm: 54.5477180480957
      vf_explained_var: 0.5663043260574341
      vf_loss: 90.44303131103516
    num_steps_sampled: 3750000
    num_steps_trained: 3750000
    wait_time_ms: 199.614
  iterations_since_restore: 375
  node_ip: 172.17.8.6
  num_metric_batches_dropped: 0
  pid: 13557
  policy_reward_mean: {}
  time_since_restore: 9201.655010938644
  time_this_iter_s: 26.072928190231323
  time_total_s: 9201.655010938644
  timestamp: 1594104021
  timesteps_since_restore: 3750000
  timesteps_this_iter: 10000
  timesteps_total: 3750000
  training_iteration: 375
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 29.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=13557], 9201 s, 375 iter, 3750000 ts, 1.19e+03 rew

agent-1: 93.0
agent-2: 107.0
agent-3: 101.0
agent-4: 108.0
agent-5: 88.0
agent-6: 121.0
agent-7: 94.0
agent-8: 115.0
agent-9: 100.0
agent-10: 95.0
Sum Reward: 1022.0
Avg Reward: 102.2
Min Reward: 88.0
Max Reward: 121.0
Gini Coefficient: 0.054598825831702544
20:20 Ratio: 1.3038674033149171
Max-min Ratio: 1.375
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_02-40-44
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1861.0
  episode_reward_mean: 1189.83
  episode_reward_min: 821.0
  episodes_this_iter: 1
  episodes_total: 375
  experiment_id: a3942a9886f24694ab1b58ca8d1ab856
  hostname: gpu006
  info:
    apply_time_ms: 2.863
    dispatch_time_ms: 5.998
    learner:
      cur_lr: 0.0011102500138804317
      grad_gnorm: 40.000003814697266
      policy_entropy: 57.793907165527344
      policy_loss: -0.592836320400238
      var_gnorm: 54.58222961425781
      vf_explained_var: 0.9541452527046204
      vf_loss: 25.943811416625977
    num_steps_sampled: 3760000
    num_steps_trained: 3760000
    wait_time_ms: 251.148
  iterations_since_restore: 376
  node_ip: 172.17.8.6
  num_metric_batches_dropped: 0
  pid: 13557
  policy_reward_mean: {}
  time_since_restore: 9224.955350399017
  time_this_iter_s: 23.300339460372925
  time_total_s: 9224.955350399017
  timestamp: 1594104044
  timesteps_since_restore: 3760000
  timesteps_this_iter: 10000
  timesteps_total: 3760000
  training_iteration: 376
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 29.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=13557], 9224 s, 376 iter, 3760000 ts, 1.19e+03 rew

agent-1: 115.0
agent-2: 103.0
agent-3: 98.0
agent-4: 120.0
agent-5: 102.0
agent-6: 108.0
agent-7: 90.0
agent-8: 93.0
agent-9: 101.0
agent-10: 138.0
Sum Reward: 1068.0
Avg Reward: 106.8
Min Reward: 90.0
Max Reward: 138.0
Gini Coefficient: 0.06816479400749063
20:20 Ratio: 1.4098360655737705
Max-min Ratio: 1.5333333333333334
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_02-41-10
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1861.0
  episode_reward_mean: 1191.26
  episode_reward_min: 821.0
  episodes_this_iter: 1
  episodes_total: 376
  experiment_id: a3942a9886f24694ab1b58ca8d1ab856
  hostname: gpu006
  info:
    apply_time_ms: 2.526
    dispatch_time_ms: 8.803
    learner:
      cur_lr: 0.0011095840018242598
      grad_gnorm: 2.0084950923919678
      policy_entropy: 65.35576629638672
      policy_loss: -0.18654222786426544
      var_gnorm: 54.5876350402832
      vf_explained_var: 0.0
      vf_loss: 0.0024144682101905346
    num_steps_sampled: 3770000
    num_steps_trained: 3770000
    wait_time_ms: 204.235
  iterations_since_restore: 377
  node_ip: 172.17.8.6
  num_metric_batches_dropped: 0
  pid: 13557
  policy_reward_mean: {}
  time_since_restore: 9250.804540157318
  time_this_iter_s: 25.84918975830078
  time_total_s: 9250.804540157318
  timestamp: 1594104070
  timesteps_since_restore: 3770000
  timesteps_this_iter: 10000
  timesteps_total: 3770000
  training_iteration: 377
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 29.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=13557], 9250 s, 377 iter, 3770000 ts, 1.19e+03 rew

agent-1: 118.0
agent-2: 91.0
agent-3: 124.0
agent-4: 106.0
agent-5: 106.0
agent-6: 104.0
agent-7: 94.0
agent-8: 107.0
agent-9: 128.0
agent-10: 115.0
Sum Reward: 1093.0
Avg Reward: 109.3
Min Reward: 91.0
Max Reward: 128.0
Gini Coefficient: 0.058645928636779504
20:20 Ratio: 1.3621621621621622
Max-min Ratio: 1.4065934065934067
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_02-41-33
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1861.0
  episode_reward_mean: 1191.65
  episode_reward_min: 821.0
  episodes_this_iter: 1
  episodes_total: 377
  experiment_id: a3942a9886f24694ab1b58ca8d1ab856
  hostname: gpu006
  info:
    apply_time_ms: 2.929
    dispatch_time_ms: 6.048
    learner:
      cur_lr: 0.0011089179897680879
      grad_gnorm: 24.34673500061035
      policy_entropy: 45.41891860961914
      policy_loss: -3.201430559158325
      var_gnorm: 54.64537811279297
      vf_explained_var: 0.9573760628700256
      vf_loss: 0.45160481333732605
    num_steps_sampled: 3780000
    num_steps_trained: 3780000
    wait_time_ms: 261.668
  iterations_since_restore: 378
  node_ip: 172.17.8.6
  num_metric_batches_dropped: 0
  pid: 13557
  policy_reward_mean: {}
  time_since_restore: 9274.223490953445
  time_this_iter_s: 23.41895079612732
  time_total_s: 9274.223490953445
  timestamp: 1594104093
  timesteps_since_restore: 3780000
  timesteps_this_iter: 10000
  timesteps_total: 3780000
  training_iteration: 378
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 29.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=13557], 9274 s, 378 iter, 3780000 ts, 1.19e+03 rew

agent-1: 135.0
agent-2: 122.0
agent-3: 103.0
agent-4: 132.0
agent-5: 142.0
agent-6: 122.0
agent-7: 118.0
agent-8: 96.0
agent-9: 87.0
agent-10: 118.0
Sum Reward: 1175.0
Avg Reward: 117.5
Min Reward: 87.0
Max Reward: 142.0
Gini Coefficient: 0.07906382978723404
20:20 Ratio: 1.5136612021857923
Max-min Ratio: 1.632183908045977
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_02-41-59
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1861.0
  episode_reward_mean: 1193.78
  episode_reward_min: 821.0
  episodes_this_iter: 1
  episodes_total: 378
  experiment_id: a3942a9886f24694ab1b58ca8d1ab856
  hostname: gpu006
  info:
    apply_time_ms: 2.668
    dispatch_time_ms: 8.906
    learner:
      cur_lr: 0.001108251977711916
      grad_gnorm: 4.094227313995361
      policy_entropy: 63.909053802490234
      policy_loss: -0.7389036417007446
      var_gnorm: 54.70807647705078
      vf_explained_var: 0.0
      vf_loss: 0.009951707907021046
    num_steps_sampled: 3790000
    num_steps_trained: 3790000
    wait_time_ms: 234.775
  iterations_since_restore: 379
  node_ip: 172.17.8.6
  num_metric_batches_dropped: 0
  pid: 13557
  policy_reward_mean: {}
  time_since_restore: 9299.86867594719
  time_this_iter_s: 25.645184993743896
  time_total_s: 9299.86867594719
  timestamp: 1594104119
  timesteps_since_restore: 3790000
  timesteps_this_iter: 10000
  timesteps_total: 3790000
  training_iteration: 379
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 29.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=13557], 9299 s, 379 iter, 3790000 ts, 1.19e+03 rew

agent-1: 93.0
agent-2: 86.0
agent-3: 88.0
agent-4: 69.0
agent-5: 90.0
agent-6: 83.0
agent-7: 76.0
agent-8: 101.0
agent-9: 86.0
agent-10: 77.0
Sum Reward: 849.0
Avg Reward: 84.9
Min Reward: 69.0
Max Reward: 101.0
Gini Coefficient: 0.05736160188457008
20:20 Ratio: 1.3379310344827586
Max-min Ratio: 1.463768115942029
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_02-42-23
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1861.0
  episode_reward_mean: 1192.2
  episode_reward_min: 821.0
  episodes_this_iter: 1
  episodes_total: 379
  experiment_id: a3942a9886f24694ab1b58ca8d1ab856
  hostname: gpu006
  info:
    apply_time_ms: 2.63
    dispatch_time_ms: 7.919
    learner:
      cur_lr: 0.001107585965655744
      grad_gnorm: 40.0
      policy_entropy: 37.795631408691406
      policy_loss: 0.07278427481651306
      var_gnorm: 54.76422882080078
      vf_explained_var: -0.8175908327102661
      vf_loss: 67.51190185546875
    num_steps_sampled: 3800000
    num_steps_trained: 3800000
    wait_time_ms: 252.049
  iterations_since_restore: 380
  node_ip: 172.17.8.6
  num_metric_batches_dropped: 0
  pid: 13557
  policy_reward_mean: {}
  time_since_restore: 9323.428364038467
  time_this_iter_s: 23.559688091278076
  time_total_s: 9323.428364038467
  timestamp: 1594104143
  timesteps_since_restore: 3800000
  timesteps_this_iter: 10000
  timesteps_total: 3800000
  training_iteration: 380
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 29.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=13557], 9323 s, 380 iter, 3800000 ts, 1.19e+03 rew

agent-1: 106.0
agent-2: 116.0
agent-3: 130.0
agent-4: 118.0
agent-5: 114.0
agent-6: 120.0
agent-7: 126.0
agent-8: 95.0
agent-9: 126.0
agent-10: 121.0
Sum Reward: 1172.0
Avg Reward: 117.2
Min Reward: 95.0
Max Reward: 130.0
Gini Coefficient: 0.04539249146757679
20:20 Ratio: 1.2736318407960199
Max-min Ratio: 1.368421052631579
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_02-42-48
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1861.0
  episode_reward_mean: 1193.12
  episode_reward_min: 821.0
  episodes_this_iter: 1
  episodes_total: 380
  experiment_id: a3942a9886f24694ab1b58ca8d1ab856
  hostname: gpu006
  info:
    apply_time_ms: 2.608
    dispatch_time_ms: 5.877
    learner:
      cur_lr: 0.0011069199535995722
      grad_gnorm: 40.0
      policy_entropy: 11.443021774291992
      policy_loss: -12.070356369018555
      var_gnorm: 54.81350326538086
      vf_explained_var: 0.6152781248092651
      vf_loss: 146.3384552001953
    num_steps_sampled: 3810000
    num_steps_trained: 3810000
    wait_time_ms: 227.957
  iterations_since_restore: 381
  node_ip: 172.17.8.6
  num_metric_batches_dropped: 0
  pid: 13557
  policy_reward_mean: {}
  time_since_restore: 9348.877526521683
  time_this_iter_s: 25.449162483215332
  time_total_s: 9348.877526521683
  timestamp: 1594104168
  timesteps_since_restore: 3810000
  timesteps_this_iter: 10000
  timesteps_total: 3810000
  training_iteration: 381
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 29.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=13557], 9348 s, 381 iter, 3810000 ts, 1.19e+03 rew

agent-1: 110.0
agent-2: 99.0
agent-3: 97.0
agent-4: 92.0
agent-5: 73.0
agent-6: 108.0
agent-7: 98.0
agent-8: 76.0
agent-9: 79.0
agent-10: 75.0
Sum Reward: 907.0
Avg Reward: 90.7
Min Reward: 73.0
Max Reward: 110.0
Gini Coefficient: 0.08169790518191841
20:20 Ratio: 1.472972972972973
Max-min Ratio: 1.5068493150684932
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_02-43-12
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1861.0
  episode_reward_mean: 1189.73
  episode_reward_min: 821.0
  episodes_this_iter: 1
  episodes_total: 381
  experiment_id: a3942a9886f24694ab1b58ca8d1ab856
  hostname: gpu006
  info:
    apply_time_ms: 2.613
    dispatch_time_ms: 7.225
    learner:
      cur_lr: 0.0011062540579587221
      grad_gnorm: 13.381757736206055
      policy_entropy: 34.67316436767578
      policy_loss: -2.13094162940979
      var_gnorm: 54.7602424621582
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 0.1063225120306015
    num_steps_sampled: 3820000
    num_steps_trained: 3820000
    wait_time_ms: 238.637
  iterations_since_restore: 382
  node_ip: 172.17.8.6
  num_metric_batches_dropped: 0
  pid: 13557
  policy_reward_mean: {}
  time_since_restore: 9372.45560002327
  time_this_iter_s: 23.578073501586914
  time_total_s: 9372.45560002327
  timestamp: 1594104192
  timesteps_since_restore: 3820000
  timesteps_this_iter: 10000
  timesteps_total: 3820000
  training_iteration: 382
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.3/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=13557], 9372 s, 382 iter, 3820000 ts, 1.19e+03 rew

agent-1: 119.0
agent-2: 88.0
agent-3: 117.0
agent-4: 83.0
agent-5: 119.0
agent-6: 104.0
agent-7: 88.0
agent-8: 118.0
agent-9: 71.0
agent-10: 104.0
Sum Reward: 1011.0
Avg Reward: 101.1
Min Reward: 71.0
Max Reward: 119.0
Gini Coefficient: 0.09109792284866469
20:20 Ratio: 1.5454545454545454
Max-min Ratio: 1.676056338028169
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_02-43-42
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1861.0
  episode_reward_mean: 1187.91
  episode_reward_min: 821.0
  episodes_this_iter: 1
  episodes_total: 382
  experiment_id: a3942a9886f24694ab1b58ca8d1ab856
  hostname: gpu006
  info:
    apply_time_ms: 2.573
    dispatch_time_ms: 7.059
    learner:
      cur_lr: 0.0011055880459025502
      grad_gnorm: 13.098485946655273
      policy_entropy: 33.59937286376953
      policy_loss: -1.0598013401031494
      var_gnorm: 54.747703552246094
      vf_explained_var: 0.9848791360855103
      vf_loss: 5.838047027587891
    num_steps_sampled: 3830000
    num_steps_trained: 3830000
    wait_time_ms: 749.851
  iterations_since_restore: 383
  node_ip: 172.17.8.6
  num_metric_batches_dropped: 0
  pid: 13557
  policy_reward_mean: {}
  time_since_restore: 9402.773749828339
  time_this_iter_s: 30.31814980506897
  time_total_s: 9402.773749828339
  timestamp: 1594104222
  timesteps_since_restore: 3830000
  timesteps_this_iter: 10000
  timesteps_total: 3830000
  training_iteration: 383
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.3/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=13557], 9402 s, 383 iter, 3830000 ts, 1.19e+03 rew

agent-1: 143.0
agent-2: 126.0
agent-3: 120.0
agent-4: 142.0
agent-5: 123.0
agent-6: 129.0
agent-7: 123.0
agent-8: 171.0
agent-9: 132.0
agent-10: 131.0
Sum Reward: 1340.0
Avg Reward: 134.0
Min Reward: 120.0
Max Reward: 171.0
Gini Coefficient: 0.05328358208955224
20:20 Ratio: 1.2921810699588476
Max-min Ratio: 1.425
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_02-44-05
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1861.0
  episode_reward_mean: 1192.05
  episode_reward_min: 821.0
  episodes_this_iter: 1
  episodes_total: 383
  experiment_id: a3942a9886f24694ab1b58ca8d1ab856
  hostname: gpu006
  info:
    apply_time_ms: 2.763
    dispatch_time_ms: 10.157
    learner:
      cur_lr: 0.0011049220338463783
      grad_gnorm: 9.259449005126953
      policy_entropy: 18.575923919677734
      policy_loss: -0.3369275629520416
      var_gnorm: 54.79228210449219
      vf_explained_var: 0.9450595378875732
      vf_loss: 0.2178671658039093
    num_steps_sampled: 3840000
    num_steps_trained: 3840000
    wait_time_ms: 259.91
  iterations_since_restore: 384
  node_ip: 172.17.8.6
  num_metric_batches_dropped: 0
  pid: 13557
  policy_reward_mean: {}
  time_since_restore: 9425.292149066925
  time_this_iter_s: 22.518399238586426
  time_total_s: 9425.292149066925
  timestamp: 1594104245
  timesteps_since_restore: 3840000
  timesteps_this_iter: 10000
  timesteps_total: 3840000
  training_iteration: 384
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=13557], 9425 s, 384 iter, 3840000 ts, 1.19e+03 rew

agent-1: 93.0
agent-2: 90.0
agent-3: 103.0
agent-4: 80.0
agent-5: 104.0
agent-6: 91.0
agent-7: 94.0
agent-8: 101.0
agent-9: 78.0
agent-10: 91.0
Sum Reward: 925.0
Avg Reward: 92.5
Min Reward: 78.0
Max Reward: 104.0
Gini Coefficient: 0.04983783783783784
20:20 Ratio: 1.3101265822784811
Max-min Ratio: 1.3333333333333333
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_02-44-31
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1861.0
  episode_reward_mean: 1188.32
  episode_reward_min: 821.0
  episodes_this_iter: 1
  episodes_total: 384
  experiment_id: a3942a9886f24694ab1b58ca8d1ab856
  hostname: gpu006
  info:
    apply_time_ms: 3.174
    dispatch_time_ms: 28.861
    learner:
      cur_lr: 0.0011042560217902064
      grad_gnorm: 4.311090469360352
      policy_entropy: 35.31629943847656
      policy_loss: -0.2707189917564392
      var_gnorm: 54.86217498779297
      vf_explained_var: 0.9567275047302246
      vf_loss: 0.01190377026796341
    num_steps_sampled: 3850000
    num_steps_trained: 3850000
    wait_time_ms: 208.882
  iterations_since_restore: 385
  node_ip: 172.17.8.6
  num_metric_batches_dropped: 0
  pid: 13557
  policy_reward_mean: {}
  time_since_restore: 9451.402166366577
  time_this_iter_s: 26.1100172996521
  time_total_s: 9451.402166366577
  timestamp: 1594104271
  timesteps_since_restore: 3850000
  timesteps_this_iter: 10000
  timesteps_total: 3850000
  training_iteration: 385
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=13557], 9451 s, 385 iter, 3850000 ts, 1.19e+03 rew

agent-1: 108.0
agent-2: 64.0
agent-3: 59.0
agent-4: 97.0
agent-5: 108.0
agent-6: 62.0
agent-7: 51.0
agent-8: 127.0
agent-9: 96.0
agent-10: 101.0
Sum Reward: 873.0
Avg Reward: 87.3
Min Reward: 51.0
Max Reward: 127.0
Gini Coefficient: 0.156815578465063
20:20 Ratio: 2.1363636363636362
Max-min Ratio: 2.4901960784313726
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_02-44-55
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1861.0
  episode_reward_mean: 1182.38
  episode_reward_min: 821.0
  episodes_this_iter: 1
  episodes_total: 385
  experiment_id: a3942a9886f24694ab1b58ca8d1ab856
  hostname: gpu006
  info:
    apply_time_ms: 2.809
    dispatch_time_ms: 22.732
    learner:
      cur_lr: 0.0011035900097340345
      grad_gnorm: 23.860998153686523
      policy_entropy: 24.637840270996094
      policy_loss: -1.722826361656189
      var_gnorm: 55.037071228027344
      vf_explained_var: 0.0
      vf_loss: 0.34177204966545105
    num_steps_sampled: 3860000
    num_steps_trained: 3860000
    wait_time_ms: 241.654
  iterations_since_restore: 386
  node_ip: 172.17.8.6
  num_metric_batches_dropped: 0
  pid: 13557
  policy_reward_mean: {}
  time_since_restore: 9475.884944200516
  time_this_iter_s: 24.4827778339386
  time_total_s: 9475.884944200516
  timestamp: 1594104295
  timesteps_since_restore: 3860000
  timesteps_this_iter: 10000
  timesteps_total: 3860000
  training_iteration: 386
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=13557], 9475 s, 386 iter, 3860000 ts, 1.18e+03 rew

W0707 02:45:12.537978 13553 node_manager.cc:250] Last heartbeat was sent 3379 ms ago 
W0707 02:45:13.279546 13553 node_manager.cc:250] Last heartbeat was sent 742 ms ago 
agent-1: 132.0
agent-2: 101.0
agent-3: 120.0
agent-4: 130.0
agent-5: 106.0
agent-6: 109.0
agent-7: 120.0
agent-8: 111.0
agent-9: 113.0
agent-10: 115.0
Sum Reward: 1157.0
Avg Reward: 115.7
Min Reward: 101.0
Max Reward: 132.0
Gini Coefficient: 0.04589455488331893
20:20 Ratio: 1.2657004830917875
Max-min Ratio: 1.306930693069307
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_02-45-24
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1861.0
  episode_reward_mean: 1184.02
  episode_reward_min: 821.0
  episodes_this_iter: 1
  episodes_total: 386
  experiment_id: a3942a9886f24694ab1b58ca8d1ab856
  hostname: gpu006
  info:
    apply_time_ms: 3.987
    dispatch_time_ms: 16.53
    learner:
      cur_lr: 0.0011029239976778626
      grad_gnorm: 40.0
      policy_entropy: 18.407676696777344
      policy_loss: 20.52959442138672
      var_gnorm: 55.06178283691406
      vf_explained_var: 0.6397033929824829
      vf_loss: 82.84272003173828
    num_steps_sampled: 3870000
    num_steps_trained: 3870000
    wait_time_ms: 205.125
  iterations_since_restore: 387
  node_ip: 172.17.8.6
  num_metric_batches_dropped: 0
  pid: 13557
  policy_reward_mean: {}
  time_since_restore: 9504.828964948654
  time_this_iter_s: 28.944020748138428
  time_total_s: 9504.828964948654
  timestamp: 1594104324
  timesteps_since_restore: 3870000
  timesteps_this_iter: 10000
  timesteps_total: 3870000
  training_iteration: 387
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.3/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=13557], 9504 s, 387 iter, 3870000 ts, 1.18e+03 rew

agent-1: 75.0
agent-2: 113.0
agent-3: 92.0
agent-4: 107.0
agent-5: 113.0
agent-6: 95.0
agent-7: 80.0
agent-8: 95.0
agent-9: 116.0
agent-10: 112.0
Sum Reward: 998.0
Avg Reward: 99.8
Min Reward: 75.0
Max Reward: 116.0
Gini Coefficient: 0.07695390781563126
20:20 Ratio: 1.4774193548387098
Max-min Ratio: 1.5466666666666666
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_02-45-49
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1861.0
  episode_reward_mean: 1182.11
  episode_reward_min: 821.0
  episodes_this_iter: 1
  episodes_total: 387
  experiment_id: a3942a9886f24694ab1b58ca8d1ab856
  hostname: gpu006
  info:
    apply_time_ms: 2.916
    dispatch_time_ms: 34.176
    learner:
      cur_lr: 0.0011022579856216908
      grad_gnorm: 39.9999885559082
      policy_entropy: 33.542930603027344
      policy_loss: 5.216896057128906
      var_gnorm: 55.009273529052734
      vf_explained_var: 0.9785653948783875
      vf_loss: 25.628747940063477
    num_steps_sampled: 3880000
    num_steps_trained: 3880000
    wait_time_ms: 222.168
  iterations_since_restore: 388
  node_ip: 172.17.8.6
  num_metric_batches_dropped: 0
  pid: 13557
  policy_reward_mean: {}
  time_since_restore: 9529.577248811722
  time_this_iter_s: 24.748283863067627
  time_total_s: 9529.577248811722
  timestamp: 1594104349
  timesteps_since_restore: 3880000
  timesteps_this_iter: 10000
  timesteps_total: 3880000
  training_iteration: 388
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=13557], 9529 s, 388 iter, 3880000 ts, 1.18e+03 rew

agent-1: 88.0
agent-2: 257.0
agent-3: 83.0
agent-4: 93.0
agent-5: 107.0
agent-6: 88.0
agent-7: 103.0
agent-8: 87.0
agent-9: 166.0
agent-10: 98.0
Sum Reward: 1170.0
Avg Reward: 117.0
Min Reward: 83.0
Max Reward: 257.0
Gini Coefficient: 0.19350427350427352
20:20 Ratio: 2.488235294117647
Max-min Ratio: 3.0963855421686746
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_02-46-15
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1861.0
  episode_reward_mean: 1179.04
  episode_reward_min: 821.0
  episodes_this_iter: 1
  episodes_total: 388
  experiment_id: a3942a9886f24694ab1b58ca8d1ab856
  hostname: gpu006
  info:
    apply_time_ms: 2.778
    dispatch_time_ms: 36.312
    learner:
      cur_lr: 0.0011015919735655189
      grad_gnorm: 40.000003814697266
      policy_entropy: 26.79578399658203
      policy_loss: 5.419738292694092
      var_gnorm: 55.001644134521484
      vf_explained_var: 0.33706164360046387
      vf_loss: 88.30978393554688
    num_steps_sampled: 3890000
    num_steps_trained: 3890000
    wait_time_ms: 210.398
  iterations_since_restore: 389
  node_ip: 172.17.8.6
  num_metric_batches_dropped: 0
  pid: 13557
  policy_reward_mean: {}
  time_since_restore: 9555.359847307205
  time_this_iter_s: 25.7825984954834
  time_total_s: 9555.359847307205
  timestamp: 1594104375
  timesteps_since_restore: 3890000
  timesteps_this_iter: 10000
  timesteps_total: 3890000
  training_iteration: 389
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=13557], 9555 s, 389 iter, 3890000 ts, 1.18e+03 rew

agent-1: 79.0
agent-2: 80.0
agent-3: 105.0
agent-4: 108.0
agent-5: 109.0
agent-6: 73.0
agent-7: 94.0
agent-8: 78.0
agent-9: 104.0
agent-10: 92.0
Sum Reward: 922.0
Avg Reward: 92.2
Min Reward: 73.0
Max Reward: 109.0
Gini Coefficient: 0.08004338394793926
20:20 Ratio: 1.4370860927152318
Max-min Ratio: 1.4931506849315068
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_02-46-40
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1861.0
  episode_reward_mean: 1172.65
  episode_reward_min: 821.0
  episodes_this_iter: 1
  episodes_total: 389
  experiment_id: a3942a9886f24694ab1b58ca8d1ab856
  hostname: gpu006
  info:
    apply_time_ms: 3.33
    dispatch_time_ms: 45.483
    learner:
      cur_lr: 0.001100925961509347
      grad_gnorm: 12.937862396240234
      policy_entropy: 47.3928337097168
      policy_loss: -1.6282356977462769
      var_gnorm: 55.017234802246094
      vf_explained_var: 0.0
      vf_loss: 0.094965860247612
    num_steps_sampled: 3900000
    num_steps_trained: 3900000
    wait_time_ms: 218.67
  iterations_since_restore: 390
  node_ip: 172.17.8.6
  num_metric_batches_dropped: 0
  pid: 13557
  policy_reward_mean: {}
  time_since_restore: 9580.026587963104
  time_this_iter_s: 24.666740655899048
  time_total_s: 9580.026587963104
  timestamp: 1594104400
  timesteps_since_restore: 3900000
  timesteps_this_iter: 10000
  timesteps_total: 3900000
  training_iteration: 390
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=13557], 9580 s, 390 iter, 3900000 ts, 1.17e+03 rew

agent-1: 119.0
agent-2: 158.0
agent-3: 102.0
agent-4: 95.0
agent-5: 101.0
agent-6: 97.0
agent-7: 104.0
agent-8: 107.0
agent-9: 109.0
agent-10: 90.0
Sum Reward: 1082.0
Avg Reward: 108.2
Min Reward: 90.0
Max Reward: 158.0
Gini Coefficient: 0.07948243992606285
20:20 Ratio: 1.4972972972972973
Max-min Ratio: 1.7555555555555555
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_02-47-05
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1861.0
  episode_reward_mean: 1166.45
  episode_reward_min: 821.0
  episodes_this_iter: 1
  episodes_total: 390
  experiment_id: a3942a9886f24694ab1b58ca8d1ab856
  hostname: gpu006
  info:
    apply_time_ms: 2.902
    dispatch_time_ms: 5.881
    learner:
      cur_lr: 0.001100259949453175
      grad_gnorm: 0.9550929665565491
      policy_entropy: 55.10045623779297
      policy_loss: -0.22891631722450256
      var_gnorm: 55.101905822753906
      vf_explained_var: 0.9959840774536133
      vf_loss: 0.013242589309811592
    num_steps_sampled: 3910000
    num_steps_trained: 3910000
    wait_time_ms: 244.641
  iterations_since_restore: 391
  node_ip: 172.17.8.6
  num_metric_batches_dropped: 0
  pid: 13557
  policy_reward_mean: {}
  time_since_restore: 9605.356859445572
  time_this_iter_s: 25.33027148246765
  time_total_s: 9605.356859445572
  timestamp: 1594104425
  timesteps_since_restore: 3910000
  timesteps_this_iter: 10000
  timesteps_total: 3910000
  training_iteration: 391
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=13557], 9605 s, 391 iter, 3910000 ts, 1.17e+03 rew

agent-1: 86.0
agent-2: 97.0
agent-3: 95.0
agent-4: 89.0
agent-5: 106.0
agent-6: 127.0
agent-7: 91.0
agent-8: 86.0
agent-9: 121.0
agent-10: 106.0
Sum Reward: 1004.0
Avg Reward: 100.4
Min Reward: 86.0
Max Reward: 127.0
Gini Coefficient: 0.07430278884462152
20:20 Ratio: 1.441860465116279
Max-min Ratio: 1.4767441860465116
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_02-47-30
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1861.0
  episode_reward_mean: 1162.57
  episode_reward_min: 821.0
  episodes_this_iter: 1
  episodes_total: 391
  experiment_id: a3942a9886f24694ab1b58ca8d1ab856
  hostname: gpu006
  info:
    apply_time_ms: 4.324
    dispatch_time_ms: 7.347
    learner:
      cur_lr: 0.001099594053812325
      grad_gnorm: 40.000003814697266
      policy_entropy: 12.089612007141113
      policy_loss: -0.054522980004549026
      var_gnorm: 55.03575897216797
      vf_explained_var: 0.7161980271339417
      vf_loss: 238.8124542236328
    num_steps_sampled: 3920000
    num_steps_trained: 3920000
    wait_time_ms: 245.382
  iterations_since_restore: 392
  node_ip: 172.17.8.6
  num_metric_batches_dropped: 0
  pid: 13557
  policy_reward_mean: {}
  time_since_restore: 9629.779250144958
  time_this_iter_s: 24.422390699386597
  time_total_s: 9629.779250144958
  timestamp: 1594104450
  timesteps_since_restore: 3920000
  timesteps_this_iter: 10000
  timesteps_total: 3920000
  training_iteration: 392
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=13557], 9629 s, 392 iter, 3920000 ts, 1.16e+03 rew

agent-1: 118.0
agent-2: 100.0
agent-3: 81.0
agent-4: 80.0
agent-5: 83.0
agent-6: 96.0
agent-7: 121.0
agent-8: 76.0
agent-9: 108.0
agent-10: 82.0
Sum Reward: 945.0
Avg Reward: 94.5
Min Reward: 76.0
Max Reward: 121.0
Gini Coefficient: 0.09238095238095238
20:20 Ratio: 1.5320512820512822
Max-min Ratio: 1.5921052631578947
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_02-47-55
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1861.0
  episode_reward_mean: 1157.85
  episode_reward_min: 821.0
  episodes_this_iter: 1
  episodes_total: 392
  experiment_id: a3942a9886f24694ab1b58ca8d1ab856
  hostname: gpu006
  info:
    apply_time_ms: 2.491
    dispatch_time_ms: 6.089
    learner:
      cur_lr: 0.001098928041756153
      grad_gnorm: 13.342146873474121
      policy_entropy: 33.47521209716797
      policy_loss: -2.0993573665618896
      var_gnorm: 55.14985656738281
      vf_explained_var: 0.5265769958496094
      vf_loss: 0.8370017409324646
    num_steps_sampled: 3930000
    num_steps_trained: 3930000
    wait_time_ms: 246.903
  iterations_since_restore: 393
  node_ip: 172.17.8.6
  num_metric_batches_dropped: 0
  pid: 13557
  policy_reward_mean: {}
  time_since_restore: 9655.01367354393
  time_this_iter_s: 25.234423398971558
  time_total_s: 9655.01367354393
  timestamp: 1594104475
  timesteps_since_restore: 3930000
  timesteps_this_iter: 10000
  timesteps_total: 3930000
  training_iteration: 393
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=13557], 9655 s, 393 iter, 3930000 ts, 1.16e+03 rew

agent-1: 86.0
agent-2: 89.0
agent-3: 97.0
agent-4: 81.0
agent-5: 107.0
agent-6: 87.0
agent-7: 89.0
agent-8: 85.0
agent-9: 101.0
agent-10: 119.0
Sum Reward: 941.0
Avg Reward: 94.1
Min Reward: 81.0
Max Reward: 119.0
Gini Coefficient: 0.0638682252922423
20:20 Ratio: 1.3614457831325302
Max-min Ratio: 1.4691358024691359
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_02-48-19
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1861.0
  episode_reward_mean: 1154.34
  episode_reward_min: 821.0
  episodes_this_iter: 1
  episodes_total: 393
  experiment_id: a3942a9886f24694ab1b58ca8d1ab856
  hostname: gpu006
  info:
    apply_time_ms: 2.814
    dispatch_time_ms: 6.715
    learner:
      cur_lr: 0.0010982620296999812
      grad_gnorm: 40.000003814697266
      policy_entropy: 28.19242286682129
      policy_loss: 24.5064754486084
      var_gnorm: 55.0345458984375
      vf_explained_var: 0.25810158252716064
      vf_loss: 288.703369140625
    num_steps_sampled: 3940000
    num_steps_trained: 3940000
    wait_time_ms: 253.671
  iterations_since_restore: 394
  node_ip: 172.17.8.6
  num_metric_batches_dropped: 0
  pid: 13557
  policy_reward_mean: {}
  time_since_restore: 9678.877279520035
  time_this_iter_s: 23.863605976104736
  time_total_s: 9678.877279520035
  timestamp: 1594104499
  timesteps_since_restore: 3940000
  timesteps_this_iter: 10000
  timesteps_total: 3940000
  training_iteration: 394
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=13557], 9678 s, 394 iter, 3940000 ts, 1.15e+03 rew

agent-1: 95.0
agent-2: 108.0
agent-3: 106.0
agent-4: 117.0
agent-5: 107.0
agent-6: 82.0
agent-7: 123.0
agent-8: 138.0
agent-9: 133.0
agent-10: 118.0
Sum Reward: 1127.0
Avg Reward: 112.7
Min Reward: 82.0
Max Reward: 138.0
Gini Coefficient: 0.07959183673469387
20:20 Ratio: 1.5310734463276836
Max-min Ratio: 1.6829268292682926
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_02-48-44
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1861.0
  episode_reward_mean: 1154.46
  episode_reward_min: 821.0
  episodes_this_iter: 1
  episodes_total: 394
  experiment_id: a3942a9886f24694ab1b58ca8d1ab856
  hostname: gpu006
  info:
    apply_time_ms: 2.742
    dispatch_time_ms: 6.45
    learner:
      cur_lr: 0.0010975960176438093
      grad_gnorm: 13.181623458862305
      policy_entropy: 31.78395652770996
      policy_loss: -0.6303452849388123
      var_gnorm: 55.00107955932617
      vf_explained_var: 0.637657105922699
      vf_loss: 0.845120906829834
    num_steps_sampled: 3950000
    num_steps_trained: 3950000
    wait_time_ms: 256.869
  iterations_since_restore: 395
  node_ip: 172.17.8.6
  num_metric_batches_dropped: 0
  pid: 13557
  policy_reward_mean: {}
  time_since_restore: 9704.167530536652
  time_this_iter_s: 25.29025101661682
  time_total_s: 9704.167530536652
  timestamp: 1594104524
  timesteps_since_restore: 3950000
  timesteps_this_iter: 10000
  timesteps_total: 3950000
  training_iteration: 395
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=13557], 9704 s, 395 iter, 3950000 ts, 1.15e+03 rew

agent-1: 69.0
agent-2: 91.0
agent-3: 108.0
agent-4: 97.0
agent-5: 91.0
agent-6: 108.0
agent-7: 116.0
agent-8: 127.0
agent-9: 81.0
agent-10: 103.0
Sum Reward: 991.0
Avg Reward: 99.1
Min Reward: 69.0
Max Reward: 127.0
Gini Coefficient: 0.0917255297679112
20:20 Ratio: 1.62
Max-min Ratio: 1.8405797101449275
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_02-49-08
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1861.0
  episode_reward_mean: 1152.25
  episode_reward_min: 821.0
  episodes_this_iter: 1
  episodes_total: 395
  experiment_id: a3942a9886f24694ab1b58ca8d1ab856
  hostname: gpu006
  info:
    apply_time_ms: 2.731
    dispatch_time_ms: 7.103
    learner:
      cur_lr: 0.0010969300055876374
      grad_gnorm: 33.12852096557617
      policy_entropy: 6.758795261383057
      policy_loss: 2.430656909942627
      var_gnorm: 55.112571716308594
      vf_explained_var: 0.9832402467727661
      vf_loss: 8.205578804016113
    num_steps_sampled: 3960000
    num_steps_trained: 3960000
    wait_time_ms: 247.332
  iterations_since_restore: 396
  node_ip: 172.17.8.6
  num_metric_batches_dropped: 0
  pid: 13557
  policy_reward_mean: {}
  time_since_restore: 9728.298748970032
  time_this_iter_s: 24.131218433380127
  time_total_s: 9728.298748970032
  timestamp: 1594104548
  timesteps_since_restore: 3960000
  timesteps_this_iter: 10000
  timesteps_total: 3960000
  training_iteration: 396
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=13557], 9728 s, 396 iter, 3960000 ts, 1.15e+03 rew

agent-1: 117.0
agent-2: 121.0
agent-3: 125.0
agent-4: 145.0
agent-5: 114.0
agent-6: 86.0
agent-7: 90.0
agent-8: 90.0
agent-9: 148.0
agent-10: 90.0
Sum Reward: 1126.0
Avg Reward: 112.6
Min Reward: 86.0
Max Reward: 148.0
Gini Coefficient: 0.10781527531083482
20:20 Ratio: 1.6647727272727273
Max-min Ratio: 1.7209302325581395
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_02-49-33
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1861.0
  episode_reward_mean: 1146.73
  episode_reward_min: 821.0
  episodes_this_iter: 1
  episodes_total: 396
  experiment_id: a3942a9886f24694ab1b58ca8d1ab856
  hostname: gpu006
  info:
    apply_time_ms: 2.652
    dispatch_time_ms: 7.254
    learner:
      cur_lr: 0.0010962639935314655
      grad_gnorm: 40.0
      policy_entropy: 15.482439994812012
      policy_loss: -7.980240821838379
      var_gnorm: 55.23295974731445
      vf_explained_var: -1.0
      vf_loss: 30.414684295654297
    num_steps_sampled: 3970000
    num_steps_trained: 3970000
    wait_time_ms: 241.42
  iterations_since_restore: 397
  node_ip: 172.17.8.6
  num_metric_batches_dropped: 0
  pid: 13557
  policy_reward_mean: {}
  time_since_restore: 9753.16994023323
  time_this_iter_s: 24.871191263198853
  time_total_s: 9753.16994023323
  timestamp: 1594104573
  timesteps_since_restore: 3970000
  timesteps_this_iter: 10000
  timesteps_total: 3970000
  training_iteration: 397
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=13557], 9753 s, 397 iter, 3970000 ts, 1.15e+03 rew

agent-1: 85.0
agent-2: 98.0
agent-3: 89.0
agent-4: 81.0
agent-5: 82.0
agent-6: 99.0
agent-7: 123.0
agent-8: 102.0
agent-9: 126.0
agent-10: 104.0
Sum Reward: 989.0
Avg Reward: 98.9
Min Reward: 81.0
Max Reward: 126.0
Gini Coefficient: 0.08361981799797776
20:20 Ratio: 1.5276073619631902
Max-min Ratio: 1.5555555555555556
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_02-49-57
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1861.0
  episode_reward_mean: 1140.86
  episode_reward_min: 821.0
  episodes_this_iter: 1
  episodes_total: 397
  experiment_id: a3942a9886f24694ab1b58ca8d1ab856
  hostname: gpu006
  info:
    apply_time_ms: 2.595
    dispatch_time_ms: 6.121
    learner:
      cur_lr: 0.0010955979814752936
      grad_gnorm: 19.766216278076172
      policy_entropy: 10.777387619018555
      policy_loss: 2.2887449264526367
      var_gnorm: 55.14992904663086
      vf_explained_var: 0.9916445016860962
      vf_loss: 9.925209045410156
    num_steps_sampled: 3980000
    num_steps_trained: 3980000
    wait_time_ms: 241.774
  iterations_since_restore: 398
  node_ip: 172.17.8.6
  num_metric_batches_dropped: 0
  pid: 13557
  policy_reward_mean: {}
  time_since_restore: 9777.36300611496
  time_this_iter_s: 24.193065881729126
  time_total_s: 9777.36300611496
  timestamp: 1594104597
  timesteps_since_restore: 3980000
  timesteps_this_iter: 10000
  timesteps_total: 3980000
  training_iteration: 398
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=13557], 9777 s, 398 iter, 3980000 ts, 1.14e+03 rew

agent-1: 110.0
agent-2: 122.0
agent-3: 122.0
agent-4: 104.0
agent-5: 89.0
agent-6: 106.0
agent-7: 99.0
agent-8: 103.0
agent-9: 116.0
agent-10: 98.0
Sum Reward: 1069.0
Avg Reward: 106.9
Min Reward: 89.0
Max Reward: 122.0
Gini Coefficient: 0.053601496725912065
20:20 Ratio: 1.304812834224599
Max-min Ratio: 1.3707865168539326
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_02-50-22
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1861.0
  episode_reward_mean: 1137.13
  episode_reward_min: 821.0
  episodes_this_iter: 1
  episodes_total: 398
  experiment_id: a3942a9886f24694ab1b58ca8d1ab856
  hostname: gpu006
  info:
    apply_time_ms: 2.64
    dispatch_time_ms: 7.413
    learner:
      cur_lr: 0.0010949319694191217
      grad_gnorm: 40.0
      policy_entropy: 29.130531311035156
      policy_loss: 3.1631503105163574
      var_gnorm: 55.291587829589844
      vf_explained_var: 0.9124776124954224
      vf_loss: 165.09750366210938
    num_steps_sampled: 3990000
    num_steps_trained: 3990000
    wait_time_ms: 229.387
  iterations_since_restore: 399
  node_ip: 172.17.8.6
  num_metric_batches_dropped: 0
  pid: 13557
  policy_reward_mean: {}
  time_since_restore: 9801.777075529099
  time_this_iter_s: 24.414069414138794
  time_total_s: 9801.777075529099
  timestamp: 1594104622
  timesteps_since_restore: 3990000
  timesteps_this_iter: 10000
  timesteps_total: 3990000
  training_iteration: 399
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=13557], 9801 s, 399 iter, 3990000 ts, 1.14e+03 rew

agent-1: 102.0
agent-2: 129.0
agent-3: 114.0
agent-4: 114.0
agent-5: 158.0
agent-6: 107.0
agent-7: 116.0
agent-8: 115.0
agent-9: 110.0
agent-10: 139.0
Sum Reward: 1204.0
Avg Reward: 120.4
Min Reward: 102.0
Max Reward: 158.0
Gini Coefficient: 0.06893687707641195
20:20 Ratio: 1.4210526315789473
Max-min Ratio: 1.5490196078431373
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_02-50-46
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1861.0
  episode_reward_mean: 1136.17
  episode_reward_min: 821.0
  episodes_this_iter: 1
  episodes_total: 399
  experiment_id: a3942a9886f24694ab1b58ca8d1ab856
  hostname: gpu006
  info:
    apply_time_ms: 2.848
    dispatch_time_ms: 8.324
    learner:
      cur_lr: 0.0010942659573629498
      grad_gnorm: 40.00000762939453
      policy_entropy: 17.50139045715332
      policy_loss: 4.126975059509277
      var_gnorm: 55.35929870605469
      vf_explained_var: 0.8251359462738037
      vf_loss: 23.52755355834961
    num_steps_sampled: 4000000
    num_steps_trained: 4000000
    wait_time_ms: 248.725
  iterations_since_restore: 400
  node_ip: 172.17.8.6
  num_metric_batches_dropped: 0
  pid: 13557
  policy_reward_mean: {}
  time_since_restore: 9825.734371900558
  time_this_iter_s: 23.95729637145996
  time_total_s: 9825.734371900558
  timestamp: 1594104646
  timesteps_since_restore: 4000000
  timesteps_this_iter: 10000
  timesteps_total: 4000000
  training_iteration: 400
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=13557], 9825 s, 400 iter, 4000000 ts, 1.14e+03 rew

agent-1: 114.0
agent-2: 99.0
agent-3: 141.0
agent-4: 108.0
agent-5: 96.0
agent-6: 106.0
agent-7: 65.0
agent-8: 122.0
agent-9: 90.0
agent-10: 83.0
Sum Reward: 1024.0
Avg Reward: 102.4
Min Reward: 65.0
Max Reward: 141.0
Gini Coefficient: 0.109375
20:20 Ratio: 1.777027027027027
Max-min Ratio: 2.169230769230769
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_02-51-13
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1861.0
  episode_reward_mean: 1135.52
  episode_reward_min: 821.0
  episodes_this_iter: 1
  episodes_total: 400
  experiment_id: a3942a9886f24694ab1b58ca8d1ab856
  hostname: gpu006
  info:
    apply_time_ms: 3.303
    dispatch_time_ms: 6.561
    learner:
      cur_lr: 0.001093599945306778
      grad_gnorm: 39.99999237060547
      policy_entropy: 14.196418762207031
      policy_loss: -2.1255927085876465
      var_gnorm: 55.45088577270508
      vf_explained_var: 0.9866089820861816
      vf_loss: 10.772878646850586
    num_steps_sampled: 4010000
    num_steps_trained: 4010000
    wait_time_ms: 222.42
  iterations_since_restore: 401
  node_ip: 172.17.8.6
  num_metric_batches_dropped: 0
  pid: 13557
  policy_reward_mean: {}
  time_since_restore: 9852.957811832428
  time_this_iter_s: 27.223439931869507
  time_total_s: 9852.957811832428
  timestamp: 1594104673
  timesteps_since_restore: 4010000
  timesteps_this_iter: 10000
  timesteps_total: 4010000
  training_iteration: 401
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=13557], 9852 s, 401 iter, 4010000 ts, 1.14e+03 rew

agent-1: 118.0
agent-2: 116.0
agent-3: 158.0
agent-4: 145.0
agent-5: 104.0
agent-6: 105.0
agent-7: 127.0
agent-8: 121.0
agent-9: 143.0
agent-10: 131.0
Sum Reward: 1268.0
Avg Reward: 126.8
Min Reward: 104.0
Max Reward: 158.0
Gini Coefficient: 0.07460567823343849
20:20 Ratio: 1.4497607655502391
Max-min Ratio: 1.5192307692307692
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_02-51-37
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1861.0
  episode_reward_mean: 1133.2
  episode_reward_min: 821.0
  episodes_this_iter: 1
  episodes_total: 401
  experiment_id: a3942a9886f24694ab1b58ca8d1ab856
  hostname: gpu006
  info:
    apply_time_ms: 2.512
    dispatch_time_ms: 6.872
    learner:
      cur_lr: 0.0010929340496659279
      grad_gnorm: 40.0
      policy_entropy: 7.835947513580322
      policy_loss: -0.38549962639808655
      var_gnorm: 55.49808883666992
      vf_explained_var: 0.7245173454284668
      vf_loss: 176.14218139648438
    num_steps_sampled: 4020000
    num_steps_trained: 4020000
    wait_time_ms: 228.5
  iterations_since_restore: 402
  node_ip: 172.17.8.6
  num_metric_batches_dropped: 0
  pid: 13557
  policy_reward_mean: {}
  time_since_restore: 9876.862475633621
  time_this_iter_s: 23.904663801193237
  time_total_s: 9876.862475633621
  timestamp: 1594104697
  timesteps_since_restore: 4020000
  timesteps_this_iter: 10000
  timesteps_total: 4020000
  training_iteration: 402
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=13557], 9876 s, 402 iter, 4020000 ts, 1.13e+03 rew

agent-1: 151.0
agent-2: 109.0
agent-3: 131.0
agent-4: 129.0
agent-5: 139.0
agent-6: 114.0
agent-7: 121.0
agent-8: 128.0
agent-9: 141.0
agent-10: 133.0
Sum Reward: 1296.0
Avg Reward: 129.6
Min Reward: 109.0
Max Reward: 151.0
Gini Coefficient: 0.052006172839506176
20:20 Ratio: 1.3094170403587444
Max-min Ratio: 1.385321100917431
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_02-52-02
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1861.0
  episode_reward_mean: 1130.24
  episode_reward_min: 821.0
  episodes_this_iter: 1
  episodes_total: 402
  experiment_id: a3942a9886f24694ab1b58ca8d1ab856
  hostname: gpu006
  info:
    apply_time_ms: 2.851
    dispatch_time_ms: 7.416
    learner:
      cur_lr: 0.001092268037609756
      grad_gnorm: 14.312835693359375
      policy_entropy: 26.596790313720703
      policy_loss: -0.0867827832698822
      var_gnorm: 55.48657989501953
      vf_explained_var: 0.9580605626106262
      vf_loss: 12.541792869567871
    num_steps_sampled: 4030000
    num_steps_trained: 4030000
    wait_time_ms: 252.451
  iterations_since_restore: 403
  node_ip: 172.17.8.6
  num_metric_batches_dropped: 0
  pid: 13557
  policy_reward_mean: {}
  time_since_restore: 9901.62516283989
  time_this_iter_s: 24.76268720626831
  time_total_s: 9901.62516283989
  timestamp: 1594104722
  timesteps_since_restore: 4030000
  timesteps_this_iter: 10000
  timesteps_total: 4030000
  training_iteration: 403
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=13557], 9901 s, 403 iter, 4030000 ts, 1.13e+03 rew

agent-1: 102.0
agent-2: 79.0
agent-3: 103.0
agent-4: 108.0
agent-5: 118.0
agent-6: 118.0
agent-7: 114.0
agent-8: 110.0
agent-9: 108.0
agent-10: 98.0
Sum Reward: 1058.0
Avg Reward: 105.8
Min Reward: 79.0
Max Reward: 118.0
Gini Coefficient: 0.05406427221172023
20:20 Ratio: 1.3333333333333333
Max-min Ratio: 1.4936708860759493
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_02-52-26
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1861.0
  episode_reward_mean: 1129.28
  episode_reward_min: 821.0
  episodes_this_iter: 1
  episodes_total: 403
  experiment_id: a3942a9886f24694ab1b58ca8d1ab856
  hostname: gpu006
  info:
    apply_time_ms: 2.733
    dispatch_time_ms: 7.302
    learner:
      cur_lr: 0.001091602025553584
      grad_gnorm: 11.870302200317383
      policy_entropy: 19.126379013061523
      policy_loss: -1.3740607500076294
      var_gnorm: 55.63972473144531
      vf_explained_var: 0.6946648359298706
      vf_loss: 0.31274470686912537
    num_steps_sampled: 4040000
    num_steps_trained: 4040000
    wait_time_ms: 253.024
  iterations_since_restore: 404
  node_ip: 172.17.8.6
  num_metric_batches_dropped: 0
  pid: 13557
  policy_reward_mean: {}
  time_since_restore: 9926.202028512955
  time_this_iter_s: 24.576865673065186
  time_total_s: 9926.202028512955
  timestamp: 1594104746
  timesteps_since_restore: 4040000
  timesteps_this_iter: 10000
  timesteps_total: 4040000
  training_iteration: 404
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=13557], 9926 s, 404 iter, 4040000 ts, 1.13e+03 rew

agent-1: 92.0
agent-2: 109.0
agent-3: 89.0
agent-4: 87.0
agent-5: 122.0
agent-6: 125.0
agent-7: 91.0
agent-8: 100.0
agent-9: 108.0
agent-10: 81.0
Sum Reward: 1004.0
Avg Reward: 100.4
Min Reward: 81.0
Max Reward: 125.0
Gini Coefficient: 0.0796812749003984
20:20 Ratio: 1.4702380952380953
Max-min Ratio: 1.5432098765432098
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_02-52-51
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1861.0
  episode_reward_mean: 1130.3
  episode_reward_min: 821.0
  episodes_this_iter: 1
  episodes_total: 404
  experiment_id: a3942a9886f24694ab1b58ca8d1ab856
  hostname: gpu006
  info:
    apply_time_ms: 4.139
    dispatch_time_ms: 6.432
    learner:
      cur_lr: 0.0010909360134974122
      grad_gnorm: 39.99999237060547
      policy_entropy: 12.03812026977539
      policy_loss: -8.328680992126465
      var_gnorm: 55.66339874267578
      vf_explained_var: 0.9628909826278687
      vf_loss: 62.83493423461914
    num_steps_sampled: 4050000
    num_steps_trained: 4050000
    wait_time_ms: 231.713
  iterations_since_restore: 405
  node_ip: 172.17.8.6
  num_metric_batches_dropped: 0
  pid: 13557
  policy_reward_mean: {}
  time_since_restore: 9950.82031083107
  time_this_iter_s: 24.618282318115234
  time_total_s: 9950.82031083107
  timestamp: 1594104771
  timesteps_since_restore: 4050000
  timesteps_this_iter: 10000
  timesteps_total: 4050000
  training_iteration: 405
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=13557], 9950 s, 405 iter, 4050000 ts, 1.13e+03 rew

agent-1: 94.0
agent-2: 101.0
agent-3: 188.0
agent-4: 70.0
agent-5: 114.0
agent-6: 77.0
agent-7: 109.0
agent-8: 128.0
agent-9: 99.0
agent-10: 103.0
Sum Reward: 1083.0
Avg Reward: 108.3
Min Reward: 70.0
Max Reward: 188.0
Gini Coefficient: 0.14321329639889196
20:20 Ratio: 2.1496598639455784
Max-min Ratio: 2.6857142857142855
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_02-53-16
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1861.0
  episode_reward_mean: 1131.32
  episode_reward_min: 821.0
  episodes_this_iter: 1
  episodes_total: 405
  experiment_id: a3942a9886f24694ab1b58ca8d1ab856
  hostname: gpu006
  info:
    apply_time_ms: 3.046
    dispatch_time_ms: 9.92
    learner:
      cur_lr: 0.0010902700014412403
      grad_gnorm: 40.00001525878906
      policy_entropy: 11.295074462890625
      policy_loss: -16.62417984008789
      var_gnorm: 55.758026123046875
      vf_explained_var: 0.5673806667327881
      vf_loss: 88.21107482910156
    num_steps_sampled: 4060000
    num_steps_trained: 4060000
    wait_time_ms: 240.452
  iterations_since_restore: 406
  node_ip: 172.17.8.6
  num_metric_batches_dropped: 0
  pid: 13557
  policy_reward_mean: {}
  time_since_restore: 9975.587262868881
  time_this_iter_s: 24.76695203781128
  time_total_s: 9975.587262868881
  timestamp: 1594104796
  timesteps_since_restore: 4060000
  timesteps_this_iter: 10000
  timesteps_total: 4060000
  training_iteration: 406
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=13557], 9975 s, 406 iter, 4060000 ts, 1.13e+03 rew

agent-1: 81.0
agent-2: 84.0
agent-3: 86.0
agent-4: 78.0
agent-5: 87.0
agent-6: 101.0
agent-7: 83.0
agent-8: 112.0
agent-9: 85.0
agent-10: 87.0
Sum Reward: 884.0
Avg Reward: 88.4
Min Reward: 78.0
Max Reward: 112.0
Gini Coefficient: 0.05384615384615385
20:20 Ratio: 1.3396226415094339
Max-min Ratio: 1.435897435897436
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_02-53-41
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1861.0
  episode_reward_mean: 1129.79
  episode_reward_min: 821.0
  episodes_this_iter: 1
  episodes_total: 406
  experiment_id: a3942a9886f24694ab1b58ca8d1ab856
  hostname: gpu006
  info:
    apply_time_ms: 2.822
    dispatch_time_ms: 5.417
    learner:
      cur_lr: 0.0010896039893850684
      grad_gnorm: 0.36678802967071533
      policy_entropy: 27.948789596557617
      policy_loss: 0.04276855289936066
      var_gnorm: 55.76133346557617
      vf_explained_var: 0.9870288968086243
      vf_loss: 0.000713699497282505
    num_steps_sampled: 4070000
    num_steps_trained: 4070000
    wait_time_ms: 240.175
  iterations_since_restore: 407
  node_ip: 172.17.8.6
  num_metric_batches_dropped: 0
  pid: 13557
  policy_reward_mean: {}
  time_since_restore: 10000.471378803253
  time_this_iter_s: 24.88411593437195
  time_total_s: 10000.471378803253
  timestamp: 1594104821
  timesteps_since_restore: 4070000
  timesteps_this_iter: 10000
  timesteps_total: 4070000
  training_iteration: 407
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=13557], 10000 s, 407 iter, 4070000 ts, 1.13e+03 rew

agent-1: 80.0
agent-2: 84.0
agent-3: 77.0
agent-4: 84.0
agent-5: 103.0
agent-6: 83.0
agent-7: 82.0
agent-8: 93.0
agent-9: 79.0
agent-10: 66.0
Sum Reward: 831.0
Avg Reward: 83.1
Min Reward: 66.0
Max Reward: 103.0
Gini Coefficient: 0.05812274368231047
20:20 Ratio: 1.3706293706293706
Max-min Ratio: 1.5606060606060606
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_02-54-06
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1861.0
  episode_reward_mean: 1128.5
  episode_reward_min: 821.0
  episodes_this_iter: 1
  episodes_total: 407
  experiment_id: a3942a9886f24694ab1b58ca8d1ab856
  hostname: gpu006
  info:
    apply_time_ms: 3.157
    dispatch_time_ms: 5.992
    learner:
      cur_lr: 0.0010889379773288965
      grad_gnorm: 40.0
      policy_entropy: 12.728683471679688
      policy_loss: -21.099985122680664
      var_gnorm: 55.77347946166992
      vf_explained_var: 0.85944002866745
      vf_loss: 150.99285888671875
    num_steps_sampled: 4080000
    num_steps_trained: 4080000
    wait_time_ms: 230.761
  iterations_since_restore: 408
  node_ip: 172.17.8.6
  num_metric_batches_dropped: 0
  pid: 13557
  policy_reward_mean: {}
  time_since_restore: 10025.147580862045
  time_this_iter_s: 24.676202058792114
  time_total_s: 10025.147580862045
  timestamp: 1594104846
  timesteps_since_restore: 4080000
  timesteps_this_iter: 10000
  timesteps_total: 4080000
  training_iteration: 408
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=13557], 10025 s, 408 iter, 4080000 ts, 1.13e+03 rew

agent-1: 71.0
agent-2: 77.0
agent-3: 84.0
agent-4: 91.0
agent-5: 95.0
agent-6: 98.0
agent-7: 85.0
agent-8: 113.0
agent-9: 72.0
agent-10: 88.0
Sum Reward: 874.0
Avg Reward: 87.4
Min Reward: 71.0
Max Reward: 113.0
Gini Coefficient: 0.07711670480549199
20:20 Ratio: 1.4755244755244756
Max-min Ratio: 1.591549295774648
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_02-54-30
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1861.0
  episode_reward_mean: 1123.28
  episode_reward_min: 821.0
  episodes_this_iter: 1
  episodes_total: 408
  experiment_id: a3942a9886f24694ab1b58ca8d1ab856
  hostname: gpu006
  info:
    apply_time_ms: 2.797
    dispatch_time_ms: 6.187
    learner:
      cur_lr: 0.0010882719652727246
      grad_gnorm: 40.0
      policy_entropy: 6.328350067138672
      policy_loss: 0.2831648886203766
      var_gnorm: 55.76922607421875
      vf_explained_var: 0.5552618503570557
      vf_loss: 566.3131713867188
    num_steps_sampled: 4090000
    num_steps_trained: 4090000
    wait_time_ms: 222.682
  iterations_since_restore: 409
  node_ip: 172.17.8.6
  num_metric_batches_dropped: 0
  pid: 13557
  policy_reward_mean: {}
  time_since_restore: 10049.996264219284
  time_this_iter_s: 24.84868335723877
  time_total_s: 10049.996264219284
  timestamp: 1594104870
  timesteps_since_restore: 4090000
  timesteps_this_iter: 10000
  timesteps_total: 4090000
  training_iteration: 409
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=13557], 10049 s, 409 iter, 4090000 ts, 1.12e+03 rew

agent-1: 128.0
agent-2: 102.0
agent-3: 90.0
agent-4: 99.0
agent-5: 98.0
agent-6: 83.0
agent-7: 97.0
agent-8: 92.0
agent-9: 96.0
agent-10: 88.0
Sum Reward: 973.0
Avg Reward: 97.3
Min Reward: 83.0
Max Reward: 128.0
Gini Coefficient: 0.05827338129496403
20:20 Ratio: 1.345029239766082
Max-min Ratio: 1.5421686746987953
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_02-54-55
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1861.0
  episode_reward_mean: 1118.09
  episode_reward_min: 821.0
  episodes_this_iter: 1
  episodes_total: 409
  experiment_id: a3942a9886f24694ab1b58ca8d1ab856
  hostname: gpu006
  info:
    apply_time_ms: 2.601
    dispatch_time_ms: 5.791
    learner:
      cur_lr: 0.0010876059532165527
      grad_gnorm: 7.591489791870117
      policy_entropy: 32.71300506591797
      policy_loss: -1.649758219718933
      var_gnorm: 55.73394012451172
      vf_explained_var: 0.943726658821106
      vf_loss: 1.2353440523147583
    num_steps_sampled: 4100000
    num_steps_trained: 4100000
    wait_time_ms: 248.278
  iterations_since_restore: 410
  node_ip: 172.17.8.6
  num_metric_batches_dropped: 0
  pid: 13557
  policy_reward_mean: {}
  time_since_restore: 10074.558813810349
  time_this_iter_s: 24.562549591064453
  time_total_s: 10074.558813810349
  timestamp: 1594104895
  timesteps_since_restore: 4100000
  timesteps_this_iter: 10000
  timesteps_total: 4100000
  training_iteration: 410
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=13557], 10074 s, 410 iter, 4100000 ts, 1.12e+03 rew

agent-1: 73.0
agent-2: 82.0
agent-3: 110.0
agent-4: 114.0
agent-5: 106.0
agent-6: 136.0
agent-7: 108.0
agent-8: 102.0
agent-9: 98.0
agent-10: 112.0
Sum Reward: 1041.0
Avg Reward: 104.1
Min Reward: 73.0
Max Reward: 136.0
Gini Coefficient: 0.08520653218059558
20:20 Ratio: 1.6129032258064515
Max-min Ratio: 1.8630136986301369
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_02-55-20
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1861.0
  episode_reward_mean: 1115.19
  episode_reward_min: 821.0
  episodes_this_iter: 1
  episodes_total: 410
  experiment_id: a3942a9886f24694ab1b58ca8d1ab856
  hostname: gpu006
  info:
    apply_time_ms: 2.811
    dispatch_time_ms: 6.367
    learner:
      cur_lr: 0.0010869400575757027
      grad_gnorm: 10.520550727844238
      policy_entropy: 30.6331844329834
      policy_loss: -0.8972963094711304
      var_gnorm: 55.77190017700195
      vf_explained_var: 0.00024127960205078125
      vf_loss: 0.06688430160284042
    num_steps_sampled: 4110000
    num_steps_trained: 4110000
    wait_time_ms: 256.131
  iterations_since_restore: 411
  node_ip: 172.17.8.6
  num_metric_batches_dropped: 0
  pid: 13557
  policy_reward_mean: {}
  time_since_restore: 10099.049068927765
  time_this_iter_s: 24.490255117416382
  time_total_s: 10099.049068927765
  timestamp: 1594104920
  timesteps_since_restore: 4110000
  timesteps_this_iter: 10000
  timesteps_total: 4110000
  training_iteration: 411
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=13557], 10099 s, 411 iter, 4110000 ts, 1.12e+03 rew

agent-1: 118.0
agent-2: 126.0
agent-3: 118.0
agent-4: 111.0
agent-5: 168.0
agent-6: 108.0
agent-7: 107.0
agent-8: 157.0
agent-9: 112.0
agent-10: 112.0
Sum Reward: 1237.0
Avg Reward: 123.7
Min Reward: 107.0
Max Reward: 168.0
Gini Coefficient: 0.08011317704122878
20:20 Ratio: 1.5116279069767442
Max-min Ratio: 1.5700934579439252
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_02-55-44
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1861.0
  episode_reward_mean: 1117.56
  episode_reward_min: 821.0
  episodes_this_iter: 1
  episodes_total: 411
  experiment_id: a3942a9886f24694ab1b58ca8d1ab856
  hostname: gpu006
  info:
    apply_time_ms: 3.854
    dispatch_time_ms: 7.9
    learner:
      cur_lr: 0.0010862740455195308
      grad_gnorm: 5.735991954803467
      policy_entropy: 49.62400817871094
      policy_loss: -0.9905350208282471
      var_gnorm: 55.824546813964844
      vf_explained_var: 0.0
      vf_loss: 0.019637782126665115
    num_steps_sampled: 4120000
    num_steps_trained: 4120000
    wait_time_ms: 237.739
  iterations_since_restore: 412
  node_ip: 172.17.8.6
  num_metric_batches_dropped: 0
  pid: 13557
  policy_reward_mean: {}
  time_since_restore: 10123.322736501694
  time_this_iter_s: 24.273667573928833
  time_total_s: 10123.322736501694
  timestamp: 1594104944
  timesteps_since_restore: 4120000
  timesteps_this_iter: 10000
  timesteps_total: 4120000
  training_iteration: 412
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=13557], 10123 s, 412 iter, 4120000 ts, 1.12e+03 rew

agent-1: 106.0
agent-2: 102.0
agent-3: 84.0
agent-4: 137.0
agent-5: 140.0
agent-6: 114.0
agent-7: 108.0
agent-8: 122.0
agent-9: 103.0
agent-10: 95.0
Sum Reward: 1111.0
Avg Reward: 111.1
Min Reward: 84.0
Max Reward: 140.0
Gini Coefficient: 0.08397839783978397
20:20 Ratio: 1.547486033519553
Max-min Ratio: 1.6666666666666667
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_02-56-09
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1861.0
  episode_reward_mean: 1118.01
  episode_reward_min: 821.0
  episodes_this_iter: 1
  episodes_total: 412
  experiment_id: a3942a9886f24694ab1b58ca8d1ab856
  hostname: gpu006
  info:
    apply_time_ms: 2.758
    dispatch_time_ms: 23.488
    learner:
      cur_lr: 0.0010856080334633589
      grad_gnorm: 39.99999237060547
      policy_entropy: 15.333720207214355
      policy_loss: 4.605289459228516
      var_gnorm: 55.88778305053711
      vf_explained_var: 0.590079665184021
      vf_loss: 270.8857116699219
    num_steps_sampled: 4130000
    num_steps_trained: 4130000
    wait_time_ms: 241.146
  iterations_since_restore: 413
  node_ip: 172.17.8.6
  num_metric_batches_dropped: 0
  pid: 13557
  policy_reward_mean: {}
  time_since_restore: 10148.393597602844
  time_this_iter_s: 25.070861101150513
  time_total_s: 10148.393597602844
  timestamp: 1594104969
  timesteps_since_restore: 4130000
  timesteps_this_iter: 10000
  timesteps_total: 4130000
  training_iteration: 413
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=13557], 10148 s, 413 iter, 4130000 ts, 1.12e+03 rew

agent-1: 76.0
agent-2: 93.0
agent-3: 84.0
agent-4: 113.0
agent-5: 75.0
agent-6: 54.0
agent-7: 85.0
agent-8: 74.0
agent-9: 114.0
agent-10: 66.0
Sum Reward: 834.0
Avg Reward: 83.4
Min Reward: 54.0
Max Reward: 114.0
Gini Coefficient: 0.12014388489208633
20:20 Ratio: 1.8916666666666666
Max-min Ratio: 2.111111111111111
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_02-56-35
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1861.0
  episode_reward_mean: 1115.97
  episode_reward_min: 821.0
  episodes_this_iter: 1
  episodes_total: 413
  experiment_id: a3942a9886f24694ab1b58ca8d1ab856
  hostname: gpu006
  info:
    apply_time_ms: 3.204
    dispatch_time_ms: 20.184
    learner:
      cur_lr: 0.001084942021407187
      grad_gnorm: 11.440325736999512
      policy_entropy: 47.3006591796875
      policy_loss: -2.0342776775360107
      var_gnorm: 55.86836624145508
      vf_explained_var: 0.9811084270477295
      vf_loss: 0.08708634972572327
    num_steps_sampled: 4140000
    num_steps_trained: 4140000
    wait_time_ms: 222.621
  iterations_since_restore: 414
  node_ip: 172.17.8.6
  num_metric_batches_dropped: 0
  pid: 13557
  policy_reward_mean: {}
  time_since_restore: 10174.029308319092
  time_this_iter_s: 25.63571071624756
  time_total_s: 10174.029308319092
  timestamp: 1594104995
  timesteps_since_restore: 4140000
  timesteps_this_iter: 10000
  timesteps_total: 4140000
  training_iteration: 414
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=13557], 10174 s, 414 iter, 4140000 ts, 1.12e+03 rew

agent-1: 127.0
agent-2: 83.0
agent-3: 113.0
agent-4: 118.0
agent-5: 101.0
agent-6: 87.0
agent-7: 93.0
agent-8: 118.0
agent-9: 95.0
agent-10: 73.0
Sum Reward: 1008.0
Avg Reward: 100.8
Min Reward: 73.0
Max Reward: 127.0
Gini Coefficient: 0.09444444444444444
20:20 Ratio: 1.5705128205128205
Max-min Ratio: 1.7397260273972603
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_02-57-00
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1861.0
  episode_reward_mean: 1116.66
  episode_reward_min: 821.0
  episodes_this_iter: 1
  episodes_total: 414
  experiment_id: a3942a9886f24694ab1b58ca8d1ab856
  hostname: gpu006
  info:
    apply_time_ms: 2.953
    dispatch_time_ms: 27.553
    learner:
      cur_lr: 0.001084276009351015
      grad_gnorm: 39.999996185302734
      policy_entropy: 8.954607963562012
      policy_loss: -1.6287055015563965
      var_gnorm: 55.91136932373047
      vf_explained_var: 0.899982213973999
      vf_loss: 95.88108825683594
    num_steps_sampled: 4150000
    num_steps_trained: 4150000
    wait_time_ms: 213.015
  iterations_since_restore: 415
  node_ip: 172.17.8.6
  num_metric_batches_dropped: 0
  pid: 13557
  policy_reward_mean: {}
  time_since_restore: 10199.50055193901
  time_this_iter_s: 25.471243619918823
  time_total_s: 10199.50055193901
  timestamp: 1594105020
  timesteps_since_restore: 4150000
  timesteps_this_iter: 10000
  timesteps_total: 4150000
  training_iteration: 415
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=13557], 10199 s, 415 iter, 4150000 ts, 1.12e+03 rew

W0707 02:57:20.059787 13553 client_connection.cc:255] [worker]ProcessMessage with type 1 took 8639 ms.
W0707 02:57:20.068001 13553 node_manager.cc:250] Last heartbeat was sent 8734 ms ago 
agent-1: 100.0
agent-2: 78.0
agent-3: 89.0
agent-4: 75.0
agent-5: 129.0
agent-6: 93.0
agent-7: 93.0
agent-8: 90.0
agent-9: 81.0
agent-10: 99.0
Sum Reward: 927.0
Avg Reward: 92.7
Min Reward: 75.0
Max Reward: 129.0
Gini Coefficient: 0.08036677454153182
20:20 Ratio: 1.4967320261437909
Max-min Ratio: 1.72
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_02-57-32
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1861.0
  episode_reward_mean: 1114.73
  episode_reward_min: 821.0
  episodes_this_iter: 1
  episodes_total: 415
  experiment_id: a3942a9886f24694ab1b58ca8d1ab856
  hostname: gpu006
  info:
    apply_time_ms: 2.557
    dispatch_time_ms: 12.852
    learner:
      cur_lr: 0.0010836099972948432
      grad_gnorm: 40.000003814697266
      policy_entropy: 17.878931045532227
      policy_loss: -16.925853729248047
      var_gnorm: 56.01052474975586
      vf_explained_var: 0.12914466857910156
      vf_loss: 341.0467834472656
    num_steps_sampled: 4160000
    num_steps_trained: 4160000
    wait_time_ms: 224.114
  iterations_since_restore: 416
  node_ip: 172.17.8.6
  num_metric_batches_dropped: 0
  pid: 13557
  policy_reward_mean: {}
  time_since_restore: 10231.47858786583
  time_this_iter_s: 31.978035926818848
  time_total_s: 10231.47858786583
  timestamp: 1594105052
  timesteps_since_restore: 4160000
  timesteps_this_iter: 10000
  timesteps_total: 4160000
  training_iteration: 416
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=13557], 10231 s, 416 iter, 4160000 ts, 1.11e+03 rew

agent-1: 105.0
agent-2: 100.0
agent-3: 98.0
agent-4: 126.0
agent-5: 84.0
agent-6: 92.0
agent-7: 122.0
agent-8: 109.0
agent-9: 108.0
agent-10: 127.0
Sum Reward: 1071.0
Avg Reward: 107.1
Min Reward: 84.0
Max Reward: 127.0
Gini Coefficient: 0.07236227824463119
20:20 Ratio: 1.4375
Max-min Ratio: 1.5119047619047619
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_02-57-57
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1861.0
  episode_reward_mean: 1114.49
  episode_reward_min: 821.0
  episodes_this_iter: 1
  episodes_total: 416
  experiment_id: a3942a9886f24694ab1b58ca8d1ab856
  hostname: gpu006
  info:
    apply_time_ms: 2.856
    dispatch_time_ms: 15.748
    learner:
      cur_lr: 0.0010829439852386713
      grad_gnorm: 1.7162060737609863
      policy_entropy: 38.58211898803711
      policy_loss: -0.19899263978004456
      var_gnorm: 56.085819244384766
      vf_explained_var: 0.994995653629303
      vf_loss: 0.005494441371411085
    num_steps_sampled: 4170000
    num_steps_trained: 4170000
    wait_time_ms: 237.728
  iterations_since_restore: 417
  node_ip: 172.17.8.6
  num_metric_batches_dropped: 0
  pid: 13557
  policy_reward_mean: {}
  time_since_restore: 10256.570529460907
  time_this_iter_s: 25.091941595077515
  time_total_s: 10256.570529460907
  timestamp: 1594105077
  timesteps_since_restore: 4170000
  timesteps_this_iter: 10000
  timesteps_total: 4170000
  training_iteration: 417
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=13557], 10256 s, 417 iter, 4170000 ts, 1.11e+03 rew

agent-1: 97.0
agent-2: 77.0
agent-3: 123.0
agent-4: 77.0
agent-5: 88.0
agent-6: 83.0
agent-7: 77.0
agent-8: 91.0
agent-9: 82.0
agent-10: 118.0
Sum Reward: 913.0
Avg Reward: 91.3
Min Reward: 77.0
Max Reward: 123.0
Gini Coefficient: 0.09123767798466594
20:20 Ratio: 1.5649350649350648
Max-min Ratio: 1.5974025974025974
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_02-58-25
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1861.0
  episode_reward_mean: 1110.72
  episode_reward_min: 821.0
  episodes_this_iter: 1
  episodes_total: 417
  experiment_id: a3942a9886f24694ab1b58ca8d1ab856
  hostname: gpu006
  info:
    apply_time_ms: 2.886
    dispatch_time_ms: 7.882
    learner:
      cur_lr: 0.0010822779731824994
      grad_gnorm: 40.0
      policy_entropy: 17.52212142944336
      policy_loss: -12.878955841064453
      var_gnorm: 56.12982177734375
      vf_explained_var: 0.4716155529022217
      vf_loss: 203.62315368652344
    num_steps_sampled: 4180000
    num_steps_trained: 4180000
    wait_time_ms: 214.734
  iterations_since_restore: 418
  node_ip: 172.17.8.6
  num_metric_batches_dropped: 0
  pid: 13557
  policy_reward_mean: {}
  time_since_restore: 10284.626822471619
  time_this_iter_s: 28.05629301071167
  time_total_s: 10284.626822471619
  timestamp: 1594105105
  timesteps_since_restore: 4180000
  timesteps_this_iter: 10000
  timesteps_total: 4180000
  training_iteration: 418
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=13557], 10284 s, 418 iter, 4180000 ts, 1.11e+03 rew

agent-1: 105.0
agent-2: 101.0
agent-3: 97.0
agent-4: 89.0
agent-5: 94.0
agent-6: 106.0
agent-7: 111.0
agent-8: 72.0
agent-9: 112.0
agent-10: 123.0
Sum Reward: 1010.0
Avg Reward: 101.0
Min Reward: 72.0
Max Reward: 123.0
Gini Coefficient: 0.07287128712871287
20:20 Ratio: 1.4596273291925466
Max-min Ratio: 1.7083333333333333
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_02-58-50
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1861.0
  episode_reward_mean: 1110.4
  episode_reward_min: 821.0
  episodes_this_iter: 1
  episodes_total: 418
  experiment_id: a3942a9886f24694ab1b58ca8d1ab856
  hostname: gpu006
  info:
    apply_time_ms: 2.696
    dispatch_time_ms: 6.588
    learner:
      cur_lr: 0.0010816119611263275
      grad_gnorm: 9.92093563079834
      policy_entropy: 63.754451751708984
      policy_loss: -1.2515848875045776
      var_gnorm: 56.1906852722168
      vf_explained_var: 0.37031733989715576
      vf_loss: 1.5545670986175537
    num_steps_sampled: 4190000
    num_steps_trained: 4190000
    wait_time_ms: 241.082
  iterations_since_restore: 419
  node_ip: 172.17.8.6
  num_metric_batches_dropped: 0
  pid: 13557
  policy_reward_mean: {}
  time_since_restore: 10308.980595111847
  time_this_iter_s: 24.35377264022827
  time_total_s: 10308.980595111847
  timestamp: 1594105130
  timesteps_since_restore: 4190000
  timesteps_this_iter: 10000
  timesteps_total: 4190000
  training_iteration: 419
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=13557], 10308 s, 419 iter, 4190000 ts, 1.11e+03 rew

agent-1: 96.0
agent-2: 100.0
agent-3: 82.0
agent-4: 104.0
agent-5: 93.0
agent-6: 101.0
agent-7: 109.0
agent-8: 108.0
agent-9: 82.0
agent-10: 109.0
Sum Reward: 984.0
Avg Reward: 98.4
Min Reward: 82.0
Max Reward: 109.0
Gini Coefficient: 0.0540650406504065
20:20 Ratio: 1.329268292682927
Max-min Ratio: 1.329268292682927
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_02-59-15
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1861.0
  episode_reward_mean: 1109.14
  episode_reward_min: 821.0
  episodes_this_iter: 1
  episodes_total: 419
  experiment_id: a3942a9886f24694ab1b58ca8d1ab856
  hostname: gpu006
  info:
    apply_time_ms: 2.897
    dispatch_time_ms: 6.034
    learner:
      cur_lr: 0.0010809459490701556
      grad_gnorm: 15.408235549926758
      policy_entropy: 78.44265747070312
      policy_loss: -3.3321826457977295
      var_gnorm: 56.26772689819336
      vf_explained_var: 0.4464336633682251
      vf_loss: 0.14063560962677002
    num_steps_sampled: 4200000
    num_steps_trained: 4200000
    wait_time_ms: 233.53
  iterations_since_restore: 420
  node_ip: 172.17.8.6
  num_metric_batches_dropped: 0
  pid: 13557
  policy_reward_mean: {}
  time_since_restore: 10333.945761680603
  time_this_iter_s: 24.965166568756104
  time_total_s: 10333.945761680603
  timestamp: 1594105155
  timesteps_since_restore: 4200000
  timesteps_this_iter: 10000
  timesteps_total: 4200000
  training_iteration: 420
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=13557], 10333 s, 420 iter, 4200000 ts, 1.11e+03 rew

agent-1: 100.0
agent-2: 104.0
agent-3: 101.0
agent-4: 96.0
agent-5: 84.0
agent-6: 101.0
agent-7: 104.0
agent-8: 88.0
agent-9: 100.0
agent-10: 110.0
Sum Reward: 988.0
Avg Reward: 98.8
Min Reward: 84.0
Max Reward: 110.0
Gini Coefficient: 0.039473684210526314
20:20 Ratio: 1.244186046511628
Max-min Ratio: 1.3095238095238095
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_02-59-40
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1861.0
  episode_reward_mean: 1103.27
  episode_reward_min: 821.0
  episodes_this_iter: 1
  episodes_total: 420
  experiment_id: a3942a9886f24694ab1b58ca8d1ab856
  hostname: gpu006
  info:
    apply_time_ms: 2.827
    dispatch_time_ms: 5.543
    learner:
      cur_lr: 0.0010802800534293056
      grad_gnorm: 40.000003814697266
      policy_entropy: 73.69432067871094
      policy_loss: 7.8824286460876465
      var_gnorm: 56.29104232788086
      vf_explained_var: 0.4591543674468994
      vf_loss: 72.5416488647461
    num_steps_sampled: 4210000
    num_steps_trained: 4210000
    wait_time_ms: 260.255
  iterations_since_restore: 421
  node_ip: 172.17.8.6
  num_metric_batches_dropped: 0
  pid: 13557
  policy_reward_mean: {}
  time_since_restore: 10358.66709446907
  time_this_iter_s: 24.721332788467407
  time_total_s: 10358.66709446907
  timestamp: 1594105180
  timesteps_since_restore: 4210000
  timesteps_this_iter: 10000
  timesteps_total: 4210000
  training_iteration: 421
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=13557], 10358 s, 421 iter, 4210000 ts, 1.1e+03 rew

agent-1: 78.0
agent-2: 109.0
agent-3: 98.0
agent-4: 102.0
agent-5: 80.0
agent-6: 123.0
agent-7: 90.0
agent-8: 109.0
agent-9: 103.0
agent-10: 95.0
Sum Reward: 987.0
Avg Reward: 98.7
Min Reward: 78.0
Max Reward: 123.0
Gini Coefficient: 0.07406281661600811
20:20 Ratio: 1.4683544303797469
Max-min Ratio: 1.5769230769230769
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_03-00-05
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1861.0
  episode_reward_mean: 1096.24
  episode_reward_min: 821.0
  episodes_this_iter: 1
  episodes_total: 421
  experiment_id: a3942a9886f24694ab1b58ca8d1ab856
  hostname: gpu006
  info:
    apply_time_ms: 2.597
    dispatch_time_ms: 5.617
    learner:
      cur_lr: 0.0010796140413731337
      grad_gnorm: 8.35971736907959
      policy_entropy: 76.6646957397461
      policy_loss: -2.1780505180358887
      var_gnorm: 56.34337615966797
      vf_explained_var: 0.9686323404312134
      vf_loss: 0.06510087102651596
    num_steps_sampled: 4220000
    num_steps_trained: 4220000
    wait_time_ms: 224.561
  iterations_since_restore: 422
  node_ip: 172.17.8.6
  num_metric_batches_dropped: 0
  pid: 13557
  policy_reward_mean: {}
  time_since_restore: 10383.77337694168
  time_this_iter_s: 25.106282472610474
  time_total_s: 10383.77337694168
  timestamp: 1594105205
  timesteps_since_restore: 4220000
  timesteps_this_iter: 10000
  timesteps_total: 4220000
  training_iteration: 422
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=13557], 10383 s, 422 iter, 4220000 ts, 1.1e+03 rew

agent-1: 91.0
agent-2: 101.0
agent-3: 82.0
agent-4: 88.0
agent-5: 75.0
agent-6: 77.0
agent-7: 106.0
agent-8: 101.0
agent-9: 112.0
agent-10: 79.0
Sum Reward: 912.0
Avg Reward: 91.2
Min Reward: 75.0
Max Reward: 112.0
Gini Coefficient: 0.07741228070175439
20:20 Ratio: 1.4342105263157894
Max-min Ratio: 1.4933333333333334
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_03-00-29
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1861.0
  episode_reward_mean: 1088.93
  episode_reward_min: 821.0
  episodes_this_iter: 1
  episodes_total: 422
  experiment_id: a3942a9886f24694ab1b58ca8d1ab856
  hostname: gpu006
  info:
    apply_time_ms: 3.051
    dispatch_time_ms: 6.381
    learner:
      cur_lr: 0.0010789480293169618
      grad_gnorm: 40.000003814697266
      policy_entropy: 16.816442489624023
      policy_loss: 7.381360054016113
      var_gnorm: 56.38311767578125
      vf_explained_var: 0.9016708731651306
      vf_loss: 58.46900939941406
    num_steps_sampled: 4230000
    num_steps_trained: 4230000
    wait_time_ms: 250.367
  iterations_since_restore: 423
  node_ip: 172.17.8.6
  num_metric_batches_dropped: 0
  pid: 13557
  policy_reward_mean: {}
  time_since_restore: 10408.35459947586
  time_this_iter_s: 24.581222534179688
  time_total_s: 10408.35459947586
  timestamp: 1594105229
  timesteps_since_restore: 4230000
  timesteps_this_iter: 10000
  timesteps_total: 4230000
  training_iteration: 423
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=13557], 10408 s, 423 iter, 4230000 ts, 1.09e+03 rew

agent-1: 91.0
agent-2: 97.0
agent-3: 103.0
agent-4: 108.0
agent-5: 80.0
agent-6: 95.0
agent-7: 99.0
agent-8: 95.0
agent-9: 94.0
agent-10: 95.0
Sum Reward: 957.0
Avg Reward: 95.7
Min Reward: 80.0
Max Reward: 108.0
Gini Coefficient: 0.03834900731452456
20:20 Ratio: 1.2339181286549707
Max-min Ratio: 1.35
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_03-00-55
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1845.0
  episode_reward_mean: 1079.89
  episode_reward_min: 821.0
  episodes_this_iter: 1
  episodes_total: 423
  experiment_id: a3942a9886f24694ab1b58ca8d1ab856
  hostname: gpu006
  info:
    apply_time_ms: 2.634
    dispatch_time_ms: 7.606
    learner:
      cur_lr: 0.0010782820172607899
      grad_gnorm: 3.77043080329895
      policy_entropy: 84.30592346191406
      policy_loss: -0.9641844034194946
      var_gnorm: 56.40066146850586
      vf_explained_var: 0.994992733001709
      vf_loss: 0.016877377405762672
    num_steps_sampled: 4240000
    num_steps_trained: 4240000
    wait_time_ms: 229.993
  iterations_since_restore: 424
  node_ip: 172.17.8.6
  num_metric_batches_dropped: 0
  pid: 13557
  policy_reward_mean: {}
  time_since_restore: 10433.560713529587
  time_this_iter_s: 25.206114053726196
  time_total_s: 10433.560713529587
  timestamp: 1594105255
  timesteps_since_restore: 4240000
  timesteps_this_iter: 10000
  timesteps_total: 4240000
  training_iteration: 424
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=13557], 10433 s, 424 iter, 4240000 ts, 1.08e+03 rew

agent-1: 86.0
agent-2: 104.0
agent-3: 92.0
agent-4: 100.0
agent-5: 108.0
agent-6: 103.0
agent-7: 97.0
agent-8: 111.0
agent-9: 107.0
agent-10: 90.0
Sum Reward: 998.0
Avg Reward: 99.8
Min Reward: 86.0
Max Reward: 111.0
Gini Coefficient: 0.045090180360721446
20:20 Ratio: 1.2443181818181819
Max-min Ratio: 1.2906976744186047
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_03-01-19
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1608.0
  episode_reward_mean: 1071.42
  episode_reward_min: 821.0
  episodes_this_iter: 1
  episodes_total: 424
  experiment_id: a3942a9886f24694ab1b58ca8d1ab856
  hostname: gpu006
  info:
    apply_time_ms: 2.826
    dispatch_time_ms: 6.352
    learner:
      cur_lr: 0.001077616005204618
      grad_gnorm: 24.09415054321289
      policy_entropy: 42.35268020629883
      policy_loss: -1.0882995128631592
      var_gnorm: 56.46735763549805
      vf_explained_var: 0.9143738150596619
      vf_loss: 10.100238800048828
    num_steps_sampled: 4250000
    num_steps_trained: 4250000
    wait_time_ms: 251.954
  iterations_since_restore: 425
  node_ip: 172.17.8.6
  num_metric_batches_dropped: 0
  pid: 13557
  policy_reward_mean: {}
  time_since_restore: 10457.641208410263
  time_this_iter_s: 24.08049488067627
  time_total_s: 10457.641208410263
  timestamp: 1594105279
  timesteps_since_restore: 4250000
  timesteps_this_iter: 10000
  timesteps_total: 4250000
  training_iteration: 425
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=13557], 10457 s, 425 iter, 4250000 ts, 1.07e+03 rew

agent-1: 96.0
agent-2: 103.0
agent-3: 149.0
agent-4: 78.0
agent-5: 96.0
agent-6: 109.0
agent-7: 104.0
agent-8: 106.0
agent-9: 94.0
agent-10: 103.0
Sum Reward: 1038.0
Avg Reward: 103.8
Min Reward: 78.0
Max Reward: 149.0
Gini Coefficient: 0.0788053949903661
20:20 Ratio: 1.5
Max-min Ratio: 1.9102564102564104
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_03-01-44
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1608.0
  episode_reward_mean: 1067.4
  episode_reward_min: 821.0
  episodes_this_iter: 1
  episodes_total: 425
  experiment_id: a3942a9886f24694ab1b58ca8d1ab856
  hostname: gpu006
  info:
    apply_time_ms: 2.642
    dispatch_time_ms: 6.231
    learner:
      cur_lr: 0.001076949993148446
      grad_gnorm: 13.155022621154785
      policy_entropy: 93.2134780883789
      policy_loss: -2.7053940296173096
      var_gnorm: 56.47731018066406
      vf_explained_var: 0.8729792237281799
      vf_loss: 0.5035686492919922
    num_steps_sampled: 4260000
    num_steps_trained: 4260000
    wait_time_ms: 213.121
  iterations_since_restore: 426
  node_ip: 172.17.8.6
  num_metric_batches_dropped: 0
  pid: 13557
  policy_reward_mean: {}
  time_since_restore: 10482.720283031464
  time_this_iter_s: 25.07907462120056
  time_total_s: 10482.720283031464
  timestamp: 1594105304
  timesteps_since_restore: 4260000
  timesteps_this_iter: 10000
  timesteps_total: 4260000
  training_iteration: 426
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=13557], 10482 s, 426 iter, 4260000 ts, 1.07e+03 rew

agent-1: 112.0
agent-2: 99.0
agent-3: 119.0
agent-4: 90.0
agent-5: 102.0
agent-6: 115.0
agent-7: 93.0
agent-8: 108.0
agent-9: 102.0
agent-10: 99.0
Sum Reward: 1039.0
Avg Reward: 103.9
Min Reward: 90.0
Max Reward: 119.0
Gini Coefficient: 0.04879692011549567
20:20 Ratio: 1.278688524590164
Max-min Ratio: 1.3222222222222222
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_03-02-07
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1608.0
  episode_reward_mean: 1062.8
  episode_reward_min: 821.0
  episodes_this_iter: 1
  episodes_total: 426
  experiment_id: a3942a9886f24694ab1b58ca8d1ab856
  hostname: gpu006
  info:
    apply_time_ms: 3.162
    dispatch_time_ms: 5.886
    learner:
      cur_lr: 0.0010762839810922742
      grad_gnorm: 40.000003814697266
      policy_entropy: 39.200443267822266
      policy_loss: -37.769046783447266
      var_gnorm: 56.53024673461914
      vf_explained_var: 0.48738306760787964
      vf_loss: 206.39547729492188
    num_steps_sampled: 4270000
    num_steps_trained: 4270000
    wait_time_ms: 242.37
  iterations_since_restore: 427
  node_ip: 172.17.8.6
  num_metric_batches_dropped: 0
  pid: 13557
  policy_reward_mean: {}
  time_since_restore: 10506.395339488983
  time_this_iter_s: 23.67505645751953
  time_total_s: 10506.395339488983
  timestamp: 1594105327
  timesteps_since_restore: 4270000
  timesteps_this_iter: 10000
  timesteps_total: 4270000
  training_iteration: 427
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=13557], 10506 s, 427 iter, 4270000 ts, 1.06e+03 rew

agent-1: 106.0
agent-2: 96.0
agent-3: 118.0
agent-4: 131.0
agent-5: 98.0
agent-6: 137.0
agent-7: 122.0
agent-8: 101.0
agent-9: 101.0
agent-10: 108.0
Sum Reward: 1118.0
Avg Reward: 111.8
Min Reward: 96.0
Max Reward: 137.0
Gini Coefficient: 0.06779964221824687
20:20 Ratio: 1.3814432989690721
Max-min Ratio: 1.4270833333333333
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_03-02-33
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1608.0
  episode_reward_mean: 1063.72
  episode_reward_min: 821.0
  episodes_this_iter: 1
  episodes_total: 427
  experiment_id: a3942a9886f24694ab1b58ca8d1ab856
  hostname: gpu006
  info:
    apply_time_ms: 2.824
    dispatch_time_ms: 7.242
    learner:
      cur_lr: 0.0010756179690361023
      grad_gnorm: 40.0
      policy_entropy: 42.37875747680664
      policy_loss: -4.5010986328125
      var_gnorm: 56.60405349731445
      vf_explained_var: 0.6303682327270508
      vf_loss: 149.67835998535156
    num_steps_sampled: 4280000
    num_steps_trained: 4280000
    wait_time_ms: 212.15
  iterations_since_restore: 428
  node_ip: 172.17.8.6
  num_metric_batches_dropped: 0
  pid: 13557
  policy_reward_mean: {}
  time_since_restore: 10531.528267383575
  time_this_iter_s: 25.132927894592285
  time_total_s: 10531.528267383575
  timestamp: 1594105353
  timesteps_since_restore: 4280000
  timesteps_this_iter: 10000
  timesteps_total: 4280000
  training_iteration: 428
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=13557], 10531 s, 428 iter, 4280000 ts, 1.06e+03 rew

agent-1: 115.0
agent-2: 114.0
agent-3: 121.0
agent-4: 111.0
agent-5: 129.0
agent-6: 125.0
agent-7: 110.0
agent-8: 101.0
agent-9: 97.0
agent-10: 109.0
Sum Reward: 1132.0
Avg Reward: 113.2
Min Reward: 97.0
Max Reward: 129.0
Gini Coefficient: 0.04717314487632509
20:20 Ratio: 1.2828282828282829
Max-min Ratio: 1.3298969072164948
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_03-02-56
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1608.0
  episode_reward_mean: 1064.99
  episode_reward_min: 821.0
  episodes_this_iter: 1
  episodes_total: 428
  experiment_id: a3942a9886f24694ab1b58ca8d1ab856
  hostname: gpu006
  info:
    apply_time_ms: 3.252
    dispatch_time_ms: 9.232
    learner:
      cur_lr: 0.0010749519569799304
      grad_gnorm: 39.99999237060547
      policy_entropy: 23.541006088256836
      policy_loss: -19.510766983032227
      var_gnorm: 56.59526062011719
      vf_explained_var: -0.3408234119415283
      vf_loss: 250.36546325683594
    num_steps_sampled: 4290000
    num_steps_trained: 4290000
    wait_time_ms: 226.775
  iterations_since_restore: 429
  node_ip: 172.17.8.6
  num_metric_batches_dropped: 0
  pid: 13557
  policy_reward_mean: {}
  time_since_restore: 10554.771894216537
  time_this_iter_s: 23.243626832962036
  time_total_s: 10554.771894216537
  timestamp: 1594105376
  timesteps_since_restore: 4290000
  timesteps_this_iter: 10000
  timesteps_total: 4290000
  training_iteration: 429
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=13557], 10554 s, 429 iter, 4290000 ts, 1.06e+03 rew

agent-1: 131.0
agent-2: 138.0
agent-3: 127.0
agent-4: 154.0
agent-5: 124.0
agent-6: 135.0
agent-7: 122.0
agent-8: 122.0
agent-9: 129.0
agent-10: 116.0
Sum Reward: 1298.0
Avg Reward: 129.8
Min Reward: 116.0
Max Reward: 154.0
Gini Coefficient: 0.04175654853620955
20:20 Ratio: 1.226890756302521
Max-min Ratio: 1.3275862068965518
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_03-03-22
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1608.0
  episode_reward_mean: 1066.01
  episode_reward_min: 821.0
  episodes_this_iter: 1
  episodes_total: 429
  experiment_id: a3942a9886f24694ab1b58ca8d1ab856
  hostname: gpu006
  info:
    apply_time_ms: 2.661
    dispatch_time_ms: 38.842
    learner:
      cur_lr: 0.0010742859449237585
      grad_gnorm: 10.36058521270752
      policy_entropy: 68.90149688720703
      policy_loss: -0.6251355409622192
      var_gnorm: 56.7117805480957
      vf_explained_var: 0.950951099395752
      vf_loss: 0.2097911536693573
    num_steps_sampled: 4300000
    num_steps_trained: 4300000
    wait_time_ms: 201.07
  iterations_since_restore: 430
  node_ip: 172.17.8.6
  num_metric_batches_dropped: 0
  pid: 13557
  policy_reward_mean: {}
  time_since_restore: 10580.519501447678
  time_this_iter_s: 25.747607231140137
  time_total_s: 10580.519501447678
  timestamp: 1594105402
  timesteps_since_restore: 4300000
  timesteps_this_iter: 10000
  timesteps_total: 4300000
  training_iteration: 430
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=13557], 10580 s, 430 iter, 4300000 ts, 1.07e+03 rew

agent-1: 112.0
agent-2: 96.0
agent-3: 105.0
agent-4: 119.0
agent-5: 95.0
agent-6: 142.0
agent-7: 100.0
agent-8: 120.0
agent-9: 121.0
agent-10: 127.0
Sum Reward: 1137.0
Avg Reward: 113.7
Min Reward: 95.0
Max Reward: 142.0
Gini Coefficient: 0.07009674582233949
20:20 Ratio: 1.4083769633507854
Max-min Ratio: 1.4947368421052631
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_03-03-47
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1608.0
  episode_reward_mean: 1068.05
  episode_reward_min: 821.0
  episodes_this_iter: 1
  episodes_total: 430
  experiment_id: a3942a9886f24694ab1b58ca8d1ab856
  hostname: gpu006
  info:
    apply_time_ms: 2.81
    dispatch_time_ms: 35.417
    learner:
      cur_lr: 0.0010736200492829084
      grad_gnorm: 40.0
      policy_entropy: 34.223636627197266
      policy_loss: -14.306074142456055
      var_gnorm: 56.757423400878906
      vf_explained_var: 0.8180886507034302
      vf_loss: 60.798065185546875
    num_steps_sampled: 4310000
    num_steps_trained: 4310000
    wait_time_ms: 239.523
  iterations_since_restore: 431
  node_ip: 172.17.8.6
  num_metric_batches_dropped: 0
  pid: 13557
  policy_reward_mean: {}
  time_since_restore: 10605.74029970169
  time_this_iter_s: 25.22079825401306
  time_total_s: 10605.74029970169
  timestamp: 1594105427
  timesteps_since_restore: 4310000
  timesteps_this_iter: 10000
  timesteps_total: 4310000
  training_iteration: 431
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=13557], 10605 s, 431 iter, 4310000 ts, 1.07e+03 rew

agent-1: 100.0
agent-2: 94.0
agent-3: 101.0
agent-4: 95.0
agent-5: 91.0
agent-6: 101.0
agent-7: 91.0
agent-8: 87.0
agent-9: 91.0
agent-10: 100.0
Sum Reward: 951.0
Avg Reward: 95.1
Min Reward: 87.0
Max Reward: 101.0
Gini Coefficient: 0.02828601472134595
20:20 Ratio: 1.1348314606741574
Max-min Ratio: 1.160919540229885
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_03-04-13
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1608.0
  episode_reward_mean: 1063.9
  episode_reward_min: 821.0
  episodes_this_iter: 1
  episodes_total: 431
  experiment_id: a3942a9886f24694ab1b58ca8d1ab856
  hostname: gpu006
  info:
    apply_time_ms: 3.113
    dispatch_time_ms: 24.373
    learner:
      cur_lr: 0.0010729540372267365
      grad_gnorm: 4.185025691986084
      policy_entropy: 92.2508316040039
      policy_loss: 0.7164924740791321
      var_gnorm: 56.790042877197266
      vf_explained_var: 0.0
      vf_loss: 0.009485366754233837
    num_steps_sampled: 4320000
    num_steps_trained: 4320000
    wait_time_ms: 202.809
  iterations_since_restore: 432
  node_ip: 172.17.8.6
  num_metric_batches_dropped: 0
  pid: 13557
  policy_reward_mean: {}
  time_since_restore: 10632.00888299942
  time_this_iter_s: 26.268583297729492
  time_total_s: 10632.00888299942
  timestamp: 1594105453
  timesteps_since_restore: 4320000
  timesteps_this_iter: 10000
  timesteps_total: 4320000
  training_iteration: 432
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=13557], 10632 s, 432 iter, 4320000 ts, 1.06e+03 rew

agent-1: 106.0
agent-2: 106.0
agent-3: 75.0
agent-4: 87.0
agent-5: 92.0
agent-6: 86.0
agent-7: 101.0
agent-8: 91.0
agent-9: 99.0
agent-10: 111.0
Sum Reward: 954.0
Avg Reward: 95.4
Min Reward: 75.0
Max Reward: 111.0
Gini Coefficient: 0.06247379454926625
20:20 Ratio: 1.3478260869565217
Max-min Ratio: 1.48
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_03-04-38
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1608.0
  episode_reward_mean: 1063.76
  episode_reward_min: 821.0
  episodes_this_iter: 1
  episodes_total: 432
  experiment_id: a3942a9886f24694ab1b58ca8d1ab856
  hostname: gpu006
  info:
    apply_time_ms: 2.71
    dispatch_time_ms: 31.168
    learner:
      cur_lr: 0.0010722880251705647
      grad_gnorm: 40.0
      policy_entropy: 40.30156707763672
      policy_loss: -0.5169948935508728
      var_gnorm: 56.87637710571289
      vf_explained_var: 0.7271920442581177
      vf_loss: 88.77627563476562
    num_steps_sampled: 4330000
    num_steps_trained: 4330000
    wait_time_ms: 225.587
  iterations_since_restore: 433
  node_ip: 172.17.8.6
  num_metric_batches_dropped: 0
  pid: 13557
  policy_reward_mean: {}
  time_since_restore: 10657.099761247635
  time_this_iter_s: 25.09087824821472
  time_total_s: 10657.099761247635
  timestamp: 1594105478
  timesteps_since_restore: 4330000
  timesteps_this_iter: 10000
  timesteps_total: 4330000
  training_iteration: 433
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=13557], 10657 s, 433 iter, 4330000 ts, 1.06e+03 rew

agent-1: 115.0
agent-2: 102.0
agent-3: 139.0
agent-4: 81.0
agent-5: 90.0
agent-6: 109.0
agent-7: 115.0
agent-8: 103.0
agent-9: 116.0
agent-10: 108.0
Sum Reward: 1078.0
Avg Reward: 107.8
Min Reward: 81.0
Max Reward: 139.0
Gini Coefficient: 0.07476808905380333
20:20 Ratio: 1.4912280701754386
Max-min Ratio: 1.7160493827160495
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_03-05-10
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1608.0
  episode_reward_mean: 1063.27
  episode_reward_min: 821.0
  episodes_this_iter: 1
  episodes_total: 433
  experiment_id: a3942a9886f24694ab1b58ca8d1ab856
  hostname: gpu006
  info:
    apply_time_ms: 3.297
    dispatch_time_ms: 16.138
    learner:
      cur_lr: 0.0010716220131143928
      grad_gnorm: 40.0
      policy_entropy: 25.19062614440918
      policy_loss: 10.619996070861816
      var_gnorm: 56.842933654785156
      vf_explained_var: -0.35815584659576416
      vf_loss: 114.84584045410156
    num_steps_sampled: 4340000
    num_steps_trained: 4340000
    wait_time_ms: 168.415
  iterations_since_restore: 434
  node_ip: 172.17.8.6
  num_metric_batches_dropped: 0
  pid: 13557
  policy_reward_mean: {}
  time_since_restore: 10688.318358898163
  time_this_iter_s: 31.218597650527954
  time_total_s: 10688.318358898163
  timestamp: 1594105510
  timesteps_since_restore: 4340000
  timesteps_this_iter: 10000
  timesteps_total: 4340000
  training_iteration: 434
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=13557], 10688 s, 434 iter, 4340000 ts, 1.06e+03 rew

agent-1: 81.0
agent-2: 81.0
agent-3: 84.0
agent-4: 73.0
agent-5: 90.0
agent-6: 81.0
agent-7: 78.0
agent-8: 79.0
agent-9: 93.0
agent-10: 98.0
Sum Reward: 838.0
Avg Reward: 83.8
Min Reward: 73.0
Max Reward: 98.0
Gini Coefficient: 0.047016706443914084
20:20 Ratio: 1.2649006622516556
Max-min Ratio: 1.3424657534246576
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_03-05-34
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1608.0
  episode_reward_mean: 1061.28
  episode_reward_min: 821.0
  episodes_this_iter: 1
  episodes_total: 434
  experiment_id: a3942a9886f24694ab1b58ca8d1ab856
  hostname: gpu006
  info:
    apply_time_ms: 2.737
    dispatch_time_ms: 9.136
    learner:
      cur_lr: 0.0010709560010582209
      grad_gnorm: 39.999996185302734
      policy_entropy: 41.831268310546875
      policy_loss: -10.58773422241211
      var_gnorm: 56.898765563964844
      vf_explained_var: 0.8298497200012207
      vf_loss: 108.54644012451172
    num_steps_sampled: 4350000
    num_steps_trained: 4350000
    wait_time_ms: 214.4
  iterations_since_restore: 435
  node_ip: 172.17.8.6
  num_metric_batches_dropped: 0
  pid: 13557
  policy_reward_mean: {}
  time_since_restore: 10712.357147932053
  time_this_iter_s: 24.03878903388977
  time_total_s: 10712.357147932053
  timestamp: 1594105534
  timesteps_since_restore: 4350000
  timesteps_this_iter: 10000
  timesteps_total: 4350000
  training_iteration: 435
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=13557], 10712 s, 435 iter, 4350000 ts, 1.06e+03 rew

agent-1: 115.0
agent-2: 111.0
agent-3: 135.0
agent-4: 99.0
agent-5: 104.0
agent-6: 100.0
agent-7: 125.0
agent-8: 125.0
agent-9: 110.0
agent-10: 98.0
Sum Reward: 1122.0
Avg Reward: 112.2
Min Reward: 98.0
Max Reward: 135.0
Gini Coefficient: 0.06007130124777184
20:20 Ratio: 1.3197969543147208
Max-min Ratio: 1.3775510204081634
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_03-05-59
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1608.0
  episode_reward_mean: 1064.29
  episode_reward_min: 831.0
  episodes_this_iter: 1
  episodes_total: 435
  experiment_id: a3942a9886f24694ab1b58ca8d1ab856
  hostname: gpu006
  info:
    apply_time_ms: 2.611
    dispatch_time_ms: 5.862
    learner:
      cur_lr: 0.001070289989002049
      grad_gnorm: 39.999996185302734
      policy_entropy: 42.58771896362305
      policy_loss: 30.2159366607666
      var_gnorm: 56.917205810546875
      vf_explained_var: -0.28615689277648926
      vf_loss: 136.48680114746094
    num_steps_sampled: 4360000
    num_steps_trained: 4360000
    wait_time_ms: 225.096
  iterations_since_restore: 436
  node_ip: 172.17.8.6
  num_metric_batches_dropped: 0
  pid: 13557
  policy_reward_mean: {}
  time_since_restore: 10737.41105556488
  time_this_iter_s: 25.05390763282776
  time_total_s: 10737.41105556488
  timestamp: 1594105559
  timesteps_since_restore: 4360000
  timesteps_this_iter: 10000
  timesteps_total: 4360000
  training_iteration: 436
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=13557], 10737 s, 436 iter, 4360000 ts, 1.06e+03 rew

agent-1: 166.0
agent-2: 135.0
agent-3: 133.0
agent-4: 136.0
agent-5: 155.0
agent-6: 125.0
agent-7: 140.0
agent-8: 135.0
agent-9: 154.0
agent-10: 136.0
Sum Reward: 1415.0
Avg Reward: 141.5
Min Reward: 125.0
Max Reward: 166.0
Gini Coefficient: 0.044734982332155476
20:20 Ratio: 1.244186046511628
Max-min Ratio: 1.328
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_03-06-22
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1608.0
  episode_reward_mean: 1068.63
  episode_reward_min: 831.0
  episodes_this_iter: 1
  episodes_total: 436
  experiment_id: a3942a9886f24694ab1b58ca8d1ab856
  hostname: gpu006
  info:
    apply_time_ms: 2.769
    dispatch_time_ms: 18.021
    learner:
      cur_lr: 0.001069623976945877
      grad_gnorm: 40.00001525878906
      policy_entropy: 76.69229125976562
      policy_loss: -78.9612045288086
      var_gnorm: 57.063804626464844
      vf_explained_var: 0.6689937114715576
      vf_loss: 219.98837280273438
    num_steps_sampled: 4370000
    num_steps_trained: 4370000
    wait_time_ms: 210.606
  iterations_since_restore: 437
  node_ip: 172.17.8.6
  num_metric_batches_dropped: 0
  pid: 13557
  policy_reward_mean: {}
  time_since_restore: 10759.997647762299
  time_this_iter_s: 22.586592197418213
  time_total_s: 10759.997647762299
  timestamp: 1594105582
  timesteps_since_restore: 4370000
  timesteps_this_iter: 10000
  timesteps_total: 4370000
  training_iteration: 437
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=13557], 10759 s, 437 iter, 4370000 ts, 1.07e+03 rew

agent-1: 161.0
agent-2: 137.0
agent-3: 140.0
agent-4: 141.0
agent-5: 172.0
agent-6: 148.0
agent-7: 142.0
agent-8: 167.0
agent-9: 181.0
agent-10: 142.0
Sum Reward: 1531.0
Avg Reward: 153.1
Min Reward: 137.0
Max Reward: 181.0
Gini Coefficient: 0.05310254735467015
20:20 Ratio: 1.2743682310469313
Max-min Ratio: 1.3211678832116789
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_03-06-47
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1608.0
  episode_reward_mean: 1075.34
  episode_reward_min: 831.0
  episodes_this_iter: 1
  episodes_total: 437
  experiment_id: a3942a9886f24694ab1b58ca8d1ab856
  hostname: gpu006
  info:
    apply_time_ms: 2.716
    dispatch_time_ms: 33.322
    learner:
      cur_lr: 0.0010689579648897052
      grad_gnorm: 40.0
      policy_entropy: 65.47589111328125
      policy_loss: 19.27185821533203
      var_gnorm: 57.124385833740234
      vf_explained_var: 0.8833407759666443
      vf_loss: 17.368417739868164
    num_steps_sampled: 4380000
    num_steps_trained: 4380000
    wait_time_ms: 190.504
  iterations_since_restore: 438
  node_ip: 172.17.8.6
  num_metric_batches_dropped: 0
  pid: 13557
  policy_reward_mean: {}
  time_since_restore: 10785.125531673431
  time_this_iter_s: 25.127883911132812
  time_total_s: 10785.125531673431
  timestamp: 1594105607
  timesteps_since_restore: 4380000
  timesteps_this_iter: 10000
  timesteps_total: 4380000
  training_iteration: 438
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=13557], 10785 s, 438 iter, 4380000 ts, 1.08e+03 rew

agent-1: 133.0
agent-2: 147.0
agent-3: 153.0
agent-4: 154.0
agent-5: 163.0
agent-6: 129.0
agent-7: 123.0
agent-8: 134.0
agent-9: 128.0
agent-10: 143.0
Sum Reward: 1407.0
Avg Reward: 140.7
Min Reward: 123.0
Max Reward: 163.0
Gini Coefficient: 0.05067519545131485
20:20 Ratio: 1.2629482071713147
Max-min Ratio: 1.3252032520325203
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_03-07-10
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1608.0
  episode_reward_mean: 1080.19
  episode_reward_min: 831.0
  episodes_this_iter: 1
  episodes_total: 438
  experiment_id: a3942a9886f24694ab1b58ca8d1ab856
  hostname: gpu006
  info:
    apply_time_ms: 3.351
    dispatch_time_ms: 31.764
    learner:
      cur_lr: 0.0010682919528335333
      grad_gnorm: 40.0
      policy_entropy: 56.31521987915039
      policy_loss: 10.617956161499023
      var_gnorm: 57.1094970703125
      vf_explained_var: 0.8953861594200134
      vf_loss: 83.48015594482422
    num_steps_sampled: 4390000
    num_steps_trained: 4390000
    wait_time_ms: 216.879
  iterations_since_restore: 439
  node_ip: 172.17.8.6
  num_metric_batches_dropped: 0
  pid: 13557
  policy_reward_mean: {}
  time_since_restore: 10808.544559001923
  time_this_iter_s: 23.41902732849121
  time_total_s: 10808.544559001923
  timestamp: 1594105630
  timesteps_since_restore: 4390000
  timesteps_this_iter: 10000
  timesteps_total: 4390000
  training_iteration: 439
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=13557], 10808 s, 439 iter, 4390000 ts, 1.08e+03 rew

agent-1: 122.0
agent-2: 137.0
agent-3: 140.0
agent-4: 141.0
agent-5: 110.0
agent-6: 120.0
agent-7: 134.0
agent-8: 129.0
agent-9: 159.0
agent-10: 112.0
Sum Reward: 1304.0
Avg Reward: 130.4
Min Reward: 110.0
Max Reward: 159.0
Gini Coefficient: 0.06088957055214724
20:20 Ratio: 1.3513513513513513
Max-min Ratio: 1.4454545454545455
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_03-07-36
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1608.0
  episode_reward_mean: 1082.79
  episode_reward_min: 831.0
  episodes_this_iter: 1
  episodes_total: 439
  experiment_id: a3942a9886f24694ab1b58ca8d1ab856
  hostname: gpu006
  info:
    apply_time_ms: 2.723
    dispatch_time_ms: 29.596
    learner:
      cur_lr: 0.0010676260571926832
      grad_gnorm: 39.99999237060547
      policy_entropy: 75.54337310791016
      policy_loss: -3.1545073986053467
      var_gnorm: 57.1299934387207
      vf_explained_var: 0.8230468034744263
      vf_loss: 83.77945709228516
    num_steps_sampled: 4400000
    num_steps_trained: 4400000
    wait_time_ms: 218.094
  iterations_since_restore: 440
  node_ip: 172.17.8.6
  num_metric_batches_dropped: 0
  pid: 13557
  policy_reward_mean: {}
  time_since_restore: 10834.62826538086
  time_this_iter_s: 26.083706378936768
  time_total_s: 10834.62826538086
  timestamp: 1594105656
  timesteps_since_restore: 4400000
  timesteps_this_iter: 10000
  timesteps_total: 4400000
  training_iteration: 440
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=13557], 10834 s, 440 iter, 4400000 ts, 1.08e+03 rew

agent-1: 113.0
agent-2: 136.0
agent-3: 130.0
agent-4: 153.0
agent-5: 100.0
agent-6: 72.0
agent-7: 120.0
agent-8: 108.0
agent-9: 147.0
agent-10: 152.0
Sum Reward: 1231.0
Avg Reward: 123.1
Min Reward: 72.0
Max Reward: 153.0
Gini Coefficient: 0.11104792851340374
20:20 Ratio: 1.7732558139534884
Max-min Ratio: 2.125
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_03-07-58
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1608.0
  episode_reward_mean: 1084.4
  episode_reward_min: 831.0
  episodes_this_iter: 1
  episodes_total: 440
  experiment_id: a3942a9886f24694ab1b58ca8d1ab856
  hostname: gpu006
  info:
    apply_time_ms: 2.795
    dispatch_time_ms: 26.522
    learner:
      cur_lr: 0.0010669600451365113
      grad_gnorm: 40.00000762939453
      policy_entropy: 57.083316802978516
      policy_loss: 11.209914207458496
      var_gnorm: 56.9583854675293
      vf_explained_var: 0.18820136785507202
      vf_loss: 84.42117309570312
    num_steps_sampled: 4410000
    num_steps_trained: 4410000
    wait_time_ms: 209.402
  iterations_since_restore: 441
  node_ip: 172.17.8.6
  num_metric_batches_dropped: 0
  pid: 13557
  policy_reward_mean: {}
  time_since_restore: 10856.745853185654
  time_this_iter_s: 22.11758780479431
  time_total_s: 10856.745853185654
  timestamp: 1594105678
  timesteps_since_restore: 4410000
  timesteps_this_iter: 10000
  timesteps_total: 4410000
  training_iteration: 441
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=13557], 10856 s, 441 iter, 4410000 ts, 1.08e+03 rew

agent-1: 166.0
agent-2: 166.0
agent-3: 119.0
agent-4: 143.0
agent-5: 135.0
agent-6: 150.0
agent-7: 176.0
agent-8: 129.0
agent-9: 142.0
agent-10: 143.0
Sum Reward: 1469.0
Avg Reward: 146.9
Min Reward: 119.0
Max Reward: 176.0
Gini Coefficient: 0.06473791695030633
20:20 Ratio: 1.3790322580645162
Max-min Ratio: 1.4789915966386555
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_03-08-23
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1608.0
  episode_reward_mean: 1087.77
  episode_reward_min: 831.0
  episodes_this_iter: 1
  episodes_total: 441
  experiment_id: a3942a9886f24694ab1b58ca8d1ab856
  hostname: gpu006
  info:
    apply_time_ms: 2.647
    dispatch_time_ms: 8.014
    learner:
      cur_lr: 0.0010662940330803394
      grad_gnorm: 21.163997650146484
      policy_entropy: 89.09397888183594
      policy_loss: -5.476348400115967
      var_gnorm: 57.06376266479492
      vf_explained_var: 0.0
      vf_loss: 0.26959675550460815
    num_steps_sampled: 4420000
    num_steps_trained: 4420000
    wait_time_ms: 204.964
  iterations_since_restore: 442
  node_ip: 172.17.8.6
  num_metric_batches_dropped: 0
  pid: 13557
  policy_reward_mean: {}
  time_since_restore: 10881.693305253983
  time_this_iter_s: 24.947452068328857
  time_total_s: 10881.693305253983
  timestamp: 1594105703
  timesteps_since_restore: 4420000
  timesteps_this_iter: 10000
  timesteps_total: 4420000
  training_iteration: 442
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=13557], 10881 s, 442 iter, 4420000 ts, 1.09e+03 rew

agent-1: 149.0
agent-2: 135.0
agent-3: 139.0
agent-4: 147.0
agent-5: 144.0
agent-6: 151.0
agent-7: 120.0
agent-8: 131.0
agent-9: 171.0
agent-10: 160.0
Sum Reward: 1447.0
Avg Reward: 144.7
Min Reward: 120.0
Max Reward: 171.0
Gini Coefficient: 0.05355908776779544
20:20 Ratio: 1.3187250996015936
Max-min Ratio: 1.425
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_03-08-46
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1608.0
  episode_reward_mean: 1090.01
  episode_reward_min: 831.0
  episodes_this_iter: 1
  episodes_total: 442
  experiment_id: a3942a9886f24694ab1b58ca8d1ab856
  hostname: gpu006
  info:
    apply_time_ms: 2.788
    dispatch_time_ms: 6.358
    learner:
      cur_lr: 0.0010656280210241675
      grad_gnorm: 40.0
      policy_entropy: 98.30980682373047
      policy_loss: 24.489696502685547
      var_gnorm: 57.164344787597656
      vf_explained_var: 0.35983604192733765
      vf_loss: 99.71847534179688
    num_steps_sampled: 4430000
    num_steps_trained: 4430000
    wait_time_ms: 213.93
  iterations_since_restore: 443
  node_ip: 172.17.8.6
  num_metric_batches_dropped: 0
  pid: 13557
  policy_reward_mean: {}
  time_since_restore: 10903.683547973633
  time_this_iter_s: 21.99024271965027
  time_total_s: 10903.683547973633
  timestamp: 1594105726
  timesteps_since_restore: 4430000
  timesteps_this_iter: 10000
  timesteps_total: 4430000
  training_iteration: 443
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=13557], 10903 s, 443 iter, 4430000 ts, 1.09e+03 rew

agent-1: 157.0
agent-2: 164.0
agent-3: 190.0
agent-4: 172.0
agent-5: 211.0
agent-6: 156.0
agent-7: 166.0
agent-8: 192.0
agent-9: 203.0
agent-10: 153.0
Sum Reward: 1764.0
Avg Reward: 176.4
Min Reward: 153.0
Max Reward: 211.0
Gini Coefficient: 0.06292517006802721
20:20 Ratio: 1.3398058252427185
Max-min Ratio: 1.3790849673202614
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_03-09-09
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1764.0
  episode_reward_mean: 1091.57
  episode_reward_min: 831.0
  episodes_this_iter: 1
  episodes_total: 443
  experiment_id: a3942a9886f24694ab1b58ca8d1ab856
  hostname: gpu006
  info:
    apply_time_ms: 2.559
    dispatch_time_ms: 7.002
    learner:
      cur_lr: 0.0010649620089679956
      grad_gnorm: 39.999996185302734
      policy_entropy: 52.1176872253418
      policy_loss: 0.5340492725372314
      var_gnorm: 57.170501708984375
      vf_explained_var: 0.0252377986907959
      vf_loss: 25.147743225097656
    num_steps_sampled: 4440000
    num_steps_trained: 4440000
    wait_time_ms: 234.997
  iterations_since_restore: 444
  node_ip: 172.17.8.6
  num_metric_batches_dropped: 0
  pid: 13557
  policy_reward_mean: {}
  time_since_restore: 10926.976141691208
  time_this_iter_s: 23.292593717575073
  time_total_s: 10926.976141691208
  timestamp: 1594105749
  timesteps_since_restore: 4440000
  timesteps_this_iter: 10000
  timesteps_total: 4440000
  training_iteration: 444
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=13557], 10926 s, 444 iter, 4440000 ts, 1.09e+03 rew

agent-1: 138.0
agent-2: 143.0
agent-3: 136.0
agent-4: 94.0
agent-5: 117.0
agent-6: 130.0
agent-7: 153.0
agent-8: 130.0
agent-9: 172.0
agent-10: 141.0
Sum Reward: 1354.0
Avg Reward: 135.4
Min Reward: 94.0
Max Reward: 172.0
Gini Coefficient: 0.07784342688330871
20:20 Ratio: 1.5402843601895735
Max-min Ratio: 1.8297872340425532
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_03-09-32
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1764.0
  episode_reward_mean: 1092.83
  episode_reward_min: 831.0
  episodes_this_iter: 1
  episodes_total: 444
  experiment_id: a3942a9886f24694ab1b58ca8d1ab856
  hostname: gpu006
  info:
    apply_time_ms: 2.792
    dispatch_time_ms: 6.261
    learner:
      cur_lr: 0.0010642959969118237
      grad_gnorm: 16.472787857055664
      policy_entropy: 70.86083984375
      policy_loss: 5.636188983917236
      var_gnorm: 57.21010971069336
      vf_explained_var: 0.6702215671539307
      vf_loss: 6.6169915199279785
    num_steps_sampled: 4450000
    num_steps_trained: 4450000
    wait_time_ms: 257.363
  iterations_since_restore: 445
  node_ip: 172.17.8.6
  num_metric_batches_dropped: 0
  pid: 13557
  policy_reward_mean: {}
  time_since_restore: 10950.198303461075
  time_this_iter_s: 23.222161769866943
  time_total_s: 10950.198303461075
  timestamp: 1594105772
  timesteps_since_restore: 4450000
  timesteps_this_iter: 10000
  timesteps_total: 4450000
  training_iteration: 445
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=13557], 10950 s, 445 iter, 4450000 ts, 1.09e+03 rew

agent-1: 107.0
agent-2: 123.0
agent-3: 93.0
agent-4: 99.0
agent-5: 121.0
agent-6: 122.0
agent-7: 128.0
agent-8: 108.0
agent-9: 116.0
agent-10: 106.0
Sum Reward: 1123.0
Avg Reward: 112.3
Min Reward: 93.0
Max Reward: 128.0
Gini Coefficient: 0.05458593054318789
20:20 Ratio: 1.3072916666666667
Max-min Ratio: 1.3763440860215055
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_03-09-57
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1764.0
  episode_reward_mean: 1090.51
  episode_reward_min: 831.0
  episodes_this_iter: 1
  episodes_total: 445
  experiment_id: a3942a9886f24694ab1b58ca8d1ab856
  hostname: gpu006
  info:
    apply_time_ms: 4.4
    dispatch_time_ms: 7.368
    learner:
      cur_lr: 0.0010636299848556519
      grad_gnorm: 8.860454559326172
      policy_entropy: 108.72341918945312
      policy_loss: -2.7233469486236572
      var_gnorm: 57.22871780395508
      vf_explained_var: -1.0
      vf_loss: 0.527746319770813
    num_steps_sampled: 4460000
    num_steps_trained: 4460000
    wait_time_ms: 211.181
  iterations_since_restore: 446
  node_ip: 172.17.8.6
  num_metric_batches_dropped: 0
  pid: 13557
  policy_reward_mean: {}
  time_since_restore: 10975.403910160065
  time_this_iter_s: 25.205606698989868
  time_total_s: 10975.403910160065
  timestamp: 1594105797
  timesteps_since_restore: 4460000
  timesteps_this_iter: 10000
  timesteps_total: 4460000
  training_iteration: 446
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=13557], 10975 s, 446 iter, 4460000 ts, 1.09e+03 rew

agent-1: 111.0
agent-2: 91.0
agent-3: 102.0
agent-4: 93.0
agent-5: 105.0
agent-6: 117.0
agent-7: 89.0
agent-8: 90.0
agent-9: 99.0
agent-10: 129.0
Sum Reward: 1026.0
Avg Reward: 102.6
Min Reward: 89.0
Max Reward: 129.0
Gini Coefficient: 0.06705653021442495
20:20 Ratio: 1.3743016759776536
Max-min Ratio: 1.449438202247191
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_03-10-22
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1764.0
  episode_reward_mean: 1088.77
  episode_reward_min: 831.0
  episodes_this_iter: 1
  episodes_total: 446
  experiment_id: a3942a9886f24694ab1b58ca8d1ab856
  hostname: gpu006
  info:
    apply_time_ms: 2.709
    dispatch_time_ms: 14.199
    learner:
      cur_lr: 0.00106296397279948
      grad_gnorm: 40.00001525878906
      policy_entropy: 35.43130874633789
      policy_loss: -5.773759841918945
      var_gnorm: 57.27558135986328
      vf_explained_var: 0.29770100116729736
      vf_loss: 178.5857696533203
    num_steps_sampled: 4470000
    num_steps_trained: 4470000
    wait_time_ms: 248.573
  iterations_since_restore: 447
  node_ip: 172.17.8.6
  num_metric_batches_dropped: 0
  pid: 13557
  policy_reward_mean: {}
  time_since_restore: 10999.633453845978
  time_this_iter_s: 24.229543685913086
  time_total_s: 10999.633453845978
  timestamp: 1594105822
  timesteps_since_restore: 4470000
  timesteps_this_iter: 10000
  timesteps_total: 4470000
  training_iteration: 447
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=13557], 10999 s, 447 iter, 4470000 ts, 1.09e+03 rew

agent-1: 97.0
agent-2: 148.0
agent-3: 114.0
agent-4: 121.0
agent-5: 135.0
agent-6: 141.0
agent-7: 118.0
agent-8: 110.0
agent-9: 148.0
agent-10: 125.0
Sum Reward: 1257.0
Avg Reward: 125.7
Min Reward: 97.0
Max Reward: 148.0
Gini Coefficient: 0.07279236276849642
20:20 Ratio: 1.429951690821256
Max-min Ratio: 1.5257731958762886
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_03-10-48
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1764.0
  episode_reward_mean: 1088.73
  episode_reward_min: 831.0
  episodes_this_iter: 1
  episodes_total: 447
  experiment_id: a3942a9886f24694ab1b58ca8d1ab856
  hostname: gpu006
  info:
    apply_time_ms: 4.672
    dispatch_time_ms: 39.94
    learner:
      cur_lr: 0.001062297960743308
      grad_gnorm: 1.1978986263275146
      policy_entropy: 108.8644790649414
      policy_loss: 1.2968486547470093
      var_gnorm: 57.29839324951172
      vf_explained_var: 0.9882416725158691
      vf_loss: 0.0007462340872734785
    num_steps_sampled: 4480000
    num_steps_trained: 4480000
    wait_time_ms: 194.952
  iterations_since_restore: 448
  node_ip: 172.17.8.6
  num_metric_batches_dropped: 0
  pid: 13557
  policy_reward_mean: {}
  time_since_restore: 11026.023945093155
  time_this_iter_s: 26.390491247177124
  time_total_s: 11026.023945093155
  timestamp: 1594105848
  timesteps_since_restore: 4480000
  timesteps_this_iter: 10000
  timesteps_total: 4480000
  training_iteration: 448
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=13557], 11026 s, 448 iter, 4480000 ts, 1.09e+03 rew

agent-1: 95.0
agent-2: 99.0
agent-3: 102.0
agent-4: 93.0
agent-5: 115.0
agent-6: 104.0
agent-7: 115.0
agent-8: 90.0
agent-9: 106.0
agent-10: 99.0
Sum Reward: 1018.0
Avg Reward: 101.8
Min Reward: 90.0
Max Reward: 115.0
Gini Coefficient: 0.044400785854616896
20:20 Ratio: 1.2568306010928962
Max-min Ratio: 1.2777777777777777
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_03-11-13
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1764.0
  episode_reward_mean: 1086.88
  episode_reward_min: 831.0
  episodes_this_iter: 1
  episodes_total: 448
  experiment_id: a3942a9886f24694ab1b58ca8d1ab856
  hostname: gpu006
  info:
    apply_time_ms: 3.8
    dispatch_time_ms: 19.77
    learner:
      cur_lr: 0.0010616319486871362
      grad_gnorm: 16.581634521484375
      policy_entropy: 72.74714660644531
      policy_loss: 4.415555000305176
      var_gnorm: 57.242576599121094
      vf_explained_var: 0.6687275171279907
      vf_loss: 25.10670280456543
    num_steps_sampled: 4490000
    num_steps_trained: 4490000
    wait_time_ms: 244.701
  iterations_since_restore: 449
  node_ip: 172.17.8.6
  num_metric_batches_dropped: 0
  pid: 13557
  policy_reward_mean: {}
  time_since_restore: 11049.84288907051
  time_this_iter_s: 23.818943977355957
  time_total_s: 11049.84288907051
  timestamp: 1594105873
  timesteps_since_restore: 4490000
  timesteps_this_iter: 10000
  timesteps_total: 4490000
  training_iteration: 449
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=13557], 11049 s, 449 iter, 4490000 ts, 1.09e+03 rew

agent-1: 94.0
agent-2: 137.0
agent-3: 118.0
agent-4: 106.0
agent-5: 92.0
agent-6: 94.0
agent-7: 94.0
agent-8: 97.0
agent-9: 149.0
agent-10: 103.0
Sum Reward: 1084.0
Avg Reward: 108.4
Min Reward: 92.0
Max Reward: 149.0
Gini Coefficient: 0.09003690036900369
20:20 Ratio: 1.5376344086021505
Max-min Ratio: 1.6195652173913044
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_03-11-39
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1764.0
  episode_reward_mean: 1086.42
  episode_reward_min: 831.0
  episodes_this_iter: 1
  episodes_total: 449
  experiment_id: a3942a9886f24694ab1b58ca8d1ab856
  hostname: gpu006
  info:
    apply_time_ms: 3.532
    dispatch_time_ms: 24.064
    learner:
      cur_lr: 0.001060966053046286
      grad_gnorm: 40.0
      policy_entropy: 61.3148307800293
      policy_loss: -47.793182373046875
      var_gnorm: 57.295536041259766
      vf_explained_var: -0.17803382873535156
      vf_loss: 165.15638732910156
    num_steps_sampled: 4500000
    num_steps_trained: 4500000
    wait_time_ms: 212.202
  iterations_since_restore: 450
  node_ip: 172.17.8.6
  num_metric_batches_dropped: 0
  pid: 13557
  policy_reward_mean: {}
  time_since_restore: 11076.0197660923
  time_this_iter_s: 26.17687702178955
  time_total_s: 11076.0197660923
  timestamp: 1594105899
  timesteps_since_restore: 4500000
  timesteps_this_iter: 10000
  timesteps_total: 4500000
  training_iteration: 450
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=13557], 11076 s, 450 iter, 4500000 ts, 1.09e+03 rew

agent-1: 109.0
agent-2: 108.0
agent-3: 106.0
agent-4: 154.0
agent-5: 113.0
agent-6: 133.0
agent-7: 184.0
agent-8: 113.0
agent-9: 116.0
agent-10: 107.0
Sum Reward: 1243.0
Avg Reward: 124.3
Min Reward: 106.0
Max Reward: 184.0
Gini Coefficient: 0.09469026548672567
20:20 Ratio: 1.5868544600938967
Max-min Ratio: 1.7358490566037736
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_03-12-02
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1764.0
  episode_reward_mean: 1088.2
  episode_reward_min: 831.0
  episodes_this_iter: 1
  episodes_total: 450
  experiment_id: a3942a9886f24694ab1b58ca8d1ab856
  hostname: gpu006
  info:
    apply_time_ms: 3.257
    dispatch_time_ms: 39.475
    learner:
      cur_lr: 0.0010603000409901142
      grad_gnorm: 39.999996185302734
      policy_entropy: 40.97418212890625
      policy_loss: -10.135889053344727
      var_gnorm: 57.371421813964844
      vf_explained_var: 0.7619876861572266
      vf_loss: 110.24812316894531
    num_steps_sampled: 4510000
    num_steps_trained: 4510000
    wait_time_ms: 216.539
  iterations_since_restore: 451
  node_ip: 172.17.8.6
  num_metric_batches_dropped: 0
  pid: 13557
  policy_reward_mean: {}
  time_since_restore: 11099.524125814438
  time_this_iter_s: 23.50435972213745
  time_total_s: 11099.524125814438
  timestamp: 1594105922
  timesteps_since_restore: 4510000
  timesteps_this_iter: 10000
  timesteps_total: 4510000
  training_iteration: 451
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=13557], 11099 s, 451 iter, 4510000 ts, 1.09e+03 rew

W0707 03:12:22.826598 13553 node_manager.cc:250] Last heartbeat was sent 573 ms ago 
agent-1: 147.0
agent-2: 151.0
agent-3: 125.0
agent-4: 141.0
agent-5: 145.0
agent-6: 138.0
agent-7: 163.0
agent-8: 148.0
agent-9: 170.0
agent-10: 160.0
Sum Reward: 1488.0
Avg Reward: 148.8
Min Reward: 125.0
Max Reward: 170.0
Gini Coefficient: 0.04663978494623656
20:20 Ratio: 1.2661596958174905
Max-min Ratio: 1.36
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_03-12-29
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1764.0
  episode_reward_mean: 1091.31
  episode_reward_min: 831.0
  episodes_this_iter: 1
  episodes_total: 451
  experiment_id: a3942a9886f24694ab1b58ca8d1ab856
  hostname: gpu006
  info:
    apply_time_ms: 2.781
    dispatch_time_ms: 6.697
    learner:
      cur_lr: 0.0010596340289339423
      grad_gnorm: 39.999996185302734
      policy_entropy: 68.87882995605469
      policy_loss: 2.927708148956299
      var_gnorm: 57.483001708984375
      vf_explained_var: 0.1447785496711731
      vf_loss: 114.2541275024414
    num_steps_sampled: 4520000
    num_steps_trained: 4520000
    wait_time_ms: 210.286
  iterations_since_restore: 452
  node_ip: 172.17.8.6
  num_metric_batches_dropped: 0
  pid: 13557
  policy_reward_mean: {}
  time_since_restore: 11125.97674202919
  time_this_iter_s: 26.452616214752197
  time_total_s: 11125.97674202919
  timestamp: 1594105949
  timesteps_since_restore: 4520000
  timesteps_this_iter: 10000
  timesteps_total: 4520000
  training_iteration: 452
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=13557], 11125 s, 452 iter, 4520000 ts, 1.09e+03 rew

agent-1: 118.0
agent-2: 113.0
agent-3: 107.0
agent-4: 92.0
agent-5: 117.0
agent-6: 123.0
agent-7: 90.0
agent-8: 98.0
agent-9: 113.0
agent-10: 99.0
Sum Reward: 1070.0
Avg Reward: 107.0
Min Reward: 90.0
Max Reward: 123.0
Gini Coefficient: 0.05813084112149533
20:20 Ratio: 1.3241758241758241
Max-min Ratio: 1.3666666666666667
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_03-12-51
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1764.0
  episode_reward_mean: 1091.83
  episode_reward_min: 831.0
  episodes_this_iter: 1
  episodes_total: 452
  experiment_id: a3942a9886f24694ab1b58ca8d1ab856
  hostname: gpu006
  info:
    apply_time_ms: 3.037
    dispatch_time_ms: 7.093
    learner:
      cur_lr: 0.0010589680168777704
      grad_gnorm: 40.00000762939453
      policy_entropy: 40.21783447265625
      policy_loss: 0.5820741653442383
      var_gnorm: 57.40501403808594
      vf_explained_var: 0.8058291077613831
      vf_loss: 167.23300170898438
    num_steps_sampled: 4530000
    num_steps_trained: 4530000
    wait_time_ms: 232.969
  iterations_since_restore: 453
  node_ip: 172.17.8.6
  num_metric_batches_dropped: 0
  pid: 13557
  policy_reward_mean: {}
  time_since_restore: 11148.432348966599
  time_this_iter_s: 22.455606937408447
  time_total_s: 11148.432348966599
  timestamp: 1594105971
  timesteps_since_restore: 4530000
  timesteps_this_iter: 10000
  timesteps_total: 4530000
  training_iteration: 453
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=13557], 11148 s, 453 iter, 4530000 ts, 1.09e+03 rew

agent-1: 131.0
agent-2: 139.0
agent-3: 119.0
agent-4: 136.0
agent-5: 142.0
agent-6: 131.0
agent-7: 127.0
agent-8: 145.0
agent-9: 152.0
agent-10: 134.0
Sum Reward: 1356.0
Avg Reward: 135.6
Min Reward: 119.0
Max Reward: 152.0
Gini Coefficient: 0.03716814159292035
20:20 Ratio: 1.2073170731707317
Max-min Ratio: 1.2773109243697478
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_03-13-17
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1764.0
  episode_reward_mean: 1096.14
  episode_reward_min: 831.0
  episodes_this_iter: 1
  episodes_total: 453
  experiment_id: a3942a9886f24694ab1b58ca8d1ab856
  hostname: gpu006
  info:
    apply_time_ms: 2.534
    dispatch_time_ms: 6.437
    learner:
      cur_lr: 0.0010583020048215985
      grad_gnorm: 5.565608501434326
      policy_entropy: 87.94749450683594
      policy_loss: -1.6088980436325073
      var_gnorm: 57.46236038208008
      vf_explained_var: 0.9943411946296692
      vf_loss: 0.027349628508090973
    num_steps_sampled: 4540000
    num_steps_trained: 4540000
    wait_time_ms: 229.324
  iterations_since_restore: 454
  node_ip: 172.17.8.6
  num_metric_batches_dropped: 0
  pid: 13557
  policy_reward_mean: {}
  time_since_restore: 11173.78290438652
  time_this_iter_s: 25.350555419921875
  time_total_s: 11173.78290438652
  timestamp: 1594105997
  timesteps_since_restore: 4540000
  timesteps_this_iter: 10000
  timesteps_total: 4540000
  training_iteration: 454
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=13557], 11173 s, 454 iter, 4540000 ts, 1.1e+03 rew

agent-1: 121.0
agent-2: 89.0
agent-3: 100.0
agent-4: 120.0
agent-5: 118.0
agent-6: 117.0
agent-7: 139.0
agent-8: 142.0
agent-9: 124.0
agent-10: 110.0
Sum Reward: 1180.0
Avg Reward: 118.0
Min Reward: 89.0
Max Reward: 142.0
Gini Coefficient: 0.07067796610169491
20:20 Ratio: 1.4867724867724867
Max-min Ratio: 1.595505617977528
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_03-13-40
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1764.0
  episode_reward_mean: 1096.03
  episode_reward_min: 831.0
  episodes_this_iter: 1
  episodes_total: 454
  experiment_id: a3942a9886f24694ab1b58ca8d1ab856
  hostname: gpu006
  info:
    apply_time_ms: 2.607
    dispatch_time_ms: 6.023
    learner:
      cur_lr: 0.0010576359927654266
      grad_gnorm: 40.0
      policy_entropy: 16.84417152404785
      policy_loss: -34.659263610839844
      var_gnorm: 57.5013427734375
      vf_explained_var: 0.7517484426498413
      vf_loss: 177.59010314941406
    num_steps_sampled: 4550000
    num_steps_trained: 4550000
    wait_time_ms: 234.911
  iterations_since_restore: 455
  node_ip: 172.17.8.6
  num_metric_batches_dropped: 0
  pid: 13557
  policy_reward_mean: {}
  time_since_restore: 11197.298749446869
  time_this_iter_s: 23.51584506034851
  time_total_s: 11197.298749446869
  timestamp: 1594106020
  timesteps_since_restore: 4550000
  timesteps_this_iter: 10000
  timesteps_total: 4550000
  training_iteration: 455
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=13557], 11197 s, 455 iter, 4550000 ts, 1.1e+03 rew

agent-1: 93.0
agent-2: 118.0
agent-3: 96.0
agent-4: 112.0
agent-5: 121.0
agent-6: 93.0
agent-7: 89.0
agent-8: 91.0
agent-9: 118.0
agent-10: 122.0
Sum Reward: 1053.0
Avg Reward: 105.3
Min Reward: 89.0
Max Reward: 122.0
Gini Coefficient: 0.06866096866096866
20:20 Ratio: 1.35
Max-min Ratio: 1.3707865168539326
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_03-14-06
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1764.0
  episode_reward_mean: 1094.23
  episode_reward_min: 831.0
  episodes_this_iter: 1
  episodes_total: 455
  experiment_id: a3942a9886f24694ab1b58ca8d1ab856
  hostname: gpu006
  info:
    apply_time_ms: 2.822
    dispatch_time_ms: 7.262
    learner:
      cur_lr: 0.0010569699807092547
      grad_gnorm: 3.1972880363464355
      policy_entropy: 58.34396743774414
      policy_loss: -0.18231827020645142
      var_gnorm: 57.532894134521484
      vf_explained_var: 0.32230257987976074
      vf_loss: 0.02275562472641468
    num_steps_sampled: 4560000
    num_steps_trained: 4560000
    wait_time_ms: 217.111
  iterations_since_restore: 456
  node_ip: 172.17.8.6
  num_metric_batches_dropped: 0
  pid: 13557
  policy_reward_mean: {}
  time_since_restore: 11222.712695360184
  time_this_iter_s: 25.41394591331482
  time_total_s: 11222.712695360184
  timestamp: 1594106046
  timesteps_since_restore: 4560000
  timesteps_this_iter: 10000
  timesteps_total: 4560000
  training_iteration: 456
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=13557], 11222 s, 456 iter, 4560000 ts, 1.09e+03 rew

agent-1: 80.0
agent-2: 88.0
agent-3: 126.0
agent-4: 140.0
agent-5: 105.0
agent-6: 120.0
agent-7: 107.0
agent-8: 107.0
agent-9: 98.0
agent-10: 122.0
Sum Reward: 1093.0
Avg Reward: 109.3
Min Reward: 80.0
Max Reward: 140.0
Gini Coefficient: 0.08883806038426349
20:20 Ratio: 1.5833333333333333
Max-min Ratio: 1.75
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_03-14-29
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1764.0
  episode_reward_mean: 1092.8
  episode_reward_min: 831.0
  episodes_this_iter: 1
  episodes_total: 456
  experiment_id: a3942a9886f24694ab1b58ca8d1ab856
  hostname: gpu006
  info:
    apply_time_ms: 2.784
    dispatch_time_ms: 7.145
    learner:
      cur_lr: 0.0010563039686530828
      grad_gnorm: 21.995052337646484
      policy_entropy: 74.85250854492188
      policy_loss: -5.180426597595215
      var_gnorm: 57.60000991821289
      vf_explained_var: 0.0
      vf_loss: 0.2890174090862274
    num_steps_sampled: 4570000
    num_steps_trained: 4570000
    wait_time_ms: 252.123
  iterations_since_restore: 457
  node_ip: 172.17.8.6
  num_metric_batches_dropped: 0
  pid: 13557
  policy_reward_mean: {}
  time_since_restore: 11246.244492530823
  time_this_iter_s: 23.531797170639038
  time_total_s: 11246.244492530823
  timestamp: 1594106069
  timesteps_since_restore: 4570000
  timesteps_this_iter: 10000
  timesteps_total: 4570000
  training_iteration: 457
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=13557], 11246 s, 457 iter, 4570000 ts, 1.09e+03 rew

agent-1: 110.0
agent-2: 115.0
agent-3: 119.0
agent-4: 108.0
agent-5: 125.0
agent-6: 90.0
agent-7: 100.0
agent-8: 95.0
agent-9: 111.0
agent-10: 109.0
Sum Reward: 1082.0
Avg Reward: 108.2
Min Reward: 90.0
Max Reward: 125.0
Gini Coefficient: 0.05249537892791128
20:20 Ratio: 1.318918918918919
Max-min Ratio: 1.3888888888888888
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_03-14-55
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1764.0
  episode_reward_mean: 1093.47
  episode_reward_min: 831.0
  episodes_this_iter: 1
  episodes_total: 457
  experiment_id: a3942a9886f24694ab1b58ca8d1ab856
  hostname: gpu006
  info:
    apply_time_ms: 2.797
    dispatch_time_ms: 6.669
    learner:
      cur_lr: 0.001055637956596911
      grad_gnorm: 2.886314630508423
      policy_entropy: 87.17342376708984
      policy_loss: 0.5724541544914246
      var_gnorm: 57.62809753417969
      vf_explained_var: 0.7077131271362305
      vf_loss: 0.008112067356705666
    num_steps_sampled: 4580000
    num_steps_trained: 4580000
    wait_time_ms: 209.813
  iterations_since_restore: 458
  node_ip: 172.17.8.6
  num_metric_batches_dropped: 0
  pid: 13557
  policy_reward_mean: {}
  time_since_restore: 11271.796373605728
  time_this_iter_s: 25.551881074905396
  time_total_s: 11271.796373605728
  timestamp: 1594106095
  timesteps_since_restore: 4580000
  timesteps_this_iter: 10000
  timesteps_total: 4580000
  training_iteration: 458
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=13557], 11271 s, 458 iter, 4580000 ts, 1.09e+03 rew

agent-1: 127.0
agent-2: 88.0
agent-3: 112.0
agent-4: 124.0
agent-5: 102.0
agent-6: 115.0
agent-7: 107.0
agent-8: 86.0
agent-9: 124.0
agent-10: 111.0
Sum Reward: 1096.0
Avg Reward: 109.6
Min Reward: 86.0
Max Reward: 127.0
Gini Coefficient: 0.06897810218978102
20:20 Ratio: 1.4425287356321839
Max-min Ratio: 1.4767441860465116
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_03-15-19
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1764.0
  episode_reward_mean: 1093.04
  episode_reward_min: 831.0
  episodes_this_iter: 1
  episodes_total: 458
  experiment_id: a3942a9886f24694ab1b58ca8d1ab856
  hostname: gpu006
  info:
    apply_time_ms: 2.69
    dispatch_time_ms: 16.394
    learner:
      cur_lr: 0.001054971944540739
      grad_gnorm: 25.637556076049805
      policy_entropy: 78.27388763427734
      policy_loss: -5.159290313720703
      var_gnorm: 57.54043197631836
      vf_explained_var: -1.0
      vf_loss: 0.5231868624687195
    num_steps_sampled: 4590000
    num_steps_trained: 4590000
    wait_time_ms: 244.17
  iterations_since_restore: 459
  node_ip: 172.17.8.6
  num_metric_batches_dropped: 0
  pid: 13557
  policy_reward_mean: {}
  time_since_restore: 11295.407242059708
  time_this_iter_s: 23.610868453979492
  time_total_s: 11295.407242059708
  timestamp: 1594106119
  timesteps_since_restore: 4590000
  timesteps_this_iter: 10000
  timesteps_total: 4590000
  training_iteration: 459
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=13557], 11295 s, 459 iter, 4590000 ts, 1.09e+03 rew

agent-1: 105.0
agent-2: 113.0
agent-3: 89.0
agent-4: 122.0
agent-5: 113.0
agent-6: 107.0
agent-7: 105.0
agent-8: 102.0
agent-9: 105.0
agent-10: 104.0
Sum Reward: 1065.0
Avg Reward: 106.5
Min Reward: 89.0
Max Reward: 122.0
Gini Coefficient: 0.03990610328638498
20:20 Ratio: 1.2303664921465969
Max-min Ratio: 1.3707865168539326
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_03-15-46
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1764.0
  episode_reward_mean: 1092.44
  episode_reward_min: 831.0
  episodes_this_iter: 1
  episodes_total: 459
  experiment_id: a3942a9886f24694ab1b58ca8d1ab856
  hostname: gpu006
  info:
    apply_time_ms: 2.945
    dispatch_time_ms: 31.84
    learner:
      cur_lr: 0.001054306048899889
      grad_gnorm: 39.999996185302734
      policy_entropy: 20.15712547302246
      policy_loss: 19.084228515625
      var_gnorm: 57.55251693725586
      vf_explained_var: 0.7821456789970398
      vf_loss: 101.0242919921875
    num_steps_sampled: 4600000
    num_steps_trained: 4600000
    wait_time_ms: 206.562
  iterations_since_restore: 460
  node_ip: 172.17.8.6
  num_metric_batches_dropped: 0
  pid: 13557
  policy_reward_mean: {}
  time_since_restore: 11323.020949363708
  time_this_iter_s: 27.613707304000854
  time_total_s: 11323.020949363708
  timestamp: 1594106146
  timesteps_since_restore: 4600000
  timesteps_this_iter: 10000
  timesteps_total: 4600000
  training_iteration: 460
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=13557], 11323 s, 460 iter, 4600000 ts, 1.09e+03 rew

agent-1: 79.0
agent-2: 82.0
agent-3: 105.0
agent-4: 94.0
agent-5: 102.0
agent-6: 109.0
agent-7: 111.0
agent-8: 98.0
agent-9: 110.0
agent-10: 103.0
Sum Reward: 993.0
Avg Reward: 99.3
Min Reward: 79.0
Max Reward: 111.0
Gini Coefficient: 0.05850956696878147
20:20 Ratio: 1.3726708074534162
Max-min Ratio: 1.4050632911392404
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_03-16-17
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1764.0
  episode_reward_mean: 1092.03
  episode_reward_min: 831.0
  episodes_this_iter: 1
  episodes_total: 460
  experiment_id: a3942a9886f24694ab1b58ca8d1ab856
  hostname: gpu006
  info:
    apply_time_ms: 3.358
    dispatch_time_ms: 17.061
    learner:
      cur_lr: 0.001053640036843717
      grad_gnorm: 40.0
      policy_entropy: 32.88984680175781
      policy_loss: -4.920394420623779
      var_gnorm: 57.784996032714844
      vf_explained_var: -0.059067726135253906
      vf_loss: 78.92398071289062
    num_steps_sampled: 4610000
    num_steps_trained: 4610000
    wait_time_ms: 247.216
  iterations_since_restore: 461
  node_ip: 172.17.8.6
  num_metric_batches_dropped: 0
  pid: 13557
  policy_reward_mean: {}
  time_since_restore: 11345.404690980911
  time_this_iter_s: 22.38374161720276
  time_total_s: 11345.404690980911
  timestamp: 1594106177
  timesteps_since_restore: 4610000
  timesteps_this_iter: 10000
  timesteps_total: 4610000
  training_iteration: 461
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=13557], 11345 s, 461 iter, 4610000 ts, 1.09e+03 rew

agent-1: 96.0
agent-2: 90.0
agent-3: 101.0
agent-4: 118.0
agent-5: 97.0
agent-6: 105.0
agent-7: 108.0
agent-8: 96.0
agent-9: 94.0
agent-10: 120.0
Sum Reward: 1025.0
Avg Reward: 102.5
Min Reward: 90.0
Max Reward: 120.0
Gini Coefficient: 0.05160975609756097
20:20 Ratio: 1.2934782608695652
Max-min Ratio: 1.3333333333333333
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_03-16-43
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1764.0
  episode_reward_mean: 1091.35
  episode_reward_min: 831.0
  episodes_this_iter: 1
  episodes_total: 461
  experiment_id: a3942a9886f24694ab1b58ca8d1ab856
  hostname: gpu006
  info:
    apply_time_ms: 2.654
    dispatch_time_ms: 29.41
    learner:
      cur_lr: 0.0010529740247875452
      grad_gnorm: 0.8421876430511475
      policy_entropy: 84.21980285644531
      policy_loss: -0.2225567102432251
      var_gnorm: 57.80062484741211
      vf_explained_var: 0.0
      vf_loss: 0.0003889119834639132
    num_steps_sampled: 4620000
    num_steps_trained: 4620000
    wait_time_ms: 194.108
  iterations_since_restore: 462
  node_ip: 172.17.8.6
  num_metric_batches_dropped: 0
  pid: 13557
  policy_reward_mean: {}
  time_since_restore: 11371.782361507416
  time_this_iter_s: 26.377670526504517
  time_total_s: 11371.782361507416
  timestamp: 1594106203
  timesteps_since_restore: 4620000
  timesteps_this_iter: 10000
  timesteps_total: 4620000
  training_iteration: 462
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=13557], 11371 s, 462 iter, 4620000 ts, 1.09e+03 rew

agent-1: 79.0
agent-2: 104.0
agent-3: 89.0
agent-4: 96.0
agent-5: 100.0
agent-6: 96.0
agent-7: 80.0
agent-8: 89.0
agent-9: 91.0
agent-10: 107.0
Sum Reward: 931.0
Avg Reward: 93.1
Min Reward: 79.0
Max Reward: 107.0
Gini Coefficient: 0.05381310418904404
20:20 Ratio: 1.3270440251572326
Max-min Ratio: 1.3544303797468353
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_03-17-06
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1764.0
  episode_reward_mean: 1089.71
  episode_reward_min: 831.0
  episodes_this_iter: 1
  episodes_total: 462
  experiment_id: a3942a9886f24694ab1b58ca8d1ab856
  hostname: gpu006
  info:
    apply_time_ms: 2.858
    dispatch_time_ms: 27.115
    learner:
      cur_lr: 0.0010523080127313733
      grad_gnorm: 40.00000762939453
      policy_entropy: 49.45978927612305
      policy_loss: 6.365190505981445
      var_gnorm: 57.79104995727539
      vf_explained_var: 0.8984565734863281
      vf_loss: 31.023298263549805
    num_steps_sampled: 4630000
    num_steps_trained: 4630000
    wait_time_ms: 212.509
  iterations_since_restore: 463
  node_ip: 172.17.8.6
  num_metric_batches_dropped: 0
  pid: 13557
  policy_reward_mean: {}
  time_since_restore: 11395.092162132263
  time_this_iter_s: 23.309800624847412
  time_total_s: 11395.092162132263
  timestamp: 1594106226
  timesteps_since_restore: 4630000
  timesteps_this_iter: 10000
  timesteps_total: 4630000
  training_iteration: 463
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=13557], 11395 s, 463 iter, 4630000 ts, 1.09e+03 rew

agent-1: 101.0
agent-2: 102.0
agent-3: 99.0
agent-4: 150.0
agent-5: 131.0
agent-6: 100.0
agent-7: 112.0
agent-8: 109.0
agent-9: 148.0
agent-10: 111.0
Sum Reward: 1163.0
Avg Reward: 116.3
Min Reward: 99.0
Max Reward: 150.0
Gini Coefficient: 0.08400687876182288
20:20 Ratio: 1.4974874371859297
Max-min Ratio: 1.5151515151515151
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_03-17-33
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1764.0
  episode_reward_mean: 1088.67
  episode_reward_min: 831.0
  episodes_this_iter: 1
  episodes_total: 463
  experiment_id: a3942a9886f24694ab1b58ca8d1ab856
  hostname: gpu006
  info:
    apply_time_ms: 2.821
    dispatch_time_ms: 6.142
    learner:
      cur_lr: 0.0010516420006752014
      grad_gnorm: 39.999996185302734
      policy_entropy: 24.593873977661133
      policy_loss: 6.190491199493408
      var_gnorm: 57.810394287109375
      vf_explained_var: 0.5676497220993042
      vf_loss: 171.7831268310547
    num_steps_sampled: 4640000
    num_steps_trained: 4640000
    wait_time_ms: 218.046
  iterations_since_restore: 464
  node_ip: 172.17.8.6
  num_metric_batches_dropped: 0
  pid: 13557
  policy_reward_mean: {}
  time_since_restore: 11421.193680763245
  time_this_iter_s: 26.101518630981445
  time_total_s: 11421.193680763245
  timestamp: 1594106253
  timesteps_since_restore: 4640000
  timesteps_this_iter: 10000
  timesteps_total: 4640000
  training_iteration: 464
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=13557], 11421 s, 464 iter, 4640000 ts, 1.09e+03 rew

agent-1: 120.0
agent-2: 127.0
agent-3: 126.0
agent-4: 148.0
agent-5: 150.0
agent-6: 119.0
agent-7: 144.0
agent-8: 151.0
agent-9: 136.0
agent-10: 140.0
Sum Reward: 1361.0
Avg Reward: 136.1
Min Reward: 119.0
Max Reward: 151.0
Gini Coefficient: 0.048714180749448936
20:20 Ratio: 1.2594142259414225
Max-min Ratio: 1.26890756302521
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_03-17-57
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1764.0
  episode_reward_mean: 1092.66
  episode_reward_min: 831.0
  episodes_this_iter: 1
  episodes_total: 464
  experiment_id: a3942a9886f24694ab1b58ca8d1ab856
  hostname: gpu006
  info:
    apply_time_ms: 2.673
    dispatch_time_ms: 5.275
    learner:
      cur_lr: 0.0010509759886190295
      grad_gnorm: 14.423317909240723
      policy_entropy: 76.11642456054688
      policy_loss: -3.9698970317840576
      var_gnorm: 57.90388870239258
      vf_explained_var: 0.8608814477920532
      vf_loss: 0.45805254578590393
    num_steps_sampled: 4650000
    num_steps_trained: 4650000
    wait_time_ms: 260.616
  iterations_since_restore: 465
  node_ip: 172.17.8.6
  num_metric_batches_dropped: 0
  pid: 13557
  policy_reward_mean: {}
  time_since_restore: 11445.223775863647
  time_this_iter_s: 24.030095100402832
  time_total_s: 11445.223775863647
  timestamp: 1594106277
  timesteps_since_restore: 4650000
  timesteps_this_iter: 10000
  timesteps_total: 4650000
  training_iteration: 465
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=13557], 11445 s, 465 iter, 4650000 ts, 1.09e+03 rew

agent-1: 108.0
agent-2: 111.0
agent-3: 106.0
agent-4: 88.0
agent-5: 101.0
agent-6: 98.0
agent-7: 105.0
agent-8: 95.0
agent-9: 123.0
agent-10: 91.0
Sum Reward: 1026.0
Avg Reward: 102.6
Min Reward: 88.0
Max Reward: 123.0
Gini Coefficient: 0.05341130604288499
20:20 Ratio: 1.3072625698324023
Max-min Ratio: 1.3977272727272727
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_03-18-23
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1764.0
  episode_reward_mean: 1092.29
  episode_reward_min: 831.0
  episodes_this_iter: 1
  episodes_total: 465
  experiment_id: a3942a9886f24694ab1b58ca8d1ab856
  hostname: gpu006
  info:
    apply_time_ms: 2.819
    dispatch_time_ms: 7.12
    learner:
      cur_lr: 0.0010503099765628576
      grad_gnorm: 0.8270950317382812
      policy_entropy: 93.641845703125
      policy_loss: -0.1332513839006424
      var_gnorm: 57.88444519042969
      vf_explained_var: 5.960464477539063e-08
      vf_loss: 0.0003751418844331056
    num_steps_sampled: 4660000
    num_steps_trained: 4660000
    wait_time_ms: 203.429
  iterations_since_restore: 466
  node_ip: 172.17.8.6
  num_metric_batches_dropped: 0
  pid: 13557
  policy_reward_mean: {}
  time_since_restore: 11471.177003622055
  time_this_iter_s: 25.953227758407593
  time_total_s: 11471.177003622055
  timestamp: 1594106303
  timesteps_since_restore: 4660000
  timesteps_this_iter: 10000
  timesteps_total: 4660000
  training_iteration: 466
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=13557], 11471 s, 466 iter, 4660000 ts, 1.09e+03 rew

agent-1: 79.0
agent-2: 81.0
agent-3: 89.0
agent-4: 96.0
agent-5: 91.0
agent-6: 71.0
agent-7: 88.0
agent-8: 88.0
agent-9: 94.0
agent-10: 93.0
Sum Reward: 870.0
Avg Reward: 87.0
Min Reward: 71.0
Max Reward: 96.0
Gini Coefficient: 0.04597701149425287
20:20 Ratio: 1.2666666666666666
Max-min Ratio: 1.352112676056338
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_03-18-46
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1764.0
  episode_reward_mean: 1088.64
  episode_reward_min: 831.0
  episodes_this_iter: 1
  episodes_total: 466
  experiment_id: a3942a9886f24694ab1b58ca8d1ab856
  hostname: gpu006
  info:
    apply_time_ms: 2.744
    dispatch_time_ms: 6.461
    learner:
      cur_lr: 0.0010496439645066857
      grad_gnorm: 40.0000114440918
      policy_entropy: 36.38669967651367
      policy_loss: 4.795416355133057
      var_gnorm: 57.9541130065918
      vf_explained_var: 0.5348930358886719
      vf_loss: 54.093017578125
    num_steps_sampled: 4670000
    num_steps_trained: 4670000
    wait_time_ms: 257.79
  iterations_since_restore: 467
  node_ip: 172.17.8.6
  num_metric_batches_dropped: 0
  pid: 13557
  policy_reward_mean: {}
  time_since_restore: 11494.854235649109
  time_this_iter_s: 23.677232027053833
  time_total_s: 11494.854235649109
  timestamp: 1594106326
  timesteps_since_restore: 4670000
  timesteps_this_iter: 10000
  timesteps_total: 4670000
  training_iteration: 467
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=13557], 11494 s, 467 iter, 4670000 ts, 1.09e+03 rew

agent-1: 96.0
agent-2: 140.0
agent-3: 108.0
agent-4: 114.0
agent-5: 97.0
agent-6: 109.0
agent-7: 96.0
agent-8: 118.0
agent-9: 130.0
agent-10: 129.0
Sum Reward: 1137.0
Avg Reward: 113.7
Min Reward: 96.0
Max Reward: 140.0
Gini Coefficient: 0.07291116974494283
20:20 Ratio: 1.40625
Max-min Ratio: 1.4583333333333333
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_03-19-12
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1764.0
  episode_reward_mean: 1089.22
  episode_reward_min: 831.0
  episodes_this_iter: 1
  episodes_total: 467
  experiment_id: a3942a9886f24694ab1b58ca8d1ab856
  hostname: gpu006
  info:
    apply_time_ms: 4.147
    dispatch_time_ms: 5.686
    learner:
      cur_lr: 0.0010489779524505138
      grad_gnorm: 40.0
      policy_entropy: 84.24124908447266
      policy_loss: 6.846611499786377
      var_gnorm: 57.93842697143555
      vf_explained_var: 0.905944287776947
      vf_loss: 9.852983474731445
    num_steps_sampled: 4680000
    num_steps_trained: 4680000
    wait_time_ms: 208.521
  iterations_since_restore: 468
  node_ip: 172.17.8.6
  num_metric_batches_dropped: 0
  pid: 13557
  policy_reward_mean: {}
  time_since_restore: 11520.63870549202
  time_this_iter_s: 25.784469842910767
  time_total_s: 11520.63870549202
  timestamp: 1594106352
  timesteps_since_restore: 4680000
  timesteps_this_iter: 10000
  timesteps_total: 4680000
  training_iteration: 468
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=13557], 11520 s, 468 iter, 4680000 ts, 1.09e+03 rew

agent-1: 85.0
agent-2: 80.0
agent-3: 90.0
agent-4: 87.0
agent-5: 93.0
agent-6: 100.0
agent-7: 130.0
agent-8: 84.0
agent-9: 75.0
agent-10: 79.0
Sum Reward: 903.0
Avg Reward: 90.3
Min Reward: 75.0
Max Reward: 130.0
Gini Coefficient: 0.0805094130675526
20:20 Ratio: 1.4935064935064934
Max-min Ratio: 1.7333333333333334
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_03-19-41
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1764.0
  episode_reward_mean: 1087.63
  episode_reward_min: 831.0
  episodes_this_iter: 1
  episodes_total: 468
  experiment_id: a3942a9886f24694ab1b58ca8d1ab856
  hostname: gpu006
  info:
    apply_time_ms: 2.714
    dispatch_time_ms: 14.877
    learner:
      cur_lr: 0.0010483120568096638
      grad_gnorm: 39.9999885559082
      policy_entropy: 51.84032440185547
      policy_loss: -0.5173225402832031
      var_gnorm: 57.970680236816406
      vf_explained_var: 0.7104592323303223
      vf_loss: 149.85501098632812
    num_steps_sampled: 4690000
    num_steps_trained: 4690000
    wait_time_ms: 52.429
  iterations_since_restore: 469
  node_ip: 172.17.8.6
  num_metric_batches_dropped: 0
  pid: 13557
  policy_reward_mean: {}
  time_since_restore: 11549.239914894104
  time_this_iter_s: 28.60120940208435
  time_total_s: 11549.239914894104
  timestamp: 1594106381
  timesteps_since_restore: 4690000
  timesteps_this_iter: 10000
  timesteps_total: 4690000
  training_iteration: 469
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=13557], 11549 s, 469 iter, 4690000 ts, 1.09e+03 rew

agent-1: 130.0
agent-2: 117.0
agent-3: 96.0
agent-4: 122.0
agent-5: 121.0
agent-6: 120.0
agent-7: 117.0
agent-8: 135.0
agent-9: 144.0
agent-10: 116.0
Sum Reward: 1218.0
Avg Reward: 121.8
Min Reward: 96.0
Max Reward: 144.0
Gini Coefficient: 0.05303776683087028
20:20 Ratio: 1.3160377358490567
Max-min Ratio: 1.5
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_03-20-06
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1764.0
  episode_reward_mean: 1091.13
  episode_reward_min: 831.0
  episodes_this_iter: 1
  episodes_total: 469
  experiment_id: a3942a9886f24694ab1b58ca8d1ab856
  hostname: gpu006
  info:
    apply_time_ms: 2.731
    dispatch_time_ms: 18.73
    learner:
      cur_lr: 0.0010476460447534919
      grad_gnorm: 1.7495371103286743
      policy_entropy: 84.25625610351562
      policy_loss: -0.2909262180328369
      var_gnorm: 58.049346923828125
      vf_explained_var: 0.0
      vf_loss: 0.0017710330430418253
    num_steps_sampled: 4700000
    num_steps_trained: 4700000
    wait_time_ms: 217.226
  iterations_since_restore: 470
  node_ip: 172.17.8.6
  num_metric_batches_dropped: 0
  pid: 13557
  policy_reward_mean: {}
  time_since_restore: 11574.739857435226
  time_this_iter_s: 25.499942541122437
  time_total_s: 11574.739857435226
  timestamp: 1594106406
  timesteps_since_restore: 4700000
  timesteps_this_iter: 10000
  timesteps_total: 4700000
  training_iteration: 470
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=13557], 11574 s, 470 iter, 4700000 ts, 1.09e+03 rew

agent-1: 118.0
agent-2: 128.0
agent-3: 128.0
agent-4: 125.0
agent-5: 130.0
agent-6: 127.0
agent-7: 109.0
agent-8: 113.0
agent-9: 127.0
agent-10: 124.0
Sum Reward: 1229.0
Avg Reward: 122.9
Min Reward: 109.0
Max Reward: 130.0
Gini Coefficient: 0.02888527257933279
20:20 Ratio: 1.162162162162162
Max-min Ratio: 1.1926605504587156
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_03-20-29
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1764.0
  episode_reward_mean: 1094.91
  episode_reward_min: 831.0
  episodes_this_iter: 1
  episodes_total: 470
  experiment_id: a3942a9886f24694ab1b58ca8d1ab856
  hostname: gpu006
  info:
    apply_time_ms: 3.033
    dispatch_time_ms: 25.491
    learner:
      cur_lr: 0.00104698003269732
      grad_gnorm: 39.999996185302734
      policy_entropy: 61.599945068359375
      policy_loss: -7.208029747009277
      var_gnorm: 58.0693359375
      vf_explained_var: 0.8791796565055847
      vf_loss: 177.27122497558594
    num_steps_sampled: 4710000
    num_steps_trained: 4710000
    wait_time_ms: 220.413
  iterations_since_restore: 471
  node_ip: 172.17.8.6
  num_metric_batches_dropped: 0
  pid: 13557
  policy_reward_mean: {}
  time_since_restore: 11597.64619898796
  time_this_iter_s: 22.906341552734375
  time_total_s: 11597.64619898796
  timestamp: 1594106429
  timesteps_since_restore: 4710000
  timesteps_this_iter: 10000
  timesteps_total: 4710000
  training_iteration: 471
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=13557], 11597 s, 471 iter, 4710000 ts, 1.09e+03 rew

agent-1: 105.0
agent-2: 119.0
agent-3: 108.0
agent-4: 149.0
agent-5: 117.0
agent-6: 99.0
agent-7: 132.0
agent-8: 131.0
agent-9: 114.0
agent-10: 100.0
Sum Reward: 1174.0
Avg Reward: 117.4
Min Reward: 99.0
Max Reward: 149.0
Gini Coefficient: 0.07155025553662692
20:20 Ratio: 1.4120603015075377
Max-min Ratio: 1.505050505050505
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_03-20-55
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1764.0
  episode_reward_mean: 1095.35
  episode_reward_min: 831.0
  episodes_this_iter: 1
  episodes_total: 471
  experiment_id: a3942a9886f24694ab1b58ca8d1ab856
  hostname: gpu006
  info:
    apply_time_ms: 3.088
    dispatch_time_ms: 8.098
    learner:
      cur_lr: 0.001046314020641148
      grad_gnorm: 1.3273905515670776
      policy_entropy: 97.94546508789062
      policy_loss: -0.28901901841163635
      var_gnorm: 58.137123107910156
      vf_explained_var: 0.0
      vf_loss: 0.001034484594129026
    num_steps_sampled: 4720000
    num_steps_trained: 4720000
    wait_time_ms: 203.552
  iterations_since_restore: 472
  node_ip: 172.17.8.6
  num_metric_batches_dropped: 0
  pid: 13557
  policy_reward_mean: {}
  time_since_restore: 11623.241921186447
  time_this_iter_s: 25.595722198486328
  time_total_s: 11623.241921186447
  timestamp: 1594106455
  timesteps_since_restore: 4720000
  timesteps_this_iter: 10000
  timesteps_total: 4720000
  training_iteration: 472
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=13557], 11623 s, 472 iter, 4720000 ts, 1.1e+03 rew

agent-1: 151.0
agent-2: 106.0
agent-3: 93.0
agent-4: 130.0
agent-5: 128.0
agent-6: 139.0
agent-7: 112.0
agent-8: 127.0
agent-9: 108.0
agent-10: 106.0
Sum Reward: 1200.0
Avg Reward: 120.0
Min Reward: 93.0
Max Reward: 151.0
Gini Coefficient: 0.079
20:20 Ratio: 1.4572864321608041
Max-min Ratio: 1.6236559139784945
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_03-21-17
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1764.0
  episode_reward_mean: 1097.11
  episode_reward_min: 831.0
  episodes_this_iter: 1
  episodes_total: 472
  experiment_id: a3942a9886f24694ab1b58ca8d1ab856
  hostname: gpu006
  info:
    apply_time_ms: 2.765
    dispatch_time_ms: 6.931
    learner:
      cur_lr: 0.0010456480085849762
      grad_gnorm: 40.0000114440918
      policy_entropy: 59.44831848144531
      policy_loss: -54.550045013427734
      var_gnorm: 58.139835357666016
      vf_explained_var: 0.812889814376831
      vf_loss: 294.81561279296875
    num_steps_sampled: 4730000
    num_steps_trained: 4730000
    wait_time_ms: 227.066
  iterations_since_restore: 473
  node_ip: 172.17.8.6
  num_metric_batches_dropped: 0
  pid: 13557
  policy_reward_mean: {}
  time_since_restore: 11645.211946964264
  time_this_iter_s: 21.970025777816772
  time_total_s: 11645.211946964264
  timestamp: 1594106477
  timesteps_since_restore: 4730000
  timesteps_this_iter: 10000
  timesteps_total: 4730000
  training_iteration: 473
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=13557], 11645 s, 473 iter, 4730000 ts, 1.1e+03 rew

agent-1: 115.0
agent-2: 127.0
agent-3: 129.0
agent-4: 131.0
agent-5: 114.0
agent-6: 128.0
agent-7: 146.0
agent-8: 124.0
agent-9: 147.0
agent-10: 122.0
Sum Reward: 1283.0
Avg Reward: 128.3
Min Reward: 114.0
Max Reward: 147.0
Gini Coefficient: 0.04481683554169914
20:20 Ratio: 1.279475982532751
Max-min Ratio: 1.2894736842105263
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_03-21-43
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1764.0
  episode_reward_mean: 1098.36
  episode_reward_min: 831.0
  episodes_this_iter: 1
  episodes_total: 473
  experiment_id: a3942a9886f24694ab1b58ca8d1ab856
  hostname: gpu006
  info:
    apply_time_ms: 3.528
    dispatch_time_ms: 6.495
    learner:
      cur_lr: 0.0010449819965288043
      grad_gnorm: 5.5682053565979
      policy_entropy: 105.75994873046875
      policy_loss: -1.0819505453109741
      var_gnorm: 58.20197296142578
      vf_explained_var: 0.8338282108306885
      vf_loss: 0.26007694005966187
    num_steps_sampled: 4740000
    num_steps_trained: 4740000
    wait_time_ms: 203.152
  iterations_since_restore: 474
  node_ip: 172.17.8.6
  num_metric_batches_dropped: 0
  pid: 13557
  policy_reward_mean: {}
  time_since_restore: 11671.03200006485
  time_this_iter_s: 25.820053100585938
  time_total_s: 11671.03200006485
  timestamp: 1594106503
  timesteps_since_restore: 4740000
  timesteps_this_iter: 10000
  timesteps_total: 4740000
  training_iteration: 474
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=13557], 11671 s, 474 iter, 4740000 ts, 1.1e+03 rew

agent-1: 72.0
agent-2: 103.0
agent-3: 89.0
agent-4: 140.0
agent-5: 96.0
agent-6: 155.0
agent-7: 104.0
agent-8: 88.0
agent-9: 137.0
agent-10: 127.0
Sum Reward: 1111.0
Avg Reward: 111.1
Min Reward: 72.0
Max Reward: 155.0
Gini Coefficient: 0.13006300630063006
20:20 Ratio: 1.84375
Max-min Ratio: 2.1527777777777777
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_03-22-05
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1764.0
  episode_reward_mean: 1099.18
  episode_reward_min: 831.0
  episodes_this_iter: 1
  episodes_total: 474
  experiment_id: a3942a9886f24694ab1b58ca8d1ab856
  hostname: gpu006
  info:
    apply_time_ms: 3.629
    dispatch_time_ms: 6.3
    learner:
      cur_lr: 0.0010443159844726324
      grad_gnorm: 40.0
      policy_entropy: 70.24063873291016
      policy_loss: -4.837756156921387
      var_gnorm: 58.22121047973633
      vf_explained_var: 0.9434968829154968
      vf_loss: 84.28671264648438
    num_steps_sampled: 4750000
    num_steps_trained: 4750000
    wait_time_ms: 223.437
  iterations_since_restore: 475
  node_ip: 172.17.8.6
  num_metric_batches_dropped: 0
  pid: 13557
  policy_reward_mean: {}
  time_since_restore: 11692.480816841125
  time_this_iter_s: 21.448816776275635
  time_total_s: 11692.480816841125
  timestamp: 1594106525
  timesteps_since_restore: 4750000
  timesteps_this_iter: 10000
  timesteps_total: 4750000
  training_iteration: 475
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=13557], 11692 s, 475 iter, 4750000 ts, 1.1e+03 rew

agent-1: 120.0
agent-2: 158.0
agent-3: 149.0
agent-4: 134.0
agent-5: 118.0
agent-6: 142.0
agent-7: 98.0
agent-8: 131.0
agent-9: 156.0
agent-10: 125.0
Sum Reward: 1331.0
Avg Reward: 133.1
Min Reward: 98.0
Max Reward: 158.0
Gini Coefficient: 0.07550713749060857
20:20 Ratio: 1.4537037037037037
Max-min Ratio: 1.6122448979591837
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_03-22-30
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1764.0
  episode_reward_mean: 1102.27
  episode_reward_min: 831.0
  episodes_this_iter: 1
  episodes_total: 475
  experiment_id: a3942a9886f24694ab1b58ca8d1ab856
  hostname: gpu006
  info:
    apply_time_ms: 2.948
    dispatch_time_ms: 6.491
    learner:
      cur_lr: 0.0010436499724164605
      grad_gnorm: 3.5231258869171143
      policy_entropy: 95.5684814453125
      policy_loss: -1.4780430793762207
      var_gnorm: 58.263553619384766
      vf_explained_var: 0.16640621423721313
      vf_loss: 0.007406170945614576
    num_steps_sampled: 4760000
    num_steps_trained: 4760000
    wait_time_ms: 203.022
  iterations_since_restore: 476
  node_ip: 172.17.8.6
  num_metric_batches_dropped: 0
  pid: 13557
  policy_reward_mean: {}
  time_since_restore: 11717.888440847397
  time_this_iter_s: 25.407624006271362
  time_total_s: 11717.888440847397
  timestamp: 1594106550
  timesteps_since_restore: 4760000
  timesteps_this_iter: 10000
  timesteps_total: 4760000
  training_iteration: 476
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=13557], 11717 s, 476 iter, 4760000 ts, 1.1e+03 rew

agent-1: 131.0
agent-2: 141.0
agent-3: 127.0
agent-4: 140.0
agent-5: 88.0
agent-6: 139.0
agent-7: 130.0
agent-8: 134.0
agent-9: 148.0
agent-10: 116.0
Sum Reward: 1294.0
Avg Reward: 129.4
Min Reward: 88.0
Max Reward: 148.0
Gini Coefficient: 0.062596599690881
20:20 Ratio: 1.4166666666666667
Max-min Ratio: 1.6818181818181819
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_03-22-53
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1764.0
  episode_reward_mean: 1104.53
  episode_reward_min: 831.0
  episodes_this_iter: 1
  episodes_total: 476
  experiment_id: a3942a9886f24694ab1b58ca8d1ab856
  hostname: gpu006
  info:
    apply_time_ms: 3.042
    dispatch_time_ms: 7.29
    learner:
      cur_lr: 0.0010429839603602886
      grad_gnorm: 39.9999885559082
      policy_entropy: 74.05083465576172
      policy_loss: -22.840129852294922
      var_gnorm: 58.186946868896484
      vf_explained_var: 0.1782105565071106
      vf_loss: 147.44703674316406
    num_steps_sampled: 4770000
    num_steps_trained: 4770000
    wait_time_ms: 248.951
  iterations_since_restore: 477
  node_ip: 172.17.8.6
  num_metric_batches_dropped: 0
  pid: 13557
  policy_reward_mean: {}
  time_since_restore: 11740.591857910156
  time_this_iter_s: 22.7034170627594
  time_total_s: 11740.591857910156
  timestamp: 1594106573
  timesteps_since_restore: 4770000
  timesteps_this_iter: 10000
  timesteps_total: 4770000
  training_iteration: 477
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=13557], 11740 s, 477 iter, 4770000 ts, 1.1e+03 rew

agent-1: 104.0
agent-2: 131.0
agent-3: 110.0
agent-4: 103.0
agent-5: 93.0
agent-6: 112.0
agent-7: 122.0
agent-8: 102.0
agent-9: 109.0
agent-10: 98.0
Sum Reward: 1084.0
Avg Reward: 108.4
Min Reward: 93.0
Max Reward: 131.0
Gini Coefficient: 0.05405904059040591
20:20 Ratio: 1.324607329842932
Max-min Ratio: 1.4086021505376345
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_03-23-19
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1764.0
  episode_reward_mean: 1104.44
  episode_reward_min: 831.0
  episodes_this_iter: 1
  episodes_total: 477
  experiment_id: a3942a9886f24694ab1b58ca8d1ab856
  hostname: gpu006
  info:
    apply_time_ms: 2.972
    dispatch_time_ms: 8.404
    learner:
      cur_lr: 0.0010423179483041167
      grad_gnorm: 40.0
      policy_entropy: 62.15195083618164
      policy_loss: 20.886167526245117
      var_gnorm: 58.163352966308594
      vf_explained_var: 0.31953662633895874
      vf_loss: 108.77515411376953
    num_steps_sampled: 4780000
    num_steps_trained: 4780000
    wait_time_ms: 221.248
  iterations_since_restore: 478
  node_ip: 172.17.8.6
  num_metric_batches_dropped: 0
  pid: 13557
  policy_reward_mean: {}
  time_since_restore: 11766.842808246613
  time_this_iter_s: 26.2509503364563
  time_total_s: 11766.842808246613
  timestamp: 1594106599
  timesteps_since_restore: 4780000
  timesteps_this_iter: 10000
  timesteps_total: 4780000
  training_iteration: 478
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=13557], 11766 s, 478 iter, 4780000 ts, 1.1e+03 rew

agent-1: 72.0
agent-2: 105.0
agent-3: 87.0
agent-4: 82.0
agent-5: 100.0
agent-6: 108.0
agent-7: 110.0
agent-8: 105.0
agent-9: 122.0
agent-10: 70.0
Sum Reward: 961.0
Avg Reward: 96.1
Min Reward: 70.0
Max Reward: 122.0
Gini Coefficient: 0.09604578563995837
20:20 Ratio: 1.6338028169014085
Max-min Ratio: 1.7428571428571429
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_03-23-42
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1764.0
  episode_reward_mean: 1102.3
  episode_reward_min: 831.0
  episodes_this_iter: 1
  episodes_total: 478
  experiment_id: a3942a9886f24694ab1b58ca8d1ab856
  hostname: gpu006
  info:
    apply_time_ms: 4.05
    dispatch_time_ms: 7.872
    learner:
      cur_lr: 0.0010416520526632667
      grad_gnorm: 40.0
      policy_entropy: 56.691707611083984
      policy_loss: -40.56996536254883
      var_gnorm: 58.35681915283203
      vf_explained_var: 0.6140141487121582
      vf_loss: 142.41590881347656
    num_steps_sampled: 4790000
    num_steps_trained: 4790000
    wait_time_ms: 228.677
  iterations_since_restore: 479
  node_ip: 172.17.8.6
  num_metric_batches_dropped: 0
  pid: 13557
  policy_reward_mean: {}
  time_since_restore: 11789.22825884819
  time_this_iter_s: 22.38545060157776
  time_total_s: 11789.22825884819
  timestamp: 1594106622
  timesteps_since_restore: 4790000
  timesteps_this_iter: 10000
  timesteps_total: 4790000
  training_iteration: 479
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=13557], 11789 s, 479 iter, 4790000 ts, 1.1e+03 rew

agent-1: 107.0
agent-2: 116.0
agent-3: 117.0
agent-4: 114.0
agent-5: 122.0
agent-6: 115.0
agent-7: 131.0
agent-8: 119.0
agent-9: 154.0
agent-10: 107.0
Sum Reward: 1202.0
Avg Reward: 120.2
Min Reward: 107.0
Max Reward: 154.0
Gini Coefficient: 0.053577371048252914
20:20 Ratio: 1.3317757009345794
Max-min Ratio: 1.439252336448598
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_03-24-08
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1764.0
  episode_reward_mean: 1105.83
  episode_reward_min: 831.0
  episodes_this_iter: 1
  episodes_total: 479
  experiment_id: a3942a9886f24694ab1b58ca8d1ab856
  hostname: gpu006
  info:
    apply_time_ms: 2.786
    dispatch_time_ms: 6.337
    learner:
      cur_lr: 0.0010409860406070948
      grad_gnorm: 2.156574249267578
      policy_entropy: 99.75166320800781
      policy_loss: -1.1088625192642212
      var_gnorm: 58.39665222167969
      vf_explained_var: 0.0
      vf_loss: 0.0026260260492563248
    num_steps_sampled: 4800000
    num_steps_trained: 4800000
    wait_time_ms: 212.305
  iterations_since_restore: 480
  node_ip: 172.17.8.6
  num_metric_batches_dropped: 0
  pid: 13557
  policy_reward_mean: {}
  time_since_restore: 11815.100931167603
  time_this_iter_s: 25.87267231941223
  time_total_s: 11815.100931167603
  timestamp: 1594106648
  timesteps_since_restore: 4800000
  timesteps_this_iter: 10000
  timesteps_total: 4800000
  training_iteration: 480
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=13557], 11815 s, 480 iter, 4800000 ts, 1.11e+03 rew

agent-1: 134.0
agent-2: 101.0
agent-3: 135.0
agent-4: 120.0
agent-5: 109.0
agent-6: 127.0
agent-7: 109.0
agent-8: 120.0
agent-9: 127.0
agent-10: 96.0
Sum Reward: 1178.0
Avg Reward: 117.8
Min Reward: 96.0
Max Reward: 135.0
Gini Coefficient: 0.061629881154499154
20:20 Ratio: 1.365482233502538
Max-min Ratio: 1.40625
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_03-24-31
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1764.0
  episode_reward_mean: 1105.89
  episode_reward_min: 831.0
  episodes_this_iter: 1
  episodes_total: 480
  experiment_id: a3942a9886f24694ab1b58ca8d1ab856
  hostname: gpu006
  info:
    apply_time_ms: 2.615
    dispatch_time_ms: 6.431
    learner:
      cur_lr: 0.0010403200285509229
      grad_gnorm: 40.0
      policy_entropy: 63.60331726074219
      policy_loss: -2.0023529529571533
      var_gnorm: 58.43865966796875
      vf_explained_var: -0.04989302158355713
      vf_loss: 70.19182586669922
    num_steps_sampled: 4810000
    num_steps_trained: 4810000
    wait_time_ms: 254.544
  iterations_since_restore: 481
  node_ip: 172.17.8.6
  num_metric_batches_dropped: 0
  pid: 13557
  policy_reward_mean: {}
  time_since_restore: 11838.049133777618
  time_this_iter_s: 22.94820261001587
  time_total_s: 11838.049133777618
  timestamp: 1594106671
  timesteps_since_restore: 4810000
  timesteps_this_iter: 10000
  timesteps_total: 4810000
  training_iteration: 481
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=13557], 11838 s, 481 iter, 4810000 ts, 1.11e+03 rew

agent-1: 93.0
agent-2: 121.0
agent-3: 82.0
agent-4: 106.0
agent-5: 116.0
agent-6: 91.0
agent-7: 108.0
agent-8: 93.0
agent-9: 130.0
agent-10: 128.0
Sum Reward: 1068.0
Avg Reward: 106.8
Min Reward: 82.0
Max Reward: 130.0
Gini Coefficient: 0.08445692883895131
20:20 Ratio: 1.4913294797687862
Max-min Ratio: 1.5853658536585367
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_03-24-57
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1764.0
  episode_reward_mean: 1107.5
  episode_reward_min: 831.0
  episodes_this_iter: 1
  episodes_total: 481
  experiment_id: a3942a9886f24694ab1b58ca8d1ab856
  hostname: gpu006
  info:
    apply_time_ms: 2.664
    dispatch_time_ms: 5.425
    learner:
      cur_lr: 0.001039654016494751
      grad_gnorm: 1.225582480430603
      policy_entropy: 86.61541748046875
      policy_loss: 0.5332660675048828
      var_gnorm: 58.449798583984375
      vf_explained_var: 1.1920928955078125e-07
      vf_loss: 0.0008616741979494691
    num_steps_sampled: 4820000
    num_steps_trained: 4820000
    wait_time_ms: 242.281
  iterations_since_restore: 482
  node_ip: 172.17.8.6
  num_metric_batches_dropped: 0
  pid: 13557
  policy_reward_mean: {}
  time_since_restore: 11864.20731806755
  time_this_iter_s: 26.15818428993225
  time_total_s: 11864.20731806755
  timestamp: 1594106697
  timesteps_since_restore: 4820000
  timesteps_this_iter: 10000
  timesteps_total: 4820000
  training_iteration: 482
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=13557], 11864 s, 482 iter, 4820000 ts, 1.11e+03 rew

agent-1: 99.0
agent-2: 98.0
agent-3: 97.0
agent-4: 103.0
agent-5: 93.0
agent-6: 107.0
agent-7: 106.0
agent-8: 107.0
agent-9: 114.0
agent-10: 96.0
Sum Reward: 1020.0
Avg Reward: 102.0
Min Reward: 93.0
Max Reward: 114.0
Gini Coefficient: 0.03372549019607843
20:20 Ratio: 1.1693121693121693
Max-min Ratio: 1.2258064516129032
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_03-25-19
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1764.0
  episode_reward_mean: 1107.59
  episode_reward_min: 831.0
  episodes_this_iter: 1
  episodes_total: 482
  experiment_id: a3942a9886f24694ab1b58ca8d1ab856
  hostname: gpu006
  info:
    apply_time_ms: 2.539
    dispatch_time_ms: 6.493
    learner:
      cur_lr: 0.001038988004438579
      grad_gnorm: 40.00000762939453
      policy_entropy: 62.035186767578125
      policy_loss: 21.426799774169922
      var_gnorm: 58.461578369140625
      vf_explained_var: 0.9481748938560486
      vf_loss: 83.8909683227539
    num_steps_sampled: 4830000
    num_steps_trained: 4830000
    wait_time_ms: 238.719
  iterations_since_restore: 483
  node_ip: 172.17.8.6
  num_metric_batches_dropped: 0
  pid: 13557
  policy_reward_mean: {}
  time_since_restore: 11886.084712982178
  time_this_iter_s: 21.877394914627075
  time_total_s: 11886.084712982178
  timestamp: 1594106719
  timesteps_since_restore: 4830000
  timesteps_this_iter: 10000
  timesteps_total: 4830000
  training_iteration: 483
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=13557], 11886 s, 483 iter, 4830000 ts, 1.11e+03 rew

agent-1: 105.0
agent-2: 124.0
agent-3: 126.0
agent-4: 120.0
agent-5: 128.0
agent-6: 125.0
agent-7: 116.0
agent-8: 106.0
agent-9: 124.0
agent-10: 111.0
Sum Reward: 1185.0
Avg Reward: 118.5
Min Reward: 105.0
Max Reward: 128.0
Gini Coefficient: 0.03755274261603375
20:20 Ratio: 1.2037914691943128
Max-min Ratio: 1.2190476190476192
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_03-25-45
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1764.0
  episode_reward_mean: 1106.04
  episode_reward_min: 831.0
  episodes_this_iter: 1
  episodes_total: 483
  experiment_id: a3942a9886f24694ab1b58ca8d1ab856
  hostname: gpu006
  info:
    apply_time_ms: 2.937
    dispatch_time_ms: 5.908
    learner:
      cur_lr: 0.0010383219923824072
      grad_gnorm: 40.0
      policy_entropy: 34.82783126831055
      policy_loss: 6.9702558517456055
      var_gnorm: 58.527278900146484
      vf_explained_var: 0.6436465978622437
      vf_loss: 218.7373046875
    num_steps_sampled: 4840000
    num_steps_trained: 4840000
    wait_time_ms: 232.315
  iterations_since_restore: 484
  node_ip: 172.17.8.6
  num_metric_batches_dropped: 0
  pid: 13557
  policy_reward_mean: {}
  time_since_restore: 11912.52113866806
  time_this_iter_s: 26.43642568588257
  time_total_s: 11912.52113866806
  timestamp: 1594106745
  timesteps_since_restore: 4840000
  timesteps_this_iter: 10000
  timesteps_total: 4840000
  training_iteration: 484
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=13557], 11912 s, 484 iter, 4840000 ts, 1.11e+03 rew

agent-1: 98.0
agent-2: 128.0
agent-3: 133.0
agent-4: 120.0
agent-5: 130.0
agent-6: 133.0
agent-7: 113.0
agent-8: 74.0
agent-9: 110.0
agent-10: 138.0
Sum Reward: 1177.0
Avg Reward: 117.7
Min Reward: 74.0
Max Reward: 138.0
Gini Coefficient: 0.08453695836873407
20:20 Ratio: 1.5755813953488371
Max-min Ratio: 1.864864864864865
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_03-26-08
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1764.0
  episode_reward_mean: 1108.56
  episode_reward_min: 831.0
  episodes_this_iter: 1
  episodes_total: 484
  experiment_id: a3942a9886f24694ab1b58ca8d1ab856
  hostname: gpu006
  info:
    apply_time_ms: 3.683
    dispatch_time_ms: 6.805
    learner:
      cur_lr: 0.0010376559803262353
      grad_gnorm: 40.000003814697266
      policy_entropy: 20.473583221435547
      policy_loss: 6.380930423736572
      var_gnorm: 58.50542449951172
      vf_explained_var: 0.3167744278907776
      vf_loss: 104.96569061279297
    num_steps_sampled: 4850000
    num_steps_trained: 4850000
    wait_time_ms: 243.408
  iterations_since_restore: 485
  node_ip: 172.17.8.6
  num_metric_batches_dropped: 0
  pid: 13557
  policy_reward_mean: {}
  time_since_restore: 11935.260990858078
  time_this_iter_s: 22.7398521900177
  time_total_s: 11935.260990858078
  timestamp: 1594106768
  timesteps_since_restore: 4850000
  timesteps_this_iter: 10000
  timesteps_total: 4850000
  training_iteration: 485
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=13557], 11935 s, 485 iter, 4850000 ts, 1.11e+03 rew

agent-1: 113.0
agent-2: 120.0
agent-3: 125.0
agent-4: 111.0
agent-5: 117.0
agent-6: 97.0
agent-7: 107.0
agent-8: 113.0
agent-9: 120.0
agent-10: 96.0
Sum Reward: 1119.0
Avg Reward: 111.9
Min Reward: 96.0
Max Reward: 125.0
Gini Coefficient: 0.0451295799821269
20:20 Ratio: 1.2694300518134716
Max-min Ratio: 1.3020833333333333
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_03-26-34
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1764.0
  episode_reward_mean: 1111.02
  episode_reward_min: 831.0
  episodes_this_iter: 1
  episodes_total: 485
  experiment_id: a3942a9886f24694ab1b58ca8d1ab856
  hostname: gpu006
  info:
    apply_time_ms: 2.661
    dispatch_time_ms: 8.307
    learner:
      cur_lr: 0.0010369899682700634
      grad_gnorm: 10.25574016571045
      policy_entropy: 103.77469635009766
      policy_loss: -2.985090494155884
      var_gnorm: 58.5469970703125
      vf_explained_var: -1.0
      vf_loss: 0.6941248774528503
    num_steps_sampled: 4860000
    num_steps_trained: 4860000
    wait_time_ms: 254.166
  iterations_since_restore: 486
  node_ip: 172.17.8.6
  num_metric_batches_dropped: 0
  pid: 13557
  policy_reward_mean: {}
  time_since_restore: 11961.636106014252
  time_this_iter_s: 26.375115156173706
  time_total_s: 11961.636106014252
  timestamp: 1594106794
  timesteps_since_restore: 4860000
  timesteps_this_iter: 10000
  timesteps_total: 4860000
  training_iteration: 486
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=13557], 11961 s, 486 iter, 4860000 ts, 1.11e+03 rew

agent-1: 102.0
agent-2: 110.0
agent-3: 105.0
agent-4: 103.0
agent-5: 120.0
agent-6: 106.0
agent-7: 104.0
agent-8: 123.0
agent-9: 120.0
agent-10: 141.0
Sum Reward: 1134.0
Avg Reward: 113.4
Min Reward: 102.0
Max Reward: 141.0
Gini Coefficient: 0.054673721340388004
20:20 Ratio: 1.2878048780487805
Max-min Ratio: 1.3823529411764706
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_03-26-59
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1764.0
  episode_reward_mean: 1110.79
  episode_reward_min: 831.0
  episodes_this_iter: 1
  episodes_total: 486
  experiment_id: a3942a9886f24694ab1b58ca8d1ab856
  hostname: gpu006
  info:
    apply_time_ms: 2.658
    dispatch_time_ms: 7.178
    learner:
      cur_lr: 0.0010363239562138915
      grad_gnorm: 11.074570655822754
      policy_entropy: 88.32080078125
      policy_loss: -1.5789462327957153
      var_gnorm: 58.58591079711914
      vf_explained_var: -0.9656904935836792
      vf_loss: 2.567828416824341
    num_steps_sampled: 4870000
    num_steps_trained: 4870000
    wait_time_ms: 253.485
  iterations_since_restore: 487
  node_ip: 172.17.8.6
  num_metric_batches_dropped: 0
  pid: 13557
  policy_reward_mean: {}
  time_since_restore: 11985.736072540283
  time_this_iter_s: 24.099966526031494
  time_total_s: 11985.736072540283
  timestamp: 1594106819
  timesteps_since_restore: 4870000
  timesteps_this_iter: 10000
  timesteps_total: 4870000
  training_iteration: 487
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=13557], 11985 s, 487 iter, 4870000 ts, 1.11e+03 rew

agent-1: 116.0
agent-2: 91.0
agent-3: 73.0
agent-4: 95.0
agent-5: 87.0
agent-6: 88.0
agent-7: 94.0
agent-8: 84.0
agent-9: 85.0
agent-10: 83.0
Sum Reward: 896.0
Avg Reward: 89.6
Min Reward: 73.0
Max Reward: 116.0
Gini Coefficient: 0.060267857142857144
20:20 Ratio: 1.3525641025641026
Max-min Ratio: 1.5890410958904109
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_03-27-25
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1764.0
  episode_reward_mean: 1109.77
  episode_reward_min: 831.0
  episodes_this_iter: 1
  episodes_total: 487
  experiment_id: a3942a9886f24694ab1b58ca8d1ab856
  hostname: gpu006
  info:
    apply_time_ms: 2.648
    dispatch_time_ms: 5.659
    learner:
      cur_lr: 0.0010356579441577196
      grad_gnorm: 40.0
      policy_entropy: 36.28105545043945
      policy_loss: 95.7513427734375
      var_gnorm: 58.61511993408203
      vf_explained_var: 0.2086825966835022
      vf_loss: 330.0565185546875
    num_steps_sampled: 4880000
    num_steps_trained: 4880000
    wait_time_ms: 237.564
  iterations_since_restore: 488
  node_ip: 172.17.8.6
  num_metric_batches_dropped: 0
  pid: 13557
  policy_reward_mean: {}
  time_since_restore: 12012.078132152557
  time_this_iter_s: 26.34205961227417
  time_total_s: 12012.078132152557
  timestamp: 1594106845
  timesteps_since_restore: 4880000
  timesteps_this_iter: 10000
  timesteps_total: 4880000
  training_iteration: 488
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=13557], 12012 s, 488 iter, 4880000 ts, 1.11e+03 rew

agent-1: 101.0
agent-2: 101.0
agent-3: 82.0
agent-4: 111.0
agent-5: 85.0
agent-6: 90.0
agent-7: 85.0
agent-8: 82.0
agent-9: 88.0
agent-10: 87.0
Sum Reward: 912.0
Avg Reward: 91.2
Min Reward: 82.0
Max Reward: 111.0
Gini Coefficient: 0.0537280701754386
20:20 Ratio: 1.2926829268292683
Max-min Ratio: 1.353658536585366
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_03-27-49
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1764.0
  episode_reward_mean: 1107.19
  episode_reward_min: 831.0
  episodes_this_iter: 1
  episodes_total: 488
  experiment_id: a3942a9886f24694ab1b58ca8d1ab856
  hostname: gpu006
  info:
    apply_time_ms: 2.894
    dispatch_time_ms: 6.026
    learner:
      cur_lr: 0.0010349920485168695
      grad_gnorm: 23.856599807739258
      policy_entropy: 77.85423278808594
      policy_loss: -4.301598072052002
      var_gnorm: 58.69326400756836
      vf_explained_var: -1.0
      vf_loss: 0.5633824467658997
    num_steps_sampled: 4890000
    num_steps_trained: 4890000
    wait_time_ms: 255.346
  iterations_since_restore: 489
  node_ip: 172.17.8.6
  num_metric_batches_dropped: 0
  pid: 13557
  policy_reward_mean: {}
  time_since_restore: 12035.74069738388
  time_this_iter_s: 23.662565231323242
  time_total_s: 12035.74069738388
  timestamp: 1594106869
  timesteps_since_restore: 4890000
  timesteps_this_iter: 10000
  timesteps_total: 4890000
  training_iteration: 489
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=13557], 12035 s, 489 iter, 4890000 ts, 1.11e+03 rew

agent-1: 94.0
agent-2: 106.0
agent-3: 76.0
agent-4: 86.0
agent-5: 86.0
agent-6: 87.0
agent-7: 92.0
agent-8: 89.0
agent-9: 89.0
agent-10: 95.0
Sum Reward: 900.0
Avg Reward: 90.0
Min Reward: 76.0
Max Reward: 106.0
Gini Coefficient: 0.043111111111111114
20:20 Ratio: 1.2407407407407407
Max-min Ratio: 1.394736842105263
agent-1: 100.0
agent-2: 99.0
agent-3: 87.0
agent-4: 94.0
agent-5: 91.0
agent-6: 98.0
agent-7: 100.0
agent-8: 83.0
agent-9: 75.0
agent-10: 73.0
Sum Reward: 900.0
Avg Reward: 90.0
Min Reward: 73.0
Max Reward: 100.0
Gini Coefficient: 0.059333333333333335
20:20 Ratio: 1.3513513513513513
Max-min Ratio: 1.36986301369863
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_03-28-15
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1764.0
  episode_reward_mean: 1105.15
  episode_reward_min: 831.0
  episodes_this_iter: 2
  episodes_total: 490
  experiment_id: a3942a9886f24694ab1b58ca8d1ab856
  hostname: gpu006
  info:
    apply_time_ms: 2.92
    dispatch_time_ms: 7.52
    learner:
      cur_lr: 0.0010343260364606977
      grad_gnorm: 2.608981132507324
      policy_entropy: 94.50732421875
      policy_loss: -0.760212779045105
      var_gnorm: 58.70661163330078
      vf_explained_var: -1.0
      vf_loss: 0.0031789708882570267
    num_steps_sampled: 4900000
    num_steps_trained: 4900000
    wait_time_ms: 252.452
  iterations_since_restore: 490
  node_ip: 172.17.8.6
  num_metric_batches_dropped: 0
  pid: 13557
  policy_reward_mean: {}
  time_since_restore: 12062.18769788742
  time_this_iter_s: 26.44700050354004
  time_total_s: 12062.18769788742
  timestamp: 1594106895
  timesteps_since_restore: 4900000
  timesteps_this_iter: 10000
  timesteps_total: 4900000
  training_iteration: 490
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=13557], 12062 s, 490 iter, 4900000 ts, 1.11e+03 rew

Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_03-28-39
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1764.0
  episode_reward_mean: 1105.15
  episode_reward_min: 831.0
  episodes_this_iter: 0
  episodes_total: 490
  experiment_id: a3942a9886f24694ab1b58ca8d1ab856
  hostname: gpu006
  info:
    apply_time_ms: 2.766
    dispatch_time_ms: 5.268
    learner:
      cur_lr: 0.0010336600244045258
      grad_gnorm: 40.00001907348633
      policy_entropy: 58.157257080078125
      policy_loss: 3.0939407348632812
      var_gnorm: 58.74130630493164
      vf_explained_var: -0.049442172050476074
      vf_loss: 28.051856994628906
    num_steps_sampled: 4910000
    num_steps_trained: 4910000
    wait_time_ms: 259.657
  iterations_since_restore: 491
  node_ip: 172.17.8.6
  num_metric_batches_dropped: 0
  pid: 13557
  policy_reward_mean: {}
  time_since_restore: 12085.814623594284
  time_this_iter_s: 23.626925706863403
  time_total_s: 12085.814623594284
  timestamp: 1594106919
  timesteps_since_restore: 4910000
  timesteps_this_iter: 10000
  timesteps_total: 4910000
  training_iteration: 491
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=13557], 12085 s, 491 iter, 4910000 ts, 1.11e+03 rew

agent-1: 118.0
agent-2: 107.0
agent-3: 83.0
agent-4: 105.0
agent-5: 106.0
agent-6: 77.0
agent-7: 82.0
agent-8: 77.0
agent-9: 100.0
agent-10: 89.0
Sum Reward: 944.0
Avg Reward: 94.4
Min Reward: 77.0
Max Reward: 118.0
Gini Coefficient: 0.08220338983050847
20:20 Ratio: 1.4610389610389611
Max-min Ratio: 1.5324675324675325
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_03-29-05
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1764.0
  episode_reward_mean: 1104.55
  episode_reward_min: 831.0
  episodes_this_iter: 1
  episodes_total: 491
  experiment_id: a3942a9886f24694ab1b58ca8d1ab856
  hostname: gpu006
  info:
    apply_time_ms: 2.824
    dispatch_time_ms: 5.766
    learner:
      cur_lr: 0.0010329940123483539
      grad_gnorm: 0.2270340919494629
      policy_entropy: 82.64046478271484
      policy_loss: -0.07149281352758408
      var_gnorm: 58.791664123535156
      vf_explained_var: 0.0
      vf_loss: 7.414180345222121e-06
    num_steps_sampled: 4920000
    num_steps_trained: 4920000
    wait_time_ms: 257.577
  iterations_since_restore: 492
  node_ip: 172.17.8.6
  num_metric_batches_dropped: 0
  pid: 13557
  policy_reward_mean: {}
  time_since_restore: 12112.240553379059
  time_this_iter_s: 26.42592978477478
  time_total_s: 12112.240553379059
  timestamp: 1594106945
  timesteps_since_restore: 4920000
  timesteps_this_iter: 10000
  timesteps_total: 4920000
  training_iteration: 492
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=13557], 12112 s, 492 iter, 4920000 ts, 1.1e+03 rew

agent-1: 101.0
agent-2: 77.0
agent-3: 97.0
agent-4: 79.0
agent-5: 91.0
agent-6: 92.0
agent-7: 90.0
agent-8: 80.0
agent-9: 71.0
agent-10: 97.0
Sum Reward: 875.0
Avg Reward: 87.5
Min Reward: 71.0
Max Reward: 101.0
Gini Coefficient: 0.06137142857142857
20:20 Ratio: 1.337837837837838
Max-min Ratio: 1.4225352112676057
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_03-29-29
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1764.0
  episode_reward_mean: 1103.85
  episode_reward_min: 831.0
  episodes_this_iter: 1
  episodes_total: 492
  experiment_id: a3942a9886f24694ab1b58ca8d1ab856
  hostname: gpu006
  info:
    apply_time_ms: 2.66
    dispatch_time_ms: 6.557
    learner:
      cur_lr: 0.001032328000292182
      grad_gnorm: 25.53127098083496
      policy_entropy: 92.19091033935547
      policy_loss: -7.855710029602051
      var_gnorm: 58.85451126098633
      vf_explained_var: -1.0
      vf_loss: 0.4882734417915344
    num_steps_sampled: 4930000
    num_steps_trained: 4930000
    wait_time_ms: 248.744
  iterations_since_restore: 493
  node_ip: 172.17.8.6
  num_metric_batches_dropped: 0
  pid: 13557
  policy_reward_mean: {}
  time_since_restore: 12135.613940954208
  time_this_iter_s: 23.373387575149536
  time_total_s: 12135.613940954208
  timestamp: 1594106969
  timesteps_since_restore: 4930000
  timesteps_this_iter: 10000
  timesteps_total: 4930000
  training_iteration: 493
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=13557], 12135 s, 493 iter, 4930000 ts, 1.1e+03 rew

agent-1: 87.0
agent-2: 110.0
agent-3: 91.0
agent-4: 85.0
agent-5: 70.0
agent-6: 92.0
agent-7: 111.0
agent-8: 112.0
agent-9: 86.0
agent-10: 82.0
Sum Reward: 926.0
Avg Reward: 92.6
Min Reward: 70.0
Max Reward: 112.0
Gini Coefficient: 0.07861771058315335
20:20 Ratio: 1.4671052631578947
Max-min Ratio: 1.6
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_03-29-55
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1764.0
  episode_reward_mean: 1103.7
  episode_reward_min: 831.0
  episodes_this_iter: 1
  episodes_total: 493
  experiment_id: a3942a9886f24694ab1b58ca8d1ab856
  hostname: gpu006
  info:
    apply_time_ms: 2.605
    dispatch_time_ms: 6.879
    learner:
      cur_lr: 0.00103166198823601
      grad_gnorm: 5.1890106201171875
      policy_entropy: 98.74003601074219
      policy_loss: 1.2253471612930298
      var_gnorm: 58.896263122558594
      vf_explained_var: 0.7337720990180969
      vf_loss: 0.1075136587023735
    num_steps_sampled: 4940000
    num_steps_trained: 4940000
    wait_time_ms: 253.333
  iterations_since_restore: 494
  node_ip: 172.17.8.6
  num_metric_batches_dropped: 0
  pid: 13557
  policy_reward_mean: {}
  time_since_restore: 12161.986052513123
  time_this_iter_s: 26.372111558914185
  time_total_s: 12161.986052513123
  timestamp: 1594106995
  timesteps_since_restore: 4940000
  timesteps_this_iter: 10000
  timesteps_total: 4940000
  training_iteration: 494
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=13557], 12161 s, 494 iter, 4940000 ts, 1.1e+03 rew

agent-1: 89.0
agent-2: 125.0
agent-3: 121.0
agent-4: 100.0
agent-5: 134.0
agent-6: 101.0
agent-7: 92.0
agent-8: 100.0
agent-9: 104.0
agent-10: 89.0
Sum Reward: 1055.0
Avg Reward: 105.5
Min Reward: 89.0
Max Reward: 134.0
Gini Coefficient: 0.07725118483412323
20:20 Ratio: 1.4550561797752808
Max-min Ratio: 1.5056179775280898
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_03-30-18
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1764.0
  episode_reward_mean: 1102.98
  episode_reward_min: 831.0
  episodes_this_iter: 1
  episodes_total: 494
  experiment_id: a3942a9886f24694ab1b58ca8d1ab856
  hostname: gpu006
  info:
    apply_time_ms: 2.842
    dispatch_time_ms: 6.24
    learner:
      cur_lr: 0.0010309959761798382
      grad_gnorm: 39.99999237060547
      policy_entropy: 57.7527961730957
      policy_loss: 23.482025146484375
      var_gnorm: 58.93352508544922
      vf_explained_var: 0.7979810237884521
      vf_loss: 84.592529296875
    num_steps_sampled: 4950000
    num_steps_trained: 4950000
    wait_time_ms: 251.483
  iterations_since_restore: 495
  node_ip: 172.17.8.6
  num_metric_batches_dropped: 0
  pid: 13557
  policy_reward_mean: {}
  time_since_restore: 12185.193578958511
  time_this_iter_s: 23.207526445388794
  time_total_s: 12185.193578958511
  timestamp: 1594107018
  timesteps_since_restore: 4950000
  timesteps_this_iter: 10000
  timesteps_total: 4950000
  training_iteration: 495
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=13557], 12185 s, 495 iter, 4950000 ts, 1.1e+03 rew

agent-1: 120.0
agent-2: 95.0
agent-3: 93.0
agent-4: 100.0
agent-5: 92.0
agent-6: 105.0
agent-7: 90.0
agent-8: 82.0
agent-9: 91.0
agent-10: 75.0
Sum Reward: 943.0
Avg Reward: 94.3
Min Reward: 75.0
Max Reward: 120.0
Gini Coefficient: 0.06670201484623542
20:20 Ratio: 1.4331210191082802
Max-min Ratio: 1.6
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_03-30-45
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1764.0
  episode_reward_mean: 1102.5
  episode_reward_min: 831.0
  episodes_this_iter: 1
  episodes_total: 495
  experiment_id: a3942a9886f24694ab1b58ca8d1ab856
  hostname: gpu006
  info:
    apply_time_ms: 3.622
    dispatch_time_ms: 8.474
    learner:
      cur_lr: 0.0010303299641236663
      grad_gnorm: 40.0
      policy_entropy: 26.44130516052246
      policy_loss: 27.428970336914062
      var_gnorm: 58.94898986816406
      vf_explained_var: 0.5068799257278442
      vf_loss: 75.21533966064453
    num_steps_sampled: 4960000
    num_steps_trained: 4960000
    wait_time_ms: 213.117
  iterations_since_restore: 496
  node_ip: 172.17.8.6
  num_metric_batches_dropped: 0
  pid: 13557
  policy_reward_mean: {}
  time_since_restore: 12211.55474805832
  time_this_iter_s: 26.36116909980774
  time_total_s: 12211.55474805832
  timestamp: 1594107045
  timesteps_since_restore: 4960000
  timesteps_this_iter: 10000
  timesteps_total: 4960000
  training_iteration: 496
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=13557], 12211 s, 496 iter, 4960000 ts, 1.1e+03 rew

agent-1: 120.0
agent-2: 99.0
agent-3: 114.0
agent-4: 106.0
agent-5: 102.0
agent-6: 96.0
agent-7: 116.0
agent-8: 81.0
agent-9: 113.0
agent-10: 96.0
Sum Reward: 1043.0
Avg Reward: 104.3
Min Reward: 81.0
Max Reward: 120.0
Gini Coefficient: 0.060115052732502394
20:20 Ratio: 1.3333333333333333
Max-min Ratio: 1.4814814814814814
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_03-31-08
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1764.0
  episode_reward_mean: 1101.67
  episode_reward_min: 831.0
  episodes_this_iter: 1
  episodes_total: 496
  experiment_id: a3942a9886f24694ab1b58ca8d1ab856
  hostname: gpu006
  info:
    apply_time_ms: 3.328
    dispatch_time_ms: 6.899
    learner:
      cur_lr: 0.0010296639520674944
      grad_gnorm: 40.0
      policy_entropy: 57.41738510131836
      policy_loss: 36.81782913208008
      var_gnorm: 58.88348388671875
      vf_explained_var: 0.7459453344345093
      vf_loss: 121.85938262939453
    num_steps_sampled: 4970000
    num_steps_trained: 4970000
    wait_time_ms: 252.001
  iterations_since_restore: 497
  node_ip: 172.17.8.6
  num_metric_batches_dropped: 0
  pid: 13557
  policy_reward_mean: {}
  time_since_restore: 12234.81367301941
  time_this_iter_s: 23.258924961090088
  time_total_s: 12234.81367301941
  timestamp: 1594107068
  timesteps_since_restore: 4970000
  timesteps_this_iter: 10000
  timesteps_total: 4970000
  training_iteration: 497
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=13557], 12234 s, 497 iter, 4970000 ts, 1.1e+03 rew

agent-1: 115.0
agent-2: 83.0
agent-3: 76.0
agent-4: 112.0
agent-5: 104.0
agent-6: 112.0
agent-7: 119.0
agent-8: 83.0
agent-9: 104.0
agent-10: 127.0
Sum Reward: 1035.0
Avg Reward: 103.5
Min Reward: 76.0
Max Reward: 127.0
Gini Coefficient: 0.08724637681159421
20:20 Ratio: 1.5471698113207548
Max-min Ratio: 1.6710526315789473
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_03-31-35
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1764.0
  episode_reward_mean: 1102.13
  episode_reward_min: 831.0
  episodes_this_iter: 1
  episodes_total: 497
  experiment_id: a3942a9886f24694ab1b58ca8d1ab856
  hostname: gpu006
  info:
    apply_time_ms: 3.537
    dispatch_time_ms: 5.092
    learner:
      cur_lr: 0.0010289980564266443
      grad_gnorm: 0.20017558336257935
      policy_entropy: 106.73484802246094
      policy_loss: 0.23370207846164703
      var_gnorm: 58.91753005981445
      vf_explained_var: 0.0
      vf_loss: 2.1741345790360356e-06
    num_steps_sampled: 4980000
    num_steps_trained: 4980000
    wait_time_ms: 216.715
  iterations_since_restore: 498
  node_ip: 172.17.8.6
  num_metric_batches_dropped: 0
  pid: 13557
  policy_reward_mean: {}
  time_since_restore: 12261.204527139664
  time_this_iter_s: 26.390854120254517
  time_total_s: 12261.204527139664
  timestamp: 1594107095
  timesteps_since_restore: 4980000
  timesteps_this_iter: 10000
  timesteps_total: 4980000
  training_iteration: 498
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=13557], 12261 s, 498 iter, 4980000 ts, 1.1e+03 rew

agent-1: 81.0
agent-2: 69.0
agent-3: 63.0
agent-4: 89.0
agent-5: 92.0
agent-6: 95.0
agent-7: 96.0
agent-8: 89.0
agent-9: 80.0
agent-10: 103.0
Sum Reward: 857.0
Avg Reward: 85.7
Min Reward: 63.0
Max Reward: 103.0
Gini Coefficient: 0.07666277712952159
20:20 Ratio: 1.5075757575757576
Max-min Ratio: 1.6349206349206349
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_03-31-58
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1764.0
  episode_reward_mean: 1100.01
  episode_reward_min: 831.0
  episodes_this_iter: 1
  episodes_total: 498
  experiment_id: a3942a9886f24694ab1b58ca8d1ab856
  hostname: gpu006
  info:
    apply_time_ms: 2.69
    dispatch_time_ms: 6.619
    learner:
      cur_lr: 0.0010283320443704724
      grad_gnorm: 39.99999237060547
      policy_entropy: 80.15384674072266
      policy_loss: -3.502938985824585
      var_gnorm: 59.0723876953125
      vf_explained_var: -0.5543884038925171
      vf_loss: 20.252117156982422
    num_steps_sampled: 4990000
    num_steps_trained: 4990000
    wait_time_ms: 260.52
  iterations_since_restore: 499
  node_ip: 172.17.8.6
  num_metric_batches_dropped: 0
  pid: 13557
  policy_reward_mean: {}
  time_since_restore: 12285.029731273651
  time_this_iter_s: 23.825204133987427
  time_total_s: 12285.029731273651
  timestamp: 1594107118
  timesteps_since_restore: 4990000
  timesteps_this_iter: 10000
  timesteps_total: 4990000
  training_iteration: 499
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=13557], 12285 s, 499 iter, 4990000 ts, 1.1e+03 rew

agent-1: 76.0
agent-2: 70.0
agent-3: 73.0
agent-4: 69.0
agent-5: 63.0
agent-6: 74.0
agent-7: 71.0
agent-8: 73.0
agent-9: 81.0
agent-10: 76.0
Sum Reward: 726.0
Avg Reward: 72.6
Min Reward: 63.0
Max Reward: 81.0
Gini Coefficient: 0.03443526170798898
20:20 Ratio: 1.1893939393939394
Max-min Ratio: 1.2857142857142858
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_03-32-25
  done: true
  episode_len_mean: 1000.0
  episode_reward_max: 1764.0
  episode_reward_mean: 1095.23
  episode_reward_min: 726.0
  episodes_this_iter: 1
  episodes_total: 499
  experiment_id: a3942a9886f24694ab1b58ca8d1ab856
  hostname: gpu006
  info:
    apply_time_ms: 2.743
    dispatch_time_ms: 6.939
    learner:
      cur_lr: 0.0010276660323143005
      grad_gnorm: 40.0
      policy_entropy: 19.878767013549805
      policy_loss: 46.826988220214844
      var_gnorm: 59.085723876953125
      vf_explained_var: 0.06097811460494995
      vf_loss: 167.2606201171875
    num_steps_sampled: 5000000
    num_steps_trained: 5000000
    wait_time_ms: 222.026
  iterations_since_restore: 500
  node_ip: 172.17.8.6
  num_metric_batches_dropped: 0
  pid: 13557
  policy_reward_mean: {}
  time_since_restore: 12311.321038246155
  time_this_iter_s: 26.291306972503662
  time_total_s: 12311.321038246155
  timestamp: 1594107145
  timesteps_since_restore: 5000000
  timesteps_this_iter: 10000
  timesteps_total: 5000000
  training_iteration: 500
  
W0707 03:32:27.125977 13553 client_connection.cc:255] [worker]ProcessMessage with type 7 took 1798 ms.
W0707 03:32:27.146386 13553 node_manager.cc:250] Last heartbeat was sent 1915 ms ago 
/h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/numpy/core/fromnumeric.py:3335: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/numpy/core/_methods.py:161: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)
[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.[0m
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 0.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
TERMINATED trials:
 - A3C_harvest_env_0:	TERMINATED [pid=13557], 12311 s, 500 iter, 5000000 ts, 1.1e+03 rew

== Status ==
Using FIFO scheduling algorithm.
Resources requested: 0.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
TERMINATED trials:
 - A3C_harvest_env_0:	TERMINATED [pid=13557], 12311 s, 500 iter, 5000000 ts, 1.1e+03 rew

Commencing experiment harvest_A3C
WARNING: Logging before InitGoogleLogging() is written to STDERR
E0707 03:32:28.117565 13575 raylet_client.cc:345] IOError: [RayletClient] Connection closed unexpectedly. [RayletClient] Failed to push profile events.
WARNING: Logging before InitGoogleLogging() is written to STDERR
E0707 03:32:28.206111 13581 raylet_client.cc:345] IOError: [RayletClient] Connection closed unexpectedly. [RayletClient] Failed to push profile events.
