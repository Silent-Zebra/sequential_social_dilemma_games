/h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:523: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint8 = np.dtype([("qint8", np.int8, 1)])
/h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:524: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint8 = np.dtype([("quint8", np.uint8, 1)])
/h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint16 = np.dtype([("qint16", np.int16, 1)])
/h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint16 = np.dtype([("quint16", np.uint16, 1)])
/h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint32 = np.dtype([("qint32", np.int32, 1)])
/h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:532: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  np_resource = np.dtype([("resource", np.ubyte, 1)])
Process STDOUT and STDERR is being redirected to /tmp/ray/session_2020-07-03_16-56-16_745/logs.
Waiting for redis server at 127.0.0.1:64569 to respond...
Waiting for redis server at 127.0.0.1:58017 to respond...
Warning: Capping object memory store to 20.0GB. To increase this further, specify `object_store_memory` when calling ray.init() or ray start.
WARNING: The object store is using /tmp instead of /dev/shm because /dev/shm has only 4291010560 bytes available. This may slow down performance! You may be able to free up space by deleting files in /dev/shm or terminating any running plasma_store_server processes. If you are inside a Docker container, you may need to pass an argument with the flag '--shm-size' to 'docker run'.
Starting the Plasma object store with 20.0 GB memory using /tmp.

======================================================================
View the web UI at http://localhost:8889/notebooks/ray_ui.ipynb?token=e58ead2a389e7f81788db973bc53b00897df15f51034bcf1
======================================================================

== Status ==
Using FIFO scheduling algorithm.
Resources requested: 0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.2/202.5 GB

Created LogSyncer for /h/zhaostep/ray_results/harvest_A3C/A3C_harvest_env_0_2020-07-03_16-56-17gdd2xeae -> 
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING

/h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:523: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint8 = np.dtype([("qint8", np.int8, 1)])
/h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:524: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint8 = np.dtype([("quint8", np.uint8, 1)])
/h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint16 = np.dtype([("qint16", np.int16, 1)])
/h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint16 = np.dtype([("quint16", np.uint16, 1)])
/h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint32 = np.dtype([("qint32", np.int32, 1)])
/h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:532: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  np_resource = np.dtype([("resource", np.ubyte, 1)])
2020-07-03 16:56:29,420	INFO policy_evaluator.py:262 -- Creating policy evaluation worker 0 on CPU (please ignore any CUDA init errors)
2020-07-03 16:56:29.421032: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
From /h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/ray/rllib/models/lstm.py:59: BasicLSTMCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.
Instructions for updating:
This class is deprecated, please use tf.nn.rnn_cell.LSTMCell, which supports all the feature this cell currently has. Please replace the existing code with tf.nn.rnn_cell.LSTMCell(name='basic_lstm_cell').
/h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:523: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint8 = np.dtype([("qint8", np.int8, 1)])
/h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:524: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint8 = np.dtype([("quint8", np.uint8, 1)])
/h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint16 = np.dtype([("qint16", np.int16, 1)])
/h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint16 = np.dtype([("quint16", np.uint16, 1)])
/h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint32 = np.dtype([("qint32", np.int32, 1)])
/h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:532: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  np_resource = np.dtype([("resource", np.ubyte, 1)])
2020-07-03 16:56:40,909	INFO policy_evaluator.py:262 -- Creating policy evaluation worker 2 on CPU (please ignore any CUDA init errors)
2020-07-03 16:56:40.910445: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
/h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:523: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint8 = np.dtype([("qint8", np.int8, 1)])
/h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:524: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint8 = np.dtype([("quint8", np.uint8, 1)])
/h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint16 = np.dtype([("qint16", np.int16, 1)])
/h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint16 = np.dtype([("quint16", np.uint16, 1)])
/h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint32 = np.dtype([("qint32", np.int32, 1)])
/h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:532: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  np_resource = np.dtype([("resource", np.ubyte, 1)])
2020-07-03 16:56:40,918	INFO policy_evaluator.py:262 -- Creating policy evaluation worker 1 on CPU (please ignore any CUDA init errors)
2020-07-03 16:56:40.920060: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
From /h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/ray/rllib/models/lstm.py:59: BasicLSTMCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.
Instructions for updating:
This class is deprecated, please use tf.nn.rnn_cell.LSTMCell, which supports all the feature this cell currently has. Please replace the existing code with tf.nn.rnn_cell.LSTMCell(name='basic_lstm_cell').
From /h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/ray/rllib/models/lstm.py:59: BasicLSTMCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.
Instructions for updating:
This class is deprecated, please use tf.nn.rnn_cell.LSTMCell, which supports all the feature this cell currently has. Please replace the existing code with tf.nn.rnn_cell.LSTMCell(name='basic_lstm_cell').
W0703 16:57:00.862355   825 task_dependency_manager.cc:259] Task lease to renew has already expired by -3660ms
W0703 16:57:00.862704   825 task_dependency_manager.cc:259] Task lease to renew has already expired by -3661ms
W0703 16:57:00.862742   825 task_dependency_manager.cc:259] Task lease to renew has already expired by -3629ms
W0703 16:57:00.862778   825 task_dependency_manager.cc:259] Task lease to renew has already expired by -3628ms
W0703 16:57:00.962970   825 node_manager.cc:250] Last heartbeat was sent 13664 ms ago 
W0703 16:57:01.957175   825 node_manager.cc:250] Last heartbeat was sent 994 ms ago 
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_16-57-06
  done: false
  episode_len_mean: .nan
  episode_reward_max: .nan
  episode_reward_mean: .nan
  episode_reward_min: .nan
  episodes_this_iter: 0
  episodes_total: 0
  experiment_id: f3470259fa9143609a5dd5049ba7f979
  hostname: gpu020
  info:
    apply_time_ms: 3.299
    dispatch_time_ms: 7.24
    learner:
      cur_lr: 0.0013599999947473407
      grad_gnorm: 40.00000762939453
      policy_entropy: 64.71604919433594
      policy_loss: 22.749431610107422
      var_gnorm: 18.066741943359375
      vf_explained_var: -0.00794363021850586
      vf_loss: 35.371482849121094
    num_steps_sampled: 5000
    num_steps_trained: 5000
    wait_time_ms: 80.489
  iterations_since_restore: 1
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 830
  policy_reward_mean: {}
  time_since_restore: 35.81660985946655
  time_this_iter_s: 35.81660985946655
  time_total_s: 35.81660985946655
  timestamp: 1593809826
  timesteps_since_restore: 5000
  timesteps_this_iter: 5000
  timesteps_total: 5000
  training_iteration: 1
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 27.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=830], 35 s, 1 iter, 5000 ts, nan rew

[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.[0m
agent-1: -58.0
agent-2: 43.0
agent-3: -179.0
agent-4: -17.0
agent-5: -15.0
Sum Reward: -226.0
Avg Reward: -45.2
Min Reward: -179.0
Gini Coefficient -0.8619469026548673
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_16-57-16
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -226.0
  episode_reward_mean: -226.0
  episode_reward_min: -226.0
  episodes_this_iter: 1
  episodes_total: 1
  experiment_id: f3470259fa9143609a5dd5049ba7f979
  hostname: gpu020
  info:
    apply_time_ms: 2.736
    dispatch_time_ms: 6.32
    learner:
      cur_lr: 0.0013596670469269156
      grad_gnorm: 40.000003814697266
      policy_entropy: 75.97867584228516
      policy_loss: 69.54296875
      var_gnorm: 18.13729476928711
      vf_explained_var: 0.5271005630493164
      vf_loss: 55.82802963256836
    num_steps_sampled: 10000
    num_steps_trained: 10000
    wait_time_ms: 84.215
  iterations_since_restore: 2
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 830
  policy_reward_mean: {}
  time_since_restore: 45.49802017211914
  time_this_iter_s: 9.681410312652588
  time_total_s: 45.49802017211914
  timestamp: 1593809836
  timesteps_since_restore: 10000
  timesteps_this_iter: 5000
  timesteps_total: 10000
  training_iteration: 2
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=830], 45 s, 2 iter, 10000 ts, -226 rew

[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.[0m
agent-1: -28.0
agent-2: -170.0
agent-3: 30.0
agent-4: -14.0
agent-5: -99.0
Sum Reward: -281.0
Avg Reward: -56.2
Min Reward: -170.0
Gini Coefficient -0.6903914590747331
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_16-57-25
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -226.0
  episode_reward_mean: -253.5
  episode_reward_min: -281.0
  episodes_this_iter: 1
  episodes_total: 2
  experiment_id: f3470259fa9143609a5dd5049ba7f979
  hostname: gpu020
  info:
    apply_time_ms: 3.164
    dispatch_time_ms: 6.401
    learner:
      cur_lr: 0.0013593339826911688
      grad_gnorm: 29.22709846496582
      policy_entropy: 74.6390609741211
      policy_loss: 11.881474494934082
      var_gnorm: 18.3483943939209
      vf_explained_var: 0.013546407222747803
      vf_loss: 11.540017127990723
    num_steps_sampled: 15000
    num_steps_trained: 15000
    wait_time_ms: 88.256
  iterations_since_restore: 3
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 830
  policy_reward_mean: {}
  time_since_restore: 55.10664892196655
  time_this_iter_s: 9.608628749847412
  time_total_s: 55.10664892196655
  timestamp: 1593809845
  timesteps_since_restore: 15000
  timesteps_this_iter: 5000
  timesteps_total: 15000
  training_iteration: 3
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=830], 55 s, 3 iter, 15000 ts, -254 rew

agent-1: 142.0
agent-2: 118.0
agent-3: 82.0
agent-4: 110.0
agent-5: 76.0
Sum Reward: 528.0
Avg Reward: 105.6
Min Reward: 76.0
Gini Coefficient 0.12727272727272726
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_16-57-35
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 528.0
  episode_reward_mean: 7.0
  episode_reward_min: -281.0
  episodes_this_iter: 1
  episodes_total: 3
  experiment_id: f3470259fa9143609a5dd5049ba7f979
  hostname: gpu020
  info:
    apply_time_ms: 3.977
    dispatch_time_ms: 6.578
    learner:
      cur_lr: 0.0013590010348707438
      grad_gnorm: 39.99998092651367
      policy_entropy: 71.75242614746094
      policy_loss: 47.465782165527344
      var_gnorm: 18.58641242980957
      vf_explained_var: 0.0772828459739685
      vf_loss: 50.3806037902832
    num_steps_sampled: 20000
    num_steps_trained: 20000
    wait_time_ms: 90.133
  iterations_since_restore: 4
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 830
  policy_reward_mean: {}
  time_since_restore: 65.18435502052307
  time_this_iter_s: 10.077706098556519
  time_total_s: 65.18435502052307
  timestamp: 1593809855
  timesteps_since_restore: 20000
  timesteps_this_iter: 5000
  timesteps_total: 20000
  training_iteration: 4
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 9.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=830], 65 s, 4 iter, 20000 ts, 7 rew

agent-1: 100.0
agent-2: 114.0
agent-3: 66.0
agent-4: 170.0
agent-5: 115.0
Sum Reward: 565.0
Avg Reward: 113.0
Min Reward: 66.0
Gini Coefficient 0.15787610619469025
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_16-57-46
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 565.0
  episode_reward_mean: 146.5
  episode_reward_min: -281.0
  episodes_this_iter: 1
  episodes_total: 4
  experiment_id: f3470259fa9143609a5dd5049ba7f979
  hostname: gpu020
  info:
    apply_time_ms: 3.418
    dispatch_time_ms: 8.849
    learner:
      cur_lr: 0.0013586679706349969
      grad_gnorm: 38.79970932006836
      policy_entropy: 71.55052185058594
      policy_loss: -1.437254786491394
      var_gnorm: 19.01446533203125
      vf_explained_var: 0.848903238773346
      vf_loss: 5.785329818725586
    num_steps_sampled: 25000
    num_steps_trained: 25000
    wait_time_ms: 93.955
  iterations_since_restore: 5
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 830
  policy_reward_mean: {}
  time_since_restore: 75.24951100349426
  time_this_iter_s: 10.065155982971191
  time_total_s: 75.24951100349426
  timestamp: 1593809866
  timesteps_since_restore: 25000
  timesteps_this_iter: 5000
  timesteps_total: 25000
  training_iteration: 5
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 9.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=830], 75 s, 5 iter, 25000 ts, 146 rew

agent-1: 107.0
agent-2: 119.0
agent-3: 108.0
agent-4: 92.0
agent-5: 111.0
Sum Reward: 537.0
Avg Reward: 107.4
Min Reward: 92.0
Gini Coefficient 0.04320297951582868
agent-1: 125.0
agent-2: 71.0
agent-3: 0.0
agent-4: 88.0
agent-5: 105.0
Sum Reward: 389.0
Avg Reward: 77.8
Min Reward: 0.0
Gini Coefficient 0.29203084832904885
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_16-57-57
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 565.0
  episode_reward_mean: 252.0
  episode_reward_min: -281.0
  episodes_this_iter: 2
  episodes_total: 6
  experiment_id: f3470259fa9143609a5dd5049ba7f979
  hostname: gpu020
  info:
    apply_time_ms: 3.149
    dispatch_time_ms: 9.116
    learner:
      cur_lr: 0.0013583350228145719
      grad_gnorm: 39.999996185302734
      policy_entropy: 66.8939437866211
      policy_loss: -657.8384399414062
      var_gnorm: 19.566184997558594
      vf_explained_var: -0.0004101991653442383
      vf_loss: 9223.1845703125
    num_steps_sampled: 30000
    num_steps_trained: 30000
    wait_time_ms: 99.921
  iterations_since_restore: 6
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 830
  policy_reward_mean: {}
  time_since_restore: 86.49276661872864
  time_this_iter_s: 11.243255615234375
  time_total_s: 86.49276661872864
  timestamp: 1593809877
  timesteps_since_restore: 30000
  timesteps_this_iter: 5000
  timesteps_total: 30000
  training_iteration: 6
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 9.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=830], 86 s, 6 iter, 30000 ts, 252 rew

Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_16-58-06
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 565.0
  episode_reward_mean: 252.0
  episode_reward_min: -281.0
  episodes_this_iter: 0
  episodes_total: 6
  experiment_id: f3470259fa9143609a5dd5049ba7f979
  hostname: gpu020
  info:
    apply_time_ms: 2.514
    dispatch_time_ms: 11.838
    learner:
      cur_lr: 0.001358001958578825
      grad_gnorm: 40.0
      policy_entropy: 62.456573486328125
      policy_loss: -23.52451515197754
      var_gnorm: 19.705114364624023
      vf_explained_var: 0.1518421769142151
      vf_loss: 29.882596969604492
    num_steps_sampled: 35000
    num_steps_trained: 35000
    wait_time_ms: 88.078
  iterations_since_restore: 7
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 830
  policy_reward_mean: {}
  time_since_restore: 95.99074578285217
  time_this_iter_s: 9.497979164123535
  time_total_s: 95.99074578285217
  timestamp: 1593809886
  timesteps_since_restore: 35000
  timesteps_this_iter: 5000
  timesteps_total: 35000
  training_iteration: 7
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 9.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=830], 95 s, 7 iter, 35000 ts, 252 rew

agent-1: 92.0
agent-2: 81.0
agent-3: 121.0
agent-4: 41.0
agent-5: 128.0
Sum Reward: 463.0
Avg Reward: 92.6
Min Reward: 41.0
Gini Coefficient 0.18488120950323975
agent-1: 59.0
agent-2: 96.0
agent-3: 119.0
agent-4: 136.0
agent-5: 104.0
Sum Reward: 514.0
Avg Reward: 102.8
Min Reward: 59.0
Gini Coefficient 0.1377431906614786
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_16-58-18
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 565.0
  episode_reward_mean: 311.125
  episode_reward_min: -281.0
  episodes_this_iter: 2
  episodes_total: 8
  experiment_id: f3470259fa9143609a5dd5049ba7f979
  hostname: gpu020
  info:
    apply_time_ms: 2.674
    dispatch_time_ms: 11.477
    learner:
      cur_lr: 0.0013576690107584
      grad_gnorm: 39.99999237060547
      policy_entropy: 52.33091735839844
      policy_loss: -381.14111328125
      var_gnorm: 19.9018611907959
      vf_explained_var: -1.0
      vf_loss: 2062.062255859375
    num_steps_sampled: 40000
    num_steps_trained: 40000
    wait_time_ms: 100.359
  iterations_since_restore: 8
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 830
  policy_reward_mean: {}
  time_since_restore: 107.1495726108551
  time_this_iter_s: 11.15882682800293
  time_total_s: 107.1495726108551
  timestamp: 1593809898
  timesteps_since_restore: 40000
  timesteps_this_iter: 5000
  timesteps_total: 40000
  training_iteration: 8
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 9.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=830], 107 s, 8 iter, 40000 ts, 311 rew

Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_16-58-28
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 565.0
  episode_reward_mean: 311.125
  episode_reward_min: -281.0
  episodes_this_iter: 0
  episodes_total: 8
  experiment_id: f3470259fa9143609a5dd5049ba7f979
  hostname: gpu020
  info:
    apply_time_ms: 3.389
    dispatch_time_ms: 6.88
    learner:
      cur_lr: 0.001357335946522653
      grad_gnorm: 39.99999237060547
      policy_entropy: 56.23104476928711
      policy_loss: -16.719091415405273
      var_gnorm: 20.135351181030273
      vf_explained_var: 0.8377493619918823
      vf_loss: 12.883382797241211
    num_steps_sampled: 45000
    num_steps_trained: 45000
    wait_time_ms: 101.281
  iterations_since_restore: 9
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 830
  policy_reward_mean: {}
  time_since_restore: 117.58253312110901
  time_this_iter_s: 10.432960510253906
  time_total_s: 117.58253312110901
  timestamp: 1593809908
  timesteps_since_restore: 45000
  timesteps_this_iter: 5000
  timesteps_total: 45000
  training_iteration: 9
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 9.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=830], 117 s, 9 iter, 45000 ts, 311 rew

agent-1: 131.0
agent-2: 195.0
agent-3: 139.0
agent-4: 132.0
agent-5: 138.0
Sum Reward: 735.0
Avg Reward: 147.0
Min Reward: 131.0
Gini Coefficient 0.07346938775510205
agent-1: 108.0
agent-2: 180.0
agent-3: 133.0
agent-4: 136.0
agent-5: 148.0
Sum Reward: 705.0
Avg Reward: 141.0
Min Reward: 108.0
Gini Coefficient 0.0902127659574468
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_16-58-39
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 735.0
  episode_reward_mean: 392.9
  episode_reward_min: -281.0
  episodes_this_iter: 2
  episodes_total: 10
  experiment_id: f3470259fa9143609a5dd5049ba7f979
  hostname: gpu020
  info:
    apply_time_ms: 2.59
    dispatch_time_ms: 9.631
    learner:
      cur_lr: 0.001357002998702228
      grad_gnorm: 39.99999237060547
      policy_entropy: 50.84912109375
      policy_loss: -574.2388305664062
      var_gnorm: 20.29963493347168
      vf_explained_var: -1.0
      vf_loss: 2658.9248046875
    num_steps_sampled: 50000
    num_steps_trained: 50000
    wait_time_ms: 98.71
  iterations_since_restore: 10
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 830
  policy_reward_mean: {}
  time_since_restore: 128.55893516540527
  time_this_iter_s: 10.976402044296265
  time_total_s: 128.55893516540527
  timestamp: 1593809919
  timesteps_since_restore: 50000
  timesteps_this_iter: 5000
  timesteps_total: 50000
  training_iteration: 10
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 9.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=830], 128 s, 10 iter, 50000 ts, 393 rew

Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_16-58-50
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 735.0
  episode_reward_mean: 392.9
  episode_reward_min: -281.0
  episodes_this_iter: 0
  episodes_total: 10
  experiment_id: f3470259fa9143609a5dd5049ba7f979
  hostname: gpu020
  info:
    apply_time_ms: 3.288
    dispatch_time_ms: 6.333
    learner:
      cur_lr: 0.001356670050881803
      grad_gnorm: 40.0
      policy_entropy: 38.50398635864258
      policy_loss: -32.26811981201172
      var_gnorm: 20.652366638183594
      vf_explained_var: 0.7856663465499878
      vf_loss: 23.17552375793457
    num_steps_sampled: 55000
    num_steps_trained: 55000
    wait_time_ms: 110.926
  iterations_since_restore: 11
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 830
  policy_reward_mean: {}
  time_since_restore: 139.18110585212708
  time_this_iter_s: 10.622170686721802
  time_total_s: 139.18110585212708
  timestamp: 1593809930
  timesteps_since_restore: 55000
  timesteps_this_iter: 5000
  timesteps_total: 55000
  training_iteration: 11
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 9.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=830], 139 s, 11 iter, 55000 ts, 393 rew

agent-1: 95.0
agent-2: 179.0
agent-3: 118.0
agent-4: 81.0
agent-5: 148.0
Sum Reward: 621.0
Avg Reward: 124.2
Min Reward: 81.0
Gini Coefficient 0.1603864734299517
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_16-59-01
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 735.0
  episode_reward_mean: 413.6363636363636
  episode_reward_min: -281.0
  episodes_this_iter: 1
  episodes_total: 11
  experiment_id: f3470259fa9143609a5dd5049ba7f979
  hostname: gpu020
  info:
    apply_time_ms: 2.539
    dispatch_time_ms: 9.963
    learner:
      cur_lr: 0.0013563369866460562
      grad_gnorm: 40.000022888183594
      policy_entropy: 47.73244094848633
      policy_loss: -2.722614288330078
      var_gnorm: 21.215085983276367
      vf_explained_var: 0.4835340976715088
      vf_loss: 11.652098655700684
    num_steps_sampled: 60000
    num_steps_trained: 60000
    wait_time_ms: 89.083
  iterations_since_restore: 12
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 830
  policy_reward_mean: {}
  time_since_restore: 150.5036916732788
  time_this_iter_s: 11.322585821151733
  time_total_s: 150.5036916732788
  timestamp: 1593809941
  timesteps_since_restore: 60000
  timesteps_this_iter: 5000
  timesteps_total: 60000
  training_iteration: 12
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 9.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=830], 150 s, 12 iter, 60000 ts, 414 rew

agent-1: 105.0
agent-2: 82.0
agent-3: 86.0
agent-4: 148.0
agent-5: 116.0
Sum Reward: 537.0
Avg Reward: 107.4
Min Reward: 82.0
Gini Coefficient 0.12067039106145251
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_16-59-12
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 735.0
  episode_reward_mean: 423.9166666666667
  episode_reward_min: -281.0
  episodes_this_iter: 1
  episodes_total: 12
  experiment_id: f3470259fa9143609a5dd5049ba7f979
  hostname: gpu020
  info:
    apply_time_ms: 3.447
    dispatch_time_ms: 7.112
    learner:
      cur_lr: 0.0013560040388256311
      grad_gnorm: 40.00000762939453
      policy_entropy: 49.49689865112305
      policy_loss: -15.860108375549316
      var_gnorm: 21.590749740600586
      vf_explained_var: 0.5990350246429443
      vf_loss: 13.488350868225098
    num_steps_sampled: 65000
    num_steps_trained: 65000
    wait_time_ms: 109.936
  iterations_since_restore: 13
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 830
  policy_reward_mean: {}
  time_since_restore: 161.62453627586365
  time_this_iter_s: 11.120844602584839
  time_total_s: 161.62453627586365
  timestamp: 1593809952
  timesteps_since_restore: 65000
  timesteps_this_iter: 5000
  timesteps_total: 65000
  training_iteration: 13
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 9.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=830], 161 s, 13 iter, 65000 ts, 424 rew

agent-1: 68.0
agent-2: 78.0
agent-3: 81.0
agent-4: 82.0
agent-5: 77.0
Sum Reward: 386.0
Avg Reward: 77.2
Min Reward: 68.0
Gini Coefficient 0.03316062176165803
agent-1: 94.0
agent-2: 78.0
agent-3: 117.0
agent-4: 137.0
agent-5: 127.0
Sum Reward: 553.0
Avg Reward: 110.6
Min Reward: 78.0
Gini Coefficient 0.10922242314647378
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_16-59-25
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 735.0
  episode_reward_mean: 430.42857142857144
  episode_reward_min: -281.0
  episodes_this_iter: 2
  episodes_total: 14
  experiment_id: f3470259fa9143609a5dd5049ba7f979
  hostname: gpu020
  info:
    apply_time_ms: 2.664
    dispatch_time_ms: 9.874
    learner:
      cur_lr: 0.0013556709745898843
      grad_gnorm: 40.000003814697266
      policy_entropy: 58.68610763549805
      policy_loss: -46.58149719238281
      var_gnorm: 21.87522315979004
      vf_explained_var: -1.0
      vf_loss: 17.937602996826172
    num_steps_sampled: 70000
    num_steps_trained: 70000
    wait_time_ms: 111.479
  iterations_since_restore: 14
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 830
  policy_reward_mean: {}
  time_since_restore: 174.06556034088135
  time_this_iter_s: 12.4410240650177
  time_total_s: 174.06556034088135
  timestamp: 1593809965
  timesteps_since_restore: 70000
  timesteps_this_iter: 5000
  timesteps_total: 70000
  training_iteration: 14
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 9.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=830], 174 s, 14 iter, 70000 ts, 430 rew

Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_16-59-36
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 735.0
  episode_reward_mean: 430.42857142857144
  episode_reward_min: -281.0
  episodes_this_iter: 0
  episodes_total: 14
  experiment_id: f3470259fa9143609a5dd5049ba7f979
  hostname: gpu020
  info:
    apply_time_ms: 3.072
    dispatch_time_ms: 6.951
    learner:
      cur_lr: 0.0013553380267694592
      grad_gnorm: 40.000003814697266
      policy_entropy: 34.71744918823242
      policy_loss: -2.174053430557251
      var_gnorm: 22.120981216430664
      vf_explained_var: 0.47051918506622314
      vf_loss: 2.9237382411956787
    num_steps_sampled: 75000
    num_steps_trained: 75000
    wait_time_ms: 110.728
  iterations_since_restore: 15
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 830
  policy_reward_mean: {}
  time_since_restore: 184.95436573028564
  time_this_iter_s: 10.888805389404297
  time_total_s: 184.95436573028564
  timestamp: 1593809976
  timesteps_since_restore: 75000
  timesteps_this_iter: 5000
  timesteps_total: 75000
  training_iteration: 15
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 9.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=830], 184 s, 15 iter, 75000 ts, 430 rew

agent-1: 98.0
agent-2: 106.0
agent-3: 119.0
agent-4: 68.0
agent-5: 90.0
Sum Reward: 481.0
Avg Reward: 96.2
Min Reward: 68.0
Gini Coefficient 0.09812889812889813
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_16-59-48
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 735.0
  episode_reward_mean: 433.8
  episode_reward_min: -281.0
  episodes_this_iter: 1
  episodes_total: 15
  experiment_id: f3470259fa9143609a5dd5049ba7f979
  hostname: gpu020
  info:
    apply_time_ms: 2.785
    dispatch_time_ms: 6.368
    learner:
      cur_lr: 0.0013550049625337124
      grad_gnorm: 4.815959453582764
      policy_entropy: 41.02667999267578
      policy_loss: 1.7234705686569214
      var_gnorm: 22.360116958618164
      vf_explained_var: -0.007065176963806152
      vf_loss: 0.02834467403590679
    num_steps_sampled: 80000
    num_steps_trained: 80000
    wait_time_ms: 105.287
  iterations_since_restore: 16
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 830
  policy_reward_mean: {}
  time_since_restore: 197.34481477737427
  time_this_iter_s: 12.390449047088623
  time_total_s: 197.34481477737427
  timestamp: 1593809988
  timesteps_since_restore: 80000
  timesteps_this_iter: 5000
  timesteps_total: 80000
  training_iteration: 16
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 9.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=830], 197 s, 16 iter, 80000 ts, 434 rew

agent-1: 75.0
agent-2: 73.0
agent-3: 78.0
agent-4: 70.0
agent-5: 79.0
Sum Reward: 375.0
Avg Reward: 75.0
Min Reward: 70.0
Gini Coefficient 0.024533333333333334
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_16-59-59
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 735.0
  episode_reward_mean: 430.125
  episode_reward_min: -281.0
  episodes_this_iter: 1
  episodes_total: 16
  experiment_id: f3470259fa9143609a5dd5049ba7f979
  hostname: gpu020
  info:
    apply_time_ms: 2.913
    dispatch_time_ms: 9.605
    learner:
      cur_lr: 0.0013546720147132874
      grad_gnorm: 40.0
      policy_entropy: 37.45671081542969
      policy_loss: 0.9354759454727173
      var_gnorm: 22.50037384033203
      vf_explained_var: 0.8765662312507629
      vf_loss: 67.9004898071289
    num_steps_sampled: 85000
    num_steps_trained: 85000
    wait_time_ms: 104.586
  iterations_since_restore: 17
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 830
  policy_reward_mean: {}
  time_since_restore: 207.85946035385132
  time_this_iter_s: 10.51464557647705
  time_total_s: 207.85946035385132
  timestamp: 1593809999
  timesteps_since_restore: 85000
  timesteps_this_iter: 5000
  timesteps_total: 85000
  training_iteration: 17
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 9.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=830], 207 s, 17 iter, 85000 ts, 430 rew

agent-1: 62.0
agent-2: 96.0
agent-3: 121.0
agent-4: 121.0
agent-5: 107.0
Sum Reward: 507.0
Avg Reward: 101.4
Min Reward: 62.0
Gini Coefficient 0.11282051282051282
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_17-00-11
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 735.0
  episode_reward_mean: 434.6470588235294
  episode_reward_min: -281.0
  episodes_this_iter: 1
  episodes_total: 17
  experiment_id: f3470259fa9143609a5dd5049ba7f979
  hostname: gpu020
  info:
    apply_time_ms: 3.168
    dispatch_time_ms: 8.984
    learner:
      cur_lr: 0.0013543389504775405
      grad_gnorm: 22.9188289642334
      policy_entropy: 65.5489273071289
      policy_loss: -5.236173629760742
      var_gnorm: 22.750024795532227
      vf_explained_var: -0.6357046365737915
      vf_loss: 1.0559247732162476
    num_steps_sampled: 90000
    num_steps_trained: 90000
    wait_time_ms: 113.848
  iterations_since_restore: 18
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 830
  policy_reward_mean: {}
  time_since_restore: 219.9175374507904
  time_this_iter_s: 12.058077096939087
  time_total_s: 219.9175374507904
  timestamp: 1593810011
  timesteps_since_restore: 90000
  timesteps_this_iter: 5000
  timesteps_total: 90000
  training_iteration: 18
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 9.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=830], 219 s, 18 iter, 90000 ts, 435 rew

agent-1: 73.0
agent-2: 79.0
agent-3: 127.0
agent-4: 51.0
agent-5: 98.0
Sum Reward: 428.0
Avg Reward: 85.6
Min Reward: 51.0
Gini Coefficient 0.16542056074766356
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_17-00-22
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 735.0
  episode_reward_mean: 434.27777777777777
  episode_reward_min: -281.0
  episodes_this_iter: 1
  episodes_total: 18
  experiment_id: f3470259fa9143609a5dd5049ba7f979
  hostname: gpu020
  info:
    apply_time_ms: 3.412
    dispatch_time_ms: 7.827
    learner:
      cur_lr: 0.0013540060026571155
      grad_gnorm: 14.956927299499512
      policy_entropy: 61.382022857666016
      policy_loss: -1.9459151029586792
      var_gnorm: 22.94278335571289
      vf_explained_var: 0.9803745746612549
      vf_loss: 0.13942992687225342
    num_steps_sampled: 95000
    num_steps_trained: 95000
    wait_time_ms: 113.046
  iterations_since_restore: 19
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 830
  policy_reward_mean: {}
  time_since_restore: 231.28270483016968
  time_this_iter_s: 11.365167379379272
  time_total_s: 231.28270483016968
  timestamp: 1593810022
  timesteps_since_restore: 95000
  timesteps_this_iter: 5000
  timesteps_total: 95000
  training_iteration: 19
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 9.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=830], 231 s, 19 iter, 95000 ts, 434 rew

agent-1: 71.0
agent-2: 67.0
agent-3: 67.0
agent-4: 69.0
agent-5: 60.0
Sum Reward: 334.0
Avg Reward: 66.8
Min Reward: 60.0
Gini Coefficient 0.02874251497005988
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_17-00-34
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 735.0
  episode_reward_mean: 429.0
  episode_reward_min: -281.0
  episodes_this_iter: 1
  episodes_total: 19
  experiment_id: f3470259fa9143609a5dd5049ba7f979
  hostname: gpu020
  info:
    apply_time_ms: 3.555
    dispatch_time_ms: 8.059
    learner:
      cur_lr: 0.0013536730548366904
      grad_gnorm: 40.0
      policy_entropy: 15.426277160644531
      policy_loss: -8.415464401245117
      var_gnorm: 23.073705673217773
      vf_explained_var: -0.0497967004776001
      vf_loss: 23.729917526245117
    num_steps_sampled: 100000
    num_steps_trained: 100000
    wait_time_ms: 106.548
  iterations_since_restore: 20
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 830
  policy_reward_mean: {}
  time_since_restore: 243.58494997024536
  time_this_iter_s: 12.302245140075684
  time_total_s: 243.58494997024536
  timestamp: 1593810034
  timesteps_since_restore: 100000
  timesteps_this_iter: 5000
  timesteps_total: 100000
  training_iteration: 20
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 9.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=830], 243 s, 20 iter, 100000 ts, 429 rew

agent-1: 91.0
agent-2: 83.0
agent-3: 97.0
agent-4: 71.0
agent-5: 79.0
Sum Reward: 421.0
Avg Reward: 84.2
Min Reward: 71.0
Gini Coefficient 0.060807600950118765
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_17-00-45
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 735.0
  episode_reward_mean: 428.6
  episode_reward_min: -281.0
  episodes_this_iter: 1
  episodes_total: 20
  experiment_id: f3470259fa9143609a5dd5049ba7f979
  hostname: gpu020
  info:
    apply_time_ms: 3.445
    dispatch_time_ms: 6.543
    learner:
      cur_lr: 0.0013533399906009436
      grad_gnorm: 30.664234161376953
      policy_entropy: 70.35684967041016
      policy_loss: -9.548644065856934
      var_gnorm: 23.26503562927246
      vf_explained_var: -0.42640459537506104
      vf_loss: 0.8130157589912415
    num_steps_sampled: 105000
    num_steps_trained: 105000
    wait_time_ms: 110.096
  iterations_since_restore: 21
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 830
  policy_reward_mean: {}
  time_since_restore: 254.56460571289062
  time_this_iter_s: 10.979655742645264
  time_total_s: 254.56460571289062
  timestamp: 1593810045
  timesteps_since_restore: 105000
  timesteps_this_iter: 5000
  timesteps_total: 105000
  training_iteration: 21
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 9.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=830], 254 s, 21 iter, 105000 ts, 429 rew

agent-1: 100.0
agent-2: 88.0
agent-3: 124.0
agent-4: 91.0
agent-5: 86.0
Sum Reward: 489.0
Avg Reward: 97.8
Min Reward: 86.0
Gini Coefficient 0.0719836400817996
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_17-00-58
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 735.0
  episode_reward_mean: 431.4761904761905
  episode_reward_min: -281.0
  episodes_this_iter: 1
  episodes_total: 21
  experiment_id: f3470259fa9143609a5dd5049ba7f979
  hostname: gpu020
  info:
    apply_time_ms: 3.42
    dispatch_time_ms: 9.113
    learner:
      cur_lr: 0.0013530070427805185
      grad_gnorm: 39.999996185302734
      policy_entropy: 36.66263198852539
      policy_loss: -4.045097351074219
      var_gnorm: 23.40619468688965
      vf_explained_var: 0.24383771419525146
      vf_loss: 41.49843978881836
    num_steps_sampled: 110000
    num_steps_trained: 110000
    wait_time_ms: 104.383
  iterations_since_restore: 22
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 830
  policy_reward_mean: {}
  time_since_restore: 266.80547881126404
  time_this_iter_s: 12.240873098373413
  time_total_s: 266.80547881126404
  timestamp: 1593810058
  timesteps_since_restore: 110000
  timesteps_this_iter: 5000
  timesteps_total: 110000
  training_iteration: 22
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 9.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=830], 266 s, 22 iter, 110000 ts, 431 rew

agent-1: 99.0
agent-2: 65.0
agent-3: 95.0
agent-4: 97.0
agent-5: 108.0
Sum Reward: 464.0
Avg Reward: 92.8
Min Reward: 65.0
Gini Coefficient 0.07758620689655173
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_17-01-09
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 735.0
  episode_reward_mean: 432.95454545454544
  episode_reward_min: -281.0
  episodes_this_iter: 1
  episodes_total: 22
  experiment_id: f3470259fa9143609a5dd5049ba7f979
  hostname: gpu020
  info:
    apply_time_ms: 2.838
    dispatch_time_ms: 7.996
    learner:
      cur_lr: 0.0013526739785447717
      grad_gnorm: 40.000003814697266
      policy_entropy: 68.70601654052734
      policy_loss: 0.9333548545837402
      var_gnorm: 23.58129119873047
      vf_explained_var: 0.5168834924697876
      vf_loss: 5.758859634399414
    num_steps_sampled: 115000
    num_steps_trained: 115000
    wait_time_ms: 111.446
  iterations_since_restore: 23
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 830
  policy_reward_mean: {}
  time_since_restore: 278.19958209991455
  time_this_iter_s: 11.394103288650513
  time_total_s: 278.19958209991455
  timestamp: 1593810069
  timesteps_since_restore: 115000
  timesteps_this_iter: 5000
  timesteps_total: 115000
  training_iteration: 23
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 9.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=830], 278 s, 23 iter, 115000 ts, 433 rew

agent-1: 78.0
agent-2: 67.0
agent-3: 88.0
agent-4: 70.0
agent-5: 72.0
Sum Reward: 375.0
Avg Reward: 75.0
Min Reward: 67.0
Gini Coefficient 0.05333333333333334
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_17-01-21
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 735.0
  episode_reward_mean: 430.4347826086956
  episode_reward_min: -281.0
  episodes_this_iter: 1
  episodes_total: 23
  experiment_id: f3470259fa9143609a5dd5049ba7f979
  hostname: gpu020
  info:
    apply_time_ms: 2.915
    dispatch_time_ms: 6.839
    learner:
      cur_lr: 0.0013523410307243466
      grad_gnorm: 2.5988144874572754
      policy_entropy: 65.6762924194336
      policy_loss: -0.5978950262069702
      var_gnorm: 23.64386558532715
      vf_explained_var: -1.0
      vf_loss: 0.0465744212269783
    num_steps_sampled: 120000
    num_steps_trained: 120000
    wait_time_ms: 98.46
  iterations_since_restore: 24
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 830
  policy_reward_mean: {}
  time_since_restore: 290.40784788131714
  time_this_iter_s: 12.208265781402588
  time_total_s: 290.40784788131714
  timestamp: 1593810081
  timesteps_since_restore: 120000
  timesteps_this_iter: 5000
  timesteps_total: 120000
  training_iteration: 24
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 9.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=830], 290 s, 24 iter, 120000 ts, 430 rew

agent-1: 56.0
agent-2: 74.0
agent-3: 75.0
agent-4: 60.0
agent-5: 72.0
Sum Reward: 337.0
Avg Reward: 67.4
Min Reward: 56.0
Gini Coefficient 0.06172106824925816
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_17-01-33
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 735.0
  episode_reward_mean: 426.5416666666667
  episode_reward_min: -281.0
  episodes_this_iter: 1
  episodes_total: 24
  experiment_id: f3470259fa9143609a5dd5049ba7f979
  hostname: gpu020
  info:
    apply_time_ms: 3.786
    dispatch_time_ms: 6.624
    learner:
      cur_lr: 0.0013520079664885998
      grad_gnorm: 39.99999237060547
      policy_entropy: 29.021087646484375
      policy_loss: -85.1500244140625
      var_gnorm: 23.816913604736328
      vf_explained_var: -0.15007483959197998
      vf_loss: 499.8995056152344
    num_steps_sampled: 125000
    num_steps_trained: 125000
    wait_time_ms: 108.105
  iterations_since_restore: 25
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 830
  policy_reward_mean: {}
  time_since_restore: 301.7177243232727
  time_this_iter_s: 11.309876441955566
  time_total_s: 301.7177243232727
  timestamp: 1593810093
  timesteps_since_restore: 125000
  timesteps_this_iter: 5000
  timesteps_total: 125000
  training_iteration: 25
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 9.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=830], 301 s, 25 iter, 125000 ts, 427 rew

agent-1: 73.0
agent-2: 80.0
agent-3: 81.0
agent-4: 98.0
agent-5: 67.0
Sum Reward: 399.0
Avg Reward: 79.8
Min Reward: 67.0
Gini Coefficient 0.07017543859649122
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_17-01-45
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 735.0
  episode_reward_mean: 425.44
  episode_reward_min: -281.0
  episodes_this_iter: 1
  episodes_total: 25
  experiment_id: f3470259fa9143609a5dd5049ba7f979
  hostname: gpu020
  info:
    apply_time_ms: 3.954
    dispatch_time_ms: 9.153
    learner:
      cur_lr: 0.0013516750186681747
      grad_gnorm: 7.773380756378174
      policy_entropy: 67.93610382080078
      policy_loss: 1.4590588808059692
      var_gnorm: 23.954452514648438
      vf_explained_var: -0.7741413116455078
      vf_loss: 0.04359976574778557
    num_steps_sampled: 130000
    num_steps_trained: 130000
    wait_time_ms: 86.618
  iterations_since_restore: 26
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 830
  policy_reward_mean: {}
  time_since_restore: 313.855819940567
  time_this_iter_s: 12.138095617294312
  time_total_s: 313.855819940567
  timestamp: 1593810105
  timesteps_since_restore: 130000
  timesteps_this_iter: 5000
  timesteps_total: 130000
  training_iteration: 26
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 9.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=830], 313 s, 26 iter, 130000 ts, 425 rew

agent-1: 90.0
agent-2: 78.0
agent-3: 95.0
agent-4: 61.0
agent-5: 97.0
Sum Reward: 421.0
Avg Reward: 84.2
Min Reward: 61.0
Gini Coefficient 0.0845605700712589
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_17-01-56
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 735.0
  episode_reward_mean: 425.2692307692308
  episode_reward_min: -281.0
  episodes_this_iter: 1
  episodes_total: 26
  experiment_id: f3470259fa9143609a5dd5049ba7f979
  hostname: gpu020
  info:
    apply_time_ms: 2.647
    dispatch_time_ms: 7.775
    learner:
      cur_lr: 0.0013513419544324279
      grad_gnorm: 39.999996185302734
      policy_entropy: 63.25444030761719
      policy_loss: -17.097434997558594
      var_gnorm: 24.141592025756836
      vf_explained_var: 0.8949417471885681
      vf_loss: 2.090261936187744
    num_steps_sampled: 135000
    num_steps_trained: 135000
    wait_time_ms: 113.21
  iterations_since_restore: 27
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 830
  policy_reward_mean: {}
  time_since_restore: 325.155161857605
  time_this_iter_s: 11.299341917037964
  time_total_s: 325.155161857605
  timestamp: 1593810116
  timesteps_since_restore: 135000
  timesteps_this_iter: 5000
  timesteps_total: 135000
  training_iteration: 27
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 9.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=830], 325 s, 27 iter, 135000 ts, 425 rew

agent-1: 89.0
agent-2: 116.0
agent-3: 66.0
agent-4: 87.0
agent-5: 70.0
Sum Reward: 428.0
Avg Reward: 85.6
Min Reward: 66.0
Gini Coefficient 0.11121495327102804
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_17-02-08
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 735.0
  episode_reward_mean: 425.3703703703704
  episode_reward_min: -281.0
  episodes_this_iter: 1
  episodes_total: 27
  experiment_id: f3470259fa9143609a5dd5049ba7f979
  hostname: gpu020
  info:
    apply_time_ms: 2.824
    dispatch_time_ms: 9.033
    learner:
      cur_lr: 0.0013510090066120028
      grad_gnorm: 40.0
      policy_entropy: 37.13422393798828
      policy_loss: -27.84776496887207
      var_gnorm: 24.379356384277344
      vf_explained_var: -0.18158769607543945
      vf_loss: 29.920259475708008
    num_steps_sampled: 140000
    num_steps_trained: 140000
    wait_time_ms: 94.612
  iterations_since_restore: 28
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 830
  policy_reward_mean: {}
  time_since_restore: 337.30866718292236
  time_this_iter_s: 12.153505325317383
  time_total_s: 337.30866718292236
  timestamp: 1593810128
  timesteps_since_restore: 140000
  timesteps_this_iter: 5000
  timesteps_total: 140000
  training_iteration: 28
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 9.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=830], 337 s, 28 iter, 140000 ts, 425 rew

agent-1: 89.0
agent-2: 92.0
agent-3: 109.0
agent-4: 106.0
agent-5: 87.0
Sum Reward: 483.0
Avg Reward: 96.6
Min Reward: 87.0
Gini Coefficient 0.0505175983436853
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_17-02-19
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 735.0
  episode_reward_mean: 427.42857142857144
  episode_reward_min: -281.0
  episodes_this_iter: 1
  episodes_total: 28
  experiment_id: f3470259fa9143609a5dd5049ba7f979
  hostname: gpu020
  info:
    apply_time_ms: 3.943
    dispatch_time_ms: 9.428
    learner:
      cur_lr: 0.001350675942376256
      grad_gnorm: 40.0
      policy_entropy: 26.50269889831543
      policy_loss: -12.43200397491455
      var_gnorm: 24.592849731445312
      vf_explained_var: -0.2701147794723511
      vf_loss: 143.08404541015625
    num_steps_sampled: 145000
    num_steps_trained: 145000
    wait_time_ms: 105.705
  iterations_since_restore: 29
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 830
  policy_reward_mean: {}
  time_since_restore: 348.3409421443939
  time_this_iter_s: 11.032274961471558
  time_total_s: 348.3409421443939
  timestamp: 1593810139
  timesteps_since_restore: 145000
  timesteps_this_iter: 5000
  timesteps_total: 145000
  training_iteration: 29
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 9.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=830], 348 s, 29 iter, 145000 ts, 427 rew

agent-1: 105.0
agent-2: 98.0
agent-3: 91.0
agent-4: 94.0
agent-5: 82.0
Sum Reward: 470.0
Avg Reward: 94.0
Min Reward: 82.0
Gini Coefficient 0.0451063829787234
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_17-02-32
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 735.0
  episode_reward_mean: 428.8965517241379
  episode_reward_min: -281.0
  episodes_this_iter: 1
  episodes_total: 29
  experiment_id: f3470259fa9143609a5dd5049ba7f979
  hostname: gpu020
  info:
    apply_time_ms: 3.182
    dispatch_time_ms: 6.678
    learner:
      cur_lr: 0.001350342994555831
      grad_gnorm: 40.0
      policy_entropy: 33.265708923339844
      policy_loss: -2.5800395011901855
      var_gnorm: 24.89408302307129
      vf_explained_var: 0.8087617754936218
      vf_loss: 1.1708037853240967
    num_steps_sampled: 150000
    num_steps_trained: 150000
    wait_time_ms: 100.144
  iterations_since_restore: 30
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 830
  policy_reward_mean: {}
  time_since_restore: 360.47267508506775
  time_this_iter_s: 12.131732940673828
  time_total_s: 360.47267508506775
  timestamp: 1593810152
  timesteps_since_restore: 150000
  timesteps_this_iter: 5000
  timesteps_total: 150000
  training_iteration: 30
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 9.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=830], 360 s, 30 iter, 150000 ts, 429 rew

agent-1: 76.0
agent-2: 95.0
agent-3: 85.0
agent-4: 91.0
agent-5: 89.0
Sum Reward: 436.0
Avg Reward: 87.2
Min Reward: 76.0
Gini Coefficient 0.04036697247706422
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_17-02-43
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 735.0
  episode_reward_mean: 429.1333333333333
  episode_reward_min: -281.0
  episodes_this_iter: 1
  episodes_total: 30
  experiment_id: f3470259fa9143609a5dd5049ba7f979
  hostname: gpu020
  info:
    apply_time_ms: 2.804
    dispatch_time_ms: 6.596
    learner:
      cur_lr: 0.001350010046735406
      grad_gnorm: 40.000003814697266
      policy_entropy: 25.10713005065918
      policy_loss: 12.355063438415527
      var_gnorm: 25.083412170410156
      vf_explained_var: -0.07845616340637207
      vf_loss: 18.679683685302734
    num_steps_sampled: 155000
    num_steps_trained: 155000
    wait_time_ms: 114.944
  iterations_since_restore: 31
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 830
  policy_reward_mean: {}
  time_since_restore: 371.9016785621643
  time_this_iter_s: 11.429003477096558
  time_total_s: 371.9016785621643
  timestamp: 1593810163
  timesteps_since_restore: 155000
  timesteps_this_iter: 5000
  timesteps_total: 155000
  training_iteration: 31
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 9.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=830], 371 s, 31 iter, 155000 ts, 429 rew

agent-1: 70.0
agent-2: 84.0
agent-3: 57.0
agent-4: 83.0
agent-5: 76.0
Sum Reward: 370.0
Avg Reward: 74.0
Min Reward: 57.0
Gini Coefficient 0.07243243243243243
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_17-02-55
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 735.0
  episode_reward_mean: 427.2258064516129
  episode_reward_min: -281.0
  episodes_this_iter: 1
  episodes_total: 31
  experiment_id: f3470259fa9143609a5dd5049ba7f979
  hostname: gpu020
  info:
    apply_time_ms: 3.782
    dispatch_time_ms: 7.88
    learner:
      cur_lr: 0.001349676982499659
      grad_gnorm: 40.0
      policy_entropy: 39.61044692993164
      policy_loss: 4.971863746643066
      var_gnorm: 25.224885940551758
      vf_explained_var: -0.19300329685211182
      vf_loss: 25.92970848083496
    num_steps_sampled: 160000
    num_steps_trained: 160000
    wait_time_ms: 92.403
  iterations_since_restore: 32
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 830
  policy_reward_mean: {}
  time_since_restore: 384.0759062767029
  time_this_iter_s: 12.174227714538574
  time_total_s: 384.0759062767029
  timestamp: 1593810175
  timesteps_since_restore: 160000
  timesteps_this_iter: 5000
  timesteps_total: 160000
  training_iteration: 32
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 9.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=830], 384 s, 32 iter, 160000 ts, 427 rew

agent-1: 82.0
agent-2: 100.0
agent-3: 79.0
agent-4: 80.0
agent-5: 52.0
Sum Reward: 393.0
Avg Reward: 78.6
Min Reward: 52.0
Gini Coefficient 0.10076335877862595
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_17-03-07
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 735.0
  episode_reward_mean: 426.15625
  episode_reward_min: -281.0
  episodes_this_iter: 1
  episodes_total: 32
  experiment_id: f3470259fa9143609a5dd5049ba7f979
  hostname: gpu020
  info:
    apply_time_ms: 2.942
    dispatch_time_ms: 8.848
    learner:
      cur_lr: 0.001349344034679234
      grad_gnorm: 40.0
      policy_entropy: 31.823301315307617
      policy_loss: -0.986635684967041
      var_gnorm: 25.4473876953125
      vf_explained_var: 0.410871684551239
      vf_loss: 20.55803680419922
    num_steps_sampled: 165000
    num_steps_trained: 165000
    wait_time_ms: 111.383
  iterations_since_restore: 33
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 830
  policy_reward_mean: {}
  time_since_restore: 395.3171937465668
  time_this_iter_s: 11.241287469863892
  time_total_s: 395.3171937465668
  timestamp: 1593810187
  timesteps_since_restore: 165000
  timesteps_this_iter: 5000
  timesteps_total: 165000
  training_iteration: 33
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 9.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=830], 395 s, 33 iter, 165000 ts, 426 rew

agent-1: 101.0
agent-2: 64.0
agent-3: 80.0
agent-4: 117.0
agent-5: 72.0
Sum Reward: 434.0
Avg Reward: 86.8
Min Reward: 64.0
Gini Coefficient 0.12442396313364056
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_17-03-19
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 735.0
  episode_reward_mean: 426.3939393939394
  episode_reward_min: -281.0
  episodes_this_iter: 1
  episodes_total: 33
  experiment_id: f3470259fa9143609a5dd5049ba7f979
  hostname: gpu020
  info:
    apply_time_ms: 2.721
    dispatch_time_ms: 7.939
    learner:
      cur_lr: 0.0013490109704434872
      grad_gnorm: 2.1519975662231445
      policy_entropy: 49.91510009765625
      policy_loss: 1.002201795578003
      var_gnorm: 25.62511444091797
      vf_explained_var: -1.0
      vf_loss: 0.2840961813926697
    num_steps_sampled: 170000
    num_steps_trained: 170000
    wait_time_ms: 112.04
  iterations_since_restore: 34
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 830
  policy_reward_mean: {}
  time_since_restore: 407.506285905838
  time_this_iter_s: 12.18909215927124
  time_total_s: 407.506285905838
  timestamp: 1593810199
  timesteps_since_restore: 170000
  timesteps_this_iter: 5000
  timesteps_total: 170000
  training_iteration: 34
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 9.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=830], 407 s, 34 iter, 170000 ts, 426 rew

agent-1: 79.0
agent-2: 58.0
agent-3: 87.0
agent-4: 75.0
agent-5: 63.0
Sum Reward: 362.0
Avg Reward: 72.4
Min Reward: 58.0
Gini Coefficient 0.08176795580110498
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_17-03-30
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 735.0
  episode_reward_mean: 424.5
  episode_reward_min: -281.0
  episodes_this_iter: 1
  episodes_total: 34
  experiment_id: f3470259fa9143609a5dd5049ba7f979
  hostname: gpu020
  info:
    apply_time_ms: 3.089
    dispatch_time_ms: 9.928
    learner:
      cur_lr: 0.0013486780226230621
      grad_gnorm: 13.754216194152832
      policy_entropy: 35.330692291259766
      policy_loss: -3.693420886993408
      var_gnorm: 25.787900924682617
      vf_explained_var: 0.9895249605178833
      vf_loss: 0.23466861248016357
    num_steps_sampled: 175000
    num_steps_trained: 175000
    wait_time_ms: 109.537
  iterations_since_restore: 35
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 830
  policy_reward_mean: {}
  time_since_restore: 419.11310482025146
  time_this_iter_s: 11.606818914413452
  time_total_s: 419.11310482025146
  timestamp: 1593810210
  timesteps_since_restore: 175000
  timesteps_this_iter: 5000
  timesteps_total: 175000
  training_iteration: 35
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 9.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=830], 419 s, 35 iter, 175000 ts, 424 rew

agent-1: 68.0
agent-2: 96.0
agent-3: 47.0
agent-4: 62.0
agent-5: 69.0
Sum Reward: 342.0
Avg Reward: 68.4
Min Reward: 47.0
Gini Coefficient 0.12280701754385964
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_17-03-42
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 735.0
  episode_reward_mean: 422.14285714285717
  episode_reward_min: -281.0
  episodes_this_iter: 1
  episodes_total: 35
  experiment_id: f3470259fa9143609a5dd5049ba7f979
  hostname: gpu020
  info:
    apply_time_ms: 2.658
    dispatch_time_ms: 7.179
    learner:
      cur_lr: 0.0013483449583873153
      grad_gnorm: 1.50007164478302
      policy_entropy: 44.12500762939453
      policy_loss: -0.3502379059791565
      var_gnorm: 25.913053512573242
      vf_explained_var: 0.9943158626556396
      vf_loss: 0.00934501364827156
    num_steps_sampled: 180000
    num_steps_trained: 180000
    wait_time_ms: 94.432
  iterations_since_restore: 36
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 830
  policy_reward_mean: {}
  time_since_restore: 431.1139278411865
  time_this_iter_s: 12.000823020935059
  time_total_s: 431.1139278411865
  timestamp: 1593810222
  timesteps_since_restore: 180000
  timesteps_this_iter: 5000
  timesteps_total: 180000
  training_iteration: 36
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 9.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=830], 431 s, 36 iter, 180000 ts, 422 rew

agent-1: 99.0
agent-2: 94.0
agent-3: 84.0
agent-4: 65.0
agent-5: 90.0
Sum Reward: 432.0
Avg Reward: 86.4
Min Reward: 65.0
Gini Coefficient 0.07222222222222222
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_17-03-54
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 735.0
  episode_reward_mean: 422.4166666666667
  episode_reward_min: -281.0
  episodes_this_iter: 1
  episodes_total: 36
  experiment_id: f3470259fa9143609a5dd5049ba7f979
  hostname: gpu020
  info:
    apply_time_ms: 2.74
    dispatch_time_ms: 6.8
    learner:
      cur_lr: 0.0013480120105668902
      grad_gnorm: 40.0
      policy_entropy: 42.3878059387207
      policy_loss: -0.023605316877365112
      var_gnorm: 26.087265014648438
      vf_explained_var: 0.43735456466674805
      vf_loss: 13.57219123840332
    num_steps_sampled: 185000
    num_steps_trained: 185000
    wait_time_ms: 105.809
  iterations_since_restore: 37
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 830
  policy_reward_mean: {}
  time_since_restore: 442.5767824649811
  time_this_iter_s: 11.462854623794556
  time_total_s: 442.5767824649811
  timestamp: 1593810234
  timesteps_since_restore: 185000
  timesteps_this_iter: 5000
  timesteps_total: 185000
  training_iteration: 37
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 9.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=830], 442 s, 37 iter, 185000 ts, 422 rew

agent-1: 98.0
agent-2: 88.0
agent-3: 100.0
agent-4: 107.0
agent-5: 91.0
Sum Reward: 484.0
Avg Reward: 96.8
Min Reward: 88.0
Gini Coefficient 0.03884297520661157
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_17-04-06
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 735.0
  episode_reward_mean: 424.0810810810811
  episode_reward_min: -281.0
  episodes_this_iter: 1
  episodes_total: 37
  experiment_id: f3470259fa9143609a5dd5049ba7f979
  hostname: gpu020
  info:
    apply_time_ms: 2.706
    dispatch_time_ms: 8.799
    learner:
      cur_lr: 0.0013476789463311434
      grad_gnorm: 1.8749769926071167
      policy_entropy: 49.8023681640625
      policy_loss: 0.37853699922561646
      var_gnorm: 26.14774513244629
      vf_explained_var: 0.9188061952590942
      vf_loss: 0.004076818935573101
    num_steps_sampled: 190000
    num_steps_trained: 190000
    wait_time_ms: 95.89
  iterations_since_restore: 38
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 830
  policy_reward_mean: {}
  time_since_restore: 454.5126485824585
  time_this_iter_s: 11.935866117477417
  time_total_s: 454.5126485824585
  timestamp: 1593810246
  timesteps_since_restore: 190000
  timesteps_this_iter: 5000
  timesteps_total: 190000
  training_iteration: 38
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 9.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=830], 454 s, 38 iter, 190000 ts, 424 rew

agent-1: 82.0
agent-2: 98.0
agent-3: 83.0
agent-4: 69.0
agent-5: 92.0
Sum Reward: 424.0
Avg Reward: 84.8
Min Reward: 69.0
Gini Coefficient 0.06415094339622641
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_17-04-17
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 735.0
  episode_reward_mean: 424.07894736842104
  episode_reward_min: -281.0
  episodes_this_iter: 1
  episodes_total: 38
  experiment_id: f3470259fa9143609a5dd5049ba7f979
  hostname: gpu020
  info:
    apply_time_ms: 2.542
    dispatch_time_ms: 6.567
    learner:
      cur_lr: 0.0013473459985107183
      grad_gnorm: 25.893531799316406
      policy_entropy: 33.20109176635742
      policy_loss: -9.966567039489746
      var_gnorm: 26.254838943481445
      vf_explained_var: 0.25765150785446167
      vf_loss: 2.1854071617126465
    num_steps_sampled: 195000
    num_steps_trained: 195000
    wait_time_ms: 113.958
  iterations_since_restore: 39
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 830
  policy_reward_mean: {}
  time_since_restore: 466.014666557312
  time_this_iter_s: 11.502017974853516
  time_total_s: 466.014666557312
  timestamp: 1593810257
  timesteps_since_restore: 195000
  timesteps_this_iter: 5000
  timesteps_total: 195000
  training_iteration: 39
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 9.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=830], 466 s, 39 iter, 195000 ts, 424 rew

agent-1: 75.0
agent-2: 76.0
agent-3: 82.0
agent-4: 70.0
agent-5: 113.0
Sum Reward: 416.0
Avg Reward: 83.2
Min Reward: 70.0
Gini Coefficient 0.08942307692307692
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_17-04-30
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 735.0
  episode_reward_mean: 423.87179487179486
  episode_reward_min: -281.0
  episodes_this_iter: 1
  episodes_total: 39
  experiment_id: f3470259fa9143609a5dd5049ba7f979
  hostname: gpu020
  info:
    apply_time_ms: 2.496
    dispatch_time_ms: 6.899
    learner:
      cur_lr: 0.0013470130506902933
      grad_gnorm: 40.000003814697266
      policy_entropy: 25.50411033630371
      policy_loss: -10.339141845703125
      var_gnorm: 26.29180335998535
      vf_explained_var: 0.05158030986785889
      vf_loss: 15.627802848815918
    num_steps_sampled: 200000
    num_steps_trained: 200000
    wait_time_ms: 105.595
  iterations_since_restore: 40
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 830
  policy_reward_mean: {}
  time_since_restore: 478.160658121109
  time_this_iter_s: 12.145991563796997
  time_total_s: 478.160658121109
  timestamp: 1593810270
  timesteps_since_restore: 200000
  timesteps_this_iter: 5000
  timesteps_total: 200000
  training_iteration: 40
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 9.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=830], 478 s, 40 iter, 200000 ts, 424 rew

agent-1: 65.0
agent-2: 68.0
agent-3: 84.0
agent-4: 68.0
agent-5: 47.0
Sum Reward: 332.0
Avg Reward: 66.4
Min Reward: 47.0
Gini Coefficient 0.0927710843373494
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_17-04-41
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 735.0
  episode_reward_mean: 421.575
  episode_reward_min: -281.0
  episodes_this_iter: 1
  episodes_total: 40
  experiment_id: f3470259fa9143609a5dd5049ba7f979
  hostname: gpu020
  info:
    apply_time_ms: 2.753
    dispatch_time_ms: 6.189
    learner:
      cur_lr: 0.0013466799864545465
      grad_gnorm: 40.00000762939453
      policy_entropy: 21.858652114868164
      policy_loss: 49.366172790527344
      var_gnorm: 26.399229049682617
      vf_explained_var: -1.0
      vf_loss: 214.22389221191406
    num_steps_sampled: 205000
    num_steps_trained: 205000
    wait_time_ms: 112.571
  iterations_since_restore: 41
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 830
  policy_reward_mean: {}
  time_since_restore: 489.75678300857544
  time_this_iter_s: 11.59612488746643
  time_total_s: 489.75678300857544
  timestamp: 1593810281
  timesteps_since_restore: 205000
  timesteps_this_iter: 5000
  timesteps_total: 205000
  training_iteration: 41
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 9.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=830], 489 s, 41 iter, 205000 ts, 422 rew

agent-1: 54.0
agent-2: 73.0
agent-3: 79.0
agent-4: 66.0
agent-5: 47.0
Sum Reward: 319.0
Avg Reward: 63.8
Min Reward: 47.0
Gini Coefficient 0.10407523510971786
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_17-04-53
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 735.0
  episode_reward_mean: 419.0731707317073
  episode_reward_min: -281.0
  episodes_this_iter: 1
  episodes_total: 41
  experiment_id: f3470259fa9143609a5dd5049ba7f979
  hostname: gpu020
  info:
    apply_time_ms: 2.522
    dispatch_time_ms: 7.612
    learner:
      cur_lr: 0.0013463470386341214
      grad_gnorm: 39.99998474121094
      policy_entropy: 36.8004150390625
      policy_loss: 33.77189636230469
      var_gnorm: 26.472658157348633
      vf_explained_var: -1.0
      vf_loss: 50.28366470336914
    num_steps_sampled: 210000
    num_steps_trained: 210000
    wait_time_ms: 90.44
  iterations_since_restore: 42
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 830
  policy_reward_mean: {}
  time_since_restore: 501.74966049194336
  time_this_iter_s: 11.99287748336792
  time_total_s: 501.74966049194336
  timestamp: 1593810293
  timesteps_since_restore: 210000
  timesteps_this_iter: 5000
  timesteps_total: 210000
  training_iteration: 42
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 9.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=830], 501 s, 42 iter, 210000 ts, 419 rew

agent-1: 72.0
agent-2: 89.0
agent-3: 79.0
agent-4: 70.0
agent-5: 73.0
Sum Reward: 383.0
Avg Reward: 76.6
Min Reward: 70.0
Gini Coefficient 0.04699738903394256
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_17-05-05
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 735.0
  episode_reward_mean: 418.2142857142857
  episode_reward_min: -281.0
  episodes_this_iter: 1
  episodes_total: 42
  experiment_id: f3470259fa9143609a5dd5049ba7f979
  hostname: gpu020
  info:
    apply_time_ms: 2.799
    dispatch_time_ms: 6.378
    learner:
      cur_lr: 0.0013460139743983746
      grad_gnorm: 40.0
      policy_entropy: 19.696430206298828
      policy_loss: 1.4417262077331543
      var_gnorm: 26.68144416809082
      vf_explained_var: 0.5149843692779541
      vf_loss: 95.096923828125
    num_steps_sampled: 215000
    num_steps_trained: 215000
    wait_time_ms: 111.325
  iterations_since_restore: 43
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 830
  policy_reward_mean: {}
  time_since_restore: 513.4616458415985
  time_this_iter_s: 11.711985349655151
  time_total_s: 513.4616458415985
  timestamp: 1593810305
  timesteps_since_restore: 215000
  timesteps_this_iter: 5000
  timesteps_total: 215000
  training_iteration: 43
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 9.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=830], 513 s, 43 iter, 215000 ts, 418 rew

agent-1: 77.0
agent-2: 74.0
agent-3: 82.0
agent-4: 82.0
agent-5: 49.0
Sum Reward: 364.0
Avg Reward: 72.8
Min Reward: 49.0
Gini Coefficient 0.08131868131868132
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_17-05-17
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 735.0
  episode_reward_mean: 416.95348837209303
  episode_reward_min: -281.0
  episodes_this_iter: 1
  episodes_total: 43
  experiment_id: f3470259fa9143609a5dd5049ba7f979
  hostname: gpu020
  info:
    apply_time_ms: 3.185
    dispatch_time_ms: 8.341
    learner:
      cur_lr: 0.0013456810265779495
      grad_gnorm: 40.00000762939453
      policy_entropy: 14.80230712890625
      policy_loss: 17.960166931152344
      var_gnorm: 26.760393142700195
      vf_explained_var: -1.0
      vf_loss: 164.45428466796875
    num_steps_sampled: 220000
    num_steps_trained: 220000
    wait_time_ms: 107.526
  iterations_since_restore: 44
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 830
  policy_reward_mean: {}
  time_since_restore: 525.4161403179169
  time_this_iter_s: 11.95449447631836
  time_total_s: 525.4161403179169
  timestamp: 1593810317
  timesteps_since_restore: 220000
  timesteps_this_iter: 5000
  timesteps_total: 220000
  training_iteration: 44
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 9.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=830], 525 s, 44 iter, 220000 ts, 417 rew

agent-1: 79.0
agent-2: 76.0
agent-3: 108.0
agent-4: 77.0
agent-5: 82.0
Sum Reward: 422.0
Avg Reward: 84.4
Min Reward: 76.0
Gini Coefficient 0.06540284360189573
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_17-05-28
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 735.0
  episode_reward_mean: 417.0681818181818
  episode_reward_min: -281.0
  episodes_this_iter: 1
  episodes_total: 44
  experiment_id: f3470259fa9143609a5dd5049ba7f979
  hostname: gpu020
  info:
    apply_time_ms: 3.23
    dispatch_time_ms: 9.447
    learner:
      cur_lr: 0.0013453479623422027
      grad_gnorm: 23.738378524780273
      policy_entropy: 44.76634216308594
      policy_loss: -5.671693325042725
      var_gnorm: 26.878421783447266
      vf_explained_var: -1.0
      vf_loss: 2.2381560802459717
    num_steps_sampled: 225000
    num_steps_trained: 225000
    wait_time_ms: 109.379
  iterations_since_restore: 45
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 830
  policy_reward_mean: {}
  time_since_restore: 536.7899403572083
  time_this_iter_s: 11.373800039291382
  time_total_s: 536.7899403572083
  timestamp: 1593810328
  timesteps_since_restore: 225000
  timesteps_this_iter: 5000
  timesteps_total: 225000
  training_iteration: 45
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 9.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=830], 536 s, 45 iter, 225000 ts, 417 rew

agent-1: 112.0
agent-2: 105.0
agent-3: 108.0
agent-4: 101.0
agent-5: 82.0
Sum Reward: 508.0
Avg Reward: 101.6
Min Reward: 82.0
Gini Coefficient 0.05275590551181102
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_17-05-40
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 735.0
  episode_reward_mean: 419.0888888888889
  episode_reward_min: -281.0
  episodes_this_iter: 1
  episodes_total: 45
  experiment_id: f3470259fa9143609a5dd5049ba7f979
  hostname: gpu020
  info:
    apply_time_ms: 3.005
    dispatch_time_ms: 6.643
    learner:
      cur_lr: 0.0013450150145217776
      grad_gnorm: 22.644742965698242
      policy_entropy: 62.46989822387695
      policy_loss: 7.544206619262695
      var_gnorm: 26.990795135498047
      vf_explained_var: 0.7555010318756104
      vf_loss: 3.365384340286255
    num_steps_sampled: 230000
    num_steps_trained: 230000
    wait_time_ms: 102.41
  iterations_since_restore: 46
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 830
  policy_reward_mean: {}
  time_since_restore: 548.6043365001678
  time_this_iter_s: 11.814396142959595
  time_total_s: 548.6043365001678
  timestamp: 1593810340
  timesteps_since_restore: 230000
  timesteps_this_iter: 5000
  timesteps_total: 230000
  training_iteration: 46
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 9.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=830], 548 s, 46 iter, 230000 ts, 419 rew

agent-1: 107.0
agent-2: 84.0
agent-3: 65.0
agent-4: 88.0
agent-5: 99.0
Sum Reward: 443.0
Avg Reward: 88.6
Min Reward: 65.0
Gini Coefficient 0.08939051918735892
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_17-05-52
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 735.0
  episode_reward_mean: 419.60869565217394
  episode_reward_min: -281.0
  episodes_this_iter: 1
  episodes_total: 46
  experiment_id: f3470259fa9143609a5dd5049ba7f979
  hostname: gpu020
  info:
    apply_time_ms: 3.19
    dispatch_time_ms: 6.328
    learner:
      cur_lr: 0.0013446819502860308
      grad_gnorm: 40.00000762939453
      policy_entropy: 51.09479522705078
      policy_loss: 26.57906723022461
      var_gnorm: 27.123432159423828
      vf_explained_var: 0.7415512800216675
      vf_loss: 55.18582534790039
    num_steps_sampled: 235000
    num_steps_trained: 235000
    wait_time_ms: 108.403
  iterations_since_restore: 47
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 830
  policy_reward_mean: {}
  time_since_restore: 559.9223055839539
  time_this_iter_s: 11.31796908378601
  time_total_s: 559.9223055839539
  timestamp: 1593810352
  timesteps_since_restore: 235000
  timesteps_this_iter: 5000
  timesteps_total: 235000
  training_iteration: 47
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 9.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=830], 559 s, 47 iter, 235000 ts, 420 rew

agent-1: 121.0
agent-2: 109.0
agent-3: 115.0
agent-4: 91.0
agent-5: 104.0
Sum Reward: 540.0
Avg Reward: 108.0
Min Reward: 91.0
Gini Coefficient 0.052592592592592594
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_17-06-03
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 735.0
  episode_reward_mean: 422.17021276595744
  episode_reward_min: -281.0
  episodes_this_iter: 1
  episodes_total: 47
  experiment_id: f3470259fa9143609a5dd5049ba7f979
  hostname: gpu020
  info:
    apply_time_ms: 2.797
    dispatch_time_ms: 8.129
    learner:
      cur_lr: 0.0013443490024656057
      grad_gnorm: 40.0000114440918
      policy_entropy: 31.592653274536133
      policy_loss: -7.554636001586914
      var_gnorm: 27.296409606933594
      vf_explained_var: 0.8965898156166077
      vf_loss: 96.32955932617188
    num_steps_sampled: 240000
    num_steps_trained: 240000
    wait_time_ms: 105.383
  iterations_since_restore: 48
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 830
  policy_reward_mean: {}
  time_since_restore: 571.5812201499939
  time_this_iter_s: 11.658914566040039
  time_total_s: 571.5812201499939
  timestamp: 1593810363
  timesteps_since_restore: 240000
  timesteps_this_iter: 5000
  timesteps_total: 240000
  training_iteration: 48
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 9.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=830], 571 s, 48 iter, 240000 ts, 422 rew

agent-1: 126.0
agent-2: 116.0
agent-3: 105.0
agent-4: 93.0
agent-5: 78.0
Sum Reward: 518.0
Avg Reward: 103.6
Min Reward: 78.0
Gini Coefficient 0.0918918918918919
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_17-06-15
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 735.0
  episode_reward_mean: 424.1666666666667
  episode_reward_min: -281.0
  episodes_this_iter: 1
  episodes_total: 48
  experiment_id: f3470259fa9143609a5dd5049ba7f979
  hostname: gpu020
  info:
    apply_time_ms: 2.929
    dispatch_time_ms: 9.674
    learner:
      cur_lr: 0.0013440160546451807
      grad_gnorm: 19.178245544433594
      policy_entropy: 47.07603454589844
      policy_loss: 0.4582745432853699
      var_gnorm: 27.386829376220703
      vf_explained_var: 0.7085213661193848
      vf_loss: 3.7949798107147217
    num_steps_sampled: 245000
    num_steps_trained: 245000
    wait_time_ms: 111.278
  iterations_since_restore: 49
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 830
  policy_reward_mean: {}
  time_since_restore: 583.3937752246857
  time_this_iter_s: 11.812555074691772
  time_total_s: 583.3937752246857
  timestamp: 1593810375
  timesteps_since_restore: 245000
  timesteps_this_iter: 5000
  timesteps_total: 245000
  training_iteration: 49
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 9.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=830], 583 s, 49 iter, 245000 ts, 424 rew

agent-1: 73.0
agent-2: 77.0
agent-3: 57.0
agent-4: 80.0
agent-5: 33.0
Sum Reward: 320.0
Avg Reward: 64.0
Min Reward: 33.0
Gini Coefficient 0.1425
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_17-06-27
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 735.0
  episode_reward_mean: 422.0408163265306
  episode_reward_min: -281.0
  episodes_this_iter: 1
  episodes_total: 49
  experiment_id: f3470259fa9143609a5dd5049ba7f979
  hostname: gpu020
  info:
    apply_time_ms: 2.959
    dispatch_time_ms: 6.613
    learner:
      cur_lr: 0.0013436829904094338
      grad_gnorm: 39.999996185302734
      policy_entropy: 14.546099662780762
      policy_loss: 2.9983904361724854
      var_gnorm: 27.435646057128906
      vf_explained_var: 0.6792292594909668
      vf_loss: 69.18618774414062
    num_steps_sampled: 250000
    num_steps_trained: 250000
    wait_time_ms: 111.126
  iterations_since_restore: 50
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 830
  policy_reward_mean: {}
  time_since_restore: 595.366480588913
  time_this_iter_s: 11.972705364227295
  time_total_s: 595.366480588913
  timestamp: 1593810387
  timesteps_since_restore: 250000
  timesteps_this_iter: 5000
  timesteps_total: 250000
  training_iteration: 50
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 9.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=830], 595 s, 50 iter, 250000 ts, 422 rew

agent-1: 58.0
agent-2: 64.0
agent-3: 71.0
agent-4: 62.0
agent-5: 58.0
Sum Reward: 313.0
Avg Reward: 62.6
Min Reward: 58.0
Gini Coefficient 0.04089456869009585
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_17-06-39
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 735.0
  episode_reward_mean: 419.86
  episode_reward_min: -281.0
  episodes_this_iter: 1
  episodes_total: 50
  experiment_id: f3470259fa9143609a5dd5049ba7f979
  hostname: gpu020
  info:
    apply_time_ms: 3.818
    dispatch_time_ms: 6.563
    learner:
      cur_lr: 0.0013433500425890088
      grad_gnorm: 6.436237335205078
      policy_entropy: 51.947322845458984
      policy_loss: -1.3008744716644287
      var_gnorm: 27.52029800415039
      vf_explained_var: -1.0
      vf_loss: 0.030470246449112892
    num_steps_sampled: 255000
    num_steps_trained: 255000
    wait_time_ms: 111.481
  iterations_since_restore: 51
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 830
  policy_reward_mean: {}
  time_since_restore: 607.158465385437
  time_this_iter_s: 11.791984796524048
  time_total_s: 607.158465385437
  timestamp: 1593810399
  timesteps_since_restore: 255000
  timesteps_this_iter: 5000
  timesteps_total: 255000
  training_iteration: 51
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 9.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=830], 607 s, 51 iter, 255000 ts, 420 rew

agent-1: 59.0
agent-2: 69.0
agent-3: 55.0
agent-4: 78.0
agent-5: 73.0
Sum Reward: 334.0
Avg Reward: 66.8
Min Reward: 55.0
Gini Coefficient 0.0718562874251497
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_17-06-51
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 735.0
  episode_reward_mean: 418.1764705882353
  episode_reward_min: -281.0
  episodes_this_iter: 1
  episodes_total: 51
  experiment_id: f3470259fa9143609a5dd5049ba7f979
  hostname: gpu020
  info:
    apply_time_ms: 2.883
    dispatch_time_ms: 7.859
    learner:
      cur_lr: 0.001343016978353262
      grad_gnorm: 2.723986864089966
      policy_entropy: 53.96672821044922
      policy_loss: -0.8985654711723328
      var_gnorm: 27.582876205444336
      vf_explained_var: 0.0
      vf_loss: 0.0102464584633708
    num_steps_sampled: 260000
    num_steps_trained: 260000
    wait_time_ms: 105.596
  iterations_since_restore: 52
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 830
  policy_reward_mean: {}
  time_since_restore: 619.1616051197052
  time_this_iter_s: 12.003139734268188
  time_total_s: 619.1616051197052
  timestamp: 1593810411
  timesteps_since_restore: 260000
  timesteps_this_iter: 5000
  timesteps_total: 260000
  training_iteration: 52
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 9.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=830], 619 s, 52 iter, 260000 ts, 418 rew

agent-1: 67.0
agent-2: 69.0
agent-3: 81.0
agent-4: 70.0
agent-5: 77.0
Sum Reward: 364.0
Avg Reward: 72.8
Min Reward: 67.0
Gini Coefficient 0.03956043956043956
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_17-07-03
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 735.0
  episode_reward_mean: 417.13461538461536
  episode_reward_min: -281.0
  episodes_this_iter: 1
  episodes_total: 52
  experiment_id: f3470259fa9143609a5dd5049ba7f979
  hostname: gpu020
  info:
    apply_time_ms: 2.644
    dispatch_time_ms: 12.045
    learner:
      cur_lr: 0.001342684030532837
      grad_gnorm: 3.9585015773773193
      policy_entropy: 40.95166778564453
      policy_loss: -1.5947872400283813
      var_gnorm: 27.675783157348633
      vf_explained_var: -1.0
      vf_loss: 0.11777782440185547
    num_steps_sampled: 265000
    num_steps_trained: 265000
    wait_time_ms: 108.104
  iterations_since_restore: 53
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 830
  policy_reward_mean: {}
  time_since_restore: 630.815370798111
  time_this_iter_s: 11.653765678405762
  time_total_s: 630.815370798111
  timestamp: 1593810423
  timesteps_since_restore: 265000
  timesteps_this_iter: 5000
  timesteps_total: 265000
  training_iteration: 53
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 9.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=830], 630 s, 53 iter, 265000 ts, 417 rew

agent-1: 69.0
agent-2: 77.0
agent-3: 95.0
agent-4: 65.0
agent-5: 79.0
Sum Reward: 385.0
Avg Reward: 77.0
Min Reward: 65.0
Gini Coefficient 0.07272727272727272
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_17-07-15
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 735.0
  episode_reward_mean: 416.52830188679246
  episode_reward_min: -281.0
  episodes_this_iter: 1
  episodes_total: 53
  experiment_id: f3470259fa9143609a5dd5049ba7f979
  hostname: gpu020
  info:
    apply_time_ms: 3.069
    dispatch_time_ms: 8.8
    learner:
      cur_lr: 0.00134235096629709
      grad_gnorm: 1.0111501216888428
      policy_entropy: 44.58315658569336
      policy_loss: -0.2374664843082428
      var_gnorm: 27.746458053588867
      vf_explained_var: -0.17321312427520752
      vf_loss: 0.02103113755583763
    num_steps_sampled: 270000
    num_steps_trained: 270000
    wait_time_ms: 106.422
  iterations_since_restore: 54
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 830
  policy_reward_mean: {}
  time_since_restore: 642.9519093036652
  time_this_iter_s: 12.1365385055542
  time_total_s: 642.9519093036652
  timestamp: 1593810435
  timesteps_since_restore: 270000
  timesteps_this_iter: 5000
  timesteps_total: 270000
  training_iteration: 54
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 10.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=830], 642 s, 54 iter, 270000 ts, 417 rew

agent-1: 71.0
agent-2: 56.0
agent-3: 58.0
agent-4: 80.0
agent-5: 58.0
Sum Reward: 323.0
Avg Reward: 64.6
Min Reward: 56.0
Gini Coefficient 0.07554179566563468
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_17-07-27
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 735.0
  episode_reward_mean: 414.7962962962963
  episode_reward_min: -281.0
  episodes_this_iter: 1
  episodes_total: 54
  experiment_id: f3470259fa9143609a5dd5049ba7f979
  hostname: gpu020
  info:
    apply_time_ms: 3.164
    dispatch_time_ms: 6.737
    learner:
      cur_lr: 0.001342018018476665
      grad_gnorm: 1.255608081817627
      policy_entropy: 48.03738021850586
      policy_loss: -0.398923397064209
      var_gnorm: 27.85946273803711
      vf_explained_var: -0.0001386404037475586
      vf_loss: 0.0021896320395171642
    num_steps_sampled: 275000
    num_steps_trained: 275000
    wait_time_ms: 119.032
  iterations_since_restore: 55
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 830
  policy_reward_mean: {}
  time_since_restore: 654.9075798988342
  time_this_iter_s: 11.955670595169067
  time_total_s: 654.9075798988342
  timestamp: 1593810447
  timesteps_since_restore: 275000
  timesteps_this_iter: 5000
  timesteps_total: 275000
  training_iteration: 55
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 10.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=830], 654 s, 55 iter, 275000 ts, 415 rew

agent-1: 56.0
agent-2: 75.0
agent-3: 56.0
agent-4: 57.0
agent-5: 53.0
Sum Reward: 297.0
Avg Reward: 59.4
Min Reward: 53.0
Gini Coefficient 0.06060606060606061
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_17-07-39
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 735.0
  episode_reward_mean: 412.6545454545454
  episode_reward_min: -281.0
  episodes_this_iter: 1
  episodes_total: 55
  experiment_id: f3470259fa9143609a5dd5049ba7f979
  hostname: gpu020
  info:
    apply_time_ms: 2.606
    dispatch_time_ms: 9.653
    learner:
      cur_lr: 0.0013416849542409182
      grad_gnorm: 40.0000114440918
      policy_entropy: 23.656436920166016
      policy_loss: 3.006375312805176
      var_gnorm: 27.914533615112305
      vf_explained_var: 0.951126217842102
      vf_loss: 40.24839401245117
    num_steps_sampled: 280000
    num_steps_trained: 280000
    wait_time_ms: 99.355
  iterations_since_restore: 56
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 830
  policy_reward_mean: {}
  time_since_restore: 666.8954863548279
  time_this_iter_s: 11.987906455993652
  time_total_s: 666.8954863548279
  timestamp: 1593810459
  timesteps_since_restore: 280000
  timesteps_this_iter: 5000
  timesteps_total: 280000
  training_iteration: 56
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 10.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=830], 666 s, 56 iter, 280000 ts, 413 rew

agent-1: 71.0
agent-2: 66.0
agent-3: 65.0
agent-4: 74.0
agent-5: 65.0
Sum Reward: 341.0
Avg Reward: 68.2
Min Reward: 65.0
Gini Coefficient 0.0281524926686217
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_17-07-50
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 735.0
  episode_reward_mean: 411.375
  episode_reward_min: -281.0
  episodes_this_iter: 1
  episodes_total: 56
  experiment_id: f3470259fa9143609a5dd5049ba7f979
  hostname: gpu020
  info:
    apply_time_ms: 3.345
    dispatch_time_ms: 6.808
    learner:
      cur_lr: 0.0013413520064204931
      grad_gnorm: 40.0
      policy_entropy: 17.897172927856445
      policy_loss: 2.8617234230041504
      var_gnorm: 28.00616455078125
      vf_explained_var: 0.3455101251602173
      vf_loss: 194.2028045654297
    num_steps_sampled: 285000
    num_steps_trained: 285000
    wait_time_ms: 106.61
  iterations_since_restore: 57
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 830
  policy_reward_mean: {}
  time_since_restore: 678.5754675865173
  time_this_iter_s: 11.679981231689453
  time_total_s: 678.5754675865173
  timestamp: 1593810470
  timesteps_since_restore: 285000
  timesteps_this_iter: 5000
  timesteps_total: 285000
  training_iteration: 57
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 10.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=830], 678 s, 57 iter, 285000 ts, 411 rew

agent-1: 104.0
agent-2: 58.0
agent-3: 49.0
agent-4: 57.0
agent-5: 53.0
Sum Reward: 321.0
Avg Reward: 64.2
Min Reward: 49.0
Gini Coefficient 0.14330218068535824
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_17-08-02
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 735.0
  episode_reward_mean: 409.7894736842105
  episode_reward_min: -281.0
  episodes_this_iter: 1
  episodes_total: 57
  experiment_id: f3470259fa9143609a5dd5049ba7f979
  hostname: gpu020
  info:
    apply_time_ms: 3.115
    dispatch_time_ms: 7.979
    learner:
      cur_lr: 0.0013410189421847463
      grad_gnorm: 39.99999237060547
      policy_entropy: 15.79885482788086
      policy_loss: -0.7756826877593994
      var_gnorm: 28.08312225341797
      vf_explained_var: 0.8897243738174438
      vf_loss: 86.71281433105469
    num_steps_sampled: 290000
    num_steps_trained: 290000
    wait_time_ms: 97.521
  iterations_since_restore: 58
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 830
  policy_reward_mean: {}
  time_since_restore: 690.4725563526154
  time_this_iter_s: 11.897088766098022
  time_total_s: 690.4725563526154
  timestamp: 1593810482
  timesteps_since_restore: 290000
  timesteps_this_iter: 5000
  timesteps_total: 290000
  training_iteration: 58
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 10.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=830], 690 s, 58 iter, 290000 ts, 410 rew

agent-1: 63.0
agent-2: 87.0
agent-3: 68.0
agent-4: 75.0
agent-5: 75.0
Sum Reward: 368.0
Avg Reward: 73.6
Min Reward: 63.0
Gini Coefficient 0.059782608695652176
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_17-08-14
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 735.0
  episode_reward_mean: 409.0689655172414
  episode_reward_min: -281.0
  episodes_this_iter: 1
  episodes_total: 58
  experiment_id: f3470259fa9143609a5dd5049ba7f979
  hostname: gpu020
  info:
    apply_time_ms: 3.422
    dispatch_time_ms: 9.289
    learner:
      cur_lr: 0.0013406859943643212
      grad_gnorm: 39.999969482421875
      policy_entropy: 51.880252838134766
      policy_loss: 3.7604494094848633
      var_gnorm: 28.230178833007812
      vf_explained_var: -0.49886131286621094
      vf_loss: 2.98022198677063
    num_steps_sampled: 295000
    num_steps_trained: 295000
    wait_time_ms: 105.553
  iterations_since_restore: 59
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 830
  policy_reward_mean: {}
  time_since_restore: 702.0091419219971
  time_this_iter_s: 11.536585569381714
  time_total_s: 702.0091419219971
  timestamp: 1593810494
  timesteps_since_restore: 295000
  timesteps_this_iter: 5000
  timesteps_total: 295000
  training_iteration: 59
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 10.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=830], 702 s, 59 iter, 295000 ts, 409 rew

agent-1: 65.0
agent-2: 80.0
agent-3: 73.0
agent-4: 78.0
agent-5: 74.0
Sum Reward: 370.0
Avg Reward: 74.0
Min Reward: 65.0
Gini Coefficient 0.03783783783783784
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_17-08-26
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 735.0
  episode_reward_mean: 408.40677966101697
  episode_reward_min: -281.0
  episodes_this_iter: 1
  episodes_total: 59
  experiment_id: f3470259fa9143609a5dd5049ba7f979
  hostname: gpu020
  info:
    apply_time_ms: 3.615
    dispatch_time_ms: 7.849
    learner:
      cur_lr: 0.0013403530465438962
      grad_gnorm: 40.00000762939453
      policy_entropy: 49.245609283447266
      policy_loss: -0.5988052487373352
      var_gnorm: 28.340839385986328
      vf_explained_var: -1.0
      vf_loss: 0.13196305930614471
    num_steps_sampled: 300000
    num_steps_trained: 300000
    wait_time_ms: 107.913
  iterations_since_restore: 60
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 830
  policy_reward_mean: {}
  time_since_restore: 713.8952372074127
  time_this_iter_s: 11.88609528541565
  time_total_s: 713.8952372074127
  timestamp: 1593810506
  timesteps_since_restore: 300000
  timesteps_this_iter: 5000
  timesteps_total: 300000
  training_iteration: 60
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 10.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=830], 713 s, 60 iter, 300000 ts, 408 rew

agent-1: 147.0
agent-2: 99.0
agent-3: 101.0
agent-4: 101.0
agent-5: 84.0
Sum Reward: 532.0
Avg Reward: 106.4
Min Reward: 84.0
Gini Coefficient 0.0962406015037594
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_17-08-38
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 735.0
  episode_reward_mean: 410.46666666666664
  episode_reward_min: -281.0
  episodes_this_iter: 1
  episodes_total: 60
  experiment_id: f3470259fa9143609a5dd5049ba7f979
  hostname: gpu020
  info:
    apply_time_ms: 2.613
    dispatch_time_ms: 6.356
    learner:
      cur_lr: 0.0013400199823081493
      grad_gnorm: 40.0
      policy_entropy: 24.94070053100586
      policy_loss: -11.541419982910156
      var_gnorm: 28.452098846435547
      vf_explained_var: 0.2581958770751953
      vf_loss: 226.7056121826172
    num_steps_sampled: 305000
    num_steps_trained: 305000
    wait_time_ms: 108.662
  iterations_since_restore: 61
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 830
  policy_reward_mean: {}
  time_since_restore: 725.6571996212006
  time_this_iter_s: 11.761962413787842
  time_total_s: 725.6571996212006
  timestamp: 1593810518
  timesteps_since_restore: 305000
  timesteps_this_iter: 5000
  timesteps_total: 305000
  training_iteration: 61
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 10.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=830], 725 s, 61 iter, 305000 ts, 410 rew

agent-1: 76.0
agent-2: 71.0
agent-3: 83.0
agent-4: 76.0
agent-5: 60.0
Sum Reward: 366.0
Avg Reward: 73.2
Min Reward: 60.0
Gini Coefficient 0.05573770491803279
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_17-08-50
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 735.0
  episode_reward_mean: 409.73770491803276
  episode_reward_min: -281.0
  episodes_this_iter: 1
  episodes_total: 61
  experiment_id: f3470259fa9143609a5dd5049ba7f979
  hostname: gpu020
  info:
    apply_time_ms: 4.07
    dispatch_time_ms: 8.599
    learner:
      cur_lr: 0.0013396870344877243
      grad_gnorm: 3.1685032844543457
      policy_entropy: 42.631675720214844
      policy_loss: -0.6645181179046631
      var_gnorm: 28.503110885620117
      vf_explained_var: -0.7601971626281738
      vf_loss: 0.009897333569824696
    num_steps_sampled: 310000
    num_steps_trained: 310000
    wait_time_ms: 112.941
  iterations_since_restore: 62
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 830
  policy_reward_mean: {}
  time_since_restore: 737.8177218437195
  time_this_iter_s: 12.160522222518921
  time_total_s: 737.8177218437195
  timestamp: 1593810530
  timesteps_since_restore: 310000
  timesteps_this_iter: 5000
  timesteps_total: 310000
  training_iteration: 62
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 10.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=830], 737 s, 62 iter, 310000 ts, 410 rew

agent-1: 72.0
agent-2: 64.0
agent-3: 86.0
agent-4: 61.0
agent-5: 54.0
Sum Reward: 337.0
Avg Reward: 67.4
Min Reward: 54.0
Gini Coefficient 0.08902077151335312
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_17-09-02
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 735.0
  episode_reward_mean: 408.56451612903226
  episode_reward_min: -281.0
  episodes_this_iter: 1
  episodes_total: 62
  experiment_id: f3470259fa9143609a5dd5049ba7f979
  hostname: gpu020
  info:
    apply_time_ms: 2.811
    dispatch_time_ms: 6.326
    learner:
      cur_lr: 0.0013393539702519774
      grad_gnorm: 3.4086105823516846
      policy_entropy: 36.92694091796875
      policy_loss: 0.5546156764030457
      var_gnorm: 28.60013198852539
      vf_explained_var: 0.9952056407928467
      vf_loss: 0.030902549624443054
    num_steps_sampled: 315000
    num_steps_trained: 315000
    wait_time_ms: 113.39
  iterations_since_restore: 63
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 830
  policy_reward_mean: {}
  time_since_restore: 749.4895424842834
  time_this_iter_s: 11.671820640563965
  time_total_s: 749.4895424842834
  timestamp: 1593810542
  timesteps_since_restore: 315000
  timesteps_this_iter: 5000
  timesteps_total: 315000
  training_iteration: 63
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 10.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=830], 749 s, 63 iter, 315000 ts, 409 rew

agent-1: 68.0
agent-2: 81.0
agent-3: 60.0
agent-4: 56.0
agent-5: 66.0
Sum Reward: 331.0
Avg Reward: 66.2
Min Reward: 56.0
Gini Coefficient 0.07009063444108761
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_17-09-13
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 735.0
  episode_reward_mean: 407.3333333333333
  episode_reward_min: -281.0
  episodes_this_iter: 1
  episodes_total: 63
  experiment_id: f3470259fa9143609a5dd5049ba7f979
  hostname: gpu020
  info:
    apply_time_ms: 3.103
    dispatch_time_ms: 7.337
    learner:
      cur_lr: 0.0013390210224315524
      grad_gnorm: 40.000003814697266
      policy_entropy: 38.76694869995117
      policy_loss: 10.273550987243652
      var_gnorm: 28.664377212524414
      vf_explained_var: 0.2901650071144104
      vf_loss: 44.26381301879883
    num_steps_sampled: 320000
    num_steps_trained: 320000
    wait_time_ms: 101.011
  iterations_since_restore: 64
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 830
  policy_reward_mean: {}
  time_since_restore: 761.3545107841492
  time_this_iter_s: 11.864968299865723
  time_total_s: 761.3545107841492
  timestamp: 1593810553
  timesteps_since_restore: 320000
  timesteps_this_iter: 5000
  timesteps_total: 320000
  training_iteration: 64
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 10.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=830], 761 s, 64 iter, 320000 ts, 407 rew

agent-1: 85.0
agent-2: 91.0
agent-3: 91.0
agent-4: 85.0
agent-5: 99.0
Sum Reward: 451.0
Avg Reward: 90.2
Min Reward: 85.0
Gini Coefficient 0.03015521064301552
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_17-09-25
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 735.0
  episode_reward_mean: 408.015625
  episode_reward_min: -281.0
  episodes_this_iter: 1
  episodes_total: 64
  experiment_id: f3470259fa9143609a5dd5049ba7f979
  hostname: gpu020
  info:
    apply_time_ms: 3.402
    dispatch_time_ms: 7.834
    learner:
      cur_lr: 0.0013386879581958055
      grad_gnorm: 11.48392391204834
      policy_entropy: 37.68220520019531
      policy_loss: -2.0360472202301025
      var_gnorm: 28.84574317932129
      vf_explained_var: -1.0
      vf_loss: 0.9890926480293274
    num_steps_sampled: 325000
    num_steps_trained: 325000
    wait_time_ms: 117.054
  iterations_since_restore: 65
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 830
  policy_reward_mean: {}
  time_since_restore: 773.0089628696442
  time_this_iter_s: 11.654452085494995
  time_total_s: 773.0089628696442
  timestamp: 1593810565
  timesteps_since_restore: 325000
  timesteps_this_iter: 5000
  timesteps_total: 325000
  training_iteration: 65
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 10.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=830], 773 s, 65 iter, 325000 ts, 408 rew

agent-1: 74.0
agent-2: 96.0
agent-3: 73.0
agent-4: 84.0
agent-5: 77.0
Sum Reward: 404.0
Avg Reward: 80.8
Min Reward: 73.0
Gini Coefficient 0.055445544554455446
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_17-09-37
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 735.0
  episode_reward_mean: 407.95384615384614
  episode_reward_min: -281.0
  episodes_this_iter: 1
  episodes_total: 65
  experiment_id: f3470259fa9143609a5dd5049ba7f979
  hostname: gpu020
  info:
    apply_time_ms: 3.229
    dispatch_time_ms: 6.734
    learner:
      cur_lr: 0.0013383550103753805
      grad_gnorm: 6.9602837562561035
      policy_entropy: 47.13373565673828
      policy_loss: -0.03253981098532677
      var_gnorm: 28.915481567382812
      vf_explained_var: -1.0
      vf_loss: 0.041387274861335754
    num_steps_sampled: 330000
    num_steps_trained: 330000
    wait_time_ms: 102.115
  iterations_since_restore: 66
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 830
  policy_reward_mean: {}
  time_since_restore: 784.9304175376892
  time_this_iter_s: 11.921454668045044
  time_total_s: 784.9304175376892
  timestamp: 1593810577
  timesteps_since_restore: 330000
  timesteps_this_iter: 5000
  timesteps_total: 330000
  training_iteration: 66
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 10.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=830], 784 s, 66 iter, 330000 ts, 408 rew

agent-1: 47.0
agent-2: 76.0
agent-3: 78.0
agent-4: 68.0
agent-5: 87.0
Sum Reward: 356.0
Avg Reward: 71.2
Min Reward: 47.0
Gini Coefficient 0.10112359550561797
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_17-09-49
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 735.0
  episode_reward_mean: 407.1666666666667
  episode_reward_min: -281.0
  episodes_this_iter: 1
  episodes_total: 66
  experiment_id: f3470259fa9143609a5dd5049ba7f979
  hostname: gpu020
  info:
    apply_time_ms: 3.177
    dispatch_time_ms: 6.821
    learner:
      cur_lr: 0.0013380219461396337
      grad_gnorm: 40.0
      policy_entropy: 38.07941436767578
      policy_loss: -32.37757110595703
      var_gnorm: 29.02324867248535
      vf_explained_var: 0.5705583095550537
      vf_loss: 148.07022094726562
    num_steps_sampled: 335000
    num_steps_trained: 335000
    wait_time_ms: 109.354
  iterations_since_restore: 67
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 830
  policy_reward_mean: {}
  time_since_restore: 796.4818406105042
  time_this_iter_s: 11.551423072814941
  time_total_s: 796.4818406105042
  timestamp: 1593810589
  timesteps_since_restore: 335000
  timesteps_this_iter: 5000
  timesteps_total: 335000
  training_iteration: 67
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 10.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=830], 796 s, 67 iter, 335000 ts, 407 rew

agent-1: 84.0
agent-2: 75.0
agent-3: 64.0
agent-4: 72.0
agent-5: 78.0
Sum Reward: 373.0
Avg Reward: 74.6
Min Reward: 64.0
Gini Coefficient 0.04932975871313673
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_17-10-00
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 735.0
  episode_reward_mean: 406.65671641791045
  episode_reward_min: -281.0
  episodes_this_iter: 1
  episodes_total: 67
  experiment_id: f3470259fa9143609a5dd5049ba7f979
  hostname: gpu020
  info:
    apply_time_ms: 2.595
    dispatch_time_ms: 9.157
    learner:
      cur_lr: 0.0013376889983192086
      grad_gnorm: 40.0000114440918
      policy_entropy: 53.3624267578125
      policy_loss: -12.400588989257812
      var_gnorm: 29.07457733154297
      vf_explained_var: 0.47088247537612915
      vf_loss: 49.558040618896484
    num_steps_sampled: 340000
    num_steps_trained: 340000
    wait_time_ms: 89.887
  iterations_since_restore: 68
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 830
  policy_reward_mean: {}
  time_since_restore: 807.5606906414032
  time_this_iter_s: 11.078850030899048
  time_total_s: 807.5606906414032
  timestamp: 1593810600
  timesteps_since_restore: 340000
  timesteps_this_iter: 5000
  timesteps_total: 340000
  training_iteration: 68
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 10.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=830], 807 s, 68 iter, 340000 ts, 407 rew

agent-1: 115.0
agent-2: 129.0
agent-3: 149.0
agent-4: 133.0
agent-5: 148.0
Sum Reward: 674.0
Avg Reward: 134.8
Min Reward: 115.0
Gini Coefficient 0.05163204747774481
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_17-10-11
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 735.0
  episode_reward_mean: 410.5882352941176
  episode_reward_min: -281.0
  episodes_this_iter: 1
  episodes_total: 68
  experiment_id: f3470259fa9143609a5dd5049ba7f979
  hostname: gpu020
  info:
    apply_time_ms: 2.603
    dispatch_time_ms: 8.826
    learner:
      cur_lr: 0.0013373560504987836
      grad_gnorm: 39.9999885559082
      policy_entropy: 30.022907257080078
      policy_loss: -29.30885124206543
      var_gnorm: 29.136493682861328
      vf_explained_var: -0.8372430801391602
      vf_loss: 105.81278991699219
    num_steps_sampled: 345000
    num_steps_trained: 345000
    wait_time_ms: 98.569
  iterations_since_restore: 69
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 830
  policy_reward_mean: {}
  time_since_restore: 818.4484057426453
  time_this_iter_s: 10.887715101242065
  time_total_s: 818.4484057426453
  timestamp: 1593810611
  timesteps_since_restore: 345000
  timesteps_this_iter: 5000
  timesteps_total: 345000
  training_iteration: 69
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 10.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=830], 818 s, 69 iter, 345000 ts, 411 rew

agent-1: 88.0
agent-2: 100.0
agent-3: 97.0
agent-4: 89.0
agent-5: 104.0
Sum Reward: 478.0
Avg Reward: 95.6
Min Reward: 88.0
Gini Coefficient 0.03598326359832636
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_17-10-22
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 735.0
  episode_reward_mean: 411.5652173913044
  episode_reward_min: -281.0
  episodes_this_iter: 1
  episodes_total: 69
  experiment_id: f3470259fa9143609a5dd5049ba7f979
  hostname: gpu020
  info:
    apply_time_ms: 2.579
    dispatch_time_ms: 7.323
    learner:
      cur_lr: 0.0013370229862630367
      grad_gnorm: 39.99999237060547
      policy_entropy: 26.138463973999023
      policy_loss: 18.425918579101562
      var_gnorm: 29.286874771118164
      vf_explained_var: -1.0
      vf_loss: 84.36592864990234
    num_steps_sampled: 350000
    num_steps_trained: 350000
    wait_time_ms: 104.047
  iterations_since_restore: 70
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 830
  policy_reward_mean: {}
  time_since_restore: 830.1353924274445
  time_this_iter_s: 11.686986684799194
  time_total_s: 830.1353924274445
  timestamp: 1593810622
  timesteps_since_restore: 350000
  timesteps_this_iter: 5000
  timesteps_total: 350000
  training_iteration: 70
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 10.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=830], 830 s, 70 iter, 350000 ts, 412 rew

agent-1: 116.0
agent-2: 123.0
agent-3: 96.0
agent-4: 140.0
agent-5: 130.0
Sum Reward: 605.0
Avg Reward: 121.0
Min Reward: 96.0
Gini Coefficient 0.06743801652892562
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_17-10-34
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 735.0
  episode_reward_mean: 414.3285714285714
  episode_reward_min: -281.0
  episodes_this_iter: 1
  episodes_total: 70
  experiment_id: f3470259fa9143609a5dd5049ba7f979
  hostname: gpu020
  info:
    apply_time_ms: 3.703
    dispatch_time_ms: 7.969
    learner:
      cur_lr: 0.0013366900384426117
      grad_gnorm: 40.0
      policy_entropy: 18.85457420349121
      policy_loss: -2.893099546432495
      var_gnorm: 29.45840835571289
      vf_explained_var: -0.7415833473205566
      vf_loss: 18.880571365356445
    num_steps_sampled: 355000
    num_steps_trained: 355000
    wait_time_ms: 106.84
  iterations_since_restore: 71
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 830
  policy_reward_mean: {}
  time_since_restore: 841.4741637706757
  time_this_iter_s: 11.338771343231201
  time_total_s: 841.4741637706757
  timestamp: 1593810634
  timesteps_since_restore: 355000
  timesteps_this_iter: 5000
  timesteps_total: 355000
  training_iteration: 71
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 10.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=830], 841 s, 71 iter, 355000 ts, 414 rew

agent-1: 82.0
agent-2: 94.0
agent-3: 86.0
agent-4: 81.0
agent-5: 98.0
Sum Reward: 441.0
Avg Reward: 88.2
Min Reward: 81.0
Gini Coefficient 0.041723356009070296
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_17-10-46
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 735.0
  episode_reward_mean: 414.7042253521127
  episode_reward_min: -281.0
  episodes_this_iter: 1
  episodes_total: 71
  experiment_id: f3470259fa9143609a5dd5049ba7f979
  hostname: gpu020
  info:
    apply_time_ms: 3.71
    dispatch_time_ms: 6.478
    learner:
      cur_lr: 0.0013363569742068648
      grad_gnorm: 39.9999885559082
      policy_entropy: 28.94647979736328
      policy_loss: 25.15374755859375
      var_gnorm: 29.578540802001953
      vf_explained_var: 0.5822907090187073
      vf_loss: 44.59986114501953
    num_steps_sampled: 360000
    num_steps_trained: 360000
    wait_time_ms: 91.841
  iterations_since_restore: 72
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 830
  policy_reward_mean: {}
  time_since_restore: 853.5368359088898
  time_this_iter_s: 12.062672138214111
  time_total_s: 853.5368359088898
  timestamp: 1593810646
  timesteps_since_restore: 360000
  timesteps_this_iter: 5000
  timesteps_total: 360000
  training_iteration: 72
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 10.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=830], 853 s, 72 iter, 360000 ts, 415 rew

agent-1: 81.0
agent-2: 59.0
agent-3: 50.0
agent-4: 70.0
agent-5: 66.0
Sum Reward: 326.0
Avg Reward: 65.2
Min Reward: 50.0
Gini Coefficient 0.08957055214723926
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_17-10-57
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 735.0
  episode_reward_mean: 413.47222222222223
  episode_reward_min: -281.0
  episodes_this_iter: 1
  episodes_total: 72
  experiment_id: f3470259fa9143609a5dd5049ba7f979
  hostname: gpu020
  info:
    apply_time_ms: 3.493
    dispatch_time_ms: 7.993
    learner:
      cur_lr: 0.0013360240263864398
      grad_gnorm: 40.00001525878906
      policy_entropy: 34.510623931884766
      policy_loss: -6.914699077606201
      var_gnorm: 29.67937469482422
      vf_explained_var: 0.5645202398300171
      vf_loss: 28.46965789794922
    num_steps_sampled: 365000
    num_steps_trained: 365000
    wait_time_ms: 95.225
  iterations_since_restore: 73
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 830
  policy_reward_mean: {}
  time_since_restore: 864.4496808052063
  time_this_iter_s: 10.912844896316528
  time_total_s: 864.4496808052063
  timestamp: 1593810657
  timesteps_since_restore: 365000
  timesteps_this_iter: 5000
  timesteps_total: 365000
  training_iteration: 73
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 10.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=830], 864 s, 73 iter, 365000 ts, 413 rew

agent-1: 170.0
agent-2: 134.0
agent-3: 137.0
agent-4: 153.0
agent-5: 122.0
Sum Reward: 716.0
Avg Reward: 143.2
Min Reward: 122.0
Gini Coefficient 0.06424581005586592
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_17-11-08
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 735.0
  episode_reward_mean: 417.6164383561644
  episode_reward_min: -281.0
  episodes_this_iter: 1
  episodes_total: 73
  experiment_id: f3470259fa9143609a5dd5049ba7f979
  hostname: gpu020
  info:
    apply_time_ms: 3.582
    dispatch_time_ms: 8.169
    learner:
      cur_lr: 0.001335690962150693
      grad_gnorm: 35.19038009643555
      policy_entropy: 30.66969871520996
      policy_loss: -0.784194827079773
      var_gnorm: 29.88689422607422
      vf_explained_var: 0.6384182572364807
      vf_loss: 1.9118374586105347
    num_steps_sampled: 370000
    num_steps_trained: 370000
    wait_time_ms: 91.511
  iterations_since_restore: 74
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 830
  policy_reward_mean: {}
  time_since_restore: 875.3879878520966
  time_this_iter_s: 10.938307046890259
  time_total_s: 875.3879878520966
  timestamp: 1593810668
  timesteps_since_restore: 370000
  timesteps_this_iter: 5000
  timesteps_total: 370000
  training_iteration: 74
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 10.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=830], 875 s, 74 iter, 370000 ts, 418 rew

agent-1: 79.0
agent-2: 76.0
agent-3: 68.0
agent-4: 44.0
agent-5: 82.0
Sum Reward: 349.0
Avg Reward: 69.8
Min Reward: 44.0
Gini Coefficient 0.0997134670487106
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_17-11-19
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 735.0
  episode_reward_mean: 416.68918918918916
  episode_reward_min: -281.0
  episodes_this_iter: 1
  episodes_total: 74
  experiment_id: f3470259fa9143609a5dd5049ba7f979
  hostname: gpu020
  info:
    apply_time_ms: 2.694
    dispatch_time_ms: 10.566
    learner:
      cur_lr: 0.001335358014330268
      grad_gnorm: 40.0000114440918
      policy_entropy: 22.91259002685547
      policy_loss: 18.758861541748047
      var_gnorm: 29.88548469543457
      vf_explained_var: 0.09133356809616089
      vf_loss: 26.600488662719727
    num_steps_sampled: 375000
    num_steps_trained: 375000
    wait_time_ms: 97.89
  iterations_since_restore: 75
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 830
  policy_reward_mean: {}
  time_since_restore: 886.2424938678741
  time_this_iter_s: 10.854506015777588
  time_total_s: 886.2424938678741
  timestamp: 1593810679
  timesteps_since_restore: 375000
  timesteps_this_iter: 5000
  timesteps_total: 375000
  training_iteration: 75
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 10.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=830], 886 s, 75 iter, 375000 ts, 417 rew

agent-1: 132.0
agent-2: 140.0
agent-3: 123.0
agent-4: 146.0
agent-5: 140.0
Sum Reward: 681.0
Avg Reward: 136.2
Min Reward: 123.0
Gini Coefficient 0.03171806167400881
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_17-11-30
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 735.0
  episode_reward_mean: 420.2133333333333
  episode_reward_min: -281.0
  episodes_this_iter: 1
  episodes_total: 75
  experiment_id: f3470259fa9143609a5dd5049ba7f979
  hostname: gpu020
  info:
    apply_time_ms: 4.026
    dispatch_time_ms: 7.774
    learner:
      cur_lr: 0.001335024950094521
      grad_gnorm: 40.000003814697266
      policy_entropy: 30.10662078857422
      policy_loss: -16.405372619628906
      var_gnorm: 30.05401611328125
      vf_explained_var: 0.6926513314247131
      vf_loss: 31.882566452026367
    num_steps_sampled: 380000
    num_steps_trained: 380000
    wait_time_ms: 115.104
  iterations_since_restore: 76
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 830
  policy_reward_mean: {}
  time_since_restore: 897.8293104171753
  time_this_iter_s: 11.586816549301147
  time_total_s: 897.8293104171753
  timestamp: 1593810690
  timesteps_since_restore: 380000
  timesteps_this_iter: 5000
  timesteps_total: 380000
  training_iteration: 76
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 10.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=830], 897 s, 76 iter, 380000 ts, 420 rew

agent-1: 61.0
agent-2: 93.0
agent-3: 78.0
agent-4: 92.0
agent-5: 81.0
Sum Reward: 405.0
Avg Reward: 81.0
Min Reward: 61.0
Gini Coefficient 0.07703703703703704
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_17-11-42
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 735.0
  episode_reward_mean: 420.0131578947368
  episode_reward_min: -281.0
  episodes_this_iter: 1
  episodes_total: 76
  experiment_id: f3470259fa9143609a5dd5049ba7f979
  hostname: gpu020
  info:
    apply_time_ms: 3.045
    dispatch_time_ms: 11.443
    learner:
      cur_lr: 0.001334692002274096
      grad_gnorm: 39.99998474121094
      policy_entropy: 34.76339340209961
      policy_loss: 36.43513107299805
      var_gnorm: 30.176118850708008
      vf_explained_var: 0.7283420562744141
      vf_loss: 70.48133087158203
    num_steps_sampled: 385000
    num_steps_trained: 385000
    wait_time_ms: 99.965
  iterations_since_restore: 77
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 830
  policy_reward_mean: {}
  time_since_restore: 909.4474873542786
  time_this_iter_s: 11.618176937103271
  time_total_s: 909.4474873542786
  timestamp: 1593810702
  timesteps_since_restore: 385000
  timesteps_this_iter: 5000
  timesteps_total: 385000
  training_iteration: 77
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 10.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=830], 909 s, 77 iter, 385000 ts, 420 rew

agent-1: 116.0
agent-2: 97.0
agent-3: 117.0
agent-4: 128.0
agent-5: 110.0
Sum Reward: 568.0
Avg Reward: 113.6
Min Reward: 97.0
Gini Coefficient 0.048591549295774646
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_17-11-53
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 735.0
  episode_reward_mean: 421.93506493506493
  episode_reward_min: -281.0
  episodes_this_iter: 1
  episodes_total: 77
  experiment_id: f3470259fa9143609a5dd5049ba7f979
  hostname: gpu020
  info:
    apply_time_ms: 2.506
    dispatch_time_ms: 6.998
    learner:
      cur_lr: 0.001334359054453671
      grad_gnorm: 39.99998474121094
      policy_entropy: 24.855728149414062
      policy_loss: 14.349739074707031
      var_gnorm: 30.279850006103516
      vf_explained_var: -0.5876264572143555
      vf_loss: 53.62169647216797
    num_steps_sampled: 390000
    num_steps_trained: 390000
    wait_time_ms: 103.025
  iterations_since_restore: 78
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 830
  policy_reward_mean: {}
  time_since_restore: 920.9291608333588
  time_this_iter_s: 11.4816734790802
  time_total_s: 920.9291608333588
  timestamp: 1593810713
  timesteps_since_restore: 390000
  timesteps_this_iter: 5000
  timesteps_total: 390000
  training_iteration: 78
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 10.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=830], 920 s, 78 iter, 390000 ts, 422 rew

agent-1: 74.0
agent-2: 84.0
agent-3: 123.0
agent-4: 51.0
agent-5: 47.0
Sum Reward: 379.0
Avg Reward: 75.8
Min Reward: 47.0
Gini Coefficient 0.19525065963060687
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_17-12-05
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 735.0
  episode_reward_mean: 421.38461538461536
  episode_reward_min: -281.0
  episodes_this_iter: 1
  episodes_total: 78
  experiment_id: f3470259fa9143609a5dd5049ba7f979
  hostname: gpu020
  info:
    apply_time_ms: 3.772
    dispatch_time_ms: 7.511
    learner:
      cur_lr: 0.0013340259902179241
      grad_gnorm: 9.575857162475586
      policy_entropy: 42.304378509521484
      policy_loss: -2.0229837894439697
      var_gnorm: 30.340654373168945
      vf_explained_var: 0.9850390553474426
      vf_loss: 0.12570731341838837
    num_steps_sampled: 395000
    num_steps_trained: 395000
    wait_time_ms: 101.717
  iterations_since_restore: 79
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 830
  policy_reward_mean: {}
  time_since_restore: 932.748494386673
  time_this_iter_s: 11.819333553314209
  time_total_s: 932.748494386673
  timestamp: 1593810725
  timesteps_since_restore: 395000
  timesteps_this_iter: 5000
  timesteps_total: 395000
  training_iteration: 79
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 10.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=830], 932 s, 79 iter, 395000 ts, 421 rew

agent-1: 113.0
agent-2: 99.0
agent-3: 94.0
agent-4: 94.0
agent-5: 100.0
Sum Reward: 500.0
Avg Reward: 100.0
Min Reward: 94.0
Gini Coefficient 0.0352
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_17-12-17
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 735.0
  episode_reward_mean: 422.37974683544303
  episode_reward_min: -281.0
  episodes_this_iter: 1
  episodes_total: 79
  experiment_id: f3470259fa9143609a5dd5049ba7f979
  hostname: gpu020
  info:
    apply_time_ms: 3.527
    dispatch_time_ms: 7.298
    learner:
      cur_lr: 0.001333693042397499
      grad_gnorm: 40.0
      policy_entropy: 20.6899471282959
      policy_loss: -2.2502193450927734
      var_gnorm: 30.385581970214844
      vf_explained_var: 0.9750944972038269
      vf_loss: 39.26007843017578
    num_steps_sampled: 400000
    num_steps_trained: 400000
    wait_time_ms: 106.795
  iterations_since_restore: 80
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 830
  policy_reward_mean: {}
  time_since_restore: 944.4168980121613
  time_this_iter_s: 11.668403625488281
  time_total_s: 944.4168980121613
  timestamp: 1593810737
  timesteps_since_restore: 400000
  timesteps_this_iter: 5000
  timesteps_total: 400000
  training_iteration: 80
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 10.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=830], 944 s, 80 iter, 400000 ts, 422 rew

agent-1: 93.0
agent-2: 80.0
agent-3: 78.0
agent-4: 80.0
agent-5: 84.0
Sum Reward: 415.0
Avg Reward: 83.0
Min Reward: 78.0
Gini Coefficient 0.0327710843373494
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_17-12-29
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 735.0
  episode_reward_mean: 422.2875
  episode_reward_min: -281.0
  episodes_this_iter: 1
  episodes_total: 80
  experiment_id: f3470259fa9143609a5dd5049ba7f979
  hostname: gpu020
  info:
    apply_time_ms: 2.981
    dispatch_time_ms: 7.038
    learner:
      cur_lr: 0.0013333599781617522
      grad_gnorm: 5.931323051452637
      policy_entropy: 33.7118034362793
      policy_loss: -1.076980710029602
      var_gnorm: 30.448030471801758
      vf_explained_var: 0.9926689863204956
      vf_loss: 0.05906112119555473
    num_steps_sampled: 405000
    num_steps_trained: 405000
    wait_time_ms: 104.514
  iterations_since_restore: 81
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 830
  policy_reward_mean: {}
  time_since_restore: 956.3117163181305
  time_this_iter_s: 11.894818305969238
  time_total_s: 956.3117163181305
  timestamp: 1593810749
  timesteps_since_restore: 405000
  timesteps_this_iter: 5000
  timesteps_total: 405000
  training_iteration: 81
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 10.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=830], 956 s, 81 iter, 405000 ts, 422 rew

agent-1: 116.0
agent-2: 75.0
agent-3: 75.0
agent-4: 99.0
agent-5: 85.0
Sum Reward: 450.0
Avg Reward: 90.0
Min Reward: 75.0
Gini Coefficient 0.09422222222222222
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_17-12-41
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 735.0
  episode_reward_mean: 422.6296296296296
  episode_reward_min: -281.0
  episodes_this_iter: 1
  episodes_total: 81
  experiment_id: f3470259fa9143609a5dd5049ba7f979
  hostname: gpu020
  info:
    apply_time_ms: 3.232
    dispatch_time_ms: 6.191
    learner:
      cur_lr: 0.0013330270303413272
      grad_gnorm: 1.733594536781311
      policy_entropy: 20.27625846862793
      policy_loss: 0.19711753726005554
      var_gnorm: 30.576990127563477
      vf_explained_var: -1.0
      vf_loss: 0.3014528453350067
    num_steps_sampled: 410000
    num_steps_trained: 410000
    wait_time_ms: 112.583
  iterations_since_restore: 82
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 830
  policy_reward_mean: {}
  time_since_restore: 967.9934360980988
  time_this_iter_s: 11.681719779968262
  time_total_s: 967.9934360980988
  timestamp: 1593810761
  timesteps_since_restore: 410000
  timesteps_this_iter: 5000
  timesteps_total: 410000
  training_iteration: 82
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 10.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=830], 967 s, 82 iter, 410000 ts, 423 rew

agent-1: 80.0
agent-2: 62.0
agent-3: 75.0
agent-4: 67.0
agent-5: 70.0
Sum Reward: 354.0
Avg Reward: 70.8
Min Reward: 62.0
Gini Coefficient 0.04971751412429379
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_17-12-53
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 735.0
  episode_reward_mean: 421.7926829268293
  episode_reward_min: -281.0
  episodes_this_iter: 1
  episodes_total: 82
  experiment_id: f3470259fa9143609a5dd5049ba7f979
  hostname: gpu020
  info:
    apply_time_ms: 2.795
    dispatch_time_ms: 8.01
    learner:
      cur_lr: 0.0013326939661055803
      grad_gnorm: 12.42191219329834
      policy_entropy: 40.399497985839844
      policy_loss: -1.2004038095474243
      var_gnorm: 30.7127685546875
      vf_explained_var: 0.7573360800743103
      vf_loss: 0.05395016074180603
    num_steps_sampled: 415000
    num_steps_trained: 415000
    wait_time_ms: 116.399
  iterations_since_restore: 83
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 830
  policy_reward_mean: {}
  time_since_restore: 979.9685006141663
  time_this_iter_s: 11.975064516067505
  time_total_s: 979.9685006141663
  timestamp: 1593810773
  timesteps_since_restore: 415000
  timesteps_this_iter: 5000
  timesteps_total: 415000
  training_iteration: 83
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 10.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=830], 979 s, 83 iter, 415000 ts, 422 rew

agent-1: 97.0
agent-2: 81.0
agent-3: 87.0
agent-4: 102.0
agent-5: 78.0
Sum Reward: 445.0
Avg Reward: 89.0
Min Reward: 78.0
Gini Coefficient 0.05752808988764045
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_17-13-04
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 735.0
  episode_reward_mean: 422.0722891566265
  episode_reward_min: -281.0
  episodes_this_iter: 1
  episodes_total: 83
  experiment_id: f3470259fa9143609a5dd5049ba7f979
  hostname: gpu020
  info:
    apply_time_ms: 2.845
    dispatch_time_ms: 9.594
    learner:
      cur_lr: 0.0013323610182851553
      grad_gnorm: 1.2454314231872559
      policy_entropy: 38.10329055786133
      policy_loss: -0.09049355238676071
      var_gnorm: 30.82093620300293
      vf_explained_var: 0.0
      vf_loss: 0.0019926996901631355
    num_steps_sampled: 420000
    num_steps_trained: 420000
    wait_time_ms: 107.786
  iterations_since_restore: 84
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 830
  policy_reward_mean: {}
  time_since_restore: 991.7038309574127
  time_this_iter_s: 11.73533034324646
  time_total_s: 991.7038309574127
  timestamp: 1593810784
  timesteps_since_restore: 420000
  timesteps_this_iter: 5000
  timesteps_total: 420000
  training_iteration: 84
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 10.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=830], 991 s, 84 iter, 420000 ts, 422 rew

agent-1: 68.0
agent-2: 68.0
agent-3: 81.0
agent-4: 64.0
agent-5: 57.0
Sum Reward: 338.0
Avg Reward: 67.6
Min Reward: 57.0
Gini Coefficient 0.06153846153846154
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_17-13-17
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 735.0
  episode_reward_mean: 421.07142857142856
  episode_reward_min: -281.0
  episodes_this_iter: 1
  episodes_total: 84
  experiment_id: f3470259fa9143609a5dd5049ba7f979
  hostname: gpu020
  info:
    apply_time_ms: 3.468
    dispatch_time_ms: 9.624
    learner:
      cur_lr: 0.0013320279540494084
      grad_gnorm: 5.4860663414001465
      policy_entropy: 37.84571075439453
      policy_loss: -1.396567463874817
      var_gnorm: 30.874420166015625
      vf_explained_var: 5.960464477539063e-08
      vf_loss: 0.03958411514759064
    num_steps_sampled: 425000
    num_steps_trained: 425000
    wait_time_ms: 112.602
  iterations_since_restore: 85
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 830
  policy_reward_mean: {}
  time_since_restore: 1003.8389751911163
  time_this_iter_s: 12.135144233703613
  time_total_s: 1003.8389751911163
  timestamp: 1593810797
  timesteps_since_restore: 425000
  timesteps_this_iter: 5000
  timesteps_total: 425000
  training_iteration: 85
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 10.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=830], 1003 s, 85 iter, 425000 ts, 421 rew

agent-1: 71.0
agent-2: 64.0
agent-3: 55.0
agent-4: 59.0
agent-5: 96.0
Sum Reward: 345.0
Avg Reward: 69.0
Min Reward: 55.0
Gini Coefficient 0.10898550724637682
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_17-13-28
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 735.0
  episode_reward_mean: 420.1764705882353
  episode_reward_min: -281.0
  episodes_this_iter: 1
  episodes_total: 85
  experiment_id: f3470259fa9143609a5dd5049ba7f979
  hostname: gpu020
  info:
    apply_time_ms: 3.325
    dispatch_time_ms: 8.766
    learner:
      cur_lr: 0.0013316950062289834
      grad_gnorm: 39.99998474121094
      policy_entropy: 37.64445114135742
      policy_loss: 7.467724323272705
      var_gnorm: 30.89588737487793
      vf_explained_var: 0.002860426902770996
      vf_loss: 10.282965660095215
    num_steps_sampled: 430000
    num_steps_trained: 430000
    wait_time_ms: 106.581
  iterations_since_restore: 86
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 830
  policy_reward_mean: {}
  time_since_restore: 1015.170825958252
  time_this_iter_s: 11.33185076713562
  time_total_s: 1015.170825958252
  timestamp: 1593810808
  timesteps_since_restore: 430000
  timesteps_this_iter: 5000
  timesteps_total: 430000
  training_iteration: 86
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 10.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=830], 1015 s, 86 iter, 430000 ts, 420 rew

agent-1: 100.0
agent-2: 97.0
agent-3: 102.0
agent-4: 94.0
agent-5: 90.0
Sum Reward: 483.0
Avg Reward: 96.6
Min Reward: 90.0
Gini Coefficient 0.024844720496894408
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_17-13-40
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 735.0
  episode_reward_mean: 420.90697674418607
  episode_reward_min: -281.0
  episodes_this_iter: 1
  episodes_total: 86
  experiment_id: f3470259fa9143609a5dd5049ba7f979
  hostname: gpu020
  info:
    apply_time_ms: 3.262
    dispatch_time_ms: 7.779
    learner:
      cur_lr: 0.0013313619419932365
      grad_gnorm: 39.999996185302734
      policy_entropy: 23.37135887145996
      policy_loss: -20.404382705688477
      var_gnorm: 31.010374069213867
      vf_explained_var: 0.34921330213546753
      vf_loss: 34.38665771484375
    num_steps_sampled: 435000
    num_steps_trained: 435000
    wait_time_ms: 102.747
  iterations_since_restore: 87
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 830
  policy_reward_mean: {}
  time_since_restore: 1027.1766602993011
  time_this_iter_s: 12.005834341049194
  time_total_s: 1027.1766602993011
  timestamp: 1593810820
  timesteps_since_restore: 435000
  timesteps_this_iter: 5000
  timesteps_total: 435000
  training_iteration: 87
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 10.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=830], 1027 s, 87 iter, 435000 ts, 421 rew

agent-1: 86.0
agent-2: 93.0
agent-3: 94.0
agent-4: 67.0
agent-5: 91.0
Sum Reward: 431.0
Avg Reward: 86.2
Min Reward: 67.0
Gini Coefficient 0.05661252900232019
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_17-13-52
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 735.0
  episode_reward_mean: 421.02298850574715
  episode_reward_min: -281.0
  episodes_this_iter: 1
  episodes_total: 87
  experiment_id: f3470259fa9143609a5dd5049ba7f979
  hostname: gpu020
  info:
    apply_time_ms: 2.947
    dispatch_time_ms: 10.477
    learner:
      cur_lr: 0.0013310289941728115
      grad_gnorm: 40.00001525878906
      policy_entropy: 37.45381164550781
      policy_loss: -2.7500596046447754
      var_gnorm: 31.160280227661133
      vf_explained_var: 0.9821842312812805
      vf_loss: 0.18858666718006134
    num_steps_sampled: 440000
    num_steps_trained: 440000
    wait_time_ms: 107.39
  iterations_since_restore: 88
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 830
  policy_reward_mean: {}
  time_since_restore: 1038.6546578407288
  time_this_iter_s: 11.477997541427612
  time_total_s: 1038.6546578407288
  timestamp: 1593810832
  timesteps_since_restore: 440000
  timesteps_this_iter: 5000
  timesteps_total: 440000
  training_iteration: 88
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 10.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=830], 1038 s, 88 iter, 440000 ts, 421 rew

agent-1: 72.0
agent-2: 97.0
agent-3: 81.0
agent-4: 71.0
agent-5: 94.0
Sum Reward: 415.0
Avg Reward: 83.0
Min Reward: 71.0
Gini Coefficient 0.07132530120481928
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_17-14-04
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 735.0
  episode_reward_mean: 420.95454545454544
  episode_reward_min: -281.0
  episodes_this_iter: 1
  episodes_total: 88
  experiment_id: f3470259fa9143609a5dd5049ba7f979
  hostname: gpu020
  info:
    apply_time_ms: 4.069
    dispatch_time_ms: 6.92
    learner:
      cur_lr: 0.0013306960463523865
      grad_gnorm: 39.99998474121094
      policy_entropy: 20.56047248840332
      policy_loss: -14.965121269226074
      var_gnorm: 31.235816955566406
      vf_explained_var: 0.03190648555755615
      vf_loss: 52.8003044128418
    num_steps_sampled: 445000
    num_steps_trained: 445000
    wait_time_ms: 97.684
  iterations_since_restore: 89
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 830
  policy_reward_mean: {}
  time_since_restore: 1050.7763621807098
  time_this_iter_s: 12.121704339981079
  time_total_s: 1050.7763621807098
  timestamp: 1593810844
  timesteps_since_restore: 445000
  timesteps_this_iter: 5000
  timesteps_total: 445000
  training_iteration: 89
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 10.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=830], 1050 s, 89 iter, 445000 ts, 421 rew

agent-1: 79.0
agent-2: 96.0
agent-3: 54.0
agent-4: 86.0
agent-5: 85.0
Sum Reward: 400.0
Avg Reward: 80.0
Min Reward: 54.0
Gini Coefficient 0.091
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_17-14-15
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 735.0
  episode_reward_mean: 420.7191011235955
  episode_reward_min: -281.0
  episodes_this_iter: 1
  episodes_total: 89
  experiment_id: f3470259fa9143609a5dd5049ba7f979
  hostname: gpu020
  info:
    apply_time_ms: 2.723
    dispatch_time_ms: 8.106
    learner:
      cur_lr: 0.0013303629821166396
      grad_gnorm: 40.000030517578125
      policy_entropy: 18.96992301940918
      policy_loss: -1.9710230827331543
      var_gnorm: 31.369251251220703
      vf_explained_var: 0.2552504539489746
      vf_loss: 82.33087158203125
    num_steps_sampled: 450000
    num_steps_trained: 450000
    wait_time_ms: 99.043
  iterations_since_restore: 90
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 830
  policy_reward_mean: {}
  time_since_restore: 1061.9993681907654
  time_this_iter_s: 11.223006010055542
  time_total_s: 1061.9993681907654
  timestamp: 1593810855
  timesteps_since_restore: 450000
  timesteps_this_iter: 5000
  timesteps_total: 450000
  training_iteration: 90
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 10.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=830], 1061 s, 90 iter, 450000 ts, 421 rew

agent-1: 103.0
agent-2: 90.0
agent-3: 94.0
agent-4: 92.0
agent-5: 101.0
Sum Reward: 480.0
Avg Reward: 96.0
Min Reward: 90.0
Gini Coefficient 0.029166666666666667
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_17-14-27
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 735.0
  episode_reward_mean: 421.3777777777778
  episode_reward_min: -281.0
  episodes_this_iter: 1
  episodes_total: 90
  experiment_id: f3470259fa9143609a5dd5049ba7f979
  hostname: gpu020
  info:
    apply_time_ms: 2.749
    dispatch_time_ms: 9.992
    learner:
      cur_lr: 0.0013300300342962146
      grad_gnorm: 40.00000762939453
      policy_entropy: 13.818410873413086
      policy_loss: 8.295536994934082
      var_gnorm: 31.476573944091797
      vf_explained_var: -0.07414460182189941
      vf_loss: 41.78271484375
    num_steps_sampled: 455000
    num_steps_trained: 455000
    wait_time_ms: 106.736
  iterations_since_restore: 91
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 830
  policy_reward_mean: {}
  time_since_restore: 1073.7190024852753
  time_this_iter_s: 11.719634294509888
  time_total_s: 1073.7190024852753
  timestamp: 1593810867
  timesteps_since_restore: 455000
  timesteps_this_iter: 5000
  timesteps_total: 455000
  training_iteration: 91
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 10.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=830], 1073 s, 91 iter, 455000 ts, 421 rew

agent-1: 134.0
agent-2: 126.0
agent-3: 146.0
agent-4: 162.0
agent-5: 109.0
Sum Reward: 677.0
Avg Reward: 135.4
Min Reward: 109.0
Gini Coefficient 0.07444608567208272
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_17-14-38
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 735.0
  episode_reward_mean: 424.1868131868132
  episode_reward_min: -281.0
  episodes_this_iter: 1
  episodes_total: 91
  experiment_id: f3470259fa9143609a5dd5049ba7f979
  hostname: gpu020
  info:
    apply_time_ms: 3.622
    dispatch_time_ms: 7.457
    learner:
      cur_lr: 0.0013296969700604677
      grad_gnorm: 39.99998092651367
      policy_entropy: 23.19965171813965
      policy_loss: -16.626277923583984
      var_gnorm: 31.605419158935547
      vf_explained_var: 0.25036370754241943
      vf_loss: 27.44061279296875
    num_steps_sampled: 460000
    num_steps_trained: 460000
    wait_time_ms: 108.057
  iterations_since_restore: 92
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 830
  policy_reward_mean: {}
  time_since_restore: 1085.188437461853
  time_this_iter_s: 11.469434976577759
  time_total_s: 1085.188437461853
  timestamp: 1593810878
  timesteps_since_restore: 460000
  timesteps_this_iter: 5000
  timesteps_total: 460000
  training_iteration: 92
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 10.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=830], 1085 s, 92 iter, 460000 ts, 424 rew

agent-1: 111.0
agent-2: 94.0
agent-3: 82.0
agent-4: 77.0
agent-5: 78.0
Sum Reward: 442.0
Avg Reward: 88.4
Min Reward: 77.0
Gini Coefficient 0.0760180995475113
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_17-14-50
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 735.0
  episode_reward_mean: 424.3804347826087
  episode_reward_min: -281.0
  episodes_this_iter: 1
  episodes_total: 92
  experiment_id: f3470259fa9143609a5dd5049ba7f979
  hostname: gpu020
  info:
    apply_time_ms: 3.003
    dispatch_time_ms: 7.564
    learner:
      cur_lr: 0.0013293640222400427
      grad_gnorm: 40.00000762939453
      policy_entropy: 24.29961395263672
      policy_loss: -55.216758728027344
      var_gnorm: 31.75340461730957
      vf_explained_var: 0.2429412603378296
      vf_loss: 178.92369079589844
    num_steps_sampled: 465000
    num_steps_trained: 465000
    wait_time_ms: 107.062
  iterations_since_restore: 93
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 830
  policy_reward_mean: {}
  time_since_restore: 1097.3614993095398
  time_this_iter_s: 12.173061847686768
  time_total_s: 1097.3614993095398
  timestamp: 1593810890
  timesteps_since_restore: 465000
  timesteps_this_iter: 5000
  timesteps_total: 465000
  training_iteration: 93
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 10.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=830], 1097 s, 93 iter, 465000 ts, 424 rew

agent-1: 77.0
agent-2: 76.0
agent-3: 83.0
agent-4: 90.0
agent-5: 84.0
Sum Reward: 410.0
Avg Reward: 82.0
Min Reward: 76.0
Gini Coefficient 0.03414634146341464
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_17-15-02
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 735.0
  episode_reward_mean: 424.2258064516129
  episode_reward_min: -281.0
  episodes_this_iter: 1
  episodes_total: 93
  experiment_id: f3470259fa9143609a5dd5049ba7f979
  hostname: gpu020
  info:
    apply_time_ms: 2.661
    dispatch_time_ms: 6.277
    learner:
      cur_lr: 0.0013290309580042958
      grad_gnorm: 37.30091857910156
      policy_entropy: 33.84577178955078
      policy_loss: -2.707455635070801
      var_gnorm: 31.83377456665039
      vf_explained_var: -0.3375159502029419
      vf_loss: 0.280575692653656
    num_steps_sampled: 470000
    num_steps_trained: 470000
    wait_time_ms: 114.389
  iterations_since_restore: 94
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 830
  policy_reward_mean: {}
  time_since_restore: 1109.1632311344147
  time_this_iter_s: 11.801731824874878
  time_total_s: 1109.1632311344147
  timestamp: 1593810902
  timesteps_since_restore: 470000
  timesteps_this_iter: 5000
  timesteps_total: 470000
  training_iteration: 94
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 10.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=830], 1109 s, 94 iter, 470000 ts, 424 rew

agent-1: 74.0
agent-2: 71.0
agent-3: 63.0
agent-4: 51.0
agent-5: 45.0
Sum Reward: 304.0
Avg Reward: 60.8
Min Reward: 45.0
Gini Coefficient 0.10263157894736842
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_17-15-16
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 735.0
  episode_reward_mean: 422.9468085106383
  episode_reward_min: -281.0
  episodes_this_iter: 1
  episodes_total: 94
  experiment_id: f3470259fa9143609a5dd5049ba7f979
  hostname: gpu020
  info:
    apply_time_ms: 2.626
    dispatch_time_ms: 9.685
    learner:
      cur_lr: 0.0013286980101838708
      grad_gnorm: 5.836002826690674
      policy_entropy: 38.146549224853516
      policy_loss: 0.9078078866004944
      var_gnorm: 31.889877319335938
      vf_explained_var: -1.0
      vf_loss: 0.46978965401649475
    num_steps_sampled: 475000
    num_steps_trained: 475000
    wait_time_ms: 103.73
  iterations_since_restore: 95
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 830
  policy_reward_mean: {}
  time_since_restore: 1123.1595861911774
  time_this_iter_s: 13.996355056762695
  time_total_s: 1123.1595861911774
  timestamp: 1593810916
  timesteps_since_restore: 475000
  timesteps_this_iter: 5000
  timesteps_total: 475000
  training_iteration: 95
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 10.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=830], 1123 s, 95 iter, 475000 ts, 423 rew

agent-1: 65.0
agent-2: 75.0
agent-3: 57.0
agent-4: 68.0
agent-5: 50.0
Sum Reward: 315.0
Avg Reward: 63.0
Min Reward: 50.0
Gini Coefficient 0.07746031746031747
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_17-15-28
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 735.0
  episode_reward_mean: 421.81052631578945
  episode_reward_min: -281.0
  episodes_this_iter: 1
  episodes_total: 95
  experiment_id: f3470259fa9143609a5dd5049ba7f979
  hostname: gpu020
  info:
    apply_time_ms: 4.131
    dispatch_time_ms: 7.631
    learner:
      cur_lr: 0.001328364945948124
      grad_gnorm: 8.057040214538574
      policy_entropy: 27.350872039794922
      policy_loss: 0.9355410933494568
      var_gnorm: 32.01552963256836
      vf_explained_var: 0.18541556596755981
      vf_loss: 0.5362494587898254
    num_steps_sampled: 480000
    num_steps_trained: 480000
    wait_time_ms: 115.069
  iterations_since_restore: 96
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 830
  policy_reward_mean: {}
  time_since_restore: 1134.8692173957825
  time_this_iter_s: 11.709631204605103
  time_total_s: 1134.8692173957825
  timestamp: 1593810928
  timesteps_since_restore: 480000
  timesteps_this_iter: 5000
  timesteps_total: 480000
  training_iteration: 96
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 10.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=830], 1134 s, 96 iter, 480000 ts, 422 rew

agent-1: 75.0
agent-2: 60.0
agent-3: 71.0
agent-4: 63.0
agent-5: 63.0
Sum Reward: 332.0
Avg Reward: 66.4
Min Reward: 60.0
Gini Coefficient 0.04578313253012048
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_17-15-40
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 735.0
  episode_reward_mean: 420.875
  episode_reward_min: -281.0
  episodes_this_iter: 1
  episodes_total: 96
  experiment_id: f3470259fa9143609a5dd5049ba7f979
  hostname: gpu020
  info:
    apply_time_ms: 2.971
    dispatch_time_ms: 11.035
    learner:
      cur_lr: 0.001328031998127699
      grad_gnorm: 39.99999237060547
      policy_entropy: 21.916622161865234
      policy_loss: 2.6382193565368652
      var_gnorm: 32.04010009765625
      vf_explained_var: 0.14295953512191772
      vf_loss: 264.8368835449219
    num_steps_sampled: 485000
    num_steps_trained: 485000
    wait_time_ms: 103.776
  iterations_since_restore: 97
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 830
  policy_reward_mean: {}
  time_since_restore: 1147.1612429618835
  time_this_iter_s: 12.292025566101074
  time_total_s: 1147.1612429618835
  timestamp: 1593810940
  timesteps_since_restore: 485000
  timesteps_this_iter: 5000
  timesteps_total: 485000
  training_iteration: 97
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 10.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=830], 1147 s, 97 iter, 485000 ts, 421 rew

agent-1: 59.0
agent-2: 66.0
agent-3: 67.0
agent-4: 64.0
agent-5: 58.0
Sum Reward: 314.0
Avg Reward: 62.8
Min Reward: 58.0
Gini Coefficient 0.03184713375796178
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_17-15-52
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 735.0
  episode_reward_mean: 419.77319587628864
  episode_reward_min: -281.0
  episodes_this_iter: 1
  episodes_total: 97
  experiment_id: f3470259fa9143609a5dd5049ba7f979
  hostname: gpu020
  info:
    apply_time_ms: 3.158
    dispatch_time_ms: 7.312
    learner:
      cur_lr: 0.0013276990503072739
      grad_gnorm: 16.0732364654541
      policy_entropy: 50.9189567565918
      policy_loss: -4.405333995819092
      var_gnorm: 32.12606430053711
      vf_explained_var: 0.026816248893737793
      vf_loss: 0.19305719435214996
    num_steps_sampled: 490000
    num_steps_trained: 490000
    wait_time_ms: 116.149
  iterations_since_restore: 98
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 830
  policy_reward_mean: {}
  time_since_restore: 1158.9742529392242
  time_this_iter_s: 11.813009977340698
  time_total_s: 1158.9742529392242
  timestamp: 1593810952
  timesteps_since_restore: 490000
  timesteps_this_iter: 5000
  timesteps_total: 490000
  training_iteration: 98
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 10.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=830], 1158 s, 98 iter, 490000 ts, 420 rew

agent-1: 60.0
agent-2: 89.0
agent-3: 76.0
agent-4: 71.0
agent-5: 69.0
Sum Reward: 365.0
Avg Reward: 73.0
Min Reward: 60.0
Gini Coefficient 0.07123287671232877
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_17-16-04
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 735.0
  episode_reward_mean: 419.2142857142857
  episode_reward_min: -281.0
  episodes_this_iter: 1
  episodes_total: 98
  experiment_id: f3470259fa9143609a5dd5049ba7f979
  hostname: gpu020
  info:
    apply_time_ms: 2.873
    dispatch_time_ms: 8.119
    learner:
      cur_lr: 0.001327365986071527
      grad_gnorm: 40.000003814697266
      policy_entropy: 20.51904296875
      policy_loss: 1.7166255712509155
      var_gnorm: 32.146549224853516
      vf_explained_var: 0.17454659938812256
      vf_loss: 57.4622688293457
    num_steps_sampled: 495000
    num_steps_trained: 495000
    wait_time_ms: 111.17
  iterations_since_restore: 99
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 830
  policy_reward_mean: {}
  time_since_restore: 1171.2388370037079
  time_this_iter_s: 12.264584064483643
  time_total_s: 1171.2388370037079
  timestamp: 1593810964
  timesteps_since_restore: 495000
  timesteps_this_iter: 5000
  timesteps_total: 495000
  training_iteration: 99
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 10.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=830], 1171 s, 99 iter, 495000 ts, 419 rew

agent-1: 82.0
agent-2: 55.0
agent-3: 78.0
agent-4: 52.0
agent-5: 67.0
Sum Reward: 334.0
Avg Reward: 66.8
Min Reward: 52.0
Gini Coefficient 0.09940119760479042
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_17-16-19
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 735.0
  episode_reward_mean: 418.35353535353534
  episode_reward_min: -281.0
  episodes_this_iter: 1
  episodes_total: 99
  experiment_id: f3470259fa9143609a5dd5049ba7f979
  hostname: gpu020
  info:
    apply_time_ms: 3.42
    dispatch_time_ms: 12.587
    learner:
      cur_lr: 0.001327033038251102
      grad_gnorm: 39.99999237060547
      policy_entropy: 20.67019271850586
      policy_loss: 15.998778343200684
      var_gnorm: 32.276145935058594
      vf_explained_var: 0.6675103902816772
      vf_loss: 48.67871856689453
    num_steps_sampled: 500000
    num_steps_trained: 500000
    wait_time_ms: 99.831
  iterations_since_restore: 100
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 830
  policy_reward_mean: {}
  time_since_restore: 1185.3145468235016
  time_this_iter_s: 14.075709819793701
  time_total_s: 1185.3145468235016
  timestamp: 1593810979
  timesteps_since_restore: 500000
  timesteps_this_iter: 5000
  timesteps_total: 500000
  training_iteration: 100
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 10.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=830], 1185 s, 100 iter, 500000 ts, 418 rew

agent-1: 81.0
agent-2: 95.0
agent-3: 75.0
agent-4: 70.0
agent-5: 53.0
Sum Reward: 374.0
Avg Reward: 74.8
Min Reward: 53.0
Gini Coefficient 0.10160427807486631
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_17-16-31
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 735.0
  episode_reward_mean: 417.91
  episode_reward_min: -281.0
  episodes_this_iter: 1
  episodes_total: 100
  experiment_id: f3470259fa9143609a5dd5049ba7f979
  hostname: gpu020
  info:
    apply_time_ms: 3.568
    dispatch_time_ms: 9.064
    learner:
      cur_lr: 0.0013266999740153551
      grad_gnorm: 15.220780372619629
      policy_entropy: 47.584442138671875
      policy_loss: 0.9016434550285339
      var_gnorm: 32.4111213684082
      vf_explained_var: 0.6273938417434692
      vf_loss: 1.7481788396835327
    num_steps_sampled: 505000
    num_steps_trained: 505000
    wait_time_ms: 95.674
  iterations_since_restore: 101
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 830
  policy_reward_mean: {}
  time_since_restore: 1197.4122104644775
  time_this_iter_s: 12.097663640975952
  time_total_s: 1197.4122104644775
  timestamp: 1593810991
  timesteps_since_restore: 505000
  timesteps_this_iter: 5000
  timesteps_total: 505000
  training_iteration: 101
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 10.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=830], 1197 s, 101 iter, 505000 ts, 418 rew

agent-1: 93.0
agent-2: 123.0
agent-3: 95.0
agent-4: 96.0
agent-5: 101.0
Sum Reward: 508.0
Avg Reward: 101.6
Min Reward: 93.0
Gini Coefficient 0.05196850393700787
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_17-16-42
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 735.0
  episode_reward_mean: 425.25
  episode_reward_min: -281.0
  episodes_this_iter: 1
  episodes_total: 101
  experiment_id: f3470259fa9143609a5dd5049ba7f979
  hostname: gpu020
  info:
    apply_time_ms: 3.932
    dispatch_time_ms: 11.135
    learner:
      cur_lr: 0.00132636702619493
      grad_gnorm: 40.0
      policy_entropy: 10.275733947753906
      policy_loss: 8.230340003967285
      var_gnorm: 32.421424865722656
      vf_explained_var: 0.48499298095703125
      vf_loss: 133.21739196777344
    num_steps_sampled: 510000
    num_steps_trained: 510000
    wait_time_ms: 108.828
  iterations_since_restore: 102
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 830
  policy_reward_mean: {}
  time_since_restore: 1209.104192018509
  time_this_iter_s: 11.691981554031372
  time_total_s: 1209.104192018509
  timestamp: 1593811002
  timesteps_since_restore: 510000
  timesteps_this_iter: 5000
  timesteps_total: 510000
  training_iteration: 102
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 10.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=830], 1209 s, 102 iter, 510000 ts, 425 rew

agent-1: 82.0
agent-2: 86.0
agent-3: 62.0
agent-4: 65.0
agent-5: 73.0
Sum Reward: 368.0
Avg Reward: 73.6
Min Reward: 62.0
Gini Coefficient 0.07065217391304347
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_17-17-00
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 735.0
  episode_reward_mean: 431.74
  episode_reward_min: 297.0
  episodes_this_iter: 1
  episodes_total: 102
  experiment_id: f3470259fa9143609a5dd5049ba7f979
  hostname: gpu020
  info:
    apply_time_ms: 2.808
    dispatch_time_ms: 9.763
    learner:
      cur_lr: 0.0013260339619591832
      grad_gnorm: 13.07922077178955
      policy_entropy: 1.1198197603225708
      policy_loss: 0.004292005207389593
      var_gnorm: 32.55884552001953
      vf_explained_var: 0.19743579626083374
      vf_loss: 0.9698615670204163
    num_steps_sampled: 515000
    num_steps_trained: 515000
    wait_time_ms: 89.751
  iterations_since_restore: 103
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 830
  policy_reward_mean: {}
  time_since_restore: 1226.6666281223297
  time_this_iter_s: 17.5624361038208
  time_total_s: 1226.6666281223297
  timestamp: 1593811020
  timesteps_since_restore: 515000
  timesteps_this_iter: 5000
  timesteps_total: 515000
  training_iteration: 103
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 10.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=830], 1226 s, 103 iter, 515000 ts, 432 rew

agent-1: 72.0
agent-2: 90.0
agent-3: 97.0
agent-4: 85.0
agent-5: 66.0
Sum Reward: 410.0
Avg Reward: 82.0
Min Reward: 66.0
Gini Coefficient 0.07804878048780488
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_17-17-17
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 735.0
  episode_reward_mean: 430.56
  episode_reward_min: 297.0
  episodes_this_iter: 1
  episodes_total: 103
  experiment_id: f3470259fa9143609a5dd5049ba7f979
  hostname: gpu020
  info:
    apply_time_ms: 4.095
    dispatch_time_ms: 28.849
    learner:
      cur_lr: 0.0013257010141387582
      grad_gnorm: 40.00000762939453
      policy_entropy: 32.5907096862793
      policy_loss: -33.24049377441406
      var_gnorm: 32.631370544433594
      vf_explained_var: -0.9460669755935669
      vf_loss: 172.46551513671875
    num_steps_sampled: 520000
    num_steps_trained: 520000
    wait_time_ms: 52.075
  iterations_since_restore: 104
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 830
  policy_reward_mean: {}
  time_since_restore: 1243.609623670578
  time_this_iter_s: 16.94299554824829
  time_total_s: 1243.609623670578
  timestamp: 1593811037
  timesteps_since_restore: 520000
  timesteps_this_iter: 5000
  timesteps_total: 520000
  training_iteration: 104
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 10.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=830], 1243 s, 104 iter, 520000 ts, 431 rew

agent-1: 101.0
agent-2: 98.0
agent-3: 114.0
agent-4: 77.0
agent-5: 117.0
Sum Reward: 507.0
Avg Reward: 101.4
Min Reward: 77.0
Gini Coefficient 0.0757396449704142
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_17-17-29
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 735.0
  episode_reward_mean: 429.98
  episode_reward_min: 297.0
  episodes_this_iter: 1
  episodes_total: 104
  experiment_id: f3470259fa9143609a5dd5049ba7f979
  hostname: gpu020
  info:
    apply_time_ms: 5.175
    dispatch_time_ms: 57.768
    learner:
      cur_lr: 0.0013253679499030113
      grad_gnorm: 39.999996185302734
      policy_entropy: 11.600472450256348
      policy_loss: -0.6035640835762024
      var_gnorm: 32.81790542602539
      vf_explained_var: -0.28610527515411377
      vf_loss: 263.8004150390625
    num_steps_sampled: 525000
    num_steps_trained: 525000
    wait_time_ms: 79.272
  iterations_since_restore: 105
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 830
  policy_reward_mean: {}
  time_since_restore: 1255.3717832565308
  time_this_iter_s: 11.762159585952759
  time_total_s: 1255.3717832565308
  timestamp: 1593811049
  timesteps_since_restore: 525000
  timesteps_this_iter: 5000
  timesteps_total: 525000
  training_iteration: 105
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 10.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=830], 1255 s, 105 iter, 525000 ts, 430 rew

agent-1: 131.0
agent-2: 134.0
agent-3: 97.0
agent-4: 95.0
agent-5: 116.0
Sum Reward: 573.0
Avg Reward: 114.6
Min Reward: 95.0
Gini Coefficient 0.07818499127399652
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_17-17-42
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 735.0
  episode_reward_mean: 431.82
  episode_reward_min: 297.0
  episodes_this_iter: 1
  episodes_total: 105
  experiment_id: f3470259fa9143609a5dd5049ba7f979
  hostname: gpu020
  info:
    apply_time_ms: 6.928
    dispatch_time_ms: 32.809
    learner:
      cur_lr: 0.0013250350020825863
      grad_gnorm: 39.999977111816406
      policy_entropy: 37.404544830322266
      policy_loss: -29.318771362304688
      var_gnorm: 32.937564849853516
      vf_explained_var: 0.6229841709136963
      vf_loss: 20.957141876220703
    num_steps_sampled: 530000
    num_steps_trained: 530000
    wait_time_ms: 59.231
  iterations_since_restore: 106
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 830
  policy_reward_mean: {}
  time_since_restore: 1268.7365579605103
  time_this_iter_s: 13.364774703979492
  time_total_s: 1268.7365579605103
  timestamp: 1593811062
  timesteps_since_restore: 530000
  timesteps_this_iter: 5000
  timesteps_total: 530000
  training_iteration: 106
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 10.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=830], 1268 s, 106 iter, 530000 ts, 432 rew

agent-1: 116.0
agent-2: 112.0
agent-3: 66.0
agent-4: 83.0
agent-5: 133.0
Sum Reward: 510.0
Avg Reward: 102.0
Min Reward: 66.0
Gini Coefficient 0.13098039215686275
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_17-17-55
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 735.0
  episode_reward_mean: 431.55
  episode_reward_min: 297.0
  episodes_this_iter: 1
  episodes_total: 106
  experiment_id: f3470259fa9143609a5dd5049ba7f979
  hostname: gpu020
  info:
    apply_time_ms: 4.161
    dispatch_time_ms: 52.005
    learner:
      cur_lr: 0.0013247020542621613
      grad_gnorm: 32.08678436279297
      policy_entropy: 39.37799072265625
      policy_loss: -0.043617140501737595
      var_gnorm: 33.016231536865234
      vf_explained_var: 0.8438564538955688
      vf_loss: 10.062004089355469
    num_steps_sampled: 535000
    num_steps_trained: 535000
    wait_time_ms: 62.397
  iterations_since_restore: 107
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 830
  policy_reward_mean: {}
  time_since_restore: 1281.1700384616852
  time_this_iter_s: 12.433480501174927
  time_total_s: 1281.1700384616852
  timestamp: 1593811075
  timesteps_since_restore: 535000
  timesteps_this_iter: 5000
  timesteps_total: 535000
  training_iteration: 107
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 10.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=830], 1281 s, 107 iter, 535000 ts, 432 rew

agent-1: 67.0
agent-2: 74.0
agent-3: 81.0
agent-4: 96.0
agent-5: 70.0
Sum Reward: 388.0
Avg Reward: 77.6
Min Reward: 67.0
Gini Coefficient 0.0711340206185567
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_17-18-09
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 735.0
  episode_reward_mean: 430.29
  episode_reward_min: 297.0
  episodes_this_iter: 1
  episodes_total: 107
  experiment_id: f3470259fa9143609a5dd5049ba7f979
  hostname: gpu020
  info:
    apply_time_ms: 3.283
    dispatch_time_ms: 28.187
    learner:
      cur_lr: 0.0013243689900264144
      grad_gnorm: 39.9999885559082
      policy_entropy: 34.05633544921875
      policy_loss: 8.319896697998047
      var_gnorm: 33.09314727783203
      vf_explained_var: 0.981879472732544
      vf_loss: 17.550806045532227
    num_steps_sampled: 540000
    num_steps_trained: 540000
    wait_time_ms: 87.744
  iterations_since_restore: 108
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 830
  policy_reward_mean: {}
  time_since_restore: 1295.7393403053284
  time_this_iter_s: 14.569301843643188
  time_total_s: 1295.7393403053284
  timestamp: 1593811089
  timesteps_since_restore: 540000
  timesteps_this_iter: 5000
  timesteps_total: 540000
  training_iteration: 108
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 10.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=830], 1295 s, 108 iter, 540000 ts, 430 rew

agent-1: 76.0
agent-2: 102.0
agent-3: 92.0
agent-4: 80.0
agent-5: 124.0
Sum Reward: 474.0
Avg Reward: 94.8
Min Reward: 76.0
Gini Coefficient 0.09957805907172995
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_17-18-21
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 735.0
  episode_reward_mean: 430.4
  episode_reward_min: 297.0
  episodes_this_iter: 1
  episodes_total: 108
  experiment_id: f3470259fa9143609a5dd5049ba7f979
  hostname: gpu020
  info:
    apply_time_ms: 3.832
    dispatch_time_ms: 65.728
    learner:
      cur_lr: 0.0013240360422059894
      grad_gnorm: 40.0
      policy_entropy: 30.520694732666016
      policy_loss: 24.400436401367188
      var_gnorm: 33.1932487487793
      vf_explained_var: 0.018859267234802246
      vf_loss: 90.27920532226562
    num_steps_sampled: 545000
    num_steps_trained: 545000
    wait_time_ms: 32.235
  iterations_since_restore: 109
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 830
  policy_reward_mean: {}
  time_since_restore: 1307.232256412506
  time_this_iter_s: 11.492916107177734
  time_total_s: 1307.232256412506
  timestamp: 1593811101
  timesteps_since_restore: 545000
  timesteps_this_iter: 5000
  timesteps_total: 545000
  training_iteration: 109
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 10.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=830], 1307 s, 109 iter, 545000 ts, 430 rew

agent-1: 119.0
agent-2: 118.0
agent-3: 96.0
agent-4: 78.0
agent-5: 92.0
Sum Reward: 503.0
Avg Reward: 100.6
Min Reward: 78.0
Gini Coefficient 0.08588469184890656
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_17-18-32
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 716.0
  episode_reward_mean: 428.08
  episode_reward_min: 297.0
  episodes_this_iter: 1
  episodes_total: 109
  experiment_id: f3470259fa9143609a5dd5049ba7f979
  hostname: gpu020
  info:
    apply_time_ms: 3.018
    dispatch_time_ms: 7.175
    learner:
      cur_lr: 0.0013237029779702425
      grad_gnorm: 40.00000762939453
      policy_entropy: 39.81401824951172
      policy_loss: -10.067134857177734
      var_gnorm: 33.25908660888672
      vf_explained_var: -1.0
      vf_loss: 24.372133255004883
    num_steps_sampled: 550000
    num_steps_trained: 550000
    wait_time_ms: 114.579
  iterations_since_restore: 110
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 830
  policy_reward_mean: {}
  time_since_restore: 1318.5892856121063
  time_this_iter_s: 11.35702919960022
  time_total_s: 1318.5892856121063
  timestamp: 1593811112
  timesteps_since_restore: 550000
  timesteps_this_iter: 5000
  timesteps_total: 550000
  training_iteration: 110
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 10.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=830], 1318 s, 110 iter, 550000 ts, 428 rew

agent-1: 68.0
agent-2: 91.0
agent-3: 145.0
agent-4: 96.0
agent-5: 89.0
Sum Reward: 489.0
Avg Reward: 97.8
Min Reward: 68.0
Gini Coefficient 0.13169734151329243
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_17-18-44
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 716.0
  episode_reward_mean: 425.92
  episode_reward_min: 297.0
  episodes_this_iter: 1
  episodes_total: 110
  experiment_id: f3470259fa9143609a5dd5049ba7f979
  hostname: gpu020
  info:
    apply_time_ms: 2.942
    dispatch_time_ms: 8.444
    learner:
      cur_lr: 0.0013233700301498175
      grad_gnorm: 10.212994575500488
      policy_entropy: 30.502201080322266
      policy_loss: -1.7007255554199219
      var_gnorm: 33.333499908447266
      vf_explained_var: -2.384185791015625e-07
      vf_loss: 0.13652248680591583
    num_steps_sampled: 555000
    num_steps_trained: 555000
    wait_time_ms: 101.139
  iterations_since_restore: 111
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 830
  policy_reward_mean: {}
  time_since_restore: 1330.6846272945404
  time_this_iter_s: 12.095341682434082
  time_total_s: 1330.6846272945404
  timestamp: 1593811124
  timesteps_since_restore: 555000
  timesteps_this_iter: 5000
  timesteps_total: 555000
  training_iteration: 111
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 10.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=830], 1330 s, 111 iter, 555000 ts, 426 rew

agent-1: 91.0
agent-2: 65.0
agent-3: 98.0
agent-4: 72.0
agent-5: 63.0
Sum Reward: 389.0
Avg Reward: 77.8
Min Reward: 63.0
Gini Coefficient 0.09871465295629821
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_17-18-56
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 716.0
  episode_reward_mean: 423.6
  episode_reward_min: 297.0
  episodes_this_iter: 1
  episodes_total: 111
  experiment_id: f3470259fa9143609a5dd5049ba7f979
  hostname: gpu020
  info:
    apply_time_ms: 3.158
    dispatch_time_ms: 10.217
    learner:
      cur_lr: 0.0013230369659140706
      grad_gnorm: 40.000003814697266
      policy_entropy: 21.95473289489746
      policy_loss: 66.48886108398438
      var_gnorm: 33.37862777709961
      vf_explained_var: -1.0
      vf_loss: 274.8688049316406
    num_steps_sampled: 560000
    num_steps_trained: 560000
    wait_time_ms: 100.097
  iterations_since_restore: 112
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 830
  policy_reward_mean: {}
  time_since_restore: 1341.9873151779175
  time_this_iter_s: 11.302687883377075
  time_total_s: 1341.9873151779175
  timestamp: 1593811136
  timesteps_since_restore: 560000
  timesteps_this_iter: 5000
  timesteps_total: 560000
  training_iteration: 112
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 10.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=830], 1341 s, 112 iter, 560000 ts, 424 rew

agent-1: 137.0
agent-2: 149.0
agent-3: 146.0
agent-4: 77.0
agent-5: 84.0
Sum Reward: 593.0
Avg Reward: 118.6
Min Reward: 77.0
Gini Coefficient 0.13895446880269816
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_17-19-08
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 716.0
  episode_reward_mean: 424.16
  episode_reward_min: 297.0
  episodes_this_iter: 1
  episodes_total: 112
  experiment_id: f3470259fa9143609a5dd5049ba7f979
  hostname: gpu020
  info:
    apply_time_ms: 3.909
    dispatch_time_ms: 13.584
    learner:
      cur_lr: 0.0013227040180936456
      grad_gnorm: 1.1356275081634521
      policy_entropy: 29.060043334960938
      policy_loss: 0.1854853630065918
      var_gnorm: 33.47627639770508
      vf_explained_var: 0.0
      vf_loss: 0.0017144620651379228
    num_steps_sampled: 565000
    num_steps_trained: 565000
    wait_time_ms: 91.742
  iterations_since_restore: 113
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 830
  policy_reward_mean: {}
  time_since_restore: 1353.9417898654938
  time_this_iter_s: 11.954474687576294
  time_total_s: 1353.9417898654938
  timestamp: 1593811148
  timesteps_since_restore: 565000
  timesteps_this_iter: 5000
  timesteps_total: 565000
  training_iteration: 113
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 10.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=830], 1353 s, 113 iter, 565000 ts, 424 rew

agent-1: 97.0
agent-2: 73.0
agent-3: 77.0
agent-4: 88.0
agent-5: 96.0
Sum Reward: 431.0
Avg Reward: 86.2
Min Reward: 73.0
Gini Coefficient 0.062180974477958235
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_17-19-20
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 716.0
  episode_reward_mean: 424.61
  episode_reward_min: 297.0
  episodes_this_iter: 1
  episodes_total: 113
  experiment_id: f3470259fa9143609a5dd5049ba7f979
  hostname: gpu020
  info:
    apply_time_ms: 2.522
    dispatch_time_ms: 5.862
    learner:
      cur_lr: 0.0013223709538578987
      grad_gnorm: 40.0
      policy_entropy: 18.16364288330078
      policy_loss: -94.71819305419922
      var_gnorm: 33.51435852050781
      vf_explained_var: -0.07426536083221436
      vf_loss: 816.8653564453125
    num_steps_sampled: 570000
    num_steps_trained: 570000
    wait_time_ms: 103.58
  iterations_since_restore: 114
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 830
  policy_reward_mean: {}
  time_since_restore: 1366.2543132305145
  time_this_iter_s: 12.312523365020752
  time_total_s: 1366.2543132305145
  timestamp: 1593811160
  timesteps_since_restore: 570000
  timesteps_this_iter: 5000
  timesteps_total: 570000
  training_iteration: 114
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 10.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=830], 1366 s, 114 iter, 570000 ts, 425 rew

agent-1: 98.0
agent-2: 93.0
agent-3: 66.0
agent-4: 115.0
agent-5: 92.0
Sum Reward: 464.0
Avg Reward: 92.8
Min Reward: 66.0
Gini Coefficient 0.0896551724137931
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_17-19-32
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 716.0
  episode_reward_mean: 423.72
  episode_reward_min: 297.0
  episodes_this_iter: 1
  episodes_total: 114
  experiment_id: f3470259fa9143609a5dd5049ba7f979
  hostname: gpu020
  info:
    apply_time_ms: 3.493
    dispatch_time_ms: 8.489
    learner:
      cur_lr: 0.0013220380060374737
      grad_gnorm: 40.0
      policy_entropy: 35.059349060058594
      policy_loss: 15.368623733520508
      var_gnorm: 33.63221740722656
      vf_explained_var: 0.47179025411605835
      vf_loss: 29.656190872192383
    num_steps_sampled: 575000
    num_steps_trained: 575000
    wait_time_ms: 100.983
  iterations_since_restore: 115
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 830
  policy_reward_mean: {}
  time_since_restore: 1378.1981329917908
  time_this_iter_s: 11.943819761276245
  time_total_s: 1378.1981329917908
  timestamp: 1593811172
  timesteps_since_restore: 575000
  timesteps_this_iter: 5000
  timesteps_total: 575000
  training_iteration: 115
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 10.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=830], 1378 s, 115 iter, 575000 ts, 424 rew

agent-1: 101.0
agent-2: 136.0
agent-3: 82.0
agent-4: 93.0
agent-5: 107.0
Sum Reward: 519.0
Avg Reward: 103.8
Min Reward: 82.0
Gini Coefficient 0.09402697495183045
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_17-19-44
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 716.0
  episode_reward_mean: 424.1
  episode_reward_min: 297.0
  episodes_this_iter: 1
  episodes_total: 115
  experiment_id: f3470259fa9143609a5dd5049ba7f979
  hostname: gpu020
  info:
    apply_time_ms: 3.703
    dispatch_time_ms: 35.372
    learner:
      cur_lr: 0.0013217049418017268
      grad_gnorm: 40.0
      policy_entropy: 25.2403564453125
      policy_loss: 14.261127471923828
      var_gnorm: 33.6207275390625
      vf_explained_var: 0.52393639087677
      vf_loss: 293.73681640625
    num_steps_sampled: 580000
    num_steps_trained: 580000
    wait_time_ms: 82.591
  iterations_since_restore: 116
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 830
  policy_reward_mean: {}
  time_since_restore: 1390.0681638717651
  time_this_iter_s: 11.870030879974365
  time_total_s: 1390.0681638717651
  timestamp: 1593811184
  timesteps_since_restore: 580000
  timesteps_this_iter: 5000
  timesteps_total: 580000
  training_iteration: 116
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 10.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=830], 1390 s, 116 iter, 580000 ts, 424 rew

agent-1: 137.0
agent-2: 122.0
agent-3: 141.0
agent-4: 118.0
agent-5: 92.0
Sum Reward: 610.0
Avg Reward: 122.0
Min Reward: 92.0
Gini Coefficient 0.07672131147540984
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_17-19-57
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 716.0
  episode_reward_mean: 426.45
  episode_reward_min: 297.0
  episodes_this_iter: 1
  episodes_total: 116
  experiment_id: f3470259fa9143609a5dd5049ba7f979
  hostname: gpu020
  info:
    apply_time_ms: 3.293
    dispatch_time_ms: 52.586
    learner:
      cur_lr: 0.0013213719939813018
      grad_gnorm: 28.900577545166016
      policy_entropy: 29.50769805908203
      policy_loss: 0.816970944404602
      var_gnorm: 33.802371978759766
      vf_explained_var: 1.245737075805664e-05
      vf_loss: 0.9026104211807251
    num_steps_sampled: 585000
    num_steps_trained: 585000
    wait_time_ms: 40.223
  iterations_since_restore: 117
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 830
  policy_reward_mean: {}
  time_since_restore: 1402.8909335136414
  time_this_iter_s: 12.82276964187622
  time_total_s: 1402.8909335136414
  timestamp: 1593811197
  timesteps_since_restore: 585000
  timesteps_this_iter: 5000
  timesteps_total: 585000
  training_iteration: 117
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 10.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=830], 1402 s, 117 iter, 585000 ts, 426 rew

agent-1: 57.0
agent-2: 85.0
agent-3: 52.0
agent-4: 66.0
agent-5: 81.0
Sum Reward: 341.0
Avg Reward: 68.2
Min Reward: 52.0
Gini Coefficient 0.10557184750733138
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_17-20-08
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 716.0
  episode_reward_mean: 424.79
  episode_reward_min: 297.0
  episodes_this_iter: 1
  episodes_total: 117
  experiment_id: f3470259fa9143609a5dd5049ba7f979
  hostname: gpu020
  info:
    apply_time_ms: 2.797
    dispatch_time_ms: 9.375
    learner:
      cur_lr: 0.0013210390461608768
      grad_gnorm: 39.999996185302734
      policy_entropy: 41.93177795410156
      policy_loss: -17.0972900390625
      var_gnorm: 33.793521881103516
      vf_explained_var: -1.0
      vf_loss: 32.955875396728516
    num_steps_sampled: 590000
    num_steps_trained: 590000
    wait_time_ms: 110.225
  iterations_since_restore: 118
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 830
  policy_reward_mean: {}
  time_since_restore: 1413.676101922989
  time_this_iter_s: 10.785168409347534
  time_total_s: 1413.676101922989
  timestamp: 1593811208
  timesteps_since_restore: 590000
  timesteps_this_iter: 5000
  timesteps_total: 590000
  training_iteration: 118
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 10.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=830], 1413 s, 118 iter, 590000 ts, 425 rew

agent-1: 84.0
agent-2: 82.0
agent-3: 126.0
agent-4: 95.0
agent-5: 108.0
Sum Reward: 495.0
Avg Reward: 99.0
Min Reward: 82.0
Gini Coefficient 0.0905050505050505
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_17-20-19
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 716.0
  episode_reward_mean: 425.46
  episode_reward_min: 297.0
  episodes_this_iter: 1
  episodes_total: 118
  experiment_id: f3470259fa9143609a5dd5049ba7f979
  hostname: gpu020
  info:
    apply_time_ms: 3.531
    dispatch_time_ms: 11.884
    learner:
      cur_lr: 0.0013207059819251299
      grad_gnorm: 40.0
      policy_entropy: 13.251705169677734
      policy_loss: 10.723515510559082
      var_gnorm: 33.88045120239258
      vf_explained_var: 0.049599289894104004
      vf_loss: 30.382150650024414
    num_steps_sampled: 595000
    num_steps_trained: 595000
    wait_time_ms: 95.276
  iterations_since_restore: 119
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 830
  policy_reward_mean: {}
  time_since_restore: 1425.351444721222
  time_this_iter_s: 11.675342798233032
  time_total_s: 1425.351444721222
  timestamp: 1593811219
  timesteps_since_restore: 595000
  timesteps_this_iter: 5000
  timesteps_total: 595000
  training_iteration: 119
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 10.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=830], 1425 s, 119 iter, 595000 ts, 425 rew

agent-1: 129.0
agent-2: 129.0
agent-3: 139.0
agent-4: 125.0
agent-5: 129.0
Sum Reward: 651.0
Avg Reward: 130.2
Min Reward: 125.0
Gini Coefficient 0.017204301075268817
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_17-20-32
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 716.0
  episode_reward_mean: 428.63
  episode_reward_min: 297.0
  episodes_this_iter: 1
  episodes_total: 119
  experiment_id: f3470259fa9143609a5dd5049ba7f979
  hostname: gpu020
  info:
    apply_time_ms: 2.625
    dispatch_time_ms: 29.338
    learner:
      cur_lr: 0.0013203730341047049
      grad_gnorm: 40.0
      policy_entropy: 31.517168045043945
      policy_loss: 10.557544708251953
      var_gnorm: 34.021400451660156
      vf_explained_var: 0.9356046915054321
      vf_loss: 66.1997299194336
    num_steps_sampled: 600000
    num_steps_trained: 600000
    wait_time_ms: 80.562
  iterations_since_restore: 120
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 830
  policy_reward_mean: {}
  time_since_restore: 1437.7841601371765
  time_this_iter_s: 12.43271541595459
  time_total_s: 1437.7841601371765
  timestamp: 1593811232
  timesteps_since_restore: 600000
  timesteps_this_iter: 5000
  timesteps_total: 600000
  training_iteration: 120
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 10.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=830], 1437 s, 120 iter, 600000 ts, 429 rew

agent-1: 103.0
agent-2: 126.0
agent-3: 83.0
agent-4: 92.0
agent-5: 127.0
Sum Reward: 531.0
Avg Reward: 106.2
Min Reward: 83.0
Gini Coefficient 0.09190207156308851
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_17-20-43
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 716.0
  episode_reward_mean: 429.73
  episode_reward_min: 297.0
  episodes_this_iter: 1
  episodes_total: 120
  experiment_id: f3470259fa9143609a5dd5049ba7f979
  hostname: gpu020
  info:
    apply_time_ms: 3.466
    dispatch_time_ms: 7.228
    learner:
      cur_lr: 0.001320039969868958
      grad_gnorm: 39.999996185302734
      policy_entropy: 32.027400970458984
      policy_loss: -7.6880388259887695
      var_gnorm: 34.17489242553711
      vf_explained_var: 0.6192235946655273
      vf_loss: 83.649658203125
    num_steps_sampled: 605000
    num_steps_trained: 605000
    wait_time_ms: 96.644
  iterations_since_restore: 121
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 830
  policy_reward_mean: {}
  time_since_restore: 1448.2599844932556
  time_this_iter_s: 10.475824356079102
  time_total_s: 1448.2599844932556
  timestamp: 1593811243
  timesteps_since_restore: 605000
  timesteps_this_iter: 5000
  timesteps_total: 605000
  training_iteration: 121
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 10.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=830], 1448 s, 121 iter, 605000 ts, 430 rew

agent-1: 84.0
agent-2: 96.0
agent-3: 92.0
agent-4: 110.0
agent-5: 106.0
Sum Reward: 488.0
Avg Reward: 97.6
Min Reward: 84.0
Gini Coefficient 0.054098360655737705
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_17-20-54
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 716.0
  episode_reward_mean: 429.72
  episode_reward_min: 297.0
  episodes_this_iter: 1
  episodes_total: 121
  experiment_id: f3470259fa9143609a5dd5049ba7f979
  hostname: gpu020
  info:
    apply_time_ms: 3.065
    dispatch_time_ms: 9.393
    learner:
      cur_lr: 0.001319707022048533
      grad_gnorm: 39.9999885559082
      policy_entropy: 33.247745513916016
      policy_loss: -5.726599216461182
      var_gnorm: 34.20343017578125
      vf_explained_var: -0.0003199577331542969
      vf_loss: 44.5389518737793
    num_steps_sampled: 610000
    num_steps_trained: 610000
    wait_time_ms: 106.063
  iterations_since_restore: 122
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 830
  policy_reward_mean: {}
  time_since_restore: 1459.2580394744873
  time_this_iter_s: 10.99805498123169
  time_total_s: 1459.2580394744873
  timestamp: 1593811254
  timesteps_since_restore: 610000
  timesteps_this_iter: 5000
  timesteps_total: 610000
  training_iteration: 122
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 10.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=830], 1459 s, 122 iter, 610000 ts, 430 rew

agent-1: 81.0
agent-2: 106.0
agent-3: 93.0
agent-4: 109.0
agent-5: 125.0
Sum Reward: 514.0
Avg Reward: 102.8
Min Reward: 81.0
Gini Coefficient 0.08093385214007782
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_17-21-06
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 716.0
  episode_reward_mean: 430.22
  episode_reward_min: 297.0
  episodes_this_iter: 1
  episodes_total: 122
  experiment_id: f3470259fa9143609a5dd5049ba7f979
  hostname: gpu020
  info:
    apply_time_ms: 2.501
    dispatch_time_ms: 11.872
    learner:
      cur_lr: 0.001319373957812786
      grad_gnorm: 8.45956802368164
      policy_entropy: 4.540019512176514
      policy_loss: -0.05461094528436661
      var_gnorm: 34.2886848449707
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 0.0963449701666832
    num_steps_sampled: 615000
    num_steps_trained: 615000
    wait_time_ms: 88.087
  iterations_since_restore: 123
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 830
  policy_reward_mean: {}
  time_since_restore: 1471.6614429950714
  time_this_iter_s: 12.403403520584106
  time_total_s: 1471.6614429950714
  timestamp: 1593811266
  timesteps_since_restore: 615000
  timesteps_this_iter: 5000
  timesteps_total: 615000
  training_iteration: 123
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 10.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=830], 1471 s, 123 iter, 615000 ts, 430 rew

agent-1: 68.0
agent-2: 77.0
agent-3: 80.0
agent-4: 80.0
agent-5: 65.0
Sum Reward: 370.0
Avg Reward: 74.0
Min Reward: 65.0
Gini Coefficient 0.04540540540540541
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_17-21-17
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 716.0
  episode_reward_mean: 430.17
  episode_reward_min: 297.0
  episodes_this_iter: 1
  episodes_total: 123
  experiment_id: f3470259fa9143609a5dd5049ba7f979
  hostname: gpu020
  info:
    apply_time_ms: 2.868
    dispatch_time_ms: 6.508
    learner:
      cur_lr: 0.001319041009992361
      grad_gnorm: 40.0
      policy_entropy: 12.488977432250977
      policy_loss: -13.543500900268555
      var_gnorm: 34.30119705200195
      vf_explained_var: -1.0
      vf_loss: 158.31724548339844
    num_steps_sampled: 620000
    num_steps_trained: 620000
    wait_time_ms: 109.258
  iterations_since_restore: 124
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 830
  policy_reward_mean: {}
  time_since_restore: 1482.6492619514465
  time_this_iter_s: 10.987818956375122
  time_total_s: 1482.6492619514465
  timestamp: 1593811277
  timesteps_since_restore: 620000
  timesteps_this_iter: 5000
  timesteps_total: 620000
  training_iteration: 124
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 10.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=830], 1482 s, 124 iter, 620000 ts, 430 rew

agent-1: 99.0
agent-2: 96.0
agent-3: 85.0
agent-4: 109.0
agent-5: 137.0
Sum Reward: 526.0
Avg Reward: 105.2
Min Reward: 85.0
Gini Coefficient 0.08897338403041825
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_17-21-31
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 716.0
  episode_reward_mean: 432.06
  episode_reward_min: 297.0
  episodes_this_iter: 1
  episodes_total: 124
  experiment_id: f3470259fa9143609a5dd5049ba7f979
  hostname: gpu020
  info:
    apply_time_ms: 3.324
    dispatch_time_ms: 69.875
    learner:
      cur_lr: 0.0013187079457566142
      grad_gnorm: 40.000003814697266
      policy_entropy: 9.609881401062012
      policy_loss: -0.3626399338245392
      var_gnorm: 34.43694305419922
      vf_explained_var: 0.2962113618850708
      vf_loss: 57.89305114746094
    num_steps_sampled: 625000
    num_steps_trained: 625000
    wait_time_ms: 68.225
  iterations_since_restore: 125
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 830
  policy_reward_mean: {}
  time_since_restore: 1495.8652334213257
  time_this_iter_s: 13.21597146987915
  time_total_s: 1495.8652334213257
  timestamp: 1593811291
  timesteps_since_restore: 625000
  timesteps_this_iter: 5000
  timesteps_total: 625000
  training_iteration: 125
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 10.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=830], 1495 s, 125 iter, 625000 ts, 432 rew

agent-1: 122.0
agent-2: 87.0
agent-3: 87.0
agent-4: 97.0
agent-5: 83.0
Sum Reward: 476.0
Avg Reward: 95.2
Min Reward: 83.0
Gini Coefficient 0.07394957983193277
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_17-21-43
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 716.0
  episode_reward_mean: 432.83
  episode_reward_min: 297.0
  episodes_this_iter: 1
  episodes_total: 125
  experiment_id: f3470259fa9143609a5dd5049ba7f979
  hostname: gpu020
  info:
    apply_time_ms: 2.967
    dispatch_time_ms: 18.76
    learner:
      cur_lr: 0.0013183749979361892
      grad_gnorm: 40.00001525878906
      policy_entropy: 37.8169059753418
      policy_loss: -6.012312412261963
      var_gnorm: 34.47395706176758
      vf_explained_var: -1.0
      vf_loss: 0.7488254904747009
    num_steps_sampled: 630000
    num_steps_trained: 630000
    wait_time_ms: 83.152
  iterations_since_restore: 126
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 830
  policy_reward_mean: {}
  time_since_restore: 1508.036689043045
  time_this_iter_s: 12.17145562171936
  time_total_s: 1508.036689043045
  timestamp: 1593811303
  timesteps_since_restore: 630000
  timesteps_this_iter: 5000
  timesteps_total: 630000
  training_iteration: 126
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 10.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=830], 1508 s, 126 iter, 630000 ts, 433 rew

agent-1: 83.0
agent-2: 105.0
agent-3: 99.0
agent-4: 100.0
agent-5: 96.0
Sum Reward: 483.0
Avg Reward: 96.6
Min Reward: 83.0
Gini Coefficient 0.03975155279503106
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_17-21-54
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 716.0
  episode_reward_mean: 433.45
  episode_reward_min: 297.0
  episodes_this_iter: 1
  episodes_total: 126
  experiment_id: f3470259fa9143609a5dd5049ba7f979
  hostname: gpu020
  info:
    apply_time_ms: 3.915
    dispatch_time_ms: 13.193
    learner:
      cur_lr: 0.0013180420501157641
      grad_gnorm: 40.0
      policy_entropy: 13.036713600158691
      policy_loss: 8.921598434448242
      var_gnorm: 34.59334945678711
      vf_explained_var: 0.05160415172576904
      vf_loss: 32.43072509765625
    num_steps_sampled: 635000
    num_steps_trained: 635000
    wait_time_ms: 81.078
  iterations_since_restore: 127
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 830
  policy_reward_mean: {}
  time_since_restore: 1519.288318157196
  time_this_iter_s: 11.251629114151001
  time_total_s: 1519.288318157196
  timestamp: 1593811314
  timesteps_since_restore: 635000
  timesteps_this_iter: 5000
  timesteps_total: 635000
  training_iteration: 127
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 10.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=830], 1519 s, 127 iter, 635000 ts, 433 rew

agent-1: 178.0
agent-2: 164.0
agent-3: 149.0
agent-4: 181.0
agent-5: 148.0
Sum Reward: 820.0
Avg Reward: 164.0
Min Reward: 148.0
Gini Coefficient 0.046341463414634146
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_17-22-07
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 820.0
  episode_reward_mean: 437.37
  episode_reward_min: 297.0
  episodes_this_iter: 1
  episodes_total: 127
  experiment_id: f3470259fa9143609a5dd5049ba7f979
  hostname: gpu020
  info:
    apply_time_ms: 4.462
    dispatch_time_ms: 10.705
    learner:
      cur_lr: 0.0013177089858800173
      grad_gnorm: 39.99998092651367
      policy_entropy: 15.750553131103516
      policy_loss: -2.0938262939453125
      var_gnorm: 34.740875244140625
      vf_explained_var: 0.33475250005722046
      vf_loss: 18.2302303314209
    num_steps_sampled: 640000
    num_steps_trained: 640000
    wait_time_ms: 102.41
  iterations_since_restore: 128
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 830
  policy_reward_mean: {}
  time_since_restore: 1531.6929779052734
  time_this_iter_s: 12.404659748077393
  time_total_s: 1531.6929779052734
  timestamp: 1593811327
  timesteps_since_restore: 640000
  timesteps_this_iter: 5000
  timesteps_total: 640000
  training_iteration: 128
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 10.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=830], 1531 s, 128 iter, 640000 ts, 437 rew

agent-1: 114.0
agent-2: 97.0
agent-3: 100.0
agent-4: 98.0
agent-5: 72.0
Sum Reward: 481.0
Avg Reward: 96.2
Min Reward: 72.0
Gini Coefficient 0.07234927234927235
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_17-22-21
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 820.0
  episode_reward_mean: 437.35
  episode_reward_min: 297.0
  episodes_this_iter: 1
  episodes_total: 128
  experiment_id: f3470259fa9143609a5dd5049ba7f979
  hostname: gpu020
  info:
    apply_time_ms: 3.63
    dispatch_time_ms: 59.586
    learner:
      cur_lr: 0.0013173760380595922
      grad_gnorm: 21.77304458618164
      policy_entropy: 40.114524841308594
      policy_loss: -2.1112303733825684
      var_gnorm: 34.860015869140625
      vf_explained_var: 0.0
      vf_loss: 0.5212010741233826
    num_steps_sampled: 645000
    num_steps_trained: 645000
    wait_time_ms: 61.925
  iterations_since_restore: 129
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 830
  policy_reward_mean: {}
  time_since_restore: 1546.604704618454
  time_this_iter_s: 14.911726713180542
  time_total_s: 1546.604704618454
  timestamp: 1593811341
  timesteps_since_restore: 645000
  timesteps_this_iter: 5000
  timesteps_total: 645000
  training_iteration: 129
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 10.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=830], 1546 s, 129 iter, 645000 ts, 437 rew

agent-1: 69.0
agent-2: 103.0
agent-3: 93.0
agent-4: 108.0
agent-5: 89.0
Sum Reward: 462.0
Avg Reward: 92.4
Min Reward: 69.0
Gini Coefficient 0.07965367965367966
W0703 17:22:57.106801   825 task_dependency_manager.cc:259] Task lease to renew has already expired by -15887ms
W0703 17:22:57.133911   825 task_dependency_manager.cc:259] Task lease to renew has already expired by -10110ms
W0703 17:22:57.207044   825 node_manager.cc:250] Last heartbeat was sent 25947 ms ago 
W0703 17:22:58.785670   825 node_manager.cc:250] Last heartbeat was sent 1579 ms ago 
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_17-23-00
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 820.0
  episode_reward_mean: 437.27
  episode_reward_min: 297.0
  episodes_this_iter: 1
  episodes_total: 129
  experiment_id: f3470259fa9143609a5dd5049ba7f979
  hostname: gpu020
  info:
    apply_time_ms: 2.795
    dispatch_time_ms: 16.56
    learner:
      cur_lr: 0.0013170429738238454
      grad_gnorm: 39.99999237060547
      policy_entropy: 33.36540222167969
      policy_loss: -1.3662912845611572
      var_gnorm: 34.912254333496094
      vf_explained_var: 0.26583003997802734
      vf_loss: 7.514410495758057
    num_steps_sampled: 650000
    num_steps_trained: 650000
    wait_time_ms: 90.238
  iterations_since_restore: 130
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 830
  policy_reward_mean: {}
  time_since_restore: 1585.1480584144592
  time_this_iter_s: 38.54335379600525
  time_total_s: 1585.1480584144592
  timestamp: 1593811380
  timesteps_since_restore: 650000
  timesteps_this_iter: 5000
  timesteps_total: 650000
  training_iteration: 130
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 10.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=830], 1585 s, 130 iter, 650000 ts, 437 rew

agent-1: 101.0
agent-2: 83.0
agent-3: 87.0
agent-4: 84.0
agent-5: 90.0
Sum Reward: 445.0
Avg Reward: 89.0
Min Reward: 83.0
Gini Coefficient 0.03775280898876404
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_17-23-14
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 820.0
  episode_reward_mean: 437.36
  episode_reward_min: 297.0
  episodes_this_iter: 1
  episodes_total: 130
  experiment_id: f3470259fa9143609a5dd5049ba7f979
  hostname: gpu020
  info:
    apply_time_ms: 3.328
    dispatch_time_ms: 14.362
    learner:
      cur_lr: 0.0013167100260034204
      grad_gnorm: 20.760986328125
      policy_entropy: 44.0552864074707
      policy_loss: -3.264738082885742
      var_gnorm: 34.9761962890625
      vf_explained_var: 0.9362003803253174
      vf_loss: 0.5630538463592529
    num_steps_sampled: 655000
    num_steps_trained: 655000
    wait_time_ms: 92.51
  iterations_since_restore: 131
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 830
  policy_reward_mean: {}
  time_since_restore: 1599.2076342105865
  time_this_iter_s: 14.05957579612732
  time_total_s: 1599.2076342105865
  timestamp: 1593811394
  timesteps_since_restore: 655000
  timesteps_this_iter: 5000
  timesteps_total: 655000
  training_iteration: 131
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 10.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=830], 1599 s, 131 iter, 655000 ts, 437 rew

agent-1: 89.0
agent-2: 100.0
agent-3: 98.0
agent-4: 96.0
agent-5: 110.0
Sum Reward: 493.0
Avg Reward: 98.6
Min Reward: 89.0
Gini Coefficient 0.037322515212981744
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_17-23-25
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 820.0
  episode_reward_mean: 438.59
  episode_reward_min: 297.0
  episodes_this_iter: 1
  episodes_total: 131
  experiment_id: f3470259fa9143609a5dd5049ba7f979
  hostname: gpu020
  info:
    apply_time_ms: 2.541
    dispatch_time_ms: 14.969
    learner:
      cur_lr: 0.0013163769617676735
      grad_gnorm: 40.00000762939453
      policy_entropy: 15.112964630126953
      policy_loss: 29.92982292175293
      var_gnorm: 35.06880187988281
      vf_explained_var: 0.2653105854988098
      vf_loss: 146.51075744628906
    num_steps_sampled: 660000
    num_steps_trained: 660000
    wait_time_ms: 98.605
  iterations_since_restore: 132
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 830
  policy_reward_mean: {}
  time_since_restore: 1610.4869232177734
  time_this_iter_s: 11.27928900718689
  time_total_s: 1610.4869232177734
  timestamp: 1593811405
  timesteps_since_restore: 660000
  timesteps_this_iter: 5000
  timesteps_total: 660000
  training_iteration: 132
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 10.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=830], 1610 s, 132 iter, 660000 ts, 439 rew

agent-1: 136.0
agent-2: 146.0
agent-3: 115.0
agent-4: 94.0
agent-5: 111.0
Sum Reward: 602.0
Avg Reward: 120.4
Min Reward: 94.0
Gini Coefficient 0.08571428571428572
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_17-23-38
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 820.0
  episode_reward_mean: 440.68
  episode_reward_min: 297.0
  episodes_this_iter: 1
  episodes_total: 132
  experiment_id: f3470259fa9143609a5dd5049ba7f979
  hostname: gpu020
  info:
    apply_time_ms: 3.449
    dispatch_time_ms: 49.343
    learner:
      cur_lr: 0.0013160440139472485
      grad_gnorm: 1.1554720401763916
      policy_entropy: 42.62157440185547
      policy_loss: -1.1250121593475342
      var_gnorm: 35.12315368652344
      vf_explained_var: 1.1920928955078125e-07
      vf_loss: 0.005627843085676432
    num_steps_sampled: 665000
    num_steps_trained: 665000
    wait_time_ms: 65.197
  iterations_since_restore: 133
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 830
  policy_reward_mean: {}
  time_since_restore: 1623.4758269786835
  time_this_iter_s: 12.988903760910034
  time_total_s: 1623.4758269786835
  timestamp: 1593811418
  timesteps_since_restore: 665000
  timesteps_this_iter: 5000
  timesteps_total: 665000
  training_iteration: 133
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 10.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=830], 1623 s, 133 iter, 665000 ts, 441 rew

agent-1: 68.0
agent-2: 67.0
agent-3: 52.0
agent-4: 50.0
agent-5: 62.0
Sum Reward: 299.0
Avg Reward: 59.8
Min Reward: 50.0
Gini Coefficient 0.06822742474916388
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_17-23-49
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 820.0
  episode_reward_mean: 439.33
  episode_reward_min: 297.0
  episodes_this_iter: 1
  episodes_total: 133
  experiment_id: f3470259fa9143609a5dd5049ba7f979
  hostname: gpu020
  info:
    apply_time_ms: 2.528
    dispatch_time_ms: 8.422
    learner:
      cur_lr: 0.0013157109497115016
      grad_gnorm: 40.0000114440918
      policy_entropy: 39.106292724609375
      policy_loss: 6.015456199645996
      var_gnorm: 35.178062438964844
      vf_explained_var: 0.6823480129241943
      vf_loss: 21.711795806884766
    num_steps_sampled: 670000
    num_steps_trained: 670000
    wait_time_ms: 109.396
  iterations_since_restore: 134
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 830
  policy_reward_mean: {}
  time_since_restore: 1634.3850224018097
  time_this_iter_s: 10.90919542312622
  time_total_s: 1634.3850224018097
  timestamp: 1593811429
  timesteps_since_restore: 670000
  timesteps_this_iter: 5000
  timesteps_total: 670000
  training_iteration: 134
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 10.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=830], 1634 s, 134 iter, 670000 ts, 439 rew

agent-1: 88.0
agent-2: 74.0
agent-3: 57.0
agent-4: 82.0
agent-5: 81.0
Sum Reward: 382.0
Avg Reward: 76.4
Min Reward: 57.0
Gini Coefficient 0.07329842931937172
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_17-24-01
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 820.0
  episode_reward_mean: 439.53
  episode_reward_min: 297.0
  episodes_this_iter: 1
  episodes_total: 134
  experiment_id: f3470259fa9143609a5dd5049ba7f979
  hostname: gpu020
  info:
    apply_time_ms: 2.807
    dispatch_time_ms: 13.082
    learner:
      cur_lr: 0.0013153780018910766
      grad_gnorm: 39.99999237060547
      policy_entropy: 16.34371566772461
      policy_loss: 8.771994590759277
      var_gnorm: 35.231483459472656
      vf_explained_var: -0.23087728023529053
      vf_loss: 62.80004119873047
    num_steps_sampled: 675000
    num_steps_trained: 675000
    wait_time_ms: 93.372
  iterations_since_restore: 135
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 830
  policy_reward_mean: {}
  time_since_restore: 1646.286069393158
  time_this_iter_s: 11.901046991348267
  time_total_s: 1646.286069393158
  timestamp: 1593811441
  timesteps_since_restore: 675000
  timesteps_this_iter: 5000
  timesteps_total: 675000
  training_iteration: 135
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 10.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=830], 1646 s, 135 iter, 675000 ts, 440 rew

agent-1: 100.0
agent-2: 86.0
agent-3: 101.0
agent-4: 87.0
agent-5: 91.0
Sum Reward: 465.0
Avg Reward: 93.0
Min Reward: 86.0
Gini Coefficient 0.036989247311827955
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_17-24-14
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 820.0
  episode_reward_mean: 440.76
  episode_reward_min: 297.0
  episodes_this_iter: 1
  episodes_total: 135
  experiment_id: f3470259fa9143609a5dd5049ba7f979
  hostname: gpu020
  info:
    apply_time_ms: 2.968
    dispatch_time_ms: 9.366
    learner:
      cur_lr: 0.0013150450540706515
      grad_gnorm: 40.0
      policy_entropy: 38.181053161621094
      policy_loss: -4.830958843231201
      var_gnorm: 35.264286041259766
      vf_explained_var: -1.0
      vf_loss: 1.3136391639709473
    num_steps_sampled: 680000
    num_steps_trained: 680000
    wait_time_ms: 28.436
  iterations_since_restore: 136
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 830
  policy_reward_mean: {}
  time_since_restore: 1658.462947845459
  time_this_iter_s: 12.176878452301025
  time_total_s: 1658.462947845459
  timestamp: 1593811454
  timesteps_since_restore: 680000
  timesteps_this_iter: 5000
  timesteps_total: 680000
  training_iteration: 136
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 10.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=830], 1658 s, 136 iter, 680000 ts, 441 rew

agent-1: 90.0
agent-2: 106.0
agent-3: 95.0
agent-4: 88.0
agent-5: 107.0
Sum Reward: 486.0
Avg Reward: 97.2
Min Reward: 88.0
Gini Coefficient 0.044444444444444446
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_17-24-25
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 820.0
  episode_reward_mean: 441.3
  episode_reward_min: 297.0
  episodes_this_iter: 1
  episodes_total: 136
  experiment_id: f3470259fa9143609a5dd5049ba7f979
  hostname: gpu020
  info:
    apply_time_ms: 3.011
    dispatch_time_ms: 15.705
    learner:
      cur_lr: 0.0013147119898349047
      grad_gnorm: 20.690942764282227
      policy_entropy: 5.736157417297363
      policy_loss: 3.8328354358673096
      var_gnorm: 35.325279235839844
      vf_explained_var: 0.006508052349090576
      vf_loss: 23.580352783203125
    num_steps_sampled: 685000
    num_steps_trained: 685000
    wait_time_ms: 88.019
  iterations_since_restore: 137
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 830
  policy_reward_mean: {}
  time_since_restore: 1670.0186429023743
  time_this_iter_s: 11.555695056915283
  time_total_s: 1670.0186429023743
  timestamp: 1593811465
  timesteps_since_restore: 685000
  timesteps_this_iter: 5000
  timesteps_total: 685000
  training_iteration: 137
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 10.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=830], 1670 s, 137 iter, 685000 ts, 441 rew

agent-1: 86.0
agent-2: 86.0
agent-3: 59.0
agent-4: 89.0
agent-5: 77.0
Sum Reward: 397.0
Avg Reward: 79.4
Min Reward: 59.0
Gini Coefficient 0.06952141057934509
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_17-24-36
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 820.0
  episode_reward_mean: 440.43
  episode_reward_min: 297.0
  episodes_this_iter: 1
  episodes_total: 137
  experiment_id: f3470259fa9143609a5dd5049ba7f979
  hostname: gpu020
  info:
    apply_time_ms: 2.872
    dispatch_time_ms: 9.76
    learner:
      cur_lr: 0.0013143790420144796
      grad_gnorm: 39.99999237060547
      policy_entropy: 29.529705047607422
      policy_loss: -0.8803579807281494
      var_gnorm: 35.34884262084961
      vf_explained_var: 0.9890449047088623
      vf_loss: 13.214180946350098
    num_steps_sampled: 690000
    num_steps_trained: 690000
    wait_time_ms: 93.892
  iterations_since_restore: 138
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 830
  policy_reward_mean: {}
  time_since_restore: 1681.2382984161377
  time_this_iter_s: 11.219655513763428
  time_total_s: 1681.2382984161377
  timestamp: 1593811476
  timesteps_since_restore: 690000
  timesteps_this_iter: 5000
  timesteps_total: 690000
  training_iteration: 138
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 10.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=830], 1681 s, 138 iter, 690000 ts, 440 rew

agent-1: 125.0
agent-2: 104.0
agent-3: 144.0
agent-4: 131.0
agent-5: 115.0
Sum Reward: 619.0
Avg Reward: 123.8
Min Reward: 104.0
Gini Coefficient 0.06203554119547657
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_17-24-51
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 820.0
  episode_reward_mean: 442.38
  episode_reward_min: 297.0
  episodes_this_iter: 1
  episodes_total: 138
  experiment_id: f3470259fa9143609a5dd5049ba7f979
  hostname: gpu020
  info:
    apply_time_ms: 2.725
    dispatch_time_ms: 14.598
    learner:
      cur_lr: 0.0013140459777787328
      grad_gnorm: 14.535318374633789
      policy_entropy: 22.761537551879883
      policy_loss: -3.8343026638031006
      var_gnorm: 35.458126068115234
      vf_explained_var: 0.0
      vf_loss: 0.2701895236968994
    num_steps_sampled: 695000
    num_steps_trained: 695000
    wait_time_ms: 98.318
  iterations_since_restore: 139
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 830
  policy_reward_mean: {}
  time_since_restore: 1695.6385037899017
  time_this_iter_s: 14.400205373764038
  time_total_s: 1695.6385037899017
  timestamp: 1593811491
  timesteps_since_restore: 695000
  timesteps_this_iter: 5000
  timesteps_total: 695000
  training_iteration: 139
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 10.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=830], 1695 s, 139 iter, 695000 ts, 442 rew

agent-1: 103.0
agent-2: 88.0
agent-3: 109.0
agent-4: 139.0
agent-5: 113.0
Sum Reward: 552.0
Avg Reward: 110.4
Min Reward: 88.0
Gini Coefficient 0.08115942028985507
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_17-25-03
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 820.0
  episode_reward_mean: 443.74
  episode_reward_min: 297.0
  episodes_this_iter: 1
  episodes_total: 139
  experiment_id: f3470259fa9143609a5dd5049ba7f979
  hostname: gpu020
  info:
    apply_time_ms: 2.798
    dispatch_time_ms: 14.159
    learner:
      cur_lr: 0.0013137130299583077
      grad_gnorm: 2.1377203464508057
      policy_entropy: 22.75849151611328
      policy_loss: -0.3821438252925873
      var_gnorm: 35.55715560913086
      vf_explained_var: 0.9757013320922852
      vf_loss: 0.18677999079227448
    num_steps_sampled: 700000
    num_steps_trained: 700000
    wait_time_ms: 109.188
  iterations_since_restore: 140
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 830
  policy_reward_mean: {}
  time_since_restore: 1707.3727390766144
  time_this_iter_s: 11.734235286712646
  time_total_s: 1707.3727390766144
  timestamp: 1593811503
  timesteps_since_restore: 700000
  timesteps_this_iter: 5000
  timesteps_total: 700000
  training_iteration: 140
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 10.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=830], 1707 s, 140 iter, 700000 ts, 444 rew

agent-1: 77.0
agent-2: 75.0
agent-3: 65.0
agent-4: 74.0
agent-5: 91.0
Sum Reward: 382.0
Avg Reward: 76.4
Min Reward: 65.0
Gini Coefficient 0.05759162303664921
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_17-25-15
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 820.0
  episode_reward_mean: 444.24
  episode_reward_min: 297.0
  episodes_this_iter: 1
  episodes_total: 140
  experiment_id: f3470259fa9143609a5dd5049ba7f979
  hostname: gpu020
  info:
    apply_time_ms: 4.178
    dispatch_time_ms: 43.727
    learner:
      cur_lr: 0.0013133799657225609
      grad_gnorm: 2.4435667991638184
      policy_entropy: 38.670257568359375
      policy_loss: 2.6557161808013916
      var_gnorm: 35.62312698364258
      vf_explained_var: 0.8158681988716125
      vf_loss: 1.3419878482818604
    num_steps_sampled: 705000
    num_steps_trained: 705000
    wait_time_ms: 64.705
  iterations_since_restore: 141
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 830
  policy_reward_mean: {}
  time_since_restore: 1720.2193548679352
  time_this_iter_s: 12.8466157913208
  time_total_s: 1720.2193548679352
  timestamp: 1593811515
  timesteps_since_restore: 705000
  timesteps_this_iter: 5000
  timesteps_total: 705000
  training_iteration: 141
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 10.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=830], 1720 s, 141 iter, 705000 ts, 444 rew

agent-1: 90.0
agent-2: 101.0
agent-3: 110.0
agent-4: 87.0
agent-5: 81.0
Sum Reward: 469.0
Avg Reward: 93.8
Min Reward: 81.0
Gini Coefficient 0.06140724946695096
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_17-25-26
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 820.0
  episode_reward_mean: 445.74
  episode_reward_min: 297.0
  episodes_this_iter: 1
  episodes_total: 141
  experiment_id: f3470259fa9143609a5dd5049ba7f979
  hostname: gpu020
  info:
    apply_time_ms: 3.43
    dispatch_time_ms: 10.211
    learner:
      cur_lr: 0.0013130470179021358
      grad_gnorm: 40.0
      policy_entropy: 19.214378356933594
      policy_loss: 14.630091667175293
      var_gnorm: 35.69940185546875
      vf_explained_var: 0.45794039964675903
      vf_loss: 101.11475372314453
    num_steps_sampled: 710000
    num_steps_trained: 710000
    wait_time_ms: 100.772
  iterations_since_restore: 142
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 830
  policy_reward_mean: {}
  time_since_restore: 1731.0904216766357
  time_this_iter_s: 10.871066808700562
  time_total_s: 1731.0904216766357
  timestamp: 1593811526
  timesteps_since_restore: 710000
  timesteps_this_iter: 5000
  timesteps_total: 710000
  training_iteration: 142
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 10.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=830], 1731 s, 142 iter, 710000 ts, 446 rew

agent-1: 80.0
agent-2: 103.0
agent-3: 97.0
agent-4: 94.0
agent-5: 80.0
Sum Reward: 454.0
Avg Reward: 90.8
Min Reward: 80.0
Gini Coefficient 0.055506607929515416
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_17-25-38
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 820.0
  episode_reward_mean: 446.45
  episode_reward_min: 297.0
  episodes_this_iter: 1
  episodes_total: 142
  experiment_id: f3470259fa9143609a5dd5049ba7f979
  hostname: gpu020
  info:
    apply_time_ms: 3.84
    dispatch_time_ms: 13.611
    learner:
      cur_lr: 0.001312713953666389
      grad_gnorm: 1.3918638229370117
      policy_entropy: 42.571380615234375
      policy_loss: -0.41673824191093445
      var_gnorm: 35.76013946533203
      vf_explained_var: 0.0
      vf_loss: 0.0025583654642105103
    num_steps_sampled: 715000
    num_steps_trained: 715000
    wait_time_ms: 99.476
  iterations_since_restore: 143
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 830
  policy_reward_mean: {}
  time_since_restore: 1743.1075704097748
  time_this_iter_s: 12.017148733139038
  time_total_s: 1743.1075704097748
  timestamp: 1593811538
  timesteps_since_restore: 715000
  timesteps_this_iter: 5000
  timesteps_total: 715000
  training_iteration: 143
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 10.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=830], 1743 s, 143 iter, 715000 ts, 446 rew

agent-1: 74.0
agent-2: 92.0
agent-3: 89.0
agent-4: 74.0
agent-5: 83.0
Sum Reward: 412.0
Avg Reward: 82.4
Min Reward: 74.0
Gini Coefficient 0.04951456310679612
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_17-25-50
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 820.0
  episode_reward_mean: 446.93
  episode_reward_min: 297.0
  episodes_this_iter: 1
  episodes_total: 143
  experiment_id: f3470259fa9143609a5dd5049ba7f979
  hostname: gpu020
  info:
    apply_time_ms: 2.679
    dispatch_time_ms: 13.645
    learner:
      cur_lr: 0.001312381005845964
      grad_gnorm: 13.528277397155762
      policy_entropy: 43.245826721191406
      policy_loss: -1.6513285636901855
      var_gnorm: 35.83415985107422
      vf_explained_var: -1.0
      vf_loss: 1.7777507305145264
    num_steps_sampled: 720000
    num_steps_trained: 720000
    wait_time_ms: 62.035
  iterations_since_restore: 144
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 830
  policy_reward_mean: {}
  time_since_restore: 1754.9739000797272
  time_this_iter_s: 11.866329669952393
  time_total_s: 1754.9739000797272
  timestamp: 1593811550
  timesteps_since_restore: 720000
  timesteps_this_iter: 5000
  timesteps_total: 720000
  training_iteration: 144
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 10.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=830], 1754 s, 144 iter, 720000 ts, 447 rew

agent-1: 99.0
agent-2: 81.0
agent-3: 87.0
agent-4: 92.0
agent-5: 85.0
Sum Reward: 444.0
Avg Reward: 88.8
Min Reward: 81.0
Gini Coefficient 0.03873873873873874
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_17-26-02
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 820.0
  episode_reward_mean: 447.15
  episode_reward_min: 297.0
  episodes_this_iter: 1
  episodes_total: 144
  experiment_id: f3470259fa9143609a5dd5049ba7f979
  hostname: gpu020
  info:
    apply_time_ms: 3.12
    dispatch_time_ms: 9.557
    learner:
      cur_lr: 0.001312048058025539
      grad_gnorm: 40.0
      policy_entropy: 27.39005470275879
      policy_loss: 6.367574691772461
      var_gnorm: 35.91189193725586
      vf_explained_var: 0.4752390384674072
      vf_loss: 29.311429977416992
    num_steps_sampled: 725000
    num_steps_trained: 725000
    wait_time_ms: 103.258
  iterations_since_restore: 145
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 830
  policy_reward_mean: {}
  time_since_restore: 1766.5789971351624
  time_this_iter_s: 11.60509705543518
  time_total_s: 1766.5789971351624
  timestamp: 1593811562
  timesteps_since_restore: 725000
  timesteps_this_iter: 5000
  timesteps_total: 725000
  training_iteration: 145
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 10.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=830], 1766 s, 145 iter, 725000 ts, 447 rew

agent-1: 144.0
agent-2: 144.0
agent-3: 131.0
agent-4: 112.0
agent-5: 137.0
Sum Reward: 668.0
Avg Reward: 133.6
Min Reward: 112.0
Gini Coefficient 0.04610778443113772
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_17-26-13
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 820.0
  episode_reward_mean: 448.75
  episode_reward_min: 297.0
  episodes_this_iter: 1
  episodes_total: 145
  experiment_id: f3470259fa9143609a5dd5049ba7f979
  hostname: gpu020
  info:
    apply_time_ms: 2.691
    dispatch_time_ms: 12.322
    learner:
      cur_lr: 0.001311714993789792
      grad_gnorm: 40.000022888183594
      policy_entropy: 20.93757438659668
      policy_loss: 3.553591728210449
      var_gnorm: 35.928794860839844
      vf_explained_var: 0.5832093954086304
      vf_loss: 97.5826644897461
    num_steps_sampled: 730000
    num_steps_trained: 730000
    wait_time_ms: 105.894
  iterations_since_restore: 146
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 830
  policy_reward_mean: {}
  time_since_restore: 1777.6983006000519
  time_this_iter_s: 11.119303464889526
  time_total_s: 1777.6983006000519
  timestamp: 1593811573
  timesteps_since_restore: 730000
  timesteps_this_iter: 5000
  timesteps_total: 730000
  training_iteration: 146
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 10.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=830], 1777 s, 146 iter, 730000 ts, 449 rew

agent-1: 90.0
agent-2: 131.0
agent-3: 78.0
agent-4: 127.0
agent-5: 114.0
Sum Reward: 540.0
Avg Reward: 108.0
Min Reward: 78.0
Gini Coefficient 0.10592592592592592
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_17-26-26
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 820.0
  episode_reward_mean: 449.72
  episode_reward_min: 297.0
  episodes_this_iter: 1
  episodes_total: 146
  experiment_id: f3470259fa9143609a5dd5049ba7f979
  hostname: gpu020
  info:
    apply_time_ms: 4.108
    dispatch_time_ms: 14.166
    learner:
      cur_lr: 0.001311382045969367
      grad_gnorm: 39.9999885559082
      policy_entropy: 22.604211807250977
      policy_loss: -14.188150405883789
      var_gnorm: 36.0056266784668
      vf_explained_var: -1.0
      vf_loss: 74.38430786132812
    num_steps_sampled: 735000
    num_steps_trained: 735000
    wait_time_ms: 34.491
  iterations_since_restore: 147
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 830
  policy_reward_mean: {}
  time_since_restore: 1790.351730108261
  time_this_iter_s: 12.653429508209229
  time_total_s: 1790.351730108261
  timestamp: 1593811586
  timesteps_since_restore: 735000
  timesteps_this_iter: 5000
  timesteps_total: 735000
  training_iteration: 147
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 10.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=830], 1790 s, 147 iter, 735000 ts, 450 rew

agent-1: 90.0
agent-2: 109.0
agent-3: 96.0
agent-4: 123.0
agent-5: 97.0
Sum Reward: 515.0
Avg Reward: 103.0
Min Reward: 90.0
Gini Coefficient 0.06135922330097087
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_17-26-37
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 820.0
  episode_reward_mean: 449.47
  episode_reward_min: 297.0
  episodes_this_iter: 1
  episodes_total: 147
  experiment_id: f3470259fa9143609a5dd5049ba7f979
  hostname: gpu020
  info:
    apply_time_ms: 2.865
    dispatch_time_ms: 13.058
    learner:
      cur_lr: 0.0013110489817336202
      grad_gnorm: 9.503828048706055
      policy_entropy: 35.480743408203125
      policy_loss: -1.7859855890274048
      var_gnorm: 36.12995910644531
      vf_explained_var: 0.18625324964523315
      vf_loss: 2.5716283321380615
    num_steps_sampled: 740000
    num_steps_trained: 740000
    wait_time_ms: 111.847
  iterations_since_restore: 148
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 830
  policy_reward_mean: {}
  time_since_restore: 1801.649486064911
  time_this_iter_s: 11.29775595664978
  time_total_s: 1801.649486064911
  timestamp: 1593811597
  timesteps_since_restore: 740000
  timesteps_this_iter: 5000
  timesteps_total: 740000
  training_iteration: 148
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 10.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=830], 1801 s, 148 iter, 740000 ts, 449 rew

agent-1: 73.0
agent-2: 71.0
agent-3: 103.0
agent-4: 74.0
agent-5: 67.0
Sum Reward: 388.0
Avg Reward: 77.6
Min Reward: 67.0
Gini Coefficient 0.07731958762886598
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_17-26-50
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 820.0
  episode_reward_mean: 448.17
  episode_reward_min: 297.0
  episodes_this_iter: 1
  episodes_total: 148
  experiment_id: f3470259fa9143609a5dd5049ba7f979
  hostname: gpu020
  info:
    apply_time_ms: 3.944
    dispatch_time_ms: 17.173
    learner:
      cur_lr: 0.0013107160339131951
      grad_gnorm: 22.620210647583008
      policy_entropy: 43.354774475097656
      policy_loss: -3.3277649879455566
      var_gnorm: 36.179603576660156
      vf_explained_var: -1.0
      vf_loss: 1.2085291147232056
    num_steps_sampled: 745000
    num_steps_trained: 745000
    wait_time_ms: 153.786
  iterations_since_restore: 149
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 830
  policy_reward_mean: {}
  time_since_restore: 1814.2074031829834
  time_this_iter_s: 12.55791711807251
  time_total_s: 1814.2074031829834
  timestamp: 1593811610
  timesteps_since_restore: 745000
  timesteps_this_iter: 5000
  timesteps_total: 745000
  training_iteration: 149
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 10.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=830], 1814 s, 149 iter, 745000 ts, 448 rew

agent-1: 92.0
agent-2: 72.0
agent-3: 76.0
agent-4: 69.0
agent-5: 74.0
Sum Reward: 383.0
Avg Reward: 76.6
Min Reward: 69.0
Gini Coefficient 0.05221932114882506
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_17-27-09
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 820.0
  episode_reward_mean: 448.8
  episode_reward_min: 297.0
  episodes_this_iter: 1
  episodes_total: 149
  experiment_id: f3470259fa9143609a5dd5049ba7f979
  hostname: gpu020
  info:
    apply_time_ms: 3.505
    dispatch_time_ms: 384.186
    learner:
      cur_lr: 0.0013103829696774483
      grad_gnorm: 40.000003814697266
      policy_entropy: 9.840490341186523
      policy_loss: 23.823482513427734
      var_gnorm: 36.234928131103516
      vf_explained_var: -0.5839245319366455
      vf_loss: 109.91110229492188
    num_steps_sampled: 750000
    num_steps_trained: 750000
    wait_time_ms: 429.972
  iterations_since_restore: 150
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 830
  policy_reward_mean: {}
  time_since_restore: 1833.2985014915466
  time_this_iter_s: 19.091098308563232
  time_total_s: 1833.2985014915466
  timestamp: 1593811629
  timesteps_since_restore: 750000
  timesteps_this_iter: 5000
  timesteps_total: 750000
  training_iteration: 150
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 10.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=830], 1833 s, 150 iter, 750000 ts, 449 rew

agent-1: 68.0
agent-2: 109.0
agent-3: 96.0
agent-4: 102.0
agent-5: 82.0
Sum Reward: 457.0
Avg Reward: 91.4
Min Reward: 68.0
Gini Coefficient 0.08927789934354485
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_17-27-38
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 820.0
  episode_reward_mean: 450.24
  episode_reward_min: 297.0
  episodes_this_iter: 1
  episodes_total: 150
  experiment_id: f3470259fa9143609a5dd5049ba7f979
  hostname: gpu020
  info:
    apply_time_ms: 3.683
    dispatch_time_ms: 66.674
    learner:
      cur_lr: 0.0013100500218570232
      grad_gnorm: 40.000003814697266
      policy_entropy: 35.47935485839844
      policy_loss: -3.229992151260376
      var_gnorm: 36.27082824707031
      vf_explained_var: 0.6480776071548462
      vf_loss: 9.77012825012207
    num_steps_sampled: 755000
    num_steps_trained: 755000
    wait_time_ms: 28.647
  iterations_since_restore: 151
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 830
  policy_reward_mean: {}
  time_since_restore: 1862.4928348064423
  time_this_iter_s: 29.19433331489563
  time_total_s: 1862.4928348064423
  timestamp: 1593811658
  timesteps_since_restore: 755000
  timesteps_this_iter: 5000
  timesteps_total: 755000
  training_iteration: 151
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 10.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=830], 1862 s, 151 iter, 755000 ts, 450 rew

agent-1: 118.0
agent-2: 115.0
agent-3: 122.0
agent-4: 105.0
agent-5: 88.0
Sum Reward: 548.0
Avg Reward: 109.6
Min Reward: 88.0
Gini Coefficient 0.059124087591240874
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_17-27-49
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 820.0
  episode_reward_mean: 452.38
  episode_reward_min: 297.0
  episodes_this_iter: 1
  episodes_total: 151
  experiment_id: f3470259fa9143609a5dd5049ba7f979
  hostname: gpu020
  info:
    apply_time_ms: 4.224
    dispatch_time_ms: 80.105
    learner:
      cur_lr: 0.0013097169576212764
      grad_gnorm: 39.999996185302734
      policy_entropy: 28.28881072998047
      policy_loss: 46.0443229675293
      var_gnorm: 36.30766677856445
      vf_explained_var: 0.27951711416244507
      vf_loss: 80.44412231445312
    num_steps_sampled: 760000
    num_steps_trained: 760000
    wait_time_ms: 24.852
  iterations_since_restore: 152
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 830
  policy_reward_mean: {}
  time_since_restore: 1873.8581459522247
  time_this_iter_s: 11.36531114578247
  time_total_s: 1873.8581459522247
  timestamp: 1593811669
  timesteps_since_restore: 760000
  timesteps_this_iter: 5000
  timesteps_total: 760000
  training_iteration: 152
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 10.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=830], 1873 s, 152 iter, 760000 ts, 452 rew

agent-1: 76.0
agent-2: 52.0
agent-3: 73.0
agent-4: 89.0
agent-5: 55.0
Sum Reward: 345.0
Avg Reward: 69.0
Min Reward: 52.0
Gini Coefficient 0.11014492753623188
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_17-28-04
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 820.0
  episode_reward_mean: 452.19
  episode_reward_min: 297.0
  episodes_this_iter: 1
  episodes_total: 152
  experiment_id: f3470259fa9143609a5dd5049ba7f979
  hostname: gpu020
  info:
    apply_time_ms: 2.504
    dispatch_time_ms: 61.896
    learner:
      cur_lr: 0.0013093840098008513
      grad_gnorm: 39.999996185302734
      policy_entropy: 11.180374145507812
      policy_loss: -11.189157485961914
      var_gnorm: 36.334869384765625
      vf_explained_var: -0.2511783838272095
      vf_loss: 68.90380859375
    num_steps_sampled: 765000
    num_steps_trained: 765000
    wait_time_ms: 29.61
  iterations_since_restore: 153
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 830
  policy_reward_mean: {}
  time_since_restore: 1888.3904058933258
  time_this_iter_s: 14.532259941101074
  time_total_s: 1888.3904058933258
  timestamp: 1593811684
  timesteps_since_restore: 765000
  timesteps_this_iter: 5000
  timesteps_total: 765000
  training_iteration: 153
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 10.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=830], 1888 s, 153 iter, 765000 ts, 452 rew

agent-1: 102.0
agent-2: 96.0
agent-3: 90.0
agent-4: 101.0
agent-5: 87.0
Sum Reward: 476.0
Avg Reward: 95.2
Min Reward: 87.0
Gini Coefficient 0.034453781512605045
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_17-28-16
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 820.0
  episode_reward_mean: 453.1
  episode_reward_min: 297.0
  episodes_this_iter: 1
  episodes_total: 153
  experiment_id: f3470259fa9143609a5dd5049ba7f979
  hostname: gpu020
  info:
    apply_time_ms: 3.532
    dispatch_time_ms: 9.17
    learner:
      cur_lr: 0.0013090509455651045
      grad_gnorm: 19.39019775390625
      policy_entropy: 41.75592041015625
      policy_loss: -4.98357629776001
      var_gnorm: 36.41209030151367
      vf_explained_var: 0.5716445446014404
      vf_loss: 0.5678308606147766
    num_steps_sampled: 770000
    num_steps_trained: 770000
    wait_time_ms: 111.707
  iterations_since_restore: 154
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 830
  policy_reward_mean: {}
  time_since_restore: 1899.920563697815
  time_this_iter_s: 11.530157804489136
  time_total_s: 1899.920563697815
  timestamp: 1593811696
  timesteps_since_restore: 770000
  timesteps_this_iter: 5000
  timesteps_total: 770000
  training_iteration: 154
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 10.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=830], 1899 s, 154 iter, 770000 ts, 453 rew

agent-1: 94.0
agent-2: 80.0
agent-3: 62.0
agent-4: 63.0
agent-5: 67.0
Sum Reward: 366.0
Avg Reward: 73.2
Min Reward: 62.0
Gini Coefficient 0.08852459016393442
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_17-28-31
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 820.0
  episode_reward_mean: 453.53
  episode_reward_min: 297.0
  episodes_this_iter: 1
  episodes_total: 154
  experiment_id: f3470259fa9143609a5dd5049ba7f979
  hostname: gpu020
  info:
    apply_time_ms: 3.54
    dispatch_time_ms: 41.447
    learner:
      cur_lr: 0.0013087179977446795
      grad_gnorm: 39.999996185302734
      policy_entropy: 17.527164459228516
      policy_loss: -36.809146881103516
      var_gnorm: 36.462806701660156
      vf_explained_var: -0.28369104862213135
      vf_loss: 117.11559295654297
    num_steps_sampled: 775000
    num_steps_trained: 775000
    wait_time_ms: 427.943
  iterations_since_restore: 155
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 830
  policy_reward_mean: {}
  time_since_restore: 1915.5892264842987
  time_this_iter_s: 15.668662786483765
  time_total_s: 1915.5892264842987
  timestamp: 1593811711
  timesteps_since_restore: 775000
  timesteps_this_iter: 5000
  timesteps_total: 775000
  training_iteration: 155
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 10.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=830], 1915 s, 155 iter, 775000 ts, 454 rew

agent-1: 103.0
agent-2: 87.0
agent-3: 108.0
agent-4: 96.0
agent-5: 109.0
Sum Reward: 503.0
Avg Reward: 100.6
Min Reward: 87.0
Gini Coefficient 0.044532803180914515
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_17-28-42
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 820.0
  episode_reward_mean: 455.59
  episode_reward_min: 299.0
  episodes_this_iter: 1
  episodes_total: 155
  experiment_id: f3470259fa9143609a5dd5049ba7f979
  hostname: gpu020
  info:
    apply_time_ms: 3.275
    dispatch_time_ms: 14.501
    learner:
      cur_lr: 0.0013083850499242544
      grad_gnorm: 14.15404224395752
      policy_entropy: 53.4550666809082
      policy_loss: -5.19275426864624
      var_gnorm: 36.5246696472168
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 0.25845327973365784
    num_steps_sampled: 780000
    num_steps_trained: 780000
    wait_time_ms: 104.447
  iterations_since_restore: 156
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 830
  policy_reward_mean: {}
  time_since_restore: 1926.524488210678
  time_this_iter_s: 10.935261726379395
  time_total_s: 1926.524488210678
  timestamp: 1593811722
  timesteps_since_restore: 780000
  timesteps_this_iter: 5000
  timesteps_total: 780000
  training_iteration: 156
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 10.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=830], 1926 s, 156 iter, 780000 ts, 456 rew

agent-1: 94.0
agent-2: 52.0
agent-3: 51.0
agent-4: 73.0
agent-5: 79.0
Sum Reward: 349.0
Avg Reward: 69.8
Min Reward: 51.0
Gini Coefficient 0.12951289398280802
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_17-28-54
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 820.0
  episode_reward_mean: 455.67
  episode_reward_min: 299.0
  episodes_this_iter: 1
  episodes_total: 156
  experiment_id: f3470259fa9143609a5dd5049ba7f979
  hostname: gpu020
  info:
    apply_time_ms: 3.277
    dispatch_time_ms: 9.705
    learner:
      cur_lr: 0.0013080519856885076
      grad_gnorm: 40.0
      policy_entropy: 19.16568374633789
      policy_loss: 11.314239501953125
      var_gnorm: 36.60622024536133
      vf_explained_var: 0.05384582281112671
      vf_loss: 82.88756561279297
    num_steps_sampled: 785000
    num_steps_trained: 785000
    wait_time_ms: 102.799
  iterations_since_restore: 157
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 830
  policy_reward_mean: {}
  time_since_restore: 1938.7275693416595
  time_this_iter_s: 12.203081130981445
  time_total_s: 1938.7275693416595
  timestamp: 1593811734
  timesteps_since_restore: 785000
  timesteps_this_iter: 5000
  timesteps_total: 785000
  training_iteration: 157
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 10.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=830], 1938 s, 157 iter, 785000 ts, 456 rew

agent-1: 86.0
agent-2: 63.0
agent-3: 66.0
agent-4: 64.0
agent-5: 74.0
Sum Reward: 353.0
Avg Reward: 70.6
Min Reward: 63.0
Gini Coefficient 0.06345609065155808
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_17-29-06
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 820.0
  episode_reward_mean: 455.99
  episode_reward_min: 299.0
  episodes_this_iter: 1
  episodes_total: 157
  experiment_id: f3470259fa9143609a5dd5049ba7f979
  hostname: gpu020
  info:
    apply_time_ms: 2.74
    dispatch_time_ms: 6.713
    learner:
      cur_lr: 0.0013077190378680825
      grad_gnorm: 40.0000114440918
      policy_entropy: 32.65791702270508
      policy_loss: 23.967926025390625
      var_gnorm: 36.687835693359375
      vf_explained_var: 0.8041664361953735
      vf_loss: 68.28324127197266
    num_steps_sampled: 790000
    num_steps_trained: 790000
    wait_time_ms: 113.294
  iterations_since_restore: 158
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 830
  policy_reward_mean: {}
  time_since_restore: 1950.4047400951385
  time_this_iter_s: 11.677170753479004
  time_total_s: 1950.4047400951385
  timestamp: 1593811746
  timesteps_since_restore: 790000
  timesteps_this_iter: 5000
  timesteps_total: 790000
  training_iteration: 158
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 10.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=830], 1950 s, 158 iter, 790000 ts, 456 rew

agent-1: 66.0
agent-2: 82.0
agent-3: 68.0
agent-4: 74.0
agent-5: 75.0
Sum Reward: 365.0
Avg Reward: 73.0
Min Reward: 66.0
Gini Coefficient 0.042739726027397264
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_17-29-18
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 820.0
  episode_reward_mean: 455.96
  episode_reward_min: 299.0
  episodes_this_iter: 1
  episodes_total: 158
  experiment_id: f3470259fa9143609a5dd5049ba7f979
  hostname: gpu020
  info:
    apply_time_ms: 2.598
    dispatch_time_ms: 9.462
    learner:
      cur_lr: 0.0013073859736323357
      grad_gnorm: 39.99999237060547
      policy_entropy: 13.428142547607422
      policy_loss: 7.197355270385742
      var_gnorm: 36.67401885986328
      vf_explained_var: -0.7092407941818237
      vf_loss: 50.15821075439453
    num_steps_sampled: 795000
    num_steps_trained: 795000
    wait_time_ms: 92.494
  iterations_since_restore: 159
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 830
  policy_reward_mean: {}
  time_since_restore: 1962.3586957454681
  time_this_iter_s: 11.95395565032959
  time_total_s: 1962.3586957454681
  timestamp: 1593811758
  timesteps_since_restore: 795000
  timesteps_this_iter: 5000
  timesteps_total: 795000
  training_iteration: 159
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 10.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=830], 1962 s, 159 iter, 795000 ts, 456 rew

agent-1: 87.0
agent-2: 75.0
agent-3: 77.0
agent-4: 66.0
agent-5: 72.0
Sum Reward: 377.0
Avg Reward: 75.4
Min Reward: 66.0
Gini Coefficient 0.04986737400530504
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_17-29-29
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 820.0
  episode_reward_mean: 456.03
  episode_reward_min: 299.0
  episodes_this_iter: 1
  episodes_total: 159
  experiment_id: f3470259fa9143609a5dd5049ba7f979
  hostname: gpu020
  info:
    apply_time_ms: 3.249
    dispatch_time_ms: 8.288
    learner:
      cur_lr: 0.0013070530258119106
      grad_gnorm: 40.000003814697266
      policy_entropy: 8.929381370544434
      policy_loss: -14.04228401184082
      var_gnorm: 36.68235397338867
      vf_explained_var: 0.16325873136520386
      vf_loss: 24.392858505249023
    num_steps_sampled: 800000
    num_steps_trained: 800000
    wait_time_ms: 105.588
  iterations_since_restore: 160
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 830
  policy_reward_mean: {}
  time_since_restore: 1973.4247913360596
  time_this_iter_s: 11.06609559059143
  time_total_s: 1973.4247913360596
  timestamp: 1593811769
  timesteps_since_restore: 800000
  timesteps_this_iter: 5000
  timesteps_total: 800000
  training_iteration: 160
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 10.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=830], 1973 s, 160 iter, 800000 ts, 456 rew

agent-1: 132.0
agent-2: 144.0
agent-3: 131.0
agent-4: 158.0
agent-5: 136.0
Sum Reward: 701.0
Avg Reward: 140.2
Min Reward: 131.0
Gini Coefficient 0.037660485021398
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_17-29-41
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 820.0
  episode_reward_mean: 457.72
  episode_reward_min: 299.0
  episodes_this_iter: 1
  episodes_total: 160
  experiment_id: f3470259fa9143609a5dd5049ba7f979
  hostname: gpu020
  info:
    apply_time_ms: 2.652
    dispatch_time_ms: 10.954
    learner:
      cur_lr: 0.0013067199615761638
      grad_gnorm: 25.10732650756836
      policy_entropy: 15.260738372802734
      policy_loss: 3.2074239253997803
      var_gnorm: 36.76251220703125
      vf_explained_var: 0.0
      vf_loss: 4.546815872192383
    num_steps_sampled: 805000
    num_steps_trained: 805000
    wait_time_ms: 97.012
  iterations_since_restore: 161
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 830
  policy_reward_mean: {}
  time_since_restore: 1985.4809272289276
  time_this_iter_s: 12.056135892868042
  time_total_s: 1985.4809272289276
  timestamp: 1593811781
  timesteps_since_restore: 805000
  timesteps_this_iter: 5000
  timesteps_total: 805000
  training_iteration: 161
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 10.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=830], 1985 s, 161 iter, 805000 ts, 458 rew

agent-1: 75.0
agent-2: 73.0
agent-3: 87.0
agent-4: 84.0
agent-5: 78.0
Sum Reward: 397.0
Avg Reward: 79.4
Min Reward: 73.0
Gini Coefficient 0.03727959697732997
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_17-29-53
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 820.0
  episode_reward_mean: 458.03
  episode_reward_min: 299.0
  episodes_this_iter: 1
  episodes_total: 161
  experiment_id: f3470259fa9143609a5dd5049ba7f979
  hostname: gpu020
  info:
    apply_time_ms: 4.094
    dispatch_time_ms: 10.133
    learner:
      cur_lr: 0.0013063870137557387
      grad_gnorm: 10.410234451293945
      policy_entropy: 26.804590225219727
      policy_loss: 2.1729822158813477
      var_gnorm: 36.83506393432617
      vf_explained_var: 0.8475892543792725
      vf_loss: 3.42063570022583
    num_steps_sampled: 810000
    num_steps_trained: 810000
    wait_time_ms: 108.589
  iterations_since_restore: 162
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 830
  policy_reward_mean: {}
  time_since_restore: 1997.1349432468414
  time_this_iter_s: 11.654016017913818
  time_total_s: 1997.1349432468414
  timestamp: 1593811793
  timesteps_since_restore: 810000
  timesteps_this_iter: 5000
  timesteps_total: 810000
  training_iteration: 162
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 10.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=830], 1997 s, 162 iter, 810000 ts, 458 rew

agent-1: 80.0
agent-2: 68.0
agent-3: 71.0
agent-4: 78.0
agent-5: 68.0
Sum Reward: 365.0
Avg Reward: 73.0
Min Reward: 68.0
Gini Coefficient 0.03726027397260274
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_17-30-07
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 820.0
  episode_reward_mean: 458.31
  episode_reward_min: 299.0
  episodes_this_iter: 1
  episodes_total: 162
  experiment_id: f3470259fa9143609a5dd5049ba7f979
  hostname: gpu020
  info:
    apply_time_ms: 2.912
    dispatch_time_ms: 67.8
    learner:
      cur_lr: 0.0013060539495199919
      grad_gnorm: 7.100310325622559
      policy_entropy: 33.78877639770508
      policy_loss: 3.2534358501434326
      var_gnorm: 36.85957336425781
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 0.05354725942015648
    num_steps_sampled: 815000
    num_steps_trained: 815000
    wait_time_ms: 68.844
  iterations_since_restore: 163
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 830
  policy_reward_mean: {}
  time_since_restore: 2010.637660741806
  time_this_iter_s: 13.5027174949646
  time_total_s: 2010.637660741806
  timestamp: 1593811807
  timesteps_since_restore: 815000
  timesteps_this_iter: 5000
  timesteps_total: 815000
  training_iteration: 163
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 10.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=830], 2010 s, 163 iter, 815000 ts, 458 rew

agent-1: 77.0
agent-2: 71.0
agent-3: 89.0
agent-4: 93.0
agent-5: 79.0
Sum Reward: 409.0
Avg Reward: 81.8
Min Reward: 71.0
Gini Coefficient 0.05476772616136919
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_17-30-19
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 820.0
  episode_reward_mean: 459.09
  episode_reward_min: 299.0
  episodes_this_iter: 1
  episodes_total: 163
  experiment_id: f3470259fa9143609a5dd5049ba7f979
  hostname: gpu020
  info:
    apply_time_ms: 3.47
    dispatch_time_ms: 16.612
    learner:
      cur_lr: 0.0013057210016995668
      grad_gnorm: 39.99999237060547
      policy_entropy: 6.342377185821533
      policy_loss: -8.623967170715332
      var_gnorm: 36.8042106628418
      vf_explained_var: -1.0
      vf_loss: 141.09765625
    num_steps_sampled: 820000
    num_steps_trained: 820000
    wait_time_ms: 98.197
  iterations_since_restore: 164
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 830
  policy_reward_mean: {}
  time_since_restore: 2020.795643568039
  time_this_iter_s: 10.15798282623291
  time_total_s: 2020.795643568039
  timestamp: 1593811819
  timesteps_since_restore: 820000
  timesteps_this_iter: 5000
  timesteps_total: 820000
  training_iteration: 164
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 10.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=830], 2020 s, 164 iter, 820000 ts, 459 rew

agent-1: 71.0
agent-2: 105.0
agent-3: 108.0
agent-4: 93.0
agent-5: 107.0
Sum Reward: 484.0
Avg Reward: 96.8
Min Reward: 71.0
Gini Coefficient 0.07272727272727272
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_17-30-32
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 820.0
  episode_reward_mean: 459.42
  episode_reward_min: 299.0
  episodes_this_iter: 1
  episodes_total: 164
  experiment_id: f3470259fa9143609a5dd5049ba7f979
  hostname: gpu020
  info:
    apply_time_ms: 2.889
    dispatch_time_ms: 9.311
    learner:
      cur_lr: 0.0013053880538791418
      grad_gnorm: 8.165132522583008
      policy_entropy: 28.669620513916016
      policy_loss: 1.5924098491668701
      var_gnorm: 36.83745193481445
      vf_explained_var: 0.9944665431976318
      vf_loss: 0.13218611478805542
    num_steps_sampled: 825000
    num_steps_trained: 825000
    wait_time_ms: 94.658
  iterations_since_restore: 165
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 830
  policy_reward_mean: {}
  time_since_restore: 2033.0490670204163
  time_this_iter_s: 12.25342345237732
  time_total_s: 2033.0490670204163
  timestamp: 1593811832
  timesteps_since_restore: 825000
  timesteps_this_iter: 5000
  timesteps_total: 825000
  training_iteration: 165
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 10.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=830], 2033 s, 165 iter, 825000 ts, 459 rew

agent-1: 80.0
agent-2: 55.0
agent-3: 83.0
agent-4: 94.0
agent-5: 94.0
Sum Reward: 406.0
Avg Reward: 81.2
Min Reward: 55.0
Gini Coefficient 0.09064039408866995
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_17-30-44
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 820.0
  episode_reward_mean: 459.44
  episode_reward_min: 299.0
  episodes_this_iter: 1
  episodes_total: 165
  experiment_id: f3470259fa9143609a5dd5049ba7f979
  hostname: gpu020
  info:
    apply_time_ms: 2.698
    dispatch_time_ms: 33.629
    learner:
      cur_lr: 0.001305054989643395
      grad_gnorm: 20.62482261657715
      policy_entropy: 37.20270538330078
      policy_loss: -2.288670063018799
      var_gnorm: 36.95559310913086
      vf_explained_var: -1.0
      vf_loss: 0.3020862340927124
    num_steps_sampled: 830000
    num_steps_trained: 830000
    wait_time_ms: 53.358
  iterations_since_restore: 166
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 830
  policy_reward_mean: {}
  time_since_restore: 2044.8885090351105
  time_this_iter_s: 11.839442014694214
  time_total_s: 2044.8885090351105
  timestamp: 1593811844
  timesteps_since_restore: 830000
  timesteps_this_iter: 5000
  timesteps_total: 830000
  training_iteration: 166
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 10.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=830], 2044 s, 166 iter, 830000 ts, 459 rew

agent-1: 74.0
agent-2: 78.0
agent-3: 73.0
agent-4: 96.0
agent-5: 109.0
Sum Reward: 430.0
Avg Reward: 86.0
Min Reward: 73.0
Gini Coefficient 0.08744186046511628
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_17-30-55
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 820.0
  episode_reward_mean: 460.18
  episode_reward_min: 299.0
  episodes_this_iter: 1
  episodes_total: 166
  experiment_id: f3470259fa9143609a5dd5049ba7f979
  hostname: gpu020
  info:
    apply_time_ms: 2.861
    dispatch_time_ms: 12.762
    learner:
      cur_lr: 0.00130472204182297
      grad_gnorm: 3.6598455905914307
      policy_entropy: 38.19114303588867
      policy_loss: 1.1034846305847168
      var_gnorm: 37.03361129760742
      vf_explained_var: -7.152557373046875e-07
      vf_loss: 0.01780303753912449
    num_steps_sampled: 835000
    num_steps_trained: 835000
    wait_time_ms: 91.621
  iterations_since_restore: 167
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 830
  policy_reward_mean: {}
  time_since_restore: 2056.706162929535
  time_this_iter_s: 11.817653894424438
  time_total_s: 2056.706162929535
  timestamp: 1593811855
  timesteps_since_restore: 835000
  timesteps_this_iter: 5000
  timesteps_total: 835000
  training_iteration: 167
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 10.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=830], 2056 s, 167 iter, 835000 ts, 460 rew

agent-1: 68.0
agent-2: 51.0
agent-3: 43.0
agent-4: 62.0
agent-5: 56.0
Sum Reward: 280.0
Avg Reward: 56.0
Min Reward: 43.0
Gini Coefficient 0.08714285714285715
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_17-31-07
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 820.0
  episode_reward_mean: 459.25
  episode_reward_min: 280.0
  episodes_this_iter: 1
  episodes_total: 167
  experiment_id: f3470259fa9143609a5dd5049ba7f979
  hostname: gpu020
  info:
    apply_time_ms: 2.764
    dispatch_time_ms: 20.939
    learner:
      cur_lr: 0.001304388977587223
      grad_gnorm: 39.99998474121094
      policy_entropy: 17.27284812927246
      policy_loss: -13.015311241149902
      var_gnorm: 37.11991882324219
      vf_explained_var: -1.0
      vf_loss: 171.67079162597656
    num_steps_sampled: 840000
    num_steps_trained: 840000
    wait_time_ms: 98.91
  iterations_since_restore: 168
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 830
  policy_reward_mean: {}
  time_since_restore: 2068.1640090942383
  time_this_iter_s: 11.45784616470337
  time_total_s: 2068.1640090942383
  timestamp: 1593811867
  timesteps_since_restore: 840000
  timesteps_this_iter: 5000
  timesteps_total: 840000
  training_iteration: 168
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 10.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=830], 2068 s, 168 iter, 840000 ts, 459 rew

agent-1: 96.0
agent-2: 68.0
agent-3: 92.0
agent-4: 76.0
agent-5: 83.0
Sum Reward: 415.0
Avg Reward: 83.0
Min Reward: 68.0
Gini Coefficient 0.06939759036144579
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_17-31-19
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 820.0
  episode_reward_mean: 456.66
  episode_reward_min: 280.0
  episodes_this_iter: 1
  episodes_total: 168
  experiment_id: f3470259fa9143609a5dd5049ba7f979
  hostname: gpu020
  info:
    apply_time_ms: 2.916
    dispatch_time_ms: 16.109
    learner:
      cur_lr: 0.001304056029766798
      grad_gnorm: 11.093239784240723
      policy_entropy: 36.74953079223633
      policy_loss: -2.137075901031494
      var_gnorm: 37.188812255859375
      vf_explained_var: 0.0
      vf_loss: 0.1581539660692215
    num_steps_sampled: 845000
    num_steps_trained: 845000
    wait_time_ms: 96.855
  iterations_since_restore: 169
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 830
  policy_reward_mean: {}
  time_since_restore: 2080.3141391277313
  time_this_iter_s: 12.150130033493042
  time_total_s: 2080.3141391277313
  timestamp: 1593811879
  timesteps_since_restore: 845000
  timesteps_this_iter: 5000
  timesteps_total: 845000
  training_iteration: 169
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 10.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=830], 2080 s, 169 iter, 845000 ts, 457 rew

agent-1: 117.0
agent-2: 114.0
agent-3: 99.0
agent-4: 115.0
agent-5: 94.0
Sum Reward: 539.0
Avg Reward: 107.8
Min Reward: 94.0
Gini Coefficient 0.04601113172541744
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_17-31-30
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 820.0
  episode_reward_mean: 457.27
  episode_reward_min: 280.0
  episodes_this_iter: 1
  episodes_total: 169
  experiment_id: f3470259fa9143609a5dd5049ba7f979
  hostname: gpu020
  info:
    apply_time_ms: 3.258
    dispatch_time_ms: 14.377
    learner:
      cur_lr: 0.0013037229655310512
      grad_gnorm: 39.99999237060547
      policy_entropy: 14.441548347473145
      policy_loss: -15.21442699432373
      var_gnorm: 37.220191955566406
      vf_explained_var: 0.3649604320526123
      vf_loss: 360.2774353027344
    num_steps_sampled: 850000
    num_steps_trained: 850000
    wait_time_ms: 95.845
  iterations_since_restore: 170
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 830
  policy_reward_mean: {}
  time_since_restore: 2091.212778568268
  time_this_iter_s: 10.898639440536499
  time_total_s: 2091.212778568268
  timestamp: 1593811890
  timesteps_since_restore: 850000
  timesteps_this_iter: 5000
  timesteps_total: 850000
  training_iteration: 170
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 10.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=830], 2091 s, 170 iter, 850000 ts, 457 rew

agent-1: 131.0
agent-2: 132.0
agent-3: 159.0
agent-4: 139.0
agent-5: 157.0
Sum Reward: 718.0
Avg Reward: 143.6
Min Reward: 131.0
Gini Coefficient 0.04512534818941504
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_17-31-42
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 820.0
  episode_reward_mean: 458.4
  episode_reward_min: 280.0
  episodes_this_iter: 1
  episodes_total: 170
  experiment_id: f3470259fa9143609a5dd5049ba7f979
  hostname: gpu020
  info:
    apply_time_ms: 3.039
    dispatch_time_ms: 25.334
    learner:
      cur_lr: 0.0013033900177106261
      grad_gnorm: 17.265653610229492
      policy_entropy: 16.398807525634766
      policy_loss: -9.13647747039795
      var_gnorm: 37.3147087097168
      vf_explained_var: 0.24465709924697876
      vf_loss: 15.985642433166504
    num_steps_sampled: 855000
    num_steps_trained: 855000
    wait_time_ms: 94.972
  iterations_since_restore: 171
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 830
  policy_reward_mean: {}
  time_since_restore: 2102.955799818039
  time_this_iter_s: 11.743021249771118
  time_total_s: 2102.955799818039
  timestamp: 1593811902
  timesteps_since_restore: 855000
  timesteps_this_iter: 5000
  timesteps_total: 855000
  training_iteration: 171
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 10.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=830], 2102 s, 171 iter, 855000 ts, 458 rew

agent-1: 112.0
agent-2: 121.0
agent-3: 106.0
agent-4: 135.0
agent-5: 116.0
Sum Reward: 590.0
Avg Reward: 118.0
Min Reward: 106.0
Gini Coefficient 0.04542372881355932
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_17-31-54
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 820.0
  episode_reward_mean: 459.89
  episode_reward_min: 280.0
  episodes_this_iter: 1
  episodes_total: 171
  experiment_id: f3470259fa9143609a5dd5049ba7f979
  hostname: gpu020
  info:
    apply_time_ms: 3.076
    dispatch_time_ms: 18.479
    learner:
      cur_lr: 0.0013030569534748793
      grad_gnorm: 40.0
      policy_entropy: 8.586017608642578
      policy_loss: -7.5306396484375
      var_gnorm: 37.384864807128906
      vf_explained_var: -0.09639561176300049
      vf_loss: 71.35917663574219
    num_steps_sampled: 860000
    num_steps_trained: 860000
    wait_time_ms: 92.723
  iterations_since_restore: 172
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 830
  policy_reward_mean: {}
  time_since_restore: 2115.2011914253235
  time_this_iter_s: 12.245391607284546
  time_total_s: 2115.2011914253235
  timestamp: 1593811914
  timesteps_since_restore: 860000
  timesteps_this_iter: 5000
  timesteps_total: 860000
  training_iteration: 172
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 10.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=830], 2115 s, 172 iter, 860000 ts, 460 rew

agent-1: 80.0
agent-2: 76.0
agent-3: 125.0
agent-4: 102.0
agent-5: 59.0
Sum Reward: 442.0
Avg Reward: 88.4
Min Reward: 59.0
Gini Coefficient 0.1429864253393665
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_17-32-07
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 820.0
  episode_reward_mean: 461.05
  episode_reward_min: 280.0
  episodes_this_iter: 1
  episodes_total: 172
  experiment_id: f3470259fa9143609a5dd5049ba7f979
  hostname: gpu020
  info:
    apply_time_ms: 2.653
    dispatch_time_ms: 18.793
    learner:
      cur_lr: 0.0013027240056544542
      grad_gnorm: 40.0
      policy_entropy: 7.086537837982178
      policy_loss: 2.302086353302002
      var_gnorm: 37.43602752685547
      vf_explained_var: -0.08028674125671387
      vf_loss: 29.81322479248047
    num_steps_sampled: 865000
    num_steps_trained: 865000
    wait_time_ms: 92.258
  iterations_since_restore: 173
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 830
  policy_reward_mean: {}
  time_since_restore: 2127.7220375537872
  time_this_iter_s: 12.520846128463745
  time_total_s: 2127.7220375537872
  timestamp: 1593811927
  timesteps_since_restore: 865000
  timesteps_this_iter: 5000
  timesteps_total: 865000
  training_iteration: 173
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 10.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=830], 2127 s, 173 iter, 865000 ts, 461 rew

agent-1: 105.0
agent-2: 111.0
agent-3: 101.0
agent-4: 102.0
agent-5: 91.0
Sum Reward: 510.0
Avg Reward: 102.0
Min Reward: 91.0
Gini Coefficient 0.034509803921568626
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_17-32-20
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 820.0
  episode_reward_mean: 458.99
  episode_reward_min: 280.0
  episodes_this_iter: 1
  episodes_total: 173
  experiment_id: f3470259fa9143609a5dd5049ba7f979
  hostname: gpu020
  info:
    apply_time_ms: 3.491
    dispatch_time_ms: 87.957
    learner:
      cur_lr: 0.0013023910578340292
      grad_gnorm: 2.3894333839416504
      policy_entropy: 21.719141006469727
      policy_loss: -2.3555803298950195
      var_gnorm: 37.53578567504883
      vf_explained_var: 2.384185791015625e-07
      vf_loss: 0.08658385276794434
    num_steps_sampled: 870000
    num_steps_trained: 870000
    wait_time_ms: 50.721
  iterations_since_restore: 174
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 830
  policy_reward_mean: {}
  time_since_restore: 2141.028675556183
  time_this_iter_s: 13.30663800239563
  time_total_s: 2141.028675556183
  timestamp: 1593811940
  timesteps_since_restore: 870000
  timesteps_this_iter: 5000
  timesteps_total: 870000
  training_iteration: 174
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 10.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=830], 2141 s, 174 iter, 870000 ts, 459 rew

agent-1: 103.0
agent-2: 104.0
agent-3: 90.0
agent-4: 90.0
agent-5: 91.0
Sum Reward: 478.0
Avg Reward: 95.6
Min Reward: 90.0
Gini Coefficient 0.03430962343096234
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_17-32-32
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 820.0
  episode_reward_mean: 460.28
  episode_reward_min: 280.0
  episodes_this_iter: 1
  episodes_total: 174
  experiment_id: f3470259fa9143609a5dd5049ba7f979
  hostname: gpu020
  info:
    apply_time_ms: 2.659
    dispatch_time_ms: 73.611
    learner:
      cur_lr: 0.0013020579935982823
      grad_gnorm: 39.999996185302734
      policy_entropy: 17.910816192626953
      policy_loss: 8.425907135009766
      var_gnorm: 37.62356948852539
      vf_explained_var: 0.09615808725357056
      vf_loss: 15.081875801086426
    num_steps_sampled: 875000
    num_steps_trained: 875000
    wait_time_ms: 38.292
  iterations_since_restore: 175
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 830
  policy_reward_mean: {}
  time_since_restore: 2153.277111530304
  time_this_iter_s: 12.248435974121094
  time_total_s: 2153.277111530304
  timestamp: 1593811952
  timesteps_since_restore: 875000
  timesteps_this_iter: 5000
  timesteps_total: 875000
  training_iteration: 175
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 10.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=830], 2153 s, 175 iter, 875000 ts, 460 rew

agent-1: 78.0
agent-2: 75.0
agent-3: 80.0
agent-4: 92.0
agent-5: 75.0
Sum Reward: 400.0
Avg Reward: 80.0
Min Reward: 75.0
Gini Coefficient 0.039
W0703 17:32:53.515830   825 node_manager.cc:250] Last heartbeat was sent 2137 ms ago 
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_17-32-49
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 820.0
  episode_reward_mean: 457.47
  episode_reward_min: 280.0
  episodes_this_iter: 1
  episodes_total: 175
  experiment_id: f3470259fa9143609a5dd5049ba7f979
  hostname: gpu020
  info:
    apply_time_ms: 3.293
    dispatch_time_ms: 179.216
    learner:
      cur_lr: 0.0013017250457778573
      grad_gnorm: 40.0
      policy_entropy: 12.70753002166748
      policy_loss: -8.376198768615723
      var_gnorm: 37.682830810546875
      vf_explained_var: 0.9088866710662842
      vf_loss: 85.66950988769531
    num_steps_sampled: 880000
    num_steps_trained: 880000
    wait_time_ms: 325.0
  iterations_since_restore: 176
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 830
  policy_reward_mean: {}
  time_since_restore: 2170.4801211357117
  time_this_iter_s: 17.203009605407715
  time_total_s: 2170.4801211357117
  timestamp: 1593811969
  timesteps_since_restore: 880000
  timesteps_this_iter: 5000
  timesteps_total: 880000
  training_iteration: 176
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 10.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=830], 2170 s, 176 iter, 880000 ts, 457 rew

agent-1: 73.0
agent-2: 70.0
agent-3: 82.0
agent-4: 95.0
agent-5: 96.0
Sum Reward: 416.0
Avg Reward: 83.2
Min Reward: 70.0
Gini Coefficient 0.07115384615384615
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_17-33-11
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 820.0
  episode_reward_mean: 457.58
  episode_reward_min: 280.0
  episodes_this_iter: 1
  episodes_total: 176
  experiment_id: f3470259fa9143609a5dd5049ba7f979
  hostname: gpu020
  info:
    apply_time_ms: 3.0
    dispatch_time_ms: 69.596
    learner:
      cur_lr: 0.0013013919815421104
      grad_gnorm: 18.073022842407227
      policy_entropy: 40.15487289428711
      policy_loss: -1.0055350065231323
      var_gnorm: 37.76038360595703
      vf_explained_var: 0.9915577173233032
      vf_loss: 0.35897302627563477
    num_steps_sampled: 885000
    num_steps_trained: 885000
    wait_time_ms: 34.526
  iterations_since_restore: 177
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 830
  policy_reward_mean: {}
  time_since_restore: 2188.244535923004
  time_this_iter_s: 17.76441478729248
  time_total_s: 2188.244535923004
  timestamp: 1593811991
  timesteps_since_restore: 885000
  timesteps_this_iter: 5000
  timesteps_total: 885000
  training_iteration: 177
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 13.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=830], 2188 s, 177 iter, 885000 ts, 458 rew

agent-1: 109.0
agent-2: 82.0
agent-3: 96.0
agent-4: 106.0
agent-5: 99.0
Sum Reward: 492.0
Avg Reward: 98.4
Min Reward: 82.0
Gini Coefficient 0.05203252032520325
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_17-33-24
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 820.0
  episode_reward_mean: 456.82
  episode_reward_min: 280.0
  episodes_this_iter: 1
  episodes_total: 177
  experiment_id: f3470259fa9143609a5dd5049ba7f979
  hostname: gpu020
  info:
    apply_time_ms: 3.011
    dispatch_time_ms: 62.873
    learner:
      cur_lr: 0.0013010590337216854
      grad_gnorm: 40.000003814697266
      policy_entropy: 28.706707000732422
      policy_loss: 2.8502037525177
      var_gnorm: 37.84299087524414
      vf_explained_var: -1.0
      vf_loss: 81.41514587402344
    num_steps_sampled: 890000
    num_steps_trained: 890000
    wait_time_ms: 54.244
  iterations_since_restore: 178
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 830
  policy_reward_mean: {}
  time_since_restore: 2201.512476205826
  time_this_iter_s: 13.267940282821655
  time_total_s: 2201.512476205826
  timestamp: 1593812004
  timesteps_since_restore: 890000
  timesteps_this_iter: 5000
  timesteps_total: 890000
  training_iteration: 178
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 13.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=830], 2201 s, 178 iter, 890000 ts, 457 rew

agent-1: 111.0
agent-2: 107.0
agent-3: 103.0
agent-4: 139.0
agent-5: 94.0
Sum Reward: 554.0
Avg Reward: 110.8
Min Reward: 94.0
Gini Coefficient 0.07075812274368232
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_17-33-36
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 820.0
  episode_reward_mean: 458.57
  episode_reward_min: 280.0
  episodes_this_iter: 1
  episodes_total: 178
  experiment_id: f3470259fa9143609a5dd5049ba7f979
  hostname: gpu020
  info:
    apply_time_ms: 3.817
    dispatch_time_ms: 11.339
    learner:
      cur_lr: 0.0013007259694859385
      grad_gnorm: 39.999996185302734
      policy_entropy: 13.951899528503418
      policy_loss: 7.493378162384033
      var_gnorm: 38.03395080566406
      vf_explained_var: -0.5378763675689697
      vf_loss: 44.423065185546875
    num_steps_sampled: 895000
    num_steps_trained: 895000
    wait_time_ms: 93.187
  iterations_since_restore: 179
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 830
  policy_reward_mean: {}
  time_since_restore: 2213.1671845912933
  time_this_iter_s: 11.65470838546753
  time_total_s: 2213.1671845912933
  timestamp: 1593812016
  timesteps_since_restore: 895000
  timesteps_this_iter: 5000
  timesteps_total: 895000
  training_iteration: 179
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 13.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=830], 2213 s, 179 iter, 895000 ts, 459 rew

agent-1: 119.0
agent-2: 108.0
agent-3: 126.0
agent-4: 114.0
agent-5: 126.0
Sum Reward: 593.0
Avg Reward: 118.6
Min Reward: 108.0
Gini Coefficient 0.03237774030354131
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_17-33-47
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 820.0
  episode_reward_mean: 459.5
  episode_reward_min: 280.0
  episodes_this_iter: 1
  episodes_total: 179
  experiment_id: f3470259fa9143609a5dd5049ba7f979
  hostname: gpu020
  info:
    apply_time_ms: 2.579
    dispatch_time_ms: 7.262
    learner:
      cur_lr: 0.0013003930216655135
      grad_gnorm: 40.00001525878906
      policy_entropy: 23.19461441040039
      policy_loss: -12.18142032623291
      var_gnorm: 38.09937286376953
      vf_explained_var: -1.0
      vf_loss: 22.08182144165039
    num_steps_sampled: 900000
    num_steps_trained: 900000
    wait_time_ms: 100.512
  iterations_since_restore: 180
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 830
  policy_reward_mean: {}
  time_since_restore: 2223.94553899765
  time_this_iter_s: 10.778354406356812
  time_total_s: 2223.94553899765
  timestamp: 1593812027
  timesteps_since_restore: 900000
  timesteps_this_iter: 5000
  timesteps_total: 900000
  training_iteration: 180
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 10.3/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=830], 2223 s, 180 iter, 900000 ts, 460 rew

agent-1: 154.0
agent-2: 140.0
agent-3: 103.0
agent-4: 134.0
agent-5: 119.0
Sum Reward: 650.0
Avg Reward: 130.0
Min Reward: 103.0
Gini Coefficient 0.0756923076923077
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_17-33-59
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 820.0
  episode_reward_mean: 461.85
  episode_reward_min: 280.0
  episodes_this_iter: 1
  episodes_total: 180
  experiment_id: f3470259fa9143609a5dd5049ba7f979
  hostname: gpu020
  info:
    apply_time_ms: 2.871
    dispatch_time_ms: 63.275
    learner:
      cur_lr: 0.0013000599574297667
      grad_gnorm: 39.999996185302734
      policy_entropy: 22.71238136291504
      policy_loss: -9.537137985229492
      var_gnorm: 38.18756866455078
      vf_explained_var: 0.618683934211731
      vf_loss: 62.071449279785156
    num_steps_sampled: 905000
    num_steps_trained: 905000
    wait_time_ms: 68.338
  iterations_since_restore: 181
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 830
  policy_reward_mean: {}
  time_since_restore: 2235.994047641754
  time_this_iter_s: 12.048508644104004
  time_total_s: 2235.994047641754
  timestamp: 1593812039
  timesteps_since_restore: 905000
  timesteps_this_iter: 5000
  timesteps_total: 905000
  training_iteration: 181
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 10.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=830], 2235 s, 181 iter, 905000 ts, 462 rew

agent-1: 96.0
agent-2: 119.0
agent-3: 157.0
agent-4: 156.0
agent-5: 140.0
Sum Reward: 668.0
Avg Reward: 133.6
Min Reward: 96.0
Gini Coefficient 0.09520958083832336
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_17-34-11
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 820.0
  episode_reward_mean: 464.03
  episode_reward_min: 280.0
  episodes_this_iter: 1
  episodes_total: 181
  experiment_id: f3470259fa9143609a5dd5049ba7f979
  hostname: gpu020
  info:
    apply_time_ms: 3.433
    dispatch_time_ms: 15.084
    learner:
      cur_lr: 0.0012997270096093416
      grad_gnorm: 39.9999885559082
      policy_entropy: 28.256162643432617
      policy_loss: -34.2149772644043
      var_gnorm: 38.18819046020508
      vf_explained_var: -0.4635576009750366
      vf_loss: 203.79470825195312
    num_steps_sampled: 910000
    num_steps_trained: 910000
    wait_time_ms: 99.687
  iterations_since_restore: 182
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 830
  policy_reward_mean: {}
  time_since_restore: 2247.748079061508
  time_this_iter_s: 11.754031419754028
  time_total_s: 2247.748079061508
  timestamp: 1593812051
  timesteps_since_restore: 910000
  timesteps_this_iter: 5000
  timesteps_total: 910000
  training_iteration: 182
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 10.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=830], 2247 s, 182 iter, 910000 ts, 464 rew

agent-1: 113.0
agent-2: 121.0
agent-3: 112.0
agent-4: 129.0
agent-5: 129.0
Sum Reward: 604.0
Avg Reward: 120.8
Min Reward: 112.0
Gini Coefficient 0.033112582781456956
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_17-34-22
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 820.0
  episode_reward_mean: 466.53
  episode_reward_min: 280.0
  episodes_this_iter: 1
  episodes_total: 182
  experiment_id: f3470259fa9143609a5dd5049ba7f979
  hostname: gpu020
  info:
    apply_time_ms: 3.493
    dispatch_time_ms: 7.961
    learner:
      cur_lr: 0.0012993939453735948
      grad_gnorm: 40.000003814697266
      policy_entropy: 12.677508354187012
      policy_loss: -13.158042907714844
      var_gnorm: 38.25119400024414
      vf_explained_var: 0.21027177572250366
      vf_loss: 49.5505256652832
    num_steps_sampled: 915000
    num_steps_trained: 915000
    wait_time_ms: 99.071
  iterations_since_restore: 183
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 830
  policy_reward_mean: {}
  time_since_restore: 2259.2999792099
  time_this_iter_s: 11.551900148391724
  time_total_s: 2259.2999792099
  timestamp: 1593812062
  timesteps_since_restore: 915000
  timesteps_this_iter: 5000
  timesteps_total: 915000
  training_iteration: 183
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 10.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=830], 2259 s, 183 iter, 915000 ts, 467 rew

agent-1: 84.0
agent-2: 126.0
agent-3: 105.0
agent-4: 124.0
agent-5: 64.0
Sum Reward: 503.0
Avg Reward: 100.6
Min Reward: 64.0
Gini Coefficient 0.13041749502982108
W0703 17:34:34.183900   825 node_manager.cc:250] Last heartbeat was sent 1946 ms ago 
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_17-34-37
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 820.0
  episode_reward_mean: 467.11
  episode_reward_min: 280.0
  episodes_this_iter: 1
  episodes_total: 183
  experiment_id: f3470259fa9143609a5dd5049ba7f979
  hostname: gpu020
  info:
    apply_time_ms: 2.698
    dispatch_time_ms: 6.146
    learner:
      cur_lr: 0.0012990609975531697
      grad_gnorm: 40.00000762939453
      policy_entropy: 20.877857208251953
      policy_loss: 7.432489395141602
      var_gnorm: 38.35358428955078
      vf_explained_var: -0.21353209018707275
      vf_loss: 44.52589416503906
    num_steps_sampled: 920000
    num_steps_trained: 920000
    wait_time_ms: 99.805
  iterations_since_restore: 184
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 830
  policy_reward_mean: {}
  time_since_restore: 2273.670361995697
  time_this_iter_s: 14.37038278579712
  time_total_s: 2273.670361995697
  timestamp: 1593812077
  timesteps_since_restore: 920000
  timesteps_this_iter: 5000
  timesteps_total: 920000
  training_iteration: 184
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 10.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=830], 2273 s, 184 iter, 920000 ts, 467 rew

agent-1: 109.0
agent-2: 105.0
agent-3: 121.0
agent-4: 113.0
agent-5: 93.0
Sum Reward: 541.0
Avg Reward: 108.2
Min Reward: 93.0
Gini Coefficient 0.04731977818853974
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_17-34-48
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 820.0
  episode_reward_mean: 469.14
  episode_reward_min: 280.0
  episodes_this_iter: 1
  episodes_total: 184
  experiment_id: f3470259fa9143609a5dd5049ba7f979
  hostname: gpu020
  info:
    apply_time_ms: 3.143
    dispatch_time_ms: 9.19
    learner:
      cur_lr: 0.0012987280497327447
      grad_gnorm: 39.999996185302734
      policy_entropy: 18.053205490112305
      policy_loss: 9.003937721252441
      var_gnorm: 38.39509582519531
      vf_explained_var: -0.05675244331359863
      vf_loss: 54.13151931762695
    num_steps_sampled: 925000
    num_steps_trained: 925000
    wait_time_ms: 87.854
  iterations_since_restore: 185
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 830
  policy_reward_mean: {}
  time_since_restore: 2285.12308716774
  time_this_iter_s: 11.452725172042847
  time_total_s: 2285.12308716774
  timestamp: 1593812088
  timesteps_since_restore: 925000
  timesteps_this_iter: 5000
  timesteps_total: 925000
  training_iteration: 185
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 10.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=830], 2285 s, 185 iter, 925000 ts, 469 rew

agent-1: 137.0
agent-2: 110.0
agent-3: 141.0
agent-4: 151.0
agent-5: 110.0
Sum Reward: 649.0
Avg Reward: 129.8
Min Reward: 110.0
Gini Coefficient 0.06964560862865947
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_17-34-59
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 820.0
  episode_reward_mean: 472.18
  episode_reward_min: 280.0
  episodes_this_iter: 1
  episodes_total: 185
  experiment_id: f3470259fa9143609a5dd5049ba7f979
  hostname: gpu020
  info:
    apply_time_ms: 3.557
    dispatch_time_ms: 11.335
    learner:
      cur_lr: 0.0012983949854969978
      grad_gnorm: 39.999977111816406
      policy_entropy: 25.424591064453125
      policy_loss: 62.80021286010742
      var_gnorm: 38.46731185913086
      vf_explained_var: 0.3515852093696594
      vf_loss: 529.48388671875
    num_steps_sampled: 930000
    num_steps_trained: 930000
    wait_time_ms: 105.102
  iterations_since_restore: 186
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 830
  policy_reward_mean: {}
  time_since_restore: 2296.4563822746277
  time_this_iter_s: 11.333295106887817
  time_total_s: 2296.4563822746277
  timestamp: 1593812099
  timesteps_since_restore: 930000
  timesteps_this_iter: 5000
  timesteps_total: 930000
  training_iteration: 186
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 10.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=830], 2296 s, 186 iter, 930000 ts, 472 rew

agent-1: 128.0
agent-2: 128.0
agent-3: 108.0
agent-4: 136.0
agent-5: 96.0
Sum Reward: 596.0
Avg Reward: 119.2
Min Reward: 96.0
Gini Coefficient 0.06711409395973154
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_17-35-16
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 820.0
  episode_reward_mean: 473.31
  episode_reward_min: 280.0
  episodes_this_iter: 1
  episodes_total: 186
  experiment_id: f3470259fa9143609a5dd5049ba7f979
  hostname: gpu020
  info:
    apply_time_ms: 2.728
    dispatch_time_ms: 12.384
    learner:
      cur_lr: 0.0012980620376765728
      grad_gnorm: 40.000003814697266
      policy_entropy: 14.736812591552734
      policy_loss: -19.043006896972656
      var_gnorm: 38.57708740234375
      vf_explained_var: 0.44952696561813354
      vf_loss: 229.779296875
    num_steps_sampled: 935000
    num_steps_trained: 935000
    wait_time_ms: 110.029
  iterations_since_restore: 187
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 830
  policy_reward_mean: {}
  time_since_restore: 2313.3878848552704
  time_this_iter_s: 16.9315025806427
  time_total_s: 2313.3878848552704
  timestamp: 1593812116
  timesteps_since_restore: 935000
  timesteps_this_iter: 5000
  timesteps_total: 935000
  training_iteration: 187
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 13.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=830], 2313 s, 187 iter, 935000 ts, 473 rew

agent-1: 83.0
agent-2: 59.0
agent-3: 108.0
agent-4: 69.0
agent-5: 70.0
Sum Reward: 389.0
Avg Reward: 77.8
Min Reward: 59.0
Gini Coefficient 0.11516709511568124
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_17-35-28
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 820.0
  episode_reward_mean: 472.89
  episode_reward_min: 280.0
  episodes_this_iter: 1
  episodes_total: 187
  experiment_id: f3470259fa9143609a5dd5049ba7f979
  hostname: gpu020
  info:
    apply_time_ms: 2.799
    dispatch_time_ms: 12.524
    learner:
      cur_lr: 0.001297728973440826
      grad_gnorm: 6.582062244415283
      policy_entropy: 17.46331787109375
      policy_loss: 2.0115554332733154
      var_gnorm: 38.620582580566406
      vf_explained_var: 0.816524088382721
      vf_loss: 1.8758525848388672
    num_steps_sampled: 940000
    num_steps_trained: 940000
    wait_time_ms: 102.99
  iterations_since_restore: 188
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 830
  policy_reward_mean: {}
  time_since_restore: 2324.9666118621826
  time_this_iter_s: 11.578727006912231
  time_total_s: 2324.9666118621826
  timestamp: 1593812128
  timesteps_since_restore: 940000
  timesteps_this_iter: 5000
  timesteps_total: 940000
  training_iteration: 188
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 13.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=830], 2324 s, 188 iter, 940000 ts, 473 rew

agent-1: 81.0
agent-2: 106.0
agent-3: 94.0
agent-4: 82.0
agent-5: 113.0
Sum Reward: 476.0
Avg Reward: 95.2
Min Reward: 81.0
Gini Coefficient 0.07394957983193277
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_17-35-40
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 820.0
  episode_reward_mean: 473.5
  episode_reward_min: 280.0
  episodes_this_iter: 1
  episodes_total: 188
  experiment_id: f3470259fa9143609a5dd5049ba7f979
  hostname: gpu020
  info:
    apply_time_ms: 5.091
    dispatch_time_ms: 19.954
    learner:
      cur_lr: 0.001297396025620401
      grad_gnorm: 40.0
      policy_entropy: 15.584771156311035
      policy_loss: 22.311458587646484
      var_gnorm: 38.6209831237793
      vf_explained_var: -0.14293479919433594
      vf_loss: 48.47857666015625
    num_steps_sampled: 945000
    num_steps_trained: 945000
    wait_time_ms: 32.746
  iterations_since_restore: 189
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 830
  policy_reward_mean: {}
  time_since_restore: 2337.124323606491
  time_this_iter_s: 12.157711744308472
  time_total_s: 2337.124323606491
  timestamp: 1593812140
  timesteps_since_restore: 945000
  timesteps_this_iter: 5000
  timesteps_total: 945000
  training_iteration: 189
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 13.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=830], 2337 s, 189 iter, 945000 ts, 474 rew

agent-1: 94.0
agent-2: 121.0
agent-3: 89.0
agent-4: 81.0
agent-5: 65.0
Sum Reward: 450.0
Avg Reward: 90.0
Min Reward: 65.0
Gini Coefficient 0.1111111111111111
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_17-35-52
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 820.0
  episode_reward_mean: 474.0
  episode_reward_min: 280.0
  episodes_this_iter: 1
  episodes_total: 189
  experiment_id: f3470259fa9143609a5dd5049ba7f979
  hostname: gpu020
  info:
    apply_time_ms: 2.523
    dispatch_time_ms: 8.388
    learner:
      cur_lr: 0.001297062961384654
      grad_gnorm: 40.0
      policy_entropy: 29.892770767211914
      policy_loss: -7.40566349029541
      var_gnorm: 38.59658432006836
      vf_explained_var: -1.0
      vf_loss: 3.0944457054138184
    num_steps_sampled: 950000
    num_steps_trained: 950000
    wait_time_ms: 113.104
  iterations_since_restore: 190
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 830
  policy_reward_mean: {}
  time_since_restore: 2348.4490411281586
  time_this_iter_s: 11.32471752166748
  time_total_s: 2348.4490411281586
  timestamp: 1593812152
  timesteps_since_restore: 950000
  timesteps_this_iter: 5000
  timesteps_total: 950000
  training_iteration: 190
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 13.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=830], 2348 s, 190 iter, 950000 ts, 474 rew

agent-1: 93.0
agent-2: 69.0
agent-3: 110.0
agent-4: 113.0
agent-5: 95.0
Sum Reward: 480.0
Avg Reward: 96.0
Min Reward: 69.0
Gini Coefficient 0.0875
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_17-36-04
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 820.0
  episode_reward_mean: 474.0
  episode_reward_min: 280.0
  episodes_this_iter: 1
  episodes_total: 190
  experiment_id: f3470259fa9143609a5dd5049ba7f979
  hostname: gpu020
  info:
    apply_time_ms: 2.888
    dispatch_time_ms: 7.223
    learner:
      cur_lr: 0.001296730013564229
      grad_gnorm: 15.18371295928955
      policy_entropy: 27.089900970458984
      policy_loss: -2.5599722862243652
      var_gnorm: 38.687164306640625
      vf_explained_var: 0.9748818874359131
      vf_loss: 0.40560802817344666
    num_steps_sampled: 955000
    num_steps_trained: 955000
    wait_time_ms: 108.086
  iterations_since_restore: 191
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 830
  policy_reward_mean: {}
  time_since_restore: 2360.5567286014557
  time_this_iter_s: 12.10768747329712
  time_total_s: 2360.5567286014557
  timestamp: 1593812164
  timesteps_since_restore: 955000
  timesteps_this_iter: 5000
  timesteps_total: 955000
  training_iteration: 191
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 13.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=830], 2360 s, 191 iter, 955000 ts, 474 rew

agent-1: 97.0
agent-2: 110.0
agent-3: 106.0
agent-4: 92.0
agent-5: 96.0
Sum Reward: 501.0
Avg Reward: 100.2
Min Reward: 92.0
Gini Coefficient 0.036726546906187624
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_17-36-16
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 820.0
  episode_reward_mean: 472.24
  episode_reward_min: 280.0
  episodes_this_iter: 1
  episodes_total: 191
  experiment_id: f3470259fa9143609a5dd5049ba7f979
  hostname: gpu020
  info:
    apply_time_ms: 3.109
    dispatch_time_ms: 16.931
    learner:
      cur_lr: 0.0012963969493284822
      grad_gnorm: 39.9999885559082
      policy_entropy: 20.90605926513672
      policy_loss: -22.27876091003418
      var_gnorm: 38.74802017211914
      vf_explained_var: 0.6268500089645386
      vf_loss: 158.39913940429688
    num_steps_sampled: 960000
    num_steps_trained: 960000
    wait_time_ms: 37.04
  iterations_since_restore: 192
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 830
  policy_reward_mean: {}
  time_since_restore: 2372.9059970378876
  time_this_iter_s: 12.349268436431885
  time_total_s: 2372.9059970378876
  timestamp: 1593812176
  timesteps_since_restore: 960000
  timesteps_this_iter: 5000
  timesteps_total: 960000
  training_iteration: 192
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 13.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=830], 2372 s, 192 iter, 960000 ts, 472 rew

agent-1: 123.0
agent-2: 118.0
agent-3: 94.0
agent-4: 89.0
agent-5: 111.0
Sum Reward: 535.0
Avg Reward: 107.0
Min Reward: 89.0
Gini Coefficient 0.06878504672897197
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_17-36-28
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 820.0
  episode_reward_mean: 473.17
  episode_reward_min: 280.0
  episodes_this_iter: 1
  episodes_total: 192
  experiment_id: f3470259fa9143609a5dd5049ba7f979
  hostname: gpu020
  info:
    apply_time_ms: 3.674
    dispatch_time_ms: 6.569
    learner:
      cur_lr: 0.0012960640015080571
      grad_gnorm: 40.0
      policy_entropy: 28.63888931274414
      policy_loss: 6.248411655426025
      var_gnorm: 38.809932708740234
      vf_explained_var: 0.5482059717178345
      vf_loss: 62.415706634521484
    num_steps_sampled: 965000
    num_steps_trained: 965000
    wait_time_ms: 113.158
  iterations_since_restore: 193
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 830
  policy_reward_mean: {}
  time_since_restore: 2384.795745611191
  time_this_iter_s: 11.889748573303223
  time_total_s: 2384.795745611191
  timestamp: 1593812188
  timesteps_since_restore: 965000
  timesteps_this_iter: 5000
  timesteps_total: 965000
  training_iteration: 193
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 13.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=830], 2384 s, 193 iter, 965000 ts, 473 rew

agent-1: 132.0
agent-2: 148.0
agent-3: 120.0
agent-4: 125.0
agent-5: 136.0
Sum Reward: 661.0
Avg Reward: 132.2
Min Reward: 120.0
Gini Coefficient 0.0405446293494705
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_17-36-40
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 820.0
  episode_reward_mean: 475.68
  episode_reward_min: 280.0
  episodes_this_iter: 1
  episodes_total: 193
  experiment_id: f3470259fa9143609a5dd5049ba7f979
  hostname: gpu020
  info:
    apply_time_ms: 4.954
    dispatch_time_ms: 74.776
    learner:
      cur_lr: 0.001295731053687632
      grad_gnorm: 39.99998474121094
      policy_entropy: 17.66245460510254
      policy_loss: -12.77519416809082
      var_gnorm: 38.89288330078125
      vf_explained_var: -1.0
      vf_loss: 113.2806396484375
    num_steps_sampled: 970000
    num_steps_trained: 970000
    wait_time_ms: 97.3
  iterations_since_restore: 194
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 830
  policy_reward_mean: {}
  time_since_restore: 2396.869201898575
  time_this_iter_s: 12.073456287384033
  time_total_s: 2396.869201898575
  timestamp: 1593812200
  timesteps_since_restore: 970000
  timesteps_this_iter: 5000
  timesteps_total: 970000
  training_iteration: 194
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 13.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=830], 2396 s, 194 iter, 970000 ts, 476 rew

agent-1: 67.0
agent-2: 77.0
agent-3: 88.0
agent-4: 93.0
agent-5: 89.0
Sum Reward: 414.0
Avg Reward: 82.8
Min Reward: 67.0
Gini Coefficient 0.06183574879227053
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_17-36-52
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 820.0
  episode_reward_mean: 476.78
  episode_reward_min: 280.0
  episodes_this_iter: 1
  episodes_total: 194
  experiment_id: f3470259fa9143609a5dd5049ba7f979
  hostname: gpu020
  info:
    apply_time_ms: 3.035
    dispatch_time_ms: 10.482
    learner:
      cur_lr: 0.0012953979894518852
      grad_gnorm: 0.45696398615837097
      policy_entropy: 15.193187713623047
      policy_loss: 0.07588640600442886
      var_gnorm: 38.96263122558594
      vf_explained_var: 1.1920928955078125e-07
      vf_loss: 0.0001040523566189222
    num_steps_sampled: 975000
    num_steps_trained: 975000
    wait_time_ms: 100.589
  iterations_since_restore: 195
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 830
  policy_reward_mean: {}
  time_since_restore: 2408.478306055069
  time_this_iter_s: 11.60910415649414
  time_total_s: 2408.478306055069
  timestamp: 1593812212
  timesteps_since_restore: 975000
  timesteps_this_iter: 5000
  timesteps_total: 975000
  training_iteration: 195
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 13.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=830], 2408 s, 195 iter, 975000 ts, 477 rew

agent-1: 92.0
agent-2: 59.0
agent-3: 77.0
agent-4: 81.0
agent-5: 90.0
Sum Reward: 399.0
Avg Reward: 79.8
Min Reward: 59.0
Gini Coefficient 0.07919799498746867
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_17-37-03
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 820.0
  episode_reward_mean: 477.62
  episode_reward_min: 280.0
  episodes_this_iter: 1
  episodes_total: 195
  experiment_id: f3470259fa9143609a5dd5049ba7f979
  hostname: gpu020
  info:
    apply_time_ms: 2.785
    dispatch_time_ms: 5.898
    learner:
      cur_lr: 0.0012950650416314602
      grad_gnorm: 40.00000762939453
      policy_entropy: 12.668320655822754
      policy_loss: 26.846872329711914
      var_gnorm: 38.958011627197266
      vf_explained_var: -0.16595828533172607
      vf_loss: 621.3905639648438
    num_steps_sampled: 980000
    num_steps_trained: 980000
    wait_time_ms: 108.018
  iterations_since_restore: 196
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 830
  policy_reward_mean: {}
  time_since_restore: 2419.343286752701
  time_this_iter_s: 10.864980697631836
  time_total_s: 2419.343286752701
  timestamp: 1593812223
  timesteps_since_restore: 980000
  timesteps_this_iter: 5000
  timesteps_total: 980000
  training_iteration: 196
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 13.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=830], 2419 s, 196 iter, 980000 ts, 478 rew

agent-1: 122.0
agent-2: 126.0
agent-3: 153.0
agent-4: 135.0
agent-5: 107.0
Sum Reward: 643.0
Avg Reward: 128.6
Min Reward: 107.0
Gini Coefficient 0.06531881804043546
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_17-37-16
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 820.0
  episode_reward_mean: 480.73
  episode_reward_min: 280.0
  episodes_this_iter: 1
  episodes_total: 196
  experiment_id: f3470259fa9143609a5dd5049ba7f979
  hostname: gpu020
  info:
    apply_time_ms: 3.268
    dispatch_time_ms: 17.758
    learner:
      cur_lr: 0.0012947319773957133
      grad_gnorm: 40.000003814697266
      policy_entropy: 4.751363277435303
      policy_loss: 1.557376503944397
      var_gnorm: 39.043731689453125
      vf_explained_var: 0.21111249923706055
      vf_loss: 43.60105514526367
    num_steps_sampled: 985000
    num_steps_trained: 985000
    wait_time_ms: 31.795
  iterations_since_restore: 197
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 830
  policy_reward_mean: {}
  time_since_restore: 2432.3196926116943
  time_this_iter_s: 12.97640585899353
  time_total_s: 2432.3196926116943
  timestamp: 1593812236
  timesteps_since_restore: 985000
  timesteps_this_iter: 5000
  timesteps_total: 985000
  training_iteration: 197
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 13.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=830], 2432 s, 197 iter, 985000 ts, 481 rew

agent-1: 70.0
agent-2: 86.0
agent-3: 80.0
agent-4: 92.0
agent-5: 79.0
Sum Reward: 407.0
Avg Reward: 81.4
Min Reward: 70.0
Gini Coefficient 0.05012285012285012
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_17-37-39
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 820.0
  episode_reward_mean: 481.66
  episode_reward_min: 280.0
  episodes_this_iter: 1
  episodes_total: 197
  experiment_id: f3470259fa9143609a5dd5049ba7f979
  hostname: gpu020
  info:
    apply_time_ms: 2.959
    dispatch_time_ms: 9.017
    learner:
      cur_lr: 0.0012943990295752883
      grad_gnorm: 40.000003814697266
      policy_entropy: 30.27976417541504
      policy_loss: -9.425681114196777
      var_gnorm: 39.08750915527344
      vf_explained_var: -1.0
      vf_loss: 22.97109603881836
    num_steps_sampled: 990000
    num_steps_trained: 990000
    wait_time_ms: 108.441
  iterations_since_restore: 198
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 830
  policy_reward_mean: {}
  time_since_restore: 2455.8233935832977
  time_this_iter_s: 23.503700971603394
  time_total_s: 2455.8233935832977
  timestamp: 1593812259
  timesteps_since_restore: 990000
  timesteps_this_iter: 5000
  timesteps_total: 990000
  training_iteration: 198
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 13.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=830], 2455 s, 198 iter, 990000 ts, 482 rew

agent-1: 98.0
agent-2: 125.0
agent-3: 65.0
agent-4: 92.0
agent-5: 106.0
Sum Reward: 486.0
Avg Reward: 97.2
Min Reward: 65.0
Gini Coefficient 0.1102880658436214
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_17-37-51
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 820.0
  episode_reward_mean: 482.87
  episode_reward_min: 280.0
  episodes_this_iter: 1
  episodes_total: 198
  experiment_id: f3470259fa9143609a5dd5049ba7f979
  hostname: gpu020
  info:
    apply_time_ms: 3.098
    dispatch_time_ms: 6.958
    learner:
      cur_lr: 0.0012940659653395414
      grad_gnorm: 1.1888083219528198
      policy_entropy: 36.559383392333984
      policy_loss: 1.1828874349594116
      var_gnorm: 39.126705169677734
      vf_explained_var: -1.0
      vf_loss: 0.3253636062145233
    num_steps_sampled: 995000
    num_steps_trained: 995000
    wait_time_ms: 102.303
  iterations_since_restore: 199
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 830
  policy_reward_mean: {}
  time_since_restore: 2467.9831204414368
  time_this_iter_s: 12.159726858139038
  time_total_s: 2467.9831204414368
  timestamp: 1593812271
  timesteps_since_restore: 995000
  timesteps_this_iter: 5000
  timesteps_total: 995000
  training_iteration: 199
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 13.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=830], 2467 s, 199 iter, 995000 ts, 483 rew

agent-1: 82.0
agent-2: 69.0
agent-3: 79.0
agent-4: 82.0
agent-5: 90.0
Sum Reward: 402.0
Avg Reward: 80.4
Min Reward: 69.0
Gini Coefficient 0.04477611940298507
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_17-38-02
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 820.0
  episode_reward_mean: 483.55
  episode_reward_min: 280.0
  episodes_this_iter: 1
  episodes_total: 199
  experiment_id: f3470259fa9143609a5dd5049ba7f979
  hostname: gpu020
  info:
    apply_time_ms: 2.894
    dispatch_time_ms: 6.441
    learner:
      cur_lr: 0.0012937330175191164
      grad_gnorm: 39.999996185302734
      policy_entropy: 34.744956970214844
      policy_loss: 17.797914505004883
      var_gnorm: 39.26642608642578
      vf_explained_var: 0.22251194715499878
      vf_loss: 47.25227355957031
    num_steps_sampled: 1000000
    num_steps_trained: 1000000
    wait_time_ms: 112.09
  iterations_since_restore: 200
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 830
  policy_reward_mean: {}
  time_since_restore: 2479.055240869522
  time_this_iter_s: 11.072120428085327
  time_total_s: 2479.055240869522
  timestamp: 1593812282
  timesteps_since_restore: 1000000
  timesteps_this_iter: 5000
  timesteps_total: 1000000
  training_iteration: 200
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 13.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=830], 2479 s, 200 iter, 1000000 ts, 484 rew

agent-1: 98.0
agent-2: 100.0
agent-3: 110.0
agent-4: 110.0
agent-5: 104.0
Sum Reward: 522.0
Avg Reward: 104.4
Min Reward: 98.0
Gini Coefficient 0.026053639846743294
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_17-38-14
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 820.0
  episode_reward_mean: 485.03
  episode_reward_min: 280.0
  episodes_this_iter: 1
  episodes_total: 200
  experiment_id: f3470259fa9143609a5dd5049ba7f979
  hostname: gpu020
  info:
    apply_time_ms: 2.993
    dispatch_time_ms: 7.34
    learner:
      cur_lr: 0.0012933999532833695
      grad_gnorm: 40.0
      policy_entropy: 32.48564910888672
      policy_loss: -27.378456115722656
      var_gnorm: 39.326866149902344
      vf_explained_var: -1.0
      vf_loss: 165.955078125
    num_steps_sampled: 1005000
    num_steps_trained: 1005000
    wait_time_ms: 98.456
  iterations_since_restore: 201
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 830
  policy_reward_mean: {}
  time_since_restore: 2490.6127910614014
  time_this_iter_s: 11.557550191879272
  time_total_s: 2490.6127910614014
  timestamp: 1593812294
  timesteps_since_restore: 1005000
  timesteps_this_iter: 5000
  timesteps_total: 1005000
  training_iteration: 201
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 13.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=830], 2490 s, 201 iter, 1005000 ts, 485 rew

agent-1: 114.0
agent-2: 159.0
agent-3: 140.0
agent-4: 150.0
agent-5: 139.0
Sum Reward: 702.0
Avg Reward: 140.4
Min Reward: 114.0
Gini Coefficient 0.05754985754985755
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_17-38-25
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 820.0
  episode_reward_mean: 486.97
  episode_reward_min: 280.0
  episodes_this_iter: 1
  episodes_total: 201
  experiment_id: f3470259fa9143609a5dd5049ba7f979
  hostname: gpu020
  info:
    apply_time_ms: 2.676
    dispatch_time_ms: 8.462
    learner:
      cur_lr: 0.0012930670054629445
      grad_gnorm: 40.0000114440918
      policy_entropy: 27.13766860961914
      policy_loss: 2.12294602394104
      var_gnorm: 39.32290267944336
      vf_explained_var: 0.9547771215438843
      vf_loss: 21.794940948486328
    num_steps_sampled: 1010000
    num_steps_trained: 1010000
    wait_time_ms: 106.058
  iterations_since_restore: 202
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 830
  policy_reward_mean: {}
  time_since_restore: 2501.865646839142
  time_this_iter_s: 11.252855777740479
  time_total_s: 2501.865646839142
  timestamp: 1593812305
  timesteps_since_restore: 1010000
  timesteps_this_iter: 5000
  timesteps_total: 1010000
  training_iteration: 202
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 13.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=830], 2501 s, 202 iter, 1010000 ts, 487 rew

agent-1: 69.0
agent-2: 85.0
agent-3: 111.0
agent-4: 77.0
agent-5: 89.0
Sum Reward: 431.0
Avg Reward: 86.2
Min Reward: 69.0
Gini Coefficient 0.08909512761020881
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_17-38-41
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 820.0
  episode_reward_mean: 487.6
  episode_reward_min: 280.0
  episodes_this_iter: 1
  episodes_total: 202
  experiment_id: f3470259fa9143609a5dd5049ba7f979
  hostname: gpu020
  info:
    apply_time_ms: 3.549
    dispatch_time_ms: 7.71
    learner:
      cur_lr: 0.0012927340576425195
      grad_gnorm: 40.0
      policy_entropy: 36.88780212402344
      policy_loss: 4.202409267425537
      var_gnorm: 39.342369079589844
      vf_explained_var: -0.16771435737609863
      vf_loss: 55.845909118652344
    num_steps_sampled: 1015000
    num_steps_trained: 1015000
    wait_time_ms: 109.554
  iterations_since_restore: 203
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 830
  policy_reward_mean: {}
  time_since_restore: 2517.377643585205
  time_this_iter_s: 15.511996746063232
  time_total_s: 2517.377643585205
  timestamp: 1593812321
  timesteps_since_restore: 1015000
  timesteps_this_iter: 5000
  timesteps_total: 1015000
  training_iteration: 203
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 13.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=830], 2517 s, 203 iter, 1015000 ts, 488 rew

agent-1: 105.0
agent-2: 95.0
agent-3: 78.0
agent-4: 93.0
agent-5: 79.0
Sum Reward: 450.0
Avg Reward: 90.0
Min Reward: 78.0
Gini Coefficient 0.06222222222222222
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_17-38-53
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 820.0
  episode_reward_mean: 488.0
  episode_reward_min: 280.0
  episodes_this_iter: 1
  episodes_total: 203
  experiment_id: f3470259fa9143609a5dd5049ba7f979
  hostname: gpu020
  info:
    apply_time_ms: 3.506
    dispatch_time_ms: 70.32
    learner:
      cur_lr: 0.0012924009934067726
      grad_gnorm: 39.9999885559082
      policy_entropy: 41.74311828613281
      policy_loss: 8.06173038482666
      var_gnorm: 39.396873474121094
      vf_explained_var: 0.38353216648101807
      vf_loss: 136.74166870117188
    num_steps_sampled: 1020000
    num_steps_trained: 1020000
    wait_time_ms: 15.297
  iterations_since_restore: 204
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 830
  policy_reward_mean: {}
  time_since_restore: 2529.3038897514343
  time_this_iter_s: 11.926246166229248
  time_total_s: 2529.3038897514343
  timestamp: 1593812333
  timesteps_since_restore: 1020000
  timesteps_this_iter: 5000
  timesteps_total: 1020000
  training_iteration: 204
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 13.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=830], 2529 s, 204 iter, 1020000 ts, 488 rew

agent-1: 60.0
agent-2: 62.0
agent-3: 71.0
agent-4: 63.0
agent-5: 69.0
Sum Reward: 325.0
Avg Reward: 65.0
Min Reward: 60.0
Gini Coefficient 0.03569230769230769
agent-1: 67.0
agent-2: 77.0
agent-3: 78.0
agent-4: 89.0
agent-5: 73.0
Sum Reward: 384.0
Avg Reward: 76.8
Min Reward: 67.0
Gini Coefficient 0.051041666666666666
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_17-39-05
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 820.0
  episode_reward_mean: 484.29
  episode_reward_min: 280.0
  episodes_this_iter: 2
  episodes_total: 205
  experiment_id: f3470259fa9143609a5dd5049ba7f979
  hostname: gpu020
  info:
    apply_time_ms: 2.602
    dispatch_time_ms: 18.378
    learner:
      cur_lr: 0.0012920680455863476
      grad_gnorm: 40.0
      policy_entropy: 44.91172790527344
      policy_loss: 20.557722091674805
      var_gnorm: 39.41306686401367
      vf_explained_var: -1.0
      vf_loss: 10.387393951416016
    num_steps_sampled: 1025000
    num_steps_trained: 1025000
    wait_time_ms: 107.25
  iterations_since_restore: 205
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 830
  policy_reward_mean: {}
  time_since_restore: 2541.603408098221
  time_this_iter_s: 12.299518346786499
  time_total_s: 2541.603408098221
  timestamp: 1593812345
  timesteps_since_restore: 1025000
  timesteps_this_iter: 5000
  timesteps_total: 1025000
  training_iteration: 205
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 13.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=830], 2541 s, 205 iter, 1025000 ts, 484 rew

Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_17-39-16
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 820.0
  episode_reward_mean: 484.29
  episode_reward_min: 280.0
  episodes_this_iter: 0
  episodes_total: 205
  experiment_id: f3470259fa9143609a5dd5049ba7f979
  hostname: gpu020
  info:
    apply_time_ms: 2.78
    dispatch_time_ms: 12.997
    learner:
      cur_lr: 0.0012917349813506007
      grad_gnorm: 40.0
      policy_entropy: 35.363121032714844
      policy_loss: 11.694605827331543
      var_gnorm: 39.47601318359375
      vf_explained_var: 0.8376826047897339
      vf_loss: 59.91379165649414
    num_steps_sampled: 1030000
    num_steps_trained: 1030000
    wait_time_ms: 103.021
  iterations_since_restore: 206
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 830
  policy_reward_mean: {}
  time_since_restore: 2552.475325345993
  time_this_iter_s: 10.871917247772217
  time_total_s: 2552.475325345993
  timestamp: 1593812356
  timesteps_since_restore: 1030000
  timesteps_this_iter: 5000
  timesteps_total: 1030000
  training_iteration: 206
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 13.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=830], 2552 s, 206 iter, 1030000 ts, 484 rew

agent-1: 84.0
agent-2: 100.0
agent-3: 139.0
agent-4: 83.0
agent-5: 113.0
Sum Reward: 519.0
Avg Reward: 103.8
Min Reward: 83.0
Gini Coefficient 0.10867052023121387
agent-1: 84.0
agent-2: 98.0
agent-3: 85.0
agent-4: 128.0
agent-5: 88.0
Sum Reward: 483.0
Avg Reward: 96.6
Min Reward: 84.0
Gini Coefficient 0.08364389233954451
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_17-39-29
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 820.0
  episode_reward_mean: 485.33
  episode_reward_min: 280.0
  episodes_this_iter: 2
  episodes_total: 207
  experiment_id: f3470259fa9143609a5dd5049ba7f979
  hostname: gpu020
  info:
    apply_time_ms: 3.529
    dispatch_time_ms: 32.615
    learner:
      cur_lr: 0.0012914020335301757
      grad_gnorm: 39.999996185302734
      policy_entropy: 49.43767166137695
      policy_loss: 5.438474655151367
      var_gnorm: 39.62886047363281
      vf_explained_var: -1.0
      vf_loss: 96.76338195800781
    num_steps_sampled: 1035000
    num_steps_trained: 1035000
    wait_time_ms: 87.465
  iterations_since_restore: 207
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 830
  policy_reward_mean: {}
  time_since_restore: 2564.9030084609985
  time_this_iter_s: 12.427683115005493
  time_total_s: 2564.9030084609985
  timestamp: 1593812369
  timesteps_since_restore: 1035000
  timesteps_this_iter: 5000
  timesteps_total: 1035000
  training_iteration: 207
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 13.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=830], 2564 s, 207 iter, 1035000 ts, 485 rew

Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_17-39-39
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 820.0
  episode_reward_mean: 485.33
  episode_reward_min: 280.0
  episodes_this_iter: 0
  episodes_total: 207
  experiment_id: f3470259fa9143609a5dd5049ba7f979
  hostname: gpu020
  info:
    apply_time_ms: 3.64
    dispatch_time_ms: 9.188
    learner:
      cur_lr: 0.0012910689692944288
      grad_gnorm: 4.531064033508301
      policy_entropy: 38.324745178222656
      policy_loss: -3.2319726943969727
      var_gnorm: 39.66944885253906
      vf_explained_var: 0.6977001428604126
      vf_loss: 3.8133294582366943
    num_steps_sampled: 1040000
    num_steps_trained: 1040000
    wait_time_ms: 104.589
  iterations_since_restore: 208
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 830
  policy_reward_mean: {}
  time_since_restore: 2575.7482833862305
  time_this_iter_s: 10.845274925231934
  time_total_s: 2575.7482833862305
  timestamp: 1593812379
  timesteps_since_restore: 1040000
  timesteps_this_iter: 5000
  timesteps_total: 1040000
  training_iteration: 208
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 13.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=830], 2575 s, 208 iter, 1040000 ts, 485 rew

agent-1: 82.0
agent-2: 89.0
agent-3: 79.0
agent-4: 89.0
agent-5: 64.0
Sum Reward: 403.0
Avg Reward: 80.6
Min Reward: 64.0
Gini Coefficient 0.05955334987593052
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_17-39-52
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 820.0
  episode_reward_mean: 484.62
  episode_reward_min: 280.0
  episodes_this_iter: 1
  episodes_total: 208
  experiment_id: f3470259fa9143609a5dd5049ba7f979
  hostname: gpu020
  info:
    apply_time_ms: 3.111
    dispatch_time_ms: 9.18
    learner:
      cur_lr: 0.0012907360214740038
      grad_gnorm: 1.3445802927017212
      policy_entropy: 52.085609436035156
      policy_loss: -0.3968416154384613
      var_gnorm: 39.698490142822266
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 0.002266813302412629
    num_steps_sampled: 1045000
    num_steps_trained: 1045000
    wait_time_ms: 117.283
  iterations_since_restore: 209
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 830
  policy_reward_mean: {}
  time_since_restore: 2588.2519967556
  time_this_iter_s: 12.503713369369507
  time_total_s: 2588.2519967556
  timestamp: 1593812392
  timesteps_since_restore: 1045000
  timesteps_this_iter: 5000
  timesteps_total: 1045000
  training_iteration: 209
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 13.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=830], 2588 s, 209 iter, 1045000 ts, 485 rew

agent-1: 96.0
agent-2: 87.0
agent-3: 78.0
agent-4: 71.0
agent-5: 94.0
Sum Reward: 426.0
Avg Reward: 85.2
Min Reward: 71.0
Gini Coefficient 0.061971830985915494
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_17-40-03
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 820.0
  episode_reward_mean: 483.85
  episode_reward_min: 280.0
  episodes_this_iter: 1
  episodes_total: 209
  experiment_id: f3470259fa9143609a5dd5049ba7f979
  hostname: gpu020
  info:
    apply_time_ms: 3.57
    dispatch_time_ms: 15.051
    learner:
      cur_lr: 0.001290402957238257
      grad_gnorm: 15.681309700012207
      policy_entropy: 50.12785720825195
      policy_loss: -4.555506229400635
      var_gnorm: 39.744876861572266
      vf_explained_var: 0.9929091334342957
      vf_loss: 0.38941794633865356
    num_steps_sampled: 1050000
    num_steps_trained: 1050000
    wait_time_ms: 106.914
  iterations_since_restore: 210
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 830
  policy_reward_mean: {}
  time_since_restore: 2599.716796875
  time_this_iter_s: 11.464800119400024
  time_total_s: 2599.716796875
  timestamp: 1593812403
  timesteps_since_restore: 1050000
  timesteps_this_iter: 5000
  timesteps_total: 1050000
  training_iteration: 210
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 13.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=830], 2599 s, 210 iter, 1050000 ts, 484 rew

agent-1: 77.0
agent-2: 54.0
agent-3: 91.0
agent-4: 99.0
agent-5: 64.0
Sum Reward: 385.0
Avg Reward: 77.0
Min Reward: 54.0
Gini Coefficient 0.12155844155844156
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_17-40-16
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 820.0
  episode_reward_mean: 482.81
  episode_reward_min: 280.0
  episodes_this_iter: 1
  episodes_total: 210
  experiment_id: f3470259fa9143609a5dd5049ba7f979
  hostname: gpu020
  info:
    apply_time_ms: 2.596
    dispatch_time_ms: 14.504
    learner:
      cur_lr: 0.001290070009417832
      grad_gnorm: 4.1935553550720215
      policy_entropy: 51.12680435180664
      policy_loss: -1.4784393310546875
      var_gnorm: 39.764732360839844
      vf_explained_var: 1.1920928955078125e-07
      vf_loss: 0.016371645033359528
    num_steps_sampled: 1055000
    num_steps_trained: 1055000
    wait_time_ms: 109.085
  iterations_since_restore: 211
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 830
  policy_reward_mean: {}
  time_since_restore: 2612.2449536323547
  time_this_iter_s: 12.528156757354736
  time_total_s: 2612.2449536323547
  timestamp: 1593812416
  timesteps_since_restore: 1055000
  timesteps_this_iter: 5000
  timesteps_total: 1055000
  training_iteration: 211
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 13.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=830], 2612 s, 211 iter, 1055000 ts, 483 rew

agent-1: 54.0
agent-2: 70.0
agent-3: 63.0
agent-4: 58.0
agent-5: 73.0
Sum Reward: 318.0
Avg Reward: 63.6
Min Reward: 54.0
Gini Coefficient 0.06289308176100629
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_17-40-28
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 820.0
  episode_reward_mean: 482.1
  episode_reward_min: 280.0
  episodes_this_iter: 1
  episodes_total: 211
  experiment_id: f3470259fa9143609a5dd5049ba7f979
  hostname: gpu020
  info:
    apply_time_ms: 4.209
    dispatch_time_ms: 17.516
    learner:
      cur_lr: 0.001289736945182085
      grad_gnorm: 40.0
      policy_entropy: 36.26195526123047
      policy_loss: -15.850444793701172
      var_gnorm: 39.79383850097656
      vf_explained_var: -1.0
      vf_loss: 14.990202903747559
    num_steps_sampled: 1060000
    num_steps_trained: 1060000
    wait_time_ms: 18.996
  iterations_since_restore: 212
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 830
  policy_reward_mean: {}
  time_since_restore: 2624.19215965271
  time_this_iter_s: 11.947206020355225
  time_total_s: 2624.19215965271
  timestamp: 1593812428
  timesteps_since_restore: 1060000
  timesteps_this_iter: 5000
  timesteps_total: 1060000
  training_iteration: 212
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 13.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=830], 2624 s, 212 iter, 1060000 ts, 482 rew

agent-1: 80.0
agent-2: 58.0
agent-3: 94.0
agent-4: 61.0
agent-5: 93.0
Sum Reward: 386.0
Avg Reward: 77.2
Min Reward: 58.0
Gini Coefficient 0.1077720207253886
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_17-40-40
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 820.0
  episode_reward_mean: 480.03
  episode_reward_min: 280.0
  episodes_this_iter: 1
  episodes_total: 212
  experiment_id: f3470259fa9143609a5dd5049ba7f979
  hostname: gpu020
  info:
    apply_time_ms: 3.219
    dispatch_time_ms: 11.975
    learner:
      cur_lr: 0.00128940399736166
      grad_gnorm: 3.3243699073791504
      policy_entropy: 54.93821334838867
      policy_loss: -1.346165657043457
      var_gnorm: 39.856048583984375
      vf_explained_var: 5.960464477539063e-08
      vf_loss: 0.013581468723714352
    num_steps_sampled: 1065000
    num_steps_trained: 1065000
    wait_time_ms: 100.272
  iterations_since_restore: 213
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 830
  policy_reward_mean: {}
  time_since_restore: 2636.489691734314
  time_this_iter_s: 12.297532081604004
  time_total_s: 2636.489691734314
  timestamp: 1593812440
  timesteps_since_restore: 1065000
  timesteps_this_iter: 5000
  timesteps_total: 1065000
  training_iteration: 213
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 13.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=830], 2636 s, 213 iter, 1065000 ts, 480 rew

agent-1: 84.0
agent-2: 76.0
agent-3: 74.0
agent-4: 98.0
agent-5: 93.0
Sum Reward: 425.0
Avg Reward: 85.0
Min Reward: 74.0
Gini Coefficient 0.0611764705882353
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_17-40-57
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 820.0
  episode_reward_mean: 479.97
  episode_reward_min: 280.0
  episodes_this_iter: 1
  episodes_total: 213
  experiment_id: f3470259fa9143609a5dd5049ba7f979
  hostname: gpu020
  info:
    apply_time_ms: 3.986
    dispatch_time_ms: 17.351
    learner:
      cur_lr: 0.001289071049541235
      grad_gnorm: 40.0
      policy_entropy: 31.657894134521484
      policy_loss: 10.324991226196289
      var_gnorm: 39.927364349365234
      vf_explained_var: 0.5994444489479065
      vf_loss: 39.409366607666016
    num_steps_sampled: 1070000
    num_steps_trained: 1070000
    wait_time_ms: 659.999
  iterations_since_restore: 214
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 830
  policy_reward_mean: {}
  time_since_restore: 2653.2793350219727
  time_this_iter_s: 16.78964328765869
  time_total_s: 2653.2793350219727
  timestamp: 1593812457
  timesteps_since_restore: 1070000
  timesteps_this_iter: 5000
  timesteps_total: 1070000
  training_iteration: 214
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 6.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=830], 2653 s, 214 iter, 1070000 ts, 480 rew

agent-1: 119.0
agent-2: 101.0
agent-3: 94.0
agent-4: 110.0
agent-5: 100.0
Sum Reward: 524.0
Avg Reward: 104.8
Min Reward: 94.0
Gini Coefficient 0.04580152671755725
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_17-41-09
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 820.0
  episode_reward_mean: 480.57
  episode_reward_min: 280.0
  episodes_this_iter: 1
  episodes_total: 214
  experiment_id: f3470259fa9143609a5dd5049ba7f979
  hostname: gpu020
  info:
    apply_time_ms: 3.529
    dispatch_time_ms: 7.839
    learner:
      cur_lr: 0.0012887379853054881
      grad_gnorm: 40.000003814697266
      policy_entropy: 14.234527587890625
      policy_loss: 34.51588821411133
      var_gnorm: 39.97069549560547
      vf_explained_var: 0.2026258111000061
      vf_loss: 106.92375183105469
    num_steps_sampled: 1075000
    num_steps_trained: 1075000
    wait_time_ms: 98.751
  iterations_since_restore: 215
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 830
  policy_reward_mean: {}
  time_since_restore: 2664.7942316532135
  time_this_iter_s: 11.514896631240845
  time_total_s: 2664.7942316532135
  timestamp: 1593812469
  timesteps_since_restore: 1075000
  timesteps_this_iter: 5000
  timesteps_total: 1075000
  training_iteration: 215
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 8.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=830], 2664 s, 215 iter, 1075000 ts, 481 rew

agent-1: 100.0
agent-2: 99.0
agent-3: 106.0
agent-4: 96.0
agent-5: 103.0
Sum Reward: 504.0
Avg Reward: 100.8
Min Reward: 96.0
Gini Coefficient 0.01904761904761905
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_17-41-20
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 820.0
  episode_reward_mean: 480.42
  episode_reward_min: 280.0
  episodes_this_iter: 1
  episodes_total: 215
  experiment_id: f3470259fa9143609a5dd5049ba7f979
  hostname: gpu020
  info:
    apply_time_ms: 3.274
    dispatch_time_ms: 9.665
    learner:
      cur_lr: 0.001288405037485063
      grad_gnorm: 33.66800308227539
      policy_entropy: 32.59619903564453
      policy_loss: -4.4574666023254395
      var_gnorm: 40.096805572509766
      vf_explained_var: 0.917914628982544
      vf_loss: 2.5708181858062744
    num_steps_sampled: 1080000
    num_steps_trained: 1080000
    wait_time_ms: 110.501
  iterations_since_restore: 216
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 830
  policy_reward_mean: {}
  time_since_restore: 2676.496739387512
  time_this_iter_s: 11.702507734298706
  time_total_s: 2676.496739387512
  timestamp: 1593812480
  timesteps_since_restore: 1080000
  timesteps_this_iter: 5000
  timesteps_total: 1080000
  training_iteration: 216
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 13.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=830], 2676 s, 216 iter, 1080000 ts, 480 rew

agent-1: 74.0
agent-2: 64.0
agent-3: 76.0
agent-4: 71.0
agent-5: 72.0
Sum Reward: 357.0
Avg Reward: 71.4
Min Reward: 64.0
Gini Coefficient 0.030252100840336135
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_17-41-33
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 820.0
  episode_reward_mean: 477.89
  episode_reward_min: 280.0
  episodes_this_iter: 1
  episodes_total: 216
  experiment_id: f3470259fa9143609a5dd5049ba7f979
  hostname: gpu020
  info:
    apply_time_ms: 2.761
    dispatch_time_ms: 11.229
    learner:
      cur_lr: 0.0012880719732493162
      grad_gnorm: 1.9450916051864624
      policy_entropy: 41.299259185791016
      policy_loss: -0.4153262674808502
      var_gnorm: 40.09071731567383
      vf_explained_var: 0.9959390759468079
      vf_loss: 0.01401736680418253
    num_steps_sampled: 1085000
    num_steps_trained: 1085000
    wait_time_ms: 95.736
  iterations_since_restore: 217
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 830
  policy_reward_mean: {}
  time_since_restore: 2688.895548582077
  time_this_iter_s: 12.39880919456482
  time_total_s: 2688.895548582077
  timestamp: 1593812493
  timesteps_since_restore: 1085000
  timesteps_this_iter: 5000
  timesteps_total: 1085000
  training_iteration: 217
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 13.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=830], 2688 s, 217 iter, 1085000 ts, 478 rew

agent-1: 88.0
agent-2: 78.0
agent-3: 70.0
agent-4: 97.0
agent-5: 61.0
Sum Reward: 394.0
Avg Reward: 78.8
Min Reward: 61.0
Gini Coefficient 0.09137055837563451
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_17-41-44
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 820.0
  episode_reward_mean: 478.42
  episode_reward_min: 280.0
  episodes_this_iter: 1
  episodes_total: 217
  experiment_id: f3470259fa9143609a5dd5049ba7f979
  hostname: gpu020
  info:
    apply_time_ms: 2.826
    dispatch_time_ms: 9.867
    learner:
      cur_lr: 0.0012877390254288912
      grad_gnorm: 40.00001525878906
      policy_entropy: 26.708003997802734
      policy_loss: 4.039694309234619
      var_gnorm: 40.10301208496094
      vf_explained_var: 0.8145666718482971
      vf_loss: 8.921156883239746
    num_steps_sampled: 1090000
    num_steps_trained: 1090000
    wait_time_ms: 109.962
  iterations_since_restore: 218
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 830
  policy_reward_mean: {}
  time_since_restore: 2700.242200613022
  time_this_iter_s: 11.346652030944824
  time_total_s: 2700.242200613022
  timestamp: 1593812504
  timesteps_since_restore: 1090000
  timesteps_this_iter: 5000
  timesteps_total: 1090000
  training_iteration: 218
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 13.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=830], 2700 s, 218 iter, 1090000 ts, 478 rew

agent-1: 69.0
agent-2: 99.0
agent-3: 64.0
agent-4: 74.0
agent-5: 68.0
Sum Reward: 374.0
Avg Reward: 74.8
Min Reward: 64.0
Gini Coefficient 0.08128342245989305
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_17-41-56
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 820.0
  episode_reward_mean: 477.21
  episode_reward_min: 280.0
  episodes_this_iter: 1
  episodes_total: 218
  experiment_id: f3470259fa9143609a5dd5049ba7f979
  hostname: gpu020
  info:
    apply_time_ms: 3.007
    dispatch_time_ms: 6.95
    learner:
      cur_lr: 0.0012874059611931443
      grad_gnorm: 6.568334579467773
      policy_entropy: 36.65685272216797
      policy_loss: -1.0307718515396118
      var_gnorm: 40.12406921386719
      vf_explained_var: 0.9444114565849304
      vf_loss: 0.27045801281929016
    num_steps_sampled: 1095000
    num_steps_trained: 1095000
    wait_time_ms: 96.852
  iterations_since_restore: 219
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 830
  policy_reward_mean: {}
  time_since_restore: 2712.5154087543488
  time_this_iter_s: 12.273208141326904
  time_total_s: 2712.5154087543488
  timestamp: 1593812516
  timesteps_since_restore: 1095000
  timesteps_this_iter: 5000
  timesteps_total: 1095000
  training_iteration: 219
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 13.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=830], 2712 s, 219 iter, 1095000 ts, 477 rew

agent-1: 59.0
agent-2: 67.0
agent-3: 90.0
agent-4: 60.0
agent-5: 66.0
Sum Reward: 342.0
Avg Reward: 68.4
Min Reward: 59.0
Gini Coefficient 0.08070175438596491
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_17-42-08
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 820.0
  episode_reward_mean: 474.12
  episode_reward_min: 280.0
  episodes_this_iter: 1
  episodes_total: 219
  experiment_id: f3470259fa9143609a5dd5049ba7f979
  hostname: gpu020
  info:
    apply_time_ms: 4.322
    dispatch_time_ms: 9.095
    learner:
      cur_lr: 0.0012870730133727193
      grad_gnorm: 12.545296669006348
      policy_entropy: 38.077903747558594
      policy_loss: 0.20081329345703125
      var_gnorm: 40.184844970703125
      vf_explained_var: 0.902070164680481
      vf_loss: 2.19742488861084
    num_steps_sampled: 1100000
    num_steps_trained: 1100000
    wait_time_ms: 111.651
  iterations_since_restore: 220
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 830
  policy_reward_mean: {}
  time_since_restore: 2724.1299571990967
  time_this_iter_s: 11.614548444747925
  time_total_s: 2724.1299571990967
  timestamp: 1593812528
  timesteps_since_restore: 1100000
  timesteps_this_iter: 5000
  timesteps_total: 1100000
  training_iteration: 220
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 13.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=830], 2724 s, 220 iter, 1100000 ts, 474 rew

agent-1: 63.0
agent-2: 55.0
agent-3: 86.0
agent-4: 77.0
agent-5: 78.0
Sum Reward: 359.0
Avg Reward: 71.8
Min Reward: 55.0
Gini Coefficient 0.08579387186629527
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_17-42-48
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 820.0
  episode_reward_mean: 472.4
  episode_reward_min: 280.0
  episodes_this_iter: 1
  episodes_total: 220
  experiment_id: f3470259fa9143609a5dd5049ba7f979
  hostname: gpu020
  info:
    apply_time_ms: 4.581
    dispatch_time_ms: 2767.309
    learner:
      cur_lr: 0.0012867399491369724
      grad_gnorm: 20.71472930908203
      policy_entropy: 36.174537658691406
      policy_loss: 0.17295271158218384
      var_gnorm: 40.20915985107422
      vf_explained_var: 1.8477439880371094e-06
      vf_loss: 0.4250204563140869
    num_steps_sampled: 1105000
    num_steps_trained: 1105000
    wait_time_ms: 68.912
  iterations_since_restore: 221
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 830
  policy_reward_mean: {}
  time_since_restore: 2763.6305747032166
  time_this_iter_s: 39.50061750411987
  time_total_s: 2763.6305747032166
  timestamp: 1593812568
  timesteps_since_restore: 1105000
  timesteps_this_iter: 5000
  timesteps_total: 1105000
  training_iteration: 221
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 13.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=830], 2763 s, 221 iter, 1105000 ts, 472 rew

agent-1: 60.0
agent-2: 80.0
agent-3: 70.0
agent-4: 80.0
agent-5: 68.0
Sum Reward: 358.0
Avg Reward: 71.6
Min Reward: 60.0
Gini Coefficient 0.05810055865921788
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_17-43-04
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 820.0
  episode_reward_mean: 471.1
  episode_reward_min: 280.0
  episodes_this_iter: 1
  episodes_total: 221
  experiment_id: f3470259fa9143609a5dd5049ba7f979
  hostname: gpu020
  info:
    apply_time_ms: 2.9
    dispatch_time_ms: 296.427
    learner:
      cur_lr: 0.0012864070013165474
      grad_gnorm: 39.99999237060547
      policy_entropy: 27.924440383911133
      policy_loss: 0.8555275797843933
      var_gnorm: 40.31774139404297
      vf_explained_var: 0.7809911370277405
      vf_loss: 7.980429172515869
    num_steps_sampled: 1110000
    num_steps_trained: 1110000
    wait_time_ms: 75.773
  iterations_since_restore: 222
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 830
  policy_reward_mean: {}
  time_since_restore: 2780.00315117836
  time_this_iter_s: 16.372576475143433
  time_total_s: 2780.00315117836
  timestamp: 1593812584
  timesteps_since_restore: 1110000
  timesteps_this_iter: 5000
  timesteps_total: 1110000
  training_iteration: 222
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 13.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=830], 2780 s, 222 iter, 1110000 ts, 471 rew

agent-1: 94.0
agent-2: 75.0
agent-3: 89.0
agent-4: 79.0
agent-5: 88.0
Sum Reward: 425.0
Avg Reward: 85.0
Min Reward: 75.0
Gini Coefficient 0.0451764705882353
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_17-43-33
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 820.0
  episode_reward_mean: 470.21
  episode_reward_min: 280.0
  episodes_this_iter: 1
  episodes_total: 222
  experiment_id: f3470259fa9143609a5dd5049ba7f979
  hostname: gpu020
  info:
    apply_time_ms: 2.351
    dispatch_time_ms: 171.502
    learner:
      cur_lr: 0.0012860740534961224
      grad_gnorm: 6.36696720123291
      policy_entropy: 36.56806564331055
      policy_loss: -2.0260701179504395
      var_gnorm: 40.35391616821289
      vf_explained_var: 1.1920928955078125e-07
      vf_loss: 0.05432366579771042
    num_steps_sampled: 1115000
    num_steps_trained: 1115000
    wait_time_ms: 303.543
  iterations_since_restore: 223
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 830
  policy_reward_mean: {}
  time_since_restore: 2809.0864057540894
  time_this_iter_s: 29.08325457572937
  time_total_s: 2809.0864057540894
  timestamp: 1593812613
  timesteps_since_restore: 1115000
  timesteps_this_iter: 5000
  timesteps_total: 1115000
  training_iteration: 223
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 13.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=830], 2809 s, 223 iter, 1115000 ts, 470 rew

agent-1: 69.0
agent-2: 52.0
agent-3: 95.0
agent-4: 80.0
agent-5: 62.0
Sum Reward: 358.0
Avg Reward: 71.6
Min Reward: 52.0
Gini Coefficient 0.11620111731843576
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_17-43-49
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 820.0
  episode_reward_mean: 470.09
  episode_reward_min: 280.0
  episodes_this_iter: 1
  episodes_total: 223
  experiment_id: f3470259fa9143609a5dd5049ba7f979
  hostname: gpu020
  info:
    apply_time_ms: 2.886
    dispatch_time_ms: 24.574
    learner:
      cur_lr: 0.0012857409892603755
      grad_gnorm: 40.00000762939453
      policy_entropy: 16.351633071899414
      policy_loss: 21.10898208618164
      var_gnorm: 40.4437370300293
      vf_explained_var: 0.9063674211502075
      vf_loss: 137.38278198242188
    num_steps_sampled: 1120000
    num_steps_trained: 1120000
    wait_time_ms: 103.609
  iterations_since_restore: 224
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 830
  policy_reward_mean: {}
  time_since_restore: 2824.426697731018
  time_this_iter_s: 15.340291976928711
  time_total_s: 2824.426697731018
  timestamp: 1593812629
  timesteps_since_restore: 1120000
  timesteps_this_iter: 5000
  timesteps_total: 1120000
  training_iteration: 224
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 13.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=830], 2824 s, 224 iter, 1120000 ts, 470 rew

agent-1: 133.0
agent-2: 143.0
agent-3: 113.0
agent-4: 114.0
agent-5: 59.0
Sum Reward: 562.0
Avg Reward: 112.4
Min Reward: 59.0
Gini Coefficient 0.13380782918149467
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_17-44-04
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 820.0
  episode_reward_mean: 470.45
  episode_reward_min: 280.0
  episodes_this_iter: 1
  episodes_total: 224
  experiment_id: f3470259fa9143609a5dd5049ba7f979
  hostname: gpu020
  info:
    apply_time_ms: 3.395
    dispatch_time_ms: 49.964
    learner:
      cur_lr: 0.0012854080414399505
      grad_gnorm: 19.682483673095703
      policy_entropy: 30.09809112548828
      policy_loss: -0.07268328964710236
      var_gnorm: 40.44308090209961
      vf_explained_var: 0.0
      vf_loss: 0.3846959173679352
    num_steps_sampled: 1125000
    num_steps_trained: 1125000
    wait_time_ms: 287.763
  iterations_since_restore: 225
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 830
  policy_reward_mean: {}
  time_since_restore: 2840.0156054496765
  time_this_iter_s: 15.588907718658447
  time_total_s: 2840.0156054496765
  timestamp: 1593812644
  timesteps_since_restore: 1125000
  timesteps_this_iter: 5000
  timesteps_total: 1125000
  training_iteration: 225
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 13.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=830], 2840 s, 225 iter, 1125000 ts, 470 rew

agent-1: 45.0
agent-2: 46.0
agent-3: 61.0
agent-4: 79.0
agent-5: 59.0
Sum Reward: 290.0
Avg Reward: 58.0
Min Reward: 45.0
Gini Coefficient 0.11448275862068966
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_17-44-15
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 820.0
  episode_reward_mean: 468.59
  episode_reward_min: 280.0
  episodes_this_iter: 1
  episodes_total: 225
  experiment_id: f3470259fa9143609a5dd5049ba7f979
  hostname: gpu020
  info:
    apply_time_ms: 2.631
    dispatch_time_ms: 17.1
    learner:
      cur_lr: 0.0012850749772042036
      grad_gnorm: 28.371307373046875
      policy_entropy: 24.413637161254883
      policy_loss: -1.5114978551864624
      var_gnorm: 40.47211837768555
      vf_explained_var: 0.9340745806694031
      vf_loss: 1.2960035800933838
    num_steps_sampled: 1130000
    num_steps_trained: 1130000
    wait_time_ms: 109.542
  iterations_since_restore: 226
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 830
  policy_reward_mean: {}
  time_since_restore: 2850.9262039661407
  time_this_iter_s: 10.910598516464233
  time_total_s: 2850.9262039661407
  timestamp: 1593812655
  timesteps_since_restore: 1130000
  timesteps_this_iter: 5000
  timesteps_total: 1130000
  training_iteration: 226
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 13.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=830], 2850 s, 226 iter, 1130000 ts, 469 rew

agent-1: 51.0
agent-2: 70.0
agent-3: 62.0
agent-4: 56.0
agent-5: 62.0
Sum Reward: 301.0
Avg Reward: 60.2
Min Reward: 51.0
Gini Coefficient 0.05847176079734219
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_17-44-27
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 820.0
  episode_reward_mean: 466.77
  episode_reward_min: 280.0
  episodes_this_iter: 1
  episodes_total: 226
  experiment_id: f3470259fa9143609a5dd5049ba7f979
  hostname: gpu020
  info:
    apply_time_ms: 2.635
    dispatch_time_ms: 13.693
    learner:
      cur_lr: 0.0012847420293837786
      grad_gnorm: 8.307299613952637
      policy_entropy: 20.828367233276367
      policy_loss: -0.3586953282356262
      var_gnorm: 40.53321075439453
      vf_explained_var: 0.9952749013900757
      vf_loss: 0.18935607373714447
    num_steps_sampled: 1135000
    num_steps_trained: 1135000
    wait_time_ms: 93.78
  iterations_since_restore: 227
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 830
  policy_reward_mean: {}
  time_since_restore: 2863.086409807205
  time_this_iter_s: 12.160205841064453
  time_total_s: 2863.086409807205
  timestamp: 1593812667
  timesteps_since_restore: 1135000
  timesteps_this_iter: 5000
  timesteps_total: 1135000
  training_iteration: 227
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 13.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=830], 2863 s, 227 iter, 1135000 ts, 467 rew

agent-1: 89.0
agent-2: 42.0
agent-3: 196.0
agent-4: 44.0
agent-5: 54.0
Sum Reward: 425.0
Avg Reward: 85.0
Min Reward: 42.0
Gini Coefficient 0.3322352941176471
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_17-44-40
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 718.0
  episode_reward_mean: 462.82
  episode_reward_min: 280.0
  episodes_this_iter: 1
  episodes_total: 227
  experiment_id: f3470259fa9143609a5dd5049ba7f979
  hostname: gpu020
  info:
    apply_time_ms: 4.529
    dispatch_time_ms: 13.801
    learner:
      cur_lr: 0.0012844089651480317
      grad_gnorm: 4.691643238067627
      policy_entropy: 5.7596845626831055
      policy_loss: -0.642490804195404
      var_gnorm: 40.61836242675781
      vf_explained_var: 0.499941885471344
      vf_loss: 2.2555439472198486
    num_steps_sampled: 1140000
    num_steps_trained: 1140000
    wait_time_ms: 108.853
  iterations_since_restore: 228
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 830
  policy_reward_mean: {}
  time_since_restore: 2875.932648420334
  time_this_iter_s: 12.846238613128662
  time_total_s: 2875.932648420334
  timestamp: 1593812680
  timesteps_since_restore: 1140000
  timesteps_this_iter: 5000
  timesteps_total: 1140000
  training_iteration: 228
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 13.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=830], 2875 s, 228 iter, 1140000 ts, 463 rew

agent-1: 102.0
agent-2: 93.0
agent-3: 92.0
agent-4: 74.0
agent-5: 83.0
Sum Reward: 444.0
Avg Reward: 88.8
Min Reward: 74.0
Gini Coefficient 0.05945945945945946
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_17-44-52
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 718.0
  episode_reward_mean: 462.45
  episode_reward_min: 280.0
  episodes_this_iter: 1
  episodes_total: 228
  experiment_id: f3470259fa9143609a5dd5049ba7f979
  hostname: gpu020
  info:
    apply_time_ms: 4.335
    dispatch_time_ms: 14.297
    learner:
      cur_lr: 0.0012840760173276067
      grad_gnorm: 2.011228561401367
      policy_entropy: 8.122879028320312
      policy_loss: 0.10255640745162964
      var_gnorm: 40.65193176269531
      vf_explained_var: 0.0
      vf_loss: 0.0049111624248325825
    num_steps_sampled: 1145000
    num_steps_trained: 1145000
    wait_time_ms: 87.367
  iterations_since_restore: 229
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 830
  policy_reward_mean: {}
  time_since_restore: 2887.9386179447174
  time_this_iter_s: 12.005969524383545
  time_total_s: 2887.9386179447174
  timestamp: 1593812692
  timesteps_since_restore: 1145000
  timesteps_this_iter: 5000
  timesteps_total: 1145000
  training_iteration: 229
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 13.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=830], 2887 s, 229 iter, 1145000 ts, 462 rew

agent-1: 68.0
agent-2: 73.0
agent-3: 74.0
agent-4: 86.0
agent-5: 84.0
Sum Reward: 385.0
Avg Reward: 77.0
Min Reward: 68.0
Gini Coefficient 0.04883116883116883
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_17-45-10
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 718.0
  episode_reward_mean: 461.68
  episode_reward_min: 280.0
  episodes_this_iter: 1
  episodes_total: 229
  experiment_id: f3470259fa9143609a5dd5049ba7f979
  hostname: gpu020
  info:
    apply_time_ms: 2.849
    dispatch_time_ms: 118.943
    learner:
      cur_lr: 0.0012837429530918598
      grad_gnorm: 39.999996185302734
      policy_entropy: 9.510740280151367
      policy_loss: 1.0157501697540283
      var_gnorm: 40.729496002197266
      vf_explained_var: 0.8863925337791443
      vf_loss: 4.635525226593018
    num_steps_sampled: 1150000
    num_steps_trained: 1150000
    wait_time_ms: 523.956
  iterations_since_restore: 230
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 830
  policy_reward_mean: {}
  time_since_restore: 2905.3268060684204
  time_this_iter_s: 17.388188123703003
  time_total_s: 2905.3268060684204
  timestamp: 1593812710
  timesteps_since_restore: 1150000
  timesteps_this_iter: 5000
  timesteps_total: 1150000
  training_iteration: 230
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 13.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=830], 2905 s, 230 iter, 1150000 ts, 462 rew

agent-1: 101.0
agent-2: 88.0
agent-3: 93.0
agent-4: 104.0
agent-5: 114.0
Sum Reward: 500.0
Avg Reward: 100.0
Min Reward: 88.0
Gini Coefficient 0.0504
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_17-45-21
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 718.0
  episode_reward_mean: 462.23
  episode_reward_min: 280.0
  episodes_this_iter: 1
  episodes_total: 230
  experiment_id: f3470259fa9143609a5dd5049ba7f979
  hostname: gpu020
  info:
    apply_time_ms: 2.794
    dispatch_time_ms: 11.31
    learner:
      cur_lr: 0.0012834100052714348
      grad_gnorm: 1.0733524560928345
      policy_entropy: 13.012581825256348
      policy_loss: -0.017188547179102898
      var_gnorm: 40.7542839050293
      vf_explained_var: 0.0
      vf_loss: 0.0013890888076275587
    num_steps_sampled: 1155000
    num_steps_trained: 1155000
    wait_time_ms: 106.514
  iterations_since_restore: 231
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 830
  policy_reward_mean: {}
  time_since_restore: 2916.4101462364197
  time_this_iter_s: 11.083340167999268
  time_total_s: 2916.4101462364197
  timestamp: 1593812721
  timesteps_since_restore: 1155000
  timesteps_this_iter: 5000
  timesteps_total: 1155000
  training_iteration: 231
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 13.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=830], 2916 s, 231 iter, 1155000 ts, 462 rew

agent-1: 72.0
agent-2: 61.0
agent-3: 70.0
agent-4: 49.0
agent-5: 49.0
Sum Reward: 301.0
Avg Reward: 60.2
Min Reward: 49.0
Gini Coefficient 0.08903654485049833
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_17-45-33
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 718.0
  episode_reward_mean: 460.31
  episode_reward_min: 280.0
  episodes_this_iter: 1
  episodes_total: 231
  experiment_id: f3470259fa9143609a5dd5049ba7f979
  hostname: gpu020
  info:
    apply_time_ms: 2.721
    dispatch_time_ms: 10.255
    learner:
      cur_lr: 0.0012830770574510098
      grad_gnorm: 2.1382429599761963
      policy_entropy: 18.162717819213867
      policy_loss: 0.14908158779144287
      var_gnorm: 40.8835563659668
      vf_explained_var: -5.245208740234375e-06
      vf_loss: 0.00557164940983057
    num_steps_sampled: 1160000
    num_steps_trained: 1160000
    wait_time_ms: 110.451
  iterations_since_restore: 232
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 830
  policy_reward_mean: {}
  time_since_restore: 2928.2854499816895
  time_this_iter_s: 11.875303745269775
  time_total_s: 2928.2854499816895
  timestamp: 1593812733
  timesteps_since_restore: 1160000
  timesteps_this_iter: 5000
  timesteps_total: 1160000
  training_iteration: 232
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 13.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=830], 2928 s, 232 iter, 1160000 ts, 460 rew

agent-1: 37.0
agent-2: 78.0
agent-3: 57.0
agent-4: 73.0
agent-5: 78.0
Sum Reward: 323.0
Avg Reward: 64.6
Min Reward: 37.0
Gini Coefficient 0.12755417956656348
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_17-45-45
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 718.0
  episode_reward_mean: 457.52
  episode_reward_min: 280.0
  episodes_this_iter: 1
  episodes_total: 232
  experiment_id: f3470259fa9143609a5dd5049ba7f979
  hostname: gpu020
  info:
    apply_time_ms: 2.646
    dispatch_time_ms: 6.185
    learner:
      cur_lr: 0.0012827439932152629
      grad_gnorm: 0.469004362821579
      policy_entropy: 30.766674041748047
      policy_loss: -0.08456278592348099
      var_gnorm: 40.978538513183594
      vf_explained_var: 0.0
      vf_loss: 0.00024247767578344792
    num_steps_sampled: 1165000
    num_steps_trained: 1165000
    wait_time_ms: 114.009
  iterations_since_restore: 233
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 830
  policy_reward_mean: {}
  time_since_restore: 2941.094348192215
  time_this_iter_s: 12.808898210525513
  time_total_s: 2941.094348192215
  timestamp: 1593812745
  timesteps_since_restore: 1165000
  timesteps_this_iter: 5000
  timesteps_total: 1165000
  training_iteration: 233
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 13.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=830], 2941 s, 233 iter, 1165000 ts, 458 rew

agent-1: 74.0
agent-2: 85.0
agent-3: 57.0
agent-4: 63.0
agent-5: 63.0
Sum Reward: 342.0
Avg Reward: 68.4
Min Reward: 57.0
Gini Coefficient 0.0783625730994152
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_17-45-57
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 718.0
  episode_reward_mean: 457.95
  episode_reward_min: 280.0
  episodes_this_iter: 1
  episodes_total: 233
  experiment_id: f3470259fa9143609a5dd5049ba7f979
  hostname: gpu020
  info:
    apply_time_ms: 2.764
    dispatch_time_ms: 17.16
    learner:
      cur_lr: 0.0012824110453948379
      grad_gnorm: 40.0
      policy_entropy: 11.05827808380127
      policy_loss: 1.7927570343017578
      var_gnorm: 40.97373962402344
      vf_explained_var: 0.9785951972007751
      vf_loss: 15.591744422912598
    num_steps_sampled: 1170000
    num_steps_trained: 1170000
    wait_time_ms: 104.632
  iterations_since_restore: 234
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 830
  policy_reward_mean: {}
  time_since_restore: 2952.6670429706573
  time_this_iter_s: 11.572694778442383
  time_total_s: 2952.6670429706573
  timestamp: 1593812757
  timesteps_since_restore: 1170000
  timesteps_this_iter: 5000
  timesteps_total: 1170000
  training_iteration: 234
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 13.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=830], 2952 s, 234 iter, 1170000 ts, 458 rew

agent-1: 92.0
agent-2: 136.0
agent-3: 88.0
agent-4: 75.0
agent-5: 68.0
Sum Reward: 459.0
Avg Reward: 91.8
Min Reward: 68.0
Gini Coefficient 0.13333333333333333
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_17-46-10
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 718.0
  episode_reward_mean: 458.72
  episode_reward_min: 280.0
  episodes_this_iter: 1
  episodes_total: 234
  experiment_id: f3470259fa9143609a5dd5049ba7f979
  hostname: gpu020
  info:
    apply_time_ms: 2.69
    dispatch_time_ms: 73.732
    learner:
      cur_lr: 0.001282077981159091
      grad_gnorm: 40.0
      policy_entropy: 6.283751964569092
      policy_loss: 6.23422384262085
      var_gnorm: 41.050167083740234
      vf_explained_var: 0.9513213634490967
      vf_loss: 56.13128662109375
    num_steps_sampled: 1175000
    num_steps_trained: 1175000
    wait_time_ms: 120.001
  iterations_since_restore: 235
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 830
  policy_reward_mean: {}
  time_since_restore: 2965.941827058792
  time_this_iter_s: 13.274784088134766
  time_total_s: 2965.941827058792
  timestamp: 1593812770
  timesteps_since_restore: 1175000
  timesteps_this_iter: 5000
  timesteps_total: 1175000
  training_iteration: 235
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 13.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=830], 2965 s, 235 iter, 1175000 ts, 459 rew

agent-1: 52.0
agent-2: 78.0
agent-3: 91.0
agent-4: 65.0
agent-5: 74.0
Sum Reward: 360.0
Avg Reward: 72.0
Min Reward: 52.0
Gini Coefficient 0.10111111111111111
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_17-46-23
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 718.0
  episode_reward_mean: 457.67
  episode_reward_min: 280.0
  episodes_this_iter: 1
  episodes_total: 235
  experiment_id: f3470259fa9143609a5dd5049ba7f979
  hostname: gpu020
  info:
    apply_time_ms: 3.716
    dispatch_time_ms: 19.67
    learner:
      cur_lr: 0.001281745033338666
      grad_gnorm: 39.9999885559082
      policy_entropy: 9.034263610839844
      policy_loss: 2.8054096698760986
      var_gnorm: 41.12800598144531
      vf_explained_var: 0.8787471652030945
      vf_loss: 59.609779357910156
    num_steps_sampled: 1180000
    num_steps_trained: 1180000
    wait_time_ms: 99.553
  iterations_since_restore: 236
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 830
  policy_reward_mean: {}
  time_since_restore: 2978.483129501343
  time_this_iter_s: 12.54130244255066
  time_total_s: 2978.483129501343
  timestamp: 1593812783
  timesteps_since_restore: 1180000
  timesteps_this_iter: 5000
  timesteps_total: 1180000
  training_iteration: 236
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 13.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=830], 2978 s, 236 iter, 1180000 ts, 458 rew

agent-1: 77.0
agent-2: 76.0
agent-3: 75.0
agent-4: 71.0
agent-5: 82.0
Sum Reward: 381.0
Avg Reward: 76.2
Min Reward: 71.0
Gini Coefficient 0.025196850393700787
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_17-46-35
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 718.0
  episode_reward_mean: 456.62
  episode_reward_min: 280.0
  episodes_this_iter: 1
  episodes_total: 236
  experiment_id: f3470259fa9143609a5dd5049ba7f979
  hostname: gpu020
  info:
    apply_time_ms: 2.68
    dispatch_time_ms: 11.181
    learner:
      cur_lr: 0.001281411969102919
      grad_gnorm: 39.99999237060547
      policy_entropy: 12.50664234161377
      policy_loss: 6.7639641761779785
      var_gnorm: 41.189453125
      vf_explained_var: -0.17861700057983398
      vf_loss: 39.628997802734375
    num_steps_sampled: 1185000
    num_steps_trained: 1185000
    wait_time_ms: 95.42
  iterations_since_restore: 237
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 830
  policy_reward_mean: {}
  time_since_restore: 2990.3804199695587
  time_this_iter_s: 11.897290468215942
  time_total_s: 2990.3804199695587
  timestamp: 1593812795
  timesteps_since_restore: 1185000
  timesteps_this_iter: 5000
  timesteps_total: 1185000
  training_iteration: 237
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 13.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=830], 2990 s, 237 iter, 1185000 ts, 457 rew

agent-1: 133.0
agent-2: 78.0
agent-3: 73.0
agent-4: 76.0
agent-5: 90.0
Sum Reward: 450.0
Avg Reward: 90.0
Min Reward: 73.0
Gini Coefficient 0.11911111111111111
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_17-46-48
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 718.0
  episode_reward_mean: 457.15
  episode_reward_min: 280.0
  episodes_this_iter: 1
  episodes_total: 237
  experiment_id: f3470259fa9143609a5dd5049ba7f979
  hostname: gpu020
  info:
    apply_time_ms: 4.05
    dispatch_time_ms: 93.569
    learner:
      cur_lr: 0.001281079021282494
      grad_gnorm: 40.0
      policy_entropy: 8.243414878845215
      policy_loss: -17.38322639465332
      var_gnorm: 41.140098571777344
      vf_explained_var: 0.34321582317352295
      vf_loss: 77.03437805175781
    num_steps_sampled: 1190000
    num_steps_trained: 1190000
    wait_time_ms: 78.728
  iterations_since_restore: 238
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 830
  policy_reward_mean: {}
  time_since_restore: 3003.7147748470306
  time_this_iter_s: 13.334354877471924
  time_total_s: 3003.7147748470306
  timestamp: 1593812808
  timesteps_since_restore: 1190000
  timesteps_this_iter: 5000
  timesteps_total: 1190000
  training_iteration: 238
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 13.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=830], 3003 s, 238 iter, 1190000 ts, 457 rew

agent-1: 109.0
agent-2: 87.0
agent-3: 105.0
agent-4: 101.0
agent-5: 115.0
Sum Reward: 517.0
Avg Reward: 103.4
Min Reward: 87.0
Gini Coefficient 0.04951644100580271
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_17-46-59
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 718.0
  episode_reward_mean: 456.13
  episode_reward_min: 280.0
  episodes_this_iter: 1
  episodes_total: 238
  experiment_id: f3470259fa9143609a5dd5049ba7f979
  hostname: gpu020
  info:
    apply_time_ms: 2.569
    dispatch_time_ms: 8.802
    learner:
      cur_lr: 0.0012807459570467472
      grad_gnorm: 11.79427719116211
      policy_entropy: 17.0689754486084
      policy_loss: -2.00270938873291
      var_gnorm: 41.18724822998047
      vf_explained_var: 0.0
      vf_loss: 0.16629040241241455
    num_steps_sampled: 1195000
    num_steps_trained: 1195000
    wait_time_ms: 90.831
  iterations_since_restore: 239
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 830
  policy_reward_mean: {}
  time_since_restore: 3014.8978979587555
  time_this_iter_s: 11.183123111724854
  time_total_s: 3014.8978979587555
  timestamp: 1593812819
  timesteps_since_restore: 1195000
  timesteps_this_iter: 5000
  timesteps_total: 1195000
  training_iteration: 239
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 13.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=830], 3014 s, 239 iter, 1195000 ts, 456 rew

agent-1: 115.0
agent-2: 116.0
agent-3: 112.0
agent-4: 83.0
agent-5: 137.0
Sum Reward: 563.0
Avg Reward: 112.6
Min Reward: 83.0
Gini Coefficient 0.07957371225577264
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_17-47-11
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 718.0
  episode_reward_mean: 456.24
  episode_reward_min: 280.0
  episodes_this_iter: 1
  episodes_total: 239
  experiment_id: f3470259fa9143609a5dd5049ba7f979
  hostname: gpu020
  info:
    apply_time_ms: 2.912
    dispatch_time_ms: 14.806
    learner:
      cur_lr: 0.0012804130092263222
      grad_gnorm: 40.0000114440918
      policy_entropy: 17.587549209594727
      policy_loss: -5.947607040405273
      var_gnorm: 41.203819274902344
      vf_explained_var: 0.27017658948898315
      vf_loss: 91.42851257324219
    num_steps_sampled: 1200000
    num_steps_trained: 1200000
    wait_time_ms: 103.569
  iterations_since_restore: 240
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 830
  policy_reward_mean: {}
  time_since_restore: 3026.26997923851
  time_this_iter_s: 11.372081279754639
  time_total_s: 3026.26997923851
  timestamp: 1593812831
  timesteps_since_restore: 1200000
  timesteps_this_iter: 5000
  timesteps_total: 1200000
  training_iteration: 240
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 13.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=830], 3026 s, 240 iter, 1200000 ts, 456 rew

agent-1: 120.0
agent-2: 101.0
agent-3: 117.0
agent-4: 78.0
agent-5: 108.0
Sum Reward: 524.0
Avg Reward: 104.8
Min Reward: 78.0
Gini Coefficient 0.07633587786259542
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_17-47-23
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 718.0
  episode_reward_mean: 457.66
  episode_reward_min: 280.0
  episodes_this_iter: 1
  episodes_total: 240
  experiment_id: f3470259fa9143609a5dd5049ba7f979
  hostname: gpu020
  info:
    apply_time_ms: 2.472
    dispatch_time_ms: 6.532
    learner:
      cur_lr: 0.0012800799449905753
      grad_gnorm: 27.429838180541992
      policy_entropy: 12.562533378601074
      policy_loss: -1.7088834047317505
      var_gnorm: 41.289337158203125
      vf_explained_var: 0.9937647581100464
      vf_loss: 6.901246547698975
    num_steps_sampled: 1205000
    num_steps_trained: 1205000
    wait_time_ms: 100.143
  iterations_since_restore: 241
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 830
  policy_reward_mean: {}
  time_since_restore: 3038.538204431534
  time_this_iter_s: 12.268225193023682
  time_total_s: 3038.538204431534
  timestamp: 1593812843
  timesteps_since_restore: 1205000
  timesteps_this_iter: 5000
  timesteps_total: 1205000
  training_iteration: 241
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 13.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=830], 3038 s, 241 iter, 1205000 ts, 458 rew

agent-1: 137.0
agent-2: 137.0
agent-3: 103.0
agent-4: 114.0
agent-5: 176.0
Sum Reward: 667.0
Avg Reward: 133.4
Min Reward: 103.0
Gini Coefficient 0.10134932533733133
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_17-47-34
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 718.0
  episode_reward_mean: 459.64
  episode_reward_min: 280.0
  episodes_this_iter: 1
  episodes_total: 241
  experiment_id: f3470259fa9143609a5dd5049ba7f979
  hostname: gpu020
  info:
    apply_time_ms: 2.708
    dispatch_time_ms: 11.586
    learner:
      cur_lr: 0.0012797469971701503
      grad_gnorm: 40.0
      policy_entropy: 16.149398803710938
      policy_loss: -0.28280144929885864
      var_gnorm: 41.38650894165039
      vf_explained_var: 0.9846085906028748
      vf_loss: 19.93311309814453
    num_steps_sampled: 1210000
    num_steps_trained: 1210000
    wait_time_ms: 106.93
  iterations_since_restore: 242
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 830
  policy_reward_mean: {}
  time_since_restore: 3049.78800368309
  time_this_iter_s: 11.249799251556396
  time_total_s: 3049.78800368309
  timestamp: 1593812854
  timesteps_since_restore: 1210000
  timesteps_this_iter: 5000
  timesteps_total: 1210000
  training_iteration: 242
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 13.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=830], 3049 s, 242 iter, 1210000 ts, 460 rew

agent-1: 124.0
agent-2: 155.0
agent-3: 110.0
agent-4: 113.0
agent-5: 79.0
Sum Reward: 581.0
Avg Reward: 116.2
Min Reward: 79.0
Gini Coefficient 0.11428571428571428
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_17-47-46
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 718.0
  episode_reward_mean: 460.91
  episode_reward_min: 280.0
  episodes_this_iter: 1
  episodes_total: 242
  experiment_id: f3470259fa9143609a5dd5049ba7f979
  hostname: gpu020
  info:
    apply_time_ms: 3.923
    dispatch_time_ms: 9.401
    learner:
      cur_lr: 0.0012794140493497252
      grad_gnorm: 27.53572654724121
      policy_entropy: 11.95541763305664
      policy_loss: 4.831410884857178
      var_gnorm: 41.5035400390625
      vf_explained_var: 0.2672310471534729
      vf_loss: 10.39118766784668
    num_steps_sampled: 1215000
    num_steps_trained: 1215000
    wait_time_ms: 107.118
  iterations_since_restore: 243
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 830
  policy_reward_mean: {}
  time_since_restore: 3061.597463607788
  time_this_iter_s: 11.809459924697876
  time_total_s: 3061.597463607788
  timestamp: 1593812866
  timesteps_since_restore: 1215000
  timesteps_this_iter: 5000
  timesteps_total: 1215000
  training_iteration: 243
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 13.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=830], 3061 s, 243 iter, 1215000 ts, 461 rew

agent-1: 111.0
agent-2: 135.0
agent-3: 128.0
agent-4: 129.0
agent-5: 131.0
Sum Reward: 634.0
Avg Reward: 126.8
Min Reward: 111.0
Gini Coefficient 0.032176656151419555
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_17-47-59
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 718.0
  episode_reward_mean: 463.13
  episode_reward_min: 280.0
  episodes_this_iter: 1
  episodes_total: 243
  experiment_id: f3470259fa9143609a5dd5049ba7f979
  hostname: gpu020
  info:
    apply_time_ms: 2.741
    dispatch_time_ms: 11.896
    learner:
      cur_lr: 0.0012790809851139784
      grad_gnorm: 39.99999237060547
      policy_entropy: 8.19890022277832
      policy_loss: 13.550024032592773
      var_gnorm: 41.653602600097656
      vf_explained_var: 0.8471107482910156
      vf_loss: 75.64896392822266
    num_steps_sampled: 1220000
    num_steps_trained: 1220000
    wait_time_ms: 98.063
  iterations_since_restore: 244
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 830
  policy_reward_mean: {}
  time_since_restore: 3074.4384546279907
  time_this_iter_s: 12.840991020202637
  time_total_s: 3074.4384546279907
  timestamp: 1593812879
  timesteps_since_restore: 1220000
  timesteps_this_iter: 5000
  timesteps_total: 1220000
  training_iteration: 244
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 13.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=830], 3074 s, 244 iter, 1220000 ts, 463 rew

agent-1: 60.0
agent-2: 113.0
agent-3: 97.0
agent-4: 73.0
agent-5: 61.0
Sum Reward: 404.0
Avg Reward: 80.8
Min Reward: 60.0
Gini Coefficient 0.1405940594059406
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_17-48-41
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 718.0
  episode_reward_mean: 462.73
  episode_reward_min: 280.0
  episodes_this_iter: 1
  episodes_total: 244
  experiment_id: f3470259fa9143609a5dd5049ba7f979
  hostname: gpu020
  info:
    apply_time_ms: 2.659
    dispatch_time_ms: 29.883
    learner:
      cur_lr: 0.0012787480372935534
      grad_gnorm: 40.0
      policy_entropy: 17.23662757873535
      policy_loss: -6.222145080566406
      var_gnorm: 41.68706512451172
      vf_explained_var: 0.5830808281898499
      vf_loss: 70.9417953491211
    num_steps_sampled: 1225000
    num_steps_trained: 1225000
    wait_time_ms: 83.025
  iterations_since_restore: 245
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 830
  policy_reward_mean: {}
  time_since_restore: 3116.2858493328094
  time_this_iter_s: 41.847394704818726
  time_total_s: 3116.2858493328094
  timestamp: 1593812921
  timesteps_since_restore: 1225000
  timesteps_this_iter: 5000
  timesteps_total: 1225000
  training_iteration: 245
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 13.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=830], 3116 s, 245 iter, 1225000 ts, 463 rew

agent-1: 94.0
agent-2: 89.0
agent-3: 94.0
agent-4: 77.0
agent-5: 97.0
Sum Reward: 451.0
Avg Reward: 90.2
Min Reward: 77.0
Gini Coefficient 0.03991130820399113
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_17-48-57
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 718.0
  episode_reward_mean: 460.56
  episode_reward_min: 280.0
  episodes_this_iter: 1
  episodes_total: 245
  experiment_id: f3470259fa9143609a5dd5049ba7f979
  hostname: gpu020
  info:
    apply_time_ms: 4.038
    dispatch_time_ms: 167.403
    learner:
      cur_lr: 0.0012784149730578065
      grad_gnorm: 40.0
      policy_entropy: 32.35795593261719
      policy_loss: -17.649282455444336
      var_gnorm: 41.67890930175781
      vf_explained_var: 0.23416811227798462
      vf_loss: 40.22264862060547
    num_steps_sampled: 1230000
    num_steps_trained: 1230000
    wait_time_ms: 34.933
  iterations_since_restore: 246
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 830
  policy_reward_mean: {}
  time_since_restore: 3132.0109639167786
  time_this_iter_s: 15.725114583969116
  time_total_s: 3132.0109639167786
  timestamp: 1593812937
  timesteps_since_restore: 1230000
  timesteps_this_iter: 5000
  timesteps_total: 1230000
  training_iteration: 246
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 13.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=830], 3132 s, 246 iter, 1230000 ts, 461 rew

agent-1: 79.0
agent-2: 143.0
agent-3: 115.0
agent-4: 89.0
agent-5: 96.0
Sum Reward: 522.0
Avg Reward: 104.4
Min Reward: 79.0
Gini Coefficient 0.11800766283524904
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_17-49-18
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 718.0
  episode_reward_mean: 460.38
  episode_reward_min: 280.0
  episodes_this_iter: 1
  episodes_total: 246
  experiment_id: f3470259fa9143609a5dd5049ba7f979
  hostname: gpu020
  info:
    apply_time_ms: 3.361
    dispatch_time_ms: 41.757
    learner:
      cur_lr: 0.0012780820252373815
      grad_gnorm: 39.999996185302734
      policy_entropy: 25.99570083618164
      policy_loss: -1.6857295036315918
      var_gnorm: 41.73992156982422
      vf_explained_var: 0.2989081144332886
      vf_loss: 30.80819320678711
    num_steps_sampled: 1235000
    num_steps_trained: 1235000
    wait_time_ms: 69.906
  iterations_since_restore: 247
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 830
  policy_reward_mean: {}
  time_since_restore: 3152.7775213718414
  time_this_iter_s: 20.766557455062866
  time_total_s: 3152.7775213718414
  timestamp: 1593812958
  timesteps_since_restore: 1235000
  timesteps_this_iter: 5000
  timesteps_total: 1235000
  training_iteration: 247
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 13.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=830], 3152 s, 247 iter, 1235000 ts, 460 rew

agent-1: 141.0
agent-2: 102.0
agent-3: 148.0
agent-4: 141.0
agent-5: 129.0
Sum Reward: 661.0
Avg Reward: 132.2
Min Reward: 102.0
Gini Coefficient 0.06293494704992436
W0703 17:49:29.753713   825 node_manager.cc:250] Last heartbeat was sent 1132 ms ago 
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_17-49-39
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 718.0
  episode_reward_mean: 461.84
  episode_reward_min: 280.0
  episodes_this_iter: 1
  episodes_total: 247
  experiment_id: f3470259fa9143609a5dd5049ba7f979
  hostname: gpu020
  info:
    apply_time_ms: 2.688
    dispatch_time_ms: 22.723
    learner:
      cur_lr: 0.0012777489610016346
      grad_gnorm: 40.00000762939453
      policy_entropy: 22.84751319885254
      policy_loss: 4.4250946044921875
      var_gnorm: 41.72399139404297
      vf_explained_var: 0.8307685852050781
      vf_loss: 137.96530151367188
    num_steps_sampled: 1240000
    num_steps_trained: 1240000
    wait_time_ms: 65.158
  iterations_since_restore: 248
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 830
  policy_reward_mean: {}
  time_since_restore: 3174.2461512088776
  time_this_iter_s: 21.468629837036133
  time_total_s: 3174.2461512088776
  timestamp: 1593812979
  timesteps_since_restore: 1240000
  timesteps_this_iter: 5000
  timesteps_total: 1240000
  training_iteration: 248
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 13.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=830], 3174 s, 248 iter, 1240000 ts, 462 rew

agent-1: 115.0
agent-2: 95.0
agent-3: 122.0
agent-4: 88.0
agent-5: 88.0
Sum Reward: 508.0
Avg Reward: 101.6
Min Reward: 88.0
Gini Coefficient 0.07480314960629922
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_17-49-51
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 718.0
  episode_reward_mean: 463.04
  episode_reward_min: 280.0
  episodes_this_iter: 1
  episodes_total: 248
  experiment_id: f3470259fa9143609a5dd5049ba7f979
  hostname: gpu020
  info:
    apply_time_ms: 5.942
    dispatch_time_ms: 11.445
    learner:
      cur_lr: 0.0012774160131812096
      grad_gnorm: 40.0
      policy_entropy: 24.592321395874023
      policy_loss: -19.328115463256836
      var_gnorm: 41.82312774658203
      vf_explained_var: 0.29497718811035156
      vf_loss: 36.31452178955078
    num_steps_sampled: 1245000
    num_steps_trained: 1245000
    wait_time_ms: 101.372
  iterations_since_restore: 249
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 830
  policy_reward_mean: {}
  time_since_restore: 3186.2213051319122
  time_this_iter_s: 11.975153923034668
  time_total_s: 3186.2213051319122
  timestamp: 1593812991
  timesteps_since_restore: 1245000
  timesteps_this_iter: 5000
  timesteps_total: 1245000
  training_iteration: 249
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 13.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=830], 3186 s, 249 iter, 1245000 ts, 463 rew

agent-1: 102.0
agent-2: 68.0
agent-3: 86.0
agent-4: 91.0
agent-5: 101.0
Sum Reward: 448.0
Avg Reward: 89.6
Min Reward: 68.0
Gini Coefficient 0.07410714285714286
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_17-50-02
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 718.0
  episode_reward_mean: 463.69
  episode_reward_min: 280.0
  episodes_this_iter: 1
  episodes_total: 249
  experiment_id: f3470259fa9143609a5dd5049ba7f979
  hostname: gpu020
  info:
    apply_time_ms: 3.386
    dispatch_time_ms: 7.762
    learner:
      cur_lr: 0.0012770829489454627
      grad_gnorm: 40.0
      policy_entropy: 25.455463409423828
      policy_loss: 13.581645965576172
      var_gnorm: 41.82076644897461
      vf_explained_var: 0.9454154968261719
      vf_loss: 47.99049377441406
    num_steps_sampled: 1250000
    num_steps_trained: 1250000
    wait_time_ms: 107.59
  iterations_since_restore: 250
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 830
  policy_reward_mean: {}
  time_since_restore: 3197.5218091011047
  time_this_iter_s: 11.300503969192505
  time_total_s: 3197.5218091011047
  timestamp: 1593813002
  timesteps_since_restore: 1250000
  timesteps_this_iter: 5000
  timesteps_total: 1250000
  training_iteration: 250
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 13.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=830], 3197 s, 250 iter, 1250000 ts, 464 rew

agent-1: 125.0
agent-2: 105.0
agent-3: 93.0
agent-4: 125.0
agent-5: 121.0
Sum Reward: 569.0
Avg Reward: 113.8
Min Reward: 93.0
Gini Coefficient 0.05905096660808436
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_17-50-14
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 718.0
  episode_reward_mean: 464.81
  episode_reward_min: 280.0
  episodes_this_iter: 1
  episodes_total: 250
  experiment_id: f3470259fa9143609a5dd5049ba7f979
  hostname: gpu020
  info:
    apply_time_ms: 3.749
    dispatch_time_ms: 13.449
    learner:
      cur_lr: 0.0012767500011250377
      grad_gnorm: 40.0
      policy_entropy: 18.04963493347168
      policy_loss: 4.718904495239258
      var_gnorm: 41.92730712890625
      vf_explained_var: 0.8468301296234131
      vf_loss: 43.96628952026367
    num_steps_sampled: 1255000
    num_steps_trained: 1255000
    wait_time_ms: 102.035
  iterations_since_restore: 251
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 830
  policy_reward_mean: {}
  time_since_restore: 3209.1224868297577
  time_this_iter_s: 11.600677728652954
  time_total_s: 3209.1224868297577
  timestamp: 1593813014
  timesteps_since_restore: 1255000
  timesteps_this_iter: 5000
  timesteps_total: 1255000
  training_iteration: 251
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 13.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=830], 3209 s, 251 iter, 1255000 ts, 465 rew

agent-1: 134.0
agent-2: 108.0
agent-3: 95.0
agent-4: 106.0
agent-5: 91.0
Sum Reward: 534.0
Avg Reward: 106.8
Min Reward: 91.0
Gini Coefficient 0.07415730337078652
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_17-50-27
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 718.0
  episode_reward_mean: 464.67
  episode_reward_min: 280.0
  episodes_this_iter: 1
  episodes_total: 251
  experiment_id: f3470259fa9143609a5dd5049ba7f979
  hostname: gpu020
  info:
    apply_time_ms: 3.57
    dispatch_time_ms: 8.886
    learner:
      cur_lr: 0.0012764170533046126
      grad_gnorm: 40.0
      policy_entropy: 14.657588958740234
      policy_loss: -1.31742525100708
      var_gnorm: 41.972660064697266
      vf_explained_var: 0.32029497623443604
      vf_loss: 32.425418853759766
    num_steps_sampled: 1260000
    num_steps_trained: 1260000
    wait_time_ms: 112.022
  iterations_since_restore: 252
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 830
  policy_reward_mean: {}
  time_since_restore: 3221.9978008270264
  time_this_iter_s: 12.875313997268677
  time_total_s: 3221.9978008270264
  timestamp: 1593813027
  timesteps_since_restore: 1260000
  timesteps_this_iter: 5000
  timesteps_total: 1260000
  training_iteration: 252
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 13.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=830], 3221 s, 252 iter, 1260000 ts, 465 rew

agent-1: 48.0
agent-2: 64.0
agent-3: 53.0
agent-4: 61.0
agent-5: 84.0
Sum Reward: 310.0
Avg Reward: 62.0
Min Reward: 48.0
Gini Coefficient 0.10709677419354839
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_17-50-39
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 718.0
  episode_reward_mean: 464.32
  episode_reward_min: 280.0
  episodes_this_iter: 1
  episodes_total: 252
  experiment_id: f3470259fa9143609a5dd5049ba7f979
  hostname: gpu020
  info:
    apply_time_ms: 2.485
    dispatch_time_ms: 13.132
    learner:
      cur_lr: 0.0012760839890688658
      grad_gnorm: 15.462064743041992
      policy_entropy: 34.320369720458984
      policy_loss: -2.8441531658172607
      var_gnorm: 42.01110076904297
      vf_explained_var: 1.1920928955078125e-07
      vf_loss: 0.27122586965560913
    num_steps_sampled: 1265000
    num_steps_trained: 1265000
    wait_time_ms: 104.733
  iterations_since_restore: 253
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 830
  policy_reward_mean: {}
  time_since_restore: 3233.9610109329224
  time_this_iter_s: 11.963210105895996
  time_total_s: 3233.9610109329224
  timestamp: 1593813039
  timesteps_since_restore: 1265000
  timesteps_this_iter: 5000
  timesteps_total: 1265000
  training_iteration: 253
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 13.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=830], 3233 s, 253 iter, 1265000 ts, 464 rew

agent-1: 105.0
agent-2: 105.0
agent-3: 98.0
agent-4: 97.0
agent-5: 93.0
Sum Reward: 498.0
Avg Reward: 99.6
Min Reward: 93.0
Gini Coefficient 0.02570281124497992
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_17-50-53
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 718.0
  episode_reward_mean: 464.54
  episode_reward_min: 280.0
  episodes_this_iter: 1
  episodes_total: 253
  experiment_id: f3470259fa9143609a5dd5049ba7f979
  hostname: gpu020
  info:
    apply_time_ms: 2.675
    dispatch_time_ms: 30.201
    learner:
      cur_lr: 0.0012757510412484407
      grad_gnorm: 7.222907066345215
      policy_entropy: 47.34962463378906
      policy_loss: -0.1220066100358963
      var_gnorm: 42.08798599243164
      vf_explained_var: 0.9965279698371887
      vf_loss: 0.09125318378210068
    num_steps_sampled: 1270000
    num_steps_trained: 1270000
    wait_time_ms: 58.562
  iterations_since_restore: 254
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 830
  policy_reward_mean: {}
  time_since_restore: 3247.6252958774567
  time_this_iter_s: 13.664284944534302
  time_total_s: 3247.6252958774567
  timestamp: 1593813053
  timesteps_since_restore: 1270000
  timesteps_this_iter: 5000
  timesteps_total: 1270000
  training_iteration: 254
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 13.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=830], 3247 s, 254 iter, 1270000 ts, 465 rew

agent-1: 59.0
agent-2: 75.0
agent-3: 74.0
agent-4: 60.0
agent-5: 69.0
Sum Reward: 337.0
Avg Reward: 67.4
Min Reward: 59.0
Gini Coefficient 0.05459940652818991
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_17-51-04
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 718.0
  episode_reward_mean: 464.25
  episode_reward_min: 280.0
  episodes_this_iter: 1
  episodes_total: 254
  experiment_id: f3470259fa9143609a5dd5049ba7f979
  hostname: gpu020
  info:
    apply_time_ms: 3.331
    dispatch_time_ms: 8.785
    learner:
      cur_lr: 0.0012754179770126939
      grad_gnorm: 9.81619644165039
      policy_entropy: 42.62678909301758
      policy_loss: -2.3645741939544678
      var_gnorm: 42.192047119140625
      vf_explained_var: 0.9950758814811707
      vf_loss: 0.207014799118042
    num_steps_sampled: 1275000
    num_steps_trained: 1275000
    wait_time_ms: 105.859
  iterations_since_restore: 255
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 830
  policy_reward_mean: {}
  time_since_restore: 3258.9609179496765
  time_this_iter_s: 11.335622072219849
  time_total_s: 3258.9609179496765
  timestamp: 1593813064
  timesteps_since_restore: 1275000
  timesteps_this_iter: 5000
  timesteps_total: 1275000
  training_iteration: 255
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 13.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=830], 3258 s, 255 iter, 1275000 ts, 464 rew

agent-1: 85.0
agent-2: 75.0
agent-3: 107.0
agent-4: 80.0
agent-5: 89.0
Sum Reward: 436.0
Avg Reward: 87.2
Min Reward: 75.0
Gini Coefficient 0.06697247706422019
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_17-51-16
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 718.0
  episode_reward_mean: 463.58
  episode_reward_min: 280.0
  episodes_this_iter: 1
  episodes_total: 255
  experiment_id: f3470259fa9143609a5dd5049ba7f979
  hostname: gpu020
  info:
    apply_time_ms: 2.844
    dispatch_time_ms: 13.196
    learner:
      cur_lr: 0.0012750850291922688
      grad_gnorm: 40.0000114440918
      policy_entropy: 46.423404693603516
      policy_loss: 4.375608444213867
      var_gnorm: 42.2862663269043
      vf_explained_var: 0.8680490255355835
      vf_loss: 4.160400867462158
    num_steps_sampled: 1280000
    num_steps_trained: 1280000
    wait_time_ms: 106.735
  iterations_since_restore: 256
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 830
  policy_reward_mean: {}
  time_since_restore: 3270.7186245918274
  time_this_iter_s: 11.757706642150879
  time_total_s: 3270.7186245918274
  timestamp: 1593813076
  timesteps_since_restore: 1280000
  timesteps_this_iter: 5000
  timesteps_total: 1280000
  training_iteration: 256
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 13.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=830], 3270 s, 256 iter, 1280000 ts, 464 rew

agent-1: 79.0
agent-2: 86.0
agent-3: 118.0
agent-4: 66.0
agent-5: 65.0
Sum Reward: 414.0
Avg Reward: 82.8
Min Reward: 65.0
Gini Coefficient 0.12173913043478261
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_17-51-29
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 718.0
  episode_reward_mean: 464.23
  episode_reward_min: 280.0
  episodes_this_iter: 1
  episodes_total: 256
  experiment_id: f3470259fa9143609a5dd5049ba7f979
  hostname: gpu020
  info:
    apply_time_ms: 4.587
    dispatch_time_ms: 30.238
    learner:
      cur_lr: 0.001274751964956522
      grad_gnorm: 9.495380401611328
      policy_entropy: 53.89406204223633
      policy_loss: -3.7572262287139893
      var_gnorm: 42.419559478759766
      vf_explained_var: 0.0
      vf_loss: 0.1095995306968689
    num_steps_sampled: 1285000
    num_steps_trained: 1285000
    wait_time_ms: 37.709
  iterations_since_restore: 257
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 830
  policy_reward_mean: {}
  time_since_restore: 3284.1188101768494
  time_this_iter_s: 13.400185585021973
  time_total_s: 3284.1188101768494
  timestamp: 1593813089
  timesteps_since_restore: 1285000
  timesteps_this_iter: 5000
  timesteps_total: 1285000
  training_iteration: 257
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 13.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=830], 3284 s, 257 iter, 1285000 ts, 464 rew

agent-1: 74.0
agent-2: 111.0
agent-3: 81.0
agent-4: 75.0
agent-5: 89.0
Sum Reward: 430.0
Avg Reward: 86.0
Min Reward: 74.0
Gini Coefficient 0.08186046511627906
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_17-51-40
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 718.0
  episode_reward_mean: 465.0
  episode_reward_min: 280.0
  episodes_this_iter: 1
  episodes_total: 257
  experiment_id: f3470259fa9143609a5dd5049ba7f979
  hostname: gpu020
  info:
    apply_time_ms: 3.08
    dispatch_time_ms: 10.699
    learner:
      cur_lr: 0.001274419017136097
      grad_gnorm: 40.0
      policy_entropy: 23.901792526245117
      policy_loss: 13.120439529418945
      var_gnorm: 42.469112396240234
      vf_explained_var: -1.0
      vf_loss: 82.00228118896484
    num_steps_sampled: 1290000
    num_steps_trained: 1290000
    wait_time_ms: 104.011
  iterations_since_restore: 258
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 830
  policy_reward_mean: {}
  time_since_restore: 3294.8376863002777
  time_this_iter_s: 10.718876123428345
  time_total_s: 3294.8376863002777
  timestamp: 1593813100
  timesteps_since_restore: 1290000
  timesteps_this_iter: 5000
  timesteps_total: 1290000
  training_iteration: 258
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 13.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=830], 3294 s, 258 iter, 1290000 ts, 465 rew

agent-1: 85.0
agent-2: 120.0
agent-3: 104.0
agent-4: 94.0
agent-5: 127.0
Sum Reward: 530.0
Avg Reward: 106.0
Min Reward: 85.0
Gini Coefficient 0.0830188679245283
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_17-51-52
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 718.0
  episode_reward_mean: 466.65
  episode_reward_min: 280.0
  episodes_this_iter: 1
  episodes_total: 258
  experiment_id: f3470259fa9143609a5dd5049ba7f979
  hostname: gpu020
  info:
    apply_time_ms: 3.211
    dispatch_time_ms: 10.476
    learner:
      cur_lr: 0.00127408595290035
      grad_gnorm: 39.99998092651367
      policy_entropy: 13.35804557800293
      policy_loss: -10.701478958129883
      var_gnorm: 42.534088134765625
      vf_explained_var: 0.7766896486282349
      vf_loss: 87.0791244506836
    num_steps_sampled: 1295000
    num_steps_trained: 1295000
    wait_time_ms: 93.636
  iterations_since_restore: 259
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 830
  policy_reward_mean: {}
  time_since_restore: 3306.53751206398
  time_this_iter_s: 11.699825763702393
  time_total_s: 3306.53751206398
  timestamp: 1593813112
  timesteps_since_restore: 1295000
  timesteps_this_iter: 5000
  timesteps_total: 1295000
  training_iteration: 259
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 13.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=830], 3306 s, 259 iter, 1295000 ts, 467 rew

agent-1: 141.0
agent-2: 122.0
agent-3: 114.0
agent-4: 120.0
agent-5: 143.0
Sum Reward: 640.0
Avg Reward: 128.0
Min Reward: 114.0
Gini Coefficient 0.049375
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_17-52-05
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 718.0
  episode_reward_mean: 469.28
  episode_reward_min: 280.0
  episodes_this_iter: 1
  episodes_total: 259
  experiment_id: f3470259fa9143609a5dd5049ba7f979
  hostname: gpu020
  info:
    apply_time_ms: 3.561
    dispatch_time_ms: 9.67
    learner:
      cur_lr: 0.001273753005079925
      grad_gnorm: 40.00001907348633
      policy_entropy: 26.5742244720459
      policy_loss: -3.903604030609131
      var_gnorm: 42.54742431640625
      vf_explained_var: 0.6777169704437256
      vf_loss: 10.104310989379883
    num_steps_sampled: 1300000
    num_steps_trained: 1300000
    wait_time_ms: 115.209
  iterations_since_restore: 260
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 830
  policy_reward_mean: {}
  time_since_restore: 3320.26172542572
  time_this_iter_s: 13.724213361740112
  time_total_s: 3320.26172542572
  timestamp: 1593813125
  timesteps_since_restore: 1300000
  timesteps_this_iter: 5000
  timesteps_total: 1300000
  training_iteration: 260
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 13.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=830], 3320 s, 260 iter, 1300000 ts, 469 rew

agent-1: 101.0
agent-2: 93.0
agent-3: 105.0
agent-4: 97.0
agent-5: 111.0
Sum Reward: 507.0
Avg Reward: 101.4
Min Reward: 93.0
Gini Coefficient 0.03471400394477318
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_17-52-17
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 718.0
  episode_reward_mean: 467.34
  episode_reward_min: 280.0
  episodes_this_iter: 1
  episodes_total: 260
  experiment_id: f3470259fa9143609a5dd5049ba7f979
  hostname: gpu020
  info:
    apply_time_ms: 3.32
    dispatch_time_ms: 10.384
    learner:
      cur_lr: 0.0012734200572595
      grad_gnorm: 40.000003814697266
      policy_entropy: 31.66921043395996
      policy_loss: -18.836843490600586
      var_gnorm: 42.606014251708984
      vf_explained_var: -1.0
      vf_loss: 45.44560623168945
    num_steps_sampled: 1305000
    num_steps_trained: 1305000
    wait_time_ms: 95.311
  iterations_since_restore: 261
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 830
  policy_reward_mean: {}
  time_since_restore: 3332.074056148529
  time_this_iter_s: 11.812330722808838
  time_total_s: 3332.074056148529
  timestamp: 1593813137
  timesteps_since_restore: 1305000
  timesteps_this_iter: 5000
  timesteps_total: 1305000
  training_iteration: 261
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 13.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=830], 3332 s, 261 iter, 1305000 ts, 467 rew

agent-1: 94.0
agent-2: 117.0
agent-3: 91.0
agent-4: 107.0
agent-5: 127.0
Sum Reward: 536.0
Avg Reward: 107.2
Min Reward: 91.0
Gini Coefficient 0.0708955223880597
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_17-52-30
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 718.0
  episode_reward_mean: 468.73
  episode_reward_min: 280.0
  episodes_this_iter: 1
  episodes_total: 261
  experiment_id: f3470259fa9143609a5dd5049ba7f979
  hostname: gpu020
  info:
    apply_time_ms: 3.331
    dispatch_time_ms: 16.794
    learner:
      cur_lr: 0.0012730869930237532
      grad_gnorm: 40.000003814697266
      policy_entropy: 18.722747802734375
      policy_loss: 26.82209587097168
      var_gnorm: 42.69357681274414
      vf_explained_var: 0.35535043478012085
      vf_loss: 405.7220764160156
    num_steps_sampled: 1310000
    num_steps_trained: 1310000
    wait_time_ms: 21.55
  iterations_since_restore: 262
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 830
  policy_reward_mean: {}
  time_since_restore: 3344.293564081192
  time_this_iter_s: 12.219507932662964
  time_total_s: 3344.293564081192
  timestamp: 1593813150
  timesteps_since_restore: 1310000
  timesteps_this_iter: 5000
  timesteps_total: 1310000
  training_iteration: 262
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 13.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=830], 3344 s, 262 iter, 1310000 ts, 469 rew

agent-1: 118.0
agent-2: 138.0
agent-3: 97.0
agent-4: 147.0
agent-5: 119.0
Sum Reward: 619.0
Avg Reward: 123.8
Min Reward: 97.0
Gini Coefficient 0.07754442649434572
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_17-52-41
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 718.0
  episode_reward_mean: 471.27
  episode_reward_min: 280.0
  episodes_this_iter: 1
  episodes_total: 262
  experiment_id: f3470259fa9143609a5dd5049ba7f979
  hostname: gpu020
  info:
    apply_time_ms: 2.956
    dispatch_time_ms: 9.81
    learner:
      cur_lr: 0.0012727540452033281
      grad_gnorm: 19.777923583984375
      policy_entropy: 18.649946212768555
      policy_loss: -8.136704444885254
      var_gnorm: 42.658451080322266
      vf_explained_var: 0.5256612300872803
      vf_loss: 66.75855255126953
    num_steps_sampled: 1315000
    num_steps_trained: 1315000
    wait_time_ms: 98.045
  iterations_since_restore: 263
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 830
  policy_reward_mean: {}
  time_since_restore: 3355.6148455142975
  time_this_iter_s: 11.321281433105469
  time_total_s: 3355.6148455142975
  timestamp: 1593813161
  timesteps_since_restore: 1315000
  timesteps_this_iter: 5000
  timesteps_total: 1315000
  training_iteration: 263
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 13.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=830], 3355 s, 263 iter, 1315000 ts, 471 rew

agent-1: 110.0
agent-2: 95.0
agent-3: 99.0
agent-4: 71.0
agent-5: 108.0
Sum Reward: 483.0
Avg Reward: 96.6
Min Reward: 71.0
Gini Coefficient 0.07536231884057971
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_17-52-52
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 718.0
  episode_reward_mean: 472.01
  episode_reward_min: 280.0
  episodes_this_iter: 1
  episodes_total: 263
  experiment_id: f3470259fa9143609a5dd5049ba7f979
  hostname: gpu020
  info:
    apply_time_ms: 3.577
    dispatch_time_ms: 10.349
    learner:
      cur_lr: 0.0012724209809675813
      grad_gnorm: 40.0
      policy_entropy: 14.290666580200195
      policy_loss: 3.441471815109253
      var_gnorm: 42.668460845947266
      vf_explained_var: 0.6686316728591919
      vf_loss: 88.97687530517578
    num_steps_sampled: 1320000
    num_steps_trained: 1320000
    wait_time_ms: 106.239
  iterations_since_restore: 264
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 830
  policy_reward_mean: {}
  time_since_restore: 3366.8719742298126
  time_this_iter_s: 11.257128715515137
  time_total_s: 3366.8719742298126
  timestamp: 1593813172
  timesteps_since_restore: 1320000
  timesteps_this_iter: 5000
  timesteps_total: 1320000
  training_iteration: 264
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 13.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=830], 3366 s, 264 iter, 1320000 ts, 472 rew

agent-1: 92.0
agent-2: 147.0
agent-3: 152.0
agent-4: 105.0
agent-5: 108.0
Sum Reward: 604.0
Avg Reward: 120.8
Min Reward: 92.0
Gini Coefficient 0.10728476821192053
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_17-53-07
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 718.0
  episode_reward_mean: 473.21
  episode_reward_min: 280.0
  episodes_this_iter: 1
  episodes_total: 264
  experiment_id: f3470259fa9143609a5dd5049ba7f979
  hostname: gpu020
  info:
    apply_time_ms: 2.957
    dispatch_time_ms: 16.62
    learner:
      cur_lr: 0.0012720880331471562
      grad_gnorm: 40.0
      policy_entropy: 16.30362892150879
      policy_loss: 3.054579257965088
      var_gnorm: 42.74138259887695
      vf_explained_var: 0.3631945252418518
      vf_loss: 37.85575866699219
    num_steps_sampled: 1325000
    num_steps_trained: 1325000
    wait_time_ms: 96.694
  iterations_since_restore: 265
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 830
  policy_reward_mean: {}
  time_since_restore: 3381.9719433784485
  time_this_iter_s: 15.099969148635864
  time_total_s: 3381.9719433784485
  timestamp: 1593813187
  timesteps_since_restore: 1325000
  timesteps_this_iter: 5000
  timesteps_total: 1325000
  training_iteration: 265
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 13.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=830], 3381 s, 265 iter, 1325000 ts, 473 rew

agent-1: 102.0
agent-2: 87.0
agent-3: 82.0
agent-4: 101.0
agent-5: 104.0
Sum Reward: 476.0
Avg Reward: 95.2
Min Reward: 82.0
Gini Coefficient 0.04957983193277311
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_17-53-18
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 718.0
  episode_reward_mean: 473.91
  episode_reward_min: 280.0
  episodes_this_iter: 1
  episodes_total: 265
  experiment_id: f3470259fa9143609a5dd5049ba7f979
  hostname: gpu020
  info:
    apply_time_ms: 2.665
    dispatch_time_ms: 10.721
    learner:
      cur_lr: 0.0012717549689114094
      grad_gnorm: 40.00001525878906
      policy_entropy: 23.410751342773438
      policy_loss: 0.9476258158683777
      var_gnorm: 42.76401901245117
      vf_explained_var: -0.5285091400146484
      vf_loss: 79.41542053222656
    num_steps_sampled: 1330000
    num_steps_trained: 1330000
    wait_time_ms: 99.902
  iterations_since_restore: 266
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 830
  policy_reward_mean: {}
  time_since_restore: 3392.712468624115
  time_this_iter_s: 10.740525245666504
  time_total_s: 3392.712468624115
  timestamp: 1593813198
  timesteps_since_restore: 1330000
  timesteps_this_iter: 5000
  timesteps_total: 1330000
  training_iteration: 266
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 13.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=830], 3392 s, 266 iter, 1330000 ts, 474 rew

agent-1: 140.0
agent-2: 129.0
agent-3: 116.0
agent-4: 123.0
agent-5: 105.0
Sum Reward: 613.0
Avg Reward: 122.6
Min Reward: 105.0
Gini Coefficient 0.05415986949429037
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_17-53-30
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 718.0
  episode_reward_mean: 475.74
  episode_reward_min: 280.0
  episodes_this_iter: 1
  episodes_total: 266
  experiment_id: f3470259fa9143609a5dd5049ba7f979
  hostname: gpu020
  info:
    apply_time_ms: 3.196
    dispatch_time_ms: 16.471
    learner:
      cur_lr: 0.0012714220210909843
      grad_gnorm: 39.999996185302734
      policy_entropy: 21.24421501159668
      policy_loss: -17.8723087310791
      var_gnorm: 42.808372497558594
      vf_explained_var: 0.3994763493537903
      vf_loss: 42.30577850341797
    num_steps_sampled: 1335000
    num_steps_trained: 1335000
    wait_time_ms: 214.858
  iterations_since_restore: 267
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 830
  policy_reward_mean: {}
  time_since_restore: 3404.980847597122
  time_this_iter_s: 12.268378973007202
  time_total_s: 3404.980847597122
  timestamp: 1593813210
  timesteps_since_restore: 1335000
  timesteps_this_iter: 5000
  timesteps_total: 1335000
  training_iteration: 267
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 13.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=830], 3404 s, 267 iter, 1335000 ts, 476 rew

agent-1: 138.0
agent-2: 132.0
agent-3: 144.0
agent-4: 138.0
agent-5: 132.0
Sum Reward: 684.0
Avg Reward: 136.8
Min Reward: 132.0
Gini Coefficient 0.017543859649122806
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_17-53-42
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 718.0
  episode_reward_mean: 479.78
  episode_reward_min: 290.0
  episodes_this_iter: 1
  episodes_total: 267
  experiment_id: f3470259fa9143609a5dd5049ba7f979
  hostname: gpu020
  info:
    apply_time_ms: 3.055
    dispatch_time_ms: 10.721
    learner:
      cur_lr: 0.0012710889568552375
      grad_gnorm: 39.999996185302734
      policy_entropy: 20.39655876159668
      policy_loss: -2.412687063217163
      var_gnorm: 42.846832275390625
      vf_explained_var: 0.5333882570266724
      vf_loss: 94.23543548583984
    num_steps_sampled: 1340000
    num_steps_trained: 1340000
    wait_time_ms: 96.793
  iterations_since_restore: 268
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 830
  policy_reward_mean: {}
  time_since_restore: 3416.353303670883
  time_this_iter_s: 11.372456073760986
  time_total_s: 3416.353303670883
  timestamp: 1593813222
  timesteps_since_restore: 1340000
  timesteps_this_iter: 5000
  timesteps_total: 1340000
  training_iteration: 268
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 13.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=830], 3416 s, 268 iter, 1340000 ts, 480 rew

agent-1: 139.0
agent-2: 154.0
agent-3: 100.0
agent-4: 135.0
agent-5: 148.0
Sum Reward: 676.0
Avg Reward: 135.2
Min Reward: 100.0
Gini Coefficient 0.07159763313609467
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_17-54-20
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 718.0
  episode_reward_mean: 482.39
  episode_reward_min: 290.0
  episodes_this_iter: 1
  episodes_total: 268
  experiment_id: f3470259fa9143609a5dd5049ba7f979
  hostname: gpu020
  info:
    apply_time_ms: 3.425
    dispatch_time_ms: 66.607
    learner:
      cur_lr: 0.0012707560090348125
      grad_gnorm: 39.99998474121094
      policy_entropy: 24.256656646728516
      policy_loss: 0.0759090781211853
      var_gnorm: 42.90984344482422
      vf_explained_var: 0.3216511607170105
      vf_loss: 107.43798828125
    num_steps_sampled: 1345000
    num_steps_trained: 1345000
    wait_time_ms: 206.824
  iterations_since_restore: 269
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 830
  policy_reward_mean: {}
  time_since_restore: 3454.076215028763
  time_this_iter_s: 37.72291135787964
  time_total_s: 3454.076215028763
  timestamp: 1593813260
  timesteps_since_restore: 1345000
  timesteps_this_iter: 5000
  timesteps_total: 1345000
  training_iteration: 269
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 13.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=830], 3454 s, 269 iter, 1345000 ts, 482 rew

agent-1: 167.0
agent-2: 144.0
agent-3: 142.0
agent-4: 125.0
agent-5: 140.0
Sum Reward: 718.0
Avg Reward: 143.6
Min Reward: 125.0
Gini Coefficient 0.04902506963788301
W0703 17:54:31.967460   825 node_manager.cc:250] Last heartbeat was sent 1411 ms ago 
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_17-54-37
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 718.0
  episode_reward_mean: 484.18
  episode_reward_min: 290.0
  episodes_this_iter: 1
  episodes_total: 269
  experiment_id: f3470259fa9143609a5dd5049ba7f979
  hostname: gpu020
  info:
    apply_time_ms: 3.734
    dispatch_time_ms: 10.974
    learner:
      cur_lr: 0.0012704229447990656
      grad_gnorm: 39.999996185302734
      policy_entropy: 38.1696891784668
      policy_loss: -4.798838138580322
      var_gnorm: 42.9636116027832
      vf_explained_var: 0.03819841146469116
      vf_loss: 34.80778121948242
    num_steps_sampled: 1350000
    num_steps_trained: 1350000
    wait_time_ms: 88.679
  iterations_since_restore: 270
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 830
  policy_reward_mean: {}
  time_since_restore: 3471.4958662986755
  time_this_iter_s: 17.41965126991272
  time_total_s: 3471.4958662986755
  timestamp: 1593813277
  timesteps_since_restore: 1350000
  timesteps_this_iter: 5000
  timesteps_total: 1350000
  training_iteration: 270
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 13.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=830], 3471 s, 270 iter, 1350000 ts, 484 rew

agent-1: 123.0
agent-2: 151.0
agent-3: 113.0
agent-4: 137.0
agent-5: 142.0
Sum Reward: 666.0
Avg Reward: 133.2
Min Reward: 113.0
Gini Coefficient 0.057057057057057055
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_17-54-49
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 718.0
  episode_reward_mean: 483.66
  episode_reward_min: 290.0
  episodes_this_iter: 1
  episodes_total: 270
  experiment_id: f3470259fa9143609a5dd5049ba7f979
  hostname: gpu020
  info:
    apply_time_ms: 4.588
    dispatch_time_ms: 82.463
    learner:
      cur_lr: 0.0012700899969786406
      grad_gnorm: 40.0
      policy_entropy: 43.0435791015625
      policy_loss: 28.566913604736328
      var_gnorm: 42.95746612548828
      vf_explained_var: 0.715078592300415
      vf_loss: 84.9889907836914
    num_steps_sampled: 1355000
    num_steps_trained: 1355000
    wait_time_ms: 60.176
  iterations_since_restore: 271
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 830
  policy_reward_mean: {}
  time_since_restore: 3483.378578901291
  time_this_iter_s: 11.882712602615356
  time_total_s: 3483.378578901291
  timestamp: 1593813289
  timesteps_since_restore: 1355000
  timesteps_this_iter: 5000
  timesteps_total: 1355000
  training_iteration: 271
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 14.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=830], 3483 s, 271 iter, 1355000 ts, 484 rew

agent-1: 161.0
agent-2: 175.0
agent-3: 133.0
agent-4: 163.0
agent-5: 131.0
Sum Reward: 763.0
Avg Reward: 152.6
Min Reward: 131.0
Gini Coefficient 0.0618610747051114
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_17-55-07
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 763.0
  episode_reward_mean: 485.39
  episode_reward_min: 290.0
  episodes_this_iter: 1
  episodes_total: 271
  experiment_id: f3470259fa9143609a5dd5049ba7f979
  hostname: gpu020
  info:
    apply_time_ms: 5.16
    dispatch_time_ms: 95.072
    learner:
      cur_lr: 0.0012697570491582155
      grad_gnorm: 18.368453979492188
      policy_entropy: 45.40434646606445
      policy_loss: -1.3106739521026611
      var_gnorm: 42.99460983276367
      vf_explained_var: 0.09862750768661499
      vf_loss: 23.900279998779297
    num_steps_sampled: 1360000
    num_steps_trained: 1360000
    wait_time_ms: 40.727
  iterations_since_restore: 272
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 830
  policy_reward_mean: {}
  time_since_restore: 3501.565165758133
  time_this_iter_s: 18.18658685684204
  time_total_s: 3501.565165758133
  timestamp: 1593813307
  timesteps_since_restore: 1360000
  timesteps_this_iter: 5000
  timesteps_total: 1360000
  training_iteration: 272
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 13.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=830], 3501 s, 272 iter, 1360000 ts, 485 rew

W0703 17:55:11.289289   825 node_manager.cc:250] Last heartbeat was sent 502 ms ago 
agent-1: 145.0
agent-2: 152.0
agent-3: 153.0
agent-4: 156.0
agent-5: 140.0
Sum Reward: 746.0
Avg Reward: 149.2
Min Reward: 140.0
Gini Coefficient 0.021447721179624665
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_17-55-21
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 763.0
  episode_reward_mean: 488.43
  episode_reward_min: 290.0
  episodes_this_iter: 1
  episodes_total: 272
  experiment_id: f3470259fa9143609a5dd5049ba7f979
  hostname: gpu020
  info:
    apply_time_ms: 2.821
    dispatch_time_ms: 11.754
    learner:
      cur_lr: 0.0012694239849224687
      grad_gnorm: 40.0
      policy_entropy: 24.89864158630371
      policy_loss: 1.236119031906128
      var_gnorm: 43.05105209350586
      vf_explained_var: 0.06562399864196777
      vf_loss: 19.741260528564453
    num_steps_sampled: 1365000
    num_steps_trained: 1365000
    wait_time_ms: 95.553
  iterations_since_restore: 273
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 830
  policy_reward_mean: {}
  time_since_restore: 3515.6197299957275
  time_this_iter_s: 14.054564237594604
  time_total_s: 3515.6197299957275
  timestamp: 1593813321
  timesteps_since_restore: 1365000
  timesteps_this_iter: 5000
  timesteps_total: 1365000
  training_iteration: 273
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 13.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=830], 3515 s, 273 iter, 1365000 ts, 488 rew

agent-1: 134.0
agent-2: 165.0
agent-3: 129.0
agent-4: 105.0
agent-5: 103.0
Sum Reward: 636.0
Avg Reward: 127.2
Min Reward: 103.0
Gini Coefficient 0.09622641509433963
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_17-55-34
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 763.0
  episode_reward_mean: 489.69
  episode_reward_min: 290.0
  episodes_this_iter: 1
  episodes_total: 273
  experiment_id: f3470259fa9143609a5dd5049ba7f979
  hostname: gpu020
  info:
    apply_time_ms: 3.637
    dispatch_time_ms: 19.694
    learner:
      cur_lr: 0.0012690910371020436
      grad_gnorm: 40.00001525878906
      policy_entropy: 29.135143280029297
      policy_loss: -7.920201301574707
      var_gnorm: 43.210636138916016
      vf_explained_var: -1.0
      vf_loss: 28.314043045043945
    num_steps_sampled: 1370000
    num_steps_trained: 1370000
    wait_time_ms: 90.092
  iterations_since_restore: 274
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 830
  policy_reward_mean: {}
  time_since_restore: 3528.5104484558105
  time_this_iter_s: 12.890718460083008
  time_total_s: 3528.5104484558105
  timestamp: 1593813334
  timesteps_since_restore: 1370000
  timesteps_this_iter: 5000
  timesteps_total: 1370000
  training_iteration: 274
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 13.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=830], 3528 s, 274 iter, 1370000 ts, 490 rew

agent-1: 117.0
agent-2: 108.0
agent-3: 131.0
agent-4: 99.0
agent-5: 100.0
Sum Reward: 555.0
Avg Reward: 111.0
Min Reward: 99.0
Gini Coefficient 0.05837837837837838
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_17-55-46
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 763.0
  episode_reward_mean: 490.46
  episode_reward_min: 290.0
  episodes_this_iter: 1
  episodes_total: 274
  experiment_id: f3470259fa9143609a5dd5049ba7f979
  hostname: gpu020
  info:
    apply_time_ms: 2.596
    dispatch_time_ms: 9.033
    learner:
      cur_lr: 0.0012687579728662968
      grad_gnorm: 40.0
      policy_entropy: 32.53843307495117
      policy_loss: 38.46921157836914
      var_gnorm: 43.28200149536133
      vf_explained_var: -0.3693861961364746
      vf_loss: 59.31642532348633
    num_steps_sampled: 1375000
    num_steps_trained: 1375000
    wait_time_ms: 103.681
  iterations_since_restore: 275
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 830
  policy_reward_mean: {}
  time_since_restore: 3539.9962632656097
  time_this_iter_s: 11.485814809799194
  time_total_s: 3539.9962632656097
  timestamp: 1593813346
  timesteps_since_restore: 1375000
  timesteps_this_iter: 5000
  timesteps_total: 1375000
  training_iteration: 275
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 13.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=830], 3539 s, 275 iter, 1375000 ts, 490 rew

agent-1: 98.0
agent-2: 96.0
agent-3: 96.0
agent-4: 105.0
agent-5: 146.0
Sum Reward: 541.0
Avg Reward: 108.2
Min Reward: 96.0
Gini Coefficient 0.08059149722735674
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_17-55-58
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 763.0
  episode_reward_mean: 491.87
  episode_reward_min: 290.0
  episodes_this_iter: 1
  episodes_total: 275
  experiment_id: f3470259fa9143609a5dd5049ba7f979
  hostname: gpu020
  info:
    apply_time_ms: 3.36
    dispatch_time_ms: 64.29
    learner:
      cur_lr: 0.0012684250250458717
      grad_gnorm: 39.999996185302734
      policy_entropy: 32.513912200927734
      policy_loss: -12.709758758544922
      var_gnorm: 43.36283874511719
      vf_explained_var: 0.9177048802375793
      vf_loss: 4.072903156280518
    num_steps_sampled: 1380000
    num_steps_trained: 1380000
    wait_time_ms: 61.733
  iterations_since_restore: 276
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 830
  policy_reward_mean: {}
  time_since_restore: 3552.657413005829
  time_this_iter_s: 12.661149740219116
  time_total_s: 3552.657413005829
  timestamp: 1593813358
  timesteps_since_restore: 1380000
  timesteps_this_iter: 5000
  timesteps_total: 1380000
  training_iteration: 276
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 13.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=830], 3552 s, 276 iter, 1380000 ts, 492 rew

agent-1: 117.0
agent-2: 145.0
agent-3: 87.0
agent-4: 112.0
agent-5: 149.0
Sum Reward: 610.0
Avg Reward: 122.0
Min Reward: 87.0
Gini Coefficient 0.10295081967213114
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_17-56-09
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 763.0
  episode_reward_mean: 493.81
  episode_reward_min: 290.0
  episodes_this_iter: 1
  episodes_total: 276
  experiment_id: f3470259fa9143609a5dd5049ba7f979
  hostname: gpu020
  info:
    apply_time_ms: 2.964
    dispatch_time_ms: 8.896
    learner:
      cur_lr: 0.0012680919608101249
      grad_gnorm: 40.0
      policy_entropy: 13.577709197998047
      policy_loss: 7.3491387367248535
      var_gnorm: 43.41014099121094
      vf_explained_var: -0.3209726810455322
      vf_loss: 57.17011260986328
    num_steps_sampled: 1385000
    num_steps_trained: 1385000
    wait_time_ms: 95.205
  iterations_since_restore: 277
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 830
  policy_reward_mean: {}
  time_since_restore: 3563.7248899936676
  time_this_iter_s: 11.067476987838745
  time_total_s: 3563.7248899936676
  timestamp: 1593813369
  timesteps_since_restore: 1385000
  timesteps_this_iter: 5000
  timesteps_total: 1385000
  training_iteration: 277
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 13.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=830], 3563 s, 277 iter, 1385000 ts, 494 rew

agent-1: 116.0
agent-2: 132.0
agent-3: 100.0
agent-4: 122.0
agent-5: 137.0
Sum Reward: 607.0
Avg Reward: 121.4
Min Reward: 100.0
Gini Coefficient 0.05930807248764415
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_17-56-21
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 763.0
  episode_reward_mean: 494.96
  episode_reward_min: 290.0
  episodes_this_iter: 1
  episodes_total: 277
  experiment_id: f3470259fa9143609a5dd5049ba7f979
  hostname: gpu020
  info:
    apply_time_ms: 3.532
    dispatch_time_ms: 11.035
    learner:
      cur_lr: 0.0012677590129896998
      grad_gnorm: 39.99998474121094
      policy_entropy: 14.276383399963379
      policy_loss: -11.849848747253418
      var_gnorm: 43.387882232666016
      vf_explained_var: -0.3603094816207886
      vf_loss: 69.79180908203125
    num_steps_sampled: 1390000
    num_steps_trained: 1390000
    wait_time_ms: 101.538
  iterations_since_restore: 278
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 830
  policy_reward_mean: {}
  time_since_restore: 3575.278879404068
  time_this_iter_s: 11.55398941040039
  time_total_s: 3575.278879404068
  timestamp: 1593813381
  timesteps_since_restore: 1390000
  timesteps_this_iter: 5000
  timesteps_total: 1390000
  training_iteration: 278
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 13.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=830], 3575 s, 278 iter, 1390000 ts, 495 rew

agent-1: 96.0
agent-2: 120.0
agent-3: 110.0
agent-4: 120.0
agent-5: 125.0
Sum Reward: 571.0
Avg Reward: 114.2
Min Reward: 96.0
Gini Coefficient 0.047635726795096325
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_17-56-33
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 763.0
  episode_reward_mean: 495.13
  episode_reward_min: 290.0
  episodes_this_iter: 1
  episodes_total: 278
  experiment_id: f3470259fa9143609a5dd5049ba7f979
  hostname: gpu020
  info:
    apply_time_ms: 2.473
    dispatch_time_ms: 10.032
    learner:
      cur_lr: 0.001267425948753953
      grad_gnorm: 39.99999237060547
      policy_entropy: 13.193659782409668
      policy_loss: 1.323914647102356
      var_gnorm: 43.4178581237793
      vf_explained_var: 0.7601919174194336
      vf_loss: 27.698694229125977
    num_steps_sampled: 1395000
    num_steps_trained: 1395000
    wait_time_ms: 98.727
  iterations_since_restore: 279
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 830
  policy_reward_mean: {}
  time_since_restore: 3587.668962240219
  time_this_iter_s: 12.390082836151123
  time_total_s: 3587.668962240219
  timestamp: 1593813393
  timesteps_since_restore: 1395000
  timesteps_this_iter: 5000
  timesteps_total: 1395000
  training_iteration: 279
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 13.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=830], 3587 s, 279 iter, 1395000 ts, 495 rew

agent-1: 127.0
agent-2: 71.0
agent-3: 111.0
agent-4: 95.0
agent-5: 92.0
Sum Reward: 496.0
Avg Reward: 99.2
Min Reward: 71.0
Gini Coefficient 0.10564516129032259
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_17-56-45
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 763.0
  episode_reward_mean: 494.16
  episode_reward_min: 290.0
  episodes_this_iter: 1
  episodes_total: 279
  experiment_id: f3470259fa9143609a5dd5049ba7f979
  hostname: gpu020
  info:
    apply_time_ms: 3.191
    dispatch_time_ms: 11.964
    learner:
      cur_lr: 0.001267093000933528
      grad_gnorm: 39.999996185302734
      policy_entropy: 24.574132919311523
      policy_loss: 7.91008996963501
      var_gnorm: 43.44276428222656
      vf_explained_var: 0.5390514135360718
      vf_loss: 48.520851135253906
    num_steps_sampled: 1400000
    num_steps_trained: 1400000
    wait_time_ms: 104.27
  iterations_since_restore: 280
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 830
  policy_reward_mean: {}
  time_since_restore: 3599.0987780094147
  time_this_iter_s: 11.429815769195557
  time_total_s: 3599.0987780094147
  timestamp: 1593813405
  timesteps_since_restore: 1400000
  timesteps_this_iter: 5000
  timesteps_total: 1400000
  training_iteration: 280
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 13.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=830], 3599 s, 280 iter, 1400000 ts, 494 rew

agent-1: 102.0
agent-2: 98.0
agent-3: 99.0
agent-4: 84.0
agent-5: 94.0
Sum Reward: 477.0
Avg Reward: 95.4
Min Reward: 84.0
Gini Coefficient 0.034381551362683435
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_17-56-56
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 763.0
  episode_reward_mean: 492.43
  episode_reward_min: 290.0
  episodes_this_iter: 1
  episodes_total: 280
  experiment_id: f3470259fa9143609a5dd5049ba7f979
  hostname: gpu020
  info:
    apply_time_ms: 2.641
    dispatch_time_ms: 11.333
    learner:
      cur_lr: 0.001266760053113103
      grad_gnorm: 40.0
      policy_entropy: 34.375221252441406
      policy_loss: -10.77956771850586
      var_gnorm: 43.52345275878906
      vf_explained_var: 0.9394608736038208
      vf_loss: 3.513118267059326
    num_steps_sampled: 1405000
    num_steps_trained: 1405000
    wait_time_ms: 101.252
  iterations_since_restore: 281
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 830
  policy_reward_mean: {}
  time_since_restore: 3610.6739287376404
  time_this_iter_s: 11.575150728225708
  time_total_s: 3610.6739287376404
  timestamp: 1593813416
  timesteps_since_restore: 1405000
  timesteps_this_iter: 5000
  timesteps_total: 1405000
  training_iteration: 281
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 13.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=830], 3610 s, 281 iter, 1405000 ts, 492 rew

agent-1: 121.0
agent-2: 122.0
agent-3: 107.0
agent-4: 146.0
agent-5: 126.0
Sum Reward: 622.0
Avg Reward: 124.4
Min Reward: 107.0
Gini Coefficient 0.05337620578778135
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_17-57-11
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 763.0
  episode_reward_mean: 491.97
  episode_reward_min: 290.0
  episodes_this_iter: 1
  episodes_total: 281
  experiment_id: f3470259fa9143609a5dd5049ba7f979
  hostname: gpu020
  info:
    apply_time_ms: 3.238
    dispatch_time_ms: 15.747
    learner:
      cur_lr: 0.001266426988877356
      grad_gnorm: 17.679698944091797
      policy_entropy: 29.028743743896484
      policy_loss: -2.252902030944824
      var_gnorm: 43.560150146484375
      vf_explained_var: 0.687164843082428
      vf_loss: 7.298024654388428
    num_steps_sampled: 1410000
    num_steps_trained: 1410000
    wait_time_ms: 95.105
  iterations_since_restore: 282
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 830
  policy_reward_mean: {}
  time_since_restore: 3624.728516101837
  time_this_iter_s: 14.054587364196777
  time_total_s: 3624.728516101837
  timestamp: 1593813431
  timesteps_since_restore: 1410000
  timesteps_this_iter: 5000
  timesteps_total: 1410000
  training_iteration: 282
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 13.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=830], 3624 s, 282 iter, 1410000 ts, 492 rew

agent-1: 151.0
agent-2: 127.0
agent-3: 152.0
agent-4: 135.0
agent-5: 121.0
Sum Reward: 686.0
Avg Reward: 137.2
Min Reward: 121.0
Gini Coefficient 0.05014577259475218
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_17-57-22
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 763.0
  episode_reward_mean: 492.79
  episode_reward_min: 290.0
  episodes_this_iter: 1
  episodes_total: 282
  experiment_id: f3470259fa9143609a5dd5049ba7f979
  hostname: gpu020
  info:
    apply_time_ms: 3.348
    dispatch_time_ms: 11.278
    learner:
      cur_lr: 0.001266094041056931
      grad_gnorm: 40.000003814697266
      policy_entropy: 32.115386962890625
      policy_loss: -7.621602535247803
      var_gnorm: 43.543338775634766
      vf_explained_var: 0.7791297435760498
      vf_loss: 8.245382308959961
    num_steps_sampled: 1415000
    num_steps_trained: 1415000
    wait_time_ms: 88.028
  iterations_since_restore: 283
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 830
  policy_reward_mean: {}
  time_since_restore: 3635.8793568611145
  time_this_iter_s: 11.150840759277344
  time_total_s: 3635.8793568611145
  timestamp: 1593813442
  timesteps_since_restore: 1415000
  timesteps_this_iter: 5000
  timesteps_total: 1415000
  training_iteration: 283
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 13.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=830], 3635 s, 283 iter, 1415000 ts, 493 rew

agent-1: 112.0
agent-2: 134.0
agent-3: 116.0
agent-4: 167.0
agent-5: 141.0
Sum Reward: 670.0
Avg Reward: 134.0
Min Reward: 112.0
Gini Coefficient 0.08059701492537313
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_17-57-35
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 763.0
  episode_reward_mean: 494.46
  episode_reward_min: 290.0
  episodes_this_iter: 1
  episodes_total: 283
  experiment_id: f3470259fa9143609a5dd5049ba7f979
  hostname: gpu020
  info:
    apply_time_ms: 3.118
    dispatch_time_ms: 99.978
    learner:
      cur_lr: 0.0012657609768211842
      grad_gnorm: 40.0
      policy_entropy: 26.191749572753906
      policy_loss: -5.025689125061035
      var_gnorm: 43.55183792114258
      vf_explained_var: 0.3330957889556885
      vf_loss: 27.707168579101562
    num_steps_sampled: 1420000
    num_steps_trained: 1420000
    wait_time_ms: 96.913
  iterations_since_restore: 284
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 830
  policy_reward_mean: {}
  time_since_restore: 3649.502158164978
  time_this_iter_s: 13.622801303863525
  time_total_s: 3649.502158164978
  timestamp: 1593813455
  timesteps_since_restore: 1420000
  timesteps_this_iter: 5000
  timesteps_total: 1420000
  training_iteration: 284
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 13.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=830], 3649 s, 284 iter, 1420000 ts, 494 rew

agent-1: 70.0
agent-2: 164.0
agent-3: 85.0
agent-4: 132.0
agent-5: 78.0
Sum Reward: 529.0
Avg Reward: 105.8
Min Reward: 70.0
Gini Coefficient 0.1829867674858223
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_17-57-46
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 763.0
  episode_reward_mean: 494.34
  episode_reward_min: 290.0
  episodes_this_iter: 1
  episodes_total: 284
  experiment_id: f3470259fa9143609a5dd5049ba7f979
  hostname: gpu020
  info:
    apply_time_ms: 3.883
    dispatch_time_ms: 10.644
    learner:
      cur_lr: 0.0012654280290007591
      grad_gnorm: 39.99999237060547
      policy_entropy: 18.45804214477539
      policy_loss: -2.9742355346679688
      var_gnorm: 43.61771774291992
      vf_explained_var: 0.1562708020210266
      vf_loss: 62.00695037841797
    num_steps_sampled: 1425000
    num_steps_trained: 1425000
    wait_time_ms: 93.991
  iterations_since_restore: 285
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 830
  policy_reward_mean: {}
  time_since_restore: 3660.18684053421
  time_this_iter_s: 10.684682369232178
  time_total_s: 3660.18684053421
  timestamp: 1593813466
  timesteps_since_restore: 1425000
  timesteps_this_iter: 5000
  timesteps_total: 1425000
  training_iteration: 285
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 13.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=830], 3660 s, 285 iter, 1425000 ts, 494 rew

agent-1: 121.0
agent-2: 110.0
agent-3: 141.0
agent-4: 90.0
agent-5: 124.0
Sum Reward: 586.0
Avg Reward: 117.2
Min Reward: 90.0
Gini Coefficient 0.07918088737201365
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_17-57-57
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 763.0
  episode_reward_mean: 493.71
  episode_reward_min: 290.0
  episodes_this_iter: 1
  episodes_total: 285
  experiment_id: f3470259fa9143609a5dd5049ba7f979
  hostname: gpu020
  info:
    apply_time_ms: 3.072
    dispatch_time_ms: 13.943
    learner:
      cur_lr: 0.0012650949647650123
      grad_gnorm: 40.000003814697266
      policy_entropy: 28.0125732421875
      policy_loss: 13.610593795776367
      var_gnorm: 43.5932502746582
      vf_explained_var: 0.23662418127059937
      vf_loss: 39.88519287109375
    num_steps_sampled: 1430000
    num_steps_trained: 1430000
    wait_time_ms: 99.897
  iterations_since_restore: 286
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 830
  policy_reward_mean: {}
  time_since_restore: 3671.226167678833
  time_this_iter_s: 11.039327144622803
  time_total_s: 3671.226167678833
  timestamp: 1593813477
  timesteps_since_restore: 1430000
  timesteps_this_iter: 5000
  timesteps_total: 1430000
  training_iteration: 286
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 13.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=830], 3671 s, 286 iter, 1430000 ts, 494 rew

agent-1: 133.0
agent-2: 177.0
agent-3: 106.0
agent-4: 157.0
agent-5: 111.0
Sum Reward: 684.0
Avg Reward: 136.8
Min Reward: 106.0
Gini Coefficient 0.10994152046783626
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_17-58-14
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 763.0
  episode_reward_mean: 494.59
  episode_reward_min: 290.0
  episodes_this_iter: 1
  episodes_total: 286
  experiment_id: f3470259fa9143609a5dd5049ba7f979
  hostname: gpu020
  info:
    apply_time_ms: 2.271
    dispatch_time_ms: 42.832
    learner:
      cur_lr: 0.0012647620169445872
      grad_gnorm: 26.190059661865234
      policy_entropy: 15.316526412963867
      policy_loss: -4.4839277267456055
      var_gnorm: 43.588050842285156
      vf_explained_var: 0.8866046071052551
      vf_loss: 29.488574981689453
    num_steps_sampled: 1435000
    num_steps_trained: 1435000
    wait_time_ms: 179.685
  iterations_since_restore: 287
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 830
  policy_reward_mean: {}
  time_since_restore: 3687.8733019828796
  time_this_iter_s: 16.64713430404663
  time_total_s: 3687.8733019828796
  timestamp: 1593813494
  timesteps_since_restore: 1435000
  timesteps_this_iter: 5000
  timesteps_total: 1435000
  training_iteration: 287
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 13.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=830], 3687 s, 287 iter, 1435000 ts, 495 rew

agent-1: 113.0
agent-2: 155.0
agent-3: 54.0
agent-4: 110.0
agent-5: 143.0
Sum Reward: 575.0
Avg Reward: 115.0
Min Reward: 54.0
Gini Coefficient 0.1634782608695652
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_17-58-24
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 763.0
  episode_reward_mean: 496.45
  episode_reward_min: 290.0
  episodes_this_iter: 1
  episodes_total: 287
  experiment_id: f3470259fa9143609a5dd5049ba7f979
  hostname: gpu020
  info:
    apply_time_ms: 3.265
    dispatch_time_ms: 22.153
    learner:
      cur_lr: 0.0012644289527088404
      grad_gnorm: 40.0
      policy_entropy: 26.694072723388672
      policy_loss: -10.475229263305664
      var_gnorm: 43.64305877685547
      vf_explained_var: 0.9431798458099365
      vf_loss: 12.765419960021973
    num_steps_sampled: 1440000
    num_steps_trained: 1440000
    wait_time_ms: 95.259
  iterations_since_restore: 288
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 830
  policy_reward_mean: {}
  time_since_restore: 3698.4295406341553
  time_this_iter_s: 10.556238651275635
  time_total_s: 3698.4295406341553
  timestamp: 1593813504
  timesteps_since_restore: 1440000
  timesteps_this_iter: 5000
  timesteps_total: 1440000
  training_iteration: 288
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 14.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=830], 3698 s, 288 iter, 1440000 ts, 496 rew

agent-1: 143.0
agent-2: 128.0
agent-3: 106.0
agent-4: 126.0
agent-5: 81.0
Sum Reward: 584.0
Avg Reward: 116.8
Min Reward: 81.0
Gini Coefficient 0.1
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_17-58-36
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 763.0
  episode_reward_mean: 497.53
  episode_reward_min: 290.0
  episodes_this_iter: 1
  episodes_total: 288
  experiment_id: f3470259fa9143609a5dd5049ba7f979
  hostname: gpu020
  info:
    apply_time_ms: 2.767
    dispatch_time_ms: 14.944
    learner:
      cur_lr: 0.0012640960048884153
      grad_gnorm: 39.99999237060547
      policy_entropy: 20.916452407836914
      policy_loss: 30.961257934570312
      var_gnorm: 43.67769241333008
      vf_explained_var: -0.08847570419311523
      vf_loss: 55.695098876953125
    num_steps_sampled: 1445000
    num_steps_trained: 1445000
    wait_time_ms: 101.101
  iterations_since_restore: 289
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 830
  policy_reward_mean: {}
  time_since_restore: 3710.143025159836
  time_this_iter_s: 11.713484525680542
  time_total_s: 3710.143025159836
  timestamp: 1593813516
  timesteps_since_restore: 1445000
  timesteps_this_iter: 5000
  timesteps_total: 1445000
  training_iteration: 289
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 14.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=830], 3710 s, 289 iter, 1445000 ts, 498 rew

agent-1: 104.0
agent-2: 104.0
agent-3: 107.0
agent-4: 63.0
agent-5: 81.0
Sum Reward: 459.0
Avg Reward: 91.8
Min Reward: 63.0
Gini Coefficient 0.09673202614379085
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_17-58-49
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 763.0
  episode_reward_mean: 497.62
  episode_reward_min: 290.0
  episodes_this_iter: 1
  episodes_total: 289
  experiment_id: f3470259fa9143609a5dd5049ba7f979
  hostname: gpu020
  info:
    apply_time_ms: 3.15
    dispatch_time_ms: 15.473
    learner:
      cur_lr: 0.0012637630570679903
      grad_gnorm: 40.0
      policy_entropy: 28.35331153869629
      policy_loss: -4.8675127029418945
      var_gnorm: 43.71427917480469
      vf_explained_var: 0.8277440071105957
      vf_loss: 18.310415267944336
    num_steps_sampled: 1450000
    num_steps_trained: 1450000
    wait_time_ms: 101.716
  iterations_since_restore: 290
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 830
  policy_reward_mean: {}
  time_since_restore: 3722.856732606888
  time_this_iter_s: 12.713707447052002
  time_total_s: 3722.856732606888
  timestamp: 1593813529
  timesteps_since_restore: 1450000
  timesteps_this_iter: 5000
  timesteps_total: 1450000
  training_iteration: 290
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 14.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=830], 3722 s, 290 iter, 1450000 ts, 498 rew

agent-1: 83.0
agent-2: 127.0
agent-3: 123.0
agent-4: 110.0
agent-5: 69.0
Sum Reward: 512.0
Avg Reward: 102.4
Min Reward: 69.0
Gini Coefficient 0.121875
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_17-59-01
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 763.0
  episode_reward_mean: 497.94
  episode_reward_min: 290.0
  episodes_this_iter: 1
  episodes_total: 290
  experiment_id: f3470259fa9143609a5dd5049ba7f979
  hostname: gpu020
  info:
    apply_time_ms: 4.13
    dispatch_time_ms: 10.613
    learner:
      cur_lr: 0.0012634299928322434
      grad_gnorm: 39.85165023803711
      policy_entropy: 35.17574691772461
      policy_loss: -8.945192337036133
      var_gnorm: 43.804298400878906
      vf_explained_var: 0.0
      vf_loss: 1.933771014213562
    num_steps_sampled: 1455000
    num_steps_trained: 1455000
    wait_time_ms: 105.142
  iterations_since_restore: 291
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 830
  policy_reward_mean: {}
  time_since_restore: 3734.686658143997
  time_this_iter_s: 11.829925537109375
  time_total_s: 3734.686658143997
  timestamp: 1593813541
  timesteps_since_restore: 1455000
  timesteps_this_iter: 5000
  timesteps_total: 1455000
  training_iteration: 291
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 14.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=830], 3734 s, 291 iter, 1455000 ts, 498 rew

agent-1: 104.0
agent-2: 112.0
agent-3: 108.0
agent-4: 97.0
agent-5: 108.0
Sum Reward: 529.0
Avg Reward: 105.8
Min Reward: 97.0
Gini Coefficient 0.02570888468809074
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_17-59-12
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 763.0
  episode_reward_mean: 498.22
  episode_reward_min: 290.0
  episodes_this_iter: 1
  episodes_total: 291
  experiment_id: f3470259fa9143609a5dd5049ba7f979
  hostname: gpu020
  info:
    apply_time_ms: 2.81
    dispatch_time_ms: 13.72
    learner:
      cur_lr: 0.0012630970450118184
      grad_gnorm: 40.0
      policy_entropy: 14.543931007385254
      policy_loss: -6.645562648773193
      var_gnorm: 43.778282165527344
      vf_explained_var: 0.6875313520431519
      vf_loss: 68.48477172851562
    num_steps_sampled: 1460000
    num_steps_trained: 1460000
    wait_time_ms: 103.244
  iterations_since_restore: 292
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 830
  policy_reward_mean: {}
  time_since_restore: 3746.1091735363007
  time_this_iter_s: 11.422515392303467
  time_total_s: 3746.1091735363007
  timestamp: 1593813552
  timesteps_since_restore: 1460000
  timesteps_this_iter: 5000
  timesteps_total: 1460000
  training_iteration: 292
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 14.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=830], 3746 s, 292 iter, 1460000 ts, 498 rew

agent-1: 128.0
agent-2: 114.0
agent-3: 181.0
agent-4: 152.0
agent-5: 158.0
Sum Reward: 733.0
Avg Reward: 146.6
Min Reward: 114.0
Gini Coefficient 0.08949522510231923
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_17-59-43
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 763.0
  episode_reward_mean: 500.2
  episode_reward_min: 290.0
  episodes_this_iter: 1
  episodes_total: 292
  experiment_id: f3470259fa9143609a5dd5049ba7f979
  hostname: gpu020
  info:
    apply_time_ms: 2.56
    dispatch_time_ms: 10.516
    learner:
      cur_lr: 0.0012627639807760715
      grad_gnorm: 34.796852111816406
      policy_entropy: 40.360050201416016
      policy_loss: -7.612171173095703
      var_gnorm: 43.87250900268555
      vf_explained_var: 0.0
      vf_loss: 1.1575839519500732
    num_steps_sampled: 1465000
    num_steps_trained: 1465000
    wait_time_ms: 112.482
  iterations_since_restore: 293
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 830
  policy_reward_mean: {}
  time_since_restore: 3776.7758333683014
  time_this_iter_s: 30.666659832000732
  time_total_s: 3776.7758333683014
  timestamp: 1593813583
  timesteps_since_restore: 1465000
  timesteps_this_iter: 5000
  timesteps_total: 1465000
  training_iteration: 293
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 14.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=830], 3776 s, 293 iter, 1465000 ts, 500 rew

agent-1: 77.0
agent-2: 62.0
agent-3: 67.0
agent-4: 59.0
agent-5: 50.0
Sum Reward: 315.0
Avg Reward: 63.0
Min Reward: 50.0
Gini Coefficient 0.07873015873015873
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_17-59-57
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 763.0
  episode_reward_mean: 496.74
  episode_reward_min: 290.0
  episodes_this_iter: 1
  episodes_total: 293
  experiment_id: f3470259fa9143609a5dd5049ba7f979
  hostname: gpu020
  info:
    apply_time_ms: 3.05
    dispatch_time_ms: 74.603
    learner:
      cur_lr: 0.0012624310329556465
      grad_gnorm: 40.0
      policy_entropy: 3.8339178562164307
      policy_loss: -1.3151286840438843
      var_gnorm: 43.866600036621094
      vf_explained_var: 0.24817544221878052
      vf_loss: 46.11933517456055
    num_steps_sampled: 1470000
    num_steps_trained: 1470000
    wait_time_ms: 65.5
  iterations_since_restore: 294
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 830
  policy_reward_mean: {}
  time_since_restore: 3791.130745410919
  time_this_iter_s: 14.354912042617798
  time_total_s: 3791.130745410919
  timestamp: 1593813597
  timesteps_since_restore: 1470000
  timesteps_this_iter: 5000
  timesteps_total: 1470000
  training_iteration: 294
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 14.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=830], 3791 s, 294 iter, 1470000 ts, 497 rew

agent-1: 72.0
agent-2: 125.0
agent-3: 151.0
agent-4: 105.0
agent-5: 100.0
Sum Reward: 553.0
Avg Reward: 110.6
Min Reward: 72.0
Gini Coefficient 0.13236889692585896
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_18-00-15
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 763.0
  episode_reward_mean: 498.13
  episode_reward_min: 290.0
  episodes_this_iter: 1
  episodes_total: 294
  experiment_id: f3470259fa9143609a5dd5049ba7f979
  hostname: gpu020
  info:
    apply_time_ms: 3.262
    dispatch_time_ms: 33.11
    learner:
      cur_lr: 0.0012620979687198997
      grad_gnorm: 38.63783645629883
      policy_entropy: 4.688873767852783
      policy_loss: -6.135917663574219
      var_gnorm: 43.873287200927734
      vf_explained_var: -1.0
      vf_loss: 58.94972610473633
    num_steps_sampled: 1475000
    num_steps_trained: 1475000
    wait_time_ms: 71.028
  iterations_since_restore: 295
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 830
  policy_reward_mean: {}
  time_since_restore: 3808.477135181427
  time_this_iter_s: 17.346389770507812
  time_total_s: 3808.477135181427
  timestamp: 1593813615
  timesteps_since_restore: 1475000
  timesteps_this_iter: 5000
  timesteps_total: 1475000
  training_iteration: 295
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 14.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=830], 3808 s, 295 iter, 1475000 ts, 498 rew

agent-1: 127.0
agent-2: 100.0
agent-3: 120.0
agent-4: 136.0
agent-5: 130.0
Sum Reward: 613.0
Avg Reward: 122.6
Min Reward: 100.0
Gini Coefficient 0.053507340946166396
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_18-00-28
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 763.0
  episode_reward_mean: 500.27
  episode_reward_min: 290.0
  episodes_this_iter: 1
  episodes_total: 295
  experiment_id: f3470259fa9143609a5dd5049ba7f979
  hostname: gpu020
  info:
    apply_time_ms: 4.115
    dispatch_time_ms: 59.925
    learner:
      cur_lr: 0.0012617650208994746
      grad_gnorm: 40.00000762939453
      policy_entropy: 6.425412178039551
      policy_loss: -2.0934529304504395
      var_gnorm: 43.921756744384766
      vf_explained_var: 0.26913899183273315
      vf_loss: 67.61748504638672
    num_steps_sampled: 1480000
    num_steps_trained: 1480000
    wait_time_ms: 50.935
  iterations_since_restore: 296
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 830
  policy_reward_mean: {}
  time_since_restore: 3821.917882204056
  time_this_iter_s: 13.440747022628784
  time_total_s: 3821.917882204056
  timestamp: 1593813628
  timesteps_since_restore: 1480000
  timesteps_this_iter: 5000
  timesteps_total: 1480000
  training_iteration: 296
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 14.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=830], 3821 s, 296 iter, 1480000 ts, 500 rew

agent-1: 104.0
agent-2: 72.0
agent-3: 108.0
agent-4: 105.0
agent-5: 88.0
Sum Reward: 477.0
Avg Reward: 95.4
Min Reward: 72.0
Gini Coefficient 0.07463312368972747
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_18-00-42
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 763.0
  episode_reward_mean: 498.61
  episode_reward_min: 290.0
  episodes_this_iter: 1
  episodes_total: 296
  experiment_id: f3470259fa9143609a5dd5049ba7f979
  hostname: gpu020
  info:
    apply_time_ms: 2.662
    dispatch_time_ms: 23.694
    learner:
      cur_lr: 0.0012614319566637278
      grad_gnorm: 39.99999237060547
      policy_entropy: 10.152536392211914
      policy_loss: 15.995610237121582
      var_gnorm: 44.0317497253418
      vf_explained_var: 0.8094900846481323
      vf_loss: 50.91679763793945
    num_steps_sampled: 1485000
    num_steps_trained: 1485000
    wait_time_ms: 87.398
  iterations_since_restore: 297
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 830
  policy_reward_mean: {}
  time_since_restore: 3836.2198536396027
  time_this_iter_s: 14.301971435546875
  time_total_s: 3836.2198536396027
  timestamp: 1593813642
  timesteps_since_restore: 1485000
  timesteps_this_iter: 5000
  timesteps_total: 1485000
  training_iteration: 297
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 14.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=830], 3836 s, 297 iter, 1485000 ts, 499 rew

agent-1: 109.0
agent-2: 86.0
agent-3: 142.0
agent-4: 100.0
agent-5: 86.0
Sum Reward: 523.0
Avg Reward: 104.6
Min Reward: 86.0
Gini Coefficient 0.10325047801147227
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_18-00-54
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 763.0
  episode_reward_mean: 499.77
  episode_reward_min: 290.0
  episodes_this_iter: 1
  episodes_total: 297
  experiment_id: f3470259fa9143609a5dd5049ba7f979
  hostname: gpu020
  info:
    apply_time_ms: 2.899
    dispatch_time_ms: 15.968
    learner:
      cur_lr: 0.0012610990088433027
      grad_gnorm: 40.0
      policy_entropy: 13.633755683898926
      policy_loss: 10.4179105758667
      var_gnorm: 44.07420349121094
      vf_explained_var: 0.8928846120834351
      vf_loss: 54.16109085083008
    num_steps_sampled: 1490000
    num_steps_trained: 1490000
    wait_time_ms: 100.272
  iterations_since_restore: 298
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 830
  policy_reward_mean: {}
  time_since_restore: 3848.00279378891
  time_this_iter_s: 11.782940149307251
  time_total_s: 3848.00279378891
  timestamp: 1593813654
  timesteps_since_restore: 1490000
  timesteps_this_iter: 5000
  timesteps_total: 1490000
  training_iteration: 298
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 14.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=830], 3848 s, 298 iter, 1490000 ts, 500 rew

agent-1: 93.0
agent-2: 156.0
agent-3: 94.0
agent-4: 159.0
agent-5: 84.0
Sum Reward: 586.0
Avg Reward: 117.2
Min Reward: 84.0
Gini Coefficient 0.1453924914675768
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_18-01-06
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 763.0
  episode_reward_mean: 500.77
  episode_reward_min: 290.0
  episodes_this_iter: 1
  episodes_total: 298
  experiment_id: f3470259fa9143609a5dd5049ba7f979
  hostname: gpu020
  info:
    apply_time_ms: 2.485
    dispatch_time_ms: 7.386
    learner:
      cur_lr: 0.0012607659446075559
      grad_gnorm: 40.000003814697266
      policy_entropy: 15.522177696228027
      policy_loss: 27.847829818725586
      var_gnorm: 44.15401077270508
      vf_explained_var: 0.7217967510223389
      vf_loss: 103.37086486816406
    num_steps_sampled: 1495000
    num_steps_trained: 1495000
    wait_time_ms: 100.773
  iterations_since_restore: 299
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 830
  policy_reward_mean: {}
  time_since_restore: 3859.39990568161
  time_this_iter_s: 11.397111892700195
  time_total_s: 3859.39990568161
  timestamp: 1593813666
  timesteps_since_restore: 1495000
  timesteps_this_iter: 5000
  timesteps_total: 1495000
  training_iteration: 299
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 14.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=830], 3859 s, 299 iter, 1495000 ts, 501 rew

agent-1: 179.0
agent-2: 106.0
agent-3: 102.0
agent-4: 76.0
agent-5: 145.0
Sum Reward: 608.0
Avg Reward: 121.6
Min Reward: 76.0
Gini Coefficient 0.16381578947368422
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_18-01-17
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 763.0
  episode_reward_mean: 502.83
  episode_reward_min: 290.0
  episodes_this_iter: 1
  episodes_total: 299
  experiment_id: f3470259fa9143609a5dd5049ba7f979
  hostname: gpu020
  info:
    apply_time_ms: 2.657
    dispatch_time_ms: 7.376
    learner:
      cur_lr: 0.0012604329967871308
      grad_gnorm: 40.00000762939453
      policy_entropy: 21.463611602783203
      policy_loss: 7.474454879760742
      var_gnorm: 44.21485137939453
      vf_explained_var: 0.6755623817443848
      vf_loss: 47.44709777832031
    num_steps_sampled: 1500000
    num_steps_trained: 1500000
    wait_time_ms: 104.029
  iterations_since_restore: 300
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 830
  policy_reward_mean: {}
  time_since_restore: 3870.853484392166
  time_this_iter_s: 11.45357871055603
  time_total_s: 3870.853484392166
  timestamp: 1593813677
  timesteps_since_restore: 1500000
  timesteps_this_iter: 5000
  timesteps_total: 1500000
  training_iteration: 300
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 14.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=830], 3870 s, 300 iter, 1500000 ts, 503 rew

agent-1: 152.0
agent-2: 153.0
agent-3: 81.0
agent-4: 96.0
agent-5: 129.0
Sum Reward: 611.0
Avg Reward: 122.2
Min Reward: 81.0
Gini Coefficient 0.1309328968903437
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_18-01-28
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 763.0
  episode_reward_mean: 503.72
  episode_reward_min: 290.0
  episodes_this_iter: 1
  episodes_total: 300
  experiment_id: f3470259fa9143609a5dd5049ba7f979
  hostname: gpu020
  info:
    apply_time_ms: 2.683
    dispatch_time_ms: 20.537
    learner:
      cur_lr: 0.0012601000489667058
      grad_gnorm: 39.999996185302734
      policy_entropy: 43.28717041015625
      policy_loss: -0.551193356513977
      var_gnorm: 44.313568115234375
      vf_explained_var: 0.46515321731567383
      vf_loss: 31.63351058959961
    num_steps_sampled: 1505000
    num_steps_trained: 1505000
    wait_time_ms: 48.735
  iterations_since_restore: 301
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 830
  policy_reward_mean: {}
  time_since_restore: 3881.946951150894
  time_this_iter_s: 11.093466758728027
  time_total_s: 3881.946951150894
  timestamp: 1593813688
  timesteps_since_restore: 1505000
  timesteps_this_iter: 5000
  timesteps_total: 1505000
  training_iteration: 301
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 14.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=830], 3881 s, 301 iter, 1505000 ts, 504 rew

agent-1: 90.0
agent-2: 152.0
agent-3: 112.0
agent-4: 88.0
agent-5: 101.0
Sum Reward: 543.0
Avg Reward: 108.6
Min Reward: 88.0
Gini Coefficient 0.11049723756906077
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_18-01-39
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 763.0
  episode_reward_mean: 502.13
  episode_reward_min: 290.0
  episodes_this_iter: 1
  episodes_total: 301
  experiment_id: f3470259fa9143609a5dd5049ba7f979
  hostname: gpu020
  info:
    apply_time_ms: 4.217
    dispatch_time_ms: 9.982
    learner:
      cur_lr: 0.001259766984730959
      grad_gnorm: 40.0
      policy_entropy: 49.77915573120117
      policy_loss: 20.530485153198242
      var_gnorm: 44.387420654296875
      vf_explained_var: 0.582210898399353
      vf_loss: 45.7084846496582
    num_steps_sampled: 1510000
    num_steps_trained: 1510000
    wait_time_ms: 93.524
  iterations_since_restore: 302
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 830
  policy_reward_mean: {}
  time_since_restore: 3892.783416748047
  time_this_iter_s: 10.83646559715271
  time_total_s: 3892.783416748047
  timestamp: 1593813699
  timesteps_since_restore: 1510000
  timesteps_this_iter: 5000
  timesteps_total: 1510000
  training_iteration: 302
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 14.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=830], 3892 s, 302 iter, 1510000 ts, 502 rew

agent-1: 103.0
agent-2: 174.0
agent-3: 150.0
agent-4: 110.0
agent-5: 155.0
Sum Reward: 692.0
Avg Reward: 138.4
Min Reward: 103.0
Gini Coefficient 0.10809248554913295
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_18-01-50
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 763.0
  episode_reward_mean: 504.74
  episode_reward_min: 290.0
  episodes_this_iter: 1
  episodes_total: 302
  experiment_id: f3470259fa9143609a5dd5049ba7f979
  hostname: gpu020
  info:
    apply_time_ms: 3.373
    dispatch_time_ms: 17.602
    learner:
      cur_lr: 0.001259434036910534
      grad_gnorm: 39.999996185302734
      policy_entropy: 40.20090866088867
      policy_loss: -36.332115173339844
      var_gnorm: 44.43895721435547
      vf_explained_var: -0.41487014293670654
      vf_loss: 90.26832580566406
    num_steps_sampled: 1515000
    num_steps_trained: 1515000
    wait_time_ms: 84.462
  iterations_since_restore: 303
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 830
  policy_reward_mean: {}
  time_since_restore: 3903.710292339325
  time_this_iter_s: 10.926875591278076
  time_total_s: 3903.710292339325
  timestamp: 1593813710
  timesteps_since_restore: 1515000
  timesteps_this_iter: 5000
  timesteps_total: 1515000
  training_iteration: 303
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 14.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=830], 3903 s, 303 iter, 1515000 ts, 505 rew

agent-1: 170.0
agent-2: 137.0
agent-3: 149.0
agent-4: 145.0
agent-5: 138.0
Sum Reward: 739.0
Avg Reward: 147.8
Min Reward: 137.0
Gini Coefficient 0.041677943166441134
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_18-02-02
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 763.0
  episode_reward_mean: 507.63
  episode_reward_min: 290.0
  episodes_this_iter: 1
  episodes_total: 303
  experiment_id: f3470259fa9143609a5dd5049ba7f979
  hostname: gpu020
  info:
    apply_time_ms: 3.109
    dispatch_time_ms: 19.802
    learner:
      cur_lr: 0.001259100972674787
      grad_gnorm: 40.0
      policy_entropy: 35.21247482299805
      policy_loss: 3.187345504760742
      var_gnorm: 44.42219924926758
      vf_explained_var: 0.8695843815803528
      vf_loss: 37.80613327026367
    num_steps_sampled: 1520000
    num_steps_trained: 1520000
    wait_time_ms: 94.586
  iterations_since_restore: 304
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 830
  policy_reward_mean: {}
  time_since_restore: 3915.1415066719055
  time_this_iter_s: 11.431214332580566
  time_total_s: 3915.1415066719055
  timestamp: 1593813722
  timesteps_since_restore: 1520000
  timesteps_this_iter: 5000
  timesteps_total: 1520000
  training_iteration: 304
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 14.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=830], 3915 s, 304 iter, 1520000 ts, 508 rew

agent-1: 142.0
agent-2: 178.0
agent-3: 117.0
agent-4: 112.0
agent-5: 83.0
Sum Reward: 632.0
Avg Reward: 126.4
Min Reward: 83.0
Gini Coefficient 0.13924050632911392
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_18-02-13
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 763.0
  episode_reward_mean: 510.7
  episode_reward_min: 290.0
  episodes_this_iter: 1
  episodes_total: 304
  experiment_id: f3470259fa9143609a5dd5049ba7f979
  hostname: gpu020
  info:
    apply_time_ms: 4.206
    dispatch_time_ms: 27.748
    learner:
      cur_lr: 0.001258768024854362
      grad_gnorm: 39.99998474121094
      policy_entropy: 33.46440505981445
      policy_loss: -8.037463188171387
      var_gnorm: 44.44338607788086
      vf_explained_var: 0.28101497888565063
      vf_loss: 24.097620010375977
    num_steps_sampled: 1525000
    num_steps_trained: 1525000
    wait_time_ms: 46.545
  iterations_since_restore: 305
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 830
  policy_reward_mean: {}
  time_since_restore: 3926.6110343933105
  time_this_iter_s: 11.46952772140503
  time_total_s: 3926.6110343933105
  timestamp: 1593813733
  timesteps_since_restore: 1525000
  timesteps_this_iter: 5000
  timesteps_total: 1525000
  training_iteration: 305
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 14.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=830], 3926 s, 305 iter, 1525000 ts, 511 rew

agent-1: 154.0
agent-2: 139.0
agent-3: 64.0
agent-4: 101.0
agent-5: 106.0
Sum Reward: 564.0
Avg Reward: 112.8
Min Reward: 64.0
Gini Coefficient 0.15460992907801419
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_18-02-25
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 763.0
  episode_reward_mean: 512.5
  episode_reward_min: 290.0
  episodes_this_iter: 1
  episodes_total: 305
  experiment_id: f3470259fa9143609a5dd5049ba7f979
  hostname: gpu020
  info:
    apply_time_ms: 3.701
    dispatch_time_ms: 18.152
    learner:
      cur_lr: 0.0012584349606186152
      grad_gnorm: 39.99998474121094
      policy_entropy: 41.51462936401367
      policy_loss: 9.788472175598145
      var_gnorm: 44.495548248291016
      vf_explained_var: 0.47132086753845215
      vf_loss: 60.377437591552734
    num_steps_sampled: 1530000
    num_steps_trained: 1530000
    wait_time_ms: 100.372
  iterations_since_restore: 306
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 830
  policy_reward_mean: {}
  time_since_restore: 3938.461663007736
  time_this_iter_s: 11.85062861442566
  time_total_s: 3938.461663007736
  timestamp: 1593813745
  timesteps_since_restore: 1530000
  timesteps_this_iter: 5000
  timesteps_total: 1530000
  training_iteration: 306
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 14.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=830], 3938 s, 306 iter, 1530000 ts, 512 rew

agent-1: 91.0
agent-2: 79.0
agent-3: 83.0
agent-4: 81.0
agent-5: 121.0
Sum Reward: 455.0
Avg Reward: 91.0
Min Reward: 79.0
Gini Coefficient 0.08263736263736264
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_18-02-36
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 763.0
  episode_reward_mean: 512.22
  episode_reward_min: 290.0
  episodes_this_iter: 1
  episodes_total: 306
  experiment_id: f3470259fa9143609a5dd5049ba7f979
  hostname: gpu020
  info:
    apply_time_ms: 3.41
    dispatch_time_ms: 12.254
    learner:
      cur_lr: 0.0012581020127981901
      grad_gnorm: 40.0
      policy_entropy: 35.25476837158203
      policy_loss: 13.78124713897705
      var_gnorm: 44.53240203857422
      vf_explained_var: 0.07104307413101196
      vf_loss: 30.738645553588867
    num_steps_sampled: 1535000
    num_steps_trained: 1535000
    wait_time_ms: 101.305
  iterations_since_restore: 307
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 830
  policy_reward_mean: {}
  time_since_restore: 3949.833864927292
  time_this_iter_s: 11.372201919555664
  time_total_s: 3949.833864927292
  timestamp: 1593813756
  timesteps_since_restore: 1535000
  timesteps_this_iter: 5000
  timesteps_total: 1535000
  training_iteration: 307
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 14.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=830], 3949 s, 307 iter, 1535000 ts, 512 rew

agent-1: 106.0
agent-2: 103.0
agent-3: 161.0
agent-4: 109.0
agent-5: 122.0
Sum Reward: 601.0
Avg Reward: 120.2
Min Reward: 103.0
Gini Coefficient 0.08785357737104825
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_18-02-49
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 763.0
  episode_reward_mean: 513.04
  episode_reward_min: 290.0
  episodes_this_iter: 1
  episodes_total: 307
  experiment_id: f3470259fa9143609a5dd5049ba7f979
  hostname: gpu020
  info:
    apply_time_ms: 2.657
    dispatch_time_ms: 57.999
    learner:
      cur_lr: 0.0012577689485624433
      grad_gnorm: 40.000003814697266
      policy_entropy: 12.353391647338867
      policy_loss: 8.106578826904297
      var_gnorm: 44.553672790527344
      vf_explained_var: 0.22445225715637207
      vf_loss: 23.392044067382812
    num_steps_sampled: 1540000
    num_steps_trained: 1540000
    wait_time_ms: 43.257
  iterations_since_restore: 308
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 830
  policy_reward_mean: {}
  time_since_restore: 3962.055737018585
  time_this_iter_s: 12.221872091293335
  time_total_s: 3962.055737018585
  timestamp: 1593813769
  timesteps_since_restore: 1540000
  timesteps_this_iter: 5000
  timesteps_total: 1540000
  training_iteration: 308
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 14.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=830], 3962 s, 308 iter, 1540000 ts, 513 rew

agent-1: 133.0
agent-2: 128.0
agent-3: 123.0
agent-4: 118.0
agent-5: 117.0
Sum Reward: 619.0
Avg Reward: 123.8
Min Reward: 117.0
Gini Coefficient 0.027140549273021
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_18-03-00
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 763.0
  episode_reward_mean: 515.2
  episode_reward_min: 290.0
  episodes_this_iter: 1
  episodes_total: 308
  experiment_id: f3470259fa9143609a5dd5049ba7f979
  hostname: gpu020
  info:
    apply_time_ms: 3.806
    dispatch_time_ms: 20.919
    learner:
      cur_lr: 0.0012574360007420182
      grad_gnorm: 26.08102035522461
      policy_entropy: 30.230194091796875
      policy_loss: -3.9433741569519043
      var_gnorm: 44.645606994628906
      vf_explained_var: 0.5069165229797363
      vf_loss: 3.292513847351074
    num_steps_sampled: 1545000
    num_steps_trained: 1545000
    wait_time_ms: 94.754
  iterations_since_restore: 309
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 830
  policy_reward_mean: {}
  time_since_restore: 3973.15624666214
  time_this_iter_s: 11.100509643554688
  time_total_s: 3973.15624666214
  timestamp: 1593813780
  timesteps_since_restore: 1545000
  timesteps_this_iter: 5000
  timesteps_total: 1545000
  training_iteration: 309
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 14.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=830], 3973 s, 309 iter, 1545000 ts, 515 rew

agent-1: 142.0
agent-2: 98.0
agent-3: 127.0
agent-4: 130.0
agent-5: 100.0
Sum Reward: 597.0
Avg Reward: 119.4
Min Reward: 98.0
Gini Coefficient 0.07906197654941373
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_18-03-11
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 763.0
  episode_reward_mean: 516.91
  episode_reward_min: 290.0
  episodes_this_iter: 1
  episodes_total: 309
  experiment_id: f3470259fa9143609a5dd5049ba7f979
  hostname: gpu020
  info:
    apply_time_ms: 3.61
    dispatch_time_ms: 10.448
    learner:
      cur_lr: 0.0012571030529215932
      grad_gnorm: 15.782543182373047
      policy_entropy: 32.76961135864258
      policy_loss: -6.308650016784668
      var_gnorm: 44.625083923339844
      vf_explained_var: 0.194408118724823
      vf_loss: 8.26368522644043
    num_steps_sampled: 1550000
    num_steps_trained: 1550000
    wait_time_ms: 97.229
  iterations_since_restore: 310
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 830
  policy_reward_mean: {}
  time_since_restore: 3984.7288715839386
  time_this_iter_s: 11.572624921798706
  time_total_s: 3984.7288715839386
  timestamp: 1593813791
  timesteps_since_restore: 1550000
  timesteps_this_iter: 5000
  timesteps_total: 1550000
  training_iteration: 310
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 14.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=830], 3984 s, 310 iter, 1550000 ts, 517 rew

agent-1: 80.0
agent-2: 98.0
agent-3: 81.0
agent-4: 99.0
agent-5: 96.0
Sum Reward: 454.0
Avg Reward: 90.8
Min Reward: 80.0
Gini Coefficient 0.048458149779735685
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_18-03-24
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 763.0
  episode_reward_mean: 517.6
  episode_reward_min: 290.0
  episodes_this_iter: 1
  episodes_total: 310
  experiment_id: f3470259fa9143609a5dd5049ba7f979
  hostname: gpu020
  info:
    apply_time_ms: 3.177
    dispatch_time_ms: 12.726
    learner:
      cur_lr: 0.0012567699886858463
      grad_gnorm: 40.000030517578125
      policy_entropy: 27.680259704589844
      policy_loss: 2.3342666625976562
      var_gnorm: 44.59899139404297
      vf_explained_var: 0.49021196365356445
      vf_loss: 63.426883697509766
    num_steps_sampled: 1555000
    num_steps_trained: 1555000
    wait_time_ms: 106.111
  iterations_since_restore: 311
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 830
  policy_reward_mean: {}
  time_since_restore: 3996.998440027237
  time_this_iter_s: 12.26956844329834
  time_total_s: 3996.998440027237
  timestamp: 1593813804
  timesteps_since_restore: 1555000
  timesteps_this_iter: 5000
  timesteps_total: 1555000
  training_iteration: 311
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 14.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=830], 3996 s, 311 iter, 1555000 ts, 518 rew

agent-1: 88.0
agent-2: 113.0
agent-3: 90.0
agent-4: 106.0
agent-5: 111.0
Sum Reward: 508.0
Avg Reward: 101.6
Min Reward: 88.0
Gini Coefficient 0.05590551181102362
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_18-03-37
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 763.0
  episode_reward_mean: 519.5
  episode_reward_min: 290.0
  episodes_this_iter: 1
  episodes_total: 311
  experiment_id: f3470259fa9143609a5dd5049ba7f979
  hostname: gpu020
  info:
    apply_time_ms: 3.012
    dispatch_time_ms: 12.303
    learner:
      cur_lr: 0.0012564370408654213
      grad_gnorm: 29.980693817138672
      policy_entropy: 31.42391014099121
      policy_loss: -1.8427557945251465
      var_gnorm: 44.6829833984375
      vf_explained_var: 0.13884776830673218
      vf_loss: 1.978581428527832
    num_steps_sampled: 1560000
    num_steps_trained: 1560000
    wait_time_ms: 108.046
  iterations_since_restore: 312
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 830
  policy_reward_mean: {}
  time_since_restore: 4010.4291937351227
  time_this_iter_s: 13.430753707885742
  time_total_s: 4010.4291937351227
  timestamp: 1593813817
  timesteps_since_restore: 1560000
  timesteps_this_iter: 5000
  timesteps_total: 1560000
  training_iteration: 312
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 14.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=830], 4010 s, 312 iter, 1560000 ts, 520 rew

agent-1: 97.0
agent-2: 78.0
agent-3: 97.0
agent-4: 74.0
agent-5: 89.0
Sum Reward: 435.0
Avg Reward: 87.0
Min Reward: 74.0
Gini Coefficient 0.059770114942528735
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_18-03-49
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 763.0
  episode_reward_mean: 519.99
  episode_reward_min: 290.0
  episodes_this_iter: 1
  episodes_total: 312
  experiment_id: f3470259fa9143609a5dd5049ba7f979
  hostname: gpu020
  info:
    apply_time_ms: 3.704
    dispatch_time_ms: 14.824
    learner:
      cur_lr: 0.0012561039766296744
      grad_gnorm: 40.0
      policy_entropy: 20.02660369873047
      policy_loss: 0.528573751449585
      var_gnorm: 44.7045783996582
      vf_explained_var: 0.6899189949035645
      vf_loss: 73.41206359863281
    num_steps_sampled: 1565000
    num_steps_trained: 1565000
    wait_time_ms: 101.033
  iterations_since_restore: 313
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 830
  policy_reward_mean: {}
  time_since_restore: 4021.992623567581
  time_this_iter_s: 11.563429832458496
  time_total_s: 4021.992623567581
  timestamp: 1593813829
  timesteps_since_restore: 1565000
  timesteps_this_iter: 5000
  timesteps_total: 1565000
  training_iteration: 313
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 14.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=830], 4021 s, 313 iter, 1565000 ts, 520 rew

agent-1: 124.0
agent-2: 99.0
agent-3: 146.0
agent-4: 118.0
agent-5: 96.0
Sum Reward: 583.0
Avg Reward: 116.6
Min Reward: 96.0
Gini Coefficient 0.08576329331046312
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_18-04-06
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 763.0
  episode_reward_mean: 521.57
  episode_reward_min: 290.0
  episodes_this_iter: 1
  episodes_total: 313
  experiment_id: f3470259fa9143609a5dd5049ba7f979
  hostname: gpu020
  info:
    apply_time_ms: 3.352
    dispatch_time_ms: 97.613
    learner:
      cur_lr: 0.0012557710288092494
      grad_gnorm: 39.999996185302734
      policy_entropy: 9.594785690307617
      policy_loss: -3.9252688884735107
      var_gnorm: 44.778385162353516
      vf_explained_var: 0.6023427844047546
      vf_loss: 71.04743194580078
    num_steps_sampled: 1570000
    num_steps_trained: 1570000
    wait_time_ms: 368.177
  iterations_since_restore: 314
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 830
  policy_reward_mean: {}
  time_since_restore: 4038.8069896698
  time_this_iter_s: 16.814366102218628
  time_total_s: 4038.8069896698
  timestamp: 1593813846
  timesteps_since_restore: 1570000
  timesteps_this_iter: 5000
  timesteps_total: 1570000
  training_iteration: 314
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 14.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=830], 4038 s, 314 iter, 1570000 ts, 522 rew

agent-1: 83.0
agent-2: 79.0
agent-3: 66.0
agent-4: 111.0
agent-5: 95.0
Sum Reward: 434.0
Avg Reward: 86.8
Min Reward: 66.0
Gini Coefficient 0.09769585253456221
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_18-04-16
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 763.0
  episode_reward_mean: 520.67
  episode_reward_min: 290.0
  episodes_this_iter: 1
  episodes_total: 314
  experiment_id: f3470259fa9143609a5dd5049ba7f979
  hostname: gpu020
  info:
    apply_time_ms: 2.784
    dispatch_time_ms: 16.645
    learner:
      cur_lr: 0.0012554379645735025
      grad_gnorm: 17.791257858276367
      policy_entropy: 24.473262786865234
      policy_loss: 0.7843600511550903
      var_gnorm: 44.79869079589844
      vf_explained_var: -0.019367337226867676
      vf_loss: 4.306479454040527
    num_steps_sampled: 1575000
    num_steps_trained: 1575000
    wait_time_ms: 99.003
  iterations_since_restore: 315
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 830
  policy_reward_mean: {}
  time_since_restore: 4049.6190388202667
  time_this_iter_s: 10.812049150466919
  time_total_s: 4049.6190388202667
  timestamp: 1593813856
  timesteps_since_restore: 1575000
  timesteps_this_iter: 5000
  timesteps_total: 1575000
  training_iteration: 315
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 14.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=830], 4049 s, 315 iter, 1575000 ts, 521 rew

agent-1: 70.0
agent-2: 108.0
agent-3: 109.0
agent-4: 91.0
agent-5: 76.0
Sum Reward: 454.0
Avg Reward: 90.8
Min Reward: 70.0
Gini Coefficient 0.09691629955947137
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_18-04-28
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 763.0
  episode_reward_mean: 520.17
  episode_reward_min: 290.0
  episodes_this_iter: 1
  episodes_total: 315
  experiment_id: f3470259fa9143609a5dd5049ba7f979
  hostname: gpu020
  info:
    apply_time_ms: 3.985
    dispatch_time_ms: 10.806
    learner:
      cur_lr: 0.0012551050167530775
      grad_gnorm: 40.0000114440918
      policy_entropy: 8.649981498718262
      policy_loss: 6.605199813842773
      var_gnorm: 44.835811614990234
      vf_explained_var: 0.9207656979560852
      vf_loss: 39.08836364746094
    num_steps_sampled: 1580000
    num_steps_trained: 1580000
    wait_time_ms: 91.413
  iterations_since_restore: 316
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 830
  policy_reward_mean: {}
  time_since_restore: 4061.5122816562653
  time_this_iter_s: 11.893242835998535
  time_total_s: 4061.5122816562653
  timestamp: 1593813868
  timesteps_since_restore: 1580000
  timesteps_this_iter: 5000
  timesteps_total: 1580000
  training_iteration: 316
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 14.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=830], 4061 s, 316 iter, 1580000 ts, 520 rew

agent-1: 86.0
agent-2: 79.0
agent-3: 84.0
agent-4: 91.0
agent-5: 82.0
Sum Reward: 422.0
Avg Reward: 84.4
Min Reward: 79.0
Gini Coefficient 0.026540284360189573
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_18-04-55
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 763.0
  episode_reward_mean: 520.82
  episode_reward_min: 290.0
  episodes_this_iter: 1
  episodes_total: 316
  experiment_id: f3470259fa9143609a5dd5049ba7f979
  hostname: gpu020
  info:
    apply_time_ms: 2.687
    dispatch_time_ms: 6.714
    learner:
      cur_lr: 0.0012547719525173306
      grad_gnorm: 39.999996185302734
      policy_entropy: 15.911493301391602
      policy_loss: -33.39207458496094
      var_gnorm: 44.88054275512695
      vf_explained_var: 0.8841071128845215
      vf_loss: 61.428810119628906
    num_steps_sampled: 1585000
    num_steps_trained: 1585000
    wait_time_ms: 107.342
  iterations_since_restore: 317
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 830
  policy_reward_mean: {}
  time_since_restore: 4087.73575258255
  time_this_iter_s: 26.22347092628479
  time_total_s: 4087.73575258255
  timestamp: 1593813895
  timesteps_since_restore: 1585000
  timesteps_this_iter: 5000
  timesteps_total: 1585000
  training_iteration: 317
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 14.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=830], 4087 s, 317 iter, 1585000 ts, 521 rew

agent-1: 88.0
agent-2: 57.0
agent-3: 109.0
agent-4: 102.0
agent-5: 89.0
Sum Reward: 445.0
Avg Reward: 89.0
Min Reward: 57.0
Gini Coefficient 0.10606741573033708
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_18-05-18
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 763.0
  episode_reward_mean: 521.33
  episode_reward_min: 290.0
  episodes_this_iter: 1
  episodes_total: 317
  experiment_id: f3470259fa9143609a5dd5049ba7f979
  hostname: gpu020
  info:
    apply_time_ms: 3.012
    dispatch_time_ms: 274.11
    learner:
      cur_lr: 0.0012544390046969056
      grad_gnorm: 40.0
      policy_entropy: 7.484999179840088
      policy_loss: 15.197787284851074
      var_gnorm: 44.98067092895508
      vf_explained_var: -1.0
      vf_loss: 259.6349182128906
    num_steps_sampled: 1590000
    num_steps_trained: 1590000
    wait_time_ms: 281.399
  iterations_since_restore: 318
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 830
  policy_reward_mean: {}
  time_since_restore: 4111.440546035767
  time_this_iter_s: 23.704793453216553
  time_total_s: 4111.440546035767
  timestamp: 1593813918
  timesteps_since_restore: 1590000
  timesteps_this_iter: 5000
  timesteps_total: 1590000
  training_iteration: 318
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 14.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=830], 4111 s, 318 iter, 1590000 ts, 521 rew

agent-1: 133.0
agent-2: 79.0
agent-3: 132.0
agent-4: 74.0
agent-5: 70.0
Sum Reward: 488.0
Avg Reward: 97.6
Min Reward: 70.0
Gini Coefficient 0.15081967213114755
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_18-05-36
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 763.0
  episode_reward_mean: 522.47
  episode_reward_min: 290.0
  episodes_this_iter: 1
  episodes_total: 318
  experiment_id: f3470259fa9143609a5dd5049ba7f979
  hostname: gpu020
  info:
    apply_time_ms: 3.757
    dispatch_time_ms: 39.281
    learner:
      cur_lr: 0.0012541060568764806
      grad_gnorm: 40.0
      policy_entropy: 25.46803855895996
      policy_loss: -10.774782180786133
      var_gnorm: 44.967987060546875
      vf_explained_var: 0.3915380835533142
      vf_loss: 6.4722676277160645
    num_steps_sampled: 1595000
    num_steps_trained: 1595000
    wait_time_ms: 191.188
  iterations_since_restore: 319
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 830
  policy_reward_mean: {}
  time_since_restore: 4128.399641990662
  time_this_iter_s: 16.95909595489502
  time_total_s: 4128.399641990662
  timestamp: 1593813936
  timesteps_since_restore: 1595000
  timesteps_this_iter: 5000
  timesteps_total: 1595000
  training_iteration: 319
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 14.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=830], 4128 s, 319 iter, 1595000 ts, 522 rew

agent-1: 85.0
agent-2: 111.0
agent-3: 153.0
agent-4: 97.0
agent-5: 105.0
Sum Reward: 551.0
Avg Reward: 110.2
Min Reward: 85.0
Gini Coefficient 0.1088929219600726
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_18-05-52
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 763.0
  episode_reward_mean: 524.56
  episode_reward_min: 290.0
  episodes_this_iter: 1
  episodes_total: 319
  experiment_id: f3470259fa9143609a5dd5049ba7f979
  hostname: gpu020
  info:
    apply_time_ms: 3.434
    dispatch_time_ms: 16.112
    learner:
      cur_lr: 0.0012537729926407337
      grad_gnorm: 40.000003814697266
      policy_entropy: 12.669097900390625
      policy_loss: 3.878641366958618
      var_gnorm: 44.969512939453125
      vf_explained_var: 0.8662227392196655
      vf_loss: 78.76100158691406
    num_steps_sampled: 1600000
    num_steps_trained: 1600000
    wait_time_ms: 71.748
  iterations_since_restore: 320
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 830
  policy_reward_mean: {}
  time_since_restore: 4144.305004358292
  time_this_iter_s: 15.905362367630005
  time_total_s: 4144.305004358292
  timestamp: 1593813952
  timesteps_since_restore: 1600000
  timesteps_this_iter: 5000
  timesteps_total: 1600000
  training_iteration: 320
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 14.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=830], 4144 s, 320 iter, 1600000 ts, 525 rew

agent-1: 199.0
agent-2: 44.0
agent-3: 58.0
agent-4: 146.0
agent-5: 141.0
Sum Reward: 588.0
Avg Reward: 117.6
Min Reward: 44.0
Gini Coefficient 0.2707482993197279
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_18-06-09
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 763.0
  episode_reward_mean: 526.85
  episode_reward_min: 290.0
  episodes_this_iter: 1
  episodes_total: 320
  experiment_id: f3470259fa9143609a5dd5049ba7f979
  hostname: gpu020
  info:
    apply_time_ms: 5.252
    dispatch_time_ms: 18.238
    learner:
      cur_lr: 0.0012534400448203087
      grad_gnorm: 21.830692291259766
      policy_entropy: 34.67051315307617
      policy_loss: -3.0536460876464844
      var_gnorm: 45.06165313720703
      vf_explained_var: 0.5205455422401428
      vf_loss: 63.42435836791992
    num_steps_sampled: 1605000
    num_steps_trained: 1605000
    wait_time_ms: 28.759
  iterations_since_restore: 321
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 830
  policy_reward_mean: {}
  time_since_restore: 4161.387894630432
  time_this_iter_s: 17.082890272140503
  time_total_s: 4161.387894630432
  timestamp: 1593813969
  timesteps_since_restore: 1605000
  timesteps_this_iter: 5000
  timesteps_total: 1605000
  training_iteration: 321
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 14.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=830], 4161 s, 321 iter, 1605000 ts, 527 rew

agent-1: 146.0
agent-2: 103.0
agent-3: 127.0
agent-4: 109.0
agent-5: 88.0
Sum Reward: 573.0
Avg Reward: 114.6
Min Reward: 88.0
Gini Coefficient 0.09773123909249563
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_18-06-21
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 763.0
  episode_reward_mean: 529.0
  episode_reward_min: 290.0
  episodes_this_iter: 1
  episodes_total: 321
  experiment_id: f3470259fa9143609a5dd5049ba7f979
  hostname: gpu020
  info:
    apply_time_ms: 2.649
    dispatch_time_ms: 16.707
    learner:
      cur_lr: 0.0012531069805845618
      grad_gnorm: 40.0
      policy_entropy: 53.443294525146484
      policy_loss: -12.70572280883789
      var_gnorm: 45.20756149291992
      vf_explained_var: -1.0
      vf_loss: 4.388683795928955
    num_steps_sampled: 1610000
    num_steps_trained: 1610000
    wait_time_ms: 89.328
  iterations_since_restore: 322
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 830
  policy_reward_mean: {}
  time_since_restore: 4172.746607065201
  time_this_iter_s: 11.358712434768677
  time_total_s: 4172.746607065201
  timestamp: 1593813981
  timesteps_since_restore: 1610000
  timesteps_this_iter: 5000
  timesteps_total: 1610000
  training_iteration: 322
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 14.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=830], 4172 s, 322 iter, 1610000 ts, 529 rew

agent-1: 93.0
agent-2: 137.0
agent-3: 99.0
agent-4: 130.0
agent-5: 100.0
Sum Reward: 559.0
Avg Reward: 111.8
Min Reward: 93.0
Gini Coefficient 0.0851520572450805
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_18-06-32
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 763.0
  episode_reward_mean: 530.34
  episode_reward_min: 290.0
  episodes_this_iter: 1
  episodes_total: 322
  experiment_id: f3470259fa9143609a5dd5049ba7f979
  hostname: gpu020
  info:
    apply_time_ms: 3.914
    dispatch_time_ms: 11.171
    learner:
      cur_lr: 0.0012527740327641368
      grad_gnorm: 24.465314865112305
      policy_entropy: 47.16161346435547
      policy_loss: -14.98271369934082
      var_gnorm: 45.25584411621094
      vf_explained_var: 0.6886431574821472
      vf_loss: 7.154996395111084
    num_steps_sampled: 1615000
    num_steps_trained: 1615000
    wait_time_ms: 99.863
  iterations_since_restore: 323
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 830
  policy_reward_mean: {}
  time_since_restore: 4184.155088186264
  time_this_iter_s: 11.408481121063232
  time_total_s: 4184.155088186264
  timestamp: 1593813992
  timesteps_since_restore: 1615000
  timesteps_this_iter: 5000
  timesteps_total: 1615000
  training_iteration: 323
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 14.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=830], 4184 s, 323 iter, 1615000 ts, 530 rew

agent-1: 174.0
agent-2: 116.0
agent-3: 198.0
agent-4: 116.0
agent-5: 124.0
Sum Reward: 728.0
Avg Reward: 145.6
Min Reward: 116.0
Gini Coefficient 0.12197802197802197
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_18-06-46
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 763.0
  episode_reward_mean: 534.04
  episode_reward_min: 290.0
  episodes_this_iter: 1
  episodes_total: 323
  experiment_id: f3470259fa9143609a5dd5049ba7f979
  hostname: gpu020
  info:
    apply_time_ms: 2.848
    dispatch_time_ms: 11.403
    learner:
      cur_lr: 0.00125244096852839
      grad_gnorm: 40.0
      policy_entropy: 25.957143783569336
      policy_loss: -14.753518104553223
      var_gnorm: 45.19939041137695
      vf_explained_var: 0.34374332427978516
      vf_loss: 203.8671417236328
    num_steps_sampled: 1620000
    num_steps_trained: 1620000
    wait_time_ms: 106.276
  iterations_since_restore: 324
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 830
  policy_reward_mean: {}
  time_since_restore: 4197.960130214691
  time_this_iter_s: 13.805042028427124
  time_total_s: 4197.960130214691
  timestamp: 1593814006
  timesteps_since_restore: 1620000
  timesteps_this_iter: 5000
  timesteps_total: 1620000
  training_iteration: 324
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 14.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=830], 4197 s, 324 iter, 1620000 ts, 534 rew

agent-1: 209.0
agent-2: 124.0
agent-3: 81.0
agent-4: 104.0
agent-5: 115.0
Sum Reward: 633.0
Avg Reward: 126.6
Min Reward: 81.0
Gini Coefficient 0.17440758293838862
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_18-06-57
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 763.0
  episode_reward_mean: 534.75
  episode_reward_min: 290.0
  episodes_this_iter: 1
  episodes_total: 324
  experiment_id: f3470259fa9143609a5dd5049ba7f979
  hostname: gpu020
  info:
    apply_time_ms: 3.574
    dispatch_time_ms: 15.054
    learner:
      cur_lr: 0.001252108020707965
      grad_gnorm: 40.0
      policy_entropy: 32.35234069824219
      policy_loss: -2.318260908126831
      var_gnorm: 45.266502380371094
      vf_explained_var: 0.8140290975570679
      vf_loss: 38.172847747802734
    num_steps_sampled: 1625000
    num_steps_trained: 1625000
    wait_time_ms: 95.15
  iterations_since_restore: 325
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 830
  policy_reward_mean: {}
  time_since_restore: 4209.261047840118
  time_this_iter_s: 11.300917625427246
  time_total_s: 4209.261047840118
  timestamp: 1593814017
  timesteps_since_restore: 1625000
  timesteps_this_iter: 5000
  timesteps_total: 1625000
  training_iteration: 325
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 14.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=830], 4209 s, 325 iter, 1625000 ts, 535 rew

agent-1: 96.0
agent-2: 126.0
agent-3: 153.0
agent-4: 95.0
agent-5: 116.0
Sum Reward: 586.0
Avg Reward: 117.2
Min Reward: 95.0
Gini Coefficient 0.09965870307167235
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_18-07-10
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 763.0
  episode_reward_mean: 537.71
  episode_reward_min: 301.0
  episodes_this_iter: 1
  episodes_total: 325
  experiment_id: f3470259fa9143609a5dd5049ba7f979
  hostname: gpu020
  info:
    apply_time_ms: 2.525
    dispatch_time_ms: 49.789
    learner:
      cur_lr: 0.001251774956472218
      grad_gnorm: 40.0
      policy_entropy: 6.220582962036133
      policy_loss: 1.3954715728759766
      var_gnorm: 45.2511100769043
      vf_explained_var: 0.0698556900024414
      vf_loss: 66.38287353515625
    num_steps_sampled: 1630000
    num_steps_trained: 1630000
    wait_time_ms: 85.975
  iterations_since_restore: 326
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 830
  policy_reward_mean: {}
  time_since_restore: 4222.279634237289
  time_this_iter_s: 13.01858639717102
  time_total_s: 4222.279634237289
  timestamp: 1593814030
  timesteps_since_restore: 1630000
  timesteps_this_iter: 5000
  timesteps_total: 1630000
  training_iteration: 326
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 14.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=830], 4222 s, 326 iter, 1630000 ts, 538 rew

agent-1: 86.0
agent-2: 81.0
agent-3: 90.0
agent-4: 68.0
agent-5: 71.0
Sum Reward: 396.0
Avg Reward: 79.2
Min Reward: 68.0
Gini Coefficient 0.0595959595959596
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_18-07-22
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 763.0
  episode_reward_mean: 538.66
  episode_reward_min: 301.0
  episodes_this_iter: 1
  episodes_total: 326
  experiment_id: f3470259fa9143609a5dd5049ba7f979
  hostname: gpu020
  info:
    apply_time_ms: 2.81
    dispatch_time_ms: 9.29
    learner:
      cur_lr: 0.001251442008651793
      grad_gnorm: 40.0
      policy_entropy: 18.907634735107422
      policy_loss: 5.407984256744385
      var_gnorm: 45.34878158569336
      vf_explained_var: 0.28813910484313965
      vf_loss: 122.60104370117188
    num_steps_sampled: 1635000
    num_steps_trained: 1635000
    wait_time_ms: 107.337
  iterations_since_restore: 327
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 830
  policy_reward_mean: {}
  time_since_restore: 4233.593800783157
  time_this_iter_s: 11.31416654586792
  time_total_s: 4233.593800783157
  timestamp: 1593814042
  timesteps_since_restore: 1635000
  timesteps_this_iter: 5000
  timesteps_total: 1635000
  training_iteration: 327
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 14.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=830], 4233 s, 327 iter, 1635000 ts, 539 rew

agent-1: 129.0
agent-2: 50.0
agent-3: 80.0
agent-4: 87.0
agent-5: 52.0
Sum Reward: 398.0
Avg Reward: 79.6
Min Reward: 50.0
Gini Coefficient 0.19396984924623115
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_18-07-34
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 763.0
  episode_reward_mean: 538.39
  episode_reward_min: 301.0
  episodes_this_iter: 1
  episodes_total: 327
  experiment_id: f3470259fa9143609a5dd5049ba7f979
  hostname: gpu020
  info:
    apply_time_ms: 3.274
    dispatch_time_ms: 13.091
    learner:
      cur_lr: 0.0012511089444160461
      grad_gnorm: 40.00000762939453
      policy_entropy: 5.037688255310059
      policy_loss: -12.481745719909668
      var_gnorm: 45.41141128540039
      vf_explained_var: 0.3283836841583252
      vf_loss: 236.37965393066406
    num_steps_sampled: 1640000
    num_steps_trained: 1640000
    wait_time_ms: 97.214
  iterations_since_restore: 328
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 830
  policy_reward_mean: {}
  time_since_restore: 4245.357612848282
  time_this_iter_s: 11.763812065124512
  time_total_s: 4245.357612848282
  timestamp: 1593814054
  timesteps_since_restore: 1640000
  timesteps_this_iter: 5000
  timesteps_total: 1640000
  training_iteration: 328
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 14.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=830], 4245 s, 328 iter, 1640000 ts, 538 rew

agent-1: 121.0
agent-2: 103.0
agent-3: 90.0
agent-4: 103.0
agent-5: 105.0
Sum Reward: 522.0
Avg Reward: 104.4
Min Reward: 90.0
Gini Coefficient 0.04904214559386973
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_18-07-45
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 763.0
  episode_reward_mean: 539.17
  episode_reward_min: 301.0
  episodes_this_iter: 1
  episodes_total: 328
  experiment_id: f3470259fa9143609a5dd5049ba7f979
  hostname: gpu020
  info:
    apply_time_ms: 2.842
    dispatch_time_ms: 12.353
    learner:
      cur_lr: 0.0012507759965956211
      grad_gnorm: 40.0000114440918
      policy_entropy: 23.751482009887695
      policy_loss: -0.29758867621421814
      var_gnorm: 45.432167053222656
      vf_explained_var: 0.9920571446418762
      vf_loss: 5.235973358154297
    num_steps_sampled: 1645000
    num_steps_trained: 1645000
    wait_time_ms: 26.481
  iterations_since_restore: 329
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 830
  policy_reward_mean: {}
  time_since_restore: 4257.104928255081
  time_this_iter_s: 11.747315406799316
  time_total_s: 4257.104928255081
  timestamp: 1593814065
  timesteps_since_restore: 1645000
  timesteps_this_iter: 5000
  timesteps_total: 1645000
  training_iteration: 329
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 14.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=830], 4257 s, 329 iter, 1645000 ts, 539 rew

agent-1: 93.0
agent-2: 61.0
agent-3: 67.0
agent-4: 73.0
agent-5: 203.0
Sum Reward: 497.0
Avg Reward: 99.4
Min Reward: 61.0
Gini Coefficient 0.24949698189134809
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_18-07-57
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 763.0
  episode_reward_mean: 540.29
  episode_reward_min: 301.0
  episodes_this_iter: 1
  episodes_total: 329
  experiment_id: f3470259fa9143609a5dd5049ba7f979
  hostname: gpu020
  info:
    apply_time_ms: 2.624
    dispatch_time_ms: 10.218
    learner:
      cur_lr: 0.001250443048775196
      grad_gnorm: 40.0
      policy_entropy: 10.216322898864746
      policy_loss: 7.0949554443359375
      var_gnorm: 45.45527648925781
      vf_explained_var: 0.7041992545127869
      vf_loss: 91.28791046142578
    num_steps_sampled: 1650000
    num_steps_trained: 1650000
    wait_time_ms: 108.658
  iterations_since_restore: 330
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 830
  policy_reward_mean: {}
  time_since_restore: 4268.438994884491
  time_this_iter_s: 11.33406662940979
  time_total_s: 4268.438994884491
  timestamp: 1593814077
  timesteps_since_restore: 1650000
  timesteps_this_iter: 5000
  timesteps_total: 1650000
  training_iteration: 330
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 14.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=830], 4268 s, 330 iter, 1650000 ts, 540 rew

agent-1: 150.0
agent-2: 72.0
agent-3: 121.0
agent-4: 134.0
agent-5: 64.0
Sum Reward: 541.0
Avg Reward: 108.2
Min Reward: 64.0
Gini Coefficient 0.17301293900184844
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_18-08-09
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 763.0
  episode_reward_mean: 540.7
  episode_reward_min: 301.0
  episodes_this_iter: 1
  episodes_total: 330
  experiment_id: f3470259fa9143609a5dd5049ba7f979
  hostname: gpu020
  info:
    apply_time_ms: 14.178
    dispatch_time_ms: 10.473
    learner:
      cur_lr: 0.0012501099845394492
      grad_gnorm: 4.1681718826293945
      policy_entropy: 15.635237693786621
      policy_loss: -0.3294055759906769
      var_gnorm: 45.46949005126953
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 0.02095843479037285
    num_steps_sampled: 1655000
    num_steps_trained: 1655000
    wait_time_ms: 99.202
  iterations_since_restore: 331
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 830
  policy_reward_mean: {}
  time_since_restore: 4280.286837339401
  time_this_iter_s: 11.847842454910278
  time_total_s: 4280.286837339401
  timestamp: 1593814089
  timesteps_since_restore: 1655000
  timesteps_this_iter: 5000
  timesteps_total: 1655000
  training_iteration: 331
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 14.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=830], 4280 s, 331 iter, 1655000 ts, 541 rew

agent-1: 76.0
agent-2: 69.0
agent-3: 84.0
agent-4: 83.0
agent-5: 72.0
Sum Reward: 384.0
Avg Reward: 76.8
Min Reward: 69.0
Gini Coefficient 0.042708333333333334
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_18-08-21
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 763.0
  episode_reward_mean: 541.53
  episode_reward_min: 310.0
  episodes_this_iter: 1
  episodes_total: 331
  experiment_id: f3470259fa9143609a5dd5049ba7f979
  hostname: gpu020
  info:
    apply_time_ms: 6.646
    dispatch_time_ms: 43.217
    learner:
      cur_lr: 0.0012497770367190242
      grad_gnorm: 40.0000114440918
      policy_entropy: 20.584840774536133
      policy_loss: -0.8631656169891357
      var_gnorm: 45.504329681396484
      vf_explained_var: 0.9133915901184082
      vf_loss: 2.9474146366119385
    num_steps_sampled: 1660000
    num_steps_trained: 1660000
    wait_time_ms: 56.218
  iterations_since_restore: 332
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 830
  policy_reward_mean: {}
  time_since_restore: 4293.125699520111
  time_this_iter_s: 12.838862180709839
  time_total_s: 4293.125699520111
  timestamp: 1593814101
  timesteps_since_restore: 1660000
  timesteps_this_iter: 5000
  timesteps_total: 1660000
  training_iteration: 332
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 14.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=830], 4293 s, 332 iter, 1660000 ts, 542 rew

agent-1: 92.0
agent-2: 73.0
agent-3: 95.0
agent-4: 86.0
agent-5: 68.0
Sum Reward: 414.0
Avg Reward: 82.8
Min Reward: 68.0
Gini Coefficient 0.07053140096618357
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_18-08-35
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 763.0
  episode_reward_mean: 542.44
  episode_reward_min: 310.0
  episodes_this_iter: 1
  episodes_total: 332
  experiment_id: f3470259fa9143609a5dd5049ba7f979
  hostname: gpu020
  info:
    apply_time_ms: 3.124
    dispatch_time_ms: 128.246
    learner:
      cur_lr: 0.0012494439724832773
      grad_gnorm: 40.000003814697266
      policy_entropy: 17.627426147460938
      policy_loss: -4.861362457275391
      var_gnorm: 45.64964294433594
      vf_explained_var: 0.30293160676956177
      vf_loss: 13.610540390014648
    num_steps_sampled: 1665000
    num_steps_trained: 1665000
    wait_time_ms: 84.898
  iterations_since_restore: 333
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 830
  policy_reward_mean: {}
  time_since_restore: 4306.272274971008
  time_this_iter_s: 13.146575450897217
  time_total_s: 4306.272274971008
  timestamp: 1593814115
  timesteps_since_restore: 1665000
  timesteps_this_iter: 5000
  timesteps_total: 1665000
  training_iteration: 333
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 14.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=830], 4306 s, 333 iter, 1665000 ts, 542 rew

agent-1: 67.0
agent-2: 80.0
agent-3: 96.0
agent-4: 55.0
agent-5: 68.0
Sum Reward: 366.0
Avg Reward: 73.2
Min Reward: 55.0
Gini Coefficient 0.10382513661202186
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_18-08-46
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 763.0
  episode_reward_mean: 542.68
  episode_reward_min: 310.0
  episodes_this_iter: 1
  episodes_total: 333
  experiment_id: f3470259fa9143609a5dd5049ba7f979
  hostname: gpu020
  info:
    apply_time_ms: 2.527
    dispatch_time_ms: 9.48
    learner:
      cur_lr: 0.0012491110246628523
      grad_gnorm: 39.999996185302734
      policy_entropy: 20.1412410736084
      policy_loss: 10.8750638961792
      var_gnorm: 45.679420471191406
      vf_explained_var: 0.9006621241569519
      vf_loss: 70.71795654296875
    num_steps_sampled: 1670000
    num_steps_trained: 1670000
    wait_time_ms: 99.73
  iterations_since_restore: 334
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 830
  policy_reward_mean: {}
  time_since_restore: 4317.858814001083
  time_this_iter_s: 11.586539030075073
  time_total_s: 4317.858814001083
  timestamp: 1593814126
  timesteps_since_restore: 1670000
  timesteps_this_iter: 5000
  timesteps_total: 1670000
  training_iteration: 334
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 14.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=830], 4317 s, 334 iter, 1670000 ts, 543 rew

agent-1: 87.0
agent-2: 68.0
agent-3: 85.0
agent-4: 86.0
agent-5: 68.0
Sum Reward: 394.0
Avg Reward: 78.8
Min Reward: 68.0
Gini Coefficient 0.05685279187817259
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_18-08-59
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 763.0
  episode_reward_mean: 542.03
  episode_reward_min: 310.0
  episodes_this_iter: 1
  episodes_total: 334
  experiment_id: f3470259fa9143609a5dd5049ba7f979
  hostname: gpu020
  info:
    apply_time_ms: 3.982
    dispatch_time_ms: 36.905
    learner:
      cur_lr: 0.0012487779604271054
      grad_gnorm: 15.205687522888184
      policy_entropy: 18.01575469970703
      policy_loss: -5.422347545623779
      var_gnorm: 45.67878723144531
      vf_explained_var: -1.0
      vf_loss: 1.1463388204574585
    num_steps_sampled: 1675000
    num_steps_trained: 1675000
    wait_time_ms: 25.431
  iterations_since_restore: 335
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 830
  policy_reward_mean: {}
  time_since_restore: 4330.8508360385895
  time_this_iter_s: 12.992022037506104
  time_total_s: 4330.8508360385895
  timestamp: 1593814139
  timesteps_since_restore: 1675000
  timesteps_this_iter: 5000
  timesteps_total: 1675000
  training_iteration: 335
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 14.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=830], 4330 s, 335 iter, 1675000 ts, 542 rew

agent-1: 89.0
agent-2: 67.0
agent-3: 85.0
agent-4: 96.0
agent-5: 71.0
Sum Reward: 408.0
Avg Reward: 81.6
Min Reward: 67.0
Gini Coefficient 0.07450980392156863
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_18-09-11
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 763.0
  episode_reward_mean: 542.51
  episode_reward_min: 310.0
  episodes_this_iter: 1
  episodes_total: 335
  experiment_id: f3470259fa9143609a5dd5049ba7f979
  hostname: gpu020
  info:
    apply_time_ms: 2.825
    dispatch_time_ms: 17.928
    learner:
      cur_lr: 0.0012484450126066804
      grad_gnorm: 40.000003814697266
      policy_entropy: 20.548870086669922
      policy_loss: -16.665000915527344
      var_gnorm: 45.686397552490234
      vf_explained_var: 0.8880460262298584
      vf_loss: 58.83777618408203
    num_steps_sampled: 1680000
    num_steps_trained: 1680000
    wait_time_ms: 99.236
  iterations_since_restore: 336
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 830
  policy_reward_mean: {}
  time_since_restore: 4342.509989500046
  time_this_iter_s: 11.659153461456299
  time_total_s: 4342.509989500046
  timestamp: 1593814151
  timesteps_since_restore: 1680000
  timesteps_this_iter: 5000
  timesteps_total: 1680000
  training_iteration: 336
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 14.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=830], 4342 s, 336 iter, 1680000 ts, 543 rew

agent-1: 78.0
agent-2: 81.0
agent-3: 61.0
agent-4: 73.0
agent-5: 64.0
Sum Reward: 357.0
Avg Reward: 71.4
Min Reward: 61.0
Gini Coefficient 0.06050420168067227
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_18-09-24
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 763.0
  episode_reward_mean: 542.27
  episode_reward_min: 310.0
  episodes_this_iter: 1
  episodes_total: 336
  experiment_id: f3470259fa9143609a5dd5049ba7f979
  hostname: gpu020
  info:
    apply_time_ms: 3.255
    dispatch_time_ms: 50.396
    learner:
      cur_lr: 0.0012481119483709335
      grad_gnorm: 40.0
      policy_entropy: 16.02497673034668
      policy_loss: 11.179679870605469
      var_gnorm: 45.74595642089844
      vf_explained_var: 0.5405746698379517
      vf_loss: 83.88902282714844
    num_steps_sampled: 1685000
    num_steps_trained: 1685000
    wait_time_ms: 136.354
  iterations_since_restore: 337
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 830
  policy_reward_mean: {}
  time_since_restore: 4355.038294315338
  time_this_iter_s: 12.528304815292358
  time_total_s: 4355.038294315338
  timestamp: 1593814164
  timesteps_since_restore: 1685000
  timesteps_this_iter: 5000
  timesteps_total: 1685000
  training_iteration: 337
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 14.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=830], 4355 s, 337 iter, 1685000 ts, 542 rew

agent-1: 61.0
agent-2: 62.0
agent-3: 77.0
agent-4: 80.0
agent-5: 76.0
Sum Reward: 356.0
Avg Reward: 71.2
Min Reward: 61.0
Gini Coefficient 0.05955056179775281
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_18-09-38
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 763.0
  episode_reward_mean: 541.33
  episode_reward_min: 310.0
  episodes_this_iter: 1
  episodes_total: 337
  experiment_id: f3470259fa9143609a5dd5049ba7f979
  hostname: gpu020
  info:
    apply_time_ms: 3.225
    dispatch_time_ms: 15.253
    learner:
      cur_lr: 0.0012477790005505085
      grad_gnorm: 40.0
      policy_entropy: 39.12605667114258
      policy_loss: 20.791900634765625
      var_gnorm: 45.83403396606445
      vf_explained_var: 0.8517739772796631
      vf_loss: 18.089969635009766
    num_steps_sampled: 1690000
    num_steps_trained: 1690000
    wait_time_ms: 96.467
  iterations_since_restore: 338
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 830
  policy_reward_mean: {}
  time_since_restore: 4368.988639354706
  time_this_iter_s: 13.950345039367676
  time_total_s: 4368.988639354706
  timestamp: 1593814178
  timesteps_since_restore: 1690000
  timesteps_this_iter: 5000
  timesteps_total: 1690000
  training_iteration: 338
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 14.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=830], 4368 s, 338 iter, 1690000 ts, 541 rew

agent-1: 62.0
agent-2: 82.0
agent-3: 91.0
agent-4: 74.0
agent-5: 122.0
Sum Reward: 431.0
Avg Reward: 86.2
Min Reward: 62.0
Gini Coefficient 0.1271461716937355
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_18-09-49
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 763.0
  episode_reward_mean: 540.47
  episode_reward_min: 310.0
  episodes_this_iter: 1
  episodes_total: 338
  experiment_id: f3470259fa9143609a5dd5049ba7f979
  hostname: gpu020
  info:
    apply_time_ms: 3.13
    dispatch_time_ms: 11.912
    learner:
      cur_lr: 0.0012474460527300835
      grad_gnorm: 33.793033599853516
      policy_entropy: 28.98208999633789
      policy_loss: 3.7565929889678955
      var_gnorm: 45.930171966552734
      vf_explained_var: 0.9556697010993958
      vf_loss: 4.329093933105469
    num_steps_sampled: 1695000
    num_steps_trained: 1695000
    wait_time_ms: 102.472
  iterations_since_restore: 339
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 830
  policy_reward_mean: {}
  time_since_restore: 4380.69641494751
  time_this_iter_s: 11.707775592803955
  time_total_s: 4380.69641494751
  timestamp: 1593814189
  timesteps_since_restore: 1695000
  timesteps_this_iter: 5000
  timesteps_total: 1695000
  training_iteration: 339
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 14.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=830], 4380 s, 339 iter, 1695000 ts, 540 rew

agent-1: 66.0
agent-2: 81.0
agent-3: 114.0
agent-4: 70.0
agent-5: 93.0
Sum Reward: 424.0
Avg Reward: 84.8
Min Reward: 66.0
Gini Coefficient 0.11226415094339623
I0703 18:10:11.615396   825 node_manager.cc:1721] Resubmitting task 00000000ce02fe8e8f1fcaa60e65fc9c2e790c20 on client ae0c74277128a8333189788a3457310d90aa1ab2
W0703 18:10:11.627882   825 node_manager.cc:31] A task was resubmitted, so we are ignoring it. This should only happen during reconstruction.
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_18-10-17
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 763.0
  episode_reward_mean: 539.08
  episode_reward_min: 310.0
  episodes_this_iter: 1
  episodes_total: 339
  experiment_id: f3470259fa9143609a5dd5049ba7f979
  hostname: gpu020
  info:
    apply_time_ms: 3.182
    dispatch_time_ms: 15.912
    learner:
      cur_lr: 0.0012471129884943366
      grad_gnorm: 32.8991584777832
      policy_entropy: 42.1664924621582
      policy_loss: 3.1134707927703857
      var_gnorm: 45.91961669921875
      vf_explained_var: 0.7013633847236633
      vf_loss: 7.123786926269531
    num_steps_sampled: 1700000
    num_steps_trained: 1700000
    wait_time_ms: 33.657
  iterations_since_restore: 340
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 830
  policy_reward_mean: {}
  time_since_restore: 4408.320212602615
  time_this_iter_s: 27.62379765510559
  time_total_s: 4408.320212602615
  timestamp: 1593814217
  timesteps_since_restore: 1700000
  timesteps_this_iter: 5000
  timesteps_total: 1700000
  training_iteration: 340
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 14.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=830], 4408 s, 340 iter, 1700000 ts, 539 rew

agent-1: 84.0
agent-2: 76.0
agent-3: 106.0
agent-4: 83.0
agent-5: 127.0
Sum Reward: 476.0
Avg Reward: 95.2
Min Reward: 76.0
Gini Coefficient 0.10504201680672269
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_18-10-29
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 763.0
  episode_reward_mean: 538.6
  episode_reward_min: 310.0
  episodes_this_iter: 1
  episodes_total: 340
  experiment_id: f3470259fa9143609a5dd5049ba7f979
  hostname: gpu020
  info:
    apply_time_ms: 4.437
    dispatch_time_ms: 10.292
    learner:
      cur_lr: 0.0012467800406739116
      grad_gnorm: 15.063851356506348
      policy_entropy: 48.60223388671875
      policy_loss: -2.0098936557769775
      var_gnorm: 46.0098991394043
      vf_explained_var: 0.9451518058776855
      vf_loss: 1.1712188720703125
    num_steps_sampled: 1705000
    num_steps_trained: 1705000
    wait_time_ms: 112.667
  iterations_since_restore: 341
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 830
  policy_reward_mean: {}
  time_since_restore: 4420.244269609451
  time_this_iter_s: 11.924057006835938
  time_total_s: 4420.244269609451
  timestamp: 1593814229
  timesteps_since_restore: 1705000
  timesteps_this_iter: 5000
  timesteps_total: 1705000
  training_iteration: 341
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 14.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=830], 4420 s, 341 iter, 1705000 ts, 539 rew

agent-1: 67.0
agent-2: 106.0
agent-3: 76.0
agent-4: 62.0
agent-5: 63.0
Sum Reward: 374.0
Avg Reward: 74.8
Min Reward: 62.0
Gini Coefficient 0.10802139037433155
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_18-10-49
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 763.0
  episode_reward_mean: 535.67
  episode_reward_min: 310.0
  episodes_this_iter: 1
  episodes_total: 341
  experiment_id: f3470259fa9143609a5dd5049ba7f979
  hostname: gpu020
  info:
    apply_time_ms: 3.864
    dispatch_time_ms: 55.939
    learner:
      cur_lr: 0.0012464469764381647
      grad_gnorm: 40.000003814697266
      policy_entropy: 15.873558044433594
      policy_loss: -4.767675876617432
      var_gnorm: 46.05031204223633
      vf_explained_var: 0.5679131150245667
      vf_loss: 131.754638671875
    num_steps_sampled: 1710000
    num_steps_trained: 1710000
    wait_time_ms: 58.608
  iterations_since_restore: 342
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 830
  policy_reward_mean: {}
  time_since_restore: 4440.3014323711395
  time_this_iter_s: 20.057162761688232
  time_total_s: 4440.3014323711395
  timestamp: 1593814249
  timesteps_since_restore: 1710000
  timesteps_this_iter: 5000
  timesteps_total: 1710000
  training_iteration: 342
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 14.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=830], 4440 s, 342 iter, 1710000 ts, 536 rew

agent-1: 69.0
agent-2: 73.0
agent-3: 86.0
agent-4: 78.0
agent-5: 53.0
Sum Reward: 359.0
Avg Reward: 71.8
Min Reward: 53.0
Gini Coefficient 0.08356545961002786
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_18-11-07
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 763.0
  episode_reward_mean: 533.45
  episode_reward_min: 310.0
  episodes_this_iter: 1
  episodes_total: 342
  experiment_id: f3470259fa9143609a5dd5049ba7f979
  hostname: gpu020
  info:
    apply_time_ms: 3.362
    dispatch_time_ms: 34.795
    learner:
      cur_lr: 0.0012461140286177397
      grad_gnorm: 7.554000377655029
      policy_entropy: 32.071903228759766
      policy_loss: -1.6419343948364258
      var_gnorm: 46.09854507446289
      vf_explained_var: 0.9944807887077332
      vf_loss: 0.20198886096477509
    num_steps_sampled: 1715000
    num_steps_trained: 1715000
    wait_time_ms: 264.794
  iterations_since_restore: 343
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 830
  policy_reward_mean: {}
  time_since_restore: 4458.667281627655
  time_this_iter_s: 18.365849256515503
  time_total_s: 4458.667281627655
  timestamp: 1593814267
  timesteps_since_restore: 1715000
  timesteps_this_iter: 5000
  timesteps_total: 1715000
  training_iteration: 343
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 14.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=830], 4458 s, 343 iter, 1715000 ts, 533 rew

agent-1: 87.0
agent-2: 108.0
agent-3: 109.0
agent-4: 91.0
agent-5: 65.0
Sum Reward: 460.0
Avg Reward: 92.0
Min Reward: 65.0
Gini Coefficient 0.09478260869565218
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_18-11-25
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 763.0
  episode_reward_mean: 531.71
  episode_reward_min: 310.0
  episodes_this_iter: 1
  episodes_total: 343
  experiment_id: f3470259fa9143609a5dd5049ba7f979
  hostname: gpu020
  info:
    apply_time_ms: 2.702
    dispatch_time_ms: 9.089
    learner:
      cur_lr: 0.0012457809643819928
      grad_gnorm: 24.54353141784668
      policy_entropy: 35.35163497924805
      policy_loss: -2.367213487625122
      var_gnorm: 46.06303024291992
      vf_explained_var: -1.0
      vf_loss: 5.206176280975342
    num_steps_sampled: 1720000
    num_steps_trained: 1720000
    wait_time_ms: 188.921
  iterations_since_restore: 344
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 830
  policy_reward_mean: {}
  time_since_restore: 4476.62126326561
  time_this_iter_s: 17.953981637954712
  time_total_s: 4476.62126326561
  timestamp: 1593814285
  timesteps_since_restore: 1720000
  timesteps_this_iter: 5000
  timesteps_total: 1720000
  training_iteration: 344
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 14.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=830], 4476 s, 344 iter, 1720000 ts, 532 rew

agent-1: 61.0
agent-2: 99.0
agent-3: 86.0
agent-4: 54.0
agent-5: 62.0
Sum Reward: 362.0
Avg Reward: 72.4
Min Reward: 54.0
Gini Coefficient 0.1270718232044199
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_18-11-37
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 763.0
  episode_reward_mean: 531.29
  episode_reward_min: 310.0
  episodes_this_iter: 1
  episodes_total: 344
  experiment_id: f3470259fa9143609a5dd5049ba7f979
  hostname: gpu020
  info:
    apply_time_ms: 4.007
    dispatch_time_ms: 7.716
    learner:
      cur_lr: 0.0012454480165615678
      grad_gnorm: 22.280214309692383
      policy_entropy: 37.36558151245117
      policy_loss: -3.1522910594940186
      var_gnorm: 46.13896942138672
      vf_explained_var: 0.9663470983505249
      vf_loss: 1.390618085861206
    num_steps_sampled: 1725000
    num_steps_trained: 1725000
    wait_time_ms: 114.686
  iterations_since_restore: 345
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 830
  policy_reward_mean: {}
  time_since_restore: 4487.428115606308
  time_this_iter_s: 10.806852340698242
  time_total_s: 4487.428115606308
  timestamp: 1593814297
  timesteps_since_restore: 1725000
  timesteps_this_iter: 5000
  timesteps_total: 1725000
  training_iteration: 345
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 14.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=830], 4487 s, 345 iter, 1725000 ts, 531 rew

agent-1: 67.0
agent-2: 75.0
agent-3: 104.0
agent-4: 100.0
agent-5: 108.0
Sum Reward: 454.0
Avg Reward: 90.8
Min Reward: 67.0
Gini Coefficient 0.09779735682819383
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_18-11-49
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 763.0
  episode_reward_mean: 531.32
  episode_reward_min: 310.0
  episodes_this_iter: 1
  episodes_total: 345
  experiment_id: f3470259fa9143609a5dd5049ba7f979
  hostname: gpu020
  info:
    apply_time_ms: 3.026
    dispatch_time_ms: 12.533
    learner:
      cur_lr: 0.001245114952325821
      grad_gnorm: 14.66524600982666
      policy_entropy: 35.44789123535156
      policy_loss: 2.1423678398132324
      var_gnorm: 46.19819259643555
      vf_explained_var: -0.041666626930236816
      vf_loss: 3.8649933338165283
    num_steps_sampled: 1730000
    num_steps_trained: 1730000
    wait_time_ms: 100.366
  iterations_since_restore: 346
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 830
  policy_reward_mean: {}
  time_since_restore: 4499.372437477112
  time_this_iter_s: 11.944321870803833
  time_total_s: 4499.372437477112
  timestamp: 1593814309
  timesteps_since_restore: 1730000
  timesteps_this_iter: 5000
  timesteps_total: 1730000
  training_iteration: 346
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 14.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=830], 4499 s, 346 iter, 1730000 ts, 531 rew

agent-1: 144.0
agent-2: 84.0
agent-3: 97.0
agent-4: 73.0
agent-5: 52.0
Sum Reward: 450.0
Avg Reward: 90.0
Min Reward: 52.0
Gini Coefficient 0.18488888888888888
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_18-12-02
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 763.0
  episode_reward_mean: 530.6
  episode_reward_min: 310.0
  episodes_this_iter: 1
  episodes_total: 346
  experiment_id: f3470259fa9143609a5dd5049ba7f979
  hostname: gpu020
  info:
    apply_time_ms: 4.397
    dispatch_time_ms: 8.324
    learner:
      cur_lr: 0.0012447820045053959
      grad_gnorm: 10.957681655883789
      policy_entropy: 38.900062561035156
      policy_loss: -2.5709304809570312
      var_gnorm: 46.17140197753906
      vf_explained_var: 0.0
      vf_loss: 0.14602087438106537
    num_steps_sampled: 1735000
    num_steps_trained: 1735000
    wait_time_ms: 96.531
  iterations_since_restore: 347
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 830
  policy_reward_mean: {}
  time_since_restore: 4512.323868513107
  time_this_iter_s: 12.951431035995483
  time_total_s: 4512.323868513107
  timestamp: 1593814322
  timesteps_since_restore: 1735000
  timesteps_this_iter: 5000
  timesteps_total: 1735000
  training_iteration: 347
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 14.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=830], 4512 s, 347 iter, 1735000 ts, 531 rew

agent-1: 78.0
agent-2: 76.0
agent-3: 53.0
agent-4: 80.0
agent-5: 71.0
Sum Reward: 358.0
Avg Reward: 71.6
Min Reward: 53.0
Gini Coefficient 0.06815642458100558
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_18-12-14
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 763.0
  episode_reward_mean: 527.57
  episode_reward_min: 310.0
  episodes_this_iter: 1
  episodes_total: 347
  experiment_id: f3470259fa9143609a5dd5049ba7f979
  hostname: gpu020
  info:
    apply_time_ms: 3.555
    dispatch_time_ms: 19.299
    learner:
      cur_lr: 0.0012444490566849709
      grad_gnorm: 40.0
      policy_entropy: 9.784730911254883
      policy_loss: 4.277099132537842
      var_gnorm: 46.163082122802734
      vf_explained_var: 0.42011165618896484
      vf_loss: 171.7206573486328
    num_steps_sampled: 1740000
    num_steps_trained: 1740000
    wait_time_ms: 90.401
  iterations_since_restore: 348
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 830
  policy_reward_mean: {}
  time_since_restore: 4524.409021615982
  time_this_iter_s: 12.085153102874756
  time_total_s: 4524.409021615982
  timestamp: 1593814334
  timesteps_since_restore: 1740000
  timesteps_this_iter: 5000
  timesteps_total: 1740000
  training_iteration: 348
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 14.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=830], 4524 s, 348 iter, 1740000 ts, 528 rew

agent-1: 141.0
agent-2: 114.0
agent-3: 94.0
agent-4: 69.0
agent-5: 78.0
Sum Reward: 496.0
Avg Reward: 99.2
Min Reward: 69.0
Gini Coefficient 0.14516129032258066
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_18-12-26
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 763.0
  episode_reward_mean: 527.45
  episode_reward_min: 310.0
  episodes_this_iter: 1
  episodes_total: 348
  experiment_id: f3470259fa9143609a5dd5049ba7f979
  hostname: gpu020
  info:
    apply_time_ms: 3.321
    dispatch_time_ms: 12.051
    learner:
      cur_lr: 0.001244115992449224
      grad_gnorm: 40.00000762939453
      policy_entropy: 31.543596267700195
      policy_loss: -0.9175534844398499
      var_gnorm: 46.18399429321289
      vf_explained_var: 0.613239586353302
      vf_loss: 1.7099568843841553
    num_steps_sampled: 1745000
    num_steps_trained: 1745000
    wait_time_ms: 107.996
  iterations_since_restore: 349
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 830
  policy_reward_mean: {}
  time_since_restore: 4536.230417728424
  time_this_iter_s: 11.821396112442017
  time_total_s: 4536.230417728424
  timestamp: 1593814346
  timesteps_since_restore: 1745000
  timesteps_this_iter: 5000
  timesteps_total: 1745000
  training_iteration: 349
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 14.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=830], 4536 s, 349 iter, 1745000 ts, 527 rew

agent-1: 101.0
agent-2: 85.0
agent-3: 82.0
agent-4: 92.0
agent-5: 86.0
Sum Reward: 446.0
Avg Reward: 89.2
Min Reward: 82.0
Gini Coefficient 0.04035874439461883
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_18-12-38
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 763.0
  episode_reward_mean: 527.43
  episode_reward_min: 310.0
  episodes_this_iter: 1
  episodes_total: 349
  experiment_id: f3470259fa9143609a5dd5049ba7f979
  hostname: gpu020
  info:
    apply_time_ms: 2.832
    dispatch_time_ms: 27.237
    learner:
      cur_lr: 0.001243783044628799
      grad_gnorm: 2.28080153465271
      policy_entropy: 35.64085388183594
      policy_loss: -0.6573081016540527
      var_gnorm: 46.22872543334961
      vf_explained_var: 0.0
      vf_loss: 0.006126146297901869
    num_steps_sampled: 1750000
    num_steps_trained: 1750000
    wait_time_ms: 55.626
  iterations_since_restore: 350
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 830
  policy_reward_mean: {}
  time_since_restore: 4548.434084653854
  time_this_iter_s: 12.203666925430298
  time_total_s: 4548.434084653854
  timestamp: 1593814358
  timesteps_since_restore: 1750000
  timesteps_this_iter: 5000
  timesteps_total: 1750000
  training_iteration: 350
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 14.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=830], 4548 s, 350 iter, 1750000 ts, 527 rew

agent-1: 60.0
agent-2: 79.0
agent-3: 69.0
agent-4: 58.0
agent-5: 61.0
Sum Reward: 327.0
Avg Reward: 65.4
Min Reward: 58.0
Gini Coefficient 0.062385321100917435
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_18-12-50
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 763.0
  episode_reward_mean: 525.01
  episode_reward_min: 310.0
  episodes_this_iter: 1
  episodes_total: 350
  experiment_id: f3470259fa9143609a5dd5049ba7f979
  hostname: gpu020
  info:
    apply_time_ms: 3.413
    dispatch_time_ms: 12.245
    learner:
      cur_lr: 0.001243449980393052
      grad_gnorm: 0.16365887224674225
      policy_entropy: 28.26496124267578
      policy_loss: -0.06183778494596481
      var_gnorm: 46.276283264160156
      vf_explained_var: 0.0
      vf_loss: 2.5483517674729228e-05
    num_steps_sampled: 1755000
    num_steps_trained: 1755000
    wait_time_ms: 112.005
  iterations_since_restore: 351
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 830
  policy_reward_mean: {}
  time_since_restore: 4560.319050550461
  time_this_iter_s: 11.884965896606445
  time_total_s: 4560.319050550461
  timestamp: 1593814370
  timesteps_since_restore: 1755000
  timesteps_this_iter: 5000
  timesteps_total: 1755000
  training_iteration: 351
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 14.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=830], 4560 s, 351 iter, 1755000 ts, 525 rew

agent-1: 65.0
agent-2: 73.0
agent-3: 63.0
agent-4: 71.0
agent-5: 65.0
Sum Reward: 337.0
Avg Reward: 67.4
Min Reward: 63.0
Gini Coefficient 0.03086053412462908
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_18-13-02
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 763.0
  episode_reward_mean: 523.04
  episode_reward_min: 310.0
  episodes_this_iter: 1
  episodes_total: 351
  experiment_id: f3470259fa9143609a5dd5049ba7f979
  hostname: gpu020
  info:
    apply_time_ms: 3.331
    dispatch_time_ms: 12.313
    learner:
      cur_lr: 0.001243117032572627
      grad_gnorm: 31.21982192993164
      policy_entropy: 6.549508571624756
      policy_loss: 7.051320552825928
      var_gnorm: 46.314090728759766
      vf_explained_var: -0.09148645401000977
      vf_loss: 39.24907302856445
    num_steps_sampled: 1760000
    num_steps_trained: 1760000
    wait_time_ms: 96.688
  iterations_since_restore: 352
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 830
  policy_reward_mean: {}
  time_since_restore: 4572.6031148433685
  time_this_iter_s: 12.284064292907715
  time_total_s: 4572.6031148433685
  timestamp: 1593814382
  timesteps_since_restore: 1760000
  timesteps_this_iter: 5000
  timesteps_total: 1760000
  training_iteration: 352
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 14.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=830], 4572 s, 352 iter, 1760000 ts, 523 rew

agent-1: 121.0
agent-2: 79.0
agent-3: 50.0
agent-4: 89.0
agent-5: 79.0
Sum Reward: 418.0
Avg Reward: 83.6
Min Reward: 50.0
Gini Coefficient 0.14545454545454545
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_18-13-14
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 763.0
  episode_reward_mean: 524.12
  episode_reward_min: 315.0
  episodes_this_iter: 1
  episodes_total: 352
  experiment_id: f3470259fa9143609a5dd5049ba7f979
  hostname: gpu020
  info:
    apply_time_ms: 2.756
    dispatch_time_ms: 13.603
    learner:
      cur_lr: 0.0012427839683368802
      grad_gnorm: 39.999996185302734
      policy_entropy: 7.640812397003174
      policy_loss: -16.74588394165039
      var_gnorm: 46.30913162231445
      vf_explained_var: -0.05809652805328369
      vf_loss: 390.0870361328125
    num_steps_sampled: 1765000
    num_steps_trained: 1765000
    wait_time_ms: 97.231
  iterations_since_restore: 353
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 830
  policy_reward_mean: {}
  time_since_restore: 4584.132781028748
  time_this_iter_s: 11.529666185379028
  time_total_s: 4584.132781028748
  timestamp: 1593814394
  timesteps_since_restore: 1765000
  timesteps_this_iter: 5000
  timesteps_total: 1765000
  training_iteration: 353
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 14.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=830], 4584 s, 353 iter, 1765000 ts, 524 rew

agent-1: 84.0
agent-2: 94.0
agent-3: 97.0
agent-4: 72.0
agent-5: 126.0
Sum Reward: 473.0
Avg Reward: 94.6
Min Reward: 72.0
Gini Coefficient 0.10232558139534884
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_18-13-26
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 763.0
  episode_reward_mean: 523.87
  episode_reward_min: 315.0
  episodes_this_iter: 1
  episodes_total: 353
  experiment_id: f3470259fa9143609a5dd5049ba7f979
  hostname: gpu020
  info:
    apply_time_ms: 2.776
    dispatch_time_ms: 9.827
    learner:
      cur_lr: 0.0012424510205164552
      grad_gnorm: 40.0
      policy_entropy: 3.2002270221710205
      policy_loss: 11.232718467712402
      var_gnorm: 46.262367248535156
      vf_explained_var: -1.0
      vf_loss: 185.8724822998047
    num_steps_sampled: 1770000
    num_steps_trained: 1770000
    wait_time_ms: 100.661
  iterations_since_restore: 354
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 830
  policy_reward_mean: {}
  time_since_restore: 4596.135623931885
  time_this_iter_s: 12.002842903137207
  time_total_s: 4596.135623931885
  timestamp: 1593814406
  timesteps_since_restore: 1770000
  timesteps_this_iter: 5000
  timesteps_total: 1770000
  training_iteration: 354
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 14.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=830], 4596 s, 354 iter, 1770000 ts, 524 rew

agent-1: 115.0
agent-2: 102.0
agent-3: 91.0
agent-4: 97.0
agent-5: 84.0
Sum Reward: 489.0
Avg Reward: 97.8
Min Reward: 84.0
Gini Coefficient 0.05971370143149284
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_18-13-39
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 763.0
  episode_reward_mean: 525.39
  episode_reward_min: 315.0
  episodes_this_iter: 1
  episodes_total: 354
  experiment_id: f3470259fa9143609a5dd5049ba7f979
  hostname: gpu020
  info:
    apply_time_ms: 3.558
    dispatch_time_ms: 13.983
    learner:
      cur_lr: 0.0012421179562807083
      grad_gnorm: 39.99999237060547
      policy_entropy: 27.550485610961914
      policy_loss: 7.425941467285156
      var_gnorm: 46.38349533081055
      vf_explained_var: 0.08273732662200928
      vf_loss: 75.03946685791016
    num_steps_sampled: 1775000
    num_steps_trained: 1775000
    wait_time_ms: 102.88
  iterations_since_restore: 355
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 830
  policy_reward_mean: {}
  time_since_restore: 4609.095871686935
  time_this_iter_s: 12.96024775505066
  time_total_s: 4609.095871686935
  timestamp: 1593814419
  timesteps_since_restore: 1775000
  timesteps_this_iter: 5000
  timesteps_total: 1775000
  training_iteration: 355
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 14.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=830], 4609 s, 355 iter, 1775000 ts, 525 rew

agent-1: 72.0
agent-2: 81.0
agent-3: 70.0
agent-4: 82.0
agent-5: 105.0
Sum Reward: 410.0
Avg Reward: 82.0
Min Reward: 70.0
Gini Coefficient 0.07804878048780488
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_18-13-51
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 763.0
  episode_reward_mean: 525.13
  episode_reward_min: 315.0
  episodes_this_iter: 1
  episodes_total: 355
  experiment_id: f3470259fa9143609a5dd5049ba7f979
  hostname: gpu020
  info:
    apply_time_ms: 2.78
    dispatch_time_ms: 12.944
    learner:
      cur_lr: 0.0012417850084602833
      grad_gnorm: 4.399359226226807
      policy_entropy: 28.160085678100586
      policy_loss: 0.8248694539070129
      var_gnorm: 46.42198944091797
      vf_explained_var: 0.0
      vf_loss: 0.023547932505607605
    num_steps_sampled: 1780000
    num_steps_trained: 1780000
    wait_time_ms: 108.285
  iterations_since_restore: 356
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 830
  policy_reward_mean: {}
  time_since_restore: 4621.513704776764
  time_this_iter_s: 12.417833089828491
  time_total_s: 4621.513704776764
  timestamp: 1593814431
  timesteps_since_restore: 1780000
  timesteps_this_iter: 5000
  timesteps_total: 1780000
  training_iteration: 356
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 14.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=830], 4621 s, 356 iter, 1780000 ts, 525 rew

agent-1: 56.0
agent-2: 50.0
agent-3: 75.0
agent-4: 53.0
agent-5: 85.0
Sum Reward: 319.0
Avg Reward: 63.8
Min Reward: 50.0
Gini Coefficient 0.11536050156739812
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_18-14-06
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 763.0
  episode_reward_mean: 524.18
  episode_reward_min: 315.0
  episodes_this_iter: 1
  episodes_total: 356
  experiment_id: f3470259fa9143609a5dd5049ba7f979
  hostname: gpu020
  info:
    apply_time_ms: 2.59
    dispatch_time_ms: 24.87
    learner:
      cur_lr: 0.0012414519442245364
      grad_gnorm: 40.000003814697266
      policy_entropy: 39.03811264038086
      policy_loss: -14.339288711547852
      var_gnorm: 46.47963333129883
      vf_explained_var: 0.4497910737991333
      vf_loss: 20.499807357788086
    num_steps_sampled: 1785000
    num_steps_trained: 1785000
    wait_time_ms: 98.44
  iterations_since_restore: 357
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 830
  policy_reward_mean: {}
  time_since_restore: 4636.459127902985
  time_this_iter_s: 14.945423126220703
  time_total_s: 4636.459127902985
  timestamp: 1593814446
  timesteps_since_restore: 1785000
  timesteps_this_iter: 5000
  timesteps_total: 1785000
  training_iteration: 357
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 14.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=830], 4636 s, 357 iter, 1785000 ts, 524 rew

agent-1: 70.0
agent-2: 79.0
agent-3: 60.0
agent-4: 66.0
agent-5: 70.0
Sum Reward: 345.0
Avg Reward: 69.0
Min Reward: 60.0
Gini Coefficient 0.04869565217391304
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_18-14-18
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 763.0
  episode_reward_mean: 523.33
  episode_reward_min: 315.0
  episodes_this_iter: 1
  episodes_total: 357
  experiment_id: f3470259fa9143609a5dd5049ba7f979
  hostname: gpu020
  info:
    apply_time_ms: 3.422
    dispatch_time_ms: 10.025
    learner:
      cur_lr: 0.0012411189964041114
      grad_gnorm: 17.60055160522461
      policy_entropy: 31.816272735595703
      policy_loss: -2.9850351810455322
      var_gnorm: 46.48269271850586
      vf_explained_var: 0.0
      vf_loss: 0.3738727569580078
    num_steps_sampled: 1790000
    num_steps_trained: 1790000
    wait_time_ms: 112.39
  iterations_since_restore: 358
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 830
  policy_reward_mean: {}
  time_since_restore: 4647.929899930954
  time_this_iter_s: 11.47077202796936
  time_total_s: 4647.929899930954
  timestamp: 1593814458
  timesteps_since_restore: 1790000
  timesteps_this_iter: 5000
  timesteps_total: 1790000
  training_iteration: 358
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 14.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=830], 4647 s, 358 iter, 1790000 ts, 523 rew

agent-1: 97.0
agent-2: 92.0
agent-3: 111.0
agent-4: 92.0
agent-5: 86.0
Sum Reward: 478.0
Avg Reward: 95.6
Min Reward: 86.0
Gini Coefficient 0.04602510460251046
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_18-14-29
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 763.0
  episode_reward_mean: 522.81
  episode_reward_min: 315.0
  episodes_this_iter: 1
  episodes_total: 358
  experiment_id: f3470259fa9143609a5dd5049ba7f979
  hostname: gpu020
  info:
    apply_time_ms: 2.753
    dispatch_time_ms: 10.745
    learner:
      cur_lr: 0.0012407860485836864
      grad_gnorm: 40.000003814697266
      policy_entropy: 16.337432861328125
      policy_loss: 3.0985467433929443
      var_gnorm: 46.48463439941406
      vf_explained_var: 0.8949054479598999
      vf_loss: 67.65715026855469
    num_steps_sampled: 1795000
    num_steps_trained: 1795000
    wait_time_ms: 103.487
  iterations_since_restore: 359
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 830
  policy_reward_mean: {}
  time_since_restore: 4659.398410081863
  time_this_iter_s: 11.468510150909424
  time_total_s: 4659.398410081863
  timestamp: 1593814469
  timesteps_since_restore: 1795000
  timesteps_this_iter: 5000
  timesteps_total: 1795000
  training_iteration: 359
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 14.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=830], 4659 s, 359 iter, 1795000 ts, 523 rew

agent-1: 33.0
agent-2: 55.0
agent-3: 102.0
agent-4: 144.0
agent-5: 75.0
Sum Reward: 409.0
Avg Reward: 81.8
Min Reward: 33.0
Gini Coefficient 0.263080684596577
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_18-14-42
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 763.0
  episode_reward_mean: 520.5
  episode_reward_min: 315.0
  episodes_this_iter: 1
  episodes_total: 359
  experiment_id: f3470259fa9143609a5dd5049ba7f979
  hostname: gpu020
  info:
    apply_time_ms: 3.486
    dispatch_time_ms: 17.421
    learner:
      cur_lr: 0.0012404529843479395
      grad_gnorm: 39.186588287353516
      policy_entropy: 3.486161470413208
      policy_loss: 0.07127195596694946
      var_gnorm: 46.499298095703125
      vf_explained_var: 0.2098400592803955
      vf_loss: 19.309160232543945
    num_steps_sampled: 1800000
    num_steps_trained: 1800000
    wait_time_ms: 21.075
  iterations_since_restore: 360
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 830
  policy_reward_mean: {}
  time_since_restore: 4672.528569698334
  time_this_iter_s: 13.130159616470337
  time_total_s: 4672.528569698334
  timestamp: 1593814482
  timesteps_since_restore: 1800000
  timesteps_this_iter: 5000
  timesteps_total: 1800000
  training_iteration: 360
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 14.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=830], 4672 s, 360 iter, 1800000 ts, 520 rew

agent-1: 105.0
agent-2: 79.0
agent-3: 74.0
agent-4: 105.0
agent-5: 86.0
Sum Reward: 449.0
Avg Reward: 89.8
Min Reward: 74.0
Gini Coefficient 0.07839643652561247
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_18-14-54
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 763.0
  episode_reward_mean: 519.92
  episode_reward_min: 315.0
  episodes_this_iter: 1
  episodes_total: 360
  experiment_id: f3470259fa9143609a5dd5049ba7f979
  hostname: gpu020
  info:
    apply_time_ms: 3.705
    dispatch_time_ms: 9.093
    learner:
      cur_lr: 0.0012401200365275145
      grad_gnorm: 16.22041893005371
      policy_entropy: 25.431764602661133
      policy_loss: 0.6346760392189026
      var_gnorm: 46.5682373046875
      vf_explained_var: 0.6279934644699097
      vf_loss: 8.89152717590332
    num_steps_sampled: 1805000
    num_steps_trained: 1805000
    wait_time_ms: 111.644
  iterations_since_restore: 361
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 830
  policy_reward_mean: {}
  time_since_restore: 4684.490535497665
  time_this_iter_s: 11.961965799331665
  time_total_s: 4684.490535497665
  timestamp: 1593814494
  timesteps_since_restore: 1805000
  timesteps_this_iter: 5000
  timesteps_total: 1805000
  training_iteration: 361
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 14.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=830], 4684 s, 361 iter, 1805000 ts, 520 rew

agent-1: 85.0
agent-2: 81.0
agent-3: 80.0
agent-4: 76.0
agent-5: 72.0
Sum Reward: 394.0
Avg Reward: 78.8
Min Reward: 72.0
Gini Coefficient 0.03147208121827411
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_18-15-08
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 763.0
  episode_reward_mean: 518.5
  episode_reward_min: 315.0
  episodes_this_iter: 1
  episodes_total: 361
  experiment_id: f3470259fa9143609a5dd5049ba7f979
  hostname: gpu020
  info:
    apply_time_ms: 2.748
    dispatch_time_ms: 81.202
    learner:
      cur_lr: 0.0012397869722917676
      grad_gnorm: 24.81995391845703
      policy_entropy: 38.48369216918945
      policy_loss: 0.03504803031682968
      var_gnorm: 46.593116760253906
      vf_explained_var: 2.9802322387695312e-06
      vf_loss: 0.5951911807060242
    num_steps_sampled: 1810000
    num_steps_trained: 1810000
    wait_time_ms: 63.088
  iterations_since_restore: 362
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 830
  policy_reward_mean: {}
  time_since_restore: 4697.837595462799
  time_this_iter_s: 13.347059965133667
  time_total_s: 4697.837595462799
  timestamp: 1593814508
  timesteps_since_restore: 1810000
  timesteps_this_iter: 5000
  timesteps_total: 1810000
  training_iteration: 362
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 14.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=830], 4697 s, 362 iter, 1810000 ts, 518 rew

agent-1: 51.0
agent-2: 68.0
agent-3: 52.0
agent-4: 55.0
agent-5: 60.0
Sum Reward: 286.0
Avg Reward: 57.2
Min Reward: 51.0
Gini Coefficient 0.05874125874125874
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_18-15-21
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 763.0
  episode_reward_mean: 515.17
  episode_reward_min: 286.0
  episodes_this_iter: 1
  episodes_total: 362
  experiment_id: f3470259fa9143609a5dd5049ba7f979
  hostname: gpu020
  info:
    apply_time_ms: 2.589
    dispatch_time_ms: 13.153
    learner:
      cur_lr: 0.0012394540244713426
      grad_gnorm: 40.0
      policy_entropy: 35.04307174682617
      policy_loss: -4.1048431396484375
      var_gnorm: 46.739192962646484
      vf_explained_var: -1.0
      vf_loss: 13.126805305480957
    num_steps_sampled: 1815000
    num_steps_trained: 1815000
    wait_time_ms: 104.863
  iterations_since_restore: 363
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 830
  policy_reward_mean: {}
  time_since_restore: 4710.751277923584
  time_this_iter_s: 12.913682460784912
  time_total_s: 4710.751277923584
  timestamp: 1593814521
  timesteps_since_restore: 1815000
  timesteps_this_iter: 5000
  timesteps_total: 1815000
  training_iteration: 363
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 14.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=830], 4710 s, 363 iter, 1815000 ts, 515 rew

agent-1: 96.0
agent-2: 45.0
agent-3: 63.0
agent-4: 59.0
agent-5: 55.0
Sum Reward: 318.0
Avg Reward: 63.6
Min Reward: 45.0
Gini Coefficient 0.13836477987421383
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_18-15-51
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 763.0
  episode_reward_mean: 513.52
  episode_reward_min: 286.0
  episodes_this_iter: 1
  episodes_total: 363
  experiment_id: f3470259fa9143609a5dd5049ba7f979
  hostname: gpu020
  info:
    apply_time_ms: 3.932
    dispatch_time_ms: 11.105
    learner:
      cur_lr: 0.0012391209602355957
      grad_gnorm: 40.0
      policy_entropy: 2.275101900100708
      policy_loss: 7.913307189941406
      var_gnorm: 46.76173400878906
      vf_explained_var: -0.21898651123046875
      vf_loss: 62.521949768066406
    num_steps_sampled: 1820000
    num_steps_trained: 1820000
    wait_time_ms: 101.183
  iterations_since_restore: 364
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 830
  policy_reward_mean: {}
  time_since_restore: 4740.822629213333
  time_this_iter_s: 30.071351289749146
  time_total_s: 4740.822629213333
  timestamp: 1593814551
  timesteps_since_restore: 1820000
  timesteps_this_iter: 5000
  timesteps_total: 1820000
  training_iteration: 364
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 14.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=830], 4740 s, 364 iter, 1820000 ts, 514 rew

agent-1: 70.0
agent-2: 87.0
agent-3: 84.0
agent-4: 95.0
agent-5: 58.0
Sum Reward: 394.0
Avg Reward: 78.8
Min Reward: 58.0
Gini Coefficient 0.09238578680203045
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_18-16-04
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 763.0
  episode_reward_mean: 511.42
  episode_reward_min: 286.0
  episodes_this_iter: 1
  episodes_total: 364
  experiment_id: f3470259fa9143609a5dd5049ba7f979
  hostname: gpu020
  info:
    apply_time_ms: 2.692
    dispatch_time_ms: 91.064
    learner:
      cur_lr: 0.0012387880124151707
      grad_gnorm: 14.912028312683105
      policy_entropy: 33.621368408203125
      policy_loss: -3.4812910556793213
      var_gnorm: 46.803489685058594
      vf_explained_var: 0.9925515651702881
      vf_loss: 0.3003217577934265
    num_steps_sampled: 1825000
    num_steps_trained: 1825000
    wait_time_ms: 246.039
  iterations_since_restore: 365
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 830
  policy_reward_mean: {}
  time_since_restore: 4754.636743783951
  time_this_iter_s: 13.814114570617676
  time_total_s: 4754.636743783951
  timestamp: 1593814564
  timesteps_since_restore: 1825000
  timesteps_this_iter: 5000
  timesteps_total: 1825000
  training_iteration: 365
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 14.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=830], 4754 s, 365 iter, 1825000 ts, 511 rew

agent-1: 89.0
agent-2: 30.0
agent-3: 84.0
agent-4: 56.0
agent-5: 84.0
Sum Reward: 343.0
Avg Reward: 68.6
Min Reward: 30.0
Gini Coefficient 0.17026239067055393
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_18-16-25
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 763.0
  episode_reward_mean: 510.09
  episode_reward_min: 286.0
  episodes_this_iter: 1
  episodes_total: 365
  experiment_id: f3470259fa9143609a5dd5049ba7f979
  hostname: gpu020
  info:
    apply_time_ms: 3.375
    dispatch_time_ms: 43.315
    learner:
      cur_lr: 0.0012384549481794238
      grad_gnorm: 18.340778350830078
      policy_entropy: 0.982923686504364
      policy_loss: 2.1722159385681152
      var_gnorm: 46.81435775756836
      vf_explained_var: -0.530622124671936
      vf_loss: 45.76638412475586
    num_steps_sampled: 1830000
    num_steps_trained: 1830000
    wait_time_ms: 100.706
  iterations_since_restore: 366
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 830
  policy_reward_mean: {}
  time_since_restore: 4775.617330312729
  time_this_iter_s: 20.980586528778076
  time_total_s: 4775.617330312729
  timestamp: 1593814585
  timesteps_since_restore: 1830000
  timesteps_this_iter: 5000
  timesteps_total: 1830000
  training_iteration: 366
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 14.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=830], 4775 s, 366 iter, 1830000 ts, 510 rew

agent-1: 75.0
agent-2: 84.0
agent-3: 86.0
agent-4: 77.0
agent-5: 58.0
Sum Reward: 380.0
Avg Reward: 76.0
Min Reward: 58.0
Gini Coefficient 0.06842105263157895
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_18-16-41
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 763.0
  episode_reward_mean: 507.76
  episode_reward_min: 286.0
  episodes_this_iter: 1
  episodes_total: 366
  experiment_id: f3470259fa9143609a5dd5049ba7f979
  hostname: gpu020
  info:
    apply_time_ms: 4.64
    dispatch_time_ms: 59.842
    learner:
      cur_lr: 0.0012381220003589988
      grad_gnorm: 39.99999237060547
      policy_entropy: 27.883291244506836
      policy_loss: 12.106742858886719
      var_gnorm: 46.94133758544922
      vf_explained_var: 0.6718171238899231
      vf_loss: 38.75466537475586
    num_steps_sampled: 1835000
    num_steps_trained: 1835000
    wait_time_ms: 56.276
  iterations_since_restore: 367
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 830
  policy_reward_mean: {}
  time_since_restore: 4790.7839550971985
  time_this_iter_s: 15.166624784469604
  time_total_s: 4790.7839550971985
  timestamp: 1593814601
  timesteps_since_restore: 1835000
  timesteps_this_iter: 5000
  timesteps_total: 1835000
  training_iteration: 367
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 14.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=830], 4790 s, 367 iter, 1835000 ts, 508 rew

agent-1: 47.0
agent-2: 53.0
agent-3: 54.0
agent-4: 59.0
agent-5: 81.0
Sum Reward: 294.0
Avg Reward: 58.8
Min Reward: 47.0
Gini Coefficient 0.10068027210884353
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_18-16-55
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 763.0
  episode_reward_mean: 503.86
  episode_reward_min: 286.0
  episodes_this_iter: 1
  episodes_total: 367
  experiment_id: f3470259fa9143609a5dd5049ba7f979
  hostname: gpu020
  info:
    apply_time_ms: 3.511
    dispatch_time_ms: 195.468
    learner:
      cur_lr: 0.0012377890525385737
      grad_gnorm: 40.00000762939453
      policy_entropy: 6.507709980010986
      policy_loss: 30.603960037231445
      var_gnorm: 46.93830490112305
      vf_explained_var: -0.18207573890686035
      vf_loss: 168.01075744628906
    num_steps_sampled: 1840000
    num_steps_trained: 1840000
    wait_time_ms: 75.4
  iterations_since_restore: 368
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 830
  policy_reward_mean: {}
  time_since_restore: 4805.552940368652
  time_this_iter_s: 14.768985271453857
  time_total_s: 4805.552940368652
  timestamp: 1593814615
  timesteps_since_restore: 1840000
  timesteps_this_iter: 5000
  timesteps_total: 1840000
  training_iteration: 368
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 14.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=830], 4805 s, 368 iter, 1840000 ts, 504 rew

agent-1: 100.0
agent-2: 100.0
agent-3: 112.0
agent-4: 86.0
agent-5: 76.0
Sum Reward: 474.0
Avg Reward: 94.8
Min Reward: 76.0
Gini Coefficient 0.07257383966244725
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_18-17-12
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 763.0
  episode_reward_mean: 501.84
  episode_reward_min: 286.0
  episodes_this_iter: 1
  episodes_total: 368
  experiment_id: f3470259fa9143609a5dd5049ba7f979
  hostname: gpu020
  info:
    apply_time_ms: 2.879
    dispatch_time_ms: 56.077
    learner:
      cur_lr: 0.0012374559883028269
      grad_gnorm: 39.999996185302734
      policy_entropy: 20.539379119873047
      policy_loss: -0.8624522686004639
      var_gnorm: 47.0810661315918
      vf_explained_var: -1.0
      vf_loss: 0.6848289966583252
    num_steps_sampled: 1845000
    num_steps_trained: 1845000
    wait_time_ms: 92.368
  iterations_since_restore: 369
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 830
  policy_reward_mean: {}
  time_since_restore: 4821.893378973007
  time_this_iter_s: 16.34043860435486
  time_total_s: 4821.893378973007
  timestamp: 1593814632
  timesteps_since_restore: 1845000
  timesteps_this_iter: 5000
  timesteps_total: 1845000
  training_iteration: 369
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 14.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=830], 4821 s, 369 iter, 1845000 ts, 502 rew

agent-1: 81.0
agent-2: 60.0
agent-3: 57.0
agent-4: 76.0
agent-5: 80.0
Sum Reward: 354.0
Avg Reward: 70.8
Min Reward: 57.0
Gini Coefficient 0.0768361581920904
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_18-17-24
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 763.0
  episode_reward_mean: 498.2
  episode_reward_min: 286.0
  episodes_this_iter: 1
  episodes_total: 369
  experiment_id: f3470259fa9143609a5dd5049ba7f979
  hostname: gpu020
  info:
    apply_time_ms: 3.272
    dispatch_time_ms: 10.483
    learner:
      cur_lr: 0.0012371230404824018
      grad_gnorm: 40.00001525878906
      policy_entropy: 12.813569068908691
      policy_loss: 2.3621931076049805
      var_gnorm: 47.11964416503906
      vf_explained_var: 0.5551998615264893
      vf_loss: 47.21194076538086
    num_steps_sampled: 1850000
    num_steps_trained: 1850000
    wait_time_ms: 103.649
  iterations_since_restore: 370
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 830
  policy_reward_mean: {}
  time_since_restore: 4834.262459278107
  time_this_iter_s: 12.369080305099487
  time_total_s: 4834.262459278107
  timestamp: 1593814644
  timesteps_since_restore: 1850000
  timesteps_this_iter: 5000
  timesteps_total: 1850000
  training_iteration: 370
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 14.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=830], 4834 s, 370 iter, 1850000 ts, 498 rew

agent-1: 74.0
agent-2: 84.0
agent-3: 47.0
agent-4: 83.0
agent-5: 103.0
Sum Reward: 391.0
Avg Reward: 78.2
Min Reward: 47.0
Gini Coefficient 0.1248081841432225
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_18-17-36
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 763.0
  episode_reward_mean: 495.45
  episode_reward_min: 286.0
  episodes_this_iter: 1
  episodes_total: 370
  experiment_id: f3470259fa9143609a5dd5049ba7f979
  hostname: gpu020
  info:
    apply_time_ms: 3.649
    dispatch_time_ms: 16.161
    learner:
      cur_lr: 0.001236789976246655
      grad_gnorm: 40.000003814697266
      policy_entropy: 21.095691680908203
      policy_loss: -10.338205337524414
      var_gnorm: 47.20274353027344
      vf_explained_var: 0.6516048908233643
      vf_loss: 24.87643814086914
    num_steps_sampled: 1855000
    num_steps_trained: 1855000
    wait_time_ms: 101.368
  iterations_since_restore: 371
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 830
  policy_reward_mean: {}
  time_since_restore: 4845.955947637558
  time_this_iter_s: 11.693488359451294
  time_total_s: 4845.955947637558
  timestamp: 1593814656
  timesteps_since_restore: 1855000
  timesteps_this_iter: 5000
  timesteps_total: 1855000
  training_iteration: 371
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 14.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=830], 4845 s, 371 iter, 1855000 ts, 495 rew

agent-1: 103.0
agent-2: 101.0
agent-3: 93.0
agent-4: 66.0
agent-5: 88.0
Sum Reward: 451.0
Avg Reward: 90.2
Min Reward: 66.0
Gini Coefficient 0.07716186252771619
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_18-17-50
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 746.0
  episode_reward_mean: 492.33
  episode_reward_min: 286.0
  episodes_this_iter: 1
  episodes_total: 371
  experiment_id: f3470259fa9143609a5dd5049ba7f979
  hostname: gpu020
  info:
    apply_time_ms: 5.231
    dispatch_time_ms: 55.278
    learner:
      cur_lr: 0.00123645702842623
      grad_gnorm: 40.00000762939453
      policy_entropy: 7.563540458679199
      policy_loss: 8.053412437438965
      var_gnorm: 47.25646209716797
      vf_explained_var: 0.5906348824501038
      vf_loss: 35.22646713256836
    num_steps_sampled: 1860000
    num_steps_trained: 1860000
    wait_time_ms: 49.385
  iterations_since_restore: 372
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 830
  policy_reward_mean: {}
  time_since_restore: 4860.084609270096
  time_this_iter_s: 14.128661632537842
  time_total_s: 4860.084609270096
  timestamp: 1593814670
  timesteps_since_restore: 1860000
  timesteps_this_iter: 5000
  timesteps_total: 1860000
  training_iteration: 372
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 14.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=830], 4860 s, 372 iter, 1860000 ts, 492 rew

agent-1: 84.0
agent-2: 88.0
agent-3: 92.0
agent-4: 119.0
agent-5: 80.0
Sum Reward: 463.0
Avg Reward: 92.6
Min Reward: 80.0
Gini Coefficient 0.07429805615550755
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_18-18-01
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 739.0
  episode_reward_mean: 489.5
  episode_reward_min: 286.0
  episodes_this_iter: 1
  episodes_total: 372
  experiment_id: f3470259fa9143609a5dd5049ba7f979
  hostname: gpu020
  info:
    apply_time_ms: 2.768
    dispatch_time_ms: 16.51
    learner:
      cur_lr: 0.001236123964190483
      grad_gnorm: 9.04593276977539
      policy_entropy: 35.169795989990234
      policy_loss: -2.6509735584259033
      var_gnorm: 47.25624465942383
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 0.09920720756053925
    num_steps_sampled: 1865000
    num_steps_trained: 1865000
    wait_time_ms: 109.437
  iterations_since_restore: 373
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 830
  policy_reward_mean: {}
  time_since_restore: 4871.405888795853
  time_this_iter_s: 11.321279525756836
  time_total_s: 4871.405888795853
  timestamp: 1593814681
  timesteps_since_restore: 1865000
  timesteps_this_iter: 5000
  timesteps_total: 1865000
  training_iteration: 373
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 14.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=830], 4871 s, 373 iter, 1865000 ts, 490 rew

agent-1: 55.0
agent-2: 50.0
agent-3: 98.0
agent-4: 55.0
agent-5: 50.0
Sum Reward: 308.0
Avg Reward: 61.6
Min Reward: 50.0
Gini Coefficient 0.13116883116883116
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_18-18-15
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 739.0
  episode_reward_mean: 486.22
  episode_reward_min: 286.0
  episodes_this_iter: 1
  episodes_total: 373
  experiment_id: f3470259fa9143609a5dd5049ba7f979
  hostname: gpu020
  info:
    apply_time_ms: 2.647
    dispatch_time_ms: 51.043
    learner:
      cur_lr: 0.001235791016370058
      grad_gnorm: 2.5036590099334717
      policy_entropy: 34.04523849487305
      policy_loss: -1.012423038482666
      var_gnorm: 47.27617263793945
      vf_explained_var: 5.960464477539063e-08
      vf_loss: 0.0108417309820652
    num_steps_sampled: 1870000
    num_steps_trained: 1870000
    wait_time_ms: 141.853
  iterations_since_restore: 374
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 830
  policy_reward_mean: {}
  time_since_restore: 4884.484689235687
  time_this_iter_s: 13.078800439834595
  time_total_s: 4884.484689235687
  timestamp: 1593814695
  timesteps_since_restore: 1870000
  timesteps_this_iter: 5000
  timesteps_total: 1870000
  training_iteration: 374
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 14.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=830], 4884 s, 374 iter, 1870000 ts, 486 rew

agent-1: 67.0
agent-2: 67.0
agent-3: 74.0
agent-4: 61.0
agent-5: 68.0
Sum Reward: 337.0
Avg Reward: 67.4
Min Reward: 61.0
Gini Coefficient 0.032047477744807124
W0703 18:18:20.250435   825 node_manager.cc:250] Last heartbeat was sent 571 ms ago 
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_18-18-28
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 739.0
  episode_reward_mean: 484.04
  episode_reward_min: 286.0
  episodes_this_iter: 1
  episodes_total: 374
  experiment_id: f3470259fa9143609a5dd5049ba7f979
  hostname: gpu020
  info:
    apply_time_ms: 2.718
    dispatch_time_ms: 11.501
    learner:
      cur_lr: 0.0012354579521343112
      grad_gnorm: 22.93385124206543
      policy_entropy: 31.53427505493164
      policy_loss: 3.7864556312561035
      var_gnorm: 47.32139205932617
      vf_explained_var: 0.09120166301727295
      vf_loss: 3.115856885910034
    num_steps_sampled: 1875000
    num_steps_trained: 1875000
    wait_time_ms: 107.894
  iterations_since_restore: 375
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 830
  policy_reward_mean: {}
  time_since_restore: 4897.957778930664
  time_this_iter_s: 13.473089694976807
  time_total_s: 4897.957778930664
  timestamp: 1593814708
  timesteps_since_restore: 1875000
  timesteps_this_iter: 5000
  timesteps_total: 1875000
  training_iteration: 375
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 14.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=830], 4897 s, 375 iter, 1875000 ts, 484 rew

agent-1: 61.0
agent-2: 74.0
agent-3: 92.0
agent-4: 52.0
agent-5: 82.0
Sum Reward: 361.0
Avg Reward: 72.2
Min Reward: 52.0
Gini Coefficient 0.11191135734072022
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_18-18-40
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 739.0
  episode_reward_mean: 482.24
  episode_reward_min: 286.0
  episodes_this_iter: 1
  episodes_total: 375
  experiment_id: f3470259fa9143609a5dd5049ba7f979
  hostname: gpu020
  info:
    apply_time_ms: 2.811
    dispatch_time_ms: 13.663
    learner:
      cur_lr: 0.0012351250043138862
      grad_gnorm: 14.25825023651123
      policy_entropy: 25.48065185546875
      policy_loss: 2.006842613220215
      var_gnorm: 47.30894088745117
      vf_explained_var: 0.4093679189682007
      vf_loss: 3.619607448577881
    num_steps_sampled: 1880000
    num_steps_trained: 1880000
    wait_time_ms: 97.027
  iterations_since_restore: 376
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 830
  policy_reward_mean: {}
  time_since_restore: 4910.277560710907
  time_this_iter_s: 12.31978178024292
  time_total_s: 4910.277560710907
  timestamp: 1593814720
  timesteps_since_restore: 1880000
  timesteps_this_iter: 5000
  timesteps_total: 1880000
  training_iteration: 376
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 14.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=830], 4910 s, 376 iter, 1880000 ts, 482 rew

agent-1: 80.0
agent-2: 83.0
agent-3: 60.0
agent-4: 57.0
agent-5: 64.0
Sum Reward: 344.0
Avg Reward: 68.8
Min Reward: 57.0
Gini Coefficient 0.08372093023255814
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_18-18-54
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 739.0
  episode_reward_mean: 479.58
  episode_reward_min: 286.0
  episodes_this_iter: 1
  episodes_total: 376
  experiment_id: f3470259fa9143609a5dd5049ba7f979
  hostname: gpu020
  info:
    apply_time_ms: 4.48
    dispatch_time_ms: 28.38
    learner:
      cur_lr: 0.0012347920564934611
      grad_gnorm: 7.752175331115723
      policy_entropy: 13.814377784729004
      policy_loss: -1.2830606698989868
      var_gnorm: 47.42686462402344
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 0.07520555704832077
    num_steps_sampled: 1885000
    num_steps_trained: 1885000
    wait_time_ms: 52.045
  iterations_since_restore: 377
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 830
  policy_reward_mean: {}
  time_since_restore: 4923.734558582306
  time_this_iter_s: 13.456997871398926
  time_total_s: 4923.734558582306
  timestamp: 1593814734
  timesteps_since_restore: 1885000
  timesteps_this_iter: 5000
  timesteps_total: 1885000
  training_iteration: 377
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 14.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=830], 4923 s, 377 iter, 1885000 ts, 480 rew

agent-1: 87.0
agent-2: 76.0
agent-3: 47.0
agent-4: 62.0
agent-5: 49.0
Sum Reward: 321.0
Avg Reward: 64.2
Min Reward: 47.0
Gini Coefficient 0.13333333333333333
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_18-19-06
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 739.0
  episode_reward_mean: 476.72
  episode_reward_min: 286.0
  episodes_this_iter: 1
  episodes_total: 377
  experiment_id: f3470259fa9143609a5dd5049ba7f979
  hostname: gpu020
  info:
    apply_time_ms: 3.936
    dispatch_time_ms: 11.45
    learner:
      cur_lr: 0.0012344589922577143
      grad_gnorm: 7.853222370147705
      policy_entropy: 35.99357986450195
      policy_loss: -1.6101367473602295
      var_gnorm: 47.5057258605957
      vf_explained_var: 0.0
      vf_loss: 0.07588250190019608
    num_steps_sampled: 1890000
    num_steps_trained: 1890000
    wait_time_ms: 97.62
  iterations_since_restore: 378
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 830
  policy_reward_mean: {}
  time_since_restore: 4935.787628889084
  time_this_iter_s: 12.053070306777954
  time_total_s: 4935.787628889084
  timestamp: 1593814746
  timesteps_since_restore: 1890000
  timesteps_this_iter: 5000
  timesteps_total: 1890000
  training_iteration: 378
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 14.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=830], 4935 s, 378 iter, 1890000 ts, 477 rew

agent-1: 79.0
agent-2: 79.0
agent-3: 53.0
agent-4: 96.0
agent-5: 71.0
Sum Reward: 378.0
Avg Reward: 75.6
Min Reward: 53.0
Gini Coefficient 0.09947089947089947
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_18-19-18
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 739.0
  episode_reward_mean: 474.79
  episode_reward_min: 286.0
  episodes_this_iter: 1
  episodes_total: 378
  experiment_id: f3470259fa9143609a5dd5049ba7f979
  hostname: gpu020
  info:
    apply_time_ms: 2.372
    dispatch_time_ms: 17.752
    learner:
      cur_lr: 0.0012341260444372892
      grad_gnorm: 14.839176177978516
      policy_entropy: 30.155942916870117
      policy_loss: -2.794865131378174
      var_gnorm: 47.57275390625
      vf_explained_var: 0.0
      vf_loss: 0.2667660415172577
    num_steps_sampled: 1895000
    num_steps_trained: 1895000
    wait_time_ms: 102.25
  iterations_since_restore: 379
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 830
  policy_reward_mean: {}
  time_since_restore: 4947.727928161621
  time_this_iter_s: 11.940299272537231
  time_total_s: 4947.727928161621
  timestamp: 1593814758
  timesteps_since_restore: 1895000
  timesteps_this_iter: 5000
  timesteps_total: 1895000
  training_iteration: 379
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 14.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=830], 4947 s, 379 iter, 1895000 ts, 475 rew

agent-1: 61.0
agent-2: 76.0
agent-3: 69.0
agent-4: 82.0
agent-5: 91.0
Sum Reward: 379.0
Avg Reward: 75.8
Min Reward: 61.0
Gini Coefficient 0.07704485488126649
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_18-19-31
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 739.0
  episode_reward_mean: 473.62
  episode_reward_min: 286.0
  episodes_this_iter: 1
  episodes_total: 379
  experiment_id: f3470259fa9143609a5dd5049ba7f979
  hostname: gpu020
  info:
    apply_time_ms: 3.297
    dispatch_time_ms: 11.865
    learner:
      cur_lr: 0.0012337929802015424
      grad_gnorm: 15.731379508972168
      policy_entropy: 34.50482940673828
      policy_loss: 2.6740832328796387
      var_gnorm: 47.56766891479492
      vf_explained_var: 0.8941534757614136
      vf_loss: 2.084601879119873
    num_steps_sampled: 1900000
    num_steps_trained: 1900000
    wait_time_ms: 83.216
  iterations_since_restore: 380
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 830
  policy_reward_mean: {}
  time_since_restore: 4960.875374078751
  time_this_iter_s: 13.147445917129517
  time_total_s: 4960.875374078751
  timestamp: 1593814771
  timesteps_since_restore: 1900000
  timesteps_this_iter: 5000
  timesteps_total: 1900000
  training_iteration: 380
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 14.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=830], 4960 s, 380 iter, 1900000 ts, 474 rew

agent-1: 81.0
agent-2: 58.0
agent-3: 53.0
agent-4: 59.0
agent-5: 85.0
Sum Reward: 336.0
Avg Reward: 67.2
Min Reward: 53.0
Gini Coefficient 0.10357142857142858
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_18-19-43
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 739.0
  episode_reward_mean: 472.21
  episode_reward_min: 286.0
  episodes_this_iter: 1
  episodes_total: 380
  experiment_id: f3470259fa9143609a5dd5049ba7f979
  hostname: gpu020
  info:
    apply_time_ms: 2.783
    dispatch_time_ms: 18.544
    learner:
      cur_lr: 0.0012334600323811173
      grad_gnorm: 40.0
      policy_entropy: 10.022136688232422
      policy_loss: -11.015195846557617
      var_gnorm: 47.57021713256836
      vf_explained_var: 0.5952991247177124
      vf_loss: 40.377960205078125
    num_steps_sampled: 1905000
    num_steps_trained: 1905000
    wait_time_ms: 105.442
  iterations_since_restore: 381
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 830
  policy_reward_mean: {}
  time_since_restore: 4972.6517379283905
  time_this_iter_s: 11.776363849639893
  time_total_s: 4972.6517379283905
  timestamp: 1593814783
  timesteps_since_restore: 1905000
  timesteps_this_iter: 5000
  timesteps_total: 1905000
  training_iteration: 381
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 14.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=830], 4972 s, 381 iter, 1905000 ts, 472 rew

agent-1: 72.0
agent-2: 94.0
agent-3: 73.0
agent-4: 69.0
agent-5: 54.0
Sum Reward: 362.0
Avg Reward: 72.4
Min Reward: 54.0
Gini Coefficient 0.09281767955801105
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_18-19-55
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 739.0
  episode_reward_mean: 469.61
  episode_reward_min: 286.0
  episodes_this_iter: 1
  episodes_total: 381
  experiment_id: f3470259fa9143609a5dd5049ba7f979
  hostname: gpu020
  info:
    apply_time_ms: 2.718
    dispatch_time_ms: 10.654
    learner:
      cur_lr: 0.0012331269681453705
      grad_gnorm: 4.003018379211426
      policy_entropy: 36.919921875
      policy_loss: 1.3522881269454956
      var_gnorm: 47.51716995239258
      vf_explained_var: 0.0
      vf_loss: 0.019610213115811348
    num_steps_sampled: 1910000
    num_steps_trained: 1910000
    wait_time_ms: 95.553
  iterations_since_restore: 382
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 830
  policy_reward_mean: {}
  time_since_restore: 4984.9640374183655
  time_this_iter_s: 12.312299489974976
  time_total_s: 4984.9640374183655
  timestamp: 1593814795
  timesteps_since_restore: 1910000
  timesteps_this_iter: 5000
  timesteps_total: 1910000
  training_iteration: 382
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 14.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=830], 4984 s, 382 iter, 1910000 ts, 470 rew

agent-1: 109.0
agent-2: 70.0
agent-3: 87.0
agent-4: 74.0
agent-5: 58.0
Sum Reward: 398.0
Avg Reward: 79.6
Min Reward: 58.0
Gini Coefficient 0.11959798994974874
W0703 18:20:05.925442   825 client_connection.cc:255] [worker]ProcessMessage with type 8 took 3436 ms.
W0703 18:20:05.925547   825 node_manager.cc:250] Last heartbeat was sent 3534 ms ago 
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_18-20-11
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 739.0
  episode_reward_mean: 466.73
  episode_reward_min: 286.0
  episodes_this_iter: 1
  episodes_total: 382
  experiment_id: f3470259fa9143609a5dd5049ba7f979
  hostname: gpu020
  info:
    apply_time_ms: 3.217
    dispatch_time_ms: 10.012
    learner:
      cur_lr: 0.0012327940203249454
      grad_gnorm: 9.922908782958984
      policy_entropy: 33.15066909790039
      policy_loss: -1.3013014793395996
      var_gnorm: 47.62938690185547
      vf_explained_var: 0.9957188367843628
      vf_loss: 0.2718353867530823
    num_steps_sampled: 1915000
    num_steps_trained: 1915000
    wait_time_ms: 115.246
  iterations_since_restore: 383
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 830
  policy_reward_mean: {}
  time_since_restore: 5000.891840457916
  time_this_iter_s: 15.927803039550781
  time_total_s: 5000.891840457916
  timestamp: 1593814811
  timesteps_since_restore: 1915000
  timesteps_this_iter: 5000
  timesteps_total: 1915000
  training_iteration: 383
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 14.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=830], 5000 s, 383 iter, 1915000 ts, 467 rew

agent-1: 73.0
agent-2: 92.0
agent-3: 66.0
agent-4: 58.0
agent-5: 77.0
Sum Reward: 366.0
Avg Reward: 73.2
Min Reward: 58.0
Gini Coefficient 0.08633879781420765
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_18-20-24
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 739.0
  episode_reward_mean: 463.69
  episode_reward_min: 286.0
  episodes_this_iter: 1
  episodes_total: 383
  experiment_id: f3470259fa9143609a5dd5049ba7f979
  hostname: gpu020
  info:
    apply_time_ms: 3.354
    dispatch_time_ms: 14.377
    learner:
      cur_lr: 0.0012324609560891986
      grad_gnorm: 2.370356798171997
      policy_entropy: 33.42107391357422
      policy_loss: 0.5220742225646973
      var_gnorm: 47.64298629760742
      vf_explained_var: 0.0
      vf_loss: 0.006839695852249861
    num_steps_sampled: 1920000
    num_steps_trained: 1920000
    wait_time_ms: 103.424
  iterations_since_restore: 384
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 830
  policy_reward_mean: {}
  time_since_restore: 5013.292057752609
  time_this_iter_s: 12.400217294692993
  time_total_s: 5013.292057752609
  timestamp: 1593814824
  timesteps_since_restore: 1920000
  timesteps_this_iter: 5000
  timesteps_total: 1920000
  training_iteration: 384
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 14.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=830], 5013 s, 384 iter, 1920000 ts, 464 rew

agent-1: 65.0
agent-2: 77.0
agent-3: 69.0
agent-4: 74.0
agent-5: 75.0
Sum Reward: 360.0
Avg Reward: 72.0
Min Reward: 65.0
Gini Coefficient 0.03333333333333333
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_18-20-38
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 739.0
  episode_reward_mean: 462.0
  episode_reward_min: 286.0
  episodes_this_iter: 1
  episodes_total: 384
  experiment_id: f3470259fa9143609a5dd5049ba7f979
  hostname: gpu020
  info:
    apply_time_ms: 2.489
    dispatch_time_ms: 11.478
    learner:
      cur_lr: 0.0012321280082687736
      grad_gnorm: 1.9389021396636963
      policy_entropy: 27.04641342163086
      policy_loss: -0.20316611230373383
      var_gnorm: 47.67223358154297
      vf_explained_var: 0.9958714842796326
      vf_loss: 0.024281363934278488
    num_steps_sampled: 1925000
    num_steps_trained: 1925000
    wait_time_ms: 111.064
  iterations_since_restore: 385
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 830
  policy_reward_mean: {}
  time_since_restore: 5027.809632539749
  time_this_iter_s: 14.517574787139893
  time_total_s: 5027.809632539749
  timestamp: 1593814838
  timesteps_since_restore: 1925000
  timesteps_this_iter: 5000
  timesteps_total: 1925000
  training_iteration: 385
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 14.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=830], 5027 s, 385 iter, 1925000 ts, 462 rew

agent-1: 86.0
agent-2: 68.0
agent-3: 64.0
agent-4: 50.0
agent-5: 71.0
Sum Reward: 339.0
Avg Reward: 67.8
Min Reward: 50.0
Gini Coefficient 0.09321533923303835
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_18-20-51
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 739.0
  episode_reward_mean: 459.53
  episode_reward_min: 286.0
  episodes_this_iter: 1
  episodes_total: 385
  experiment_id: f3470259fa9143609a5dd5049ba7f979
  hostname: gpu020
  info:
    apply_time_ms: 4.269
    dispatch_time_ms: 14.85
    learner:
      cur_lr: 0.0012317949440330267
      grad_gnorm: 5.584151268005371
      policy_entropy: 28.1015625
      policy_loss: 1.1302169561386108
      var_gnorm: 47.746681213378906
      vf_explained_var: 0.0
      vf_loss: 0.03761986270546913
    num_steps_sampled: 1930000
    num_steps_trained: 1930000
    wait_time_ms: 96.808
  iterations_since_restore: 386
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 830
  policy_reward_mean: {}
  time_since_restore: 5040.212307691574
  time_this_iter_s: 12.402675151824951
  time_total_s: 5040.212307691574
  timestamp: 1593814851
  timesteps_since_restore: 1930000
  timesteps_this_iter: 5000
  timesteps_total: 1930000
  training_iteration: 386
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 14.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=830], 5040 s, 386 iter, 1930000 ts, 460 rew

agent-1: 66.0
agent-2: 71.0
agent-3: 101.0
agent-4: 99.0
agent-5: 86.0
Sum Reward: 423.0
Avg Reward: 84.6
Min Reward: 66.0
Gini Coefficient 0.09267139479905437
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_18-21-03
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 739.0
  episode_reward_mean: 456.92
  episode_reward_min: 286.0
  episodes_this_iter: 1
  episodes_total: 386
  experiment_id: f3470259fa9143609a5dd5049ba7f979
  hostname: gpu020
  info:
    apply_time_ms: 2.497
    dispatch_time_ms: 14.079
    learner:
      cur_lr: 0.0012314619962126017
      grad_gnorm: 25.076475143432617
      policy_entropy: 32.48178482055664
      policy_loss: 8.556045532226562
      var_gnorm: 47.86642837524414
      vf_explained_var: 0.08531910181045532
      vf_loss: 2.758688449859619
    num_steps_sampled: 1935000
    num_steps_trained: 1935000
    wait_time_ms: 115.707
  iterations_since_restore: 387
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 830
  policy_reward_mean: {}
  time_since_restore: 5052.212089776993
  time_this_iter_s: 11.999782085418701
  time_total_s: 5052.212089776993
  timestamp: 1593814863
  timesteps_since_restore: 1935000
  timesteps_this_iter: 5000
  timesteps_total: 1935000
  training_iteration: 387
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 14.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=830], 5052 s, 387 iter, 1935000 ts, 457 rew

agent-1: 70.0
agent-2: 49.0
agent-3: 54.0
agent-4: 31.0
agent-5: 64.0
Sum Reward: 268.0
Avg Reward: 53.6
Min Reward: 31.0
Gini Coefficient 0.13880597014925372
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_18-21-27
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 739.0
  episode_reward_mean: 453.85
  episode_reward_min: 268.0
  episodes_this_iter: 1
  episodes_total: 387
  experiment_id: f3470259fa9143609a5dd5049ba7f979
  hostname: gpu020
  info:
    apply_time_ms: 4.884
    dispatch_time_ms: 6.334
    learner:
      cur_lr: 0.0012311290483921766
      grad_gnorm: 6.0034332275390625
      policy_entropy: 24.88019561767578
      policy_loss: -1.196702480316162
      var_gnorm: 47.87039566040039
      vf_explained_var: 0.9956393837928772
      vf_loss: 0.1619739979505539
    num_steps_sampled: 1940000
    num_steps_trained: 1940000
    wait_time_ms: 108.062
  iterations_since_restore: 388
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 830
  policy_reward_mean: {}
  time_since_restore: 5076.172630548477
  time_this_iter_s: 23.960540771484375
  time_total_s: 5076.172630548477
  timestamp: 1593814887
  timesteps_since_restore: 1940000
  timesteps_this_iter: 5000
  timesteps_total: 1940000
  training_iteration: 388
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 14.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=830], 5076 s, 388 iter, 1940000 ts, 454 rew

agent-1: 63.0
agent-2: 94.0
agent-3: 65.0
agent-4: 60.0
agent-5: 75.0
Sum Reward: 357.0
Avg Reward: 71.4
Min Reward: 60.0
Gini Coefficient 0.0896358543417367
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_18-21-38
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 739.0
  episode_reward_mean: 451.58
  episode_reward_min: 268.0
  episodes_this_iter: 1
  episodes_total: 388
  experiment_id: f3470259fa9143609a5dd5049ba7f979
  hostname: gpu020
  info:
    apply_time_ms: 2.562
    dispatch_time_ms: 6.106
    learner:
      cur_lr: 0.0012307959841564298
      grad_gnorm: 30.130327224731445
      policy_entropy: 31.071868896484375
      policy_loss: -9.972614288330078
      var_gnorm: 47.87345504760742
      vf_explained_var: 0.5640819668769836
      vf_loss: 27.236343383789062
    num_steps_sampled: 1945000
    num_steps_trained: 1945000
    wait_time_ms: 115.812
  iterations_since_restore: 389
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 830
  policy_reward_mean: {}
  time_since_restore: 5087.586260557175
  time_this_iter_s: 11.41363000869751
  time_total_s: 5087.586260557175
  timestamp: 1593814898
  timesteps_since_restore: 1945000
  timesteps_this_iter: 5000
  timesteps_total: 1945000
  training_iteration: 389
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 14.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=830], 5087 s, 389 iter, 1945000 ts, 452 rew

agent-1: 86.0
agent-2: 88.0
agent-3: 40.0
agent-4: 74.0
agent-5: 83.0
Sum Reward: 371.0
Avg Reward: 74.2
Min Reward: 40.0
Gini Coefficient 0.11644204851752021
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_18-21-50
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 739.0
  episode_reward_mean: 450.7
  episode_reward_min: 268.0
  episodes_this_iter: 1
  episodes_total: 389
  experiment_id: f3470259fa9143609a5dd5049ba7f979
  hostname: gpu020
  info:
    apply_time_ms: 4.527
    dispatch_time_ms: 8.899
    learner:
      cur_lr: 0.0012304630363360047
      grad_gnorm: 39.999996185302734
      policy_entropy: 17.928499221801758
      policy_loss: 5.255752086639404
      var_gnorm: 48.00429916381836
      vf_explained_var: 0.8377190828323364
      vf_loss: 14.498213768005371
    num_steps_sampled: 1950000
    num_steps_trained: 1950000
    wait_time_ms: 102.249
  iterations_since_restore: 390
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 830
  policy_reward_mean: {}
  time_since_restore: 5099.877466440201
  time_this_iter_s: 12.291205883026123
  time_total_s: 5099.877466440201
  timestamp: 1593814910
  timesteps_since_restore: 1950000
  timesteps_this_iter: 5000
  timesteps_total: 1950000
  training_iteration: 390
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 14.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=830], 5099 s, 390 iter, 1950000 ts, 451 rew

agent-1: 95.0
agent-2: 81.0
agent-3: 117.0
agent-4: 77.0
agent-5: 87.0
Sum Reward: 457.0
Avg Reward: 91.4
Min Reward: 77.0
Gini Coefficient 0.08227571115973742
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_18-22-02
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 739.0
  episode_reward_mean: 450.15
  episode_reward_min: 268.0
  episodes_this_iter: 1
  episodes_total: 390
  experiment_id: f3470259fa9143609a5dd5049ba7f979
  hostname: gpu020
  info:
    apply_time_ms: 2.983
    dispatch_time_ms: 9.313
    learner:
      cur_lr: 0.0012301299721002579
      grad_gnorm: 1.4562104940414429
      policy_entropy: 41.4554443359375
      policy_loss: 0.22664155066013336
      var_gnorm: 48.105194091796875
      vf_explained_var: 0.0
      vf_loss: 0.002600631443783641
    num_steps_sampled: 1955000
    num_steps_trained: 1955000
    wait_time_ms: 114.163
  iterations_since_restore: 391
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 830
  policy_reward_mean: {}
  time_since_restore: 5111.9195721149445
  time_this_iter_s: 12.042105674743652
  time_total_s: 5111.9195721149445
  timestamp: 1593814922
  timesteps_since_restore: 1955000
  timesteps_this_iter: 5000
  timesteps_total: 1955000
  training_iteration: 391
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 14.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=830], 5111 s, 391 iter, 1955000 ts, 450 rew

agent-1: 67.0
agent-2: 61.0
agent-3: 76.0
agent-4: 41.0
agent-5: 65.0
Sum Reward: 310.0
Avg Reward: 62.0
Min Reward: 41.0
Gini Coefficient 0.09806451612903226
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_18-22-17
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 739.0
  episode_reward_mean: 447.96
  episode_reward_min: 268.0
  episodes_this_iter: 1
  episodes_total: 391
  experiment_id: f3470259fa9143609a5dd5049ba7f979
  hostname: gpu020
  info:
    apply_time_ms: 3.97
    dispatch_time_ms: 8.471
    learner:
      cur_lr: 0.0012297970242798328
      grad_gnorm: 39.99999237060547
      policy_entropy: 14.60583782196045
      policy_loss: 8.2716646194458
      var_gnorm: 48.12665557861328
      vf_explained_var: 0.3112568259239197
      vf_loss: 50.25398254394531
    num_steps_sampled: 1960000
    num_steps_trained: 1960000
    wait_time_ms: 94.665
  iterations_since_restore: 392
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 830
  policy_reward_mean: {}
  time_since_restore: 5126.730642557144
  time_this_iter_s: 14.811070442199707
  time_total_s: 5126.730642557144
  timestamp: 1593814937
  timesteps_since_restore: 1960000
  timesteps_this_iter: 5000
  timesteps_total: 1960000
  training_iteration: 392
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 14.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=830], 5126 s, 392 iter, 1960000 ts, 448 rew

agent-1: 82.0
agent-2: 56.0
agent-3: 104.0
agent-4: 65.0
agent-5: 109.0
Sum Reward: 416.0
Avg Reward: 83.2
Min Reward: 56.0
Gini Coefficient 0.13942307692307693
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_18-22-29
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 739.0
  episode_reward_mean: 444.79
  episode_reward_min: 268.0
  episodes_this_iter: 1
  episodes_total: 392
  experiment_id: f3470259fa9143609a5dd5049ba7f979
  hostname: gpu020
  info:
    apply_time_ms: 4.45
    dispatch_time_ms: 6.362
    learner:
      cur_lr: 0.001229463960044086
      grad_gnorm: 40.000003814697266
      policy_entropy: 41.090579986572266
      policy_loss: -10.999320030212402
      var_gnorm: 48.17197036743164
      vf_explained_var: 0.284709632396698
      vf_loss: 9.844675064086914
    num_steps_sampled: 1965000
    num_steps_trained: 1965000
    wait_time_ms: 109.909
  iterations_since_restore: 393
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 830
  policy_reward_mean: {}
  time_since_restore: 5138.195331335068
  time_this_iter_s: 11.464688777923584
  time_total_s: 5138.195331335068
  timestamp: 1593814949
  timesteps_since_restore: 1965000
  timesteps_this_iter: 5000
  timesteps_total: 1965000
  training_iteration: 393
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 14.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=830], 5138 s, 393 iter, 1965000 ts, 445 rew

agent-1: 88.0
agent-2: 60.0
agent-3: 81.0
agent-4: 73.0
agent-5: 79.0
Sum Reward: 381.0
Avg Reward: 76.2
Min Reward: 60.0
Gini Coefficient 0.06719160104986877
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_18-22-41
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 739.0
  episode_reward_mean: 445.45
  episode_reward_min: 268.0
  episodes_this_iter: 1
  episodes_total: 393
  experiment_id: f3470259fa9143609a5dd5049ba7f979
  hostname: gpu020
  info:
    apply_time_ms: 2.903
    dispatch_time_ms: 23.083
    learner:
      cur_lr: 0.001229131012223661
      grad_gnorm: 1.5335025787353516
      policy_entropy: 32.658241271972656
      policy_loss: 0.2867451608181
      var_gnorm: 48.17582702636719
      vf_explained_var: 1.1920928955078125e-07
      vf_loss: 0.00230734096840024
    num_steps_sampled: 1970000
    num_steps_trained: 1970000
    wait_time_ms: 74.073
  iterations_since_restore: 394
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 830
  policy_reward_mean: {}
  time_since_restore: 5150.611943721771
  time_this_iter_s: 12.416612386703491
  time_total_s: 5150.611943721771
  timestamp: 1593814961
  timesteps_since_restore: 1970000
  timesteps_this_iter: 5000
  timesteps_total: 1970000
  training_iteration: 394
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 14.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=830], 5150 s, 394 iter, 1970000 ts, 445 rew

agent-1: 84.0
agent-2: 80.0
agent-3: 93.0
agent-4: 62.0
agent-5: 79.0
Sum Reward: 398.0
Avg Reward: 79.6
Min Reward: 62.0
Gini Coefficient 0.06733668341708543
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_18-22-53
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 739.0
  episode_reward_mean: 443.9
  episode_reward_min: 268.0
  episodes_this_iter: 1
  episodes_total: 394
  experiment_id: f3470259fa9143609a5dd5049ba7f979
  hostname: gpu020
  info:
    apply_time_ms: 3.953
    dispatch_time_ms: 6.97
    learner:
      cur_lr: 0.001228797947987914
      grad_gnorm: 40.0
      policy_entropy: 14.553343772888184
      policy_loss: -9.011772155761719
      var_gnorm: 48.21760940551758
      vf_explained_var: 0.39047539234161377
      vf_loss: 190.98716735839844
    num_steps_sampled: 1975000
    num_steps_trained: 1975000
    wait_time_ms: 110.421
  iterations_since_restore: 395
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 830
  policy_reward_mean: {}
  time_since_restore: 5162.380629062653
  time_this_iter_s: 11.768685340881348
  time_total_s: 5162.380629062653
  timestamp: 1593814973
  timesteps_since_restore: 1975000
  timesteps_this_iter: 5000
  timesteps_total: 1975000
  training_iteration: 395
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 14.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=830], 5162 s, 395 iter, 1975000 ts, 444 rew

agent-1: 63.0
agent-2: 72.0
agent-3: 74.0
agent-4: 57.0
agent-5: 60.0
Sum Reward: 326.0
Avg Reward: 65.2
Min Reward: 57.0
Gini Coefficient 0.05644171779141104
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_18-23-06
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 739.0
  episode_reward_mean: 441.03
  episode_reward_min: 268.0
  episodes_this_iter: 1
  episodes_total: 395
  experiment_id: f3470259fa9143609a5dd5049ba7f979
  hostname: gpu020
  info:
    apply_time_ms: 2.487
    dispatch_time_ms: 10.621
    learner:
      cur_lr: 0.001228465000167489
      grad_gnorm: 34.25047302246094
      policy_entropy: 3.7603561878204346
      policy_loss: 1.38604736328125
      var_gnorm: 48.22549819946289
      vf_explained_var: -0.2350142002105713
      vf_loss: 35.760414123535156
    num_steps_sampled: 1980000
    num_steps_trained: 1980000
    wait_time_ms: 98.173
  iterations_since_restore: 396
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 830
  policy_reward_mean: {}
  time_since_restore: 5174.797940254211
  time_this_iter_s: 12.417311191558838
  time_total_s: 5174.797940254211
  timestamp: 1593814986
  timesteps_since_restore: 1980000
  timesteps_this_iter: 5000
  timesteps_total: 1980000
  training_iteration: 396
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 14.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=830], 5174 s, 396 iter, 1980000 ts, 441 rew

agent-1: 100.0
agent-2: 70.0
agent-3: 66.0
agent-4: 52.0
agent-5: 62.0
Sum Reward: 350.0
Avg Reward: 70.0
Min Reward: 52.0
Gini Coefficient 0.11885714285714286
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_18-23-17
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 739.0
  episode_reward_mean: 439.76
  episode_reward_min: 268.0
  episodes_this_iter: 1
  episodes_total: 396
  experiment_id: f3470259fa9143609a5dd5049ba7f979
  hostname: gpu020
  info:
    apply_time_ms: 2.864
    dispatch_time_ms: 14.785
    learner:
      cur_lr: 0.001228132052347064
      grad_gnorm: 15.653852462768555
      policy_entropy: 35.13648223876953
      policy_loss: -3.224109411239624
      var_gnorm: 48.38556671142578
      vf_explained_var: 0.9806005954742432
      vf_loss: 0.7850819826126099
    num_steps_sampled: 1985000
    num_steps_trained: 1985000
    wait_time_ms: 105.929
  iterations_since_restore: 397
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 830
  policy_reward_mean: {}
  time_since_restore: 5186.312606096268
  time_this_iter_s: 11.514665842056274
  time_total_s: 5186.312606096268
  timestamp: 1593814997
  timesteps_since_restore: 1985000
  timesteps_this_iter: 5000
  timesteps_total: 1985000
  training_iteration: 397
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 14.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=830], 5186 s, 397 iter, 1985000 ts, 440 rew

agent-1: 74.0
agent-2: 102.0
agent-3: 87.0
agent-4: 93.0
agent-5: 61.0
Sum Reward: 417.0
Avg Reward: 83.4
Min Reward: 61.0
Gini Coefficient 0.09688249400479616
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_18-23-29
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 739.0
  episode_reward_mean: 438.7
  episode_reward_min: 268.0
  episodes_this_iter: 1
  episodes_total: 397
  experiment_id: f3470259fa9143609a5dd5049ba7f979
  hostname: gpu020
  info:
    apply_time_ms: 2.88
    dispatch_time_ms: 9.886
    learner:
      cur_lr: 0.0012277989881113172
      grad_gnorm: 23.5523681640625
      policy_entropy: 5.480267524719238
      policy_loss: 0.06639143824577332
      var_gnorm: 48.39667510986328
      vf_explained_var: 0.3755800724029541
      vf_loss: 86.04046630859375
    num_steps_sampled: 1990000
    num_steps_trained: 1990000
    wait_time_ms: 101.679
  iterations_since_restore: 398
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 830
  policy_reward_mean: {}
  time_since_restore: 5198.559203863144
  time_this_iter_s: 12.24659776687622
  time_total_s: 5198.559203863144
  timestamp: 1593815009
  timesteps_since_restore: 1990000
  timesteps_this_iter: 5000
  timesteps_total: 1990000
  training_iteration: 398
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 14.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=830], 5198 s, 398 iter, 1990000 ts, 439 rew

agent-1: 57.0
agent-2: 80.0
agent-3: 80.0
agent-4: 76.0
agent-5: 93.0
Sum Reward: 386.0
Avg Reward: 77.2
Min Reward: 57.0
Gini Coefficient 0.07875647668393783
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_18-23-41
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 739.0
  episode_reward_mean: 436.7
  episode_reward_min: 268.0
  episodes_this_iter: 1
  episodes_total: 398
  experiment_id: f3470259fa9143609a5dd5049ba7f979
  hostname: gpu020
  info:
    apply_time_ms: 3.119
    dispatch_time_ms: 12.594
    learner:
      cur_lr: 0.0012274660402908921
      grad_gnorm: 39.999996185302734
      policy_entropy: 20.05000877380371
      policy_loss: 15.439326286315918
      var_gnorm: 48.51158905029297
      vf_explained_var: 0.3500549793243408
      vf_loss: 127.49565124511719
    num_steps_sampled: 1995000
    num_steps_trained: 1995000
    wait_time_ms: 102.76
  iterations_since_restore: 399
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 830
  policy_reward_mean: {}
  time_since_restore: 5210.023705244064
  time_this_iter_s: 11.46450138092041
  time_total_s: 5210.023705244064
  timestamp: 1593815021
  timesteps_since_restore: 1995000
  timesteps_this_iter: 5000
  timesteps_total: 1995000
  training_iteration: 399
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 14.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=830], 5210 s, 399 iter, 1995000 ts, 437 rew

agent-1: 78.0
agent-2: 64.0
agent-3: 67.0
agent-4: 106.0
agent-5: 78.0
Sum Reward: 393.0
Avg Reward: 78.6
Min Reward: 64.0
Gini Coefficient 0.09669211195928754
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_18-23-53
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 739.0
  episode_reward_mean: 434.55
  episode_reward_min: 268.0
  episodes_this_iter: 1
  episodes_total: 399
  experiment_id: f3470259fa9143609a5dd5049ba7f979
  hostname: gpu020
  info:
    apply_time_ms: 3.418
    dispatch_time_ms: 9.87
    learner:
      cur_lr: 0.0012271329760551453
      grad_gnorm: 4.974421977996826
      policy_entropy: 33.077919006347656
      policy_loss: -0.836142897605896
      var_gnorm: 48.483436584472656
      vf_explained_var: 1.1920928955078125e-07
      vf_loss: 0.030413975939154625
    num_steps_sampled: 2000000
    num_steps_trained: 2000000
    wait_time_ms: 96.684
  iterations_since_restore: 400
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 830
  policy_reward_mean: {}
  time_since_restore: 5222.087513446808
  time_this_iter_s: 12.06380820274353
  time_total_s: 5222.087513446808
  timestamp: 1593815033
  timesteps_since_restore: 2000000
  timesteps_this_iter: 5000
  timesteps_total: 2000000
  training_iteration: 400
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 14.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=830], 5222 s, 400 iter, 2000000 ts, 435 rew

agent-1: 81.0
agent-2: 101.0
agent-3: 73.0
agent-4: 70.0
agent-5: 100.0
Sum Reward: 425.0
Avg Reward: 85.0
Min Reward: 70.0
Gini Coefficient 0.08376470588235294
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_18-24-06
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 739.0
  episode_reward_mean: 432.69
  episode_reward_min: 268.0
  episodes_this_iter: 1
  episodes_total: 400
  experiment_id: f3470259fa9143609a5dd5049ba7f979
  hostname: gpu020
  info:
    apply_time_ms: 3.068
    dispatch_time_ms: 88.787
    learner:
      cur_lr: 0.0012268000282347202
      grad_gnorm: 40.0
      policy_entropy: 14.029461860656738
      policy_loss: 45.22705841064453
      var_gnorm: 48.41289520263672
      vf_explained_var: -1.0
      vf_loss: 512.6138305664062
    num_steps_sampled: 2005000
    num_steps_trained: 2005000
    wait_time_ms: 66.865
  iterations_since_restore: 401
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 830
  policy_reward_mean: {}
  time_since_restore: 5234.888024806976
  time_this_iter_s: 12.800511360168457
  time_total_s: 5234.888024806976
  timestamp: 1593815046
  timesteps_since_restore: 2005000
  timesteps_this_iter: 5000
  timesteps_total: 2005000
  training_iteration: 401
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 14.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=830], 5234 s, 401 iter, 2005000 ts, 433 rew

W0703 18:24:08.983222   825 client_connection.cc:255] [worker]ProcessMessage with type 19 took 2434 ms.
W0703 18:24:08.983346   825 node_manager.cc:250] Last heartbeat was sent 2497 ms ago 
agent-1: 64.0
agent-2: 65.0
agent-3: 55.0
agent-4: 73.0
agent-5: 68.0
Sum Reward: 325.0
Avg Reward: 65.0
Min Reward: 55.0
Gini Coefficient 0.04923076923076923
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_18-24-21
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 739.0
  episode_reward_mean: 430.51
  episode_reward_min: 268.0
  episodes_this_iter: 1
  episodes_total: 401
  experiment_id: f3470259fa9143609a5dd5049ba7f979
  hostname: gpu020
  info:
    apply_time_ms: 3.902
    dispatch_time_ms: 45.738
    learner:
      cur_lr: 0.0012264669639989734
      grad_gnorm: 27.59195899963379
      policy_entropy: 2.608215093612671
      policy_loss: 4.07476282119751
      var_gnorm: 48.406375885009766
      vf_explained_var: -0.7526358366012573
      vf_loss: 14.458074569702148
    num_steps_sampled: 2010000
    num_steps_trained: 2010000
    wait_time_ms: 51.673
  iterations_since_restore: 402
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 830
  policy_reward_mean: {}
  time_since_restore: 5249.881072759628
  time_this_iter_s: 14.993047952651978
  time_total_s: 5249.881072759628
  timestamp: 1593815061
  timesteps_since_restore: 2010000
  timesteps_this_iter: 5000
  timesteps_total: 2010000
  training_iteration: 402
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 14.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=830], 5249 s, 402 iter, 2010000 ts, 431 rew

agent-1: 82.0
agent-2: 86.0
agent-3: 90.0
agent-4: 103.0
agent-5: 96.0
Sum Reward: 457.0
Avg Reward: 91.4
Min Reward: 82.0
Gini Coefficient 0.045514223194748356
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_18-24-31
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 739.0
  episode_reward_mean: 428.16
  episode_reward_min: 268.0
  episodes_this_iter: 1
  episodes_total: 402
  experiment_id: f3470259fa9143609a5dd5049ba7f979
  hostname: gpu020
  info:
    apply_time_ms: 3.048
    dispatch_time_ms: 21.145
    learner:
      cur_lr: 0.0012261340161785483
      grad_gnorm: 40.0
      policy_entropy: 27.157644271850586
      policy_loss: -9.367339134216309
      var_gnorm: 48.38796615600586
      vf_explained_var: 0.9370863437652588
      vf_loss: 49.67445373535156
    num_steps_sampled: 2015000
    num_steps_trained: 2015000
    wait_time_ms: 96.852
  iterations_since_restore: 403
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 830
  policy_reward_mean: {}
  time_since_restore: 5260.358198881149
  time_this_iter_s: 10.477126121520996
  time_total_s: 5260.358198881149
  timestamp: 1593815071
  timesteps_since_restore: 2015000
  timesteps_this_iter: 5000
  timesteps_total: 2015000
  training_iteration: 403
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 14.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=830], 5260 s, 403 iter, 2015000 ts, 428 rew

agent-1: 121.0
agent-2: 106.0
agent-3: 45.0
agent-4: 104.0
agent-5: 73.0
Sum Reward: 449.0
Avg Reward: 89.8
Min Reward: 45.0
Gini Coefficient 0.16481069042316257
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_18-24-44
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 728.0
  episode_reward_mean: 425.26
  episode_reward_min: 268.0
  episodes_this_iter: 1
  episodes_total: 403
  experiment_id: f3470259fa9143609a5dd5049ba7f979
  hostname: gpu020
  info:
    apply_time_ms: 3.133
    dispatch_time_ms: 12.758
    learner:
      cur_lr: 0.0012258009519428015
      grad_gnorm: 4.5074687004089355
      policy_entropy: 40.8774528503418
      policy_loss: 2.765047311782837
      var_gnorm: 48.534915924072266
      vf_explained_var: 0.9238294363021851
      vf_loss: 1.161026120185852
    num_steps_sampled: 2020000
    num_steps_trained: 2020000
    wait_time_ms: 99.262
  iterations_since_restore: 404
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 830
  policy_reward_mean: {}
  time_since_restore: 5272.688633441925
  time_this_iter_s: 12.330434560775757
  time_total_s: 5272.688633441925
  timestamp: 1593815084
  timesteps_since_restore: 2020000
  timesteps_this_iter: 5000
  timesteps_total: 2020000
  training_iteration: 404
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 14.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=830], 5272 s, 404 iter, 2020000 ts, 425 rew

agent-1: 86.0
agent-2: 111.0
agent-3: 91.0
agent-4: 83.0
agent-5: 70.0
Sum Reward: 441.0
Avg Reward: 88.2
Min Reward: 70.0
Gini Coefficient 0.08163265306122448
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_18-24-57
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 728.0
  episode_reward_mean: 423.35
  episode_reward_min: 268.0
  episodes_this_iter: 1
  episodes_total: 404
  experiment_id: f3470259fa9143609a5dd5049ba7f979
  hostname: gpu020
  info:
    apply_time_ms: 2.778
    dispatch_time_ms: 9.278
    learner:
      cur_lr: 0.0012254680041223764
      grad_gnorm: 39.99998474121094
      policy_entropy: 20.787029266357422
      policy_loss: -1.5567821264266968
      var_gnorm: 48.51372528076172
      vf_explained_var: 0.9370150566101074
      vf_loss: 34.63839340209961
    num_steps_sampled: 2025000
    num_steps_trained: 2025000
    wait_time_ms: 36.25
  iterations_since_restore: 405
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 830
  policy_reward_mean: {}
  time_since_restore: 5285.749176502228
  time_this_iter_s: 13.060543060302734
  time_total_s: 5285.749176502228
  timestamp: 1593815097
  timesteps_since_restore: 2025000
  timesteps_this_iter: 5000
  timesteps_total: 2025000
  training_iteration: 405
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 14.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=830], 5285 s, 405 iter, 2025000 ts, 423 rew

agent-1: 74.0
agent-2: 95.0
agent-3: 72.0
agent-4: 69.0
agent-5: 107.0
Sum Reward: 417.0
Avg Reward: 83.4
Min Reward: 69.0
Gini Coefficient 0.09496402877697842
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_18-25-09
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 728.0
  episode_reward_mean: 421.88
  episode_reward_min: 268.0
  episodes_this_iter: 1
  episodes_total: 405
  experiment_id: f3470259fa9143609a5dd5049ba7f979
  hostname: gpu020
  info:
    apply_time_ms: 4.073
    dispatch_time_ms: 10.745
    learner:
      cur_lr: 0.0012251350563019514
      grad_gnorm: 4.188717365264893
      policy_entropy: 20.683155059814453
      policy_loss: 0.8705272674560547
      var_gnorm: 48.61417770385742
      vf_explained_var: 0.9925592541694641
      vf_loss: 0.025789890438318253
    num_steps_sampled: 2030000
    num_steps_trained: 2030000
    wait_time_ms: 91.171
  iterations_since_restore: 406
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 830
  policy_reward_mean: {}
  time_since_restore: 5298.073514699936
  time_this_iter_s: 12.32433819770813
  time_total_s: 5298.073514699936
  timestamp: 1593815109
  timesteps_since_restore: 2030000
  timesteps_this_iter: 5000
  timesteps_total: 2030000
  training_iteration: 406
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 14.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=830], 5298 s, 406 iter, 2030000 ts, 422 rew

agent-1: 73.0
agent-2: 111.0
agent-3: 94.0
agent-4: 87.0
agent-5: 96.0
Sum Reward: 461.0
Avg Reward: 92.2
Min Reward: 73.0
Gini Coefficient 0.0737527114967462
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_18-25-22
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 728.0
  episode_reward_mean: 421.94
  episode_reward_min: 268.0
  episodes_this_iter: 1
  episodes_total: 406
  experiment_id: f3470259fa9143609a5dd5049ba7f979
  hostname: gpu020
  info:
    apply_time_ms: 3.194
    dispatch_time_ms: 54.98
    learner:
      cur_lr: 0.0012248019920662045
      grad_gnorm: 40.0
      policy_entropy: 25.98671531677246
      policy_loss: -0.660702109336853
      var_gnorm: 48.71914291381836
      vf_explained_var: 0.04862487316131592
      vf_loss: 31.698400497436523
    num_steps_sampled: 2035000
    num_steps_trained: 2035000
    wait_time_ms: 182.704
  iterations_since_restore: 407
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 830
  policy_reward_mean: {}
  time_since_restore: 5310.732352733612
  time_this_iter_s: 12.658838033676147
  time_total_s: 5310.732352733612
  timestamp: 1593815122
  timesteps_since_restore: 2035000
  timesteps_this_iter: 5000
  timesteps_total: 2035000
  training_iteration: 407
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 14.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=830], 5310 s, 407 iter, 2035000 ts, 422 rew

agent-1: 62.0
agent-2: 96.0
agent-3: 76.0
agent-4: 69.0
agent-5: 99.0
Sum Reward: 402.0
Avg Reward: 80.4
Min Reward: 62.0
Gini Coefficient 0.10049751243781095
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_18-25-34
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 728.0
  episode_reward_mean: 419.95
  episode_reward_min: 268.0
  episodes_this_iter: 1
  episodes_total: 407
  experiment_id: f3470259fa9143609a5dd5049ba7f979
  hostname: gpu020
  info:
    apply_time_ms: 2.862
    dispatch_time_ms: 12.611
    learner:
      cur_lr: 0.0012244690442457795
      grad_gnorm: 1.6490224599838257
      policy_entropy: 31.69706153869629
      policy_loss: -0.2615896463394165
      var_gnorm: 48.766685485839844
      vf_explained_var: 5.960464477539063e-08
      vf_loss: 0.003190461779013276
    num_steps_sampled: 2040000
    num_steps_trained: 2040000
    wait_time_ms: 92.901
  iterations_since_restore: 408
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 830
  policy_reward_mean: {}
  time_since_restore: 5322.739805936813
  time_this_iter_s: 12.007453203201294
  time_total_s: 5322.739805936813
  timestamp: 1593815134
  timesteps_since_restore: 2040000
  timesteps_this_iter: 5000
  timesteps_total: 2040000
  training_iteration: 408
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 14.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=830], 5322 s, 408 iter, 2040000 ts, 420 rew

agent-1: 102.0
agent-2: 73.0
agent-3: 93.0
agent-4: 84.0
agent-5: 96.0
Sum Reward: 448.0
Avg Reward: 89.6
Min Reward: 73.0
Gini Coefficient 0.0625
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_18-25-46
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 728.0
  episode_reward_mean: 418.24
  episode_reward_min: 268.0
  episodes_this_iter: 1
  episodes_total: 408
  experiment_id: f3470259fa9143609a5dd5049ba7f979
  hostname: gpu020
  info:
    apply_time_ms: 3.072
    dispatch_time_ms: 8.684
    learner:
      cur_lr: 0.0012241359800100327
      grad_gnorm: 40.0
      policy_entropy: 30.22189712524414
      policy_loss: -7.819676399230957
      var_gnorm: 48.80996322631836
      vf_explained_var: 0.23431318998336792
      vf_loss: 15.663440704345703
    num_steps_sampled: 2045000
    num_steps_trained: 2045000
    wait_time_ms: 123.081
  iterations_since_restore: 409
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 830
  policy_reward_mean: {}
  time_since_restore: 5334.6578142642975
  time_this_iter_s: 11.91800832748413
  time_total_s: 5334.6578142642975
  timestamp: 1593815146
  timesteps_since_restore: 2045000
  timesteps_this_iter: 5000
  timesteps_total: 2045000
  training_iteration: 409
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 14.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=830], 5334 s, 409 iter, 2045000 ts, 418 rew

agent-1: 64.0
agent-2: 55.0
agent-3: 59.0
agent-4: 76.0
agent-5: 56.0
Sum Reward: 310.0
Avg Reward: 62.0
Min Reward: 55.0
Gini Coefficient 0.06451612903225806
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_18-25-58
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 728.0
  episode_reward_mean: 415.37
  episode_reward_min: 268.0
  episodes_this_iter: 1
  episodes_total: 409
  experiment_id: f3470259fa9143609a5dd5049ba7f979
  hostname: gpu020
  info:
    apply_time_ms: 2.829
    dispatch_time_ms: 17.418
    learner:
      cur_lr: 0.0012238030321896076
      grad_gnorm: 3.2756385803222656
      policy_entropy: 34.58190155029297
      policy_loss: 3.123751401901245
      var_gnorm: 48.809810638427734
      vf_explained_var: -1.0
      vf_loss: 0.2525944113731384
    num_steps_sampled: 2050000
    num_steps_trained: 2050000
    wait_time_ms: 23.87
  iterations_since_restore: 410
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 830
  policy_reward_mean: {}
  time_since_restore: 5347.370791435242
  time_this_iter_s: 12.712977170944214
  time_total_s: 5347.370791435242
  timestamp: 1593815158
  timesteps_since_restore: 2050000
  timesteps_this_iter: 5000
  timesteps_total: 2050000
  training_iteration: 410
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 14.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=830], 5347 s, 410 iter, 2050000 ts, 415 rew

agent-1: 62.0
agent-2: 61.0
agent-3: 72.0
agent-4: 63.0
agent-5: 57.0
Sum Reward: 315.0
Avg Reward: 63.0
Min Reward: 57.0
Gini Coefficient 0.040634920634920635
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_18-26-10
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 728.0
  episode_reward_mean: 413.98
  episode_reward_min: 268.0
  episodes_this_iter: 1
  episodes_total: 410
  experiment_id: f3470259fa9143609a5dd5049ba7f979
  hostname: gpu020
  info:
    apply_time_ms: 2.732
    dispatch_time_ms: 14.459
    learner:
      cur_lr: 0.0012234699679538608
      grad_gnorm: 12.781250953674316
      policy_entropy: 40.78907012939453
      policy_loss: -3.760498523712158
      var_gnorm: 48.82455062866211
      vf_explained_var: 0.9925089478492737
      vf_loss: 0.2527908980846405
    num_steps_sampled: 2055000
    num_steps_trained: 2055000
    wait_time_ms: 117.822
  iterations_since_restore: 411
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 830
  policy_reward_mean: {}
  time_since_restore: 5359.026268005371
  time_this_iter_s: 11.655476570129395
  time_total_s: 5359.026268005371
  timestamp: 1593815170
  timesteps_since_restore: 2055000
  timesteps_this_iter: 5000
  timesteps_total: 2055000
  training_iteration: 411
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 14.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=830], 5359 s, 411 iter, 2055000 ts, 414 rew

agent-1: 77.0
agent-2: 52.0
agent-3: 78.0
agent-4: 77.0
agent-5: 69.0
Sum Reward: 353.0
Avg Reward: 70.6
Min Reward: 52.0
Gini Coefficient 0.0679886685552408
agent-1: 123.0
agent-2: 84.0
agent-3: 84.0
agent-4: 111.0
agent-5: 78.0
Sum Reward: 480.0
Avg Reward: 96.0
Min Reward: 78.0
Gini Coefficient 0.0975
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_18-26-33
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 728.0
  episode_reward_mean: 412.88
  episode_reward_min: 268.0
  episodes_this_iter: 2
  episodes_total: 412
  experiment_id: f3470259fa9143609a5dd5049ba7f979
  hostname: gpu020
  info:
    apply_time_ms: 2.893
    dispatch_time_ms: 34.598
    learner:
      cur_lr: 0.0012231370201334357
      grad_gnorm: 30.760427474975586
      policy_entropy: 24.923160552978516
      policy_loss: -0.4254753589630127
      var_gnorm: 48.99330139160156
      vf_explained_var: 0.9924827814102173
      vf_loss: 1.0669517517089844
    num_steps_sampled: 2060000
    num_steps_trained: 2060000
    wait_time_ms: 262.995
  iterations_since_restore: 412
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 830
  policy_reward_mean: {}
  time_since_restore: 5382.037096977234
  time_this_iter_s: 23.010828971862793
  time_total_s: 5382.037096977234
  timestamp: 1593815193
  timesteps_since_restore: 2060000
  timesteps_this_iter: 5000
  timesteps_total: 2060000
  training_iteration: 412
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 14.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=830], 5382 s, 412 iter, 2060000 ts, 413 rew

Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_18-26-45
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 728.0
  episode_reward_mean: 412.88
  episode_reward_min: 268.0
  episodes_this_iter: 0
  episodes_total: 412
  experiment_id: f3470259fa9143609a5dd5049ba7f979
  hostname: gpu020
  info:
    apply_time_ms: 3.124
    dispatch_time_ms: 16.265
    learner:
      cur_lr: 0.0012228039558976889
      grad_gnorm: 7.674156188964844
      policy_entropy: 34.40627670288086
      policy_loss: -1.5712039470672607
      var_gnorm: 49.07712936401367
      vf_explained_var: 0.9830816984176636
      vf_loss: 0.07439936697483063
    num_steps_sampled: 2065000
    num_steps_trained: 2065000
    wait_time_ms: 109.177
  iterations_since_restore: 413
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 830
  policy_reward_mean: {}
  time_since_restore: 5394.152512073517
  time_this_iter_s: 12.115415096282959
  time_total_s: 5394.152512073517
  timestamp: 1593815205
  timesteps_since_restore: 2065000
  timesteps_this_iter: 5000
  timesteps_total: 2065000
  training_iteration: 413
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 14.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=830], 5394 s, 413 iter, 2065000 ts, 413 rew

agent-1: 73.0
agent-2: 67.0
agent-3: 87.0
agent-4: 78.0
agent-5: 90.0
Sum Reward: 395.0
Avg Reward: 79.0
Min Reward: 67.0
Gini Coefficient 0.060759493670886074
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_18-27-08
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 728.0
  episode_reward_mean: 411.0
  episode_reward_min: 268.0
  episodes_this_iter: 1
  episodes_total: 413
  experiment_id: f3470259fa9143609a5dd5049ba7f979
  hostname: gpu020
  info:
    apply_time_ms: 3.055
    dispatch_time_ms: 14.008
    learner:
      cur_lr: 0.0012224710080772638
      grad_gnorm: 40.0
      policy_entropy: 5.966771125793457
      policy_loss: -0.5654726624488831
      var_gnorm: 49.13008117675781
      vf_explained_var: -0.09113264083862305
      vf_loss: 42.730133056640625
    num_steps_sampled: 2070000
    num_steps_trained: 2070000
    wait_time_ms: 97.136
  iterations_since_restore: 414
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 830
  policy_reward_mean: {}
  time_since_restore: 5417.271748304367
  time_this_iter_s: 23.11923623085022
  time_total_s: 5417.271748304367
  timestamp: 1593815228
  timesteps_since_restore: 2070000
  timesteps_this_iter: 5000
  timesteps_total: 2070000
  training_iteration: 414
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 14.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=830], 5417 s, 414 iter, 2070000 ts, 411 rew

agent-1: 103.0
agent-2: 61.0
agent-3: 70.0
agent-4: 66.0
agent-5: 63.0
Sum Reward: 363.0
Avg Reward: 72.6
Min Reward: 61.0
Gini Coefficient 0.10027548209366391
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_18-27-32
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 728.0
  episode_reward_mean: 410.29
  episode_reward_min: 268.0
  episodes_this_iter: 1
  episodes_total: 414
  experiment_id: f3470259fa9143609a5dd5049ba7f979
  hostname: gpu020
  info:
    apply_time_ms: 3.987
    dispatch_time_ms: 182.605
    learner:
      cur_lr: 0.001222137943841517
      grad_gnorm: 39.999996185302734
      policy_entropy: 32.142642974853516
      policy_loss: 4.362090110778809
      var_gnorm: 49.15874099731445
      vf_explained_var: 0.3717467784881592
      vf_loss: 22.600631713867188
    num_steps_sampled: 2075000
    num_steps_trained: 2075000
    wait_time_ms: 82.419
  iterations_since_restore: 415
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 830
  policy_reward_mean: {}
  time_since_restore: 5440.914644956589
  time_this_iter_s: 23.64289665222168
  time_total_s: 5440.914644956589
  timestamp: 1593815252
  timesteps_since_restore: 2075000
  timesteps_this_iter: 5000
  timesteps_total: 2075000
  training_iteration: 415
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 14.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=830], 5440 s, 415 iter, 2075000 ts, 410 rew

agent-1: 106.0
agent-2: 81.0
agent-3: 90.0
agent-4: 106.0
agent-5: 114.0
Sum Reward: 497.0
Avg Reward: 99.4
Min Reward: 81.0
Gini Coefficient 0.06599597585513078
agent-1: 98.0
agent-2: 85.0
agent-3: 97.0
agent-4: 98.0
agent-5: 85.0
Sum Reward: 463.0
Avg Reward: 92.6
Min Reward: 85.0
Gini Coefficient 0.033693304535637146
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_18-27-45
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 728.0
  episode_reward_mean: 410.72
  episode_reward_min: 268.0
  episodes_this_iter: 1
  episodes_total: 415
  experiment_id: f3470259fa9143609a5dd5049ba7f979
  hostname: gpu020
  info:
    apply_time_ms: 3.446
    dispatch_time_ms: 48.436
    learner:
      cur_lr: 0.001221804996021092
      grad_gnorm: 19.039997100830078
      policy_entropy: 37.759403228759766
      policy_loss: 0.6070866584777832
      var_gnorm: 49.15498352050781
      vf_explained_var: 0.0
      vf_loss: 0.35518160462379456
    num_steps_sampled: 2080000
    num_steps_trained: 2080000
    wait_time_ms: 92.53
  iterations_since_restore: 416
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 830
  policy_reward_mean: {}
  time_since_restore: 5454.227191448212
  time_this_iter_s: 13.312546491622925
  time_total_s: 5454.227191448212
  timestamp: 1593815265
  timesteps_since_restore: 2080000
  timesteps_this_iter: 5000
  timesteps_total: 2080000
  training_iteration: 416
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 14.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=830], 5454 s, 416 iter, 2080000 ts, 411 rew

Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_18-27-56
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 728.0
  episode_reward_mean: 411.13
  episode_reward_min: 268.0
  episodes_this_iter: 1
  episodes_total: 416
  experiment_id: f3470259fa9143609a5dd5049ba7f979
  hostname: gpu020
  info:
    apply_time_ms: 3.588
    dispatch_time_ms: 7.891
    learner:
      cur_lr: 0.001221472048200667
      grad_gnorm: 23.545761108398438
      policy_entropy: 10.73344612121582
      policy_loss: -0.26472246646881104
      var_gnorm: 49.23421859741211
      vf_explained_var: 0.42183220386505127
      vf_loss: 4.835147380828857
    num_steps_sampled: 2085000
    num_steps_trained: 2085000
    wait_time_ms: 111.658
  iterations_since_restore: 417
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 830
  policy_reward_mean: {}
  time_since_restore: 5464.62042093277
  time_this_iter_s: 10.393229484558105
  time_total_s: 5464.62042093277
  timestamp: 1593815276
  timesteps_since_restore: 2085000
  timesteps_this_iter: 5000
  timesteps_total: 2085000
  training_iteration: 417
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 14.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=830], 5464 s, 417 iter, 2085000 ts, 411 rew

agent-1: 78.0
agent-2: 103.0
agent-3: 93.0
agent-4: 112.0
agent-5: 90.0
Sum Reward: 476.0
Avg Reward: 95.2
Min Reward: 78.0
Gini Coefficient 0.0680672268907563
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_18-28-08
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 728.0
  episode_reward_mean: 411.44
  episode_reward_min: 268.0
  episodes_this_iter: 1
  episodes_total: 417
  experiment_id: f3470259fa9143609a5dd5049ba7f979
  hostname: gpu020
  info:
    apply_time_ms: 2.72
    dispatch_time_ms: 12.311
    learner:
      cur_lr: 0.00122113898396492
      grad_gnorm: 22.986026763916016
      policy_entropy: 33.3350715637207
      policy_loss: 4.4636383056640625
      var_gnorm: 49.318572998046875
      vf_explained_var: 0.4489869475364685
      vf_loss: 3.6255459785461426
    num_steps_sampled: 2090000
    num_steps_trained: 2090000
    wait_time_ms: 91.766
  iterations_since_restore: 418
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 830
  policy_reward_mean: {}
  time_since_restore: 5476.943454027176
  time_this_iter_s: 12.323033094406128
  time_total_s: 5476.943454027176
  timestamp: 1593815288
  timesteps_since_restore: 2090000
  timesteps_this_iter: 5000
  timesteps_total: 2090000
  training_iteration: 418
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 14.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=830], 5476 s, 418 iter, 2090000 ts, 411 rew

agent-1: 65.0
agent-2: 91.0
agent-3: 100.0
agent-4: 117.0
agent-5: 79.0
Sum Reward: 452.0
Avg Reward: 90.4
Min Reward: 65.0
Gini Coefficient 0.11061946902654868
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_18-28-22
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 728.0
  episode_reward_mean: 411.08
  episode_reward_min: 268.0
  episodes_this_iter: 1
  episodes_total: 418
  experiment_id: f3470259fa9143609a5dd5049ba7f979
  hostname: gpu020
  info:
    apply_time_ms: 3.05
    dispatch_time_ms: 32.347
    learner:
      cur_lr: 0.001220806036144495
      grad_gnorm: 25.917545318603516
      policy_entropy: 31.069547653198242
      policy_loss: 5.485187530517578
      var_gnorm: 49.34657669067383
      vf_explained_var: 0.602907657623291
      vf_loss: 6.8171868324279785
    num_steps_sampled: 2095000
    num_steps_trained: 2095000
    wait_time_ms: 55.483
  iterations_since_restore: 419
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 830
  policy_reward_mean: {}
  time_since_restore: 5490.172058105469
  time_this_iter_s: 13.228604078292847
  time_total_s: 5490.172058105469
  timestamp: 1593815302
  timesteps_since_restore: 2095000
  timesteps_this_iter: 5000
  timesteps_total: 2095000
  training_iteration: 419
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 14.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=830], 5490 s, 419 iter, 2095000 ts, 411 rew

agent-1: 70.0
agent-2: 83.0
agent-3: 79.0
agent-4: 67.0
agent-5: 84.0
Sum Reward: 383.0
Avg Reward: 76.6
Min Reward: 67.0
Gini Coefficient 0.04908616187989556
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_18-28-33
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 728.0
  episode_reward_mean: 409.4
  episode_reward_min: 268.0
  episodes_this_iter: 1
  episodes_total: 419
  experiment_id: f3470259fa9143609a5dd5049ba7f979
  hostname: gpu020
  info:
    apply_time_ms: 3.796
    dispatch_time_ms: 14.065
    learner:
      cur_lr: 0.0012204729719087481
      grad_gnorm: 40.0
      policy_entropy: 15.551152229309082
      policy_loss: -3.1789398193359375
      var_gnorm: 49.37078857421875
      vf_explained_var: 0.0902220606803894
      vf_loss: 42.87472915649414
    num_steps_sampled: 2100000
    num_steps_trained: 2100000
    wait_time_ms: 89.238
  iterations_since_restore: 420
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 830
  policy_reward_mean: {}
  time_since_restore: 5501.864394664764
  time_this_iter_s: 11.692336559295654
  time_total_s: 5501.864394664764
  timestamp: 1593815313
  timesteps_since_restore: 2100000
  timesteps_this_iter: 5000
  timesteps_total: 2100000
  training_iteration: 420
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 14.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=830], 5501 s, 420 iter, 2100000 ts, 409 rew

agent-1: 67.0
agent-2: 74.0
agent-3: 51.0
agent-4: 67.0
agent-5: 76.0
Sum Reward: 335.0
Avg Reward: 67.0
Min Reward: 51.0
Gini Coefficient 0.06805970149253732
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_18-28-44
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 728.0
  episode_reward_mean: 406.87
  episode_reward_min: 268.0
  episodes_this_iter: 1
  episodes_total: 420
  experiment_id: f3470259fa9143609a5dd5049ba7f979
  hostname: gpu020
  info:
    apply_time_ms: 4.303
    dispatch_time_ms: 14.792
    learner:
      cur_lr: 0.0012201400240883231
      grad_gnorm: 39.99998474121094
      policy_entropy: 10.743913650512695
      policy_loss: 16.834537506103516
      var_gnorm: 49.267303466796875
      vf_explained_var: 0.9172005653381348
      vf_loss: 118.062744140625
    num_steps_sampled: 2105000
    num_steps_trained: 2105000
    wait_time_ms: 96.746
  iterations_since_restore: 421
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 830
  policy_reward_mean: {}
  time_since_restore: 5512.375992536545
  time_this_iter_s: 10.511597871780396
  time_total_s: 5512.375992536545
  timestamp: 1593815324
  timesteps_since_restore: 2105000
  timesteps_this_iter: 5000
  timesteps_total: 2105000
  training_iteration: 421
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 14.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=830], 5512 s, 421 iter, 2105000 ts, 407 rew

agent-1: 169.0
agent-2: 123.0
agent-3: 106.0
agent-4: 123.0
agent-5: 111.0
Sum Reward: 632.0
Avg Reward: 126.4
Min Reward: 106.0
Gini Coefficient 0.08734177215189873
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_18-28-56
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 728.0
  episode_reward_mean: 407.46
  episode_reward_min: 268.0
  episodes_this_iter: 1
  episodes_total: 421
  experiment_id: f3470259fa9143609a5dd5049ba7f979
  hostname: gpu020
  info:
    apply_time_ms: 2.967
    dispatch_time_ms: 49.834
    learner:
      cur_lr: 0.0012198069598525763
      grad_gnorm: 40.000003814697266
      policy_entropy: 14.792844772338867
      policy_loss: 4.884054660797119
      var_gnorm: 49.424312591552734
      vf_explained_var: -0.19840919971466064
      vf_loss: 71.38687133789062
    num_steps_sampled: 2110000
    num_steps_trained: 2110000
    wait_time_ms: 68.65
  iterations_since_restore: 422
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 830
  policy_reward_mean: {}
  time_since_restore: 5524.238393545151
  time_this_iter_s: 11.862401008605957
  time_total_s: 5524.238393545151
  timestamp: 1593815336
  timesteps_since_restore: 2110000
  timesteps_this_iter: 5000
  timesteps_total: 2110000
  training_iteration: 422
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 14.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=830], 5524 s, 422 iter, 2110000 ts, 407 rew

agent-1: 151.0
agent-2: 152.0
agent-3: 133.0
agent-4: 169.0
agent-5: 146.0
Sum Reward: 751.0
Avg Reward: 150.2
Min Reward: 133.0
Gini Coefficient 0.04154460719041278
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_18-29-07
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 751.0
  episode_reward_mean: 409.38
  episode_reward_min: 268.0
  episodes_this_iter: 1
  episodes_total: 422
  experiment_id: f3470259fa9143609a5dd5049ba7f979
  hostname: gpu020
  info:
    apply_time_ms: 3.973
    dispatch_time_ms: 8.726
    learner:
      cur_lr: 0.0012194740120321512
      grad_gnorm: 40.000003814697266
      policy_entropy: 15.771869659423828
      policy_loss: -2.7098910808563232
      var_gnorm: 49.52830123901367
      vf_explained_var: 0.0966382622718811
      vf_loss: 36.579307556152344
    num_steps_sampled: 2115000
    num_steps_trained: 2115000
    wait_time_ms: 107.567
  iterations_since_restore: 423
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 830
  policy_reward_mean: {}
  time_since_restore: 5535.4304831027985
  time_this_iter_s: 11.192089557647705
  time_total_s: 5535.4304831027985
  timestamp: 1593815347
  timesteps_since_restore: 2115000
  timesteps_this_iter: 5000
  timesteps_total: 2115000
  training_iteration: 423
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 14.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=830], 5535 s, 423 iter, 2115000 ts, 409 rew

agent-1: 95.0
agent-2: 94.0
agent-3: 104.0
agent-4: 72.0
agent-5: 90.0
Sum Reward: 455.0
Avg Reward: 91.0
Min Reward: 72.0
Gini Coefficient 0.06065934065934066
agent-1: 92.0
agent-2: 46.0
agent-3: 115.0
agent-4: 93.0
agent-5: 107.0
Sum Reward: 453.0
Avg Reward: 90.6
Min Reward: 46.0
Gini Coefficient 0.13509933774834437
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_18-29-21
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 751.0
  episode_reward_mean: 404.85
  episode_reward_min: 268.0
  episodes_this_iter: 2
  episodes_total: 424
  experiment_id: f3470259fa9143609a5dd5049ba7f979
  hostname: gpu020
  info:
    apply_time_ms: 3.189
    dispatch_time_ms: 94.207
    learner:
      cur_lr: 0.0012191409477964044
      grad_gnorm: 3.55930757522583
      policy_entropy: 32.19453048706055
      policy_loss: -3.449465274810791
      var_gnorm: 49.5861701965332
      vf_explained_var: -1.0
      vf_loss: 0.2795068025588989
    num_steps_sampled: 2120000
    num_steps_trained: 2120000
    wait_time_ms: 51.917
  iterations_since_restore: 424
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 830
  policy_reward_mean: {}
  time_since_restore: 5549.162625551224
  time_this_iter_s: 13.732142448425293
  time_total_s: 5549.162625551224
  timestamp: 1593815361
  timesteps_since_restore: 2120000
  timesteps_this_iter: 5000
  timesteps_total: 2120000
  training_iteration: 424
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 14.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=830], 5549 s, 424 iter, 2120000 ts, 405 rew

Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_18-29-33
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 751.0
  episode_reward_mean: 404.85
  episode_reward_min: 268.0
  episodes_this_iter: 0
  episodes_total: 424
  experiment_id: f3470259fa9143609a5dd5049ba7f979
  hostname: gpu020
  info:
    apply_time_ms: 2.398
    dispatch_time_ms: 7.822
    learner:
      cur_lr: 0.0012188079999759793
      grad_gnorm: 39.99999237060547
      policy_entropy: 29.772615432739258
      policy_loss: 0.8536924719810486
      var_gnorm: 49.58723831176758
      vf_explained_var: 0.43310868740081787
      vf_loss: 10.548608779907227
    num_steps_sampled: 2125000
    num_steps_trained: 2125000
    wait_time_ms: 113.616
  iterations_since_restore: 425
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 830
  policy_reward_mean: {}
  time_since_restore: 5561.843225717545
  time_this_iter_s: 12.6806001663208
  time_total_s: 5561.843225717545
  timestamp: 1593815373
  timesteps_since_restore: 2125000
  timesteps_this_iter: 5000
  timesteps_total: 2125000
  training_iteration: 425
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 14.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=830], 5561 s, 425 iter, 2125000 ts, 405 rew

agent-1: 88.0
agent-2: 81.0
agent-3: 70.0
agent-4: 113.0
agent-5: 70.0
Sum Reward: 422.0
Avg Reward: 84.4
Min Reward: 70.0
Gini Coefficient 0.0985781990521327
agent-1: 67.0
agent-2: 56.0
agent-3: 53.0
agent-4: 48.0
agent-5: 68.0
Sum Reward: 292.0
Avg Reward: 58.4
Min Reward: 48.0
Gini Coefficient 0.07397260273972603
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_18-29-47
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 751.0
  episode_reward_mean: 402.17
  episode_reward_min: 268.0
  episodes_this_iter: 2
  episodes_total: 426
  experiment_id: f3470259fa9143609a5dd5049ba7f979
  hostname: gpu020
  info:
    apply_time_ms: 3.744
    dispatch_time_ms: 49.446
    learner:
      cur_lr: 0.0012184750521555543
      grad_gnorm: 25.658201217651367
      policy_entropy: 28.86928367614746
      policy_loss: 0.9245401620864868
      var_gnorm: 49.595703125
      vf_explained_var: 0.0
      vf_loss: 0.6517055034637451
    num_steps_sampled: 2130000
    num_steps_trained: 2130000
    wait_time_ms: 194.382
  iterations_since_restore: 426
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 830
  policy_reward_mean: {}
  time_since_restore: 5575.7192640304565
  time_this_iter_s: 13.876038312911987
  time_total_s: 5575.7192640304565
  timestamp: 1593815387
  timesteps_since_restore: 2130000
  timesteps_this_iter: 5000
  timesteps_total: 2130000
  training_iteration: 426
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 14.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=830], 5575 s, 426 iter, 2130000 ts, 402 rew

Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_18-29-58
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 751.0
  episode_reward_mean: 402.17
  episode_reward_min: 268.0
  episodes_this_iter: 0
  episodes_total: 426
  experiment_id: f3470259fa9143609a5dd5049ba7f979
  hostname: gpu020
  info:
    apply_time_ms: 3.562
    dispatch_time_ms: 14.788
    learner:
      cur_lr: 0.0012181419879198074
      grad_gnorm: 40.0000114440918
      policy_entropy: 3.4764864444732666
      policy_loss: 2.633150815963745
      var_gnorm: 49.478145599365234
      vf_explained_var: 0.3781192898750305
      vf_loss: 33.20493698120117
    num_steps_sampled: 2135000
    num_steps_trained: 2135000
    wait_time_ms: 100.184
  iterations_since_restore: 427
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 830
  policy_reward_mean: {}
  time_since_restore: 5586.673757553101
  time_this_iter_s: 10.954493522644043
  time_total_s: 5586.673757553101
  timestamp: 1593815398
  timesteps_since_restore: 2135000
  timesteps_this_iter: 5000
  timesteps_total: 2135000
  training_iteration: 427
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 14.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=830], 5586 s, 427 iter, 2135000 ts, 402 rew

agent-1: 123.0
agent-2: 141.0
agent-3: 128.0
agent-4: 109.0
agent-5: 96.0
Sum Reward: 597.0
Avg Reward: 119.4
Min Reward: 96.0
Gini Coefficient 0.07303182579564489
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_18-30-10
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 751.0
  episode_reward_mean: 404.16
  episode_reward_min: 268.0
  episodes_this_iter: 1
  episodes_total: 427
  experiment_id: f3470259fa9143609a5dd5049ba7f979
  hostname: gpu020
  info:
    apply_time_ms: 2.873
    dispatch_time_ms: 19.394
    learner:
      cur_lr: 0.0012178090400993824
      grad_gnorm: 40.000003814697266
      policy_entropy: 9.50841999053955
      policy_loss: -3.3438663482666016
      var_gnorm: 49.5189208984375
      vf_explained_var: 0.03653627634048462
      vf_loss: 27.905569076538086
    num_steps_sampled: 2140000
    num_steps_trained: 2140000
    wait_time_ms: 74.099
  iterations_since_restore: 428
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 830
  policy_reward_mean: {}
  time_since_restore: 5597.923188924789
  time_this_iter_s: 11.249431371688843
  time_total_s: 5597.923188924789
  timestamp: 1593815410
  timesteps_since_restore: 2140000
  timesteps_this_iter: 5000
  timesteps_total: 2140000
  training_iteration: 428
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 14.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=830], 5597 s, 428 iter, 2140000 ts, 404 rew

agent-1: 122.0
agent-2: 186.0
agent-3: 159.0
agent-4: 132.0
agent-5: 122.0
Sum Reward: 721.0
Avg Reward: 144.2
Min Reward: 122.0
Gini Coefficient 0.09153952843273232
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_18-30-21
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 751.0
  episode_reward_mean: 406.15
  episode_reward_min: 268.0
  episodes_this_iter: 1
  episodes_total: 428
  experiment_id: f3470259fa9143609a5dd5049ba7f979
  hostname: gpu020
  info:
    apply_time_ms: 3.879
    dispatch_time_ms: 13.307
    learner:
      cur_lr: 0.0012174759758636355
      grad_gnorm: 39.99999237060547
      policy_entropy: 11.709688186645508
      policy_loss: 18.18727684020996
      var_gnorm: 49.63008499145508
      vf_explained_var: 0.44135135412216187
      vf_loss: 206.33485412597656
    num_steps_sampled: 2145000
    num_steps_trained: 2145000
    wait_time_ms: 103.1
  iterations_since_restore: 429
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 830
  policy_reward_mean: {}
  time_since_restore: 5609.00883936882
  time_this_iter_s: 11.085650444030762
  time_total_s: 5609.00883936882
  timestamp: 1593815421
  timesteps_since_restore: 2145000
  timesteps_this_iter: 5000
  timesteps_total: 2145000
  training_iteration: 429
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 14.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=830], 5609 s, 429 iter, 2145000 ts, 406 rew

agent-1: 75.0
agent-2: 96.0
agent-3: 85.0
agent-4: 78.0
agent-5: 66.0
Sum Reward: 400.0
Avg Reward: 80.0
Min Reward: 66.0
Gini Coefficient 0.07
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_18-30-35
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 751.0
  episode_reward_mean: 405.18
  episode_reward_min: 268.0
  episodes_this_iter: 1
  episodes_total: 429
  experiment_id: f3470259fa9143609a5dd5049ba7f979
  hostname: gpu020
  info:
    apply_time_ms: 3.006
    dispatch_time_ms: 10.649
    learner:
      cur_lr: 0.0012171430280432105
      grad_gnorm: 40.000003814697266
      policy_entropy: 9.857357025146484
      policy_loss: 6.1870269775390625
      var_gnorm: 49.66172409057617
      vf_explained_var: 0.18278104066848755
      vf_loss: 52.743221282958984
    num_steps_sampled: 2150000
    num_steps_trained: 2150000
    wait_time_ms: 99.8
  iterations_since_restore: 430
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 830
  policy_reward_mean: {}
  time_since_restore: 5622.851243495941
  time_this_iter_s: 13.842404127120972
  time_total_s: 5622.851243495941
  timestamp: 1593815435
  timesteps_since_restore: 2150000
  timesteps_this_iter: 5000
  timesteps_total: 2150000
  training_iteration: 430
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 14.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=830], 5622 s, 430 iter, 2150000 ts, 405 rew

agent-1: 105.0
agent-2: 120.0
agent-3: 118.0
agent-4: 118.0
agent-5: 92.0
Sum Reward: 553.0
Avg Reward: 110.6
Min Reward: 92.0
Gini Coefficient 0.049909584086799276
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_18-30-45
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 751.0
  episode_reward_mean: 405.3
  episode_reward_min: 268.0
  episodes_this_iter: 1
  episodes_total: 430
  experiment_id: f3470259fa9143609a5dd5049ba7f979
  hostname: gpu020
  info:
    apply_time_ms: 3.595
    dispatch_time_ms: 9.281
    learner:
      cur_lr: 0.0012168099638074636
      grad_gnorm: 39.999996185302734
      policy_entropy: 32.726524353027344
      policy_loss: 3.280012607574463
      var_gnorm: 49.71258544921875
      vf_explained_var: 0.9279685020446777
      vf_loss: 11.849527359008789
    num_steps_sampled: 2155000
    num_steps_trained: 2155000
    wait_time_ms: 102.85
  iterations_since_restore: 431
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 830
  policy_reward_mean: {}
  time_since_restore: 5633.644150972366
  time_this_iter_s: 10.792907476425171
  time_total_s: 5633.644150972366
  timestamp: 1593815445
  timesteps_since_restore: 2155000
  timesteps_this_iter: 5000
  timesteps_total: 2155000
  training_iteration: 431
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 14.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=830], 5633 s, 431 iter, 2155000 ts, 405 rew

agent-1: 119.0
agent-2: 147.0
agent-3: 133.0
agent-4: 125.0
agent-5: 133.0
Sum Reward: 657.0
Avg Reward: 131.4
Min Reward: 119.0
Gini Coefficient 0.03896499238964993
agent-1: 113.0
agent-2: 131.0
agent-3: 85.0
agent-4: 136.0
agent-5: 116.0
Sum Reward: 581.0
Avg Reward: 116.2
Min Reward: 85.0
Gini Coefficient 0.08261617900172118
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_18-31-00
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 751.0
  episode_reward_mean: 409.7
  episode_reward_min: 268.0
  episodes_this_iter: 2
  episodes_total: 432
  experiment_id: f3470259fa9143609a5dd5049ba7f979
  hostname: gpu020
  info:
    apply_time_ms: 2.508
    dispatch_time_ms: 38.0
    learner:
      cur_lr: 0.0012164770159870386
      grad_gnorm: 39.99999237060547
      policy_entropy: 18.882070541381836
      policy_loss: 7.6057233810424805
      var_gnorm: 49.699729919433594
      vf_explained_var: -1.0
      vf_loss: 33.567962646484375
    num_steps_sampled: 2160000
    num_steps_trained: 2160000
    wait_time_ms: 107.549
  iterations_since_restore: 432
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 830
  policy_reward_mean: {}
  time_since_restore: 5647.768235683441
  time_this_iter_s: 14.124084711074829
  time_total_s: 5647.768235683441
  timestamp: 1593815460
  timesteps_since_restore: 2160000
  timesteps_this_iter: 5000
  timesteps_total: 2160000
  training_iteration: 432
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 14.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=830], 5647 s, 432 iter, 2160000 ts, 410 rew

Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_18-31-10
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 751.0
  episode_reward_mean: 409.7
  episode_reward_min: 268.0
  episodes_this_iter: 0
  episodes_total: 432
  experiment_id: f3470259fa9143609a5dd5049ba7f979
  hostname: gpu020
  info:
    apply_time_ms: 2.793
    dispatch_time_ms: 8.495
    learner:
      cur_lr: 0.0012161439517512918
      grad_gnorm: 40.0
      policy_entropy: 24.025907516479492
      policy_loss: -2.91629695892334
      var_gnorm: 49.67053985595703
      vf_explained_var: 0.5523684620857239
      vf_loss: 95.82312774658203
    num_steps_sampled: 2165000
    num_steps_trained: 2165000
    wait_time_ms: 110.831
  iterations_since_restore: 433
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 830
  policy_reward_mean: {}
  time_since_restore: 5658.1557013988495
  time_this_iter_s: 10.387465715408325
  time_total_s: 5658.1557013988495
  timestamp: 1593815470
  timesteps_since_restore: 2165000
  timesteps_this_iter: 5000
  timesteps_total: 2165000
  training_iteration: 433
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 14.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=830], 5658 s, 433 iter, 2165000 ts, 410 rew

agent-1: 63.0
agent-2: 79.0
agent-3: 60.0
agent-4: 73.0
agent-5: 92.0
Sum Reward: 367.0
Avg Reward: 73.4
Min Reward: 60.0
Gini Coefficient 0.08719346049046321
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-03_18-31-23
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 751.0
  episode_reward_mean: 409.71
  episode_reward_min: 268.0
  episodes_this_iter: 1
  episodes_total: 433
  experiment_id: f3470259fa9143609a5dd5049ba7f979
  hostname: gpu020
  info:
    apply_time_ms: 4.091
    dispatch_time_ms: 13.575
    learner:
      cur_lr: 0.0012158110039308667
      grad_gnorm: 5.425375938415527
      policy_entropy: 41.667049407958984
      policy_loss: 1.8849477767944336
      var_gnorm: 49.75810241699219
      vf_explained_var: 0.9952753186225891
      vf_loss: 0.07155225425958633
    num_steps_sampled: 2170000
    num_steps_trained: 2170000
    wait_time_ms: 109.139
  iterations_since_restore: 434
  node_ip: 172.17.8.20
  num_metric_batches_dropped: 0
  pid: 830
  policy_reward_mean: {}
  time_since_restore: 5670.7645926475525
  time_this_iter_s: 12.608891248703003
  time_total_s: 5670.7645926475525
  timestamp: 1593815483
  timesteps_since_restore: 2170000
  timesteps_this_iter: 5000
  timesteps_total: 2170000
  training_iteration: 434
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 14.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=830], 5670 s, 434 iter, 2170000 ts, 410 rew

agent-1: 86.0
agent-2: 84.0
agent-3: 85.0
agent-4: 68.0
agent-5: 106.0
Sum Reward: 429.0
Avg Reward: 85.8
Min Reward: 68.0
Gini Coefficient 0.07272727272727272
F0703 18:31:48.056870   825 node_manager.cc:1771]  Check failed: waiting_task_id_set.empty() 
*** Check failure stack trace: ***
    @           0x5b1006  google::LogMessage::Fail()
    @           0x5b0f52  google::LogMessage::SendToLog()
    @           0x5b08d6  google::LogMessage::Flush()
    @           0x5b06e5  google::LogMessage::~LogMessage()
    @           0x5020e8  ray::RayLog::~RayLog()
    @           0x53d9bd  ray::raylet::NodeManager::HandleObjectMissing()
    @           0x55f110  ray::ObjectStoreNotificationManager::ProcessStoreRemove()
    @           0x55fb00  ray::ObjectStoreNotificationManager::ProcessStoreNotification()
    @           0x560c42  boost::asio::detail::read_op<>::operator()()
    @           0x560e33  boost::asio::detail::reactive_socket_recv_op<>::do_complete()
    @           0x4bb41d  boost::asio::detail::scheduler::run()
    @           0x4b1bc7  main
    @     0x7fbbcb899b97  __libc_start_main
    @           0x4b7311  (unknown)
WARNING: Logging before InitGoogleLogging() is written to STDERR
F0703 18:31:48.082315   832 raylet_extension.cc:66]  Check failed: _s.ok() [RayletClient] Failed to get a task from raylet.: IOError: [RayletClient] Raylet connection closed.
*** Check failure stack trace: ***
Fatal Python error: Aborted

Stack (most recent call first):
  File "/h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/ray/worker.py", line 944 in _get_next_task_from_local_scheduler
  File "/h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/ray/worker.py", line 961 in main_loop
  File "/h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/ray/workers/default_worker.py", line 107 in <module>
WARNING: Logging before InitGoogleLogging() is written to STDERR
F0703 18:31:56.081985   841 raylet_extension.cc:66]  Check failed: _s.ok() [RayletClient] Failed to get a task from raylet.: IOError: [RayletClient] Connection closed unexpectedly.
*** Check failure stack trace: ***
Fatal Python error: Aborted

Stack (most recent call first):
  File "/h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/ray/worker.py", line 944 in _get_next_task_from_local_scheduler
  File "/h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/ray/worker.py", line 961 in main_loop
  File "/h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/ray/workers/default_worker.py", line 107 in <module>
WARNING: Logging before InitGoogleLogging() is written to STDERR
F0703 18:31:56.320106   745 raylet_extension.cc:190]  Check failed: _s.ok() [RayletClient] Failed to wait for objects.: IOError: [RayletClient] Raylet connection closed.
WARNING: Logging before InitGoogleLogging() is written to STDERR
F0703 18:31:56.320149   830 raylet_extension.cc:190]  Check failed: _s.ok() [RayletClient] Failed to wait for objects.: IOError: [RayletClient] Raylet connection closed.
*** Check failure stack trace: ***
*** Check failure stack trace: ***
Fatal Python error: AbortedFatal Python error: 

Aborted

Stack (most recent call first):
Stack (most recent call first):
  File   File ""//hh//zzhhaaoosstteepp//..ccoonnddaa//eennvvss//ccaauussaall//lliibb//ppyytthhoonn33..66//ssiittee--ppaacckkaaggeess//rraayy//wwoorrkkeerr..ppyy"", line , line 24852485 in  in wwaaiitt

  File   File "/h"//zhh/azohsatoespt/e.pc/o.ncdoan/dean/vesn/vcsa/ucsaauls/alli/bl/ipby/tphyotnh3o.n63/.s6i/tsei-tpea-cpkaacgkeasg/ersa/yr/atyu/nrel/lriaby/_otprtiiamli_zeexresc/uatsoyrn.cp_yg"r, line a199d in iegnetts__noepxtti_maivzaeirl.apbyl"e_t, line r46i in als
te  File p"
/  File h/z"h/aho/sztheapo/s.tceopn/d.ac/oenndvas//ecnavuss/acla/ulsiabl//plyitbh/opny3t.h6o/ns3i.t6e/-spiatcek-apgaecsk/argaeys//truanye//rtlrliiabl/_arguennntesr/.ap3yc"/, line a2593 in c._ppyr"o, line c68e in ss__tervaeinnt
s  File 
"  File /"h//hz/hzahoasotsetpe/p./c.ocnodnad/ae/nevnsv/sc/acuasuasla/ll/ilbi/bp/yptyhtohno3n.36./6s/istiet-ep-apcakcakgaegse/sr/arya/yt/utnuen/et/rtariinaalb_lreu.npnye"r.py, line "146, line  in 118t in rsatienp

  File   File "/"h//hz/hzahoasotsetpe/p./c.ocnodnad/ae/nevnsv/sc/acuasuasla/ll/ilbi/bp/yptyhtohno3n.36./6s/istiet-ep-apcakcakgaegse/sr/arya/yr/ltluinbe//atguennet.sp/ya"g, line e108n in tr.upny_"e, line x279p in etrriamienn
t  File s
"  File /h/zha"otsrtaeipn/_.acgoenndtas/.epnyv"s, line /201c in aumsaailn/
lib  File /"ptyrtahionn_3a.g6e/nstist.ep-yp"ac, line k223a in g<emso/drualye/>f
unction_manager.py", line 713 in actor_method_executor
  File "/h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/ray/worker.py", line 820 in _process_task
  File "/h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/ray/worker.py", line 919 in _wait_for_and_process_task
  File "/h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/ray/worker.py", line 962 in main_loop
  File "/h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/ray/workers/default_worker.py", line 107 in <module>
srun: error: gpu020: task 0: Aborted
