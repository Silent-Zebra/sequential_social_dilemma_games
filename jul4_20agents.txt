/h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:523: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint8 = np.dtype([("qint8", np.int8, 1)])
/h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:524: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint8 = np.dtype([("quint8", np.uint8, 1)])
/h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint16 = np.dtype([("qint16", np.int16, 1)])
/h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint16 = np.dtype([("quint16", np.uint16, 1)])
/h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint32 = np.dtype([("qint32", np.int32, 1)])
/h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:532: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  np_resource = np.dtype([("resource", np.ubyte, 1)])
Process STDOUT and STDERR is being redirected to /tmp/ray/session_2020-07-04_21-57-27_25418/logs.
Waiting for redis server at 127.0.0.1:22585 to respond...
Waiting for redis server at 127.0.0.1:52121 to respond...
Warning: Capping object memory store to 20.0GB. To increase this further, specify `object_store_memory` when calling ray.init() or ray start.
Starting the Plasma object store with 20.0 GB memory using /dev/shm.

======================================================================
View the web UI at http://localhost:8888/notebooks/ray_ui.ipynb?token=46a2acb06d0b29a7885cf6c82d94422885fbe33e04fc4318
======================================================================

== Status ==
Using FIFO scheduling algorithm.
Resources requested: 0/2 CPUs, 0/1 GPUs
Memory usage on this node: 14.3/202.5 GB

Created LogSyncer for /h/zhaostep/ray_results/harvest_A3C/A3C_harvest_env_0_2020-07-04_21-57-28yz3k82pd -> 
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 14.3/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING

/h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:523: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint8 = np.dtype([("qint8", np.int8, 1)])
/h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:524: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint8 = np.dtype([("quint8", np.uint8, 1)])
/h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint16 = np.dtype([("qint16", np.int16, 1)])
/h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint16 = np.dtype([("quint16", np.uint16, 1)])
/h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint32 = np.dtype([("qint32", np.int32, 1)])
/h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:532: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  np_resource = np.dtype([("resource", np.ubyte, 1)])
2020-07-04 21:57:40,615	INFO policy_evaluator.py:262 -- Creating policy evaluation worker 0 on CPU (please ignore any CUDA init errors)
2020-07-04 21:57:40.616276: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
From /h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/ray/rllib/models/lstm.py:59: BasicLSTMCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.
Instructions for updating:
This class is deprecated, please use tf.nn.rnn_cell.LSTMCell, which supports all the feature this cell currently has. Please replace the existing code with tf.nn.rnn_cell.LSTMCell(name='basic_lstm_cell').
/h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:523: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint8 = np.dtype([("qint8", np.int8, 1)])
/h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:524: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint8 = np.dtype([("quint8", np.uint8, 1)])
/h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint16 = np.dtype([("qint16", np.int16, 1)])
/h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint16 = np.dtype([("quint16", np.uint16, 1)])
/h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint32 = np.dtype([("qint32", np.int32, 1)])
/h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:532: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  np_resource = np.dtype([("resource", np.ubyte, 1)])
2020-07-04 21:57:52,476	INFO policy_evaluator.py:262 -- Creating policy evaluation worker 2 on CPU (please ignore any CUDA init errors)
/h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:523: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint8 = np.dtype([("qint8", np.int8, 1)])
/h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:524: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint8 = np.dtype([("quint8", np.uint8, 1)])
/h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint16 = np.dtype([("qint16", np.int16, 1)])
/h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint16 = np.dtype([("quint16", np.uint16, 1)])
/h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint32 = np.dtype([("qint32", np.int32, 1)])
/h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:532: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  np_resource = np.dtype([("resource", np.ubyte, 1)])
2020-07-04 21:57:52,477	INFO policy_evaluator.py:262 -- Creating policy evaluation worker 1 on CPU (please ignore any CUDA init errors)
2020-07-04 21:57:52.478020: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
2020-07-04 21:57:52.478185: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
From /h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/ray/rllib/models/lstm.py:59: BasicLSTMCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.
Instructions for updating:
This class is deprecated, please use tf.nn.rnn_cell.LSTMCell, which supports all the feature this cell currently has. Please replace the existing code with tf.nn.rnn_cell.LSTMCell(name='basic_lstm_cell').
From /h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/ray/rllib/models/lstm.py:59: BasicLSTMCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.
Instructions for updating:
This class is deprecated, please use tf.nn.rnn_cell.LSTMCell, which supports all the feature this cell currently has. Please replace the existing code with tf.nn.rnn_cell.LSTMCell(name='basic_lstm_cell').
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_21-58-22
  done: false
  episode_len_mean: .nan
  episode_reward_max: .nan
  episode_reward_mean: .nan
  episode_reward_min: .nan
  episodes_this_iter: 0
  episodes_total: 0
  experiment_id: 35d66058da2d4c9882f832ee91e4aa4a
  hostname: gpu011
  info:
    apply_time_ms: 5.242
    dispatch_time_ms: 11.21
    learner:
      cur_lr: 0.0013599999947473407
      grad_gnorm: 39.999996185302734
      policy_entropy: 358.845703125
      policy_loss: -4681.306640625
      var_gnorm: 18.11065101623535
      vf_explained_var: 0.001233220100402832
      vf_loss: 85849.375
    num_steps_sampled: 20000
    num_steps_trained: 20000
    wait_time_ms: 269.381
  iterations_since_restore: 1
  node_ip: 172.17.8.11
  num_metric_batches_dropped: 0
  pid: 25504
  policy_reward_mean: {}
  time_since_restore: 40.58528542518616
  time_this_iter_s: 40.58528542518616
  time_total_s: 40.58528542518616
  timestamp: 1593914302
  timesteps_since_restore: 20000
  timesteps_this_iter: 20000
  timesteps_total: 20000
  training_iteration: 1
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 15.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=25504], 40 s, 1 iter, 20000 ts, nan rew

[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.[0m
agent-1: -2500.0
agent-2: -1722.0
agent-3: -2927.0
agent-4: -1847.0
agent-5: -2663.0
agent-6: -2541.0
agent-7: -1971.0
agent-8: -2633.0
agent-9: -2369.0
agent-10: -2009.0
agent-11: -3418.0
agent-12: -2727.0
agent-13: -2034.0
agent-14: -1617.0
agent-15: -2499.0
agent-16: -2901.0
agent-17: -2022.0
agent-18: -1865.0
agent-19: -2265.0
agent-20: -1244.0
Sum Reward: -45774.0
Avg Reward: -2288.7
Min Reward: -3418.0
Gini Coefficient: -0.12567177873902216
20:20 Ratio: 0.5370416771068237
Max-min Ratio: 0.3639555295494441
[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.[0m
agent-1: -1383.0
agent-2: -1658.0
agent-3: -2046.0
agent-4: -2881.0
agent-5: -1859.0
agent-6: -2917.0
agent-7: -1820.0
agent-8: -2321.0
agent-9: -3228.0
agent-10: -1253.0
agent-11: -1613.0
agent-12: -1521.0
agent-13: -1579.0
agent-14: -2274.0
agent-15: -2998.0
agent-16: -2624.0
agent-17: -3411.0
agent-18: -2478.0
agent-19: -2320.0
agent-20: -2413.0
Sum Reward: -44597.0
Avg Reward: -2229.85
Min Reward: -3411.0
Gini Coefficient: -0.16010606094580354
20:20 Ratio: 0.4569061653656205
Max-min Ratio: 0.36734095573145703
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_21-58-51
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -44597.0
  episode_reward_mean: -45185.5
  episode_reward_min: -45774.0
  episodes_this_iter: 2
  episodes_total: 2
  experiment_id: 35d66058da2d4c9882f832ee91e4aa4a
  hostname: gpu011
  info:
    apply_time_ms: 3.166
    dispatch_time_ms: 7.14
    learner:
      cur_lr: 0.0013586679706349969
      grad_gnorm: 39.999996185302734
      policy_entropy: 145.1213836669922
      policy_loss: 3218.387451171875
      var_gnorm: 18.287582397460938
      vf_explained_var: -1.0
      vf_loss: 36936.33984375
    num_steps_sampled: 40000
    num_steps_trained: 40000
    wait_time_ms: 263.894
  iterations_since_restore: 2
  node_ip: 172.17.8.11
  num_metric_batches_dropped: 0
  pid: 25504
  policy_reward_mean: {}
  time_since_restore: 69.27530479431152
  time_this_iter_s: 28.690019369125366
  time_total_s: 69.27530479431152
  timestamp: 1593914331
  timesteps_since_restore: 40000
  timesteps_this_iter: 20000
  timesteps_total: 40000
  training_iteration: 2
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 15.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=25504], 69 s, 2 iter, 40000 ts, -4.52e+04 rew

Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_21-59-17
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -44597.0
  episode_reward_mean: -45185.5
  episode_reward_min: -45774.0
  episodes_this_iter: 0
  episodes_total: 2
  experiment_id: 35d66058da2d4c9882f832ee91e4aa4a
  hostname: gpu011
  info:
    apply_time_ms: 2.557
    dispatch_time_ms: 5.878
    learner:
      cur_lr: 0.001357335946522653
      grad_gnorm: 40.0
      policy_entropy: 274.3892822265625
      policy_loss: -225.07972717285156
      var_gnorm: 18.40536117553711
      vf_explained_var: -1.7881393432617188e-05
      vf_loss: 7947.9775390625
    num_steps_sampled: 60000
    num_steps_trained: 60000
    wait_time_ms: 271.018
  iterations_since_restore: 3
  node_ip: 172.17.8.11
  num_metric_batches_dropped: 0
  pid: 25504
  policy_reward_mean: {}
  time_since_restore: 96.01313090324402
  time_this_iter_s: 26.737826108932495
  time_total_s: 96.01313090324402
  timestamp: 1593914357
  timesteps_since_restore: 60000
  timesteps_this_iter: 20000
  timesteps_total: 60000
  training_iteration: 3
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 16.3/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=25504], 96 s, 3 iter, 60000 ts, -4.52e+04 rew

agent-1: -152.0
agent-2: -396.0
agent-3: -420.0
agent-4: -498.0
agent-5: -206.0
agent-6: -551.0
agent-7: -295.0
agent-8: -329.0
agent-9: -190.0
agent-10: -243.0
agent-11: -293.0
agent-12: -305.0
agent-13: -291.0
agent-14: -287.0
agent-15: -294.0
agent-16: -231.0
agent-17: -393.0
agent-18: -549.0
agent-19: -545.0
agent-20: -293.0
Sum Reward: -6761.0
Avg Reward: -338.05
Min Reward: -551.0
Gini Coefficient: -0.19301138884780358
20:20 Ratio: 0.3635090993933738
Max-min Ratio: 0.27586206896551724
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_21-59-45
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -6761.0
  episode_reward_mean: -32377.333333333332
  episode_reward_min: -45774.0
  episodes_this_iter: 1
  episodes_total: 3
  experiment_id: 35d66058da2d4c9882f832ee91e4aa4a
  hostname: gpu011
  info:
    apply_time_ms: 2.551
    dispatch_time_ms: 6.57
    learner:
      cur_lr: 0.0013560040388256311
      grad_gnorm: 40.0
      policy_entropy: 320.3610534667969
      policy_loss: -1030.7581787109375
      var_gnorm: 18.45328140258789
      vf_explained_var: -0.0018323659896850586
      vf_loss: 18599.5078125
    num_steps_sampled: 80000
    num_steps_trained: 80000
    wait_time_ms: 255.516
  iterations_since_restore: 4
  node_ip: 172.17.8.11
  num_metric_batches_dropped: 0
  pid: 25504
  policy_reward_mean: {}
  time_since_restore: 123.64887046813965
  time_this_iter_s: 27.63573956489563
  time_total_s: 123.64887046813965
  timestamp: 1593914385
  timesteps_since_restore: 80000
  timesteps_this_iter: 20000
  timesteps_total: 80000
  training_iteration: 4
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 16.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=25504], 123 s, 4 iter, 80000 ts, -3.24e+04 rew

agent-1: -138.0
agent-2: -352.0
agent-3: -384.0
agent-4: -48.0
agent-5: -82.0
agent-6: -299.0
agent-7: -183.0
agent-8: -435.0
agent-9: -297.0
agent-10: -224.0
agent-11: -194.0
agent-12: -657.0
agent-13: -298.0
agent-14: -236.0
agent-15: -552.0
agent-16: -180.0
agent-17: -735.0
agent-18: -250.0
agent-19: -488.0
agent-20: -146.0
Sum Reward: -6178.0
Avg Reward: -308.9
Min Reward: -735.0
Gini Coefficient: -0.32220783425056654
20:20 Ratio: 0.17023026315789475
Max-min Ratio: 0.0653061224489796
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_22-00-12
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -6178.0
  episode_reward_mean: -25827.5
  episode_reward_min: -45774.0
  episodes_this_iter: 1
  episodes_total: 4
  experiment_id: 35d66058da2d4c9882f832ee91e4aa4a
  hostname: gpu011
  info:
    apply_time_ms: 2.842
    dispatch_time_ms: 7.317
    learner:
      cur_lr: 0.0013546720147132874
      grad_gnorm: 40.0
      policy_entropy: 336.9349365234375
      policy_loss: 94.40518951416016
      var_gnorm: 18.646419525146484
      vf_explained_var: 0.05790287256240845
      vf_loss: 48.82847595214844
    num_steps_sampled: 100000
    num_steps_trained: 100000
    wait_time_ms: 259.528
  iterations_since_restore: 5
  node_ip: 172.17.8.11
  num_metric_batches_dropped: 0
  pid: 25504
  policy_reward_mean: {}
  time_since_restore: 149.9702582359314
  time_this_iter_s: 26.321387767791748
  time_total_s: 149.9702582359314
  timestamp: 1593914412
  timesteps_since_restore: 100000
  timesteps_this_iter: 20000
  timesteps_total: 100000
  training_iteration: 5
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 17.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=25504], 149 s, 5 iter, 100000 ts, -2.58e+04 rew

agent-1: -221.0
agent-2: -85.0
agent-3: -33.0
agent-4: -79.0
agent-5: -56.0
agent-6: -201.0
agent-7: -11.0
agent-8: -242.0
agent-9: -145.0
agent-10: -8.0
agent-11: 15.0
agent-12: 2.0
agent-13: -194.0
agent-14: -106.0
agent-15: -133.0
agent-16: -200.0
agent-17: 4.0
agent-18: -93.0
agent-19: -88.0
agent-20: -132.0
Sum Reward: -2006.0
Avg Reward: -100.3
Min Reward: -242.0
Gini Coefficient: -0.45219341974077765
20:20 Ratio: -0.015046296296296295
Max-min Ratio: -0.06198347107438017
agent-1: 6.0
agent-2: -79.0
agent-3: -42.0
agent-4: -84.0
agent-5: -81.0
agent-6: -135.0
agent-7: -87.0
agent-8: 12.0
agent-9: -37.0
agent-10: -150.0
agent-11: -65.0
agent-12: -79.0
agent-13: -75.0
agent-14: -222.0
agent-15: -393.0
agent-16: -76.0
agent-17: -88.0
agent-18: -201.0
agent-19: -26.0
agent-20: 16.0
Sum Reward: -1886.0
Avg Reward: -94.3
Min Reward: -393.0
Gini Coefficient: -0.4817603393425239
20:20 Ratio: -0.008281573498964804
Max-min Ratio: -0.04071246819338423
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_22-00-39
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -1886.0
  episode_reward_mean: -17867.0
  episode_reward_min: -45774.0
  episodes_this_iter: 2
  episodes_total: 6
  experiment_id: 35d66058da2d4c9882f832ee91e4aa4a
  hostname: gpu011
  info:
    apply_time_ms: 3.507
    dispatch_time_ms: 6.96
    learner:
      cur_lr: 0.0013533399906009436
      grad_gnorm: 40.00000762939453
      policy_entropy: 317.1839904785156
      policy_loss: 153.88575744628906
      var_gnorm: 18.730865478515625
      vf_explained_var: -0.0251237154006958
      vf_loss: 92.85198211669922
    num_steps_sampled: 120000
    num_steps_trained: 120000
    wait_time_ms: 264.986
  iterations_since_restore: 6
  node_ip: 172.17.8.11
  num_metric_batches_dropped: 0
  pid: 25504
  policy_reward_mean: {}
  time_since_restore: 177.4550085067749
  time_this_iter_s: 27.484750270843506
  time_total_s: 177.4550085067749
  timestamp: 1593914439
  timesteps_since_restore: 120000
  timesteps_this_iter: 20000
  timesteps_total: 120000
  training_iteration: 6
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 17.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=25504], 177 s, 6 iter, 120000 ts, -1.79e+04 rew

Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_22-01-06
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -1886.0
  episode_reward_mean: -17867.0
  episode_reward_min: -45774.0
  episodes_this_iter: 0
  episodes_total: 6
  experiment_id: 35d66058da2d4c9882f832ee91e4aa4a
  hostname: gpu011
  info:
    apply_time_ms: 2.434
    dispatch_time_ms: 6.434
    learner:
      cur_lr: 0.0013520079664885998
      grad_gnorm: 17.689340591430664
      policy_entropy: 208.11068725585938
      policy_loss: -5.9676313400268555
      var_gnorm: 18.772287368774414
      vf_explained_var: 0.19751882553100586
      vf_loss: 3.6274547576904297
    num_steps_sampled: 140000
    num_steps_trained: 140000
    wait_time_ms: 275.093
  iterations_since_restore: 7
  node_ip: 172.17.8.11
  num_metric_batches_dropped: 0
  pid: 25504
  policy_reward_mean: {}
  time_since_restore: 204.36342334747314
  time_this_iter_s: 26.908414840698242
  time_total_s: 204.36342334747314
  timestamp: 1593914466
  timesteps_since_restore: 140000
  timesteps_this_iter: 20000
  timesteps_total: 140000
  training_iteration: 7
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 17.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=25504], 204 s, 7 iter, 140000 ts, -1.79e+04 rew

agent-1: 17.0
agent-2: 25.0
agent-3: -35.0
agent-4: 4.0
agent-5: 37.0
agent-6: 27.0
agent-7: -9.0
agent-8: -42.0
agent-9: -29.0
agent-10: -46.0
agent-11: -85.0
agent-12: -2.0
agent-13: 6.0
agent-14: 31.0
agent-15: 29.0
agent-16: 16.0
agent-17: 27.0
agent-18: 13.0
agent-19: 33.0
agent-20: -73.0
Sum Reward: -56.0
Avg Reward: -2.8
Min Reward: -85.0
Gini Coefficient: -6.928571428571429
20:20 Ratio: -0.5284552845528455
Max-min Ratio: -0.43529411764705883
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_22-01-34
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -56.0
  episode_reward_mean: -15322.57142857143
  episode_reward_min: -45774.0
  episodes_this_iter: 1
  episodes_total: 7
  experiment_id: 35d66058da2d4c9882f832ee91e4aa4a
  hostname: gpu011
  info:
    apply_time_ms: 3.315
    dispatch_time_ms: 7.901
    learner:
      cur_lr: 0.001350675942376256
      grad_gnorm: 40.000003814697266
      policy_entropy: 242.08016967773438
      policy_loss: 176.18115234375
      var_gnorm: 18.789356231689453
      vf_explained_var: 0.02528280019760132
      vf_loss: 282.11956787109375
    num_steps_sampled: 160000
    num_steps_trained: 160000
    wait_time_ms: 253.665
  iterations_since_restore: 8
  node_ip: 172.17.8.11
  num_metric_batches_dropped: 0
  pid: 25504
  policy_reward_mean: {}
  time_since_restore: 231.93007516860962
  time_this_iter_s: 27.566651821136475
  time_total_s: 231.93007516860962
  timestamp: 1593914494
  timesteps_since_restore: 160000
  timesteps_this_iter: 20000
  timesteps_total: 160000
  training_iteration: 8
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 18.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=25504], 231 s, 8 iter, 160000 ts, -1.53e+04 rew

agent-1: 26.0
agent-2: 30.0
agent-3: 23.0
agent-4: 19.0
agent-5: 14.0
agent-6: -24.0
agent-7: 18.0
agent-8: 34.0
agent-9: 39.0
agent-10: 19.0
agent-11: 20.0
agent-12: 8.0
agent-13: -28.0
agent-14: 21.0
agent-15: 14.0
agent-16: 12.0
agent-17: 15.0
agent-18: 35.0
agent-19: 19.0
agent-20: 22.0
Sum Reward: 336.0
Avg Reward: 16.8
Min Reward: -28.0
Gini Coefficient: 0.4732142857142857
20:20 Ratio: -4.3125
Max-min Ratio: -1.3928571428571428
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_22-02-00
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 336.0
  episode_reward_mean: -13365.25
  episode_reward_min: -45774.0
  episodes_this_iter: 1
  episodes_total: 8
  experiment_id: 35d66058da2d4c9882f832ee91e4aa4a
  hostname: gpu011
  info:
    apply_time_ms: 2.625
    dispatch_time_ms: 7.796
    learner:
      cur_lr: 0.001349344034679234
      grad_gnorm: 39.999996185302734
      policy_entropy: 207.9113311767578
      policy_loss: -19.039419174194336
      var_gnorm: 18.812597274780273
      vf_explained_var: 5.960464477539063e-08
      vf_loss: 0.7985255122184753
    num_steps_sampled: 180000
    num_steps_trained: 180000
    wait_time_ms: 267.595
  iterations_since_restore: 9
  node_ip: 172.17.8.11
  num_metric_batches_dropped: 0
  pid: 25504
  policy_reward_mean: {}
  time_since_restore: 258.75500106811523
  time_this_iter_s: 26.824925899505615
  time_total_s: 258.75500106811523
  timestamp: 1593914520
  timesteps_since_restore: 180000
  timesteps_this_iter: 20000
  timesteps_total: 180000
  training_iteration: 9
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 18.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=25504], 258 s, 9 iter, 180000 ts, -1.34e+04 rew

agent-1: 12.0
agent-2: 12.0
agent-3: 6.0
agent-4: 16.0
agent-5: 44.0
agent-6: 15.0
agent-7: 17.0
agent-8: 20.0
agent-9: 32.0
agent-10: 8.0
agent-11: 21.0
agent-12: 16.0
agent-13: 17.0
agent-14: 10.0
agent-15: 38.0
agent-16: 28.0
agent-17: -28.0
agent-18: 16.0
agent-19: 15.0
agent-20: 23.0
Sum Reward: 338.0
Avg Reward: 16.9
Min Reward: -28.0
Gini Coefficient: 0.4076923076923077
20:20 Ratio: -35.5
Max-min Ratio: -1.5714285714285714
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_22-02-28
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 338.0
  episode_reward_mean: -11842.666666666666
  episode_reward_min: -45774.0
  episodes_this_iter: 1
  episodes_total: 9
  experiment_id: 35d66058da2d4c9882f832ee91e4aa4a
  hostname: gpu011
  info:
    apply_time_ms: 4.203
    dispatch_time_ms: 5.558
    learner:
      cur_lr: 0.0013480120105668902
      grad_gnorm: 40.000003814697266
      policy_entropy: 246.541259765625
      policy_loss: 168.95199584960938
      var_gnorm: 18.832246780395508
      vf_explained_var: -0.002599000930786133
      vf_loss: 204.96713256835938
    num_steps_sampled: 200000
    num_steps_trained: 200000
    wait_time_ms: 266.515
  iterations_since_restore: 10
  node_ip: 172.17.8.11
  num_metric_batches_dropped: 0
  pid: 25504
  policy_reward_mean: {}
  time_since_restore: 286.6006042957306
  time_this_iter_s: 27.845603227615356
  time_total_s: 286.6006042957306
  timestamp: 1593914548
  timesteps_since_restore: 200000
  timesteps_this_iter: 20000
  timesteps_total: 200000
  training_iteration: 10
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 18.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=25504], 286 s, 10 iter, 200000 ts, -1.18e+04 rew

agent-1: 3.0
agent-2: 21.0
agent-3: -19.0
agent-4: -27.0
agent-5: -42.0
agent-6: 22.0
agent-7: 10.0
agent-8: -41.0
agent-9: 10.0
agent-10: -29.0
agent-11: 17.0
agent-12: 21.0
agent-13: 16.0
agent-14: 17.0
agent-15: 17.0
agent-16: 27.0
agent-17: 24.0
agent-18: 16.0
agent-19: 41.0
agent-20: 5.0
Sum Reward: 109.0
Avg Reward: 5.45
Min Reward: -42.0
Gini Coefficient: 2.2509174311926605
20:20 Ratio: -0.8201438848920863
Max-min Ratio: -0.9761904761904762
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_22-02-55
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 338.0
  episode_reward_mean: -10647.5
  episode_reward_min: -45774.0
  episodes_this_iter: 1
  episodes_total: 10
  experiment_id: 35d66058da2d4c9882f832ee91e4aa4a
  hostname: gpu011
  info:
    apply_time_ms: 3.879
    dispatch_time_ms: 7.577
    learner:
      cur_lr: 0.0013466799864545465
      grad_gnorm: 38.97224807739258
      policy_entropy: 136.82237243652344
      policy_loss: -10.257928848266602
      var_gnorm: 18.84012794494629
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 0.5657826662063599
    num_steps_sampled: 220000
    num_steps_trained: 220000
    wait_time_ms: 265.932
  iterations_since_restore: 11
  node_ip: 172.17.8.11
  num_metric_batches_dropped: 0
  pid: 25504
  policy_reward_mean: {}
  time_since_restore: 313.4435398578644
  time_this_iter_s: 26.84293556213379
  time_total_s: 313.4435398578644
  timestamp: 1593914575
  timesteps_since_restore: 220000
  timesteps_this_iter: 20000
  timesteps_total: 220000
  training_iteration: 11
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 19.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=25504], 313 s, 11 iter, 220000 ts, -1.06e+04 rew

agent-1: -22.0
agent-2: -39.0
agent-3: 35.0
agent-4: 29.0
agent-5: 19.0
agent-6: 30.0
agent-7: 21.0
agent-8: -27.0
agent-9: 12.0
agent-10: -90.0
agent-11: 32.0
agent-12: 25.0
agent-13: -33.0
agent-14: 41.0
agent-15: 11.0
agent-16: 37.0
agent-17: 35.0
agent-18: -87.0
agent-19: 21.0
agent-20: 26.0
Sum Reward: 76.0
Avg Reward: 3.8
Min Reward: -90.0
Gini Coefficient: 5.211842105263158
20:20 Ratio: -0.5943775100401606
Max-min Ratio: -0.45555555555555555
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_22-03-23
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 338.0
  episode_reward_mean: -9672.636363636364
  episode_reward_min: -45774.0
  episodes_this_iter: 1
  episodes_total: 11
  experiment_id: 35d66058da2d4c9882f832ee91e4aa4a
  hostname: gpu011
  info:
    apply_time_ms: 3.416
    dispatch_time_ms: 6.61
    learner:
      cur_lr: 0.0013453479623422027
      grad_gnorm: 20.486637115478516
      policy_entropy: 159.4101104736328
      policy_loss: 0.80729079246521
      var_gnorm: 18.841564178466797
      vf_explained_var: 0.0
      vf_loss: 14.973533630371094
    num_steps_sampled: 240000
    num_steps_trained: 240000
    wait_time_ms: 264.271
  iterations_since_restore: 12
  node_ip: 172.17.8.11
  num_metric_batches_dropped: 0
  pid: 25504
  policy_reward_mean: {}
  time_since_restore: 341.1493697166443
  time_this_iter_s: 27.705829858779907
  time_total_s: 341.1493697166443
  timestamp: 1593914603
  timesteps_since_restore: 240000
  timesteps_this_iter: 20000
  timesteps_total: 240000
  training_iteration: 12
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 19.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=25504], 341 s, 12 iter, 240000 ts, -9.67e+03 rew

agent-1: 23.0
agent-2: 17.0
agent-3: 17.0
agent-4: 15.0
agent-5: 18.0
agent-6: -27.0
agent-7: 24.0
agent-8: 16.0
agent-9: 28.0
agent-10: 36.0
agent-11: 20.0
agent-12: 27.0
agent-13: 16.0
agent-14: 16.0
agent-15: 17.0
agent-16: 8.0
agent-17: 12.0
agent-18: 29.0
agent-19: 20.0
agent-20: 28.0
Sum Reward: 360.0
Avg Reward: 18.0
Min Reward: -27.0
Gini Coefficient: 0.30972222222222223
20:20 Ratio: 15.125
Max-min Ratio: -1.3333333333333333
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_22-03-50
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 360.0
  episode_reward_mean: -8836.583333333334
  episode_reward_min: -45774.0
  episodes_this_iter: 1
  episodes_total: 12
  experiment_id: 35d66058da2d4c9882f832ee91e4aa4a
  hostname: gpu011
  info:
    apply_time_ms: 3.227
    dispatch_time_ms: 5.707
    learner:
      cur_lr: 0.0013440160546451807
      grad_gnorm: 40.0
      policy_entropy: 191.37599182128906
      policy_loss: -25.767776489257812
      var_gnorm: 18.847612380981445
      vf_explained_var: 1.1920928955078125e-07
      vf_loss: 1.0901901721954346
    num_steps_sampled: 260000
    num_steps_trained: 260000
    wait_time_ms: 258.828
  iterations_since_restore: 13
  node_ip: 172.17.8.11
  num_metric_batches_dropped: 0
  pid: 25504
  policy_reward_mean: {}
  time_since_restore: 367.8086669445038
  time_this_iter_s: 26.659297227859497
  time_total_s: 367.8086669445038
  timestamp: 1593914630
  timesteps_since_restore: 260000
  timesteps_this_iter: 20000
  timesteps_total: 260000
  training_iteration: 13
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 19.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=25504], 367 s, 13 iter, 260000 ts, -8.84e+03 rew

agent-1: 16.0
agent-2: 29.0
agent-3: 18.0
agent-4: 11.0
agent-5: 17.0
agent-6: 16.0
agent-7: 6.0
agent-8: 19.0
agent-9: 11.0
agent-10: 38.0
agent-11: -35.0
agent-12: 10.0
agent-13: 25.0
agent-14: 11.0
agent-15: 16.0
agent-16: 5.0
agent-17: 26.0
agent-18: 22.0
agent-19: 11.0
agent-20: 21.0
Sum Reward: 293.0
Avg Reward: 14.65
Min Reward: -35.0
Gini Coefficient: 0.44283276450511944
20:20 Ratio: -8.428571428571429
Max-min Ratio: -1.0857142857142856
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_22-04-17
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 360.0
  episode_reward_mean: -8134.307692307692
  episode_reward_min: -45774.0
  episodes_this_iter: 1
  episodes_total: 13
  experiment_id: 35d66058da2d4c9882f832ee91e4aa4a
  hostname: gpu011
  info:
    apply_time_ms: 3.889
    dispatch_time_ms: 7.623
    learner:
      cur_lr: 0.001342684030532837
      grad_gnorm: 2.562300682067871
      policy_entropy: 205.3295440673828
      policy_loss: -1.0896116495132446
      var_gnorm: 18.85080337524414
      vf_explained_var: 2.980232238769531e-07
      vf_loss: 0.0021403832361102104
    num_steps_sampled: 280000
    num_steps_trained: 280000
    wait_time_ms: 258.773
  iterations_since_restore: 14
  node_ip: 172.17.8.11
  num_metric_batches_dropped: 0
  pid: 25504
  policy_reward_mean: {}
  time_since_restore: 395.64338970184326
  time_this_iter_s: 27.834722757339478
  time_total_s: 395.64338970184326
  timestamp: 1593914657
  timesteps_since_restore: 280000
  timesteps_this_iter: 20000
  timesteps_total: 280000
  training_iteration: 14
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 20.3/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=25504], 395 s, 14 iter, 280000 ts, -8.13e+03 rew

agent-1: -34.0
agent-2: 24.0
agent-3: 26.0
agent-4: 14.0
agent-5: 22.0
agent-6: 26.0
agent-7: 24.0
agent-8: 24.0
agent-9: -34.0
agent-10: 10.0
agent-11: 20.0
agent-12: 30.0
agent-13: 23.0
agent-14: 7.0
agent-15: 32.0
agent-16: 21.0
agent-17: 6.0
agent-18: 31.0
agent-19: 16.0
agent-20: 24.0
Sum Reward: 312.0
Avg Reward: 15.6
Min Reward: -34.0
Gini Coefficient: 0.5317307692307692
20:20 Ratio: -2.1636363636363636
Max-min Ratio: -0.9411764705882353
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_22-04-45
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 360.0
  episode_reward_mean: -7531.0
  episode_reward_min: -45774.0
  episodes_this_iter: 1
  episodes_total: 14
  experiment_id: 35d66058da2d4c9882f832ee91e4aa4a
  hostname: gpu011
  info:
    apply_time_ms: 2.953
    dispatch_time_ms: 6.752
    learner:
      cur_lr: 0.0013413520064204931
      grad_gnorm: 16.838531494140625
      policy_entropy: 186.8946990966797
      policy_loss: -4.834623336791992
      var_gnorm: 18.873231887817383
      vf_explained_var: 0.002623438835144043
      vf_loss: 3.6695396900177
    num_steps_sampled: 300000
    num_steps_trained: 300000
    wait_time_ms: 260.035
  iterations_since_restore: 15
  node_ip: 172.17.8.11
  num_metric_batches_dropped: 0
  pid: 25504
  policy_reward_mean: {}
  time_since_restore: 422.6418945789337
  time_this_iter_s: 26.998504877090454
  time_total_s: 422.6418945789337
  timestamp: 1593914685
  timesteps_since_restore: 300000
  timesteps_this_iter: 20000
  timesteps_total: 300000
  training_iteration: 15
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 20.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=25504], 422 s, 15 iter, 300000 ts, -7.53e+03 rew

agent-1: 23.0
agent-2: 48.0
agent-3: -26.0
agent-4: 45.0
agent-5: 19.0
agent-6: 19.0
agent-7: 22.0
agent-8: 15.0
agent-9: 28.0
agent-10: 26.0
agent-11: 7.0
agent-12: 20.0
agent-13: 16.0
agent-14: 4.0
agent-15: 32.0
agent-16: 15.0
agent-17: 39.0
agent-18: 30.0
agent-19: 15.0
agent-20: 2.0
Sum Reward: 399.0
Avg Reward: 19.95
Min Reward: -26.0
Gini Coefficient: 0.424937343358396
20:20 Ratio: -12.615384615384615
Max-min Ratio: -1.8461538461538463
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_22-05-12
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 399.0
  episode_reward_mean: -7002.333333333333
  episode_reward_min: -45774.0
  episodes_this_iter: 1
  episodes_total: 15
  experiment_id: 35d66058da2d4c9882f832ee91e4aa4a
  hostname: gpu011
  info:
    apply_time_ms: 3.17
    dispatch_time_ms: 7.721
    learner:
      cur_lr: 0.0013400199823081493
      grad_gnorm: 40.0
      policy_entropy: 175.47213745117188
      policy_loss: 118.76290130615234
      var_gnorm: 18.905982971191406
      vf_explained_var: -0.09214580059051514
      vf_loss: 151.6243133544922
    num_steps_sampled: 320000
    num_steps_trained: 320000
    wait_time_ms: 252.437
  iterations_since_restore: 16
  node_ip: 172.17.8.11
  num_metric_batches_dropped: 0
  pid: 25504
  policy_reward_mean: {}
  time_since_restore: 450.44299387931824
  time_this_iter_s: 27.80109930038452
  time_total_s: 450.44299387931824
  timestamp: 1593914712
  timesteps_since_restore: 320000
  timesteps_this_iter: 20000
  timesteps_total: 320000
  training_iteration: 16
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 21.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=25504], 450 s, 16 iter, 320000 ts, -7e+03 rew

agent-1: 21.0
agent-2: 38.0
agent-3: 28.0
agent-4: 17.0
agent-5: 17.0
agent-6: 12.0
agent-7: 15.0
agent-8: 13.0
agent-9: 16.0
agent-10: 11.0
agent-11: -36.0
agent-12: 11.0
agent-13: 28.0
agent-14: 18.0
agent-15: 18.0
agent-16: -30.0
agent-17: 17.0
agent-18: 38.0
agent-19: 20.0
agent-20: 36.0
Sum Reward: 308.0
Avg Reward: 15.4
Min Reward: -36.0
Gini Coefficient: 0.5607142857142857
20:20 Ratio: -3.1818181818181817
Max-min Ratio: -1.0555555555555556
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_22-05-39
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 399.0
  episode_reward_mean: -6545.4375
  episode_reward_min: -45774.0
  episodes_this_iter: 1
  episodes_total: 16
  experiment_id: 35d66058da2d4c9882f832ee91e4aa4a
  hostname: gpu011
  info:
    apply_time_ms: 2.608
    dispatch_time_ms: 7.225
    learner:
      cur_lr: 0.0013386879581958055
      grad_gnorm: 30.693857192993164
      policy_entropy: 196.47711181640625
      policy_loss: -12.361705780029297
      var_gnorm: 18.927812576293945
      vf_explained_var: 0.0
      vf_loss: 0.8112267255783081
    num_steps_sampled: 340000
    num_steps_trained: 340000
    wait_time_ms: 260.401
  iterations_since_restore: 17
  node_ip: 172.17.8.11
  num_metric_batches_dropped: 0
  pid: 25504
  policy_reward_mean: {}
  time_since_restore: 477.392418384552
  time_this_iter_s: 26.949424505233765
  time_total_s: 477.392418384552
  timestamp: 1593914739
  timesteps_since_restore: 340000
  timesteps_this_iter: 20000
  timesteps_total: 340000
  training_iteration: 17
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 21.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=25504], 477 s, 17 iter, 340000 ts, -6.55e+03 rew

agent-1: 26.0
agent-2: 26.0
agent-3: 16.0
agent-4: 19.0
agent-5: 10.0
agent-6: 18.0
agent-7: 26.0
agent-8: 28.0
agent-9: 21.0
agent-10: 28.0
agent-11: 11.0
agent-12: 30.0
agent-13: 15.0
agent-14: 18.0
agent-15: 19.0
agent-16: 19.0
agent-17: 27.0
agent-18: 16.0
agent-19: 16.0
agent-20: 13.0
Sum Reward: 402.0
Avg Reward: 20.1
Min Reward: 10.0
Gini Coefficient: 0.1664179104477612
20:20 Ratio: 2.306122448979592
Max-min Ratio: 3.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_22-06-07
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 402.0
  episode_reward_mean: -6136.764705882353
  episode_reward_min: -45774.0
  episodes_this_iter: 1
  episodes_total: 17
  experiment_id: 35d66058da2d4c9882f832ee91e4aa4a
  hostname: gpu011
  info:
    apply_time_ms: 2.952
    dispatch_time_ms: 7.819
    learner:
      cur_lr: 0.0013373560504987836
      grad_gnorm: 0.8303021788597107
      policy_entropy: 187.13328552246094
      policy_loss: 0.7155184745788574
      var_gnorm: 18.94061279296875
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 0.0001803605555323884
    num_steps_sampled: 360000
    num_steps_trained: 360000
    wait_time_ms: 268.582
  iterations_since_restore: 18
  node_ip: 172.17.8.11
  num_metric_batches_dropped: 0
  pid: 25504
  policy_reward_mean: {}
  time_since_restore: 505.13778924942017
  time_this_iter_s: 27.745370864868164
  time_total_s: 505.13778924942017
  timestamp: 1593914767
  timesteps_since_restore: 360000
  timesteps_this_iter: 20000
  timesteps_total: 360000
  training_iteration: 18
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 21.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=25504], 505 s, 18 iter, 360000 ts, -6.14e+03 rew

agent-1: 27.0
agent-2: 30.0
agent-3: 14.0
agent-4: 14.0
agent-5: 6.0
agent-6: 7.0
agent-7: 39.0
agent-8: 35.0
agent-9: 11.0
agent-10: 36.0
agent-11: 21.0
agent-12: 24.0
agent-13: 11.0
agent-14: 15.0
agent-15: 19.0
agent-16: 12.0
agent-17: 16.0
agent-18: 9.0
agent-19: 19.0
agent-20: 34.0
Sum Reward: 399.0
Avg Reward: 19.95
Min Reward: 6.0
Gini Coefficient: 0.28483709273182956
20:20 Ratio: 4.363636363636363
Max-min Ratio: 6.5
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_22-06-34
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 402.0
  episode_reward_mean: -5773.666666666667
  episode_reward_min: -45774.0
  episodes_this_iter: 1
  episodes_total: 18
  experiment_id: 35d66058da2d4c9882f832ee91e4aa4a
  hostname: gpu011
  info:
    apply_time_ms: 2.77
    dispatch_time_ms: 6.649
    learner:
      cur_lr: 0.0013360240263864398
      grad_gnorm: 16.95955467224121
      policy_entropy: 167.96507263183594
      policy_loss: 2.3829145431518555
      var_gnorm: 18.941905975341797
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 20.101055145263672
    num_steps_sampled: 380000
    num_steps_trained: 380000
    wait_time_ms: 265.574
  iterations_since_restore: 19
  node_ip: 172.17.8.11
  num_metric_batches_dropped: 0
  pid: 25504
  policy_reward_mean: {}
  time_since_restore: 531.7756719589233
  time_this_iter_s: 26.637882709503174
  time_total_s: 531.7756719589233
  timestamp: 1593914794
  timesteps_since_restore: 380000
  timesteps_this_iter: 20000
  timesteps_total: 380000
  training_iteration: 19
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 22.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=25504], 531 s, 19 iter, 380000 ts, -5.77e+03 rew

agent-1: 42.0
agent-2: -29.0
agent-3: 25.0
agent-4: 27.0
agent-5: 28.0
agent-6: 18.0
agent-7: 39.0
agent-8: 38.0
agent-9: 40.0
agent-10: 29.0
agent-11: 22.0
agent-12: 30.0
agent-13: 25.0
agent-14: 29.0
agent-15: 13.0
agent-16: 8.0
agent-17: 24.0
agent-18: 24.0
agent-19: 47.0
agent-20: 31.0
Sum Reward: 510.0
Avg Reward: 25.5
Min Reward: -29.0
Gini Coefficient: 0.29549019607843136
20:20 Ratio: 16.8
Max-min Ratio: -1.6206896551724137
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_22-07-01
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 510.0
  episode_reward_mean: -5442.9473684210525
  episode_reward_min: -45774.0
  episodes_this_iter: 1
  episodes_total: 19
  experiment_id: 35d66058da2d4c9882f832ee91e4aa4a
  hostname: gpu011
  info:
    apply_time_ms: 2.742
    dispatch_time_ms: 5.962
    learner:
      cur_lr: 0.001334692002274096
      grad_gnorm: 27.52721405029297
      policy_entropy: 119.33306884765625
      policy_loss: -6.607709884643555
      var_gnorm: 18.955156326293945
      vf_explained_var: 1.1920928955078125e-07
      vf_loss: 0.27511000633239746
    num_steps_sampled: 400000
    num_steps_trained: 400000
    wait_time_ms: 245.1
  iterations_since_restore: 20
  node_ip: 172.17.8.11
  num_metric_batches_dropped: 0
  pid: 25504
  policy_reward_mean: {}
  time_since_restore: 559.3133192062378
  time_this_iter_s: 27.537647247314453
  time_total_s: 559.3133192062378
  timestamp: 1593914821
  timesteps_since_restore: 400000
  timesteps_this_iter: 20000
  timesteps_total: 400000
  training_iteration: 20
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 22.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=25504], 559 s, 20 iter, 400000 ts, -5.44e+03 rew

agent-1: 17.0
agent-2: 23.0
agent-3: 6.0
agent-4: 34.0
agent-5: 6.0
agent-6: 36.0
agent-7: 12.0
agent-8: 7.0
agent-9: 23.0
agent-10: 52.0
agent-11: 16.0
agent-12: 25.0
agent-13: 15.0
agent-14: 27.0
agent-15: 38.0
agent-16: 16.0
agent-17: 23.0
agent-18: 24.0
agent-19: 29.0
agent-20: 12.0
Sum Reward: 441.0
Avg Reward: 22.05
Min Reward: 6.0
Gini Coefficient: 0.2896825396825397
20:20 Ratio: 5.161290322580645
Max-min Ratio: 8.666666666666666
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_22-07-28
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 510.0
  episode_reward_mean: -5148.75
  episode_reward_min: -45774.0
  episodes_this_iter: 1
  episodes_total: 20
  experiment_id: 35d66058da2d4c9882f832ee91e4aa4a
  hostname: gpu011
  info:
    apply_time_ms: 2.899
    dispatch_time_ms: 7.132
    learner:
      cur_lr: 0.0013333599781617522
      grad_gnorm: 24.27315902709961
      policy_entropy: 116.29196166992188
      policy_loss: 5.466155529022217
      var_gnorm: 18.960721969604492
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 22.577056884765625
    num_steps_sampled: 420000
    num_steps_trained: 420000
    wait_time_ms: 263.395
  iterations_since_restore: 21
  node_ip: 172.17.8.11
  num_metric_batches_dropped: 0
  pid: 25504
  policy_reward_mean: {}
  time_since_restore: 586.1994543075562
  time_this_iter_s: 26.88613510131836
  time_total_s: 586.1994543075562
  timestamp: 1593914848
  timesteps_since_restore: 420000
  timesteps_this_iter: 20000
  timesteps_total: 420000
  training_iteration: 21
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 22.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=25504], 586 s, 21 iter, 420000 ts, -5.15e+03 rew

agent-1: 26.0
agent-2: 40.0
agent-3: 42.0
agent-4: 33.0
agent-5: 28.0
agent-6: 11.0
agent-7: 26.0
agent-8: 29.0
agent-9: 16.0
agent-10: 18.0
agent-11: 40.0
agent-12: 46.0
agent-13: 21.0
agent-14: 18.0
agent-15: 28.0
agent-16: 22.0
agent-17: 20.0
agent-18: 17.0
agent-19: 25.0
agent-20: 15.0
Sum Reward: 521.0
Avg Reward: 26.05
Min Reward: 11.0
Gini Coefficient: 0.2064299424184261
20:20 Ratio: 2.847457627118644
Max-min Ratio: 4.181818181818182
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_22-07-56
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 521.0
  episode_reward_mean: -4878.761904761905
  episode_reward_min: -45774.0
  episodes_this_iter: 1
  episodes_total: 21
  experiment_id: 35d66058da2d4c9882f832ee91e4aa4a
  hostname: gpu011
  info:
    apply_time_ms: 2.761
    dispatch_time_ms: 7.511
    learner:
      cur_lr: 0.0013320279540494084
      grad_gnorm: 40.000003814697266
      policy_entropy: 142.7206573486328
      policy_loss: 48.169315338134766
      var_gnorm: 18.964040756225586
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 37.32066345214844
    num_steps_sampled: 440000
    num_steps_trained: 440000
    wait_time_ms: 251.857
  iterations_since_restore: 22
  node_ip: 172.17.8.11
  num_metric_batches_dropped: 0
  pid: 25504
  policy_reward_mean: {}
  time_since_restore: 613.863299369812
  time_this_iter_s: 27.66384506225586
  time_total_s: 613.863299369812
  timestamp: 1593914876
  timesteps_since_restore: 440000
  timesteps_this_iter: 20000
  timesteps_total: 440000
  training_iteration: 22
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 23.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=25504], 613 s, 22 iter, 440000 ts, -4.88e+03 rew

agent-1: 26.0
agent-2: 30.0
agent-3: 23.0
agent-4: 31.0
agent-5: 24.0
agent-6: 16.0
agent-7: 24.0
agent-8: 23.0
agent-9: 35.0
agent-10: 14.0
agent-11: 17.0
agent-12: 22.0
agent-13: 8.0
agent-14: 29.0
agent-15: 23.0
agent-16: 28.0
agent-17: 26.0
agent-18: 21.0
agent-19: 17.0
agent-20: 11.0
Sum Reward: 448.0
Avg Reward: 22.4
Min Reward: 8.0
Gini Coefficient: 0.16875
20:20 Ratio: 2.5510204081632653
Max-min Ratio: 4.375
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_22-08-23
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 521.0
  episode_reward_mean: -4636.636363636364
  episode_reward_min: -45774.0
  episodes_this_iter: 1
  episodes_total: 22
  experiment_id: 35d66058da2d4c9882f832ee91e4aa4a
  hostname: gpu011
  info:
    apply_time_ms: 3.26
    dispatch_time_ms: 5.648
    learner:
      cur_lr: 0.0013306960463523865
      grad_gnorm: 40.0
      policy_entropy: 133.00381469726562
      policy_loss: -13.978521347045898
      var_gnorm: 18.966745376586914
      vf_explained_var: 0.0
      vf_loss: 1.055390477180481
    num_steps_sampled: 460000
    num_steps_trained: 460000
    wait_time_ms: 261.493
  iterations_since_restore: 23
  node_ip: 172.17.8.11
  num_metric_batches_dropped: 0
  pid: 25504
  policy_reward_mean: {}
  time_since_restore: 640.718255519867
  time_this_iter_s: 26.85495615005493
  time_total_s: 640.718255519867
  timestamp: 1593914903
  timesteps_since_restore: 460000
  timesteps_this_iter: 20000
  timesteps_total: 460000
  training_iteration: 23
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 23.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=25504], 640 s, 23 iter, 460000 ts, -4.64e+03 rew

agent-1: -24.0
agent-2: 21.0
agent-3: 15.0
agent-4: 30.0
agent-5: 20.0
agent-6: -8.0
agent-7: 12.0
agent-8: 26.0
agent-9: 32.0
agent-10: 31.0
agent-11: 26.0
agent-12: 34.0
agent-13: 22.0
agent-14: 27.0
agent-15: 13.0
agent-16: 31.0
agent-17: 27.0
agent-18: 44.0
agent-19: 21.0
agent-20: 27.0
Sum Reward: 427.0
Avg Reward: 21.35
Min Reward: -24.0
Gini Coefficient: 0.33875878220140515
20:20 Ratio: -20.142857142857142
Max-min Ratio: -1.8333333333333333
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_22-08-51
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 521.0
  episode_reward_mean: -4416.478260869565
  episode_reward_min: -45774.0
  episodes_this_iter: 1
  episodes_total: 23
  experiment_id: 35d66058da2d4c9882f832ee91e4aa4a
  hostname: gpu011
  info:
    apply_time_ms: 2.841
    dispatch_time_ms: 7.519
    learner:
      cur_lr: 0.0013293640222400427
      grad_gnorm: 17.679962158203125
      policy_entropy: 171.23855590820312
      policy_loss: -5.822792053222656
      var_gnorm: 18.97430419921875
      vf_explained_var: 1.1920928955078125e-07
      vf_loss: 0.10842849314212799
    num_steps_sampled: 480000
    num_steps_trained: 480000
    wait_time_ms: 266.811
  iterations_since_restore: 24
  node_ip: 172.17.8.11
  num_metric_batches_dropped: 0
  pid: 25504
  policy_reward_mean: {}
  time_since_restore: 668.3439149856567
  time_this_iter_s: 27.625659465789795
  time_total_s: 668.3439149856567
  timestamp: 1593914931
  timesteps_since_restore: 480000
  timesteps_this_iter: 20000
  timesteps_total: 480000
  training_iteration: 24
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 24.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=25504], 668 s, 24 iter, 480000 ts, -4.42e+03 rew

agent-1: 6.0
agent-2: 16.0
agent-3: 22.0
agent-4: 6.0
agent-5: 33.0
agent-6: 39.0
agent-7: 27.0
agent-8: 11.0
agent-9: 28.0
agent-10: 5.0
agent-11: 32.0
agent-12: 22.0
agent-13: 23.0
agent-14: 24.0
agent-15: 27.0
agent-16: 15.0
agent-17: 19.0
agent-18: 11.0
agent-19: 16.0
agent-20: 11.0
Sum Reward: 393.0
Avg Reward: 19.65
Min Reward: 5.0
Gini Coefficient: 0.2741730279898219
20:20 Ratio: 4.714285714285714
Max-min Ratio: 7.8
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_22-09-18
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 521.0
  episode_reward_mean: -4216.083333333333
  episode_reward_min: -45774.0
  episodes_this_iter: 1
  episodes_total: 24
  experiment_id: 35d66058da2d4c9882f832ee91e4aa4a
  hostname: gpu011
  info:
    apply_time_ms: 3.97
    dispatch_time_ms: 6.44
    learner:
      cur_lr: 0.001328031998127699
      grad_gnorm: 40.0
      policy_entropy: 196.0354766845703
      policy_loss: 16.719829559326172
      var_gnorm: 18.978471755981445
      vf_explained_var: 1.1920928955078125e-07
      vf_loss: 33.387481689453125
    num_steps_sampled: 500000
    num_steps_trained: 500000
    wait_time_ms: 270.163
  iterations_since_restore: 25
  node_ip: 172.17.8.11
  num_metric_batches_dropped: 0
  pid: 25504
  policy_reward_mean: {}
  time_since_restore: 695.4497005939484
  time_this_iter_s: 27.105785608291626
  time_total_s: 695.4497005939484
  timestamp: 1593914958
  timesteps_since_restore: 500000
  timesteps_this_iter: 20000
  timesteps_total: 500000
  training_iteration: 25
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 24.3/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=25504], 695 s, 25 iter, 500000 ts, -4.22e+03 rew

agent-1: 10.0
agent-2: 4.0
agent-3: 28.0
agent-4: 22.0
agent-5: 20.0
agent-6: 12.0
agent-7: 20.0
agent-8: 13.0
agent-9: 14.0
agent-10: 8.0
agent-11: 8.0
agent-12: 12.0
agent-13: 20.0
agent-14: 15.0
agent-15: 9.0
agent-16: 10.0
agent-17: 12.0
agent-18: 12.0
agent-19: 5.0
agent-20: 17.0
Sum Reward: 271.0
Avg Reward: 13.55
Min Reward: 4.0
Gini Coefficient: 0.2422509225092251
20:20 Ratio: 3.6
Max-min Ratio: 7.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_22-09-46
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 521.0
  episode_reward_mean: -4036.6
  episode_reward_min: -45774.0
  episodes_this_iter: 1
  episodes_total: 25
  experiment_id: 35d66058da2d4c9882f832ee91e4aa4a
  hostname: gpu011
  info:
    apply_time_ms: 2.685
    dispatch_time_ms: 5.944
    learner:
      cur_lr: 0.0013266999740153551
      grad_gnorm: 0.3339535892009735
      policy_entropy: 211.9209442138672
      policy_loss: 0.46547776460647583
      var_gnorm: 18.97688865661621
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 1.1680514944600873e-05
    num_steps_sampled: 520000
    num_steps_trained: 520000
    wait_time_ms: 266.857
  iterations_since_restore: 26
  node_ip: 172.17.8.11
  num_metric_batches_dropped: 0
  pid: 25504
  policy_reward_mean: {}
  time_since_restore: 723.2285385131836
  time_this_iter_s: 27.77883791923523
  time_total_s: 723.2285385131836
  timestamp: 1593914986
  timesteps_since_restore: 520000
  timesteps_this_iter: 20000
  timesteps_total: 520000
  training_iteration: 26
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 24.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=25504], 723 s, 26 iter, 520000 ts, -4.04e+03 rew

agent-1: 23.0
agent-2: 42.0
agent-3: 36.0
agent-4: 41.0
agent-5: 25.0
agent-6: 15.0
agent-7: 16.0
agent-8: 22.0
agent-9: 13.0
agent-10: 6.0
agent-11: 38.0
agent-12: 5.0
agent-13: 25.0
agent-14: 24.0
agent-15: 4.0
agent-16: 33.0
agent-17: 30.0
agent-18: 24.0
agent-19: 13.0
agent-20: 32.0
Sum Reward: 467.0
Avg Reward: 23.35
Min Reward: 4.0
Gini Coefficient: 0.27890792291220556
20:20 Ratio: 5.607142857142857
Max-min Ratio: 10.5
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_22-10-13
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 521.0
  episode_reward_mean: -3863.3846153846152
  episode_reward_min: -45774.0
  episodes_this_iter: 1
  episodes_total: 26
  experiment_id: 35d66058da2d4c9882f832ee91e4aa4a
  hostname: gpu011
  info:
    apply_time_ms: 2.796
    dispatch_time_ms: 6.764
    learner:
      cur_lr: 0.0013253679499030113
      grad_gnorm: 10.86713981628418
      policy_entropy: 182.81338500976562
      policy_loss: -3.9983737468719482
      var_gnorm: 18.977258682250977
      vf_explained_var: 0.0
      vf_loss: 0.042065851390361786
    num_steps_sampled: 540000
    num_steps_trained: 540000
    wait_time_ms: 269.957
  iterations_since_restore: 27
  node_ip: 172.17.8.11
  num_metric_batches_dropped: 0
  pid: 25504
  policy_reward_mean: {}
  time_since_restore: 750.3916888237
  time_this_iter_s: 27.163150310516357
  time_total_s: 750.3916888237
  timestamp: 1593915013
  timesteps_since_restore: 540000
  timesteps_this_iter: 20000
  timesteps_total: 540000
  training_iteration: 27
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=25504], 750 s, 27 iter, 540000 ts, -3.86e+03 rew

agent-1: 18.0
agent-2: 22.0
agent-3: 6.0
agent-4: 18.0
agent-5: 2.0
agent-6: 13.0
agent-7: 21.0
agent-8: 14.0
agent-9: 21.0
agent-10: 14.0
agent-11: 14.0
agent-12: 16.0
agent-13: 9.0
agent-14: 8.0
agent-15: 10.0
agent-16: 12.0
agent-17: 12.0
agent-18: 8.0
agent-19: 15.0
agent-20: 8.0
Sum Reward: 261.0
Avg Reward: 13.05
Min Reward: 2.0
Gini Coefficient: 0.22701149425287356
20:20 Ratio: 3.4166666666666665
Max-min Ratio: 11.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_22-10-41
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 521.0
  episode_reward_mean: -3710.6296296296296
  episode_reward_min: -45774.0
  episodes_this_iter: 1
  episodes_total: 27
  experiment_id: 35d66058da2d4c9882f832ee91e4aa4a
  hostname: gpu011
  info:
    apply_time_ms: 4.071
    dispatch_time_ms: 5.824
    learner:
      cur_lr: 0.0013240360422059894
      grad_gnorm: 40.0
      policy_entropy: 190.3854522705078
      policy_loss: 130.85858154296875
      var_gnorm: 18.978412628173828
      vf_explained_var: 1.1920928955078125e-07
      vf_loss: 166.481689453125
    num_steps_sampled: 560000
    num_steps_trained: 560000
    wait_time_ms: 251.929
  iterations_since_restore: 28
  node_ip: 172.17.8.11
  num_metric_batches_dropped: 0
  pid: 25504
  policy_reward_mean: {}
  time_since_restore: 778.3113985061646
  time_this_iter_s: 27.9197096824646
  time_total_s: 778.3113985061646
  timestamp: 1593915041
  timesteps_since_restore: 560000
  timesteps_this_iter: 20000
  timesteps_total: 560000
  training_iteration: 28
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=25504], 778 s, 28 iter, 560000 ts, -3.71e+03 rew

agent-1: 5.0
agent-2: 18.0
agent-3: 30.0
agent-4: 25.0
agent-5: 28.0
agent-6: 4.0
agent-7: 41.0
agent-8: 11.0
agent-9: 14.0
agent-10: 12.0
agent-11: 37.0
agent-12: 8.0
agent-13: 12.0
agent-14: 4.0
agent-15: 17.0
agent-16: 18.0
agent-17: 9.0
agent-18: 15.0
agent-19: 35.0
agent-20: 21.0
Sum Reward: 364.0
Avg Reward: 18.2
Min Reward: 4.0
Gini Coefficient: 0.3354395604395604
20:20 Ratio: 6.809523809523809
Max-min Ratio: 10.25
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_22-11-08
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 521.0
  episode_reward_mean: -3565.1071428571427
  episode_reward_min: -45774.0
  episodes_this_iter: 1
  episodes_total: 28
  experiment_id: 35d66058da2d4c9882f832ee91e4aa4a
  hostname: gpu011
  info:
    apply_time_ms: 3.237
    dispatch_time_ms: 5.808
    learner:
      cur_lr: 0.0013227040180936456
      grad_gnorm: 12.944262504577637
      policy_entropy: 171.37600708007812
      policy_loss: -4.95400333404541
      var_gnorm: 18.98217010498047
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 0.059747714549303055
    num_steps_sampled: 580000
    num_steps_trained: 580000
    wait_time_ms: 270.179
  iterations_since_restore: 29
  node_ip: 172.17.8.11
  num_metric_batches_dropped: 0
  pid: 25504
  policy_reward_mean: {}
  time_since_restore: 805.8139650821686
  time_this_iter_s: 27.50256657600403
  time_total_s: 805.8139650821686
  timestamp: 1593915068
  timesteps_since_restore: 580000
  timesteps_this_iter: 20000
  timesteps_total: 580000
  training_iteration: 29
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=25504], 805 s, 29 iter, 580000 ts, -3.57e+03 rew

agent-1: 22.0
agent-2: 11.0
agent-3: 16.0
agent-4: 6.0
agent-5: 28.0
agent-6: 6.0
agent-7: 13.0
agent-8: 19.0
agent-9: 24.0
agent-10: 21.0
agent-11: 18.0
agent-12: 9.0
agent-13: 11.0
agent-14: 13.0
agent-15: 10.0
agent-16: 34.0
agent-17: 14.0
agent-18: 5.0
agent-19: 14.0
agent-20: 16.0
Sum Reward: 310.0
Avg Reward: 15.5
Min Reward: 5.0
Gini Coefficient: 0.2629032258064516
20:20 Ratio: 4.153846153846154
Max-min Ratio: 6.8
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_22-11-36
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 521.0
  episode_reward_mean: -3431.4827586206898
  episode_reward_min: -45774.0
  episodes_this_iter: 1
  episodes_total: 29
  experiment_id: 35d66058da2d4c9882f832ee91e4aa4a
  hostname: gpu011
  info:
    apply_time_ms: 2.867
    dispatch_time_ms: 11.485
    learner:
      cur_lr: 0.0013213719939813018
      grad_gnorm: 40.0
      policy_entropy: 204.53221130371094
      policy_loss: 128.65988159179688
      var_gnorm: 18.981443405151367
      vf_explained_var: 0.0
      vf_loss: 145.90438842773438
    num_steps_sampled: 600000
    num_steps_trained: 600000
    wait_time_ms: 248.263
  iterations_since_restore: 30
  node_ip: 172.17.8.11
  num_metric_batches_dropped: 0
  pid: 25504
  policy_reward_mean: {}
  time_since_restore: 833.5264887809753
  time_this_iter_s: 27.712523698806763
  time_total_s: 833.5264887809753
  timestamp: 1593915096
  timesteps_since_restore: 600000
  timesteps_this_iter: 20000
  timesteps_total: 600000
  training_iteration: 30
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=25504], 833 s, 30 iter, 600000 ts, -3.43e+03 rew

agent-1: 12.0
agent-2: 10.0
agent-3: 22.0
agent-4: 11.0
agent-5: 8.0
agent-6: 3.0
agent-7: 34.0
agent-8: 27.0
agent-9: 16.0
agent-10: 14.0
agent-11: 11.0
agent-12: 8.0
agent-13: 3.0
agent-14: 16.0
agent-15: 8.0
agent-16: 12.0
agent-17: 16.0
agent-18: 22.0
agent-19: 10.0
agent-20: 18.0
Sum Reward: 281.0
Avg Reward: 14.05
Min Reward: 3.0
Gini Coefficient: 0.28985765124555163
20:20 Ratio: 4.7727272727272725
Max-min Ratio: 11.333333333333334
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_22-12-03
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 521.0
  episode_reward_mean: -3307.733333333333
  episode_reward_min: -45774.0
  episodes_this_iter: 1
  episodes_total: 30
  experiment_id: 35d66058da2d4c9882f832ee91e4aa4a
  hostname: gpu011
  info:
    apply_time_ms: 2.603
    dispatch_time_ms: 6.948
    learner:
      cur_lr: 0.001320039969868958
      grad_gnorm: 40.0
      policy_entropy: 174.7215118408203
      policy_loss: 49.13641357421875
      var_gnorm: 18.984939575195312
      vf_explained_var: 1.1920928955078125e-07
      vf_loss: 49.47369384765625
    num_steps_sampled: 620000
    num_steps_trained: 620000
    wait_time_ms: 260.98
  iterations_since_restore: 31
  node_ip: 172.17.8.11
  num_metric_batches_dropped: 0
  pid: 25504
  policy_reward_mean: {}
  time_since_restore: 860.686812877655
  time_this_iter_s: 27.160324096679688
  time_total_s: 860.686812877655
  timestamp: 1593915123
  timesteps_since_restore: 620000
  timesteps_this_iter: 20000
  timesteps_total: 620000
  training_iteration: 31
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=25504], 860 s, 31 iter, 620000 ts, -3.31e+03 rew

agent-1: 29.0
agent-2: 40.0
agent-3: 11.0
agent-4: 10.0
agent-5: 9.0
agent-6: 14.0
agent-7: 16.0
agent-8: 30.0
agent-9: 21.0
agent-10: 10.0
agent-11: 23.0
agent-12: 22.0
agent-13: 33.0
agent-14: 12.0
agent-15: 16.0
agent-16: 38.0
agent-17: 14.0
agent-18: 16.0
agent-19: 7.0
agent-20: 11.0
Sum Reward: 382.0
Avg Reward: 19.1
Min Reward: 7.0
Gini Coefficient: 0.28036649214659687
20:20 Ratio: 3.9166666666666665
Max-min Ratio: 5.714285714285714
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_22-12-31
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 521.0
  episode_reward_mean: -3188.7096774193546
  episode_reward_min: -45774.0
  episodes_this_iter: 1
  episodes_total: 31
  experiment_id: 35d66058da2d4c9882f832ee91e4aa4a
  hostname: gpu011
  info:
    apply_time_ms: 2.763
    dispatch_time_ms: 7.821
    learner:
      cur_lr: 0.0013187079457566142
      grad_gnorm: 0.5839203596115112
      policy_entropy: 209.22129821777344
      policy_loss: 0.3019869327545166
      var_gnorm: 18.984094619750977
      vf_explained_var: 5.960464477539063e-08
      vf_loss: 2.351707371417433e-05
    num_steps_sampled: 640000
    num_steps_trained: 640000
    wait_time_ms: 268.158
  iterations_since_restore: 32
  node_ip: 172.17.8.11
  num_metric_batches_dropped: 0
  pid: 25504
  policy_reward_mean: {}
  time_since_restore: 888.5401904582977
  time_this_iter_s: 27.8533775806427
  time_total_s: 888.5401904582977
  timestamp: 1593915151
  timesteps_since_restore: 640000
  timesteps_this_iter: 20000
  timesteps_total: 640000
  training_iteration: 32
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=25504], 888 s, 32 iter, 640000 ts, -3.19e+03 rew

agent-1: 16.0
agent-2: 13.0
agent-3: 14.0
agent-4: 12.0
agent-5: 16.0
agent-6: 26.0
agent-7: 20.0
agent-8: 11.0
agent-9: 13.0
agent-10: 14.0
agent-11: 8.0
agent-12: 3.0
agent-13: 25.0
agent-14: 7.0
agent-15: 23.0
agent-16: 16.0
agent-17: 6.0
agent-18: 1.0
agent-19: 4.0
agent-20: 22.0
Sum Reward: 270.0
Avg Reward: 13.5
Min Reward: 1.0
Gini Coefficient: 0.2992592592592593
20:20 Ratio: 6.857142857142857
Max-min Ratio: 26.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_22-12-58
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 521.0
  episode_reward_mean: -3080.625
  episode_reward_min: -45774.0
  episodes_this_iter: 1
  episodes_total: 32
  experiment_id: 35d66058da2d4c9882f832ee91e4aa4a
  hostname: gpu011
  info:
    apply_time_ms: 3.906
    dispatch_time_ms: 6.524
    learner:
      cur_lr: 0.0013173760380595922
      grad_gnorm: 16.341083526611328
      policy_entropy: 189.133056640625
      policy_loss: -5.97702693939209
      var_gnorm: 18.988130569458008
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 0.09459969401359558
    num_steps_sampled: 660000
    num_steps_trained: 660000
    wait_time_ms: 269.894
  iterations_since_restore: 33
  node_ip: 172.17.8.11
  num_metric_batches_dropped: 0
  pid: 25504
  policy_reward_mean: {}
  time_since_restore: 915.9890270233154
  time_this_iter_s: 27.4488365650177
  time_total_s: 915.9890270233154
  timestamp: 1593915178
  timesteps_since_restore: 660000
  timesteps_this_iter: 20000
  timesteps_total: 660000
  training_iteration: 33
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 27.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=25504], 915 s, 33 iter, 660000 ts, -3.08e+03 rew

agent-1: 5.0
agent-2: 16.0
agent-3: 14.0
agent-4: 22.0
agent-5: 6.0
agent-6: 1.0
agent-7: 12.0
agent-8: 17.0
agent-9: 12.0
agent-10: 12.0
agent-11: 26.0
agent-12: 12.0
agent-13: 15.0
agent-14: 12.0
agent-15: 28.0
agent-16: 13.0
agent-17: 16.0
agent-18: 11.0
agent-19: 15.0
agent-20: 11.0
Sum Reward: 276.0
Avg Reward: 13.8
Min Reward: 1.0
Gini Coefficient: 0.2394927536231884
20:20 Ratio: 4.043478260869565
Max-min Ratio: 28.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_22-13-26
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 521.0
  episode_reward_mean: -2978.909090909091
  episode_reward_min: -45774.0
  episodes_this_iter: 1
  episodes_total: 33
  experiment_id: 35d66058da2d4c9882f832ee91e4aa4a
  hostname: gpu011
  info:
    apply_time_ms: 2.576
    dispatch_time_ms: 5.958
    learner:
      cur_lr: 0.0013160440139472485
      grad_gnorm: 0.36598876118659973
      policy_entropy: 192.36309814453125
      policy_loss: 0.12629380822181702
      var_gnorm: 18.987728118896484
      vf_explained_var: 0.0
      vf_loss: 2.2199685190571472e-05
    num_steps_sampled: 680000
    num_steps_trained: 680000
    wait_time_ms: 267.661
  iterations_since_restore: 34
  node_ip: 172.17.8.11
  num_metric_batches_dropped: 0
  pid: 25504
  policy_reward_mean: {}
  time_since_restore: 943.7317566871643
  time_this_iter_s: 27.742729663848877
  time_total_s: 943.7317566871643
  timestamp: 1593915206
  timesteps_since_restore: 680000
  timesteps_this_iter: 20000
  timesteps_total: 680000
  training_iteration: 34
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 27.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=25504], 943 s, 34 iter, 680000 ts, -2.98e+03 rew

agent-1: 14.0
agent-2: 8.0
agent-3: 5.0
agent-4: 8.0
agent-5: 8.0
agent-6: 6.0
agent-7: 19.0
agent-8: 32.0
agent-9: 14.0
agent-10: 22.0
agent-11: 13.0
agent-12: 13.0
agent-13: 17.0
agent-14: 27.0
agent-15: 4.0
agent-16: 18.0
agent-17: 27.0
agent-18: 10.0
agent-19: 13.0
agent-20: 14.0
Sum Reward: 292.0
Avg Reward: 14.6
Min Reward: 4.0
Gini Coefficient: 0.2863013698630137
20:20 Ratio: 4.695652173913044
Max-min Ratio: 8.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_22-13-54
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 521.0
  episode_reward_mean: -2882.705882352941
  episode_reward_min: -45774.0
  episodes_this_iter: 1
  episodes_total: 34
  experiment_id: 35d66058da2d4c9882f832ee91e4aa4a
  hostname: gpu011
  info:
    apply_time_ms: 2.836
    dispatch_time_ms: 6.493
    learner:
      cur_lr: 0.0013147119898349047
      grad_gnorm: 18.558942794799805
      policy_entropy: 187.05445861816406
      policy_loss: -6.776093006134033
      var_gnorm: 18.991464614868164
      vf_explained_var: 1.1920928955078125e-07
      vf_loss: 0.11780733615159988
    num_steps_sampled: 700000
    num_steps_trained: 700000
    wait_time_ms: 270.549
  iterations_since_restore: 35
  node_ip: 172.17.8.11
  num_metric_batches_dropped: 0
  pid: 25504
  policy_reward_mean: {}
  time_since_restore: 971.0352301597595
  time_this_iter_s: 27.303473472595215
  time_total_s: 971.0352301597595
  timestamp: 1593915234
  timesteps_since_restore: 700000
  timesteps_this_iter: 20000
  timesteps_total: 700000
  training_iteration: 35
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=25504], 971 s, 35 iter, 700000 ts, -2.88e+03 rew

agent-1: 15.0
agent-2: 19.0
agent-3: 9.0
agent-4: 15.0
agent-5: 16.0
agent-6: 10.0
agent-7: 10.0
agent-8: 7.0
agent-9: 22.0
agent-10: 11.0
agent-11: 5.0
agent-12: 21.0
agent-13: 14.0
agent-14: 25.0
agent-15: 30.0
agent-16: 7.0
agent-17: 17.0
agent-18: 18.0
agent-19: 9.0
agent-20: 4.0
Sum Reward: 284.0
Avg Reward: 14.2
Min Reward: 4.0
Gini Coefficient: 0.26830985915492955
20:20 Ratio: 4.260869565217392
Max-min Ratio: 7.5
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_22-14-21
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 521.0
  episode_reward_mean: -2792.2285714285713
  episode_reward_min: -45774.0
  episodes_this_iter: 1
  episodes_total: 35
  experiment_id: 35d66058da2d4c9882f832ee91e4aa4a
  hostname: gpu011
  info:
    apply_time_ms: 3.169
    dispatch_time_ms: 6.459
    learner:
      cur_lr: 0.0013133799657225609
      grad_gnorm: 39.999996185302734
      policy_entropy: 176.97064208984375
      policy_loss: 113.60499572753906
      var_gnorm: 18.990127563476562
      vf_explained_var: 0.0
      vf_loss: 123.87301635742188
    num_steps_sampled: 720000
    num_steps_trained: 720000
    wait_time_ms: 254.412
  iterations_since_restore: 36
  node_ip: 172.17.8.11
  num_metric_batches_dropped: 0
  pid: 25504
  policy_reward_mean: {}
  time_since_restore: 998.9335889816284
  time_this_iter_s: 27.898358821868896
  time_total_s: 998.9335889816284
  timestamp: 1593915261
  timesteps_since_restore: 720000
  timesteps_this_iter: 20000
  timesteps_total: 720000
  training_iteration: 36
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.3/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=25504], 998 s, 36 iter, 720000 ts, -2.79e+03 rew

agent-1: 22.0
agent-2: 27.0
agent-3: 16.0
agent-4: 24.0
agent-5: 5.0
agent-6: 28.0
agent-7: 15.0
agent-8: 11.0
agent-9: 6.0
agent-10: 7.0
agent-11: 24.0
agent-12: 20.0
agent-13: 26.0
agent-14: 9.0
agent-15: 12.0
agent-16: 21.0
agent-17: 11.0
agent-18: 11.0
agent-19: 5.0
agent-20: 30.0
Sum Reward: 330.0
Avg Reward: 16.5
Min Reward: 5.0
Gini Coefficient: 0.2821212121212121
20:20 Ratio: 4.826086956521739
Max-min Ratio: 6.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_22-14-49
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 521.0
  episode_reward_mean: -2705.5
  episode_reward_min: -45774.0
  episodes_this_iter: 1
  episodes_total: 36
  experiment_id: 35d66058da2d4c9882f832ee91e4aa4a
  hostname: gpu011
  info:
    apply_time_ms: 2.595
    dispatch_time_ms: 6.369
    learner:
      cur_lr: 0.001312048058025539
      grad_gnorm: 19.048683166503906
      policy_entropy: 189.62948608398438
      policy_loss: -6.629648685455322
      var_gnorm: 18.993288040161133
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 0.12161887437105179
    num_steps_sampled: 740000
    num_steps_trained: 740000
    wait_time_ms: 267.096
  iterations_since_restore: 37
  node_ip: 172.17.8.11
  num_metric_batches_dropped: 0
  pid: 25504
  policy_reward_mean: {}
  time_since_restore: 1026.1312491893768
  time_this_iter_s: 27.197660207748413
  time_total_s: 1026.1312491893768
  timestamp: 1593915289
  timesteps_since_restore: 740000
  timesteps_this_iter: 20000
  timesteps_total: 740000
  training_iteration: 37
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=25504], 1026 s, 37 iter, 740000 ts, -2.71e+03 rew

agent-1: 12.0
agent-2: 10.0
agent-3: 6.0
agent-4: 14.0
agent-5: 35.0
agent-6: 6.0
agent-7: 15.0
agent-8: 22.0
agent-9: 9.0
agent-10: 18.0
agent-11: 11.0
agent-12: 14.0
agent-13: 13.0
agent-14: -43.0
agent-15: 18.0
agent-16: 21.0
agent-17: 6.0
agent-18: 7.0
agent-19: -29.0
agent-20: 16.0
Sum Reward: 181.0
Avg Reward: 9.05
Min Reward: -43.0
Gini Coefficient: 0.8328729281767956
20:20 Ratio: -1.6
Max-min Ratio: -0.813953488372093
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_22-15-17
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 521.0
  episode_reward_mean: -2627.4864864864867
  episode_reward_min: -45774.0
  episodes_this_iter: 1
  episodes_total: 37
  experiment_id: 35d66058da2d4c9882f832ee91e4aa4a
  hostname: gpu011
  info:
    apply_time_ms: 2.439
    dispatch_time_ms: 6.351
    learner:
      cur_lr: 0.0013107160339131951
      grad_gnorm: 40.0
      policy_entropy: 200.9132537841797
      policy_loss: 171.26004028320312
      var_gnorm: 18.993547439575195
      vf_explained_var: -0.007025718688964844
      vf_loss: 243.44667053222656
    num_steps_sampled: 760000
    num_steps_trained: 760000
    wait_time_ms: 259.073
  iterations_since_restore: 38
  node_ip: 172.17.8.11
  num_metric_batches_dropped: 0
  pid: 25504
  policy_reward_mean: {}
  time_since_restore: 1053.9435331821442
  time_this_iter_s: 27.812283992767334
  time_total_s: 1053.9435331821442
  timestamp: 1593915317
  timesteps_since_restore: 760000
  timesteps_this_iter: 20000
  timesteps_total: 760000
  training_iteration: 38
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 29.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=25504], 1053 s, 38 iter, 760000 ts, -2.63e+03 rew

agent-1: 21.0
agent-2: 9.0
agent-3: 5.0
agent-4: 9.0
agent-5: 35.0
agent-6: 12.0
agent-7: 8.0
agent-8: 15.0
agent-9: 37.0
agent-10: 27.0
agent-11: 20.0
agent-12: 8.0
agent-13: 25.0
agent-14: 23.0
agent-15: 19.0
agent-16: 16.0
agent-17: 17.0
agent-18: 13.0
agent-19: 5.0
agent-20: 14.0
Sum Reward: 338.0
Avg Reward: 16.9
Min Reward: 5.0
Gini Coefficient: 0.29319526627218934
20:20 Ratio: 4.769230769230769
Max-min Ratio: 7.4
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_22-15-44
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 521.0
  episode_reward_mean: -2549.4473684210525
  episode_reward_min: -45774.0
  episodes_this_iter: 1
  episodes_total: 38
  experiment_id: 35d66058da2d4c9882f832ee91e4aa4a
  hostname: gpu011
  info:
    apply_time_ms: 2.646
    dispatch_time_ms: 8.74
    learner:
      cur_lr: 0.0013093840098008513
      grad_gnorm: 7.587856769561768
      policy_entropy: 116.05294799804688
      policy_loss: 0.6409926414489746
      var_gnorm: 18.999513626098633
      vf_explained_var: 0.0
      vf_loss: 14.828577995300293
    num_steps_sampled: 780000
    num_steps_trained: 780000
    wait_time_ms: 265.926
  iterations_since_restore: 39
  node_ip: 172.17.8.11
  num_metric_batches_dropped: 0
  pid: 25504
  policy_reward_mean: {}
  time_since_restore: 1081.3185000419617
  time_this_iter_s: 27.374966859817505
  time_total_s: 1081.3185000419617
  timestamp: 1593915344
  timesteps_since_restore: 780000
  timesteps_this_iter: 20000
  timesteps_total: 780000
  training_iteration: 39
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 29.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=25504], 1081 s, 39 iter, 780000 ts, -2.55e+03 rew

agent-1: 19.0
agent-2: 11.0
agent-3: 18.0
agent-4: 15.0
agent-5: 14.0
agent-6: -38.0
agent-7: 21.0
agent-8: 20.0
agent-9: 24.0
agent-10: 18.0
agent-11: 5.0
agent-12: 12.0
agent-13: 25.0
agent-14: 26.0
agent-15: 21.0
agent-16: 20.0
agent-17: 19.0
agent-18: 13.0
agent-19: 21.0
agent-20: 34.0
Sum Reward: 318.0
Avg Reward: 15.9
Min Reward: -38.0
Gini Coefficient: 0.36163522012578614
20:20 Ratio: -10.9
Max-min Ratio: -0.8947368421052632
agent-1: 28.0
agent-2: 7.0
agent-3: 3.0
agent-4: 21.0
agent-5: 22.0
agent-6: 14.0
agent-7: 12.0
agent-8: 20.0
agent-9: 17.0
agent-10: 13.0
agent-11: 10.0
agent-12: 21.0
agent-13: 10.0
agent-14: 18.0
agent-15: 17.0
agent-16: 33.0
agent-17: 20.0
agent-18: 13.0
agent-19: 14.0
agent-20: 6.0
Sum Reward: 319.0
Avg Reward: 15.95
Min Reward: 3.0
Gini Coefficient: 0.2493730407523511
20:20 Ratio: 4.0
Max-min Ratio: 11.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_22-16-12
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 521.0
  episode_reward_mean: -2406.05
  episode_reward_min: -45774.0
  episodes_this_iter: 2
  episodes_total: 40
  experiment_id: 35d66058da2d4c9882f832ee91e4aa4a
  hostname: gpu011
  info:
    apply_time_ms: 2.94
    dispatch_time_ms: 6.551
    learner:
      cur_lr: 0.0013080519856885076
      grad_gnorm: 40.0
      policy_entropy: 181.97032165527344
      policy_loss: -47.377357482910156
      var_gnorm: 18.997119903564453
      vf_explained_var: -1.0
      vf_loss: 6.692886829376221
    num_steps_sampled: 800000
    num_steps_trained: 800000
    wait_time_ms: 264.198
  iterations_since_restore: 40
  node_ip: 172.17.8.11
  num_metric_batches_dropped: 0
  pid: 25504
  policy_reward_mean: {}
  time_since_restore: 1109.0594203472137
  time_this_iter_s: 27.740920305252075
  time_total_s: 1109.0594203472137
  timestamp: 1593915372
  timesteps_since_restore: 800000
  timesteps_this_iter: 20000
  timesteps_total: 800000
  training_iteration: 40
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 29.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=25504], 1109 s, 40 iter, 800000 ts, -2.41e+03 rew

Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_22-16-39
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 521.0
  episode_reward_mean: -2406.05
  episode_reward_min: -45774.0
  episodes_this_iter: 0
  episodes_total: 40
  experiment_id: 35d66058da2d4c9882f832ee91e4aa4a
  hostname: gpu011
  info:
    apply_time_ms: 3.359
    dispatch_time_ms: 10.003
    learner:
      cur_lr: 0.0013067199615761638
      grad_gnorm: 8.556546211242676
      policy_entropy: 154.48394775390625
      policy_loss: -3.5864672660827637
      var_gnorm: 18.99247932434082
      vf_explained_var: 1.1920928955078125e-07
      vf_loss: 0.02434506267309189
    num_steps_sampled: 820000
    num_steps_trained: 820000
    wait_time_ms: 264.745
  iterations_since_restore: 41
  node_ip: 172.17.8.11
  num_metric_batches_dropped: 0
  pid: 25504
  policy_reward_mean: {}
  time_since_restore: 1136.2479872703552
  time_this_iter_s: 27.18856692314148
  time_total_s: 1136.2479872703552
  timestamp: 1593915399
  timesteps_since_restore: 820000
  timesteps_this_iter: 20000
  timesteps_total: 820000
  training_iteration: 41
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=25504], 1136 s, 41 iter, 820000 ts, -2.41e+03 rew

agent-1: 4.0
agent-2: 5.0
agent-3: 11.0
agent-4: 18.0
agent-5: 17.0
agent-6: 26.0
agent-7: 7.0
agent-8: 21.0
agent-9: 20.0
agent-10: 15.0
agent-11: 3.0
agent-12: 19.0
agent-13: 8.0
agent-14: 24.0
agent-15: 7.0
agent-16: 23.0
agent-17: 19.0
agent-18: 17.0
agent-19: 16.0
agent-20: 31.0
Sum Reward: 311.0
Avg Reward: 15.55
Min Reward: 3.0
Gini Coefficient: 0.2802250803858521
20:20 Ratio: 5.473684210526316
Max-min Ratio: 10.333333333333334
agent-1: 14.0
agent-2: 28.0
agent-3: 20.0
agent-4: 3.0
agent-5: 32.0
agent-6: 5.0
agent-7: 25.0
agent-8: 13.0
agent-9: 17.0
agent-10: 24.0
agent-11: 7.0
agent-12: 14.0
agent-13: 23.0
agent-14: 19.0
agent-15: 23.0
agent-16: 22.0
agent-17: 14.0
agent-18: 11.0
agent-19: 10.0
agent-20: 12.0
Sum Reward: 336.0
Avg Reward: 16.8
Min Reward: 3.0
Gini Coefficient: 0.25833333333333336
20:20 Ratio: 4.36
Max-min Ratio: 10.666666666666666
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_22-17-07
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 521.0
  episode_reward_mean: -2276.0714285714284
  episode_reward_min: -45774.0
  episodes_this_iter: 2
  episodes_total: 42
  experiment_id: 35d66058da2d4c9882f832ee91e4aa4a
  hostname: gpu011
  info:
    apply_time_ms: 2.694
    dispatch_time_ms: 7.135
    learner:
      cur_lr: 0.0013053880538791418
      grad_gnorm: 39.999996185302734
      policy_entropy: 106.27363586425781
      policy_loss: -36.347450256347656
      var_gnorm: 18.99134063720703
      vf_explained_var: -1.0
      vf_loss: 12.336395263671875
    num_steps_sampled: 840000
    num_steps_trained: 840000
    wait_time_ms: 268.713
  iterations_since_restore: 42
  node_ip: 172.17.8.11
  num_metric_batches_dropped: 0
  pid: 25504
  policy_reward_mean: {}
  time_since_restore: 1164.0808861255646
  time_this_iter_s: 27.83289885520935
  time_total_s: 1164.0808861255646
  timestamp: 1593915427
  timesteps_since_restore: 840000
  timesteps_this_iter: 20000
  timesteps_total: 840000
  training_iteration: 42
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=25504], 1164 s, 42 iter, 840000 ts, -2.28e+03 rew

Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_22-17-34
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 521.0
  episode_reward_mean: -2276.0714285714284
  episode_reward_min: -45774.0
  episodes_this_iter: 0
  episodes_total: 42
  experiment_id: 35d66058da2d4c9882f832ee91e4aa4a
  hostname: gpu011
  info:
    apply_time_ms: 2.702
    dispatch_time_ms: 8.861
    learner:
      cur_lr: 0.001304056029766798
      grad_gnorm: 13.501462936401367
      policy_entropy: 66.52062225341797
      policy_loss: -3.2136752605438232
      var_gnorm: 18.99608039855957
      vf_explained_var: 0.0
      vf_loss: 20.383506774902344
    num_steps_sampled: 860000
    num_steps_trained: 860000
    wait_time_ms: 260.572
  iterations_since_restore: 43
  node_ip: 172.17.8.11
  num_metric_batches_dropped: 0
  pid: 25504
  policy_reward_mean: {}
  time_since_restore: 1191.255933523178
  time_this_iter_s: 27.175047397613525
  time_total_s: 1191.255933523178
  timestamp: 1593915454
  timesteps_since_restore: 860000
  timesteps_this_iter: 20000
  timesteps_total: 860000
  training_iteration: 43
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=25504], 1191 s, 43 iter, 860000 ts, -2.28e+03 rew

W0704 22:17:57.924768 25498 node_manager.cc:250] Last heartbeat was sent 1195 ms ago 
W0704 22:17:58.471323 25498 node_manager.cc:250] Last heartbeat was sent 547 ms ago 
agent-1: 51.0
agent-2: 18.0
agent-3: 29.0
agent-4: 21.0
agent-5: 44.0
agent-6: 11.0
agent-7: 39.0
agent-8: 39.0
agent-9: 34.0
agent-10: 9.0
agent-11: 23.0
agent-12: 45.0
agent-13: 52.0
agent-14: 16.0
agent-15: 49.0
agent-16: 52.0
agent-17: 25.0
agent-18: 35.0
agent-19: 40.0
agent-20: 23.0
Sum Reward: 655.0
Avg Reward: 32.75
Min Reward: 9.0
Gini Coefficient: 0.23778625954198473
20:20 Ratio: 3.7777777777777777
Max-min Ratio: 5.777777777777778
agent-1: 20.0
agent-2: 12.0
agent-3: 23.0
agent-4: 27.0
agent-5: 21.0
agent-6: 12.0
agent-7: 10.0
agent-8: 7.0
agent-9: 4.0
agent-10: 10.0
agent-11: 29.0
agent-12: 24.0
agent-13: 30.0
agent-14: 10.0
agent-15: 17.0
agent-16: 20.0
agent-17: 20.0
agent-18: 24.0
agent-19: 32.0
agent-20: 14.0
Sum Reward: 366.0
Avg Reward: 18.3
Min Reward: 4.0
Gini Coefficient: 0.24754098360655738
20:20 Ratio: 3.806451612903226
Max-min Ratio: 8.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_22-18-03
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 655.0
  episode_reward_mean: -2207.906976744186
  episode_reward_min: -45774.0
  episodes_this_iter: 1
  episodes_total: 43
  experiment_id: 35d66058da2d4c9882f832ee91e4aa4a
  hostname: gpu011
  info:
    apply_time_ms: 2.822
    dispatch_time_ms: 7.905
    learner:
      cur_lr: 0.0013027240056544542
      grad_gnorm: 24.01131820678711
      policy_entropy: 84.78558349609375
      policy_loss: -2.4752492904663086
      var_gnorm: 19.000595092773438
      vf_explained_var: 1.1920928955078125e-07
      vf_loss: 3.7782278060913086
    num_steps_sampled: 880000
    num_steps_trained: 880000
    wait_time_ms: 267.587
  iterations_since_restore: 44
  node_ip: 172.17.8.11
  num_metric_batches_dropped: 0
  pid: 25504
  policy_reward_mean: {}
  time_since_restore: 1220.4095039367676
  time_this_iter_s: 29.153570413589478
  time_total_s: 1220.4095039367676
  timestamp: 1593915483
  timesteps_since_restore: 880000
  timesteps_this_iter: 20000
  timesteps_total: 880000
  training_iteration: 44
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=25504], 1220 s, 44 iter, 880000 ts, -2.21e+03 rew

Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_22-18-31
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 655.0
  episode_reward_mean: -2149.409090909091
  episode_reward_min: -45774.0
  episodes_this_iter: 1
  episodes_total: 44
  experiment_id: 35d66058da2d4c9882f832ee91e4aa4a
  hostname: gpu011
  info:
    apply_time_ms: 3.722
    dispatch_time_ms: 6.255
    learner:
      cur_lr: 0.0013013919815421104
      grad_gnorm: 35.96922302246094
      policy_entropy: 108.18391418457031
      policy_loss: -7.439177989959717
      var_gnorm: 18.99957847595215
      vf_explained_var: 0.0
      vf_loss: 5.287065505981445
    num_steps_sampled: 900000
    num_steps_trained: 900000
    wait_time_ms: 263.451
  iterations_since_restore: 45
  node_ip: 172.17.8.11
  num_metric_batches_dropped: 0
  pid: 25504
  policy_reward_mean: {}
  time_since_restore: 1246.9291269779205
  time_this_iter_s: 26.519623041152954
  time_total_s: 1246.9291269779205
  timestamp: 1593915511
  timesteps_since_restore: 900000
  timesteps_this_iter: 20000
  timesteps_total: 900000
  training_iteration: 45
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=25504], 1246 s, 45 iter, 900000 ts, -2.15e+03 rew

agent-1: 19.0
agent-2: 13.0
agent-3: 11.0
agent-4: 18.0
agent-5: 25.0
agent-6: 24.0
agent-7: 17.0
agent-8: 20.0
agent-9: 24.0
agent-10: 17.0
agent-11: 40.0
agent-12: 14.0
agent-13: 15.0
agent-14: 26.0
agent-15: 22.0
agent-16: 14.0
agent-17: 17.0
agent-18: 15.0
agent-19: 26.0
agent-20: 33.0
Sum Reward: 410.0
Avg Reward: 20.5
Min Reward: 11.0
Gini Coefficient: 0.18317073170731707
20:20 Ratio: 2.4038461538461537
Max-min Ratio: 3.6363636363636362
agent-1: 22.0
agent-2: 16.0
agent-3: 36.0
agent-4: 18.0
agent-5: 44.0
agent-6: 21.0
agent-7: 17.0
agent-8: 22.0
agent-9: 35.0
agent-10: 27.0
agent-11: 22.0
agent-12: 36.0
agent-13: 36.0
agent-14: 38.0
agent-15: 25.0
agent-16: 30.0
agent-17: 25.0
agent-18: 46.0
agent-19: 20.0
agent-20: 23.0
Sum Reward: 559.0
Avg Reward: 27.95
Min Reward: 16.0
Gini Coefficient: 0.17629695885509838
20:20 Ratio: 2.3098591549295775
Max-min Ratio: 2.875
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_22-18-59
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 655.0
  episode_reward_mean: -2034.891304347826
  episode_reward_min: -45774.0
  episodes_this_iter: 2
  episodes_total: 46
  experiment_id: 35d66058da2d4c9882f832ee91e4aa4a
  hostname: gpu011
  info:
    apply_time_ms: 2.737
    dispatch_time_ms: 7.976
    learner:
      cur_lr: 0.0013000599574297667
      grad_gnorm: 40.0
      policy_entropy: 98.00987243652344
      policy_loss: -72.9554443359375
      var_gnorm: 18.99796485900879
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 79.05619812011719
    num_steps_sampled: 920000
    num_steps_trained: 920000
    wait_time_ms: 263.618
  iterations_since_restore: 46
  node_ip: 172.17.8.11
  num_metric_batches_dropped: 0
  pid: 25504
  policy_reward_mean: {}
  time_since_restore: 1274.9473445415497
  time_this_iter_s: 28.01821756362915
  time_total_s: 1274.9473445415497
  timestamp: 1593915539
  timesteps_since_restore: 920000
  timesteps_this_iter: 20000
  timesteps_total: 920000
  training_iteration: 46
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=25504], 1274 s, 46 iter, 920000 ts, -2.03e+03 rew

Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_22-19-26
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 655.0
  episode_reward_mean: -2034.891304347826
  episode_reward_min: -45774.0
  episodes_this_iter: 0
  episodes_total: 46
  experiment_id: 35d66058da2d4c9882f832ee91e4aa4a
  hostname: gpu011
  info:
    apply_time_ms: 21.75
    dispatch_time_ms: 8.164
    learner:
      cur_lr: 0.0012987280497327447
      grad_gnorm: 39.999996185302734
      policy_entropy: 103.11674499511719
      policy_loss: -9.958550453186035
      var_gnorm: 18.99372100830078
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 1.6025183200836182
    num_steps_sampled: 940000
    num_steps_trained: 940000
    wait_time_ms: 255.981
  iterations_since_restore: 47
  node_ip: 172.17.8.11
  num_metric_batches_dropped: 0
  pid: 25504
  policy_reward_mean: {}
  time_since_restore: 1302.146250486374
  time_this_iter_s: 27.19890594482422
  time_total_s: 1302.146250486374
  timestamp: 1593915566
  timesteps_since_restore: 940000
  timesteps_this_iter: 20000
  timesteps_total: 940000
  training_iteration: 47
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=25504], 1302 s, 47 iter, 940000 ts, -2.03e+03 rew

agent-1: 5.0
agent-2: 29.0
agent-3: 10.0
agent-4: 29.0
agent-5: 23.0
agent-6: 10.0
agent-7: 39.0
agent-8: 25.0
agent-9: 6.0
agent-10: 22.0
agent-11: 30.0
agent-12: 18.0
agent-13: 16.0
agent-14: 23.0
agent-15: 19.0
agent-16: 29.0
agent-17: 28.0
agent-18: 33.0
agent-19: 25.0
agent-20: 19.0
Sum Reward: 438.0
Avg Reward: 21.9
Min Reward: 5.0
Gini Coefficient: 0.2278538812785388
20:20 Ratio: 4.225806451612903
Max-min Ratio: 7.8
agent-1: 11.0
agent-2: 39.0
agent-3: 10.0
agent-4: 21.0
agent-5: 9.0
agent-6: 21.0
agent-7: 17.0
agent-8: 18.0
agent-9: 32.0
agent-10: 26.0
agent-11: 18.0
agent-12: 16.0
agent-13: 8.0
agent-14: 25.0
agent-15: 17.0
agent-16: 31.0
agent-17: 25.0
agent-18: 14.0
agent-19: 24.0
agent-20: 22.0
Sum Reward: 404.0
Avg Reward: 20.2
Min Reward: 8.0
Gini Coefficient: 0.22004950495049505
20:20 Ratio: 3.3684210526315788
Max-min Ratio: 4.875
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_22-20-08
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 655.0
  episode_reward_mean: -1932.5625
  episode_reward_min: -45774.0
  episodes_this_iter: 2
  episodes_total: 48
  experiment_id: 35d66058da2d4c9882f832ee91e4aa4a
  hostname: gpu011
  info:
    apply_time_ms: 3.711
    dispatch_time_ms: 12.484
    learner:
      cur_lr: 0.001297396025620401
      grad_gnorm: 40.0
      policy_entropy: 118.48796844482422
      policy_loss: -18.20022201538086
      var_gnorm: 18.99231719970703
      vf_explained_var: -1.0
      vf_loss: 1.8486500978469849
    num_steps_sampled: 960000
    num_steps_trained: 960000
    wait_time_ms: 273.919
  iterations_since_restore: 48
  node_ip: 172.17.8.11
  num_metric_batches_dropped: 0
  pid: 25504
  policy_reward_mean: {}
  time_since_restore: 1343.8204686641693
  time_this_iter_s: 41.67421817779541
  time_total_s: 1343.8204686641693
  timestamp: 1593915608
  timesteps_since_restore: 960000
  timesteps_this_iter: 20000
  timesteps_total: 960000
  training_iteration: 48
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=25504], 1343 s, 48 iter, 960000 ts, -1.93e+03 rew

Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_22-20-54
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 655.0
  episode_reward_mean: -1932.5625
  episode_reward_min: -45774.0
  episodes_this_iter: 0
  episodes_total: 48
  experiment_id: 35d66058da2d4c9882f832ee91e4aa4a
  hostname: gpu011
  info:
    apply_time_ms: 3.761
    dispatch_time_ms: 15.799
    learner:
      cur_lr: 0.0012960640015080571
      grad_gnorm: 13.845414161682129
      policy_entropy: 97.07703399658203
      policy_loss: 2.3288040161132812
      var_gnorm: 18.996274948120117
      vf_explained_var: 0.0
      vf_loss: 9.925063133239746
    num_steps_sampled: 980000
    num_steps_trained: 980000
    wait_time_ms: 268.45
  iterations_since_restore: 49
  node_ip: 172.17.8.11
  num_metric_batches_dropped: 0
  pid: 25504
  policy_reward_mean: {}
  time_since_restore: 1389.466213464737
  time_this_iter_s: 45.64574480056763
  time_total_s: 1389.466213464737
  timestamp: 1593915654
  timesteps_since_restore: 980000
  timesteps_this_iter: 20000
  timesteps_total: 980000
  training_iteration: 49
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=25504], 1389 s, 49 iter, 980000 ts, -1.93e+03 rew

agent-1: 25.0
agent-2: 9.0
agent-3: 27.0
agent-4: 10.0
agent-5: 22.0
agent-6: 17.0
agent-7: 25.0
agent-8: 16.0
agent-9: 8.0
agent-10: 9.0
agent-11: 24.0
agent-12: 17.0
agent-13: 8.0
agent-14: 7.0
agent-15: 19.0
agent-16: 7.0
agent-17: 13.0
agent-18: 19.0
agent-19: 11.0
agent-20: 20.0
Sum Reward: 313.0
Avg Reward: 15.65
Min Reward: 7.0
Gini Coefficient: 0.24073482428115017
20:20 Ratio: 3.3666666666666667
Max-min Ratio: 3.857142857142857
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_22-21-23
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 655.0
  episode_reward_mean: -1886.734693877551
  episode_reward_min: -45774.0
  episodes_this_iter: 1
  episodes_total: 49
  experiment_id: 35d66058da2d4c9882f832ee91e4aa4a
  hostname: gpu011
  info:
    apply_time_ms: 2.782
    dispatch_time_ms: 15.22
    learner:
      cur_lr: 0.0012947319773957133
      grad_gnorm: 8.119421005249023
      policy_entropy: 118.08719635009766
      policy_loss: -0.8264725208282471
      var_gnorm: 18.988285064697266
      vf_explained_var: 0.0
      vf_loss: 0.023413263261318207
    num_steps_sampled: 1000000
    num_steps_trained: 1000000
    wait_time_ms: 287.155
  iterations_since_restore: 50
  node_ip: 172.17.8.11
  num_metric_batches_dropped: 0
  pid: 25504
  policy_reward_mean: {}
  time_since_restore: 1418.515071630478
  time_this_iter_s: 29.048858165740967
  time_total_s: 1418.515071630478
  timestamp: 1593915683
  timesteps_since_restore: 1000000
  timesteps_this_iter: 20000
  timesteps_total: 1000000
  training_iteration: 50
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=25504], 1418 s, 50 iter, 1000000 ts, -1.89e+03 rew

agent-1: 34.0
agent-2: 22.0
agent-3: 31.0
agent-4: 36.0
agent-5: 9.0
agent-6: 18.0
agent-7: 30.0
agent-8: 14.0
agent-9: 12.0
agent-10: 17.0
agent-11: 25.0
agent-12: 46.0
agent-13: 30.0
agent-14: 9.0
agent-15: 17.0
agent-16: 38.0
agent-17: 12.0
agent-18: 20.0
agent-19: 24.0
agent-20: 25.0
Sum Reward: 469.0
Avg Reward: 23.45
Min Reward: 9.0
Gini Coefficient: 0.24402985074626865
20:20 Ratio: 3.6666666666666665
Max-min Ratio: 5.111111111111111
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_22-21-51
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 655.0
  episode_reward_mean: -1839.62
  episode_reward_min: -45774.0
  episodes_this_iter: 1
  episodes_total: 50
  experiment_id: 35d66058da2d4c9882f832ee91e4aa4a
  hostname: gpu011
  info:
    apply_time_ms: 3.711
    dispatch_time_ms: 34.141
    learner:
      cur_lr: 0.0012933999532833695
      grad_gnorm: 21.901975631713867
      policy_entropy: 117.14247131347656
      policy_loss: -5.883855819702148
      var_gnorm: 18.994029998779297
      vf_explained_var: 0.0
      vf_loss: 18.45159912109375
    num_steps_sampled: 1020000
    num_steps_trained: 1020000
    wait_time_ms: 255.996
  iterations_since_restore: 51
  node_ip: 172.17.8.11
  num_metric_batches_dropped: 0
  pid: 25504
  policy_reward_mean: {}
  time_since_restore: 1446.5474226474762
  time_this_iter_s: 28.03235101699829
  time_total_s: 1446.5474226474762
  timestamp: 1593915711
  timesteps_since_restore: 1020000
  timesteps_this_iter: 20000
  timesteps_total: 1020000
  training_iteration: 51
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=25504], 1446 s, 51 iter, 1020000 ts, -1.84e+03 rew

agent-1: 12.0
agent-2: 25.0
agent-3: 28.0
agent-4: 21.0
agent-5: 20.0
agent-6: 31.0
agent-7: 19.0
agent-8: 12.0
agent-9: 22.0
agent-10: 20.0
agent-11: 24.0
agent-12: 24.0
agent-13: 27.0
agent-14: 24.0
agent-15: 26.0
agent-16: 19.0
agent-17: 15.0
agent-18: 22.0
agent-19: 20.0
agent-20: 18.0
Sum Reward: 429.0
Avg Reward: 21.45
Min Reward: 12.0
Gini Coefficient: 0.12622377622377623
20:20 Ratio: 1.9649122807017543
Max-min Ratio: 2.5833333333333335
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_22-22-20
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 655.0
  episode_reward_mean: -1795.137254901961
  episode_reward_min: -45774.0
  episodes_this_iter: 1
  episodes_total: 51
  experiment_id: 35d66058da2d4c9882f832ee91e4aa4a
  hostname: gpu011
  info:
    apply_time_ms: 2.961
    dispatch_time_ms: 25.54
    learner:
      cur_lr: 0.0012920680455863476
      grad_gnorm: 40.000003814697266
      policy_entropy: 99.30814361572266
      policy_loss: 30.681180953979492
      var_gnorm: 18.990385055541992
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 91.17129516601562
    num_steps_sampled: 1040000
    num_steps_trained: 1040000
    wait_time_ms: 246.865
  iterations_since_restore: 52
  node_ip: 172.17.8.11
  num_metric_batches_dropped: 0
  pid: 25504
  policy_reward_mean: {}
  time_since_restore: 1475.383530139923
  time_this_iter_s: 28.8361074924469
  time_total_s: 1475.383530139923
  timestamp: 1593915740
  timesteps_since_restore: 1040000
  timesteps_this_iter: 20000
  timesteps_total: 1040000
  training_iteration: 52
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=25504], 1475 s, 52 iter, 1040000 ts, -1.8e+03 rew

agent-1: 29.0
agent-2: 16.0
agent-3: 16.0
agent-4: 29.0
agent-5: 23.0
agent-6: 19.0
agent-7: 15.0
agent-8: 15.0
agent-9: 26.0
agent-10: 8.0
agent-11: 10.0
agent-12: 25.0
agent-13: 19.0
agent-14: 15.0
agent-15: 3.0
agent-16: 21.0
agent-17: 30.0
agent-18: 12.0
agent-19: 21.0
agent-20: 13.0
Sum Reward: 365.0
Avg Reward: 18.25
Min Reward: 3.0
Gini Coefficient: 0.2226027397260274
20:20 Ratio: 3.4545454545454546
Max-min Ratio: 10.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_22-22-48
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 655.0
  episode_reward_mean: -1753.5961538461538
  episode_reward_min: -45774.0
  episodes_this_iter: 1
  episodes_total: 52
  experiment_id: 35d66058da2d4c9882f832ee91e4aa4a
  hostname: gpu011
  info:
    apply_time_ms: 4.534
    dispatch_time_ms: 32.552
    learner:
      cur_lr: 0.0012907360214740038
      grad_gnorm: 28.203224182128906
      policy_entropy: 165.86709594726562
      policy_loss: 1.6644554138183594
      var_gnorm: 18.996173858642578
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 29.38360595703125
    num_steps_sampled: 1060000
    num_steps_trained: 1060000
    wait_time_ms: 236.777
  iterations_since_restore: 53
  node_ip: 172.17.8.11
  num_metric_batches_dropped: 0
  pid: 25504
  policy_reward_mean: {}
  time_since_restore: 1503.3485929965973
  time_this_iter_s: 27.965062856674194
  time_total_s: 1503.3485929965973
  timestamp: 1593915768
  timesteps_since_restore: 1060000
  timesteps_this_iter: 20000
  timesteps_total: 1060000
  training_iteration: 53
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=25504], 1503 s, 53 iter, 1060000 ts, -1.75e+03 rew

agent-1: 17.0
agent-2: 21.0
agent-3: 18.0
agent-4: 10.0
agent-5: 19.0
agent-6: 17.0
agent-7: 17.0
agent-8: 46.0
agent-9: 11.0
agent-10: 21.0
agent-11: 9.0
agent-12: 28.0
agent-13: 38.0
agent-14: 29.0
agent-15: 13.0
agent-16: 37.0
agent-17: 24.0
agent-18: 38.0
agent-19: 41.0
agent-20: 24.0
Sum Reward: 478.0
Avg Reward: 23.9
Min Reward: 9.0
Gini Coefficient: 0.252092050209205
20:20 Ratio: 3.7906976744186047
Max-min Ratio: 5.111111111111111
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_22-23-16
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 655.0
  episode_reward_mean: -1711.4905660377358
  episode_reward_min: -45774.0
  episodes_this_iter: 1
  episodes_total: 53
  experiment_id: 35d66058da2d4c9882f832ee91e4aa4a
  hostname: gpu011
  info:
    apply_time_ms: 2.606
    dispatch_time_ms: 15.857
    learner:
      cur_lr: 0.00128940399736166
      grad_gnorm: 39.999996185302734
      policy_entropy: 182.30616760253906
      policy_loss: 83.64458465576172
      var_gnorm: 18.99446678161621
      vf_explained_var: 5.960464477539063e-08
      vf_loss: 95.86700439453125
    num_steps_sampled: 1080000
    num_steps_trained: 1080000
    wait_time_ms: 266.556
  iterations_since_restore: 54
  node_ip: 172.17.8.11
  num_metric_batches_dropped: 0
  pid: 25504
  policy_reward_mean: {}
  time_since_restore: 1532.1025958061218
  time_this_iter_s: 28.754002809524536
  time_total_s: 1532.1025958061218
  timestamp: 1593915796
  timesteps_since_restore: 1080000
  timesteps_this_iter: 20000
  timesteps_total: 1080000
  training_iteration: 54
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=25504], 1532 s, 54 iter, 1080000 ts, -1.71e+03 rew

agent-1: 19.0
agent-2: 14.0
agent-3: 10.0
agent-4: 10.0
agent-5: 14.0
agent-6: 19.0
agent-7: 26.0
agent-8: 18.0
agent-9: 24.0
agent-10: 22.0
agent-11: 25.0
agent-12: 15.0
agent-13: 23.0
agent-14: 36.0
agent-15: 20.0
agent-16: 24.0
agent-17: 17.0
agent-18: 22.0
agent-19: 21.0
agent-20: 21.0
Sum Reward: 400.0
Avg Reward: 20.0
Min Reward: 10.0
Gini Coefficient: 0.158
20:20 Ratio: 2.3125
Max-min Ratio: 3.6
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_22-23-45
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 655.0
  episode_reward_mean: -1672.388888888889
  episode_reward_min: -45774.0
  episodes_this_iter: 1
  episodes_total: 54
  experiment_id: 35d66058da2d4c9882f832ee91e4aa4a
  hostname: gpu011
  info:
    apply_time_ms: 5.494
    dispatch_time_ms: 29.277
    learner:
      cur_lr: 0.0012880719732493162
      grad_gnorm: 18.74673080444336
      policy_entropy: 190.34121704101562
      policy_loss: -10.257898330688477
      var_gnorm: 19.01157569885254
      vf_explained_var: 0.0
      vf_loss: 0.12386571615934372
    num_steps_sampled: 1100000
    num_steps_trained: 1100000
    wait_time_ms: 262.522
  iterations_since_restore: 55
  node_ip: 172.17.8.11
  num_metric_batches_dropped: 0
  pid: 25504
  policy_reward_mean: {}
  time_since_restore: 1560.639890909195
  time_this_iter_s: 28.53729510307312
  time_total_s: 1560.639890909195
  timestamp: 1593915825
  timesteps_since_restore: 1100000
  timesteps_this_iter: 20000
  timesteps_total: 1100000
  training_iteration: 55
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=25504], 1560 s, 55 iter, 1100000 ts, -1.67e+03 rew

agent-1: 27.0
agent-2: 14.0
agent-3: 15.0
agent-4: 7.0
agent-5: 9.0
agent-6: 8.0
agent-7: 16.0
agent-8: 6.0
agent-9: 9.0
agent-10: 13.0
agent-11: 20.0
agent-12: 9.0
agent-13: 2.0
agent-14: 13.0
agent-15: 12.0
agent-16: 21.0
agent-17: 21.0
agent-18: 27.0
agent-19: 22.0
agent-20: 12.0
Sum Reward: 283.0
Avg Reward: 14.15
Min Reward: 2.0
Gini Coefficient: 0.2697879858657244
20:20 Ratio: 4.217391304347826
Max-min Ratio: 13.5
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_22-24-14
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 655.0
  episode_reward_mean: -1636.8363636363636
  episode_reward_min: -45774.0
  episodes_this_iter: 1
  episodes_total: 55
  experiment_id: 35d66058da2d4c9882f832ee91e4aa4a
  hostname: gpu011
  info:
    apply_time_ms: 3.413
    dispatch_time_ms: 25.643
    learner:
      cur_lr: 0.0012867399491369724
      grad_gnorm: 4.547404766082764
      policy_entropy: 191.708740234375
      policy_loss: 2.013939619064331
      var_gnorm: 19.0109920501709
      vf_explained_var: 5.960464477539063e-08
      vf_loss: 0.007107418961822987
    num_steps_sampled: 1120000
    num_steps_trained: 1120000
    wait_time_ms: 242.15
  iterations_since_restore: 56
  node_ip: 172.17.8.11
  num_metric_batches_dropped: 0
  pid: 25504
  policy_reward_mean: {}
  time_since_restore: 1589.3719007968903
  time_this_iter_s: 28.732009887695312
  time_total_s: 1589.3719007968903
  timestamp: 1593915854
  timesteps_since_restore: 1120000
  timesteps_this_iter: 20000
  timesteps_total: 1120000
  training_iteration: 56
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=25504], 1589 s, 56 iter, 1120000 ts, -1.64e+03 rew

agent-1: 19.0
agent-2: 23.0
agent-3: 11.0
agent-4: 8.0
agent-5: 13.0
agent-6: 11.0
agent-7: 16.0
agent-8: 19.0
agent-9: 10.0
agent-10: 11.0
agent-11: 15.0
agent-12: 15.0
agent-13: 19.0
agent-14: 14.0
agent-15: 15.0
agent-16: 6.0
agent-17: 11.0
agent-18: 15.0
agent-19: 3.0
agent-20: 6.0
Sum Reward: 260.0
Avg Reward: 13.0
Min Reward: 3.0
Gini Coefficient: 0.21192307692307694
20:20 Ratio: 3.4782608695652173
Max-min Ratio: 7.666666666666667
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_22-24-42
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 655.0
  episode_reward_mean: -1602.9642857142858
  episode_reward_min: -45774.0
  episodes_this_iter: 1
  episodes_total: 56
  experiment_id: 35d66058da2d4c9882f832ee91e4aa4a
  hostname: gpu011
  info:
    apply_time_ms: 3.799
    dispatch_time_ms: 16.972
    learner:
      cur_lr: 0.0012854080414399505
      grad_gnorm: 38.723350524902344
      policy_entropy: 159.49656677246094
      policy_loss: -13.368318557739258
      var_gnorm: 19.00969696044922
      vf_explained_var: 2.384185791015625e-07
      vf_loss: 0.5250996947288513
    num_steps_sampled: 1140000
    num_steps_trained: 1140000
    wait_time_ms: 269.966
  iterations_since_restore: 57
  node_ip: 172.17.8.11
  num_metric_batches_dropped: 0
  pid: 25504
  policy_reward_mean: {}
  time_since_restore: 1617.6979222297668
  time_this_iter_s: 28.326021432876587
  time_total_s: 1617.6979222297668
  timestamp: 1593915882
  timesteps_since_restore: 1140000
  timesteps_this_iter: 20000
  timesteps_total: 1140000
  training_iteration: 57
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=25504], 1617 s, 57 iter, 1140000 ts, -1.6e+03 rew

agent-1: 7.0
agent-2: 17.0
agent-3: 9.0
agent-4: 14.0
agent-5: 8.0
agent-6: 8.0
agent-7: 22.0
agent-8: 15.0
agent-9: 19.0
agent-10: 12.0
agent-11: 19.0
agent-12: 32.0
agent-13: 18.0
agent-14: 21.0
agent-15: 11.0
agent-16: 1.0
agent-17: 13.0
agent-18: 29.0
agent-19: 26.0
agent-20: 7.0
Sum Reward: 308.0
Avg Reward: 15.4
Min Reward: 1.0
Gini Coefficient: 0.28603896103896104
20:20 Ratio: 4.739130434782608
Max-min Ratio: 32.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_22-25-11
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 655.0
  episode_reward_mean: -1569.438596491228
  episode_reward_min: -45774.0
  episodes_this_iter: 1
  episodes_total: 57
  experiment_id: 35d66058da2d4c9882f832ee91e4aa4a
  hostname: gpu011
  info:
    apply_time_ms: 2.716
    dispatch_time_ms: 30.485
    learner:
      cur_lr: 0.0012840760173276067
      grad_gnorm: 19.58283805847168
      policy_entropy: 175.9413299560547
      policy_loss: 6.2978386878967285
      var_gnorm: 19.010284423828125
      vf_explained_var: 0.0
      vf_loss: 8.01109504699707
    num_steps_sampled: 1160000
    num_steps_trained: 1160000
    wait_time_ms: 263.11
  iterations_since_restore: 58
  node_ip: 172.17.8.11
  num_metric_batches_dropped: 0
  pid: 25504
  policy_reward_mean: {}
  time_since_restore: 1646.7100114822388
  time_this_iter_s: 29.012089252471924
  time_total_s: 1646.7100114822388
  timestamp: 1593915911
  timesteps_since_restore: 1160000
  timesteps_this_iter: 20000
  timesteps_total: 1160000
  training_iteration: 58
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=25504], 1646 s, 58 iter, 1160000 ts, -1.57e+03 rew

agent-1: 7.0
agent-2: 14.0
agent-3: 23.0
agent-4: 25.0
agent-5: 10.0
agent-6: 22.0
agent-7: 16.0
agent-8: 12.0
agent-9: 18.0
agent-10: 26.0
agent-11: 10.0
agent-12: 12.0
agent-13: 41.0
agent-14: 12.0
agent-15: 25.0
agent-16: 13.0
agent-17: 18.0
agent-18: 22.0
agent-19: 15.0
agent-20: 21.0
Sum Reward: 362.0
Avg Reward: 18.1
Min Reward: 7.0
Gini Coefficient: 0.225414364640884
20:20 Ratio: 3.0
Max-min Ratio: 5.857142857142857
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_22-25-40
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 655.0
  episode_reward_mean: -1536.1379310344828
  episode_reward_min: -45774.0
  episodes_this_iter: 1
  episodes_total: 58
  experiment_id: 35d66058da2d4c9882f832ee91e4aa4a
  hostname: gpu011
  info:
    apply_time_ms: 3.588
    dispatch_time_ms: 13.216
    learner:
      cur_lr: 0.0012827439932152629
      grad_gnorm: 14.32636547088623
      policy_entropy: 88.75867462158203
      policy_loss: -4.9747819900512695
      var_gnorm: 19.016132354736328
      vf_explained_var: 5.960464477539063e-08
      vf_loss: 4.728277206420898
    num_steps_sampled: 1180000
    num_steps_trained: 1180000
    wait_time_ms: 274.24
  iterations_since_restore: 59
  node_ip: 172.17.8.11
  num_metric_batches_dropped: 0
  pid: 25504
  policy_reward_mean: {}
  time_since_restore: 1675.2855591773987
  time_this_iter_s: 28.575547695159912
  time_total_s: 1675.2855591773987
  timestamp: 1593915940
  timesteps_since_restore: 1180000
  timesteps_this_iter: 20000
  timesteps_total: 1180000
  training_iteration: 59
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=25504], 1675 s, 59 iter, 1180000 ts, -1.54e+03 rew

agent-1: 34.0
agent-2: 13.0
agent-3: 19.0
agent-4: 36.0
agent-5: 20.0
agent-6: 8.0
agent-7: 11.0
agent-8: 22.0
agent-9: 17.0
agent-10: 16.0
agent-11: 3.0
agent-12: 26.0
agent-13: 10.0
agent-14: 7.0
agent-15: 25.0
agent-16: 23.0
agent-17: 5.0
agent-18: 11.0
agent-19: 16.0
agent-20: 4.0
Sum Reward: 326.0
Avg Reward: 16.3
Min Reward: 3.0
Gini Coefficient: 0.31809815950920245
20:20 Ratio: 6.368421052631579
Max-min Ratio: 12.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_22-26-09
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 655.0
  episode_reward_mean: -1504.5762711864406
  episode_reward_min: -45774.0
  episodes_this_iter: 1
  episodes_total: 59
  experiment_id: 35d66058da2d4c9882f832ee91e4aa4a
  hostname: gpu011
  info:
    apply_time_ms: 3.98
    dispatch_time_ms: 36.264
    learner:
      cur_lr: 0.001281411969102919
      grad_gnorm: 40.0
      policy_entropy: 128.76820373535156
      policy_loss: 23.16817855834961
      var_gnorm: 19.01599884033203
      vf_explained_var: 0.0
      vf_loss: 27.158382415771484
    num_steps_sampled: 1200000
    num_steps_trained: 1200000
    wait_time_ms: 236.295
  iterations_since_restore: 60
  node_ip: 172.17.8.11
  num_metric_batches_dropped: 0
  pid: 25504
  policy_reward_mean: {}
  time_since_restore: 1704.1072301864624
  time_this_iter_s: 28.82167100906372
  time_total_s: 1704.1072301864624
  timestamp: 1593915969
  timesteps_since_restore: 1200000
  timesteps_this_iter: 20000
  timesteps_total: 1200000
  training_iteration: 60
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=25504], 1704 s, 60 iter, 1200000 ts, -1.5e+03 rew

agent-1: 30.0
agent-2: 10.0
agent-3: 21.0
agent-4: 14.0
agent-5: 10.0
agent-6: 27.0
agent-7: 10.0
agent-8: 20.0
agent-9: 30.0
agent-10: 13.0
agent-11: 8.0
agent-12: 16.0
agent-13: 22.0
agent-14: 9.0
agent-15: 23.0
agent-16: 21.0
agent-17: 18.0
agent-18: 15.0
agent-19: 39.0
agent-20: 15.0
Sum Reward: 371.0
Avg Reward: 18.55
Min Reward: 8.0
Gini Coefficient: 0.2408355795148248
20:20 Ratio: 3.4054054054054053
Max-min Ratio: 4.875
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_22-26-37
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 655.0
  episode_reward_mean: -1473.3166666666666
  episode_reward_min: -45774.0
  episodes_this_iter: 1
  episodes_total: 60
  experiment_id: 35d66058da2d4c9882f832ee91e4aa4a
  hostname: gpu011
  info:
    apply_time_ms: 3.534
    dispatch_time_ms: 68.74
    learner:
      cur_lr: 0.0012800799449905753
      grad_gnorm: 39.999996185302734
      policy_entropy: 202.01341247558594
      policy_loss: -1.4092888832092285
      var_gnorm: 19.023765563964844
      vf_explained_var: 0.0
      vf_loss: 10.706977844238281
    num_steps_sampled: 1220000
    num_steps_trained: 1220000
    wait_time_ms: 218.82
  iterations_since_restore: 61
  node_ip: 172.17.8.11
  num_metric_batches_dropped: 0
  pid: 25504
  policy_reward_mean: {}
  time_since_restore: 1732.1704561710358
  time_this_iter_s: 28.063225984573364
  time_total_s: 1732.1704561710358
  timestamp: 1593915997
  timesteps_since_restore: 1220000
  timesteps_this_iter: 20000
  timesteps_total: 1220000
  training_iteration: 61
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=25504], 1732 s, 61 iter, 1220000 ts, -1.47e+03 rew

agent-1: 16.0
agent-2: 11.0
agent-3: 46.0
agent-4: 18.0
agent-5: 10.0
agent-6: 8.0
agent-7: 28.0
agent-8: 24.0
agent-9: 7.0
agent-10: 34.0
agent-11: 3.0
agent-12: 12.0
agent-13: 16.0
agent-14: 25.0
agent-15: 19.0
agent-16: 6.0
agent-17: 18.0
agent-18: 22.0
agent-19: 16.0
agent-20: 8.0
Sum Reward: 347.0
Avg Reward: 17.35
Min Reward: 3.0
Gini Coefficient: 0.3177233429394813
20:20 Ratio: 5.541666666666667
Max-min Ratio: 15.333333333333334
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_22-27-06
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 655.0
  episode_reward_mean: -1443.4754098360656
  episode_reward_min: -45774.0
  episodes_this_iter: 1
  episodes_total: 61
  experiment_id: 35d66058da2d4c9882f832ee91e4aa4a
  hostname: gpu011
  info:
    apply_time_ms: 3.789
    dispatch_time_ms: 31.811
    learner:
      cur_lr: 0.0012787480372935534
      grad_gnorm: 40.000003814697266
      policy_entropy: 193.3589630126953
      policy_loss: 78.14364624023438
      var_gnorm: 19.024864196777344
      vf_explained_var: 0.0
      vf_loss: 62.093021392822266
    num_steps_sampled: 1240000
    num_steps_trained: 1240000
    wait_time_ms: 238.72
  iterations_since_restore: 62
  node_ip: 172.17.8.11
  num_metric_batches_dropped: 0
  pid: 25504
  policy_reward_mean: {}
  time_since_restore: 1761.0133776664734
  time_this_iter_s: 28.842921495437622
  time_total_s: 1761.0133776664734
  timestamp: 1593916026
  timesteps_since_restore: 1240000
  timesteps_this_iter: 20000
  timesteps_total: 1240000
  training_iteration: 62
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=25504], 1761 s, 62 iter, 1240000 ts, -1.44e+03 rew

agent-1: 10.0
agent-2: 19.0
agent-3: 17.0
agent-4: 23.0
agent-5: 10.0
agent-6: 19.0
agent-7: 17.0
agent-8: 14.0
agent-9: 27.0
agent-10: 21.0
agent-11: 20.0
agent-12: 12.0
agent-13: 23.0
agent-14: 35.0
agent-15: 4.0
agent-16: 15.0
agent-17: 6.0
agent-18: 17.0
agent-19: 18.0
agent-20: 20.0
Sum Reward: 347.0
Avg Reward: 17.35
Min Reward: 4.0
Gini Coefficient: 0.21829971181556196
20:20 Ratio: 3.6
Max-min Ratio: 8.75
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_22-27-35
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 655.0
  episode_reward_mean: -1414.5967741935483
  episode_reward_min: -45774.0
  episodes_this_iter: 1
  episodes_total: 62
  experiment_id: 35d66058da2d4c9882f832ee91e4aa4a
  hostname: gpu011
  info:
    apply_time_ms: 3.672
    dispatch_time_ms: 18.607
    learner:
      cur_lr: 0.0012774160131812096
      grad_gnorm: 19.89579200744629
      policy_entropy: 179.73019409179688
      policy_loss: -9.404959678649902
      var_gnorm: 19.02811622619629
      vf_explained_var: 0.0
      vf_loss: 0.13981640338897705
    num_steps_sampled: 1260000
    num_steps_trained: 1260000
    wait_time_ms: 279.635
  iterations_since_restore: 63
  node_ip: 172.17.8.11
  num_metric_batches_dropped: 0
  pid: 25504
  policy_reward_mean: {}
  time_since_restore: 1789.5097749233246
  time_this_iter_s: 28.496397256851196
  time_total_s: 1789.5097749233246
  timestamp: 1593916055
  timesteps_since_restore: 1260000
  timesteps_this_iter: 20000
  timesteps_total: 1260000
  training_iteration: 63
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=25504], 1789 s, 63 iter, 1260000 ts, -1.41e+03 rew

agent-1: 8.0
agent-2: 13.0
agent-3: 14.0
agent-4: 17.0
agent-5: 12.0
agent-6: 5.0
agent-7: 11.0
agent-8: 26.0
agent-9: 16.0
agent-10: 21.0
agent-11: 10.0
agent-12: 13.0
agent-13: 20.0
agent-14: 17.0
agent-15: 2.0
agent-16: 13.0
agent-17: 13.0
agent-18: 11.0
agent-19: 10.0
agent-20: 3.0
Sum Reward: 255.0
Avg Reward: 12.75
Min Reward: 2.0
Gini Coefficient: 0.2488235294117647
20:20 Ratio: 4.666666666666667
Max-min Ratio: 13.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_22-28-04
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 655.0
  episode_reward_mean: -1388.095238095238
  episode_reward_min: -45774.0
  episodes_this_iter: 1
  episodes_total: 63
  experiment_id: 35d66058da2d4c9882f832ee91e4aa4a
  hostname: gpu011
  info:
    apply_time_ms: 2.631
    dispatch_time_ms: 58.704
    learner:
      cur_lr: 0.0012760839890688658
      grad_gnorm: 40.0
      policy_entropy: 176.0673370361328
      policy_loss: 32.88081741333008
      var_gnorm: 19.02791976928711
      vf_explained_var: 0.0
      vf_loss: 34.7604866027832
    num_steps_sampled: 1280000
    num_steps_trained: 1280000
    wait_time_ms: 213.325
  iterations_since_restore: 64
  node_ip: 172.17.8.11
  num_metric_batches_dropped: 0
  pid: 25504
  policy_reward_mean: {}
  time_since_restore: 1818.3086140155792
  time_this_iter_s: 28.79883909225464
  time_total_s: 1818.3086140155792
  timestamp: 1593916084
  timesteps_since_restore: 1280000
  timesteps_this_iter: 20000
  timesteps_total: 1280000
  training_iteration: 64
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=25504], 1818 s, 64 iter, 1280000 ts, -1.39e+03 rew

agent-1: 18.0
agent-2: 26.0
agent-3: 8.0
agent-4: 6.0
agent-5: 10.0
agent-6: 20.0
agent-7: 15.0
agent-8: 17.0
agent-9: 50.0
agent-10: 24.0
agent-11: 15.0
agent-12: 12.0
agent-13: 11.0
agent-14: 28.0
agent-15: 34.0
agent-16: 18.0
agent-17: 12.0
agent-18: 11.0
agent-19: 18.0
agent-20: 2.0
Sum Reward: 355.0
Avg Reward: 17.75
Min Reward: 2.0
Gini Coefficient: 0.31028169014084506
20:20 Ratio: 5.3076923076923075
Max-min Ratio: 25.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_22-28-32
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 655.0
  episode_reward_mean: -1360.859375
  episode_reward_min: -45774.0
  episodes_this_iter: 1
  episodes_total: 64
  experiment_id: 35d66058da2d4c9882f832ee91e4aa4a
  hostname: gpu011
  info:
    apply_time_ms: 2.933
    dispatch_time_ms: 14.616
    learner:
      cur_lr: 0.001274751964956522
      grad_gnorm: 25.28360366821289
      policy_entropy: 179.93199157714844
      policy_loss: -11.741329193115234
      var_gnorm: 19.03025245666504
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 0.21172210574150085
    num_steps_sampled: 1300000
    num_steps_trained: 1300000
    wait_time_ms: 265.474
  iterations_since_restore: 65
  node_ip: 172.17.8.11
  num_metric_batches_dropped: 0
  pid: 25504
  policy_reward_mean: {}
  time_since_restore: 1846.6636123657227
  time_this_iter_s: 28.354998350143433
  time_total_s: 1846.6636123657227
  timestamp: 1593916112
  timesteps_since_restore: 1300000
  timesteps_this_iter: 20000
  timesteps_total: 1300000
  training_iteration: 65
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=25504], 1846 s, 65 iter, 1300000 ts, -1.36e+03 rew

agent-1: 26.0
agent-2: 19.0
agent-3: 28.0
agent-4: 14.0
agent-5: 13.0
agent-6: 5.0
agent-7: 28.0
agent-8: 13.0
agent-9: 23.0
agent-10: 15.0
agent-11: 18.0
agent-12: 16.0
agent-13: 4.0
agent-14: 22.0
agent-15: 11.0
agent-16: 19.0
agent-17: 17.0
agent-18: 19.0
agent-19: 15.0
agent-20: 16.0
Sum Reward: 341.0
Avg Reward: 17.05
Min Reward: 4.0
Gini Coefficient: 0.20542521994134896
20:20 Ratio: 3.1818181818181817
Max-min Ratio: 7.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_22-29-01
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 655.0
  episode_reward_mean: -1334.676923076923
  episode_reward_min: -45774.0
  episodes_this_iter: 1
  episodes_total: 65
  experiment_id: 35d66058da2d4c9882f832ee91e4aa4a
  hostname: gpu011
  info:
    apply_time_ms: 3.004
    dispatch_time_ms: 39.278
    learner:
      cur_lr: 0.0012734200572595
      grad_gnorm: 5.689884185791016
      policy_entropy: 174.0546875
      policy_loss: 3.121339797973633
      var_gnorm: 19.028039932250977
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 0.0115132424980402
    num_steps_sampled: 1320000
    num_steps_trained: 1320000
    wait_time_ms: 213.249
  iterations_since_restore: 66
  node_ip: 172.17.8.11
  num_metric_batches_dropped: 0
  pid: 25504
  policy_reward_mean: {}
  time_since_restore: 1875.6958513259888
  time_this_iter_s: 29.032238960266113
  time_total_s: 1875.6958513259888
  timestamp: 1593916141
  timesteps_since_restore: 1320000
  timesteps_this_iter: 20000
  timesteps_total: 1320000
  training_iteration: 66
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=25504], 1875 s, 66 iter, 1320000 ts, -1.33e+03 rew

agent-1: 14.0
agent-2: 19.0
agent-3: 26.0
agent-4: 11.0
agent-5: 17.0
agent-6: 17.0
agent-7: 16.0
agent-8: 17.0
agent-9: 10.0
agent-10: 9.0
agent-11: 11.0
agent-12: 7.0
agent-13: 14.0
agent-14: 10.0
agent-15: 3.0
agent-16: 17.0
agent-17: 20.0
agent-18: 14.0
agent-19: 12.0
agent-20: 11.0
Sum Reward: 275.0
Avg Reward: 13.75
Min Reward: 3.0
Gini Coefficient: 0.20054545454545455
20:20 Ratio: 2.8275862068965516
Max-min Ratio: 8.666666666666666
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_22-29-30
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 655.0
  episode_reward_mean: -1310.2878787878788
  episode_reward_min: -45774.0
  episodes_this_iter: 1
  episodes_total: 66
  experiment_id: 35d66058da2d4c9882f832ee91e4aa4a
  hostname: gpu011
  info:
    apply_time_ms: 3.404
    dispatch_time_ms: 27.364
    learner:
      cur_lr: 0.0012720880331471562
      grad_gnorm: 17.533206939697266
      policy_entropy: 180.59603881835938
      policy_loss: -17.854862213134766
      var_gnorm: 19.029680252075195
      vf_explained_var: -2.384185791015625e-07
      vf_loss: 0.08138413727283478
    num_steps_sampled: 1340000
    num_steps_trained: 1340000
    wait_time_ms: 267.944
  iterations_since_restore: 67
  node_ip: 172.17.8.11
  num_metric_batches_dropped: 0
  pid: 25504
  policy_reward_mean: {}
  time_since_restore: 1904.185712814331
  time_this_iter_s: 28.489861488342285
  time_total_s: 1904.185712814331
  timestamp: 1593916170
  timesteps_since_restore: 1340000
  timesteps_this_iter: 20000
  timesteps_total: 1340000
  training_iteration: 67
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=25504], 1904 s, 67 iter, 1340000 ts, -1.31e+03 rew

agent-1: 7.0
agent-2: 33.0
agent-3: 11.0
agent-4: 28.0
agent-5: 43.0
agent-6: 12.0
agent-7: 4.0
agent-8: 16.0
agent-9: 2.0
agent-10: 13.0
agent-11: 8.0
agent-12: 22.0
agent-13: 1.0
agent-14: 20.0
agent-15: 27.0
agent-16: 12.0
agent-17: 22.0
agent-18: 21.0
agent-19: 17.0
agent-20: 32.0
Sum Reward: 351.0
Avg Reward: 17.55
Min Reward: 1.0
Gini Coefficient: 0.35085470085470083
20:20 Ratio: 9.714285714285714
Max-min Ratio: 43.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_22-29-58
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 655.0
  episode_reward_mean: -1285.4925373134329
  episode_reward_min: -45774.0
  episodes_this_iter: 1
  episodes_total: 67
  experiment_id: 35d66058da2d4c9882f832ee91e4aa4a
  hostname: gpu011
  info:
    apply_time_ms: 3.701
    dispatch_time_ms: 25.583
    learner:
      cur_lr: 0.0012707560090348125
      grad_gnorm: 40.000003814697266
      policy_entropy: 206.80096435546875
      policy_loss: 68.30557250976562
      var_gnorm: 19.029340744018555
      vf_explained_var: 0.0
      vf_loss: 55.3491325378418
    num_steps_sampled: 1360000
    num_steps_trained: 1360000
    wait_time_ms: 254.683
  iterations_since_restore: 68
  node_ip: 172.17.8.11
  num_metric_batches_dropped: 0
  pid: 25504
  policy_reward_mean: {}
  time_since_restore: 1933.029732465744
  time_this_iter_s: 28.844019651412964
  time_total_s: 1933.029732465744
  timestamp: 1593916198
  timesteps_since_restore: 1360000
  timesteps_this_iter: 20000
  timesteps_total: 1360000
  training_iteration: 68
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=25504], 1933 s, 68 iter, 1360000 ts, -1.29e+03 rew

agent-1: 17.0
agent-2: 22.0
agent-3: 22.0
agent-4: 19.0
agent-5: 21.0
agent-6: 19.0
agent-7: 19.0
agent-8: 11.0
agent-9: 17.0
agent-10: 12.0
agent-11: 18.0
agent-12: 14.0
agent-13: 11.0
agent-14: 3.0
agent-15: 12.0
agent-16: 11.0
agent-17: 12.0
agent-18: 10.0
agent-19: 11.0
agent-20: 20.0
Sum Reward: 301.0
Avg Reward: 15.05
Min Reward: 3.0
Gini Coefficient: 0.1808970099667774
20:20 Ratio: 2.4285714285714284
Max-min Ratio: 7.333333333333333
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_22-30-27
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 655.0
  episode_reward_mean: -1262.1617647058824
  episode_reward_min: -45774.0
  episodes_this_iter: 1
  episodes_total: 68
  experiment_id: 35d66058da2d4c9882f832ee91e4aa4a
  hostname: gpu011
  info:
    apply_time_ms: 3.141
    dispatch_time_ms: 24.752
    learner:
      cur_lr: 0.0012694239849224687
      grad_gnorm: 22.730501174926758
      policy_entropy: 177.63796997070312
      policy_loss: -11.43557357788086
      var_gnorm: 19.03377914428711
      vf_explained_var: 0.0
      vf_loss: 0.1772213876247406
    num_steps_sampled: 1380000
    num_steps_trained: 1380000
    wait_time_ms: 268.598
  iterations_since_restore: 69
  node_ip: 172.17.8.11
  num_metric_batches_dropped: 0
  pid: 25504
  policy_reward_mean: {}
  time_since_restore: 1961.6734683513641
  time_this_iter_s: 28.643735885620117
  time_total_s: 1961.6734683513641
  timestamp: 1593916227
  timesteps_since_restore: 1380000
  timesteps_this_iter: 20000
  timesteps_total: 1380000
  training_iteration: 69
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=25504], 1961 s, 69 iter, 1380000 ts, -1.26e+03 rew

agent-1: 9.0
agent-2: 10.0
agent-3: 27.0
agent-4: 30.0
agent-5: 27.0
agent-6: 10.0
agent-7: 14.0
agent-8: 7.0
agent-9: 7.0
agent-10: 23.0
agent-11: 20.0
agent-12: 6.0
agent-13: 20.0
agent-14: 13.0
agent-15: 3.0
agent-16: 10.0
agent-17: 8.0
agent-18: 13.0
agent-19: 13.0
agent-20: 11.0
Sum Reward: 281.0
Avg Reward: 14.05
Min Reward: 3.0
Gini Coefficient: 0.29590747330960854
20:20 Ratio: 4.6521739130434785
Max-min Ratio: 10.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_22-30-57
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 655.0
  episode_reward_mean: -1239.7971014492753
  episode_reward_min: -45774.0
  episodes_this_iter: 1
  episodes_total: 69
  experiment_id: 35d66058da2d4c9882f832ee91e4aa4a
  hostname: gpu011
  info:
    apply_time_ms: 3.643
    dispatch_time_ms: 34.891
    learner:
      cur_lr: 0.0012680919608101249
      grad_gnorm: 40.0
      policy_entropy: 181.82408142089844
      policy_loss: 73.74491882324219
      var_gnorm: 19.03277015686035
      vf_explained_var: 2.384185791015625e-07
      vf_loss: 51.8560676574707
    num_steps_sampled: 1400000
    num_steps_trained: 1400000
    wait_time_ms: 247.343
  iterations_since_restore: 70
  node_ip: 172.17.8.11
  num_metric_batches_dropped: 0
  pid: 25504
  policy_reward_mean: {}
  time_since_restore: 1991.1981222629547
  time_this_iter_s: 29.524653911590576
  time_total_s: 1991.1981222629547
  timestamp: 1593916257
  timesteps_since_restore: 1400000
  timesteps_this_iter: 20000
  timesteps_total: 1400000
  training_iteration: 70
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=25504], 1991 s, 70 iter, 1400000 ts, -1.24e+03 rew

agent-1: 15.0
agent-2: 13.0
agent-3: 15.0
agent-4: 13.0
agent-5: 13.0
agent-6: 14.0
agent-7: 24.0
agent-8: 29.0
agent-9: 2.0
agent-10: 15.0
agent-11: 19.0
agent-12: 10.0
agent-13: 14.0
agent-14: 16.0
agent-15: 10.0
agent-16: 8.0
agent-17: 16.0
agent-18: 23.0
agent-19: 2.0
agent-20: 2.0
Sum Reward: 273.0
Avg Reward: 13.65
Min Reward: 2.0
Gini Coefficient: 0.27380952380952384
20:20 Ratio: 6.785714285714286
Max-min Ratio: 14.5
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_22-31-25
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 655.0
  episode_reward_mean: -1218.1857142857143
  episode_reward_min: -45774.0
  episodes_this_iter: 1
  episodes_total: 70
  experiment_id: 35d66058da2d4c9882f832ee91e4aa4a
  hostname: gpu011
  info:
    apply_time_ms: 3.783
    dispatch_time_ms: 19.622
    learner:
      cur_lr: 0.001266760053113103
      grad_gnorm: 11.130115509033203
      policy_entropy: 149.78012084960938
      policy_loss: -7.657787322998047
      var_gnorm: 19.036409378051758
      vf_explained_var: 0.0
      vf_loss: 0.9925550222396851
    num_steps_sampled: 1420000
    num_steps_trained: 1420000
    wait_time_ms: 260.922
  iterations_since_restore: 71
  node_ip: 172.17.8.11
  num_metric_batches_dropped: 0
  pid: 25504
  policy_reward_mean: {}
  time_since_restore: 2019.7502913475037
  time_this_iter_s: 28.55216908454895
  time_total_s: 2019.7502913475037
  timestamp: 1593916285
  timesteps_since_restore: 1420000
  timesteps_this_iter: 20000
  timesteps_total: 1420000
  training_iteration: 71
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=25504], 2019 s, 71 iter, 1420000 ts, -1.22e+03 rew

agent-1: 16.0
agent-2: 16.0
agent-3: 26.0
agent-4: 21.0
agent-5: 10.0
agent-6: 0.0
agent-7: 14.0
agent-8: 18.0
agent-9: 33.0
agent-10: 11.0
agent-11: 10.0
agent-12: 7.0
agent-13: 12.0
agent-14: 5.0
agent-15: 27.0
agent-16: 9.0
agent-17: 14.0
agent-18: 20.0
agent-19: 22.0
agent-20: 12.0
Sum Reward: 303.0
Avg Reward: 15.15
Min Reward: 0.0
Gini Coefficient: 0.2882838283828383
20:20 Ratio: 5.142857142857143
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_22-31-54
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 655.0
  episode_reward_mean: -1196.7605633802816
  episode_reward_min: -45774.0
  episodes_this_iter: 1
  episodes_total: 71
  experiment_id: 35d66058da2d4c9882f832ee91e4aa4a
  hostname: gpu011
  info:
    apply_time_ms: 2.953
    dispatch_time_ms: 52.874
    learner:
      cur_lr: 0.0012654280290007591
      grad_gnorm: 39.999996185302734
      policy_entropy: 161.0355224609375
      policy_loss: 66.41867065429688
      var_gnorm: 19.035696029663086
      vf_explained_var: 0.0
      vf_loss: 55.6673583984375
    num_steps_sampled: 1440000
    num_steps_trained: 1440000
    wait_time_ms: 245.113
  iterations_since_restore: 72
  node_ip: 172.17.8.11
  num_metric_batches_dropped: 0
  pid: 25504
  policy_reward_mean: {}
  time_since_restore: 2048.697494506836
  time_this_iter_s: 28.947203159332275
  time_total_s: 2048.697494506836
  timestamp: 1593916314
  timesteps_since_restore: 1440000
  timesteps_this_iter: 20000
  timesteps_total: 1440000
  training_iteration: 72
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=25504], 2048 s, 72 iter, 1440000 ts, -1.2e+03 rew

agent-1: 12.0
agent-2: 14.0
agent-3: 10.0
agent-4: 26.0
agent-5: 6.0
agent-6: 17.0
agent-7: 14.0
agent-8: 8.0
agent-9: 11.0
agent-10: 13.0
agent-11: 24.0
agent-12: 11.0
agent-13: 14.0
agent-14: 11.0
agent-15: 14.0
agent-16: 28.0
agent-17: 5.0
agent-18: 16.0
agent-19: 15.0
agent-20: 14.0
Sum Reward: 283.0
Avg Reward: 14.15
Min Reward: 5.0
Gini Coefficient: 0.21784452296819787
20:20 Ratio: 3.2758620689655173
Max-min Ratio: 5.6
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_22-32-22
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 655.0
  episode_reward_mean: -1176.2083333333333
  episode_reward_min: -45774.0
  episodes_this_iter: 1
  episodes_total: 72
  experiment_id: 35d66058da2d4c9882f832ee91e4aa4a
  hostname: gpu011
  info:
    apply_time_ms: 4.18
    dispatch_time_ms: 19.979
    learner:
      cur_lr: 0.0012640960048884153
      grad_gnorm: 40.0
      policy_entropy: 209.22193908691406
      policy_loss: -21.525821685791016
      var_gnorm: 19.03348159790039
      vf_explained_var: -2.384185791015625e-07
      vf_loss: 0.7301206588745117
    num_steps_sampled: 1460000
    num_steps_trained: 1460000
    wait_time_ms: 262.58
  iterations_since_restore: 73
  node_ip: 172.17.8.11
  num_metric_batches_dropped: 0
  pid: 25504
  policy_reward_mean: {}
  time_since_restore: 2076.886086463928
  time_this_iter_s: 28.188591957092285
  time_total_s: 2076.886086463928
  timestamp: 1593916342
  timesteps_since_restore: 1460000
  timesteps_this_iter: 20000
  timesteps_total: 1460000
  training_iteration: 73
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=25504], 2076 s, 73 iter, 1460000 ts, -1.18e+03 rew

agent-1: 20.0
agent-2: 9.0
agent-3: 16.0
agent-4: 24.0
agent-5: 12.0
agent-6: 20.0
agent-7: 10.0
agent-8: 7.0
agent-9: 27.0
agent-10: 18.0
agent-11: 4.0
agent-12: 13.0
agent-13: 29.0
agent-14: 16.0
agent-15: 19.0
agent-16: 23.0
agent-17: 16.0
agent-18: 27.0
agent-19: 30.0
agent-20: 17.0
Sum Reward: 357.0
Avg Reward: 17.85
Min Reward: 4.0
Gini Coefficient: 0.2295518207282913
20:20 Ratio: 3.7666666666666666
Max-min Ratio: 7.5
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_22-32-51
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 655.0
  episode_reward_mean: -1155.2054794520548
  episode_reward_min: -45774.0
  episodes_this_iter: 1
  episodes_total: 73
  experiment_id: 35d66058da2d4c9882f832ee91e4aa4a
  hostname: gpu011
  info:
    apply_time_ms: 3.045
    dispatch_time_ms: 32.715
    learner:
      cur_lr: 0.0012627639807760715
      grad_gnorm: 10.630805969238281
      policy_entropy: 196.80621337890625
      policy_loss: -0.910666823387146
      var_gnorm: 19.03166389465332
      vf_explained_var: 0.0
      vf_loss: 0.04012542963027954
    num_steps_sampled: 1480000
    num_steps_trained: 1480000
    wait_time_ms: 266.538
  iterations_since_restore: 74
  node_ip: 172.17.8.11
  num_metric_batches_dropped: 0
  pid: 25504
  policy_reward_mean: {}
  time_since_restore: 2105.7381649017334
  time_this_iter_s: 28.852078437805176
  time_total_s: 2105.7381649017334
  timestamp: 1593916371
  timesteps_since_restore: 1480000
  timesteps_this_iter: 20000
  timesteps_total: 1480000
  training_iteration: 74
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=25504], 2105 s, 74 iter, 1480000 ts, -1.16e+03 rew

agent-1: 27.0
agent-2: 20.0
agent-3: 19.0
agent-4: 9.0
agent-5: 12.0
agent-6: 10.0
agent-7: 15.0
agent-8: 25.0
agent-9: 12.0
agent-10: 16.0
agent-11: 14.0
agent-12: 22.0
agent-13: 10.0
agent-14: 17.0
agent-15: 15.0
agent-16: 10.0
agent-17: 20.0
agent-18: 27.0
agent-19: 16.0
agent-20: 22.0
Sum Reward: 338.0
Avg Reward: 16.9
Min Reward: 9.0
Gini Coefficient: 0.18668639053254438
20:20 Ratio: 2.58974358974359
Max-min Ratio: 3.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_22-33-20
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 655.0
  episode_reward_mean: -1135.027027027027
  episode_reward_min: -45774.0
  episodes_this_iter: 1
  episodes_total: 74
  experiment_id: 35d66058da2d4c9882f832ee91e4aa4a
  hostname: gpu011
  info:
    apply_time_ms: 3.072
    dispatch_time_ms: 46.972
    learner:
      cur_lr: 0.0012614319566637278
      grad_gnorm: 40.0
      policy_entropy: 153.62420654296875
      policy_loss: 45.28917694091797
      var_gnorm: 19.036069869995117
      vf_explained_var: 0.0
      vf_loss: 60.516815185546875
    num_steps_sampled: 1500000
    num_steps_trained: 1500000
    wait_time_ms: 236.525
  iterations_since_restore: 75
  node_ip: 172.17.8.11
  num_metric_batches_dropped: 0
  pid: 25504
  policy_reward_mean: {}
  time_since_restore: 2133.916855573654
  time_this_iter_s: 28.178690671920776
  time_total_s: 2133.916855573654
  timestamp: 1593916400
  timesteps_since_restore: 1500000
  timesteps_this_iter: 20000
  timesteps_total: 1500000
  training_iteration: 75
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=25504], 2133 s, 75 iter, 1500000 ts, -1.14e+03 rew

agent-1: 15.0
agent-2: 17.0
agent-3: 17.0
agent-4: 21.0
agent-5: 32.0
agent-6: 18.0
agent-7: 19.0
agent-8: 9.0
agent-9: 26.0
agent-10: 4.0
agent-11: 14.0
agent-12: 17.0
agent-13: 21.0
agent-14: 6.0
agent-15: 12.0
agent-16: 7.0
agent-17: 22.0
agent-18: 8.0
agent-19: 11.0
agent-20: 7.0
Sum Reward: 303.0
Avg Reward: 15.15
Min Reward: 4.0
Gini Coefficient: 0.2635313531353135
20:20 Ratio: 4.208333333333333
Max-min Ratio: 8.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_22-33-48
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 655.0
  episode_reward_mean: -1115.8533333333332
  episode_reward_min: -45774.0
  episodes_this_iter: 1
  episodes_total: 75
  experiment_id: 35d66058da2d4c9882f832ee91e4aa4a
  hostname: gpu011
  info:
    apply_time_ms: 2.7
    dispatch_time_ms: 22.397
    learner:
      cur_lr: 0.0012601000489667058
      grad_gnorm: 8.211918830871582
      policy_entropy: 153.61476135253906
      policy_loss: 1.0219945907592773
      var_gnorm: 19.037429809570312
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 0.023998329415917397
    num_steps_sampled: 1520000
    num_steps_trained: 1520000
    wait_time_ms: 244.777
  iterations_since_restore: 76
  node_ip: 172.17.8.11
  num_metric_batches_dropped: 0
  pid: 25504
  policy_reward_mean: {}
  time_since_restore: 2162.6316781044006
  time_this_iter_s: 28.71482253074646
  time_total_s: 2162.6316781044006
  timestamp: 1593916428
  timesteps_since_restore: 1520000
  timesteps_this_iter: 20000
  timesteps_total: 1520000
  training_iteration: 76
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=25504], 2162 s, 76 iter, 1520000 ts, -1.12e+03 rew

agent-1: 23.0
agent-2: 10.0
agent-3: 14.0
agent-4: 20.0
agent-5: 9.0
agent-6: 17.0
agent-7: 36.0
agent-8: 32.0
agent-9: 18.0
agent-10: 41.0
agent-11: 12.0
agent-12: 8.0
agent-13: 17.0
agent-14: 21.0
agent-15: 14.0
agent-16: 16.0
agent-17: 13.0
agent-18: 32.0
agent-19: 14.0
agent-20: 16.0
Sum Reward: 383.0
Avg Reward: 19.15
Min Reward: 8.0
Gini Coefficient: 0.25
20:20 Ratio: 3.6153846153846154
Max-min Ratio: 5.125
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_22-34-17
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 655.0
  episode_reward_mean: -1096.1315789473683
  episode_reward_min: -45774.0
  episodes_this_iter: 1
  episodes_total: 76
  experiment_id: 35d66058da2d4c9882f832ee91e4aa4a
  hostname: gpu011
  info:
    apply_time_ms: 3.62
    dispatch_time_ms: 33.896
    learner:
      cur_lr: 0.001258768024854362
      grad_gnorm: 40.000003814697266
      policy_entropy: 189.1475372314453
      policy_loss: -15.789027214050293
      var_gnorm: 19.03668212890625
      vf_explained_var: 0.0
      vf_loss: 0.790105938911438
    num_steps_sampled: 1540000
    num_steps_trained: 1540000
    wait_time_ms: 257.523
  iterations_since_restore: 77
  node_ip: 172.17.8.11
  num_metric_batches_dropped: 0
  pid: 25504
  policy_reward_mean: {}
  time_since_restore: 2190.9516146183014
  time_this_iter_s: 28.319936513900757
  time_total_s: 2190.9516146183014
  timestamp: 1593916457
  timesteps_since_restore: 1540000
  timesteps_this_iter: 20000
  timesteps_total: 1540000
  training_iteration: 77
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=25504], 2190 s, 77 iter, 1540000 ts, -1.1e+03 rew

agent-1: 15.0
agent-2: 14.0
agent-3: 4.0
agent-4: 16.0
agent-5: 28.0
agent-6: 5.0
agent-7: 27.0
agent-8: 16.0
agent-9: 19.0
agent-10: 19.0
agent-11: 12.0
agent-12: 5.0
agent-13: 14.0
agent-14: 2.0
agent-15: 19.0
agent-16: 31.0
agent-17: 17.0
agent-18: 19.0
agent-19: 19.0
agent-20: 27.0
Sum Reward: 328.0
Avg Reward: 16.4
Min Reward: 2.0
Gini Coefficient: 0.2685975609756098
20:20 Ratio: 7.0625
Max-min Ratio: 15.5
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_22-34-45
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 655.0
  episode_reward_mean: -1077.6363636363637
  episode_reward_min: -45774.0
  episodes_this_iter: 1
  episodes_total: 77
  experiment_id: 35d66058da2d4c9882f832ee91e4aa4a
  hostname: gpu011
  info:
    apply_time_ms: 3.054
    dispatch_time_ms: 11.966
    learner:
      cur_lr: 0.0012574360007420182
      grad_gnorm: 40.0
      policy_entropy: 168.31858825683594
      policy_loss: 24.744400024414062
      var_gnorm: 19.036211013793945
      vf_explained_var: 0.0
      vf_loss: 18.8149356842041
    num_steps_sampled: 1560000
    num_steps_trained: 1560000
    wait_time_ms: 252.697
  iterations_since_restore: 78
  node_ip: 172.17.8.11
  num_metric_batches_dropped: 0
  pid: 25504
  policy_reward_mean: {}
  time_since_restore: 2219.7290325164795
  time_this_iter_s: 28.7774178981781
  time_total_s: 2219.7290325164795
  timestamp: 1593916485
  timesteps_since_restore: 1560000
  timesteps_this_iter: 20000
  timesteps_total: 1560000
  training_iteration: 78
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=25504], 2219 s, 78 iter, 1560000 ts, -1.08e+03 rew

agent-1: 13.0
agent-2: 21.0
agent-3: 18.0
agent-4: 35.0
agent-5: 26.0
agent-6: 12.0
agent-7: 21.0
agent-8: 12.0
agent-9: 12.0
agent-10: 9.0
agent-11: 8.0
agent-12: 26.0
agent-13: 24.0
agent-14: 25.0
agent-15: 19.0
agent-16: 25.0
agent-17: 34.0
agent-18: 3.0
agent-19: 37.0
agent-20: 16.0
Sum Reward: 396.0
Avg Reward: 19.8
Min Reward: 3.0
Gini Coefficient: 0.2611111111111111
20:20 Ratio: 4.125
Max-min Ratio: 12.333333333333334
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_22-35-14
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 655.0
  episode_reward_mean: -1058.7435897435898
  episode_reward_min: -45774.0
  episodes_this_iter: 1
  episodes_total: 78
  experiment_id: 35d66058da2d4c9882f832ee91e4aa4a
  hostname: gpu011
  info:
    apply_time_ms: 2.797
    dispatch_time_ms: 52.956
    learner:
      cur_lr: 0.0012561039766296744
      grad_gnorm: 18.24561309814453
      policy_entropy: 186.0763397216797
      policy_loss: -5.477985382080078
      var_gnorm: 19.04277229309082
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 4.8513407707214355
    num_steps_sampled: 1580000
    num_steps_trained: 1580000
    wait_time_ms: 240.599
  iterations_since_restore: 79
  node_ip: 172.17.8.11
  num_metric_batches_dropped: 0
  pid: 25504
  policy_reward_mean: {}
  time_since_restore: 2248.2108097076416
  time_this_iter_s: 28.48177719116211
  time_total_s: 2248.2108097076416
  timestamp: 1593916514
  timesteps_since_restore: 1580000
  timesteps_this_iter: 20000
  timesteps_total: 1580000
  training_iteration: 79
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=25504], 2248 s, 79 iter, 1580000 ts, -1.06e+03 rew

agent-1: 12.0
agent-2: 14.0
agent-3: 20.0
agent-4: 24.0
agent-5: 21.0
agent-6: 28.0
agent-7: 8.0
agent-8: 23.0
agent-9: 15.0
agent-10: 8.0
agent-11: 7.0
agent-12: 21.0
agent-13: 15.0
agent-14: 29.0
agent-15: 15.0
agent-16: 22.0
agent-17: 17.0
agent-18: 19.0
agent-19: 17.0
agent-20: 18.0
Sum Reward: 353.0
Avg Reward: 17.65
Min Reward: 7.0
Gini Coefficient: 0.19220963172804534
20:20 Ratio: 2.9714285714285715
Max-min Ratio: 4.142857142857143
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_22-35-43
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 655.0
  episode_reward_mean: -1040.873417721519
  episode_reward_min: -45774.0
  episodes_this_iter: 1
  episodes_total: 79
  experiment_id: 35d66058da2d4c9882f832ee91e4aa4a
  hostname: gpu011
  info:
    apply_time_ms: 2.525
    dispatch_time_ms: 16.239
    learner:
      cur_lr: 0.0012547719525173306
      grad_gnorm: 39.999996185302734
      policy_entropy: 191.48397827148438
      policy_loss: 67.46394348144531
      var_gnorm: 19.044151306152344
      vf_explained_var: 0.0
      vf_loss: 75.70199584960938
    num_steps_sampled: 1600000
    num_steps_trained: 1600000
    wait_time_ms: 256.11
  iterations_since_restore: 80
  node_ip: 172.17.8.11
  num_metric_batches_dropped: 0
  pid: 25504
  policy_reward_mean: {}
  time_since_restore: 2276.766963005066
  time_this_iter_s: 28.556153297424316
  time_total_s: 2276.766963005066
  timestamp: 1593916543
  timesteps_since_restore: 1600000
  timesteps_this_iter: 20000
  timesteps_total: 1600000
  training_iteration: 80
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=25504], 2276 s, 80 iter, 1600000 ts, -1.04e+03 rew

agent-1: 25.0
agent-2: 12.0
agent-3: 20.0
agent-4: 21.0
agent-5: 30.0
agent-6: 25.0
agent-7: 7.0
agent-8: 9.0
agent-9: 21.0
agent-10: 19.0
agent-11: 28.0
agent-12: 29.0
agent-13: 22.0
agent-14: 22.0
agent-15: 23.0
agent-16: 18.0
agent-17: 19.0
agent-18: 37.0
agent-19: 22.0
agent-20: 38.0
Sum Reward: 447.0
Avg Reward: 22.35
Min Reward: 7.0
Gini Coefficient: 0.1878076062639821
20:20 Ratio: 2.9130434782608696
Max-min Ratio: 5.428571428571429
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_22-36-12
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 655.0
  episode_reward_mean: -1022.275
  episode_reward_min: -45774.0
  episodes_this_iter: 1
  episodes_total: 80
  experiment_id: 35d66058da2d4c9882f832ee91e4aa4a
  hostname: gpu011
  info:
    apply_time_ms: 3.704
    dispatch_time_ms: 24.449
    learner:
      cur_lr: 0.0012534400448203087
      grad_gnorm: 35.147457122802734
      policy_entropy: 192.33740234375
      policy_loss: -22.170652389526367
      var_gnorm: 19.048683166503906
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 0.43178537487983704
    num_steps_sampled: 1620000
    num_steps_trained: 1620000
    wait_time_ms: 283.026
  iterations_since_restore: 81
  node_ip: 172.17.8.11
  num_metric_batches_dropped: 0
  pid: 25504
  policy_reward_mean: {}
  time_since_restore: 2306.1713483333588
  time_this_iter_s: 29.404385328292847
  time_total_s: 2306.1713483333588
  timestamp: 1593916572
  timesteps_since_restore: 1620000
  timesteps_this_iter: 20000
  timesteps_total: 1620000
  training_iteration: 81
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=25504], 2306 s, 81 iter, 1620000 ts, -1.02e+03 rew

agent-1: 10.0
agent-2: 11.0
agent-3: 15.0
agent-4: 16.0
agent-5: 17.0
agent-6: 30.0
agent-7: 5.0
agent-8: 26.0
agent-9: 12.0
agent-10: 22.0
agent-11: 13.0
agent-12: 16.0
agent-13: 5.0
agent-14: 8.0
agent-15: 14.0
agent-16: 20.0
agent-17: 18.0
agent-18: 17.0
agent-19: 11.0
agent-20: 17.0
Sum Reward: 303.0
Avg Reward: 15.15
Min Reward: 5.0
Gini Coefficient: 0.22524752475247525
20:20 Ratio: 3.5
Max-min Ratio: 6.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_22-36-41
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 655.0
  episode_reward_mean: -1005.9135802469136
  episode_reward_min: -45774.0
  episodes_this_iter: 1
  episodes_total: 81
  experiment_id: 35d66058da2d4c9882f832ee91e4aa4a
  hostname: gpu011
  info:
    apply_time_ms: 2.571
    dispatch_time_ms: 38.268
    learner:
      cur_lr: 0.001252108020707965
      grad_gnorm: 40.0
      policy_entropy: 178.40206909179688
      policy_loss: 88.36801147460938
      var_gnorm: 19.048418045043945
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 67.25433349609375
    num_steps_sampled: 1640000
    num_steps_trained: 1640000
    wait_time_ms: 234.663
  iterations_since_restore: 82
  node_ip: 172.17.8.11
  num_metric_batches_dropped: 0
  pid: 25504
  policy_reward_mean: {}
  time_since_restore: 2334.889099597931
  time_this_iter_s: 28.717751264572144
  time_total_s: 2334.889099597931
  timestamp: 1593916601
  timesteps_since_restore: 1640000
  timesteps_this_iter: 20000
  timesteps_total: 1640000
  training_iteration: 82
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=25504], 2334 s, 82 iter, 1640000 ts, -1.01e+03 rew

agent-1: 24.0
agent-2: 25.0
agent-3: 22.0
agent-4: 15.0
agent-5: 18.0
agent-6: 4.0
agent-7: 31.0
agent-8: 19.0
agent-9: 25.0
agent-10: 18.0
agent-11: 14.0
agent-12: 13.0
agent-13: 35.0
agent-14: 36.0
agent-15: 13.0
agent-16: 17.0
agent-17: 15.0
agent-18: 21.0
agent-19: 5.0
agent-20: 20.0
Sum Reward: 390.0
Avg Reward: 19.5
Min Reward: 4.0
Gini Coefficient: 0.23358974358974358
20:20 Ratio: 3.6285714285714286
Max-min Ratio: 9.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_22-37-10
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 655.0
  episode_reward_mean: -988.890243902439
  episode_reward_min: -45774.0
  episodes_this_iter: 1
  episodes_total: 82
  experiment_id: 35d66058da2d4c9882f832ee91e4aa4a
  hostname: gpu011
  info:
    apply_time_ms: 3.321
    dispatch_time_ms: 38.324
    learner:
      cur_lr: 0.0012507759965956211
      grad_gnorm: 6.486165523529053
      policy_entropy: 136.81201171875
      policy_loss: -2.963912010192871
      var_gnorm: 19.051437377929688
      vf_explained_var: 0.0
      vf_loss: 3.1695590019226074
    num_steps_sampled: 1660000
    num_steps_trained: 1660000
    wait_time_ms: 316.458
  iterations_since_restore: 83
  node_ip: 172.17.8.11
  num_metric_batches_dropped: 0
  pid: 25504
  policy_reward_mean: {}
  time_since_restore: 2363.928564310074
  time_this_iter_s: 29.039464712142944
  time_total_s: 2363.928564310074
  timestamp: 1593916630
  timesteps_since_restore: 1660000
  timesteps_this_iter: 20000
  timesteps_total: 1660000
  training_iteration: 83
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=25504], 2363 s, 83 iter, 1660000 ts, -989 rew

agent-1: 12.0
agent-2: 11.0
agent-3: 12.0
agent-4: 14.0
agent-5: 17.0
agent-6: 21.0
agent-7: 10.0
agent-8: 21.0
agent-9: 14.0
agent-10: 14.0
agent-11: 16.0
agent-12: 7.0
agent-13: 13.0
agent-14: 29.0
agent-15: 19.0
agent-16: 10.0
agent-17: 6.0
agent-18: 27.0
agent-19: 17.0
agent-20: 12.0
Sum Reward: 302.0
Avg Reward: 15.1
Min Reward: 6.0
Gini Coefficient: 0.21125827814569537
20:20 Ratio: 2.9696969696969697
Max-min Ratio: 4.833333333333333
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_22-37-38
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 655.0
  episode_reward_mean: -973.3373493975904
  episode_reward_min: -45774.0
  episodes_this_iter: 1
  episodes_total: 83
  experiment_id: 35d66058da2d4c9882f832ee91e4aa4a
  hostname: gpu011
  info:
    apply_time_ms: 3.937
    dispatch_time_ms: 60.807
    learner:
      cur_lr: 0.0012494439724832773
      grad_gnorm: 8.871868133544922
      policy_entropy: 178.56214904785156
      policy_loss: 8.85013198852539
      var_gnorm: 19.05321502685547
      vf_explained_var: 0.0
      vf_loss: 0.02338895946741104
    num_steps_sampled: 1680000
    num_steps_trained: 1680000
    wait_time_ms: 232.32
  iterations_since_restore: 84
  node_ip: 172.17.8.11
  num_metric_batches_dropped: 0
  pid: 25504
  policy_reward_mean: {}
  time_since_restore: 2392.1308801174164
  time_this_iter_s: 28.20231580734253
  time_total_s: 2392.1308801174164
  timestamp: 1593916658
  timesteps_since_restore: 1680000
  timesteps_this_iter: 20000
  timesteps_total: 1680000
  training_iteration: 84
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=25504], 2392 s, 84 iter, 1680000 ts, -973 rew

agent-1: 16.0
agent-2: 4.0
agent-3: 31.0
agent-4: 26.0
agent-5: 24.0
agent-6: 20.0
agent-7: 11.0
agent-8: 22.0
agent-9: 11.0
agent-10: 13.0
agent-11: 9.0
agent-12: 18.0
agent-13: 5.0
agent-14: 23.0
agent-15: 21.0
agent-16: 6.0
agent-17: 1.0
agent-18: 21.0
agent-19: 22.0
agent-20: 20.0
Sum Reward: 324.0
Avg Reward: 16.2
Min Reward: 1.0
Gini Coefficient: 0.2802469135802469
20:20 Ratio: 6.5
Max-min Ratio: 31.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_22-38-06
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 655.0
  episode_reward_mean: -957.8928571428571
  episode_reward_min: -45774.0
  episodes_this_iter: 1
  episodes_total: 84
  experiment_id: 35d66058da2d4c9882f832ee91e4aa4a
  hostname: gpu011
  info:
    apply_time_ms: 3.851
    dispatch_time_ms: 37.866
    learner:
      cur_lr: 0.0012481119483709335
      grad_gnorm: 38.85647201538086
      policy_entropy: 182.46958923339844
      policy_loss: -18.994264602661133
      var_gnorm: 19.049514770507812
      vf_explained_var: 0.0
      vf_loss: 3.2207043170928955
    num_steps_sampled: 1700000
    num_steps_trained: 1700000
    wait_time_ms: 256.822
  iterations_since_restore: 85
  node_ip: 172.17.8.11
  num_metric_batches_dropped: 0
  pid: 25504
  policy_reward_mean: {}
  time_since_restore: 2420.2881813049316
  time_this_iter_s: 28.15730118751526
  time_total_s: 2420.2881813049316
  timestamp: 1593916686
  timesteps_since_restore: 1700000
  timesteps_this_iter: 20000
  timesteps_total: 1700000
  training_iteration: 85
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=25504], 2420 s, 85 iter, 1700000 ts, -958 rew

agent-1: 15.0
agent-2: 15.0
agent-3: 22.0
agent-4: 29.0
agent-5: 54.0
agent-6: 12.0
agent-7: 13.0
agent-8: 20.0
agent-9: 29.0
agent-10: 7.0
agent-11: 6.0
agent-12: 4.0
agent-13: 24.0
agent-14: 13.0
agent-15: 33.0
agent-16: 23.0
agent-17: 40.0
agent-18: 26.0
agent-19: 44.0
agent-20: 14.0
Sum Reward: 443.0
Avg Reward: 22.15
Min Reward: 4.0
Gini Coefficient: 0.32042889390519186
20:20 Ratio: 5.896551724137931
Max-min Ratio: 13.5
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_22-38-35
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 655.0
  episode_reward_mean: -941.4117647058823
  episode_reward_min: -45774.0
  episodes_this_iter: 1
  episodes_total: 85
  experiment_id: 35d66058da2d4c9882f832ee91e4aa4a
  hostname: gpu011
  info:
    apply_time_ms: 3.184
    dispatch_time_ms: 37.753
    learner:
      cur_lr: 0.0012467800406739116
      grad_gnorm: 11.207036972045898
      policy_entropy: 166.95211791992188
      policy_loss: -0.3468474745750427
      var_gnorm: 19.047992706298828
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 0.04423109441995621
    num_steps_sampled: 1720000
    num_steps_trained: 1720000
    wait_time_ms: 239.113
  iterations_since_restore: 86
  node_ip: 172.17.8.11
  num_metric_batches_dropped: 0
  pid: 25504
  policy_reward_mean: {}
  time_since_restore: 2449.078194618225
  time_this_iter_s: 28.790013313293457
  time_total_s: 2449.078194618225
  timestamp: 1593916715
  timesteps_since_restore: 1720000
  timesteps_this_iter: 20000
  timesteps_total: 1720000
  training_iteration: 86
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=25504], 2449 s, 86 iter, 1720000 ts, -941 rew

agent-1: 16.0
agent-2: 16.0
agent-3: 11.0
agent-4: 3.0
agent-5: 9.0
agent-6: 41.0
agent-7: 20.0
agent-8: 13.0
agent-9: 15.0
agent-10: 7.0
agent-11: 4.0
agent-12: 31.0
agent-13: 28.0
agent-14: 14.0
agent-15: 8.0
agent-16: 23.0
agent-17: 17.0
agent-18: 12.0
agent-19: 13.0
agent-20: 23.0
Sum Reward: 324.0
Avg Reward: 16.2
Min Reward: 3.0
Gini Coefficient: 0.30648148148148147
20:20 Ratio: 5.590909090909091
Max-min Ratio: 13.666666666666666
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_22-39-03
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 655.0
  episode_reward_mean: -926.6976744186046
  episode_reward_min: -45774.0
  episodes_this_iter: 1
  episodes_total: 86
  experiment_id: 35d66058da2d4c9882f832ee91e4aa4a
  hostname: gpu011
  info:
    apply_time_ms: 2.912
    dispatch_time_ms: 15.146
    learner:
      cur_lr: 0.0012454480165615678
      grad_gnorm: 15.53341007232666
      policy_entropy: 147.77789306640625
      policy_loss: -6.12742280960083
      var_gnorm: 19.04728126525879
      vf_explained_var: 5.960464477539063e-08
      vf_loss: 18.07105255126953
    num_steps_sampled: 1740000
    num_steps_trained: 1740000
    wait_time_ms: 260.351
  iterations_since_restore: 87
  node_ip: 172.17.8.11
  num_metric_batches_dropped: 0
  pid: 25504
  policy_reward_mean: {}
  time_since_restore: 2477.1423053741455
  time_this_iter_s: 28.06411075592041
  time_total_s: 2477.1423053741455
  timestamp: 1593916743
  timesteps_since_restore: 1740000
  timesteps_this_iter: 20000
  timesteps_total: 1740000
  training_iteration: 87
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=25504], 2477 s, 87 iter, 1740000 ts, -927 rew

agent-1: 25.0
agent-2: 34.0
agent-3: 23.0
agent-4: 34.0
agent-5: 32.0
agent-6: 12.0
agent-7: 8.0
agent-8: 19.0
agent-9: 10.0
agent-10: 13.0
agent-11: 16.0
agent-12: 19.0
agent-13: 12.0
agent-14: 23.0
agent-15: 14.0
agent-16: 17.0
agent-17: 36.0
agent-18: 17.0
agent-19: 7.0
agent-20: 16.0
Sum Reward: 387.0
Avg Reward: 19.35
Min Reward: 7.0
Gini Coefficient: 0.24974160206718346
20:20 Ratio: 3.675675675675676
Max-min Ratio: 5.142857142857143
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_22-39-32
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 655.0
  episode_reward_mean: -911.5977011494252
  episode_reward_min: -45774.0
  episodes_this_iter: 1
  episodes_total: 87
  experiment_id: 35d66058da2d4c9882f832ee91e4aa4a
  hostname: gpu011
  info:
    apply_time_ms: 3.955
    dispatch_time_ms: 23.742
    learner:
      cur_lr: 0.001244115992449224
      grad_gnorm: 29.07401466369629
      policy_entropy: 139.34579467773438
      policy_loss: 13.171062469482422
      var_gnorm: 19.047290802001953
      vf_explained_var: 0.0
      vf_loss: 6.978568077087402
    num_steps_sampled: 1760000
    num_steps_trained: 1760000
    wait_time_ms: 270.722
  iterations_since_restore: 88
  node_ip: 172.17.8.11
  num_metric_batches_dropped: 0
  pid: 25504
  policy_reward_mean: {}
  time_since_restore: 2506.097575902939
  time_this_iter_s: 28.955270528793335
  time_total_s: 2506.097575902939
  timestamp: 1593916772
  timesteps_since_restore: 1760000
  timesteps_this_iter: 20000
  timesteps_total: 1760000
  training_iteration: 88
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=25504], 2506 s, 88 iter, 1760000 ts, -912 rew

agent-1: 23.0
agent-2: 28.0
agent-3: 23.0
agent-4: 20.0
agent-5: 25.0
agent-6: 19.0
agent-7: 15.0
agent-8: 16.0
agent-9: 27.0
agent-10: 26.0
agent-11: 19.0
agent-12: 31.0
agent-13: 13.0
agent-14: 27.0
agent-15: 22.0
agent-16: 13.0
agent-17: 21.0
agent-18: 18.0
agent-19: 34.0
agent-20: 38.0
Sum Reward: 458.0
Avg Reward: 22.9
Min Reward: 13.0
Gini Coefficient: 0.1615720524017467
20:20 Ratio: 2.2982456140350878
Max-min Ratio: 2.923076923076923
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_22-40-01
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 655.0
  episode_reward_mean: -896.0340909090909
  episode_reward_min: -45774.0
  episodes_this_iter: 1
  episodes_total: 88
  experiment_id: 35d66058da2d4c9882f832ee91e4aa4a
  hostname: gpu011
  info:
    apply_time_ms: 2.814
    dispatch_time_ms: 37.07
    learner:
      cur_lr: 0.0012427839683368802
      grad_gnorm: 40.000003814697266
      policy_entropy: 158.79579162597656
      policy_loss: -2.661285638809204
      var_gnorm: 19.049612045288086
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 38.334068298339844
    num_steps_sampled: 1780000
    num_steps_trained: 1780000
    wait_time_ms: 285.068
  iterations_since_restore: 89
  node_ip: 172.17.8.11
  num_metric_batches_dropped: 0
  pid: 25504
  policy_reward_mean: {}
  time_since_restore: 2534.6117894649506
  time_this_iter_s: 28.51421356201172
  time_total_s: 2534.6117894649506
  timestamp: 1593916801
  timesteps_since_restore: 1780000
  timesteps_this_iter: 20000
  timesteps_total: 1780000
  training_iteration: 89
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=25504], 2534 s, 89 iter, 1780000 ts, -896 rew

agent-1: 5.0
agent-2: 14.0
agent-3: 48.0
agent-4: 7.0
agent-5: 25.0
agent-6: 16.0
agent-7: 35.0
agent-8: 19.0
agent-9: 29.0
agent-10: 21.0
agent-11: 18.0
agent-12: 14.0
agent-13: 17.0
agent-14: 11.0
agent-15: 36.0
agent-16: 23.0
agent-17: 8.0
agent-18: 12.0
agent-19: 30.0
agent-20: 2.0
Sum Reward: 390.0
Avg Reward: 19.5
Min Reward: 2.0
Gini Coefficient: 0.3243589743589744
20:20 Ratio: 6.7727272727272725
Max-min Ratio: 24.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_22-40-29
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 655.0
  episode_reward_mean: -881.5842696629213
  episode_reward_min: -45774.0
  episodes_this_iter: 1
  episodes_total: 89
  experiment_id: 35d66058da2d4c9882f832ee91e4aa4a
  hostname: gpu011
  info:
    apply_time_ms: 3.012
    dispatch_time_ms: 22.043
    learner:
      cur_lr: 0.0012414519442245364
      grad_gnorm: 13.458944320678711
      policy_entropy: 153.75274658203125
      policy_loss: -1.9473010301589966
      var_gnorm: 19.048084259033203
      vf_explained_var: 0.0
      vf_loss: 0.06451250612735748
    num_steps_sampled: 1800000
    num_steps_trained: 1800000
    wait_time_ms: 264.003
  iterations_since_restore: 90
  node_ip: 172.17.8.11
  num_metric_batches_dropped: 0
  pid: 25504
  policy_reward_mean: {}
  time_since_restore: 2563.2501142024994
  time_this_iter_s: 28.638324737548828
  time_total_s: 2563.2501142024994
  timestamp: 1593916829
  timesteps_since_restore: 1800000
  timesteps_this_iter: 20000
  timesteps_total: 1800000
  training_iteration: 90
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=25504], 2563 s, 90 iter, 1800000 ts, -882 rew

agent-1: 10.0
agent-2: 22.0
agent-3: 17.0
agent-4: 40.0
agent-5: 30.0
agent-6: 17.0
agent-7: 12.0
agent-8: 33.0
agent-9: 27.0
agent-10: 15.0
agent-11: 17.0
agent-12: 17.0
agent-13: 14.0
agent-14: 32.0
agent-15: 19.0
agent-16: 22.0
agent-17: 26.0
agent-18: 21.0
agent-19: 8.0
agent-20: 7.0
Sum Reward: 406.0
Avg Reward: 20.3
Min Reward: 7.0
Gini Coefficient: 0.23793103448275862
20:20 Ratio: 3.6486486486486487
Max-min Ratio: 5.714285714285714
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_22-40-58
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 655.0
  episode_reward_mean: -867.2777777777778
  episode_reward_min: -45774.0
  episodes_this_iter: 1
  episodes_total: 90
  experiment_id: 35d66058da2d4c9882f832ee91e4aa4a
  hostname: gpu011
  info:
    apply_time_ms: 2.999
    dispatch_time_ms: 27.968
    learner:
      cur_lr: 0.0012401200365275145
      grad_gnorm: 40.0
      policy_entropy: 153.25978088378906
      policy_loss: 20.843027114868164
      var_gnorm: 19.05769920349121
      vf_explained_var: 0.0
      vf_loss: 38.012611389160156
    num_steps_sampled: 1820000
    num_steps_trained: 1820000
    wait_time_ms: 237.735
  iterations_since_restore: 91
  node_ip: 172.17.8.11
  num_metric_batches_dropped: 0
  pid: 25504
  policy_reward_mean: {}
  time_since_restore: 2591.608101129532
  time_this_iter_s: 28.35798692703247
  time_total_s: 2591.608101129532
  timestamp: 1593916858
  timesteps_since_restore: 1820000
  timesteps_this_iter: 20000
  timesteps_total: 1820000
  training_iteration: 91
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=25504], 2591 s, 91 iter, 1820000 ts, -867 rew

W0704 22:41:20.855952 25498 node_manager.cc:250] Last heartbeat was sent 3466 ms ago 
agent-1: 40.0
agent-2: 21.0
agent-3: 23.0
agent-4: 8.0
agent-5: 27.0
agent-6: 29.0
agent-7: 12.0
agent-8: 15.0
agent-9: 11.0
agent-10: 13.0
agent-11: 9.0
agent-12: 8.0
agent-13: 18.0
agent-14: 6.0
agent-15: 29.0
agent-16: 24.0
agent-17: 20.0
agent-18: 8.0
agent-19: 5.0
agent-20: 7.0
Sum Reward: 333.0
Avg Reward: 16.65
Min Reward: 5.0
Gini Coefficient: 0.31426426426426424
20:20 Ratio: 4.8076923076923075
Max-min Ratio: 8.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_22-41-31
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 655.0
  episode_reward_mean: -854.0879120879121
  episode_reward_min: -45774.0
  episodes_this_iter: 1
  episodes_total: 91
  experiment_id: 35d66058da2d4c9882f832ee91e4aa4a
  hostname: gpu011
  info:
    apply_time_ms: 3.57
    dispatch_time_ms: 5.716
    learner:
      cur_lr: 0.0012387880124151707
      grad_gnorm: 40.0
      policy_entropy: 145.56216430664062
      policy_loss: 41.94743347167969
      var_gnorm: 19.05630874633789
      vf_explained_var: 0.0
      vf_loss: 39.04842758178711
    num_steps_sampled: 1840000
    num_steps_trained: 1840000
    wait_time_ms: 270.225
  iterations_since_restore: 92
  node_ip: 172.17.8.11
  num_metric_batches_dropped: 0
  pid: 25504
  policy_reward_mean: {}
  time_since_restore: 2624.8318753242493
  time_this_iter_s: 33.22377419471741
  time_total_s: 2624.8318753242493
  timestamp: 1593916891
  timesteps_since_restore: 1840000
  timesteps_this_iter: 20000
  timesteps_total: 1840000
  training_iteration: 92
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=25504], 2624 s, 92 iter, 1840000 ts, -854 rew

agent-1: 13.0
agent-2: 34.0
agent-3: 13.0
agent-4: 29.0
agent-5: 33.0
agent-6: 21.0
agent-7: 14.0
agent-8: 34.0
agent-9: 18.0
agent-10: 12.0
agent-11: 12.0
agent-12: 22.0
agent-13: 45.0
agent-14: 8.0
agent-15: 19.0
agent-16: 20.0
agent-17: 29.0
agent-18: 48.0
agent-19: 29.0
agent-20: 29.0
Sum Reward: 482.0
Avg Reward: 24.1
Min Reward: 8.0
Gini Coefficient: 0.2524896265560166
20:20 Ratio: 3.577777777777778
Max-min Ratio: 6.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_22-41-58
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 655.0
  episode_reward_mean: -839.5652173913044
  episode_reward_min: -45774.0
  episodes_this_iter: 1
  episodes_total: 92
  experiment_id: 35d66058da2d4c9882f832ee91e4aa4a
  hostname: gpu011
  info:
    apply_time_ms: 2.613
    dispatch_time_ms: 5.8
    learner:
      cur_lr: 0.0012374559883028269
      grad_gnorm: 40.0
      policy_entropy: 134.37037658691406
      policy_loss: 10.298279762268066
      var_gnorm: 19.06224822998047
      vf_explained_var: 0.0
      vf_loss: 21.274261474609375
    num_steps_sampled: 1860000
    num_steps_trained: 1860000
    wait_time_ms: 274.201
  iterations_since_restore: 93
  node_ip: 172.17.8.11
  num_metric_batches_dropped: 0
  pid: 25504
  policy_reward_mean: {}
  time_since_restore: 2651.7887477874756
  time_this_iter_s: 26.95687246322632
  time_total_s: 2651.7887477874756
  timestamp: 1593916918
  timesteps_since_restore: 1860000
  timesteps_this_iter: 20000
  timesteps_total: 1860000
  training_iteration: 93
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=25504], 2651 s, 93 iter, 1860000 ts, -840 rew

agent-1: 17.0
agent-2: 25.0
agent-3: 17.0
agent-4: 28.0
agent-5: 18.0
agent-6: 14.0
agent-7: 34.0
agent-8: 15.0
agent-9: 15.0
agent-10: 12.0
agent-11: 11.0
agent-12: 25.0
agent-13: 13.0
agent-14: 14.0
agent-15: 31.0
agent-16: 31.0
agent-17: 24.0
agent-18: 9.0
agent-19: 21.0
agent-20: 31.0
Sum Reward: 405.0
Avg Reward: 20.25
Min Reward: 9.0
Gini Coefficient: 0.21172839506172839
20:20 Ratio: 2.8222222222222224
Max-min Ratio: 3.7777777777777777
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_22-42-26
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 655.0
  episode_reward_mean: -826.1827956989247
  episode_reward_min: -45774.0
  episodes_this_iter: 1
  episodes_total: 93
  experiment_id: 35d66058da2d4c9882f832ee91e4aa4a
  hostname: gpu011
  info:
    apply_time_ms: 2.751
    dispatch_time_ms: 5.102
    learner:
      cur_lr: 0.001236123964190483
      grad_gnorm: 40.0
      policy_entropy: 133.8676300048828
      policy_loss: 26.085363388061523
      var_gnorm: 19.065820693969727
      vf_explained_var: 0.0002644062042236328
      vf_loss: 44.732994079589844
    num_steps_sampled: 1880000
    num_steps_trained: 1880000
    wait_time_ms: 248.158
  iterations_since_restore: 94
  node_ip: 172.17.8.11
  num_metric_batches_dropped: 0
  pid: 25504
  policy_reward_mean: {}
  time_since_restore: 2679.212903738022
  time_this_iter_s: 27.424155950546265
  time_total_s: 2679.212903738022
  timestamp: 1593916946
  timesteps_since_restore: 1880000
  timesteps_this_iter: 20000
  timesteps_total: 1880000
  training_iteration: 94
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=25504], 2679 s, 94 iter, 1880000 ts, -826 rew

agent-1: 15.0
agent-2: 17.0
agent-3: 28.0
agent-4: 24.0
agent-5: 31.0
agent-6: 25.0
agent-7: 29.0
agent-8: 24.0
agent-9: 17.0
agent-10: 18.0
agent-11: 11.0
agent-12: 8.0
agent-13: 10.0
agent-14: 23.0
agent-15: 36.0
agent-16: 26.0
agent-17: 13.0
agent-18: 33.0
agent-19: 22.0
agent-20: 18.0
Sum Reward: 428.0
Avg Reward: 21.4
Min Reward: 8.0
Gini Coefficient: 0.205607476635514
20:20 Ratio: 3.0714285714285716
Max-min Ratio: 4.5
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_22-42-53
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 655.0
  episode_reward_mean: -812.8404255319149
  episode_reward_min: -45774.0
  episodes_this_iter: 1
  episodes_total: 94
  experiment_id: 35d66058da2d4c9882f832ee91e4aa4a
  hostname: gpu011
  info:
    apply_time_ms: 3.185
    dispatch_time_ms: 6.092
    learner:
      cur_lr: 0.0012347920564934611
      grad_gnorm: 40.0
      policy_entropy: 109.20549011230469
      policy_loss: -8.190492630004883
      var_gnorm: 19.07467269897461
      vf_explained_var: 0.0
      vf_loss: 0.7566828727722168
    num_steps_sampled: 1900000
    num_steps_trained: 1900000
    wait_time_ms: 273.295
  iterations_since_restore: 95
  node_ip: 172.17.8.11
  num_metric_batches_dropped: 0
  pid: 25504
  policy_reward_mean: {}
  time_since_restore: 2706.5388939380646
  time_this_iter_s: 27.325990200042725
  time_total_s: 2706.5388939380646
  timestamp: 1593916973
  timesteps_since_restore: 1900000
  timesteps_this_iter: 20000
  timesteps_total: 1900000
  training_iteration: 95
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=25504], 2706 s, 95 iter, 1900000 ts, -813 rew

agent-1: 25.0
agent-2: 20.0
agent-3: 6.0
agent-4: 22.0
agent-5: 34.0
agent-6: 17.0
agent-7: 30.0
agent-8: 10.0
agent-9: 19.0
agent-10: 27.0
agent-11: 16.0
agent-12: 18.0
agent-13: 12.0
agent-14: 17.0
agent-15: 12.0
agent-16: 22.0
agent-17: 11.0
agent-18: 9.0
agent-19: 18.0
agent-20: 14.0
Sum Reward: 359.0
Avg Reward: 17.95
Min Reward: 6.0
Gini Coefficient: 0.22103064066852368
20:20 Ratio: 3.2222222222222223
Max-min Ratio: 5.666666666666667
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_22-43-20
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 655.0
  episode_reward_mean: -800.5052631578948
  episode_reward_min: -45774.0
  episodes_this_iter: 1
  episodes_total: 95
  experiment_id: 35d66058da2d4c9882f832ee91e4aa4a
  hostname: gpu011
  info:
    apply_time_ms: 3.558
    dispatch_time_ms: 8.499
    learner:
      cur_lr: 0.0012334600323811173
      grad_gnorm: 8.66064739227295
      policy_entropy: 131.16702270507812
      policy_loss: -1.6103006601333618
      var_gnorm: 19.064815521240234
      vf_explained_var: 0.0
      vf_loss: 0.027000021189451218
    num_steps_sampled: 1920000
    num_steps_trained: 1920000
    wait_time_ms: 267.104
  iterations_since_restore: 96
  node_ip: 172.17.8.11
  num_metric_batches_dropped: 0
  pid: 25504
  policy_reward_mean: {}
  time_since_restore: 2733.938958644867
  time_this_iter_s: 27.400064706802368
  time_total_s: 2733.938958644867
  timestamp: 1593917000
  timesteps_since_restore: 1920000
  timesteps_this_iter: 20000
  timesteps_total: 1920000
  training_iteration: 96
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=25504], 2733 s, 96 iter, 1920000 ts, -801 rew

agent-1: 25.0
agent-2: 25.0
agent-3: 14.0
agent-4: 14.0
agent-5: 34.0
agent-6: 38.0
agent-7: 3.0
agent-8: 14.0
agent-9: 5.0
agent-10: 16.0
agent-11: 27.0
agent-12: 19.0
agent-13: 3.0
agent-14: 25.0
agent-15: 6.0
agent-16: 5.0
agent-17: 19.0
agent-18: 4.0
agent-19: 26.0
agent-20: 23.0
Sum Reward: 345.0
Avg Reward: 17.25
Min Reward: 3.0
Gini Coefficient: 0.3392753623188406
20:20 Ratio: 8.333333333333334
Max-min Ratio: 12.666666666666666
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_22-43-48
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 655.0
  episode_reward_mean: -788.5729166666666
  episode_reward_min: -45774.0
  episodes_this_iter: 1
  episodes_total: 96
  experiment_id: 35d66058da2d4c9882f832ee91e4aa4a
  hostname: gpu011
  info:
    apply_time_ms: 3.283
    dispatch_time_ms: 7.551
    learner:
      cur_lr: 0.0012321280082687736
      grad_gnorm: 29.53893280029297
      policy_entropy: 135.51889038085938
      policy_loss: -6.593341827392578
      var_gnorm: 19.06232261657715
      vf_explained_var: 0.45284152030944824
      vf_loss: 1.4916858673095703
    num_steps_sampled: 1940000
    num_steps_trained: 1940000
    wait_time_ms: 268.669
  iterations_since_restore: 97
  node_ip: 172.17.8.11
  num_metric_batches_dropped: 0
  pid: 25504
  policy_reward_mean: {}
  time_since_restore: 2760.989424943924
  time_this_iter_s: 27.050466299057007
  time_total_s: 2760.989424943924
  timestamp: 1593917028
  timesteps_since_restore: 1940000
  timesteps_this_iter: 20000
  timesteps_total: 1940000
  training_iteration: 97
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=25504], 2760 s, 97 iter, 1940000 ts, -789 rew

agent-1: 23.0
agent-2: 7.0
agent-3: 6.0
agent-4: 13.0
agent-5: 17.0
agent-6: 14.0
agent-7: 21.0
agent-8: 3.0
agent-9: 11.0
agent-10: 6.0
agent-11: 19.0
agent-12: 13.0
agent-13: 22.0
agent-14: 23.0
agent-15: 33.0
agent-16: 13.0
agent-17: 37.0
agent-18: 10.0
agent-19: 22.0
agent-20: 6.0
Sum Reward: 319.0
Avg Reward: 15.95
Min Reward: 3.0
Gini Coefficient: 0.308307210031348
20:20 Ratio: 5.523809523809524
Max-min Ratio: 12.333333333333334
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_22-44-15
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 655.0
  episode_reward_mean: -777.1546391752578
  episode_reward_min: -45774.0
  episodes_this_iter: 1
  episodes_total: 97
  experiment_id: 35d66058da2d4c9882f832ee91e4aa4a
  hostname: gpu011
  info:
    apply_time_ms: 3.075
    dispatch_time_ms: 7.514
    learner:
      cur_lr: 0.0012307959841564298
      grad_gnorm: 7.8821210861206055
      policy_entropy: 192.61679077148438
      policy_loss: -0.20595908164978027
      var_gnorm: 19.801939010620117
      vf_explained_var: 0.9922735095024109
      vf_loss: 0.024470314383506775
    num_steps_sampled: 1960000
    num_steps_trained: 1960000
    wait_time_ms: 248.094
  iterations_since_restore: 98
  node_ip: 172.17.8.11
  num_metric_batches_dropped: 0
  pid: 25504
  policy_reward_mean: {}
  time_since_restore: 2788.581046819687
  time_this_iter_s: 27.59162187576294
  time_total_s: 2788.581046819687
  timestamp: 1593917055
  timesteps_since_restore: 1960000
  timesteps_this_iter: 20000
  timesteps_total: 1960000
  training_iteration: 98
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=25504], 2788 s, 98 iter, 1960000 ts, -777 rew

agent-1: 18.0
agent-2: 7.0
agent-3: 2.0
agent-4: 22.0
agent-5: 16.0
agent-6: 7.0
agent-7: 10.0
agent-8: 26.0
agent-9: 12.0
agent-10: 16.0
agent-11: 21.0
agent-12: 10.0
agent-13: 12.0
agent-14: 8.0
agent-15: 13.0
agent-16: 16.0
agent-17: 12.0
agent-18: 9.0
agent-19: 28.0
agent-20: 23.0
Sum Reward: 288.0
Avg Reward: 14.4
Min Reward: 2.0
Gini Coefficient: 0.2635416666666667
20:20 Ratio: 4.125
Max-min Ratio: 14.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_22-44-43
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 655.0
  episode_reward_mean: -766.2857142857143
  episode_reward_min: -45774.0
  episodes_this_iter: 1
  episodes_total: 98
  experiment_id: 35d66058da2d4c9882f832ee91e4aa4a
  hostname: gpu011
  info:
    apply_time_ms: 4.347
    dispatch_time_ms: 8.58
    learner:
      cur_lr: 0.001229463960044086
      grad_gnorm: 37.604881286621094
      policy_entropy: 190.5732421875
      policy_loss: -12.991959571838379
      var_gnorm: 19.83196258544922
      vf_explained_var: 0.0
      vf_loss: 0.554253339767456
    num_steps_sampled: 1980000
    num_steps_trained: 1980000
    wait_time_ms: 267.739
  iterations_since_restore: 99
  node_ip: 172.17.8.11
  num_metric_batches_dropped: 0
  pid: 25504
  policy_reward_mean: {}
  time_since_restore: 2816.0067772865295
  time_this_iter_s: 27.42573046684265
  time_total_s: 2816.0067772865295
  timestamp: 1593917083
  timesteps_since_restore: 1980000
  timesteps_this_iter: 20000
  timesteps_total: 1980000
  training_iteration: 99
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=25504], 2816 s, 99 iter, 1980000 ts, -766 rew

agent-1: 9.0
agent-2: 22.0
agent-3: 21.0
agent-4: 22.0
agent-5: 30.0
agent-6: 9.0
agent-7: 12.0
agent-8: 14.0
agent-9: 25.0
agent-10: 16.0
agent-11: 26.0
agent-12: 14.0
agent-13: 22.0
agent-14: 15.0
agent-15: 18.0
agent-16: 8.0
agent-17: 39.0
agent-18: 15.0
agent-19: 12.0
agent-20: 9.0
Sum Reward: 358.0
Avg Reward: 17.9
Min Reward: 8.0
Gini Coefficient: 0.2388268156424581
20:20 Ratio: 3.4285714285714284
Max-min Ratio: 4.875
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_22-45-11
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 655.0
  episode_reward_mean: -754.929292929293
  episode_reward_min: -45774.0
  episodes_this_iter: 1
  episodes_total: 99
  experiment_id: 35d66058da2d4c9882f832ee91e4aa4a
  hostname: gpu011
  info:
    apply_time_ms: 3.53
    dispatch_time_ms: 13.623
    learner:
      cur_lr: 0.001228132052347064
      grad_gnorm: 40.0
      policy_entropy: 189.79119873046875
      policy_loss: 70.62812042236328
      var_gnorm: 19.833391189575195
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 114.00889587402344
    num_steps_sampled: 2000000
    num_steps_trained: 2000000
    wait_time_ms: 252.889
  iterations_since_restore: 100
  node_ip: 172.17.8.11
  num_metric_batches_dropped: 0
  pid: 25504
  policy_reward_mean: {}
  time_since_restore: 2843.9887731075287
  time_this_iter_s: 27.981995820999146
  time_total_s: 2843.9887731075287
  timestamp: 1593917111
  timesteps_since_restore: 2000000
  timesteps_this_iter: 20000
  timesteps_total: 2000000
  training_iteration: 100
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=25504], 2843 s, 100 iter, 2000000 ts, -755 rew

agent-1: 6.0
agent-2: 6.0
agent-3: 30.0
agent-4: 17.0
agent-5: 7.0
agent-6: 13.0
agent-7: 18.0
agent-8: 7.0
agent-9: 14.0
agent-10: 38.0
agent-11: 9.0
agent-12: 21.0
agent-13: 11.0
agent-14: 25.0
agent-15: 12.0
agent-16: 8.0
agent-17: 3.0
agent-18: 7.0
agent-19: 39.0
agent-20: 24.0
Sum Reward: 315.0
Avg Reward: 15.75
Min Reward: 3.0
Gini Coefficient: 0.35793650793650794
20:20 Ratio: 6.0
Max-min Ratio: 13.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_22-45-39
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 655.0
  episode_reward_mean: -744.23
  episode_reward_min: -45774.0
  episodes_this_iter: 1
  episodes_total: 100
  experiment_id: 35d66058da2d4c9882f832ee91e4aa4a
  hostname: gpu011
  info:
    apply_time_ms: 2.707
    dispatch_time_ms: 17.974
    learner:
      cur_lr: 0.0012268000282347202
      grad_gnorm: 33.67572021484375
      policy_entropy: 169.31405639648438
      policy_loss: -13.452816009521484
      var_gnorm: 19.83987045288086
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 0.452047735452652
    num_steps_sampled: 2020000
    num_steps_trained: 2020000
    wait_time_ms: 264.66
  iterations_since_restore: 101
  node_ip: 172.17.8.11
  num_metric_batches_dropped: 0
  pid: 25504
  policy_reward_mean: {}
  time_since_restore: 2872.0370576381683
  time_this_iter_s: 28.04828453063965
  time_total_s: 2872.0370576381683
  timestamp: 1593917139
  timesteps_since_restore: 2020000
  timesteps_this_iter: 20000
  timesteps_total: 2020000
  training_iteration: 101
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=25504], 2872 s, 101 iter, 2020000 ts, -744 rew

agent-1: 9.0
agent-2: 18.0
agent-3: 8.0
agent-4: 27.0
agent-5: 16.0
agent-6: 34.0
agent-7: 15.0
agent-8: 19.0
agent-9: 11.0
agent-10: 24.0
agent-11: 18.0
agent-12: 17.0
agent-13: 13.0
agent-14: 14.0
agent-15: 13.0
agent-16: 21.0
agent-17: 11.0
agent-18: 15.0
agent-19: 8.0
agent-20: 11.0
Sum Reward: 322.0
Avg Reward: 16.1
Min Reward: 8.0
Gini Coefficient: 0.21490683229813665
20:20 Ratio: 2.9444444444444446
Max-min Ratio: 4.25
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_22-46-08
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 655.0
  episode_reward_mean: -295.04
  episode_reward_min: -45774.0
  episodes_this_iter: 1
  episodes_total: 101
  experiment_id: 35d66058da2d4c9882f832ee91e4aa4a
  hostname: gpu011
  info:
    apply_time_ms: 2.777
    dispatch_time_ms: 59.577
    learner:
      cur_lr: 0.0012254680041223764
      grad_gnorm: 40.0
      policy_entropy: 177.91864013671875
      policy_loss: 39.02231979370117
      var_gnorm: 19.8383846282959
      vf_explained_var: 0.0
      vf_loss: 39.4956169128418
    num_steps_sampled: 2040000
    num_steps_trained: 2040000
    wait_time_ms: 207.518
  iterations_since_restore: 102
  node_ip: 172.17.8.11
  num_metric_batches_dropped: 0
  pid: 25504
  policy_reward_mean: {}
  time_since_restore: 2900.99512219429
  time_this_iter_s: 28.958064556121826
  time_total_s: 2900.99512219429
  timestamp: 1593917168
  timesteps_since_restore: 2040000
  timesteps_this_iter: 20000
  timesteps_total: 2040000
  training_iteration: 102
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=25504], 2900 s, 102 iter, 2040000 ts, -295 rew

agent-1: 16.0
agent-2: 14.0
agent-3: 9.0
agent-4: 19.0
agent-5: 4.0
agent-6: 14.0
agent-7: 6.0
agent-8: 10.0
agent-9: 2.0
agent-10: 17.0
agent-11: 11.0
agent-12: 15.0
agent-13: 21.0
agent-14: 20.0
agent-15: 35.0
agent-16: 14.0
agent-17: 20.0
agent-18: 17.0
agent-19: 13.0
agent-20: 13.0
Sum Reward: 290.0
Avg Reward: 14.5
Min Reward: 2.0
Gini Coefficient: 0.25310344827586206
20:20 Ratio: 4.571428571428571
Max-min Ratio: 17.5
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_22-46-36
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 655.0
  episode_reward_mean: 165.6
  episode_reward_min: -6761.0
  episodes_this_iter: 1
  episodes_total: 102
  experiment_id: 35d66058da2d4c9882f832ee91e4aa4a
  hostname: gpu011
  info:
    apply_time_ms: 3.707
    dispatch_time_ms: 5.207
    learner:
      cur_lr: 0.0012241359800100327
      grad_gnorm: 40.0
      policy_entropy: 172.45726013183594
      policy_loss: -15.045234680175781
      var_gnorm: 19.848255157470703
      vf_explained_var: 5.960464477539063e-08
      vf_loss: 0.77527916431427
    num_steps_sampled: 2060000
    num_steps_trained: 2060000
    wait_time_ms: 267.201
  iterations_since_restore: 103
  node_ip: 172.17.8.11
  num_metric_batches_dropped: 0
  pid: 25504
  policy_reward_mean: {}
  time_since_restore: 2929.142313480377
  time_this_iter_s: 28.147191286087036
  time_total_s: 2929.142313480377
  timestamp: 1593917196
  timesteps_since_restore: 2060000
  timesteps_this_iter: 20000
  timesteps_total: 2060000
  training_iteration: 103
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=25504], 2929 s, 103 iter, 2060000 ts, 166 rew

agent-1: 5.0
agent-2: 17.0
agent-3: 8.0
agent-4: 21.0
agent-5: 32.0
agent-6: 16.0
agent-7: 35.0
agent-8: 22.0
agent-9: 15.0
agent-10: 8.0
agent-11: 21.0
agent-12: 16.0
agent-13: 21.0
agent-14: 17.0
agent-15: 5.0
agent-16: 27.0
agent-17: 27.0
agent-18: 10.0
agent-19: 12.0
agent-20: 16.0
Sum Reward: 351.0
Avg Reward: 17.55
Min Reward: 5.0
Gini Coefficient: 0.26282051282051283
20:20 Ratio: 4.653846153846154
Max-min Ratio: 7.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_22-47-04
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 655.0
  episode_reward_mean: 236.72
  episode_reward_min: -6178.0
  episodes_this_iter: 1
  episodes_total: 103
  experiment_id: 35d66058da2d4c9882f832ee91e4aa4a
  hostname: gpu011
  info:
    apply_time_ms: 3.159
    dispatch_time_ms: 6.167
    learner:
      cur_lr: 0.0012228039558976889
      grad_gnorm: 38.268863677978516
      policy_entropy: 178.5316619873047
      policy_loss: 16.285842895507812
      var_gnorm: 19.859289169311523
      vf_explained_var: 0.0
      vf_loss: 9.965841293334961
    num_steps_sampled: 2080000
    num_steps_trained: 2080000
    wait_time_ms: 273.585
  iterations_since_restore: 104
  node_ip: 172.17.8.11
  num_metric_batches_dropped: 0
  pid: 25504
  policy_reward_mean: {}
  time_since_restore: 2956.760353088379
  time_this_iter_s: 27.61803960800171
  time_total_s: 2956.760353088379
  timestamp: 1593917224
  timesteps_since_restore: 2080000
  timesteps_this_iter: 20000
  timesteps_total: 2080000
  training_iteration: 104
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=25504], 2956 s, 104 iter, 2080000 ts, 237 rew

agent-1: 33.0
agent-2: 12.0
agent-3: 17.0
agent-4: 23.0
agent-5: 1.0
agent-6: 24.0
agent-7: 20.0
agent-8: 16.0
agent-9: 21.0
agent-10: 9.0
agent-11: 22.0
agent-12: 25.0
agent-13: 17.0
agent-14: 39.0
agent-15: 28.0
agent-16: 16.0
agent-17: 26.0
agent-18: 16.0
agent-19: 10.0
agent-20: -25.0
Sum Reward: 350.0
Avg Reward: 17.5
Min Reward: -25.0
Gini Coefficient: 0.366
20:20 Ratio: -25.2
Max-min Ratio: -1.56
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_22-47-31
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 655.0
  episode_reward_mean: 302.0
  episode_reward_min: -2006.0
  episodes_this_iter: 1
  episodes_total: 104
  experiment_id: 35d66058da2d4c9882f832ee91e4aa4a
  hostname: gpu011
  info:
    apply_time_ms: 2.47
    dispatch_time_ms: 6.761
    learner:
      cur_lr: 0.001221472048200667
      grad_gnorm: 21.94603157043457
      policy_entropy: 182.92697143554688
      policy_loss: -8.241903305053711
      var_gnorm: 19.855335235595703
      vf_explained_var: 0.0
      vf_loss: 0.6595950126647949
    num_steps_sampled: 2100000
    num_steps_trained: 2100000
    wait_time_ms: 266.93
  iterations_since_restore: 105
  node_ip: 172.17.8.11
  num_metric_batches_dropped: 0
  pid: 25504
  policy_reward_mean: {}
  time_since_restore: 2984.0680611133575
  time_this_iter_s: 27.307708024978638
  time_total_s: 2984.0680611133575
  timestamp: 1593917251
  timesteps_since_restore: 2100000
  timesteps_this_iter: 20000
  timesteps_total: 2100000
  training_iteration: 105
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=25504], 2984 s, 105 iter, 2100000 ts, 302 rew

agent-1: 25.0
agent-2: 21.0
agent-3: 21.0
agent-4: 1.0
agent-5: 21.0
agent-6: 23.0
agent-7: 15.0
agent-8: 10.0
agent-9: 20.0
agent-10: 18.0
agent-11: 27.0
agent-12: 5.0
agent-13: 7.0
agent-14: 2.0
agent-15: 17.0
agent-16: 19.0
agent-17: 11.0
agent-18: 27.0
agent-19: 6.0
agent-20: 15.0
Sum Reward: 311.0
Avg Reward: 15.55
Min Reward: 1.0
Gini Coefficient: 0.2895498392282958
20:20 Ratio: 7.285714285714286
Max-min Ratio: 27.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_22-47-59
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 655.0
  episode_reward_mean: 323.97
  episode_reward_min: -2006.0
  episodes_this_iter: 1
  episodes_total: 105
  experiment_id: 35d66058da2d4c9882f832ee91e4aa4a
  hostname: gpu011
  info:
    apply_time_ms: 2.786
    dispatch_time_ms: 6.371
    learner:
      cur_lr: 0.0012201400240883231
      grad_gnorm: 40.0
      policy_entropy: 181.07554626464844
      policy_loss: 29.556293487548828
      var_gnorm: 19.853076934814453
      vf_explained_var: 0.0
      vf_loss: 21.927631378173828
    num_steps_sampled: 2120000
    num_steps_trained: 2120000
    wait_time_ms: 252.085
  iterations_since_restore: 106
  node_ip: 172.17.8.11
  num_metric_batches_dropped: 0
  pid: 25504
  policy_reward_mean: {}
  time_since_restore: 3011.489173412323
  time_this_iter_s: 27.421112298965454
  time_total_s: 3011.489173412323
  timestamp: 1593917279
  timesteps_since_restore: 2120000
  timesteps_this_iter: 20000
  timesteps_total: 2120000
  training_iteration: 106
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=25504], 3011 s, 106 iter, 2120000 ts, 324 rew

agent-1: 25.0
agent-2: 13.0
agent-3: 11.0
agent-4: 9.0
agent-5: 22.0
agent-6: 11.0
agent-7: 11.0
agent-8: 3.0
agent-9: 20.0
agent-10: 9.0
agent-11: 1.0
agent-12: 9.0
agent-13: 26.0
agent-14: 7.0
agent-15: 19.0
agent-16: 5.0
agent-17: 25.0
agent-18: 38.0
agent-19: 13.0
agent-20: 24.0
Sum Reward: 301.0
Avg Reward: 15.05
Min Reward: 1.0
Gini Coefficient: 0.3380398671096346
20:20 Ratio: 7.125
Max-min Ratio: 38.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_22-48-26
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 655.0
  episode_reward_mean: 347.04
  episode_reward_min: -56.0
  episodes_this_iter: 1
  episodes_total: 106
  experiment_id: 35d66058da2d4c9882f832ee91e4aa4a
  hostname: gpu011
  info:
    apply_time_ms: 3.464
    dispatch_time_ms: 7.648
    learner:
      cur_lr: 0.0012188079999759793
      grad_gnorm: 9.545188903808594
      policy_entropy: 180.8006134033203
      policy_loss: -3.706190824508667
      var_gnorm: 19.85862922668457
      vf_explained_var: 0.0
      vf_loss: 2.7513654232025146
    num_steps_sampled: 2140000
    num_steps_trained: 2140000
    wait_time_ms: 273.915
  iterations_since_restore: 107
  node_ip: 172.17.8.11
  num_metric_batches_dropped: 0
  pid: 25504
  policy_reward_mean: {}
  time_since_restore: 3039.061164855957
  time_this_iter_s: 27.571991443634033
  time_total_s: 3039.061164855957
  timestamp: 1593917306
  timesteps_since_restore: 2140000
  timesteps_this_iter: 20000
  timesteps_total: 2140000
  training_iteration: 107
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=25504], 3039 s, 107 iter, 2140000 ts, 347 rew

agent-1: 6.0
agent-2: 1.0
agent-3: 8.0
agent-4: 22.0
agent-5: 12.0
agent-6: 9.0
agent-7: 16.0
agent-8: 16.0
agent-9: 15.0
agent-10: 28.0
agent-11: 5.0
agent-12: 16.0
agent-13: 7.0
agent-14: 20.0
agent-15: -37.0
agent-16: 33.0
agent-17: 13.0
agent-18: 6.0
agent-19: 14.0
agent-20: 14.0
Sum Reward: 224.0
Avg Reward: 11.2
Min Reward: -37.0
Gini Coefficient: 0.5602678571428571
20:20 Ratio: -4.12
Max-min Ratio: -0.8918918918918919
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_22-48-54
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 655.0
  episode_reward_mean: 349.84
  episode_reward_min: 76.0
  episodes_this_iter: 1
  episodes_total: 107
  experiment_id: 35d66058da2d4c9882f832ee91e4aa4a
  hostname: gpu011
  info:
    apply_time_ms: 2.936
    dispatch_time_ms: 6.481
    learner:
      cur_lr: 0.0012174759758636355
      grad_gnorm: 40.000003814697266
      policy_entropy: 179.2239990234375
      policy_loss: 56.5594482421875
      var_gnorm: 19.85866928100586
      vf_explained_var: 1.1920928955078125e-07
      vf_loss: 35.08103942871094
    num_steps_sampled: 2160000
    num_steps_trained: 2160000
    wait_time_ms: 253.063
  iterations_since_restore: 108
  node_ip: 172.17.8.11
  num_metric_batches_dropped: 0
  pid: 25504
  policy_reward_mean: {}
  time_since_restore: 3066.529425382614
  time_this_iter_s: 27.468260526657104
  time_total_s: 3066.529425382614
  timestamp: 1593917334
  timesteps_since_restore: 2160000
  timesteps_this_iter: 20000
  timesteps_total: 2160000
  training_iteration: 108
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=25504], 3066 s, 108 iter, 2160000 ts, 350 rew

agent-1: 10.0
agent-2: 26.0
agent-3: 6.0
agent-4: 15.0
agent-5: 24.0
agent-6: 21.0
agent-7: 14.0
agent-8: 12.0
agent-9: 5.0
agent-10: 12.0
agent-11: 19.0
agent-12: 20.0
agent-13: 14.0
agent-14: 29.0
agent-15: 10.0
agent-16: 11.0
agent-17: 24.0
agent-18: 11.0
agent-19: 9.0
agent-20: 2.0
Sum Reward: 294.0
Avg Reward: 14.7
Min Reward: 2.0
Gini Coefficient: 0.27721088435374147
20:20 Ratio: 4.681818181818182
Max-min Ratio: 14.5
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_22-49-21
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 655.0
  episode_reward_mean: 349.42
  episode_reward_min: 76.0
  episodes_this_iter: 1
  episodes_total: 108
  experiment_id: 35d66058da2d4c9882f832ee91e4aa4a
  hostname: gpu011
  info:
    apply_time_ms: 2.423
    dispatch_time_ms: 5.839
    learner:
      cur_lr: 0.0012161439517512918
      grad_gnorm: 7.771154880523682
      policy_entropy: 143.96478271484375
      policy_loss: 2.437943935394287
      var_gnorm: 19.864341735839844
      vf_explained_var: 0.0
      vf_loss: 10.378754615783691
    num_steps_sampled: 2180000
    num_steps_trained: 2180000
    wait_time_ms: 262.632
  iterations_since_restore: 109
  node_ip: 172.17.8.11
  num_metric_batches_dropped: 0
  pid: 25504
  policy_reward_mean: {}
  time_since_restore: 3093.8484025001526
  time_this_iter_s: 27.318977117538452
  time_total_s: 3093.8484025001526
  timestamp: 1593917361
  timesteps_since_restore: 2180000
  timesteps_this_iter: 20000
  timesteps_total: 2180000
  training_iteration: 109
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=25504], 3093 s, 109 iter, 2180000 ts, 349 rew

agent-1: 16.0
agent-2: 11.0
agent-3: 10.0
agent-4: 22.0
agent-5: 15.0
agent-6: 13.0
agent-7: 16.0
agent-8: 14.0
agent-9: 8.0
agent-10: 38.0
agent-11: 7.0
agent-12: 21.0
agent-13: 28.0
agent-14: 21.0
agent-15: 5.0
agent-16: 5.0
agent-17: 6.0
agent-18: 12.0
agent-19: 6.0
agent-20: 5.0
Sum Reward: 279.0
Avg Reward: 13.95
Min Reward: 5.0
Gini Coefficient: 0.3234767025089606
20:20 Ratio: 5.190476190476191
Max-min Ratio: 7.6
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_22-49-49
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 655.0
  episode_reward_mean: 348.83
  episode_reward_min: 76.0
  episodes_this_iter: 1
  episodes_total: 109
  experiment_id: 35d66058da2d4c9882f832ee91e4aa4a
  hostname: gpu011
  info:
    apply_time_ms: 2.621
    dispatch_time_ms: 6.617
    learner:
      cur_lr: 0.0012148120440542698
      grad_gnorm: 10.249979972839355
      policy_entropy: 130.8731231689453
      policy_loss: -1.9121086597442627
      var_gnorm: 19.861257553100586
      vf_explained_var: 0.0
      vf_loss: 0.042416203767061234
    num_steps_sampled: 2200000
    num_steps_trained: 2200000
    wait_time_ms: 270.822
  iterations_since_restore: 110
  node_ip: 172.17.8.11
  num_metric_batches_dropped: 0
  pid: 25504
  policy_reward_mean: {}
  time_since_restore: 3121.587872982025
  time_this_iter_s: 27.73947048187256
  time_total_s: 3121.587872982025
  timestamp: 1593917389
  timesteps_since_restore: 2200000
  timesteps_this_iter: 20000
  timesteps_total: 2200000
  training_iteration: 110
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=25504], 3121 s, 110 iter, 2200000 ts, 349 rew

agent-1: 42.0
agent-2: 22.0
agent-3: 17.0
agent-4: 10.0
agent-5: 22.0
agent-6: 32.0
agent-7: 19.0
agent-8: 27.0
agent-9: 31.0
agent-10: 20.0
agent-11: 14.0
agent-12: 22.0
agent-13: 14.0
agent-14: 27.0
agent-15: 13.0
agent-16: 15.0
agent-17: 22.0
agent-18: 29.0
agent-19: 32.0
agent-20: 30.0
Sum Reward: 460.0
Avg Reward: 23.0
Min Reward: 10.0
Gini Coefficient: 0.1941304347826087
20:20 Ratio: 2.6862745098039214
Max-min Ratio: 4.2
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_22-50-16
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 655.0
  episode_reward_mean: 352.34
  episode_reward_min: 76.0
  episodes_this_iter: 1
  episodes_total: 110
  experiment_id: 35d66058da2d4c9882f832ee91e4aa4a
  hostname: gpu011
  info:
    apply_time_ms: 2.903
    dispatch_time_ms: 6.544
    learner:
      cur_lr: 0.001213480019941926
      grad_gnorm: 35.54233169555664
      policy_entropy: 110.09001922607422
      policy_loss: -9.637643814086914
      var_gnorm: 19.862829208374023
      vf_explained_var: 0.0
      vf_loss: 0.49360567331314087
    num_steps_sampled: 2220000
    num_steps_trained: 2220000
    wait_time_ms: 271.934
  iterations_since_restore: 111
  node_ip: 172.17.8.11
  num_metric_batches_dropped: 0
  pid: 25504
  policy_reward_mean: {}
  time_since_restore: 3148.8712458610535
  time_this_iter_s: 27.28337287902832
  time_total_s: 3148.8712458610535
  timestamp: 1593917416
  timesteps_since_restore: 2220000
  timesteps_this_iter: 20000
  timesteps_total: 2220000
  training_iteration: 111
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=25504], 3148 s, 111 iter, 2220000 ts, 352 rew

agent-1: 19.0
agent-2: 10.0
agent-3: 17.0
agent-4: 27.0
agent-5: 16.0
agent-6: 18.0
agent-7: 6.0
agent-8: 24.0
agent-9: 29.0
agent-10: 54.0
agent-11: 11.0
agent-12: 30.0
agent-13: 5.0
agent-14: 19.0
agent-15: 8.0
agent-16: 8.0
agent-17: 8.0
agent-18: 14.0
agent-19: 7.0
agent-20: 22.0
Sum Reward: 352.0
Avg Reward: 17.6
Min Reward: 5.0
Gini Coefficient: 0.3315340909090909
20:20 Ratio: 5.384615384615385
Max-min Ratio: 10.8
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_22-50-44
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 655.0
  episode_reward_mean: 355.1
  episode_reward_min: 181.0
  episodes_this_iter: 1
  episodes_total: 111
  experiment_id: 35d66058da2d4c9882f832ee91e4aa4a
  hostname: gpu011
  info:
    apply_time_ms: 3.656
    dispatch_time_ms: 7.701
    learner:
      cur_lr: 0.0012121479958295822
      grad_gnorm: 40.0
      policy_entropy: 116.82396697998047
      policy_loss: 54.25630187988281
      var_gnorm: 19.860942840576172
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 52.39178466796875
    num_steps_sampled: 2240000
    num_steps_trained: 2240000
    wait_time_ms: 263.748
  iterations_since_restore: 112
  node_ip: 172.17.8.11
  num_metric_batches_dropped: 0
  pid: 25504
  policy_reward_mean: {}
  time_since_restore: 3176.473775625229
  time_this_iter_s: 27.602529764175415
  time_total_s: 3176.473775625229
  timestamp: 1593917444
  timesteps_since_restore: 2240000
  timesteps_this_iter: 20000
  timesteps_total: 2240000
  training_iteration: 112
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=25504], 3176 s, 112 iter, 2240000 ts, 355 rew

agent-1: 11.0
agent-2: 18.0
agent-3: 13.0
agent-4: 16.0
agent-5: 11.0
agent-6: 16.0
agent-7: 11.0
agent-8: 17.0
agent-9: 13.0
agent-10: 6.0
agent-11: 21.0
agent-12: 24.0
agent-13: 16.0
agent-14: 17.0
agent-15: 15.0
agent-16: 15.0
agent-17: 25.0
agent-18: 9.0
agent-19: 30.0
agent-20: 14.0
Sum Reward: 318.0
Avg Reward: 15.9
Min Reward: 6.0
Gini Coefficient: 0.189937106918239
20:20 Ratio: 2.7027027027027026
Max-min Ratio: 5.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_22-51-11
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 655.0
  episode_reward_mean: 354.68
  episode_reward_min: 181.0
  episodes_this_iter: 1
  episodes_total: 112
  experiment_id: 35d66058da2d4c9882f832ee91e4aa4a
  hostname: gpu011
  info:
    apply_time_ms: 2.799
    dispatch_time_ms: 6.287
    learner:
      cur_lr: 0.0012108159717172384
      grad_gnorm: 32.927215576171875
      policy_entropy: 204.3190155029297
      policy_loss: -13.339844703674316
      var_gnorm: 19.857118606567383
      vf_explained_var: 5.960464477539063e-08
      vf_loss: 0.43590277433395386
    num_steps_sampled: 2260000
    num_steps_trained: 2260000
    wait_time_ms: 273.674
  iterations_since_restore: 113
  node_ip: 172.17.8.11
  num_metric_batches_dropped: 0
  pid: 25504
  policy_reward_mean: {}
  time_since_restore: 3203.616868019104
  time_this_iter_s: 27.143092393875122
  time_total_s: 3203.616868019104
  timestamp: 1593917471
  timesteps_since_restore: 2260000
  timesteps_this_iter: 20000
  timesteps_total: 2260000
  training_iteration: 113
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=25504], 3203 s, 113 iter, 2260000 ts, 355 rew

agent-1: 38.0
agent-2: 23.0
agent-3: 8.0
agent-4: 19.0
agent-5: 17.0
agent-6: 11.0
agent-7: 27.0
agent-8: 21.0
agent-9: 6.0
agent-10: 19.0
agent-11: 14.0
agent-12: 29.0
agent-13: 13.0
agent-14: 24.0
agent-15: 21.0
agent-16: 19.0
agent-17: 24.0
agent-18: 10.0
agent-19: 15.0
agent-20: 25.0
Sum Reward: 383.0
Avg Reward: 19.15
Min Reward: 6.0
Gini Coefficient: 0.2212793733681462
20:20 Ratio: 3.4
Max-min Ratio: 6.333333333333333
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_22-51-38
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 655.0
  episode_reward_mean: 355.58
  episode_reward_min: 181.0
  episodes_this_iter: 1
  episodes_total: 113
  experiment_id: 35d66058da2d4c9882f832ee91e4aa4a
  hostname: gpu011
  info:
    apply_time_ms: 3.426
    dispatch_time_ms: 7.268
    learner:
      cur_lr: 0.0012094839476048946
      grad_gnorm: 11.740819931030273
      policy_entropy: 201.24510192871094
      policy_loss: -3.038510799407959
      var_gnorm: 19.854291915893555
      vf_explained_var: 0.0
      vf_loss: 0.054546281695365906
    num_steps_sampled: 2280000
    num_steps_trained: 2280000
    wait_time_ms: 262.245
  iterations_since_restore: 114
  node_ip: 172.17.8.11
  num_metric_batches_dropped: 0
  pid: 25504
  policy_reward_mean: {}
  time_since_restore: 3231.113925933838
  time_this_iter_s: 27.497057914733887
  time_total_s: 3231.113925933838
  timestamp: 1593917498
  timesteps_since_restore: 2280000
  timesteps_this_iter: 20000
  timesteps_total: 2280000
  training_iteration: 114
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=25504], 3231 s, 114 iter, 2280000 ts, 356 rew

agent-1: 15.0
agent-2: 6.0
agent-3: 35.0
agent-4: 19.0
agent-5: 15.0
agent-6: 12.0
agent-7: 14.0
agent-8: 16.0
agent-9: 16.0
agent-10: 6.0
agent-11: 9.0
agent-12: 7.0
agent-13: 12.0
agent-14: 8.0
agent-15: 17.0
agent-16: 22.0
agent-17: 11.0
agent-18: 9.0
agent-19: 5.0
agent-20: 3.0
Sum Reward: 257.0
Avg Reward: 12.85
Min Reward: 3.0
Gini Coefficient: 0.28929961089494166
20:20 Ratio: 4.65
Max-min Ratio: 11.666666666666666
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_22-52-06
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 655.0
  episode_reward_mean: 355.03
  episode_reward_min: 181.0
  episodes_this_iter: 1
  episodes_total: 114
  experiment_id: 35d66058da2d4c9882f832ee91e4aa4a
  hostname: gpu011
  info:
    apply_time_ms: 3.886
    dispatch_time_ms: 5.614
    learner:
      cur_lr: 0.0012081520399078727
      grad_gnorm: 24.150529861450195
      policy_entropy: 173.0271759033203
      policy_loss: -8.563705444335938
      var_gnorm: 19.857572555541992
      vf_explained_var: -2.384185791015625e-07
      vf_loss: 0.22856676578521729
    num_steps_sampled: 2300000
    num_steps_trained: 2300000
    wait_time_ms: 278.547
  iterations_since_restore: 115
  node_ip: 172.17.8.11
  num_metric_batches_dropped: 0
  pid: 25504
  policy_reward_mean: {}
  time_since_restore: 3258.5550327301025
  time_this_iter_s: 27.44110679626465
  time_total_s: 3258.5550327301025
  timestamp: 1593917526
  timesteps_since_restore: 2300000
  timesteps_this_iter: 20000
  timesteps_total: 2300000
  training_iteration: 115
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=25504], 3258 s, 115 iter, 2300000 ts, 355 rew

agent-1: 15.0
agent-2: 21.0
agent-3: 21.0
agent-4: 23.0
agent-5: 22.0
agent-6: 26.0
agent-7: 18.0
agent-8: 9.0
agent-9: 10.0
agent-10: 21.0
agent-11: 14.0
agent-12: 6.0
agent-13: 21.0
agent-14: 7.0
agent-15: 15.0
agent-16: 3.0
agent-17: 16.0
agent-18: 12.0
agent-19: 17.0
agent-20: 1.0
Sum Reward: 298.0
Avg Reward: 14.9
Min Reward: 1.0
Gini Coefficient: 0.2614093959731544
20:20 Ratio: 5.411764705882353
Max-min Ratio: 26.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_22-52-34
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 655.0
  episode_reward_mean: 354.02
  episode_reward_min: 181.0
  episodes_this_iter: 1
  episodes_total: 115
  experiment_id: 35d66058da2d4c9882f832ee91e4aa4a
  hostname: gpu011
  info:
    apply_time_ms: 3.436
    dispatch_time_ms: 8.857
    learner:
      cur_lr: 0.0012068200157955289
      grad_gnorm: 40.0
      policy_entropy: 172.5380096435547
      policy_loss: 28.54285430908203
      var_gnorm: 19.857044219970703
      vf_explained_var: -2.384185791015625e-07
      vf_loss: 38.198883056640625
    num_steps_sampled: 2320000
    num_steps_trained: 2320000
    wait_time_ms: 259.825
  iterations_since_restore: 116
  node_ip: 172.17.8.11
  num_metric_batches_dropped: 0
  pid: 25504
  policy_reward_mean: {}
  time_since_restore: 3286.129086971283
  time_this_iter_s: 27.57405424118042
  time_total_s: 3286.129086971283
  timestamp: 1593917554
  timesteps_since_restore: 2320000
  timesteps_this_iter: 20000
  timesteps_total: 2320000
  training_iteration: 116
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=25504], 3286 s, 116 iter, 2320000 ts, 354 rew

agent-1: 15.0
agent-2: 11.0
agent-3: 14.0
agent-4: 17.0
agent-5: 30.0
agent-6: 12.0
agent-7: 4.0
agent-8: 16.0
agent-9: 8.0
agent-10: 24.0
agent-11: 13.0
agent-12: 20.0
agent-13: 31.0
agent-14: 13.0
agent-15: 10.0
agent-16: 9.0
agent-17: 25.0
agent-18: 5.0
agent-19: 9.0
agent-20: 11.0
Sum Reward: 297.0
Avg Reward: 14.85
Min Reward: 4.0
Gini Coefficient: 0.2749158249158249
20:20 Ratio: 4.230769230769231
Max-min Ratio: 7.75
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_22-53-01
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 655.0
  episode_reward_mean: 353.91
  episode_reward_min: 181.0
  episodes_this_iter: 1
  episodes_total: 116
  experiment_id: 35d66058da2d4c9882f832ee91e4aa4a
  hostname: gpu011
  info:
    apply_time_ms: 2.431
    dispatch_time_ms: 8.156
    learner:
      cur_lr: 0.001205487991683185
      grad_gnorm: 11.306640625
      policy_entropy: 182.62860107421875
      policy_loss: -4.415617942810059
      var_gnorm: 19.86356544494629
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 1.8977386951446533
    num_steps_sampled: 2340000
    num_steps_trained: 2340000
    wait_time_ms: 267.573
  iterations_since_restore: 117
  node_ip: 172.17.8.11
  num_metric_batches_dropped: 0
  pid: 25504
  policy_reward_mean: {}
  time_since_restore: 3313.5734844207764
  time_this_iter_s: 27.444397449493408
  time_total_s: 3313.5734844207764
  timestamp: 1593917581
  timesteps_since_restore: 2340000
  timesteps_this_iter: 20000
  timesteps_total: 2340000
  training_iteration: 117
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=25504], 3313 s, 117 iter, 2340000 ts, 354 rew

agent-1: 16.0
agent-2: 11.0
agent-3: 17.0
agent-4: 12.0
agent-5: 24.0
agent-6: 25.0
agent-7: 11.0
agent-8: 34.0
agent-9: 30.0
agent-10: 40.0
agent-11: 6.0
agent-12: 15.0
agent-13: 12.0
agent-14: 2.0
agent-15: 11.0
agent-16: 19.0
agent-17: 11.0
agent-18: 18.0
agent-19: 18.0
agent-20: 17.0
Sum Reward: 349.0
Avg Reward: 17.45
Min Reward: 2.0
Gini Coefficient: 0.28065902578796564
20:20 Ratio: 4.3
Max-min Ratio: 20.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_22-53-28
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 655.0
  episode_reward_mean: 353.38
  episode_reward_min: 181.0
  episodes_this_iter: 1
  episodes_total: 117
  experiment_id: 35d66058da2d4c9882f832ee91e4aa4a
  hostname: gpu011
  info:
    apply_time_ms: 3.002
    dispatch_time_ms: 8.101
    learner:
      cur_lr: 0.0012041559675708413
      grad_gnorm: 15.31838321685791
      policy_entropy: 159.04046630859375
      policy_loss: -3.5647778511047363
      var_gnorm: 19.863473892211914
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 0.09292881935834885
    num_steps_sampled: 2360000
    num_steps_trained: 2360000
    wait_time_ms: 265.423
  iterations_since_restore: 118
  node_ip: 172.17.8.11
  num_metric_batches_dropped: 0
  pid: 25504
  policy_reward_mean: {}
  time_since_restore: 3340.98447060585
  time_this_iter_s: 27.410986185073853
  time_total_s: 3340.98447060585
  timestamp: 1593917608
  timesteps_since_restore: 2360000
  timesteps_this_iter: 20000
  timesteps_total: 2360000
  training_iteration: 118
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=25504], 3340 s, 118 iter, 2360000 ts, 353 rew

agent-1: 26.0
agent-2: 24.0
agent-3: 10.0
agent-4: 17.0
agent-5: 26.0
agent-6: 24.0
agent-7: 25.0
agent-8: 16.0
agent-9: 13.0
agent-10: 14.0
agent-11: 20.0
agent-12: 9.0
agent-13: 4.0
agent-14: 15.0
agent-15: 17.0
agent-16: 18.0
agent-17: 21.0
agent-18: 5.0
agent-19: 13.0
agent-20: 10.0
Sum Reward: 327.0
Avg Reward: 16.35
Min Reward: 4.0
Gini Coefficient: 0.22920489296636085
20:20 Ratio: 3.607142857142857
Max-min Ratio: 6.5
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_22-53-56
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 655.0
  episode_reward_mean: 352.66
  episode_reward_min: 181.0
  episodes_this_iter: 1
  episodes_total: 118
  experiment_id: 35d66058da2d4c9882f832ee91e4aa4a
  hostname: gpu011
  info:
    apply_time_ms: 2.971
    dispatch_time_ms: 8.668
    learner:
      cur_lr: 0.0012028239434584975
      grad_gnorm: 28.593528747558594
      policy_entropy: 172.7194366455078
      policy_loss: -11.05745792388916
      var_gnorm: 19.858745574951172
      vf_explained_var: 5.960464477539063e-08
      vf_loss: 0.3301863670349121
    num_steps_sampled: 2380000
    num_steps_trained: 2380000
    wait_time_ms: 260.875
  iterations_since_restore: 119
  node_ip: 172.17.8.11
  num_metric_batches_dropped: 0
  pid: 25504
  policy_reward_mean: {}
  time_since_restore: 3368.231377840042
  time_this_iter_s: 27.246907234191895
  time_total_s: 3368.231377840042
  timestamp: 1593917636
  timesteps_since_restore: 2380000
  timesteps_this_iter: 20000
  timesteps_total: 2380000
  training_iteration: 119
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=25504], 3368 s, 119 iter, 2380000 ts, 353 rew

agent-1: 26.0
agent-2: 33.0
agent-3: 25.0
agent-4: 24.0
agent-5: 16.0
agent-6: 36.0
agent-7: 18.0
agent-8: 19.0
agent-9: 16.0
agent-10: 16.0
agent-11: 36.0
agent-12: 25.0
agent-13: 26.0
agent-14: 14.0
agent-15: 36.0
agent-16: 11.0
agent-17: 27.0
agent-18: 19.0
agent-19: 23.0
agent-20: 15.0
Sum Reward: 461.0
Avg Reward: 23.05
Min Reward: 11.0
Gini Coefficient: 0.18449023861171365
20:20 Ratio: 2.517857142857143
Max-min Ratio: 3.272727272727273
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_22-54-23
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 655.0
  episode_reward_mean: 352.17
  episode_reward_min: 181.0
  episodes_this_iter: 1
  episodes_total: 119
  experiment_id: 35d66058da2d4c9882f832ee91e4aa4a
  hostname: gpu011
  info:
    apply_time_ms: 2.962
    dispatch_time_ms: 6.236
    learner:
      cur_lr: 0.0012014920357614756
      grad_gnorm: 39.999996185302734
      policy_entropy: 176.23216247558594
      policy_loss: 41.18080139160156
      var_gnorm: 19.857318878173828
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 51.72303771972656
    num_steps_sampled: 2400000
    num_steps_trained: 2400000
    wait_time_ms: 252.823
  iterations_since_restore: 120
  node_ip: 172.17.8.11
  num_metric_batches_dropped: 0
  pid: 25504
  policy_reward_mean: {}
  time_since_restore: 3395.6617403030396
  time_this_iter_s: 27.430362462997437
  time_total_s: 3395.6617403030396
  timestamp: 1593917663
  timesteps_since_restore: 2400000
  timesteps_this_iter: 20000
  timesteps_total: 2400000
  training_iteration: 120
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=25504], 3395 s, 120 iter, 2400000 ts, 352 rew

agent-1: 4.0
agent-2: 16.0
agent-3: 15.0
agent-4: 15.0
agent-5: 10.0
agent-6: 13.0
agent-7: 26.0
agent-8: 11.0
agent-9: 19.0
agent-10: 5.0
agent-11: 18.0
agent-12: 23.0
agent-13: 7.0
agent-14: 7.0
agent-15: 18.0
agent-16: 18.0
agent-17: 6.0
agent-18: 9.0
agent-19: 14.0
agent-20: 15.0
Sum Reward: 269.0
Avg Reward: 13.45
Min Reward: 4.0
Gini Coefficient: 0.24776951672862454
20:20 Ratio: 3.909090909090909
Max-min Ratio: 6.5
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_22-54-50
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 655.0
  episode_reward_mean: 350.45
  episode_reward_min: 181.0
  episodes_this_iter: 1
  episodes_total: 120
  experiment_id: 35d66058da2d4c9882f832ee91e4aa4a
  hostname: gpu011
  info:
    apply_time_ms: 3.799
    dispatch_time_ms: 7.347
    learner:
      cur_lr: 0.0012001600116491318
      grad_gnorm: 19.05988311767578
      policy_entropy: 175.99664306640625
      policy_loss: -0.5400197505950928
      var_gnorm: 19.872629165649414
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 6.939313888549805
    num_steps_sampled: 2420000
    num_steps_trained: 2420000
    wait_time_ms: 267.244
  iterations_since_restore: 121
  node_ip: 172.17.8.11
  num_metric_batches_dropped: 0
  pid: 25504
  policy_reward_mean: {}
  time_since_restore: 3422.6772027015686
  time_this_iter_s: 27.015462398529053
  time_total_s: 3422.6772027015686
  timestamp: 1593917690
  timesteps_since_restore: 2420000
  timesteps_this_iter: 20000
  timesteps_total: 2420000
  training_iteration: 121
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=25504], 3422 s, 121 iter, 2420000 ts, 350 rew

agent-1: 28.0
agent-2: 16.0
agent-3: 20.0
agent-4: 9.0
agent-5: 20.0
agent-6: 27.0
agent-7: 29.0
agent-8: 30.0
agent-9: 9.0
agent-10: 21.0
agent-11: 8.0
agent-12: 20.0
agent-13: 19.0
agent-14: 29.0
agent-15: 19.0
agent-16: 22.0
agent-17: 46.0
agent-18: 31.0
agent-19: 5.0
agent-20: 30.0
Sum Reward: 438.0
Avg Reward: 21.9
Min Reward: 5.0
Gini Coefficient: 0.23926940639269406
20:20 Ratio: 4.419354838709677
Max-min Ratio: 9.2
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_22-55-18
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 655.0
  episode_reward_mean: 349.62
  episode_reward_min: 181.0
  episodes_this_iter: 1
  episodes_total: 121
  experiment_id: 35d66058da2d4c9882f832ee91e4aa4a
  hostname: gpu011
  info:
    apply_time_ms: 3.443
    dispatch_time_ms: 6.076
    learner:
      cur_lr: 0.001198827987536788
      grad_gnorm: 27.72835350036621
      policy_entropy: 168.39585876464844
      policy_loss: 1.7803714275360107
      var_gnorm: 19.871150970458984
      vf_explained_var: 5.960464477539063e-08
      vf_loss: 9.733237266540527
    num_steps_sampled: 2440000
    num_steps_trained: 2440000
    wait_time_ms: 261.52
  iterations_since_restore: 122
  node_ip: 172.17.8.11
  num_metric_batches_dropped: 0
  pid: 25504
  policy_reward_mean: {}
  time_since_restore: 3450.2566287517548
  time_this_iter_s: 27.579426050186157
  time_total_s: 3450.2566287517548
  timestamp: 1593917718
  timesteps_since_restore: 2440000
  timesteps_this_iter: 20000
  timesteps_total: 2440000
  training_iteration: 122
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=25504], 3450 s, 122 iter, 2440000 ts, 350 rew

agent-1: 15.0
agent-2: 22.0
agent-3: 15.0
agent-4: 19.0
agent-5: 19.0
agent-6: 26.0
agent-7: 11.0
agent-8: 40.0
agent-9: 29.0
agent-10: 23.0
agent-11: 29.0
agent-12: 17.0
agent-13: 23.0
agent-14: 19.0
agent-15: 3.0
agent-16: 11.0
agent-17: 40.0
agent-18: 17.0
agent-19: 15.0
agent-20: 13.0
Sum Reward: 406.0
Avg Reward: 20.3
Min Reward: 3.0
Gini Coefficient: 0.24064039408866994
20:20 Ratio: 3.6315789473684212
Max-min Ratio: 13.333333333333334
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_22-55-45
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 655.0
  episode_reward_mean: 349.2
  episode_reward_min: 181.0
  episodes_this_iter: 1
  episodes_total: 122
  experiment_id: 35d66058da2d4c9882f832ee91e4aa4a
  hostname: gpu011
  info:
    apply_time_ms: 2.977
    dispatch_time_ms: 5.598
    learner:
      cur_lr: 0.0011974959634244442
      grad_gnorm: 40.0
      policy_entropy: 184.6000518798828
      policy_loss: 14.055070877075195
      var_gnorm: 19.878511428833008
      vf_explained_var: 5.960464477539063e-08
      vf_loss: 37.93154525756836
    num_steps_sampled: 2460000
    num_steps_trained: 2460000
    wait_time_ms: 267.542
  iterations_since_restore: 123
  node_ip: 172.17.8.11
  num_metric_batches_dropped: 0
  pid: 25504
  policy_reward_mean: {}
  time_since_restore: 3477.1665954589844
  time_this_iter_s: 26.909966707229614
  time_total_s: 3477.1665954589844
  timestamp: 1593917745
  timesteps_since_restore: 2460000
  timesteps_this_iter: 20000
  timesteps_total: 2460000
  training_iteration: 123
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=25504], 3477 s, 123 iter, 2460000 ts, 349 rew

agent-1: 21.0
agent-2: 26.0
agent-3: 14.0
agent-4: 33.0
agent-5: 10.0
agent-6: 12.0
agent-7: 14.0
agent-8: 34.0
agent-9: 33.0
agent-10: 29.0
agent-11: 44.0
agent-12: 20.0
agent-13: 25.0
agent-14: 20.0
agent-15: 22.0
agent-16: 17.0
agent-17: 19.0
agent-18: 25.0
agent-19: 21.0
agent-20: 34.0
Sum Reward: 473.0
Avg Reward: 23.65
Min Reward: 10.0
Gini Coefficient: 0.2022198731501057
20:20 Ratio: 2.9
Max-min Ratio: 4.4
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_22-56-12
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 655.0
  episode_reward_mean: 349.66
  episode_reward_min: 181.0
  episodes_this_iter: 1
  episodes_total: 123
  experiment_id: 35d66058da2d4c9882f832ee91e4aa4a
  hostname: gpu011
  info:
    apply_time_ms: 2.933
    dispatch_time_ms: 5.954
    learner:
      cur_lr: 0.0011961640557274222
      grad_gnorm: 25.988773345947266
      policy_entropy: 167.11209106445312
      policy_loss: -7.068669319152832
      var_gnorm: 19.877506256103516
      vf_explained_var: 0.0
      vf_loss: 0.2724878191947937
    num_steps_sampled: 2480000
    num_steps_trained: 2480000
    wait_time_ms: 279.4
  iterations_since_restore: 124
  node_ip: 172.17.8.11
  num_metric_batches_dropped: 0
  pid: 25504
  policy_reward_mean: {}
  time_since_restore: 3504.642854452133
  time_this_iter_s: 27.476258993148804
  time_total_s: 3504.642854452133
  timestamp: 1593917772
  timesteps_since_restore: 2480000
  timesteps_this_iter: 20000
  timesteps_total: 2480000
  training_iteration: 124
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=25504], 3504 s, 124 iter, 2480000 ts, 350 rew

agent-1: 14.0
agent-2: 17.0
agent-3: 31.0
agent-4: 32.0
agent-5: 32.0
agent-6: 17.0
agent-7: 11.0
agent-8: 17.0
agent-9: 16.0
agent-10: 22.0
agent-11: 30.0
agent-12: 11.0
agent-13: 28.0
agent-14: 18.0
agent-15: 8.0
agent-16: 6.0
agent-17: 17.0
agent-18: 33.0
agent-19: 14.0
agent-20: 27.0
Sum Reward: 401.0
Avg Reward: 20.05
Min Reward: 6.0
Gini Coefficient: 0.23728179551122194
20:20 Ratio: 3.5555555555555554
Max-min Ratio: 5.5
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_22-56-40
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 655.0
  episode_reward_mean: 349.74
  episode_reward_min: 181.0
  episodes_this_iter: 1
  episodes_total: 124
  experiment_id: 35d66058da2d4c9882f832ee91e4aa4a
  hostname: gpu011
  info:
    apply_time_ms: 3.229
    dispatch_time_ms: 6.57
    learner:
      cur_lr: 0.0011948320316150784
      grad_gnorm: 18.26339340209961
      policy_entropy: 183.1560821533203
      policy_loss: -8.081808090209961
      var_gnorm: 19.874616622924805
      vf_explained_var: 0.0
      vf_loss: 1.5235576629638672
    num_steps_sampled: 2500000
    num_steps_trained: 2500000
    wait_time_ms: 271.188
  iterations_since_restore: 125
  node_ip: 172.17.8.11
  num_metric_batches_dropped: 0
  pid: 25504
  policy_reward_mean: {}
  time_since_restore: 3532.219467163086
  time_this_iter_s: 27.57661271095276
  time_total_s: 3532.219467163086
  timestamp: 1593917800
  timesteps_since_restore: 2500000
  timesteps_this_iter: 20000
  timesteps_total: 2500000
  training_iteration: 125
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=25504], 3532 s, 125 iter, 2500000 ts, 350 rew

agent-1: 26.0
agent-2: 26.0
agent-3: 18.0
agent-4: 21.0
agent-5: 12.0
agent-6: 8.0
agent-7: 9.0
agent-8: 16.0
agent-9: 17.0
agent-10: 6.0
agent-11: 13.0
agent-12: 18.0
agent-13: 13.0
agent-14: 10.0
agent-15: 19.0
agent-16: 18.0
agent-17: 25.0
agent-18: 20.0
agent-19: 34.0
agent-20: 13.0
Sum Reward: 342.0
Avg Reward: 17.1
Min Reward: 6.0
Gini Coefficient: 0.22280701754385965
20:20 Ratio: 3.3636363636363638
Max-min Ratio: 5.666666666666667
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_22-57-08
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 655.0
  episode_reward_mean: 350.45
  episode_reward_min: 181.0
  episodes_this_iter: 1
  episodes_total: 125
  experiment_id: 35d66058da2d4c9882f832ee91e4aa4a
  hostname: gpu011
  info:
    apply_time_ms: 4.208
    dispatch_time_ms: 6.244
    learner:
      cur_lr: 0.0011935000075027347
      grad_gnorm: 17.238893508911133
      policy_entropy: 189.26837158203125
      policy_loss: -5.0399580001831055
      var_gnorm: 19.87800407409668
      vf_explained_var: 1.1920928955078125e-07
      vf_loss: 0.11830876767635345
    num_steps_sampled: 2520000
    num_steps_trained: 2520000
    wait_time_ms: 264.001
  iterations_since_restore: 126
  node_ip: 172.17.8.11
  num_metric_batches_dropped: 0
  pid: 25504
  policy_reward_mean: {}
  time_since_restore: 3559.702919483185
  time_this_iter_s: 27.483452320098877
  time_total_s: 3559.702919483185
  timestamp: 1593917828
  timesteps_since_restore: 2520000
  timesteps_this_iter: 20000
  timesteps_total: 2520000
  training_iteration: 126
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=25504], 3559 s, 126 iter, 2520000 ts, 350 rew

agent-1: 4.0
agent-2: 3.0
agent-3: 11.0
agent-4: 9.0
agent-5: 31.0
agent-6: 9.0
agent-7: 16.0
agent-8: 22.0
agent-9: 11.0
agent-10: 6.0
agent-11: 17.0
agent-12: 23.0
agent-13: 10.0
agent-14: 15.0
agent-15: 12.0
agent-16: 8.0
agent-17: 9.0
agent-18: 6.0
agent-19: 7.0
agent-20: 9.0
Sum Reward: 238.0
Avg Reward: 11.9
Min Reward: 3.0
Gini Coefficient: 0.30210084033613444
20:20 Ratio: 4.894736842105263
Max-min Ratio: 10.333333333333334
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_22-57-35
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 655.0
  episode_reward_mean: 348.16
  episode_reward_min: 181.0
  episodes_this_iter: 1
  episodes_total: 126
  experiment_id: 35d66058da2d4c9882f832ee91e4aa4a
  hostname: gpu011
  info:
    apply_time_ms: 2.592
    dispatch_time_ms: 8.079
    learner:
      cur_lr: 0.0011921679833903909
      grad_gnorm: 19.476600646972656
      policy_entropy: 154.8257293701172
      policy_loss: 4.879672050476074
      var_gnorm: 19.87807273864746
      vf_explained_var: 0.0
      vf_loss: 10.317919731140137
    num_steps_sampled: 2540000
    num_steps_trained: 2540000
    wait_time_ms: 266.633
  iterations_since_restore: 127
  node_ip: 172.17.8.11
  num_metric_batches_dropped: 0
  pid: 25504
  policy_reward_mean: {}
  time_since_restore: 3586.144228696823
  time_this_iter_s: 26.441309213638306
  time_total_s: 3586.144228696823
  timestamp: 1593917855
  timesteps_since_restore: 2540000
  timesteps_this_iter: 20000
  timesteps_total: 2540000
  training_iteration: 127
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=25504], 3586 s, 127 iter, 2540000 ts, 348 rew

agent-1: 10.0
agent-2: 16.0
agent-3: 17.0
agent-4: 10.0
agent-5: 9.0
agent-6: 0.0
agent-7: 14.0
agent-8: 18.0
agent-9: 12.0
agent-10: 13.0
agent-11: 26.0
agent-12: 18.0
agent-13: 19.0
agent-14: 10.0
agent-15: 19.0
agent-16: 26.0
agent-17: 19.0
agent-18: 14.0
agent-19: 14.0
agent-20: 9.0
Sum Reward: 293.0
Avg Reward: 14.65
Min Reward: 0.0
Gini Coefficient: 0.21996587030716724
20:20 Ratio: 3.2142857142857144
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_22-58-02
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 655.0
  episode_reward_mean: 348.48
  episode_reward_min: 181.0
  episodes_this_iter: 1
  episodes_total: 127
  experiment_id: 35d66058da2d4c9882f832ee91e4aa4a
  hostname: gpu011
  info:
    apply_time_ms: 2.729
    dispatch_time_ms: 6.574
    learner:
      cur_lr: 0.001190835959278047
      grad_gnorm: 17.78795623779297
      policy_entropy: 182.78578186035156
      policy_loss: -4.685858726501465
      var_gnorm: 19.872995376586914
      vf_explained_var: 0.0
      vf_loss: 0.12782113254070282
    num_steps_sampled: 2560000
    num_steps_trained: 2560000
    wait_time_ms: 261.249
  iterations_since_restore: 128
  node_ip: 172.17.8.11
  num_metric_batches_dropped: 0
  pid: 25504
  policy_reward_mean: {}
  time_since_restore: 3613.7152309417725
  time_this_iter_s: 27.57100224494934
  time_total_s: 3613.7152309417725
  timestamp: 1593917882
  timesteps_since_restore: 2560000
  timesteps_this_iter: 20000
  timesteps_total: 2560000
  training_iteration: 128
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=25504], 3613 s, 128 iter, 2560000 ts, 348 rew

agent-1: 3.0
agent-2: 7.0
agent-3: 27.0
agent-4: 27.0
agent-5: 15.0
agent-6: 33.0
agent-7: 17.0
agent-8: 18.0
agent-9: 11.0
agent-10: 22.0
agent-11: 16.0
agent-12: 10.0
agent-13: 22.0
agent-14: 12.0
agent-15: 16.0
agent-16: 11.0
agent-17: 10.0
agent-18: 6.0
agent-19: 17.0
agent-20: 5.0
Sum Reward: 305.0
Avg Reward: 15.25
Min Reward: 3.0
Gini Coefficient: 0.2857377049180328
20:20 Ratio: 5.190476190476191
Max-min Ratio: 11.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_22-58-30
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 655.0
  episode_reward_mean: 347.89
  episode_reward_min: 181.0
  episodes_this_iter: 1
  episodes_total: 128
  experiment_id: 35d66058da2d4c9882f832ee91e4aa4a
  hostname: gpu011
  info:
    apply_time_ms: 2.621
    dispatch_time_ms: 6.878
    learner:
      cur_lr: 0.0011895040515810251
      grad_gnorm: 12.686935424804688
      policy_entropy: 123.23931121826172
      policy_loss: 2.4477572441101074
      var_gnorm: 19.875221252441406
      vf_explained_var: 0.0
      vf_loss: 6.424968242645264
    num_steps_sampled: 2580000
    num_steps_trained: 2580000
    wait_time_ms: 267.375
  iterations_since_restore: 129
  node_ip: 172.17.8.11
  num_metric_batches_dropped: 0
  pid: 25504
  policy_reward_mean: {}
  time_since_restore: 3641.1859517097473
  time_this_iter_s: 27.470720767974854
  time_total_s: 3641.1859517097473
  timestamp: 1593917910
  timesteps_since_restore: 2580000
  timesteps_this_iter: 20000
  timesteps_total: 2580000
  training_iteration: 129
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=25504], 3641 s, 129 iter, 2580000 ts, 348 rew

agent-1: 24.0
agent-2: 23.0
agent-3: 12.0
agent-4: 15.0
agent-5: 3.0
agent-6: 5.0
agent-7: 25.0
agent-8: 15.0
agent-9: 25.0
agent-10: 7.0
agent-11: 38.0
agent-12: 9.0
agent-13: 12.0
agent-14: 28.0
agent-15: 11.0
agent-16: 10.0
agent-17: 10.0
agent-18: 22.0
agent-19: 10.0
agent-20: 30.0
Sum Reward: 334.0
Avg Reward: 16.7
Min Reward: 3.0
Gini Coefficient: 0.3086826347305389
20:20 Ratio: 5.041666666666667
Max-min Ratio: 12.666666666666666
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_22-58-57
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 655.0
  episode_reward_mean: 348.13
  episode_reward_min: 181.0
  episodes_this_iter: 1
  episodes_total: 129
  experiment_id: 35d66058da2d4c9882f832ee91e4aa4a
  hostname: gpu011
  info:
    apply_time_ms: 3.18
    dispatch_time_ms: 7.026
    learner:
      cur_lr: 0.0011881720274686813
      grad_gnorm: 27.456443786621094
      policy_entropy: 120.79047393798828
      policy_loss: 8.539487838745117
      var_gnorm: 19.876483917236328
      vf_explained_var: 1.1920928955078125e-07
      vf_loss: 6.995678424835205
    num_steps_sampled: 2600000
    num_steps_trained: 2600000
    wait_time_ms: 257.047
  iterations_since_restore: 130
  node_ip: 172.17.8.11
  num_metric_batches_dropped: 0
  pid: 25504
  policy_reward_mean: {}
  time_since_restore: 3668.5444071292877
  time_this_iter_s: 27.358455419540405
  time_total_s: 3668.5444071292877
  timestamp: 1593917937
  timesteps_since_restore: 2600000
  timesteps_this_iter: 20000
  timesteps_total: 2600000
  training_iteration: 130
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=25504], 3668 s, 130 iter, 2600000 ts, 348 rew

agent-1: 16.0
agent-2: 5.0
agent-3: 13.0
agent-4: 14.0
agent-5: 12.0
agent-6: 24.0
agent-7: 21.0
agent-8: 10.0
agent-9: 17.0
agent-10: 23.0
agent-11: 8.0
agent-12: 11.0
agent-13: 18.0
agent-14: 3.0
agent-15: 24.0
agent-16: 17.0
agent-17: 13.0
agent-18: 6.0
agent-19: 4.0
agent-20: 8.0
Sum Reward: 267.0
Avg Reward: 13.35
Min Reward: 3.0
Gini Coefficient: 0.2762172284644195
20:20 Ratio: 5.111111111111111
Max-min Ratio: 8.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_22-59-25
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 655.0
  episode_reward_mean: 347.99
  episode_reward_min: 181.0
  episodes_this_iter: 1
  episodes_total: 130
  experiment_id: 35d66058da2d4c9882f832ee91e4aa4a
  hostname: gpu011
  info:
    apply_time_ms: 2.78
    dispatch_time_ms: 6.423
    learner:
      cur_lr: 0.0011868400033563375
      grad_gnorm: 40.000003814697266
      policy_entropy: 136.1339111328125
      policy_loss: 12.754375457763672
      var_gnorm: 19.878190994262695
      vf_explained_var: 0.0
      vf_loss: 26.41097068786621
    num_steps_sampled: 2620000
    num_steps_trained: 2620000
    wait_time_ms: 268.356
  iterations_since_restore: 131
  node_ip: 172.17.8.11
  num_metric_batches_dropped: 0
  pid: 25504
  policy_reward_mean: {}
  time_since_restore: 3696.110193967819
  time_this_iter_s: 27.565786838531494
  time_total_s: 3696.110193967819
  timestamp: 1593917965
  timesteps_since_restore: 2620000
  timesteps_this_iter: 20000
  timesteps_total: 2620000
  training_iteration: 131
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=25504], 3696 s, 131 iter, 2620000 ts, 348 rew

agent-1: 13.0
agent-2: 7.0
agent-3: 11.0
agent-4: 10.0
agent-5: 9.0
agent-6: 4.0
agent-7: 24.0
agent-8: 24.0
agent-9: 13.0
agent-10: 20.0
agent-11: 11.0
agent-12: 16.0
agent-13: 15.0
agent-14: 12.0
agent-15: 10.0
agent-16: 10.0
agent-17: 10.0
agent-18: 27.0
agent-19: 16.0
agent-20: 9.0
Sum Reward: 271.0
Avg Reward: 13.55
Min Reward: 4.0
Gini Coefficient: 0.23450184501845017
20:20 Ratio: 3.2758620689655173
Max-min Ratio: 6.75
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_22-59-52
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 655.0
  episode_reward_mean: 346.88
  episode_reward_min: 181.0
  episodes_this_iter: 1
  episodes_total: 131
  experiment_id: 35d66058da2d4c9882f832ee91e4aa4a
  hostname: gpu011
  info:
    apply_time_ms: 2.727
    dispatch_time_ms: 6.704
    learner:
      cur_lr: 0.0011855079792439938
      grad_gnorm: 18.828645706176758
      policy_entropy: 166.5663299560547
      policy_loss: -4.917115688323975
      var_gnorm: 19.87868881225586
      vf_explained_var: 0.0
      vf_loss: 0.14304529130458832
    num_steps_sampled: 2640000
    num_steps_trained: 2640000
    wait_time_ms: 263.455
  iterations_since_restore: 132
  node_ip: 172.17.8.11
  num_metric_batches_dropped: 0
  pid: 25504
  policy_reward_mean: {}
  time_since_restore: 3723.436046600342
  time_this_iter_s: 27.325852632522583
  time_total_s: 3723.436046600342
  timestamp: 1593917992
  timesteps_since_restore: 2640000
  timesteps_this_iter: 20000
  timesteps_total: 2640000
  training_iteration: 132
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=25504], 3723 s, 132 iter, 2640000 ts, 347 rew

agent-1: 17.0
agent-2: 16.0
agent-3: 10.0
agent-4: 9.0
agent-5: 25.0
agent-6: 15.0
agent-7: 23.0
agent-8: 6.0
agent-9: 37.0
agent-10: 22.0
agent-11: 16.0
agent-12: 13.0
agent-13: 12.0
agent-14: 21.0
agent-15: 9.0
agent-16: 22.0
agent-17: 31.0
agent-18: 25.0
agent-19: 26.0
agent-20: 30.0
Sum Reward: 385.0
Avg Reward: 19.25
Min Reward: 6.0
Gini Coefficient: 0.2396103896103896
20:20 Ratio: 3.6470588235294117
Max-min Ratio: 6.166666666666667
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_23-00-20
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 655.0
  episode_reward_mean: 348.03
  episode_reward_min: 181.0
  episodes_this_iter: 1
  episodes_total: 132
  experiment_id: 35d66058da2d4c9882f832ee91e4aa4a
  hostname: gpu011
  info:
    apply_time_ms: 4.705
    dispatch_time_ms: 6.52
    learner:
      cur_lr: 0.00118417595513165
      grad_gnorm: 10.969640731811523
      policy_entropy: 185.6219940185547
      policy_loss: -3.5905768871307373
      var_gnorm: 19.88591194152832
      vf_explained_var: 0.0
      vf_loss: 4.022697448730469
    num_steps_sampled: 2660000
    num_steps_trained: 2660000
    wait_time_ms: 273.687
  iterations_since_restore: 133
  node_ip: 172.17.8.11
  num_metric_batches_dropped: 0
  pid: 25504
  policy_reward_mean: {}
  time_since_restore: 3751.0468335151672
  time_this_iter_s: 27.61078691482544
  time_total_s: 3751.0468335151672
  timestamp: 1593918020
  timesteps_since_restore: 2660000
  timesteps_this_iter: 20000
  timesteps_total: 2660000
  training_iteration: 133
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=25504], 3751 s, 133 iter, 2660000 ts, 348 rew

agent-1: 27.0
agent-2: 11.0
agent-3: 11.0
agent-4: 14.0
agent-5: 11.0
agent-6: 54.0
agent-7: 9.0
agent-8: 26.0
agent-9: 20.0
agent-10: 7.0
agent-11: 18.0
agent-12: 4.0
agent-13: 20.0
agent-14: 7.0
agent-15: 15.0
agent-16: 7.0
agent-17: 15.0
agent-18: 16.0
agent-19: 24.0
agent-20: 6.0
Sum Reward: 322.0
Avg Reward: 16.1
Min Reward: 4.0
Gini Coefficient: 0.33260869565217394
20:20 Ratio: 5.458333333333333
Max-min Ratio: 13.5
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_23-00-47
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 655.0
  episode_reward_mean: 348.49
  episode_reward_min: 181.0
  episodes_this_iter: 1
  episodes_total: 133
  experiment_id: 35d66058da2d4c9882f832ee91e4aa4a
  hostname: gpu011
  info:
    apply_time_ms: 3.792
    dispatch_time_ms: 7.391
    learner:
      cur_lr: 0.001182844047434628
      grad_gnorm: 40.0
      policy_entropy: 199.72830200195312
      policy_loss: 34.662803649902344
      var_gnorm: 19.88437271118164
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 57.73149490356445
    num_steps_sampled: 2680000
    num_steps_trained: 2680000
    wait_time_ms: 258.656
  iterations_since_restore: 134
  node_ip: 172.17.8.11
  num_metric_batches_dropped: 0
  pid: 25504
  policy_reward_mean: {}
  time_since_restore: 3778.4351530075073
  time_this_iter_s: 27.388319492340088
  time_total_s: 3778.4351530075073
  timestamp: 1593918047
  timesteps_since_restore: 2680000
  timesteps_this_iter: 20000
  timesteps_total: 2680000
  training_iteration: 134
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=25504], 3778 s, 134 iter, 2680000 ts, 348 rew

agent-1: 26.0
agent-2: 17.0
agent-3: 20.0
agent-4: 8.0
agent-5: 7.0
agent-6: 18.0
agent-7: 3.0
agent-8: 3.0
agent-9: 25.0
agent-10: 22.0
agent-11: 11.0
agent-12: 28.0
agent-13: 6.0
agent-14: 14.0
agent-15: 29.0
agent-16: 14.0
agent-17: 29.0
agent-18: 9.0
agent-19: 6.0
agent-20: 27.0
Sum Reward: 322.0
Avg Reward: 16.1
Min Reward: 3.0
Gini Coefficient: 0.31863354037267083
20:20 Ratio: 6.277777777777778
Max-min Ratio: 9.666666666666666
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_23-01-15
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 655.0
  episode_reward_mean: 348.79
  episode_reward_min: 181.0
  episodes_this_iter: 1
  episodes_total: 134
  experiment_id: 35d66058da2d4c9882f832ee91e4aa4a
  hostname: gpu011
  info:
    apply_time_ms: 3.228
    dispatch_time_ms: 6.682
    learner:
      cur_lr: 0.0011815120233222842
      grad_gnorm: 31.9244441986084
      policy_entropy: 171.24708557128906
      policy_loss: -11.261760711669922
      var_gnorm: 19.888219833374023
      vf_explained_var: -2.384185791015625e-07
      vf_loss: 0.41159066557884216
    num_steps_sampled: 2700000
    num_steps_trained: 2700000
    wait_time_ms: 269.317
  iterations_since_restore: 135
  node_ip: 172.17.8.11
  num_metric_batches_dropped: 0
  pid: 25504
  policy_reward_mean: {}
  time_since_restore: 3805.654343366623
  time_this_iter_s: 27.2191903591156
  time_total_s: 3805.654343366623
  timestamp: 1593918075
  timesteps_since_restore: 2700000
  timesteps_this_iter: 20000
  timesteps_total: 2700000
  training_iteration: 135
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=25504], 3805 s, 135 iter, 2700000 ts, 349 rew

agent-1: 20.0
agent-2: 7.0
agent-3: 10.0
agent-4: 24.0
agent-5: 25.0
agent-6: 15.0
agent-7: 12.0
agent-8: 44.0
agent-9: 15.0
agent-10: 14.0
agent-11: 15.0
agent-12: 6.0
agent-13: 12.0
agent-14: 3.0
agent-15: 19.0
agent-16: 8.0
agent-17: 23.0
agent-18: 14.0
agent-19: 26.0
agent-20: 23.0
Sum Reward: 335.0
Avg Reward: 16.75
Min Reward: 3.0
Gini Coefficient: 0.28701492537313433
20:20 Ratio: 4.958333333333333
Max-min Ratio: 14.666666666666666
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_23-01-43
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 655.0
  episode_reward_mean: 349.3
  episode_reward_min: 181.0
  episodes_this_iter: 1
  episodes_total: 135
  experiment_id: 35d66058da2d4c9882f832ee91e4aa4a
  hostname: gpu011
  info:
    apply_time_ms: 3.454
    dispatch_time_ms: 8.777
    learner:
      cur_lr: 0.0011801799992099404
      grad_gnorm: 11.863831520080566
      policy_entropy: 178.17576599121094
      policy_loss: 2.8580322265625
      var_gnorm: 19.888736724853516
      vf_explained_var: 0.0
      vf_loss: 2.7586536407470703
    num_steps_sampled: 2720000
    num_steps_trained: 2720000
    wait_time_ms: 209.186
  iterations_since_restore: 136
  node_ip: 172.17.8.11
  num_metric_batches_dropped: 0
  pid: 25504
  policy_reward_mean: {}
  time_since_restore: 3833.511878490448
  time_this_iter_s: 27.857535123825073
  time_total_s: 3833.511878490448
  timestamp: 1593918103
  timesteps_since_restore: 2720000
  timesteps_this_iter: 20000
  timesteps_total: 2720000
  training_iteration: 136
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=25504], 3833 s, 136 iter, 2720000 ts, 349 rew

agent-1: 3.0
agent-2: 10.0
agent-3: 23.0
agent-4: 12.0
agent-5: 8.0
agent-6: 16.0
agent-7: 6.0
agent-8: 14.0
agent-9: 13.0
agent-10: 15.0
agent-11: 11.0
agent-12: 1.0
agent-13: 14.0
agent-14: 17.0
agent-15: 12.0
agent-16: 19.0
agent-17: 16.0
agent-18: 14.0
agent-19: 34.0
agent-20: 9.0
Sum Reward: 267.0
Avg Reward: 13.35
Min Reward: 1.0
Gini Coefficient: 0.27247191011235955
20:20 Ratio: 5.166666666666667
Max-min Ratio: 34.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_23-02-10
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 655.0
  episode_reward_mean: 348.67
  episode_reward_min: 181.0
  episodes_this_iter: 1
  episodes_total: 136
  experiment_id: 35d66058da2d4c9882f832ee91e4aa4a
  hostname: gpu011
  info:
    apply_time_ms: 2.877
    dispatch_time_ms: 6.119
    learner:
      cur_lr: 0.0011788479750975966
      grad_gnorm: 13.556983947753906
      policy_entropy: 185.5872802734375
      policy_loss: -5.2003374099731445
      var_gnorm: 19.893020629882812
      vf_explained_var: 0.0
      vf_loss: 0.07351601123809814
    num_steps_sampled: 2740000
    num_steps_trained: 2740000
    wait_time_ms: 268.067
  iterations_since_restore: 137
  node_ip: 172.17.8.11
  num_metric_batches_dropped: 0
  pid: 25504
  policy_reward_mean: {}
  time_since_restore: 3861.123654127121
  time_this_iter_s: 27.611775636672974
  time_total_s: 3861.123654127121
  timestamp: 1593918130
  timesteps_since_restore: 2740000
  timesteps_this_iter: 20000
  timesteps_total: 2740000
  training_iteration: 137
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=25504], 3861 s, 137 iter, 2740000 ts, 349 rew

agent-1: 12.0
agent-2: 34.0
agent-3: 23.0
agent-4: 11.0
agent-5: 19.0
agent-6: 2.0
agent-7: 19.0
agent-8: 11.0
agent-9: 20.0
agent-10: 24.0
agent-11: 14.0
agent-12: 13.0
agent-13: 8.0
agent-14: 3.0
agent-15: 16.0
agent-16: 15.0
agent-17: 16.0
agent-18: 5.0
agent-19: 24.0
agent-20: 13.0
Sum Reward: 302.0
Avg Reward: 15.1
Min Reward: 2.0
Gini Coefficient: 0.27980132450331124
20:20 Ratio: 5.833333333333333
Max-min Ratio: 17.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_23-02-39
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 655.0
  episode_reward_mean: 349.88
  episode_reward_min: 224.0
  episodes_this_iter: 1
  episodes_total: 137
  experiment_id: 35d66058da2d4c9882f832ee91e4aa4a
  hostname: gpu011
  info:
    apply_time_ms: 3.218
    dispatch_time_ms: 19.467
    learner:
      cur_lr: 0.0011775159509852529
      grad_gnorm: 23.03366470336914
      policy_entropy: 173.0067901611328
      policy_loss: 10.671585083007812
      var_gnorm: 19.8931941986084
      vf_explained_var: 0.0
      vf_loss: 12.315502166748047
    num_steps_sampled: 2760000
    num_steps_trained: 2760000
    wait_time_ms: 272.403
  iterations_since_restore: 138
  node_ip: 172.17.8.11
  num_metric_batches_dropped: 0
  pid: 25504
  policy_reward_mean: {}
  time_since_restore: 3889.7692487239838
  time_this_iter_s: 28.645594596862793
  time_total_s: 3889.7692487239838
  timestamp: 1593918159
  timesteps_since_restore: 2760000
  timesteps_this_iter: 20000
  timesteps_total: 2760000
  training_iteration: 138
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=25504], 3889 s, 138 iter, 2760000 ts, 350 rew

agent-1: 10.0
agent-2: 14.0
agent-3: 14.0
agent-4: 4.0
agent-5: 15.0
agent-6: 28.0
agent-7: 10.0
agent-8: 16.0
agent-9: 17.0
agent-10: 2.0
agent-11: 18.0
agent-12: 9.0
agent-13: 9.0
agent-14: 9.0
agent-15: 6.0
agent-16: 3.0
agent-17: 14.0
agent-18: 22.0
agent-19: 10.0
agent-20: 5.0
Sum Reward: 235.0
Avg Reward: 11.75
Min Reward: 2.0
Gini Coefficient: 0.3019148936170213
20:20 Ratio: 6.071428571428571
Max-min Ratio: 14.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_23-03-07
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 655.0
  episode_reward_mean: 348.85
  episode_reward_min: 224.0
  episodes_this_iter: 1
  episodes_total: 138
  experiment_id: 35d66058da2d4c9882f832ee91e4aa4a
  hostname: gpu011
  info:
    apply_time_ms: 3.103
    dispatch_time_ms: 7.019
    learner:
      cur_lr: 0.001176184043288231
      grad_gnorm: 24.007736206054688
      policy_entropy: 164.33218383789062
      policy_loss: -6.971078872680664
      var_gnorm: 19.892911911010742
      vf_explained_var: 0.0
      vf_loss: 0.2328067570924759
    num_steps_sampled: 2780000
    num_steps_trained: 2780000
    wait_time_ms: 269.96
  iterations_since_restore: 139
  node_ip: 172.17.8.11
  num_metric_batches_dropped: 0
  pid: 25504
  policy_reward_mean: {}
  time_since_restore: 3918.238744497299
  time_this_iter_s: 28.46949577331543
  time_total_s: 3918.238744497299
  timestamp: 1593918187
  timesteps_since_restore: 2780000
  timesteps_this_iter: 20000
  timesteps_total: 2780000
  training_iteration: 139
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=25504], 3918 s, 139 iter, 2780000 ts, 349 rew

agent-1: 22.0
agent-2: 8.0
agent-3: 19.0
agent-4: 9.0
agent-5: 7.0
agent-6: 13.0
agent-7: 4.0
agent-8: 23.0
agent-9: 9.0
agent-10: 12.0
agent-11: 9.0
agent-12: 17.0
agent-13: 13.0
agent-14: 10.0
agent-15: 20.0
agent-16: 5.0
agent-17: 16.0
agent-18: 16.0
agent-19: 21.0
agent-20: 9.0
Sum Reward: 262.0
Avg Reward: 13.1
Min Reward: 4.0
Gini Coefficient: 0.24656488549618322
20:20 Ratio: 3.5833333333333335
Max-min Ratio: 5.75
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_23-03-35
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 655.0
  episode_reward_mean: 348.28
  episode_reward_min: 224.0
  episodes_this_iter: 1
  episodes_total: 139
  experiment_id: 35d66058da2d4c9882f832ee91e4aa4a
  hostname: gpu011
  info:
    apply_time_ms: 2.733
    dispatch_time_ms: 7.034
    learner:
      cur_lr: 0.001174852019175887
      grad_gnorm: 22.03562355041504
      policy_entropy: 179.17022705078125
      policy_loss: -5.801516532897949
      var_gnorm: 19.893178939819336
      vf_explained_var: 0.0
      vf_loss: 0.19501399993896484
    num_steps_sampled: 2800000
    num_steps_trained: 2800000
    wait_time_ms: 268.607
  iterations_since_restore: 140
  node_ip: 172.17.8.11
  num_metric_batches_dropped: 0
  pid: 25504
  policy_reward_mean: {}
  time_since_restore: 3945.62464761734
  time_this_iter_s: 27.385903120040894
  time_total_s: 3945.62464761734
  timestamp: 1593918215
  timesteps_since_restore: 2800000
  timesteps_this_iter: 20000
  timesteps_total: 2800000
  training_iteration: 140
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=25504], 3945 s, 140 iter, 2800000 ts, 348 rew

agent-1: 15.0
agent-2: 14.0
agent-3: 36.0
agent-4: 25.0
agent-5: 8.0
agent-6: 12.0
agent-7: 27.0
agent-8: 15.0
agent-9: 6.0
agent-10: 22.0
agent-11: 19.0
agent-12: 26.0
agent-13: 18.0
agent-14: 12.0
agent-15: 14.0
agent-16: 8.0
agent-17: 13.0
agent-18: 19.0
agent-19: 17.0
agent-20: 13.0
Sum Reward: 339.0
Avg Reward: 16.95
Min Reward: 6.0
Gini Coefficient: 0.23112094395280236
20:20 Ratio: 3.3529411764705883
Max-min Ratio: 6.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_23-04-02
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 655.0
  episode_reward_mean: 348.49
  episode_reward_min: 224.0
  episodes_this_iter: 1
  episodes_total: 140
  experiment_id: 35d66058da2d4c9882f832ee91e4aa4a
  hostname: gpu011
  info:
    apply_time_ms: 2.675
    dispatch_time_ms: 22.318
    learner:
      cur_lr: 0.0011735199950635433
      grad_gnorm: 40.000003814697266
      policy_entropy: 185.35296630859375
      policy_loss: 9.310511589050293
      var_gnorm: 19.896333694458008
      vf_explained_var: 0.0
      vf_loss: 20.24941635131836
    num_steps_sampled: 2820000
    num_steps_trained: 2820000
    wait_time_ms: 243.657
  iterations_since_restore: 141
  node_ip: 172.17.8.11
  num_metric_batches_dropped: 0
  pid: 25504
  policy_reward_mean: {}
  time_since_restore: 3973.1307060718536
  time_this_iter_s: 27.50605845451355
  time_total_s: 3973.1307060718536
  timestamp: 1593918242
  timesteps_since_restore: 2820000
  timesteps_this_iter: 20000
  timesteps_total: 2820000
  training_iteration: 141
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=25504], 3973 s, 141 iter, 2820000 ts, 348 rew

agent-1: 9.0
agent-2: 12.0
agent-3: 33.0
agent-4: 32.0
agent-5: 19.0
agent-6: 16.0
agent-7: 11.0
agent-8: 18.0
agent-9: 7.0
agent-10: 16.0
agent-11: 29.0
agent-12: 12.0
agent-13: 26.0
agent-14: 25.0
agent-15: 24.0
agent-16: 10.0
agent-17: 13.0
agent-18: 23.0
agent-19: 15.0
agent-20: 24.0
Sum Reward: 374.0
Avg Reward: 18.7
Min Reward: 7.0
Gini Coefficient: 0.23315508021390374
20:20 Ratio: 3.2432432432432434
Max-min Ratio: 4.714285714285714
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_23-04-32
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 655.0
  episode_reward_mean: 348.87
  episode_reward_min: 224.0
  episodes_this_iter: 1
  episodes_total: 141
  experiment_id: 35d66058da2d4c9882f832ee91e4aa4a
  hostname: gpu011
  info:
    apply_time_ms: 3.119
    dispatch_time_ms: 21.344
    learner:
      cur_lr: 0.0011721879709511995
      grad_gnorm: 40.000003814697266
      policy_entropy: 148.80357360839844
      policy_loss: 0.8796986937522888
      var_gnorm: 19.895797729492188
      vf_explained_var: 0.0
      vf_loss: 1.4224402904510498
    num_steps_sampled: 2840000
    num_steps_trained: 2840000
    wait_time_ms: 263.677
  iterations_since_restore: 142
  node_ip: 172.17.8.11
  num_metric_batches_dropped: 0
  pid: 25504
  policy_reward_mean: {}
  time_since_restore: 4002.1650602817535
  time_this_iter_s: 29.034354209899902
  time_total_s: 4002.1650602817535
  timestamp: 1593918272
  timesteps_since_restore: 2840000
  timesteps_this_iter: 20000
  timesteps_total: 2840000
  training_iteration: 142
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=25504], 4002 s, 142 iter, 2840000 ts, 349 rew

agent-1: 30.0
agent-2: 13.0
agent-3: 43.0
agent-4: 22.0
agent-5: 32.0
agent-6: 14.0
agent-7: 26.0
agent-8: 15.0
agent-9: 19.0
agent-10: 29.0
agent-11: 24.0
agent-12: 24.0
agent-13: 19.0
agent-14: 17.0
agent-15: 18.0
agent-16: 17.0
agent-17: 29.0
agent-18: 27.0
agent-19: 17.0
agent-20: 9.0
Sum Reward: 444.0
Avg Reward: 22.2
Min Reward: 9.0
Gini Coefficient: 0.19414414414414413
20:20 Ratio: 2.627450980392157
Max-min Ratio: 4.777777777777778
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_23-05-00
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 655.0
  episode_reward_mean: 350.2
  episode_reward_min: 224.0
  episodes_this_iter: 1
  episodes_total: 142
  experiment_id: 35d66058da2d4c9882f832ee91e4aa4a
  hostname: gpu011
  info:
    apply_time_ms: 2.621
    dispatch_time_ms: 26.157
    learner:
      cur_lr: 0.0011708559468388557
      grad_gnorm: 32.672386169433594
      policy_entropy: 176.34568786621094
      policy_loss: -11.30020523071289
      var_gnorm: 19.903345108032227
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 2.6663155555725098
    num_steps_sampled: 2860000
    num_steps_trained: 2860000
    wait_time_ms: 265.413
  iterations_since_restore: 143
  node_ip: 172.17.8.11
  num_metric_batches_dropped: 0
  pid: 25504
  policy_reward_mean: {}
  time_since_restore: 4030.6806898117065
  time_this_iter_s: 28.515629529953003
  time_total_s: 4030.6806898117065
  timestamp: 1593918300
  timesteps_since_restore: 2860000
  timesteps_this_iter: 20000
  timesteps_total: 2860000
  training_iteration: 143
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=25504], 4030 s, 143 iter, 2860000 ts, 350 rew

agent-1: 16.0
agent-2: 24.0
agent-3: 30.0
agent-4: 29.0
agent-5: 30.0
agent-6: 24.0
agent-7: 20.0
agent-8: 21.0
agent-9: 27.0
agent-10: 8.0
agent-11: 15.0
agent-12: 17.0
agent-13: 18.0
agent-14: 9.0
agent-15: 6.0
agent-16: 19.0
agent-17: 16.0
agent-18: 17.0
agent-19: 28.0
agent-20: 20.0
Sum Reward: 394.0
Avg Reward: 19.7
Min Reward: 6.0
Gini Coefficient: 0.19898477157360406
20:20 Ratio: 3.0789473684210527
Max-min Ratio: 5.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_23-05-28
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 559.0
  episode_reward_mean: 347.59
  episode_reward_min: 224.0
  episodes_this_iter: 1
  episodes_total: 143
  experiment_id: 35d66058da2d4c9882f832ee91e4aa4a
  hostname: gpu011
  info:
    apply_time_ms: 3.594
    dispatch_time_ms: 5.365
    learner:
      cur_lr: 0.0011695240391418338
      grad_gnorm: 17.146886825561523
      policy_entropy: 152.7677001953125
      policy_loss: -4.304567337036133
      var_gnorm: 19.902616500854492
      vf_explained_var: 0.0
      vf_loss: 0.11881051957607269
    num_steps_sampled: 2880000
    num_steps_trained: 2880000
    wait_time_ms: 275.799
  iterations_since_restore: 144
  node_ip: 172.17.8.11
  num_metric_batches_dropped: 0
  pid: 25504
  policy_reward_mean: {}
  time_since_restore: 4058.990037918091
  time_this_iter_s: 28.309348106384277
  time_total_s: 4058.990037918091
  timestamp: 1593918328
  timesteps_since_restore: 2880000
  timesteps_this_iter: 20000
  timesteps_total: 2880000
  training_iteration: 144
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=25504], 4058 s, 144 iter, 2880000 ts, 348 rew

agent-1: 14.0
agent-2: 13.0
agent-3: 23.0
agent-4: 12.0
agent-5: 7.0
agent-6: 16.0
agent-7: 12.0
agent-8: 0.0
agent-9: 9.0
agent-10: 5.0
agent-11: 10.0
agent-12: 9.0
agent-13: 32.0
agent-14: 5.0
agent-15: 20.0
agent-16: 19.0
agent-17: 13.0
agent-18: 25.0
agent-19: 11.0
agent-20: 14.0
Sum Reward: 269.0
Avg Reward: 13.45
Min Reward: 0.0
Gini Coefficient: 0.2986988847583643
20:20 Ratio: 5.882352941176471
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_23-05-56
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 559.0
  episode_reward_mean: 346.62
  episode_reward_min: 224.0
  episodes_this_iter: 1
  episodes_total: 144
  experiment_id: 35d66058da2d4c9882f832ee91e4aa4a
  hostname: gpu011
  info:
    apply_time_ms: 2.777
    dispatch_time_ms: 5.903
    learner:
      cur_lr: 0.00116819201502949
      grad_gnorm: 31.335357666015625
      policy_entropy: 173.00830078125
      policy_loss: -10.17770004272461
      var_gnorm: 19.90625762939453
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 0.3951230049133301
    num_steps_sampled: 2900000
    num_steps_trained: 2900000
    wait_time_ms: 265.406
  iterations_since_restore: 145
  node_ip: 172.17.8.11
  num_metric_batches_dropped: 0
  pid: 25504
  policy_reward_mean: {}
  time_since_restore: 4086.1865849494934
  time_this_iter_s: 27.196547031402588
  time_total_s: 4086.1865849494934
  timestamp: 1593918356
  timesteps_since_restore: 2900000
  timesteps_this_iter: 20000
  timesteps_total: 2900000
  training_iteration: 145
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=25504], 4086 s, 145 iter, 2900000 ts, 347 rew

agent-1: 12.0
agent-2: 27.0
agent-3: 14.0
agent-4: 30.0
agent-5: 19.0
agent-6: 9.0
agent-7: 15.0
agent-8: 11.0
agent-9: 13.0
agent-10: 12.0
agent-11: 26.0
agent-12: 13.0
agent-13: 13.0
agent-14: 15.0
agent-15: 17.0
agent-16: 13.0
agent-17: 14.0
agent-18: 18.0
agent-19: 20.0
agent-20: 36.0
Sum Reward: 347.0
Avg Reward: 17.35
Min Reward: 9.0
Gini Coefficient: 0.2064841498559078
20:20 Ratio: 2.7045454545454546
Max-min Ratio: 4.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_23-06-23
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 559.0
  episode_reward_mean: 345.99
  episode_reward_min: 224.0
  episodes_this_iter: 1
  episodes_total: 145
  experiment_id: 35d66058da2d4c9882f832ee91e4aa4a
  hostname: gpu011
  info:
    apply_time_ms: 3.169
    dispatch_time_ms: 7.633
    learner:
      cur_lr: 0.0011668599909171462
      grad_gnorm: 40.0
      policy_entropy: 178.6464385986328
      policy_loss: 30.946195602416992
      var_gnorm: 19.90054702758789
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 37.10414123535156
    num_steps_sampled: 2920000
    num_steps_trained: 2920000
    wait_time_ms: 257.713
  iterations_since_restore: 146
  node_ip: 172.17.8.11
  num_metric_batches_dropped: 0
  pid: 25504
  policy_reward_mean: {}
  time_since_restore: 4113.813245773315
  time_this_iter_s: 27.62666082382202
  time_total_s: 4113.813245773315
  timestamp: 1593918383
  timesteps_since_restore: 2920000
  timesteps_this_iter: 20000
  timesteps_total: 2920000
  training_iteration: 146
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=25504], 4113 s, 146 iter, 2920000 ts, 346 rew

agent-1: 15.0
agent-2: 16.0
agent-3: 14.0
agent-4: 10.0
agent-5: 11.0
agent-6: 5.0
agent-7: 15.0
agent-8: 26.0
agent-9: 28.0
agent-10: 15.0
agent-11: 12.0
agent-12: 19.0
agent-13: 18.0
agent-14: 15.0
agent-15: 7.0
agent-16: 21.0
agent-17: 19.0
agent-18: 21.0
agent-19: 34.0
agent-20: 21.0
Sum Reward: 342.0
Avg Reward: 17.1
Min Reward: 5.0
Gini Coefficient: 0.21900584795321637
20:20 Ratio: 3.303030303030303
Max-min Ratio: 6.8
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_23-06-52
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 482.0
  episode_reward_mean: 343.82
  episode_reward_min: 224.0
  episodes_this_iter: 1
  episodes_total: 146
  experiment_id: 35d66058da2d4c9882f832ee91e4aa4a
  hostname: gpu011
  info:
    apply_time_ms: 3.609
    dispatch_time_ms: 10.176
    learner:
      cur_lr: 0.0011655279668048024
      grad_gnorm: 15.53101921081543
      policy_entropy: 163.03684997558594
      policy_loss: -8.337312698364258
      var_gnorm: 19.902446746826172
      vf_explained_var: 0.0
      vf_loss: 0.1206919401884079
    num_steps_sampled: 2940000
    num_steps_trained: 2940000
    wait_time_ms: 72.102
  iterations_since_restore: 147
  node_ip: 172.17.8.11
  num_metric_batches_dropped: 0
  pid: 25504
  policy_reward_mean: {}
  time_since_restore: 4142.719398736954
  time_this_iter_s: 28.906152963638306
  time_total_s: 4142.719398736954
  timestamp: 1593918412
  timesteps_since_restore: 2940000
  timesteps_this_iter: 20000
  timesteps_total: 2940000
  training_iteration: 147
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=25504], 4142 s, 147 iter, 2940000 ts, 344 rew

agent-1: 21.0
agent-2: 26.0
agent-3: 24.0
agent-4: 7.0
agent-5: 24.0
agent-6: 3.0
agent-7: 24.0
agent-8: 14.0
agent-9: 25.0
agent-10: 0.0
agent-11: 9.0
agent-12: 17.0
agent-13: 11.0
agent-14: 21.0
agent-15: 28.0
agent-16: 8.0
agent-17: 17.0
agent-18: 13.0
agent-19: 10.0
agent-20: 30.0
Sum Reward: 332.0
Avg Reward: 16.6
Min Reward: 0.0
Gini Coefficient: 0.2927710843373494
20:20 Ratio: 6.055555555555555
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_23-07-19
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 482.0
  episode_reward_mean: 343.1
  episode_reward_min: 224.0
  episodes_this_iter: 1
  episodes_total: 147
  experiment_id: 35d66058da2d4c9882f832ee91e4aa4a
  hostname: gpu011
  info:
    apply_time_ms: 3.308
    dispatch_time_ms: 6.705
    learner:
      cur_lr: 0.0011641959426924586
      grad_gnorm: 20.89575958251953
      policy_entropy: 181.28140258789062
      policy_loss: -5.911632537841797
      var_gnorm: 19.90370750427246
      vf_explained_var: 0.0
      vf_loss: 0.17386004328727722
    num_steps_sampled: 2960000
    num_steps_trained: 2960000
    wait_time_ms: 261.237
  iterations_since_restore: 148
  node_ip: 172.17.8.11
  num_metric_batches_dropped: 0
  pid: 25504
  policy_reward_mean: {}
  time_since_restore: 4169.202154636383
  time_this_iter_s: 26.48275589942932
  time_total_s: 4169.202154636383
  timestamp: 1593918439
  timesteps_since_restore: 2960000
  timesteps_this_iter: 20000
  timesteps_total: 2960000
  training_iteration: 148
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=25504], 4169 s, 148 iter, 2960000 ts, 343 rew

agent-1: 17.0
agent-2: 9.0
agent-3: 24.0
agent-4: 9.0
agent-5: 17.0
agent-6: 1.0
agent-7: 12.0
agent-8: 6.0
agent-9: 18.0
agent-10: 23.0
agent-11: 21.0
agent-12: 11.0
agent-13: 12.0
agent-14: 12.0
agent-15: 6.0
agent-16: 21.0
agent-17: 22.0
agent-18: 14.0
agent-19: 26.0
agent-20: 18.0
Sum Reward: 299.0
Avg Reward: 14.95
Min Reward: 1.0
Gini Coefficient: 0.2536789297658863
20:20 Ratio: 4.318181818181818
Max-min Ratio: 26.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_23-07-46
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 482.0
  episode_reward_mean: 341.71
  episode_reward_min: 224.0
  episodes_this_iter: 1
  episodes_total: 148
  experiment_id: 35d66058da2d4c9882f832ee91e4aa4a
  hostname: gpu011
  info:
    apply_time_ms: 3.94
    dispatch_time_ms: 5.976
    learner:
      cur_lr: 0.0011628640349954367
      grad_gnorm: 27.044958114624023
      policy_entropy: 161.5181121826172
      policy_loss: -7.857895851135254
      var_gnorm: 19.91354751586914
      vf_explained_var: 0.0
      vf_loss: 0.2902003526687622
    num_steps_sampled: 2980000
    num_steps_trained: 2980000
    wait_time_ms: 261.98
  iterations_since_restore: 149
  node_ip: 172.17.8.11
  num_metric_batches_dropped: 0
  pid: 25504
  policy_reward_mean: {}
  time_since_restore: 4196.571160316467
  time_this_iter_s: 27.36900568008423
  time_total_s: 4196.571160316467
  timestamp: 1593918466
  timesteps_since_restore: 2980000
  timesteps_this_iter: 20000
  timesteps_total: 2980000
  training_iteration: 149
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=25504], 4196 s, 149 iter, 2980000 ts, 342 rew

agent-1: 15.0
agent-2: 22.0
agent-3: 23.0
agent-4: 21.0
agent-5: 20.0
agent-6: 11.0
agent-7: 7.0
agent-8: 22.0
agent-9: 17.0
agent-10: 7.0
agent-11: 16.0
agent-12: 15.0
agent-13: 8.0
agent-14: 7.0
agent-15: 21.0
agent-16: 8.0
agent-17: 8.0
agent-18: 8.0
agent-19: 14.0
agent-20: 29.0
Sum Reward: 299.0
Avg Reward: 14.95
Min Reward: 7.0
Gini Coefficient: 0.24698996655518396
20:20 Ratio: 3.310344827586207
Max-min Ratio: 4.142857142857143
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_23-08-14
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 482.0
  episode_reward_mean: 341.57
  episode_reward_min: 224.0
  episodes_this_iter: 1
  episodes_total: 149
  experiment_id: 35d66058da2d4c9882f832ee91e4aa4a
  hostname: gpu011
  info:
    apply_time_ms: 2.696
    dispatch_time_ms: 6.014
    learner:
      cur_lr: 0.0011615320108830929
      grad_gnorm: 19.351438522338867
      policy_entropy: 191.86489868164062
      policy_loss: 7.424144744873047
      var_gnorm: 19.913551330566406
      vf_explained_var: 0.0
      vf_loss: 6.539466857910156
    num_steps_sampled: 3000000
    num_steps_trained: 3000000
    wait_time_ms: 263.723
  iterations_since_restore: 150
  node_ip: 172.17.8.11
  num_metric_batches_dropped: 0
  pid: 25504
  policy_reward_mean: {}
  time_since_restore: 4224.014300823212
  time_this_iter_s: 27.443140506744385
  time_total_s: 4224.014300823212
  timestamp: 1593918494
  timesteps_since_restore: 3000000
  timesteps_this_iter: 20000
  timesteps_total: 3000000
  training_iteration: 150
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=25504], 4224 s, 150 iter, 3000000 ts, 342 rew

agent-1: 4.0
agent-2: 29.0
agent-3: 21.0
agent-4: 17.0
agent-5: 28.0
agent-6: 22.0
agent-7: 21.0
agent-8: 12.0
agent-9: 26.0
agent-10: 18.0
agent-11: 12.0
agent-12: 23.0
agent-13: 25.0
agent-14: 16.0
agent-15: 21.0
agent-16: 25.0
agent-17: 23.0
agent-18: 17.0
agent-19: 13.0
agent-20: 32.0
Sum Reward: 405.0
Avg Reward: 20.25
Min Reward: 4.0
Gini Coefficient: 0.18160493827160493
20:20 Ratio: 2.8048780487804876
Max-min Ratio: 8.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_23-08-41
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 482.0
  episode_reward_mean: 340.93
  episode_reward_min: 224.0
  episodes_this_iter: 1
  episodes_total: 150
  experiment_id: 35d66058da2d4c9882f832ee91e4aa4a
  hostname: gpu011
  info:
    apply_time_ms: 2.818
    dispatch_time_ms: 5.919
    learner:
      cur_lr: 0.001160199986770749
      grad_gnorm: 34.54974365234375
      policy_entropy: 172.66030883789062
      policy_loss: -10.531609535217285
      var_gnorm: 19.920486450195312
      vf_explained_var: 0.0
      vf_loss: 0.473613440990448
    num_steps_sampled: 3020000
    num_steps_trained: 3020000
    wait_time_ms: 265.243
  iterations_since_restore: 151
  node_ip: 172.17.8.11
  num_metric_batches_dropped: 0
  pid: 25504
  policy_reward_mean: {}
  time_since_restore: 4251.343171596527
  time_this_iter_s: 27.32887077331543
  time_total_s: 4251.343171596527
  timestamp: 1593918521
  timesteps_since_restore: 3020000
  timesteps_this_iter: 20000
  timesteps_total: 3020000
  training_iteration: 151
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=25504], 4251 s, 151 iter, 3020000 ts, 341 rew

agent-1: 38.0
agent-2: 6.0
agent-3: 17.0
agent-4: 11.0
agent-5: 26.0
agent-6: 20.0
agent-7: 21.0
agent-8: 23.0
agent-9: 7.0
agent-10: 12.0
agent-11: 3.0
agent-12: 17.0
agent-13: 2.0
agent-14: 6.0
agent-15: 15.0
agent-16: 12.0
agent-17: 1.0
agent-18: 12.0
agent-19: 5.0
agent-20: 33.0
Sum Reward: 287.0
Avg Reward: 14.35
Min Reward: 1.0
Gini Coefficient: 0.3848432055749129
20:20 Ratio: 10.909090909090908
Max-min Ratio: 38.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_23-09-08
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 482.0
  episode_reward_mean: 339.51
  episode_reward_min: 224.0
  episodes_this_iter: 1
  episodes_total: 151
  experiment_id: 35d66058da2d4c9882f832ee91e4aa4a
  hostname: gpu011
  info:
    apply_time_ms: 2.774
    dispatch_time_ms: 5.743
    learner:
      cur_lr: 0.0011588679626584053
      grad_gnorm: 39.999996185302734
      policy_entropy: 186.41468811035156
      policy_loss: 18.578670501708984
      var_gnorm: 19.920438766479492
      vf_explained_var: 0.0
      vf_loss: 22.22852897644043
    num_steps_sampled: 3040000
    num_steps_trained: 3040000
    wait_time_ms: 255.741
  iterations_since_restore: 152
  node_ip: 172.17.8.11
  num_metric_batches_dropped: 0
  pid: 25504
  policy_reward_mean: {}
  time_since_restore: 4278.776260852814
  time_this_iter_s: 27.43308925628662
  time_total_s: 4278.776260852814
  timestamp: 1593918548
  timesteps_since_restore: 3040000
  timesteps_this_iter: 20000
  timesteps_total: 3040000
  training_iteration: 152
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=25504], 4278 s, 152 iter, 3040000 ts, 340 rew

agent-1: 11.0
agent-2: 15.0
agent-3: 21.0
agent-4: 12.0
agent-5: 7.0
agent-6: 10.0
agent-7: 30.0
agent-8: 16.0
agent-9: 22.0
agent-10: 7.0
agent-11: 30.0
agent-12: 23.0
agent-13: 11.0
agent-14: 10.0
agent-15: 26.0
agent-16: 0.0
agent-17: 26.0
agent-18: 15.0
agent-19: 6.0
agent-20: 32.0
Sum Reward: 330.0
Avg Reward: 16.5
Min Reward: 0.0
Gini Coefficient: 0.3090909090909091
20:20 Ratio: 5.9
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_23-09-36
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 482.0
  episode_reward_mean: 339.16
  episode_reward_min: 224.0
  episodes_this_iter: 1
  episodes_total: 152
  experiment_id: 35d66058da2d4c9882f832ee91e4aa4a
  hostname: gpu011
  info:
    apply_time_ms: 3.181
    dispatch_time_ms: 7.391
    learner:
      cur_lr: 0.0011575360549613833
      grad_gnorm: 13.254183769226074
      policy_entropy: 175.5039520263672
      policy_loss: -4.507110595703125
      var_gnorm: 19.921764373779297
      vf_explained_var: 0.0
      vf_loss: 2.447977304458618
    num_steps_sampled: 3060000
    num_steps_trained: 3060000
    wait_time_ms: 265.67
  iterations_since_restore: 153
  node_ip: 172.17.8.11
  num_metric_batches_dropped: 0
  pid: 25504
  policy_reward_mean: {}
  time_since_restore: 4306.431035757065
  time_this_iter_s: 27.6547749042511
  time_total_s: 4306.431035757065
  timestamp: 1593918576
  timesteps_since_restore: 3060000
  timesteps_this_iter: 20000
  timesteps_total: 3060000
  training_iteration: 153
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=25504], 4306 s, 153 iter, 3060000 ts, 339 rew

agent-1: 8.0
agent-2: 19.0
agent-3: 6.0
agent-4: 8.0
agent-5: 14.0
agent-6: 16.0
agent-7: 21.0
agent-8: 44.0
agent-9: 9.0
agent-10: 20.0
agent-11: 12.0
agent-12: 14.0
agent-13: 17.0
agent-14: 13.0
agent-15: 17.0
agent-16: 15.0
agent-17: 15.0
agent-18: 18.0
agent-19: 17.0
agent-20: 6.0
Sum Reward: 309.0
Avg Reward: 15.45
Min Reward: 6.0
Gini Coefficient: 0.24158576051779934
20:20 Ratio: 3.7142857142857144
Max-min Ratio: 7.333333333333333
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_23-10-04
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 482.0
  episode_reward_mean: 337.47
  episode_reward_min: 224.0
  episodes_this_iter: 1
  episodes_total: 153
  experiment_id: 35d66058da2d4c9882f832ee91e4aa4a
  hostname: gpu011
  info:
    apply_time_ms: 4.118
    dispatch_time_ms: 6.645
    learner:
      cur_lr: 0.0011562040308490396
      grad_gnorm: 18.0302734375
      policy_entropy: 170.08604431152344
      policy_loss: -4.575740814208984
      var_gnorm: 19.922653198242188
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 0.131169393658638
    num_steps_sampled: 3080000
    num_steps_trained: 3080000
    wait_time_ms: 264.94
  iterations_since_restore: 154
  node_ip: 172.17.8.11
  num_metric_batches_dropped: 0
  pid: 25504
  policy_reward_mean: {}
  time_since_restore: 4333.851652383804
  time_this_iter_s: 27.420616626739502
  time_total_s: 4333.851652383804
  timestamp: 1593918604
  timesteps_since_restore: 3080000
  timesteps_this_iter: 20000
  timesteps_total: 3080000
  training_iteration: 154
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=25504], 4333 s, 154 iter, 3080000 ts, 337 rew

agent-1: 11.0
agent-2: 6.0
agent-3: 19.0
agent-4: 10.0
agent-5: 7.0
agent-6: 4.0
agent-7: 2.0
agent-8: 18.0
agent-9: 18.0
agent-10: 14.0
agent-11: 6.0
agent-12: 12.0
agent-13: 29.0
agent-14: 6.0
agent-15: 9.0
agent-16: 6.0
agent-17: 2.0
agent-18: 29.0
agent-19: 34.0
agent-20: 23.0
Sum Reward: 265.0
Avg Reward: 13.25
Min Reward: 2.0
Gini Coefficient: 0.38547169811320753
20:20 Ratio: 8.214285714285714
Max-min Ratio: 17.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_23-10-44
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 482.0
  episode_reward_mean: 336.12
  episode_reward_min: 224.0
  episodes_this_iter: 1
  episodes_total: 154
  experiment_id: 35d66058da2d4c9882f832ee91e4aa4a
  hostname: gpu011
  info:
    apply_time_ms: 4.019
    dispatch_time_ms: 6.356
    learner:
      cur_lr: 0.0011548720067366958
      grad_gnorm: 40.0
      policy_entropy: 180.01483154296875
      policy_loss: 9.125696182250977
      var_gnorm: 19.92868995666504
      vf_explained_var: 5.960464477539063e-08
      vf_loss: 19.73164939880371
    num_steps_sampled: 3100000
    num_steps_trained: 3100000
    wait_time_ms: 266.194
  iterations_since_restore: 155
  node_ip: 172.17.8.11
  num_metric_batches_dropped: 0
  pid: 25504
  policy_reward_mean: {}
  time_since_restore: 4374.512099742889
  time_this_iter_s: 40.66044735908508
  time_total_s: 4374.512099742889
  timestamp: 1593918644
  timesteps_since_restore: 3100000
  timesteps_this_iter: 20000
  timesteps_total: 3100000
  training_iteration: 155
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=25504], 4374 s, 155 iter, 3100000 ts, 336 rew

agent-1: 18.0
agent-2: 13.0
agent-3: 23.0
agent-4: 30.0
agent-5: 36.0
agent-6: 21.0
agent-7: 10.0
agent-8: 7.0
agent-9: 14.0
agent-10: 26.0
agent-11: 7.0
agent-12: 24.0
agent-13: 22.0
agent-14: 28.0
agent-15: 7.0
agent-16: 26.0
agent-17: 15.0
agent-18: 12.0
agent-19: 8.0
agent-20: 42.0
Sum Reward: 389.0
Avg Reward: 19.45
Min Reward: 7.0
Gini Coefficient: 0.28419023136246785
20:20 Ratio: 4.689655172413793
Max-min Ratio: 6.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_23-11-12
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 482.0
  episode_reward_mean: 337.18
  episode_reward_min: 224.0
  episodes_this_iter: 1
  episodes_total: 155
  experiment_id: 35d66058da2d4c9882f832ee91e4aa4a
  hostname: gpu011
  info:
    apply_time_ms: 2.875
    dispatch_time_ms: 5.66
    learner:
      cur_lr: 0.001153539982624352
      grad_gnorm: 16.944698333740234
      policy_entropy: 179.1724853515625
      policy_loss: -4.084774494171143
      var_gnorm: 19.927282333374023
      vf_explained_var: 5.960464477539063e-08
      vf_loss: 0.1152305006980896
    num_steps_sampled: 3120000
    num_steps_trained: 3120000
    wait_time_ms: 264.107
  iterations_since_restore: 156
  node_ip: 172.17.8.11
  num_metric_batches_dropped: 0
  pid: 25504
  policy_reward_mean: {}
  time_since_restore: 4401.93141245842
  time_this_iter_s: 27.419312715530396
  time_total_s: 4401.93141245842
  timestamp: 1593918672
  timesteps_since_restore: 3120000
  timesteps_this_iter: 20000
  timesteps_total: 3120000
  training_iteration: 156
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=25504], 4401 s, 156 iter, 3120000 ts, 337 rew

agent-1: 18.0
agent-2: 15.0
agent-3: 16.0
agent-4: 12.0
agent-5: 9.0
agent-6: 10.0
agent-7: 5.0
agent-8: 7.0
agent-9: 33.0
agent-10: 30.0
agent-11: 20.0
agent-12: 20.0
agent-13: 9.0
agent-14: 3.0
agent-15: 23.0
agent-16: 20.0
agent-17: 17.0
agent-18: 18.0
agent-19: 3.0
agent-20: 29.0
Sum Reward: 317.0
Avg Reward: 15.85
Min Reward: 3.0
Gini Coefficient: 0.30394321766561516
20:20 Ratio: 6.388888888888889
Max-min Ratio: 11.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_23-11-39
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 482.0
  episode_reward_mean: 337.75
  episode_reward_min: 224.0
  episodes_this_iter: 1
  episodes_total: 156
  experiment_id: 35d66058da2d4c9882f832ee91e4aa4a
  hostname: gpu011
  info:
    apply_time_ms: 4.19
    dispatch_time_ms: 7.654
    learner:
      cur_lr: 0.0011522079585120082
      grad_gnorm: 33.15068435668945
      policy_entropy: 185.93002319335938
      policy_loss: -12.322059631347656
      var_gnorm: 19.937013626098633
      vf_explained_var: 0.0
      vf_loss: 0.43186095356941223
    num_steps_sampled: 3140000
    num_steps_trained: 3140000
    wait_time_ms: 265.458
  iterations_since_restore: 157
  node_ip: 172.17.8.11
  num_metric_batches_dropped: 0
  pid: 25504
  policy_reward_mean: {}
  time_since_restore: 4429.403334379196
  time_this_iter_s: 27.471921920776367
  time_total_s: 4429.403334379196
  timestamp: 1593918699
  timesteps_since_restore: 3140000
  timesteps_this_iter: 20000
  timesteps_total: 3140000
  training_iteration: 157
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=25504], 4429 s, 157 iter, 3140000 ts, 338 rew

agent-1: 32.0
agent-2: 22.0
agent-3: 13.0
agent-4: 29.0
agent-5: 19.0
agent-6: 28.0
agent-7: 30.0
agent-8: 20.0
agent-9: 9.0
agent-10: 19.0
agent-11: 21.0
agent-12: 5.0
agent-13: 18.0
agent-14: 22.0
agent-15: 27.0
agent-16: 28.0
agent-17: 18.0
agent-18: 11.0
agent-19: 9.0
agent-20: 5.0
Sum Reward: 385.0
Avg Reward: 19.25
Min Reward: 5.0
Gini Coefficient: 0.24064935064935064
20:20 Ratio: 4.25
Max-min Ratio: 6.4
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_23-12-07
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 482.0
  episode_reward_mean: 338.52
  episode_reward_min: 224.0
  episodes_this_iter: 1
  episodes_total: 157
  experiment_id: 35d66058da2d4c9882f832ee91e4aa4a
  hostname: gpu011
  info:
    apply_time_ms: 3.417
    dispatch_time_ms: 5.937
    learner:
      cur_lr: 0.0011508760508149862
      grad_gnorm: 19.50690269470215
      policy_entropy: 180.25363159179688
      policy_loss: -5.717522144317627
      var_gnorm: 19.94916534423828
      vf_explained_var: 1.7881393432617188e-07
      vf_loss: 0.15306513011455536
    num_steps_sampled: 3160000
    num_steps_trained: 3160000
    wait_time_ms: 271.609
  iterations_since_restore: 158
  node_ip: 172.17.8.11
  num_metric_batches_dropped: 0
  pid: 25504
  policy_reward_mean: {}
  time_since_restore: 4457.0447742938995
  time_this_iter_s: 27.64143991470337
  time_total_s: 4457.0447742938995
  timestamp: 1593918727
  timesteps_since_restore: 3160000
  timesteps_this_iter: 20000
  timesteps_total: 3160000
  training_iteration: 158
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=25504], 4457 s, 158 iter, 3160000 ts, 339 rew

agent-1: 8.0
agent-2: 10.0
agent-3: 8.0
agent-4: 10.0
agent-5: 13.0
agent-6: 7.0
agent-7: 13.0
agent-8: 9.0
agent-9: 14.0
agent-10: 14.0
agent-11: 9.0
agent-12: 13.0
agent-13: 8.0
agent-14: 17.0
agent-15: 13.0
agent-16: 16.0
agent-17: 13.0
agent-18: 18.0
agent-19: 9.0
agent-20: 9.0
Sum Reward: 231.0
Avg Reward: 11.55
Min Reward: 7.0
Gini Coefficient: 0.1538961038961039
20:20 Ratio: 2.096774193548387
Max-min Ratio: 2.5714285714285716
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_23-12-34
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 482.0
  episode_reward_mean: 337.21
  episode_reward_min: 224.0
  episodes_this_iter: 1
  episodes_total: 158
  experiment_id: 35d66058da2d4c9882f832ee91e4aa4a
  hostname: gpu011
  info:
    apply_time_ms: 3.718
    dispatch_time_ms: 5.463
    learner:
      cur_lr: 0.0011495440267026424
      grad_gnorm: 9.547479629516602
      policy_entropy: 194.85943603515625
      policy_loss: -3.283958911895752
      var_gnorm: 19.94850730895996
      vf_explained_var: 0.0
      vf_loss: 4.724638938903809
    num_steps_sampled: 3180000
    num_steps_trained: 3180000
    wait_time_ms: 268.683
  iterations_since_restore: 159
  node_ip: 172.17.8.11
  num_metric_batches_dropped: 0
  pid: 25504
  policy_reward_mean: {}
  time_since_restore: 4484.483252763748
  time_this_iter_s: 27.438478469848633
  time_total_s: 4484.483252763748
  timestamp: 1593918754
  timesteps_since_restore: 3180000
  timesteps_this_iter: 20000
  timesteps_total: 3180000
  training_iteration: 159
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=25504], 4484 s, 159 iter, 3180000 ts, 337 rew

agent-1: 21.0
agent-2: 1.0
agent-3: 21.0
agent-4: 10.0
agent-5: 12.0
agent-6: 15.0
agent-7: 22.0
agent-8: 1.0
agent-9: 16.0
agent-10: 19.0
agent-11: 25.0
agent-12: 8.0
agent-13: 15.0
agent-14: 11.0
agent-15: 29.0
agent-16: 21.0
agent-17: 14.0
agent-18: 22.0
agent-19: 31.0
agent-20: 9.0
Sum Reward: 323.0
Avg Reward: 16.15
Min Reward: 1.0
Gini Coefficient: 0.27910216718266256
20:20 Ratio: 5.631578947368421
Max-min Ratio: 31.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_23-13-02
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 482.0
  episode_reward_mean: 337.18
  episode_reward_min: 224.0
  episodes_this_iter: 1
  episodes_total: 159
  experiment_id: 35d66058da2d4c9882f832ee91e4aa4a
  hostname: gpu011
  info:
    apply_time_ms: 2.905
    dispatch_time_ms: 6.277
    learner:
      cur_lr: 0.0011482120025902987
      grad_gnorm: 20.46636199951172
      policy_entropy: 178.6700897216797
      policy_loss: -5.845151424407959
      var_gnorm: 19.935277938842773
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 0.16740573942661285
    num_steps_sampled: 3200000
    num_steps_trained: 3200000
    wait_time_ms: 270.77
  iterations_since_restore: 160
  node_ip: 172.17.8.11
  num_metric_batches_dropped: 0
  pid: 25504
  policy_reward_mean: {}
  time_since_restore: 4511.916771888733
  time_this_iter_s: 27.43351912498474
  time_total_s: 4511.916771888733
  timestamp: 1593918782
  timesteps_since_restore: 3200000
  timesteps_this_iter: 20000
  timesteps_total: 3200000
  training_iteration: 160
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=25504], 4511 s, 160 iter, 3200000 ts, 337 rew

agent-1: 19.0
agent-2: 14.0
agent-3: 3.0
agent-4: 9.0
agent-5: 22.0
agent-6: 31.0
agent-7: 23.0
agent-8: 6.0
agent-9: 10.0
agent-10: 29.0
agent-11: 9.0
agent-12: 19.0
agent-13: 13.0
agent-14: 15.0
agent-15: 26.0
agent-16: 9.0
agent-17: 11.0
agent-18: 10.0
agent-19: 9.0
agent-20: 25.0
Sum Reward: 312.0
Avg Reward: 15.6
Min Reward: 3.0
Gini Coefficient: 0.2849358974358974
20:20 Ratio: 4.111111111111111
Max-min Ratio: 10.333333333333334
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_23-13-29
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 482.0
  episode_reward_mean: 336.59
  episode_reward_min: 224.0
  episodes_this_iter: 1
  episodes_total: 160
  experiment_id: 35d66058da2d4c9882f832ee91e4aa4a
  hostname: gpu011
  info:
    apply_time_ms: 3.845
    dispatch_time_ms: 7.131
    learner:
      cur_lr: 0.0011468799784779549
      grad_gnorm: 11.80700397491455
      policy_entropy: 175.32476806640625
      policy_loss: 2.8556957244873047
      var_gnorm: 19.93741226196289
      vf_explained_var: 0.0
      vf_loss: 7.994077682495117
    num_steps_sampled: 3220000
    num_steps_trained: 3220000
    wait_time_ms: 258.466
  iterations_since_restore: 161
  node_ip: 172.17.8.11
  num_metric_batches_dropped: 0
  pid: 25504
  policy_reward_mean: {}
  time_since_restore: 4539.249019384384
  time_this_iter_s: 27.332247495651245
  time_total_s: 4539.249019384384
  timestamp: 1593918809
  timesteps_since_restore: 3220000
  timesteps_this_iter: 20000
  timesteps_total: 3220000
  training_iteration: 161
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=25504], 4539 s, 161 iter, 3220000 ts, 337 rew

agent-1: 22.0
agent-2: 15.0
agent-3: 10.0
agent-4: 20.0
agent-5: 10.0
agent-6: 4.0
agent-7: 15.0
agent-8: 20.0
agent-9: 12.0
agent-10: 26.0
agent-11: 16.0
agent-12: 7.0
agent-13: 5.0
agent-14: 11.0
agent-15: 6.0
agent-16: 13.0
agent-17: 21.0
agent-18: 12.0
agent-19: 20.0
agent-20: 3.0
Sum Reward: 268.0
Avg Reward: 13.4
Min Reward: 3.0
Gini Coefficient: 0.27425373134328357
20:20 Ratio: 4.944444444444445
Max-min Ratio: 8.666666666666666
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_23-13-57
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 482.0
  episode_reward_mean: 335.8
  episode_reward_min: 224.0
  episodes_this_iter: 1
  episodes_total: 161
  experiment_id: 35d66058da2d4c9882f832ee91e4aa4a
  hostname: gpu011
  info:
    apply_time_ms: 2.956
    dispatch_time_ms: 7.844
    learner:
      cur_lr: 0.001145547954365611
      grad_gnorm: 32.06954574584961
      policy_entropy: 175.25860595703125
      policy_loss: 6.312542915344238
      var_gnorm: 19.940082550048828
      vf_explained_var: 1.1920928955078125e-07
      vf_loss: 16.09056854248047
    num_steps_sampled: 3240000
    num_steps_trained: 3240000
    wait_time_ms: 257.205
  iterations_since_restore: 162
  node_ip: 172.17.8.11
  num_metric_batches_dropped: 0
  pid: 25504
  policy_reward_mean: {}
  time_since_restore: 4566.591498374939
  time_this_iter_s: 27.34247899055481
  time_total_s: 4566.591498374939
  timestamp: 1593918837
  timesteps_since_restore: 3240000
  timesteps_this_iter: 20000
  timesteps_total: 3240000
  training_iteration: 162
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=25504], 4566 s, 162 iter, 3240000 ts, 336 rew

agent-1: 7.0
agent-2: 10.0
agent-3: 21.0
agent-4: 21.0
agent-5: 23.0
agent-6: 16.0
agent-7: 25.0
agent-8: 22.0
agent-9: 20.0
agent-10: 43.0
agent-11: 17.0
agent-12: 11.0
agent-13: 14.0
agent-14: 20.0
agent-15: 13.0
agent-16: 30.0
agent-17: 18.0
agent-18: 25.0
agent-19: 14.0
agent-20: 31.0
Sum Reward: 401.0
Avg Reward: 20.05
Min Reward: 7.0
Gini Coefficient: 0.2188279301745636
20:20 Ratio: 3.1463414634146343
Max-min Ratio: 6.142857142857143
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_23-14-24
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 482.0
  episode_reward_mean: 336.34
  episode_reward_min: 224.0
  episodes_this_iter: 1
  episodes_total: 162
  experiment_id: 35d66058da2d4c9882f832ee91e4aa4a
  hostname: gpu011
  info:
    apply_time_ms: 2.602
    dispatch_time_ms: 5.938
    learner:
      cur_lr: 0.0011442160466685891
      grad_gnorm: 29.81843376159668
      policy_entropy: 177.8382568359375
      policy_loss: -10.970775604248047
      var_gnorm: 19.947036743164062
      vf_explained_var: 0.0
      vf_loss: 0.3557153642177582
    num_steps_sampled: 3260000
    num_steps_trained: 3260000
    wait_time_ms: 262.436
  iterations_since_restore: 163
  node_ip: 172.17.8.11
  num_metric_batches_dropped: 0
  pid: 25504
  policy_reward_mean: {}
  time_since_restore: 4594.140884399414
  time_this_iter_s: 27.549386024475098
  time_total_s: 4594.140884399414
  timestamp: 1593918864
  timesteps_since_restore: 3260000
  timesteps_this_iter: 20000
  timesteps_total: 3260000
  training_iteration: 163
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=25504], 4594 s, 163 iter, 3260000 ts, 336 rew

agent-1: 27.0
agent-2: 12.0
agent-3: 11.0
agent-4: 10.0
agent-5: 12.0
agent-6: 16.0
agent-7: 11.0
agent-8: 10.0
agent-9: 14.0
agent-10: 19.0
agent-11: 19.0
agent-12: 4.0
agent-13: 6.0
agent-14: 31.0
agent-15: 9.0
agent-16: 26.0
agent-17: 30.0
agent-18: 26.0
agent-19: 23.0
agent-20: 9.0
Sum Reward: 325.0
Avg Reward: 16.25
Min Reward: 4.0
Gini Coefficient: 0.2792307692307692
20:20 Ratio: 4.071428571428571
Max-min Ratio: 7.75
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_23-14-52
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 482.0
  episode_reward_mean: 337.04
  episode_reward_min: 224.0
  episodes_this_iter: 1
  episodes_total: 163
  experiment_id: 35d66058da2d4c9882f832ee91e4aa4a
  hostname: gpu011
  info:
    apply_time_ms: 3.318
    dispatch_time_ms: 5.325
    learner:
      cur_lr: 0.0011428840225562453
      grad_gnorm: 40.000003814697266
      policy_entropy: 149.1401824951172
      policy_loss: 38.852577209472656
      var_gnorm: 19.948461532592773
      vf_explained_var: 5.960464477539063e-08
      vf_loss: 39.26475524902344
    num_steps_sampled: 3280000
    num_steps_trained: 3280000
    wait_time_ms: 257.169
  iterations_since_restore: 164
  node_ip: 172.17.8.11
  num_metric_batches_dropped: 0
  pid: 25504
  policy_reward_mean: {}
  time_since_restore: 4621.445194721222
  time_this_iter_s: 27.30431032180786
  time_total_s: 4621.445194721222
  timestamp: 1593918892
  timesteps_since_restore: 3280000
  timesteps_this_iter: 20000
  timesteps_total: 3280000
  training_iteration: 164
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=25504], 4621 s, 164 iter, 3280000 ts, 337 rew

agent-1: 11.0
agent-2: 10.0
agent-3: 14.0
agent-4: 7.0
agent-5: 12.0
agent-6: 18.0
agent-7: 19.0
agent-8: 20.0
agent-9: 14.0
agent-10: 11.0
agent-11: 29.0
agent-12: 30.0
agent-13: 8.0
agent-14: 14.0
agent-15: 28.0
agent-16: 28.0
agent-17: 26.0
agent-18: 10.0
agent-19: 12.0
agent-20: 22.0
Sum Reward: 343.0
Avg Reward: 17.15
Min Reward: 7.0
Gini Coefficient: 0.24271137026239067
20:20 Ratio: 3.2857142857142856
Max-min Ratio: 4.285714285714286
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_23-15-19
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 482.0
  episode_reward_mean: 336.92
  episode_reward_min: 224.0
  episodes_this_iter: 1
  episodes_total: 164
  experiment_id: 35d66058da2d4c9882f832ee91e4aa4a
  hostname: gpu011
  info:
    apply_time_ms: 3.563
    dispatch_time_ms: 6.993
    learner:
      cur_lr: 0.0011415519984439015
      grad_gnorm: 39.64433288574219
      policy_entropy: 179.50099182128906
      policy_loss: -13.480875015258789
      var_gnorm: 19.952899932861328
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 1.5310890674591064
    num_steps_sampled: 3300000
    num_steps_trained: 3300000
    wait_time_ms: 261.858
  iterations_since_restore: 165
  node_ip: 172.17.8.11
  num_metric_batches_dropped: 0
  pid: 25504
  policy_reward_mean: {}
  time_since_restore: 4648.761564493179
  time_this_iter_s: 27.316369771957397
  time_total_s: 4648.761564493179
  timestamp: 1593918919
  timesteps_since_restore: 3300000
  timesteps_this_iter: 20000
  timesteps_total: 3300000
  training_iteration: 165
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=25504], 4648 s, 165 iter, 3300000 ts, 337 rew

agent-1: 31.0
agent-2: 34.0
agent-3: 15.0
agent-4: 18.0
agent-5: 24.0
agent-6: 25.0
agent-7: 18.0
agent-8: 12.0
agent-9: 36.0
agent-10: 11.0
agent-11: 15.0
agent-12: 35.0
agent-13: 34.0
agent-14: 11.0
agent-15: 15.0
agent-16: 37.0
agent-17: 43.0
agent-18: 42.0
agent-19: 18.0
agent-20: 9.0
Sum Reward: 483.0
Avg Reward: 24.15
Min Reward: 9.0
Gini Coefficient: 0.25786749482401655
20:20 Ratio: 3.6744186046511627
Max-min Ratio: 4.777777777777778
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_23-15-46
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 483.0
  episode_reward_mean: 338.34
  episode_reward_min: 224.0
  episodes_this_iter: 1
  episodes_total: 165
  experiment_id: 35d66058da2d4c9882f832ee91e4aa4a
  hostname: gpu011
  info:
    apply_time_ms: 2.635
    dispatch_time_ms: 5.283
    learner:
      cur_lr: 0.0011402199743315578
      grad_gnorm: 22.80078887939453
      policy_entropy: 174.20030212402344
      policy_loss: -6.437421798706055
      var_gnorm: 19.954063415527344
      vf_explained_var: 0.0
      vf_loss: 0.20705920457839966
    num_steps_sampled: 3320000
    num_steps_trained: 3320000
    wait_time_ms: 270.857
  iterations_since_restore: 166
  node_ip: 172.17.8.11
  num_metric_batches_dropped: 0
  pid: 25504
  policy_reward_mean: {}
  time_since_restore: 4676.055124044418
  time_this_iter_s: 27.293559551239014
  time_total_s: 4676.055124044418
  timestamp: 1593918946
  timesteps_since_restore: 3320000
  timesteps_this_iter: 20000
  timesteps_total: 3320000
  training_iteration: 166
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=25504], 4676 s, 166 iter, 3320000 ts, 338 rew

agent-1: 13.0
agent-2: 8.0
agent-3: 7.0
agent-4: 20.0
agent-5: 15.0
agent-6: 26.0
agent-7: 24.0
agent-8: 12.0
agent-9: 26.0
agent-10: 10.0
agent-11: 12.0
agent-12: 29.0
agent-13: 11.0
agent-14: 18.0
agent-15: 13.0
agent-16: 11.0
agent-17: 19.0
agent-18: 17.0
agent-19: 17.0
agent-20: 17.0
Sum Reward: 325.0
Avg Reward: 16.25
Min Reward: 7.0
Gini Coefficient: 0.21092307692307694
20:20 Ratio: 2.9166666666666665
Max-min Ratio: 4.142857142857143
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_23-16-14
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 483.0
  episode_reward_mean: 338.84
  episode_reward_min: 224.0
  episodes_this_iter: 1
  episodes_total: 166
  experiment_id: 35d66058da2d4c9882f832ee91e4aa4a
  hostname: gpu011
  info:
    apply_time_ms: 2.658
    dispatch_time_ms: 5.865
    learner:
      cur_lr: 0.001138887950219214
      grad_gnorm: 29.13926887512207
      policy_entropy: 147.53726196289062
      policy_loss: -8.299633979797363
      var_gnorm: 19.957172393798828
      vf_explained_var: 0.0
      vf_loss: 0.33429789543151855
    num_steps_sampled: 3340000
    num_steps_trained: 3340000
    wait_time_ms: 273.085
  iterations_since_restore: 167
  node_ip: 172.17.8.11
  num_metric_batches_dropped: 0
  pid: 25504
  policy_reward_mean: {}
  time_since_restore: 4703.486305952072
  time_this_iter_s: 27.43118190765381
  time_total_s: 4703.486305952072
  timestamp: 1593918974
  timesteps_since_restore: 3340000
  timesteps_this_iter: 20000
  timesteps_total: 3340000
  training_iteration: 167
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=25504], 4703 s, 167 iter, 3340000 ts, 339 rew

agent-1: 16.0
agent-2: 18.0
agent-3: 20.0
agent-4: 25.0
agent-5: 29.0
agent-6: 28.0
agent-7: 10.0
agent-8: 26.0
agent-9: 16.0
agent-10: 3.0
agent-11: 11.0
agent-12: 9.0
agent-13: 25.0
agent-14: 12.0
agent-15: 16.0
agent-16: 5.0
agent-17: 7.0
agent-18: 1.0
agent-19: 13.0
agent-20: 11.0
Sum Reward: 301.0
Avg Reward: 15.05
Min Reward: 1.0
Gini Coefficient: 0.30913621262458474
20:20 Ratio: 6.75
Max-min Ratio: 29.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_23-16-41
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 483.0
  episode_reward_mean: 338.34
  episode_reward_min: 224.0
  episodes_this_iter: 1
  episodes_total: 167
  experiment_id: 35d66058da2d4c9882f832ee91e4aa4a
  hostname: gpu011
  info:
    apply_time_ms: 3.309
    dispatch_time_ms: 7.057
    learner:
      cur_lr: 0.001137556042522192
      grad_gnorm: 22.564382553100586
      policy_entropy: 171.85629272460938
      policy_loss: 0.2857680320739746
      var_gnorm: 19.960224151611328
      vf_explained_var: 1.1920928955078125e-07
      vf_loss: 6.857534408569336
    num_steps_sampled: 3360000
    num_steps_trained: 3360000
    wait_time_ms: 258.081
  iterations_since_restore: 168
  node_ip: 172.17.8.11
  num_metric_batches_dropped: 0
  pid: 25504
  policy_reward_mean: {}
  time_since_restore: 4730.655204772949
  time_this_iter_s: 27.168898820877075
  time_total_s: 4730.655204772949
  timestamp: 1593919001
  timesteps_since_restore: 3360000
  timesteps_this_iter: 20000
  timesteps_total: 3360000
  training_iteration: 168
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=25504], 4730 s, 168 iter, 3360000 ts, 338 rew

agent-1: 41.0
agent-2: 37.0
agent-3: 20.0
agent-4: 25.0
agent-5: 18.0
agent-6: 14.0
agent-7: 31.0
agent-8: 22.0
agent-9: 32.0
agent-10: 27.0
agent-11: 17.0
agent-12: 38.0
agent-13: 22.0
agent-14: 20.0
agent-15: 31.0
agent-16: 15.0
agent-17: 37.0
agent-18: 18.0
agent-19: 19.0
agent-20: 18.0
Sum Reward: 502.0
Avg Reward: 25.1
Min Reward: 14.0
Gini Coefficient: 0.1848605577689243
20:20 Ratio: 2.390625
Max-min Ratio: 2.9285714285714284
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_23-17-09
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 502.0
  episode_reward_mean: 340.35
  episode_reward_min: 224.0
  episodes_this_iter: 1
  episodes_total: 168
  experiment_id: 35d66058da2d4c9882f832ee91e4aa4a
  hostname: gpu011
  info:
    apply_time_ms: 3.12
    dispatch_time_ms: 9.927
    learner:
      cur_lr: 0.0011362240184098482
      grad_gnorm: 21.244836807250977
      policy_entropy: 192.83407592773438
      policy_loss: 4.9864044189453125
      var_gnorm: 19.96116828918457
      vf_explained_var: 0.0
      vf_loss: 28.732284545898438
    num_steps_sampled: 3380000
    num_steps_trained: 3380000
    wait_time_ms: 287.654
  iterations_since_restore: 169
  node_ip: 172.17.8.11
  num_metric_batches_dropped: 0
  pid: 25504
  policy_reward_mean: {}
  time_since_restore: 4758.274840354919
  time_this_iter_s: 27.619635581970215
  time_total_s: 4758.274840354919
  timestamp: 1593919029
  timesteps_since_restore: 3380000
  timesteps_this_iter: 20000
  timesteps_total: 3380000
  training_iteration: 169
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=25504], 4758 s, 169 iter, 3380000 ts, 340 rew

agent-1: 20.0
agent-2: 7.0
agent-3: 15.0
agent-4: 25.0
agent-5: 26.0
agent-6: 16.0
agent-7: 28.0
agent-8: 15.0
agent-9: 16.0
agent-10: 22.0
agent-11: 19.0
agent-12: 23.0
agent-13: 12.0
agent-14: 28.0
agent-15: 2.0
agent-16: 29.0
agent-17: 19.0
agent-18: 32.0
agent-19: 18.0
agent-20: 16.0
Sum Reward: 388.0
Avg Reward: 19.4
Min Reward: 2.0
Gini Coefficient: 0.211340206185567
20:20 Ratio: 3.25
Max-min Ratio: 16.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_23-17-36
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 502.0
  episode_reward_mean: 341.42
  episode_reward_min: 224.0
  episodes_this_iter: 1
  episodes_total: 169
  experiment_id: 35d66058da2d4c9882f832ee91e4aa4a
  hostname: gpu011
  info:
    apply_time_ms: 3.038
    dispatch_time_ms: 7.708
    learner:
      cur_lr: 0.0011348919942975044
      grad_gnorm: 25.7637996673584
      policy_entropy: 191.50811767578125
      policy_loss: -8.654764175415039
      var_gnorm: 19.96059226989746
      vf_explained_var: 0.0
      vf_loss: 0.2676158547401428
    num_steps_sampled: 3400000
    num_steps_trained: 3400000
    wait_time_ms: 266.626
  iterations_since_restore: 170
  node_ip: 172.17.8.11
  num_metric_batches_dropped: 0
  pid: 25504
  policy_reward_mean: {}
  time_since_restore: 4785.413068532944
  time_this_iter_s: 27.138228178024292
  time_total_s: 4785.413068532944
  timestamp: 1593919056
  timesteps_since_restore: 3400000
  timesteps_this_iter: 20000
  timesteps_total: 3400000
  training_iteration: 170
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=25504], 4785 s, 170 iter, 3400000 ts, 341 rew

agent-1: 11.0
agent-2: 4.0
agent-3: 4.0
agent-4: 30.0
agent-5: 18.0
agent-6: 13.0
agent-7: 24.0
agent-8: 8.0
agent-9: 13.0
agent-10: 9.0
agent-11: 12.0
agent-12: 4.0
agent-13: 28.0
agent-14: 36.0
agent-15: 31.0
agent-16: 17.0
agent-17: 9.0
agent-18: 15.0
agent-19: 30.0
agent-20: 9.0
Sum Reward: 325.0
Avg Reward: 16.25
Min Reward: 4.0
Gini Coefficient: 0.33676923076923077
20:20 Ratio: 6.35
Max-min Ratio: 9.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_23-18-03
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 502.0
  episode_reward_mean: 341.94
  episode_reward_min: 224.0
  episodes_this_iter: 1
  episodes_total: 170
  experiment_id: 35d66058da2d4c9882f832ee91e4aa4a
  hostname: gpu011
  info:
    apply_time_ms: 3.503
    dispatch_time_ms: 6.408
    learner:
      cur_lr: 0.0011335599701851606
      grad_gnorm: 18.781686782836914
      policy_entropy: 172.170654296875
      policy_loss: -3.13027286529541
      var_gnorm: 19.961383819580078
      vf_explained_var: 0.0
      vf_loss: 4.006898880004883
    num_steps_sampled: 3420000
    num_steps_trained: 3420000
    wait_time_ms: 265.381
  iterations_since_restore: 171
  node_ip: 172.17.8.11
  num_metric_batches_dropped: 0
  pid: 25504
  policy_reward_mean: {}
  time_since_restore: 4812.828095436096
  time_this_iter_s: 27.415026903152466
  time_total_s: 4812.828095436096
  timestamp: 1593919083
  timesteps_since_restore: 3420000
  timesteps_this_iter: 20000
  timesteps_total: 3420000
  training_iteration: 171
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=25504], 4812 s, 171 iter, 3420000 ts, 342 rew

agent-1: 21.0
agent-2: 11.0
agent-3: 14.0
agent-4: 15.0
agent-5: 5.0
agent-6: 4.0
agent-7: 11.0
agent-8: 18.0
agent-9: 10.0
agent-10: 19.0
agent-11: 6.0
agent-12: 30.0
agent-13: 14.0
agent-14: 7.0
agent-15: 12.0
agent-16: 16.0
agent-17: 17.0
agent-18: 29.0
agent-19: 13.0
agent-20: 28.0
Sum Reward: 300.0
Avg Reward: 15.0
Min Reward: 4.0
Gini Coefficient: 0.274
20:20 Ratio: 4.909090909090909
Max-min Ratio: 7.5
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_23-18-31
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 502.0
  episode_reward_mean: 341.91
  episode_reward_min: 224.0
  episodes_this_iter: 1
  episodes_total: 171
  experiment_id: 35d66058da2d4c9882f832ee91e4aa4a
  hostname: gpu011
  info:
    apply_time_ms: 2.693
    dispatch_time_ms: 5.752
    learner:
      cur_lr: 0.0011322279460728168
      grad_gnorm: 11.340537071228027
      policy_entropy: 170.528564453125
      policy_loss: -2.8213508129119873
      var_gnorm: 19.959909439086914
      vf_explained_var: 0.0
      vf_loss: 1.8792645931243896
    num_steps_sampled: 3440000
    num_steps_trained: 3440000
    wait_time_ms: 264.591
  iterations_since_restore: 172
  node_ip: 172.17.8.11
  num_metric_batches_dropped: 0
  pid: 25504
  policy_reward_mean: {}
  time_since_restore: 4840.2561547756195
  time_this_iter_s: 27.428059339523315
  time_total_s: 4840.2561547756195
  timestamp: 1593919111
  timesteps_since_restore: 3440000
  timesteps_this_iter: 20000
  timesteps_total: 3440000
  training_iteration: 172
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=25504], 4840 s, 172 iter, 3440000 ts, 342 rew

agent-1: 25.0
agent-2: 23.0
agent-3: 14.0
agent-4: 9.0
agent-5: 9.0
agent-6: 4.0
agent-7: 18.0
agent-8: 17.0
agent-9: 25.0
agent-10: 19.0
agent-11: 16.0
agent-12: 18.0
agent-13: 11.0
agent-14: 16.0
agent-15: 19.0
agent-16: 8.0
agent-17: 17.0
agent-18: 26.0
agent-19: 17.0
agent-20: 27.0
Sum Reward: 338.0
Avg Reward: 16.9
Min Reward: 4.0
Gini Coefficient: 0.207396449704142
20:20 Ratio: 3.433333333333333
Max-min Ratio: 6.75
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_23-18-58
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 502.0
  episode_reward_mean: 342.46
  episode_reward_min: 224.0
  episodes_this_iter: 1
  episodes_total: 172
  experiment_id: 35d66058da2d4c9882f832ee91e4aa4a
  hostname: gpu011
  info:
    apply_time_ms: 2.987
    dispatch_time_ms: 8.02
    learner:
      cur_lr: 0.0011308960383757949
      grad_gnorm: 24.065340042114258
      policy_entropy: 179.94500732421875
      policy_loss: -7.67330265045166
      var_gnorm: 19.95319175720215
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 0.23131069540977478
    num_steps_sampled: 3460000
    num_steps_trained: 3460000
    wait_time_ms: 262.992
  iterations_since_restore: 173
  node_ip: 172.17.8.11
  num_metric_batches_dropped: 0
  pid: 25504
  policy_reward_mean: {}
  time_since_restore: 4867.573225259781
  time_this_iter_s: 27.317070484161377
  time_total_s: 4867.573225259781
  timestamp: 1593919138
  timesteps_since_restore: 3460000
  timesteps_this_iter: 20000
  timesteps_total: 3460000
  training_iteration: 173
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=25504], 4867 s, 173 iter, 3460000 ts, 342 rew

agent-1: 34.0
agent-2: 4.0
agent-3: 13.0
agent-4: 20.0
agent-5: 16.0
agent-6: 3.0
agent-7: 23.0
agent-8: 20.0
agent-9: 13.0
agent-10: 11.0
agent-11: 11.0
agent-12: 12.0
agent-13: 19.0
agent-14: 21.0
agent-15: 4.0
agent-16: 8.0
agent-17: 9.0
agent-18: 15.0
agent-19: 25.0
agent-20: 15.0
Sum Reward: 296.0
Avg Reward: 14.8
Min Reward: 3.0
Gini Coefficient: 0.2847972972972973
20:20 Ratio: 5.421052631578948
Max-min Ratio: 11.333333333333334
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_23-19-26
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 502.0
  episode_reward_mean: 341.85
  episode_reward_min: 224.0
  episodes_this_iter: 1
  episodes_total: 173
  experiment_id: 35d66058da2d4c9882f832ee91e4aa4a
  hostname: gpu011
  info:
    apply_time_ms: 2.527
    dispatch_time_ms: 6.321
    learner:
      cur_lr: 0.001129564014263451
      grad_gnorm: 16.82573699951172
      policy_entropy: 176.94039916992188
      policy_loss: -4.600445747375488
      var_gnorm: 19.952726364135742
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 0.11209457367658615
    num_steps_sampled: 3480000
    num_steps_trained: 3480000
    wait_time_ms: 265.624
  iterations_since_restore: 174
  node_ip: 172.17.8.11
  num_metric_batches_dropped: 0
  pid: 25504
  policy_reward_mean: {}
  time_since_restore: 4895.159947872162
  time_this_iter_s: 27.58672261238098
  time_total_s: 4895.159947872162
  timestamp: 1593919166
  timesteps_since_restore: 3480000
  timesteps_this_iter: 20000
  timesteps_total: 3480000
  training_iteration: 174
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=25504], 4895 s, 174 iter, 3480000 ts, 342 rew

agent-1: 15.0
agent-2: 15.0
agent-3: 17.0
agent-4: 19.0
agent-5: 21.0
agent-6: 22.0
agent-7: 5.0
agent-8: 21.0
agent-9: 18.0
agent-10: 15.0
agent-11: 14.0
agent-12: 12.0
agent-13: 15.0
agent-14: 16.0
agent-15: 11.0
agent-16: 23.0
agent-17: 15.0
agent-18: 17.0
agent-19: 23.0
agent-20: 18.0
Sum Reward: 332.0
Avg Reward: 16.6
Min Reward: 5.0
Gini Coefficient: 0.14036144578313253
20:20 Ratio: 2.119047619047619
Max-min Ratio: 4.6
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_23-19-53
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 502.0
  episode_reward_mean: 341.79
  episode_reward_min: 224.0
  episodes_this_iter: 1
  episodes_total: 174
  experiment_id: 35d66058da2d4c9882f832ee91e4aa4a
  hostname: gpu011
  info:
    apply_time_ms: 3.429
    dispatch_time_ms: 6.032
    learner:
      cur_lr: 0.0011282319901511073
      grad_gnorm: 19.770418167114258
      policy_entropy: 176.72727966308594
      policy_loss: -7.236857891082764
      var_gnorm: 19.966384887695312
      vf_explained_var: 1.7881393432617188e-07
      vf_loss: 0.15766051411628723
    num_steps_sampled: 3500000
    num_steps_trained: 3500000
    wait_time_ms: 264.664
  iterations_since_restore: 175
  node_ip: 172.17.8.11
  num_metric_batches_dropped: 0
  pid: 25504
  policy_reward_mean: {}
  time_since_restore: 4922.698920726776
  time_this_iter_s: 27.538972854614258
  time_total_s: 4922.698920726776
  timestamp: 1593919193
  timesteps_since_restore: 3500000
  timesteps_this_iter: 20000
  timesteps_total: 3500000
  training_iteration: 175
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=25504], 4922 s, 175 iter, 3500000 ts, 342 rew

agent-1: 20.0
agent-2: 16.0
agent-3: 13.0
agent-4: 12.0
agent-5: 11.0
agent-6: 26.0
agent-7: 18.0
agent-8: 23.0
agent-9: 15.0
agent-10: 16.0
agent-11: 16.0
agent-12: 10.0
agent-13: 15.0
agent-14: 14.0
agent-15: 2.0
agent-16: 5.0
agent-17: 20.0
agent-18: 10.0
agent-19: 5.0
agent-20: 11.0
Sum Reward: 278.0
Avg Reward: 13.9
Min Reward: 2.0
Gini Coefficient: 0.23597122302158274
20:20 Ratio: 4.045454545454546
Max-min Ratio: 13.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_23-20-21
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 502.0
  episode_reward_mean: 341.54
  episode_reward_min: 224.0
  episodes_this_iter: 1
  episodes_total: 175
  experiment_id: 35d66058da2d4c9882f832ee91e4aa4a
  hostname: gpu011
  info:
    apply_time_ms: 3.056
    dispatch_time_ms: 7.286
    learner:
      cur_lr: 0.0011268999660387635
      grad_gnorm: 19.420015335083008
      policy_entropy: 177.4898223876953
      policy_loss: -5.569650650024414
      var_gnorm: 19.965824127197266
      vf_explained_var: 1.1920928955078125e-07
      vf_loss: 0.14905384182929993
    num_steps_sampled: 3520000
    num_steps_trained: 3520000
    wait_time_ms: 264.643
  iterations_since_restore: 176
  node_ip: 172.17.8.11
  num_metric_batches_dropped: 0
  pid: 25504
  policy_reward_mean: {}
  time_since_restore: 4950.161883354187
  time_this_iter_s: 27.46296262741089
  time_total_s: 4950.161883354187
  timestamp: 1593919221
  timesteps_since_restore: 3520000
  timesteps_this_iter: 20000
  timesteps_total: 3520000
  training_iteration: 176
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=25504], 4950 s, 176 iter, 3520000 ts, 342 rew

agent-1: 6.0
agent-2: 12.0
agent-3: 6.0
agent-4: 14.0
agent-5: 15.0
agent-6: 9.0
agent-7: 25.0
agent-8: 22.0
agent-9: 17.0
agent-10: 9.0
agent-11: 21.0
agent-12: 14.0
agent-13: 19.0
agent-14: 17.0
agent-15: 12.0
agent-16: 7.0
agent-17: 18.0
agent-18: 8.0
agent-19: 13.0
agent-20: 11.0
Sum Reward: 275.0
Avg Reward: 13.75
Min Reward: 6.0
Gini Coefficient: 0.222
20:20 Ratio: 3.2222222222222223
Max-min Ratio: 4.166666666666667
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_23-20-48
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 502.0
  episode_reward_mean: 340.46
  episode_reward_min: 224.0
  episodes_this_iter: 1
  episodes_total: 176
  experiment_id: 35d66058da2d4c9882f832ee91e4aa4a
  hostname: gpu011
  info:
    apply_time_ms: 3.267
    dispatch_time_ms: 7.747
    learner:
      cur_lr: 0.0011255679419264197
      grad_gnorm: 40.0
      policy_entropy: 182.16665649414062
      policy_loss: -13.392914772033691
      var_gnorm: 19.96763038635254
      vf_explained_var: 0.0
      vf_loss: 1.039336919784546
    num_steps_sampled: 3540000
    num_steps_trained: 3540000
    wait_time_ms: 276.596
  iterations_since_restore: 177
  node_ip: 172.17.8.11
  num_metric_batches_dropped: 0
  pid: 25504
  policy_reward_mean: {}
  time_since_restore: 4977.613283157349
  time_this_iter_s: 27.45139980316162
  time_total_s: 4977.613283157349
  timestamp: 1593919248
  timesteps_since_restore: 3540000
  timesteps_this_iter: 20000
  timesteps_total: 3540000
  training_iteration: 177
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=25504], 4977 s, 177 iter, 3540000 ts, 340 rew

agent-1: 23.0
agent-2: 24.0
agent-3: 38.0
agent-4: 18.0
agent-5: 12.0
agent-6: 14.0
agent-7: 13.0
agent-8: 29.0
agent-9: 19.0
agent-10: 21.0
agent-11: 8.0
agent-12: 14.0
agent-13: 17.0
agent-14: 4.0
agent-15: 18.0
agent-16: 21.0
agent-17: 20.0
agent-18: 11.0
agent-19: 18.0
agent-20: 12.0
Sum Reward: 354.0
Avg Reward: 17.7
Min Reward: 4.0
Gini Coefficient: 0.22344632768361583
20:20 Ratio: 3.257142857142857
Max-min Ratio: 9.5
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_23-21-16
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 502.0
  episode_reward_mean: 340.72
  episode_reward_min: 224.0
  episodes_this_iter: 1
  episodes_total: 177
  experiment_id: 35d66058da2d4c9882f832ee91e4aa4a
  hostname: gpu011
  info:
    apply_time_ms: 2.879
    dispatch_time_ms: 7.671
    learner:
      cur_lr: 0.0011242360342293978
      grad_gnorm: 18.133846282958984
      policy_entropy: 169.07192993164062
      policy_loss: -5.049973487854004
      var_gnorm: 19.958189010620117
      vf_explained_var: 0.0
      vf_loss: 0.13263222575187683
    num_steps_sampled: 3560000
    num_steps_trained: 3560000
    wait_time_ms: 274.805
  iterations_since_restore: 178
  node_ip: 172.17.8.11
  num_metric_batches_dropped: 0
  pid: 25504
  policy_reward_mean: {}
  time_since_restore: 5004.986839771271
  time_this_iter_s: 27.37355661392212
  time_total_s: 5004.986839771271
  timestamp: 1593919276
  timesteps_since_restore: 3560000
  timesteps_this_iter: 20000
  timesteps_total: 3560000
  training_iteration: 178
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=25504], 5004 s, 178 iter, 3560000 ts, 341 rew

agent-1: 14.0
agent-2: 20.0
agent-3: 26.0
agent-4: 13.0
agent-5: 19.0
agent-6: 5.0
agent-7: 25.0
agent-8: 21.0
agent-9: 18.0
agent-10: 20.0
agent-11: 18.0
agent-12: 13.0
agent-13: 20.0
agent-14: 9.0
agent-15: 19.0
agent-16: 22.0
agent-17: 12.0
agent-18: 13.0
agent-19: 9.0
agent-20: 27.0
Sum Reward: 343.0
Avg Reward: 17.15
Min Reward: 5.0
Gini Coefficient: 0.19110787172011662
20:20 Ratio: 2.857142857142857
Max-min Ratio: 5.4
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_23-21-57
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 502.0
  episode_reward_mean: 340.19
  episode_reward_min: 224.0
  episodes_this_iter: 1
  episodes_total: 178
  experiment_id: 35d66058da2d4c9882f832ee91e4aa4a
  hostname: gpu011
  info:
    apply_time_ms: 2.657
    dispatch_time_ms: 7.442
    learner:
      cur_lr: 0.001122904010117054
      grad_gnorm: 37.01810073852539
      policy_entropy: 188.61769104003906
      policy_loss: -11.659857749938965
      var_gnorm: 19.961000442504883
      vf_explained_var: 0.0
      vf_loss: 0.5448530912399292
    num_steps_sampled: 3580000
    num_steps_trained: 3580000
    wait_time_ms: 266.102
  iterations_since_restore: 179
  node_ip: 172.17.8.11
  num_metric_batches_dropped: 0
  pid: 25504
  policy_reward_mean: {}
  time_since_restore: 5046.7034595012665
  time_this_iter_s: 41.71661972999573
  time_total_s: 5046.7034595012665
  timestamp: 1593919317
  timesteps_since_restore: 3580000
  timesteps_this_iter: 20000
  timesteps_total: 3580000
  training_iteration: 179
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=25504], 5046 s, 179 iter, 3580000 ts, 340 rew

agent-1: 11.0
agent-2: 19.0
agent-3: 19.0
agent-4: 18.0
agent-5: 36.0
agent-6: 20.0
agent-7: 12.0
agent-8: 22.0
agent-9: 25.0
agent-10: 21.0
agent-11: 26.0
agent-12: 11.0
agent-13: 22.0
agent-14: 24.0
agent-15: 17.0
agent-16: 33.0
agent-17: 15.0
agent-18: 11.0
agent-19: 19.0
agent-20: 23.0
Sum Reward: 404.0
Avg Reward: 20.2
Min Reward: 11.0
Gini Coefficient: 0.17896039603960395
20:20 Ratio: 2.6666666666666665
Max-min Ratio: 3.272727272727273
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_23-22-25
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 502.0
  episode_reward_mean: 340.7
  episode_reward_min: 224.0
  episodes_this_iter: 1
  episodes_total: 179
  experiment_id: 35d66058da2d4c9882f832ee91e4aa4a
  hostname: gpu011
  info:
    apply_time_ms: 2.77
    dispatch_time_ms: 6.79
    learner:
      cur_lr: 0.0011215719860047102
      grad_gnorm: 39.99999237060547
      policy_entropy: 183.37290954589844
      policy_loss: 30.552255630493164
      var_gnorm: 19.962785720825195
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 27.045475006103516
    num_steps_sampled: 3600000
    num_steps_trained: 3600000
    wait_time_ms: 263.733
  iterations_since_restore: 180
  node_ip: 172.17.8.11
  num_metric_batches_dropped: 0
  pid: 25504
  policy_reward_mean: {}
  time_since_restore: 5074.366126537323
  time_this_iter_s: 27.66266703605652
  time_total_s: 5074.366126537323
  timestamp: 1593919345
  timesteps_since_restore: 3600000
  timesteps_this_iter: 20000
  timesteps_total: 3600000
  training_iteration: 180
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=25504], 5074 s, 180 iter, 3600000 ts, 341 rew

agent-1: 10.0
agent-2: 39.0
agent-3: 9.0
agent-4: 5.0
agent-5: 2.0
agent-6: 12.0
agent-7: 20.0
agent-8: 9.0
agent-9: 19.0
agent-10: 10.0
agent-11: 28.0
agent-12: 38.0
agent-13: 17.0
agent-14: 18.0
agent-15: 21.0
agent-16: 23.0
agent-17: 20.0
agent-18: 14.0
agent-19: 12.0
agent-20: 15.0
Sum Reward: 341.0
Avg Reward: 17.05
Min Reward: 2.0
Gini Coefficient: 0.3001466275659824
20:20 Ratio: 5.12
Max-min Ratio: 19.5
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_23-22-53
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 502.0
  episode_reward_mean: 339.64
  episode_reward_min: 224.0
  episodes_this_iter: 1
  episodes_total: 180
  experiment_id: 35d66058da2d4c9882f832ee91e4aa4a
  hostname: gpu011
  info:
    apply_time_ms: 4.253
    dispatch_time_ms: 5.111
    learner:
      cur_lr: 0.0011202399618923664
      grad_gnorm: 18.56511878967285
      policy_entropy: 182.6866455078125
      policy_loss: 2.908421039581299
      var_gnorm: 19.964452743530273
      vf_explained_var: 0.0
      vf_loss: 3.570657730102539
    num_steps_sampled: 3620000
    num_steps_trained: 3620000
    wait_time_ms: 271.339
  iterations_since_restore: 181
  node_ip: 172.17.8.11
  num_metric_batches_dropped: 0
  pid: 25504
  policy_reward_mean: {}
  time_since_restore: 5102.035617589951
  time_this_iter_s: 27.669491052627563
  time_total_s: 5102.035617589951
  timestamp: 1593919373
  timesteps_since_restore: 3620000
  timesteps_this_iter: 20000
  timesteps_total: 3620000
  training_iteration: 181
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=25504], 5102 s, 181 iter, 3620000 ts, 340 rew

agent-1: 15.0
agent-2: 16.0
agent-3: 9.0
agent-4: 13.0
agent-5: 4.0
agent-6: 16.0
agent-7: 2.0
agent-8: 18.0
agent-9: 18.0
agent-10: 19.0
agent-11: 6.0
agent-12: 5.0
agent-13: 18.0
agent-14: 15.0
agent-15: 17.0
agent-16: 27.0
agent-17: 9.0
agent-18: 12.0
agent-19: 10.0
agent-20: 10.0
Sum Reward: 259.0
Avg Reward: 12.95
Min Reward: 2.0
Gini Coefficient: 0.2577220077220077
20:20 Ratio: 4.823529411764706
Max-min Ratio: 13.5
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_23-23-20
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 502.0
  episode_reward_mean: 339.2
  episode_reward_min: 224.0
  episodes_this_iter: 1
  episodes_total: 181
  experiment_id: 35d66058da2d4c9882f832ee91e4aa4a
  hostname: gpu011
  info:
    apply_time_ms: 3.623
    dispatch_time_ms: 5.616
    learner:
      cur_lr: 0.0011189080541953444
      grad_gnorm: 40.0
      policy_entropy: 182.57444763183594
      policy_loss: 31.947376251220703
      var_gnorm: 19.945053100585938
      vf_explained_var: 1.1920928955078125e-07
      vf_loss: 30.163206100463867
    num_steps_sampled: 3640000
    num_steps_trained: 3640000
    wait_time_ms: 269.207
  iterations_since_restore: 182
  node_ip: 172.17.8.11
  num_metric_batches_dropped: 0
  pid: 25504
  policy_reward_mean: {}
  time_since_restore: 5129.425954341888
  time_this_iter_s: 27.390336751937866
  time_total_s: 5129.425954341888
  timestamp: 1593919400
  timesteps_since_restore: 3640000
  timesteps_this_iter: 20000
  timesteps_total: 3640000
  training_iteration: 182
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=25504], 5129 s, 182 iter, 3640000 ts, 339 rew

agent-1: 7.0
agent-2: 28.0
agent-3: 17.0
agent-4: 25.0
agent-5: 12.0
agent-6: 14.0
agent-7: 25.0
agent-8: 17.0
agent-9: 14.0
agent-10: 4.0
agent-11: 1.0
agent-12: 8.0
agent-13: 8.0
agent-14: 15.0
agent-15: 19.0
agent-16: 4.0
agent-17: 23.0
agent-18: 10.0
agent-19: 5.0
agent-20: 24.0
Sum Reward: 280.0
Avg Reward: 14.0
Min Reward: 1.0
Gini Coefficient: 0.32392857142857145
20:20 Ratio: 7.285714285714286
Max-min Ratio: 28.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_23-23-48
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 502.0
  episode_reward_mean: 338.1
  episode_reward_min: 224.0
  episodes_this_iter: 1
  episodes_total: 182
  experiment_id: 35d66058da2d4c9882f832ee91e4aa4a
  hostname: gpu011
  info:
    apply_time_ms: 3.432
    dispatch_time_ms: 7.044
    learner:
      cur_lr: 0.0011175760300830007
      grad_gnorm: 17.526485443115234
      policy_entropy: 178.18374633789062
      policy_loss: 1.100116491317749
      var_gnorm: 19.94269371032715
      vf_explained_var: 0.0
      vf_loss: 5.746382713317871
    num_steps_sampled: 3660000
    num_steps_trained: 3660000
    wait_time_ms: 266.25
  iterations_since_restore: 183
  node_ip: 172.17.8.11
  num_metric_batches_dropped: 0
  pid: 25504
  policy_reward_mean: {}
  time_since_restore: 5156.945253372192
  time_this_iter_s: 27.519299030303955
  time_total_s: 5156.945253372192
  timestamp: 1593919428
  timesteps_since_restore: 3660000
  timesteps_this_iter: 20000
  timesteps_total: 3660000
  training_iteration: 183
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=25504], 5156 s, 183 iter, 3660000 ts, 338 rew

agent-1: 16.0
agent-2: 26.0
agent-3: 19.0
agent-4: 8.0
agent-5: 16.0
agent-6: 9.0
agent-7: 13.0
agent-8: 18.0
agent-9: 19.0
agent-10: 8.0
agent-11: 3.0
agent-12: 13.0
agent-13: 10.0
agent-14: 12.0
agent-15: 19.0
agent-16: 11.0
agent-17: 11.0
agent-18: 35.0
agent-19: 10.0
agent-20: 11.0
Sum Reward: 287.0
Avg Reward: 14.35
Min Reward: 3.0
Gini Coefficient: 0.25209059233449477
20:20 Ratio: 3.5357142857142856
Max-min Ratio: 11.666666666666666
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_23-24-17
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 502.0
  episode_reward_mean: 337.95
  episode_reward_min: 224.0
  episodes_this_iter: 1
  episodes_total: 183
  experiment_id: 35d66058da2d4c9882f832ee91e4aa4a
  hostname: gpu011
  info:
    apply_time_ms: 3.583
    dispatch_time_ms: 32.966
    learner:
      cur_lr: 0.0011162440059706569
      grad_gnorm: 20.048370361328125
      policy_entropy: 174.68226623535156
      policy_loss: -3.7187118530273438
      var_gnorm: 19.942241668701172
      vf_explained_var: 0.0
      vf_loss: 0.1613662987947464
    num_steps_sampled: 3680000
    num_steps_trained: 3680000
    wait_time_ms: 248.207
  iterations_since_restore: 184
  node_ip: 172.17.8.11
  num_metric_batches_dropped: 0
  pid: 25504
  policy_reward_mean: {}
  time_since_restore: 5185.824439287186
  time_this_iter_s: 28.879185914993286
  time_total_s: 5185.824439287186
  timestamp: 1593919457
  timesteps_since_restore: 3680000
  timesteps_this_iter: 20000
  timesteps_total: 3680000
  training_iteration: 184
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=25504], 5185 s, 184 iter, 3680000 ts, 338 rew

agent-1: 11.0
agent-2: 16.0
agent-3: 21.0
agent-4: 18.0
agent-5: 22.0
agent-6: 15.0
agent-7: 11.0
agent-8: 35.0
agent-9: 4.0
agent-10: 4.0
agent-11: 6.0
agent-12: 5.0
agent-13: 16.0
agent-14: 12.0
agent-15: 16.0
agent-16: 7.0
agent-17: 24.0
agent-18: 24.0
agent-19: 4.0
agent-20: 16.0
Sum Reward: 287.0
Avg Reward: 14.35
Min Reward: 4.0
Gini Coefficient: 0.3113240418118467
20:20 Ratio: 6.176470588235294
Max-min Ratio: 8.75
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_23-24-45
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 502.0
  episode_reward_mean: 337.58
  episode_reward_min: 224.0
  episodes_this_iter: 1
  episodes_total: 184
  experiment_id: 35d66058da2d4c9882f832ee91e4aa4a
  hostname: gpu011
  info:
    apply_time_ms: 4.066
    dispatch_time_ms: 6.747
    learner:
      cur_lr: 0.001114911981858313
      grad_gnorm: 32.5919075012207
      policy_entropy: 190.32351684570312
      policy_loss: -11.877206802368164
      var_gnorm: 19.94530487060547
      vf_explained_var: 0.0
      vf_loss: 0.8925613164901733
    num_steps_sampled: 3700000
    num_steps_trained: 3700000
    wait_time_ms: 259.353
  iterations_since_restore: 185
  node_ip: 172.17.8.11
  num_metric_batches_dropped: 0
  pid: 25504
  policy_reward_mean: {}
  time_since_restore: 5214.21431016922
  time_this_iter_s: 28.3898708820343
  time_total_s: 5214.21431016922
  timestamp: 1593919485
  timesteps_since_restore: 3700000
  timesteps_this_iter: 20000
  timesteps_total: 3700000
  training_iteration: 185
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=25504], 5214 s, 185 iter, 3700000 ts, 338 rew

agent-1: 13.0
agent-2: 14.0
agent-3: 8.0
agent-4: 17.0
agent-5: 14.0
agent-6: 21.0
agent-7: 15.0
agent-8: 24.0
agent-9: 23.0
agent-10: 29.0
agent-11: 24.0
agent-12: 25.0
agent-13: 10.0
agent-14: 11.0
agent-15: 13.0
agent-16: 25.0
agent-17: 16.0
agent-18: 21.0
agent-19: 8.0
agent-20: 27.0
Sum Reward: 358.0
Avg Reward: 17.9
Min Reward: 8.0
Gini Coefficient: 0.2047486033519553
20:20 Ratio: 2.864864864864865
Max-min Ratio: 3.625
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_23-25-13
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 502.0
  episode_reward_mean: 336.73
  episode_reward_min: 224.0
  episodes_this_iter: 1
  episodes_total: 185
  experiment_id: 35d66058da2d4c9882f832ee91e4aa4a
  hostname: gpu011
  info:
    apply_time_ms: 3.144
    dispatch_time_ms: 6.939
    learner:
      cur_lr: 0.0011135799577459693
      grad_gnorm: 21.33450698852539
      policy_entropy: 176.34707641601562
      policy_loss: -6.210916042327881
      var_gnorm: 19.94720458984375
      vf_explained_var: 0.0
      vf_loss: 0.18397308886051178
    num_steps_sampled: 3720000
    num_steps_trained: 3720000
    wait_time_ms: 275.733
  iterations_since_restore: 186
  node_ip: 172.17.8.11
  num_metric_batches_dropped: 0
  pid: 25504
  policy_reward_mean: {}
  time_since_restore: 5241.733263731003
  time_this_iter_s: 27.518953561782837
  time_total_s: 5241.733263731003
  timestamp: 1593919513
  timesteps_since_restore: 3720000
  timesteps_this_iter: 20000
  timesteps_total: 3720000
  training_iteration: 186
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=25504], 5241 s, 186 iter, 3720000 ts, 337 rew

agent-1: 5.0
agent-2: 9.0
agent-3: 4.0
agent-4: 12.0
agent-5: 11.0
agent-6: 22.0
agent-7: 11.0
agent-8: 14.0
agent-9: 21.0
agent-10: 18.0
agent-11: 25.0
agent-12: 10.0
agent-13: 13.0
agent-14: 18.0
agent-15: 16.0
agent-16: 8.0
agent-17: 28.0
agent-18: 16.0
agent-19: 5.0
agent-20: 19.0
Sum Reward: 285.0
Avg Reward: 14.25
Min Reward: 4.0
Gini Coefficient: 0.2612280701754386
20:20 Ratio: 4.363636363636363
Max-min Ratio: 7.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_23-25-40
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 502.0
  episode_reward_mean: 336.34
  episode_reward_min: 224.0
  episodes_this_iter: 1
  episodes_total: 186
  experiment_id: 35d66058da2d4c9882f832ee91e4aa4a
  hostname: gpu011
  info:
    apply_time_ms: 3.118
    dispatch_time_ms: 7.013
    learner:
      cur_lr: 0.0011122480500489473
      grad_gnorm: 28.540010452270508
      policy_entropy: 166.54054260253906
      policy_loss: -8.373291015625
      var_gnorm: 19.952917098999023
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 0.32869914174079895
    num_steps_sampled: 3740000
    num_steps_trained: 3740000
    wait_time_ms: 271.183
  iterations_since_restore: 187
  node_ip: 172.17.8.11
  num_metric_batches_dropped: 0
  pid: 25504
  policy_reward_mean: {}
  time_since_restore: 5269.208014011383
  time_this_iter_s: 27.47475028038025
  time_total_s: 5269.208014011383
  timestamp: 1593919540
  timesteps_since_restore: 3740000
  timesteps_this_iter: 20000
  timesteps_total: 3740000
  training_iteration: 187
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=25504], 5269 s, 187 iter, 3740000 ts, 336 rew

agent-1: 19.0
agent-2: 10.0
agent-3: 26.0
agent-4: 17.0
agent-5: 15.0
agent-6: 12.0
agent-7: 8.0
agent-8: 6.0
agent-9: 20.0
agent-10: 14.0
agent-11: 13.0
agent-12: 8.0
agent-13: 18.0
agent-14: 7.0
agent-15: 25.0
agent-16: 10.0
agent-17: 25.0
agent-18: 24.0
agent-19: 21.0
agent-20: 25.0
Sum Reward: 323.0
Avg Reward: 16.15
Min Reward: 6.0
Gini Coefficient: 0.23452012383900928
20:20 Ratio: 3.4827586206896552
Max-min Ratio: 4.333333333333333
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_23-26-08
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 502.0
  episode_reward_mean: 335.7
  episode_reward_min: 224.0
  episodes_this_iter: 1
  episodes_total: 187
  experiment_id: 35d66058da2d4c9882f832ee91e4aa4a
  hostname: gpu011
  info:
    apply_time_ms: 2.734
    dispatch_time_ms: 8.227
    learner:
      cur_lr: 0.0011109160259366035
      grad_gnorm: 13.987276077270508
      policy_entropy: 193.33047485351562
      policy_loss: 1.886272668838501
      var_gnorm: 19.95375633239746
      vf_explained_var: 0.0
      vf_loss: 4.408916473388672
    num_steps_sampled: 3760000
    num_steps_trained: 3760000
    wait_time_ms: 261.074
  iterations_since_restore: 188
  node_ip: 172.17.8.11
  num_metric_batches_dropped: 0
  pid: 25504
  policy_reward_mean: {}
  time_since_restore: 5296.527811288834
  time_this_iter_s: 27.31979727745056
  time_total_s: 5296.527811288834
  timestamp: 1593919568
  timesteps_since_restore: 3760000
  timesteps_this_iter: 20000
  timesteps_total: 3760000
  training_iteration: 188
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=25504], 5296 s, 188 iter, 3760000 ts, 336 rew

agent-1: 4.0
agent-2: 16.0
agent-3: 15.0
agent-4: 33.0
agent-5: 20.0
agent-6: 21.0
agent-7: 27.0
agent-8: 7.0
agent-9: 24.0
agent-10: 38.0
agent-11: 10.0
agent-12: 11.0
agent-13: 14.0
agent-14: 29.0
agent-15: 24.0
agent-16: 19.0
agent-17: 12.0
agent-18: 29.0
agent-19: 26.0
agent-20: 5.0
Sum Reward: 384.0
Avg Reward: 19.2
Min Reward: 4.0
Gini Coefficient: 0.27760416666666665
20:20 Ratio: 4.961538461538462
Max-min Ratio: 9.5
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_23-26-35
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 502.0
  episode_reward_mean: 334.96
  episode_reward_min: 224.0
  episodes_this_iter: 1
  episodes_total: 188
  experiment_id: 35d66058da2d4c9882f832ee91e4aa4a
  hostname: gpu011
  info:
    apply_time_ms: 3.858
    dispatch_time_ms: 6.205
    learner:
      cur_lr: 0.0011095840018242598
      grad_gnorm: 25.720664978027344
      policy_entropy: 184.6558837890625
      policy_loss: -7.824446201324463
      var_gnorm: 19.948957443237305
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 0.26275908946990967
    num_steps_sampled: 3780000
    num_steps_trained: 3780000
    wait_time_ms: 271.781
  iterations_since_restore: 189
  node_ip: 172.17.8.11
  num_metric_batches_dropped: 0
  pid: 25504
  policy_reward_mean: {}
  time_since_restore: 5324.0575041770935
  time_this_iter_s: 27.529692888259888
  time_total_s: 5324.0575041770935
  timestamp: 1593919595
  timesteps_since_restore: 3780000
  timesteps_this_iter: 20000
  timesteps_total: 3780000
  training_iteration: 189
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=25504], 5324 s, 189 iter, 3780000 ts, 335 rew

agent-1: 14.0
agent-2: 14.0
agent-3: 24.0
agent-4: 9.0
agent-5: 21.0
agent-6: 18.0
agent-7: 11.0
agent-8: 12.0
agent-9: 8.0
agent-10: 24.0
agent-11: 9.0
agent-12: 11.0
agent-13: 12.0
agent-14: 33.0
agent-15: 5.0
agent-16: 5.0
agent-17: 10.0
agent-18: 20.0
agent-19: 19.0
agent-20: 1.0
Sum Reward: 280.0
Avg Reward: 14.0
Min Reward: 1.0
Gini Coefficient: 0.29928571428571427
20:20 Ratio: 5.368421052631579
Max-min Ratio: 33.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_23-27-03
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 502.0
  episode_reward_mean: 333.86
  episode_reward_min: 224.0
  episodes_this_iter: 1
  episodes_total: 189
  experiment_id: 35d66058da2d4c9882f832ee91e4aa4a
  hostname: gpu011
  info:
    apply_time_ms: 3.282
    dispatch_time_ms: 6.918
    learner:
      cur_lr: 0.001108251977711916
      grad_gnorm: 24.8912410736084
      policy_entropy: 177.35787963867188
      policy_loss: -7.065447807312012
      var_gnorm: 19.949260711669922
      vf_explained_var: 0.0
      vf_loss: 0.24951757490634918
    num_steps_sampled: 3800000
    num_steps_trained: 3800000
    wait_time_ms: 262.302
  iterations_since_restore: 190
  node_ip: 172.17.8.11
  num_metric_batches_dropped: 0
  pid: 25504
  policy_reward_mean: {}
  time_since_restore: 5351.399877309799
  time_this_iter_s: 27.34237313270569
  time_total_s: 5351.399877309799
  timestamp: 1593919623
  timesteps_since_restore: 3800000
  timesteps_this_iter: 20000
  timesteps_total: 3800000
  training_iteration: 190
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=25504], 5351 s, 190 iter, 3800000 ts, 334 rew

agent-1: 17.0
agent-2: 20.0
agent-3: 9.0
agent-4: 8.0
agent-5: 5.0
agent-6: 13.0
agent-7: 13.0
agent-8: 30.0
agent-9: 16.0
agent-10: 24.0
agent-11: 29.0
agent-12: 18.0
agent-13: 13.0
agent-14: 7.0
agent-15: 26.0
agent-16: 22.0
agent-17: 15.0
agent-18: 7.0
agent-19: 5.0
agent-20: 12.0
Sum Reward: 309.0
Avg Reward: 15.45
Min Reward: 5.0
Gini Coefficient: 0.27750809061488674
20:20 Ratio: 4.541666666666667
Max-min Ratio: 6.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_23-27-30
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 502.0
  episode_reward_mean: 332.89
  episode_reward_min: 224.0
  episodes_this_iter: 1
  episodes_total: 190
  experiment_id: 35d66058da2d4c9882f832ee91e4aa4a
  hostname: gpu011
  info:
    apply_time_ms: 3.726
    dispatch_time_ms: 8.458
    learner:
      cur_lr: 0.0011069199535995722
      grad_gnorm: 24.150171279907227
      policy_entropy: 161.6065673828125
      policy_loss: -0.651465892791748
      var_gnorm: 19.950517654418945
      vf_explained_var: 1.1920928955078125e-07
      vf_loss: 14.678794860839844
    num_steps_sampled: 3820000
    num_steps_trained: 3820000
    wait_time_ms: 267.794
  iterations_since_restore: 191
  node_ip: 172.17.8.11
  num_metric_batches_dropped: 0
  pid: 25504
  policy_reward_mean: {}
  time_since_restore: 5378.799046993256
  time_this_iter_s: 27.39916968345642
  time_total_s: 5378.799046993256
  timestamp: 1593919650
  timesteps_since_restore: 3820000
  timesteps_this_iter: 20000
  timesteps_total: 3820000
  training_iteration: 191
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=25504], 5378 s, 191 iter, 3820000 ts, 333 rew

W0704 23:27:41.269472 25498 task_dependency_manager.cc:259] Task lease to renew has already expired by -740ms
W0704 23:27:41.284567 25498 node_manager.cc:250] Last heartbeat was sent 8087 ms ago 
agent-1: 27.0
agent-2: 14.0
agent-3: 33.0
agent-4: 20.0
agent-5: 18.0
agent-6: 19.0
agent-7: 17.0
agent-8: 11.0
agent-9: 21.0
agent-10: 19.0
agent-11: 6.0
agent-12: 20.0
agent-13: 25.0
agent-14: 8.0
agent-15: 19.0
agent-16: 28.0
agent-17: 12.0
agent-18: 28.0
agent-19: 23.0
agent-20: 14.0
Sum Reward: 382.0
Avg Reward: 19.1
Min Reward: 6.0
Gini Coefficient: 0.20235602094240837
20:20 Ratio: 3.135135135135135
Max-min Ratio: 5.5
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_23-28-05
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 502.0
  episode_reward_mean: 333.38
  episode_reward_min: 224.0
  episodes_this_iter: 1
  episodes_total: 191
  experiment_id: 35d66058da2d4c9882f832ee91e4aa4a
  hostname: gpu011
  info:
    apply_time_ms: 3.562
    dispatch_time_ms: 20.8
    learner:
      cur_lr: 0.0011055880459025502
      grad_gnorm: 27.066343307495117
      policy_entropy: 195.95095825195312
      policy_loss: -8.793073654174805
      var_gnorm: 19.94894027709961
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 0.2947995066642761
    num_steps_sampled: 3840000
    num_steps_trained: 3840000
    wait_time_ms: 253.465
  iterations_since_restore: 192
  node_ip: 172.17.8.11
  num_metric_batches_dropped: 0
  pid: 25504
  policy_reward_mean: {}
  time_since_restore: 5413.75288271904
  time_this_iter_s: 34.9538357257843
  time_total_s: 5413.75288271904
  timestamp: 1593919685
  timesteps_since_restore: 3840000
  timesteps_this_iter: 20000
  timesteps_total: 3840000
  training_iteration: 192
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=25504], 5413 s, 192 iter, 3840000 ts, 333 rew

agent-1: 9.0
agent-2: 15.0
agent-3: 9.0
agent-4: 20.0
agent-5: 30.0
agent-6: 11.0
agent-7: 12.0
agent-8: 9.0
agent-9: 16.0
agent-10: 9.0
agent-11: 27.0
agent-12: 11.0
agent-13: 19.0
agent-14: 19.0
agent-15: 18.0
agent-16: 13.0
agent-17: 17.0
agent-18: 15.0
agent-19: 10.0
agent-20: 17.0
Sum Reward: 306.0
Avg Reward: 15.3
Min Reward: 9.0
Gini Coefficient: 0.2022875816993464
20:20 Ratio: 2.6666666666666665
Max-min Ratio: 3.3333333333333335
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_23-28-32
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 502.0
  episode_reward_mean: 331.62
  episode_reward_min: 224.0
  episodes_this_iter: 1
  episodes_total: 192
  experiment_id: 35d66058da2d4c9882f832ee91e4aa4a
  hostname: gpu011
  info:
    apply_time_ms: 3.231
    dispatch_time_ms: 6.361
    learner:
      cur_lr: 0.0011042560217902064
      grad_gnorm: 28.84349822998047
      policy_entropy: 166.7373809814453
      policy_loss: 10.601568222045898
      var_gnorm: 19.955228805541992
      vf_explained_var: 0.0
      vf_loss: 14.047304153442383
    num_steps_sampled: 3860000
    num_steps_trained: 3860000
    wait_time_ms: 267.53
  iterations_since_restore: 193
  node_ip: 172.17.8.11
  num_metric_batches_dropped: 0
  pid: 25504
  policy_reward_mean: {}
  time_since_restore: 5441.128220319748
  time_this_iter_s: 27.375337600708008
  time_total_s: 5441.128220319748
  timestamp: 1593919712
  timesteps_since_restore: 3860000
  timesteps_this_iter: 20000
  timesteps_total: 3860000
  training_iteration: 193
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=25504], 5441 s, 193 iter, 3860000 ts, 332 rew

agent-1: 29.0
agent-2: 21.0
agent-3: 3.0
agent-4: 13.0
agent-5: 10.0
agent-6: 7.0
agent-7: 12.0
agent-8: 17.0
agent-9: 15.0
agent-10: 22.0
agent-11: 14.0
agent-12: 13.0
agent-13: 24.0
agent-14: 10.0
agent-15: 25.0
agent-16: 31.0
agent-17: 5.0
agent-18: 17.0
agent-19: 19.0
agent-20: 16.0
Sum Reward: 323.0
Avg Reward: 16.15
Min Reward: 3.0
Gini Coefficient: 0.2595975232198142
20:20 Ratio: 4.36
Max-min Ratio: 10.333333333333334
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_23-29-00
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 502.0
  episode_reward_mean: 330.8
  episode_reward_min: 224.0
  episodes_this_iter: 1
  episodes_total: 193
  experiment_id: 35d66058da2d4c9882f832ee91e4aa4a
  hostname: gpu011
  info:
    apply_time_ms: 2.776
    dispatch_time_ms: 6.853
    learner:
      cur_lr: 0.0011029239976778626
      grad_gnorm: 40.0
      policy_entropy: 153.9911651611328
      policy_loss: 21.17633819580078
      var_gnorm: 19.953962326049805
      vf_explained_var: 0.0
      vf_loss: 25.98785400390625
    num_steps_sampled: 3880000
    num_steps_trained: 3880000
    wait_time_ms: 264.925
  iterations_since_restore: 194
  node_ip: 172.17.8.11
  num_metric_batches_dropped: 0
  pid: 25504
  policy_reward_mean: {}
  time_since_restore: 5468.509153604507
  time_this_iter_s: 27.38093328475952
  time_total_s: 5468.509153604507
  timestamp: 1593919740
  timesteps_since_restore: 3880000
  timesteps_this_iter: 20000
  timesteps_total: 3880000
  training_iteration: 194
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=25504], 5468 s, 194 iter, 3880000 ts, 331 rew

agent-1: 16.0
agent-2: 14.0
agent-3: 25.0
agent-4: 37.0
agent-5: 20.0
agent-6: 19.0
agent-7: 13.0
agent-8: 15.0
agent-9: 25.0
agent-10: 19.0
agent-11: 25.0
agent-12: 9.0
agent-13: 21.0
agent-14: 12.0
agent-15: 18.0
agent-16: 16.0
agent-17: 27.0
agent-18: 18.0
agent-19: 32.0
agent-20: 17.0
Sum Reward: 398.0
Avg Reward: 19.9
Min Reward: 9.0
Gini Coefficient: 0.18467336683417085
20:20 Ratio: 2.5208333333333335
Max-min Ratio: 4.111111111111111
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_23-29-27
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 502.0
  episode_reward_mean: 330.5
  episode_reward_min: 224.0
  episodes_this_iter: 1
  episodes_total: 194
  experiment_id: 35d66058da2d4c9882f832ee91e4aa4a
  hostname: gpu011
  info:
    apply_time_ms: 3.379
    dispatch_time_ms: 5.163
    learner:
      cur_lr: 0.0011015919735655189
      grad_gnorm: 40.0
      policy_entropy: 173.9666290283203
      policy_loss: 15.411194801330566
      var_gnorm: 19.95699691772461
      vf_explained_var: 0.0
      vf_loss: 26.0439453125
    num_steps_sampled: 3900000
    num_steps_trained: 3900000
    wait_time_ms: 262.269
  iterations_since_restore: 195
  node_ip: 172.17.8.11
  num_metric_batches_dropped: 0
  pid: 25504
  policy_reward_mean: {}
  time_since_restore: 5495.8606724739075
  time_this_iter_s: 27.351518869400024
  time_total_s: 5495.8606724739075
  timestamp: 1593919767
  timesteps_since_restore: 3900000
  timesteps_this_iter: 20000
  timesteps_total: 3900000
  training_iteration: 195
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=25504], 5495 s, 195 iter, 3900000 ts, 330 rew

agent-1: 13.0
agent-2: 3.0
agent-3: 11.0
agent-4: 31.0
agent-5: 6.0
agent-6: 8.0
agent-7: 5.0
agent-8: 23.0
agent-9: 11.0
agent-10: 23.0
agent-11: 12.0
agent-12: 21.0
agent-13: 11.0
agent-14: 23.0
agent-15: 10.0
agent-16: 6.0
agent-17: 13.0
agent-18: 17.0
agent-19: 12.0
agent-20: 7.0
Sum Reward: 266.0
Avg Reward: 13.3
Min Reward: 3.0
Gini Coefficient: 0.29774436090225564
20:20 Ratio: 5.0
Max-min Ratio: 10.333333333333334
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_23-29-55
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 502.0
  episode_reward_mean: 329.57
  episode_reward_min: 224.0
  episodes_this_iter: 1
  episodes_total: 195
  experiment_id: 35d66058da2d4c9882f832ee91e4aa4a
  hostname: gpu011
  info:
    apply_time_ms: 3.482
    dispatch_time_ms: 7.062
    learner:
      cur_lr: 0.001100259949453175
      grad_gnorm: 40.0
      policy_entropy: 185.15765380859375
      policy_loss: 29.181440353393555
      var_gnorm: 19.962923049926758
      vf_explained_var: 0.0
      vf_loss: 42.62602996826172
    num_steps_sampled: 3920000
    num_steps_trained: 3920000
    wait_time_ms: 259.837
  iterations_since_restore: 196
  node_ip: 172.17.8.11
  num_metric_batches_dropped: 0
  pid: 25504
  policy_reward_mean: {}
  time_since_restore: 5523.459618330002
  time_this_iter_s: 27.59894585609436
  time_total_s: 5523.459618330002
  timestamp: 1593919795
  timesteps_since_restore: 3920000
  timesteps_this_iter: 20000
  timesteps_total: 3920000
  training_iteration: 196
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=25504], 5523 s, 196 iter, 3920000 ts, 330 rew

agent-1: 6.0
agent-2: 41.0
agent-3: 22.0
agent-4: 13.0
agent-5: 18.0
agent-6: 21.0
agent-7: 33.0
agent-8: 2.0
agent-9: 21.0
agent-10: 1.0
agent-11: 19.0
agent-12: 28.0
agent-13: 8.0
agent-14: 43.0
agent-15: 11.0
agent-16: 9.0
agent-17: 35.0
agent-18: 18.0
agent-19: 24.0
agent-20: 12.0
Sum Reward: 385.0
Avg Reward: 19.25
Min Reward: 1.0
Gini Coefficient: 0.3463636363636364
20:20 Ratio: 8.941176470588236
Max-min Ratio: 43.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_23-30-22
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 502.0
  episode_reward_mean: 329.97
  episode_reward_min: 224.0
  episodes_this_iter: 1
  episodes_total: 196
  experiment_id: 35d66058da2d4c9882f832ee91e4aa4a
  hostname: gpu011
  info:
    apply_time_ms: 2.639
    dispatch_time_ms: 14.257
    learner:
      cur_lr: 0.001098928041756153
      grad_gnorm: 26.359601974487305
      policy_entropy: 184.41464233398438
      policy_loss: -9.072980880737305
      var_gnorm: 19.96728515625
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 5.410476207733154
    num_steps_sampled: 3940000
    num_steps_trained: 3940000
    wait_time_ms: 274.195
  iterations_since_restore: 197
  node_ip: 172.17.8.11
  num_metric_batches_dropped: 0
  pid: 25504
  policy_reward_mean: {}
  time_since_restore: 5550.731249570847
  time_this_iter_s: 27.271631240844727
  time_total_s: 5550.731249570847
  timestamp: 1593919822
  timesteps_since_restore: 3940000
  timesteps_this_iter: 20000
  timesteps_total: 3940000
  training_iteration: 197
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=25504], 5550 s, 197 iter, 3940000 ts, 330 rew

agent-1: 4.0
agent-2: 26.0
agent-3: 14.0
agent-4: 8.0
agent-5: 16.0
agent-6: 3.0
agent-7: 31.0
agent-8: 12.0
agent-9: 14.0
agent-10: 20.0
agent-11: 30.0
agent-12: 10.0
agent-13: 29.0
agent-14: 14.0
agent-15: 27.0
agent-16: 33.0
agent-17: 27.0
agent-18: 36.0
agent-19: 20.0
agent-20: 16.0
Sum Reward: 390.0
Avg Reward: 19.5
Min Reward: 3.0
Gini Coefficient: 0.2815384615384615
20:20 Ratio: 5.2
Max-min Ratio: 12.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_23-30-51
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 502.0
  episode_reward_mean: 330.68
  episode_reward_min: 224.0
  episodes_this_iter: 1
  episodes_total: 197
  experiment_id: 35d66058da2d4c9882f832ee91e4aa4a
  hostname: gpu011
  info:
    apply_time_ms: 3.042
    dispatch_time_ms: 29.114
    learner:
      cur_lr: 0.0010975960176438093
      grad_gnorm: 30.282184600830078
      policy_entropy: 170.3497772216797
      policy_loss: -7.826428413391113
      var_gnorm: 19.967187881469727
      vf_explained_var: 0.0
      vf_loss: 0.3693985939025879
    num_steps_sampled: 3960000
    num_steps_trained: 3960000
    wait_time_ms: 241.074
  iterations_since_restore: 198
  node_ip: 172.17.8.11
  num_metric_batches_dropped: 0
  pid: 25504
  policy_reward_mean: {}
  time_since_restore: 5579.526014328003
  time_this_iter_s: 28.794764757156372
  time_total_s: 5579.526014328003
  timestamp: 1593919851
  timesteps_since_restore: 3960000
  timesteps_this_iter: 20000
  timesteps_total: 3960000
  training_iteration: 198
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=25504], 5579 s, 198 iter, 3960000 ts, 331 rew

agent-1: 3.0
agent-2: 15.0
agent-3: 3.0
agent-4: 5.0
agent-5: 24.0
agent-6: 27.0
agent-7: 15.0
agent-8: 39.0
agent-9: 30.0
agent-10: 21.0
agent-11: 7.0
agent-12: 8.0
agent-13: 31.0
agent-14: 29.0
agent-15: 16.0
agent-16: 29.0
agent-17: 29.0
agent-18: 11.0
agent-19: 23.0
agent-20: 17.0
Sum Reward: 382.0
Avg Reward: 19.1
Min Reward: 3.0
Gini Coefficient: 0.3099476439790576
20:20 Ratio: 7.166666666666667
Max-min Ratio: 13.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_23-31-22
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 502.0
  episode_reward_mean: 331.62
  episode_reward_min: 224.0
  episodes_this_iter: 1
  episodes_total: 198
  experiment_id: 35d66058da2d4c9882f832ee91e4aa4a
  hostname: gpu011
  info:
    apply_time_ms: 4.723
    dispatch_time_ms: 31.906
    learner:
      cur_lr: 0.0010962639935314655
      grad_gnorm: 33.448360443115234
      policy_entropy: 125.42017364501953
      policy_loss: -4.696473598480225
      var_gnorm: 19.97382354736328
      vf_explained_var: 0.0
      vf_loss: 17.335325241088867
    num_steps_sampled: 3980000
    num_steps_trained: 3980000
    wait_time_ms: 90.387
  iterations_since_restore: 199
  node_ip: 172.17.8.11
  num_metric_batches_dropped: 0
  pid: 25504
  policy_reward_mean: {}
  time_since_restore: 5610.631476640701
  time_this_iter_s: 31.105462312698364
  time_total_s: 5610.631476640701
  timestamp: 1593919882
  timesteps_since_restore: 3980000
  timesteps_this_iter: 20000
  timesteps_total: 3980000
  training_iteration: 199
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=25504], 5610 s, 199 iter, 3980000 ts, 332 rew

agent-1: 20.0
agent-2: 31.0
agent-3: 8.0
agent-4: 27.0
agent-5: 32.0
agent-6: 50.0
agent-7: 25.0
agent-8: 18.0
agent-9: 33.0
agent-10: 6.0
agent-11: 9.0
agent-12: 5.0
agent-13: 28.0
agent-14: 32.0
agent-15: 27.0
agent-16: 14.0
agent-17: 20.0
agent-18: 12.0
agent-19: 13.0
agent-20: 36.0
Sum Reward: 446.0
Avg Reward: 22.3
Min Reward: 5.0
Gini Coefficient: 0.29035874439461884
20:20 Ratio: 5.392857142857143
Max-min Ratio: 10.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_23-31-50
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 502.0
  episode_reward_mean: 332.5
  episode_reward_min: 224.0
  episodes_this_iter: 1
  episodes_total: 199
  experiment_id: 35d66058da2d4c9882f832ee91e4aa4a
  hostname: gpu011
  info:
    apply_time_ms: 3.086
    dispatch_time_ms: 27.033
    learner:
      cur_lr: 0.0010949319694191217
      grad_gnorm: 39.99999237060547
      policy_entropy: 149.95599365234375
      policy_loss: 26.69508934020996
      var_gnorm: 19.97505760192871
      vf_explained_var: 5.960464477539063e-08
      vf_loss: 45.64875030517578
    num_steps_sampled: 4000000
    num_steps_trained: 4000000
    wait_time_ms: 257.811
  iterations_since_restore: 200
  node_ip: 172.17.8.11
  num_metric_batches_dropped: 0
  pid: 25504
  policy_reward_mean: {}
  time_since_restore: 5638.788745164871
  time_this_iter_s: 28.157268524169922
  time_total_s: 5638.788745164871
  timestamp: 1593919910
  timesteps_since_restore: 4000000
  timesteps_this_iter: 20000
  timesteps_total: 4000000
  training_iteration: 200
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.3/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=25504], 5638 s, 200 iter, 4000000 ts, 332 rew

agent-1: 27.0
agent-2: 19.0
agent-3: 16.0
agent-4: 22.0
agent-5: 18.0
agent-6: 23.0
agent-7: 16.0
agent-8: 24.0
agent-9: 11.0
agent-10: 25.0
agent-11: 15.0
agent-12: 32.0
agent-13: 22.0
agent-14: 32.0
agent-15: 21.0
agent-16: 28.0
agent-17: 25.0
agent-18: 11.0
agent-19: 19.0
agent-20: 13.0
Sum Reward: 419.0
Avg Reward: 20.95
Min Reward: 11.0
Gini Coefficient: 0.16575178997613366
20:20 Ratio: 2.38
Max-min Ratio: 2.909090909090909
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_23-32-19
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 502.0
  episode_reward_mean: 333.54
  episode_reward_min: 224.0
  episodes_this_iter: 1
  episodes_total: 200
  experiment_id: 35d66058da2d4c9882f832ee91e4aa4a
  hostname: gpu011
  info:
    apply_time_ms: 4.119
    dispatch_time_ms: 27.835
    learner:
      cur_lr: 0.001093599945306778
      grad_gnorm: 8.650575637817383
      policy_entropy: 122.15422821044922
      policy_loss: 0.08143877983093262
      var_gnorm: 19.98005485534668
      vf_explained_var: 5.960464477539063e-08
      vf_loss: 8.399188995361328
    num_steps_sampled: 4020000
    num_steps_trained: 4020000
    wait_time_ms: 255.011
  iterations_since_restore: 201
  node_ip: 172.17.8.11
  num_metric_batches_dropped: 0
  pid: 25504
  policy_reward_mean: {}
  time_since_restore: 5667.05943775177
  time_this_iter_s: 28.270692586898804
  time_total_s: 5667.05943775177
  timestamp: 1593919939
  timesteps_since_restore: 4020000
  timesteps_this_iter: 20000
  timesteps_total: 4020000
  training_iteration: 201
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=25504], 5667 s, 201 iter, 4020000 ts, 334 rew

agent-1: 27.0
agent-2: 10.0
agent-3: 18.0
agent-4: 18.0
agent-5: 5.0
agent-6: 14.0
agent-7: 18.0
agent-8: 38.0
agent-9: 18.0
agent-10: 17.0
agent-11: 20.0
agent-12: 12.0
agent-13: 29.0
agent-14: 9.0
agent-15: 16.0
agent-16: 15.0
agent-17: 10.0
agent-18: 22.0
agent-19: 16.0
agent-20: 29.0
Sum Reward: 361.0
Avg Reward: 18.05
Min Reward: 5.0
Gini Coefficient: 0.23199445983379502
20:20 Ratio: 3.6176470588235294
Max-min Ratio: 7.6
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_23-32-47
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 502.0
  episode_reward_mean: 333.93
  episode_reward_min: 224.0
  episodes_this_iter: 1
  episodes_total: 201
  experiment_id: 35d66058da2d4c9882f832ee91e4aa4a
  hostname: gpu011
  info:
    apply_time_ms: 3.646
    dispatch_time_ms: 31.684
    learner:
      cur_lr: 0.001092268037609756
      grad_gnorm: 28.18243408203125
      policy_entropy: 168.26670837402344
      policy_loss: -3.360197067260742
      var_gnorm: 19.981107711791992
      vf_explained_var: 0.0
      vf_loss: 6.238213539123535
    num_steps_sampled: 4040000
    num_steps_trained: 4040000
    wait_time_ms: 234.34
  iterations_since_restore: 202
  node_ip: 172.17.8.11
  num_metric_batches_dropped: 0
  pid: 25504
  policy_reward_mean: {}
  time_since_restore: 5695.5944719314575
  time_this_iter_s: 28.5350341796875
  time_total_s: 5695.5944719314575
  timestamp: 1593919967
  timesteps_since_restore: 4040000
  timesteps_this_iter: 20000
  timesteps_total: 4040000
  training_iteration: 202
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.3/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=25504], 5695 s, 202 iter, 4040000 ts, 334 rew

agent-1: 24.0
agent-2: 20.0
agent-3: 37.0
agent-4: 26.0
agent-5: 24.0
agent-6: 19.0
agent-7: 10.0
agent-8: 47.0
agent-9: 23.0
agent-10: 24.0
agent-11: 43.0
agent-12: 25.0
agent-13: 30.0
agent-14: 22.0
agent-15: 26.0
agent-16: 13.0
agent-17: 16.0
agent-18: 21.0
agent-19: 40.0
agent-20: 24.0
Sum Reward: 514.0
Avg Reward: 25.7
Min Reward: 10.0
Gini Coefficient: 0.19455252918287938
20:20 Ratio: 2.8793103448275863
Max-min Ratio: 4.7
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_23-33-17
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 514.0
  episode_reward_mean: 336.17
  episode_reward_min: 224.0
  episodes_this_iter: 1
  episodes_total: 202
  experiment_id: 35d66058da2d4c9882f832ee91e4aa4a
  hostname: gpu011
  info:
    apply_time_ms: 4.621
    dispatch_time_ms: 6.477
    learner:
      cur_lr: 0.0010909360134974122
      grad_gnorm: 34.86188888549805
      policy_entropy: 126.29436492919922
      policy_loss: -7.992781639099121
      var_gnorm: 19.98147964477539
      vf_explained_var: 0.0
      vf_loss: 0.4910978376865387
    num_steps_sampled: 4060000
    num_steps_trained: 4060000
    wait_time_ms: 259.434
  iterations_since_restore: 203
  node_ip: 172.17.8.11
  num_metric_batches_dropped: 0
  pid: 25504
  policy_reward_mean: {}
  time_since_restore: 5725.455612421036
  time_this_iter_s: 29.861140489578247
  time_total_s: 5725.455612421036
  timestamp: 1593919997
  timesteps_since_restore: 4060000
  timesteps_this_iter: 20000
  timesteps_total: 4060000
  training_iteration: 203
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=25504], 5725 s, 203 iter, 4060000 ts, 336 rew

agent-1: 8.0
agent-2: 23.0
agent-3: 14.0
agent-4: 22.0
agent-5: 5.0
agent-6: 14.0
agent-7: 17.0
agent-8: 10.0
agent-9: 28.0
agent-10: 18.0
agent-11: 22.0
agent-12: 14.0
agent-13: 17.0
agent-14: 4.0
agent-15: 13.0
agent-16: 10.0
agent-17: 17.0
agent-18: 29.0
agent-19: 27.0
agent-20: 19.0
Sum Reward: 331.0
Avg Reward: 16.55
Min Reward: 4.0
Gini Coefficient: 0.24123867069486404
20:20 Ratio: 3.962962962962963
Max-min Ratio: 7.25
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_23-33-45
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 514.0
  episode_reward_mean: 335.97
  episode_reward_min: 224.0
  episodes_this_iter: 1
  episodes_total: 203
  experiment_id: 35d66058da2d4c9882f832ee91e4aa4a
  hostname: gpu011
  info:
    apply_time_ms: 3.022
    dispatch_time_ms: 6.208
    learner:
      cur_lr: 0.0010896039893850684
      grad_gnorm: 10.832773208618164
      policy_entropy: 155.15782165527344
      policy_loss: -2.8100054264068604
      var_gnorm: 19.98615837097168
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 4.003355979919434
    num_steps_sampled: 4080000
    num_steps_trained: 4080000
    wait_time_ms: 252.667
  iterations_since_restore: 204
  node_ip: 172.17.8.11
  num_metric_batches_dropped: 0
  pid: 25504
  policy_reward_mean: {}
  time_since_restore: 5752.741659641266
  time_this_iter_s: 27.286047220230103
  time_total_s: 5752.741659641266
  timestamp: 1593920025
  timesteps_since_restore: 4080000
  timesteps_this_iter: 20000
  timesteps_total: 4080000
  training_iteration: 204
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=25504], 5752 s, 204 iter, 4080000 ts, 336 rew

agent-1: 11.0
agent-2: 25.0
agent-3: 33.0
agent-4: 12.0
agent-5: 9.0
agent-6: 7.0
agent-7: 7.0
agent-8: 37.0
agent-9: 8.0
agent-10: 52.0
agent-11: 35.0
agent-12: 31.0
agent-13: 24.0
agent-14: 35.0
agent-15: 21.0
agent-16: 22.0
agent-17: 17.0
agent-18: 11.0
agent-19: 7.0
agent-20: 9.0
Sum Reward: 413.0
Avg Reward: 20.65
Min Reward: 7.0
Gini Coefficient: 0.3383777239709443
20:20 Ratio: 5.482758620689655
Max-min Ratio: 7.428571428571429
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_23-34-12
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 514.0
  episode_reward_mean: 336.6
  episode_reward_min: 224.0
  episodes_this_iter: 1
  episodes_total: 204
  experiment_id: 35d66058da2d4c9882f832ee91e4aa4a
  hostname: gpu011
  info:
    apply_time_ms: 3.19
    dispatch_time_ms: 6.548
    learner:
      cur_lr: 0.0010882719652727246
      grad_gnorm: 30.420940399169922
      policy_entropy: 179.94564819335938
      policy_loss: -11.087921142578125
      var_gnorm: 19.991064071655273
      vf_explained_var: 1.7881393432617188e-07
      vf_loss: 4.817229747772217
    num_steps_sampled: 4100000
    num_steps_trained: 4100000
    wait_time_ms: 263.441
  iterations_since_restore: 205
  node_ip: 172.17.8.11
  num_metric_batches_dropped: 0
  pid: 25504
  policy_reward_mean: {}
  time_since_restore: 5780.059292316437
  time_this_iter_s: 27.3176326751709
  time_total_s: 5780.059292316437
  timestamp: 1593920052
  timesteps_since_restore: 4100000
  timesteps_this_iter: 20000
  timesteps_total: 4100000
  training_iteration: 205
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=25504], 5780 s, 205 iter, 4100000 ts, 337 rew

agent-1: 10.0
agent-2: 27.0
agent-3: 27.0
agent-4: 5.0
agent-5: 25.0
agent-6: 27.0
agent-7: 28.0
agent-8: 32.0
agent-9: 21.0
agent-10: 10.0
agent-11: 26.0
agent-12: 15.0
agent-13: 37.0
agent-14: 26.0
agent-15: 35.0
agent-16: 32.0
agent-17: 39.0
agent-18: 36.0
agent-19: 18.0
agent-20: 29.0
Sum Reward: 505.0
Avg Reward: 25.25
Min Reward: 5.0
Gini Coefficient: 0.20287128712871288
20:20 Ratio: 3.675
Max-min Ratio: 7.8
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_23-34-39
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 514.0
  episode_reward_mean: 338.54
  episode_reward_min: 224.0
  episodes_this_iter: 1
  episodes_total: 205
  experiment_id: 35d66058da2d4c9882f832ee91e4aa4a
  hostname: gpu011
  info:
    apply_time_ms: 2.758
    dispatch_time_ms: 7.032
    learner:
      cur_lr: 0.0010869400575757027
      grad_gnorm: 40.000003814697266
      policy_entropy: 165.85122680664062
      policy_loss: 11.448304176330566
      var_gnorm: 19.984344482421875
      vf_explained_var: 0.0
      vf_loss: 15.524782180786133
    num_steps_sampled: 4120000
    num_steps_trained: 4120000
    wait_time_ms: 262.755
  iterations_since_restore: 206
  node_ip: 172.17.8.11
  num_metric_batches_dropped: 0
  pid: 25504
  policy_reward_mean: {}
  time_since_restore: 5807.427580356598
  time_this_iter_s: 27.368288040161133
  time_total_s: 5807.427580356598
  timestamp: 1593920079
  timesteps_since_restore: 4120000
  timesteps_this_iter: 20000
  timesteps_total: 4120000
  training_iteration: 206
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=25504], 5807 s, 206 iter, 4120000 ts, 339 rew

agent-1: 25.0
agent-2: 12.0
agent-3: 6.0
agent-4: 13.0
agent-5: 10.0
agent-6: 29.0
agent-7: 23.0
agent-8: 28.0
agent-9: 19.0
agent-10: 5.0
agent-11: 21.0
agent-12: 19.0
agent-13: 6.0
agent-14: 9.0
agent-15: 10.0
agent-16: 9.0
agent-17: 11.0
agent-18: 26.0
agent-19: 10.0
agent-20: 6.0
Sum Reward: 297.0
Avg Reward: 14.85
Min Reward: 5.0
Gini Coefficient: 0.29579124579124577
20:20 Ratio: 4.695652173913044
Max-min Ratio: 5.8
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_23-35-07
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 514.0
  episode_reward_mean: 338.5
  episode_reward_min: 224.0
  episodes_this_iter: 1
  episodes_total: 206
  experiment_id: 35d66058da2d4c9882f832ee91e4aa4a
  hostname: gpu011
  info:
    apply_time_ms: 2.822
    dispatch_time_ms: 31.391
    learner:
      cur_lr: 0.0010856080334633589
      grad_gnorm: 27.60416030883789
      policy_entropy: 157.44776916503906
      policy_loss: -9.197002410888672
      var_gnorm: 19.98720932006836
      vf_explained_var: 1.1920928955078125e-07
      vf_loss: 0.3060724437236786
    num_steps_sampled: 4140000
    num_steps_trained: 4140000
    wait_time_ms: 271.02
  iterations_since_restore: 207
  node_ip: 172.17.8.11
  num_metric_batches_dropped: 0
  pid: 25504
  policy_reward_mean: {}
  time_since_restore: 5835.2112555503845
  time_this_iter_s: 27.78367519378662
  time_total_s: 5835.2112555503845
  timestamp: 1593920107
  timesteps_since_restore: 4140000
  timesteps_this_iter: 20000
  timesteps_total: 4140000
  training_iteration: 207
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=25504], 5835 s, 207 iter, 4140000 ts, 338 rew

agent-1: 3.0
agent-2: 17.0
agent-3: 16.0
agent-4: 18.0
agent-5: 16.0
agent-6: 17.0
agent-7: 20.0
agent-8: 21.0
agent-9: 13.0
agent-10: 25.0
agent-11: 33.0
agent-12: 20.0
agent-13: 16.0
agent-14: 2.0
agent-15: 19.0
agent-16: 10.0
agent-17: 8.0
agent-18: 23.0
agent-19: 22.0
agent-20: 12.0
Sum Reward: 331.0
Avg Reward: 16.55
Min Reward: 2.0
Gini Coefficient: 0.2348942598187311
20:20 Ratio: 4.478260869565218
Max-min Ratio: 16.5
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_23-35-36
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 514.0
  episode_reward_mean: 339.57
  episode_reward_min: 231.0
  episodes_this_iter: 1
  episodes_total: 207
  experiment_id: 35d66058da2d4c9882f832ee91e4aa4a
  hostname: gpu011
  info:
    apply_time_ms: 2.771
    dispatch_time_ms: 38.032
    learner:
      cur_lr: 0.001084276009351015
      grad_gnorm: 15.841118812561035
      policy_entropy: 189.08612060546875
      policy_loss: -1.4618258476257324
      var_gnorm: 19.988014221191406
      vf_explained_var: 2.980232238769531e-07
      vf_loss: 2.800901412963867
    num_steps_sampled: 4160000
    num_steps_trained: 4160000
    wait_time_ms: 233.505
  iterations_since_restore: 208
  node_ip: 172.17.8.11
  num_metric_batches_dropped: 0
  pid: 25504
  policy_reward_mean: {}
  time_since_restore: 5863.776850700378
  time_this_iter_s: 28.565595149993896
  time_total_s: 5863.776850700378
  timestamp: 1593920136
  timesteps_since_restore: 4160000
  timesteps_this_iter: 20000
  timesteps_total: 4160000
  training_iteration: 208
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=25504], 5863 s, 208 iter, 4160000 ts, 340 rew

agent-1: 22.0
agent-2: 10.0
agent-3: 23.0
agent-4: 7.0
agent-5: 33.0
agent-6: 37.0
agent-7: 26.0
agent-8: 5.0
agent-9: 14.0
agent-10: 20.0
agent-11: 8.0
agent-12: 15.0
agent-13: 17.0
agent-14: 6.0
agent-15: 3.0
agent-16: 8.0
agent-17: 20.0
agent-18: 17.0
agent-19: 9.0
agent-20: 13.0
Sum Reward: 313.0
Avg Reward: 15.65
Min Reward: 3.0
Gini Coefficient: 0.3222044728434505
20:20 Ratio: 5.666666666666667
Max-min Ratio: 12.333333333333334
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_23-36-05
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 514.0
  episode_reward_mean: 339.76
  episode_reward_min: 231.0
  episodes_this_iter: 1
  episodes_total: 208
  experiment_id: 35d66058da2d4c9882f832ee91e4aa4a
  hostname: gpu011
  info:
    apply_time_ms: 3.18
    dispatch_time_ms: 29.372
    learner:
      cur_lr: 0.0010829439852386713
      grad_gnorm: 17.589391708374023
      policy_entropy: 182.26913452148438
      policy_loss: 4.328442573547363
      var_gnorm: 19.988046646118164
      vf_explained_var: 0.0
      vf_loss: 8.47064208984375
    num_steps_sampled: 4180000
    num_steps_trained: 4180000
    wait_time_ms: 273.165
  iterations_since_restore: 209
  node_ip: 172.17.8.11
  num_metric_batches_dropped: 0
  pid: 25504
  policy_reward_mean: {}
  time_since_restore: 5892.575083732605
  time_this_iter_s: 28.798233032226562
  time_total_s: 5892.575083732605
  timestamp: 1593920165
  timesteps_since_restore: 4180000
  timesteps_this_iter: 20000
  timesteps_total: 4180000
  training_iteration: 209
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.3/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=25504], 5892 s, 209 iter, 4180000 ts, 340 rew

agent-1: 15.0
agent-2: 11.0
agent-3: 18.0
agent-4: 5.0
agent-5: 28.0
agent-6: 28.0
agent-7: 4.0
agent-8: 12.0
agent-9: 16.0
agent-10: 23.0
agent-11: 26.0
agent-12: 15.0
agent-13: 16.0
agent-14: 33.0
agent-15: 11.0
agent-16: 12.0
agent-17: 4.0
agent-18: 8.0
agent-19: 26.0
agent-20: 6.0
Sum Reward: 317.0
Avg Reward: 15.85
Min Reward: 4.0
Gini Coefficient: 0.30772870662460566
20:20 Ratio: 6.052631578947368
Max-min Ratio: 8.25
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_23-36-33
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 514.0
  episode_reward_mean: 340.14
  episode_reward_min: 231.0
  episodes_this_iter: 1
  episodes_total: 209
  experiment_id: 35d66058da2d4c9882f832ee91e4aa4a
  hostname: gpu011
  info:
    apply_time_ms: 4.175
    dispatch_time_ms: 15.051
    learner:
      cur_lr: 0.0010816119611263275
      grad_gnorm: 40.000003814697266
      policy_entropy: 171.16732788085938
      policy_loss: 51.011714935302734
      var_gnorm: 19.98798179626465
      vf_explained_var: 0.0
      vf_loss: 48.64485549926758
    num_steps_sampled: 4200000
    num_steps_trained: 4200000
    wait_time_ms: 236.634
  iterations_since_restore: 210
  node_ip: 172.17.8.11
  num_metric_batches_dropped: 0
  pid: 25504
  policy_reward_mean: {}
  time_since_restore: 5921.0379893779755
  time_this_iter_s: 28.462905645370483
  time_total_s: 5921.0379893779755
  timestamp: 1593920193
  timesteps_since_restore: 4200000
  timesteps_this_iter: 20000
  timesteps_total: 4200000
  training_iteration: 210
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.3/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=25504], 5921 s, 210 iter, 4200000 ts, 340 rew

agent-1: 13.0
agent-2: 18.0
agent-3: 4.0
agent-4: 26.0
agent-5: 3.0
agent-6: 8.0
agent-7: 16.0
agent-8: 16.0
agent-9: 11.0
agent-10: 17.0
agent-11: 5.0
agent-12: 4.0
agent-13: 2.0
agent-14: 20.0
agent-15: 15.0
agent-16: 12.0
agent-17: 21.0
agent-18: 16.0
agent-19: 12.0
agent-20: 32.0
Sum Reward: 271.0
Avg Reward: 13.55
Min Reward: 2.0
Gini Coefficient: 0.31678966789667895
20:20 Ratio: 7.615384615384615
Max-min Ratio: 16.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_23-37-01
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 514.0
  episode_reward_mean: 338.25
  episode_reward_min: 231.0
  episodes_this_iter: 1
  episodes_total: 210
  experiment_id: 35d66058da2d4c9882f832ee91e4aa4a
  hostname: gpu011
  info:
    apply_time_ms: 2.795
    dispatch_time_ms: 9.304
    learner:
      cur_lr: 0.0010802800534293056
      grad_gnorm: 24.48638343811035
      policy_entropy: 169.7989044189453
      policy_loss: -7.74942684173584
      var_gnorm: 19.990291595458984
      vf_explained_var: 0.0
      vf_loss: 0.24184483289718628
    num_steps_sampled: 4220000
    num_steps_trained: 4220000
    wait_time_ms: 263.066
  iterations_since_restore: 211
  node_ip: 172.17.8.11
  num_metric_batches_dropped: 0
  pid: 25504
  policy_reward_mean: {}
  time_since_restore: 5948.715807914734
  time_this_iter_s: 27.677818536758423
  time_total_s: 5948.715807914734
  timestamp: 1593920221
  timesteps_since_restore: 4220000
  timesteps_this_iter: 20000
  timesteps_total: 4220000
  training_iteration: 211
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=25504], 5948 s, 211 iter, 4220000 ts, 338 rew

agent-1: 17.0
agent-2: 5.0
agent-3: 16.0
agent-4: 17.0
agent-5: 20.0
agent-6: 13.0
agent-7: 8.0
agent-8: 25.0
agent-9: 16.0
agent-10: 18.0
agent-11: 12.0
agent-12: 32.0
agent-13: 6.0
agent-14: 12.0
agent-15: 7.0
agent-16: 2.0
agent-17: 30.0
agent-18: 22.0
agent-19: 15.0
agent-20: 15.0
Sum Reward: 308.0
Avg Reward: 15.4
Min Reward: 2.0
Gini Coefficient: 0.2792207792207792
20:20 Ratio: 5.45
Max-min Ratio: 16.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_23-37-28
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 514.0
  episode_reward_mean: 337.81
  episode_reward_min: 231.0
  episodes_this_iter: 1
  episodes_total: 211
  experiment_id: 35d66058da2d4c9882f832ee91e4aa4a
  hostname: gpu011
  info:
    apply_time_ms: 2.757
    dispatch_time_ms: 6.371
    learner:
      cur_lr: 0.0010789480293169618
      grad_gnorm: 40.0
      policy_entropy: 177.58470153808594
      policy_loss: 43.669837951660156
      var_gnorm: 19.982786178588867
      vf_explained_var: 0.0
      vf_loss: 40.64734649658203
    num_steps_sampled: 4240000
    num_steps_trained: 4240000
    wait_time_ms: 259.206
  iterations_since_restore: 212
  node_ip: 172.17.8.11
  num_metric_batches_dropped: 0
  pid: 25504
  policy_reward_mean: {}
  time_since_restore: 5976.052283525467
  time_this_iter_s: 27.336475610733032
  time_total_s: 5976.052283525467
  timestamp: 1593920248
  timesteps_since_restore: 4240000
  timesteps_this_iter: 20000
  timesteps_total: 4240000
  training_iteration: 212
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.3/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=25504], 5976 s, 212 iter, 4240000 ts, 338 rew

agent-1: 8.0
agent-2: 21.0
agent-3: 18.0
agent-4: 22.0
agent-5: 9.0
agent-6: 11.0
agent-7: 24.0
agent-8: 15.0
agent-9: 16.0
agent-10: 17.0
agent-11: 4.0
agent-12: 9.0
agent-13: 20.0
agent-14: 20.0
agent-15: 18.0
agent-16: 11.0
agent-17: 19.0
agent-18: 10.0
agent-19: 15.0
agent-20: 16.0
Sum Reward: 303.0
Avg Reward: 15.15
Min Reward: 4.0
Gini Coefficient: 0.19686468646864685
20:20 Ratio: 2.9
Max-min Ratio: 6.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_23-37-56
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 514.0
  episode_reward_mean: 337.66
  episode_reward_min: 231.0
  episodes_this_iter: 1
  episodes_total: 212
  experiment_id: 35d66058da2d4c9882f832ee91e4aa4a
  hostname: gpu011
  info:
    apply_time_ms: 2.348
    dispatch_time_ms: 7.142
    learner:
      cur_lr: 0.001077616005204618
      grad_gnorm: 18.201364517211914
      policy_entropy: 167.1402130126953
      policy_loss: -4.7743239402771
      var_gnorm: 19.985130310058594
      vf_explained_var: 0.0
      vf_loss: 7.313916206359863
    num_steps_sampled: 4260000
    num_steps_trained: 4260000
    wait_time_ms: 260.578
  iterations_since_restore: 213
  node_ip: 172.17.8.11
  num_metric_batches_dropped: 0
  pid: 25504
  policy_reward_mean: {}
  time_since_restore: 6003.562491416931
  time_this_iter_s: 27.510207891464233
  time_total_s: 6003.562491416931
  timestamp: 1593920276
  timesteps_since_restore: 4260000
  timesteps_this_iter: 20000
  timesteps_total: 4260000
  training_iteration: 213
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=25504], 6003 s, 213 iter, 4260000 ts, 338 rew

agent-1: 35.0
agent-2: 30.0
agent-3: 12.0
agent-4: 27.0
agent-5: 13.0
agent-6: 23.0
agent-7: 39.0
agent-8: 12.0
agent-9: 8.0
agent-10: 36.0
agent-11: 21.0
agent-12: 40.0
agent-13: 28.0
agent-14: 12.0
agent-15: 47.0
agent-16: 21.0
agent-17: 34.0
agent-18: 32.0
agent-19: 21.0
agent-20: 12.0
Sum Reward: 503.0
Avg Reward: 25.15
Min Reward: 8.0
Gini Coefficient: 0.2507952286282306
20:20 Ratio: 3.6818181818181817
Max-min Ratio: 5.875
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_23-38-26
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 514.0
  episode_reward_mean: 338.86
  episode_reward_min: 231.0
  episodes_this_iter: 1
  episodes_total: 213
  experiment_id: 35d66058da2d4c9882f832ee91e4aa4a
  hostname: gpu011
  info:
    apply_time_ms: 3.685
    dispatch_time_ms: 27.686
    learner:
      cur_lr: 0.0010762839810922742
      grad_gnorm: 2.519897222518921
      policy_entropy: 177.941162109375
      policy_loss: -0.14926838874816895
      var_gnorm: 19.983230590820312
      vf_explained_var: -2.384185791015625e-07
      vf_loss: 13.292801856994629
    num_steps_sampled: 4280000
    num_steps_trained: 4280000
    wait_time_ms: 229.362
  iterations_since_restore: 214
  node_ip: 172.17.8.11
  num_metric_batches_dropped: 0
  pid: 25504
  policy_reward_mean: {}
  time_since_restore: 6033.330112934113
  time_this_iter_s: 29.767621517181396
  time_total_s: 6033.330112934113
  timestamp: 1593920306
  timesteps_since_restore: 4280000
  timesteps_this_iter: 20000
  timesteps_total: 4280000
  training_iteration: 214
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.3/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=25504], 6033 s, 214 iter, 4280000 ts, 339 rew

agent-1: 12.0
agent-2: 29.0
agent-3: 26.0
agent-4: 12.0
agent-5: 10.0
agent-6: 8.0
agent-7: 5.0
agent-8: 8.0
agent-9: 13.0
agent-10: 23.0
agent-11: 8.0
agent-12: 12.0
agent-13: 25.0
agent-14: 8.0
agent-15: 27.0
agent-16: 36.0
agent-17: 12.0
agent-18: 32.0
agent-19: 23.0
agent-20: 9.0
Sum Reward: 338.0
Avg Reward: 16.9
Min Reward: 5.0
Gini Coefficient: 0.3032544378698225
20:20 Ratio: 4.275862068965517
Max-min Ratio: 7.2
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_23-39-04
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 514.0
  episode_reward_mean: 339.67
  episode_reward_min: 231.0
  episodes_this_iter: 1
  episodes_total: 214
  experiment_id: 35d66058da2d4c9882f832ee91e4aa4a
  hostname: gpu011
  info:
    apply_time_ms: 2.955
    dispatch_time_ms: 19.058
    learner:
      cur_lr: 0.0010749519569799304
      grad_gnorm: 24.081558227539062
      policy_entropy: 165.15823364257812
      policy_loss: -5.571205139160156
      var_gnorm: 19.983779907226562
      vf_explained_var: 0.0
      vf_loss: 0.2318153828382492
    num_steps_sampled: 4300000
    num_steps_trained: 4300000
    wait_time_ms: 262.248
  iterations_since_restore: 215
  node_ip: 172.17.8.11
  num_metric_batches_dropped: 0
  pid: 25504
  policy_reward_mean: {}
  time_since_restore: 6071.857262134552
  time_this_iter_s: 38.52714920043945
  time_total_s: 6071.857262134552
  timestamp: 1593920344
  timesteps_since_restore: 4300000
  timesteps_this_iter: 20000
  timesteps_total: 4300000
  training_iteration: 215
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.3/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=25504], 6071 s, 215 iter, 4300000 ts, 340 rew

agent-1: 9.0
agent-2: 20.0
agent-3: 10.0
agent-4: 8.0
agent-5: 33.0
agent-6: 36.0
agent-7: 17.0
agent-8: 27.0
agent-9: 12.0
agent-10: 16.0
agent-11: 19.0
agent-12: 15.0
agent-13: 17.0
agent-14: 36.0
agent-15: 12.0
agent-16: 6.0
agent-17: 20.0
agent-18: 10.0
agent-19: 16.0
agent-20: 15.0
Sum Reward: 354.0
Avg Reward: 17.7
Min Reward: 6.0
Gini Coefficient: 0.2646892655367232
20:20 Ratio: 4.0
Max-min Ratio: 6.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_23-39-32
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 514.0
  episode_reward_mean: 340.23
  episode_reward_min: 231.0
  episodes_this_iter: 1
  episodes_total: 215
  experiment_id: 35d66058da2d4c9882f832ee91e4aa4a
  hostname: gpu011
  info:
    apply_time_ms: 2.796
    dispatch_time_ms: 19.757
    learner:
      cur_lr: 0.0010736200492829084
      grad_gnorm: 28.29767608642578
      policy_entropy: 134.676025390625
      policy_loss: -8.203035354614258
      var_gnorm: 19.985715866088867
      vf_explained_var: 0.0
      vf_loss: 0.31961724162101746
    num_steps_sampled: 4320000
    num_steps_trained: 4320000
    wait_time_ms: 273.626
  iterations_since_restore: 216
  node_ip: 172.17.8.11
  num_metric_batches_dropped: 0
  pid: 25504
  policy_reward_mean: {}
  time_since_restore: 6100.089203119278
  time_this_iter_s: 28.231940984725952
  time_total_s: 6100.089203119278
  timestamp: 1593920372
  timesteps_since_restore: 4320000
  timesteps_this_iter: 20000
  timesteps_total: 4320000
  training_iteration: 216
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.3/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=25504], 6100 s, 216 iter, 4320000 ts, 340 rew

agent-1: 12.0
agent-2: 30.0
agent-3: 9.0
agent-4: 17.0
agent-5: 33.0
agent-6: 17.0
agent-7: 16.0
agent-8: 16.0
agent-9: 11.0
agent-10: 22.0
agent-11: 20.0
agent-12: 23.0
agent-13: 34.0
agent-14: 17.0
agent-15: 13.0
agent-16: 14.0
agent-17: 21.0
agent-18: 15.0
agent-19: 8.0
agent-20: 19.0
Sum Reward: 367.0
Avg Reward: 18.35
Min Reward: 8.0
Gini Coefficient: 0.21049046321525886
20:20 Ratio: 3.0
Max-min Ratio: 4.25
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_23-40-00
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 514.0
  episode_reward_mean: 340.93
  episode_reward_min: 231.0
  episodes_this_iter: 1
  episodes_total: 216
  experiment_id: 35d66058da2d4c9882f832ee91e4aa4a
  hostname: gpu011
  info:
    apply_time_ms: 2.576
    dispatch_time_ms: 6.019
    learner:
      cur_lr: 0.0010722880251705647
      grad_gnorm: 28.26209259033203
      policy_entropy: 151.8938446044922
      policy_loss: -6.929379463195801
      var_gnorm: 19.98634147644043
      vf_explained_var: 1.7881393432617188e-07
      vf_loss: 0.32247206568717957
    num_steps_sampled: 4340000
    num_steps_trained: 4340000
    wait_time_ms: 274.666
  iterations_since_restore: 217
  node_ip: 172.17.8.11
  num_metric_batches_dropped: 0
  pid: 25504
  policy_reward_mean: {}
  time_since_restore: 6127.714106559753
  time_this_iter_s: 27.624903440475464
  time_total_s: 6127.714106559753
  timestamp: 1593920400
  timesteps_since_restore: 4340000
  timesteps_this_iter: 20000
  timesteps_total: 4340000
  training_iteration: 217
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.3/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=25504], 6127 s, 217 iter, 4340000 ts, 341 rew

agent-1: 24.0
agent-2: 19.0
agent-3: 19.0
agent-4: 38.0
agent-5: 19.0
agent-6: 23.0
agent-7: 22.0
agent-8: 12.0
agent-9: 16.0
agent-10: 16.0
agent-11: 19.0
agent-12: 15.0
agent-13: 23.0
agent-14: 14.0
agent-15: 27.0
agent-16: 19.0
agent-17: 22.0
agent-18: 10.0
agent-19: 19.0
agent-20: 27.0
Sum Reward: 403.0
Avg Reward: 20.15
Min Reward: 10.0
Gini Coefficient: 0.15818858560794044
20:20 Ratio: 2.2745098039215685
Max-min Ratio: 3.8
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_23-40-27
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 514.0
  episode_reward_mean: 341.47
  episode_reward_min: 231.0
  episodes_this_iter: 1
  episodes_total: 217
  experiment_id: 35d66058da2d4c9882f832ee91e4aa4a
  hostname: gpu011
  info:
    apply_time_ms: 2.586
    dispatch_time_ms: 6.146
    learner:
      cur_lr: 0.0010709560010582209
      grad_gnorm: 22.503456115722656
      policy_entropy: 156.00192260742188
      policy_loss: -7.1552886962890625
      var_gnorm: 19.988309860229492
      vf_explained_var: 1.1920928955078125e-07
      vf_loss: 2.026524305343628
    num_steps_sampled: 4360000
    num_steps_trained: 4360000
    wait_time_ms: 263.11
  iterations_since_restore: 218
  node_ip: 172.17.8.11
  num_metric_batches_dropped: 0
  pid: 25504
  policy_reward_mean: {}
  time_since_restore: 6155.04763174057
  time_this_iter_s: 27.33352518081665
  time_total_s: 6155.04763174057
  timestamp: 1593920427
  timesteps_since_restore: 4360000
  timesteps_this_iter: 20000
  timesteps_total: 4360000
  training_iteration: 218
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=25504], 6155 s, 218 iter, 4360000 ts, 341 rew

agent-1: 20.0
agent-2: 22.0
agent-3: 31.0
agent-4: 13.0
agent-5: 14.0
agent-6: 3.0
agent-7: 17.0
agent-8: 28.0
agent-9: 11.0
agent-10: 14.0
agent-11: 10.0
agent-12: 26.0
agent-13: 5.0
agent-14: 29.0
agent-15: 8.0
agent-16: 17.0
agent-17: 29.0
agent-18: 14.0
agent-19: 11.0
agent-20: 25.0
Sum Reward: 347.0
Avg Reward: 17.35
Min Reward: 3.0
Gini Coefficient: 0.2716138328530259
20:20 Ratio: 4.5
Max-min Ratio: 10.333333333333334
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_23-40-55
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 514.0
  episode_reward_mean: 341.67
  episode_reward_min: 231.0
  episodes_this_iter: 1
  episodes_total: 218
  experiment_id: 35d66058da2d4c9882f832ee91e4aa4a
  hostname: gpu011
  info:
    apply_time_ms: 2.945
    dispatch_time_ms: 6.087
    learner:
      cur_lr: 0.001069623976945877
      grad_gnorm: 16.55838394165039
      policy_entropy: 169.43325805664062
      policy_loss: -4.478377342224121
      var_gnorm: 19.987571716308594
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 0.1107775941491127
    num_steps_sampled: 4380000
    num_steps_trained: 4380000
    wait_time_ms: 277.28
  iterations_since_restore: 219
  node_ip: 172.17.8.11
  num_metric_batches_dropped: 0
  pid: 25504
  policy_reward_mean: {}
  time_since_restore: 6182.417788743973
  time_this_iter_s: 27.37015700340271
  time_total_s: 6182.417788743973
  timestamp: 1593920455
  timesteps_since_restore: 4380000
  timesteps_this_iter: 20000
  timesteps_total: 4380000
  training_iteration: 219
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.3/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=25504], 6182 s, 219 iter, 4380000 ts, 342 rew

agent-1: 21.0
agent-2: 14.0
agent-3: 13.0
agent-4: 15.0
agent-5: 22.0
agent-6: 3.0
agent-7: 20.0
agent-8: 27.0
agent-9: 3.0
agent-10: 31.0
agent-11: 35.0
agent-12: 18.0
agent-13: 43.0
agent-14: 26.0
agent-15: 19.0
agent-16: 16.0
agent-17: 22.0
agent-18: 12.0
agent-19: 29.0
agent-20: 25.0
Sum Reward: 414.0
Avg Reward: 20.7
Min Reward: 3.0
Gini Coefficient: 0.257487922705314
20:20 Ratio: 4.451612903225806
Max-min Ratio: 14.333333333333334
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_23-41-22
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 514.0
  episode_reward_mean: 341.2
  episode_reward_min: 231.0
  episodes_this_iter: 1
  episodes_total: 219
  experiment_id: 35d66058da2d4c9882f832ee91e4aa4a
  hostname: gpu011
  info:
    apply_time_ms: 2.665
    dispatch_time_ms: 6.764
    learner:
      cur_lr: 0.0010682919528335333
      grad_gnorm: 31.427169799804688
      policy_entropy: 165.98867797851562
      policy_loss: -10.520788192749023
      var_gnorm: 19.98906707763672
      vf_explained_var: 0.0
      vf_loss: 0.3991984724998474
    num_steps_sampled: 4400000
    num_steps_trained: 4400000
    wait_time_ms: 269.033
  iterations_since_restore: 220
  node_ip: 172.17.8.11
  num_metric_batches_dropped: 0
  pid: 25504
  policy_reward_mean: {}
  time_since_restore: 6209.473932027817
  time_this_iter_s: 27.056143283843994
  time_total_s: 6209.473932027817
  timestamp: 1593920482
  timesteps_since_restore: 4400000
  timesteps_this_iter: 20000
  timesteps_total: 4400000
  training_iteration: 220
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=25504], 6209 s, 220 iter, 4400000 ts, 341 rew

agent-1: 16.0
agent-2: 12.0
agent-3: 10.0
agent-4: 12.0
agent-5: 9.0
agent-6: 36.0
agent-7: 31.0
agent-8: 0.0
agent-9: 24.0
agent-10: 17.0
agent-11: 16.0
agent-12: 15.0
agent-13: 13.0
agent-14: 21.0
agent-15: 28.0
agent-16: 9.0
agent-17: 14.0
agent-18: 10.0
agent-19: 23.0
agent-20: 17.0
Sum Reward: 333.0
Avg Reward: 16.65
Min Reward: 0.0
Gini Coefficient: 0.27192192192192194
20:20 Ratio: 4.25
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_23-41-50
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 514.0
  episode_reward_mean: 341.84
  episode_reward_min: 231.0
  episodes_this_iter: 1
  episodes_total: 220
  experiment_id: 35d66058da2d4c9882f832ee91e4aa4a
  hostname: gpu011
  info:
    apply_time_ms: 2.89
    dispatch_time_ms: 6.108
    learner:
      cur_lr: 0.0010669600451365113
      grad_gnorm: 14.641411781311035
      policy_entropy: 165.05189514160156
      policy_loss: -3.568948984146118
      var_gnorm: 19.9896297454834
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 0.08398403972387314
    num_steps_sampled: 4420000
    num_steps_trained: 4420000
    wait_time_ms: 270.457
  iterations_since_restore: 221
  node_ip: 172.17.8.11
  num_metric_batches_dropped: 0
  pid: 25504
  policy_reward_mean: {}
  time_since_restore: 6237.038628578186
  time_this_iter_s: 27.564696550369263
  time_total_s: 6237.038628578186
  timestamp: 1593920510
  timesteps_since_restore: 4420000
  timesteps_this_iter: 20000
  timesteps_total: 4420000
  training_iteration: 221
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=25504], 6237 s, 221 iter, 4420000 ts, 342 rew

agent-1: 13.0
agent-2: 31.0
agent-3: 7.0
agent-4: 12.0
agent-5: 20.0
agent-6: 14.0
agent-7: 27.0
agent-8: 7.0
agent-9: 29.0
agent-10: 12.0
agent-11: 8.0
agent-12: 28.0
agent-13: 27.0
agent-14: 18.0
agent-15: 19.0
agent-16: 14.0
agent-17: 6.0
agent-18: 26.0
agent-19: 4.0
agent-20: 13.0
Sum Reward: 335.0
Avg Reward: 16.75
Min Reward: 4.0
Gini Coefficient: 0.28582089552238804
20:20 Ratio: 4.791666666666667
Max-min Ratio: 7.75
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_23-42-17
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 514.0
  episode_reward_mean: 340.81
  episode_reward_min: 231.0
  episodes_this_iter: 1
  episodes_total: 221
  experiment_id: 35d66058da2d4c9882f832ee91e4aa4a
  hostname: gpu011
  info:
    apply_time_ms: 3.135
    dispatch_time_ms: 8.371
    learner:
      cur_lr: 0.0010656280210241675
      grad_gnorm: 27.423622131347656
      policy_entropy: 169.41033935546875
      policy_loss: -4.370691776275635
      var_gnorm: 19.993783950805664
      vf_explained_var: 0.0
      vf_loss: 8.392833709716797
    num_steps_sampled: 4440000
    num_steps_trained: 4440000
    wait_time_ms: 256.224
  iterations_since_restore: 222
  node_ip: 172.17.8.11
  num_metric_batches_dropped: 0
  pid: 25504
  policy_reward_mean: {}
  time_since_restore: 6264.242086648941
  time_this_iter_s: 27.203458070755005
  time_total_s: 6264.242086648941
  timestamp: 1593920537
  timesteps_since_restore: 4440000
  timesteps_this_iter: 20000
  timesteps_total: 4440000
  training_iteration: 222
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=25504], 6264 s, 222 iter, 4440000 ts, 341 rew

agent-1: 3.0
agent-2: 6.0
agent-3: 17.0
agent-4: 13.0
agent-5: 31.0
agent-6: 22.0
agent-7: 21.0
agent-8: 30.0
agent-9: 8.0
agent-10: 29.0
agent-11: 11.0
agent-12: 8.0
agent-13: 16.0
agent-14: 24.0
agent-15: 34.0
agent-16: 24.0
agent-17: 18.0
agent-18: 23.0
agent-19: 12.0
agent-20: 9.0
Sum Reward: 359.0
Avg Reward: 17.95
Min Reward: 3.0
Gini Coefficient: 0.28370473537604457
20:20 Ratio: 4.96
Max-min Ratio: 11.333333333333334
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_23-42-44
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 514.0
  episode_reward_mean: 340.34
  episode_reward_min: 231.0
  episodes_this_iter: 1
  episodes_total: 222
  experiment_id: 35d66058da2d4c9882f832ee91e4aa4a
  hostname: gpu011
  info:
    apply_time_ms: 3.867
    dispatch_time_ms: 6.651
    learner:
      cur_lr: 0.0010642959969118237
      grad_gnorm: 28.544347763061523
      policy_entropy: 146.9314727783203
      policy_loss: -7.247866630554199
      var_gnorm: 19.999055862426758
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 0.32919755578041077
    num_steps_sampled: 4460000
    num_steps_trained: 4460000
    wait_time_ms: 271.495
  iterations_since_restore: 223
  node_ip: 172.17.8.11
  num_metric_batches_dropped: 0
  pid: 25504
  policy_reward_mean: {}
  time_since_restore: 6291.587759256363
  time_this_iter_s: 27.345672607421875
  time_total_s: 6291.587759256363
  timestamp: 1593920564
  timesteps_since_restore: 4460000
  timesteps_this_iter: 20000
  timesteps_total: 4460000
  training_iteration: 223
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=25504], 6291 s, 223 iter, 4460000 ts, 340 rew

agent-1: 27.0
agent-2: 17.0
agent-3: 36.0
agent-4: 21.0
agent-5: 7.0
agent-6: 48.0
agent-7: 19.0
agent-8: 25.0
agent-9: 20.0
agent-10: 14.0
agent-11: 23.0
agent-12: 15.0
agent-13: 29.0
agent-14: 36.0
agent-15: 15.0
agent-16: 35.0
agent-17: 19.0
agent-18: 23.0
agent-19: 26.0
agent-20: 38.0
Sum Reward: 493.0
Avg Reward: 24.65
Min Reward: 7.0
Gini Coefficient: 0.2191683569979716
20:20 Ratio: 3.0980392156862746
Max-min Ratio: 6.857142857142857
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_23-43-11
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 514.0
  episode_reward_mean: 340.54
  episode_reward_min: 231.0
  episodes_this_iter: 1
  episodes_total: 223
  experiment_id: 35d66058da2d4c9882f832ee91e4aa4a
  hostname: gpu011
  info:
    apply_time_ms: 2.601
    dispatch_time_ms: 5.33
    learner:
      cur_lr: 0.00106296397279948
      grad_gnorm: 34.389495849609375
      policy_entropy: 166.5971221923828
      policy_loss: -11.27009391784668
      var_gnorm: 20.000171661376953
      vf_explained_var: 0.0
      vf_loss: 0.47779160737991333
    num_steps_sampled: 4480000
    num_steps_trained: 4480000
    wait_time_ms: 275.424
  iterations_since_restore: 224
  node_ip: 172.17.8.11
  num_metric_batches_dropped: 0
  pid: 25504
  policy_reward_mean: {}
  time_since_restore: 6318.765886068344
  time_this_iter_s: 27.1781268119812
  time_total_s: 6318.765886068344
  timestamp: 1593920591
  timesteps_since_restore: 4480000
  timesteps_this_iter: 20000
  timesteps_total: 4480000
  training_iteration: 224
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=25504], 6318 s, 224 iter, 4480000 ts, 341 rew

agent-1: 21.0
agent-2: 12.0
agent-3: 14.0
agent-4: 35.0
agent-5: 14.0
agent-6: 26.0
agent-7: 30.0
agent-8: 20.0
agent-9: 13.0
agent-10: 9.0
agent-11: 16.0
agent-12: 13.0
agent-13: 22.0
agent-14: 15.0
agent-15: 9.0
agent-16: 20.0
agent-17: 23.0
agent-18: 13.0
agent-19: 20.0
agent-20: 26.0
Sum Reward: 371.0
Avg Reward: 18.55
Min Reward: 9.0
Gini Coefficient: 0.20471698113207548
20:20 Ratio: 2.7209302325581395
Max-min Ratio: 3.888888888888889
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_23-43-39
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 514.0
  episode_reward_mean: 340.24
  episode_reward_min: 231.0
  episodes_this_iter: 1
  episodes_total: 224
  experiment_id: 35d66058da2d4c9882f832ee91e4aa4a
  hostname: gpu011
  info:
    apply_time_ms: 3.381
    dispatch_time_ms: 7.111
    learner:
      cur_lr: 0.0010616319486871362
      grad_gnorm: 12.897114753723145
      policy_entropy: 185.63868713378906
      policy_loss: -2.996480941772461
      var_gnorm: 19.995223999023438
      vf_explained_var: 1.1920928955078125e-07
      vf_loss: 0.0670904666185379
    num_steps_sampled: 4500000
    num_steps_trained: 4500000
    wait_time_ms: 257.873
  iterations_since_restore: 225
  node_ip: 172.17.8.11
  num_metric_batches_dropped: 0
  pid: 25504
  policy_reward_mean: {}
  time_since_restore: 6346.2749655246735
  time_this_iter_s: 27.509079456329346
  time_total_s: 6346.2749655246735
  timestamp: 1593920619
  timesteps_since_restore: 4500000
  timesteps_this_iter: 20000
  timesteps_total: 4500000
  training_iteration: 225
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=25504], 6346 s, 225 iter, 4500000 ts, 340 rew

agent-1: 8.0
agent-2: 31.0
agent-3: 21.0
agent-4: 7.0
agent-5: 6.0
agent-6: 11.0
agent-7: 7.0
agent-8: 4.0
agent-9: 24.0
agent-10: 16.0
agent-11: 12.0
agent-12: 11.0
agent-13: 14.0
agent-14: 21.0
agent-15: 13.0
agent-16: 23.0
agent-17: 25.0
agent-18: 13.0
agent-19: 14.0
agent-20: 10.0
Sum Reward: 291.0
Avg Reward: 14.55
Min Reward: 4.0
Gini Coefficient: 0.2743986254295533
20:20 Ratio: 4.291666666666667
Max-min Ratio: 7.75
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_23-44-06
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 514.0
  episode_reward_mean: 339.73
  episode_reward_min: 231.0
  episodes_this_iter: 1
  episodes_total: 225
  experiment_id: 35d66058da2d4c9882f832ee91e4aa4a
  hostname: gpu011
  info:
    apply_time_ms: 3.0
    dispatch_time_ms: 6.301
    learner:
      cur_lr: 0.0010603000409901142
      grad_gnorm: 26.074459075927734
      policy_entropy: 188.946044921875
      policy_loss: -9.331921577453613
      var_gnorm: 19.990629196166992
      vf_explained_var: 1.1920928955078125e-07
      vf_loss: 0.25817930698394775
    num_steps_sampled: 4520000
    num_steps_trained: 4520000
    wait_time_ms: 268.944
  iterations_since_restore: 226
  node_ip: 172.17.8.11
  num_metric_batches_dropped: 0
  pid: 25504
  policy_reward_mean: {}
  time_since_restore: 6373.658703327179
  time_this_iter_s: 27.383737802505493
  time_total_s: 6373.658703327179
  timestamp: 1593920646
  timesteps_since_restore: 4520000
  timesteps_this_iter: 20000
  timesteps_total: 4520000
  training_iteration: 226
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.3/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=25504], 6373 s, 226 iter, 4520000 ts, 340 rew

agent-1: 17.0
agent-2: 10.0
agent-3: 36.0
agent-4: 27.0
agent-5: 21.0
agent-6: 11.0
agent-7: 22.0
agent-8: 21.0
agent-9: 14.0
agent-10: 9.0
agent-11: 7.0
agent-12: 12.0
agent-13: 19.0
agent-14: 18.0
agent-15: 18.0
agent-16: 23.0
agent-17: 22.0
agent-18: 7.0
agent-19: 16.0
agent-20: 38.0
Sum Reward: 368.0
Avg Reward: 18.4
Min Reward: 7.0
Gini Coefficient: 0.24619565217391304
20:20 Ratio: 3.757575757575758
Max-min Ratio: 5.428571428571429
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_23-44-34
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 514.0
  episode_reward_mean: 341.03
  episode_reward_min: 231.0
  episodes_this_iter: 1
  episodes_total: 226
  experiment_id: 35d66058da2d4c9882f832ee91e4aa4a
  hostname: gpu011
  info:
    apply_time_ms: 3.356
    dispatch_time_ms: 7.41
    learner:
      cur_lr: 0.0010589680168777704
      grad_gnorm: 12.537843704223633
      policy_entropy: 181.8182830810547
      policy_loss: -3.1390252113342285
      var_gnorm: 19.990238189697266
      vf_explained_var: 0.0
      vf_loss: 0.06256231665611267
    num_steps_sampled: 4540000
    num_steps_trained: 4540000
    wait_time_ms: 262.149
  iterations_since_restore: 227
  node_ip: 172.17.8.11
  num_metric_batches_dropped: 0
  pid: 25504
  policy_reward_mean: {}
  time_since_restore: 6401.067704677582
  time_this_iter_s: 27.409001350402832
  time_total_s: 6401.067704677582
  timestamp: 1593920674
  timesteps_since_restore: 4540000
  timesteps_this_iter: 20000
  timesteps_total: 4540000
  training_iteration: 227
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=25504], 6401 s, 227 iter, 4540000 ts, 341 rew

agent-1: 3.0
agent-2: 11.0
agent-3: 13.0
agent-4: 5.0
agent-5: 15.0
agent-6: 19.0
agent-7: 20.0
agent-8: 20.0
agent-9: 19.0
agent-10: 9.0
agent-11: 6.0
agent-12: 17.0
agent-13: 8.0
agent-14: 21.0
agent-15: 24.0
agent-16: 9.0
agent-17: 12.0
agent-18: 34.0
agent-19: 6.0
agent-20: 27.0
Sum Reward: 298.0
Avg Reward: 14.9
Min Reward: 3.0
Gini Coefficient: 0.29966442953020134
20:20 Ratio: 5.3
Max-min Ratio: 11.333333333333334
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_23-45-01
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 514.0
  episode_reward_mean: 341.08
  episode_reward_min: 231.0
  episodes_this_iter: 1
  episodes_total: 227
  experiment_id: 35d66058da2d4c9882f832ee91e4aa4a
  hostname: gpu011
  info:
    apply_time_ms: 2.735
    dispatch_time_ms: 6.083
    learner:
      cur_lr: 0.0010576359927654266
      grad_gnorm: 39.71878433227539
      policy_entropy: 191.51646423339844
      policy_loss: -13.710245132446289
      var_gnorm: 19.993122100830078
      vf_explained_var: 0.0
      vf_loss: 0.6276073455810547
    num_steps_sampled: 4560000
    num_steps_trained: 4560000
    wait_time_ms: 266.378
  iterations_since_restore: 228
  node_ip: 172.17.8.11
  num_metric_batches_dropped: 0
  pid: 25504
  policy_reward_mean: {}
  time_since_restore: 6428.455097198486
  time_this_iter_s: 27.38739252090454
  time_total_s: 6428.455097198486
  timestamp: 1593920701
  timesteps_since_restore: 4560000
  timesteps_this_iter: 20000
  timesteps_total: 4560000
  training_iteration: 228
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=25504], 6428 s, 228 iter, 4560000 ts, 341 rew

agent-1: 28.0
agent-2: 20.0
agent-3: 18.0
agent-4: 20.0
agent-5: 15.0
agent-6: 12.0
agent-7: 32.0
agent-8: 10.0
agent-9: 13.0
agent-10: 13.0
agent-11: 13.0
agent-12: 21.0
agent-13: 14.0
agent-14: 20.0
agent-15: 19.0
agent-16: 4.0
agent-17: 13.0
agent-18: 9.0
agent-19: 45.0
agent-20: 30.0
Sum Reward: 369.0
Avg Reward: 18.45
Min Reward: 4.0
Gini Coefficient: 0.2616531165311653
20:20 Ratio: 3.857142857142857
Max-min Ratio: 11.25
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_23-45-29
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 514.0
  episode_reward_mean: 341.72
  episode_reward_min: 231.0
  episodes_this_iter: 1
  episodes_total: 228
  experiment_id: 35d66058da2d4c9882f832ee91e4aa4a
  hostname: gpu011
  info:
    apply_time_ms: 3.087
    dispatch_time_ms: 7.519
    learner:
      cur_lr: 0.0010563039686530828
      grad_gnorm: 18.629030227661133
      policy_entropy: 176.75401306152344
      policy_loss: -4.893815994262695
      var_gnorm: 19.990745544433594
      vf_explained_var: 0.0
      vf_loss: 0.1381579339504242
    num_steps_sampled: 4580000
    num_steps_trained: 4580000
    wait_time_ms: 253.52
  iterations_since_restore: 229
  node_ip: 172.17.8.11
  num_metric_batches_dropped: 0
  pid: 25504
  policy_reward_mean: {}
  time_since_restore: 6455.773458003998
  time_this_iter_s: 27.318360805511475
  time_total_s: 6455.773458003998
  timestamp: 1593920729
  timesteps_since_restore: 4580000
  timesteps_this_iter: 20000
  timesteps_total: 4580000
  training_iteration: 229
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.3/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=25504], 6455 s, 229 iter, 4580000 ts, 342 rew

agent-1: 13.0
agent-2: 15.0
agent-3: 15.0
agent-4: 28.0
agent-5: 28.0
agent-6: 11.0
agent-7: 29.0
agent-8: 15.0
agent-9: 16.0
agent-10: 9.0
agent-11: 9.0
agent-12: 12.0
agent-13: 24.0
agent-14: 5.0
agent-15: 12.0
agent-16: 24.0
agent-17: 22.0
agent-18: 4.0
agent-19: 4.0
agent-20: 12.0
Sum Reward: 307.0
Avg Reward: 15.35
Min Reward: 4.0
Gini Coefficient: 0.28355048859934856
20:20 Ratio: 4.954545454545454
Max-min Ratio: 7.25
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_23-45-56
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 514.0
  episode_reward_mean: 341.45
  episode_reward_min: 231.0
  episodes_this_iter: 1
  episodes_total: 229
  experiment_id: 35d66058da2d4c9882f832ee91e4aa4a
  hostname: gpu011
  info:
    apply_time_ms: 2.88
    dispatch_time_ms: 7.541
    learner:
      cur_lr: 0.001054971944540739
      grad_gnorm: 32.73093795776367
      policy_entropy: 194.05393981933594
      policy_loss: -12.3936767578125
      var_gnorm: 19.991806030273438
      vf_explained_var: 0.0
      vf_loss: 0.4327929615974426
    num_steps_sampled: 4600000
    num_steps_trained: 4600000
    wait_time_ms: 266.737
  iterations_since_restore: 230
  node_ip: 172.17.8.11
  num_metric_batches_dropped: 0
  pid: 25504
  policy_reward_mean: {}
  time_since_restore: 6483.130575656891
  time_this_iter_s: 27.357117652893066
  time_total_s: 6483.130575656891
  timestamp: 1593920756
  timesteps_since_restore: 4600000
  timesteps_this_iter: 20000
  timesteps_total: 4600000
  training_iteration: 230
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=25504], 6483 s, 230 iter, 4600000 ts, 341 rew

agent-1: 3.0
agent-2: 14.0
agent-3: 9.0
agent-4: 26.0
agent-5: 14.0
agent-6: 20.0
agent-7: 15.0
agent-8: 23.0
agent-9: 23.0
agent-10: 13.0
agent-11: 19.0
agent-12: 14.0
agent-13: 15.0
agent-14: 12.0
agent-15: 1.0
agent-16: 24.0
agent-17: 30.0
agent-18: 6.0
agent-19: 16.0
agent-20: 16.0
Sum Reward: 313.0
Avg Reward: 15.65
Min Reward: 1.0
Gini Coefficient: 0.260223642172524
20:20 Ratio: 5.421052631578948
Max-min Ratio: 30.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_23-46-24
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 514.0
  episode_reward_mean: 341.91
  episode_reward_min: 231.0
  episodes_this_iter: 1
  episodes_total: 230
  experiment_id: 35d66058da2d4c9882f832ee91e4aa4a
  hostname: gpu011
  info:
    apply_time_ms: 2.695
    dispatch_time_ms: 5.081
    learner:
      cur_lr: 0.001053640036843717
      grad_gnorm: 12.014081001281738
      policy_entropy: 190.19964599609375
      policy_loss: -3.421128749847412
      var_gnorm: 19.985515594482422
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 0.05814573913812637
    num_steps_sampled: 4620000
    num_steps_trained: 4620000
    wait_time_ms: 276.325
  iterations_since_restore: 231
  node_ip: 172.17.8.11
  num_metric_batches_dropped: 0
  pid: 25504
  policy_reward_mean: {}
  time_since_restore: 6510.809329986572
  time_this_iter_s: 27.678754329681396
  time_total_s: 6510.809329986572
  timestamp: 1593920784
  timesteps_since_restore: 4620000
  timesteps_this_iter: 20000
  timesteps_total: 4620000
  training_iteration: 231
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=25504], 6510 s, 231 iter, 4620000 ts, 342 rew

agent-1: 12.0
agent-2: 15.0
agent-3: 10.0
agent-4: 14.0
agent-5: 15.0
agent-6: 11.0
agent-7: 17.0
agent-8: 29.0
agent-9: 14.0
agent-10: 7.0
agent-11: 47.0
agent-12: 9.0
agent-13: 20.0
agent-14: 10.0
agent-15: 24.0
agent-16: 23.0
agent-17: 16.0
agent-18: 6.0
agent-19: 15.0
agent-20: 15.0
Sum Reward: 329.0
Avg Reward: 16.45
Min Reward: 6.0
Gini Coefficient: 0.2655015197568389
20:20 Ratio: 3.84375
Max-min Ratio: 7.833333333333333
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_23-46-51
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 514.0
  episode_reward_mean: 342.49
  episode_reward_min: 231.0
  episodes_this_iter: 1
  episodes_total: 231
  experiment_id: 35d66058da2d4c9882f832ee91e4aa4a
  hostname: gpu011
  info:
    apply_time_ms: 2.562
    dispatch_time_ms: 6.574
    learner:
      cur_lr: 0.0010523080127313733
      grad_gnorm: 11.042407989501953
      policy_entropy: 187.71640014648438
      policy_loss: -4.709765434265137
      var_gnorm: 19.99078369140625
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 0.048392049968242645
    num_steps_sampled: 4640000
    num_steps_trained: 4640000
    wait_time_ms: 266.628
  iterations_since_restore: 232
  node_ip: 172.17.8.11
  num_metric_batches_dropped: 0
  pid: 25504
  policy_reward_mean: {}
  time_since_restore: 6538.258828163147
  time_this_iter_s: 27.449498176574707
  time_total_s: 6538.258828163147
  timestamp: 1593920811
  timesteps_since_restore: 4640000
  timesteps_this_iter: 20000
  timesteps_total: 4640000
  training_iteration: 232
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=25504], 6538 s, 232 iter, 4640000 ts, 342 rew

agent-1: 2.0
agent-2: 10.0
agent-3: 2.0
agent-4: 13.0
agent-5: 29.0
agent-6: 12.0
agent-7: 2.0
agent-8: 8.0
agent-9: 18.0
agent-10: 24.0
agent-11: 13.0
agent-12: 20.0
agent-13: 21.0
agent-14: 10.0
agent-15: 15.0
agent-16: 16.0
agent-17: 13.0
agent-18: 27.0
agent-19: 20.0
agent-20: 8.0
Sum Reward: 283.0
Avg Reward: 14.15
Min Reward: 2.0
Gini Coefficient: 0.30759717314487633
20:20 Ratio: 7.214285714285714
Max-min Ratio: 14.5
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_23-47-19
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 514.0
  episode_reward_mean: 341.47
  episode_reward_min: 231.0
  episodes_this_iter: 1
  episodes_total: 232
  experiment_id: 35d66058da2d4c9882f832ee91e4aa4a
  hostname: gpu011
  info:
    apply_time_ms: 3.837
    dispatch_time_ms: 6.023
    learner:
      cur_lr: 0.0010509759886190295
      grad_gnorm: 40.0
      policy_entropy: 183.87326049804688
      policy_loss: 65.53849792480469
      var_gnorm: 19.984914779663086
      vf_explained_var: 0.0
      vf_loss: 69.08930969238281
    num_steps_sampled: 4660000
    num_steps_trained: 4660000
    wait_time_ms: 263.174
  iterations_since_restore: 233
  node_ip: 172.17.8.11
  num_metric_batches_dropped: 0
  pid: 25504
  policy_reward_mean: {}
  time_since_restore: 6565.772303819656
  time_this_iter_s: 27.5134756565094
  time_total_s: 6565.772303819656
  timestamp: 1593920839
  timesteps_since_restore: 4660000
  timesteps_this_iter: 20000
  timesteps_total: 4660000
  training_iteration: 233
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=25504], 6565 s, 233 iter, 4660000 ts, 341 rew

agent-1: 5.0
agent-2: 14.0
agent-3: 9.0
agent-4: 1.0
agent-5: 7.0
agent-6: 8.0
agent-7: 6.0
agent-8: 11.0
agent-9: 8.0
agent-10: 2.0
agent-11: 9.0
agent-12: 11.0
agent-13: 24.0
agent-14: 15.0
agent-15: 22.0
agent-16: 9.0
agent-17: 18.0
agent-18: 23.0
agent-19: 8.0
agent-20: 18.0
Sum Reward: 228.0
Avg Reward: 11.4
Min Reward: 1.0
Gini Coefficient: 0.31842105263157894
20:20 Ratio: 6.214285714285714
Max-min Ratio: 24.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_23-47-46
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 514.0
  episode_reward_mean: 340.53
  episode_reward_min: 228.0
  episodes_this_iter: 1
  episodes_total: 233
  experiment_id: 35d66058da2d4c9882f832ee91e4aa4a
  hostname: gpu011
  info:
    apply_time_ms: 4.225
    dispatch_time_ms: 5.802
    learner:
      cur_lr: 0.0010496439645066857
      grad_gnorm: 32.184364318847656
      policy_entropy: 163.44044494628906
      policy_loss: -10.667823791503906
      var_gnorm: 19.98969268798828
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 0.41790831089019775
    num_steps_sampled: 4680000
    num_steps_trained: 4680000
    wait_time_ms: 270.991
  iterations_since_restore: 234
  node_ip: 172.17.8.11
  num_metric_batches_dropped: 0
  pid: 25504
  policy_reward_mean: {}
  time_since_restore: 6593.078783035278
  time_this_iter_s: 27.30647921562195
  time_total_s: 6593.078783035278
  timestamp: 1593920866
  timesteps_since_restore: 4680000
  timesteps_this_iter: 20000
  timesteps_total: 4680000
  training_iteration: 234
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=25504], 6593 s, 234 iter, 4680000 ts, 341 rew

agent-1: 16.0
agent-2: 15.0
agent-3: 21.0
agent-4: 12.0
agent-5: 23.0
agent-6: 7.0
agent-7: 22.0
agent-8: 20.0
agent-9: 21.0
agent-10: 13.0
agent-11: 13.0
agent-12: 20.0
agent-13: 35.0
agent-14: 34.0
agent-15: 13.0
agent-16: 3.0
agent-17: 16.0
agent-18: 31.0
agent-19: 5.0
agent-20: 6.0
Sum Reward: 346.0
Avg Reward: 17.3
Min Reward: 3.0
Gini Coefficient: 0.28497109826589595
20:20 Ratio: 5.857142857142857
Max-min Ratio: 11.666666666666666
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_23-48-14
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 514.0
  episode_reward_mean: 340.77
  episode_reward_min: 228.0
  episodes_this_iter: 1
  episodes_total: 234
  experiment_id: 35d66058da2d4c9882f832ee91e4aa4a
  hostname: gpu011
  info:
    apply_time_ms: 3.687
    dispatch_time_ms: 5.42
    learner:
      cur_lr: 0.0010483120568096638
      grad_gnorm: 14.985243797302246
      policy_entropy: 158.57327270507812
      policy_loss: -0.940701961517334
      var_gnorm: 19.98892593383789
      vf_explained_var: 0.0
      vf_loss: 1.4710309505462646
    num_steps_sampled: 4700000
    num_steps_trained: 4700000
    wait_time_ms: 274.395
  iterations_since_restore: 235
  node_ip: 172.17.8.11
  num_metric_batches_dropped: 0
  pid: 25504
  policy_reward_mean: {}
  time_since_restore: 6620.512011289597
  time_this_iter_s: 27.433228254318237
  time_total_s: 6620.512011289597
  timestamp: 1593920894
  timesteps_since_restore: 4700000
  timesteps_this_iter: 20000
  timesteps_total: 4700000
  training_iteration: 235
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=25504], 6620 s, 235 iter, 4700000 ts, 341 rew

agent-1: 26.0
agent-2: 15.0
agent-3: 38.0
agent-4: 21.0
agent-5: 31.0
agent-6: 19.0
agent-7: 23.0
agent-8: 6.0
agent-9: 29.0
agent-10: 27.0
agent-11: 16.0
agent-12: 24.0
agent-13: 15.0
agent-14: 28.0
agent-15: 29.0
agent-16: 14.0
agent-17: 12.0
agent-18: 12.0
agent-19: 19.0
agent-20: 19.0
Sum Reward: 423.0
Avg Reward: 21.15
Min Reward: 6.0
Gini Coefficient: 0.2057919621749409
20:20 Ratio: 2.8863636363636362
Max-min Ratio: 6.333333333333333
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_23-48-41
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 514.0
  episode_reward_mean: 341.65
  episode_reward_min: 228.0
  episodes_this_iter: 1
  episodes_total: 235
  experiment_id: 35d66058da2d4c9882f832ee91e4aa4a
  hostname: gpu011
  info:
    apply_time_ms: 2.655
    dispatch_time_ms: 7.207
    learner:
      cur_lr: 0.00104698003269732
      grad_gnorm: 40.0
      policy_entropy: 149.6395263671875
      policy_loss: -13.284416198730469
      var_gnorm: 19.995447158813477
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 0.8441932797431946
    num_steps_sampled: 4720000
    num_steps_trained: 4720000
    wait_time_ms: 266.881
  iterations_since_restore: 236
  node_ip: 172.17.8.11
  num_metric_batches_dropped: 0
  pid: 25504
  policy_reward_mean: {}
  time_since_restore: 6647.681537866592
  time_this_iter_s: 27.16952657699585
  time_total_s: 6647.681537866592
  timestamp: 1593920921
  timesteps_since_restore: 4720000
  timesteps_this_iter: 20000
  timesteps_total: 4720000
  training_iteration: 236
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=25504], 6647 s, 236 iter, 4720000 ts, 342 rew

agent-1: 19.0
agent-2: 3.0
agent-3: 21.0
agent-4: 20.0
agent-5: 23.0
agent-6: 20.0
agent-7: 28.0
agent-8: 32.0
agent-9: 20.0
agent-10: 26.0
agent-11: 14.0
agent-12: 19.0
agent-13: 19.0
agent-14: 12.0
agent-15: 19.0
agent-16: 15.0
agent-17: 28.0
agent-18: 30.0
agent-19: 25.0
agent-20: 20.0
Sum Reward: 413.0
Avg Reward: 20.65
Min Reward: 3.0
Gini Coefficient: 0.17009685230024213
20:20 Ratio: 2.6818181818181817
Max-min Ratio: 10.666666666666666
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_23-49-08
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 514.0
  episode_reward_mean: 343.11
  episode_reward_min: 228.0
  episodes_this_iter: 1
  episodes_total: 236
  experiment_id: 35d66058da2d4c9882f832ee91e4aa4a
  hostname: gpu011
  info:
    apply_time_ms: 2.417
    dispatch_time_ms: 5.813
    learner:
      cur_lr: 0.0010456480085849762
      grad_gnorm: 39.999996185302734
      policy_entropy: 175.75189208984375
      policy_loss: 50.04701614379883
      var_gnorm: 19.98952865600586
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 52.90252685546875
    num_steps_sampled: 4740000
    num_steps_trained: 4740000
    wait_time_ms: 250.779
  iterations_since_restore: 237
  node_ip: 172.17.8.11
  num_metric_batches_dropped: 0
  pid: 25504
  policy_reward_mean: {}
  time_since_restore: 6675.28463101387
  time_this_iter_s: 27.603093147277832
  time_total_s: 6675.28463101387
  timestamp: 1593920948
  timesteps_since_restore: 4740000
  timesteps_this_iter: 20000
  timesteps_total: 4740000
  training_iteration: 237
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=25504], 6675 s, 237 iter, 4740000 ts, 343 rew

agent-1: 21.0
agent-2: 12.0
agent-3: 18.0
agent-4: 26.0
agent-5: 18.0
agent-6: 16.0
agent-7: 9.0
agent-8: 29.0
agent-9: 3.0
agent-10: 18.0
agent-11: 15.0
agent-12: 10.0
agent-13: 10.0
agent-14: 19.0
agent-15: 6.0
agent-16: 8.0
agent-17: 8.0
agent-18: 4.0
agent-19: 30.0
agent-20: 8.0
Sum Reward: 288.0
Avg Reward: 14.4
Min Reward: 3.0
Gini Coefficient: 0.30243055555555554
20:20 Ratio: 5.0476190476190474
Max-min Ratio: 10.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_23-49-36
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 514.0
  episode_reward_mean: 342.97
  episode_reward_min: 228.0
  episodes_this_iter: 1
  episodes_total: 237
  experiment_id: 35d66058da2d4c9882f832ee91e4aa4a
  hostname: gpu011
  info:
    apply_time_ms: 2.78
    dispatch_time_ms: 7.551
    learner:
      cur_lr: 0.0010443159844726324
      grad_gnorm: 40.0
      policy_entropy: 184.8827667236328
      policy_loss: 14.289092063903809
      var_gnorm: 19.9954891204834
      vf_explained_var: 0.0
      vf_loss: 24.227025985717773
    num_steps_sampled: 4760000
    num_steps_trained: 4760000
    wait_time_ms: 256.567
  iterations_since_restore: 238
  node_ip: 172.17.8.11
  num_metric_batches_dropped: 0
  pid: 25504
  policy_reward_mean: {}
  time_since_restore: 6702.473655223846
  time_this_iter_s: 27.189024209976196
  time_total_s: 6702.473655223846
  timestamp: 1593920976
  timesteps_since_restore: 4760000
  timesteps_this_iter: 20000
  timesteps_total: 4760000
  training_iteration: 238
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=25504], 6702 s, 238 iter, 4760000 ts, 343 rew

agent-1: 15.0
agent-2: 26.0
agent-3: 14.0
agent-4: 7.0
agent-5: 19.0
agent-6: 26.0
agent-7: 15.0
agent-8: 23.0
agent-9: 20.0
agent-10: 27.0
agent-11: 36.0
agent-12: 15.0
agent-13: 29.0
agent-14: 11.0
agent-15: 17.0
agent-16: 12.0
agent-17: 17.0
agent-18: 18.0
agent-19: 11.0
agent-20: 31.0
Sum Reward: 389.0
Avg Reward: 19.45
Min Reward: 7.0
Gini Coefficient: 0.2152956298200514
20:20 Ratio: 3.0
Max-min Ratio: 5.142857142857143
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_23-50-03
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 514.0
  episode_reward_mean: 344.51
  episode_reward_min: 228.0
  episodes_this_iter: 1
  episodes_total: 238
  experiment_id: 35d66058da2d4c9882f832ee91e4aa4a
  hostname: gpu011
  info:
    apply_time_ms: 2.61
    dispatch_time_ms: 6.93
    learner:
      cur_lr: 0.0010429839603602886
      grad_gnorm: 40.0
      policy_entropy: 184.52455139160156
      policy_loss: 40.5968132019043
      var_gnorm: 19.985502243041992
      vf_explained_var: 0.0
      vf_loss: 51.53175354003906
    num_steps_sampled: 4780000
    num_steps_trained: 4780000
    wait_time_ms: 262.103
  iterations_since_restore: 239
  node_ip: 172.17.8.11
  num_metric_batches_dropped: 0
  pid: 25504
  policy_reward_mean: {}
  time_since_restore: 6729.927492141724
  time_this_iter_s: 27.453836917877197
  time_total_s: 6729.927492141724
  timestamp: 1593921003
  timesteps_since_restore: 4780000
  timesteps_this_iter: 20000
  timesteps_total: 4780000
  training_iteration: 239
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=25504], 6729 s, 239 iter, 4780000 ts, 345 rew

agent-1: 13.0
agent-2: 17.0
agent-3: 21.0
agent-4: 10.0
agent-5: 28.0
agent-6: 11.0
agent-7: 17.0
agent-8: 25.0
agent-9: 32.0
agent-10: 37.0
agent-11: 13.0
agent-12: 13.0
agent-13: 9.0
agent-14: 26.0
agent-15: 14.0
agent-16: 26.0
agent-17: 29.0
agent-18: 3.0
agent-19: 27.0
agent-20: 20.0
Sum Reward: 391.0
Avg Reward: 19.55
Min Reward: 3.0
Gini Coefficient: 0.25255754475703324
20:20 Ratio: 3.8181818181818183
Max-min Ratio: 12.333333333333334
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_23-50-30
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 514.0
  episode_reward_mean: 345.8
  episode_reward_min: 228.0
  episodes_this_iter: 1
  episodes_total: 239
  experiment_id: 35d66058da2d4c9882f832ee91e4aa4a
  hostname: gpu011
  info:
    apply_time_ms: 2.973
    dispatch_time_ms: 8.065
    learner:
      cur_lr: 0.0010416520526632667
      grad_gnorm: 22.714139938354492
      policy_entropy: 181.03787231445312
      policy_loss: -7.903839111328125
      var_gnorm: 20.001096725463867
      vf_explained_var: 0.0
      vf_loss: 0.20769546926021576
    num_steps_sampled: 4800000
    num_steps_trained: 4800000
    wait_time_ms: 268.328
  iterations_since_restore: 240
  node_ip: 172.17.8.11
  num_metric_batches_dropped: 0
  pid: 25504
  policy_reward_mean: {}
  time_since_restore: 6757.14633846283
  time_this_iter_s: 27.218846321105957
  time_total_s: 6757.14633846283
  timestamp: 1593921030
  timesteps_since_restore: 4800000
  timesteps_this_iter: 20000
  timesteps_total: 4800000
  training_iteration: 240
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=25504], 6757 s, 240 iter, 4800000 ts, 346 rew

agent-1: 6.0
agent-2: 4.0
agent-3: 16.0
agent-4: 22.0
agent-5: 14.0
agent-6: 19.0
agent-7: 13.0
agent-8: 16.0
agent-9: 13.0
agent-10: 11.0
agent-11: 13.0
agent-12: 13.0
agent-13: 4.0
agent-14: 9.0
agent-15: 18.0
agent-16: 13.0
agent-17: 4.0
agent-18: 13.0
agent-19: 20.0
agent-20: 17.0
Sum Reward: 258.0
Avg Reward: 12.9
Min Reward: 4.0
Gini Coefficient: 0.22364341085271316
20:20 Ratio: 4.388888888888889
Max-min Ratio: 5.5
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_23-50-58
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 514.0
  episode_reward_mean: 344.99
  episode_reward_min: 228.0
  episodes_this_iter: 1
  episodes_total: 240
  experiment_id: 35d66058da2d4c9882f832ee91e4aa4a
  hostname: gpu011
  info:
    apply_time_ms: 2.86
    dispatch_time_ms: 6.129
    learner:
      cur_lr: 0.0010403200285509229
      grad_gnorm: 39.963104248046875
      policy_entropy: 171.23602294921875
      policy_loss: 14.59208869934082
      var_gnorm: 20.00653648376465
      vf_explained_var: 0.0
      vf_loss: 17.121009826660156
    num_steps_sampled: 4820000
    num_steps_trained: 4820000
    wait_time_ms: 270.444
  iterations_since_restore: 241
  node_ip: 172.17.8.11
  num_metric_batches_dropped: 0
  pid: 25504
  policy_reward_mean: {}
  time_since_restore: 6784.7856023311615
  time_this_iter_s: 27.63926386833191
  time_total_s: 6784.7856023311615
  timestamp: 1593921058
  timesteps_since_restore: 4820000
  timesteps_this_iter: 20000
  timesteps_total: 4820000
  training_iteration: 241
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=25504], 6784 s, 241 iter, 4820000 ts, 345 rew

agent-1: 10.0
agent-2: 17.0
agent-3: 10.0
agent-4: 20.0
agent-5: 30.0
agent-6: 9.0
agent-7: 28.0
agent-8: 16.0
agent-9: 16.0
agent-10: 22.0
agent-11: 27.0
agent-12: 6.0
agent-13: 18.0
agent-14: 19.0
agent-15: 23.0
agent-16: 17.0
agent-17: 18.0
agent-18: 16.0
agent-19: 19.0
agent-20: 26.0
Sum Reward: 367.0
Avg Reward: 18.35
Min Reward: 6.0
Gini Coefficient: 0.1930517711171662
20:20 Ratio: 3.1714285714285713
Max-min Ratio: 5.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_23-51-25
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 514.0
  episode_reward_mean: 344.92
  episode_reward_min: 228.0
  episodes_this_iter: 1
  episodes_total: 241
  experiment_id: 35d66058da2d4c9882f832ee91e4aa4a
  hostname: gpu011
  info:
    apply_time_ms: 2.727
    dispatch_time_ms: 6.74
    learner:
      cur_lr: 0.001038988004438579
      grad_gnorm: 15.961568832397461
      policy_entropy: 163.53924560546875
      policy_loss: 4.906733989715576
      var_gnorm: 20.01093101501465
      vf_explained_var: 0.0
      vf_loss: 7.839125633239746
    num_steps_sampled: 4840000
    num_steps_trained: 4840000
    wait_time_ms: 276.1
  iterations_since_restore: 242
  node_ip: 172.17.8.11
  num_metric_batches_dropped: 0
  pid: 25504
  policy_reward_mean: {}
  time_since_restore: 6811.955014705658
  time_this_iter_s: 27.16941237449646
  time_total_s: 6811.955014705658
  timestamp: 1593921085
  timesteps_since_restore: 4840000
  timesteps_this_iter: 20000
  timesteps_total: 4840000
  training_iteration: 242
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=25504], 6811 s, 242 iter, 4840000 ts, 345 rew

agent-1: 28.0
agent-2: 13.0
agent-3: 13.0
agent-4: 13.0
agent-5: 15.0
agent-6: 9.0
agent-7: 22.0
agent-8: 26.0
agent-9: 17.0
agent-10: 15.0
agent-11: 30.0
agent-12: 17.0
agent-13: 10.0
agent-14: 17.0
agent-15: 12.0
agent-16: 4.0
agent-17: 31.0
agent-18: 8.0
agent-19: 11.0
agent-20: 19.0
Sum Reward: 330.0
Avg Reward: 16.5
Min Reward: 4.0
Gini Coefficient: 0.24606060606060606
20:20 Ratio: 3.7096774193548385
Max-min Ratio: 7.75
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_23-51-53
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 514.0
  episode_reward_mean: 343.78
  episode_reward_min: 228.0
  episodes_this_iter: 1
  episodes_total: 242
  experiment_id: 35d66058da2d4c9882f832ee91e4aa4a
  hostname: gpu011
  info:
    apply_time_ms: 4.71
    dispatch_time_ms: 6.399
    learner:
      cur_lr: 0.0010376559803262353
      grad_gnorm: 10.065643310546875
      policy_entropy: 179.9677734375
      policy_loss: -0.8958857655525208
      var_gnorm: 20.007686614990234
      vf_explained_var: 2.384185791015625e-07
      vf_loss: 0.04074127972126007
    num_steps_sampled: 4860000
    num_steps_trained: 4860000
    wait_time_ms: 256.54
  iterations_since_restore: 243
  node_ip: 172.17.8.11
  num_metric_batches_dropped: 0
  pid: 25504
  policy_reward_mean: {}
  time_since_restore: 6839.3936088085175
  time_this_iter_s: 27.438594102859497
  time_total_s: 6839.3936088085175
  timestamp: 1593921113
  timesteps_since_restore: 4860000
  timesteps_this_iter: 20000
  timesteps_total: 4860000
  training_iteration: 243
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=25504], 6839 s, 243 iter, 4860000 ts, 344 rew

agent-1: 14.0
agent-2: 24.0
agent-3: 8.0
agent-4: 33.0
agent-5: 16.0
agent-6: 12.0
agent-7: 20.0
agent-8: 9.0
agent-9: 15.0
agent-10: 25.0
agent-11: 13.0
agent-12: 3.0
agent-13: 14.0
agent-14: 18.0
agent-15: 17.0
agent-16: 17.0
agent-17: 3.0
agent-18: 17.0
agent-19: 12.0
agent-20: 9.0
Sum Reward: 299.0
Avg Reward: 14.95
Min Reward: 3.0
Gini Coefficient: 0.2563545150501672
20:20 Ratio: 4.434782608695652
Max-min Ratio: 11.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_23-52-20
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 514.0
  episode_reward_mean: 342.83
  episode_reward_min: 228.0
  episodes_this_iter: 1
  episodes_total: 243
  experiment_id: 35d66058da2d4c9882f832ee91e4aa4a
  hostname: gpu011
  info:
    apply_time_ms: 2.507
    dispatch_time_ms: 5.376
    learner:
      cur_lr: 0.0010363239562138915
      grad_gnorm: 30.75514030456543
      policy_entropy: 179.0299530029297
      policy_loss: -10.75387191772461
      var_gnorm: 20.010866165161133
      vf_explained_var: 0.0
      vf_loss: 0.3744523823261261
    num_steps_sampled: 4880000
    num_steps_trained: 4880000
    wait_time_ms: 268.698
  iterations_since_restore: 244
  node_ip: 172.17.8.11
  num_metric_batches_dropped: 0
  pid: 25504
  policy_reward_mean: {}
  time_since_restore: 6866.622587680817
  time_this_iter_s: 27.228978872299194
  time_total_s: 6866.622587680817
  timestamp: 1593921140
  timesteps_since_restore: 4880000
  timesteps_this_iter: 20000
  timesteps_total: 4880000
  training_iteration: 244
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=25504], 6866 s, 244 iter, 4880000 ts, 343 rew

agent-1: 8.0
agent-2: 4.0
agent-3: 19.0
agent-4: 21.0
agent-5: 13.0
agent-6: 17.0
agent-7: 16.0
agent-8: 9.0
agent-9: 9.0
agent-10: 19.0
agent-11: 22.0
agent-12: 17.0
agent-13: 11.0
agent-14: 22.0
agent-15: 22.0
agent-16: 8.0
agent-17: 13.0
agent-18: 19.0
agent-19: 18.0
agent-20: 12.0
Sum Reward: 299.0
Avg Reward: 14.95
Min Reward: 4.0
Gini Coefficient: 0.20317725752508362
20:20 Ratio: 3.0
Max-min Ratio: 5.5
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_23-52-48
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 514.0
  episode_reward_mean: 343.13
  episode_reward_min: 228.0
  episodes_this_iter: 1
  episodes_total: 244
  experiment_id: 35d66058da2d4c9882f832ee91e4aa4a
  hostname: gpu011
  info:
    apply_time_ms: 3.932
    dispatch_time_ms: 6.447
    learner:
      cur_lr: 0.0010349920485168695
      grad_gnorm: 40.0
      policy_entropy: 189.96340942382812
      policy_loss: 35.73243713378906
      var_gnorm: 20.005537033081055
      vf_explained_var: 0.0
      vf_loss: 25.89310073852539
    num_steps_sampled: 4900000
    num_steps_trained: 4900000
    wait_time_ms: 252.673
  iterations_since_restore: 245
  node_ip: 172.17.8.11
  num_metric_batches_dropped: 0
  pid: 25504
  policy_reward_mean: {}
  time_since_restore: 6894.384038686752
  time_this_iter_s: 27.76145100593567
  time_total_s: 6894.384038686752
  timestamp: 1593921168
  timesteps_since_restore: 4900000
  timesteps_this_iter: 20000
  timesteps_total: 4900000
  training_iteration: 245
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=25504], 6894 s, 245 iter, 4900000 ts, 343 rew

agent-1: 20.0
agent-2: 24.0
agent-3: 23.0
agent-4: 32.0
agent-5: 9.0
agent-6: 17.0
agent-7: 4.0
agent-8: 15.0
agent-9: 9.0
agent-10: 23.0
agent-11: 11.0
agent-12: 7.0
agent-13: 34.0
agent-14: 23.0
agent-15: 16.0
agent-16: 28.0
agent-17: 10.0
agent-18: 17.0
agent-19: 27.0
agent-20: 11.0
Sum Reward: 360.0
Avg Reward: 18.0
Min Reward: 4.0
Gini Coefficient: 0.26555555555555554
20:20 Ratio: 4.172413793103448
Max-min Ratio: 8.5
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_23-53-15
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 514.0
  episode_reward_mean: 343.26
  episode_reward_min: 228.0
  episodes_this_iter: 1
  episodes_total: 245
  experiment_id: 35d66058da2d4c9882f832ee91e4aa4a
  hostname: gpu011
  info:
    apply_time_ms: 3.109
    dispatch_time_ms: 7.378
    learner:
      cur_lr: 0.0010336600244045258
      grad_gnorm: 17.231128692626953
      policy_entropy: 180.27432250976562
      policy_loss: -5.749880790710449
      var_gnorm: 20.006282806396484
      vf_explained_var: 0.0
      vf_loss: 0.11984671652317047
    num_steps_sampled: 4920000
    num_steps_trained: 4920000
    wait_time_ms: 269.739
  iterations_since_restore: 246
  node_ip: 172.17.8.11
  num_metric_batches_dropped: 0
  pid: 25504
  policy_reward_mean: {}
  time_since_restore: 6921.9306309223175
  time_this_iter_s: 27.546592235565186
  time_total_s: 6921.9306309223175
  timestamp: 1593921195
  timesteps_since_restore: 4920000
  timesteps_this_iter: 20000
  timesteps_total: 4920000
  training_iteration: 246
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=25504], 6921 s, 246 iter, 4920000 ts, 343 rew

agent-1: 14.0
agent-2: 5.0
agent-3: 11.0
agent-4: 6.0
agent-5: 10.0
agent-6: 7.0
agent-7: 20.0
agent-8: 18.0
agent-9: 17.0
agent-10: 5.0
agent-11: 16.0
agent-12: 23.0
agent-13: 14.0
agent-14: 10.0
agent-15: 13.0
agent-16: 8.0
agent-17: 16.0
agent-18: 18.0
agent-19: 18.0
agent-20: 6.0
Sum Reward: 255.0
Avg Reward: 12.75
Min Reward: 5.0
Gini Coefficient: 0.23862745098039215
20:20 Ratio: 3.590909090909091
Max-min Ratio: 4.6
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_23-53-44
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 514.0
  episode_reward_mean: 342.39
  episode_reward_min: 228.0
  episodes_this_iter: 1
  episodes_total: 246
  experiment_id: 35d66058da2d4c9882f832ee91e4aa4a
  hostname: gpu011
  info:
    apply_time_ms: 3.81
    dispatch_time_ms: 28.963
    learner:
      cur_lr: 0.001032328000292182
      grad_gnorm: 40.000003814697266
      policy_entropy: 185.1211395263672
      policy_loss: 41.50615310668945
      var_gnorm: 20.00200843811035
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 49.89881896972656
    num_steps_sampled: 4940000
    num_steps_trained: 4940000
    wait_time_ms: 253.285
  iterations_since_restore: 247
  node_ip: 172.17.8.11
  num_metric_batches_dropped: 0
  pid: 25504
  policy_reward_mean: {}
  time_since_restore: 6950.8313138484955
  time_this_iter_s: 28.90068292617798
  time_total_s: 6950.8313138484955
  timestamp: 1593921224
  timesteps_since_restore: 4940000
  timesteps_this_iter: 20000
  timesteps_total: 4940000
  training_iteration: 247
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=25504], 6950 s, 247 iter, 4940000 ts, 342 rew

agent-1: 17.0
agent-2: 24.0
agent-3: 12.0
agent-4: 14.0
agent-5: 4.0
agent-6: 25.0
agent-7: 20.0
agent-8: 20.0
agent-9: 5.0
agent-10: 20.0
agent-11: 4.0
agent-12: 4.0
agent-13: 15.0
agent-14: 9.0
agent-15: 9.0
agent-16: 9.0
agent-17: 16.0
agent-18: 14.0
agent-19: 9.0
agent-20: 15.0
Sum Reward: 265.0
Avg Reward: 13.25
Min Reward: 4.0
Gini Coefficient: 0.27452830188679245
20:20 Ratio: 5.235294117647059
Max-min Ratio: 6.25
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_23-54-13
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 514.0
  episode_reward_mean: 341.72
  episode_reward_min: 228.0
  episodes_this_iter: 1
  episodes_total: 247
  experiment_id: 35d66058da2d4c9882f832ee91e4aa4a
  hostname: gpu011
  info:
    apply_time_ms: 2.931
    dispatch_time_ms: 22.482
    learner:
      cur_lr: 0.0010309959761798382
      grad_gnorm: 40.0
      policy_entropy: 169.38211059570312
      policy_loss: 36.753028869628906
      var_gnorm: 20.00364112854004
      vf_explained_var: 0.0
      vf_loss: 47.88779830932617
    num_steps_sampled: 4960000
    num_steps_trained: 4960000
    wait_time_ms: 265.857
  iterations_since_restore: 248
  node_ip: 172.17.8.11
  num_metric_batches_dropped: 0
  pid: 25504
  policy_reward_mean: {}
  time_since_restore: 6979.312229156494
  time_this_iter_s: 28.480915307998657
  time_total_s: 6979.312229156494
  timestamp: 1593921253
  timesteps_since_restore: 4960000
  timesteps_this_iter: 20000
  timesteps_total: 4960000
  training_iteration: 248
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=25504], 6979 s, 248 iter, 4960000 ts, 342 rew

agent-1: 12.0
agent-2: 4.0
agent-3: 18.0
agent-4: 25.0
agent-5: 31.0
agent-6: 7.0
agent-7: 20.0
agent-8: 8.0
agent-9: 29.0
agent-10: 30.0
agent-11: 14.0
agent-12: 24.0
agent-13: 17.0
agent-14: 30.0
agent-15: 5.0
agent-16: 19.0
agent-17: 2.0
agent-18: 25.0
agent-19: 12.0
agent-20: 20.0
Sum Reward: 352.0
Avg Reward: 17.6
Min Reward: 2.0
Gini Coefficient: 0.29573863636363634
20:20 Ratio: 6.666666666666667
Max-min Ratio: 15.5
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_23-54-41
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 514.0
  episode_reward_mean: 342.25
  episode_reward_min: 228.0
  episodes_this_iter: 1
  episodes_total: 248
  experiment_id: 35d66058da2d4c9882f832ee91e4aa4a
  hostname: gpu011
  info:
    apply_time_ms: 3.498
    dispatch_time_ms: 29.532
    learner:
      cur_lr: 0.0010296639520674944
      grad_gnorm: 14.002927780151367
      policy_entropy: 158.59605407714844
      policy_loss: 4.586341857910156
      var_gnorm: 20.003740310668945
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 9.203048706054688
    num_steps_sampled: 4980000
    num_steps_trained: 4980000
    wait_time_ms: 241.213
  iterations_since_restore: 249
  node_ip: 172.17.8.11
  num_metric_batches_dropped: 0
  pid: 25504
  policy_reward_mean: {}
  time_since_restore: 7007.912310361862
  time_this_iter_s: 28.600081205368042
  time_total_s: 7007.912310361862
  timestamp: 1593921281
  timesteps_since_restore: 4980000
  timesteps_this_iter: 20000
  timesteps_total: 4980000
  training_iteration: 249
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=25504], 7007 s, 249 iter, 4980000 ts, 342 rew

agent-1: 37.0
agent-2: 18.0
agent-3: 27.0
agent-4: 28.0
agent-5: 21.0
agent-6: 56.0
agent-7: 45.0
agent-8: 22.0
agent-9: 38.0
agent-10: 38.0
agent-11: 41.0
agent-12: 23.0
agent-13: 12.0
agent-14: 17.0
agent-15: 4.0
agent-16: 14.0
agent-17: 9.0
agent-18: 24.0
agent-19: 28.0
agent-20: 20.0
Sum Reward: 522.0
Avg Reward: 26.1
Min Reward: 4.0
Gini Coefficient: 0.2735632183908046
20:20 Ratio: 4.615384615384615
Max-min Ratio: 14.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_23-55-10
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 522.0
  episode_reward_mean: 344.48
  episode_reward_min: 228.0
  episodes_this_iter: 1
  episodes_total: 249
  experiment_id: 35d66058da2d4c9882f832ee91e4aa4a
  hostname: gpu011
  info:
    apply_time_ms: 5.026
    dispatch_time_ms: 30.182
    learner:
      cur_lr: 0.0010283320443704724
      grad_gnorm: 40.0
      policy_entropy: 151.14306640625
      policy_loss: -19.78537368774414
      var_gnorm: 20.01784896850586
      vf_explained_var: 0.0
      vf_loss: 1.0762763023376465
    num_steps_sampled: 5000000
    num_steps_trained: 5000000
    wait_time_ms: 253.32
  iterations_since_restore: 250
  node_ip: 172.17.8.11
  num_metric_batches_dropped: 0
  pid: 25504
  policy_reward_mean: {}
  time_since_restore: 7036.363257646561
  time_this_iter_s: 28.450947284698486
  time_total_s: 7036.363257646561
  timestamp: 1593921310
  timesteps_since_restore: 5000000
  timesteps_this_iter: 20000
  timesteps_total: 5000000
  training_iteration: 250
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=25504], 7036 s, 250 iter, 5000000 ts, 344 rew

agent-1: 16.0
agent-2: 22.0
agent-3: 22.0
agent-4: 49.0
agent-5: 30.0
agent-6: 21.0
agent-7: 18.0
agent-8: 53.0
agent-9: 27.0
agent-10: 22.0
agent-11: 21.0
agent-12: 23.0
agent-13: 18.0
agent-14: 15.0
agent-15: 29.0
agent-16: 20.0
agent-17: 45.0
agent-18: 12.0
agent-19: 15.0
agent-20: 35.0
Sum Reward: 513.0
Avg Reward: 25.65
Min Reward: 12.0
Gini Coefficient: 0.22875243664717348
20:20 Ratio: 3.1379310344827585
Max-min Ratio: 4.416666666666667
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_23-55-39
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 522.0
  episode_reward_mean: 345.56
  episode_reward_min: 228.0
  episodes_this_iter: 1
  episodes_total: 250
  experiment_id: 35d66058da2d4c9882f832ee91e4aa4a
  hostname: gpu011
  info:
    apply_time_ms: 3.564
    dispatch_time_ms: 10.615
    learner:
      cur_lr: 0.0010270000202581286
      grad_gnorm: 14.656946182250977
      policy_entropy: 142.3745880126953
      policy_loss: -2.7957215309143066
      var_gnorm: 20.006452560424805
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 0.08663639426231384
    num_steps_sampled: 5020000
    num_steps_trained: 5020000
    wait_time_ms: 256.435
  iterations_since_restore: 251
  node_ip: 172.17.8.11
  num_metric_batches_dropped: 0
  pid: 25504
  policy_reward_mean: {}
  time_since_restore: 7064.9722311496735
  time_this_iter_s: 28.608973503112793
  time_total_s: 7064.9722311496735
  timestamp: 1593921339
  timesteps_since_restore: 5020000
  timesteps_this_iter: 20000
  timesteps_total: 5020000
  training_iteration: 251
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=25504], 7064 s, 251 iter, 5020000 ts, 346 rew

agent-1: 18.0
agent-2: 6.0
agent-3: 18.0
agent-4: 12.0
agent-5: 20.0
agent-6: 12.0
agent-7: 30.0
agent-8: 7.0
agent-9: 14.0
agent-10: 12.0
agent-11: 17.0
agent-12: 14.0
agent-13: 16.0
agent-14: 14.0
agent-15: 21.0
agent-16: 25.0
agent-17: 4.0
agent-18: 4.0
agent-19: 14.0
agent-20: 26.0
Sum Reward: 304.0
Avg Reward: 15.2
Min Reward: 4.0
Gini Coefficient: 0.2532894736842105
20:20 Ratio: 4.857142857142857
Max-min Ratio: 7.5
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_23-56-06
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 522.0
  episode_reward_mean: 345.73
  episode_reward_min: 228.0
  episodes_this_iter: 1
  episodes_total: 251
  experiment_id: 35d66058da2d4c9882f832ee91e4aa4a
  hostname: gpu011
  info:
    apply_time_ms: 2.684
    dispatch_time_ms: 6.138
    learner:
      cur_lr: 0.0010256679961457849
      grad_gnorm: 39.999996185302734
      policy_entropy: 189.39974975585938
      policy_loss: -18.50524139404297
      var_gnorm: 20.019765853881836
      vf_explained_var: 0.0
      vf_loss: 0.9189094305038452
    num_steps_sampled: 5040000
    num_steps_trained: 5040000
    wait_time_ms: 273.851
  iterations_since_restore: 252
  node_ip: 172.17.8.11
  num_metric_batches_dropped: 0
  pid: 25504
  policy_reward_mean: {}
  time_since_restore: 7092.058942317963
  time_this_iter_s: 27.086711168289185
  time_total_s: 7092.058942317963
  timestamp: 1593921366
  timesteps_since_restore: 5040000
  timesteps_this_iter: 20000
  timesteps_total: 5040000
  training_iteration: 252
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=25504], 7092 s, 252 iter, 5040000 ts, 346 rew

agent-1: 15.0
agent-2: 35.0
agent-3: 20.0
agent-4: 23.0
agent-5: 13.0
agent-6: 17.0
agent-7: 22.0
agent-8: 13.0
agent-9: 13.0
agent-10: 6.0
agent-11: 16.0
agent-12: 22.0
agent-13: 20.0
agent-14: 9.0
agent-15: 45.0
agent-16: 16.0
agent-17: 26.0
agent-18: 15.0
agent-19: 11.0
agent-20: 14.0
Sum Reward: 371.0
Avg Reward: 18.55
Min Reward: 6.0
Gini Coefficient: 0.24137466307277627
20:20 Ratio: 3.3076923076923075
Max-min Ratio: 7.5
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_23-56-33
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 522.0
  episode_reward_mean: 346.14
  episode_reward_min: 228.0
  episodes_this_iter: 1
  episodes_total: 252
  experiment_id: 35d66058da2d4c9882f832ee91e4aa4a
  hostname: gpu011
  info:
    apply_time_ms: 3.155
    dispatch_time_ms: 6.738
    learner:
      cur_lr: 0.001024335972033441
      grad_gnorm: 37.99114227294922
      policy_entropy: 205.127685546875
      policy_loss: 13.056863784790039
      var_gnorm: 20.01310157775879
      vf_explained_var: 0.0
      vf_loss: 6.880845069885254
    num_steps_sampled: 5060000
    num_steps_trained: 5060000
    wait_time_ms: 258.889
  iterations_since_restore: 253
  node_ip: 172.17.8.11
  num_metric_batches_dropped: 0
  pid: 25504
  policy_reward_mean: {}
  time_since_restore: 7119.685743093491
  time_this_iter_s: 27.626800775527954
  time_total_s: 7119.685743093491
  timestamp: 1593921393
  timesteps_since_restore: 5060000
  timesteps_this_iter: 20000
  timesteps_total: 5060000
  training_iteration: 253
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=25504], 7119 s, 253 iter, 5060000 ts, 346 rew

agent-1: 14.0
agent-2: 22.0
agent-3: 13.0
agent-4: 14.0
agent-5: 15.0
agent-6: 4.0
agent-7: 20.0
agent-8: 17.0
agent-9: 26.0
agent-10: 24.0
agent-11: 20.0
agent-12: 14.0
agent-13: 16.0
agent-14: 7.0
agent-15: 13.0
agent-16: 3.0
agent-17: 31.0
agent-18: 13.0
agent-19: 20.0
agent-20: 17.0
Sum Reward: 323.0
Avg Reward: 16.15
Min Reward: 3.0
Gini Coefficient: 0.22987616099071206
20:20 Ratio: 3.814814814814815
Max-min Ratio: 10.333333333333334
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_23-57-01
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 522.0
  episode_reward_mean: 346.28
  episode_reward_min: 228.0
  episodes_this_iter: 1
  episodes_total: 253
  experiment_id: 35d66058da2d4c9882f832ee91e4aa4a
  hostname: gpu011
  info:
    apply_time_ms: 3.458
    dispatch_time_ms: 5.574
    learner:
      cur_lr: 0.0010230039479210973
      grad_gnorm: 26.5490665435791
      policy_entropy: 144.72616577148438
      policy_loss: 7.02230978012085
      var_gnorm: 20.01661491394043
      vf_explained_var: 1.1920928955078125e-07
      vf_loss: 12.162879943847656
    num_steps_sampled: 5080000
    num_steps_trained: 5080000
    wait_time_ms: 261.981
  iterations_since_restore: 254
  node_ip: 172.17.8.11
  num_metric_batches_dropped: 0
  pid: 25504
  policy_reward_mean: {}
  time_since_restore: 7146.99782705307
  time_this_iter_s: 27.312083959579468
  time_total_s: 7146.99782705307
  timestamp: 1593921421
  timesteps_since_restore: 5080000
  timesteps_this_iter: 20000
  timesteps_total: 5080000
  training_iteration: 254
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=25504], 7146 s, 254 iter, 5080000 ts, 346 rew

agent-1: 19.0
agent-2: 6.0
agent-3: 20.0
agent-4: 14.0
agent-5: 8.0
agent-6: 12.0
agent-7: 21.0
agent-8: 7.0
agent-9: 25.0
agent-10: 13.0
agent-11: 26.0
agent-12: 25.0
agent-13: 9.0
agent-14: 17.0
agent-15: 18.0
agent-16: 14.0
agent-17: 3.0
agent-18: 18.0
agent-19: 25.0
agent-20: 23.0
Sum Reward: 323.0
Avg Reward: 16.15
Min Reward: 3.0
Gini Coefficient: 0.2434984520123839
20:20 Ratio: 4.208333333333333
Max-min Ratio: 8.666666666666666
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_23-57-28
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 522.0
  episode_reward_mean: 346.86
  episode_reward_min: 228.0
  episodes_this_iter: 1
  episodes_total: 254
  experiment_id: 35d66058da2d4c9882f832ee91e4aa4a
  hostname: gpu011
  info:
    apply_time_ms: 2.805
    dispatch_time_ms: 5.891
    learner:
      cur_lr: 0.0010216720402240753
      grad_gnorm: 9.312007904052734
      policy_entropy: 166.54356384277344
      policy_loss: -1.142020344734192
      var_gnorm: 20.01361846923828
      vf_explained_var: 1.7881393432617188e-07
      vf_loss: 0.035016462206840515
    num_steps_sampled: 5100000
    num_steps_trained: 5100000
    wait_time_ms: 255.046
  iterations_since_restore: 255
  node_ip: 172.17.8.11
  num_metric_batches_dropped: 0
  pid: 25504
  policy_reward_mean: {}
  time_since_restore: 7174.489469766617
  time_this_iter_s: 27.491642713546753
  time_total_s: 7174.489469766617
  timestamp: 1593921448
  timesteps_since_restore: 5100000
  timesteps_this_iter: 20000
  timesteps_total: 5100000
  training_iteration: 255
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=25504], 7174 s, 255 iter, 5100000 ts, 347 rew

agent-1: 25.0
agent-2: 7.0
agent-3: 11.0
agent-4: 17.0
agent-5: 9.0
agent-6: 18.0
agent-7: 26.0
agent-8: 5.0
agent-9: 12.0
agent-10: 13.0
agent-11: 13.0
agent-12: 24.0
agent-13: 5.0
agent-14: 9.0
agent-15: 31.0
agent-16: 22.0
agent-17: 17.0
agent-18: 29.0
agent-19: 9.0
agent-20: 32.0
Sum Reward: 334.0
Avg Reward: 16.7
Min Reward: 5.0
Gini Coefficient: 0.2904191616766467
20:20 Ratio: 4.538461538461538
Max-min Ratio: 6.4
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_23-57-55
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 522.0
  episode_reward_mean: 346.31
  episode_reward_min: 228.0
  episodes_this_iter: 1
  episodes_total: 255
  experiment_id: 35d66058da2d4c9882f832ee91e4aa4a
  hostname: gpu011
  info:
    apply_time_ms: 2.745
    dispatch_time_ms: 7.058
    learner:
      cur_lr: 0.0010203400161117315
      grad_gnorm: 39.999996185302734
      policy_entropy: 158.68963623046875
      policy_loss: -15.247476577758789
      var_gnorm: 20.018238067626953
      vf_explained_var: 0.0
      vf_loss: 0.9926478862762451
    num_steps_sampled: 5120000
    num_steps_trained: 5120000
    wait_time_ms: 262.163
  iterations_since_restore: 256
  node_ip: 172.17.8.11
  num_metric_batches_dropped: 0
  pid: 25504
  policy_reward_mean: {}
  time_since_restore: 7201.534375905991
  time_this_iter_s: 27.04490613937378
  time_total_s: 7201.534375905991
  timestamp: 1593921475
  timesteps_since_restore: 5120000
  timesteps_this_iter: 20000
  timesteps_total: 5120000
  training_iteration: 256
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=25504], 7201 s, 256 iter, 5120000 ts, 346 rew

agent-1: 15.0
agent-2: 18.0
agent-3: 24.0
agent-4: 6.0
agent-5: 27.0
agent-6: 2.0
agent-7: 21.0
agent-8: 16.0
agent-9: 19.0
agent-10: 24.0
agent-11: 18.0
agent-12: 12.0
agent-13: 20.0
agent-14: 35.0
agent-15: 15.0
agent-16: 28.0
agent-17: 22.0
agent-18: 18.0
agent-19: 12.0
agent-20: 14.0
Sum Reward: 366.0
Avg Reward: 18.3
Min Reward: 2.0
Gini Coefficient: 0.22131147540983606
20:20 Ratio: 3.5625
Max-min Ratio: 17.5
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_23-58-23
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 522.0
  episode_reward_mean: 346.8
  episode_reward_min: 228.0
  episodes_this_iter: 1
  episodes_total: 256
  experiment_id: 35d66058da2d4c9882f832ee91e4aa4a
  hostname: gpu011
  info:
    apply_time_ms: 3.757
    dispatch_time_ms: 6.99
    learner:
      cur_lr: 0.0010190079919993877
      grad_gnorm: 39.999996185302734
      policy_entropy: 162.2684783935547
      policy_loss: 29.87189483642578
      var_gnorm: 20.01355743408203
      vf_explained_var: 0.0
      vf_loss: 39.083980560302734
    num_steps_sampled: 5140000
    num_steps_trained: 5140000
    wait_time_ms: 242.947
  iterations_since_restore: 257
  node_ip: 172.17.8.11
  num_metric_batches_dropped: 0
  pid: 25504
  policy_reward_mean: {}
  time_since_restore: 7228.95214009285
  time_this_iter_s: 27.41776418685913
  time_total_s: 7228.95214009285
  timestamp: 1593921503
  timesteps_since_restore: 5140000
  timesteps_this_iter: 20000
  timesteps_total: 5140000
  training_iteration: 257
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=25504], 7228 s, 257 iter, 5140000 ts, 347 rew

agent-1: 26.0
agent-2: 21.0
agent-3: 17.0
agent-4: 35.0
agent-5: 35.0
agent-6: 21.0
agent-7: 19.0
agent-8: 5.0
agent-9: 36.0
agent-10: 26.0
agent-11: 34.0
agent-12: 21.0
agent-13: 16.0
agent-14: 17.0
agent-15: 28.0
agent-16: 18.0
agent-17: 29.0
agent-18: 13.0
agent-19: 33.0
agent-20: 27.0
Sum Reward: 477.0
Avg Reward: 23.85
Min Reward: 5.0
Gini Coefficient: 0.19465408805031448
20:20 Ratio: 2.7450980392156863
Max-min Ratio: 7.2
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_23-58-51
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 522.0
  episode_reward_mean: 347.72
  episode_reward_min: 228.0
  episodes_this_iter: 1
  episodes_total: 257
  experiment_id: 35d66058da2d4c9882f832ee91e4aa4a
  hostname: gpu011
  info:
    apply_time_ms: 2.757
    dispatch_time_ms: 7.715
    learner:
      cur_lr: 0.001017675967887044
      grad_gnorm: 36.78911209106445
      policy_entropy: 145.98428344726562
      policy_loss: -10.009248733520508
      var_gnorm: 20.019588470458984
      vf_explained_var: 0.0
      vf_loss: 0.5462063550949097
    num_steps_sampled: 5160000
    num_steps_trained: 5160000
    wait_time_ms: 264.534
  iterations_since_restore: 258
  node_ip: 172.17.8.11
  num_metric_batches_dropped: 0
  pid: 25504
  policy_reward_mean: {}
  time_since_restore: 7257.20713019371
  time_this_iter_s: 28.254990100860596
  time_total_s: 7257.20713019371
  timestamp: 1593921531
  timesteps_since_restore: 5160000
  timesteps_this_iter: 20000
  timesteps_total: 5160000
  training_iteration: 258
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=25504], 7257 s, 258 iter, 5160000 ts, 348 rew

agent-1: 13.0
agent-2: 13.0
agent-3: 21.0
agent-4: 22.0
agent-5: 10.0
agent-6: 26.0
agent-7: 11.0
agent-8: 18.0
agent-9: 7.0
agent-10: 10.0
agent-11: 20.0
agent-12: 24.0
agent-13: 4.0
agent-14: 22.0
agent-15: 21.0
agent-16: 19.0
agent-17: 17.0
agent-18: 16.0
agent-19: 10.0
agent-20: 14.0
Sum Reward: 318.0
Avg Reward: 15.9
Min Reward: 4.0
Gini Coefficient: 0.21163522012578617
20:20 Ratio: 3.032258064516129
Max-min Ratio: 6.5
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_23-59-19
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 522.0
  episode_reward_mean: 348.59
  episode_reward_min: 228.0
  episodes_this_iter: 1
  episodes_total: 258
  experiment_id: 35d66058da2d4c9882f832ee91e4aa4a
  hostname: gpu011
  info:
    apply_time_ms: 2.676
    dispatch_time_ms: 5.623
    learner:
      cur_lr: 0.0010163439437747002
      grad_gnorm: 7.6513519287109375
      policy_entropy: 144.71298217773438
      policy_loss: -1.614318609237671
      var_gnorm: 20.015750885009766
      vf_explained_var: 1.1920928955078125e-07
      vf_loss: 0.023629117757081985
    num_steps_sampled: 5180000
    num_steps_trained: 5180000
    wait_time_ms: 269.088
  iterations_since_restore: 259
  node_ip: 172.17.8.11
  num_metric_batches_dropped: 0
  pid: 25504
  policy_reward_mean: {}
  time_since_restore: 7285.011390686035
  time_this_iter_s: 27.80426049232483
  time_total_s: 7285.011390686035
  timestamp: 1593921559
  timesteps_since_restore: 5180000
  timesteps_this_iter: 20000
  timesteps_total: 5180000
  training_iteration: 259
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=25504], 7285 s, 259 iter, 5180000 ts, 349 rew

agent-1: 24.0
agent-2: 18.0
agent-3: 32.0
agent-4: 6.0
agent-5: 15.0
agent-6: 16.0
agent-7: 10.0
agent-8: 29.0
agent-9: 15.0
agent-10: 19.0
agent-11: 22.0
agent-12: 27.0
agent-13: 12.0
agent-14: 25.0
agent-15: 16.0
agent-16: 23.0
agent-17: 33.0
agent-18: 21.0
agent-19: 24.0
agent-20: 8.0
Sum Reward: 395.0
Avg Reward: 19.75
Min Reward: 6.0
Gini Coefficient: 0.2148101265822785
20:20 Ratio: 3.361111111111111
Max-min Ratio: 5.5
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-04_23-59-46
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 522.0
  episode_reward_mean: 349.31
  episode_reward_min: 228.0
  episodes_this_iter: 1
  episodes_total: 259
  experiment_id: 35d66058da2d4c9882f832ee91e4aa4a
  hostname: gpu011
  info:
    apply_time_ms: 2.907
    dispatch_time_ms: 6.351
    learner:
      cur_lr: 0.0010150120360776782
      grad_gnorm: 28.007205963134766
      policy_entropy: 193.3226318359375
      policy_loss: -10.483410835266113
      var_gnorm: 20.01675033569336
      vf_explained_var: 0.0
      vf_loss: 0.300714373588562
    num_steps_sampled: 5200000
    num_steps_trained: 5200000
    wait_time_ms: 268.409
  iterations_since_restore: 260
  node_ip: 172.17.8.11
  num_metric_batches_dropped: 0
  pid: 25504
  policy_reward_mean: {}
  time_since_restore: 7312.02291560173
  time_this_iter_s: 27.01152491569519
  time_total_s: 7312.02291560173
  timestamp: 1593921586
  timesteps_since_restore: 5200000
  timesteps_this_iter: 20000
  timesteps_total: 5200000
  training_iteration: 260
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=25504], 7312 s, 260 iter, 5200000 ts, 349 rew

agent-1: 5.0
agent-2: 5.0
agent-3: 17.0
agent-4: 14.0
agent-5: 21.0
agent-6: 17.0
agent-7: 19.0
agent-8: 29.0
agent-9: 17.0
agent-10: 26.0
agent-11: 13.0
agent-12: 12.0
agent-13: 18.0
agent-14: 13.0
agent-15: 7.0
agent-16: 16.0
agent-17: 31.0
agent-18: 24.0
agent-19: 14.0
agent-20: 25.0
Sum Reward: 343.0
Avg Reward: 17.15
Min Reward: 5.0
Gini Coefficient: 0.23425655976676385
20:20 Ratio: 3.8275862068965516
Max-min Ratio: 6.2
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_00-00-13
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 522.0
  episode_reward_mean: 349.62
  episode_reward_min: 228.0
  episodes_this_iter: 1
  episodes_total: 260
  experiment_id: 35d66058da2d4c9882f832ee91e4aa4a
  hostname: gpu011
  info:
    apply_time_ms: 2.562
    dispatch_time_ms: 5.788
    learner:
      cur_lr: 0.0010136800119653344
      grad_gnorm: 40.0
      policy_entropy: 194.70338439941406
      policy_loss: 48.90142822265625
      var_gnorm: 20.011234283447266
      vf_explained_var: 0.0
      vf_loss: 65.05413055419922
    num_steps_sampled: 5220000
    num_steps_trained: 5220000
    wait_time_ms: 242.203
  iterations_since_restore: 261
  node_ip: 172.17.8.11
  num_metric_batches_dropped: 0
  pid: 25504
  policy_reward_mean: {}
  time_since_restore: 7339.533526659012
  time_this_iter_s: 27.510611057281494
  time_total_s: 7339.533526659012
  timestamp: 1593921613
  timesteps_since_restore: 5220000
  timesteps_this_iter: 20000
  timesteps_total: 5220000
  training_iteration: 261
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=25504], 7339 s, 261 iter, 5220000 ts, 350 rew

agent-1: 11.0
agent-2: 25.0
agent-3: 21.0
agent-4: 10.0
agent-5: 18.0
agent-6: 2.0
agent-7: 19.0
agent-8: 23.0
agent-9: 22.0
agent-10: 12.0
agent-11: 12.0
agent-12: 11.0
agent-13: 4.0
agent-14: 15.0
agent-15: 17.0
agent-16: 14.0
agent-17: 13.0
agent-18: 16.0
agent-19: 12.0
agent-20: 23.0
Sum Reward: 300.0
Avg Reward: 15.0
Min Reward: 2.0
Gini Coefficient: 0.22466666666666665
20:20 Ratio: 3.4444444444444446
Max-min Ratio: 12.5
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_00-00-41
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 522.0
  episode_reward_mean: 349.94
  episode_reward_min: 228.0
  episodes_this_iter: 1
  episodes_total: 261
  experiment_id: 35d66058da2d4c9882f832ee91e4aa4a
  hostname: gpu011
  info:
    apply_time_ms: 2.875
    dispatch_time_ms: 7.635
    learner:
      cur_lr: 0.0010123479878529906
      grad_gnorm: 24.18004035949707
      policy_entropy: 147.5471954345703
      policy_loss: -7.096778869628906
      var_gnorm: 20.014528274536133
      vf_explained_var: 0.0
      vf_loss: 0.23622176051139832
    num_steps_sampled: 5240000
    num_steps_trained: 5240000
    wait_time_ms: 269.58
  iterations_since_restore: 262
  node_ip: 172.17.8.11
  num_metric_batches_dropped: 0
  pid: 25504
  policy_reward_mean: {}
  time_since_restore: 7366.840495824814
  time_this_iter_s: 27.306969165802002
  time_total_s: 7366.840495824814
  timestamp: 1593921641
  timesteps_since_restore: 5240000
  timesteps_this_iter: 20000
  timesteps_total: 5240000
  training_iteration: 262
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=25504], 7366 s, 262 iter, 5240000 ts, 350 rew

agent-1: 5.0
agent-2: 10.0
agent-3: 30.0
agent-4: 6.0
agent-5: 10.0
agent-6: 9.0
agent-7: 14.0
agent-8: 17.0
agent-9: 10.0
agent-10: 7.0
agent-11: 32.0
agent-12: 10.0
agent-13: 19.0
agent-14: 15.0
agent-15: 4.0
agent-16: 17.0
agent-17: 18.0
agent-18: 20.0
agent-19: 26.0
agent-20: 6.0
Sum Reward: 285.0
Avg Reward: 14.25
Min Reward: 4.0
Gini Coefficient: 0.3078947368421053
20:20 Ratio: 5.142857142857143
Max-min Ratio: 8.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_00-01-09
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 522.0
  episode_reward_mean: 348.78
  episode_reward_min: 228.0
  episodes_this_iter: 1
  episodes_total: 262
  experiment_id: 35d66058da2d4c9882f832ee91e4aa4a
  hostname: gpu011
  info:
    apply_time_ms: 2.652
    dispatch_time_ms: 6.421
    learner:
      cur_lr: 0.0010110159637406468
      grad_gnorm: 40.000003814697266
      policy_entropy: 168.2559814453125
      policy_loss: 61.875457763671875
      var_gnorm: 20.0087890625
      vf_explained_var: 0.0
      vf_loss: 47.67682647705078
    num_steps_sampled: 5260000
    num_steps_trained: 5260000
    wait_time_ms: 250.827
  iterations_since_restore: 263
  node_ip: 172.17.8.11
  num_metric_batches_dropped: 0
  pid: 25504
  policy_reward_mean: {}
  time_since_restore: 7394.5673904418945
  time_this_iter_s: 27.72689461708069
  time_total_s: 7394.5673904418945
  timestamp: 1593921669
  timesteps_since_restore: 5260000
  timesteps_this_iter: 20000
  timesteps_total: 5260000
  training_iteration: 263
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=25504], 7394 s, 263 iter, 5260000 ts, 349 rew

agent-1: 5.0
agent-2: 10.0
agent-3: 21.0
agent-4: 19.0
agent-5: 21.0
agent-6: 6.0
agent-7: 17.0
agent-8: 24.0
agent-9: 9.0
agent-10: 10.0
agent-11: 12.0
agent-12: 10.0
agent-13: 4.0
agent-14: 11.0
agent-15: 19.0
agent-16: 11.0
agent-17: 14.0
agent-18: 18.0
agent-19: 22.0
agent-20: 18.0
Sum Reward: 281.0
Avg Reward: 14.05
Min Reward: 4.0
Gini Coefficient: 0.2386120996441281
20:20 Ratio: 3.6666666666666665
Max-min Ratio: 6.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_00-01-36
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 522.0
  episode_reward_mean: 348.34
  episode_reward_min: 228.0
  episodes_this_iter: 1
  episodes_total: 263
  experiment_id: 35d66058da2d4c9882f832ee91e4aa4a
  hostname: gpu011
  info:
    apply_time_ms: 2.579
    dispatch_time_ms: 6.322
    learner:
      cur_lr: 0.0010096840560436249
      grad_gnorm: 40.000003814697266
      policy_entropy: 118.9283447265625
      policy_loss: 0.8898439407348633
      var_gnorm: 20.001272201538086
      vf_explained_var: 0.0
      vf_loss: 44.963645935058594
    num_steps_sampled: 5280000
    num_steps_trained: 5280000
    wait_time_ms: 264.192
  iterations_since_restore: 264
  node_ip: 172.17.8.11
  num_metric_batches_dropped: 0
  pid: 25504
  policy_reward_mean: {}
  time_since_restore: 7421.619979381561
  time_this_iter_s: 27.052588939666748
  time_total_s: 7421.619979381561
  timestamp: 1593921696
  timesteps_since_restore: 5280000
  timesteps_this_iter: 20000
  timesteps_total: 5280000
  training_iteration: 264
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=25504], 7421 s, 264 iter, 5280000 ts, 348 rew

agent-1: 21.0
agent-2: 22.0
agent-3: 40.0
agent-4: 35.0
agent-5: 20.0
agent-6: 19.0
agent-7: 7.0
agent-8: 17.0
agent-9: 18.0
agent-10: 11.0
agent-11: 15.0
agent-12: 39.0
agent-13: 11.0
agent-14: 19.0
agent-15: 16.0
agent-16: 24.0
agent-17: 11.0
agent-18: 25.0
agent-19: 12.0
agent-20: 19.0
Sum Reward: 401.0
Avg Reward: 20.05
Min Reward: 7.0
Gini Coefficient: 0.23603491271820448
20:20 Ratio: 3.475
Max-min Ratio: 5.714285714285714
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_00-02-03
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 522.0
  episode_reward_mean: 348.92
  episode_reward_min: 228.0
  episodes_this_iter: 1
  episodes_total: 264
  experiment_id: 35d66058da2d4c9882f832ee91e4aa4a
  hostname: gpu011
  info:
    apply_time_ms: 3.897
    dispatch_time_ms: 6.795
    learner:
      cur_lr: 0.001008352031931281
      grad_gnorm: 40.0
      policy_entropy: 126.60406494140625
      policy_loss: 54.152976989746094
      var_gnorm: 19.993125915527344
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 120.76769256591797
    num_steps_sampled: 5300000
    num_steps_trained: 5300000
    wait_time_ms: 253.955
  iterations_since_restore: 265
  node_ip: 172.17.8.11
  num_metric_batches_dropped: 0
  pid: 25504
  policy_reward_mean: {}
  time_since_restore: 7449.077323913574
  time_this_iter_s: 27.45734453201294
  time_total_s: 7449.077323913574
  timestamp: 1593921723
  timesteps_since_restore: 5300000
  timesteps_this_iter: 20000
  timesteps_total: 5300000
  training_iteration: 265
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=25504], 7449 s, 265 iter, 5300000 ts, 349 rew

agent-1: 5.0
agent-2: 18.0
agent-3: 18.0
agent-4: 9.0
agent-5: 38.0
agent-6: 40.0
agent-7: 18.0
agent-8: 18.0
agent-9: 19.0
agent-10: 34.0
agent-11: 40.0
agent-12: 18.0
agent-13: 3.0
agent-14: 12.0
agent-15: 5.0
agent-16: 16.0
agent-17: 26.0
agent-18: 30.0
agent-19: 7.0
agent-20: 33.0
Sum Reward: 407.0
Avg Reward: 20.35
Min Reward: 3.0
Gini Coefficient: 0.3249385749385749
20:20 Ratio: 7.6
Max-min Ratio: 13.333333333333334
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_00-02-32
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 522.0
  episode_reward_mean: 348.16
  episode_reward_min: 228.0
  episodes_this_iter: 1
  episodes_total: 265
  experiment_id: 35d66058da2d4c9882f832ee91e4aa4a
  hostname: gpu011
  info:
    apply_time_ms: 3.096
    dispatch_time_ms: 26.457
    learner:
      cur_lr: 0.0010070200078189373
      grad_gnorm: 18.031993865966797
      policy_entropy: 129.81375122070312
      policy_loss: -8.310714721679688
      var_gnorm: 19.996971130371094
      vf_explained_var: 1.1920928955078125e-07
      vf_loss: 4.069953918457031
    num_steps_sampled: 5320000
    num_steps_trained: 5320000
    wait_time_ms: 242.786
  iterations_since_restore: 266
  node_ip: 172.17.8.11
  num_metric_batches_dropped: 0
  pid: 25504
  policy_reward_mean: {}
  time_since_restore: 7477.7162935733795
  time_this_iter_s: 28.638969659805298
  time_total_s: 7477.7162935733795
  timestamp: 1593921752
  timesteps_since_restore: 5320000
  timesteps_this_iter: 20000
  timesteps_total: 5320000
  training_iteration: 266
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=25504], 7477 s, 266 iter, 5320000 ts, 348 rew

agent-1: 14.0
agent-2: 14.0
agent-3: 40.0
agent-4: 21.0
agent-5: 28.0
agent-6: 22.0
agent-7: 35.0
agent-8: 16.0
agent-9: 21.0
agent-10: 16.0
agent-11: 21.0
agent-12: 22.0
agent-13: 19.0
agent-14: 35.0
agent-15: 21.0
agent-16: 16.0
agent-17: 13.0
agent-18: 20.0
agent-19: 17.0
agent-20: 19.0
Sum Reward: 430.0
Avg Reward: 21.5
Min Reward: 13.0
Gini Coefficient: 0.17511627906976746
20:20 Ratio: 2.4210526315789473
Max-min Ratio: 3.076923076923077
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_00-03-01
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 522.0
  episode_reward_mean: 349.21
  episode_reward_min: 228.0
  episodes_this_iter: 1
  episodes_total: 266
  experiment_id: 35d66058da2d4c9882f832ee91e4aa4a
  hostname: gpu011
  info:
    apply_time_ms: 3.731
    dispatch_time_ms: 31.254
    learner:
      cur_lr: 0.0010056879837065935
      grad_gnorm: 3.7342705726623535
      policy_entropy: 134.63197326660156
      policy_loss: 1.1288118362426758
      var_gnorm: 19.999187469482422
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 0.005595483351498842
    num_steps_sampled: 5340000
    num_steps_trained: 5340000
    wait_time_ms: 247.06
  iterations_since_restore: 267
  node_ip: 172.17.8.11
  num_metric_batches_dropped: 0
  pid: 25504
  policy_reward_mean: {}
  time_since_restore: 7506.552902698517
  time_this_iter_s: 28.83660912513733
  time_total_s: 7506.552902698517
  timestamp: 1593921781
  timesteps_since_restore: 5340000
  timesteps_this_iter: 20000
  timesteps_total: 5340000
  training_iteration: 267
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=25504], 7506 s, 267 iter, 5340000 ts, 349 rew

agent-1: 15.0
agent-2: 8.0
agent-3: 29.0
agent-4: 10.0
agent-5: 28.0
agent-6: 20.0
agent-7: 4.0
agent-8: 17.0
agent-9: 16.0
agent-10: 11.0
agent-11: 16.0
agent-12: 32.0
agent-13: 12.0
agent-14: 17.0
agent-15: 21.0
agent-16: 11.0
agent-17: 6.0
agent-18: 11.0
agent-19: 5.0
agent-20: 19.0
Sum Reward: 308.0
Avg Reward: 15.4
Min Reward: 4.0
Gini Coefficient: 0.27694805194805194
20:20 Ratio: 4.782608695652174
Max-min Ratio: 8.0
W0705 00:03:05.991755 25498 node_manager.cc:250] Last heartbeat was sent 4522 ms ago 
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_00-03-37
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 522.0
  episode_reward_mean: 349.28
  episode_reward_min: 228.0
  episodes_this_iter: 1
  episodes_total: 267
  experiment_id: 35d66058da2d4c9882f832ee91e4aa4a
  hostname: gpu011
  info:
    apply_time_ms: 3.856
    dispatch_time_ms: 20.164
    learner:
      cur_lr: 0.0010043559595942497
      grad_gnorm: 40.0
      policy_entropy: 110.50466918945312
      policy_loss: -12.442754745483398
      var_gnorm: 20.008268356323242
      vf_explained_var: 0.0
      vf_loss: 1.2538188695907593
    num_steps_sampled: 5360000
    num_steps_trained: 5360000
    wait_time_ms: 259.245
  iterations_since_restore: 268
  node_ip: 172.17.8.11
  num_metric_batches_dropped: 0
  pid: 25504
  policy_reward_mean: {}
  time_since_restore: 7542.438517570496
  time_this_iter_s: 35.88561487197876
  time_total_s: 7542.438517570496
  timestamp: 1593921817
  timesteps_since_restore: 5360000
  timesteps_this_iter: 20000
  timesteps_total: 5360000
  training_iteration: 268
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=25504], 7542 s, 268 iter, 5360000 ts, 349 rew

agent-1: 13.0
agent-2: 9.0
agent-3: 26.0
agent-4: 13.0
agent-5: 32.0
agent-6: 5.0
agent-7: 27.0
agent-8: 30.0
agent-9: 24.0
agent-10: 11.0
agent-11: 28.0
agent-12: 30.0
agent-13: 17.0
agent-14: 22.0
agent-15: 17.0
agent-16: 18.0
agent-17: 25.0
agent-18: 12.0
agent-19: 32.0
agent-20: 24.0
Sum Reward: 415.0
Avg Reward: 20.75
Min Reward: 5.0
Gini Coefficient: 0.22132530120481927
20:20 Ratio: 3.3513513513513513
Max-min Ratio: 6.4
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_00-04-05
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 522.0
  episode_reward_mean: 348.41
  episode_reward_min: 228.0
  episodes_this_iter: 1
  episodes_total: 268
  experiment_id: 35d66058da2d4c9882f832ee91e4aa4a
  hostname: gpu011
  info:
    apply_time_ms: 3.378
    dispatch_time_ms: 5.476
    learner:
      cur_lr: 0.0010030240518972278
      grad_gnorm: 40.0
      policy_entropy: 118.77074432373047
      policy_loss: 40.69504165649414
      var_gnorm: 20.00044822692871
      vf_explained_var: 0.0
      vf_loss: 58.051902770996094
    num_steps_sampled: 5380000
    num_steps_trained: 5380000
    wait_time_ms: 247.025
  iterations_since_restore: 269
  node_ip: 172.17.8.11
  num_metric_batches_dropped: 0
  pid: 25504
  policy_reward_mean: {}
  time_since_restore: 7570.446214437485
  time_this_iter_s: 28.007696866989136
  time_total_s: 7570.446214437485
  timestamp: 1593921845
  timesteps_since_restore: 5380000
  timesteps_this_iter: 20000
  timesteps_total: 5380000
  training_iteration: 269
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=25504], 7570 s, 269 iter, 5380000 ts, 348 rew

agent-1: 20.0
agent-2: 16.0
agent-3: 17.0
agent-4: 29.0
agent-5: 31.0
agent-6: 24.0
agent-7: 34.0
agent-8: 12.0
agent-9: 11.0
agent-10: 5.0
agent-11: 24.0
agent-12: 29.0
agent-13: 40.0
agent-14: 21.0
agent-15: 10.0
agent-16: 19.0
agent-17: 19.0
agent-18: 26.0
agent-19: 24.0
agent-20: 29.0
Sum Reward: 440.0
Avg Reward: 22.0
Min Reward: 5.0
Gini Coefficient: 0.2197727272727273
20:20 Ratio: 3.526315789473684
Max-min Ratio: 8.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_00-04-32
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 522.0
  episode_reward_mean: 348.93
  episode_reward_min: 228.0
  episodes_this_iter: 1
  episodes_total: 269
  experiment_id: 35d66058da2d4c9882f832ee91e4aa4a
  hostname: gpu011
  info:
    apply_time_ms: 4.527
    dispatch_time_ms: 6.142
    learner:
      cur_lr: 0.001001692027784884
      grad_gnorm: 40.0
      policy_entropy: 91.11627197265625
      policy_loss: -7.608188629150391
      var_gnorm: 20.0093936920166
      vf_explained_var: 0.0
      vf_loss: 4.48729133605957
    num_steps_sampled: 5400000
    num_steps_trained: 5400000
    wait_time_ms: 270.236
  iterations_since_restore: 270
  node_ip: 172.17.8.11
  num_metric_batches_dropped: 0
  pid: 25504
  policy_reward_mean: {}
  time_since_restore: 7597.397909402847
  time_this_iter_s: 26.95169496536255
  time_total_s: 7597.397909402847
  timestamp: 1593921872
  timesteps_since_restore: 5400000
  timesteps_this_iter: 20000
  timesteps_total: 5400000
  training_iteration: 270
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=25504], 7597 s, 270 iter, 5400000 ts, 349 rew

agent-1: 27.0
agent-2: 34.0
agent-3: 26.0
agent-4: 32.0
agent-5: 18.0
agent-6: 45.0
agent-7: 34.0
agent-8: 27.0
agent-9: 15.0
agent-10: 29.0
agent-11: 15.0
agent-12: 36.0
agent-13: 33.0
agent-14: 27.0
agent-15: 24.0
agent-16: 35.0
agent-17: 22.0
agent-18: 27.0
agent-19: 33.0
agent-20: 33.0
Sum Reward: 572.0
Avg Reward: 28.6
Min Reward: 15.0
Gini Coefficient: 0.13986013986013987
20:20 Ratio: 2.142857142857143
Max-min Ratio: 3.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_00-04-59
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 572.0
  episode_reward_mean: 351.4
  episode_reward_min: 228.0
  episodes_this_iter: 1
  episodes_total: 270
  experiment_id: 35d66058da2d4c9882f832ee91e4aa4a
  hostname: gpu011
  info:
    apply_time_ms: 4.565
    dispatch_time_ms: 6.117
    learner:
      cur_lr: 0.0010003600036725402
      grad_gnorm: 40.0
      policy_entropy: 102.9815673828125
      policy_loss: 4.310870170593262
      var_gnorm: 20.00092887878418
      vf_explained_var: 0.0
      vf_loss: 15.067891120910645
    num_steps_sampled: 5420000
    num_steps_trained: 5420000
    wait_time_ms: 243.137
  iterations_since_restore: 271
  node_ip: 172.17.8.11
  num_metric_batches_dropped: 0
  pid: 25504
  policy_reward_mean: {}
  time_since_restore: 7624.554657697678
  time_this_iter_s: 27.156748294830322
  time_total_s: 7624.554657697678
  timestamp: 1593921899
  timesteps_since_restore: 5420000
  timesteps_this_iter: 20000
  timesteps_total: 5420000
  training_iteration: 271
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=25504], 7624 s, 271 iter, 5420000 ts, 351 rew

agent-1: 17.0
agent-2: 23.0
agent-3: 36.0
agent-4: 28.0
agent-5: 16.0
agent-6: 37.0
agent-7: 35.0
agent-8: 8.0
agent-9: 27.0
agent-10: 9.0
agent-11: 11.0
agent-12: 18.0
agent-13: 10.0
agent-14: 16.0
agent-15: 13.0
agent-16: 31.0
agent-17: 9.0
agent-18: 28.0
agent-19: 12.0
agent-20: 17.0
Sum Reward: 401.0
Avg Reward: 20.05
Min Reward: 8.0
Gini Coefficient: 0.2672069825436409
20:20 Ratio: 3.861111111111111
Max-min Ratio: 4.625
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_00-05-26
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 572.0
  episode_reward_mean: 352.41
  episode_reward_min: 228.0
  episodes_this_iter: 1
  episodes_total: 271
  experiment_id: 35d66058da2d4c9882f832ee91e4aa4a
  hostname: gpu011
  info:
    apply_time_ms: 2.634
    dispatch_time_ms: 7.212
    learner:
      cur_lr: 0.0009990279795601964
      grad_gnorm: 36.80586624145508
      policy_entropy: 77.00799560546875
      policy_loss: -7.631601810455322
      var_gnorm: 20.006826400756836
      vf_explained_var: 0.0
      vf_loss: 2.739962100982666
    num_steps_sampled: 5440000
    num_steps_trained: 5440000
    wait_time_ms: 272.27
  iterations_since_restore: 272
  node_ip: 172.17.8.11
  num_metric_batches_dropped: 0
  pid: 25504
  policy_reward_mean: {}
  time_since_restore: 7651.578239679337
  time_this_iter_s: 27.023581981658936
  time_total_s: 7651.578239679337
  timestamp: 1593921926
  timesteps_since_restore: 5440000
  timesteps_this_iter: 20000
  timesteps_total: 5440000
  training_iteration: 272
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=25504], 7651 s, 272 iter, 5440000 ts, 352 rew

agent-1: 18.0
agent-2: 13.0
agent-3: 9.0
agent-4: 16.0
agent-5: 15.0
agent-6: 21.0
agent-7: 22.0
agent-8: 12.0
agent-9: 11.0
agent-10: 32.0
agent-11: 25.0
agent-12: 14.0
agent-13: 20.0
agent-14: 35.0
agent-15: 20.0
agent-16: 38.0
agent-17: 27.0
agent-18: 14.0
agent-19: 21.0
agent-20: 9.0
Sum Reward: 392.0
Avg Reward: 19.6
Min Reward: 9.0
Gini Coefficient: 0.22959183673469388
20:20 Ratio: 3.2195121951219514
Max-min Ratio: 4.222222222222222
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_00-05-54
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 572.0
  episode_reward_mean: 352.95
  episode_reward_min: 228.0
  episodes_this_iter: 1
  episodes_total: 272
  experiment_id: 35d66058da2d4c9882f832ee91e4aa4a
  hostname: gpu011
  info:
    apply_time_ms: 3.826
    dispatch_time_ms: 6.655
    learner:
      cur_lr: 0.0009976959554478526
      grad_gnorm: 10.454617500305176
      policy_entropy: 97.23165893554688
      policy_loss: -1.6680245399475098
      var_gnorm: 20.001272201538086
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 0.04388834908604622
    num_steps_sampled: 5460000
    num_steps_trained: 5460000
    wait_time_ms: 260.562
  iterations_since_restore: 273
  node_ip: 172.17.8.11
  num_metric_batches_dropped: 0
  pid: 25504
  policy_reward_mean: {}
  time_since_restore: 7679.154442071915
  time_this_iter_s: 27.576202392578125
  time_total_s: 7679.154442071915
  timestamp: 1593921954
  timesteps_since_restore: 5460000
  timesteps_this_iter: 20000
  timesteps_total: 5460000
  training_iteration: 273
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=25504], 7679 s, 273 iter, 5460000 ts, 353 rew

agent-1: 23.0
agent-2: 21.0
agent-3: 31.0
agent-4: 9.0
agent-5: 25.0
agent-6: 12.0
agent-7: 39.0
agent-8: 15.0
agent-9: 21.0
agent-10: 14.0
agent-11: 25.0
agent-12: 6.0
agent-13: 19.0
agent-14: 28.0
agent-15: 22.0
agent-16: 31.0
agent-17: 24.0
agent-18: 26.0
agent-19: 7.0
agent-20: 16.0
Sum Reward: 414.0
Avg Reward: 20.7
Min Reward: 6.0
Gini Coefficient: 0.22826086956521738
20:20 Ratio: 3.7941176470588234
Max-min Ratio: 6.5
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_00-06-20
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 572.0
  episode_reward_mean: 354.13
  episode_reward_min: 228.0
  episodes_this_iter: 1
  episodes_total: 273
  experiment_id: 35d66058da2d4c9882f832ee91e4aa4a
  hostname: gpu011
  info:
    apply_time_ms: 2.574
    dispatch_time_ms: 8.331
    learner:
      cur_lr: 0.0009963640477508307
      grad_gnorm: 31.63758659362793
      policy_entropy: 92.07230377197266
      policy_loss: -2.9152421951293945
      var_gnorm: 20.015987396240234
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 3.533182382583618
    num_steps_sampled: 5480000
    num_steps_trained: 5480000
    wait_time_ms: 265.04
  iterations_since_restore: 274
  node_ip: 172.17.8.11
  num_metric_batches_dropped: 0
  pid: 25504
  policy_reward_mean: {}
  time_since_restore: 7706.020131587982
  time_this_iter_s: 26.865689516067505
  time_total_s: 7706.020131587982
  timestamp: 1593921980
  timesteps_since_restore: 5480000
  timesteps_this_iter: 20000
  timesteps_total: 5480000
  training_iteration: 274
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=25504], 7706 s, 274 iter, 5480000 ts, 354 rew

agent-1: 30.0
agent-2: 33.0
agent-3: 23.0
agent-4: 25.0
agent-5: 30.0
agent-6: 19.0
agent-7: 13.0
agent-8: 19.0
agent-9: 22.0
agent-10: 15.0
agent-11: 21.0
agent-12: 31.0
agent-13: 18.0
agent-14: 12.0
agent-15: 17.0
agent-16: 39.0
agent-17: 44.0
agent-18: 39.0
agent-19: 31.0
agent-20: 16.0
Sum Reward: 497.0
Avg Reward: 24.85
Min Reward: 12.0
Gini Coefficient: 0.20593561368209257
20:20 Ratio: 2.767857142857143
Max-min Ratio: 3.6666666666666665
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_00-06-48
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 572.0
  episode_reward_mean: 355.78
  episode_reward_min: 228.0
  episodes_this_iter: 1
  episodes_total: 274
  experiment_id: 35d66058da2d4c9882f832ee91e4aa4a
  hostname: gpu011
  info:
    apply_time_ms: 2.751
    dispatch_time_ms: 5.845
    learner:
      cur_lr: 0.0009950320236384869
      grad_gnorm: 11.445176124572754
      policy_entropy: 114.18203735351562
      policy_loss: -2.409693717956543
      var_gnorm: 20.01767349243164
      vf_explained_var: 0.0
      vf_loss: 0.05288919061422348
    num_steps_sampled: 5500000
    num_steps_trained: 5500000
    wait_time_ms: 238.101
  iterations_since_restore: 275
  node_ip: 172.17.8.11
  num_metric_batches_dropped: 0
  pid: 25504
  policy_reward_mean: {}
  time_since_restore: 7733.489834308624
  time_this_iter_s: 27.46970272064209
  time_total_s: 7733.489834308624
  timestamp: 1593922008
  timesteps_since_restore: 5500000
  timesteps_this_iter: 20000
  timesteps_total: 5500000
  training_iteration: 275
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=25504], 7733 s, 275 iter, 5500000 ts, 356 rew

agent-1: 28.0
agent-2: 26.0
agent-3: 16.0
agent-4: 17.0
agent-5: 15.0
agent-6: 20.0
agent-7: 13.0
agent-8: 17.0
agent-9: 29.0
agent-10: 11.0
agent-11: 11.0
agent-12: 19.0
agent-13: 18.0
agent-14: 10.0
agent-15: 25.0
agent-16: 23.0
agent-17: 22.0
agent-18: 21.0
agent-19: 20.0
agent-20: 13.0
Sum Reward: 374.0
Avg Reward: 18.7
Min Reward: 10.0
Gini Coefficient: 0.16898395721925133
20:20 Ratio: 2.4
Max-min Ratio: 2.9
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_00-07-15
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 572.0
  episode_reward_mean: 356.74
  episode_reward_min: 228.0
  episodes_this_iter: 1
  episodes_total: 275
  experiment_id: 35d66058da2d4c9882f832ee91e4aa4a
  hostname: gpu011
  info:
    apply_time_ms: 3.268
    dispatch_time_ms: 7.879
    learner:
      cur_lr: 0.000993699999526143
      grad_gnorm: 40.0
      policy_entropy: 140.9049835205078
      policy_loss: -12.527772903442383
      var_gnorm: 20.021196365356445
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 0.6918355226516724
    num_steps_sampled: 5520000
    num_steps_trained: 5520000
    wait_time_ms: 272.354
  iterations_since_restore: 276
  node_ip: 172.17.8.11
  num_metric_batches_dropped: 0
  pid: 25504
  policy_reward_mean: {}
  time_since_restore: 7760.7699246406555
  time_this_iter_s: 27.28009033203125
  time_total_s: 7760.7699246406555
  timestamp: 1593922035
  timesteps_since_restore: 5520000
  timesteps_this_iter: 20000
  timesteps_total: 5520000
  training_iteration: 276
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=25504], 7760 s, 276 iter, 5520000 ts, 357 rew

agent-1: 22.0
agent-2: 13.0
agent-3: 19.0
agent-4: 18.0
agent-5: 14.0
agent-6: 16.0
agent-7: 6.0
agent-8: 17.0
agent-9: 22.0
agent-10: 34.0
agent-11: 16.0
agent-12: 10.0
agent-13: 17.0
agent-14: 6.0
agent-15: 17.0
agent-16: 24.0
agent-17: 4.0
agent-18: 5.0
agent-19: 14.0
agent-20: 40.0
Sum Reward: 334.0
Avg Reward: 16.7
Min Reward: 4.0
Gini Coefficient: 0.28263473053892213
20:20 Ratio: 5.714285714285714
Max-min Ratio: 10.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_00-07-44
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 572.0
  episode_reward_mean: 357.33
  episode_reward_min: 228.0
  episodes_this_iter: 1
  episodes_total: 276
  experiment_id: 35d66058da2d4c9882f832ee91e4aa4a
  hostname: gpu011
  info:
    apply_time_ms: 3.212
    dispatch_time_ms: 35.064
    learner:
      cur_lr: 0.0009923679754137993
      grad_gnorm: 40.000003814697266
      policy_entropy: 172.88082885742188
      policy_loss: 58.508544921875
      var_gnorm: 20.018468856811523
      vf_explained_var: 0.0
      vf_loss: 40.261924743652344
    num_steps_sampled: 5540000
    num_steps_trained: 5540000
    wait_time_ms: 243.443
  iterations_since_restore: 277
  node_ip: 172.17.8.11
  num_metric_batches_dropped: 0
  pid: 25504
  policy_reward_mean: {}
  time_since_restore: 7789.247883796692
  time_this_iter_s: 28.477959156036377
  time_total_s: 7789.247883796692
  timestamp: 1593922064
  timesteps_since_restore: 5540000
  timesteps_this_iter: 20000
  timesteps_total: 5540000
  training_iteration: 277
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=25504], 7789 s, 277 iter, 5540000 ts, 357 rew

agent-1: 7.0
agent-2: 12.0
agent-3: 16.0
agent-4: 12.0
agent-5: 24.0
agent-6: 39.0
agent-7: 30.0
agent-8: 15.0
agent-9: 37.0
agent-10: 18.0
agent-11: 7.0
agent-12: 16.0
agent-13: 30.0
agent-14: 2.0
agent-15: 12.0
agent-16: 21.0
agent-17: 6.0
agent-18: 12.0
agent-19: 12.0
agent-20: 23.0
Sum Reward: 351.0
Avg Reward: 17.55
Min Reward: 2.0
Gini Coefficient: 0.31495726495726495
20:20 Ratio: 6.181818181818182
Max-min Ratio: 19.5
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_00-08-12
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 572.0
  episode_reward_mean: 357.3
  episode_reward_min: 228.0
  episodes_this_iter: 1
  episodes_total: 277
  experiment_id: 35d66058da2d4c9882f832ee91e4aa4a
  hostname: gpu011
  info:
    apply_time_ms: 2.994
    dispatch_time_ms: 38.343
    learner:
      cur_lr: 0.0009910359513014555
      grad_gnorm: 36.20338439941406
      policy_entropy: 189.22186279296875
      policy_loss: -14.620853424072266
      var_gnorm: 20.02420997619629
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 0.5196352601051331
    num_steps_sampled: 5560000
    num_steps_trained: 5560000
    wait_time_ms: 256.303
  iterations_since_restore: 278
  node_ip: 172.17.8.11
  num_metric_batches_dropped: 0
  pid: 25504
  policy_reward_mean: {}
  time_since_restore: 7817.505194187164
  time_this_iter_s: 28.257310390472412
  time_total_s: 7817.505194187164
  timestamp: 1593922092
  timesteps_since_restore: 5560000
  timesteps_this_iter: 20000
  timesteps_total: 5560000
  training_iteration: 278
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=25504], 7817 s, 278 iter, 5560000 ts, 357 rew

agent-1: 6.0
agent-2: 14.0
agent-3: 14.0
agent-4: 8.0
agent-5: 15.0
agent-6: 10.0
agent-7: 5.0
agent-8: 14.0
agent-9: 15.0
agent-10: 23.0
agent-11: 7.0
agent-12: 5.0
agent-13: 8.0
agent-14: 19.0
agent-15: 14.0
agent-16: 17.0
agent-17: 11.0
agent-18: 16.0
agent-19: 17.0
agent-20: 14.0
Sum Reward: 252.0
Avg Reward: 12.6
Min Reward: 5.0
Gini Coefficient: 0.21349206349206348
20:20 Ratio: 3.3043478260869565
Max-min Ratio: 4.6
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_00-08-41
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 572.0
  episode_reward_mean: 356.39
  episode_reward_min: 228.0
  episodes_this_iter: 1
  episodes_total: 278
  experiment_id: 35d66058da2d4c9882f832ee91e4aa4a
  hostname: gpu011
  info:
    apply_time_ms: 3.285
    dispatch_time_ms: 40.375
    learner:
      cur_lr: 0.0009897040436044335
      grad_gnorm: 40.0
      policy_entropy: 124.6028823852539
      policy_loss: 59.611907958984375
      var_gnorm: 20.022525787353516
      vf_explained_var: 0.0
      vf_loss: 140.37728881835938
    num_steps_sampled: 5580000
    num_steps_trained: 5580000
    wait_time_ms: 225.674
  iterations_since_restore: 279
  node_ip: 172.17.8.11
  num_metric_batches_dropped: 0
  pid: 25504
  policy_reward_mean: {}
  time_since_restore: 7846.74076962471
  time_this_iter_s: 29.235575437545776
  time_total_s: 7846.74076962471
  timestamp: 1593922121
  timesteps_since_restore: 5580000
  timesteps_this_iter: 20000
  timesteps_total: 5580000
  training_iteration: 279
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=25504], 7846 s, 279 iter, 5580000 ts, 356 rew

agent-1: 8.0
agent-2: 17.0
agent-3: 23.0
agent-4: 36.0
agent-5: 12.0
agent-6: 7.0
agent-7: 15.0
agent-8: 26.0
agent-9: 43.0
agent-10: 11.0
agent-11: 12.0
agent-12: 40.0
agent-13: 40.0
agent-14: 19.0
agent-15: 17.0
agent-16: 41.0
agent-17: 10.0
agent-18: 10.0
agent-19: 15.0
agent-20: 42.0
Sum Reward: 444.0
Avg Reward: 22.2
Min Reward: 7.0
Gini Coefficient: 0.31554054054054054
20:20 Ratio: 4.742857142857143
Max-min Ratio: 6.142857142857143
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_00-09-09
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 572.0
  episode_reward_mean: 356.79
  episode_reward_min: 228.0
  episodes_this_iter: 1
  episodes_total: 279
  experiment_id: 35d66058da2d4c9882f832ee91e4aa4a
  hostname: gpu011
  info:
    apply_time_ms: 2.708
    dispatch_time_ms: 7.37
    learner:
      cur_lr: 0.0009883720194920897
      grad_gnorm: 31.514799118041992
      policy_entropy: 130.47833251953125
      policy_loss: -2.341609477996826
      var_gnorm: 20.0289249420166
      vf_explained_var: 0.0
      vf_loss: 22.10543441772461
    num_steps_sampled: 5600000
    num_steps_trained: 5600000
    wait_time_ms: 265.81
  iterations_since_restore: 280
  node_ip: 172.17.8.11
  num_metric_batches_dropped: 0
  pid: 25504
  policy_reward_mean: {}
  time_since_restore: 7874.6425840854645
  time_this_iter_s: 27.901814460754395
  time_total_s: 7874.6425840854645
  timestamp: 1593922149
  timesteps_since_restore: 5600000
  timesteps_this_iter: 20000
  timesteps_total: 5600000
  training_iteration: 280
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=25504], 7874 s, 280 iter, 5600000 ts, 357 rew

agent-1: 42.0
agent-2: 17.0
agent-3: 22.0
agent-4: 22.0
agent-5: 28.0
agent-6: 28.0
agent-7: 28.0
agent-8: 27.0
agent-9: 51.0
agent-10: 25.0
agent-11: 21.0
agent-12: 21.0
agent-13: 17.0
agent-14: 23.0
agent-15: 7.0
agent-16: 25.0
agent-17: 21.0
agent-18: 25.0
agent-19: 13.0
agent-20: 21.0
Sum Reward: 484.0
Avg Reward: 24.2
Min Reward: 7.0
Gini Coefficient: 0.18863636363636363
20:20 Ratio: 2.759259259259259
Max-min Ratio: 7.285714285714286
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_00-09-37
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 572.0
  episode_reward_mean: 358.22
  episode_reward_min: 228.0
  episodes_this_iter: 1
  episodes_total: 280
  experiment_id: 35d66058da2d4c9882f832ee91e4aa4a
  hostname: gpu011
  info:
    apply_time_ms: 3.299
    dispatch_time_ms: 5.854
    learner:
      cur_lr: 0.000987039995379746
      grad_gnorm: 19.925655364990234
      policy_entropy: 115.5693130493164
      policy_loss: -4.542511940002441
      var_gnorm: 20.026836395263672
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 0.15985079109668732
    num_steps_sampled: 5620000
    num_steps_trained: 5620000
    wait_time_ms: 275.073
  iterations_since_restore: 281
  node_ip: 172.17.8.11
  num_metric_batches_dropped: 0
  pid: 25504
  policy_reward_mean: {}
  time_since_restore: 7902.246369361877
  time_this_iter_s: 27.603785276412964
  time_total_s: 7902.246369361877
  timestamp: 1593922177
  timesteps_since_restore: 5620000
  timesteps_this_iter: 20000
  timesteps_total: 5620000
  training_iteration: 281
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=25504], 7902 s, 281 iter, 5620000 ts, 358 rew

agent-1: 11.0
agent-2: 6.0
agent-3: 24.0
agent-4: 13.0
agent-5: 46.0
agent-6: 18.0
agent-7: 14.0
agent-8: 38.0
agent-9: 15.0
agent-10: 27.0
agent-11: 28.0
agent-12: 21.0
agent-13: 29.0
agent-14: 11.0
agent-15: 18.0
agent-16: 14.0
agent-17: 25.0
agent-18: 49.0
agent-19: 15.0
agent-20: 18.0
Sum Reward: 440.0
Avg Reward: 22.0
Min Reward: 6.0
Gini Coefficient: 0.275
20:20 Ratio: 3.951219512195122
Max-min Ratio: 8.166666666666666
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_00-10-04
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 572.0
  episode_reward_mean: 360.03
  episode_reward_min: 228.0
  episodes_this_iter: 1
  episodes_total: 281
  experiment_id: 35d66058da2d4c9882f832ee91e4aa4a
  hostname: gpu011
  info:
    apply_time_ms: 2.581
    dispatch_time_ms: 6.482
    learner:
      cur_lr: 0.0009857079712674022
      grad_gnorm: 21.92788314819336
      policy_entropy: 88.93891906738281
      policy_loss: -0.0413970947265625
      var_gnorm: 20.03533363342285
      vf_explained_var: 1.7881393432617188e-07
      vf_loss: 9.106088638305664
    num_steps_sampled: 5640000
    num_steps_trained: 5640000
    wait_time_ms: 265.974
  iterations_since_restore: 282
  node_ip: 172.17.8.11
  num_metric_batches_dropped: 0
  pid: 25504
  policy_reward_mean: {}
  time_since_restore: 7928.955233573914
  time_this_iter_s: 26.708864212036133
  time_total_s: 7928.955233573914
  timestamp: 1593922204
  timesteps_since_restore: 5640000
  timesteps_this_iter: 20000
  timesteps_total: 5640000
  training_iteration: 282
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=25504], 7928 s, 282 iter, 5640000 ts, 360 rew

agent-1: 19.0
agent-2: 35.0
agent-3: 14.0
agent-4: 10.0
agent-5: 21.0
agent-6: 30.0
agent-7: 29.0
agent-8: 25.0
agent-9: 34.0
agent-10: 29.0
agent-11: 22.0
agent-12: 31.0
agent-13: 28.0
agent-14: 20.0
agent-15: 18.0
agent-16: 17.0
agent-17: 36.0
agent-18: 18.0
agent-19: 37.0
agent-20: 23.0
Sum Reward: 496.0
Avg Reward: 24.8
Min Reward: 10.0
Gini Coefficient: 0.1743951612903226
20:20 Ratio: 2.406779661016949
Max-min Ratio: 3.7
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_00-10-31
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 572.0
  episode_reward_mean: 362.19
  episode_reward_min: 228.0
  episodes_this_iter: 1
  episodes_total: 282
  experiment_id: 35d66058da2d4c9882f832ee91e4aa4a
  hostname: gpu011
  info:
    apply_time_ms: 2.733
    dispatch_time_ms: 5.866
    learner:
      cur_lr: 0.0009843759471550584
      grad_gnorm: 4.325667858123779
      policy_entropy: 147.64707946777344
      policy_loss: -1.2429978847503662
      var_gnorm: 20.02899932861328
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 0.007416167762130499
    num_steps_sampled: 5660000
    num_steps_trained: 5660000
    wait_time_ms: 259.519
  iterations_since_restore: 283
  node_ip: 172.17.8.11
  num_metric_batches_dropped: 0
  pid: 25504
  policy_reward_mean: {}
  time_since_restore: 7956.709745168686
  time_this_iter_s: 27.75451159477234
  time_total_s: 7956.709745168686
  timestamp: 1593922231
  timesteps_since_restore: 5660000
  timesteps_this_iter: 20000
  timesteps_total: 5660000
  training_iteration: 283
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=25504], 7956 s, 283 iter, 5660000 ts, 362 rew

agent-1: 18.0
agent-2: 14.0
agent-3: 20.0
agent-4: 12.0
agent-5: 15.0
agent-6: 15.0
agent-7: 8.0
agent-8: 14.0
agent-9: 17.0
agent-10: 14.0
agent-11: 13.0
agent-12: 24.0
agent-13: 31.0
agent-14: 12.0
agent-15: 9.0
agent-16: 17.0
agent-17: 26.0
agent-18: 21.0
agent-19: 27.0
agent-20: 13.0
Sum Reward: 340.0
Avg Reward: 17.0
Min Reward: 8.0
Gini Coefficient: 0.19294117647058823
20:20 Ratio: 2.6341463414634148
Max-min Ratio: 3.875
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_00-10-58
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 572.0
  episode_reward_mean: 362.72
  episode_reward_min: 228.0
  episodes_this_iter: 1
  episodes_total: 283
  experiment_id: 35d66058da2d4c9882f832ee91e4aa4a
  hostname: gpu011
  info:
    apply_time_ms: 2.633
    dispatch_time_ms: 5.064
    learner:
      cur_lr: 0.0009830440394580364
      grad_gnorm: 36.48112487792969
      policy_entropy: 123.84972381591797
      policy_loss: -6.203373432159424
      var_gnorm: 20.031158447265625
      vf_explained_var: 1.1920928955078125e-07
      vf_loss: 0.5150272846221924
    num_steps_sampled: 5680000
    num_steps_trained: 5680000
    wait_time_ms: 262.98
  iterations_since_restore: 284
  node_ip: 172.17.8.11
  num_metric_batches_dropped: 0
  pid: 25504
  policy_reward_mean: {}
  time_since_restore: 7983.495794296265
  time_this_iter_s: 26.786049127578735
  time_total_s: 7983.495794296265
  timestamp: 1593922258
  timesteps_since_restore: 5680000
  timesteps_this_iter: 20000
  timesteps_total: 5680000
  training_iteration: 284
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=25504], 7983 s, 284 iter, 5680000 ts, 363 rew

agent-1: 29.0
agent-2: 18.0
agent-3: 12.0
agent-4: 16.0
agent-5: 10.0
agent-6: 8.0
agent-7: 9.0
agent-8: 7.0
agent-9: 20.0
agent-10: 28.0
agent-11: 4.0
agent-12: 6.0
agent-13: 7.0
agent-14: 19.0
agent-15: 6.0
agent-16: 18.0
agent-17: 16.0
agent-18: 22.0
agent-19: 20.0
agent-20: 20.0
Sum Reward: 295.0
Avg Reward: 14.75
Min Reward: 4.0
Gini Coefficient: 0.2774576271186441
20:20 Ratio: 4.304347826086956
Max-min Ratio: 7.25
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_00-11-27
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 572.0
  episode_reward_mean: 362.8
  episode_reward_min: 228.0
  episodes_this_iter: 1
  episodes_total: 284
  experiment_id: 35d66058da2d4c9882f832ee91e4aa4a
  hostname: gpu011
  info:
    apply_time_ms: 2.817
    dispatch_time_ms: 23.242
    learner:
      cur_lr: 0.0009817120153456926
      grad_gnorm: 0.9997601509094238
      policy_entropy: 154.7602081298828
      policy_loss: 0.48757195472717285
      var_gnorm: 20.026124954223633
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 0.0003432160010561347
    num_steps_sampled: 5700000
    num_steps_trained: 5700000
    wait_time_ms: 255.703
  iterations_since_restore: 285
  node_ip: 172.17.8.11
  num_metric_batches_dropped: 0
  pid: 25504
  policy_reward_mean: {}
  time_since_restore: 8012.440041780472
  time_this_iter_s: 28.944247484207153
  time_total_s: 8012.440041780472
  timestamp: 1593922287
  timesteps_since_restore: 5700000
  timesteps_this_iter: 20000
  timesteps_total: 5700000
  training_iteration: 285
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=25504], 8012 s, 285 iter, 5700000 ts, 363 rew

agent-1: 23.0
agent-2: 31.0
agent-3: 10.0
agent-4: 20.0
agent-5: 9.0
agent-6: 8.0
agent-7: 29.0
agent-8: 25.0
agent-9: 32.0
agent-10: 15.0
agent-11: 12.0
agent-12: 9.0
agent-13: 8.0
agent-14: 23.0
agent-15: 31.0
agent-16: 14.0
agent-17: 22.0
agent-18: 24.0
agent-19: 25.0
agent-20: 11.0
Sum Reward: 381.0
Avg Reward: 19.05
Min Reward: 8.0
Gini Coefficient: 0.24711286089238846
20:20 Ratio: 3.6176470588235294
Max-min Ratio: 4.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_00-11-56
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 572.0
  episode_reward_mean: 363.03
  episode_reward_min: 228.0
  episodes_this_iter: 1
  episodes_total: 285
  experiment_id: 35d66058da2d4c9882f832ee91e4aa4a
  hostname: gpu011
  info:
    apply_time_ms: 2.969
    dispatch_time_ms: 33.544
    learner:
      cur_lr: 0.0009803799912333488
      grad_gnorm: 23.477298736572266
      policy_entropy: 165.30455017089844
      policy_loss: -10.096109390258789
      var_gnorm: 20.03160858154297
      vf_explained_var: 0.0
      vf_loss: 0.21975494921207428
    num_steps_sampled: 5720000
    num_steps_trained: 5720000
    wait_time_ms: 240.988
  iterations_since_restore: 286
  node_ip: 172.17.8.11
  num_metric_batches_dropped: 0
  pid: 25504
  policy_reward_mean: {}
  time_since_restore: 8041.138412475586
  time_this_iter_s: 28.698370695114136
  time_total_s: 8041.138412475586
  timestamp: 1593922316
  timesteps_since_restore: 5720000
  timesteps_this_iter: 20000
  timesteps_total: 5720000
  training_iteration: 286
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=25504], 8041 s, 286 iter, 5720000 ts, 363 rew

agent-1: 15.0
agent-2: 13.0
agent-3: 23.0
agent-4: 7.0
agent-5: 38.0
agent-6: 38.0
agent-7: 22.0
agent-8: 28.0
agent-9: 6.0
agent-10: 16.0
agent-11: 3.0
agent-12: 2.0
agent-13: 9.0
agent-14: 12.0
agent-15: 7.0
agent-16: 6.0
agent-17: 16.0
agent-18: 7.0
agent-19: 21.0
agent-20: 12.0
Sum Reward: 301.0
Avg Reward: 15.05
Min Reward: 2.0
Gini Coefficient: 0.370265780730897
20:20 Ratio: 7.470588235294118
Max-min Ratio: 19.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_00-12-26
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 572.0
  episode_reward_mean: 363.19
  episode_reward_min: 228.0
  episodes_this_iter: 1
  episodes_total: 286
  experiment_id: 35d66058da2d4c9882f832ee91e4aa4a
  hostname: gpu011
  info:
    apply_time_ms: 3.351
    dispatch_time_ms: 28.365
    learner:
      cur_lr: 0.000979047967121005
      grad_gnorm: 0.9820979833602905
      policy_entropy: 168.8851776123047
      policy_loss: 0.9569085836410522
      var_gnorm: 20.028413772583008
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 0.00034786126343533397
    num_steps_sampled: 5740000
    num_steps_trained: 5740000
    wait_time_ms: 267.658
  iterations_since_restore: 287
  node_ip: 172.17.8.11
  num_metric_batches_dropped: 0
  pid: 25504
  policy_reward_mean: {}
  time_since_restore: 8070.749703884125
  time_this_iter_s: 29.61129140853882
  time_total_s: 8070.749703884125
  timestamp: 1593922346
  timesteps_since_restore: 5740000
  timesteps_this_iter: 20000
  timesteps_total: 5740000
  training_iteration: 287
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=25504], 8070 s, 287 iter, 5740000 ts, 363 rew

agent-1: 14.0
agent-2: 14.0
agent-3: 5.0
agent-4: 21.0
agent-5: 14.0
agent-6: 12.0
agent-7: 18.0
agent-8: 11.0
agent-9: 19.0
agent-10: 9.0
agent-11: 33.0
agent-12: 10.0
agent-13: 34.0
agent-14: 18.0
agent-15: 22.0
agent-16: 23.0
agent-17: 11.0
agent-18: 11.0
agent-19: 21.0
agent-20: 11.0
Sum Reward: 331.0
Avg Reward: 16.55
Min Reward: 5.0
Gini Coefficient: 0.24093655589123866
20:20 Ratio: 3.2
Max-min Ratio: 6.8
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_00-12-54
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 572.0
  episode_reward_mean: 363.27
  episode_reward_min: 228.0
  episodes_this_iter: 1
  episodes_total: 287
  experiment_id: 35d66058da2d4c9882f832ee91e4aa4a
  hostname: gpu011
  info:
    apply_time_ms: 3.571
    dispatch_time_ms: 43.876
    learner:
      cur_lr: 0.0009777159430086613
      grad_gnorm: 35.904911041259766
      policy_entropy: 179.2282257080078
      policy_loss: -14.451275825500488
      var_gnorm: 20.030473709106445
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 0.5099692344665527
    num_steps_sampled: 5760000
    num_steps_trained: 5760000
    wait_time_ms: 253.481
  iterations_since_restore: 288
  node_ip: 172.17.8.11
  num_metric_batches_dropped: 0
  pid: 25504
  policy_reward_mean: {}
  time_since_restore: 8099.197557449341
  time_this_iter_s: 28.447853565216064
  time_total_s: 8099.197557449341
  timestamp: 1593922374
  timesteps_since_restore: 5760000
  timesteps_this_iter: 20000
  timesteps_total: 5760000
  training_iteration: 288
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=25504], 8099 s, 288 iter, 5760000 ts, 363 rew

agent-1: 3.0
agent-2: 28.0
agent-3: 9.0
agent-4: 15.0
agent-5: 18.0
agent-6: 26.0
agent-7: 22.0
agent-8: 20.0
agent-9: 6.0
agent-10: 15.0
agent-11: 6.0
agent-12: 19.0
agent-13: 20.0
agent-14: 21.0
agent-15: 17.0
agent-16: 17.0
agent-17: 5.0
agent-18: 14.0
agent-19: 20.0
agent-20: 6.0
Sum Reward: 307.0
Avg Reward: 15.35
Min Reward: 3.0
Gini Coefficient: 0.25912052117263845
20:20 Ratio: 4.85
Max-min Ratio: 9.333333333333334
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_00-13-23
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 572.0
  episode_reward_mean: 362.5
  episode_reward_min: 228.0
  episodes_this_iter: 1
  episodes_total: 288
  experiment_id: 35d66058da2d4c9882f832ee91e4aa4a
  hostname: gpu011
  info:
    apply_time_ms: 3.364
    dispatch_time_ms: 28.232
    learner:
      cur_lr: 0.0009763839771039784
      grad_gnorm: 40.0
      policy_entropy: 184.69508361816406
      policy_loss: 95.58663940429688
      var_gnorm: 20.02526092529297
      vf_explained_var: 0.0
      vf_loss: 81.45903015136719
    num_steps_sampled: 5780000
    num_steps_trained: 5780000
    wait_time_ms: 250.434
  iterations_since_restore: 289
  node_ip: 172.17.8.11
  num_metric_batches_dropped: 0
  pid: 25504
  policy_reward_mean: {}
  time_since_restore: 8128.136207342148
  time_this_iter_s: 28.938649892807007
  time_total_s: 8128.136207342148
  timestamp: 1593922403
  timesteps_since_restore: 5780000
  timesteps_this_iter: 20000
  timesteps_total: 5780000
  training_iteration: 289
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=25504], 8128 s, 289 iter, 5780000 ts, 362 rew

agent-1: 26.0
agent-2: 11.0
agent-3: 7.0
agent-4: 31.0
agent-5: 19.0
agent-6: 35.0
agent-7: 24.0
agent-8: 22.0
agent-9: 11.0
agent-10: 7.0
agent-11: 28.0
agent-12: 13.0
agent-13: 17.0
agent-14: 11.0
agent-15: 12.0
agent-16: 16.0
agent-17: 33.0
agent-18: 5.0
agent-19: 13.0
agent-20: 17.0
Sum Reward: 358.0
Avg Reward: 17.9
Min Reward: 5.0
Gini Coefficient: 0.2776536312849162
20:20 Ratio: 4.233333333333333
Max-min Ratio: 7.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_00-13-52
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 572.0
  episode_reward_mean: 363.28
  episode_reward_min: 228.0
  episodes_this_iter: 1
  episodes_total: 289
  experiment_id: 35d66058da2d4c9882f832ee91e4aa4a
  hostname: gpu011
  info:
    apply_time_ms: 3.612
    dispatch_time_ms: 23.033
    learner:
      cur_lr: 0.0009750520111992955
      grad_gnorm: 24.274959564208984
      policy_entropy: 184.088623046875
      policy_loss: -12.552002906799316
      var_gnorm: 20.03069305419922
      vf_explained_var: 0.0
      vf_loss: 0.20660829544067383
    num_steps_sampled: 5800000
    num_steps_trained: 5800000
    wait_time_ms: 228.633
  iterations_since_restore: 290
  node_ip: 172.17.8.11
  num_metric_batches_dropped: 0
  pid: 25504
  policy_reward_mean: {}
  time_since_restore: 8156.688677310944
  time_this_iter_s: 28.552469968795776
  time_total_s: 8156.688677310944
  timestamp: 1593922432
  timesteps_since_restore: 5800000
  timesteps_this_iter: 20000
  timesteps_total: 5800000
  training_iteration: 290
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=25504], 8156 s, 290 iter, 5800000 ts, 363 rew

agent-1: 25.0
agent-2: 7.0
agent-3: 17.0
agent-4: 27.0
agent-5: 20.0
agent-6: 7.0
agent-7: 17.0
agent-8: 14.0
agent-9: 14.0
agent-10: 19.0
agent-11: 19.0
agent-12: 13.0
agent-13: 15.0
agent-14: 18.0
agent-15: 22.0
agent-16: 3.0
agent-17: 10.0
agent-18: 23.0
agent-19: 8.0
agent-20: 21.0
Sum Reward: 319.0
Avg Reward: 15.95
Min Reward: 3.0
Gini Coefficient: 0.22523510971786834
20:20 Ratio: 3.88
Max-min Ratio: 9.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_00-14-21
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 572.0
  episode_reward_mean: 363.38
  episode_reward_min: 228.0
  episodes_this_iter: 1
  episodes_total: 290
  experiment_id: 35d66058da2d4c9882f832ee91e4aa4a
  hostname: gpu011
  info:
    apply_time_ms: 3.059
    dispatch_time_ms: 6.959
    learner:
      cur_lr: 0.0009737199870869517
      grad_gnorm: 40.0
      policy_entropy: 182.40115356445312
      policy_loss: 80.63935852050781
      var_gnorm: 20.023569107055664
      vf_explained_var: 0.0
      vf_loss: 68.63516998291016
    num_steps_sampled: 5820000
    num_steps_trained: 5820000
    wait_time_ms: 234.66
  iterations_since_restore: 291
  node_ip: 172.17.8.11
  num_metric_batches_dropped: 0
  pid: 25504
  policy_reward_mean: {}
  time_since_restore: 8185.429537534714
  time_this_iter_s: 28.74086022377014
  time_total_s: 8185.429537534714
  timestamp: 1593922461
  timesteps_since_restore: 5820000
  timesteps_this_iter: 20000
  timesteps_total: 5820000
  training_iteration: 291
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=25504], 8185 s, 291 iter, 5820000 ts, 363 rew

agent-1: 31.0
agent-2: 4.0
agent-3: 10.0
agent-4: 22.0
agent-5: 15.0
agent-6: 30.0
agent-7: 15.0
agent-8: 7.0
agent-9: 34.0
agent-10: 4.0
agent-11: 32.0
agent-12: 5.0
agent-13: 12.0
agent-14: 9.0
agent-15: 4.0
agent-16: 19.0
agent-17: 13.0
agent-18: 2.0
agent-19: 18.0
agent-20: 14.0
Sum Reward: 300.0
Avg Reward: 15.0
Min Reward: 2.0
Gini Coefficient: 0.37
20:20 Ratio: 9.071428571428571
Max-min Ratio: 17.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_00-14-48
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 572.0
  episode_reward_mean: 362.56
  episode_reward_min: 228.0
  episodes_this_iter: 1
  episodes_total: 291
  experiment_id: 35d66058da2d4c9882f832ee91e4aa4a
  hostname: gpu011
  info:
    apply_time_ms: 4.282
    dispatch_time_ms: 8.474
    learner:
      cur_lr: 0.0009723880211822689
      grad_gnorm: 27.46385383605957
      policy_entropy: 178.66641235351562
      policy_loss: -8.659453392028809
      var_gnorm: 20.024633407592773
      vf_explained_var: -2.384185791015625e-07
      vf_loss: 0.29272934794425964
    num_steps_sampled: 5840000
    num_steps_trained: 5840000
    wait_time_ms: 275.543
  iterations_since_restore: 292
  node_ip: 172.17.8.11
  num_metric_batches_dropped: 0
  pid: 25504
  policy_reward_mean: {}
  time_since_restore: 8212.779783248901
  time_this_iter_s: 27.350245714187622
  time_total_s: 8212.779783248901
  timestamp: 1593922488
  timesteps_since_restore: 5840000
  timesteps_this_iter: 20000
  timesteps_total: 5840000
  training_iteration: 292
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=25504], 8212 s, 292 iter, 5840000 ts, 363 rew

agent-1: 20.0
agent-2: 12.0
agent-3: 28.0
agent-4: 17.0
agent-5: 21.0
agent-6: 16.0
agent-7: 8.0
agent-8: 8.0
agent-9: 17.0
agent-10: 8.0
agent-11: 6.0
agent-12: 25.0
agent-13: 15.0
agent-14: 12.0
agent-15: 27.0
agent-16: 16.0
agent-17: 9.0
agent-18: 17.0
agent-19: 15.0
agent-20: 16.0
Sum Reward: 313.0
Avg Reward: 15.65
Min Reward: 6.0
Gini Coefficient: 0.22028753993610223
20:20 Ratio: 3.3666666666666667
Max-min Ratio: 4.666666666666667
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_00-15-15
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 572.0
  episode_reward_mean: 362.63
  episode_reward_min: 228.0
  episodes_this_iter: 1
  episodes_total: 292
  experiment_id: 35d66058da2d4c9882f832ee91e4aa4a
  hostname: gpu011
  info:
    apply_time_ms: 2.847
    dispatch_time_ms: 5.877
    learner:
      cur_lr: 0.0009710559970699251
      grad_gnorm: 40.0
      policy_entropy: 172.62559509277344
      policy_loss: 53.511863708496094
      var_gnorm: 20.022029876708984
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 90.62332153320312
    num_steps_sampled: 5860000
    num_steps_trained: 5860000
    wait_time_ms: 237.238
  iterations_since_restore: 293
  node_ip: 172.17.8.11
  num_metric_batches_dropped: 0
  pid: 25504
  policy_reward_mean: {}
  time_since_restore: 8240.320860624313
  time_this_iter_s: 27.541077375411987
  time_total_s: 8240.320860624313
  timestamp: 1593922515
  timesteps_since_restore: 5860000
  timesteps_this_iter: 20000
  timesteps_total: 5860000
  training_iteration: 293
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=25504], 8240 s, 293 iter, 5860000 ts, 363 rew

agent-1: 5.0
agent-2: 18.0
agent-3: 26.0
agent-4: 36.0
agent-5: 30.0
agent-6: 5.0
agent-7: 12.0
agent-8: 16.0
agent-9: 11.0
agent-10: 1.0
agent-11: 8.0
agent-12: 5.0
agent-13: 8.0
agent-14: 21.0
agent-15: 20.0
agent-16: 15.0
agent-17: 15.0
agent-18: 24.0
agent-19: 11.0
agent-20: 15.0
Sum Reward: 302.0
Avg Reward: 15.1
Min Reward: 1.0
Gini Coefficient: 0.32880794701986754
20:20 Ratio: 7.25
Max-min Ratio: 36.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_00-15-43
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 572.0
  episode_reward_mean: 362.42
  episode_reward_min: 228.0
  episodes_this_iter: 1
  episodes_total: 293
  experiment_id: 35d66058da2d4c9882f832ee91e4aa4a
  hostname: gpu011
  info:
    apply_time_ms: 2.539
    dispatch_time_ms: 9.179
    learner:
      cur_lr: 0.0009697239729575813
      grad_gnorm: 40.0
      policy_entropy: 146.07736206054688
      policy_loss: 21.230804443359375
      var_gnorm: 20.028711318969727
      vf_explained_var: 0.0
      vf_loss: 42.30329513549805
    num_steps_sampled: 5880000
    num_steps_trained: 5880000
    wait_time_ms: 265.197
  iterations_since_restore: 294
  node_ip: 172.17.8.11
  num_metric_batches_dropped: 0
  pid: 25504
  policy_reward_mean: {}
  time_since_restore: 8267.609019041061
  time_this_iter_s: 27.288158416748047
  time_total_s: 8267.609019041061
  timestamp: 1593922543
  timesteps_since_restore: 5880000
  timesteps_this_iter: 20000
  timesteps_total: 5880000
  training_iteration: 294
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=25504], 8267 s, 294 iter, 5880000 ts, 362 rew

agent-1: 28.0
agent-2: 22.0
agent-3: 19.0
agent-4: 23.0
agent-5: 10.0
agent-6: 10.0
agent-7: 13.0
agent-8: 22.0
agent-9: 30.0
agent-10: 8.0
agent-11: 14.0
agent-12: 14.0
agent-13: 23.0
agent-14: 2.0
agent-15: 8.0
agent-16: 20.0
agent-17: 20.0
agent-18: 7.0
agent-19: 18.0
agent-20: 6.0
Sum Reward: 317.0
Avg Reward: 15.85
Min Reward: 2.0
Gini Coefficient: 0.272397476340694
20:20 Ratio: 4.521739130434782
Max-min Ratio: 15.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_00-16-10
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 572.0
  episode_reward_mean: 361.61
  episode_reward_min: 228.0
  episodes_this_iter: 1
  episodes_total: 294
  experiment_id: 35d66058da2d4c9882f832ee91e4aa4a
  hostname: gpu011
  info:
    apply_time_ms: 3.37
    dispatch_time_ms: 7.391
    learner:
      cur_lr: 0.0009683920070528984
      grad_gnorm: 40.0
      policy_entropy: 160.2664794921875
      policy_loss: 95.34294128417969
      var_gnorm: 20.021392822265625
      vf_explained_var: 0.0
      vf_loss: 125.79026794433594
    num_steps_sampled: 5900000
    num_steps_trained: 5900000
    wait_time_ms: 247.358
  iterations_since_restore: 295
  node_ip: 172.17.8.11
  num_metric_batches_dropped: 0
  pid: 25504
  policy_reward_mean: {}
  time_since_restore: 8295.241110801697
  time_this_iter_s: 27.632091760635376
  time_total_s: 8295.241110801697
  timestamp: 1593922570
  timesteps_since_restore: 5900000
  timesteps_this_iter: 20000
  timesteps_total: 5900000
  training_iteration: 295
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=25504], 8295 s, 295 iter, 5900000 ts, 362 rew

agent-1: 25.0
agent-2: 34.0
agent-3: 13.0
agent-4: 12.0
agent-5: 10.0
agent-6: 23.0
agent-7: 20.0
agent-8: 19.0
agent-9: 18.0
agent-10: 11.0
agent-11: 12.0
agent-12: 30.0
agent-13: 42.0
agent-14: 11.0
agent-15: 25.0
agent-16: 19.0
agent-17: 11.0
agent-18: 8.0
agent-19: 10.0
agent-20: 9.0
Sum Reward: 362.0
Avg Reward: 18.1
Min Reward: 8.0
Gini Coefficient: 0.2696132596685083
20:20 Ratio: 3.5405405405405403
Max-min Ratio: 5.25
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_00-16-37
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 572.0
  episode_reward_mean: 362.57
  episode_reward_min: 228.0
  episodes_this_iter: 1
  episodes_total: 295
  experiment_id: 35d66058da2d4c9882f832ee91e4aa4a
  hostname: gpu011
  info:
    apply_time_ms: 2.797
    dispatch_time_ms: 6.778
    learner:
      cur_lr: 0.0009670599829405546
      grad_gnorm: 36.32575607299805
      policy_entropy: 149.51246643066406
      policy_loss: -10.873109817504883
      var_gnorm: 20.028118133544922
      vf_explained_var: 2.384185791015625e-07
      vf_loss: 0.5179575085639954
    num_steps_sampled: 5920000
    num_steps_trained: 5920000
    wait_time_ms: 261.858
  iterations_since_restore: 296
  node_ip: 172.17.8.11
  num_metric_batches_dropped: 0
  pid: 25504
  policy_reward_mean: {}
  time_since_restore: 8322.192880630493
  time_this_iter_s: 26.951769828796387
  time_total_s: 8322.192880630493
  timestamp: 1593922597
  timesteps_since_restore: 5920000
  timesteps_this_iter: 20000
  timesteps_total: 5920000
  training_iteration: 296
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=25504], 8322 s, 296 iter, 5920000 ts, 363 rew

agent-1: 24.0
agent-2: 13.0
agent-3: 6.0
agent-4: 12.0
agent-5: 18.0
agent-6: 24.0
agent-7: 15.0
agent-8: 15.0
agent-9: 12.0
agent-10: 21.0
agent-11: 16.0
agent-12: 9.0
agent-13: 14.0
agent-14: 21.0
agent-15: 23.0
agent-16: 2.0
agent-17: 21.0
agent-18: 33.0
agent-19: 12.0
agent-20: 14.0
Sum Reward: 325.0
Avg Reward: 16.25
Min Reward: 2.0
Gini Coefficient: 0.23461538461538461
20:20 Ratio: 3.586206896551724
Max-min Ratio: 16.5
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_00-17-05
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 572.0
  episode_reward_mean: 361.97
  episode_reward_min: 228.0
  episodes_this_iter: 1
  episodes_total: 296
  experiment_id: 35d66058da2d4c9882f832ee91e4aa4a
  hostname: gpu011
  info:
    apply_time_ms: 3.239
    dispatch_time_ms: 6.378
    learner:
      cur_lr: 0.0009657280170358717
      grad_gnorm: 40.000003814697266
      policy_entropy: 126.29885864257812
      policy_loss: 60.13557052612305
      var_gnorm: 20.021228790283203
      vf_explained_var: 0.0
      vf_loss: 121.80988311767578
    num_steps_sampled: 5940000
    num_steps_trained: 5940000
    wait_time_ms: 250.857
  iterations_since_restore: 297
  node_ip: 172.17.8.11
  num_metric_batches_dropped: 0
  pid: 25504
  policy_reward_mean: {}
  time_since_restore: 8349.797070741653
  time_this_iter_s: 27.60419011116028
  time_total_s: 8349.797070741653
  timestamp: 1593922625
  timesteps_since_restore: 5940000
  timesteps_this_iter: 20000
  timesteps_total: 5940000
  training_iteration: 297
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=25504], 8349 s, 297 iter, 5940000 ts, 362 rew

agent-1: 9.0
agent-2: 20.0
agent-3: 20.0
agent-4: 35.0
agent-5: 40.0
agent-6: 19.0
agent-7: 18.0
agent-8: 17.0
agent-9: 9.0
agent-10: 12.0
agent-11: 25.0
agent-12: 27.0
agent-13: 11.0
agent-14: 13.0
agent-15: 16.0
agent-16: 30.0
agent-17: 29.0
agent-18: 17.0
agent-19: 22.0
agent-20: 26.0
Sum Reward: 415.0
Avg Reward: 20.75
Min Reward: 9.0
Gini Coefficient: 0.22518072289156627
20:20 Ratio: 3.268292682926829
Max-min Ratio: 4.444444444444445
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_00-17-32
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 572.0
  episode_reward_mean: 362.22
  episode_reward_min: 228.0
  episodes_this_iter: 1
  episodes_total: 297
  experiment_id: 35d66058da2d4c9882f832ee91e4aa4a
  hostname: gpu011
  info:
    apply_time_ms: 2.845
    dispatch_time_ms: 5.948
    learner:
      cur_lr: 0.000964395992923528
      grad_gnorm: 40.0
      policy_entropy: 103.00923919677734
      policy_loss: -11.455985069274902
      var_gnorm: 20.04064178466797
      vf_explained_var: 5.960464477539063e-08
      vf_loss: 3.458853244781494
    num_steps_sampled: 5960000
    num_steps_trained: 5960000
    wait_time_ms: 265.376
  iterations_since_restore: 298
  node_ip: 172.17.8.11
  num_metric_batches_dropped: 0
  pid: 25504
  policy_reward_mean: {}
  time_since_restore: 8376.776448726654
  time_this_iter_s: 26.97937798500061
  time_total_s: 8376.776448726654
  timestamp: 1593922652
  timesteps_since_restore: 5960000
  timesteps_this_iter: 20000
  timesteps_total: 5960000
  training_iteration: 298
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=25504], 8376 s, 298 iter, 5960000 ts, 362 rew

agent-1: 29.0
agent-2: 21.0
agent-3: 36.0
agent-4: 11.0
agent-5: 36.0
agent-6: 21.0
agent-7: 23.0
agent-8: 23.0
agent-9: 29.0
agent-10: 16.0
agent-11: 12.0
agent-12: 7.0
agent-13: 16.0
agent-14: 13.0
agent-15: 13.0
agent-16: 19.0
agent-17: 17.0
agent-18: 23.0
agent-19: 27.0
agent-20: 7.0
Sum Reward: 399.0
Avg Reward: 19.95
Min Reward: 7.0
Gini Coefficient: 0.23521303258145362
20:20 Ratio: 3.5135135135135136
Max-min Ratio: 5.142857142857143
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_00-18-00
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 572.0
  episode_reward_mean: 362.39
  episode_reward_min: 228.0
  episodes_this_iter: 1
  episodes_total: 298
  experiment_id: 35d66058da2d4c9882f832ee91e4aa4a
  hostname: gpu011
  info:
    apply_time_ms: 3.531
    dispatch_time_ms: 6.227
    learner:
      cur_lr: 0.0009630640270188451
      grad_gnorm: 40.000003814697266
      policy_entropy: 132.60020446777344
      policy_loss: 84.24446105957031
      var_gnorm: 20.027488708496094
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 148.85618591308594
    num_steps_sampled: 5980000
    num_steps_trained: 5980000
    wait_time_ms: 255.156
  iterations_since_restore: 299
  node_ip: 172.17.8.11
  num_metric_batches_dropped: 0
  pid: 25504
  policy_reward_mean: {}
  time_since_restore: 8404.309736728668
  time_this_iter_s: 27.53328800201416
  time_total_s: 8404.309736728668
  timestamp: 1593922680
  timesteps_since_restore: 5980000
  timesteps_this_iter: 20000
  timesteps_total: 5980000
  training_iteration: 299
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=25504], 8404 s, 299 iter, 5980000 ts, 362 rew

agent-1: 32.0
agent-2: 21.0
agent-3: 15.0
agent-4: 25.0
agent-5: 10.0
agent-6: 23.0
agent-7: 29.0
agent-8: 23.0
agent-9: 17.0
agent-10: 36.0
agent-11: 13.0
agent-12: 24.0
agent-13: 11.0
agent-14: 16.0
agent-15: 35.0
agent-16: 26.0
agent-17: 19.0
agent-18: 24.0
agent-19: 23.0
agent-20: 16.0
Sum Reward: 438.0
Avg Reward: 21.9
Min Reward: 10.0
Gini Coefficient: 0.1872146118721461
20:20 Ratio: 2.693877551020408
Max-min Ratio: 3.6
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_00-18-27
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 572.0
  episode_reward_mean: 362.31
  episode_reward_min: 228.0
  episodes_this_iter: 1
  episodes_total: 299
  experiment_id: 35d66058da2d4c9882f832ee91e4aa4a
  hostname: gpu011
  info:
    apply_time_ms: 2.777
    dispatch_time_ms: 9.088
    learner:
      cur_lr: 0.0009617320029065013
      grad_gnorm: 40.0
      policy_entropy: 116.810791015625
      policy_loss: -9.34129524230957
      var_gnorm: 20.03837776184082
      vf_explained_var: 0.0
      vf_loss: 0.741981029510498
    num_steps_sampled: 6000000
    num_steps_trained: 6000000
    wait_time_ms: 264.928
  iterations_since_restore: 300
  node_ip: 172.17.8.11
  num_metric_batches_dropped: 0
  pid: 25504
  policy_reward_mean: {}
  time_since_restore: 8431.3790538311
  time_this_iter_s: 27.06931710243225
  time_total_s: 8431.3790538311
  timestamp: 1593922707
  timesteps_since_restore: 6000000
  timesteps_this_iter: 20000
  timesteps_total: 6000000
  training_iteration: 300
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=25504], 8431 s, 300 iter, 6000000 ts, 362 rew

agent-1: 16.0
agent-2: 19.0
agent-3: 11.0
agent-4: 24.0
agent-5: 26.0
agent-6: 11.0
agent-7: 16.0
agent-8: 21.0
agent-9: 19.0
agent-10: 20.0
agent-11: 28.0
agent-12: 31.0
agent-13: 19.0
agent-14: 41.0
agent-15: 20.0
agent-16: 14.0
agent-17: 14.0
agent-18: 18.0
agent-19: 23.0
agent-20: 20.0
Sum Reward: 411.0
Avg Reward: 20.55
Min Reward: 11.0
Gini Coefficient: 0.17725060827250608
20:20 Ratio: 2.52
Max-min Ratio: 3.727272727272727
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_00-18-54
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 572.0
  episode_reward_mean: 362.23
  episode_reward_min: 228.0
  episodes_this_iter: 1
  episodes_total: 300
  experiment_id: 35d66058da2d4c9882f832ee91e4aa4a
  hostname: gpu011
  info:
    apply_time_ms: 2.946
    dispatch_time_ms: 5.894
    learner:
      cur_lr: 0.0009603999787941575
      grad_gnorm: 40.0
      policy_entropy: 112.0090560913086
      policy_loss: 95.7391586303711
      var_gnorm: 20.03282356262207
      vf_explained_var: -2.384185791015625e-07
      vf_loss: 159.639892578125
    num_steps_sampled: 6020000
    num_steps_trained: 6020000
    wait_time_ms: 262.947
  iterations_since_restore: 301
  node_ip: 172.17.8.11
  num_metric_batches_dropped: 0
  pid: 25504
  policy_reward_mean: {}
  time_since_restore: 8458.873878955841
  time_this_iter_s: 27.4948251247406
  time_total_s: 8458.873878955841
  timestamp: 1593922734
  timesteps_since_restore: 6020000
  timesteps_this_iter: 20000
  timesteps_total: 6020000
  training_iteration: 301
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=25504], 8458 s, 301 iter, 6020000 ts, 362 rew

agent-1: 22.0
agent-2: 27.0
agent-3: 20.0
agent-4: 8.0
agent-5: 25.0
agent-6: 22.0
agent-7: 15.0
agent-8: 37.0
agent-9: 18.0
agent-10: 13.0
agent-11: 12.0
agent-12: 28.0
agent-13: 12.0
agent-14: 13.0
agent-15: 26.0
agent-16: 18.0
agent-17: 15.0
agent-18: 26.0
agent-19: 30.0
agent-20: 24.0
Sum Reward: 411.0
Avg Reward: 20.55
Min Reward: 8.0
Gini Coefficient: 0.1989051094890511
20:20 Ratio: 2.7111111111111112
Max-min Ratio: 4.625
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_00-19-22
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 572.0
  episode_reward_mean: 362.73
  episode_reward_min: 228.0
  episodes_this_iter: 1
  episodes_total: 301
  experiment_id: 35d66058da2d4c9882f832ee91e4aa4a
  hostname: gpu011
  info:
    apply_time_ms: 2.751
    dispatch_time_ms: 6.833
    learner:
      cur_lr: 0.0009590680128894746
      grad_gnorm: 37.91682815551758
      policy_entropy: 106.07280731201172
      policy_loss: -8.118368148803711
      var_gnorm: 20.041732788085938
      vf_explained_var: 1.1920928955078125e-07
      vf_loss: 0.5798220038414001
    num_steps_sampled: 6040000
    num_steps_trained: 6040000
    wait_time_ms: 268.675
  iterations_since_restore: 302
  node_ip: 172.17.8.11
  num_metric_batches_dropped: 0
  pid: 25504
  policy_reward_mean: {}
  time_since_restore: 8486.123401641846
  time_this_iter_s: 27.24952268600464
  time_total_s: 8486.123401641846
  timestamp: 1593922762
  timesteps_since_restore: 6040000
  timesteps_this_iter: 20000
  timesteps_total: 6040000
  training_iteration: 302
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=25504], 8486 s, 302 iter, 6040000 ts, 363 rew

agent-1: 13.0
agent-2: 5.0
agent-3: 16.0
agent-4: 24.0
agent-5: 5.0
agent-6: 24.0
agent-7: 19.0
agent-8: 39.0
agent-9: 18.0
agent-10: 16.0
agent-11: 21.0
agent-12: 34.0
agent-13: 15.0
agent-14: 12.0
agent-15: 11.0
agent-16: 8.0
agent-17: 6.0
agent-18: 13.0
agent-19: 25.0
agent-20: 6.0
Sum Reward: 330.0
Avg Reward: 16.5
Min Reward: 5.0
Gini Coefficient: 0.30424242424242426
20:20 Ratio: 5.545454545454546
Max-min Ratio: 7.8
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_00-19-50
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 572.0
  episode_reward_mean: 360.89
  episode_reward_min: 228.0
  episodes_this_iter: 1
  episodes_total: 302
  experiment_id: 35d66058da2d4c9882f832ee91e4aa4a
  hostname: gpu011
  info:
    apply_time_ms: 2.525
    dispatch_time_ms: 21.401
    learner:
      cur_lr: 0.0009577359887771308
      grad_gnorm: 39.99999237060547
      policy_entropy: 143.78857421875
      policy_loss: 44.9619026184082
      var_gnorm: 20.027280807495117
      vf_explained_var: 0.001113593578338623
      vf_loss: 91.49278259277344
    num_steps_sampled: 6060000
    num_steps_trained: 6060000
    wait_time_ms: 242.191
  iterations_since_restore: 303
  node_ip: 172.17.8.11
  num_metric_batches_dropped: 0
  pid: 25504
  policy_reward_mean: {}
  time_since_restore: 8514.867679595947
  time_this_iter_s: 28.744277954101562
  time_total_s: 8514.867679595947
  timestamp: 1593922790
  timesteps_since_restore: 6060000
  timesteps_this_iter: 20000
  timesteps_total: 6060000
  training_iteration: 303
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=25504], 8514 s, 303 iter, 6060000 ts, 361 rew

agent-1: 32.0
agent-2: 13.0
agent-3: 22.0
agent-4: 11.0
agent-5: 24.0
agent-6: 19.0
agent-7: 15.0
agent-8: 22.0
agent-9: 24.0
agent-10: 22.0
agent-11: 21.0
agent-12: 23.0
agent-13: 43.0
agent-14: 21.0
agent-15: 6.0
agent-16: 9.0
agent-17: 22.0
agent-18: 6.0
agent-19: 27.0
agent-20: 10.0
Sum Reward: 392.0
Avg Reward: 19.6
Min Reward: 6.0
Gini Coefficient: 0.24209183673469387
20:20 Ratio: 4.064516129032258
Max-min Ratio: 7.166666666666667
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_00-20-17
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 572.0
  episode_reward_mean: 361.5
  episode_reward_min: 228.0
  episodes_this_iter: 1
  episodes_total: 303
  experiment_id: 35d66058da2d4c9882f832ee91e4aa4a
  hostname: gpu011
  info:
    apply_time_ms: 3.267
    dispatch_time_ms: 6.482
    learner:
      cur_lr: 0.000956404022872448
      grad_gnorm: 40.0
      policy_entropy: 82.22541046142578
      policy_loss: -7.289418697357178
      var_gnorm: 20.044523239135742
      vf_explained_var: 0.0
      vf_loss: 1.036953330039978
    num_steps_sampled: 6080000
    num_steps_trained: 6080000
    wait_time_ms: 268.79
  iterations_since_restore: 304
  node_ip: 172.17.8.11
  num_metric_batches_dropped: 0
  pid: 25504
  policy_reward_mean: {}
  time_since_restore: 8541.597477436066
  time_this_iter_s: 26.729797840118408
  time_total_s: 8541.597477436066
  timestamp: 1593922817
  timesteps_since_restore: 6080000
  timesteps_this_iter: 20000
  timesteps_total: 6080000
  training_iteration: 304
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=25504], 8541 s, 304 iter, 6080000 ts, 362 rew

agent-1: 19.0
agent-2: 25.0
agent-3: 27.0
agent-4: 31.0
agent-5: 5.0
agent-6: 28.0
agent-7: 14.0
agent-8: 14.0
agent-9: 6.0
agent-10: 32.0
agent-11: 29.0
agent-12: 22.0
agent-13: 47.0
agent-14: 22.0
agent-15: 26.0
agent-16: 31.0
agent-17: 23.0
agent-18: 38.0
agent-19: 33.0
agent-20: 43.0
Sum Reward: 515.0
Avg Reward: 25.75
Min Reward: 5.0
Gini Coefficient: 0.2292233009708738
20:20 Ratio: 4.128205128205129
Max-min Ratio: 9.4
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_00-20-45
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 572.0
  episode_reward_mean: 362.52
  episode_reward_min: 228.0
  episodes_this_iter: 1
  episodes_total: 304
  experiment_id: 35d66058da2d4c9882f832ee91e4aa4a
  hostname: gpu011
  info:
    apply_time_ms: 2.97
    dispatch_time_ms: 7.492
    learner:
      cur_lr: 0.0009550719987601042
      grad_gnorm: 40.0
      policy_entropy: 88.05816650390625
      policy_loss: 75.85847473144531
      var_gnorm: 20.042835235595703
      vf_explained_var: -0.004917740821838379
      vf_loss: 294.2281494140625
    num_steps_sampled: 6100000
    num_steps_trained: 6100000
    wait_time_ms: 264.034
  iterations_since_restore: 305
  node_ip: 172.17.8.11
  num_metric_batches_dropped: 0
  pid: 25504
  policy_reward_mean: {}
  time_since_restore: 8569.117864847183
  time_this_iter_s: 27.520387411117554
  time_total_s: 8569.117864847183
  timestamp: 1593922845
  timesteps_since_restore: 6100000
  timesteps_this_iter: 20000
  timesteps_total: 6100000
  training_iteration: 305
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=25504], 8569 s, 305 iter, 6100000 ts, 363 rew

agent-1: 13.0
agent-2: 24.0
agent-3: 7.0
agent-4: 19.0
agent-5: 26.0
agent-6: 25.0
agent-7: 19.0
agent-8: 27.0
agent-9: 28.0
agent-10: 31.0
agent-11: 8.0
agent-12: 24.0
agent-13: 10.0
agent-14: 20.0
agent-15: 29.0
agent-16: 32.0
agent-17: 22.0
agent-18: 10.0
agent-19: 22.0
agent-20: 21.0
Sum Reward: 417.0
Avg Reward: 20.85
Min Reward: 7.0
Gini Coefficient: 0.20059952038369305
20:20 Ratio: 3.4285714285714284
Max-min Ratio: 4.571428571428571
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_00-21-11
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 572.0
  episode_reward_mean: 361.64
  episode_reward_min: 228.0
  episodes_this_iter: 1
  episodes_total: 305
  experiment_id: 35d66058da2d4c9882f832ee91e4aa4a
  hostname: gpu011
  info:
    apply_time_ms: 2.531
    dispatch_time_ms: 9.572
    learner:
      cur_lr: 0.0009537399746477604
      grad_gnorm: 40.0
      policy_entropy: 85.36905670166016
      policy_loss: -10.163814544677734
      var_gnorm: 20.06179428100586
      vf_explained_var: 0.0
      vf_loss: 1.2450807094573975
    num_steps_sampled: 6120000
    num_steps_trained: 6120000
    wait_time_ms: 260.177
  iterations_since_restore: 306
  node_ip: 172.17.8.11
  num_metric_batches_dropped: 0
  pid: 25504
  policy_reward_mean: {}
  time_since_restore: 8595.845646619797
  time_this_iter_s: 26.727781772613525
  time_total_s: 8595.845646619797
  timestamp: 1593922871
  timesteps_since_restore: 6120000
  timesteps_this_iter: 20000
  timesteps_total: 6120000
  training_iteration: 306
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=25504], 8595 s, 306 iter, 6120000 ts, 362 rew

agent-1: 17.0
agent-2: 48.0
agent-3: 19.0
agent-4: 27.0
agent-5: 18.0
agent-6: 22.0
agent-7: 29.0
agent-8: 32.0
agent-9: 44.0
agent-10: 29.0
agent-11: 42.0
agent-12: 14.0
agent-13: 37.0
agent-14: 33.0
agent-15: 29.0
agent-16: 28.0
agent-17: 25.0
agent-18: 15.0
agent-19: 6.0
agent-20: 20.0
Sum Reward: 534.0
Avg Reward: 26.7
Min Reward: 6.0
Gini Coefficient: 0.22153558052434458
20:20 Ratio: 3.2884615384615383
Max-min Ratio: 8.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_00-21-39
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 572.0
  episode_reward_mean: 364.01
  episode_reward_min: 228.0
  episodes_this_iter: 1
  episodes_total: 306
  experiment_id: 35d66058da2d4c9882f832ee91e4aa4a
  hostname: gpu011
  info:
    apply_time_ms: 2.58
    dispatch_time_ms: 6.652
    learner:
      cur_lr: 0.0009524080087430775
      grad_gnorm: 12.813518524169922
      policy_entropy: 139.5215606689453
      policy_loss: -3.7740273475646973
      var_gnorm: 20.035310745239258
      vf_explained_var: 0.0
      vf_loss: 0.06598559021949768
    num_steps_sampled: 6140000
    num_steps_trained: 6140000
    wait_time_ms: 268.982
  iterations_since_restore: 307
  node_ip: 172.17.8.11
  num_metric_batches_dropped: 0
  pid: 25504
  policy_reward_mean: {}
  time_since_restore: 8623.522478580475
  time_this_iter_s: 27.6768319606781
  time_total_s: 8623.522478580475
  timestamp: 1593922899
  timesteps_since_restore: 6140000
  timesteps_this_iter: 20000
  timesteps_total: 6140000
  training_iteration: 307
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=25504], 8623 s, 307 iter, 6140000 ts, 364 rew

agent-1: 22.0
agent-2: 8.0
agent-3: 13.0
agent-4: 8.0
agent-5: 19.0
agent-6: 2.0
agent-7: 29.0
agent-8: 7.0
agent-9: 29.0
agent-10: 34.0
agent-11: 28.0
agent-12: 8.0
agent-13: 24.0
agent-14: 17.0
agent-15: 15.0
agent-16: 29.0
agent-17: 12.0
agent-18: 25.0
agent-19: 13.0
agent-20: 22.0
Sum Reward: 364.0
Avg Reward: 18.2
Min Reward: 2.0
Gini Coefficient: 0.28186813186813187
20:20 Ratio: 4.84
Max-min Ratio: 17.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_00-22-06
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 572.0
  episode_reward_mean: 364.34
  episode_reward_min: 228.0
  episodes_this_iter: 1
  episodes_total: 307
  experiment_id: 35d66058da2d4c9882f832ee91e4aa4a
  hostname: gpu011
  info:
    apply_time_ms: 2.907
    dispatch_time_ms: 5.839
    learner:
      cur_lr: 0.0009510759846307337
      grad_gnorm: 34.51551055908203
      policy_entropy: 112.65029907226562
      policy_loss: -8.588605880737305
      var_gnorm: 20.04744529724121
      vf_explained_var: 0.0
      vf_loss: 0.47887924313545227
    num_steps_sampled: 6160000
    num_steps_trained: 6160000
    wait_time_ms: 265.291
  iterations_since_restore: 308
  node_ip: 172.17.8.11
  num_metric_batches_dropped: 0
  pid: 25504
  policy_reward_mean: {}
  time_since_restore: 8650.450363636017
  time_this_iter_s: 26.927885055541992
  time_total_s: 8650.450363636017
  timestamp: 1593922926
  timesteps_since_restore: 6160000
  timesteps_this_iter: 20000
  timesteps_total: 6160000
  training_iteration: 308
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=25504], 8650 s, 308 iter, 6160000 ts, 364 rew

agent-1: 38.0
agent-2: 33.0
agent-3: 27.0
agent-4: 18.0
agent-5: 19.0
agent-6: 34.0
agent-7: 17.0
agent-8: 11.0
agent-9: 9.0
agent-10: 17.0
agent-11: 24.0
agent-12: 27.0
agent-13: 12.0
agent-14: 19.0
agent-15: 22.0
agent-16: 11.0
agent-17: 43.0
agent-18: 15.0
agent-19: 4.0
agent-20: 3.0
Sum Reward: 403.0
Avg Reward: 20.15
Min Reward: 3.0
Gini Coefficient: 0.29838709677419356
20:20 Ratio: 5.481481481481482
Max-min Ratio: 14.333333333333334
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_00-22-34
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 572.0
  episode_reward_mean: 365.24
  episode_reward_min: 228.0
  episodes_this_iter: 1
  episodes_total: 308
  experiment_id: 35d66058da2d4c9882f832ee91e4aa4a
  hostname: gpu011
  info:
    apply_time_ms: 3.206
    dispatch_time_ms: 9.558
    learner:
      cur_lr: 0.0009497440187260509
      grad_gnorm: 2.842322587966919
      policy_entropy: 160.2847900390625
      policy_loss: -1.0813876390457153
      var_gnorm: 20.027332305908203
      vf_explained_var: 0.0
      vf_loss: 0.0032354893628507853
    num_steps_sampled: 6180000
    num_steps_trained: 6180000
    wait_time_ms: 264.577
  iterations_since_restore: 309
  node_ip: 172.17.8.11
  num_metric_batches_dropped: 0
  pid: 25504
  policy_reward_mean: {}
  time_since_restore: 8678.024100780487
  time_this_iter_s: 27.573737144470215
  time_total_s: 8678.024100780487
  timestamp: 1593922954
  timesteps_since_restore: 6180000
  timesteps_this_iter: 20000
  timesteps_total: 6180000
  training_iteration: 309
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=25504], 8678 s, 309 iter, 6180000 ts, 365 rew

agent-1: 12.0
agent-2: 14.0
agent-3: 25.0
agent-4: 13.0
agent-5: 16.0
agent-6: 10.0
agent-7: 22.0
agent-8: 1.0
agent-9: 9.0
agent-10: 8.0
agent-11: 17.0
agent-12: 21.0
agent-13: 11.0
agent-14: 23.0
agent-15: 4.0
agent-16: 32.0
agent-17: 23.0
agent-18: 22.0
agent-19: 19.0
agent-20: 19.0
Sum Reward: 321.0
Avg Reward: 16.05
Min Reward: 1.0
Gini Coefficient: 0.26370716510903425
20:20 Ratio: 4.681818181818182
Max-min Ratio: 32.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_00-23-01
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 572.0
  episode_reward_mean: 365.28
  episode_reward_min: 228.0
  episodes_this_iter: 1
  episodes_total: 309
  experiment_id: 35d66058da2d4c9882f832ee91e4aa4a
  hostname: gpu011
  info:
    apply_time_ms: 3.379
    dispatch_time_ms: 5.524
    learner:
      cur_lr: 0.0009484119946137071
      grad_gnorm: 39.999996185302734
      policy_entropy: 109.67826080322266
      policy_loss: 3.2059099674224854
      var_gnorm: 20.052135467529297
      vf_explained_var: 0.0
      vf_loss: 31.32599639892578
    num_steps_sampled: 6200000
    num_steps_trained: 6200000
    wait_time_ms: 273.558
  iterations_since_restore: 310
  node_ip: 172.17.8.11
  num_metric_batches_dropped: 0
  pid: 25504
  policy_reward_mean: {}
  time_since_restore: 8705.142482995987
  time_this_iter_s: 27.118382215499878
  time_total_s: 8705.142482995987
  timestamp: 1593922981
  timesteps_since_restore: 6200000
  timesteps_this_iter: 20000
  timesteps_total: 6200000
  training_iteration: 310
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=25504], 8705 s, 310 iter, 6200000 ts, 365 rew

agent-1: 15.0
agent-2: 7.0
agent-3: 19.0
agent-4: 11.0
agent-5: 39.0
agent-6: 16.0
agent-7: 17.0
agent-8: 17.0
agent-9: 10.0
agent-10: 30.0
agent-11: 24.0
agent-12: 21.0
agent-13: 18.0
agent-14: 12.0
agent-15: 37.0
agent-16: 11.0
agent-17: 13.0
agent-18: 14.0
agent-19: 25.0
agent-20: 16.0
Sum Reward: 372.0
Avg Reward: 18.6
Min Reward: 7.0
Gini Coefficient: 0.24086021505376345
20:20 Ratio: 3.358974358974359
Max-min Ratio: 5.571428571428571
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_00-23-29
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 572.0
  episode_reward_mean: 366.29
  episode_reward_min: 228.0
  episodes_this_iter: 1
  episodes_total: 310
  experiment_id: 35d66058da2d4c9882f832ee91e4aa4a
  hostname: gpu011
  info:
    apply_time_ms: 3.012
    dispatch_time_ms: 6.287
    learner:
      cur_lr: 0.0009470800287090242
      grad_gnorm: 40.0
      policy_entropy: 137.0887908935547
      policy_loss: 21.73711395263672
      var_gnorm: 20.037456512451172
      vf_explained_var: 0.0
      vf_loss: 22.932350158691406
    num_steps_sampled: 6220000
    num_steps_trained: 6220000
    wait_time_ms: 259.486
  iterations_since_restore: 311
  node_ip: 172.17.8.11
  num_metric_batches_dropped: 0
  pid: 25504
  policy_reward_mean: {}
  time_since_restore: 8732.786490678787
  time_this_iter_s: 27.644007682800293
  time_total_s: 8732.786490678787
  timestamp: 1593923009
  timesteps_since_restore: 6220000
  timesteps_this_iter: 20000
  timesteps_total: 6220000
  training_iteration: 311
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=25504], 8732 s, 311 iter, 6220000 ts, 366 rew

agent-1: 16.0
agent-2: 23.0
agent-3: 20.0
agent-4: 7.0
agent-5: 18.0
agent-6: 13.0
agent-7: 26.0
agent-8: 26.0
agent-9: 19.0
agent-10: 0.0
agent-11: 20.0
agent-12: 11.0
agent-13: 14.0
agent-14: 25.0
agent-15: 20.0
agent-16: 23.0
agent-17: 6.0
agent-18: 28.0
agent-19: 14.0
agent-20: 10.0
Sum Reward: 339.0
Avg Reward: 16.95
Min Reward: 0.0
Gini Coefficient: 0.24469026548672565
20:20 Ratio: 4.565217391304348
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_00-23-55
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 572.0
  episode_reward_mean: 366.6
  episode_reward_min: 228.0
  episodes_this_iter: 1
  episodes_total: 311
  experiment_id: 35d66058da2d4c9882f832ee91e4aa4a
  hostname: gpu011
  info:
    apply_time_ms: 3.023
    dispatch_time_ms: 6.437
    learner:
      cur_lr: 0.0009457480045966804
      grad_gnorm: 40.0
      policy_entropy: 152.6786346435547
      policy_loss: -12.01651668548584
      var_gnorm: 20.050119400024414
      vf_explained_var: 1.1920928955078125e-07
      vf_loss: 0.7769612073898315
    num_steps_sampled: 6240000
    num_steps_trained: 6240000
    wait_time_ms: 265.248
  iterations_since_restore: 312
  node_ip: 172.17.8.11
  num_metric_batches_dropped: 0
  pid: 25504
  policy_reward_mean: {}
  time_since_restore: 8759.559599637985
  time_this_iter_s: 26.773108959197998
  time_total_s: 8759.559599637985
  timestamp: 1593923035
  timesteps_since_restore: 6240000
  timesteps_this_iter: 20000
  timesteps_total: 6240000
  training_iteration: 312
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=25504], 8759 s, 312 iter, 6240000 ts, 367 rew

agent-1: 18.0
agent-2: 30.0
agent-3: 40.0
agent-4: 45.0
agent-5: 10.0
agent-6: 2.0
agent-7: 23.0
agent-8: 49.0
agent-9: 24.0
agent-10: 20.0
agent-11: 14.0
agent-12: 18.0
agent-13: 22.0
agent-14: 16.0
agent-15: 18.0
agent-16: 23.0
agent-17: 9.0
agent-18: 29.0
agent-19: 54.0
agent-20: 12.0
Sum Reward: 476.0
Avg Reward: 23.8
Min Reward: 2.0
Gini Coefficient: 0.3081932773109244
20:20 Ratio: 5.696969696969697
Max-min Ratio: 27.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_00-24-23
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 572.0
  episode_reward_mean: 368.33
  episode_reward_min: 228.0
  episodes_this_iter: 1
  episodes_total: 312
  experiment_id: 35d66058da2d4c9882f832ee91e4aa4a
  hostname: gpu011
  info:
    apply_time_ms: 3.599
    dispatch_time_ms: 7.161
    learner:
      cur_lr: 0.0009444159804843366
      grad_gnorm: 40.000003814697266
      policy_entropy: 165.50611877441406
      policy_loss: 115.39154052734375
      var_gnorm: 20.0302677154541
      vf_explained_var: 1.7881393432617188e-07
      vf_loss: 183.70018005371094
    num_steps_sampled: 6260000
    num_steps_trained: 6260000
    wait_time_ms: 245.36
  iterations_since_restore: 313
  node_ip: 172.17.8.11
  num_metric_batches_dropped: 0
  pid: 25504
  policy_reward_mean: {}
  time_since_restore: 8787.336352348328
  time_this_iter_s: 27.776752710342407
  time_total_s: 8787.336352348328
  timestamp: 1593923063
  timesteps_since_restore: 6260000
  timesteps_this_iter: 20000
  timesteps_total: 6260000
  training_iteration: 313
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=25504], 8787 s, 313 iter, 6260000 ts, 368 rew

agent-1: 5.0
agent-2: 18.0
agent-3: 15.0
agent-4: 26.0
agent-5: 33.0
agent-6: 14.0
agent-7: 11.0
agent-8: 18.0
agent-9: 18.0
agent-10: 20.0
agent-11: 13.0
agent-12: 12.0
agent-13: 15.0
agent-14: 5.0
agent-15: 18.0
agent-16: 22.0
agent-17: 5.0
agent-18: 12.0
agent-19: 9.0
agent-20: 14.0
Sum Reward: 303.0
Avg Reward: 15.15
Min Reward: 5.0
Gini Coefficient: 0.2457095709570957
20:20 Ratio: 4.208333333333333
Max-min Ratio: 6.6
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_00-24-50
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 572.0
  episode_reward_mean: 366.33
  episode_reward_min: 228.0
  episodes_this_iter: 1
  episodes_total: 313
  experiment_id: 35d66058da2d4c9882f832ee91e4aa4a
  hostname: gpu011
  info:
    apply_time_ms: 2.696
    dispatch_time_ms: 5.79
    learner:
      cur_lr: 0.0009430840145796537
      grad_gnorm: 31.754047393798828
      policy_entropy: 108.1441421508789
      policy_loss: 0.9899449348449707
      var_gnorm: 20.05586051940918
      vf_explained_var: 0.0
      vf_loss: 14.948246955871582
    num_steps_sampled: 6280000
    num_steps_trained: 6280000
    wait_time_ms: 269.568
  iterations_since_restore: 314
  node_ip: 172.17.8.11
  num_metric_batches_dropped: 0
  pid: 25504
  policy_reward_mean: {}
  time_since_restore: 8814.186814785004
  time_this_iter_s: 26.850462436676025
  time_total_s: 8814.186814785004
  timestamp: 1593923090
  timesteps_since_restore: 6280000
  timesteps_this_iter: 20000
  timesteps_total: 6280000
  training_iteration: 314
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=25504], 8814 s, 314 iter, 6280000 ts, 366 rew

agent-1: 49.0
agent-2: 20.0
agent-3: 10.0
agent-4: 23.0
agent-5: 16.0
agent-6: 17.0
agent-7: 20.0
agent-8: 8.0
agent-9: 5.0
agent-10: 22.0
agent-11: 10.0
agent-12: 23.0
agent-13: 25.0
agent-14: 28.0
agent-15: 33.0
agent-16: 26.0
agent-17: 22.0
agent-18: 20.0
agent-19: 28.0
agent-20: 13.0
Sum Reward: 418.0
Avg Reward: 20.9
Min Reward: 5.0
Gini Coefficient: 0.24569377990430621
20:20 Ratio: 4.181818181818182
Max-min Ratio: 9.8
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_00-25-18
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 572.0
  episode_reward_mean: 367.13
  episode_reward_min: 228.0
  episodes_this_iter: 1
  episodes_total: 314
  experiment_id: 35d66058da2d4c9882f832ee91e4aa4a
  hostname: gpu011
  info:
    apply_time_ms: 3.152
    dispatch_time_ms: 6.032
    learner:
      cur_lr: 0.00094175199046731
      grad_gnorm: 40.0
      policy_entropy: 133.94949340820312
      policy_loss: 107.9625473022461
      var_gnorm: 20.056350708007812
      vf_explained_var: 0.0
      vf_loss: 168.43600463867188
    num_steps_sampled: 6300000
    num_steps_trained: 6300000
    wait_time_ms: 260.343
  iterations_since_restore: 315
  node_ip: 172.17.8.11
  num_metric_batches_dropped: 0
  pid: 25504
  policy_reward_mean: {}
  time_since_restore: 8841.956478834152
  time_this_iter_s: 27.76966404914856
  time_total_s: 8841.956478834152
  timestamp: 1593923118
  timesteps_since_restore: 6300000
  timesteps_this_iter: 20000
  timesteps_total: 6300000
  training_iteration: 315
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=25504], 8841 s, 315 iter, 6300000 ts, 367 rew

agent-1: 18.0
agent-2: 20.0
agent-3: 3.0
agent-4: 15.0
agent-5: 36.0
agent-6: 2.0
agent-7: 4.0
agent-8: 14.0
agent-9: 16.0
agent-10: 16.0
agent-11: 28.0
agent-12: 5.0
agent-13: 15.0
agent-14: 38.0
agent-15: 6.0
agent-16: 32.0
agent-17: 21.0
agent-18: 29.0
agent-19: 8.0
agent-20: 32.0
Sum Reward: 358.0
Avg Reward: 17.9
Min Reward: 2.0
Gini Coefficient: 0.3536312849162011
20:20 Ratio: 9.857142857142858
Max-min Ratio: 19.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_00-25-45
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 572.0
  episode_reward_mean: 367.17
  episode_reward_min: 228.0
  episodes_this_iter: 1
  episodes_total: 315
  experiment_id: 35d66058da2d4c9882f832ee91e4aa4a
  hostname: gpu011
  info:
    apply_time_ms: 3.795
    dispatch_time_ms: 6.568
    learner:
      cur_lr: 0.0009404200245626271
      grad_gnorm: 35.87089920043945
      policy_entropy: 133.95361328125
      policy_loss: -10.725573539733887
      var_gnorm: 20.048791885375977
      vf_explained_var: 0.0
      vf_loss: 0.5115942358970642
    num_steps_sampled: 6320000
    num_steps_trained: 6320000
    wait_time_ms: 265.858
  iterations_since_restore: 316
  node_ip: 172.17.8.11
  num_metric_batches_dropped: 0
  pid: 25504
  policy_reward_mean: {}
  time_since_restore: 8869.17450094223
  time_this_iter_s: 27.218022108078003
  time_total_s: 8869.17450094223
  timestamp: 1593923145
  timesteps_since_restore: 6320000
  timesteps_this_iter: 20000
  timesteps_total: 6320000
  training_iteration: 316
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=25504], 8869 s, 316 iter, 6320000 ts, 367 rew

agent-1: 10.0
agent-2: 17.0
agent-3: 5.0
agent-4: 27.0
agent-5: 19.0
agent-6: 26.0
agent-7: 17.0
agent-8: 15.0
agent-9: 9.0
agent-10: 15.0
agent-11: 6.0
agent-12: 5.0
agent-13: 8.0
agent-14: 29.0
agent-15: 15.0
agent-16: 10.0
agent-17: 13.0
agent-18: 25.0
agent-19: 16.0
agent-20: 22.0
Sum Reward: 309.0
Avg Reward: 15.45
Min Reward: 5.0
Gini Coefficient: 0.26650485436893206
20:20 Ratio: 4.458333333333333
Max-min Ratio: 5.8
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_00-26-13
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 572.0
  episode_reward_mean: 366.59
  episode_reward_min: 228.0
  episodes_this_iter: 1
  episodes_total: 316
  experiment_id: 35d66058da2d4c9882f832ee91e4aa4a
  hostname: gpu011
  info:
    apply_time_ms: 3.286
    dispatch_time_ms: 7.559
    learner:
      cur_lr: 0.0009390880004502833
      grad_gnorm: 0.7026933431625366
      policy_entropy: 147.44264221191406
      policy_loss: 0.12080554664134979
      var_gnorm: 20.04827308654785
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 0.00013333247625268996
    num_steps_sampled: 6340000
    num_steps_trained: 6340000
    wait_time_ms: 274.622
  iterations_since_restore: 317
  node_ip: 172.17.8.11
  num_metric_batches_dropped: 0
  pid: 25504
  policy_reward_mean: {}
  time_since_restore: 8896.941930532455
  time_this_iter_s: 27.76742959022522
  time_total_s: 8896.941930532455
  timestamp: 1593923173
  timesteps_since_restore: 6340000
  timesteps_this_iter: 20000
  timesteps_total: 6340000
  training_iteration: 317
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=25504], 8896 s, 317 iter, 6340000 ts, 367 rew

agent-1: 30.0
agent-2: 24.0
agent-3: 23.0
agent-4: 17.0
agent-5: 10.0
agent-6: 25.0
agent-7: 19.0
agent-8: 11.0
agent-9: 19.0
agent-10: 9.0
agent-11: 9.0
agent-12: 7.0
agent-13: 34.0
agent-14: 10.0
agent-15: 8.0
agent-16: 17.0
agent-17: 1.0
agent-18: 12.0
agent-19: 25.0
agent-20: 23.0
Sum Reward: 333.0
Avg Reward: 16.65
Min Reward: 1.0
Gini Coefficient: 0.2875375375375375
20:20 Ratio: 4.56
Max-min Ratio: 34.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_00-26-40
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 572.0
  episode_reward_mean: 365.89
  episode_reward_min: 228.0
  episodes_this_iter: 1
  episodes_total: 317
  experiment_id: 35d66058da2d4c9882f832ee91e4aa4a
  hostname: gpu011
  info:
    apply_time_ms: 3.108
    dispatch_time_ms: 7.008
    learner:
      cur_lr: 0.0009377559763379395
      grad_gnorm: 16.729347229003906
      policy_entropy: 107.59749603271484
      policy_loss: -1.5492979288101196
      var_gnorm: 20.05477523803711
      vf_explained_var: -2.384185791015625e-07
      vf_loss: 14.447949409484863
    num_steps_sampled: 6360000
    num_steps_trained: 6360000
    wait_time_ms: 260.792
  iterations_since_restore: 318
  node_ip: 172.17.8.11
  num_metric_batches_dropped: 0
  pid: 25504
  policy_reward_mean: {}
  time_since_restore: 8923.72208070755
  time_this_iter_s: 26.780150175094604
  time_total_s: 8923.72208070755
  timestamp: 1593923200
  timesteps_since_restore: 6360000
  timesteps_this_iter: 20000
  timesteps_total: 6360000
  training_iteration: 318
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=25504], 8923 s, 318 iter, 6360000 ts, 366 rew

agent-1: 19.0
agent-2: 19.0
agent-3: 32.0
agent-4: 19.0
agent-5: 20.0
agent-6: 21.0
agent-7: 27.0
agent-8: 19.0
agent-9: 9.0
agent-10: 20.0
agent-11: 20.0
agent-12: 29.0
agent-13: 48.0
agent-14: 22.0
agent-15: 26.0
agent-16: 27.0
agent-17: 20.0
agent-18: 16.0
agent-19: 29.0
agent-20: 28.0
Sum Reward: 470.0
Avg Reward: 23.5
Min Reward: 9.0
Gini Coefficient: 0.16489361702127658
20:20 Ratio: 2.1904761904761907
Max-min Ratio: 5.333333333333333
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_00-27-07
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 572.0
  episode_reward_mean: 367.12
  episode_reward_min: 228.0
  episodes_this_iter: 1
  episodes_total: 318
  experiment_id: 35d66058da2d4c9882f832ee91e4aa4a
  hostname: gpu011
  info:
    apply_time_ms: 2.319
    dispatch_time_ms: 6.169
    learner:
      cur_lr: 0.0009364240104332566
      grad_gnorm: 40.000003814697266
      policy_entropy: 159.58059692382812
      policy_loss: 81.33642578125
      var_gnorm: 20.047805786132812
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 68.73324584960938
    num_steps_sampled: 6380000
    num_steps_trained: 6380000
    wait_time_ms: 264.66
  iterations_since_restore: 319
  node_ip: 172.17.8.11
  num_metric_batches_dropped: 0
  pid: 25504
  policy_reward_mean: {}
  time_since_restore: 8951.06371307373
  time_this_iter_s: 27.34163236618042
  time_total_s: 8951.06371307373
  timestamp: 1593923227
  timesteps_since_restore: 6380000
  timesteps_this_iter: 20000
  timesteps_total: 6380000
  training_iteration: 319
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=25504], 8951 s, 319 iter, 6380000 ts, 367 rew

agent-1: 31.0
agent-2: 29.0
agent-3: 20.0
agent-4: 45.0
agent-5: 26.0
agent-6: 25.0
agent-7: 24.0
agent-8: 30.0
agent-9: 28.0
agent-10: 19.0
agent-11: 7.0
agent-12: 19.0
agent-13: 16.0
agent-14: 17.0
agent-15: 41.0
agent-16: 30.0
agent-17: 14.0
agent-18: 29.0
agent-19: 19.0
agent-20: 21.0
Sum Reward: 490.0
Avg Reward: 24.5
Min Reward: 7.0
Gini Coefficient: 0.19510204081632654
20:20 Ratio: 2.7222222222222223
Max-min Ratio: 6.428571428571429
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_00-27-34
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 572.0
  episode_reward_mean: 367.88
  episode_reward_min: 228.0
  episodes_this_iter: 1
  episodes_total: 319
  experiment_id: 35d66058da2d4c9882f832ee91e4aa4a
  hostname: gpu011
  info:
    apply_time_ms: 3.572
    dispatch_time_ms: 7.124
    learner:
      cur_lr: 0.0009350919863209128
      grad_gnorm: 24.811872482299805
      policy_entropy: 152.1680450439453
      policy_loss: -7.222309589385986
      var_gnorm: 20.048791885375977
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 0.2471596598625183
    num_steps_sampled: 6400000
    num_steps_trained: 6400000
    wait_time_ms: 282.621
  iterations_since_restore: 320
  node_ip: 172.17.8.11
  num_metric_batches_dropped: 0
  pid: 25504
  policy_reward_mean: {}
  time_since_restore: 8978.232474565506
  time_this_iter_s: 27.168761491775513
  time_total_s: 8978.232474565506
  timestamp: 1593923254
  timesteps_since_restore: 6400000
  timesteps_this_iter: 20000
  timesteps_total: 6400000
  training_iteration: 320
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=25504], 8978 s, 320 iter, 6400000 ts, 368 rew

agent-1: 25.0
agent-2: 13.0
agent-3: 2.0
agent-4: 1.0
agent-5: 5.0
agent-6: 14.0
agent-7: 14.0
agent-8: 14.0
agent-9: 4.0
agent-10: 24.0
agent-11: 5.0
agent-12: 26.0
agent-13: 10.0
agent-14: 11.0
agent-15: 27.0
agent-16: 6.0
agent-17: 16.0
agent-18: 9.0
agent-19: 20.0
agent-20: 11.0
Sum Reward: 257.0
Avg Reward: 12.85
Min Reward: 1.0
Gini Coefficient: 0.3472762645914397
20:20 Ratio: 8.5
Max-min Ratio: 27.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_00-28-02
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 572.0
  episode_reward_mean: 367.12
  episode_reward_min: 228.0
  episodes_this_iter: 1
  episodes_total: 320
  experiment_id: 35d66058da2d4c9882f832ee91e4aa4a
  hostname: gpu011
  info:
    apply_time_ms: 3.2
    dispatch_time_ms: 6.794
    learner:
      cur_lr: 0.00093376002041623
      grad_gnorm: 40.0
      policy_entropy: 162.42025756835938
      policy_loss: 72.62889862060547
      var_gnorm: 20.047975540161133
      vf_explained_var: 0.0
      vf_loss: 72.70314025878906
    num_steps_sampled: 6420000
    num_steps_trained: 6420000
    wait_time_ms: 253.607
  iterations_since_restore: 321
  node_ip: 172.17.8.11
  num_metric_batches_dropped: 0
  pid: 25504
  policy_reward_mean: {}
  time_since_restore: 9005.870308160782
  time_this_iter_s: 27.63783359527588
  time_total_s: 9005.870308160782
  timestamp: 1593923282
  timesteps_since_restore: 6420000
  timesteps_this_iter: 20000
  timesteps_total: 6420000
  training_iteration: 321
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=25504], 9005 s, 321 iter, 6420000 ts, 367 rew

agent-1: 6.0
agent-2: 31.0
agent-3: 7.0
agent-4: 16.0
agent-5: 13.0
agent-6: 18.0
agent-7: 16.0
agent-8: 10.0
agent-9: 14.0
agent-10: 9.0
agent-11: 29.0
agent-12: 4.0
agent-13: 18.0
agent-14: 25.0
agent-15: 9.0
agent-16: 11.0
agent-17: 17.0
agent-18: 15.0
agent-19: 9.0
agent-20: 29.0
Sum Reward: 306.0
Avg Reward: 15.3
Min Reward: 4.0
Gini Coefficient: 0.27875816993464053
20:20 Ratio: 4.384615384615385
Max-min Ratio: 7.75
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_00-28-29
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 572.0
  episode_reward_mean: 366.83
  episode_reward_min: 228.0
  episodes_this_iter: 1
  episodes_total: 321
  experiment_id: 35d66058da2d4c9882f832ee91e4aa4a
  hostname: gpu011
  info:
    apply_time_ms: 2.807
    dispatch_time_ms: 7.762
    learner:
      cur_lr: 0.0009324279963038862
      grad_gnorm: 40.0
      policy_entropy: 170.42005920410156
      policy_loss: 38.9354133605957
      var_gnorm: 20.05108070373535
      vf_explained_var: 0.0
      vf_loss: 68.6396255493164
    num_steps_sampled: 6440000
    num_steps_trained: 6440000
    wait_time_ms: 267.417
  iterations_since_restore: 322
  node_ip: 172.17.8.11
  num_metric_batches_dropped: 0
  pid: 25504
  policy_reward_mean: {}
  time_since_restore: 9032.790126085281
  time_this_iter_s: 26.91981792449951
  time_total_s: 9032.790126085281
  timestamp: 1593923309
  timesteps_since_restore: 6440000
  timesteps_this_iter: 20000
  timesteps_total: 6440000
  training_iteration: 322
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=25504], 9032 s, 322 iter, 6440000 ts, 367 rew

agent-1: 25.0
agent-2: 16.0
agent-3: 16.0
agent-4: 22.0
agent-5: 5.0
agent-6: 9.0
agent-7: 4.0
agent-8: 25.0
agent-9: 19.0
agent-10: 22.0
agent-11: 9.0
agent-12: 9.0
agent-13: 15.0
agent-14: 15.0
agent-15: 14.0
agent-16: 15.0
agent-17: 16.0
agent-18: 19.0
agent-19: 25.0
agent-20: 6.0
Sum Reward: 306.0
Avg Reward: 15.3
Min Reward: 4.0
Gini Coefficient: 0.24019607843137256
20:20 Ratio: 4.041666666666667
Max-min Ratio: 6.25
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_00-28-57
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 572.0
  episode_reward_mean: 366.3
  episode_reward_min: 228.0
  episodes_this_iter: 1
  episodes_total: 322
  experiment_id: 35d66058da2d4c9882f832ee91e4aa4a
  hostname: gpu011
  info:
    apply_time_ms: 3.072
    dispatch_time_ms: 6.688
    learner:
      cur_lr: 0.0009310959721915424
      grad_gnorm: 39.999996185302734
      policy_entropy: 196.7215576171875
      policy_loss: 141.66036987304688
      var_gnorm: 20.048065185546875
      vf_explained_var: 1.1920928955078125e-07
      vf_loss: 182.77928161621094
    num_steps_sampled: 6460000
    num_steps_trained: 6460000
    wait_time_ms: 257.692
  iterations_since_restore: 323
  node_ip: 172.17.8.11
  num_metric_batches_dropped: 0
  pid: 25504
  policy_reward_mean: {}
  time_since_restore: 9060.465060472488
  time_this_iter_s: 27.67493438720703
  time_total_s: 9060.465060472488
  timestamp: 1593923337
  timesteps_since_restore: 6460000
  timesteps_this_iter: 20000
  timesteps_total: 6460000
  training_iteration: 323
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=25504], 9060 s, 323 iter, 6460000 ts, 366 rew

agent-1: 20.0
agent-2: 24.0
agent-3: 15.0
agent-4: 23.0
agent-5: 29.0
agent-6: 21.0
agent-7: 17.0
agent-8: 28.0
agent-9: 22.0
agent-10: 1.0
agent-11: 23.0
agent-12: 23.0
agent-13: 28.0
agent-14: 18.0
agent-15: 40.0
agent-16: 18.0
agent-17: 38.0
agent-18: 36.0
agent-19: 13.0
agent-20: 16.0
Sum Reward: 453.0
Avg Reward: 22.65
Min Reward: 1.0
Gini Coefficient: 0.21247240618101546
20:20 Ratio: 3.1777777777777776
Max-min Ratio: 40.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_00-29-26
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 572.0
  episode_reward_mean: 365.9
  episode_reward_min: 228.0
  episodes_this_iter: 1
  episodes_total: 323
  experiment_id: 35d66058da2d4c9882f832ee91e4aa4a
  hostname: gpu011
  info:
    apply_time_ms: 2.625
    dispatch_time_ms: 6.748
    learner:
      cur_lr: 0.0009297640062868595
      grad_gnorm: 36.51693344116211
      policy_entropy: 171.4847869873047
      policy_loss: -11.421957015991211
      var_gnorm: 20.053272247314453
      vf_explained_var: 0.0
      vf_loss: 2.869389772415161
    num_steps_sampled: 6480000
    num_steps_trained: 6480000
    wait_time_ms: 277.083
  iterations_since_restore: 324
  node_ip: 172.17.8.11
  num_metric_batches_dropped: 0
  pid: 25504
  policy_reward_mean: {}
  time_since_restore: 9089.695066213608
  time_this_iter_s: 29.230005741119385
  time_total_s: 9089.695066213608
  timestamp: 1593923366
  timesteps_since_restore: 6480000
  timesteps_this_iter: 20000
  timesteps_total: 6480000
  training_iteration: 324
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=25504], 9089 s, 324 iter, 6480000 ts, 366 rew

agent-1: 16.0
agent-2: 25.0
agent-3: 5.0
agent-4: 25.0
agent-5: 14.0
agent-6: 31.0
agent-7: 15.0
agent-8: 15.0
agent-9: 15.0
agent-10: 10.0
agent-11: 10.0
agent-12: 10.0
agent-13: 11.0
agent-14: 12.0
agent-15: 30.0
agent-16: 25.0
agent-17: 22.0
agent-18: 16.0
agent-19: 24.0
agent-20: 24.0
Sum Reward: 355.0
Avg Reward: 17.75
Min Reward: 5.0
Gini Coefficient: 0.22887323943661972
20:20 Ratio: 3.1714285714285713
Max-min Ratio: 6.2
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_00-29-54
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 572.0
  episode_reward_mean: 365.74
  episode_reward_min: 228.0
  episodes_this_iter: 1
  episodes_total: 324
  experiment_id: 35d66058da2d4c9882f832ee91e4aa4a
  hostname: gpu011
  info:
    apply_time_ms: 2.899
    dispatch_time_ms: 7.074
    learner:
      cur_lr: 0.0009284319821745157
      grad_gnorm: 0.7549717426300049
      policy_entropy: 170.285400390625
      policy_loss: -0.2761760652065277
      var_gnorm: 20.0504150390625
      vf_explained_var: 1.1920928955078125e-07
      vf_loss: 0.00021418480901047587
    num_steps_sampled: 6500000
    num_steps_trained: 6500000
    wait_time_ms: 261.268
  iterations_since_restore: 325
  node_ip: 172.17.8.11
  num_metric_batches_dropped: 0
  pid: 25504
  policy_reward_mean: {}
  time_since_restore: 9117.328336000443
  time_this_iter_s: 27.633269786834717
  time_total_s: 9117.328336000443
  timestamp: 1593923394
  timesteps_since_restore: 6500000
  timesteps_this_iter: 20000
  timesteps_total: 6500000
  training_iteration: 325
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=25504], 9117 s, 325 iter, 6500000 ts, 366 rew

agent-1: 11.0
agent-2: 31.0
agent-3: 23.0
agent-4: 24.0
agent-5: 12.0
agent-6: 2.0
agent-7: 14.0
agent-8: 12.0
agent-9: 12.0
agent-10: 21.0
agent-11: 10.0
agent-12: 4.0
agent-13: 25.0
agent-14: 13.0
agent-15: 18.0
agent-16: 6.0
agent-17: 14.0
agent-18: 9.0
agent-19: 28.0
agent-20: 21.0
Sum Reward: 310.0
Avg Reward: 15.5
Min Reward: 2.0
Gini Coefficient: 0.28580645161290325
20:20 Ratio: 5.142857142857143
Max-min Ratio: 15.5
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_00-30-21
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 572.0
  episode_reward_mean: 365.93
  episode_reward_min: 228.0
  episodes_this_iter: 1
  episodes_total: 325
  experiment_id: 35d66058da2d4c9882f832ee91e4aa4a
  hostname: gpu011
  info:
    apply_time_ms: 2.625
    dispatch_time_ms: 7.086
    learner:
      cur_lr: 0.0009271000162698328
      grad_gnorm: 40.000003814697266
      policy_entropy: 165.91685485839844
      policy_loss: 15.813860893249512
      var_gnorm: 20.053462982177734
      vf_explained_var: 2.384185791015625e-07
      vf_loss: 20.08673858642578
    num_steps_sampled: 6520000
    num_steps_trained: 6520000
    wait_time_ms: 273.093
  iterations_since_restore: 326
  node_ip: 172.17.8.11
  num_metric_batches_dropped: 0
  pid: 25504
  policy_reward_mean: {}
  time_since_restore: 9144.53280544281
  time_this_iter_s: 27.204469442367554
  time_total_s: 9144.53280544281
  timestamp: 1593923421
  timesteps_since_restore: 6520000
  timesteps_this_iter: 20000
  timesteps_total: 6520000
  training_iteration: 326
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=25504], 9144 s, 326 iter, 6520000 ts, 366 rew

agent-1: 21.0
agent-2: 15.0
agent-3: 14.0
agent-4: 15.0
agent-5: 19.0
agent-6: 22.0
agent-7: 26.0
agent-8: 30.0
agent-9: 2.0
agent-10: 20.0
agent-11: 11.0
agent-12: 15.0
agent-13: 19.0
agent-14: 16.0
agent-15: 24.0
agent-16: 10.0
agent-17: 10.0
agent-18: 25.0
agent-19: 18.0
agent-20: 6.0
Sum Reward: 338.0
Avg Reward: 16.9
Min Reward: 2.0
Gini Coefficient: 0.22662721893491125
20:20 Ratio: 3.75
Max-min Ratio: 15.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_00-30-49
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 572.0
  episode_reward_mean: 365.63
  episode_reward_min: 228.0
  episodes_this_iter: 1
  episodes_total: 326
  experiment_id: 35d66058da2d4c9882f832ee91e4aa4a
  hostname: gpu011
  info:
    apply_time_ms: 3.233
    dispatch_time_ms: 9.143
    learner:
      cur_lr: 0.0009257679921574891
      grad_gnorm: 1.4998195171356201
      policy_entropy: 172.64608764648438
      policy_loss: -0.518359899520874
      var_gnorm: 20.050199508666992
      vf_explained_var: 0.0
      vf_loss: 0.0008370942086912692
    num_steps_sampled: 6540000
    num_steps_trained: 6540000
    wait_time_ms: 266.53
  iterations_since_restore: 327
  node_ip: 172.17.8.11
  num_metric_batches_dropped: 0
  pid: 25504
  policy_reward_mean: {}
  time_since_restore: 9172.282986402512
  time_this_iter_s: 27.750180959701538
  time_total_s: 9172.282986402512
  timestamp: 1593923449
  timesteps_since_restore: 6540000
  timesteps_this_iter: 20000
  timesteps_total: 6540000
  training_iteration: 327
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=25504], 9172 s, 327 iter, 6540000 ts, 366 rew

agent-1: 13.0
agent-2: 11.0
agent-3: 9.0
agent-4: 21.0
agent-5: 20.0
agent-6: 5.0
agent-7: 26.0
agent-8: 6.0
agent-9: 30.0
agent-10: 13.0
agent-11: 14.0
agent-12: 4.0
agent-13: 20.0
agent-14: 25.0
agent-15: 15.0
agent-16: 19.0
agent-17: 11.0
agent-18: 3.0
agent-19: 22.0
agent-20: 19.0
Sum Reward: 306.0
Avg Reward: 15.3
Min Reward: 3.0
Gini Coefficient: 0.28104575163398693
20:20 Ratio: 5.722222222222222
Max-min Ratio: 10.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_00-31-16
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 572.0
  episode_reward_mean: 365.71
  episode_reward_min: 228.0
  episodes_this_iter: 1
  episodes_total: 327
  experiment_id: 35d66058da2d4c9882f832ee91e4aa4a
  hostname: gpu011
  info:
    apply_time_ms: 2.777
    dispatch_time_ms: 5.836
    learner:
      cur_lr: 0.0009244360262528062
      grad_gnorm: 30.111177444458008
      policy_entropy: 155.42312622070312
      policy_loss: -8.341724395751953
      var_gnorm: 20.050764083862305
      vf_explained_var: 5.960464477539063e-08
      vf_loss: 0.36348509788513184
    num_steps_sampled: 6560000
    num_steps_trained: 6560000
    wait_time_ms: 268.345
  iterations_since_restore: 328
  node_ip: 172.17.8.11
  num_metric_batches_dropped: 0
  pid: 25504
  policy_reward_mean: {}
  time_since_restore: 9199.599784374237
  time_this_iter_s: 27.316797971725464
  time_total_s: 9199.599784374237
  timestamp: 1593923476
  timesteps_since_restore: 6560000
  timesteps_this_iter: 20000
  timesteps_total: 6560000
  training_iteration: 328
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=25504], 9199 s, 328 iter, 6560000 ts, 366 rew

W0705 00:31:39.426313 25498 task_dependency_manager.cc:259] Task lease to renew has already expired by -181ms
W0705 00:31:39.432514 25498 task_dependency_manager.cc:259] Task lease to renew has already expired by -190ms
W0705 00:31:39.432552 25498 node_manager.cc:250] Last heartbeat was sent 9622 ms ago 
W0705 00:31:41.037895 25498 node_manager.cc:250] Last heartbeat was sent 1606 ms ago 
W0705 00:31:44.440351 25498 client_connection.cc:255] [worker]ProcessMessage with type 16 took 124 ms.
agent-1: 32.0
agent-2: 12.0
agent-3: 17.0
agent-4: 33.0
agent-5: 20.0
agent-6: 19.0
agent-7: 25.0
agent-8: 7.0
agent-9: 12.0
agent-10: 11.0
agent-11: 28.0
agent-12: 8.0
agent-13: 6.0
agent-14: 22.0
agent-15: 24.0
agent-16: 33.0
agent-17: 24.0
agent-18: 14.0
agent-19: 23.0
agent-20: 4.0
Sum Reward: 374.0
Avg Reward: 18.7
Min Reward: 4.0
Gini Coefficient: 0.27433155080213906
20:20 Ratio: 5.04
Max-min Ratio: 8.25
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_00-31-55
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 572.0
  episode_reward_mean: 365.76
  episode_reward_min: 228.0
  episodes_this_iter: 1
  episodes_total: 328
  experiment_id: 35d66058da2d4c9882f832ee91e4aa4a
  hostname: gpu011
  info:
    apply_time_ms: 2.741
    dispatch_time_ms: 17.578
    learner:
      cur_lr: 0.0009231040021404624
      grad_gnorm: 4.178740501403809
      policy_entropy: 162.30914306640625
      policy_loss: -2.9279730319976807
      var_gnorm: 20.04712677001953
      vf_explained_var: 0.0
      vf_loss: 0.0064526768401265144
    num_steps_sampled: 6580000
    num_steps_trained: 6580000
    wait_time_ms: 265.885
  iterations_since_restore: 329
  node_ip: 172.17.8.11
  num_metric_batches_dropped: 0
  pid: 25504
  policy_reward_mean: {}
  time_since_restore: 9238.961540222168
  time_this_iter_s: 39.36175584793091
  time_total_s: 9238.961540222168
  timestamp: 1593923515
  timesteps_since_restore: 6580000
  timesteps_this_iter: 20000
  timesteps_total: 6580000
  training_iteration: 329
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=25504], 9238 s, 329 iter, 6580000 ts, 366 rew

agent-1: 9.0
agent-2: 11.0
agent-3: 14.0
agent-4: 10.0
agent-5: 12.0
agent-6: 11.0
agent-7: 15.0
agent-8: 13.0
agent-9: 14.0
agent-10: 7.0
agent-11: 12.0
agent-12: 11.0
agent-13: 12.0
agent-14: 8.0
agent-15: 12.0
agent-16: 18.0
agent-17: 8.0
agent-18: 7.0
agent-19: 13.0
agent-20: 24.0
Sum Reward: 241.0
Avg Reward: 12.05
Min Reward: 7.0
Gini Coefficient: 0.16535269709543568
20:20 Ratio: 2.3666666666666667
Max-min Ratio: 3.4285714285714284
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_00-32-23
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 572.0
  episode_reward_mean: 365.1
  episode_reward_min: 228.0
  episodes_this_iter: 1
  episodes_total: 329
  experiment_id: 35d66058da2d4c9882f832ee91e4aa4a
  hostname: gpu011
  info:
    apply_time_ms: 3.408
    dispatch_time_ms: 23.807
    learner:
      cur_lr: 0.0009217719780281186
      grad_gnorm: 40.0
      policy_entropy: 153.93014526367188
      policy_loss: 17.4295597076416
      var_gnorm: 20.048694610595703
      vf_explained_var: 0.0
      vf_loss: 36.223182678222656
    num_steps_sampled: 6600000
    num_steps_trained: 6600000
    wait_time_ms: 260.633
  iterations_since_restore: 330
  node_ip: 172.17.8.11
  num_metric_batches_dropped: 0
  pid: 25504
  policy_reward_mean: {}
  time_since_restore: 9266.912960290909
  time_this_iter_s: 27.951420068740845
  time_total_s: 9266.912960290909
  timestamp: 1593923543
  timesteps_since_restore: 6600000
  timesteps_this_iter: 20000
  timesteps_total: 6600000
  training_iteration: 330
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=25504], 9266 s, 330 iter, 6600000 ts, 365 rew

agent-1: 13.0
agent-2: 3.0
agent-3: 21.0
agent-4: 21.0
agent-5: 9.0
agent-6: 15.0
agent-7: 7.0
agent-8: 23.0
agent-9: 18.0
agent-10: 17.0
agent-11: 19.0
agent-12: 19.0
agent-13: 10.0
agent-14: 11.0
agent-15: 21.0
agent-16: 4.0
agent-17: 9.0
agent-18: 29.0
agent-19: 9.0
agent-20: 12.0
Sum Reward: 290.0
Avg Reward: 14.5
Min Reward: 3.0
Gini Coefficient: 0.2620689655172414
20:20 Ratio: 4.086956521739131
Max-min Ratio: 9.666666666666666
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_00-32-52
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 572.0
  episode_reward_mean: 364.87
  episode_reward_min: 228.0
  episodes_this_iter: 1
  episodes_total: 330
  experiment_id: 35d66058da2d4c9882f832ee91e4aa4a
  hostname: gpu011
  info:
    apply_time_ms: 3.254
    dispatch_time_ms: 23.936
    learner:
      cur_lr: 0.0009204400121234357
      grad_gnorm: 0.2466614991426468
      policy_entropy: 160.66717529296875
      policy_loss: -0.0390872061252594
      var_gnorm: 20.04672622680664
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 5.956647797233927e-08
    num_steps_sampled: 6620000
    num_steps_trained: 6620000
    wait_time_ms: 261.61
  iterations_since_restore: 331
  node_ip: 172.17.8.11
  num_metric_batches_dropped: 0
  pid: 25504
  policy_reward_mean: {}
  time_since_restore: 9295.443071603775
  time_this_iter_s: 28.53011131286621
  time_total_s: 9295.443071603775
  timestamp: 1593923572
  timesteps_since_restore: 6620000
  timesteps_this_iter: 20000
  timesteps_total: 6620000
  training_iteration: 331
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=25504], 9295 s, 331 iter, 6620000 ts, 365 rew

agent-1: 16.0
agent-2: 25.0
agent-3: 12.0
agent-4: 11.0
agent-5: 21.0
agent-6: 17.0
agent-7: 24.0
agent-8: 6.0
agent-9: 23.0
agent-10: 13.0
agent-11: 3.0
agent-12: 13.0
agent-13: 17.0
agent-14: 16.0
agent-15: 12.0
agent-16: 6.0
agent-17: 24.0
agent-18: 21.0
agent-19: 18.0
agent-20: 23.0
Sum Reward: 321.0
Avg Reward: 16.05
Min Reward: 3.0
Gini Coefficient: 0.22383177570093457
20:20 Ratio: 3.6923076923076925
Max-min Ratio: 8.333333333333334
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_00-33-19
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 572.0
  episode_reward_mean: 364.79
  episode_reward_min: 228.0
  episodes_this_iter: 1
  episodes_total: 331
  experiment_id: 35d66058da2d4c9882f832ee91e4aa4a
  hostname: gpu011
  info:
    apply_time_ms: 3.078
    dispatch_time_ms: 7.405
    learner:
      cur_lr: 0.000919107988011092
      grad_gnorm: 15.537338256835938
      policy_entropy: 164.90187072753906
      policy_loss: -5.887231349945068
      var_gnorm: 20.050350189208984
      vf_explained_var: 0.0
      vf_loss: 4.108521461486816
    num_steps_sampled: 6640000
    num_steps_trained: 6640000
    wait_time_ms: 271.6
  iterations_since_restore: 332
  node_ip: 172.17.8.11
  num_metric_batches_dropped: 0
  pid: 25504
  policy_reward_mean: {}
  time_since_restore: 9322.636088609695
  time_this_iter_s: 27.19301700592041
  time_total_s: 9322.636088609695
  timestamp: 1593923599
  timesteps_since_restore: 6640000
  timesteps_this_iter: 20000
  timesteps_total: 6640000
  training_iteration: 332
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=25504], 9322 s, 332 iter, 6640000 ts, 365 rew

agent-1: 20.0
agent-2: 21.0
agent-3: 30.0
agent-4: 13.0
agent-5: 28.0
agent-6: 23.0
agent-7: 25.0
agent-8: 8.0
agent-9: 5.0
agent-10: 28.0
agent-11: 44.0
agent-12: 10.0
agent-13: 34.0
agent-14: 10.0
agent-15: 21.0
agent-16: 13.0
agent-17: 11.0
agent-18: 33.0
agent-19: 24.0
agent-20: 16.0
Sum Reward: 417.0
Avg Reward: 20.85
Min Reward: 5.0
Gini Coefficient: 0.26894484412470027
20:20 Ratio: 4.2727272727272725
Max-min Ratio: 8.8
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_00-33-47
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 572.0
  episode_reward_mean: 366.13
  episode_reward_min: 228.0
  episodes_this_iter: 1
  episodes_total: 332
  experiment_id: 35d66058da2d4c9882f832ee91e4aa4a
  hostname: gpu011
  info:
    apply_time_ms: 3.288
    dispatch_time_ms: 7.051
    learner:
      cur_lr: 0.0009177760221064091
      grad_gnorm: 2.92997407913208
      policy_entropy: 189.18695068359375
      policy_loss: -1.372657299041748
      var_gnorm: 20.047374725341797
      vf_explained_var: 0.0
      vf_loss: 0.0032991967163980007
    num_steps_sampled: 6660000
    num_steps_trained: 6660000
    wait_time_ms: 266.91
  iterations_since_restore: 333
  node_ip: 172.17.8.11
  num_metric_batches_dropped: 0
  pid: 25504
  policy_reward_mean: {}
  time_since_restore: 9350.312121629715
  time_this_iter_s: 27.67603302001953
  time_total_s: 9350.312121629715
  timestamp: 1593923627
  timesteps_since_restore: 6660000
  timesteps_this_iter: 20000
  timesteps_total: 6660000
  training_iteration: 333
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=25504], 9350 s, 333 iter, 6660000 ts, 366 rew

agent-1: 16.0
agent-2: 10.0
agent-3: 16.0
agent-4: 12.0
agent-5: 14.0
agent-6: 23.0
agent-7: 17.0
agent-8: 10.0
agent-9: 6.0
agent-10: 18.0
agent-11: 18.0
agent-12: 24.0
agent-13: 15.0
agent-14: 13.0
agent-15: 32.0
agent-16: 18.0
agent-17: 14.0
agent-18: 8.0
agent-19: 24.0
agent-20: 10.0
Sum Reward: 318.0
Avg Reward: 15.9
Min Reward: 6.0
Gini Coefficient: 0.21132075471698114
20:20 Ratio: 3.0294117647058822
Max-min Ratio: 5.333333333333333
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_00-34-14
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 572.0
  episode_reward_mean: 367.03
  episode_reward_min: 241.0
  episodes_this_iter: 1
  episodes_total: 333
  experiment_id: 35d66058da2d4c9882f832ee91e4aa4a
  hostname: gpu011
  info:
    apply_time_ms: 2.476
    dispatch_time_ms: 7.915
    learner:
      cur_lr: 0.0009164439979940653
      grad_gnorm: 14.91717529296875
      policy_entropy: 158.44676208496094
      policy_loss: 1.5544390678405762
      var_gnorm: 20.05179214477539
      vf_explained_var: 0.0
      vf_loss: 4.0013933181762695
    num_steps_sampled: 6680000
    num_steps_trained: 6680000
    wait_time_ms: 262.49
  iterations_since_restore: 334
  node_ip: 172.17.8.11
  num_metric_batches_dropped: 0
  pid: 25504
  policy_reward_mean: {}
  time_since_restore: 9377.345213890076
  time_this_iter_s: 27.033092260360718
  time_total_s: 9377.345213890076
  timestamp: 1593923654
  timesteps_since_restore: 6680000
  timesteps_this_iter: 20000
  timesteps_total: 6680000
  training_iteration: 334
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=25504], 9377 s, 334 iter, 6680000 ts, 367 rew

agent-1: 29.0
agent-2: 3.0
agent-3: 10.0
agent-4: 12.0
agent-5: 10.0
agent-6: 25.0
agent-7: 29.0
agent-8: 13.0
agent-9: 7.0
agent-10: 14.0
agent-11: 26.0
agent-12: 14.0
agent-13: 2.0
agent-14: 1.0
agent-15: 23.0
agent-16: 20.0
agent-17: 14.0
agent-18: 8.0
agent-19: 16.0
agent-20: 21.0
Sum Reward: 297.0
Avg Reward: 14.85
Min Reward: 1.0
Gini Coefficient: 0.3244107744107744
20:20 Ratio: 8.384615384615385
Max-min Ratio: 29.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_00-34-42
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 572.0
  episode_reward_mean: 366.54
  episode_reward_min: 241.0
  episodes_this_iter: 1
  episodes_total: 334
  experiment_id: 35d66058da2d4c9882f832ee91e4aa4a
  hostname: gpu011
  info:
    apply_time_ms: 3.169
    dispatch_time_ms: 7.864
    learner:
      cur_lr: 0.0009151119738817215
      grad_gnorm: 39.999996185302734
      policy_entropy: 181.93309020996094
      policy_loss: 125.73841857910156
      var_gnorm: 20.048067092895508
      vf_explained_var: 5.960464477539063e-08
      vf_loss: 138.95437622070312
    num_steps_sampled: 6700000
    num_steps_trained: 6700000
    wait_time_ms: 264.192
  iterations_since_restore: 335
  node_ip: 172.17.8.11
  num_metric_batches_dropped: 0
  pid: 25504
  policy_reward_mean: {}
  time_since_restore: 9405.344621181488
  time_this_iter_s: 27.999407291412354
  time_total_s: 9405.344621181488
  timestamp: 1593923682
  timesteps_since_restore: 6700000
  timesteps_this_iter: 20000
  timesteps_total: 6700000
  training_iteration: 335
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=25504], 9405 s, 335 iter, 6700000 ts, 367 rew

agent-1: 3.0
agent-2: 9.0
agent-3: 27.0
agent-4: 17.0
agent-5: 24.0
agent-6: 17.0
agent-7: 25.0
agent-8: 22.0
agent-9: 20.0
agent-10: 17.0
agent-11: 17.0
agent-12: 21.0
agent-13: 6.0
agent-14: 21.0
agent-15: 12.0
agent-16: 26.0
agent-17: 12.0
agent-18: 13.0
agent-19: 29.0
agent-20: 15.0
Sum Reward: 353.0
Avg Reward: 17.65
Min Reward: 3.0
Gini Coefficient: 0.2208215297450425
20:20 Ratio: 3.566666666666667
Max-min Ratio: 9.666666666666666
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_00-35-09
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 572.0
  episode_reward_mean: 365.84
  episode_reward_min: 241.0
  episodes_this_iter: 1
  episodes_total: 335
  experiment_id: 35d66058da2d4c9882f832ee91e4aa4a
  hostname: gpu011
  info:
    apply_time_ms: 3.063
    dispatch_time_ms: 7.707
    learner:
      cur_lr: 0.0009137800079770386
      grad_gnorm: 24.758275985717773
      policy_entropy: 186.14947509765625
      policy_loss: -7.326192378997803
      var_gnorm: 20.044126510620117
      vf_explained_var: 1.1920928955078125e-07
      vf_loss: 1.1435647010803223
    num_steps_sampled: 6720000
    num_steps_trained: 6720000
    wait_time_ms: 267.393
  iterations_since_restore: 336
  node_ip: 172.17.8.11
  num_metric_batches_dropped: 0
  pid: 25504
  policy_reward_mean: {}
  time_since_restore: 9432.544932842255
  time_this_iter_s: 27.2003116607666
  time_total_s: 9432.544932842255
  timestamp: 1593923709
  timesteps_since_restore: 6720000
  timesteps_this_iter: 20000
  timesteps_total: 6720000
  training_iteration: 336
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=25504], 9432 s, 336 iter, 6720000 ts, 366 rew

agent-1: 22.0
agent-2: 23.0
agent-3: 10.0
agent-4: 9.0
agent-5: 8.0
agent-6: 16.0
agent-7: 11.0
agent-8: 19.0
agent-9: 10.0
agent-10: 13.0
agent-11: 11.0
agent-12: 14.0
agent-13: 10.0
agent-14: 12.0
agent-15: 13.0
agent-16: 5.0
agent-17: 19.0
agent-18: 26.0
agent-19: 9.0
agent-20: 8.0
Sum Reward: 268.0
Avg Reward: 13.4
Min Reward: 5.0
Gini Coefficient: 0.2253731343283582
20:20 Ratio: 3.0
Max-min Ratio: 5.2
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_00-35-37
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 572.0
  episode_reward_mean: 364.39
  episode_reward_min: 241.0
  episodes_this_iter: 1
  episodes_total: 336
  experiment_id: 35d66058da2d4c9882f832ee91e4aa4a
  hostname: gpu011
  info:
    apply_time_ms: 3.163
    dispatch_time_ms: 6.598
    learner:
      cur_lr: 0.0009124479838646948
      grad_gnorm: 40.0
      policy_entropy: 180.0496368408203
      policy_loss: 125.32210540771484
      var_gnorm: 20.040267944335938
      vf_explained_var: 1.7881393432617188e-07
      vf_loss: 190.62973022460938
    num_steps_sampled: 6740000
    num_steps_trained: 6740000
    wait_time_ms: 246.806
  iterations_since_restore: 337
  node_ip: 172.17.8.11
  num_metric_batches_dropped: 0
  pid: 25504
  policy_reward_mean: {}
  time_since_restore: 9460.18825340271
  time_this_iter_s: 27.643320560455322
  time_total_s: 9460.18825340271
  timestamp: 1593923737
  timesteps_since_restore: 6740000
  timesteps_this_iter: 20000
  timesteps_total: 6740000
  training_iteration: 337
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=25504], 9460 s, 337 iter, 6740000 ts, 364 rew

agent-1: 15.0
agent-2: 29.0
agent-3: 13.0
agent-4: 25.0
agent-5: 21.0
agent-6: 28.0
agent-7: 8.0
agent-8: 23.0
agent-9: 16.0
agent-10: 0.0
agent-11: 10.0
agent-12: 16.0
agent-13: 16.0
agent-14: 21.0
agent-15: 24.0
agent-16: 23.0
agent-17: 21.0
agent-18: 18.0
agent-19: 35.0
agent-20: 6.0
Sum Reward: 368.0
Avg Reward: 18.4
Min Reward: 0.0
Gini Coefficient: 0.24945652173913044
20:20 Ratio: 4.875
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_00-36-04
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 572.0
  episode_reward_mean: 365.19
  episode_reward_min: 241.0
  episodes_this_iter: 1
  episodes_total: 337
  experiment_id: 35d66058da2d4c9882f832ee91e4aa4a
  hostname: gpu011
  info:
    apply_time_ms: 2.922
    dispatch_time_ms: 6.417
    learner:
      cur_lr: 0.000911116017960012
      grad_gnorm: 23.639894485473633
      policy_entropy: 171.08267211914062
      policy_loss: -7.640718460083008
      var_gnorm: 20.045001983642578
      vf_explained_var: 0.0
      vf_loss: 0.2147555649280548
    num_steps_sampled: 6760000
    num_steps_trained: 6760000
    wait_time_ms: 263.593
  iterations_since_restore: 338
  node_ip: 172.17.8.11
  num_metric_batches_dropped: 0
  pid: 25504
  policy_reward_mean: {}
  time_since_restore: 9487.455331802368
  time_this_iter_s: 27.267078399658203
  time_total_s: 9487.455331802368
  timestamp: 1593923764
  timesteps_since_restore: 6760000
  timesteps_this_iter: 20000
  timesteps_total: 6760000
  training_iteration: 338
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=25504], 9487 s, 338 iter, 6760000 ts, 365 rew

agent-1: 24.0
agent-2: 11.0
agent-3: 19.0
agent-4: 26.0
agent-5: 8.0
agent-6: 4.0
agent-7: 4.0
agent-8: 34.0
agent-9: 4.0
agent-10: 15.0
agent-11: 6.0
agent-12: 9.0
agent-13: 6.0
agent-14: 15.0
agent-15: 2.0
agent-16: 10.0
agent-17: 12.0
agent-18: 24.0
agent-19: 16.0
agent-20: 24.0
Sum Reward: 273.0
Avg Reward: 13.65
Min Reward: 2.0
Gini Coefficient: 0.3587912087912088
20:20 Ratio: 7.714285714285714
Max-min Ratio: 17.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_00-36-32
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 572.0
  episode_reward_mean: 364.03
  episode_reward_min: 241.0
  episodes_this_iter: 1
  episodes_total: 338
  experiment_id: 35d66058da2d4c9882f832ee91e4aa4a
  hostname: gpu011
  info:
    apply_time_ms: 2.783
    dispatch_time_ms: 5.72
    learner:
      cur_lr: 0.0009097839938476682
      grad_gnorm: 5.410518646240234
      policy_entropy: 175.3776092529297
      policy_loss: -1.452799677848816
      var_gnorm: 20.042144775390625
      vf_explained_var: 5.960464477539063e-08
      vf_loss: 0.011600776575505733
    num_steps_sampled: 6780000
    num_steps_trained: 6780000
    wait_time_ms: 273.817
  iterations_since_restore: 339
  node_ip: 172.17.8.11
  num_metric_batches_dropped: 0
  pid: 25504
  policy_reward_mean: {}
  time_since_restore: 9515.077976942062
  time_this_iter_s: 27.622645139694214
  time_total_s: 9515.077976942062
  timestamp: 1593923792
  timesteps_since_restore: 6780000
  timesteps_this_iter: 20000
  timesteps_total: 6780000
  training_iteration: 339
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=25504], 9515 s, 339 iter, 6780000 ts, 364 rew

agent-1: 20.0
agent-2: 20.0
agent-3: 22.0
agent-4: 6.0
agent-5: 12.0
agent-6: 25.0
agent-7: 12.0
agent-8: 32.0
agent-9: 22.0
agent-10: 19.0
agent-11: 5.0
agent-12: 21.0
agent-13: 24.0
agent-14: 29.0
agent-15: 35.0
agent-16: 13.0
agent-17: 25.0
agent-18: 33.0
agent-19: 3.0
agent-20: 23.0
Sum Reward: 401.0
Avg Reward: 20.05
Min Reward: 3.0
Gini Coefficient: 0.2497506234413965
20:20 Ratio: 4.961538461538462
Max-min Ratio: 11.666666666666666
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_00-36-59
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 572.0
  episode_reward_mean: 364.13
  episode_reward_min: 241.0
  episodes_this_iter: 1
  episodes_total: 339
  experiment_id: 35d66058da2d4c9882f832ee91e4aa4a
  hostname: gpu011
  info:
    apply_time_ms: 2.547
    dispatch_time_ms: 7.179
    learner:
      cur_lr: 0.0009084520279429853
      grad_gnorm: 30.890336990356445
      policy_entropy: 172.6932830810547
      policy_loss: -10.053762435913086
      var_gnorm: 20.041833877563477
      vf_explained_var: 5.960464477539063e-08
      vf_loss: 0.38132423162460327
    num_steps_sampled: 6800000
    num_steps_trained: 6800000
    wait_time_ms: 273.548
  iterations_since_restore: 340
  node_ip: 172.17.8.11
  num_metric_batches_dropped: 0
  pid: 25504
  policy_reward_mean: {}
  time_since_restore: 9542.069123983383
  time_this_iter_s: 26.9911470413208
  time_total_s: 9542.069123983383
  timestamp: 1593923819
  timesteps_since_restore: 6800000
  timesteps_this_iter: 20000
  timesteps_total: 6800000
  training_iteration: 340
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=25504], 9542 s, 340 iter, 6800000 ts, 364 rew

agent-1: 23.0
agent-2: 25.0
agent-3: 21.0
agent-4: 14.0
agent-5: 7.0
agent-6: 26.0
agent-7: 16.0
agent-8: 2.0
agent-9: 13.0
agent-10: 3.0
agent-11: 17.0
agent-12: 19.0
agent-13: 20.0
agent-14: 21.0
agent-15: 16.0
agent-16: 4.0
agent-17: 22.0
agent-18: 12.0
agent-19: 22.0
agent-20: 7.0
Sum Reward: 310.0
Avg Reward: 15.5
Min Reward: 2.0
Gini Coefficient: 0.26645161290322583
20:20 Ratio: 6.0
Max-min Ratio: 13.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_00-37-27
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 572.0
  episode_reward_mean: 364.65
  episode_reward_min: 241.0
  episodes_this_iter: 1
  episodes_total: 340
  experiment_id: 35d66058da2d4c9882f832ee91e4aa4a
  hostname: gpu011
  info:
    apply_time_ms: 3.035
    dispatch_time_ms: 5.939
    learner:
      cur_lr: 0.0009071200038306415
      grad_gnorm: 40.000003814697266
      policy_entropy: 173.77626037597656
      policy_loss: 106.41625213623047
      var_gnorm: 20.037967681884766
      vf_explained_var: -2.384185791015625e-07
      vf_loss: 200.0384979248047
    num_steps_sampled: 6820000
    num_steps_trained: 6820000
    wait_time_ms: 264.911
  iterations_since_restore: 341
  node_ip: 172.17.8.11
  num_metric_batches_dropped: 0
  pid: 25504
  policy_reward_mean: {}
  time_since_restore: 9569.73921918869
  time_this_iter_s: 27.670095205307007
  time_total_s: 9569.73921918869
  timestamp: 1593923847
  timesteps_since_restore: 6820000
  timesteps_this_iter: 20000
  timesteps_total: 6820000
  training_iteration: 341
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=25504], 9569 s, 341 iter, 6820000 ts, 365 rew

agent-1: 15.0
agent-2: 4.0
agent-3: 7.0
agent-4: 13.0
agent-5: 38.0
agent-6: 34.0
agent-7: 31.0
agent-8: 23.0
agent-9: 31.0
agent-10: 22.0
agent-11: 23.0
agent-12: 7.0
agent-13: 25.0
agent-14: 16.0
agent-15: 12.0
agent-16: 22.0
agent-17: 23.0
agent-18: 14.0
agent-19: 24.0
agent-20: 21.0
Sum Reward: 405.0
Avg Reward: 20.25
Min Reward: 4.0
Gini Coefficient: 0.25074074074074076
20:20 Ratio: 4.466666666666667
Max-min Ratio: 9.5
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_00-37-54
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 572.0
  episode_reward_mean: 365.03
  episode_reward_min: 241.0
  episodes_this_iter: 1
  episodes_total: 341
  experiment_id: 35d66058da2d4c9882f832ee91e4aa4a
  hostname: gpu011
  info:
    apply_time_ms: 2.895
    dispatch_time_ms: 6.27
    learner:
      cur_lr: 0.0009057879797182977
      grad_gnorm: 37.54462432861328
      policy_entropy: 176.16372680664062
      policy_loss: -12.145709037780762
      var_gnorm: 20.04225730895996
      vf_explained_var: 0.0
      vf_loss: 0.5641642808914185
    num_steps_sampled: 6840000
    num_steps_trained: 6840000
    wait_time_ms: 266.536
  iterations_since_restore: 342
  node_ip: 172.17.8.11
  num_metric_batches_dropped: 0
  pid: 25504
  policy_reward_mean: {}
  time_since_restore: 9596.796109676361
  time_this_iter_s: 27.0568904876709
  time_total_s: 9596.796109676361
  timestamp: 1593923874
  timesteps_since_restore: 6840000
  timesteps_this_iter: 20000
  timesteps_total: 6840000
  training_iteration: 342
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=25504], 9596 s, 342 iter, 6840000 ts, 365 rew

agent-1: 32.0
agent-2: 22.0
agent-3: 16.0
agent-4: 17.0
agent-5: 17.0
agent-6: 10.0
agent-7: 23.0
agent-8: 8.0
agent-9: 27.0
agent-10: 19.0
agent-11: 8.0
agent-12: 13.0
agent-13: 8.0
agent-14: 11.0
agent-15: 29.0
agent-16: 26.0
agent-17: 13.0
agent-18: 11.0
agent-19: 19.0
agent-20: 41.0
Sum Reward: 370.0
Avg Reward: 18.5
Min Reward: 8.0
Gini Coefficient: 0.26297297297297295
20:20 Ratio: 3.7941176470588234
Max-min Ratio: 5.125
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_00-38-22
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 572.0
  episode_reward_mean: 365.43
  episode_reward_min: 241.0
  episodes_this_iter: 1
  episodes_total: 342
  experiment_id: 35d66058da2d4c9882f832ee91e4aa4a
  hostname: gpu011
  info:
    apply_time_ms: 2.581
    dispatch_time_ms: 7.003
    learner:
      cur_lr: 0.0009044560138136148
      grad_gnorm: 40.0
      policy_entropy: 177.2865447998047
      policy_loss: 70.4521484375
      var_gnorm: 20.040420532226562
      vf_explained_var: 0.0
      vf_loss: 82.35858154296875
    num_steps_sampled: 6860000
    num_steps_trained: 6860000
    wait_time_ms: 254.853
  iterations_since_restore: 343
  node_ip: 172.17.8.11
  num_metric_batches_dropped: 0
  pid: 25504
  policy_reward_mean: {}
  time_since_restore: 9624.560286998749
  time_this_iter_s: 27.764177322387695
  time_total_s: 9624.560286998749
  timestamp: 1593923902
  timesteps_since_restore: 6860000
  timesteps_this_iter: 20000
  timesteps_total: 6860000
  training_iteration: 343
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=25504], 9624 s, 343 iter, 6860000 ts, 365 rew

agent-1: 17.0
agent-2: 17.0
agent-3: 35.0
agent-4: 21.0
agent-5: 10.0
agent-6: 13.0
agent-7: 12.0
agent-8: 15.0
agent-9: 18.0
agent-10: 13.0
agent-11: 16.0
agent-12: 4.0
agent-13: 13.0
agent-14: 22.0
agent-15: 22.0
agent-16: 10.0
agent-17: 8.0
agent-18: 28.0
agent-19: 12.0
agent-20: 14.0
Sum Reward: 320.0
Avg Reward: 16.0
Min Reward: 4.0
Gini Coefficient: 0.230625
20:20 Ratio: 3.34375
Max-min Ratio: 8.75
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_00-38-49
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 572.0
  episode_reward_mean: 365.64
  episode_reward_min: 241.0
  episodes_this_iter: 1
  episodes_total: 343
  experiment_id: 35d66058da2d4c9882f832ee91e4aa4a
  hostname: gpu011
  info:
    apply_time_ms: 3.502
    dispatch_time_ms: 9.583
    learner:
      cur_lr: 0.0009031239897012711
      grad_gnorm: 28.55234718322754
      policy_entropy: 142.9258575439453
      policy_loss: -6.79364013671875
      var_gnorm: 20.048248291015625
      vf_explained_var: 0.0
      vf_loss: 0.3236963152885437
    num_steps_sampled: 6880000
    num_steps_trained: 6880000
    wait_time_ms: 265.915
  iterations_since_restore: 344
  node_ip: 172.17.8.11
  num_metric_batches_dropped: 0
  pid: 25504
  policy_reward_mean: {}
  time_since_restore: 9651.543867349625
  time_this_iter_s: 26.983580350875854
  time_total_s: 9651.543867349625
  timestamp: 1593923929
  timesteps_since_restore: 6880000
  timesteps_this_iter: 20000
  timesteps_total: 6880000
  training_iteration: 344
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=25504], 9651 s, 344 iter, 6880000 ts, 366 rew

agent-1: 5.0
agent-2: 4.0
agent-3: 5.0
agent-4: 21.0
agent-5: 14.0
agent-6: 6.0
agent-7: 21.0
agent-8: 26.0
agent-9: 18.0
agent-10: 6.0
agent-11: 20.0
agent-12: 10.0
agent-13: 15.0
agent-14: 15.0
agent-15: 15.0
agent-16: 15.0
agent-17: 15.0
agent-18: 7.0
agent-19: 22.0
agent-20: 19.0
Sum Reward: 279.0
Avg Reward: 13.95
Min Reward: 4.0
Gini Coefficient: 0.2625448028673835
20:20 Ratio: 4.5
Max-min Ratio: 6.5
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_00-39-16
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 572.0
  episode_reward_mean: 365.44
  episode_reward_min: 241.0
  episodes_this_iter: 1
  episodes_total: 344
  experiment_id: 35d66058da2d4c9882f832ee91e4aa4a
  hostname: gpu011
  info:
    apply_time_ms: 2.703
    dispatch_time_ms: 5.636
    learner:
      cur_lr: 0.0009017920237965882
      grad_gnorm: 12.405792236328125
      policy_entropy: 155.0845947265625
      policy_loss: -3.527742862701416
      var_gnorm: 20.044151306152344
      vf_explained_var: 0.0
      vf_loss: 0.06205320730805397
    num_steps_sampled: 6900000
    num_steps_trained: 6900000
    wait_time_ms: 262.735
  iterations_since_restore: 345
  node_ip: 172.17.8.11
  num_metric_batches_dropped: 0
  pid: 25504
  policy_reward_mean: {}
  time_since_restore: 9679.187201023102
  time_this_iter_s: 27.643333673477173
  time_total_s: 9679.187201023102
  timestamp: 1593923956
  timesteps_since_restore: 6900000
  timesteps_this_iter: 20000
  timesteps_total: 6900000
  training_iteration: 345
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=25504], 9679 s, 345 iter, 6900000 ts, 365 rew

agent-1: 19.0
agent-2: 27.0
agent-3: 11.0
agent-4: 8.0
agent-5: 28.0
agent-6: 39.0
agent-7: 13.0
agent-8: 12.0
agent-9: 22.0
agent-10: 26.0
agent-11: 38.0
agent-12: 13.0
agent-13: 23.0
agent-14: 19.0
agent-15: 11.0
agent-16: 33.0
agent-17: 27.0
agent-18: 23.0
agent-19: 39.0
agent-20: 16.0
Sum Reward: 447.0
Avg Reward: 22.35
Min Reward: 8.0
Gini Coefficient: 0.24149888143176734
20:20 Ratio: 3.5476190476190474
Max-min Ratio: 4.875
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_00-39-45
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 572.0
  episode_reward_mean: 366.31
  episode_reward_min: 241.0
  episodes_this_iter: 1
  episodes_total: 345
  experiment_id: 35d66058da2d4c9882f832ee91e4aa4a
  hostname: gpu011
  info:
    apply_time_ms: 3.181
    dispatch_time_ms: 7.721
    learner:
      cur_lr: 0.0009004599996842444
      grad_gnorm: 37.756996154785156
      policy_entropy: 185.3477325439453
      policy_loss: 1.1312289237976074
      var_gnorm: 20.050140380859375
      vf_explained_var: 0.0
      vf_loss: 22.586885452270508
    num_steps_sampled: 6920000
    num_steps_trained: 6920000
    wait_time_ms: 202.574
  iterations_since_restore: 346
  node_ip: 172.17.8.11
  num_metric_batches_dropped: 0
  pid: 25504
  policy_reward_mean: {}
  time_since_restore: 9707.439218759537
  time_this_iter_s: 28.252017736434937
  time_total_s: 9707.439218759537
  timestamp: 1593923985
  timesteps_since_restore: 6920000
  timesteps_this_iter: 20000
  timesteps_total: 6920000
  training_iteration: 346
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=25504], 9707 s, 346 iter, 6920000 ts, 366 rew

agent-1: 13.0
agent-2: 19.0
agent-3: 19.0
agent-4: 9.0
agent-5: 11.0
agent-6: 10.0
agent-7: 5.0
agent-8: 4.0
agent-9: 11.0
agent-10: 15.0
agent-11: 14.0
agent-12: 17.0
agent-13: 14.0
agent-14: 22.0
agent-15: 5.0
agent-16: 35.0
agent-17: 36.0
agent-18: 17.0
agent-19: 5.0
agent-20: 22.0
Sum Reward: 303.0
Avg Reward: 15.15
Min Reward: 4.0
Gini Coefficient: 0.3074257425742574
20:20 Ratio: 6.052631578947368
Max-min Ratio: 9.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_00-40-12
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 572.0
  episode_reward_mean: 366.79
  episode_reward_min: 241.0
  episodes_this_iter: 1
  episodes_total: 346
  experiment_id: 35d66058da2d4c9882f832ee91e4aa4a
  hostname: gpu011
  info:
    apply_time_ms: 2.754
    dispatch_time_ms: 7.602
    learner:
      cur_lr: 0.0008991279755719006
      grad_gnorm: 40.0
      policy_entropy: 187.46124267578125
      policy_loss: 56.39060592651367
      var_gnorm: 20.039804458618164
      vf_explained_var: 1.1920928955078125e-07
      vf_loss: 59.82035827636719
    num_steps_sampled: 6940000
    num_steps_trained: 6940000
    wait_time_ms: 245.784
  iterations_since_restore: 347
  node_ip: 172.17.8.11
  num_metric_batches_dropped: 0
  pid: 25504
  policy_reward_mean: {}
  time_since_restore: 9735.3111307621
  time_this_iter_s: 27.871912002563477
  time_total_s: 9735.3111307621
  timestamp: 1593924012
  timesteps_since_restore: 6940000
  timesteps_this_iter: 20000
  timesteps_total: 6940000
  training_iteration: 347
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=25504], 9735 s, 347 iter, 6940000 ts, 367 rew

agent-1: 31.0
agent-2: 23.0
agent-3: 22.0
agent-4: 14.0
agent-5: 1.0
agent-6: 20.0
agent-7: 16.0
agent-8: 16.0
agent-9: 16.0
agent-10: 10.0
agent-11: 27.0
agent-12: 46.0
agent-13: 12.0
agent-14: 10.0
agent-15: 16.0
agent-16: 11.0
agent-17: 16.0
agent-18: 11.0
agent-19: 9.0
agent-20: 29.0
Sum Reward: 356.0
Avg Reward: 17.8
Min Reward: 1.0
Gini Coefficient: 0.2853932584269663
20:20 Ratio: 4.433333333333334
Max-min Ratio: 46.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_00-40-40
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 572.0
  episode_reward_mean: 367.7
  episode_reward_min: 241.0
  episodes_this_iter: 1
  episodes_total: 347
  experiment_id: 35d66058da2d4c9882f832ee91e4aa4a
  hostname: gpu011
  info:
    apply_time_ms: 2.743
    dispatch_time_ms: 26.76
    learner:
      cur_lr: 0.0008977960096672177
      grad_gnorm: 22.93271255493164
      policy_entropy: 173.2200164794922
      policy_loss: -11.33696460723877
      var_gnorm: 20.036666870117188
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 0.20921362936496735
    num_steps_sampled: 6960000
    num_steps_trained: 6960000
    wait_time_ms: 236.077
  iterations_since_restore: 348
  node_ip: 172.17.8.11
  num_metric_batches_dropped: 0
  pid: 25504
  policy_reward_mean: {}
  time_since_restore: 9763.056366920471
  time_this_iter_s: 27.74523615837097
  time_total_s: 9763.056366920471
  timestamp: 1593924040
  timesteps_since_restore: 6960000
  timesteps_this_iter: 20000
  timesteps_total: 6960000
  training_iteration: 348
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=25504], 9763 s, 348 iter, 6960000 ts, 368 rew

agent-1: 8.0
agent-2: 8.0
agent-3: 19.0
agent-4: 14.0
agent-5: 23.0
agent-6: 14.0
agent-7: 6.0
agent-8: 5.0
agent-9: 38.0
agent-10: 18.0
agent-11: 21.0
agent-12: 3.0
agent-13: 24.0
agent-14: 8.0
agent-15: 26.0
agent-16: 7.0
agent-17: 37.0
agent-18: 17.0
agent-19: 21.0
agent-20: 31.0
Sum Reward: 348.0
Avg Reward: 17.4
Min Reward: 3.0
Gini Coefficient: 0.3281609195402299
20:20 Ratio: 6.285714285714286
Max-min Ratio: 12.666666666666666
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_00-41-09
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 572.0
  episode_reward_mean: 367.66
  episode_reward_min: 241.0
  episodes_this_iter: 1
  episodes_total: 348
  experiment_id: 35d66058da2d4c9882f832ee91e4aa4a
  hostname: gpu011
  info:
    apply_time_ms: 4.183
    dispatch_time_ms: 24.936
    learner:
      cur_lr: 0.0008964639855548739
      grad_gnorm: 7.469758033752441
      policy_entropy: 183.70169067382812
      policy_loss: -2.1653177738189697
      var_gnorm: 20.02885627746582
      vf_explained_var: 0.0
      vf_loss: 0.02250923588871956
    num_steps_sampled: 6980000
    num_steps_trained: 6980000
    wait_time_ms: 267.458
  iterations_since_restore: 349
  node_ip: 172.17.8.11
  num_metric_batches_dropped: 0
  pid: 25504
  policy_reward_mean: {}
  time_since_restore: 9792.046617031097
  time_this_iter_s: 28.99025011062622
  time_total_s: 9792.046617031097
  timestamp: 1593924069
  timesteps_since_restore: 6980000
  timesteps_this_iter: 20000
  timesteps_total: 6980000
  training_iteration: 349
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=25504], 9792 s, 349 iter, 6980000 ts, 368 rew

agent-1: 31.0
agent-2: 5.0
agent-3: 11.0
agent-4: 19.0
agent-5: 20.0
agent-6: 6.0
agent-7: 16.0
agent-8: 18.0
agent-9: 8.0
agent-10: 21.0
agent-11: 18.0
agent-12: 8.0
agent-13: 20.0
agent-14: 21.0
agent-15: 11.0
agent-16: 3.0
agent-17: 11.0
agent-18: 17.0
agent-19: 17.0
agent-20: 19.0
Sum Reward: 300.0
Avg Reward: 15.0
Min Reward: 3.0
Gini Coefficient: 0.24766666666666667
20:20 Ratio: 4.2272727272727275
Max-min Ratio: 10.333333333333334
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_00-41-38
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 572.0
  episode_reward_mean: 365.44
  episode_reward_min: 241.0
  episodes_this_iter: 1
  episodes_total: 349
  experiment_id: 35d66058da2d4c9882f832ee91e4aa4a
  hostname: gpu011
  info:
    apply_time_ms: 2.674
    dispatch_time_ms: 31.596
    learner:
      cur_lr: 0.0008951320196501911
      grad_gnorm: 7.641436576843262
      policy_entropy: 173.8966522216797
      policy_loss: 0.6354673504829407
      var_gnorm: 20.034587860107422
      vf_explained_var: 1.7881393432617188e-07
      vf_loss: 4.406186580657959
    num_steps_sampled: 7000000
    num_steps_trained: 7000000
    wait_time_ms: 256.416
  iterations_since_restore: 350
  node_ip: 172.17.8.11
  num_metric_batches_dropped: 0
  pid: 25504
  policy_reward_mean: {}
  time_since_restore: 9820.848505735397
  time_this_iter_s: 28.801888704299927
  time_total_s: 9820.848505735397
  timestamp: 1593924098
  timesteps_since_restore: 7000000
  timesteps_this_iter: 20000
  timesteps_total: 7000000
  training_iteration: 350
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=25504], 9820 s, 350 iter, 7000000 ts, 365 rew

agent-1: 6.0
agent-2: 13.0
agent-3: 13.0
agent-4: 27.0
agent-5: 17.0
agent-6: 0.0
agent-7: 6.0
agent-8: 2.0
agent-9: 18.0
agent-10: 21.0
agent-11: 0.0
agent-12: 16.0
agent-13: 21.0
agent-14: 7.0
agent-15: 7.0
agent-16: 31.0
agent-17: 13.0
agent-18: 17.0
agent-19: 20.0
agent-20: 29.0
Sum Reward: 284.0
Avg Reward: 14.2
Min Reward: 0.0
Gini Coefficient: 0.3602112676056338
20:20 Ratio: 13.5
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_00-42-06
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 572.0
  episode_reward_mean: 363.15
  episode_reward_min: 241.0
  episodes_this_iter: 1
  episodes_total: 350
  experiment_id: 35d66058da2d4c9882f832ee91e4aa4a
  hostname: gpu011
  info:
    apply_time_ms: 3.255
    dispatch_time_ms: 6.08
    learner:
      cur_lr: 0.0008937999955378473
      grad_gnorm: 40.0
      policy_entropy: 188.67861938476562
      policy_loss: 184.06829833984375
      var_gnorm: 20.024993896484375
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 240.28204345703125
    num_steps_sampled: 7020000
    num_steps_trained: 7020000
    wait_time_ms: 243.087
  iterations_since_restore: 351
  node_ip: 172.17.8.11
  num_metric_batches_dropped: 0
  pid: 25504
  policy_reward_mean: {}
  time_since_restore: 9848.685293197632
  time_this_iter_s: 27.836787462234497
  time_total_s: 9848.685293197632
  timestamp: 1593924126
  timesteps_since_restore: 7020000
  timesteps_this_iter: 20000
  timesteps_total: 7020000
  training_iteration: 351
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=25504], 9848 s, 351 iter, 7020000 ts, 363 rew

agent-1: 17.0
agent-2: 18.0
agent-3: 24.0
agent-4: 29.0
agent-5: 25.0
agent-6: 24.0
agent-7: 15.0
agent-8: 5.0
agent-9: 11.0
agent-10: 19.0
agent-11: 15.0
agent-12: 12.0
agent-13: 24.0
agent-14: 13.0
agent-15: 15.0
agent-16: 15.0
agent-17: 21.0
agent-18: 8.0
agent-19: 12.0
agent-20: 16.0
Sum Reward: 338.0
Avg Reward: 16.9
Min Reward: 5.0
Gini Coefficient: 0.1997041420118343
20:20 Ratio: 2.8333333333333335
Max-min Ratio: 5.8
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_00-42-33
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 572.0
  episode_reward_mean: 363.49
  episode_reward_min: 241.0
  episodes_this_iter: 1
  episodes_total: 351
  experiment_id: 35d66058da2d4c9882f832ee91e4aa4a
  hostname: gpu011
  info:
    apply_time_ms: 3.182
    dispatch_time_ms: 6.571
    learner:
      cur_lr: 0.0008924679714255035
      grad_gnorm: 16.605751037597656
      policy_entropy: 195.12136840820312
      policy_loss: -7.48803186416626
      var_gnorm: 20.02973175048828
      vf_explained_var: 5.960464477539063e-08
      vf_loss: 0.11042775213718414
    num_steps_sampled: 7040000
    num_steps_trained: 7040000
    wait_time_ms: 267.504
  iterations_since_restore: 352
  node_ip: 172.17.8.11
  num_metric_batches_dropped: 0
  pid: 25504
  policy_reward_mean: {}
  time_since_restore: 9876.038729429245
  time_this_iter_s: 27.35343623161316
  time_total_s: 9876.038729429245
  timestamp: 1593924153
  timesteps_since_restore: 7040000
  timesteps_this_iter: 20000
  timesteps_total: 7040000
  training_iteration: 352
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=25504], 9876 s, 352 iter, 7040000 ts, 363 rew

agent-1: 11.0
agent-2: 30.0
agent-3: 22.0
agent-4: 1.0
agent-5: 14.0
agent-6: 1.0
agent-7: 22.0
agent-8: 10.0
agent-9: 1.0
agent-10: 30.0
agent-11: 2.0
agent-12: 6.0
agent-13: 9.0
agent-14: 11.0
agent-15: 22.0
agent-16: 16.0
agent-17: 20.0
agent-18: 27.0
agent-19: 18.0
agent-20: 10.0
Sum Reward: 283.0
Avg Reward: 14.15
Min Reward: 1.0
Gini Coefficient: 0.3736749116607774
20:20 Ratio: 21.8
Max-min Ratio: 30.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_00-43-01
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 572.0
  episode_reward_mean: 362.61
  episode_reward_min: 241.0
  episodes_this_iter: 1
  episodes_total: 352
  experiment_id: 35d66058da2d4c9882f832ee91e4aa4a
  hostname: gpu011
  info:
    apply_time_ms: 4.087
    dispatch_time_ms: 6.261
    learner:
      cur_lr: 0.0008911360055208206
      grad_gnorm: 40.0
      policy_entropy: 185.60830688476562
      policy_loss: 95.56975555419922
      var_gnorm: 20.02065086364746
      vf_explained_var: 0.0
      vf_loss: 99.1334457397461
    num_steps_sampled: 7060000
    num_steps_trained: 7060000
    wait_time_ms: 239.865
  iterations_since_restore: 353
  node_ip: 172.17.8.11
  num_metric_batches_dropped: 0
  pid: 25504
  policy_reward_mean: {}
  time_since_restore: 9903.61112856865
  time_this_iter_s: 27.572399139404297
  time_total_s: 9903.61112856865
  timestamp: 1593924181
  timesteps_since_restore: 7060000
  timesteps_this_iter: 20000
  timesteps_total: 7060000
  training_iteration: 353
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=25504], 9903 s, 353 iter, 7060000 ts, 363 rew

agent-1: 12.0
agent-2: 12.0
agent-3: 10.0
agent-4: 16.0
agent-5: 6.0
agent-6: 7.0
agent-7: 14.0
agent-8: 17.0
agent-9: 23.0
agent-10: 26.0
agent-11: 4.0
agent-12: 13.0
agent-13: 18.0
agent-14: 9.0
agent-15: 16.0
agent-16: 12.0
agent-17: 32.0
agent-18: 1.0
agent-19: 10.0
agent-20: 22.0
Sum Reward: 280.0
Avg Reward: 14.0
Min Reward: 1.0
Gini Coefficient: 0.2935714285714286
20:20 Ratio: 5.722222222222222
Max-min Ratio: 32.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_00-43-29
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 572.0
  episode_reward_mean: 362.18
  episode_reward_min: 241.0
  episodes_this_iter: 1
  episodes_total: 353
  experiment_id: 35d66058da2d4c9882f832ee91e4aa4a
  hostname: gpu011
  info:
    apply_time_ms: 3.718
    dispatch_time_ms: 9.856
    learner:
      cur_lr: 0.0008898039814084768
      grad_gnorm: 40.0
      policy_entropy: 207.93911743164062
      policy_loss: 23.781503677368164
      var_gnorm: 20.024457931518555
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 29.16364288330078
    num_steps_sampled: 7080000
    num_steps_trained: 7080000
    wait_time_ms: 254.763
  iterations_since_restore: 354
  node_ip: 172.17.8.11
  num_metric_batches_dropped: 0
  pid: 25504
  policy_reward_mean: {}
  time_since_restore: 9931.308468341827
  time_this_iter_s: 27.6973397731781
  time_total_s: 9931.308468341827
  timestamp: 1593924209
  timesteps_since_restore: 7080000
  timesteps_this_iter: 20000
  timesteps_total: 7080000
  training_iteration: 354
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=25504], 9931 s, 354 iter, 7080000 ts, 362 rew

W0705 00:43:43.633008 25498 client_connection.cc:255] [worker]ProcessMessage with type 8 took 123 ms.
W0705 00:43:44.865154 25498 node_manager.cc:250] Last heartbeat was sent 9467 ms ago 
agent-1: 20.0
agent-2: 1.0
agent-3: 17.0
agent-4: 17.0
agent-5: 15.0
agent-6: 19.0
agent-7: 14.0
agent-8: 18.0
agent-9: 19.0
agent-10: 22.0
agent-11: 6.0
agent-12: 6.0
agent-13: 17.0
agent-14: 8.0
agent-15: 20.0
agent-16: 11.0
agent-17: 13.0
agent-18: 10.0
agent-19: 15.0
agent-20: 8.0
Sum Reward: 276.0
Avg Reward: 13.8
Min Reward: 1.0
Gini Coefficient: 0.22717391304347825
20:20 Ratio: 3.857142857142857
Max-min Ratio: 22.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_00-44-03
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 572.0
  episode_reward_mean: 361.71
  episode_reward_min: 241.0
  episodes_this_iter: 1
  episodes_total: 354
  experiment_id: 35d66058da2d4c9882f832ee91e4aa4a
  hostname: gpu011
  info:
    apply_time_ms: 3.592
    dispatch_time_ms: 6.525
    learner:
      cur_lr: 0.000888472015503794
      grad_gnorm: 5.2237982749938965
      policy_entropy: 205.34527587890625
      policy_loss: -1.7144460678100586
      var_gnorm: 19.9964542388916
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 0.010974094271659851
    num_steps_sampled: 7100000
    num_steps_trained: 7100000
    wait_time_ms: 252.267
  iterations_since_restore: 355
  node_ip: 172.17.8.11
  num_metric_batches_dropped: 0
  pid: 25504
  policy_reward_mean: {}
  time_since_restore: 9965.769249916077
  time_this_iter_s: 34.46078157424927
  time_total_s: 9965.769249916077
  timestamp: 1593924243
  timesteps_since_restore: 7100000
  timesteps_this_iter: 20000
  timesteps_total: 7100000
  training_iteration: 355
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=25504], 9965 s, 355 iter, 7100000 ts, 362 rew

agent-1: 16.0
agent-2: 11.0
agent-3: 18.0
agent-4: 12.0
agent-5: 12.0
agent-6: 9.0
agent-7: 14.0
agent-8: 14.0
agent-9: 6.0
agent-10: 32.0
agent-11: 25.0
agent-12: 9.0
agent-13: 7.0
agent-14: 17.0
agent-15: 30.0
agent-16: 4.0
agent-17: 21.0
agent-18: 21.0
agent-19: 29.0
agent-20: 19.0
Sum Reward: 326.0
Avg Reward: 16.3
Min Reward: 4.0
Gini Coefficient: 0.2745398773006135
20:20 Ratio: 4.461538461538462
Max-min Ratio: 8.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_00-44-30
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 572.0
  episode_reward_mean: 361.63
  episode_reward_min: 241.0
  episodes_this_iter: 1
  episodes_total: 355
  experiment_id: 35d66058da2d4c9882f832ee91e4aa4a
  hostname: gpu011
  info:
    apply_time_ms: 3.899
    dispatch_time_ms: 7.13
    learner:
      cur_lr: 0.0008871399913914502
      grad_gnorm: 12.803352355957031
      policy_entropy: 182.15228271484375
      policy_loss: -5.071769714355469
      var_gnorm: 19.995967864990234
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 0.06509774178266525
    num_steps_sampled: 7120000
    num_steps_trained: 7120000
    wait_time_ms: 266.819
  iterations_since_restore: 356
  node_ip: 172.17.8.11
  num_metric_batches_dropped: 0
  pid: 25504
  policy_reward_mean: {}
  time_since_restore: 9993.046793699265
  time_this_iter_s: 27.277543783187866
  time_total_s: 9993.046793699265
  timestamp: 1593924270
  timesteps_since_restore: 7120000
  timesteps_this_iter: 20000
  timesteps_total: 7120000
  training_iteration: 356
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=25504], 9993 s, 356 iter, 7120000 ts, 362 rew

agent-1: 1.0
agent-2: 15.0
agent-3: 14.0
agent-4: 16.0
agent-5: 15.0
agent-6: 14.0
agent-7: 6.0
agent-8: 8.0
agent-9: 8.0
agent-10: 14.0
agent-11: 26.0
agent-12: 9.0
agent-13: 27.0
agent-14: 32.0
agent-15: 7.0
agent-16: 8.0
agent-17: 11.0
agent-18: 9.0
agent-19: 9.0
agent-20: 8.0
Sum Reward: 257.0
Avg Reward: 12.85
Min Reward: 1.0
Gini Coefficient: 0.3033073929961089
20:20 Ratio: 4.590909090909091
Max-min Ratio: 32.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_00-44-59
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 572.0
  episode_reward_mean: 360.54
  episode_reward_min: 241.0
  episodes_this_iter: 1
  episodes_total: 356
  experiment_id: 35d66058da2d4c9882f832ee91e4aa4a
  hostname: gpu011
  info:
    apply_time_ms: 4.261
    dispatch_time_ms: 12.607
    learner:
      cur_lr: 0.0008858080254867673
      grad_gnorm: 40.0
      policy_entropy: 184.49757385253906
      policy_loss: 102.17513275146484
      var_gnorm: 20.004837036132812
      vf_explained_var: 0.0
      vf_loss: 113.47380828857422
    num_steps_sampled: 7140000
    num_steps_trained: 7140000
    wait_time_ms: 66.936
  iterations_since_restore: 357
  node_ip: 172.17.8.11
  num_metric_batches_dropped: 0
  pid: 25504
  policy_reward_mean: {}
  time_since_restore: 10021.419834136963
  time_this_iter_s: 28.373040437698364
  time_total_s: 10021.419834136963
  timestamp: 1593924299
  timesteps_since_restore: 7140000
  timesteps_this_iter: 20000
  timesteps_total: 7140000
  training_iteration: 357
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=25504], 10021 s, 357 iter, 7140000 ts, 361 rew

agent-1: 11.0
agent-2: 6.0
agent-3: 2.0
agent-4: 22.0
agent-5: 6.0
agent-6: 6.0
agent-7: 11.0
agent-8: 19.0
agent-9: 5.0
agent-10: 15.0
agent-11: 13.0
agent-12: 20.0
agent-13: 8.0
agent-14: 8.0
agent-15: 19.0
agent-16: 15.0
agent-17: 19.0
agent-18: 13.0
agent-19: 31.0
agent-20: 4.0
Sum Reward: 253.0
Avg Reward: 12.65
Min Reward: 2.0
Gini Coefficient: 0.316798418972332
20:20 Ratio: 5.411764705882353
Max-min Ratio: 15.5
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_00-45-26
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 572.0
  episode_reward_mean: 358.3
  episode_reward_min: 241.0
  episodes_this_iter: 1
  episodes_total: 357
  experiment_id: 35d66058da2d4c9882f832ee91e4aa4a
  hostname: gpu011
  info:
    apply_time_ms: 3.212
    dispatch_time_ms: 6.782
    learner:
      cur_lr: 0.0008844760013744235
      grad_gnorm: 21.381624221801758
      policy_entropy: 187.6949005126953
      policy_loss: -7.927550315856934
      var_gnorm: 20.008378982543945
      vf_explained_var: 0.0
      vf_loss: 0.18213260173797607
    num_steps_sampled: 7160000
    num_steps_trained: 7160000
    wait_time_ms: 266.007
  iterations_since_restore: 358
  node_ip: 172.17.8.11
  num_metric_batches_dropped: 0
  pid: 25504
  policy_reward_mean: {}
  time_since_restore: 10048.85828590393
  time_this_iter_s: 27.438451766967773
  time_total_s: 10048.85828590393
  timestamp: 1593924326
  timesteps_since_restore: 7160000
  timesteps_this_iter: 20000
  timesteps_total: 7160000
  training_iteration: 358
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=25504], 10048 s, 358 iter, 7160000 ts, 358 rew

agent-1: 12.0
agent-2: 4.0
agent-3: 22.0
agent-4: 12.0
agent-5: 30.0
agent-6: 22.0
agent-7: 15.0
agent-8: 17.0
agent-9: 1.0
agent-10: 3.0
agent-11: 17.0
agent-12: 17.0
agent-13: 31.0
agent-14: 7.0
agent-15: 29.0
agent-16: 7.0
agent-17: 10.0
agent-18: 23.0
agent-19: 23.0
agent-20: 5.0
Sum Reward: 307.0
Avg Reward: 15.35
Min Reward: 1.0
Gini Coefficient: 0.33794788273615634
20:20 Ratio: 8.692307692307692
Max-min Ratio: 31.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_00-45-54
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 572.0
  episode_reward_mean: 358.19
  episode_reward_min: 241.0
  episodes_this_iter: 1
  episodes_total: 358
  experiment_id: 35d66058da2d4c9882f832ee91e4aa4a
  hostname: gpu011
  info:
    apply_time_ms: 3.567
    dispatch_time_ms: 17.75
    learner:
      cur_lr: 0.0008831439772620797
      grad_gnorm: 1.3186125755310059
      policy_entropy: 196.20855712890625
      policy_loss: 1.6226598024368286
      var_gnorm: 20.00626564025879
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 0.000700555625371635
    num_steps_sampled: 7180000
    num_steps_trained: 7180000
    wait_time_ms: 248.876
  iterations_since_restore: 359
  node_ip: 172.17.8.11
  num_metric_batches_dropped: 0
  pid: 25504
  policy_reward_mean: {}
  time_since_restore: 10076.92359161377
  time_this_iter_s: 28.065305709838867
  time_total_s: 10076.92359161377
  timestamp: 1593924354
  timesteps_since_restore: 7180000
  timesteps_this_iter: 20000
  timesteps_total: 7180000
  training_iteration: 359
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=25504], 10076 s, 359 iter, 7180000 ts, 358 rew

agent-1: 26.0
agent-2: 5.0
agent-3: 25.0
agent-4: 8.0
agent-5: 16.0
agent-6: 18.0
agent-7: 4.0
agent-8: 24.0
agent-9: 5.0
agent-10: 20.0
agent-11: 25.0
agent-12: 10.0
agent-13: 9.0
agent-14: 31.0
agent-15: 8.0
agent-16: 0.0
agent-17: 6.0
agent-18: 15.0
agent-19: 8.0
agent-20: 35.0
Sum Reward: 298.0
Avg Reward: 14.9
Min Reward: 0.0
Gini Coefficient: 0.3711409395973154
20:20 Ratio: 8.357142857142858
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_00-46-23
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 572.0
  episode_reward_mean: 357.22
  episode_reward_min: 241.0
  episodes_this_iter: 1
  episodes_total: 359
  experiment_id: 35d66058da2d4c9882f832ee91e4aa4a
  hostname: gpu011
  info:
    apply_time_ms: 2.778
    dispatch_time_ms: 7.82
    learner:
      cur_lr: 0.0008818120113573968
      grad_gnorm: 30.166213989257812
      policy_entropy: 175.26002502441406
      policy_loss: -10.44552993774414
      var_gnorm: 20.008981704711914
      vf_explained_var: 0.0
      vf_loss: 0.35924845933914185
    num_steps_sampled: 7200000
    num_steps_trained: 7200000
    wait_time_ms: 266.66
  iterations_since_restore: 360
  node_ip: 172.17.8.11
  num_metric_batches_dropped: 0
  pid: 25504
  policy_reward_mean: {}
  time_since_restore: 10105.123205900192
  time_this_iter_s: 28.19961428642273
  time_total_s: 10105.123205900192
  timestamp: 1593924383
  timesteps_since_restore: 7200000
  timesteps_this_iter: 20000
  timesteps_total: 7200000
  training_iteration: 360
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=25504], 10105 s, 360 iter, 7200000 ts, 357 rew

agent-1: 14.0
agent-2: 18.0
agent-3: 23.0
agent-4: 22.0
agent-5: 12.0
agent-6: 18.0
agent-7: 23.0
agent-8: 7.0
agent-9: 24.0
agent-10: 31.0
agent-11: 22.0
agent-12: 10.0
agent-13: 21.0
agent-14: 11.0
agent-15: 5.0
agent-16: 20.0
agent-17: 25.0
agent-18: 9.0
agent-19: 17.0
agent-20: 10.0
Sum Reward: 342.0
Avg Reward: 17.1
Min Reward: 5.0
Gini Coefficient: 0.22660818713450293
20:20 Ratio: 3.3225806451612905
Max-min Ratio: 6.2
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_00-46-50
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 572.0
  episode_reward_mean: 357.21
  episode_reward_min: 241.0
  episodes_this_iter: 1
  episodes_total: 360
  experiment_id: 35d66058da2d4c9882f832ee91e4aa4a
  hostname: gpu011
  info:
    apply_time_ms: 3.677
    dispatch_time_ms: 5.663
    learner:
      cur_lr: 0.000880479987245053
      grad_gnorm: 40.0
      policy_entropy: 168.97988891601562
      policy_loss: 51.33159637451172
      var_gnorm: 20.005712509155273
      vf_explained_var: 0.0
      vf_loss: 70.935546875
    num_steps_sampled: 7220000
    num_steps_trained: 7220000
    wait_time_ms: 239.995
  iterations_since_restore: 361
  node_ip: 172.17.8.11
  num_metric_batches_dropped: 0
  pid: 25504
  policy_reward_mean: {}
  time_since_restore: 10132.761518239975
  time_this_iter_s: 27.638312339782715
  time_total_s: 10132.761518239975
  timestamp: 1593924410
  timesteps_since_restore: 7220000
  timesteps_this_iter: 20000
  timesteps_total: 7220000
  training_iteration: 361
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=25504], 10132 s, 361 iter, 7220000 ts, 357 rew

agent-1: 6.0
agent-2: 24.0
agent-3: 28.0
agent-4: 9.0
agent-5: 5.0
agent-6: 21.0
agent-7: 11.0
agent-8: 6.0
agent-9: 8.0
agent-10: 11.0
agent-11: 20.0
agent-12: 1.0
agent-13: 9.0
agent-14: 6.0
agent-15: 14.0
agent-16: 24.0
agent-17: 31.0
agent-18: 12.0
agent-19: 21.0
agent-20: 17.0
Sum Reward: 284.0
Avg Reward: 14.2
Min Reward: 1.0
Gini Coefficient: 0.32992957746478874
20:20 Ratio: 5.944444444444445
Max-min Ratio: 31.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_00-47-18
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 572.0
  episode_reward_mean: 357.05
  episode_reward_min: 241.0
  episodes_this_iter: 1
  episodes_total: 361
  experiment_id: 35d66058da2d4c9882f832ee91e4aa4a
  hostname: gpu011
  info:
    apply_time_ms: 2.702
    dispatch_time_ms: 42.94
    learner:
      cur_lr: 0.0008791480213403702
      grad_gnorm: 31.252172470092773
      policy_entropy: 169.70982360839844
      policy_loss: -19.705699920654297
      var_gnorm: 20.007667541503906
      vf_explained_var: 0.0
      vf_loss: 0.3414419889450073
    num_steps_sampled: 7240000
    num_steps_trained: 7240000
    wait_time_ms: 273.731
  iterations_since_restore: 362
  node_ip: 172.17.8.11
  num_metric_batches_dropped: 0
  pid: 25504
  policy_reward_mean: {}
  time_since_restore: 10160.790102243423
  time_this_iter_s: 28.028584003448486
  time_total_s: 10160.790102243423
  timestamp: 1593924438
  timesteps_since_restore: 7240000
  timesteps_this_iter: 20000
  timesteps_total: 7240000
  training_iteration: 362
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=25504], 10160 s, 362 iter, 7240000 ts, 357 rew

agent-1: 17.0
agent-2: 23.0
agent-3: 15.0
agent-4: 24.0
agent-5: 5.0
agent-6: 15.0
agent-7: 16.0
agent-8: 32.0
agent-9: 9.0
agent-10: 4.0
agent-11: 18.0
agent-12: 16.0
agent-13: 11.0
agent-14: 15.0
agent-15: 32.0
agent-16: 14.0
agent-17: 3.0
agent-18: 22.0
agent-19: 15.0
agent-20: 4.0
Sum Reward: 310.0
Avg Reward: 15.5
Min Reward: 3.0
Gini Coefficient: 0.2896774193548387
20:20 Ratio: 6.9375
Max-min Ratio: 10.666666666666666
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_00-47-47
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 572.0
  episode_reward_mean: 357.3
  episode_reward_min: 241.0
  episodes_this_iter: 1
  episodes_total: 362
  experiment_id: 35d66058da2d4c9882f832ee91e4aa4a
  hostname: gpu011
  info:
    apply_time_ms: 3.529
    dispatch_time_ms: 25.164
    learner:
      cur_lr: 0.0008778159972280264
      grad_gnorm: 40.0
      policy_entropy: 159.54833984375
      policy_loss: 24.8968505859375
      var_gnorm: 20.004161834716797
      vf_explained_var: 0.0
      vf_loss: 27.457073211669922
    num_steps_sampled: 7260000
    num_steps_trained: 7260000
    wait_time_ms: 242.034
  iterations_since_restore: 363
  node_ip: 172.17.8.11
  num_metric_batches_dropped: 0
  pid: 25504
  policy_reward_mean: {}
  time_since_restore: 10189.51716041565
  time_this_iter_s: 28.727058172225952
  time_total_s: 10189.51716041565
  timestamp: 1593924467
  timesteps_since_restore: 7260000
  timesteps_this_iter: 20000
  timesteps_total: 7260000
  training_iteration: 363
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=25504], 10189 s, 363 iter, 7260000 ts, 357 rew

agent-1: 17.0
agent-2: 17.0
agent-3: 23.0
agent-4: 18.0
agent-5: 6.0
agent-6: 32.0
agent-7: 10.0
agent-8: 25.0
agent-9: 23.0
agent-10: 15.0
agent-11: 19.0
agent-12: 40.0
agent-13: 9.0
agent-14: 7.0
agent-15: 19.0
agent-16: 18.0
agent-17: 18.0
agent-18: 18.0
agent-19: 22.0
agent-20: 11.0
Sum Reward: 367.0
Avg Reward: 18.35
Min Reward: 6.0
Gini Coefficient: 0.23147138964577657
20:20 Ratio: 3.75
Max-min Ratio: 6.666666666666667
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_00-48-15
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 572.0
  episode_reward_mean: 358.16
  episode_reward_min: 241.0
  episodes_this_iter: 1
  episodes_total: 363
  experiment_id: 35d66058da2d4c9882f832ee91e4aa4a
  hostname: gpu011
  info:
    apply_time_ms: 3.665
    dispatch_time_ms: 33.024
    learner:
      cur_lr: 0.0008764839731156826
      grad_gnorm: 16.999380111694336
      policy_entropy: 123.65604400634766
      policy_loss: -1.715688943862915
      var_gnorm: 20.021940231323242
      vf_explained_var: -2.384185791015625e-07
      vf_loss: 8.152173042297363
    num_steps_sampled: 7280000
    num_steps_trained: 7280000
    wait_time_ms: 241.661
  iterations_since_restore: 364
  node_ip: 172.17.8.11
  num_metric_batches_dropped: 0
  pid: 25504
  policy_reward_mean: {}
  time_since_restore: 10217.632410049438
  time_this_iter_s: 28.115249633789062
  time_total_s: 10217.632410049438
  timestamp: 1593924495
  timesteps_since_restore: 7280000
  timesteps_this_iter: 20000
  timesteps_total: 7280000
  training_iteration: 364
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=25504], 10217 s, 364 iter, 7280000 ts, 358 rew

agent-1: 28.0
agent-2: 11.0
agent-3: 15.0
agent-4: 16.0
agent-5: 24.0
agent-6: 17.0
agent-7: 29.0
agent-8: 38.0
agent-9: 12.0
agent-10: 18.0
agent-11: 36.0
agent-12: 29.0
agent-13: 26.0
agent-14: 17.0
agent-15: 28.0
agent-16: 28.0
agent-17: 19.0
agent-18: 19.0
agent-19: 13.0
agent-20: 12.0
Sum Reward: 435.0
Avg Reward: 21.75
Min Reward: 11.0
Gini Coefficient: 0.20402298850574713
20:20 Ratio: 2.75
Max-min Ratio: 3.4545454545454546
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_00-48-44
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 572.0
  episode_reward_mean: 358.5
  episode_reward_min: 241.0
  episodes_this_iter: 1
  episodes_total: 364
  experiment_id: 35d66058da2d4c9882f832ee91e4aa4a
  hostname: gpu011
  info:
    apply_time_ms: 2.819
    dispatch_time_ms: 11.84
    learner:
      cur_lr: 0.0008751520072109997
      grad_gnorm: 9.556953430175781
      policy_entropy: 132.52828979492188
      policy_loss: -2.2004241943359375
      var_gnorm: 20.025907516479492
      vf_explained_var: 0.0
      vf_loss: 6.718097686767578
    num_steps_sampled: 7300000
    num_steps_trained: 7300000
    wait_time_ms: 262.713
  iterations_since_restore: 365
  node_ip: 172.17.8.11
  num_metric_batches_dropped: 0
  pid: 25504
  policy_reward_mean: {}
  time_since_restore: 10245.914826631546
  time_this_iter_s: 28.282416582107544
  time_total_s: 10245.914826631546
  timestamp: 1593924524
  timesteps_since_restore: 7300000
  timesteps_this_iter: 20000
  timesteps_total: 7300000
  training_iteration: 365
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=25504], 10245 s, 365 iter, 7300000 ts, 358 rew

agent-1: 23.0
agent-2: 21.0
agent-3: 37.0
agent-4: 16.0
agent-5: 30.0
agent-6: 16.0
agent-7: 25.0
agent-8: 25.0
agent-9: 9.0
agent-10: 38.0
agent-11: 21.0
agent-12: 31.0
agent-13: 35.0
agent-14: 30.0
agent-15: 41.0
agent-16: 31.0
agent-17: 14.0
agent-18: 26.0
agent-19: 23.0
agent-20: 40.0
Sum Reward: 532.0
Avg Reward: 26.6
Min Reward: 9.0
Gini Coefficient: 0.18834586466165412
20:20 Ratio: 2.8363636363636364
Max-min Ratio: 4.555555555555555
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_00-49-11
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 572.0
  episode_reward_mean: 359.75
  episode_reward_min: 241.0
  episodes_this_iter: 1
  episodes_total: 365
  experiment_id: 35d66058da2d4c9882f832ee91e4aa4a
  hostname: gpu011
  info:
    apply_time_ms: 3.003
    dispatch_time_ms: 6.279
    learner:
      cur_lr: 0.0008738199830986559
      grad_gnorm: 16.102153778076172
      policy_entropy: 110.04232788085938
      policy_loss: 6.04951286315918
      var_gnorm: 20.030179977416992
      vf_explained_var: 0.0
      vf_loss: 9.77334213256836
    num_steps_sampled: 7320000
    num_steps_trained: 7320000
    wait_time_ms: 257.34
  iterations_since_restore: 366
  node_ip: 172.17.8.11
  num_metric_batches_dropped: 0
  pid: 25504
  policy_reward_mean: {}
  time_since_restore: 10272.709884881973
  time_this_iter_s: 26.795058250427246
  time_total_s: 10272.709884881973
  timestamp: 1593924551
  timesteps_since_restore: 7320000
  timesteps_this_iter: 20000
  timesteps_total: 7320000
  training_iteration: 366
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=25504], 10272 s, 366 iter, 7320000 ts, 360 rew

agent-1: 13.0
agent-2: 3.0
agent-3: 15.0
agent-4: 25.0
agent-5: 23.0
agent-6: 20.0
agent-7: 11.0
agent-8: 27.0
agent-9: 13.0
agent-10: 21.0
agent-11: 32.0
agent-12: 18.0
agent-13: 34.0
agent-14: 38.0
agent-15: 17.0
agent-16: 26.0
agent-17: 20.0
agent-18: 21.0
agent-19: 32.0
agent-20: 24.0
Sum Reward: 433.0
Avg Reward: 21.65
Min Reward: 3.0
Gini Coefficient: 0.21697459584295611
20:20 Ratio: 3.4
Max-min Ratio: 12.666666666666666
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_00-49-38
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 572.0
  episode_reward_mean: 359.78
  episode_reward_min: 241.0
  episodes_this_iter: 1
  episodes_total: 366
  experiment_id: 35d66058da2d4c9882f832ee91e4aa4a
  hostname: gpu011
  info:
    apply_time_ms: 2.903
    dispatch_time_ms: 5.716
    learner:
      cur_lr: 0.0008724880171939731
      grad_gnorm: 14.337247848510742
      policy_entropy: 116.15029907226562
      policy_loss: 1.4890623092651367
      var_gnorm: 20.026235580444336
      vf_explained_var: 0.0
      vf_loss: 4.42369270324707
    num_steps_sampled: 7340000
    num_steps_trained: 7340000
    wait_time_ms: 255.996
  iterations_since_restore: 367
  node_ip: 172.17.8.11
  num_metric_batches_dropped: 0
  pid: 25504
  policy_reward_mean: {}
  time_since_restore: 10300.07249879837
  time_this_iter_s: 27.362613916397095
  time_total_s: 10300.07249879837
  timestamp: 1593924578
  timesteps_since_restore: 7340000
  timesteps_this_iter: 20000
  timesteps_total: 7340000
  training_iteration: 367
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=25504], 10300 s, 367 iter, 7340000 ts, 360 rew

agent-1: 13.0
agent-2: 11.0
agent-3: 22.0
agent-4: 35.0
agent-5: 28.0
agent-6: 18.0
agent-7: 29.0
agent-8: 41.0
agent-9: 24.0
agent-10: 35.0
agent-11: 45.0
agent-12: 52.0
agent-13: 34.0
agent-14: 9.0
agent-15: 23.0
agent-16: 34.0
agent-17: 25.0
agent-18: 35.0
agent-19: 41.0
agent-20: 8.0
Sum Reward: 562.0
Avg Reward: 28.1
Min Reward: 8.0
Gini Coefficient: 0.24270462633451959
20:20 Ratio: 4.365853658536586
Max-min Ratio: 6.5
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_00-50-05
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 572.0
  episode_reward_mean: 362.32
  episode_reward_min: 241.0
  episodes_this_iter: 1
  episodes_total: 367
  experiment_id: 35d66058da2d4c9882f832ee91e4aa4a
  hostname: gpu011
  info:
    apply_time_ms: 2.841
    dispatch_time_ms: 9.932
    learner:
      cur_lr: 0.0008711559930816293
      grad_gnorm: 40.0
      policy_entropy: 139.95652770996094
      policy_loss: 4.503728866577148
      var_gnorm: 20.028732299804688
      vf_explained_var: 0.0
      vf_loss: 34.74067687988281
    num_steps_sampled: 7360000
    num_steps_trained: 7360000
    wait_time_ms: 243.12
  iterations_since_restore: 368
  node_ip: 172.17.8.11
  num_metric_batches_dropped: 0
  pid: 25504
  policy_reward_mean: {}
  time_since_restore: 10327.175847053528
  time_this_iter_s: 27.10334825515747
  time_total_s: 10327.175847053528
  timestamp: 1593924605
  timesteps_since_restore: 7360000
  timesteps_this_iter: 20000
  timesteps_total: 7360000
  training_iteration: 368
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=25504], 10327 s, 368 iter, 7360000 ts, 362 rew

agent-1: 30.0
agent-2: 26.0
agent-3: 20.0
agent-4: 27.0
agent-5: 24.0
agent-6: 24.0
agent-7: 23.0
agent-8: 17.0
agent-9: 25.0
agent-10: 27.0
agent-11: 21.0
agent-12: 9.0
agent-13: 22.0
agent-14: 24.0
agent-15: 31.0
agent-16: 34.0
agent-17: 36.0
agent-18: 21.0
agent-19: 7.0
agent-20: 11.0
Sum Reward: 459.0
Avg Reward: 22.95
Min Reward: 7.0
Gini Coefficient: 0.17745098039215687
20:20 Ratio: 2.977272727272727
Max-min Ratio: 5.142857142857143
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_00-50-33
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 572.0
  episode_reward_mean: 362.76
  episode_reward_min: 241.0
  episodes_this_iter: 1
  episodes_total: 368
  experiment_id: 35d66058da2d4c9882f832ee91e4aa4a
  hostname: gpu011
  info:
    apply_time_ms: 2.903
    dispatch_time_ms: 7.074
    learner:
      cur_lr: 0.0008698240271769464
      grad_gnorm: 1.2339329719543457
      policy_entropy: 108.23420715332031
      policy_loss: -0.16255168616771698
      var_gnorm: 20.026981353759766
      vf_explained_var: 1.1920928955078125e-07
      vf_loss: 0.0005673074629157782
    num_steps_sampled: 7380000
    num_steps_trained: 7380000
    wait_time_ms: 255.834
  iterations_since_restore: 369
  node_ip: 172.17.8.11
  num_metric_batches_dropped: 0
  pid: 25504
  policy_reward_mean: {}
  time_since_restore: 10354.930593252182
  time_this_iter_s: 27.754746198654175
  time_total_s: 10354.930593252182
  timestamp: 1593924633
  timesteps_since_restore: 7380000
  timesteps_this_iter: 20000
  timesteps_total: 7380000
  training_iteration: 369
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=25504], 10354 s, 369 iter, 7380000 ts, 363 rew

agent-1: 16.0
agent-2: 20.0
agent-3: 22.0
agent-4: 25.0
agent-5: 10.0
agent-6: 37.0
agent-7: 10.0
agent-8: 15.0
agent-9: 14.0
agent-10: 11.0
agent-11: 11.0
agent-12: 26.0
agent-13: 22.0
agent-14: 4.0
agent-15: 9.0
agent-16: 27.0
agent-17: 20.0
agent-18: 12.0
agent-19: 11.0
agent-20: 3.0
Sum Reward: 325.0
Avg Reward: 16.25
Min Reward: 3.0
Gini Coefficient: 0.28292307692307694
20:20 Ratio: 4.423076923076923
Max-min Ratio: 12.333333333333334
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_00-51-00
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 572.0
  episode_reward_mean: 361.61
  episode_reward_min: 241.0
  episodes_this_iter: 1
  episodes_total: 369
  experiment_id: 35d66058da2d4c9882f832ee91e4aa4a
  hostname: gpu011
  info:
    apply_time_ms: 2.786
    dispatch_time_ms: 6.786
    learner:
      cur_lr: 0.0008684920030646026
      grad_gnorm: 34.15428924560547
      policy_entropy: 151.00827026367188
      policy_loss: -7.98725700378418
      var_gnorm: 20.027545928955078
      vf_explained_var: 0.0
      vf_loss: 0.46228906512260437
    num_steps_sampled: 7400000
    num_steps_trained: 7400000
    wait_time_ms: 268.441
  iterations_since_restore: 370
  node_ip: 172.17.8.11
  num_metric_batches_dropped: 0
  pid: 25504
  policy_reward_mean: {}
  time_since_restore: 10381.899074316025
  time_this_iter_s: 26.968481063842773
  time_total_s: 10381.899074316025
  timestamp: 1593924660
  timesteps_since_restore: 7400000
  timesteps_this_iter: 20000
  timesteps_total: 7400000
  training_iteration: 370
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=25504], 10381 s, 370 iter, 7400000 ts, 362 rew

agent-1: 22.0
agent-2: 19.0
agent-3: 10.0
agent-4: 24.0
agent-5: 16.0
agent-6: 8.0
agent-7: 32.0
agent-8: 17.0
agent-9: 10.0
agent-10: 25.0
agent-11: 12.0
agent-12: 18.0
agent-13: 8.0
agent-14: 21.0
agent-15: 6.0
agent-16: 12.0
agent-17: 16.0
agent-18: 15.0
agent-19: 34.0
agent-20: 7.0
Sum Reward: 332.0
Avg Reward: 16.6
Min Reward: 6.0
Gini Coefficient: 0.26144578313253014
20:20 Ratio: 3.9655172413793105
Max-min Ratio: 5.666666666666667
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_00-51-28
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 562.0
  episode_reward_mean: 359.21
  episode_reward_min: 241.0
  episodes_this_iter: 1
  episodes_total: 370
  experiment_id: 35d66058da2d4c9882f832ee91e4aa4a
  hostname: gpu011
  info:
    apply_time_ms: 2.784
    dispatch_time_ms: 7.167
    learner:
      cur_lr: 0.0008671599789522588
      grad_gnorm: 5.917290687561035
      policy_entropy: 184.70611572265625
      policy_loss: -1.581284523010254
      var_gnorm: 20.027685165405273
      vf_explained_var: 0.0
      vf_loss: 0.013798884116113186
    num_steps_sampled: 7420000
    num_steps_trained: 7420000
    wait_time_ms: 274.911
  iterations_since_restore: 371
  node_ip: 172.17.8.11
  num_metric_batches_dropped: 0
  pid: 25504
  policy_reward_mean: {}
  time_since_restore: 10409.722004652023
  time_this_iter_s: 27.822930335998535
  time_total_s: 10409.722004652023
  timestamp: 1593924688
  timesteps_since_restore: 7420000
  timesteps_this_iter: 20000
  timesteps_total: 7420000
  training_iteration: 371
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=25504], 10409 s, 371 iter, 7420000 ts, 359 rew

agent-1: 17.0
agent-2: 26.0
agent-3: 25.0
agent-4: 19.0
agent-5: 11.0
agent-6: 3.0
agent-7: 2.0
agent-8: 14.0
agent-9: 19.0
agent-10: 33.0
agent-11: 13.0
agent-12: 15.0
agent-13: 21.0
agent-14: 24.0
agent-15: 25.0
agent-16: 17.0
agent-17: 8.0
agent-18: 18.0
agent-19: 30.0
agent-20: 0.0
Sum Reward: 340.0
Avg Reward: 17.0
Min Reward: 0.0
Gini Coefficient: 0.2938235294117647
20:20 Ratio: 8.76923076923077
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_00-51-54
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 562.0
  episode_reward_mean: 358.6
  episode_reward_min: 241.0
  episodes_this_iter: 1
  episodes_total: 371
  experiment_id: 35d66058da2d4c9882f832ee91e4aa4a
  hostname: gpu011
  info:
    apply_time_ms: 3.876
    dispatch_time_ms: 6.911
    learner:
      cur_lr: 0.000865828013047576
      grad_gnorm: 40.0
      policy_entropy: 180.86138916015625
      policy_loss: 12.329703330993652
      var_gnorm: 20.03345489501953
      vf_explained_var: 0.0
      vf_loss: 24.363731384277344
    num_steps_sampled: 7440000
    num_steps_trained: 7440000
    wait_time_ms: 252.243
  iterations_since_restore: 372
  node_ip: 172.17.8.11
  num_metric_batches_dropped: 0
  pid: 25504
  policy_reward_mean: {}
  time_since_restore: 10436.35983800888
  time_this_iter_s: 26.6378333568573
  time_total_s: 10436.35983800888
  timestamp: 1593924714
  timesteps_since_restore: 7440000
  timesteps_this_iter: 20000
  timesteps_total: 7440000
  training_iteration: 372
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=25504], 10436 s, 372 iter, 7440000 ts, 359 rew

agent-1: 31.0
agent-2: 8.0
agent-3: 12.0
agent-4: 31.0
agent-5: 9.0
agent-6: 9.0
agent-7: 20.0
agent-8: 15.0
agent-9: 6.0
agent-10: 26.0
agent-11: 27.0
agent-12: 37.0
agent-13: 14.0
agent-14: 14.0
agent-15: 16.0
agent-16: 19.0
agent-17: 14.0
agent-18: 14.0
agent-19: 24.0
agent-20: 15.0
Sum Reward: 361.0
Avg Reward: 18.05
Min Reward: 6.0
Gini Coefficient: 0.2577562326869806
20:20 Ratio: 3.9375
Max-min Ratio: 6.166666666666667
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_00-52-22
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 562.0
  episode_reward_mean: 358.29
  episode_reward_min: 241.0
  episodes_this_iter: 1
  episodes_total: 372
  experiment_id: 35d66058da2d4c9882f832ee91e4aa4a
  hostname: gpu011
  info:
    apply_time_ms: 4.018
    dispatch_time_ms: 6.102
    learner:
      cur_lr: 0.0008644959889352322
      grad_gnorm: 39.999996185302734
      policy_entropy: 176.35159301757812
      policy_loss: 101.37884521484375
      var_gnorm: 20.029584884643555
      vf_explained_var: 5.960464477539063e-08
      vf_loss: 171.4406280517578
    num_steps_sampled: 7460000
    num_steps_trained: 7460000
    wait_time_ms: 235.06
  iterations_since_restore: 373
  node_ip: 172.17.8.11
  num_metric_batches_dropped: 0
  pid: 25504
  policy_reward_mean: {}
  time_since_restore: 10463.744879245758
  time_this_iter_s: 27.38504123687744
  time_total_s: 10463.744879245758
  timestamp: 1593924742
  timesteps_since_restore: 7460000
  timesteps_this_iter: 20000
  timesteps_total: 7460000
  training_iteration: 373
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=25504], 10463 s, 373 iter, 7460000 ts, 358 rew

agent-1: 22.0
agent-2: 5.0
agent-3: 44.0
agent-4: 6.0
agent-5: 47.0
agent-6: 24.0
agent-7: 7.0
agent-8: 16.0
agent-9: 30.0
agent-10: 15.0
agent-11: 28.0
agent-12: 19.0
agent-13: 29.0
agent-14: 29.0
agent-15: 34.0
agent-16: 16.0
agent-17: 17.0
agent-18: 7.0
agent-19: 23.0
agent-20: 50.0
Sum Reward: 468.0
Avg Reward: 23.4
Min Reward: 5.0
Gini Coefficient: 0.31004273504273505
20:20 Ratio: 7.0
Max-min Ratio: 10.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_00-52-49
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 562.0
  episode_reward_mean: 358.83
  episode_reward_min: 241.0
  episodes_this_iter: 1
  episodes_total: 373
  experiment_id: 35d66058da2d4c9882f832ee91e4aa4a
  hostname: gpu011
  info:
    apply_time_ms: 2.567
    dispatch_time_ms: 7.33
    learner:
      cur_lr: 0.0008631640230305493
      grad_gnorm: 34.00455093383789
      policy_entropy: 180.14361572265625
      policy_loss: -11.449934005737305
      var_gnorm: 20.04058265686035
      vf_explained_var: 5.960464477539063e-08
      vf_loss: 0.46702831983566284
    num_steps_sampled: 7480000
    num_steps_trained: 7480000
    wait_time_ms: 267.87
  iterations_since_restore: 374
  node_ip: 172.17.8.11
  num_metric_batches_dropped: 0
  pid: 25504
  policy_reward_mean: {}
  time_since_restore: 10490.976266860962
  time_this_iter_s: 27.231387615203857
  time_total_s: 10490.976266860962
  timestamp: 1593924769
  timesteps_since_restore: 7480000
  timesteps_this_iter: 20000
  timesteps_total: 7480000
  training_iteration: 374
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=25504], 10490 s, 374 iter, 7480000 ts, 359 rew

agent-1: 30.0
agent-2: 22.0
agent-3: 15.0
agent-4: 13.0
agent-5: 19.0
agent-6: 18.0
agent-7: 7.0
agent-8: 20.0
agent-9: 26.0
agent-10: 19.0
agent-11: 19.0
agent-12: 17.0
agent-13: 16.0
agent-14: 19.0
agent-15: 18.0
agent-16: 15.0
agent-17: 31.0
agent-18: 11.0
agent-19: 12.0
agent-20: 17.0
Sum Reward: 364.0
Avg Reward: 18.2
Min Reward: 7.0
Gini Coefficient: 0.16950549450549451
20:20 Ratio: 2.5348837209302326
Max-min Ratio: 4.428571428571429
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_00-53-17
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 562.0
  episode_reward_mean: 357.5
  episode_reward_min: 241.0
  episodes_this_iter: 1
  episodes_total: 374
  experiment_id: 35d66058da2d4c9882f832ee91e4aa4a
  hostname: gpu011
  info:
    apply_time_ms: 2.906
    dispatch_time_ms: 5.937
    learner:
      cur_lr: 0.0008618319989182055
      grad_gnorm: 40.0
      policy_entropy: 174.70005798339844
      policy_loss: 140.53173828125
      var_gnorm: 20.03857421875
      vf_explained_var: 0.0
      vf_loss: 189.27926635742188
    num_steps_sampled: 7500000
    num_steps_trained: 7500000
    wait_time_ms: 240.662
  iterations_since_restore: 375
  node_ip: 172.17.8.11
  num_metric_batches_dropped: 0
  pid: 25504
  policy_reward_mean: {}
  time_since_restore: 10518.658133745193
  time_this_iter_s: 27.681866884231567
  time_total_s: 10518.658133745193
  timestamp: 1593924797
  timesteps_since_restore: 7500000
  timesteps_this_iter: 20000
  timesteps_total: 7500000
  training_iteration: 375
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=25504], 10518 s, 375 iter, 7500000 ts, 358 rew

agent-1: 7.0
agent-2: 9.0
agent-3: 10.0
agent-4: 20.0
agent-5: 20.0
agent-6: 17.0
agent-7: 24.0
agent-8: 19.0
agent-9: 26.0
agent-10: 15.0
agent-11: 13.0
agent-12: 14.0
agent-13: 23.0
agent-14: 7.0
agent-15: 17.0
agent-16: 11.0
agent-17: 19.0
agent-18: 18.0
agent-19: 16.0
agent-20: 17.0
Sum Reward: 322.0
Avg Reward: 16.1
Min Reward: 7.0
Gini Coefficient: 0.18571428571428572
20:20 Ratio: 2.8181818181818183
Max-min Ratio: 3.7142857142857144
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_00-53-44
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 562.0
  episode_reward_mean: 356.98
  episode_reward_min: 241.0
  episodes_this_iter: 1
  episodes_total: 375
  experiment_id: 35d66058da2d4c9882f832ee91e4aa4a
  hostname: gpu011
  info:
    apply_time_ms: 3.187
    dispatch_time_ms: 6.98
    learner:
      cur_lr: 0.0008604999748058617
      grad_gnorm: 31.589738845825195
      policy_entropy: 169.32984924316406
      policy_loss: -9.367294311523438
      var_gnorm: 20.040828704833984
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 0.39526820182800293
    num_steps_sampled: 7520000
    num_steps_trained: 7520000
    wait_time_ms: 262.315
  iterations_since_restore: 376
  node_ip: 172.17.8.11
  num_metric_batches_dropped: 0
  pid: 25504
  policy_reward_mean: {}
  time_since_restore: 10545.78311753273
  time_this_iter_s: 27.12498378753662
  time_total_s: 10545.78311753273
  timestamp: 1593924824
  timesteps_since_restore: 7520000
  timesteps_this_iter: 20000
  timesteps_total: 7520000
  training_iteration: 376
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=25504], 10545 s, 376 iter, 7520000 ts, 357 rew

agent-1: 13.0
agent-2: 15.0
agent-3: 11.0
agent-4: 12.0
agent-5: 29.0
agent-6: 17.0
agent-7: 25.0
agent-8: 14.0
agent-9: 10.0
agent-10: 11.0
agent-11: 17.0
agent-12: 22.0
agent-13: 29.0
agent-14: 10.0
agent-15: 20.0
agent-16: 14.0
agent-17: 14.0
agent-18: 19.0
agent-19: 14.0
agent-20: 13.0
Sum Reward: 329.0
Avg Reward: 16.45
Min Reward: 10.0
Gini Coefficient: 0.18617021276595744
20:20 Ratio: 2.5
Max-min Ratio: 2.9
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_00-54-12
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 562.0
  episode_reward_mean: 356.93
  episode_reward_min: 241.0
  episodes_this_iter: 1
  episodes_total: 376
  experiment_id: 35d66058da2d4c9882f832ee91e4aa4a
  hostname: gpu011
  info:
    apply_time_ms: 3.002
    dispatch_time_ms: 6.567
    learner:
      cur_lr: 0.0008591680089011788
      grad_gnorm: 39.999996185302734
      policy_entropy: 176.83538818359375
      policy_loss: 56.786842346191406
      var_gnorm: 20.03205680847168
      vf_explained_var: -2.384185791015625e-07
      vf_loss: 75.41345977783203
    num_steps_sampled: 7540000
    num_steps_trained: 7540000
    wait_time_ms: 253.313
  iterations_since_restore: 377
  node_ip: 172.17.8.11
  num_metric_batches_dropped: 0
  pid: 25504
  policy_reward_mean: {}
  time_since_restore: 10573.450573444366
  time_this_iter_s: 27.667455911636353
  time_total_s: 10573.450573444366
  timestamp: 1593924852
  timesteps_since_restore: 7540000
  timesteps_this_iter: 20000
  timesteps_total: 7540000
  training_iteration: 377
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=25504], 10573 s, 377 iter, 7540000 ts, 357 rew

agent-1: 27.0
agent-2: 27.0
agent-3: 14.0
agent-4: 20.0
agent-5: 19.0
agent-6: 19.0
agent-7: 17.0
agent-8: 25.0
agent-9: 16.0
agent-10: 21.0
agent-11: 27.0
agent-12: 27.0
agent-13: 17.0
agent-14: 22.0
agent-15: 26.0
agent-16: 9.0
agent-17: 5.0
agent-18: 25.0
agent-19: 25.0
agent-20: 34.0
Sum Reward: 422.0
Avg Reward: 21.1
Min Reward: 5.0
Gini Coefficient: 0.17464454976303317
20:20 Ratio: 2.6136363636363638
Max-min Ratio: 6.8
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_00-54-39
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 562.0
  episode_reward_mean: 357.64
  episode_reward_min: 241.0
  episodes_this_iter: 1
  episodes_total: 377
  experiment_id: 35d66058da2d4c9882f832ee91e4aa4a
  hostname: gpu011
  info:
    apply_time_ms: 3.178
    dispatch_time_ms: 6.85
    learner:
      cur_lr: 0.000857835984788835
      grad_gnorm: 33.94229507446289
      policy_entropy: 191.07057189941406
      policy_loss: -12.0693359375
      var_gnorm: 20.030532836914062
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 0.418870210647583
    num_steps_sampled: 7560000
    num_steps_trained: 7560000
    wait_time_ms: 263.865
  iterations_since_restore: 378
  node_ip: 172.17.8.11
  num_metric_batches_dropped: 0
  pid: 25504
  policy_reward_mean: {}
  time_since_restore: 10600.401609182358
  time_this_iter_s: 26.951035737991333
  time_total_s: 10600.401609182358
  timestamp: 1593924879
  timesteps_since_restore: 7560000
  timesteps_this_iter: 20000
  timesteps_total: 7560000
  training_iteration: 378
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=25504], 10600 s, 378 iter, 7560000 ts, 358 rew

agent-1: 14.0
agent-2: 10.0
agent-3: 33.0
agent-4: 12.0
agent-5: 9.0
agent-6: 11.0
agent-7: 8.0
agent-8: 24.0
agent-9: 7.0
agent-10: 20.0
agent-11: 16.0
agent-12: 23.0
agent-13: 11.0
agent-14: 11.0
agent-15: 8.0
agent-16: 11.0
agent-17: 7.0
agent-18: 30.0
agent-19: 21.0
agent-20: 9.0
Sum Reward: 295.0
Avg Reward: 14.75
Min Reward: 7.0
Gini Coefficient: 0.27305084745762714
20:20 Ratio: 3.6666666666666665
Max-min Ratio: 4.714285714285714
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_00-55-07
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 562.0
  episode_reward_mean: 358.07
  episode_reward_min: 241.0
  episodes_this_iter: 1
  episodes_total: 378
  experiment_id: 35d66058da2d4c9882f832ee91e4aa4a
  hostname: gpu011
  info:
    apply_time_ms: 3.153
    dispatch_time_ms: 6.505
    learner:
      cur_lr: 0.0008565040188841522
      grad_gnorm: 3.6105592250823975
      policy_entropy: 186.33143615722656
      policy_loss: -0.6854360103607178
      var_gnorm: 20.035755157470703
      vf_explained_var: 0.0
      vf_loss: 0.00521255424246192
    num_steps_sampled: 7580000
    num_steps_trained: 7580000
    wait_time_ms: 284.971
  iterations_since_restore: 379
  node_ip: 172.17.8.11
  num_metric_batches_dropped: 0
  pid: 25504
  policy_reward_mean: {}
  time_since_restore: 10628.28052854538
  time_this_iter_s: 27.87891936302185
  time_total_s: 10628.28052854538
  timestamp: 1593924907
  timesteps_since_restore: 7580000
  timesteps_this_iter: 20000
  timesteps_total: 7580000
  training_iteration: 379
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=25504], 10628 s, 379 iter, 7580000 ts, 358 rew

agent-1: 10.0
agent-2: 12.0
agent-3: 5.0
agent-4: 17.0
agent-5: 19.0
agent-6: 18.0
agent-7: 27.0
agent-8: 10.0
agent-9: 15.0
agent-10: 30.0
agent-11: 24.0
agent-12: 22.0
agent-13: 22.0
agent-14: 30.0
agent-15: 18.0
agent-16: 14.0
agent-17: 22.0
agent-18: 10.0
agent-19: 19.0
agent-20: 15.0
Sum Reward: 359.0
Avg Reward: 17.95
Min Reward: 5.0
Gini Coefficient: 0.21016713091922007
20:20 Ratio: 3.1714285714285713
Max-min Ratio: 6.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_00-55-34
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 562.0
  episode_reward_mean: 357.22
  episode_reward_min: 241.0
  episodes_this_iter: 1
  episodes_total: 379
  experiment_id: 35d66058da2d4c9882f832ee91e4aa4a
  hostname: gpu011
  info:
    apply_time_ms: 2.663
    dispatch_time_ms: 7.155
    learner:
      cur_lr: 0.0008551719947718084
      grad_gnorm: 30.516307830810547
      policy_entropy: 155.4174041748047
      policy_loss: -9.29141616821289
      var_gnorm: 20.037702560424805
      vf_explained_var: 5.960464477539063e-08
      vf_loss: 0.37582746148109436
    num_steps_sampled: 7600000
    num_steps_trained: 7600000
    wait_time_ms: 272.088
  iterations_since_restore: 380
  node_ip: 172.17.8.11
  num_metric_batches_dropped: 0
  pid: 25504
  policy_reward_mean: {}
  time_since_restore: 10655.65689587593
  time_this_iter_s: 27.376367330551147
  time_total_s: 10655.65689587593
  timestamp: 1593924934
  timesteps_since_restore: 7600000
  timesteps_this_iter: 20000
  timesteps_total: 7600000
  training_iteration: 380
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=25504], 10655 s, 380 iter, 7600000 ts, 357 rew

agent-1: 10.0
agent-2: 18.0
agent-3: 8.0
agent-4: 28.0
agent-5: 27.0
agent-6: 21.0
agent-7: 9.0
agent-8: 12.0
agent-9: 16.0
agent-10: 16.0
agent-11: 33.0
agent-12: 23.0
agent-13: 14.0
agent-14: 15.0
agent-15: 20.0
agent-16: 4.0
agent-17: 13.0
agent-18: 17.0
agent-19: 33.0
agent-20: 6.0
Sum Reward: 343.0
Avg Reward: 17.15
Min Reward: 4.0
Gini Coefficient: 0.26865889212827987
20:20 Ratio: 4.481481481481482
Max-min Ratio: 8.25
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_00-56-02
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 562.0
  episode_reward_mean: 355.81
  episode_reward_min: 241.0
  episodes_this_iter: 1
  episodes_total: 380
  experiment_id: 35d66058da2d4c9882f832ee91e4aa4a
  hostname: gpu011
  info:
    apply_time_ms: 2.608
    dispatch_time_ms: 7.35
    learner:
      cur_lr: 0.0008538400288671255
      grad_gnorm: 11.624287605285645
      policy_entropy: 140.61570739746094
      policy_loss: -2.6937758922576904
      var_gnorm: 20.036815643310547
      vf_explained_var: 0.0
      vf_loss: 0.05457979440689087
    num_steps_sampled: 7620000
    num_steps_trained: 7620000
    wait_time_ms: 274.342
  iterations_since_restore: 381
  node_ip: 172.17.8.11
  num_metric_batches_dropped: 0
  pid: 25504
  policy_reward_mean: {}
  time_since_restore: 10683.132899999619
  time_this_iter_s: 27.476004123687744
  time_total_s: 10683.132899999619
  timestamp: 1593924962
  timesteps_since_restore: 7620000
  timesteps_this_iter: 20000
  timesteps_total: 7620000
  training_iteration: 381
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=25504], 10683 s, 381 iter, 7620000 ts, 356 rew

agent-1: 12.0
agent-2: 20.0
agent-3: 9.0
agent-4: 14.0
agent-5: 6.0
agent-6: 19.0
agent-7: 25.0
agent-8: 28.0
agent-9: 6.0
agent-10: 6.0
agent-11: 17.0
agent-12: 18.0
agent-13: 10.0
agent-14: 15.0
agent-15: 14.0
agent-16: 11.0
agent-17: 33.0
agent-18: 23.0
agent-19: 22.0
agent-20: 9.0
Sum Reward: 317.0
Avg Reward: 15.85
Min Reward: 6.0
Gini Coefficient: 0.26545741324921135
20:20 Ratio: 4.037037037037037
Max-min Ratio: 5.5
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_00-56-29
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 562.0
  episode_reward_mean: 354.58
  episode_reward_min: 241.0
  episodes_this_iter: 1
  episodes_total: 381
  experiment_id: 35d66058da2d4c9882f832ee91e4aa4a
  hostname: gpu011
  info:
    apply_time_ms: 2.697
    dispatch_time_ms: 6.307
    learner:
      cur_lr: 0.0008525080047547817
      grad_gnorm: 40.0
      policy_entropy: 132.69810485839844
      policy_loss: 15.250676155090332
      var_gnorm: 20.038835525512695
      vf_explained_var: 1.7881393432617188e-07
      vf_loss: 18.611024856567383
    num_steps_sampled: 7640000
    num_steps_trained: 7640000
    wait_time_ms: 260.528
  iterations_since_restore: 382
  node_ip: 172.17.8.11
  num_metric_batches_dropped: 0
  pid: 25504
  policy_reward_mean: {}
  time_since_restore: 10710.122696638107
  time_this_iter_s: 26.98979663848877
  time_total_s: 10710.122696638107
  timestamp: 1593924989
  timesteps_since_restore: 7640000
  timesteps_this_iter: 20000
  timesteps_total: 7640000
  training_iteration: 382
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=25504], 10710 s, 382 iter, 7640000 ts, 355 rew

agent-1: 17.0
agent-2: 24.0
agent-3: 20.0
agent-4: 31.0
agent-5: 26.0
agent-6: 15.0
agent-7: 15.0
agent-8: 24.0
agent-9: 17.0
agent-10: 17.0
agent-11: 18.0
agent-12: 16.0
agent-13: 32.0
agent-14: 7.0
agent-15: 27.0
agent-16: 21.0
agent-17: 23.0
agent-18: 11.0
agent-19: 10.0
agent-20: 10.0
Sum Reward: 381.0
Avg Reward: 19.05
Min Reward: 7.0
Gini Coefficient: 0.2022309711286089
20:20 Ratio: 3.0526315789473686
Max-min Ratio: 4.571428571428571
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_00-56-57
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 562.0
  episode_reward_mean: 353.43
  episode_reward_min: 241.0
  episodes_this_iter: 1
  episodes_total: 382
  experiment_id: 35d66058da2d4c9882f832ee91e4aa4a
  hostname: gpu011
  info:
    apply_time_ms: 3.452
    dispatch_time_ms: 7.217
    learner:
      cur_lr: 0.0008511759806424379
      grad_gnorm: 40.0
      policy_entropy: 165.4857940673828
      policy_loss: 45.537288665771484
      var_gnorm: 20.03690528869629
      vf_explained_var: 0.0
      vf_loss: 58.83726501464844
    num_steps_sampled: 7660000
    num_steps_trained: 7660000
    wait_time_ms: 266.849
  iterations_since_restore: 383
  node_ip: 172.17.8.11
  num_metric_batches_dropped: 0
  pid: 25504
  policy_reward_mean: {}
  time_since_restore: 10737.84802532196
  time_this_iter_s: 27.72532868385315
  time_total_s: 10737.84802532196
  timestamp: 1593925017
  timesteps_since_restore: 7660000
  timesteps_this_iter: 20000
  timesteps_total: 7660000
  training_iteration: 383
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=25504], 10737 s, 383 iter, 7660000 ts, 353 rew

agent-1: 34.0
agent-2: 18.0
agent-3: 25.0
agent-4: 7.0
agent-5: 14.0
agent-6: 20.0
agent-7: 23.0
agent-8: 22.0
agent-9: 10.0
agent-10: 15.0
agent-11: 14.0
agent-12: 18.0
agent-13: 19.0
agent-14: 30.0
agent-15: 12.0
agent-16: 14.0
agent-17: 10.0
agent-18: 22.0
agent-19: 18.0
agent-20: 22.0
Sum Reward: 367.0
Avg Reward: 18.35
Min Reward: 7.0
Gini Coefficient: 0.19959128065395096
20:20 Ratio: 2.871794871794872
Max-min Ratio: 4.857142857142857
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_00-57-24
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 562.0
  episode_reward_mean: 353.7
  episode_reward_min: 241.0
  episodes_this_iter: 1
  episodes_total: 383
  experiment_id: 35d66058da2d4c9882f832ee91e4aa4a
  hostname: gpu011
  info:
    apply_time_ms: 3.39
    dispatch_time_ms: 6.786
    learner:
      cur_lr: 0.0008498440147377551
      grad_gnorm: 33.17467498779297
      policy_entropy: 152.35923767089844
      policy_loss: -10.03330135345459
      var_gnorm: 20.040958404541016
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 0.4358066916465759
    num_steps_sampled: 7680000
    num_steps_trained: 7680000
    wait_time_ms: 261.53
  iterations_since_restore: 384
  node_ip: 172.17.8.11
  num_metric_batches_dropped: 0
  pid: 25504
  policy_reward_mean: {}
  time_since_restore: 10765.116750955582
  time_this_iter_s: 27.268725633621216
  time_total_s: 10765.116750955582
  timestamp: 1593925044
  timesteps_since_restore: 7680000
  timesteps_this_iter: 20000
  timesteps_total: 7680000
  training_iteration: 384
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=25504], 10765 s, 384 iter, 7680000 ts, 354 rew

agent-1: 5.0
agent-2: 18.0
agent-3: 29.0
agent-4: 24.0
agent-5: 11.0
agent-6: 16.0
agent-7: 16.0
agent-8: 24.0
agent-9: 7.0
agent-10: 13.0
agent-11: 11.0
agent-12: 7.0
agent-13: 16.0
agent-14: 11.0
agent-15: 22.0
agent-16: 25.0
agent-17: 11.0
agent-18: 23.0
agent-19: 17.0
agent-20: 23.0
Sum Reward: 329.0
Avg Reward: 16.45
Min Reward: 5.0
Gini Coefficient: 0.23267477203647416
20:20 Ratio: 3.4
Max-min Ratio: 5.8
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_00-57-51
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 562.0
  episode_reward_mean: 354.04
  episode_reward_min: 241.0
  episodes_this_iter: 1
  episodes_total: 384
  experiment_id: 35d66058da2d4c9882f832ee91e4aa4a
  hostname: gpu011
  info:
    apply_time_ms: 3.064
    dispatch_time_ms: 5.988
    learner:
      cur_lr: 0.0008485119906254113
      grad_gnorm: 40.0
      policy_entropy: 147.2667999267578
      policy_loss: 33.923927307128906
      var_gnorm: 20.039613723754883
      vf_explained_var: 0.0
      vf_loss: 39.458438873291016
    num_steps_sampled: 7700000
    num_steps_trained: 7700000
    wait_time_ms: 255.865
  iterations_since_restore: 385
  node_ip: 172.17.8.11
  num_metric_batches_dropped: 0
  pid: 25504
  policy_reward_mean: {}
  time_since_restore: 10792.753265857697
  time_this_iter_s: 27.636514902114868
  time_total_s: 10792.753265857697
  timestamp: 1593925071
  timesteps_since_restore: 7700000
  timesteps_this_iter: 20000
  timesteps_total: 7700000
  training_iteration: 385
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=25504], 10792 s, 385 iter, 7700000 ts, 354 rew

agent-1: 19.0
agent-2: 16.0
agent-3: 20.0
agent-4: 11.0
agent-5: 8.0
agent-6: 15.0
agent-7: 22.0
agent-8: 18.0
agent-9: 26.0
agent-10: 24.0
agent-11: 24.0
agent-12: 16.0
agent-13: 32.0
agent-14: 19.0
agent-15: 19.0
agent-16: 16.0
agent-17: 12.0
agent-18: 12.0
agent-19: 13.0
agent-20: 27.0
Sum Reward: 369.0
Avg Reward: 18.45
Min Reward: 8.0
Gini Coefficient: 0.18035230352303522
20:20 Ratio: 2.5348837209302326
Max-min Ratio: 4.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_00-58-19
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 562.0
  episode_reward_mean: 353.92
  episode_reward_min: 241.0
  episodes_this_iter: 1
  episodes_total: 385
  experiment_id: 35d66058da2d4c9882f832ee91e4aa4a
  hostname: gpu011
  info:
    apply_time_ms: 3.428
    dispatch_time_ms: 7.901
    learner:
      cur_lr: 0.0008471800247207284
      grad_gnorm: 16.72222137451172
      policy_entropy: 155.03677368164062
      policy_loss: 3.120670795440674
      var_gnorm: 20.03348731994629
      vf_explained_var: 0.0
      vf_loss: 12.976327896118164
    num_steps_sampled: 7720000
    num_steps_trained: 7720000
    wait_time_ms: 263.398
  iterations_since_restore: 386
  node_ip: 172.17.8.11
  num_metric_batches_dropped: 0
  pid: 25504
  policy_reward_mean: {}
  time_since_restore: 10820.068984031677
  time_this_iter_s: 27.315718173980713
  time_total_s: 10820.068984031677
  timestamp: 1593925099
  timesteps_since_restore: 7720000
  timesteps_this_iter: 20000
  timesteps_total: 7720000
  training_iteration: 386
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=25504], 10820 s, 386 iter, 7720000 ts, 354 rew

agent-1: 21.0
agent-2: 32.0
agent-3: 19.0
agent-4: 25.0
agent-5: 29.0
agent-6: 25.0
agent-7: 24.0
agent-8: 16.0
agent-9: 16.0
agent-10: 40.0
agent-11: 8.0
agent-12: 21.0
agent-13: 29.0
agent-14: 19.0
agent-15: 27.0
agent-16: 15.0
agent-17: 7.0
agent-18: 29.0
agent-19: 14.0
agent-20: 18.0
Sum Reward: 434.0
Avg Reward: 21.7
Min Reward: 7.0
Gini Coefficient: 0.20483870967741935
20:20 Ratio: 2.9545454545454546
Max-min Ratio: 5.714285714285714
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_00-58-46
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 562.0
  episode_reward_mean: 355.25
  episode_reward_min: 241.0
  episodes_this_iter: 1
  episodes_total: 386
  experiment_id: 35d66058da2d4c9882f832ee91e4aa4a
  hostname: gpu011
  info:
    apply_time_ms: 2.77
    dispatch_time_ms: 6.525
    learner:
      cur_lr: 0.0008458480006083846
      grad_gnorm: 40.0
      policy_entropy: 177.6291046142578
      policy_loss: 49.571861267089844
      var_gnorm: 20.03353500366211
      vf_explained_var: 0.0
      vf_loss: 98.50457763671875
    num_steps_sampled: 7740000
    num_steps_trained: 7740000
    wait_time_ms: 256.214
  iterations_since_restore: 387
  node_ip: 172.17.8.11
  num_metric_batches_dropped: 0
  pid: 25504
  policy_reward_mean: {}
  time_since_restore: 10847.658046245575
  time_this_iter_s: 27.589062213897705
  time_total_s: 10847.658046245575
  timestamp: 1593925126
  timesteps_since_restore: 7740000
  timesteps_this_iter: 20000
  timesteps_total: 7740000
  training_iteration: 387
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=25504], 10847 s, 387 iter, 7740000 ts, 355 rew

agent-1: 23.0
agent-2: 12.0
agent-3: 26.0
agent-4: 17.0
agent-5: 13.0
agent-6: 15.0
agent-7: 7.0
agent-8: 19.0
agent-9: 10.0
agent-10: 15.0
agent-11: 19.0
agent-12: 8.0
agent-13: 8.0
agent-14: 15.0
agent-15: 22.0
agent-16: 16.0
agent-17: 16.0
agent-18: 11.0
agent-19: 17.0
agent-20: 6.0
Sum Reward: 295.0
Avg Reward: 14.75
Min Reward: 6.0
Gini Coefficient: 0.2052542372881356
20:20 Ratio: 3.103448275862069
Max-min Ratio: 4.333333333333333
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_00-59-14
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 562.0
  episode_reward_mean: 354.89
  episode_reward_min: 241.0
  episodes_this_iter: 1
  episodes_total: 387
  experiment_id: 35d66058da2d4c9882f832ee91e4aa4a
  hostname: gpu011
  info:
    apply_time_ms: 2.786
    dispatch_time_ms: 7.933
    learner:
      cur_lr: 0.0008445159764960408
      grad_gnorm: 28.415544509887695
      policy_entropy: 135.1227264404297
      policy_loss: -6.387093544006348
      var_gnorm: 20.03612518310547
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 0.32256370782852173
    num_steps_sampled: 7760000
    num_steps_trained: 7760000
    wait_time_ms: 265.004
  iterations_since_restore: 388
  node_ip: 172.17.8.11
  num_metric_batches_dropped: 0
  pid: 25504
  policy_reward_mean: {}
  time_since_restore: 10875.131304979324
  time_this_iter_s: 27.47325873374939
  time_total_s: 10875.131304979324
  timestamp: 1593925154
  timesteps_since_restore: 7760000
  timesteps_this_iter: 20000
  timesteps_total: 7760000
  training_iteration: 388
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=25504], 10875 s, 388 iter, 7760000 ts, 355 rew

agent-1: 6.0
agent-2: 8.0
agent-3: 16.0
agent-4: 6.0
agent-5: 8.0
agent-6: 27.0
agent-7: 19.0
agent-8: 25.0
agent-9: 17.0
agent-10: 16.0
agent-11: 12.0
agent-12: 22.0
agent-13: 26.0
agent-14: 25.0
agent-15: 8.0
agent-16: 13.0
agent-17: 21.0
agent-18: 27.0
agent-19: 0.0
agent-20: 17.0
Sum Reward: 319.0
Avg Reward: 15.95
Min Reward: 0.0
Gini Coefficient: 0.2822884012539185
20:20 Ratio: 5.25
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_00-59-42
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 562.0
  episode_reward_mean: 355.01
  episode_reward_min: 241.0
  episodes_this_iter: 1
  episodes_total: 388
  experiment_id: 35d66058da2d4c9882f832ee91e4aa4a
  hostname: gpu011
  info:
    apply_time_ms: 2.721
    dispatch_time_ms: 5.982
    learner:
      cur_lr: 0.000843184010591358
      grad_gnorm: 40.0
      policy_entropy: 174.8846893310547
      policy_loss: 37.0532112121582
      var_gnorm: 20.038667678833008
      vf_explained_var: 0.0
      vf_loss: 49.202667236328125
    num_steps_sampled: 7780000
    num_steps_trained: 7780000
    wait_time_ms: 252.36
  iterations_since_restore: 389
  node_ip: 172.17.8.11
  num_metric_batches_dropped: 0
  pid: 25504
  policy_reward_mean: {}
  time_since_restore: 10902.724489688873
  time_this_iter_s: 27.59318470954895
  time_total_s: 10902.724489688873
  timestamp: 1593925182
  timesteps_since_restore: 7780000
  timesteps_this_iter: 20000
  timesteps_total: 7780000
  training_iteration: 389
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=25504], 10902 s, 389 iter, 7780000 ts, 355 rew

agent-1: 26.0
agent-2: 5.0
agent-3: 28.0
agent-4: 9.0
agent-5: 17.0
agent-6: 23.0
agent-7: 15.0
agent-8: 15.0
agent-9: 17.0
agent-10: 27.0
agent-11: 25.0
agent-12: 4.0
agent-13: 14.0
agent-14: 19.0
agent-15: 12.0
agent-16: 13.0
agent-17: 13.0
agent-18: 13.0
agent-19: 8.0
agent-20: 16.0
Sum Reward: 319.0
Avg Reward: 15.95
Min Reward: 4.0
Gini Coefficient: 0.2409090909090909
20:20 Ratio: 4.076923076923077
Max-min Ratio: 7.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_01-00-09
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 562.0
  episode_reward_mean: 354.62
  episode_reward_min: 241.0
  episodes_this_iter: 1
  episodes_total: 389
  experiment_id: 35d66058da2d4c9882f832ee91e4aa4a
  hostname: gpu011
  info:
    apply_time_ms: 3.899
    dispatch_time_ms: 5.678
    learner:
      cur_lr: 0.0008418519864790142
      grad_gnorm: 25.591541290283203
      policy_entropy: 185.7989044189453
      policy_loss: 4.256466388702393
      var_gnorm: 20.035221099853516
      vf_explained_var: 0.0
      vf_loss: 19.77655792236328
    num_steps_sampled: 7800000
    num_steps_trained: 7800000
    wait_time_ms: 307.545
  iterations_since_restore: 390
  node_ip: 172.17.8.11
  num_metric_batches_dropped: 0
  pid: 25504
  policy_reward_mean: {}
  time_since_restore: 10930.205375671387
  time_this_iter_s: 27.480885982513428
  time_total_s: 10930.205375671387
  timestamp: 1593925209
  timesteps_since_restore: 7800000
  timesteps_this_iter: 20000
  timesteps_total: 7800000
  training_iteration: 390
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=25504], 10930 s, 390 iter, 7800000 ts, 355 rew

agent-1: 8.0
agent-2: 17.0
agent-3: 10.0
agent-4: 8.0
agent-5: 41.0
agent-6: 30.0
agent-7: 28.0
agent-8: 20.0
agent-9: 35.0
agent-10: 21.0
agent-11: 25.0
agent-12: 23.0
agent-13: 21.0
agent-14: 17.0
agent-15: 16.0
agent-16: 22.0
agent-17: 7.0
agent-18: 18.0
agent-19: 18.0
agent-20: 27.0
Sum Reward: 412.0
Avg Reward: 20.6
Min Reward: 7.0
Gini Coefficient: 0.23470873786407767
20:20 Ratio: 4.0606060606060606
Max-min Ratio: 5.857142857142857
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_01-00-36
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 562.0
  episode_reward_mean: 355.55
  episode_reward_min: 241.0
  episodes_this_iter: 1
  episodes_total: 390
  experiment_id: 35d66058da2d4c9882f832ee91e4aa4a
  hostname: gpu011
  info:
    apply_time_ms: 4.033
    dispatch_time_ms: 6.622
    learner:
      cur_lr: 0.0008405200205743313
      grad_gnorm: 14.534372329711914
      policy_entropy: 194.47056579589844
      policy_loss: -3.9846670627593994
      var_gnorm: 20.036216735839844
      vf_explained_var: 0.0
      vf_loss: 0.5547009706497192
    num_steps_sampled: 7820000
    num_steps_trained: 7820000
    wait_time_ms: 247.408
  iterations_since_restore: 391
  node_ip: 172.17.8.11
  num_metric_batches_dropped: 0
  pid: 25504
  policy_reward_mean: {}
  time_since_restore: 10957.405165195465
  time_this_iter_s: 27.19978952407837
  time_total_s: 10957.405165195465
  timestamp: 1593925236
  timesteps_since_restore: 7820000
  timesteps_this_iter: 20000
  timesteps_total: 7820000
  training_iteration: 391
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=25504], 10957 s, 391 iter, 7820000 ts, 356 rew

agent-1: 28.0
agent-2: 21.0
agent-3: 29.0
agent-4: 20.0
agent-5: 16.0
agent-6: 32.0
agent-7: 38.0
agent-8: 22.0
agent-9: 33.0
agent-10: 6.0
agent-11: 26.0
agent-12: 25.0
agent-13: 31.0
agent-14: 19.0
agent-15: 7.0
agent-16: 5.0
agent-17: 30.0
agent-18: 12.0
agent-19: 22.0
agent-20: 21.0
Sum Reward: 443.0
Avg Reward: 22.15
Min Reward: 5.0
Gini Coefficient: 0.23081264108352145
20:20 Ratio: 4.466666666666667
Max-min Ratio: 7.6
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_01-01-04
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 562.0
  episode_reward_mean: 356.98
  episode_reward_min: 241.0
  episodes_this_iter: 1
  episodes_total: 391
  experiment_id: 35d66058da2d4c9882f832ee91e4aa4a
  hostname: gpu011
  info:
    apply_time_ms: 3.284
    dispatch_time_ms: 7.187
    learner:
      cur_lr: 0.0008391879964619875
      grad_gnorm: 40.0
      policy_entropy: 177.8601531982422
      policy_loss: 19.22162628173828
      var_gnorm: 20.03486442565918
      vf_explained_var: 1.1920928955078125e-07
      vf_loss: 16.58611297607422
    num_steps_sampled: 7840000
    num_steps_trained: 7840000
    wait_time_ms: 262.91
  iterations_since_restore: 392
  node_ip: 172.17.8.11
  num_metric_batches_dropped: 0
  pid: 25504
  policy_reward_mean: {}
  time_since_restore: 10984.977531671524
  time_this_iter_s: 27.57236647605896
  time_total_s: 10984.977531671524
  timestamp: 1593925264
  timesteps_since_restore: 7840000
  timesteps_this_iter: 20000
  timesteps_total: 7840000
  training_iteration: 392
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=25504], 10984 s, 392 iter, 7840000 ts, 357 rew

agent-1: 10.0
agent-2: 17.0
agent-3: 10.0
agent-4: 9.0
agent-5: 19.0
agent-6: 17.0
agent-7: 16.0
agent-8: 15.0
agent-9: 15.0
agent-10: 14.0
agent-11: 26.0
agent-12: 9.0
agent-13: 7.0
agent-14: 3.0
agent-15: 30.0
agent-16: 13.0
agent-17: 24.0
agent-18: 16.0
agent-19: 27.0
agent-20: 24.0
Sum Reward: 321.0
Avg Reward: 16.05
Min Reward: 3.0
Gini Coefficient: 0.2468847352024922
20:20 Ratio: 3.8214285714285716
Max-min Ratio: 10.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_01-01-32
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 562.0
  episode_reward_mean: 357.06
  episode_reward_min: 241.0
  episodes_this_iter: 1
  episodes_total: 392
  experiment_id: 35d66058da2d4c9882f832ee91e4aa4a
  hostname: gpu011
  info:
    apply_time_ms: 3.052
    dispatch_time_ms: 7.164
    learner:
      cur_lr: 0.0008378559723496437
      grad_gnorm: 7.099381923675537
      policy_entropy: 188.70274353027344
      policy_loss: -1.8123500347137451
      var_gnorm: 20.034656524658203
      vf_explained_var: 0.0
      vf_loss: 0.019348744302988052
    num_steps_sampled: 7860000
    num_steps_trained: 7860000
    wait_time_ms: 274.953
  iterations_since_restore: 393
  node_ip: 172.17.8.11
  num_metric_batches_dropped: 0
  pid: 25504
  policy_reward_mean: {}
  time_since_restore: 11012.832650661469
  time_this_iter_s: 27.855118989944458
  time_total_s: 11012.832650661469
  timestamp: 1593925292
  timesteps_since_restore: 7860000
  timesteps_this_iter: 20000
  timesteps_total: 7860000
  training_iteration: 393
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=25504], 11012 s, 393 iter, 7860000 ts, 357 rew

agent-1: 16.0
agent-2: 6.0
agent-3: 20.0
agent-4: 31.0
agent-5: 6.0
agent-6: 11.0
agent-7: 16.0
agent-8: 8.0
agent-9: 17.0
agent-10: 9.0
agent-11: 8.0
agent-12: 5.0
agent-13: 9.0
agent-14: 9.0
agent-15: 20.0
agent-16: 18.0
agent-17: 9.0
agent-18: 7.0
agent-19: 24.0
agent-20: 11.0
Sum Reward: 260.0
Avg Reward: 13.0
Min Reward: 5.0
Gini Coefficient: 0.28115384615384614
20:20 Ratio: 3.9583333333333335
Max-min Ratio: 6.2
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_01-01-59
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 562.0
  episode_reward_mean: 356.64
  episode_reward_min: 241.0
  episodes_this_iter: 1
  episodes_total: 393
  experiment_id: 35d66058da2d4c9882f832ee91e4aa4a
  hostname: gpu011
  info:
    apply_time_ms: 2.789
    dispatch_time_ms: 5.883
    learner:
      cur_lr: 0.0008365240064449608
      grad_gnorm: 21.929506301879883
      policy_entropy: 183.57302856445312
      policy_loss: -4.433856964111328
      var_gnorm: 20.037641525268555
      vf_explained_var: 2.384185791015625e-07
      vf_loss: 6.707849502563477
    num_steps_sampled: 7880000
    num_steps_trained: 7880000
    wait_time_ms: 266.89
  iterations_since_restore: 394
  node_ip: 172.17.8.11
  num_metric_batches_dropped: 0
  pid: 25504
  policy_reward_mean: {}
  time_since_restore: 11040.105075597763
  time_this_iter_s: 27.272424936294556
  time_total_s: 11040.105075597763
  timestamp: 1593925319
  timesteps_since_restore: 7880000
  timesteps_this_iter: 20000
  timesteps_total: 7880000
  training_iteration: 394
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=25504], 11040 s, 394 iter, 7880000 ts, 357 rew

agent-1: 16.0
agent-2: 25.0
agent-3: 25.0
agent-4: 16.0
agent-5: 29.0
agent-6: 9.0
agent-7: 38.0
agent-8: 11.0
agent-9: 22.0
agent-10: 5.0
agent-11: 15.0
agent-12: 1.0
agent-13: 22.0
agent-14: 10.0
agent-15: 18.0
agent-16: 22.0
agent-17: 8.0
agent-18: 3.0
agent-19: 9.0
agent-20: 28.0
Sum Reward: 332.0
Avg Reward: 16.6
Min Reward: 1.0
Gini Coefficient: 0.3240963855421687
20:20 Ratio: 7.0588235294117645
Max-min Ratio: 38.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_01-02-27
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 562.0
  episode_reward_mean: 356.79
  episode_reward_min: 241.0
  episodes_this_iter: 1
  episodes_total: 394
  experiment_id: 35d66058da2d4c9882f832ee91e4aa4a
  hostname: gpu011
  info:
    apply_time_ms: 3.287
    dispatch_time_ms: 6.68
    learner:
      cur_lr: 0.000835191982332617
      grad_gnorm: 6.267718315124512
      policy_entropy: 186.33917236328125
      policy_loss: -1.6469686031341553
      var_gnorm: 20.037567138671875
      vf_explained_var: 0.0
      vf_loss: 0.01581629365682602
    num_steps_sampled: 7900000
    num_steps_trained: 7900000
    wait_time_ms: 270.986
  iterations_since_restore: 395
  node_ip: 172.17.8.11
  num_metric_batches_dropped: 0
  pid: 25504
  policy_reward_mean: {}
  time_since_restore: 11068.036804199219
  time_this_iter_s: 27.93172860145569
  time_total_s: 11068.036804199219
  timestamp: 1593925347
  timesteps_since_restore: 7900000
  timesteps_this_iter: 20000
  timesteps_total: 7900000
  training_iteration: 395
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=25504], 11068 s, 395 iter, 7900000 ts, 357 rew

agent-1: 19.0
agent-2: 20.0
agent-3: 13.0
agent-4: 18.0
agent-5: 12.0
agent-6: 1.0
agent-7: 10.0
agent-8: 7.0
agent-9: 12.0
agent-10: 14.0
agent-11: 9.0
agent-12: 19.0
agent-13: 19.0
agent-14: 11.0
agent-15: 5.0
agent-16: 9.0
agent-17: 30.0
agent-18: 8.0
agent-19: 15.0
agent-20: 13.0
Sum Reward: 264.0
Avg Reward: 13.2
Min Reward: 1.0
Gini Coefficient: 0.26022727272727275
20:20 Ratio: 4.190476190476191
Max-min Ratio: 30.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_01-02-54
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 562.0
  episode_reward_mean: 355.81
  episode_reward_min: 241.0
  episodes_this_iter: 1
  episodes_total: 395
  experiment_id: 35d66058da2d4c9882f832ee91e4aa4a
  hostname: gpu011
  info:
    apply_time_ms: 3.027
    dispatch_time_ms: 5.977
    learner:
      cur_lr: 0.0008338600164279342
      grad_gnorm: 31.965402603149414
      policy_entropy: 174.98471069335938
      policy_loss: -10.20881462097168
      var_gnorm: 20.041242599487305
      vf_explained_var: 0.0
      vf_loss: 3.090939521789551
    num_steps_sampled: 7920000
    num_steps_trained: 7920000
    wait_time_ms: 261.638
  iterations_since_restore: 396
  node_ip: 172.17.8.11
  num_metric_batches_dropped: 0
  pid: 25504
  policy_reward_mean: {}
  time_since_restore: 11095.015802621841
  time_this_iter_s: 26.97899842262268
  time_total_s: 11095.015802621841
  timestamp: 1593925374
  timesteps_since_restore: 7920000
  timesteps_this_iter: 20000
  timesteps_total: 7920000
  training_iteration: 396
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=25504], 11095 s, 396 iter, 7920000 ts, 356 rew

agent-1: 16.0
agent-2: 15.0
agent-3: 13.0
agent-4: 7.0
agent-5: 20.0
agent-6: 39.0
agent-7: 16.0
agent-8: 29.0
agent-9: 22.0
agent-10: 26.0
agent-11: 15.0
agent-12: 9.0
agent-13: 9.0
agent-14: 17.0
agent-15: 22.0
agent-16: 19.0
agent-17: 15.0
agent-18: 18.0
agent-19: 23.0
agent-20: 9.0
Sum Reward: 359.0
Avg Reward: 17.95
Min Reward: 7.0
Gini Coefficient: 0.22409470752089136
20:20 Ratio: 3.4411764705882355
Max-min Ratio: 5.571428571428571
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_01-03-22
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 562.0
  episode_reward_mean: 356.15
  episode_reward_min: 241.0
  episodes_this_iter: 1
  episodes_total: 396
  experiment_id: 35d66058da2d4c9882f832ee91e4aa4a
  hostname: gpu011
  info:
    apply_time_ms: 2.917
    dispatch_time_ms: 6.587
    learner:
      cur_lr: 0.0008325279923155904
      grad_gnorm: 14.210124969482422
      policy_entropy: 189.56671142578125
      policy_loss: -4.047606468200684
      var_gnorm: 20.038272857666016
      vf_explained_var: 5.960464477539063e-08
      vf_loss: 0.0815795436501503
    num_steps_sampled: 7940000
    num_steps_trained: 7940000
    wait_time_ms: 270.386
  iterations_since_restore: 397
  node_ip: 172.17.8.11
  num_metric_batches_dropped: 0
  pid: 25504
  policy_reward_mean: {}
  time_since_restore: 11122.716225385666
  time_this_iter_s: 27.700422763824463
  time_total_s: 11122.716225385666
  timestamp: 1593925402
  timesteps_since_restore: 7940000
  timesteps_this_iter: 20000
  timesteps_total: 7940000
  training_iteration: 397
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=25504], 11122 s, 397 iter, 7940000 ts, 356 rew

agent-1: 31.0
agent-2: 33.0
agent-3: 29.0
agent-4: 43.0
agent-5: 29.0
agent-6: 34.0
agent-7: 32.0
agent-8: 18.0
agent-9: 20.0
agent-10: 32.0
agent-11: 13.0
agent-12: 20.0
agent-13: 28.0
agent-14: 18.0
agent-15: 27.0
agent-16: 35.0
agent-17: 12.0
agent-18: 6.0
agent-19: 7.0
agent-20: 24.0
Sum Reward: 491.0
Avg Reward: 24.55
Min Reward: 6.0
Gini Coefficient: 0.22270875763747455
20:20 Ratio: 3.8157894736842106
Max-min Ratio: 7.166666666666667
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_01-03-49
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 562.0
  episode_reward_mean: 356.91
  episode_reward_min: 241.0
  episodes_this_iter: 1
  episodes_total: 397
  experiment_id: 35d66058da2d4c9882f832ee91e4aa4a
  hostname: gpu011
  info:
    apply_time_ms: 3.216
    dispatch_time_ms: 7.702
    learner:
      cur_lr: 0.0008311960264109075
      grad_gnorm: 32.90434646606445
      policy_entropy: 174.42593383789062
      policy_loss: -11.098270416259766
      var_gnorm: 20.04525375366211
      vf_explained_var: 1.1920928955078125e-07
      vf_loss: 0.4375600218772888
    num_steps_sampled: 7960000
    num_steps_trained: 7960000
    wait_time_ms: 275.838
  iterations_since_restore: 398
  node_ip: 172.17.8.11
  num_metric_batches_dropped: 0
  pid: 25504
  policy_reward_mean: {}
  time_since_restore: 11149.962234735489
  time_this_iter_s: 27.246009349822998
  time_total_s: 11149.962234735489
  timestamp: 1593925429
  timesteps_since_restore: 7960000
  timesteps_this_iter: 20000
  timesteps_total: 7960000
  training_iteration: 398
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=25504], 11149 s, 398 iter, 7960000 ts, 357 rew

agent-1: 14.0
agent-2: 36.0
agent-3: 17.0
agent-4: 26.0
agent-5: 16.0
agent-6: 22.0
agent-7: 3.0
agent-8: 4.0
agent-9: 29.0
agent-10: 10.0
agent-11: 17.0
agent-12: 26.0
agent-13: 25.0
agent-14: 7.0
agent-15: 23.0
agent-16: 19.0
agent-17: 22.0
agent-18: 11.0
agent-19: 3.0
agent-20: 13.0
Sum Reward: 343.0
Avg Reward: 17.15
Min Reward: 3.0
Gini Coefficient: 0.29606413994169095
20:20 Ratio: 6.882352941176471
Max-min Ratio: 12.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_01-04-17
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 562.0
  episode_reward_mean: 356.35
  episode_reward_min: 241.0
  episodes_this_iter: 1
  episodes_total: 398
  experiment_id: 35d66058da2d4c9882f832ee91e4aa4a
  hostname: gpu011
  info:
    apply_time_ms: 2.888
    dispatch_time_ms: 8.823
    learner:
      cur_lr: 0.0008298640022985637
      grad_gnorm: 6.043838024139404
      policy_entropy: 166.73837280273438
      policy_loss: -1.3918955326080322
      var_gnorm: 20.043371200561523
      vf_explained_var: 0.0
      vf_loss: 0.01465368177741766
    num_steps_sampled: 7980000
    num_steps_trained: 7980000
    wait_time_ms: 270.144
  iterations_since_restore: 399
  node_ip: 172.17.8.11
  num_metric_batches_dropped: 0
  pid: 25504
  policy_reward_mean: {}
  time_since_restore: 11177.795174121857
  time_this_iter_s: 27.832939386367798
  time_total_s: 11177.795174121857
  timestamp: 1593925457
  timesteps_since_restore: 7980000
  timesteps_this_iter: 20000
  timesteps_total: 7980000
  training_iteration: 399
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=25504], 11177 s, 399 iter, 7980000 ts, 356 rew

agent-1: 7.0
agent-2: 19.0
agent-3: 31.0
agent-4: 17.0
agent-5: 22.0
agent-6: 8.0
agent-7: 30.0
agent-8: 15.0
agent-9: 7.0
agent-10: 14.0
agent-11: 20.0
agent-12: 10.0
agent-13: 24.0
agent-14: 26.0
agent-15: 5.0
agent-16: 7.0
agent-17: 26.0
agent-18: 15.0
agent-19: 14.0
agent-20: 19.0
Sum Reward: 336.0
Avg Reward: 16.8
Min Reward: 5.0
Gini Coefficient: 0.26517857142857143
20:20 Ratio: 4.346153846153846
Max-min Ratio: 6.2
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_01-04-44
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 562.0
  episode_reward_mean: 355.33
  episode_reward_min: 241.0
  episodes_this_iter: 1
  episodes_total: 399
  experiment_id: 35d66058da2d4c9882f832ee91e4aa4a
  hostname: gpu011
  info:
    apply_time_ms: 3.113
    dispatch_time_ms: 6.209
    learner:
      cur_lr: 0.0008285319781862199
      grad_gnorm: 22.782121658325195
      policy_entropy: 157.11178588867188
      policy_loss: -2.4600906372070312
      var_gnorm: 20.045698165893555
      vf_explained_var: 0.0
      vf_loss: 7.872729778289795
    num_steps_sampled: 8000000
    num_steps_trained: 8000000
    wait_time_ms: 265.1
  iterations_since_restore: 400
  node_ip: 172.17.8.11
  num_metric_batches_dropped: 0
  pid: 25504
  policy_reward_mean: {}
  time_since_restore: 11205.06086063385
  time_this_iter_s: 27.265686511993408
  time_total_s: 11205.06086063385
  timestamp: 1593925484
  timesteps_since_restore: 8000000
  timesteps_this_iter: 20000
  timesteps_total: 8000000
  training_iteration: 400
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=25504], 11205 s, 400 iter, 8000000 ts, 355 rew

agent-1: 23.0
agent-2: 31.0
agent-3: 7.0
agent-4: 36.0
agent-5: 44.0
agent-6: 18.0
agent-7: 13.0
agent-8: 5.0
agent-9: 5.0
agent-10: 15.0
agent-11: 21.0
agent-12: 24.0
agent-13: 5.0
agent-14: 13.0
agent-15: 15.0
agent-16: 11.0
agent-17: 14.0
agent-18: 22.0
agent-19: 32.0
agent-20: 13.0
Sum Reward: 367.0
Avg Reward: 18.35
Min Reward: 5.0
Gini Coefficient: 0.3178474114441417
20:20 Ratio: 6.5
Max-min Ratio: 8.8
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_01-05-12
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 562.0
  episode_reward_mean: 354.89
  episode_reward_min: 241.0
  episodes_this_iter: 1
  episodes_total: 400
  experiment_id: 35d66058da2d4c9882f832ee91e4aa4a
  hostname: gpu011
  info:
    apply_time_ms: 3.389
    dispatch_time_ms: 5.817
    learner:
      cur_lr: 0.0008272000122815371
      grad_gnorm: 40.000003814697266
      policy_entropy: 168.30458068847656
      policy_loss: 61.71296310424805
      var_gnorm: 20.038225173950195
      vf_explained_var: 1.7881393432617188e-07
      vf_loss: 89.68561553955078
    num_steps_sampled: 8020000
    num_steps_trained: 8020000
    wait_time_ms: 263.698
  iterations_since_restore: 401
  node_ip: 172.17.8.11
  num_metric_batches_dropped: 0
  pid: 25504
  policy_reward_mean: {}
  time_since_restore: 11232.703034877777
  time_this_iter_s: 27.642174243927002
  time_total_s: 11232.703034877777
  timestamp: 1593925512
  timesteps_since_restore: 8020000
  timesteps_this_iter: 20000
  timesteps_total: 8020000
  training_iteration: 401
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=25504], 11232 s, 401 iter, 8020000 ts, 355 rew

agent-1: 22.0
agent-2: 19.0
agent-3: 7.0
agent-4: 12.0
agent-5: 4.0
agent-6: 27.0
agent-7: 7.0
agent-8: 9.0
agent-9: 11.0
agent-10: 3.0
agent-11: 19.0
agent-12: 18.0
agent-13: 9.0
agent-14: 16.0
agent-15: 18.0
agent-16: 19.0
agent-17: 33.0
agent-18: 12.0
agent-19: 11.0
agent-20: 26.0
Sum Reward: 302.0
Avg Reward: 15.1
Min Reward: 3.0
Gini Coefficient: 0.2903973509933775
20:20 Ratio: 5.142857142857143
Max-min Ratio: 11.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_01-05-41
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 562.0
  episode_reward_mean: 353.8
  episode_reward_min: 241.0
  episodes_this_iter: 1
  episodes_total: 401
  experiment_id: 35d66058da2d4c9882f832ee91e4aa4a
  hostname: gpu011
  info:
    apply_time_ms: 3.198
    dispatch_time_ms: 6.785
    learner:
      cur_lr: 0.0008258679881691933
      grad_gnorm: 23.51543617248535
      policy_entropy: 158.40875244140625
      policy_loss: -7.816267967224121
      var_gnorm: 20.03816032409668
      vf_explained_var: 0.0
      vf_loss: 4.26992654800415
    num_steps_sampled: 8040000
    num_steps_trained: 8040000
    wait_time_ms: 273.079
  iterations_since_restore: 402
  node_ip: 172.17.8.11
  num_metric_batches_dropped: 0
  pid: 25504
  policy_reward_mean: {}
  time_since_restore: 11261.501215457916
  time_this_iter_s: 28.79818058013916
  time_total_s: 11261.501215457916
  timestamp: 1593925541
  timesteps_since_restore: 8040000
  timesteps_this_iter: 20000
  timesteps_total: 8040000
  training_iteration: 402
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=25504], 11261 s, 402 iter, 8040000 ts, 354 rew

agent-1: 17.0
agent-2: 9.0
agent-3: 34.0
agent-4: 32.0
agent-5: 17.0
agent-6: 26.0
agent-7: 14.0
agent-8: 17.0
agent-9: 17.0
agent-10: 29.0
agent-11: 21.0
agent-12: 32.0
agent-13: 23.0
agent-14: 5.0
agent-15: 10.0
agent-16: 15.0
agent-17: 17.0
agent-18: 31.0
agent-19: 15.0
agent-20: 5.0
Sum Reward: 386.0
Avg Reward: 19.3
Min Reward: 5.0
Gini Coefficient: 0.2549222797927461
20:20 Ratio: 4.448275862068965
Max-min Ratio: 6.8
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_01-06-08
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 562.0
  episode_reward_mean: 354.36
  episode_reward_min: 241.0
  episodes_this_iter: 1
  episodes_total: 402
  experiment_id: 35d66058da2d4c9882f832ee91e4aa4a
  hostname: gpu011
  info:
    apply_time_ms: 2.925
    dispatch_time_ms: 6.089
    learner:
      cur_lr: 0.0008245360222645104
      grad_gnorm: 40.0
      policy_entropy: 177.51199340820312
      policy_loss: 57.92802429199219
      var_gnorm: 20.032470703125
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 61.6466064453125
    num_steps_sampled: 8060000
    num_steps_trained: 8060000
    wait_time_ms: 257.502
  iterations_since_restore: 403
  node_ip: 172.17.8.11
  num_metric_batches_dropped: 0
  pid: 25504
  policy_reward_mean: {}
  time_since_restore: 11288.971331357956
  time_this_iter_s: 27.470115900039673
  time_total_s: 11288.971331357956
  timestamp: 1593925568
  timesteps_since_restore: 8060000
  timesteps_this_iter: 20000
  timesteps_total: 8060000
  training_iteration: 403
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=25504], 11288 s, 403 iter, 8060000 ts, 354 rew

agent-1: 6.0
agent-2: 35.0
agent-3: 12.0
agent-4: 13.0
agent-5: 29.0
agent-6: 32.0
agent-7: 16.0
agent-8: 5.0
agent-9: 32.0
agent-10: 7.0
agent-11: 18.0
agent-12: 30.0
agent-13: 17.0
agent-14: 10.0
agent-15: 11.0
agent-16: 26.0
agent-17: 5.0
agent-18: 27.0
agent-19: 27.0
agent-20: 15.0
Sum Reward: 373.0
Avg Reward: 18.65
Min Reward: 5.0
Gini Coefficient: 0.3017426273458445
20:20 Ratio: 5.608695652173913
Max-min Ratio: 7.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_01-06-36
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 562.0
  episode_reward_mean: 354.17
  episode_reward_min: 241.0
  episodes_this_iter: 1
  episodes_total: 403
  experiment_id: 35d66058da2d4c9882f832ee91e4aa4a
  hostname: gpu011
  info:
    apply_time_ms: 2.516
    dispatch_time_ms: 6.911
    learner:
      cur_lr: 0.0008232039981521666
      grad_gnorm: 39.07461929321289
      policy_entropy: 181.2276153564453
      policy_loss: -13.839655876159668
      var_gnorm: 20.028074264526367
      vf_explained_var: 0.0
      vf_loss: 0.6120374202728271
    num_steps_sampled: 8080000
    num_steps_trained: 8080000
    wait_time_ms: 269.033
  iterations_since_restore: 404
  node_ip: 172.17.8.11
  num_metric_batches_dropped: 0
  pid: 25504
  policy_reward_mean: {}
  time_since_restore: 11316.278815746307
  time_this_iter_s: 27.30748438835144
  time_total_s: 11316.278815746307
  timestamp: 1593925596
  timesteps_since_restore: 8080000
  timesteps_this_iter: 20000
  timesteps_total: 8080000
  training_iteration: 404
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=25504], 11316 s, 404 iter, 8080000 ts, 354 rew

agent-1: 13.0
agent-2: 26.0
agent-3: 20.0
agent-4: 26.0
agent-5: 15.0
agent-6: 5.0
agent-7: 12.0
agent-8: 8.0
agent-9: 8.0
agent-10: 12.0
agent-11: 11.0
agent-12: 14.0
agent-13: 30.0
agent-14: 22.0
agent-15: 6.0
agent-16: 20.0
agent-17: 16.0
agent-18: 22.0
agent-19: 28.0
agent-20: 21.0
Sum Reward: 335.0
Avg Reward: 16.75
Min Reward: 5.0
Gini Coefficient: 0.2508955223880597
20:20 Ratio: 4.074074074074074
Max-min Ratio: 6.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_01-07-05
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 562.0
  episode_reward_mean: 352.37
  episode_reward_min: 241.0
  episodes_this_iter: 1
  episodes_total: 404
  experiment_id: 35d66058da2d4c9882f832ee91e4aa4a
  hostname: gpu011
  info:
    apply_time_ms: 2.488
    dispatch_time_ms: 52.103
    learner:
      cur_lr: 0.0008218719740398228
      grad_gnorm: 10.55288314819336
      policy_entropy: 181.43650817871094
      policy_loss: -0.9386114478111267
      var_gnorm: 20.02665138244629
      vf_explained_var: 5.960464477539063e-08
      vf_loss: 0.044975291937589645
    num_steps_sampled: 8100000
    num_steps_trained: 8100000
    wait_time_ms: 238.048
  iterations_since_restore: 405
  node_ip: 172.17.8.11
  num_metric_batches_dropped: 0
  pid: 25504
  policy_reward_mean: {}
  time_since_restore: 11345.711287736893
  time_this_iter_s: 29.432471990585327
  time_total_s: 11345.711287736893
  timestamp: 1593925625
  timesteps_since_restore: 8100000
  timesteps_this_iter: 20000
  timesteps_total: 8100000
  training_iteration: 405
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=25504], 11345 s, 405 iter, 8100000 ts, 352 rew

agent-1: 18.0
agent-2: 4.0
agent-3: 25.0
agent-4: 16.0
agent-5: 18.0
agent-6: 23.0
agent-7: 18.0
agent-8: 16.0
agent-9: 16.0
agent-10: 13.0
agent-11: 17.0
agent-12: 41.0
agent-13: 16.0
agent-14: 13.0
agent-15: 17.0
agent-16: 22.0
agent-17: 15.0
agent-18: 28.0
agent-19: 15.0
agent-20: 15.0
Sum Reward: 366.0
Avg Reward: 18.3
Min Reward: 4.0
Gini Coefficient: 0.18770491803278688
20:20 Ratio: 2.6
Max-min Ratio: 10.25
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_01-07-34
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 562.0
  episode_reward_mean: 351.86
  episode_reward_min: 241.0
  episodes_this_iter: 1
  episodes_total: 405
  experiment_id: 35d66058da2d4c9882f832ee91e4aa4a
  hostname: gpu011
  info:
    apply_time_ms: 3.0
    dispatch_time_ms: 28.923
    learner:
      cur_lr: 0.0008205400081351399
      grad_gnorm: 21.993324279785156
      policy_entropy: 186.4822540283203
      policy_loss: -8.546823501586914
      var_gnorm: 20.028263092041016
      vf_explained_var: 0.0
      vf_loss: 0.18366822600364685
    num_steps_sampled: 8120000
    num_steps_trained: 8120000
    wait_time_ms: 232.265
  iterations_since_restore: 406
  node_ip: 172.17.8.11
  num_metric_batches_dropped: 0
  pid: 25504
  policy_reward_mean: {}
  time_since_restore: 11374.297694921494
  time_this_iter_s: 28.58640718460083
  time_total_s: 11374.297694921494
  timestamp: 1593925654
  timesteps_since_restore: 8120000
  timesteps_this_iter: 20000
  timesteps_total: 8120000
  training_iteration: 406
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=25504], 11374 s, 406 iter, 8120000 ts, 352 rew

agent-1: 14.0
agent-2: 7.0
agent-3: 16.0
agent-4: 11.0
agent-5: 12.0
agent-6: 22.0
agent-7: 12.0
agent-8: 14.0
agent-9: 6.0
agent-10: 9.0
agent-11: 2.0
agent-12: 20.0
agent-13: 18.0
agent-14: 25.0
agent-15: 19.0
agent-16: 18.0
agent-17: 9.0
agent-18: 7.0
agent-19: 8.0
agent-20: 15.0
Sum Reward: 264.0
Avg Reward: 13.2
Min Reward: 2.0
Gini Coefficient: 0.2515151515151515
20:20 Ratio: 3.909090909090909
Max-min Ratio: 12.5
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_01-08-01
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 562.0
  episode_reward_mean: 349.16
  episode_reward_min: 241.0
  episodes_this_iter: 1
  episodes_total: 406
  experiment_id: 35d66058da2d4c9882f832ee91e4aa4a
  hostname: gpu011
  info:
    apply_time_ms: 2.943
    dispatch_time_ms: 7.462
    learner:
      cur_lr: 0.0008192079840227962
      grad_gnorm: 7.132873058319092
      policy_entropy: 185.90419006347656
      policy_loss: -1.8563507795333862
      var_gnorm: 20.026927947998047
      vf_explained_var: 0.0
      vf_loss: 0.0204116590321064
    num_steps_sampled: 8140000
    num_steps_trained: 8140000
    wait_time_ms: 269.39
  iterations_since_restore: 407
  node_ip: 172.17.8.11
  num_metric_batches_dropped: 0
  pid: 25504
  policy_reward_mean: {}
  time_since_restore: 11401.916846752167
  time_this_iter_s: 27.619151830673218
  time_total_s: 11401.916846752167
  timestamp: 1593925681
  timesteps_since_restore: 8140000
  timesteps_this_iter: 20000
  timesteps_total: 8140000
  training_iteration: 407
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=25504], 11401 s, 407 iter, 8140000 ts, 349 rew

agent-1: 14.0
agent-2: 19.0
agent-3: 16.0
agent-4: 10.0
agent-5: 7.0
agent-6: 22.0
agent-7: 1.0
agent-8: 2.0
agent-9: 5.0
agent-10: 26.0
agent-11: 11.0
agent-12: 11.0
agent-13: 6.0
agent-14: 18.0
agent-15: 4.0
agent-16: 20.0
agent-17: 32.0
agent-18: 13.0
agent-19: 13.0
agent-20: 10.0
Sum Reward: 260.0
Avg Reward: 13.0
Min Reward: 1.0
Gini Coefficient: 0.34115384615384614
20:20 Ratio: 8.333333333333334
Max-min Ratio: 32.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_01-08-29
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 562.0
  episode_reward_mean: 348.12
  episode_reward_min: 241.0
  episodes_this_iter: 1
  episodes_total: 407
  experiment_id: 35d66058da2d4c9882f832ee91e4aa4a
  hostname: gpu011
  info:
    apply_time_ms: 2.592
    dispatch_time_ms: 7.334
    learner:
      cur_lr: 0.0008178760181181133
      grad_gnorm: 29.95585060119629
      policy_entropy: 159.78048706054688
      policy_loss: 8.602455139160156
      var_gnorm: 20.029468536376953
      vf_explained_var: 0.0
      vf_loss: 14.666243553161621
    num_steps_sampled: 8160000
    num_steps_trained: 8160000
    wait_time_ms: 261.288
  iterations_since_restore: 408
  node_ip: 172.17.8.11
  num_metric_batches_dropped: 0
  pid: 25504
  policy_reward_mean: {}
  time_since_restore: 11429.280956745148
  time_this_iter_s: 27.364109992980957
  time_total_s: 11429.280956745148
  timestamp: 1593925709
  timesteps_since_restore: 8160000
  timesteps_this_iter: 20000
  timesteps_total: 8160000
  training_iteration: 408
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=25504], 11429 s, 408 iter, 8160000 ts, 348 rew

agent-1: 18.0
agent-2: 33.0
agent-3: 23.0
agent-4: 9.0
agent-5: 20.0
agent-6: 33.0
agent-7: 10.0
agent-8: 10.0
agent-9: 18.0
agent-10: 6.0
agent-11: 15.0
agent-12: 29.0
agent-13: 10.0
agent-14: 5.0
agent-15: 30.0
agent-16: 21.0
agent-17: 19.0
agent-18: 10.0
agent-19: 22.0
agent-20: 25.0
Sum Reward: 366.0
Avg Reward: 18.3
Min Reward: 5.0
Gini Coefficient: 0.26721311475409837
20:20 Ratio: 4.166666666666667
Max-min Ratio: 6.6
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_01-08-57
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 562.0
  episode_reward_mean: 347.75
  episode_reward_min: 241.0
  episodes_this_iter: 1
  episodes_total: 408
  experiment_id: 35d66058da2d4c9882f832ee91e4aa4a
  hostname: gpu011
  info:
    apply_time_ms: 3.799
    dispatch_time_ms: 9.533
    learner:
      cur_lr: 0.0008165439940057695
      grad_gnorm: 40.00000762939453
      policy_entropy: 177.0504150390625
      policy_loss: 36.477500915527344
      var_gnorm: 20.028419494628906
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 27.814250946044922
    num_steps_sampled: 8180000
    num_steps_trained: 8180000
    wait_time_ms: 248.161
  iterations_since_restore: 409
  node_ip: 172.17.8.11
  num_metric_batches_dropped: 0
  pid: 25504
  policy_reward_mean: {}
  time_since_restore: 11456.879357814789
  time_this_iter_s: 27.598401069641113
  time_total_s: 11456.879357814789
  timestamp: 1593925737
  timesteps_since_restore: 8180000
  timesteps_this_iter: 20000
  timesteps_total: 8180000
  training_iteration: 409
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=25504], 11456 s, 409 iter, 8180000 ts, 348 rew

agent-1: 3.0
agent-2: 23.0
agent-3: 21.0
agent-4: 18.0
agent-5: 39.0
agent-6: 13.0
agent-7: 18.0
agent-8: 5.0
agent-9: 41.0
agent-10: 21.0
agent-11: 8.0
agent-12: 15.0
agent-13: 30.0
agent-14: 9.0
agent-15: 34.0
agent-16: 12.0
agent-17: 20.0
agent-18: 32.0
agent-19: 17.0
agent-20: 18.0
Sum Reward: 397.0
Avg Reward: 19.85
Min Reward: 3.0
Gini Coefficient: 0.29534005037783373
20:20 Ratio: 5.84
Max-min Ratio: 13.666666666666666
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_01-09-24
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 562.0
  episode_reward_mean: 348.51
  episode_reward_min: 241.0
  episodes_this_iter: 1
  episodes_total: 409
  experiment_id: 35d66058da2d4c9882f832ee91e4aa4a
  hostname: gpu011
  info:
    apply_time_ms: 2.598
    dispatch_time_ms: 8.712
    learner:
      cur_lr: 0.0008152120281010866
      grad_gnorm: 40.000003814697266
      policy_entropy: 182.15054321289062
      policy_loss: -16.47854995727539
      var_gnorm: 20.0263671875
      vf_explained_var: 0.0
      vf_loss: 0.7860310673713684
    num_steps_sampled: 8200000
    num_steps_trained: 8200000
    wait_time_ms: 269.677
  iterations_since_restore: 410
  node_ip: 172.17.8.11
  num_metric_batches_dropped: 0
  pid: 25504
  policy_reward_mean: {}
  time_since_restore: 11484.390218257904
  time_this_iter_s: 27.510860443115234
  time_total_s: 11484.390218257904
  timestamp: 1593925764
  timesteps_since_restore: 8200000
  timesteps_this_iter: 20000
  timesteps_total: 8200000
  training_iteration: 410
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=25504], 11484 s, 410 iter, 8200000 ts, 349 rew

agent-1: 5.0
agent-2: 2.0
agent-3: 25.0
agent-4: 21.0
agent-5: 20.0
agent-6: 20.0
agent-7: 11.0
agent-8: 23.0
agent-9: 8.0
agent-10: 19.0
agent-11: 17.0
agent-12: 30.0
agent-13: 15.0
agent-14: 10.0
agent-15: 18.0
agent-16: 17.0
agent-17: 25.0
agent-18: 12.0
agent-19: 14.0
agent-20: 27.0
Sum Reward: 339.0
Avg Reward: 16.95
Min Reward: 2.0
Gini Coefficient: 0.24233038348082594
20:20 Ratio: 4.28
Max-min Ratio: 15.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_01-09-53
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 562.0
  episode_reward_mean: 348.18
  episode_reward_min: 241.0
  episodes_this_iter: 1
  episodes_total: 410
  experiment_id: 35d66058da2d4c9882f832ee91e4aa4a
  hostname: gpu011
  info:
    apply_time_ms: 2.793
    dispatch_time_ms: 75.167
    learner:
      cur_lr: 0.0008138800039887428
      grad_gnorm: 21.733264923095703
      policy_entropy: 175.42356872558594
      policy_loss: -2.1795401573181152
      var_gnorm: 20.01944923400879
      vf_explained_var: 5.960464477539063e-08
      vf_loss: 0.15573535859584808
    num_steps_sampled: 8220000
    num_steps_trained: 8220000
    wait_time_ms: 205.818
  iterations_since_restore: 411
  node_ip: 172.17.8.11
  num_metric_batches_dropped: 0
  pid: 25504
  policy_reward_mean: {}
  time_since_restore: 11513.46767783165
  time_this_iter_s: 29.077459573745728
  time_total_s: 11513.46767783165
  timestamp: 1593925793
  timesteps_since_restore: 8220000
  timesteps_this_iter: 20000
  timesteps_total: 8220000
  training_iteration: 411
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=25504], 11513 s, 411 iter, 8220000 ts, 348 rew

agent-1: 28.0
agent-2: 17.0
agent-3: 31.0
agent-4: 19.0
agent-5: 14.0
agent-6: 3.0
agent-7: 16.0
agent-8: 15.0
agent-9: 32.0
agent-10: 24.0
agent-11: 9.0
agent-12: 8.0
agent-13: 22.0
agent-14: 9.0
agent-15: 25.0
agent-16: 16.0
agent-17: 11.0
agent-18: 21.0
agent-19: 19.0
agent-20: 3.0
Sum Reward: 342.0
Avg Reward: 17.1
Min Reward: 3.0
Gini Coefficient: 0.27456140350877195
20:20 Ratio: 5.043478260869565
Max-min Ratio: 10.666666666666666
W0705 01:11:04.522888 25498 client_connection.cc:255] [worker]ProcessMessage with type 10 took 36900 ms.
W0705 01:11:04.758227 25498 task_dependency_manager.cc:259] Task lease to renew has already expired by -16038ms
W0705 01:11:04.758298 25498 task_dependency_manager.cc:259] Task lease to renew has already expired by -27659ms
W0705 01:11:04.758329 25498 task_dependency_manager.cc:259] Task lease to renew has already expired by -27541ms
W0705 01:11:04.758356 25498 task_dependency_manager.cc:259] Task lease to renew has already expired by -27541ms
W0705 01:11:04.758383 25498 node_manager.cc:250] Last heartbeat was sent 37207 ms ago 
W0705 01:11:05.697074 25498 client_connection.cc:255] [worker]ProcessMessage with type 8 took 105 ms.
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_01-11-11
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 562.0
  episode_reward_mean: 348.21
  episode_reward_min: 241.0
  episodes_this_iter: 1
  episodes_total: 411
  experiment_id: 35d66058da2d4c9882f832ee91e4aa4a
  hostname: gpu011
  info:
    apply_time_ms: 2.981
    dispatch_time_ms: 113.541
    learner:
      cur_lr: 0.000812547979876399
      grad_gnorm: 37.60676574707031
      policy_entropy: 150.27606201171875
      policy_loss: 7.380398750305176
      var_gnorm: 20.022586822509766
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 13.699560165405273
    num_steps_sampled: 8240000
    num_steps_trained: 8240000
    wait_time_ms: 330.789
  iterations_since_restore: 412
  node_ip: 172.17.8.11
  num_metric_batches_dropped: 0
  pid: 25504
  policy_reward_mean: {}
  time_since_restore: 11591.714039087296
  time_this_iter_s: 78.24636125564575
  time_total_s: 11591.714039087296
  timestamp: 1593925871
  timesteps_since_restore: 8240000
  timesteps_this_iter: 20000
  timesteps_total: 8240000
  training_iteration: 412
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=25504], 11591 s, 412 iter, 8240000 ts, 348 rew

agent-1: 17.0
agent-2: 20.0
agent-3: 19.0
agent-4: 12.0
agent-5: 19.0
agent-6: 6.0
agent-7: 21.0
agent-8: 20.0
agent-9: 9.0
agent-10: 19.0
agent-11: 14.0
agent-12: 5.0
agent-13: 21.0
agent-14: 13.0
agent-15: 24.0
agent-16: 9.0
agent-17: 20.0
agent-18: 12.0
agent-19: 17.0
agent-20: 9.0
Sum Reward: 306.0
Avg Reward: 15.3
Min Reward: 5.0
Gini Coefficient: 0.20032679738562092
20:20 Ratio: 2.9655172413793105
Max-min Ratio: 4.8
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_01-11-44
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 562.0
  episode_reward_mean: 346.51
  episode_reward_min: 241.0
  episodes_this_iter: 1
  episodes_total: 412
  experiment_id: 35d66058da2d4c9882f832ee91e4aa4a
  hostname: gpu011
  info:
    apply_time_ms: 4.371
    dispatch_time_ms: 33.056
    learner:
      cur_lr: 0.0008112160139717162
      grad_gnorm: 38.671295166015625
      policy_entropy: 148.6240234375
      policy_loss: 13.222220420837402
      var_gnorm: 20.0211181640625
      vf_explained_var: 0.0
      vf_loss: 13.428839683532715
    num_steps_sampled: 8260000
    num_steps_trained: 8260000
    wait_time_ms: 244.856
  iterations_since_restore: 413
  node_ip: 172.17.8.11
  num_metric_batches_dropped: 0
  pid: 25504
  policy_reward_mean: {}
  time_since_restore: 11623.999552249908
  time_this_iter_s: 32.285513162612915
  time_total_s: 11623.999552249908
  timestamp: 1593925904
  timesteps_since_restore: 8260000
  timesteps_this_iter: 20000
  timesteps_total: 8260000
  training_iteration: 413
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=25504], 11623 s, 413 iter, 8260000 ts, 347 rew

agent-1: 8.0
agent-2: 11.0
agent-3: 16.0
agent-4: 12.0
agent-5: 11.0
agent-6: 11.0
agent-7: 21.0
agent-8: 17.0
agent-9: 10.0
agent-10: 7.0
agent-11: 17.0
agent-12: 20.0
agent-13: 13.0
agent-14: 16.0
agent-15: 18.0
agent-16: 7.0
agent-17: 19.0
agent-18: 14.0
agent-19: 10.0
agent-20: 6.0
Sum Reward: 264.0
Avg Reward: 13.2
Min Reward: 6.0
Gini Coefficient: 0.1943181818181818
20:20 Ratio: 2.7857142857142856
Max-min Ratio: 3.5
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_01-12-11
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 562.0
  episode_reward_mean: 346.12
  episode_reward_min: 241.0
  episodes_this_iter: 1
  episodes_total: 413
  experiment_id: 35d66058da2d4c9882f832ee91e4aa4a
  hostname: gpu011
  info:
    apply_time_ms: 3.065
    dispatch_time_ms: 6.729
    learner:
      cur_lr: 0.0008098839898593724
      grad_gnorm: 37.96183395385742
      policy_entropy: 131.4535369873047
      policy_loss: -8.900440216064453
      var_gnorm: 20.027820587158203
      vf_explained_var: 0.0
      vf_loss: 3.254578113555908
    num_steps_sampled: 8280000
    num_steps_trained: 8280000
    wait_time_ms: 264.141
  iterations_since_restore: 414
  node_ip: 172.17.8.11
  num_metric_batches_dropped: 0
  pid: 25504
  policy_reward_mean: {}
  time_since_restore: 11651.208769083023
  time_this_iter_s: 27.209216833114624
  time_total_s: 11651.208769083023
  timestamp: 1593925931
  timesteps_since_restore: 8280000
  timesteps_this_iter: 20000
  timesteps_total: 8280000
  training_iteration: 414
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=25504], 11651 s, 414 iter, 8280000 ts, 346 rew

agent-1: 32.0
agent-2: 14.0
agent-3: 28.0
agent-4: 38.0
agent-5: 17.0
agent-6: 24.0
agent-7: 33.0
agent-8: 23.0
agent-9: 10.0
agent-10: 34.0
agent-11: 16.0
agent-12: 16.0
agent-13: 31.0
agent-14: 23.0
agent-15: 19.0
agent-16: 17.0
agent-17: 23.0
agent-18: 12.0
agent-19: 21.0
agent-20: 22.0
Sum Reward: 453.0
Avg Reward: 22.65
Min Reward: 10.0
Gini Coefficient: 0.19194260485651213
20:20 Ratio: 2.6346153846153846
Max-min Ratio: 3.8
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_01-12-39
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 562.0
  episode_reward_mean: 346.47
  episode_reward_min: 241.0
  episodes_this_iter: 1
  episodes_total: 414
  experiment_id: 35d66058da2d4c9882f832ee91e4aa4a
  hostname: gpu011
  info:
    apply_time_ms: 4.152
    dispatch_time_ms: 6.654
    learner:
      cur_lr: 0.0008085520239546895
      grad_gnorm: 40.0
      policy_entropy: 142.06500244140625
      policy_loss: 19.956218719482422
      var_gnorm: 20.025449752807617
      vf_explained_var: 0.0
      vf_loss: 62.305843353271484
    num_steps_sampled: 8300000
    num_steps_trained: 8300000
    wait_time_ms: 257.415
  iterations_since_restore: 415
  node_ip: 172.17.8.11
  num_metric_batches_dropped: 0
  pid: 25504
  policy_reward_mean: {}
  time_since_restore: 11678.70154619217
  time_this_iter_s: 27.492777109146118
  time_total_s: 11678.70154619217
  timestamp: 1593925959
  timesteps_since_restore: 8300000
  timesteps_this_iter: 20000
  timesteps_total: 8300000
  training_iteration: 415
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=25504], 11678 s, 415 iter, 8300000 ts, 346 rew

agent-1: 30.0
agent-2: 34.0
agent-3: 15.0
agent-4: 14.0
agent-5: 30.0
agent-6: 35.0
agent-7: 13.0
agent-8: 24.0
agent-9: 13.0
agent-10: 10.0
agent-11: 19.0
agent-12: 25.0
agent-13: 19.0
agent-14: 34.0
agent-15: 23.0
agent-16: 18.0
agent-17: 14.0
agent-18: 21.0
agent-19: 29.0
agent-20: 21.0
Sum Reward: 441.0
Avg Reward: 22.05
Min Reward: 10.0
Gini Coefficient: 0.1976190476190476
20:20 Ratio: 2.66
Max-min Ratio: 3.5
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_01-13-06
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 562.0
  episode_reward_mean: 347.3
  episode_reward_min: 241.0
  episodes_this_iter: 1
  episodes_total: 415
  experiment_id: 35d66058da2d4c9882f832ee91e4aa4a
  hostname: gpu011
  info:
    apply_time_ms: 2.704
    dispatch_time_ms: 5.446
    learner:
      cur_lr: 0.0008072199998423457
      grad_gnorm: 27.52971649169922
      policy_entropy: 122.15784454345703
      policy_loss: -6.6542744636535645
      var_gnorm: 20.027976989746094
      vf_explained_var: 0.0
      vf_loss: 0.30477142333984375
    num_steps_sampled: 8320000
    num_steps_trained: 8320000
    wait_time_ms: 275.127
  iterations_since_restore: 416
  node_ip: 172.17.8.11
  num_metric_batches_dropped: 0
  pid: 25504
  policy_reward_mean: {}
  time_since_restore: 11706.312002897263
  time_this_iter_s: 27.610456705093384
  time_total_s: 11706.312002897263
  timestamp: 1593925986
  timesteps_since_restore: 8320000
  timesteps_this_iter: 20000
  timesteps_total: 8320000
  training_iteration: 416
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=25504], 11706 s, 416 iter, 8320000 ts, 347 rew

agent-1: 16.0
agent-2: 23.0
agent-3: 37.0
agent-4: 28.0
agent-5: 15.0
agent-6: 5.0
agent-7: 17.0
agent-8: 8.0
agent-9: 10.0
agent-10: 8.0
agent-11: 14.0
agent-12: 21.0
agent-13: 5.0
agent-14: 13.0
agent-15: 4.0
agent-16: 8.0
agent-17: 14.0
agent-18: 11.0
agent-19: 22.0
agent-20: 7.0
Sum Reward: 286.0
Avg Reward: 14.3
Min Reward: 4.0
Gini Coefficient: 0.31433566433566434
20:20 Ratio: 5.238095238095238
Max-min Ratio: 9.25
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_01-13-34
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 562.0
  episode_reward_mean: 347.07
  episode_reward_min: 241.0
  episodes_this_iter: 1
  episodes_total: 416
  experiment_id: 35d66058da2d4c9882f832ee91e4aa4a
  hostname: gpu011
  info:
    apply_time_ms: 2.552
    dispatch_time_ms: 6.837
    learner:
      cur_lr: 0.0008058879757300019
      grad_gnorm: 7.812335014343262
      policy_entropy: 130.7235565185547
      policy_loss: -1.321985125541687
      var_gnorm: 20.02581024169922
      vf_explained_var: 0.0
      vf_loss: 0.024433014914393425
    num_steps_sampled: 8340000
    num_steps_trained: 8340000
    wait_time_ms: 276.583
  iterations_since_restore: 417
  node_ip: 172.17.8.11
  num_metric_batches_dropped: 0
  pid: 25504
  policy_reward_mean: {}
  time_since_restore: 11734.033154726028
  time_this_iter_s: 27.72115182876587
  time_total_s: 11734.033154726028
  timestamp: 1593926014
  timesteps_since_restore: 8340000
  timesteps_this_iter: 20000
  timesteps_total: 8340000
  training_iteration: 417
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=25504], 11734 s, 417 iter, 8340000 ts, 347 rew

agent-1: 12.0
agent-2: 7.0
agent-3: 20.0
agent-4: 9.0
agent-5: 29.0
agent-6: 31.0
agent-7: 19.0
agent-8: 7.0
agent-9: 6.0
agent-10: 11.0
agent-11: 14.0
agent-12: 13.0
agent-13: 10.0
agent-14: 14.0
agent-15: 4.0
agent-16: 17.0
agent-17: 21.0
agent-18: 11.0
agent-19: 17.0
agent-20: 2.0
Sum Reward: 274.0
Avg Reward: 13.7
Min Reward: 2.0
Gini Coefficient: 0.3007299270072993
20:20 Ratio: 5.315789473684211
Max-min Ratio: 15.5
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_01-14-01
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 562.0
  episode_reward_mean: 346.48
  episode_reward_min: 241.0
  episodes_this_iter: 1
  episodes_total: 417
  experiment_id: 35d66058da2d4c9882f832ee91e4aa4a
  hostname: gpu011
  info:
    apply_time_ms: 3.071
    dispatch_time_ms: 6.124
    learner:
      cur_lr: 0.000804556009825319
      grad_gnorm: 24.224985122680664
      policy_entropy: 150.23350524902344
      policy_loss: 2.38968563079834
      var_gnorm: 20.031404495239258
      vf_explained_var: 5.960464477539063e-08
      vf_loss: 33.88288116455078
    num_steps_sampled: 8360000
    num_steps_trained: 8360000
    wait_time_ms: 264.269
  iterations_since_restore: 418
  node_ip: 172.17.8.11
  num_metric_batches_dropped: 0
  pid: 25504
  policy_reward_mean: {}
  time_since_restore: 11760.836050748825
  time_this_iter_s: 26.80289602279663
  time_total_s: 11760.836050748825
  timestamp: 1593926041
  timesteps_since_restore: 8360000
  timesteps_this_iter: 20000
  timesteps_total: 8360000
  training_iteration: 418
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=25504], 11760 s, 418 iter, 8360000 ts, 346 rew

agent-1: 6.0
agent-2: 26.0
agent-3: 9.0
agent-4: 21.0
agent-5: 13.0
agent-6: 21.0
agent-7: 30.0
agent-8: 14.0
agent-9: 24.0
agent-10: 23.0
agent-11: 28.0
agent-12: 35.0
agent-13: 7.0
agent-14: 27.0
agent-15: 33.0
agent-16: 40.0
agent-17: 25.0
agent-18: 18.0
agent-19: 18.0
agent-20: 14.0
Sum Reward: 432.0
Avg Reward: 21.6
Min Reward: 6.0
Gini Coefficient: 0.24027777777777778
20:20 Ratio: 3.942857142857143
Max-min Ratio: 6.666666666666667
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_01-14-29
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 562.0
  episode_reward_mean: 346.1
  episode_reward_min: 241.0
  episodes_this_iter: 1
  episodes_total: 418
  experiment_id: 35d66058da2d4c9882f832ee91e4aa4a
  hostname: gpu011
  info:
    apply_time_ms: 2.635
    dispatch_time_ms: 5.807
    learner:
      cur_lr: 0.0008032239857129753
      grad_gnorm: 40.0
      policy_entropy: 141.02952575683594
      policy_loss: 37.53247833251953
      var_gnorm: 20.026885986328125
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 79.17890930175781
    num_steps_sampled: 8380000
    num_steps_trained: 8380000
    wait_time_ms: 253.41
  iterations_since_restore: 419
  node_ip: 172.17.8.11
  num_metric_batches_dropped: 0
  pid: 25504
  policy_reward_mean: {}
  time_since_restore: 11788.432281017303
  time_this_iter_s: 27.596230268478394
  time_total_s: 11788.432281017303
  timestamp: 1593926069
  timesteps_since_restore: 8380000
  timesteps_this_iter: 20000
  timesteps_total: 8380000
  training_iteration: 419
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=25504], 11788 s, 419 iter, 8380000 ts, 346 rew

agent-1: 29.0
agent-2: 14.0
agent-3: 31.0
agent-4: 23.0
agent-5: 32.0
agent-6: 14.0
agent-7: 13.0
agent-8: 18.0
agent-9: 42.0
agent-10: 23.0
agent-11: 17.0
agent-12: 33.0
agent-13: 20.0
agent-14: 3.0
agent-15: 26.0
agent-16: 29.0
agent-17: 25.0
agent-18: 19.0
agent-19: 26.0
agent-20: 33.0
Sum Reward: 470.0
Avg Reward: 23.5
Min Reward: 3.0
Gini Coefficient: 0.20893617021276595
20:20 Ratio: 3.1818181818181817
Max-min Ratio: 14.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_01-14-56
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 562.0
  episode_reward_mean: 345.9
  episode_reward_min: 241.0
  episodes_this_iter: 1
  episodes_total: 419
  experiment_id: 35d66058da2d4c9882f832ee91e4aa4a
  hostname: gpu011
  info:
    apply_time_ms: 2.995
    dispatch_time_ms: 39.348
    learner:
      cur_lr: 0.0008018920198082924
      grad_gnorm: 39.999996185302734
      policy_entropy: 179.84158325195312
      policy_loss: -19.506263732910156
      var_gnorm: 20.031330108642578
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 1.1547114849090576
    num_steps_sampled: 8400000
    num_steps_trained: 8400000
    wait_time_ms: 252.11
  iterations_since_restore: 420
  node_ip: 172.17.8.11
  num_metric_batches_dropped: 0
  pid: 25504
  policy_reward_mean: {}
  time_since_restore: 11815.85845041275
  time_this_iter_s: 27.426169395446777
  time_total_s: 11815.85845041275
  timestamp: 1593926096
  timesteps_since_restore: 8400000
  timesteps_this_iter: 20000
  timesteps_total: 8400000
  training_iteration: 420
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=25504], 11815 s, 420 iter, 8400000 ts, 346 rew

agent-1: 19.0
agent-2: 19.0
agent-3: 39.0
agent-4: 22.0
agent-5: 31.0
agent-6: 35.0
agent-7: 24.0
agent-8: 15.0
agent-9: 30.0
agent-10: 16.0
agent-11: 20.0
agent-12: 16.0
agent-13: 25.0
agent-14: 35.0
agent-15: 18.0
agent-16: 24.0
agent-17: 22.0
agent-18: 10.0
agent-19: 39.0
agent-20: 15.0
Sum Reward: 474.0
Avg Reward: 23.7
Min Reward: 10.0
Gini Coefficient: 0.1959915611814346
20:20 Ratio: 2.642857142857143
Max-min Ratio: 3.9
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_01-15-24
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 562.0
  episode_reward_mean: 348.07
  episode_reward_min: 241.0
  episodes_this_iter: 1
  episodes_total: 420
  experiment_id: 35d66058da2d4c9882f832ee91e4aa4a
  hostname: gpu011
  info:
    apply_time_ms: 2.934
    dispatch_time_ms: 55.045
    learner:
      cur_lr: 0.0008005599956959486
      grad_gnorm: 40.0
      policy_entropy: 179.19886779785156
      policy_loss: 18.73733901977539
      var_gnorm: 20.023639678955078
      vf_explained_var: 0.0
      vf_loss: 20.167024612426758
    num_steps_sampled: 8420000
    num_steps_trained: 8420000
    wait_time_ms: 212.795
  iterations_since_restore: 421
  node_ip: 172.17.8.11
  num_metric_batches_dropped: 0
  pid: 25504
  policy_reward_mean: {}
  time_since_restore: 11844.072309970856
  time_this_iter_s: 28.21385955810547
  time_total_s: 11844.072309970856
  timestamp: 1593926124
  timesteps_since_restore: 8420000
  timesteps_this_iter: 20000
  timesteps_total: 8420000
  training_iteration: 421
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=25504], 11844 s, 421 iter, 8420000 ts, 348 rew

agent-1: 9.0
agent-2: 29.0
agent-3: 31.0
agent-4: 18.0
agent-5: 20.0
agent-6: 9.0
agent-7: 3.0
agent-8: 22.0
agent-9: 23.0
agent-10: 12.0
agent-11: 18.0
agent-12: 5.0
agent-13: 19.0
agent-14: 7.0
agent-15: 9.0
agent-16: 9.0
agent-17: 20.0
agent-18: 11.0
agent-19: 7.0
agent-20: 15.0
Sum Reward: 296.0
Avg Reward: 14.8
Min Reward: 3.0
Gini Coefficient: 0.2929054054054054
20:20 Ratio: 4.7727272727272725
Max-min Ratio: 10.333333333333334
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_01-15-52
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 562.0
  episode_reward_mean: 347.97
  episode_reward_min: 241.0
  episodes_this_iter: 1
  episodes_total: 421
  experiment_id: 35d66058da2d4c9882f832ee91e4aa4a
  hostname: gpu011
  info:
    apply_time_ms: 3.601
    dispatch_time_ms: 47.133
    learner:
      cur_lr: 0.0007992279715836048
      grad_gnorm: 27.918975830078125
      policy_entropy: 185.4904327392578
      policy_loss: -9.412565231323242
      var_gnorm: 20.02802848815918
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 0.31436097621917725
    num_steps_sampled: 8440000
    num_steps_trained: 8440000
    wait_time_ms: 240.507
  iterations_since_restore: 422
  node_ip: 172.17.8.11
  num_metric_batches_dropped: 0
  pid: 25504
  policy_reward_mean: {}
  time_since_restore: 11872.13871717453
  time_this_iter_s: 28.066407203674316
  time_total_s: 11872.13871717453
  timestamp: 1593926152
  timesteps_since_restore: 8440000
  timesteps_this_iter: 20000
  timesteps_total: 8440000
  training_iteration: 422
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=25504], 11872 s, 422 iter, 8440000 ts, 348 rew

agent-1: 8.0
agent-2: 5.0
agent-3: 22.0
agent-4: 10.0
agent-5: 9.0
agent-6: 15.0
agent-7: 23.0
agent-8: 9.0
agent-9: 5.0
agent-10: 9.0
agent-11: 23.0
agent-12: 18.0
agent-13: 7.0
agent-14: 15.0
agent-15: 17.0
agent-16: 4.0
agent-17: 9.0
agent-18: 13.0
agent-19: 22.0
agent-20: 6.0
Sum Reward: 249.0
Avg Reward: 12.45
Min Reward: 4.0
Gini Coefficient: 0.28453815261044174
20:20 Ratio: 4.5
Max-min Ratio: 5.75
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_01-16-21
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 562.0
  episode_reward_mean: 347.4
  episode_reward_min: 241.0
  episodes_this_iter: 1
  episodes_total: 422
  experiment_id: 35d66058da2d4c9882f832ee91e4aa4a
  hostname: gpu011
  info:
    apply_time_ms: 2.953
    dispatch_time_ms: 51.301
    learner:
      cur_lr: 0.0007978960056789219
      grad_gnorm: 8.948553085327148
      policy_entropy: 192.20838928222656
      policy_loss: -0.29193833470344543
      var_gnorm: 20.025447845458984
      vf_explained_var: 0.0
      vf_loss: 0.03236773610115051
    num_steps_sampled: 8460000
    num_steps_trained: 8460000
    wait_time_ms: 239.701
  iterations_since_restore: 423
  node_ip: 172.17.8.11
  num_metric_batches_dropped: 0
  pid: 25504
  policy_reward_mean: {}
  time_since_restore: 11900.564126253128
  time_this_iter_s: 28.425409078598022
  time_total_s: 11900.564126253128
  timestamp: 1593926181
  timesteps_since_restore: 8460000
  timesteps_this_iter: 20000
  timesteps_total: 8460000
  training_iteration: 423
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=25504], 11900 s, 423 iter, 8460000 ts, 347 rew

agent-1: 25.0
agent-2: 13.0
agent-3: 3.0
agent-4: 3.0
agent-5: 12.0
agent-6: 10.0
agent-7: 26.0
agent-8: 31.0
agent-9: 30.0
agent-10: 14.0
agent-11: 9.0
agent-12: 26.0
agent-13: 2.0
agent-14: 27.0
agent-15: 24.0
agent-16: 17.0
agent-17: 12.0
agent-18: 45.0
agent-19: 18.0
agent-20: 10.0
Sum Reward: 357.0
Avg Reward: 17.85
Min Reward: 2.0
Gini Coefficient: 0.33907563025210086
20:20 Ratio: 7.823529411764706
Max-min Ratio: 22.5
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_01-16-51
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 562.0
  episode_reward_mean: 346.44
  episode_reward_min: 241.0
  episodes_this_iter: 1
  episodes_total: 423
  experiment_id: 35d66058da2d4c9882f832ee91e4aa4a
  hostname: gpu011
  info:
    apply_time_ms: 2.575
    dispatch_time_ms: 7.161
    learner:
      cur_lr: 0.0007965639815665781
      grad_gnorm: 19.59853172302246
      policy_entropy: 194.26571655273438
      policy_loss: -7.222386360168457
      var_gnorm: 20.027263641357422
      vf_explained_var: 0.0
      vf_loss: 0.15510573983192444
    num_steps_sampled: 8480000
    num_steps_trained: 8480000
    wait_time_ms: 267.765
  iterations_since_restore: 424
  node_ip: 172.17.8.11
  num_metric_batches_dropped: 0
  pid: 25504
  policy_reward_mean: {}
  time_since_restore: 11930.307564020157
  time_this_iter_s: 29.74343776702881
  time_total_s: 11930.307564020157
  timestamp: 1593926211
  timesteps_since_restore: 8480000
  timesteps_this_iter: 20000
  timesteps_total: 8480000
  training_iteration: 424
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=25504], 11930 s, 424 iter, 8480000 ts, 346 rew

agent-1: 0.0
agent-2: 14.0
agent-3: 45.0
agent-4: 10.0
agent-5: 8.0
agent-6: 8.0
agent-7: 28.0
agent-8: 16.0
agent-9: 6.0
agent-10: 8.0
agent-11: 1.0
agent-12: 11.0
agent-13: 10.0
agent-14: 1.0
agent-15: 21.0
agent-16: 25.0
agent-17: 21.0
agent-18: 14.0
agent-19: 13.0
agent-20: 23.0
Sum Reward: 283.0
Avg Reward: 14.15
Min Reward: 0.0
Gini Coefficient: 0.39664310954063603
20:20 Ratio: 15.125
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_01-17-18
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 562.0
  episode_reward_mean: 345.72
  episode_reward_min: 241.0
  episodes_this_iter: 1
  episodes_total: 424
  experiment_id: 35d66058da2d4c9882f832ee91e4aa4a
  hostname: gpu011
  info:
    apply_time_ms: 3.662
    dispatch_time_ms: 6.806
    learner:
      cur_lr: 0.0007952320156618953
      grad_gnorm: 7.764992713928223
      policy_entropy: 193.27200317382812
      policy_loss: -2.134545087814331
      var_gnorm: 20.025188446044922
      vf_explained_var: 1.1920928955078125e-07
      vf_loss: 0.02430753968656063
    num_steps_sampled: 8500000
    num_steps_trained: 8500000
    wait_time_ms: 250.923
  iterations_since_restore: 425
  node_ip: 172.17.8.11
  num_metric_batches_dropped: 0
  pid: 25504
  policy_reward_mean: {}
  time_since_restore: 11957.945847988129
  time_this_iter_s: 27.6382839679718
  time_total_s: 11957.945847988129
  timestamp: 1593926238
  timesteps_since_restore: 8500000
  timesteps_this_iter: 20000
  timesteps_total: 8500000
  training_iteration: 425
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=25504], 11957 s, 425 iter, 8500000 ts, 346 rew

agent-1: 21.0
agent-2: 14.0
agent-3: 17.0
agent-4: 11.0
agent-5: 9.0
agent-6: 6.0
agent-7: 3.0
agent-8: 16.0
agent-9: 9.0
agent-10: 9.0
agent-11: 11.0
agent-12: 11.0
agent-13: 23.0
agent-14: 17.0
agent-15: 9.0
agent-16: 21.0
agent-17: 13.0
agent-18: 27.0
agent-19: 7.0
agent-20: 9.0
Sum Reward: 263.0
Avg Reward: 13.15
Min Reward: 3.0
Gini Coefficient: 0.25684410646387834
20:20 Ratio: 3.68
Max-min Ratio: 9.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_01-17-46
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 562.0
  episode_reward_mean: 345.25
  episode_reward_min: 241.0
  episodes_this_iter: 1
  episodes_total: 425
  experiment_id: 35d66058da2d4c9882f832ee91e4aa4a
  hostname: gpu011
  info:
    apply_time_ms: 2.856
    dispatch_time_ms: 6.68
    learner:
      cur_lr: 0.0007938999915495515
      grad_gnorm: 27.93001365661621
      policy_entropy: 168.4501495361328
      policy_loss: 6.596473693847656
      var_gnorm: 20.030059814453125
      vf_explained_var: 0.0
      vf_loss: 17.110788345336914
    num_steps_sampled: 8520000
    num_steps_trained: 8520000
    wait_time_ms: 268.188
  iterations_since_restore: 426
  node_ip: 172.17.8.11
  num_metric_batches_dropped: 0
  pid: 25504
  policy_reward_mean: {}
  time_since_restore: 11985.696511983871
  time_this_iter_s: 27.750663995742798
  time_total_s: 11985.696511983871
  timestamp: 1593926266
  timesteps_since_restore: 8520000
  timesteps_this_iter: 20000
  timesteps_total: 8520000
  training_iteration: 426
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=25504], 11985 s, 426 iter, 8520000 ts, 345 rew

agent-1: 8.0
agent-2: 42.0
agent-3: 9.0
agent-4: 18.0
agent-5: 15.0
agent-6: 6.0
agent-7: 18.0
agent-8: 15.0
agent-9: 10.0
agent-10: 5.0
agent-11: 2.0
agent-12: 17.0
agent-13: 5.0
agent-14: 24.0
agent-15: 2.0
agent-16: 38.0
agent-17: 11.0
agent-18: 12.0
agent-19: 21.0
agent-20: 20.0
Sum Reward: 298.0
Avg Reward: 14.9
Min Reward: 2.0
Gini Coefficient: 0.37281879194630874
20:20 Ratio: 8.928571428571429
Max-min Ratio: 21.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_01-18-13
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 562.0
  episode_reward_mean: 344.85
  episode_reward_min: 241.0
  episodes_this_iter: 1
  episodes_total: 426
  experiment_id: 35d66058da2d4c9882f832ee91e4aa4a
  hostname: gpu011
  info:
    apply_time_ms: 2.884
    dispatch_time_ms: 6.499
    learner:
      cur_lr: 0.0007925680256448686
      grad_gnorm: 40.0
      policy_entropy: 179.77626037597656
      policy_loss: 15.602855682373047
      var_gnorm: 20.029327392578125
      vf_explained_var: 0.0
      vf_loss: 15.224869728088379
    num_steps_sampled: 8540000
    num_steps_trained: 8540000
    wait_time_ms: 252.658
  iterations_since_restore: 427
  node_ip: 172.17.8.11
  num_metric_batches_dropped: 0
  pid: 25504
  policy_reward_mean: {}
  time_since_restore: 12013.021069765091
  time_this_iter_s: 27.324557781219482
  time_total_s: 12013.021069765091
  timestamp: 1593926293
  timesteps_since_restore: 8540000
  timesteps_this_iter: 20000
  timesteps_total: 8540000
  training_iteration: 427
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=25504], 12013 s, 427 iter, 8540000 ts, 345 rew

agent-1: 13.0
agent-2: 25.0
agent-3: 14.0
agent-4: 17.0
agent-5: 18.0
agent-6: 21.0
agent-7: 24.0
agent-8: 19.0
agent-9: 6.0
agent-10: 9.0
agent-11: 27.0
agent-12: 16.0
agent-13: 9.0
agent-14: 8.0
agent-15: 10.0
agent-16: 10.0
agent-17: 9.0
agent-18: 16.0
agent-19: 13.0
agent-20: 7.0
Sum Reward: 291.0
Avg Reward: 14.55
Min Reward: 6.0
Gini Coefficient: 0.23728522336769758
20:20 Ratio: 3.2333333333333334
Max-min Ratio: 4.5
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_01-18-41
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 562.0
  episode_reward_mean: 344.7
  episode_reward_min: 241.0
  episodes_this_iter: 1
  episodes_total: 427
  experiment_id: 35d66058da2d4c9882f832ee91e4aa4a
  hostname: gpu011
  info:
    apply_time_ms: 3.904
    dispatch_time_ms: 66.693
    learner:
      cur_lr: 0.0007912360015325248
      grad_gnorm: 9.377330780029297
      policy_entropy: 168.4658203125
      policy_loss: -9.370150566101074
      var_gnorm: 20.041086196899414
      vf_explained_var: 2.980232238769531e-07
      vf_loss: 4.034266471862793
    num_steps_sampled: 8560000
    num_steps_trained: 8560000
    wait_time_ms: 227.318
  iterations_since_restore: 428
  node_ip: 172.17.8.11
  num_metric_batches_dropped: 0
  pid: 25504
  policy_reward_mean: {}
  time_since_restore: 12040.84053850174
  time_this_iter_s: 27.81946873664856
  time_total_s: 12040.84053850174
  timestamp: 1593926321
  timesteps_since_restore: 8560000
  timesteps_this_iter: 20000
  timesteps_total: 8560000
  training_iteration: 428
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=25504], 12040 s, 428 iter, 8560000 ts, 345 rew

agent-1: 33.0
agent-2: 21.0
agent-3: 26.0
agent-4: 13.0
agent-5: 25.0
agent-6: 9.0
agent-7: 36.0
agent-8: 8.0
agent-9: 20.0
agent-10: 5.0
agent-11: 17.0
agent-12: 29.0
agent-13: 10.0
agent-14: 6.0
agent-15: 5.0
agent-16: 14.0
agent-17: 1.0
agent-18: 21.0
agent-19: 27.0
agent-20: 11.0
Sum Reward: 337.0
Avg Reward: 16.85
Min Reward: 1.0
Gini Coefficient: 0.3363501483679525
20:20 Ratio: 7.352941176470588
Max-min Ratio: 36.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_01-19-10
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 562.0
  episode_reward_mean: 344.33
  episode_reward_min: 241.0
  episodes_this_iter: 1
  episodes_total: 428
  experiment_id: 35d66058da2d4c9882f832ee91e4aa4a
  hostname: gpu011
  info:
    apply_time_ms: 3.46
    dispatch_time_ms: 68.805
    learner:
      cur_lr: 0.000789903977420181
      grad_gnorm: 40.0
      policy_entropy: 153.0991973876953
      policy_loss: 35.688865661621094
      var_gnorm: 20.04582977294922
      vf_explained_var: 0.0
      vf_loss: 74.67007446289062
    num_steps_sampled: 8580000
    num_steps_trained: 8580000
    wait_time_ms: 232.685
  iterations_since_restore: 429
  node_ip: 172.17.8.11
  num_metric_batches_dropped: 0
  pid: 25504
  policy_reward_mean: {}
  time_since_restore: 12069.739790439606
  time_this_iter_s: 28.89925193786621
  time_total_s: 12069.739790439606
  timestamp: 1593926350
  timesteps_since_restore: 8580000
  timesteps_this_iter: 20000
  timesteps_total: 8580000
  training_iteration: 429
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=25504], 12069 s, 429 iter, 8580000 ts, 344 rew

agent-1: 17.0
agent-2: 51.0
agent-3: 30.0
agent-4: 33.0
agent-5: 14.0
agent-6: 34.0
agent-7: 24.0
agent-8: 23.0
agent-9: 16.0
agent-10: 36.0
agent-11: 36.0
agent-12: 15.0
agent-13: 36.0
agent-14: 47.0
agent-15: 18.0
agent-16: 15.0
agent-17: 25.0
agent-18: 13.0
agent-19: 15.0
agent-20: 3.0
Sum Reward: 501.0
Avg Reward: 25.05
Min Reward: 3.0
Gini Coefficient: 0.269560878243513
20:20 Ratio: 3.7777777777777777
Max-min Ratio: 17.0
W0705 01:19:44.690713 25498 client_connection.cc:255] [worker]ProcessMessage with type 8 took 19419 ms.
W0705 01:19:44.816552 25498 task_dependency_manager.cc:259] Task lease to renew has already expired by -9009ms
W0705 01:19:44.816625 25498 task_dependency_manager.cc:259] Task lease to renew has already expired by -10121ms
W0705 01:19:44.816655 25498 task_dependency_manager.cc:259] Task lease to renew has already expired by -10083ms
W0705 01:19:44.816685 25498 node_manager.cc:250] Last heartbeat was sent 19614 ms ago 
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_01-20-00
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 562.0
  episode_reward_mean: 346.93
  episode_reward_min: 249.0
  episodes_this_iter: 1
  episodes_total: 429
  experiment_id: 35d66058da2d4c9882f832ee91e4aa4a
  hostname: gpu011
  info:
    apply_time_ms: 2.703
    dispatch_time_ms: 61.86
    learner:
      cur_lr: 0.0007885720115154982
      grad_gnorm: 39.999996185302734
      policy_entropy: 193.8122100830078
      policy_loss: -27.100561141967773
      var_gnorm: 20.051292419433594
      vf_explained_var: 0.0
      vf_loss: 1.2139091491699219
    num_steps_sampled: 8600000
    num_steps_trained: 8600000
    wait_time_ms: 223.284
  iterations_since_restore: 430
  node_ip: 172.17.8.11
  num_metric_batches_dropped: 0
  pid: 25504
  policy_reward_mean: {}
  time_since_restore: 12119.356215715408
  time_this_iter_s: 49.61642527580261
  time_total_s: 12119.356215715408
  timestamp: 1593926400
  timesteps_since_restore: 8600000
  timesteps_this_iter: 20000
  timesteps_total: 8600000
  training_iteration: 430
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=25504], 12119 s, 430 iter, 8600000 ts, 347 rew

W0705 01:20:09.666537 25498 client_connection.cc:255] [worker]ProcessMessage with type 8 took 201 ms.
agent-1: 20.0
agent-2: 22.0
agent-3: 11.0
agent-4: 41.0
agent-5: 14.0
agent-6: 11.0
agent-7: 22.0
agent-8: 27.0
agent-9: 29.0
agent-10: 12.0
agent-11: 18.0
agent-12: 18.0
agent-13: 42.0
agent-14: 16.0
agent-15: 25.0
agent-16: 35.0
agent-17: 9.0
agent-18: 19.0
agent-19: 35.0
agent-20: 24.0
Sum Reward: 450.0
Avg Reward: 22.5
Min Reward: 9.0
Gini Coefficient: 0.2388888888888889
20:20 Ratio: 3.558139534883721
Max-min Ratio: 4.666666666666667
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_01-20-28
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 562.0
  episode_reward_mean: 348.53
  episode_reward_min: 249.0
  episodes_this_iter: 1
  episodes_total: 430
  experiment_id: 35d66058da2d4c9882f832ee91e4aa4a
  hostname: gpu011
  info:
    apply_time_ms: 5.462
    dispatch_time_ms: 45.183
    learner:
      cur_lr: 0.0007872399874031544
      grad_gnorm: 39.999996185302734
      policy_entropy: 178.05508422851562
      policy_loss: 45.516719818115234
      var_gnorm: 20.046125411987305
      vf_explained_var: -2.384185791015625e-07
      vf_loss: 68.77791595458984
    num_steps_sampled: 8620000
    num_steps_trained: 8620000
    wait_time_ms: 234.682
  iterations_since_restore: 431
  node_ip: 172.17.8.11
  num_metric_batches_dropped: 0
  pid: 25504
  policy_reward_mean: {}
  time_since_restore: 12147.596124649048
  time_this_iter_s: 28.239908933639526
  time_total_s: 12147.596124649048
  timestamp: 1593926428
  timesteps_since_restore: 8620000
  timesteps_this_iter: 20000
  timesteps_total: 8620000
  training_iteration: 431
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=25504], 12147 s, 431 iter, 8620000 ts, 349 rew

agent-1: 11.0
agent-2: 16.0
agent-3: 14.0
agent-4: 23.0
agent-5: 40.0
agent-6: 8.0
agent-7: 21.0
agent-8: 29.0
agent-9: 32.0
agent-10: 21.0
agent-11: 10.0
agent-12: 12.0
agent-13: 20.0
agent-14: 25.0
agent-15: 19.0
agent-16: 19.0
agent-17: 9.0
agent-18: 17.0
agent-19: 8.0
agent-20: 13.0
Sum Reward: 367.0
Avg Reward: 18.35
Min Reward: 8.0
Gini Coefficient: 0.24809264305177112
20:20 Ratio: 3.6
Max-min Ratio: 5.0
W0705 01:20:56.027611 25498 client_connection.cc:255] [worker]ProcessMessage with type 19 took 276 ms.
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_01-20-56
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 562.0
  episode_reward_mean: 348.99
  episode_reward_min: 249.0
  episodes_this_iter: 1
  episodes_total: 431
  experiment_id: 35d66058da2d4c9882f832ee91e4aa4a
  hostname: gpu011
  info:
    apply_time_ms: 2.989
    dispatch_time_ms: 5.921
    learner:
      cur_lr: 0.0007859080214984715
      grad_gnorm: 9.995453834533691
      policy_entropy: 159.01083374023438
      policy_loss: -0.7074344754219055
      var_gnorm: 20.04885482788086
      vf_explained_var: 1.1920928955078125e-07
      vf_loss: 4.019318580627441
    num_steps_sampled: 8640000
    num_steps_trained: 8640000
    wait_time_ms: 295.659
  iterations_since_restore: 432
  node_ip: 172.17.8.11
  num_metric_batches_dropped: 0
  pid: 25504
  policy_reward_mean: {}
  time_since_restore: 12174.96278500557
  time_this_iter_s: 27.366660356521606
  time_total_s: 12174.96278500557
  timestamp: 1593926456
  timesteps_since_restore: 8640000
  timesteps_this_iter: 20000
  timesteps_total: 8640000
  training_iteration: 432
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=25504], 12174 s, 432 iter, 8640000 ts, 349 rew

agent-1: 19.0
agent-2: 12.0
agent-3: 32.0
agent-4: 1.0
agent-5: 27.0
agent-6: 5.0
agent-7: 16.0
agent-8: 18.0
agent-9: 11.0
agent-10: 10.0
agent-11: 8.0
agent-12: 35.0
agent-13: 1.0
agent-14: 17.0
agent-15: 21.0
agent-16: 30.0
agent-17: 7.0
agent-18: 25.0
agent-19: 12.0
agent-20: 16.0
Sum Reward: 323.0
Avg Reward: 16.15
Min Reward: 1.0
Gini Coefficient: 0.3397832817337461
20:20 Ratio: 8.857142857142858
Max-min Ratio: 35.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_01-21-23
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 562.0
  episode_reward_mean: 348.05
  episode_reward_min: 249.0
  episodes_this_iter: 1
  episodes_total: 432
  experiment_id: 35d66058da2d4c9882f832ee91e4aa4a
  hostname: gpu011
  info:
    apply_time_ms: 2.681
    dispatch_time_ms: 7.655
    learner:
      cur_lr: 0.0007845759973861277
      grad_gnorm: 40.0
      policy_entropy: 150.20635986328125
      policy_loss: 20.358097076416016
      var_gnorm: 20.04497718811035
      vf_explained_var: 1.1920928955078125e-07
      vf_loss: 26.085412979125977
    num_steps_sampled: 8660000
    num_steps_trained: 8660000
    wait_time_ms: 243.49
  iterations_since_restore: 433
  node_ip: 172.17.8.11
  num_metric_batches_dropped: 0
  pid: 25504
  policy_reward_mean: {}
  time_since_restore: 12202.537725687027
  time_this_iter_s: 27.57494068145752
  time_total_s: 12202.537725687027
  timestamp: 1593926483
  timesteps_since_restore: 8660000
  timesteps_this_iter: 20000
  timesteps_total: 8660000
  training_iteration: 433
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=25504], 12202 s, 433 iter, 8660000 ts, 348 rew

agent-1: 11.0
agent-2: 6.0
agent-3: 22.0
agent-4: 15.0
agent-5: 15.0
agent-6: 29.0
agent-7: 21.0
agent-8: 11.0
agent-9: 10.0
agent-10: 32.0
agent-11: 25.0
agent-12: 12.0
agent-13: 18.0
agent-14: 14.0
agent-15: 20.0
agent-16: 9.0
agent-17: 9.0
agent-18: 28.0
agent-19: 25.0
agent-20: 12.0
Sum Reward: 344.0
Avg Reward: 17.2
Min Reward: 6.0
Gini Coefficient: 0.2444767441860465
20:20 Ratio: 3.3529411764705883
Max-min Ratio: 5.333333333333333
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_01-21-50
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 562.0
  episode_reward_mean: 348.31
  episode_reward_min: 249.0
  episodes_this_iter: 1
  episodes_total: 433
  experiment_id: 35d66058da2d4c9882f832ee91e4aa4a
  hostname: gpu011
  info:
    apply_time_ms: 4.036
    dispatch_time_ms: 7.681
    learner:
      cur_lr: 0.0007832439732737839
      grad_gnorm: 27.449331283569336
      policy_entropy: 118.8846206665039
      policy_loss: -8.028223037719727
      var_gnorm: 20.050376892089844
      vf_explained_var: 5.960464477539063e-08
      vf_loss: 22.59218978881836
    num_steps_sampled: 8680000
    num_steps_trained: 8680000
    wait_time_ms: 259.419
  iterations_since_restore: 434
  node_ip: 172.17.8.11
  num_metric_batches_dropped: 0
  pid: 25504
  policy_reward_mean: {}
  time_since_restore: 12229.595248222351
  time_this_iter_s: 27.057522535324097
  time_total_s: 12229.595248222351
  timestamp: 1593926510
  timesteps_since_restore: 8680000
  timesteps_this_iter: 20000
  timesteps_total: 8680000
  training_iteration: 434
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=25504], 12229 s, 434 iter, 8680000 ts, 348 rew

agent-1: 20.0
agent-2: 21.0
agent-3: 13.0
agent-4: 4.0
agent-5: 21.0
agent-6: 7.0
agent-7: 21.0
agent-8: 26.0
agent-9: 34.0
agent-10: 15.0
agent-11: 18.0
agent-12: 10.0
agent-13: 51.0
agent-14: 20.0
agent-15: 29.0
agent-16: 31.0
agent-17: 15.0
agent-18: 27.0
agent-19: 19.0
agent-20: 8.0
Sum Reward: 410.0
Avg Reward: 20.5
Min Reward: 4.0
Gini Coefficient: 0.275609756097561
20:20 Ratio: 5.0
Max-min Ratio: 12.75
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_01-22-18
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 562.0
  episode_reward_mean: 349.44
  episode_reward_min: 249.0
  episodes_this_iter: 1
  episodes_total: 434
  experiment_id: 35d66058da2d4c9882f832ee91e4aa4a
  hostname: gpu011
  info:
    apply_time_ms: 2.683
    dispatch_time_ms: 7.965
    learner:
      cur_lr: 0.000781912007369101
      grad_gnorm: 17.262983322143555
      policy_entropy: 161.23072814941406
      policy_loss: -4.920835971832275
      var_gnorm: 20.044694900512695
      vf_explained_var: 0.0
      vf_loss: 0.12021715939044952
    num_steps_sampled: 8700000
    num_steps_trained: 8700000
    wait_time_ms: 249.742
  iterations_since_restore: 435
  node_ip: 172.17.8.11
  num_metric_batches_dropped: 0
  pid: 25504
  policy_reward_mean: {}
  time_since_restore: 12257.295234203339
  time_this_iter_s: 27.69998598098755
  time_total_s: 12257.295234203339
  timestamp: 1593926538
  timesteps_since_restore: 8700000
  timesteps_this_iter: 20000
  timesteps_total: 8700000
  training_iteration: 435
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=25504], 12257 s, 435 iter, 8700000 ts, 349 rew

agent-1: 33.0
agent-2: 16.0
agent-3: 15.0
agent-4: 19.0
agent-5: 43.0
agent-6: 60.0
agent-7: 19.0
agent-8: 19.0
agent-9: 20.0
agent-10: 17.0
agent-11: 10.0
agent-12: 16.0
agent-13: 10.0
agent-14: 7.0
agent-15: 37.0
agent-16: 32.0
agent-17: 17.0
agent-18: 9.0
agent-19: 16.0
agent-20: 21.0
Sum Reward: 436.0
Avg Reward: 21.8
Min Reward: 7.0
Gini Coefficient: 0.29495412844036695
20:20 Ratio: 4.805555555555555
Max-min Ratio: 8.571428571428571
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_01-22-46
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 562.0
  episode_reward_mean: 350.27
  episode_reward_min: 249.0
  episodes_this_iter: 1
  episodes_total: 435
  experiment_id: 35d66058da2d4c9882f832ee91e4aa4a
  hostname: gpu011
  info:
    apply_time_ms: 3.488
    dispatch_time_ms: 7.132
    learner:
      cur_lr: 0.0007805799832567573
      grad_gnorm: 15.112822532653809
      policy_entropy: 125.88214874267578
      policy_loss: -2.6356711387634277
      var_gnorm: 20.04252052307129
      vf_explained_var: 0.0
      vf_loss: 3.2361321449279785
    num_steps_sampled: 8720000
    num_steps_trained: 8720000
    wait_time_ms: 271.401
  iterations_since_restore: 436
  node_ip: 172.17.8.11
  num_metric_batches_dropped: 0
  pid: 25504
  policy_reward_mean: {}
  time_since_restore: 12284.761054992676
  time_this_iter_s: 27.465820789337158
  time_total_s: 12284.761054992676
  timestamp: 1593926566
  timesteps_since_restore: 8720000
  timesteps_this_iter: 20000
  timesteps_total: 8720000
  training_iteration: 436
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=25504], 12284 s, 436 iter, 8720000 ts, 350 rew

agent-1: 17.0
agent-2: 16.0
agent-3: 8.0
agent-4: 9.0
agent-5: 26.0
agent-6: 34.0
agent-7: 27.0
agent-8: 29.0
agent-9: 19.0
agent-10: 20.0
agent-11: 15.0
agent-12: 21.0
agent-13: 21.0
agent-14: 10.0
agent-15: 23.0
agent-16: 17.0
agent-17: 14.0
agent-18: 33.0
agent-19: 10.0
agent-20: 22.0
Sum Reward: 391.0
Avg Reward: 19.55
Min Reward: 8.0
Gini Coefficient: 0.21572890025575447
20:20 Ratio: 3.324324324324324
Max-min Ratio: 4.25
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_01-23-13
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 562.0
  episode_reward_mean: 351.5
  episode_reward_min: 249.0
  episodes_this_iter: 1
  episodes_total: 436
  experiment_id: 35d66058da2d4c9882f832ee91e4aa4a
  hostname: gpu011
  info:
    apply_time_ms: 3.318
    dispatch_time_ms: 6.589
    learner:
      cur_lr: 0.0007792480173520744
      grad_gnorm: 13.486567497253418
      policy_entropy: 134.47747802734375
      policy_loss: -2.489718198776245
      var_gnorm: 20.039329528808594
      vf_explained_var: 0.0
      vf_loss: 0.07341431081295013
    num_steps_sampled: 8740000
    num_steps_trained: 8740000
    wait_time_ms: 263.474
  iterations_since_restore: 437
  node_ip: 172.17.8.11
  num_metric_batches_dropped: 0
  pid: 25504
  policy_reward_mean: {}
  time_since_restore: 12312.327620744705
  time_this_iter_s: 27.56656575202942
  time_total_s: 12312.327620744705
  timestamp: 1593926593
  timesteps_since_restore: 8740000
  timesteps_this_iter: 20000
  timesteps_total: 8740000
  training_iteration: 437
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=25504], 12312 s, 437 iter, 8740000 ts, 352 rew

agent-1: 18.0
agent-2: 8.0
agent-3: 22.0
agent-4: 16.0
agent-5: 16.0
agent-6: 15.0
agent-7: 27.0
agent-8: 21.0
agent-9: 15.0
agent-10: 13.0
agent-11: 18.0
agent-12: 20.0
agent-13: 10.0
agent-14: 24.0
agent-15: 13.0
agent-16: 9.0
agent-17: 16.0
agent-18: 22.0
agent-19: 6.0
agent-20: 16.0
Sum Reward: 325.0
Avg Reward: 16.25
Min Reward: 6.0
Gini Coefficient: 0.186
20:20 Ratio: 2.878787878787879
Max-min Ratio: 4.5
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_01-23-41
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 562.0
  episode_reward_mean: 351.07
  episode_reward_min: 249.0
  episodes_this_iter: 1
  episodes_total: 437
  experiment_id: 35d66058da2d4c9882f832ee91e4aa4a
  hostname: gpu011
  info:
    apply_time_ms: 3.14
    dispatch_time_ms: 5.169
    learner:
      cur_lr: 0.0007779159932397306
      grad_gnorm: 6.432458400726318
      policy_entropy: 114.76822662353516
      policy_loss: 1.6601009368896484
      var_gnorm: 20.04311752319336
      vf_explained_var: 0.0
      vf_loss: 6.415241241455078
    num_steps_sampled: 8760000
    num_steps_trained: 8760000
    wait_time_ms: 282.851
  iterations_since_restore: 438
  node_ip: 172.17.8.11
  num_metric_batches_dropped: 0
  pid: 25504
  policy_reward_mean: {}
  time_since_restore: 12339.663966655731
  time_this_iter_s: 27.336345911026
  time_total_s: 12339.663966655731
  timestamp: 1593926621
  timesteps_since_restore: 8760000
  timesteps_this_iter: 20000
  timesteps_total: 8760000
  training_iteration: 438
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=25504], 12339 s, 438 iter, 8760000 ts, 351 rew

agent-1: 23.0
agent-2: 17.0
agent-3: 19.0
agent-4: 20.0
agent-5: 15.0
agent-6: 24.0
agent-7: 23.0
agent-8: 5.0
agent-9: 13.0
agent-10: 23.0
agent-11: 18.0
agent-12: 7.0
agent-13: 35.0
agent-14: 14.0
agent-15: 18.0
agent-16: 17.0
agent-17: 32.0
agent-18: 16.0
agent-19: 22.0
agent-20: 5.0
Sum Reward: 366.0
Avg Reward: 18.3
Min Reward: 5.0
Gini Coefficient: 0.22513661202185792
20:20 Ratio: 3.8
Max-min Ratio: 7.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_01-24-09
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 562.0
  episode_reward_mean: 352.0
  episode_reward_min: 249.0
  episodes_this_iter: 1
  episodes_total: 438
  experiment_id: 35d66058da2d4c9882f832ee91e4aa4a
  hostname: gpu011
  info:
    apply_time_ms: 3.134
    dispatch_time_ms: 45.966
    learner:
      cur_lr: 0.0007765840273350477
      grad_gnorm: 9.86186695098877
      policy_entropy: 106.59197235107422
      policy_loss: -1.328530192375183
      var_gnorm: 20.044023513793945
      vf_explained_var: 5.960464477539063e-08
      vf_loss: 0.03930065780878067
    num_steps_sampled: 8780000
    num_steps_trained: 8780000
    wait_time_ms: 217.136
  iterations_since_restore: 439
  node_ip: 172.17.8.11
  num_metric_batches_dropped: 0
  pid: 25504
  policy_reward_mean: {}
  time_since_restore: 12367.60709285736
  time_this_iter_s: 27.94312620162964
  time_total_s: 12367.60709285736
  timestamp: 1593926649
  timesteps_since_restore: 8780000
  timesteps_this_iter: 20000
  timesteps_total: 8780000
  training_iteration: 439
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=25504], 12367 s, 439 iter, 8780000 ts, 352 rew

agent-1: 6.0
agent-2: 20.0
agent-3: 31.0
agent-4: 12.0
agent-5: 6.0
agent-6: 28.0
agent-7: 12.0
agent-8: 11.0
agent-9: 23.0
agent-10: 23.0
agent-11: 22.0
agent-12: 26.0
agent-13: 15.0
agent-14: 13.0
agent-15: 19.0
agent-16: 24.0
agent-17: 9.0
agent-18: 10.0
agent-19: 27.0
agent-20: 13.0
Sum Reward: 350.0
Avg Reward: 17.5
Min Reward: 6.0
Gini Coefficient: 0.24514285714285713
20:20 Ratio: 3.6129032258064515
Max-min Ratio: 5.166666666666667
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_01-24-36
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 562.0
  episode_reward_mean: 351.49
  episode_reward_min: 249.0
  episodes_this_iter: 1
  episodes_total: 439
  experiment_id: 35d66058da2d4c9882f832ee91e4aa4a
  hostname: gpu011
  info:
    apply_time_ms: 3.15
    dispatch_time_ms: 51.379
    learner:
      cur_lr: 0.0007752520032227039
      grad_gnorm: 38.207252502441406
      policy_entropy: 73.87791442871094
      policy_loss: -1.3199766874313354
      var_gnorm: 20.05716323852539
      vf_explained_var: 0.0
      vf_loss: 22.177539825439453
    num_steps_sampled: 8800000
    num_steps_trained: 8800000
    wait_time_ms: 239.954
  iterations_since_restore: 440
  node_ip: 172.17.8.11
  num_metric_batches_dropped: 0
  pid: 25504
  policy_reward_mean: {}
  time_since_restore: 12395.200095415115
  time_this_iter_s: 27.593002557754517
  time_total_s: 12395.200095415115
  timestamp: 1593926676
  timesteps_since_restore: 8800000
  timesteps_this_iter: 20000
  timesteps_total: 8800000
  training_iteration: 440
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=25504], 12395 s, 440 iter, 8800000 ts, 351 rew

agent-1: 40.0
agent-2: 18.0
agent-3: 13.0
agent-4: 33.0
agent-5: 18.0
agent-6: 27.0
agent-7: 5.0
agent-8: 34.0
agent-9: 13.0
agent-10: 24.0
agent-11: 9.0
agent-12: 22.0
agent-13: 6.0
agent-14: 6.0
agent-15: 25.0
agent-16: 17.0
agent-17: 33.0
agent-18: 30.0
agent-19: 25.0
agent-20: 9.0
Sum Reward: 407.0
Avg Reward: 20.35
Min Reward: 5.0
Gini Coefficient: 0.29004914004914006
20:20 Ratio: 5.384615384615385
Max-min Ratio: 8.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_01-25-04
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 562.0
  episode_reward_mean: 352.46
  episode_reward_min: 249.0
  episodes_this_iter: 1
  episodes_total: 440
  experiment_id: 35d66058da2d4c9882f832ee91e4aa4a
  hostname: gpu011
  info:
    apply_time_ms: 3.053
    dispatch_time_ms: 70.752
    learner:
      cur_lr: 0.0007739199791103601
      grad_gnorm: 40.0
      policy_entropy: 118.55010223388672
      policy_loss: 26.604944229125977
      var_gnorm: 20.05206298828125
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 54.40991973876953
    num_steps_sampled: 8820000
    num_steps_trained: 8820000
    wait_time_ms: 191.464
  iterations_since_restore: 441
  node_ip: 172.17.8.11
  num_metric_batches_dropped: 0
  pid: 25504
  policy_reward_mean: {}
  time_since_restore: 12423.167784452438
  time_this_iter_s: 27.967689037322998
  time_total_s: 12423.167784452438
  timestamp: 1593926704
  timesteps_since_restore: 8820000
  timesteps_this_iter: 20000
  timesteps_total: 8820000
  training_iteration: 441
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=25504], 12423 s, 441 iter, 8820000 ts, 352 rew

agent-1: 43.0
agent-2: 28.0
agent-3: 27.0
agent-4: 29.0
agent-5: 29.0
agent-6: 32.0
agent-7: 14.0
agent-8: 43.0
agent-9: 37.0
agent-10: 59.0
agent-11: 18.0
agent-12: 22.0
agent-13: 24.0
agent-14: 42.0
agent-15: 41.0
agent-16: 16.0
agent-17: 46.0
agent-18: 27.0
agent-19: 7.0
agent-20: 31.0
Sum Reward: 615.0
Avg Reward: 30.75
Min Reward: 7.0
Gini Coefficient: 0.2226829268292683
20:20 Ratio: 3.4727272727272727
Max-min Ratio: 8.428571428571429
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_01-25-33
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 615.0
  episode_reward_mean: 354.56
  episode_reward_min: 249.0
  episodes_this_iter: 1
  episodes_total: 441
  experiment_id: 35d66058da2d4c9882f832ee91e4aa4a
  hostname: gpu011
  info:
    apply_time_ms: 2.703
    dispatch_time_ms: 43.484
    learner:
      cur_lr: 0.0007725880132056773
      grad_gnorm: 40.0
      policy_entropy: 149.7484893798828
      policy_loss: 11.861221313476562
      var_gnorm: 20.055179595947266
      vf_explained_var: 0.0
      vf_loss: 25.616561889648438
    num_steps_sampled: 8840000
    num_steps_trained: 8840000
    wait_time_ms: 237.559
  iterations_since_restore: 442
  node_ip: 172.17.8.11
  num_metric_batches_dropped: 0
  pid: 25504
  policy_reward_mean: {}
  time_since_restore: 12451.754059553146
  time_this_iter_s: 28.586275100708008
  time_total_s: 12451.754059553146
  timestamp: 1593926733
  timesteps_since_restore: 8840000
  timesteps_this_iter: 20000
  timesteps_total: 8840000
  training_iteration: 442
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=25504], 12451 s, 442 iter, 8840000 ts, 355 rew

agent-1: 17.0
agent-2: 19.0
agent-3: 32.0
agent-4: 24.0
agent-5: 0.0
agent-6: 22.0
agent-7: 22.0
agent-8: 13.0
agent-9: 24.0
agent-10: 12.0
agent-11: 22.0
agent-12: 7.0
agent-13: 20.0
agent-14: 6.0
agent-15: 20.0
agent-16: 11.0
agent-17: 16.0
agent-18: 14.0
agent-19: 15.0
agent-20: 2.0
Sum Reward: 318.0
Avg Reward: 15.9
Min Reward: 0.0
Gini Coefficient: 0.2751572327044025
20:20 Ratio: 6.8
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_01-26-05
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 615.0
  episode_reward_mean: 354.04
  episode_reward_min: 249.0
  episodes_this_iter: 1
  episodes_total: 442
  experiment_id: 35d66058da2d4c9882f832ee91e4aa4a
  hostname: gpu011
  info:
    apply_time_ms: 2.847
    dispatch_time_ms: 5.728
    learner:
      cur_lr: 0.0007712559890933335
      grad_gnorm: 16.61415672302246
      policy_entropy: 123.85182189941406
      policy_loss: -3.8524274826049805
      var_gnorm: 20.05473518371582
      vf_explained_var: 1.1920928955078125e-07
      vf_loss: 0.11070451140403748
    num_steps_sampled: 8860000
    num_steps_trained: 8860000
    wait_time_ms: 261.122
  iterations_since_restore: 443
  node_ip: 172.17.8.11
  num_metric_batches_dropped: 0
  pid: 25504
  policy_reward_mean: {}
  time_since_restore: 12483.762987613678
  time_this_iter_s: 32.008928060531616
  time_total_s: 12483.762987613678
  timestamp: 1593926765
  timesteps_since_restore: 8860000
  timesteps_this_iter: 20000
  timesteps_total: 8860000
  training_iteration: 443
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=25504], 12483 s, 443 iter, 8860000 ts, 354 rew

agent-1: 42.0
agent-2: 31.0
agent-3: 31.0
agent-4: 9.0
agent-5: 40.0
agent-6: 23.0
agent-7: 53.0
agent-8: 19.0
agent-9: 23.0
agent-10: 12.0
agent-11: 21.0
agent-12: 31.0
agent-13: 15.0
agent-14: 21.0
agent-15: 3.0
agent-16: 35.0
agent-17: 11.0
agent-18: 18.0
agent-19: 13.0
agent-20: 37.0
Sum Reward: 488.0
Avg Reward: 24.4
Min Reward: 3.0
Gini Coefficient: 0.28852459016393445
20:20 Ratio: 4.914285714285715
Max-min Ratio: 17.666666666666668
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_01-26-32
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 615.0
  episode_reward_mean: 355.72
  episode_reward_min: 249.0
  episodes_this_iter: 1
  episodes_total: 443
  experiment_id: 35d66058da2d4c9882f832ee91e4aa4a
  hostname: gpu011
  info:
    apply_time_ms: 3.3
    dispatch_time_ms: 7.529
    learner:
      cur_lr: 0.0007699240231886506
      grad_gnorm: 40.0
      policy_entropy: 97.20038604736328
      policy_loss: -6.6690826416015625
      var_gnorm: 20.06037712097168
      vf_explained_var: 0.0
      vf_loss: 0.8218305706977844
    num_steps_sampled: 8880000
    num_steps_trained: 8880000
    wait_time_ms: 275.071
  iterations_since_restore: 444
  node_ip: 172.17.8.11
  num_metric_batches_dropped: 0
  pid: 25504
  policy_reward_mean: {}
  time_since_restore: 12510.957036018372
  time_this_iter_s: 27.194048404693604
  time_total_s: 12510.957036018372
  timestamp: 1593926792
  timesteps_since_restore: 8880000
  timesteps_this_iter: 20000
  timesteps_total: 8880000
  training_iteration: 444
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=25504], 12510 s, 444 iter, 8880000 ts, 356 rew

agent-1: 27.0
agent-2: 15.0
agent-3: 17.0
agent-4: 15.0
agent-5: 29.0
agent-6: 26.0
agent-7: 3.0
agent-8: 18.0
agent-9: 9.0
agent-10: 17.0
agent-11: 12.0
agent-12: 4.0
agent-13: 30.0
agent-14: 6.0
agent-15: 29.0
agent-16: 14.0
agent-17: 26.0
agent-18: 14.0
agent-19: 12.0
agent-20: 7.0
Sum Reward: 330.0
Avg Reward: 16.5
Min Reward: 3.0
Gini Coefficient: 0.2912121212121212
20:20 Ratio: 5.75
Max-min Ratio: 10.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_01-27-00
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 615.0
  episode_reward_mean: 356.23
  episode_reward_min: 249.0
  episodes_this_iter: 1
  episodes_total: 444
  experiment_id: 35d66058da2d4c9882f832ee91e4aa4a
  hostname: gpu011
  info:
    apply_time_ms: 2.89
    dispatch_time_ms: 6.69
    learner:
      cur_lr: 0.0007685919990763068
      grad_gnorm: 9.955385208129883
      policy_entropy: 132.88360595703125
      policy_loss: -2.522944450378418
      var_gnorm: 20.06426429748535
      vf_explained_var: 0.0
      vf_loss: 0.03983461856842041
    num_steps_sampled: 8900000
    num_steps_trained: 8900000
    wait_time_ms: 266.134
  iterations_since_restore: 445
  node_ip: 172.17.8.11
  num_metric_batches_dropped: 0
  pid: 25504
  policy_reward_mean: {}
  time_since_restore: 12538.746369600296
  time_this_iter_s: 27.78933358192444
  time_total_s: 12538.746369600296
  timestamp: 1593926820
  timesteps_since_restore: 8900000
  timesteps_this_iter: 20000
  timesteps_total: 8900000
  training_iteration: 445
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=25504], 12538 s, 445 iter, 8900000 ts, 356 rew

agent-1: 2.0
agent-2: 20.0
agent-3: 13.0
agent-4: 20.0
agent-5: 32.0
agent-6: 32.0
agent-7: 51.0
agent-8: 17.0
agent-9: 21.0
agent-10: 13.0
agent-11: 30.0
agent-12: 25.0
agent-13: 25.0
agent-14: 22.0
agent-15: 26.0
agent-16: 3.0
agent-17: 32.0
agent-18: 11.0
agent-19: 28.0
agent-20: 18.0
Sum Reward: 441.0
Avg Reward: 22.05
Min Reward: 2.0
Gini Coefficient: 0.26859410430839004
20:20 Ratio: 5.068965517241379
Max-min Ratio: 25.5
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_01-27-27
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 615.0
  episode_reward_mean: 356.17
  episode_reward_min: 249.0
  episodes_this_iter: 1
  episodes_total: 445
  experiment_id: 35d66058da2d4c9882f832ee91e4aa4a
  hostname: gpu011
  info:
    apply_time_ms: 2.944
    dispatch_time_ms: 5.745
    learner:
      cur_lr: 0.000767259974963963
      grad_gnorm: 34.37184524536133
      policy_entropy: 141.471435546875
      policy_loss: -9.612597465515137
      var_gnorm: 20.066682815551758
      vf_explained_var: 0.0
      vf_loss: 0.4753705859184265
    num_steps_sampled: 8920000
    num_steps_trained: 8920000
    wait_time_ms: 274.122
  iterations_since_restore: 446
  node_ip: 172.17.8.11
  num_metric_batches_dropped: 0
  pid: 25504
  policy_reward_mean: {}
  time_since_restore: 12565.863003969193
  time_this_iter_s: 27.116634368896484
  time_total_s: 12565.863003969193
  timestamp: 1593926847
  timesteps_since_restore: 8920000
  timesteps_this_iter: 20000
  timesteps_total: 8920000
  training_iteration: 446
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=25504], 12565 s, 446 iter, 8920000 ts, 356 rew

agent-1: 35.0
agent-2: 12.0
agent-3: 6.0
agent-4: 17.0
agent-5: 34.0
agent-6: 17.0
agent-7: 20.0
agent-8: 16.0
agent-9: 9.0
agent-10: 30.0
agent-11: 43.0
agent-12: 7.0
agent-13: 32.0
agent-14: 17.0
agent-15: 8.0
agent-16: 31.0
agent-17: 14.0
agent-18: 16.0
agent-19: 4.0
agent-20: 33.0
Sum Reward: 401.0
Avg Reward: 20.05
Min Reward: 4.0
Gini Coefficient: 0.3145885286783042
20:20 Ratio: 5.8
Max-min Ratio: 10.75
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_01-27-55
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 615.0
  episode_reward_mean: 357.15
  episode_reward_min: 249.0
  episodes_this_iter: 1
  episodes_total: 446
  experiment_id: 35d66058da2d4c9882f832ee91e4aa4a
  hostname: gpu011
  info:
    apply_time_ms: 2.674
    dispatch_time_ms: 7.236
    learner:
      cur_lr: 0.0007659280090592802
      grad_gnorm: 40.000003814697266
      policy_entropy: 133.66513061523438
      policy_loss: 70.47354888916016
      var_gnorm: 20.061681747436523
      vf_explained_var: 0.0
      vf_loss: 160.941650390625
    num_steps_sampled: 8940000
    num_steps_trained: 8940000
    wait_time_ms: 250.714
  iterations_since_restore: 447
  node_ip: 172.17.8.11
  num_metric_batches_dropped: 0
  pid: 25504
  policy_reward_mean: {}
  time_since_restore: 12593.594611406326
  time_this_iter_s: 27.73160743713379
  time_total_s: 12593.594611406326
  timestamp: 1593926875
  timesteps_since_restore: 8940000
  timesteps_this_iter: 20000
  timesteps_total: 8940000
  training_iteration: 447
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=25504], 12593 s, 447 iter, 8940000 ts, 357 rew

agent-1: 10.0
agent-2: 16.0
agent-3: 35.0
agent-4: 8.0
agent-5: 33.0
agent-6: 12.0
agent-7: 9.0
agent-8: 18.0
agent-9: 35.0
agent-10: 11.0
agent-11: 6.0
agent-12: 5.0
agent-13: 19.0
agent-14: 15.0
agent-15: 17.0
agent-16: 20.0
agent-17: 21.0
agent-18: 24.0
agent-19: 6.0
agent-20: 11.0
Sum Reward: 331.0
Avg Reward: 16.55
Min Reward: 5.0
Gini Coefficient: 0.3028700906344411
20:20 Ratio: 5.08
Max-min Ratio: 7.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_01-28-22
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 615.0
  episode_reward_mean: 356.9
  episode_reward_min: 249.0
  episodes_this_iter: 1
  episodes_total: 447
  experiment_id: 35d66058da2d4c9882f832ee91e4aa4a
  hostname: gpu011
  info:
    apply_time_ms: 3.698
    dispatch_time_ms: 7.372
    learner:
      cur_lr: 0.0007645959849469364
      grad_gnorm: 23.352680206298828
      policy_entropy: 170.75680541992188
      policy_loss: -8.198795318603516
      var_gnorm: 20.063478469848633
      vf_explained_var: 5.960464477539063e-08
      vf_loss: 0.21832826733589172
    num_steps_sampled: 8960000
    num_steps_trained: 8960000
    wait_time_ms: 268.892
  iterations_since_restore: 448
  node_ip: 172.17.8.11
  num_metric_batches_dropped: 0
  pid: 25504
  policy_reward_mean: {}
  time_since_restore: 12620.76613855362
  time_this_iter_s: 27.17152714729309
  time_total_s: 12620.76613855362
  timestamp: 1593926902
  timesteps_since_restore: 8960000
  timesteps_this_iter: 20000
  timesteps_total: 8960000
  training_iteration: 448
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=25504], 12620 s, 448 iter, 8960000 ts, 357 rew

agent-1: 20.0
agent-2: 16.0
agent-3: 25.0
agent-4: 27.0
agent-5: 3.0
agent-6: 16.0
agent-7: 27.0
agent-8: 15.0
agent-9: 14.0
agent-10: 10.0
agent-11: 6.0
agent-12: 7.0
agent-13: 23.0
agent-14: 11.0
agent-15: 15.0
agent-16: 11.0
agent-17: 19.0
agent-18: 11.0
agent-19: 15.0
agent-20: 7.0
Sum Reward: 298.0
Avg Reward: 14.9
Min Reward: 3.0
Gini Coefficient: 0.25771812080536916
20:20 Ratio: 4.434782608695652
Max-min Ratio: 9.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_01-28-50
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 615.0
  episode_reward_mean: 356.4
  episode_reward_min: 249.0
  episodes_this_iter: 1
  episodes_total: 448
  experiment_id: 35d66058da2d4c9882f832ee91e4aa4a
  hostname: gpu011
  info:
    apply_time_ms: 2.537
    dispatch_time_ms: 6.452
    learner:
      cur_lr: 0.0007632640190422535
      grad_gnorm: 0.6261996626853943
      policy_entropy: 187.3100128173828
      policy_loss: -0.2901006042957306
      var_gnorm: 20.05733299255371
      vf_explained_var: 0.0
      vf_loss: 0.00013926965766586363
    num_steps_sampled: 8980000
    num_steps_trained: 8980000
    wait_time_ms: 266.836
  iterations_since_restore: 449
  node_ip: 172.17.8.11
  num_metric_batches_dropped: 0
  pid: 25504
  policy_reward_mean: {}
  time_since_restore: 12648.749410629272
  time_this_iter_s: 27.983272075653076
  time_total_s: 12648.749410629272
  timestamp: 1593926930
  timesteps_since_restore: 8980000
  timesteps_this_iter: 20000
  timesteps_total: 8980000
  training_iteration: 449
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=25504], 12648 s, 449 iter, 8980000 ts, 356 rew

agent-1: 10.0
agent-2: 13.0
agent-3: 18.0
agent-4: 8.0
agent-5: 24.0
agent-6: 16.0
agent-7: 21.0
agent-8: 15.0
agent-9: 13.0
agent-10: 20.0
agent-11: 11.0
agent-12: 12.0
agent-13: 18.0
agent-14: 13.0
agent-15: 13.0
agent-16: 21.0
agent-17: 20.0
agent-18: 14.0
agent-19: 16.0
agent-20: 22.0
Sum Reward: 318.0
Avg Reward: 15.9
Min Reward: 8.0
Gini Coefficient: 0.15440251572327043
20:20 Ratio: 2.1463414634146343
Max-min Ratio: 3.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_01-29-17
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 615.0
  episode_reward_mean: 356.58
  episode_reward_min: 249.0
  episodes_this_iter: 1
  episodes_total: 449
  experiment_id: 35d66058da2d4c9882f832ee91e4aa4a
  hostname: gpu011
  info:
    apply_time_ms: 3.02
    dispatch_time_ms: 7.236
    learner:
      cur_lr: 0.0007619319949299097
      grad_gnorm: 37.37342071533203
      policy_entropy: 167.78567504882812
      policy_loss: -11.702930450439453
      var_gnorm: 20.063961029052734
      vf_explained_var: 1.7881393432617188e-07
      vf_loss: 0.5634267330169678
    num_steps_sampled: 9000000
    num_steps_trained: 9000000
    wait_time_ms: 272.128
  iterations_since_restore: 450
  node_ip: 172.17.8.11
  num_metric_batches_dropped: 0
  pid: 25504
  policy_reward_mean: {}
  time_since_restore: 12675.890930891037
  time_this_iter_s: 27.141520261764526
  time_total_s: 12675.890930891037
  timestamp: 1593926957
  timesteps_since_restore: 9000000
  timesteps_this_iter: 20000
  timesteps_total: 9000000
  training_iteration: 450
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=25504], 12675 s, 450 iter, 9000000 ts, 357 rew

agent-1: 18.0
agent-2: 22.0
agent-3: 6.0
agent-4: 18.0
agent-5: 18.0
agent-6: 13.0
agent-7: 10.0
agent-8: 30.0
agent-9: 25.0
agent-10: 24.0
agent-11: 34.0
agent-12: 4.0
agent-13: 23.0
agent-14: 40.0
agent-15: 10.0
agent-16: 33.0
agent-17: 32.0
agent-18: 23.0
agent-19: 5.0
agent-20: 10.0
Sum Reward: 398.0
Avg Reward: 19.9
Min Reward: 4.0
Gini Coefficient: 0.29447236180904524
20:20 Ratio: 5.56
Max-min Ratio: 10.0
agent-1: 16.0
agent-2: 6.0
agent-3: 18.0
agent-4: 24.0
agent-5: 20.0
agent-6: 22.0
agent-7: 23.0
agent-8: 12.0
agent-9: 15.0
agent-10: 27.0
agent-11: 5.0
agent-12: 10.0
agent-13: 4.0
agent-14: 11.0
agent-15: 19.0
agent-16: 8.0
agent-17: 28.0
agent-18: 17.0
agent-19: 14.0
agent-20: 6.0
Sum Reward: 305.0
Avg Reward: 15.25
Min Reward: 4.0
Gini Coefficient: 0.27229508196721314
20:20 Ratio: 4.857142857142857
Max-min Ratio: 7.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_01-29-45
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 615.0
  episode_reward_mean: 357.72
  episode_reward_min: 249.0
  episodes_this_iter: 1
  episodes_total: 450
  experiment_id: 35d66058da2d4c9882f832ee91e4aa4a
  hostname: gpu011
  info:
    apply_time_ms: 3.467
    dispatch_time_ms: 6.436
    learner:
      cur_lr: 0.0007606000290252268
      grad_gnorm: 40.0
      policy_entropy: 167.701171875
      policy_loss: 110.90296173095703
      var_gnorm: 20.05689239501953
      vf_explained_var: 0.000904083251953125
      vf_loss: 156.6054229736328
    num_steps_sampled: 9020000
    num_steps_trained: 9020000
    wait_time_ms: 268.891
  iterations_since_restore: 451
  node_ip: 172.17.8.11
  num_metric_batches_dropped: 0
  pid: 25504
  policy_reward_mean: {}
  time_since_restore: 12703.689339399338
  time_this_iter_s: 27.79840850830078
  time_total_s: 12703.689339399338
  timestamp: 1593926985
  timesteps_since_restore: 9020000
  timesteps_this_iter: 20000
  timesteps_total: 9020000
  training_iteration: 451
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=25504], 12703 s, 451 iter, 9020000 ts, 358 rew

Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_01-30-12
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 615.0
  episode_reward_mean: 357.39
  episode_reward_min: 249.0
  episodes_this_iter: 1
  episodes_total: 451
  experiment_id: 35d66058da2d4c9882f832ee91e4aa4a
  hostname: gpu011
  info:
    apply_time_ms: 2.769
    dispatch_time_ms: 9.664
    learner:
      cur_lr: 0.000759268004912883
      grad_gnorm: 5.4051995277404785
      policy_entropy: 148.4927978515625
      policy_loss: -2.078566789627075
      var_gnorm: 20.062307357788086
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 4.449729919433594
    num_steps_sampled: 9040000
    num_steps_trained: 9040000
    wait_time_ms: 269.724
  iterations_since_restore: 452
  node_ip: 172.17.8.11
  num_metric_batches_dropped: 0
  pid: 25504
  policy_reward_mean: {}
  time_since_restore: 12730.62242436409
  time_this_iter_s: 26.933084964752197
  time_total_s: 12730.62242436409
  timestamp: 1593927012
  timesteps_since_restore: 9040000
  timesteps_this_iter: 20000
  timesteps_total: 9040000
  training_iteration: 452
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=25504], 12730 s, 452 iter, 9040000 ts, 357 rew

agent-1: 11.0
agent-2: 11.0
agent-3: 24.0
agent-4: 15.0
agent-5: 17.0
agent-6: 5.0
agent-7: 18.0
agent-8: 17.0
agent-9: 25.0
agent-10: 31.0
agent-11: 17.0
agent-12: 16.0
agent-13: 13.0
agent-14: 18.0
agent-15: 26.0
agent-16: 20.0
agent-17: 9.0
agent-18: 24.0
agent-19: 10.0
agent-20: 25.0
Sum Reward: 352.0
Avg Reward: 17.6
Min Reward: 5.0
Gini Coefficient: 0.21022727272727273
20:20 Ratio: 3.057142857142857
Max-min Ratio: 6.2
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_01-30-40
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 615.0
  episode_reward_mean: 358.08
  episode_reward_min: 249.0
  episodes_this_iter: 1
  episodes_total: 452
  experiment_id: 35d66058da2d4c9882f832ee91e4aa4a
  hostname: gpu011
  info:
    apply_time_ms: 2.885
    dispatch_time_ms: 6.406
    learner:
      cur_lr: 0.0007579359808005393
      grad_gnorm: 39.999996185302734
      policy_entropy: 145.6898956298828
      policy_loss: 88.40782165527344
      var_gnorm: 20.054588317871094
      vf_explained_var: 0.0016965866088867188
      vf_loss: 139.27513122558594
    num_steps_sampled: 9060000
    num_steps_trained: 9060000
    wait_time_ms: 265.42
  iterations_since_restore: 453
  node_ip: 172.17.8.11
  num_metric_batches_dropped: 0
  pid: 25504
  policy_reward_mean: {}
  time_since_restore: 12758.552916049957
  time_this_iter_s: 27.93049168586731
  time_total_s: 12758.552916049957
  timestamp: 1593927040
  timesteps_since_restore: 9060000
  timesteps_this_iter: 20000
  timesteps_total: 9060000
  training_iteration: 453
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=25504], 12758 s, 453 iter, 9060000 ts, 358 rew

agent-1: 19.0
agent-2: 12.0
agent-3: 11.0
agent-4: 8.0
agent-5: 11.0
agent-6: 10.0
agent-7: 29.0
agent-8: 21.0
agent-9: 18.0
agent-10: 23.0
agent-11: 11.0
agent-12: 16.0
agent-13: 12.0
agent-14: 10.0
agent-15: 31.0
agent-16: 3.0
agent-17: 14.0
agent-18: 23.0
agent-19: 10.0
agent-20: 13.0
Sum Reward: 305.0
Avg Reward: 15.25
Min Reward: 3.0
Gini Coefficient: 0.250327868852459
20:20 Ratio: 3.4193548387096775
Max-min Ratio: 10.333333333333334
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_01-31-07
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 615.0
  episode_reward_mean: 358.33
  episode_reward_min: 249.0
  episodes_this_iter: 1
  episodes_total: 453
  experiment_id: 35d66058da2d4c9882f832ee91e4aa4a
  hostname: gpu011
  info:
    apply_time_ms: 3.151
    dispatch_time_ms: 7.082
    learner:
      cur_lr: 0.0007566040148958564
      grad_gnorm: 33.8631591796875
      policy_entropy: 194.50924682617188
      policy_loss: -12.87856388092041
      var_gnorm: 20.062543869018555
      vf_explained_var: 0.0
      vf_loss: 1.820651888847351
    num_steps_sampled: 9080000
    num_steps_trained: 9080000
    wait_time_ms: 266.786
  iterations_since_restore: 454
  node_ip: 172.17.8.11
  num_metric_batches_dropped: 0
  pid: 25504
  policy_reward_mean: {}
  time_since_restore: 12785.470846652985
  time_this_iter_s: 26.917930603027344
  time_total_s: 12785.470846652985
  timestamp: 1593927067
  timesteps_since_restore: 9080000
  timesteps_this_iter: 20000
  timesteps_total: 9080000
  training_iteration: 454
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=25504], 12785 s, 454 iter, 9080000 ts, 358 rew

agent-1: 22.0
agent-2: 23.0
agent-3: 26.0
agent-4: 17.0
agent-5: 9.0
agent-6: 22.0
agent-7: 17.0
agent-8: 10.0
agent-9: 18.0
agent-10: 8.0
agent-11: 20.0
agent-12: 14.0
agent-13: 36.0
agent-14: 19.0
agent-15: 10.0
agent-16: 13.0
agent-17: 6.0
agent-18: 8.0
agent-19: 9.0
agent-20: 25.0
Sum Reward: 332.0
Avg Reward: 16.6
Min Reward: 6.0
Gini Coefficient: 0.2524096385542169
20:20 Ratio: 3.5483870967741935
Max-min Ratio: 6.0
agent-1: 20.0
agent-2: 24.0
agent-3: 25.0
agent-4: 19.0
agent-5: 6.0
agent-6: 10.0
agent-7: 15.0
agent-8: 9.0
agent-9: 6.0
agent-10: 49.0
agent-11: 16.0
agent-12: 9.0
agent-13: 24.0
agent-14: 20.0
agent-15: 32.0
agent-16: 16.0
agent-17: 23.0
agent-18: 19.0
agent-19: 25.0
agent-20: 22.0
Sum Reward: 389.0
Avg Reward: 19.45
Min Reward: 6.0
Gini Coefficient: 0.2602827763496144
20:20 Ratio: 4.366666666666666
Max-min Ratio: 8.166666666666666
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_01-31-35
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 615.0
  episode_reward_mean: 359.52
  episode_reward_min: 249.0
  episodes_this_iter: 2
  episodes_total: 455
  experiment_id: 35d66058da2d4c9882f832ee91e4aa4a
  hostname: gpu011
  info:
    apply_time_ms: 3.376
    dispatch_time_ms: 7.279
    learner:
      cur_lr: 0.0007552719907835126
      grad_gnorm: 36.529624938964844
      policy_entropy: 194.1749725341797
      policy_loss: -12.864243507385254
      var_gnorm: 20.049470901489258
      vf_explained_var: -1.0
      vf_loss: 0.4252517819404602
    num_steps_sampled: 9100000
    num_steps_trained: 9100000
    wait_time_ms: 264.679
  iterations_since_restore: 455
  node_ip: 172.17.8.11
  num_metric_batches_dropped: 0
  pid: 25504
  policy_reward_mean: {}
  time_since_restore: 12813.296801805496
  time_this_iter_s: 27.825955152511597
  time_total_s: 12813.296801805496
  timestamp: 1593927095
  timesteps_since_restore: 9100000
  timesteps_this_iter: 20000
  timesteps_total: 9100000
  training_iteration: 455
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=25504], 12813 s, 455 iter, 9100000 ts, 360 rew

Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_01-32-03
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 615.0
  episode_reward_mean: 359.52
  episode_reward_min: 249.0
  episodes_this_iter: 0
  episodes_total: 455
  experiment_id: 35d66058da2d4c9882f832ee91e4aa4a
  hostname: gpu011
  info:
    apply_time_ms: 3.933
    dispatch_time_ms: 6.744
    learner:
      cur_lr: 0.0007539400248788297
      grad_gnorm: 6.172367095947266
      policy_entropy: 176.0601043701172
      policy_loss: -0.14992433786392212
      var_gnorm: 20.053647994995117
      vf_explained_var: 0.0
      vf_loss: 2.303523302078247
    num_steps_sampled: 9120000
    num_steps_trained: 9120000
    wait_time_ms: 273.947
  iterations_since_restore: 456
  node_ip: 172.17.8.11
  num_metric_batches_dropped: 0
  pid: 25504
  policy_reward_mean: {}
  time_since_restore: 12840.762600898743
  time_this_iter_s: 27.46579909324646
  time_total_s: 12840.762600898743
  timestamp: 1593927123
  timesteps_since_restore: 9120000
  timesteps_this_iter: 20000
  timesteps_total: 9120000
  training_iteration: 456
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=25504], 12840 s, 456 iter, 9120000 ts, 360 rew

agent-1: 19.0
agent-2: 25.0
agent-3: 3.0
agent-4: 11.0
agent-5: 12.0
agent-6: 14.0
agent-7: 11.0
agent-8: 13.0
agent-9: 15.0
agent-10: 13.0
agent-11: 9.0
agent-12: 6.0
agent-13: 8.0
agent-14: 18.0
agent-15: 2.0
agent-16: 26.0
agent-17: 15.0
agent-18: 10.0
agent-19: 19.0
agent-20: 10.0
Sum Reward: 259.0
Avg Reward: 12.95
Min Reward: 2.0
Gini Coefficient: 0.2642857142857143
20:20 Ratio: 4.684210526315789
Max-min Ratio: 13.0
agent-1: 12.0
agent-2: 16.0
agent-3: 3.0
agent-4: 19.0
agent-5: 15.0
agent-6: 17.0
agent-7: 7.0
agent-8: 14.0
agent-9: 14.0
agent-10: 19.0
agent-11: 15.0
agent-12: 9.0
agent-13: 9.0
agent-14: 8.0
agent-15: 19.0
agent-16: 12.0
agent-17: 10.0
agent-18: 24.0
agent-19: 7.0
agent-20: 7.0
Sum Reward: 256.0
Avg Reward: 12.8
Min Reward: 3.0
Gini Coefficient: 0.2296875
20:20 Ratio: 3.375
Max-min Ratio: 8.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_01-32-31
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 615.0
  episode_reward_mean: 359.57
  episode_reward_min: 249.0
  episodes_this_iter: 2
  episodes_total: 457
  experiment_id: 35d66058da2d4c9882f832ee91e4aa4a
  hostname: gpu011
  info:
    apply_time_ms: 4.024
    dispatch_time_ms: 8.136
    learner:
      cur_lr: 0.0007526080007664859
      grad_gnorm: 4.924214839935303
      policy_entropy: 176.71778869628906
      policy_loss: -1.654754400253296
      var_gnorm: 20.04646110534668
      vf_explained_var: -1.0
      vf_loss: 0.007512269541621208
    num_steps_sampled: 9140000
    num_steps_trained: 9140000
    wait_time_ms: 271.176
  iterations_since_restore: 457
  node_ip: 172.17.8.11
  num_metric_batches_dropped: 0
  pid: 25504
  policy_reward_mean: {}
  time_since_restore: 12868.804683923721
  time_this_iter_s: 28.042083024978638
  time_total_s: 12868.804683923721
  timestamp: 1593927151
  timesteps_since_restore: 9140000
  timesteps_this_iter: 20000
  timesteps_total: 9140000
  training_iteration: 457
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=25504], 12868 s, 457 iter, 9140000 ts, 360 rew

Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_01-32-58
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 615.0
  episode_reward_mean: 359.57
  episode_reward_min: 249.0
  episodes_this_iter: 0
  episodes_total: 457
  experiment_id: 35d66058da2d4c9882f832ee91e4aa4a
  hostname: gpu011
  info:
    apply_time_ms: 3.083
    dispatch_time_ms: 7.172
    learner:
      cur_lr: 0.0007512759766541421
      grad_gnorm: 29.501697540283203
      policy_entropy: 193.83306884765625
      policy_loss: -10.645727157592773
      var_gnorm: 20.053537368774414
      vf_explained_var: 5.960464477539063e-08
      vf_loss: 0.34880369901657104
    num_steps_sampled: 9160000
    num_steps_trained: 9160000
    wait_time_ms: 270.932
  iterations_since_restore: 458
  node_ip: 172.17.8.11
  num_metric_batches_dropped: 0
  pid: 25504
  policy_reward_mean: {}
  time_since_restore: 12896.082161664963
  time_this_iter_s: 27.277477741241455
  time_total_s: 12896.082161664963
  timestamp: 1593927178
  timesteps_since_restore: 9160000
  timesteps_this_iter: 20000
  timesteps_total: 9160000
  training_iteration: 458
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=25504], 12896 s, 458 iter, 9160000 ts, 360 rew

agent-1: 15.0
agent-2: 3.0
agent-3: 19.0
agent-4: 3.0
agent-5: 14.0
agent-6: 5.0
agent-7: 4.0
agent-8: 13.0
agent-9: 31.0
agent-10: 11.0
agent-11: 33.0
agent-12: 13.0
agent-13: 15.0
agent-14: 15.0
agent-15: 8.0
agent-16: 11.0
agent-17: 19.0
agent-18: 21.0
agent-19: 19.0
agent-20: 14.0
Sum Reward: 286.0
Avg Reward: 14.3
Min Reward: 3.0
Gini Coefficient: 0.3006993006993007
20:20 Ratio: 6.933333333333334
Max-min Ratio: 11.0
agent-1: 19.0
agent-2: 27.0
agent-3: 15.0
agent-4: 26.0
agent-5: 13.0
agent-6: 11.0
agent-7: 13.0
agent-8: 12.0
agent-9: 22.0
agent-10: 8.0
agent-11: 16.0
agent-12: 8.0
agent-13: 24.0
agent-14: 17.0
agent-15: 12.0
agent-16: 16.0
agent-17: 24.0
agent-18: 18.0
agent-19: 14.0
agent-20: 15.0
Sum Reward: 330.0
Avg Reward: 16.5
Min Reward: 8.0
Gini Coefficient: 0.18727272727272729
20:20 Ratio: 2.58974358974359
Max-min Ratio: 3.375
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_01-33-26
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 615.0
  episode_reward_mean: 359.68
  episode_reward_min: 249.0
  episodes_this_iter: 2
  episodes_total: 459
  experiment_id: 35d66058da2d4c9882f832ee91e4aa4a
  hostname: gpu011
  info:
    apply_time_ms: 3.092
    dispatch_time_ms: 7.083
    learner:
      cur_lr: 0.0007499440107494593
      grad_gnorm: 10.654717445373535
      policy_entropy: 187.4327392578125
      policy_loss: -3.6570346355438232
      var_gnorm: 20.037080764770508
      vf_explained_var: -1.0
      vf_loss: 0.0363067165017128
    num_steps_sampled: 9180000
    num_steps_trained: 9180000
    wait_time_ms: 272.908
  iterations_since_restore: 459
  node_ip: 172.17.8.11
  num_metric_batches_dropped: 0
  pid: 25504
  policy_reward_mean: {}
  time_since_restore: 12923.78488612175
  time_this_iter_s: 27.70272445678711
  time_total_s: 12923.78488612175
  timestamp: 1593927206
  timesteps_since_restore: 9180000
  timesteps_this_iter: 20000
  timesteps_total: 9180000
  training_iteration: 459
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=25504], 12923 s, 459 iter, 9180000 ts, 360 rew

Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_01-33-53
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 615.0
  episode_reward_mean: 359.68
  episode_reward_min: 249.0
  episodes_this_iter: 0
  episodes_total: 459
  experiment_id: 35d66058da2d4c9882f832ee91e4aa4a
  hostname: gpu011
  info:
    apply_time_ms: 3.952
    dispatch_time_ms: 6.197
    learner:
      cur_lr: 0.0007486119866371155
      grad_gnorm: 18.241689682006836
      policy_entropy: 132.6654052734375
      policy_loss: -5.202767372131348
      var_gnorm: 20.052967071533203
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 3.3776187896728516
    num_steps_sampled: 9200000
    num_steps_trained: 9200000
    wait_time_ms: 269.584
  iterations_since_restore: 460
  node_ip: 172.17.8.11
  num_metric_batches_dropped: 0
  pid: 25504
  policy_reward_mean: {}
  time_since_restore: 12950.881247758865
  time_this_iter_s: 27.09636163711548
  time_total_s: 12950.881247758865
  timestamp: 1593927233
  timesteps_since_restore: 9200000
  timesteps_this_iter: 20000
  timesteps_total: 9200000
  training_iteration: 460
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=25504], 12950 s, 460 iter, 9200000 ts, 360 rew

agent-1: 21.0
agent-2: 24.0
agent-3: 21.0
agent-4: 20.0
agent-5: 20.0
agent-6: 26.0
agent-7: 9.0
agent-8: 19.0
agent-9: 26.0
agent-10: 20.0
agent-11: 29.0
agent-12: 17.0
agent-13: 17.0
agent-14: 19.0
agent-15: 25.0
agent-16: 38.0
agent-17: 20.0
agent-18: 19.0
agent-19: 20.0
agent-20: 18.0
Sum Reward: 428.0
Avg Reward: 21.4
Min Reward: 9.0
Gini Coefficient: 0.13130841121495326
20:20 Ratio: 1.9508196721311475
Max-min Ratio: 4.222222222222222
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_01-34-21
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 615.0
  episode_reward_mean: 360.54
  episode_reward_min: 249.0
  episodes_this_iter: 1
  episodes_total: 460
  experiment_id: 35d66058da2d4c9882f832ee91e4aa4a
  hostname: gpu011
  info:
    apply_time_ms: 3.206
    dispatch_time_ms: 8.835
    learner:
      cur_lr: 0.0007472800207324326
      grad_gnorm: 40.0
      policy_entropy: 132.22557067871094
      policy_loss: 93.68409729003906
      var_gnorm: 20.04034996032715
      vf_explained_var: 0.0
      vf_loss: 225.09552001953125
    num_steps_sampled: 9220000
    num_steps_trained: 9220000
    wait_time_ms: 259.936
  iterations_since_restore: 461
  node_ip: 172.17.8.11
  num_metric_batches_dropped: 0
  pid: 25504
  policy_reward_mean: {}
  time_since_restore: 12978.730520963669
  time_this_iter_s: 27.849273204803467
  time_total_s: 12978.730520963669
  timestamp: 1593927261
  timesteps_since_restore: 9220000
  timesteps_this_iter: 20000
  timesteps_total: 9220000
  training_iteration: 461
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=25504], 12978 s, 461 iter, 9220000 ts, 361 rew

agent-1: 11.0
agent-2: 20.0
agent-3: 17.0
agent-4: 8.0
agent-5: 4.0
agent-6: 25.0
agent-7: 14.0
agent-8: 19.0
agent-9: 2.0
agent-10: 17.0
agent-11: 26.0
agent-12: 17.0
agent-13: 20.0
agent-14: 26.0
agent-15: 8.0
agent-16: 21.0
agent-17: 14.0
agent-18: 15.0
agent-19: 17.0
agent-20: 19.0
Sum Reward: 320.0
Avg Reward: 16.0
Min Reward: 2.0
Gini Coefficient: 0.2284375
20:20 Ratio: 4.454545454545454
Max-min Ratio: 13.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_01-34-48
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 615.0
  episode_reward_mean: 360.9
  episode_reward_min: 249.0
  episodes_this_iter: 1
  episodes_total: 461
  experiment_id: 35d66058da2d4c9882f832ee91e4aa4a
  hostname: gpu011
  info:
    apply_time_ms: 2.963
    dispatch_time_ms: 6.949
    learner:
      cur_lr: 0.0007459479966200888
      grad_gnorm: 38.146060943603516
      policy_entropy: 142.13156127929688
      policy_loss: -8.85312557220459
      var_gnorm: 20.051082611083984
      vf_explained_var: 0.0
      vf_loss: 0.5770657062530518
    num_steps_sampled: 9240000
    num_steps_trained: 9240000
    wait_time_ms: 266.562
  iterations_since_restore: 462
  node_ip: 172.17.8.11
  num_metric_batches_dropped: 0
  pid: 25504
  policy_reward_mean: {}
  time_since_restore: 13005.776962518692
  time_this_iter_s: 27.046441555023193
  time_total_s: 13005.776962518692
  timestamp: 1593927288
  timesteps_since_restore: 9240000
  timesteps_this_iter: 20000
  timesteps_total: 9240000
  training_iteration: 462
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=25504], 13005 s, 462 iter, 9240000 ts, 361 rew

agent-1: 17.0
agent-2: 17.0
agent-3: 20.0
agent-4: 19.0
agent-5: 17.0
agent-6: 8.0
agent-7: 14.0
agent-8: 37.0
agent-9: 7.0
agent-10: 24.0
agent-11: 28.0
agent-12: 22.0
agent-13: 14.0
agent-14: 26.0
agent-15: 12.0
agent-16: 18.0
agent-17: 9.0
agent-18: 17.0
agent-19: 11.0
agent-20: 12.0
Sum Reward: 349.0
Avg Reward: 17.45
Min Reward: 7.0
Gini Coefficient: 0.22507163323782234
20:20 Ratio: 3.2857142857142856
Max-min Ratio: 5.285714285714286
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_01-35-16
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 615.0
  episode_reward_mean: 361.29
  episode_reward_min: 249.0
  episodes_this_iter: 1
  episodes_total: 462
  experiment_id: 35d66058da2d4c9882f832ee91e4aa4a
  hostname: gpu011
  info:
    apply_time_ms: 3.835
    dispatch_time_ms: 7.69
    learner:
      cur_lr: 0.000744615972507745
      grad_gnorm: 1.8012250661849976
      policy_entropy: 143.1044158935547
      policy_loss: -0.46399301290512085
      var_gnorm: 20.03010368347168
      vf_explained_var: 0.0
      vf_loss: 0.0010699492413550615
    num_steps_sampled: 9260000
    num_steps_trained: 9260000
    wait_time_ms: 268.544
  iterations_since_restore: 463
  node_ip: 172.17.8.11
  num_metric_batches_dropped: 0
  pid: 25504
  policy_reward_mean: {}
  time_since_restore: 13033.542802095413
  time_this_iter_s: 27.76583957672119
  time_total_s: 13033.542802095413
  timestamp: 1593927316
  timesteps_since_restore: 9260000
  timesteps_this_iter: 20000
  timesteps_total: 9260000
  training_iteration: 463
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=25504], 13033 s, 463 iter, 9260000 ts, 361 rew

agent-1: 6.0
agent-2: 13.0
agent-3: 10.0
agent-4: 24.0
agent-5: 25.0
agent-6: 19.0
agent-7: 11.0
agent-8: 12.0
agent-9: 7.0
agent-10: 16.0
agent-11: 19.0
agent-12: 10.0
agent-13: 29.0
agent-14: 18.0
agent-15: 9.0
agent-16: 33.0
agent-17: 30.0
agent-18: 17.0
agent-19: 18.0
agent-20: 19.0
Sum Reward: 345.0
Avg Reward: 17.25
Min Reward: 6.0
Gini Coefficient: 0.24797101449275363
20:20 Ratio: 3.65625
Max-min Ratio: 5.5
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_01-35-43
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 615.0
  episode_reward_mean: 361.07
  episode_reward_min: 249.0
  episodes_this_iter: 1
  episodes_total: 463
  experiment_id: 35d66058da2d4c9882f832ee91e4aa4a
  hostname: gpu011
  info:
    apply_time_ms: 2.758
    dispatch_time_ms: 6.364
    learner:
      cur_lr: 0.0007432840066030622
      grad_gnorm: 35.46866989135742
      policy_entropy: 130.81646728515625
      policy_loss: -8.630135536193848
      var_gnorm: 20.044998168945312
      vf_explained_var: 0.0
      vf_loss: 0.5082976818084717
    num_steps_sampled: 9280000
    num_steps_trained: 9280000
    wait_time_ms: 262.562
  iterations_since_restore: 464
  node_ip: 172.17.8.11
  num_metric_batches_dropped: 0
  pid: 25504
  policy_reward_mean: {}
  time_since_restore: 13060.58308506012
  time_this_iter_s: 27.04028296470642
  time_total_s: 13060.58308506012
  timestamp: 1593927343
  timesteps_since_restore: 9280000
  timesteps_this_iter: 20000
  timesteps_total: 9280000
  training_iteration: 464
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=25504], 13060 s, 464 iter, 9280000 ts, 361 rew

agent-1: 27.0
agent-2: 20.0
agent-3: 11.0
agent-4: 11.0
agent-5: 28.0
agent-6: 39.0
agent-7: 20.0
agent-8: 13.0
agent-9: 12.0
agent-10: 26.0
agent-11: 22.0
agent-12: -25.0
agent-13: 27.0
agent-14: 8.0
agent-15: 23.0
agent-16: 21.0
agent-17: 19.0
agent-18: 18.0
agent-19: 32.0
agent-20: 19.0
Sum Reward: 371.0
Avg Reward: 18.55
Min Reward: -25.0
Gini Coefficient: 0.32681940700808626
20:20 Ratio: 25.2
Max-min Ratio: -1.56
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_01-36-11
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 615.0
  episode_reward_mean: 360.43
  episode_reward_min: 249.0
  episodes_this_iter: 1
  episodes_total: 464
  experiment_id: 35d66058da2d4c9882f832ee91e4aa4a
  hostname: gpu011
  info:
    apply_time_ms: 3.191
    dispatch_time_ms: 7.949
    learner:
      cur_lr: 0.0007419519824907184
      grad_gnorm: 24.078577041625977
      policy_entropy: 123.927734375
      policy_loss: -5.908816337585449
      var_gnorm: 20.041046142578125
      vf_explained_var: 1.7881393432617188e-07
      vf_loss: 0.23421815037727356
    num_steps_sampled: 9300000
    num_steps_trained: 9300000
    wait_time_ms: 267.743
  iterations_since_restore: 465
  node_ip: 172.17.8.11
  num_metric_batches_dropped: 0
  pid: 25504
  policy_reward_mean: {}
  time_since_restore: 13088.427377939224
  time_this_iter_s: 27.844292879104614
  time_total_s: 13088.427377939224
  timestamp: 1593927371
  timesteps_since_restore: 9300000
  timesteps_this_iter: 20000
  timesteps_total: 9300000
  training_iteration: 465
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=25504], 13088 s, 465 iter, 9300000 ts, 360 rew

agent-1: 33.0
agent-2: 15.0
agent-3: 13.0
agent-4: 16.0
agent-5: 25.0
agent-6: 23.0
agent-7: 28.0
agent-8: 23.0
agent-9: 26.0
agent-10: 7.0
agent-11: 14.0
agent-12: 15.0
agent-13: 23.0
agent-14: 33.0
agent-15: 20.0
agent-16: 21.0
agent-17: 26.0
agent-18: 24.0
agent-19: 19.0
agent-20: 15.0
Sum Reward: 419.0
Avg Reward: 20.95
Min Reward: 7.0
Gini Coefficient: 0.17720763723150357
20:20 Ratio: 2.4489795918367347
Max-min Ratio: 4.714285714285714
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_01-36-37
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 615.0
  episode_reward_mean: 359.3
  episode_reward_min: 249.0
  episodes_this_iter: 1
  episodes_total: 465
  experiment_id: 35d66058da2d4c9882f832ee91e4aa4a
  hostname: gpu011
  info:
    apply_time_ms: 3.227
    dispatch_time_ms: 9.486
    learner:
      cur_lr: 0.0007406200165860355
      grad_gnorm: 40.0
      policy_entropy: 135.6367645263672
      policy_loss: -11.921239852905273
      var_gnorm: 20.050159454345703
      vf_explained_var: 0.0
      vf_loss: 4.354578018188477
    num_steps_sampled: 9320000
    num_steps_trained: 9320000
    wait_time_ms: 263.328
  iterations_since_restore: 466
  node_ip: 172.17.8.11
  num_metric_batches_dropped: 0
  pid: 25504
  policy_reward_mean: {}
  time_since_restore: 13114.844612121582
  time_this_iter_s: 26.417234182357788
  time_total_s: 13114.844612121582
  timestamp: 1593927397
  timesteps_since_restore: 9320000
  timesteps_this_iter: 20000
  timesteps_total: 9320000
  training_iteration: 466
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=25504], 13114 s, 466 iter, 9320000 ts, 359 rew

agent-1: 22.0
agent-2: 34.0
agent-3: 23.0
agent-4: 32.0
agent-5: 25.0
agent-6: 40.0
agent-7: 35.0
agent-8: 26.0
agent-9: 21.0
agent-10: 29.0
agent-11: 48.0
agent-12: 43.0
agent-13: 29.0
agent-14: 26.0
agent-15: 41.0
agent-16: 23.0
agent-17: 23.0
agent-18: 28.0
agent-19: 23.0
agent-20: 7.0
Sum Reward: 578.0
Avg Reward: 28.9
Min Reward: 7.0
Gini Coefficient: 0.17162629757785466
20:20 Ratio: 2.356164383561644
Max-min Ratio: 6.857142857142857
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_01-37-27
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 615.0
  episode_reward_mean: 360.75
  episode_reward_min: 249.0
  episodes_this_iter: 1
  episodes_total: 466
  experiment_id: 35d66058da2d4c9882f832ee91e4aa4a
  hostname: gpu011
  info:
    apply_time_ms: 2.793
    dispatch_time_ms: 7.088
    learner:
      cur_lr: 0.0007392879924736917
      grad_gnorm: 39.999996185302734
      policy_entropy: 153.7613067626953
      policy_loss: 62.95990753173828
      var_gnorm: 20.032773971557617
      vf_explained_var: 0.0
      vf_loss: 154.82632446289062
    num_steps_sampled: 9340000
    num_steps_trained: 9340000
    wait_time_ms: 251.334
  iterations_since_restore: 467
  node_ip: 172.17.8.11
  num_metric_batches_dropped: 0
  pid: 25504
  policy_reward_mean: {}
  time_since_restore: 13165.04799413681
  time_this_iter_s: 50.20338201522827
  time_total_s: 13165.04799413681
  timestamp: 1593927447
  timesteps_since_restore: 9340000
  timesteps_this_iter: 20000
  timesteps_total: 9340000
  training_iteration: 467
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=25504], 13165 s, 467 iter, 9340000 ts, 361 rew

agent-1: 4.0
agent-2: 20.0
agent-3: 16.0
agent-4: 5.0
agent-5: 20.0
agent-6: 15.0
agent-7: 10.0
agent-8: 21.0
agent-9: 31.0
agent-10: 33.0
agent-11: 14.0
agent-12: 28.0
agent-13: 15.0
agent-14: 41.0
agent-15: 16.0
agent-16: 21.0
agent-17: 31.0
agent-18: 14.0
agent-19: 18.0
agent-20: 33.0
Sum Reward: 406.0
Avg Reward: 20.3
Min Reward: 4.0
Gini Coefficient: 0.2623152709359606
20:20 Ratio: 4.181818181818182
Max-min Ratio: 10.25
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_01-37-58
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 615.0
  episode_reward_mean: 359.19
  episode_reward_min: 249.0
  episodes_this_iter: 1
  episodes_total: 467
  experiment_id: 35d66058da2d4c9882f832ee91e4aa4a
  hostname: gpu011
  info:
    apply_time_ms: 3.906
    dispatch_time_ms: 46.643
    learner:
      cur_lr: 0.0007379560265690088
      grad_gnorm: 40.0
      policy_entropy: 141.54925537109375
      policy_loss: 14.032170295715332
      var_gnorm: 20.04010772705078
      vf_explained_var: 5.960464477539063e-08
      vf_loss: 23.641277313232422
    num_steps_sampled: 9360000
    num_steps_trained: 9360000
    wait_time_ms: 238.616
  iterations_since_restore: 468
  node_ip: 172.17.8.11
  num_metric_batches_dropped: 0
  pid: 25504
  policy_reward_mean: {}
  time_since_restore: 13196.03983926773
  time_this_iter_s: 30.99184513092041
  time_total_s: 13196.03983926773
  timestamp: 1593927478
  timesteps_since_restore: 9360000
  timesteps_this_iter: 20000
  timesteps_total: 9360000
  training_iteration: 468
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=25504], 13196 s, 468 iter, 9360000 ts, 359 rew

agent-1: 26.0
agent-2: 14.0
agent-3: 25.0
agent-4: 12.0
agent-5: 14.0
agent-6: 18.0
agent-7: 19.0
agent-8: 15.0
agent-9: 36.0
agent-10: 29.0
agent-11: 28.0
agent-12: 21.0
agent-13: 23.0
agent-14: 17.0
agent-15: 44.0
agent-16: 33.0
agent-17: 12.0
agent-18: 25.0
agent-19: 25.0
agent-20: 28.0
Sum Reward: 464.0
Avg Reward: 23.2
Min Reward: 12.0
Gini Coefficient: 0.1980603448275862
20:20 Ratio: 2.730769230769231
Max-min Ratio: 3.6666666666666665
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_01-38-28
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 615.0
  episode_reward_mean: 359.24
  episode_reward_min: 249.0
  episodes_this_iter: 1
  episodes_total: 468
  experiment_id: 35d66058da2d4c9882f832ee91e4aa4a
  hostname: gpu011
  info:
    apply_time_ms: 2.739
    dispatch_time_ms: 50.771
    learner:
      cur_lr: 0.000736624002456665
      grad_gnorm: 8.784564971923828
      policy_entropy: 147.69271850585938
      policy_loss: -2.7759833335876465
      var_gnorm: 20.015151977539062
      vf_explained_var: 0.0
      vf_loss: 0.031066477298736572
    num_steps_sampled: 9380000
    num_steps_trained: 9380000
    wait_time_ms: 225.391
  iterations_since_restore: 469
  node_ip: 172.17.8.11
  num_metric_batches_dropped: 0
  pid: 25504
  policy_reward_mean: {}
  time_since_restore: 13225.463241577148
  time_this_iter_s: 29.423402309417725
  time_total_s: 13225.463241577148
  timestamp: 1593927508
  timesteps_since_restore: 9380000
  timesteps_this_iter: 20000
  timesteps_total: 9380000
  training_iteration: 469
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=25504], 13225 s, 469 iter, 9380000 ts, 359 rew

agent-1: 21.0
agent-2: 7.0
agent-3: 34.0
agent-4: 15.0
agent-5: 20.0
agent-6: 13.0
agent-7: 13.0
agent-8: 22.0
agent-9: 15.0
agent-10: 14.0
agent-11: 21.0
agent-12: 13.0
agent-13: 32.0
agent-14: 42.0
agent-15: 13.0
agent-16: 39.0
agent-17: 4.0
agent-18: 15.0
agent-19: 32.0
agent-20: 19.0
Sum Reward: 404.0
Avg Reward: 20.2
Min Reward: 4.0
Gini Coefficient: 0.2742574257425743
20:20 Ratio: 3.972972972972973
Max-min Ratio: 10.5
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_01-38-56
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 615.0
  episode_reward_mean: 360.03
  episode_reward_min: 249.0
  episodes_this_iter: 1
  episodes_total: 469
  experiment_id: 35d66058da2d4c9882f832ee91e4aa4a
  hostname: gpu011
  info:
    apply_time_ms: 2.861
    dispatch_time_ms: 91.569
    learner:
      cur_lr: 0.0007352919783443213
      grad_gnorm: 26.209901809692383
      policy_entropy: 122.67182922363281
      policy_loss: -9.525430679321289
      var_gnorm: 20.034862518310547
      vf_explained_var: 0.0
      vf_loss: 3.3234903812408447
    num_steps_sampled: 9400000
    num_steps_trained: 9400000
    wait_time_ms: 211.509
  iterations_since_restore: 470
  node_ip: 172.17.8.11
  num_metric_batches_dropped: 0
  pid: 25504
  policy_reward_mean: {}
  time_since_restore: 13253.635106563568
  time_this_iter_s: 28.171864986419678
  time_total_s: 13253.635106563568
  timestamp: 1593927536
  timesteps_since_restore: 9400000
  timesteps_this_iter: 20000
  timesteps_total: 9400000
  training_iteration: 470
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=25504], 13253 s, 470 iter, 9400000 ts, 360 rew

agent-1: 14.0
agent-2: 17.0
agent-3: 14.0
agent-4: 13.0
agent-5: 23.0
agent-6: 11.0
agent-7: 22.0
agent-8: 19.0
agent-9: 15.0
agent-10: 24.0
agent-11: 28.0
agent-12: 25.0
agent-13: 14.0
agent-14: 11.0
agent-15: 7.0
agent-16: 23.0
agent-17: 12.0
agent-18: 12.0
agent-19: 26.0
agent-20: 13.0
Sum Reward: 343.0
Avg Reward: 17.15
Min Reward: 7.0
Gini Coefficient: 0.19373177842565598
20:20 Ratio: 2.5121951219512195
Max-min Ratio: 4.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_01-39-25
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 615.0
  episode_reward_mean: 360.14
  episode_reward_min: 249.0
  episodes_this_iter: 1
  episodes_total: 470
  experiment_id: 35d66058da2d4c9882f832ee91e4aa4a
  hostname: gpu011
  info:
    apply_time_ms: 3.948
    dispatch_time_ms: 78.69
    learner:
      cur_lr: 0.0007339600124396384
      grad_gnorm: 40.0
      policy_entropy: 133.0673370361328
      policy_loss: 71.19986724853516
      var_gnorm: 20.254209518432617
      vf_explained_var: 1.1920928955078125e-07
      vf_loss: 123.21660614013672
    num_steps_sampled: 9420000
    num_steps_trained: 9420000
    wait_time_ms: 165.491
  iterations_since_restore: 471
  node_ip: 172.17.8.11
  num_metric_batches_dropped: 0
  pid: 25504
  policy_reward_mean: {}
  time_since_restore: 13282.899935483932
  time_this_iter_s: 29.26482892036438
  time_total_s: 13282.899935483932
  timestamp: 1593927565
  timesteps_since_restore: 9420000
  timesteps_this_iter: 20000
  timesteps_total: 9420000
  training_iteration: 471
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=25504], 13282 s, 471 iter, 9420000 ts, 360 rew

agent-1: 45.0
agent-2: 11.0
agent-3: 33.0
agent-4: 21.0
agent-5: 27.0
agent-6: 23.0
agent-7: 34.0
agent-8: 27.0
agent-9: 18.0
agent-10: 25.0
agent-11: 22.0
agent-12: 42.0
agent-13: 8.0
agent-14: 16.0
agent-15: 26.0
agent-16: 8.0
agent-17: 21.0
agent-18: 9.0
agent-19: 17.0
agent-20: 14.0
Sum Reward: 447.0
Avg Reward: 22.35
Min Reward: 8.0
Gini Coefficient: 0.25604026845637584
20:20 Ratio: 4.277777777777778
Max-min Ratio: 5.625
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_01-39-54
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 615.0
  episode_reward_mean: 361.21
  episode_reward_min: 249.0
  episodes_this_iter: 1
  episodes_total: 471
  experiment_id: 35d66058da2d4c9882f832ee91e4aa4a
  hostname: gpu011
  info:
    apply_time_ms: 3.697
    dispatch_time_ms: 75.316
    learner:
      cur_lr: 0.0007326279883272946
      grad_gnorm: 40.0
      policy_entropy: 172.09423828125
      policy_loss: -15.243274688720703
      var_gnorm: 20.29039192199707
      vf_explained_var: -2.384185791015625e-07
      vf_loss: 1.5684046745300293
    num_steps_sampled: 9440000
    num_steps_trained: 9440000
    wait_time_ms: 186.279
  iterations_since_restore: 472
  node_ip: 172.17.8.11
  num_metric_batches_dropped: 0
  pid: 25504
  policy_reward_mean: {}
  time_since_restore: 13311.105571985245
  time_this_iter_s: 28.205636501312256
  time_total_s: 13311.105571985245
  timestamp: 1593927594
  timesteps_since_restore: 9440000
  timesteps_this_iter: 20000
  timesteps_total: 9440000
  training_iteration: 472
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=25504], 13311 s, 472 iter, 9440000 ts, 361 rew

agent-1: 24.0
agent-2: 11.0
agent-3: 12.0
agent-4: 13.0
agent-5: 16.0
agent-6: 17.0
agent-7: 29.0
agent-8: 21.0
agent-9: 23.0
agent-10: 27.0
agent-11: 22.0
agent-12: 22.0
agent-13: 5.0
agent-14: 22.0
agent-15: 18.0
agent-16: 13.0
agent-17: 11.0
agent-18: 12.0
agent-19: 6.0
agent-20: 11.0
Sum Reward: 335.0
Avg Reward: 16.75
Min Reward: 5.0
Gini Coefficient: 0.22402985074626866
20:20 Ratio: 3.121212121212121
Max-min Ratio: 5.8
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_01-40-22
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 615.0
  episode_reward_mean: 360.95
  episode_reward_min: 249.0
  episodes_this_iter: 1
  episodes_total: 472
  experiment_id: 35d66058da2d4c9882f832ee91e4aa4a
  hostname: gpu011
  info:
    apply_time_ms: 2.618
    dispatch_time_ms: 6.503
    learner:
      cur_lr: 0.0007312960224226117
      grad_gnorm: 40.0
      policy_entropy: 177.7740478515625
      policy_loss: 76.3131103515625
      var_gnorm: 20.28722381591797
      vf_explained_var: 5.960464477539063e-08
      vf_loss: 106.68827819824219
    num_steps_sampled: 9460000
    num_steps_trained: 9460000
    wait_time_ms: 240.308
  iterations_since_restore: 473
  node_ip: 172.17.8.11
  num_metric_batches_dropped: 0
  pid: 25504
  policy_reward_mean: {}
  time_since_restore: 13338.986164808273
  time_this_iter_s: 27.880592823028564
  time_total_s: 13338.986164808273
  timestamp: 1593927622
  timesteps_since_restore: 9460000
  timesteps_this_iter: 20000
  timesteps_total: 9460000
  training_iteration: 473
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=25504], 13338 s, 473 iter, 9460000 ts, 361 rew

agent-1: 13.0
agent-2: 32.0
agent-3: 30.0
agent-4: 9.0
agent-5: 30.0
agent-6: 8.0
agent-7: 11.0
agent-8: 25.0
agent-9: 23.0
agent-10: 22.0
agent-11: 20.0
agent-12: 6.0
agent-13: 36.0
agent-14: 19.0
agent-15: 22.0
agent-16: 31.0
agent-17: 17.0
agent-18: 33.0
agent-19: 15.0
agent-20: 6.0
Sum Reward: 408.0
Avg Reward: 20.4
Min Reward: 6.0
Gini Coefficient: 0.26323529411764707
20:20 Ratio: 4.551724137931035
Max-min Ratio: 6.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_01-40-49
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 615.0
  episode_reward_mean: 360.35
  episode_reward_min: 249.0
  episodes_this_iter: 1
  episodes_total: 473
  experiment_id: 35d66058da2d4c9882f832ee91e4aa4a
  hostname: gpu011
  info:
    apply_time_ms: 3.151
    dispatch_time_ms: 6.715
    learner:
      cur_lr: 0.0007299639983102679
      grad_gnorm: 29.12921142578125
      policy_entropy: 138.8429412841797
      policy_loss: -6.720261573791504
      var_gnorm: 20.288875579833984
      vf_explained_var: 1.7881393432617188e-07
      vf_loss: 0.3272324204444885
    num_steps_sampled: 9480000
    num_steps_trained: 9480000
    wait_time_ms: 263.491
  iterations_since_restore: 474
  node_ip: 172.17.8.11
  num_metric_batches_dropped: 0
  pid: 25504
  policy_reward_mean: {}
  time_since_restore: 13366.192103147507
  time_this_iter_s: 27.2059383392334
  time_total_s: 13366.192103147507
  timestamp: 1593927649
  timesteps_since_restore: 9480000
  timesteps_this_iter: 20000
  timesteps_total: 9480000
  training_iteration: 474
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=25504], 13366 s, 474 iter, 9480000 ts, 360 rew

agent-1: 9.0
agent-2: 13.0
agent-3: 5.0
agent-4: 18.0
agent-5: 6.0
agent-6: 15.0
agent-7: 12.0
agent-8: 3.0
agent-9: 8.0
agent-10: 13.0
agent-11: 9.0
agent-12: 9.0
agent-13: 29.0
agent-14: 18.0
agent-15: 21.0
agent-16: 31.0
agent-17: 16.0
agent-18: 18.0
agent-19: 13.0
agent-20: 22.0
Sum Reward: 288.0
Avg Reward: 14.4
Min Reward: 3.0
Gini Coefficient: 0.2809027777777778
20:20 Ratio: 4.681818181818182
Max-min Ratio: 10.333333333333334
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_01-41-17
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 615.0
  episode_reward_mean: 359.59
  episode_reward_min: 249.0
  episodes_this_iter: 1
  episodes_total: 474
  experiment_id: 35d66058da2d4c9882f832ee91e4aa4a
  hostname: gpu011
  info:
    apply_time_ms: 2.786
    dispatch_time_ms: 5.697
    learner:
      cur_lr: 0.0007286319741979241
      grad_gnorm: 40.0
      policy_entropy: 163.02720642089844
      policy_loss: 77.96585083007812
      var_gnorm: 20.299402236938477
      vf_explained_var: 0.0
      vf_loss: 90.93655395507812
    num_steps_sampled: 9500000
    num_steps_trained: 9500000
    wait_time_ms: 259.78
  iterations_since_restore: 475
  node_ip: 172.17.8.11
  num_metric_batches_dropped: 0
  pid: 25504
  policy_reward_mean: {}
  time_since_restore: 13394.199690818787
  time_this_iter_s: 28.007587671279907
  time_total_s: 13394.199690818787
  timestamp: 1593927677
  timesteps_since_restore: 9500000
  timesteps_this_iter: 20000
  timesteps_total: 9500000
  training_iteration: 475
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=25504], 13394 s, 475 iter, 9500000 ts, 360 rew

agent-1: 13.0
agent-2: 14.0
agent-3: 19.0
agent-4: 21.0
agent-5: 23.0
agent-6: 24.0
agent-7: 14.0
agent-8: 16.0
agent-9: 12.0
agent-10: 37.0
agent-11: 30.0
agent-12: 13.0
agent-13: 29.0
agent-14: 20.0
agent-15: 15.0
agent-16: 13.0
agent-17: 13.0
agent-18: 17.0
agent-19: 15.0
agent-20: 12.0
Sum Reward: 370.0
Avg Reward: 18.5
Min Reward: 12.0
Gini Coefficient: 0.1918918918918919
20:20 Ratio: 2.4
Max-min Ratio: 3.0833333333333335
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_01-41-44
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 615.0
  episode_reward_mean: 360.07
  episode_reward_min: 249.0
  episodes_this_iter: 1
  episodes_total: 475
  experiment_id: 35d66058da2d4c9882f832ee91e4aa4a
  hostname: gpu011
  info:
    apply_time_ms: 2.59
    dispatch_time_ms: 6.563
    learner:
      cur_lr: 0.0007273000082932413
      grad_gnorm: 32.230045318603516
      policy_entropy: 160.35386657714844
      policy_loss: -9.498461723327637
      var_gnorm: 20.30051612854004
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 0.40453192591667175
    num_steps_sampled: 9520000
    num_steps_trained: 9520000
    wait_time_ms: 268.342
  iterations_since_restore: 476
  node_ip: 172.17.8.11
  num_metric_batches_dropped: 0
  pid: 25504
  policy_reward_mean: {}
  time_since_restore: 13421.30799627304
  time_this_iter_s: 27.10830545425415
  time_total_s: 13421.30799627304
  timestamp: 1593927704
  timesteps_since_restore: 9520000
  timesteps_this_iter: 20000
  timesteps_total: 9520000
  training_iteration: 476
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=25504], 13421 s, 476 iter, 9520000 ts, 360 rew

agent-1: 10.0
agent-2: 11.0
agent-3: 16.0
agent-4: 21.0
agent-5: 14.0
agent-6: 17.0
agent-7: 5.0
agent-8: 13.0
agent-9: 10.0
agent-10: 12.0
agent-11: 26.0
agent-12: 33.0
agent-13: 15.0
agent-14: 2.0
agent-15: 12.0
agent-16: 16.0
agent-17: 35.0
agent-18: 3.0
agent-19: 8.0
agent-20: 24.0
Sum Reward: 303.0
Avg Reward: 15.15
Min Reward: 2.0
Gini Coefficient: 0.31501650165016504
20:20 Ratio: 6.555555555555555
Max-min Ratio: 17.5
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_01-42-12
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 615.0
  episode_reward_mean: 359.81
  episode_reward_min: 249.0
  episodes_this_iter: 1
  episodes_total: 476
  experiment_id: 35d66058da2d4c9882f832ee91e4aa4a
  hostname: gpu011
  info:
    apply_time_ms: 2.785
    dispatch_time_ms: 8.409
    learner:
      cur_lr: 0.0007259679841808975
      grad_gnorm: 40.0
      policy_entropy: 160.37191772460938
      policy_loss: 114.22889709472656
      var_gnorm: 20.299388885498047
      vf_explained_var: 0.0
      vf_loss: 158.45201110839844
    num_steps_sampled: 9540000
    num_steps_trained: 9540000
    wait_time_ms: 245.408
  iterations_since_restore: 477
  node_ip: 172.17.8.11
  num_metric_batches_dropped: 0
  pid: 25504
  policy_reward_mean: {}
  time_since_restore: 13449.328120470047
  time_this_iter_s: 28.020124197006226
  time_total_s: 13449.328120470047
  timestamp: 1593927732
  timesteps_since_restore: 9540000
  timesteps_this_iter: 20000
  timesteps_total: 9540000
  training_iteration: 477
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=25504], 13449 s, 477 iter, 9540000 ts, 360 rew

agent-1: 12.0
agent-2: 13.0
agent-3: 9.0
agent-4: 11.0
agent-5: 17.0
agent-6: 13.0
agent-7: 18.0
agent-8: 6.0
agent-9: 32.0
agent-10: 20.0
agent-11: 20.0
agent-12: 15.0
agent-13: 17.0
agent-14: 26.0
agent-15: 15.0
agent-16: 29.0
agent-17: 20.0
agent-18: 28.0
agent-19: 24.0
agent-20: 24.0
Sum Reward: 369.0
Avg Reward: 18.45
Min Reward: 6.0
Gini Coefficient: 0.21151761517615175
20:20 Ratio: 3.026315789473684
Max-min Ratio: 5.333333333333333
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_01-42-39
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 615.0
  episode_reward_mean: 359.28
  episode_reward_min: 249.0
  episodes_this_iter: 1
  episodes_total: 477
  experiment_id: 35d66058da2d4c9882f832ee91e4aa4a
  hostname: gpu011
  info:
    apply_time_ms: 3.299
    dispatch_time_ms: 7.239
    learner:
      cur_lr: 0.0007246360182762146
      grad_gnorm: 9.606261253356934
      policy_entropy: 144.52268981933594
      policy_loss: -2.3439247608184814
      var_gnorm: 20.29986572265625
      vf_explained_var: 0.0
      vf_loss: 1.440769910812378
    num_steps_sampled: 9560000
    num_steps_trained: 9560000
    wait_time_ms: 269.777
  iterations_since_restore: 478
  node_ip: 172.17.8.11
  num_metric_batches_dropped: 0
  pid: 25504
  policy_reward_mean: {}
  time_since_restore: 13476.620565652847
  time_this_iter_s: 27.292445182800293
  time_total_s: 13476.620565652847
  timestamp: 1593927759
  timesteps_since_restore: 9560000
  timesteps_this_iter: 20000
  timesteps_total: 9560000
  training_iteration: 478
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=25504], 13476 s, 478 iter, 9560000 ts, 359 rew

agent-1: 9.0
agent-2: 11.0
agent-3: 16.0
agent-4: 6.0
agent-5: 13.0
agent-6: 18.0
agent-7: 6.0
agent-8: 6.0
agent-9: 8.0
agent-10: 6.0
agent-11: 21.0
agent-12: 10.0
agent-13: 14.0
agent-14: 21.0
agent-15: 7.0
agent-16: 26.0
agent-17: 12.0
agent-18: 13.0
agent-19: 10.0
agent-20: 12.0
Sum Reward: 245.0
Avg Reward: 12.25
Min Reward: 6.0
Gini Coefficient: 0.24877551020408165
20:20 Ratio: 3.5833333333333335
Max-min Ratio: 4.333333333333333
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_01-43-11
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 615.0
  episode_reward_mean: 358.78
  episode_reward_min: 245.0
  episodes_this_iter: 1
  episodes_total: 478
  experiment_id: 35d66058da2d4c9882f832ee91e4aa4a
  hostname: gpu011
  info:
    apply_time_ms: 2.891
    dispatch_time_ms: 6.288
    learner:
      cur_lr: 0.0007233039941638708
      grad_gnorm: 1.5036439895629883
      policy_entropy: 151.12396240234375
      policy_loss: -0.28959527611732483
      var_gnorm: 20.29945182800293
      vf_explained_var: 0.0
      vf_loss: 0.0008315188460983336
    num_steps_sampled: 9580000
    num_steps_trained: 9580000
    wait_time_ms: 274.703
  iterations_since_restore: 479
  node_ip: 172.17.8.11
  num_metric_batches_dropped: 0
  pid: 25504
  policy_reward_mean: {}
  time_since_restore: 13508.063503742218
  time_this_iter_s: 31.442938089370728
  time_total_s: 13508.063503742218
  timestamp: 1593927791
  timesteps_since_restore: 9580000
  timesteps_this_iter: 20000
  timesteps_total: 9580000
  training_iteration: 479
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=25504], 13508 s, 479 iter, 9580000 ts, 359 rew

agent-1: 16.0
agent-2: 8.0
agent-3: 10.0
agent-4: 21.0
agent-5: 10.0
agent-6: 11.0
agent-7: 26.0
agent-8: 11.0
agent-9: 21.0
agent-10: 13.0
agent-11: 15.0
agent-12: 20.0
agent-13: 23.0
agent-14: 14.0
agent-15: 20.0
agent-16: 18.0
agent-17: 13.0
agent-18: 11.0
agent-19: 13.0
agent-20: 8.0
Sum Reward: 302.0
Avg Reward: 15.1
Min Reward: 8.0
Gini Coefficient: 0.1913907284768212
20:20 Ratio: 2.5277777777777777
Max-min Ratio: 3.25
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_01-43-38
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 615.0
  episode_reward_mean: 358.21
  episode_reward_min: 245.0
  episodes_this_iter: 1
  episodes_total: 479
  experiment_id: 35d66058da2d4c9882f832ee91e4aa4a
  hostname: gpu011
  info:
    apply_time_ms: 2.576
    dispatch_time_ms: 8.352
    learner:
      cur_lr: 0.0007219720282591879
      grad_gnorm: 32.08095169067383
      policy_entropy: 144.0023651123047
      policy_loss: -8.391483306884766
      var_gnorm: 20.30211639404297
      vf_explained_var: 5.960464477539063e-08
      vf_loss: 0.4014911949634552
    num_steps_sampled: 9600000
    num_steps_trained: 9600000
    wait_time_ms: 270.446
  iterations_since_restore: 480
  node_ip: 172.17.8.11
  num_metric_batches_dropped: 0
  pid: 25504
  policy_reward_mean: {}
  time_since_restore: 13535.142719745636
  time_this_iter_s: 27.07921600341797
  time_total_s: 13535.142719745636
  timestamp: 1593927818
  timesteps_since_restore: 9600000
  timesteps_this_iter: 20000
  timesteps_total: 9600000
  training_iteration: 480
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=25504], 13535 s, 480 iter, 9600000 ts, 358 rew

agent-1: 17.0
agent-2: 12.0
agent-3: 21.0
agent-4: 23.0
agent-5: 15.0
agent-6: 21.0
agent-7: 17.0
agent-8: 2.0
agent-9: 22.0
agent-10: 27.0
agent-11: 12.0
agent-12: 16.0
agent-13: 12.0
agent-14: 4.0
agent-15: 18.0
agent-16: 23.0
agent-17: 19.0
agent-18: 17.0
agent-19: 17.0
agent-20: 14.0
Sum Reward: 329.0
Avg Reward: 16.45
Min Reward: 2.0
Gini Coefficient: 0.19650455927051672
20:20 Ratio: 3.1666666666666665
Max-min Ratio: 13.5
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_01-44-06
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 615.0
  episode_reward_mean: 358.07
  episode_reward_min: 245.0
  episodes_this_iter: 1
  episodes_total: 480
  experiment_id: 35d66058da2d4c9882f832ee91e4aa4a
  hostname: gpu011
  info:
    apply_time_ms: 3.528
    dispatch_time_ms: 7.807
    learner:
      cur_lr: 0.0007206400041468441
      grad_gnorm: 1.7502204179763794
      policy_entropy: 131.5811004638672
      policy_loss: -0.4019712805747986
      var_gnorm: 20.301313400268555
      vf_explained_var: 0.0
      vf_loss: 0.0011872872710227966
    num_steps_sampled: 9620000
    num_steps_trained: 9620000
    wait_time_ms: 273.695
  iterations_since_restore: 481
  node_ip: 172.17.8.11
  num_metric_batches_dropped: 0
  pid: 25504
  policy_reward_mean: {}
  time_since_restore: 13563.139420986176
  time_this_iter_s: 27.99670124053955
  time_total_s: 13563.139420986176
  timestamp: 1593927846
  timesteps_since_restore: 9620000
  timesteps_this_iter: 20000
  timesteps_total: 9620000
  training_iteration: 481
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=25504], 13563 s, 481 iter, 9620000 ts, 358 rew

agent-1: 15.0
agent-2: 18.0
agent-3: 24.0
agent-4: 8.0
agent-5: 7.0
agent-6: 17.0
agent-7: 39.0
agent-8: 5.0
agent-9: 5.0
agent-10: 28.0
agent-11: 11.0
agent-12: 16.0
agent-13: 7.0
agent-14: 27.0
agent-15: 21.0
agent-16: 17.0
agent-17: 13.0
agent-18: 4.0
agent-19: 15.0
agent-20: 19.0
Sum Reward: 316.0
Avg Reward: 15.8
Min Reward: 4.0
Gini Coefficient: 0.30632911392405066
20:20 Ratio: 5.619047619047619
Max-min Ratio: 9.75
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_01-44-33
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 615.0
  episode_reward_mean: 358.06
  episode_reward_min: 245.0
  episodes_this_iter: 1
  episodes_total: 481
  experiment_id: 35d66058da2d4c9882f832ee91e4aa4a
  hostname: gpu011
  info:
    apply_time_ms: 2.748
    dispatch_time_ms: 6.073
    learner:
      cur_lr: 0.0007193079800345004
      grad_gnorm: 39.732757568359375
      policy_entropy: 175.4904327392578
      policy_loss: -12.390483856201172
      var_gnorm: 20.3031005859375
      vf_explained_var: 0.0
      vf_loss: 2.393007755279541
    num_steps_sampled: 9640000
    num_steps_trained: 9640000
    wait_time_ms: 270.351
  iterations_since_restore: 482
  node_ip: 172.17.8.11
  num_metric_batches_dropped: 0
  pid: 25504
  policy_reward_mean: {}
  time_since_restore: 13590.157494783401
  time_this_iter_s: 27.018073797225952
  time_total_s: 13590.157494783401
  timestamp: 1593927873
  timesteps_since_restore: 9640000
  timesteps_this_iter: 20000
  timesteps_total: 9640000
  training_iteration: 482
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=25504], 13590 s, 482 iter, 9640000 ts, 358 rew

agent-1: 21.0
agent-2: 30.0
agent-3: 11.0
agent-4: 31.0
agent-5: 31.0
agent-6: 9.0
agent-7: 16.0
agent-8: 23.0
agent-9: 23.0
agent-10: 24.0
agent-11: 14.0
agent-12: 12.0
agent-13: 21.0
agent-14: 26.0
agent-15: 25.0
agent-16: 9.0
agent-17: 12.0
agent-18: 27.0
agent-19: 19.0
agent-20: 26.0
Sum Reward: 410.0
Avg Reward: 20.5
Min Reward: 9.0
Gini Coefficient: 0.19878048780487806
20:20 Ratio: 2.902439024390244
Max-min Ratio: 3.4444444444444446
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_01-45-01
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 615.0
  episode_reward_mean: 358.35
  episode_reward_min: 245.0
  episodes_this_iter: 1
  episodes_total: 482
  experiment_id: 35d66058da2d4c9882f832ee91e4aa4a
  hostname: gpu011
  info:
    apply_time_ms: 2.94
    dispatch_time_ms: 6.568
    learner:
      cur_lr: 0.0007179760141298175
      grad_gnorm: 39.999996185302734
      policy_entropy: 172.4475555419922
      policy_loss: 88.074462890625
      var_gnorm: 20.300914764404297
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 92.04386901855469
    num_steps_sampled: 9660000
    num_steps_trained: 9660000
    wait_time_ms: 266.364
  iterations_since_restore: 483
  node_ip: 172.17.8.11
  num_metric_batches_dropped: 0
  pid: 25504
  policy_reward_mean: {}
  time_since_restore: 13617.916232347488
  time_this_iter_s: 27.758737564086914
  time_total_s: 13617.916232347488
  timestamp: 1593927901
  timesteps_since_restore: 9660000
  timesteps_this_iter: 20000
  timesteps_total: 9660000
  training_iteration: 483
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=25504], 13617 s, 483 iter, 9660000 ts, 358 rew

agent-1: 34.0
agent-2: 16.0
agent-3: 7.0
agent-4: 19.0
agent-5: 2.0
agent-6: 17.0
agent-7: 38.0
agent-8: 35.0
agent-9: 14.0
agent-10: 23.0
agent-11: 43.0
agent-12: 48.0
agent-13: 8.0
agent-14: 13.0
agent-15: 16.0
agent-16: 19.0
agent-17: 9.0
agent-18: 20.0
agent-19: 19.0
agent-20: 6.0
Sum Reward: 406.0
Avg Reward: 20.3
Min Reward: 2.0
Gini Coefficient: 0.3389162561576355
20:20 Ratio: 7.130434782608695
Max-min Ratio: 24.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_01-45-28
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 615.0
  episode_reward_mean: 358.74
  episode_reward_min: 245.0
  episodes_this_iter: 1
  episodes_total: 483
  experiment_id: 35d66058da2d4c9882f832ee91e4aa4a
  hostname: gpu011
  info:
    apply_time_ms: 2.929
    dispatch_time_ms: 7.851
    learner:
      cur_lr: 0.0007166439900174737
      grad_gnorm: 40.0
      policy_entropy: 129.49008178710938
      policy_loss: 9.785892486572266
      var_gnorm: 20.298809051513672
      vf_explained_var: 5.960464477539063e-08
      vf_loss: 43.301544189453125
    num_steps_sampled: 9680000
    num_steps_trained: 9680000
    wait_time_ms: 264.756
  iterations_since_restore: 484
  node_ip: 172.17.8.11
  num_metric_batches_dropped: 0
  pid: 25504
  policy_reward_mean: {}
  time_since_restore: 13645.118733167648
  time_this_iter_s: 27.202500820159912
  time_total_s: 13645.118733167648
  timestamp: 1593927928
  timesteps_since_restore: 9680000
  timesteps_this_iter: 20000
  timesteps_total: 9680000
  training_iteration: 484
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=25504], 13645 s, 484 iter, 9680000 ts, 359 rew

agent-1: 23.0
agent-2: 20.0
agent-3: 24.0
agent-4: 17.0
agent-5: 9.0
agent-6: 26.0
agent-7: 7.0
agent-8: 18.0
agent-9: 19.0
agent-10: 32.0
agent-11: 15.0
agent-12: 10.0
agent-13: 34.0
agent-14: 19.0
agent-15: 8.0
agent-16: 27.0
agent-17: 10.0
agent-18: 23.0
agent-19: 7.0
agent-20: 19.0
Sum Reward: 367.0
Avg Reward: 18.35
Min Reward: 7.0
Gini Coefficient: 0.24373297002724795
20:20 Ratio: 3.838709677419355
Max-min Ratio: 4.857142857142857
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_01-45-56
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 615.0
  episode_reward_mean: 359.12
  episode_reward_min: 245.0
  episodes_this_iter: 1
  episodes_total: 484
  experiment_id: 35d66058da2d4c9882f832ee91e4aa4a
  hostname: gpu011
  info:
    apply_time_ms: 2.549
    dispatch_time_ms: 39.391
    learner:
      cur_lr: 0.0007153120241127908
      grad_gnorm: 40.0
      policy_entropy: 140.8119659423828
      policy_loss: 74.98967742919922
      var_gnorm: 20.305917739868164
      vf_explained_var: 5.960464477539063e-08
      vf_loss: 116.79368591308594
    num_steps_sampled: 9700000
    num_steps_trained: 9700000
    wait_time_ms: 265.022
  iterations_since_restore: 485
  node_ip: 172.17.8.11
  num_metric_batches_dropped: 0
  pid: 25504
  policy_reward_mean: {}
  time_since_restore: 13673.198242664337
  time_this_iter_s: 28.079509496688843
  time_total_s: 13673.198242664337
  timestamp: 1593927956
  timesteps_since_restore: 9700000
  timesteps_this_iter: 20000
  timesteps_total: 9700000
  training_iteration: 485
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=25504], 13673 s, 485 iter, 9700000 ts, 359 rew

agent-1: 14.0
agent-2: 10.0
agent-3: 20.0
agent-4: 32.0
agent-5: 18.0
agent-6: 14.0
agent-7: 15.0
agent-8: 13.0
agent-9: 17.0
agent-10: 10.0
agent-11: 14.0
agent-12: 23.0
agent-13: 12.0
agent-14: 6.0
agent-15: 8.0
agent-16: 22.0
agent-17: -34.0
agent-18: 13.0
agent-19: 14.0
agent-20: 40.0
Sum Reward: 281.0
Avg Reward: 14.05
Min Reward: -34.0
Gini Coefficient: 0.43256227758007115
20:20 Ratio: -11.7
Max-min Ratio: -1.1764705882352942
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_01-46-25
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 615.0
  episode_reward_mean: 358.24
  episode_reward_min: 245.0
  episodes_this_iter: 1
  episodes_total: 485
  experiment_id: 35d66058da2d4c9882f832ee91e4aa4a
  hostname: gpu011
  info:
    apply_time_ms: 4.086
    dispatch_time_ms: 67.793
    learner:
      cur_lr: 0.000713980000000447
      grad_gnorm: 30.263803482055664
      policy_entropy: 181.0196990966797
      policy_loss: 12.155021667480469
      var_gnorm: 20.30621910095215
      vf_explained_var: 1.1920928955078125e-07
      vf_loss: 13.0089750289917
    num_steps_sampled: 9720000
    num_steps_trained: 9720000
    wait_time_ms: 195.686
  iterations_since_restore: 486
  node_ip: 172.17.8.11
  num_metric_batches_dropped: 0
  pid: 25504
  policy_reward_mean: {}
  time_since_restore: 13701.570311546326
  time_this_iter_s: 28.372068881988525
  time_total_s: 13701.570311546326
  timestamp: 1593927985
  timesteps_since_restore: 9720000
  timesteps_this_iter: 20000
  timesteps_total: 9720000
  training_iteration: 486
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=25504], 13701 s, 486 iter, 9720000 ts, 358 rew

agent-1: 7.0
agent-2: 12.0
agent-3: 12.0
agent-4: 16.0
agent-5: 12.0
agent-6: 18.0
agent-7: 21.0
agent-8: 35.0
agent-9: 19.0
agent-10: 15.0
agent-11: 17.0
agent-12: 17.0
agent-13: 10.0
agent-14: 24.0
agent-15: 16.0
agent-16: 15.0
agent-17: 24.0
agent-18: 16.0
agent-19: 5.0
agent-20: 19.0
Sum Reward: 330.0
Avg Reward: 16.5
Min Reward: 5.0
Gini Coefficient: 0.20606060606060606
20:20 Ratio: 3.0588235294117645
Max-min Ratio: 7.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_01-46-54
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 615.0
  episode_reward_mean: 357.2
  episode_reward_min: 245.0
  episodes_this_iter: 1
  episodes_total: 486
  experiment_id: 35d66058da2d4c9882f832ee91e4aa4a
  hostname: gpu011
  info:
    apply_time_ms: 2.948
    dispatch_time_ms: 97.255
    learner:
      cur_lr: 0.0007126479758881032
      grad_gnorm: 7.001495838165283
      policy_entropy: 189.02508544921875
      policy_loss: -0.3933282494544983
      var_gnorm: 20.304874420166016
      vf_explained_var: 0.0
      vf_loss: 0.01923869177699089
    num_steps_sampled: 9740000
    num_steps_trained: 9740000
    wait_time_ms: 197.364
  iterations_since_restore: 487
  node_ip: 172.17.8.11
  num_metric_batches_dropped: 0
  pid: 25504
  policy_reward_mean: {}
  time_since_restore: 13731.155760526657
  time_this_iter_s: 29.58544898033142
  time_total_s: 13731.155760526657
  timestamp: 1593928014
  timesteps_since_restore: 9740000
  timesteps_this_iter: 20000
  timesteps_total: 9740000
  training_iteration: 487
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=25504], 13731 s, 487 iter, 9740000 ts, 357 rew

agent-1: 28.0
agent-2: 12.0
agent-3: 21.0
agent-4: 17.0
agent-5: 20.0
agent-6: 2.0
agent-7: 18.0
agent-8: 16.0
agent-9: 9.0
agent-10: 16.0
agent-11: 27.0
agent-12: 17.0
agent-13: 17.0
agent-14: 18.0
agent-15: 21.0
agent-16: 9.0
agent-17: 11.0
agent-18: 18.0
agent-19: 15.0
agent-20: 26.0
Sum Reward: 338.0
Avg Reward: 16.9
Min Reward: 2.0
Gini Coefficient: 0.20059171597633135
20:20 Ratio: 3.2903225806451615
Max-min Ratio: 14.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_01-47-23
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 615.0
  episode_reward_mean: 357.63
  episode_reward_min: 245.0
  episodes_this_iter: 1
  episodes_total: 487
  experiment_id: 35d66058da2d4c9882f832ee91e4aa4a
  hostname: gpu011
  info:
    apply_time_ms: 5.188
    dispatch_time_ms: 52.697
    learner:
      cur_lr: 0.0007113160099834204
      grad_gnorm: 11.145188331604004
      policy_entropy: 157.27877807617188
      policy_loss: -0.052211880683898926
      var_gnorm: 20.306055068969727
      vf_explained_var: 0.0
      vf_loss: 3.5736846923828125
    num_steps_sampled: 9760000
    num_steps_trained: 9760000
    wait_time_ms: 234.49
  iterations_since_restore: 488
  node_ip: 172.17.8.11
  num_metric_batches_dropped: 0
  pid: 25504
  policy_reward_mean: {}
  time_since_restore: 13759.870015621185
  time_this_iter_s: 28.7142550945282
  time_total_s: 13759.870015621185
  timestamp: 1593928043
  timesteps_since_restore: 9760000
  timesteps_this_iter: 20000
  timesteps_total: 9760000
  training_iteration: 488
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=25504], 13759 s, 488 iter, 9760000 ts, 358 rew

agent-1: 14.0
agent-2: 8.0
agent-3: 29.0
agent-4: 10.0
agent-5: 14.0
agent-6: 20.0
agent-7: 16.0
agent-8: 18.0
agent-9: 27.0
agent-10: 30.0
agent-11: 23.0
agent-12: 20.0
agent-13: 19.0
agent-14: 8.0
agent-15: 17.0
agent-16: 18.0
agent-17: 29.0
agent-18: 20.0
agent-19: 12.0
agent-20: 19.0
Sum Reward: 371.0
Avg Reward: 18.55
Min Reward: 8.0
Gini Coefficient: 0.19609164420485176
20:20 Ratio: 3.026315789473684
Max-min Ratio: 3.75
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_01-47-51
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 615.0
  episode_reward_mean: 358.15
  episode_reward_min: 245.0
  episodes_this_iter: 1
  episodes_total: 488
  experiment_id: 35d66058da2d4c9882f832ee91e4aa4a
  hostname: gpu011
  info:
    apply_time_ms: 2.744
    dispatch_time_ms: 6.459
    learner:
      cur_lr: 0.0007099839858710766
      grad_gnorm: 4.630782127380371
      policy_entropy: 161.6956024169922
      policy_loss: -0.9588547348976135
      var_gnorm: 20.314472198486328
      vf_explained_var: 0.0
      vf_loss: 0.008239472284913063
    num_steps_sampled: 9780000
    num_steps_trained: 9780000
    wait_time_ms: 270.559
  iterations_since_restore: 489
  node_ip: 172.17.8.11
  num_metric_batches_dropped: 0
  pid: 25504
  policy_reward_mean: {}
  time_since_restore: 13788.262656450272
  time_this_iter_s: 28.392640829086304
  time_total_s: 13788.262656450272
  timestamp: 1593928071
  timesteps_since_restore: 9780000
  timesteps_this_iter: 20000
  timesteps_total: 9780000
  training_iteration: 489
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=25504], 13788 s, 489 iter, 9780000 ts, 358 rew

agent-1: 10.0
agent-2: 17.0
agent-3: 18.0
agent-4: 16.0
agent-5: 20.0
agent-6: 6.0
agent-7: 14.0
agent-8: 11.0
agent-9: 1.0
agent-10: 21.0
agent-11: 16.0
agent-12: 12.0
agent-13: 5.0
agent-14: 10.0
agent-15: 17.0
agent-16: 5.0
agent-17: 14.0
agent-18: 14.0
agent-19: 13.0
agent-20: 22.0
Sum Reward: 262.0
Avg Reward: 13.1
Min Reward: 1.0
Gini Coefficient: 0.2385496183206107
20:20 Ratio: 4.764705882352941
Max-min Ratio: 22.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_01-48-22
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 615.0
  episode_reward_mean: 357.58
  episode_reward_min: 245.0
  episodes_this_iter: 1
  episodes_total: 489
  experiment_id: 35d66058da2d4c9882f832ee91e4aa4a
  hostname: gpu011
  info:
    apply_time_ms: 3.34
    dispatch_time_ms: 7.507
    learner:
      cur_lr: 0.0007086520199663937
      grad_gnorm: 27.41023826599121
      policy_entropy: 157.4952392578125
      policy_loss: -7.807302951812744
      var_gnorm: 20.316434860229492
      vf_explained_var: 0.0
      vf_loss: 1.219993233680725
    num_steps_sampled: 9800000
    num_steps_trained: 9800000
    wait_time_ms: 266.435
  iterations_since_restore: 490
  node_ip: 172.17.8.11
  num_metric_batches_dropped: 0
  pid: 25504
  policy_reward_mean: {}
  time_since_restore: 13819.012917280197
  time_this_iter_s: 30.750260829925537
  time_total_s: 13819.012917280197
  timestamp: 1593928102
  timesteps_since_restore: 9800000
  timesteps_this_iter: 20000
  timesteps_total: 9800000
  training_iteration: 490
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 29.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=25504], 13819 s, 490 iter, 9800000 ts, 358 rew

agent-1: 5.0
agent-2: 38.0
agent-3: 7.0
agent-4: 21.0
agent-5: 14.0
agent-6: 7.0
agent-7: 7.0
agent-8: 14.0
agent-9: 14.0
agent-10: 28.0
agent-11: 15.0
agent-12: 21.0
agent-13: 12.0
agent-14: 14.0
agent-15: 9.0
agent-16: 24.0
agent-17: 5.0
agent-18: 9.0
agent-19: 8.0
agent-20: 27.0
Sum Reward: 299.0
Avg Reward: 14.95
Min Reward: 5.0
Gini Coefficient: 0.3148829431438127
20:20 Ratio: 4.875
Max-min Ratio: 7.6
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_01-48-50
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 615.0
  episode_reward_mean: 356.45
  episode_reward_min: 245.0
  episodes_this_iter: 1
  episodes_total: 490
  experiment_id: 35d66058da2d4c9882f832ee91e4aa4a
  hostname: gpu011
  info:
    apply_time_ms: 3.043
    dispatch_time_ms: 6.07
    learner:
      cur_lr: 0.0007073199958540499
      grad_gnorm: 40.0
      policy_entropy: 132.11398315429688
      policy_loss: 71.27836608886719
      var_gnorm: 20.31590461730957
      vf_explained_var: 0.0
      vf_loss: 119.46658325195312
    num_steps_sampled: 9820000
    num_steps_trained: 9820000
    wait_time_ms: 254.065
  iterations_since_restore: 491
  node_ip: 172.17.8.11
  num_metric_batches_dropped: 0
  pid: 25504
  policy_reward_mean: {}
  time_since_restore: 13846.464223623276
  time_this_iter_s: 27.451306343078613
  time_total_s: 13846.464223623276
  timestamp: 1593928130
  timesteps_since_restore: 9820000
  timesteps_this_iter: 20000
  timesteps_total: 9820000
  training_iteration: 491
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=25504], 13846 s, 491 iter, 9820000 ts, 356 rew

agent-1: 20.0
agent-2: 41.0
agent-3: 14.0
agent-4: 25.0
agent-5: 23.0
agent-6: 3.0
agent-7: 16.0
agent-8: 31.0
agent-9: 19.0
agent-10: 19.0
agent-11: 9.0
agent-12: 25.0
agent-13: 31.0
agent-14: 24.0
agent-15: 47.0
agent-16: 27.0
agent-17: 24.0
agent-18: 18.0
agent-19: 22.0
agent-20: 33.0
Sum Reward: 471.0
Avg Reward: 23.55
Min Reward: 3.0
Gini Coefficient: 0.2281316348195329
20:20 Ratio: 3.619047619047619
Max-min Ratio: 15.666666666666666
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_01-49-17
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 615.0
  episode_reward_mean: 356.73
  episode_reward_min: 245.0
  episodes_this_iter: 1
  episodes_total: 491
  experiment_id: 35d66058da2d4c9882f832ee91e4aa4a
  hostname: gpu011
  info:
    apply_time_ms: 3.073
    dispatch_time_ms: 7.216
    learner:
      cur_lr: 0.0007059879717417061
      grad_gnorm: 20.485137939453125
      policy_entropy: 121.43327331542969
      policy_loss: -0.439875066280365
      var_gnorm: 20.31987953186035
      vf_explained_var: 0.0
      vf_loss: 7.39752197265625
    num_steps_sampled: 9840000
    num_steps_trained: 9840000
    wait_time_ms: 261.946
  iterations_since_restore: 492
  node_ip: 172.17.8.11
  num_metric_batches_dropped: 0
  pid: 25504
  policy_reward_mean: {}
  time_since_restore: 13873.390259504318
  time_this_iter_s: 26.92603588104248
  time_total_s: 13873.390259504318
  timestamp: 1593928157
  timesteps_since_restore: 9840000
  timesteps_this_iter: 20000
  timesteps_total: 9840000
  training_iteration: 492
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 36.3/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=25504], 13873 s, 492 iter, 9840000 ts, 357 rew

agent-1: 38.0
agent-2: 32.0
agent-3: 50.0
agent-4: 17.0
agent-5: 11.0
agent-6: 14.0
agent-7: 32.0
agent-8: 22.0
agent-9: 25.0
agent-10: 38.0
agent-11: 21.0
agent-12: 11.0
agent-13: 11.0
agent-14: 32.0
agent-15: 26.0
agent-16: 19.0
agent-17: 21.0
agent-18: 38.0
agent-19: 46.0
agent-20: 11.0
Sum Reward: 515.0
Avg Reward: 25.75
Min Reward: 11.0
Gini Coefficient: 0.25776699029126215
20:20 Ratio: 3.909090909090909
Max-min Ratio: 4.545454545454546
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_01-49-44
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 615.0
  episode_reward_mean: 358.67
  episode_reward_min: 245.0
  episodes_this_iter: 1
  episodes_total: 492
  experiment_id: 35d66058da2d4c9882f832ee91e4aa4a
  hostname: gpu011
  info:
    apply_time_ms: 2.979
    dispatch_time_ms: 7.083
    learner:
      cur_lr: 0.0007046560058370233
      grad_gnorm: 15.708273887634277
      policy_entropy: 135.49075317382812
      policy_loss: -3.716862678527832
      var_gnorm: 20.31633186340332
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 0.09655848890542984
    num_steps_sampled: 9860000
    num_steps_trained: 9860000
    wait_time_ms: 260.983
  iterations_since_restore: 493
  node_ip: 172.17.8.11
  num_metric_batches_dropped: 0
  pid: 25504
  policy_reward_mean: {}
  time_since_restore: 13900.803222179413
  time_this_iter_s: 27.412962675094604
  time_total_s: 13900.803222179413
  timestamp: 1593928184
  timesteps_since_restore: 9860000
  timesteps_this_iter: 20000
  timesteps_total: 9860000
  training_iteration: 493
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 36.3/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=25504], 13900 s, 493 iter, 9860000 ts, 359 rew

agent-1: 16.0
agent-2: 29.0
agent-3: 20.0
agent-4: 26.0
agent-5: 9.0
agent-6: 23.0
agent-7: 17.0
agent-8: 27.0
agent-9: 27.0
agent-10: 18.0
agent-11: 14.0
agent-12: 18.0
agent-13: 31.0
agent-14: 9.0
agent-15: 30.0
agent-16: 17.0
agent-17: 25.0
agent-18: 24.0
agent-19: 30.0
agent-20: 23.0
Sum Reward: 433.0
Avg Reward: 21.65
Min Reward: 9.0
Gini Coefficient: 0.17170900692840646
20:20 Ratio: 2.5
Max-min Ratio: 3.4444444444444446
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_01-50-11
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 615.0
  episode_reward_mean: 360.4
  episode_reward_min: 245.0
  episodes_this_iter: 1
  episodes_total: 493
  experiment_id: 35d66058da2d4c9882f832ee91e4aa4a
  hostname: gpu011
  info:
    apply_time_ms: 2.531
    dispatch_time_ms: 5.67
    learner:
      cur_lr: 0.0007033239817246795
      grad_gnorm: 7.957295894622803
      policy_entropy: 142.55404663085938
      policy_loss: 1.355982780456543
      var_gnorm: 20.316877365112305
      vf_explained_var: 0.0
      vf_loss: 4.830738544464111
    num_steps_sampled: 9880000
    num_steps_trained: 9880000
    wait_time_ms: 268.498
  iterations_since_restore: 494
  node_ip: 172.17.8.11
  num_metric_batches_dropped: 0
  pid: 25504
  policy_reward_mean: {}
  time_since_restore: 13928.13516664505
  time_this_iter_s: 27.331944465637207
  time_total_s: 13928.13516664505
  timestamp: 1593928211
  timesteps_since_restore: 9880000
  timesteps_this_iter: 20000
  timesteps_total: 9880000
  training_iteration: 494
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 36.3/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=25504], 13928 s, 494 iter, 9880000 ts, 360 rew

agent-1: 21.0
agent-2: 20.0
agent-3: 7.0
agent-4: 17.0
agent-5: 33.0
agent-6: 18.0
agent-7: 19.0
agent-8: 11.0
agent-9: 14.0
agent-10: 30.0
agent-11: 32.0
agent-12: 22.0
agent-13: 27.0
agent-14: 5.0
agent-15: 21.0
agent-16: 14.0
agent-17: 19.0
agent-18: 16.0
agent-19: 8.0
agent-20: 18.0
Sum Reward: 372.0
Avg Reward: 18.6
Min Reward: 5.0
Gini Coefficient: 0.22849462365591397
20:20 Ratio: 3.935483870967742
Max-min Ratio: 6.6
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_01-50-39
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 615.0
  episode_reward_mean: 360.8
  episode_reward_min: 245.0
  episodes_this_iter: 1
  episodes_total: 494
  experiment_id: 35d66058da2d4c9882f832ee91e4aa4a
  hostname: gpu011
  info:
    apply_time_ms: 3.054
    dispatch_time_ms: 6.878
    learner:
      cur_lr: 0.0007019920158199966
      grad_gnorm: 40.0
      policy_entropy: 176.56251525878906
      policy_loss: 110.2061767578125
      var_gnorm: 20.31309700012207
      vf_explained_var: 0.0
      vf_loss: 121.35150909423828
    num_steps_sampled: 9900000
    num_steps_trained: 9900000
    wait_time_ms: 248.175
  iterations_since_restore: 495
  node_ip: 172.17.8.11
  num_metric_batches_dropped: 0
  pid: 25504
  policy_reward_mean: {}
  time_since_restore: 13955.668382644653
  time_this_iter_s: 27.53321599960327
  time_total_s: 13955.668382644653
  timestamp: 1593928239
  timesteps_since_restore: 9900000
  timesteps_this_iter: 20000
  timesteps_total: 9900000
  training_iteration: 495
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 36.3/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=25504], 13955 s, 495 iter, 9900000 ts, 361 rew

agent-1: 13.0
agent-2: 8.0
agent-3: 16.0
agent-4: 32.0
agent-5: 14.0
agent-6: 27.0
agent-7: 19.0
agent-8: 17.0
agent-9: 15.0
agent-10: 4.0
agent-11: 5.0
agent-12: 37.0
agent-13: 16.0
agent-14: 11.0
agent-15: 20.0
agent-16: 14.0
agent-17: 18.0
agent-18: 20.0
agent-19: 31.0
agent-20: 21.0
Sum Reward: 358.0
Avg Reward: 17.9
Min Reward: 4.0
Gini Coefficient: 0.25837988826815644
20:20 Ratio: 4.535714285714286
Max-min Ratio: 9.25
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_01-51-06
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 615.0
  episode_reward_mean: 361.74
  episode_reward_min: 245.0
  episodes_this_iter: 1
  episodes_total: 495
  experiment_id: 35d66058da2d4c9882f832ee91e4aa4a
  hostname: gpu011
  info:
    apply_time_ms: 2.619
    dispatch_time_ms: 7.168
    learner:
      cur_lr: 0.0007006599917076528
      grad_gnorm: 10.134028434753418
      policy_entropy: 165.98789978027344
      policy_loss: -2.1313517093658447
      var_gnorm: 20.312580108642578
      vf_explained_var: 1.7881393432617188e-07
      vf_loss: 4.550915718078613
    num_steps_sampled: 9920000
    num_steps_trained: 9920000
    wait_time_ms: 270.205
  iterations_since_restore: 496
  node_ip: 172.17.8.11
  num_metric_batches_dropped: 0
  pid: 25504
  policy_reward_mean: {}
  time_since_restore: 13982.97936463356
  time_this_iter_s: 27.31098198890686
  time_total_s: 13982.97936463356
  timestamp: 1593928266
  timesteps_since_restore: 9920000
  timesteps_this_iter: 20000
  timesteps_total: 9920000
  training_iteration: 496
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 36.3/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=25504], 13982 s, 496 iter, 9920000 ts, 362 rew

agent-1: 5.0
agent-2: 11.0
agent-3: 4.0
agent-4: 8.0
agent-5: 18.0
agent-6: 14.0
agent-7: 4.0
agent-8: 26.0
agent-9: 26.0
agent-10: 5.0
agent-11: 16.0
agent-12: 12.0
agent-13: 24.0
agent-14: 16.0
agent-15: 25.0
agent-16: 22.0
agent-17: 10.0
agent-18: 18.0
agent-19: 18.0
agent-20: 13.0
Sum Reward: 295.0
Avg Reward: 14.75
Min Reward: 4.0
Gini Coefficient: 0.2805084745762712
20:20 Ratio: 5.611111111111111
Max-min Ratio: 6.5
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_01-51-34
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 615.0
  episode_reward_mean: 361.1
  episode_reward_min: 245.0
  episodes_this_iter: 1
  episodes_total: 496
  experiment_id: 35d66058da2d4c9882f832ee91e4aa4a
  hostname: gpu011
  info:
    apply_time_ms: 3.371
    dispatch_time_ms: 6.231
    learner:
      cur_lr: 0.0006993280258029699
      grad_gnorm: 4.352555751800537
      policy_entropy: 174.2385711669922
      policy_loss: -1.1507205963134766
      var_gnorm: 20.310876846313477
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 0.007320430129766464
    num_steps_sampled: 9940000
    num_steps_trained: 9940000
    wait_time_ms: 276.752
  iterations_since_restore: 497
  node_ip: 172.17.8.11
  num_metric_batches_dropped: 0
  pid: 25504
  policy_reward_mean: {}
  time_since_restore: 14010.884028434753
  time_this_iter_s: 27.904663801193237
  time_total_s: 14010.884028434753
  timestamp: 1593928294
  timesteps_since_restore: 9940000
  timesteps_this_iter: 20000
  timesteps_total: 9940000
  training_iteration: 497
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 36.3/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=25504], 14010 s, 497 iter, 9940000 ts, 361 rew

agent-1: 22.0
agent-2: 23.0
agent-3: 14.0
agent-4: 27.0
agent-5: 8.0
agent-6: 12.0
agent-7: 20.0
agent-8: 8.0
agent-9: 22.0
agent-10: 20.0
agent-11: 10.0
agent-12: 16.0
agent-13: 20.0
agent-14: 36.0
agent-15: 12.0
agent-16: 27.0
agent-17: 10.0
agent-18: 26.0
agent-19: 14.0
agent-20: 17.0
Sum Reward: 364.0
Avg Reward: 18.2
Min Reward: 8.0
Gini Coefficient: 0.2239010989010989
20:20 Ratio: 3.2222222222222223
Max-min Ratio: 4.5
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_01-52-03
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 615.0
  episode_reward_mean: 359.83
  episode_reward_min: 245.0
  episodes_this_iter: 1
  episodes_total: 497
  experiment_id: 35d66058da2d4c9882f832ee91e4aa4a
  hostname: gpu011
  info:
    apply_time_ms: 2.803
    dispatch_time_ms: 46.219
    learner:
      cur_lr: 0.0006979960016906261
      grad_gnorm: 6.907896041870117
      policy_entropy: 152.5254669189453
      policy_loss: -1.9486231803894043
      var_gnorm: 20.31241798400879
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 3.164607286453247
    num_steps_sampled: 9960000
    num_steps_trained: 9960000
    wait_time_ms: 244.065
  iterations_since_restore: 498
  node_ip: 172.17.8.11
  num_metric_batches_dropped: 0
  pid: 25504
  policy_reward_mean: {}
  time_since_restore: 14039.355705738068
  time_this_iter_s: 28.47167730331421
  time_total_s: 14039.355705738068
  timestamp: 1593928323
  timesteps_since_restore: 9960000
  timesteps_this_iter: 20000
  timesteps_total: 9960000
  training_iteration: 498
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 36.3/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=25504], 14039 s, 498 iter, 9960000 ts, 360 rew

agent-1: 11.0
agent-2: 11.0
agent-3: 23.0
agent-4: 26.0
agent-5: 9.0
agent-6: 15.0
agent-7: 5.0
agent-8: 16.0
agent-9: 12.0
agent-10: 16.0
agent-11: 16.0
agent-12: 12.0
agent-13: 4.0
agent-14: 15.0
agent-15: 16.0
agent-16: 12.0
agent-17: 2.0
agent-18: 15.0
agent-19: 16.0
agent-20: 19.0
Sum Reward: 271.0
Avg Reward: 13.55
Min Reward: 2.0
Gini Coefficient: 0.22822878228782287
20:20 Ratio: 4.2
Max-min Ratio: 13.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_01-52-32
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 615.0
  episode_reward_mean: 359.11
  episode_reward_min: 245.0
  episodes_this_iter: 1
  episodes_total: 498
  experiment_id: 35d66058da2d4c9882f832ee91e4aa4a
  hostname: gpu011
  info:
    apply_time_ms: 2.842
    dispatch_time_ms: 45.746
    learner:
      cur_lr: 0.0006966639775782824
      grad_gnorm: 4.7786431312561035
      policy_entropy: 173.20962524414062
      policy_loss: 3.022052049636841
      var_gnorm: 20.311012268066406
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 0.008575516752898693
    num_steps_sampled: 9980000
    num_steps_trained: 9980000
    wait_time_ms: 229.295
  iterations_since_restore: 499
  node_ip: 172.17.8.11
  num_metric_batches_dropped: 0
  pid: 25504
  policy_reward_mean: {}
  time_since_restore: 14068.609296560287
  time_this_iter_s: 29.25359082221985
  time_total_s: 14068.609296560287
  timestamp: 1593928352
  timesteps_since_restore: 9980000
  timesteps_this_iter: 20000
  timesteps_total: 9980000
  training_iteration: 499
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 36.3/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=25504], 14068 s, 499 iter, 9980000 ts, 359 rew

agent-1: 24.0
agent-2: 15.0
agent-3: 5.0
agent-4: 17.0
agent-5: 10.0
agent-6: 29.0
agent-7: 13.0
agent-8: 17.0
agent-9: 11.0
agent-10: 10.0
agent-11: 17.0
agent-12: 9.0
agent-13: 17.0
agent-14: 28.0
agent-15: 13.0
agent-16: 17.0
agent-17: 28.0
agent-18: 14.0
agent-19: 23.0
agent-20: 8.0
Sum Reward: 325.0
Avg Reward: 16.25
Min Reward: 5.0
Gini Coefficient: 0.2336923076923077
20:20 Ratio: 3.40625
Max-min Ratio: 5.8
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-05_01-53-01
  done: true
  episode_len_mean: 1000.0
  episode_reward_max: 615.0
  episode_reward_mean: 359.0
  episode_reward_min: 245.0
  episodes_this_iter: 1
  episodes_total: 499
  experiment_id: 35d66058da2d4c9882f832ee91e4aa4a
  hostname: gpu011
  info:
    apply_time_ms: 2.876
    dispatch_time_ms: 44.973
    learner:
      cur_lr: 0.0006953320116735995
      grad_gnorm: 11.812582969665527
      policy_entropy: 148.7792510986328
      policy_loss: -5.790475845336914
      var_gnorm: 20.313819885253906
      vf_explained_var: 5.960464477539063e-08
      vf_loss: 5.4041900634765625
    num_steps_sampled: 10000000
    num_steps_trained: 10000000
    wait_time_ms: 252.557
  iterations_since_restore: 500
  node_ip: 172.17.8.11
  num_metric_batches_dropped: 0
  pid: 25504
  policy_reward_mean: {}
  time_since_restore: 14097.43181681633
  time_this_iter_s: 28.82252025604248
  time_total_s: 14097.43181681633
  timestamp: 1593928381
  timesteps_since_restore: 10000000
  timesteps_this_iter: 20000
  timesteps_total: 10000000
  training_iteration: 500
  
W0705 01:53:19.289819 25498 client_connection.cc:255] [worker]ProcessMessage with type 7 took 16328 ms.
W0705 01:53:19.310905 25498 task_dependency_manager.cc:259] Task lease to renew has already expired by -6357ms
W0705 01:53:19.312520 25498 node_manager.cc:250] Last heartbeat was sent 16446 ms ago 
/h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/numpy/core/fromnumeric.py:3335: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/numpy/core/_methods.py:161: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)
[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.[0m
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 0.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 35.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
TERMINATED trials:
 - A3C_harvest_env_0:	TERMINATED [pid=25504], 14097 s, 500 iter, 10000000 ts, 359 rew

== Status ==
Using FIFO scheduling algorithm.
Resources requested: 0.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 35.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
TERMINATED trials:
 - A3C_harvest_env_0:	TERMINATED [pid=25504], 14097 s, 500 iter, 10000000 ts, 359 rew

Commencing experiment harvest_A3C
