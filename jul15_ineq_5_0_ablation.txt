/h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:523: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint8 = np.dtype([("qint8", np.int8, 1)])
/h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:524: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint8 = np.dtype([("quint8", np.uint8, 1)])
/h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint16 = np.dtype([("qint16", np.int16, 1)])
/h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint16 = np.dtype([("quint16", np.uint16, 1)])
/h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint32 = np.dtype([("qint32", np.int32, 1)])
/h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:532: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  np_resource = np.dtype([("resource", np.ubyte, 1)])
Process STDOUT and STDERR is being redirected to /tmp/ray/session_2020-07-15_20-11-16_8903/logs.
Waiting for redis server at 127.0.0.1:12235 to respond...
Waiting for redis server at 127.0.0.1:65374 to respond...
Warning: Capping object memory store to 20.0GB. To increase this further, specify `object_store_memory` when calling ray.init() or ray start.
Starting the Plasma object store with 20.0 GB memory using /dev/shm.

======================================================================
View the web UI at http://localhost:8888/notebooks/ray_ui.ipynb?token=52028971d6b60b64bb1841f79c87660bdccef4cbb5bd51e1
======================================================================

Commencing experiment harvest_A3C
{'monitor': False, 'log_level': 'INFO', 'callbacks': {'on_episode_start': <ray.tune.suggest.variant_generator.function object at 0x7f94bc721e80>, 'on_episode_end': <ray.tune.suggest.variant_generator.function object at 0x7f94bc721da0>}, 'model': {'custom_model': 'conv_to_fc_net', 'use_lstm': True, 'lstm_cell_size': 128}, 'optimizer': {}, 'gamma': 0.99, 'horizon': 1000, 'env_config': {'func_create': <ray.tune.suggest.variant_generator.function object at 0x7f94be039668>, 'env_name': 'harvest_env', 'run': 'A3C'}, 'env': None, 'clip_rewards': None, 'clip_actions': True, 'preprocessor_pref': 'deepmind', 'num_workers': 2, 'num_gpus': 0, 'num_cpus_per_worker': 0.5, 'num_gpus_per_worker': 0, 'custom_resources_per_worker': {}, 'num_cpus_for_driver': 1, 'num_envs_per_worker': 1, 'sample_batch_size': 10, 'train_batch_size': 30000, 'batch_mode': 'truncate_episodes', 'sample_async': True, 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_evaluator_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'compress_observations': False, 'collect_metrics_timeout': 180, 'input': 'sampler', 'input_evaluation': None, 'output': None, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'multiagent': {'policy_graphs': {}, 'policy_mapping_fn': None, 'policies_to_train': None}, 'use_pytorch': False, 'lambda': 1.0, 'grad_clip': 40.0, 'lr': 0.0001, 'lr_schedule': [[0, 0.00136], [20000000, 2.8e-05]], 'vf_loss_coeff': 0.5, 'entropy_coeff': -0.000687, 'min_iter_time_s': 5}
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 0/2 CPUs, 0/1 GPUs
Memory usage on this node: 6.6/202.5 GB

Created LogSyncer for /h/zhaostep/ray_results/harvest_A3C/A3C_harvest_env_0_2020-07-15_20-11-17o9bqa1l9 -> 
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 6.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING

/h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:523: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint8 = np.dtype([("qint8", np.int8, 1)])
/h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:524: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint8 = np.dtype([("quint8", np.uint8, 1)])
/h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint16 = np.dtype([("qint16", np.int16, 1)])
/h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint16 = np.dtype([("quint16", np.uint16, 1)])
/h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint32 = np.dtype([("qint32", np.int32, 1)])
/h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:532: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  np_resource = np.dtype([("resource", np.ubyte, 1)])
2020-07-15 20:11:29,292	INFO policy_evaluator.py:262 -- Creating policy evaluation worker 0 on CPU (please ignore any CUDA init errors)
2020-07-15 20:11:29.292958: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
From /h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/ray/rllib/models/lstm.py:59: BasicLSTMCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.
Instructions for updating:
This class is deprecated, please use tf.nn.rnn_cell.LSTMCell, which supports all the feature this cell currently has. Please replace the existing code with tf.nn.rnn_cell.LSTMCell(name='basic_lstm_cell').
/h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:523: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint8 = np.dtype([("qint8", np.int8, 1)])
/h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:524: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint8 = np.dtype([("quint8", np.uint8, 1)])
/h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint16 = np.dtype([("qint16", np.int16, 1)])
/h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint16 = np.dtype([("quint16", np.uint16, 1)])
/h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint32 = np.dtype([("qint32", np.int32, 1)])
/h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:532: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  np_resource = np.dtype([("resource", np.ubyte, 1)])
2020-07-15 20:11:40,532	INFO policy_evaluator.py:262 -- Creating policy evaluation worker 1 on CPU (please ignore any CUDA init errors)
2020-07-15 20:11:40.533910: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
/h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:523: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint8 = np.dtype([("qint8", np.int8, 1)])
/h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:524: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint8 = np.dtype([("quint8", np.uint8, 1)])
/h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint16 = np.dtype([("qint16", np.int16, 1)])
/h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint16 = np.dtype([("quint16", np.uint16, 1)])
/h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint32 = np.dtype([("qint32", np.int32, 1)])
/h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:532: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  np_resource = np.dtype([("resource", np.ubyte, 1)])
2020-07-15 20:11:40,691	INFO policy_evaluator.py:262 -- Creating policy evaluation worker 2 on CPU (please ignore any CUDA init errors)
2020-07-15 20:11:40.692006: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
From /h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/ray/rllib/models/lstm.py:59: BasicLSTMCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.
Instructions for updating:
This class is deprecated, please use tf.nn.rnn_cell.LSTMCell, which supports all the feature this cell currently has. Please replace the existing code with tf.nn.rnn_cell.LSTMCell(name='basic_lstm_cell').
From /h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/ray/rllib/models/lstm.py:59: BasicLSTMCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.
Instructions for updating:
This class is deprecated, please use tf.nn.rnn_cell.LSTMCell, which supports all the feature this cell currently has. Please replace the existing code with tf.nn.rnn_cell.LSTMCell(name='basic_lstm_cell').
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-11-52
  done: false
  episode_len_mean: .nan
  episode_reward_max: .nan
  episode_reward_mean: .nan
  episode_reward_min: .nan
  episodes_this_iter: 0
  episodes_total: 0
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 3.266
    dispatch_time_ms: 6.527
    learner:
      cur_lr: 0.0013599999947473407
      grad_gnorm: 40.0
      policy_entropy: 66.23027038574219
      policy_loss: -160195.25
      var_gnorm: 18.44169807434082
      vf_explained_var: 7.152557373046875e-06
      vf_loss: 613479936.0
    num_steps_sampled: 5000
    num_steps_trained: 5000
    wait_time_ms: 77.246
  iterations_since_restore: 1
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 21.569268703460693
  time_this_iter_s: 21.569268703460693
  time_total_s: 21.569268703460693
  timestamp: 1594858312
  timesteps_since_restore: 5000
  timesteps_this_iter: 5000
  timesteps_total: 5000
  training_iteration: 1
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 9.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 21 s, 1 iter, 5000 ts, nan rew

[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.[0m
agent-1: -183070.94306506988
agent-2: -425464.33087525493
agent-3: -305842.0383667477
agent-4: -156935.18755826043
agent-5: -320336.1627984089
Extrinsic Rewards:
-5201
-7054
-6624
-4972
-6039
Sum Reward: -29890
Avg Reward: -5978.0
Min Reward: -7054
Max Reward: -4972
Gini Coefficient: -0.07476748076279692
20:20 Ratio: 0.7048483130138928
Max-min Ratio: 0.7048483130138928
[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.[0m
agent-1: -322248.10626698285
agent-2: -552588.0675606977
agent-3: -233838.7948304153
agent-4: -167025.20476044196
agent-5: -215345.37801374358
Extrinsic Rewards:
-6790
-8072
-5446
-4175
-5866
Sum Reward: -30349
Avg Reward: -6069.8
Min Reward: -8072
Max Reward: -4175
Gini Coefficient: -0.1204388941975024
20:20 Ratio: 0.5172200198216056
Max-min Ratio: 0.5172200198216056
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-12-00
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -1391648.6626637413
  episode_reward_mean: -1441347.1070480132
  episode_reward_min: -1491045.5514322852
  episodes_this_iter: 2
  episodes_total: 2
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.434
    dispatch_time_ms: 9.783
    learner:
      cur_lr: 0.0013596670469269156
      grad_gnorm: 40.0
      policy_entropy: 53.04547119140625
      policy_loss: -199849.390625
      var_gnorm: 18.779041290283203
      vf_explained_var: -2.384185791015625e-07
      vf_loss: 762856448.0
    num_steps_sampled: 10000
    num_steps_trained: 10000
    wait_time_ms: 76.399
  iterations_since_restore: 2
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 30.11625385284424
  time_this_iter_s: 8.546985149383545
  time_total_s: 30.11625385284424
  timestamp: 1594858320
  timesteps_since_restore: 10000
  timesteps_this_iter: 5000
  timesteps_total: 10000
  training_iteration: 2
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 9.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 30 s, 2 iter, 10000 ts, -1.44e+06 rew

Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-12-09
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -1391648.6626637413
  episode_reward_mean: -1441347.1070480132
  episode_reward_min: -1491045.5514322852
  episodes_this_iter: 0
  episodes_total: 2
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.593
    dispatch_time_ms: 9.074
    learner:
      cur_lr: 0.0013593339826911688
      grad_gnorm: 39.999996185302734
      policy_entropy: 14.982085227966309
      policy_loss: -59314.58203125
      var_gnorm: 19.293617248535156
      vf_explained_var: 0.0
      vf_loss: 20469968896.0
    num_steps_sampled: 15000
    num_steps_trained: 15000
    wait_time_ms: 76.012
  iterations_since_restore: 3
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 38.92416214942932
  time_this_iter_s: 8.807908296585083
  time_total_s: 38.92416214942932
  timestamp: 1594858329
  timesteps_since_restore: 15000
  timesteps_this_iter: 5000
  timesteps_total: 15000
  training_iteration: 3
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 9.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 38 s, 3 iter, 15000 ts, -1.44e+06 rew

agent-1: -1169708.201159414
agent-2: -3067321.9464209736
agent-3: -3491114.3667827877
agent-4: -3921552.106606263
agent-5: -2335003.3213108075
Extrinsic Rewards:
-18075
-36834
-41151
-37852
-26200
Sum Reward: -160112
Avg Reward: -32022.4
Min Reward: -41151
Max Reward: -18075
Gini Coefficient: -0.14440891376036774
20:20 Ratio: 0.4392359845447255
Max-min Ratio: 0.4392359845447255
agent-1: -1942625.774681389
agent-2: -2283202.0767704397
agent-3: -2348127.803124691
agent-4: -1442305.5538639338
agent-5: -4419729.473609417
Extrinsic Rewards:
-21814
-20814
-25152
-20371
-41414
Sum Reward: -129565
Avg Reward: -25913.0
Min Reward: -41414
Max Reward: -20371
Gini Coefficient: -0.14332265658163856
20:20 Ratio: 0.4918868015646883
Max-min Ratio: 0.4918868015646883
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-12-18
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -1391648.6626637413
  episode_reward_mean: -7325846.209606535
  episode_reward_min: -13984699.942280233
  episodes_this_iter: 2
  episodes_total: 4
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.809
    dispatch_time_ms: 7.514
    learner:
      cur_lr: 0.0013590010348707438
      grad_gnorm: 40.0
      policy_entropy: 2.8010547161102295
      policy_loss: -6162.74462890625
      var_gnorm: 23.44200325012207
      vf_explained_var: -5.960464477539062e-07
      vf_loss: 20418856960.0
    num_steps_sampled: 20000
    num_steps_trained: 20000
    wait_time_ms: 82.888
  iterations_since_restore: 4
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 47.639363527297974
  time_this_iter_s: 8.715201377868652
  time_total_s: 47.639363527297974
  timestamp: 1594858338
  timesteps_since_restore: 20000
  timesteps_this_iter: 5000
  timesteps_total: 20000
  training_iteration: 4
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 9.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 47 s, 4 iter, 20000 ts, -7.33e+06 rew

Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-12-26
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -1391648.6626637413
  episode_reward_mean: -7325846.209606534
  episode_reward_min: -13984699.942280233
  episodes_this_iter: 0
  episodes_total: 4
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.736
    dispatch_time_ms: 9.365
    learner:
      cur_lr: 0.0013586679706349969
      grad_gnorm: 39.999996185302734
      policy_entropy: 0.25214558839797974
      policy_loss: -7.338140487670898
      var_gnorm: 25.101301193237305
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 7727989.0
    num_steps_sampled: 25000
    num_steps_trained: 25000
    wait_time_ms: 72.287
  iterations_since_restore: 5
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 56.1246874332428
  time_this_iter_s: 8.485323905944824
  time_total_s: 56.1246874332428
  timestamp: 1594858346
  timesteps_since_restore: 25000
  timesteps_this_iter: 5000
  timesteps_total: 25000
  training_iteration: 5
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 10.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 56 s, 5 iter, 25000 ts, -7.33e+06 rew

agent-1: -5921.166575265423
agent-2: -1496412.550165983
agent-3: -1255184.9256782033
agent-4: -563361.6396919575
agent-5: -627867.8006640025
Extrinsic Rewards:
-804
-14958
-13413
-7598
-8749
Sum Reward: -45522
Avg Reward: -9104.4
Min Reward: -14958
Max Reward: -804
Gini Coefficient: -0.299837441237204
20:20 Ratio: 0.053750501403931006
Max-min Ratio: 0.053750501403931006
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-12-35
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -1391648.6626637413
  episode_reward_mean: -6650426.58424031
  episode_reward_min: -13984699.942280233
  episodes_this_iter: 1
  episodes_total: 5
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.749
    dispatch_time_ms: 6.902
    learner:
      cur_lr: 0.0013583350228145719
      grad_gnorm: 39.99998092651367
      policy_entropy: 0.8829045295715332
      policy_loss: -0.20017199218273163
      var_gnorm: 25.0595760345459
      vf_explained_var: -1.0
      vf_loss: 592.927978515625
    num_steps_sampled: 30000
    num_steps_trained: 30000
    wait_time_ms: 74.065
  iterations_since_restore: 6
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 64.38726019859314
  time_this_iter_s: 8.262572765350342
  time_total_s: 64.38726019859314
  timestamp: 1594858355
  timesteps_since_restore: 30000
  timesteps_this_iter: 5000
  timesteps_total: 30000
  training_iteration: 6
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 10.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 64 s, 6 iter, 30000 ts, -6.65e+06 rew

agent-1: -590757.1584564974
agent-2: -450966.8666573409
agent-3: -1303603.9617536257
agent-4: -17613.580057984942
agent-5: -1413408.4629394691
Extrinsic Rewards:
-6457
-4520
-10862
-868
-10659
Sum Reward: -33366
Avg Reward: -6673.2
Min Reward: -10862
Max Reward: -868
Gini Coefficient: -0.31321704729365224
20:20 Ratio: 0.07991161848646658
Max-min Ratio: 0.07991161848646658
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-12-43
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -1391648.6626637413
  episode_reward_mean: -6171413.825177743
  episode_reward_min: -13984699.942280233
  episodes_this_iter: 1
  episodes_total: 6
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.661
    dispatch_time_ms: 6.651
    learner:
      cur_lr: 0.001358001958578825
      grad_gnorm: 39.999996185302734
      policy_entropy: 47.49313735961914
      policy_loss: -57055.28515625
      var_gnorm: 25.19016456604004
      vf_explained_var: -0.0001703500747680664
      vf_loss: 105455880.0
    num_steps_sampled: 35000
    num_steps_trained: 35000
    wait_time_ms: 73.83
  iterations_since_restore: 7
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 72.71157145500183
  time_this_iter_s: 8.324311256408691
  time_total_s: 72.71157145500183
  timestamp: 1594858363
  timesteps_since_restore: 35000
  timesteps_this_iter: 5000
  timesteps_total: 35000
  training_iteration: 7
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 10.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 72 s, 7 iter, 35000 ts, -6.17e+06 rew

agent-1: -21890.58404766459
agent-2: -334360.2371536109
agent-3: -123661.48071090618
agent-4: -490021.11067377566
agent-5: -425798.92621380487
Extrinsic Rewards:
-1024
-4252
-2226
-5266
-4864
Sum Reward: -17632
Avg Reward: -3526.4
Min Reward: -5266
Max Reward: -1024
Gini Coefficient: -0.25231397459165156
20:20 Ratio: 0.19445499430307633
Max-min Ratio: 0.19445499430307633
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-12-52
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -1391648.6626637413
  episode_reward_mean: -5489173.612838031
  episode_reward_min: -13984699.942280233
  episodes_this_iter: 1
  episodes_total: 7
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.553
    dispatch_time_ms: 10.077
    learner:
      cur_lr: 0.0013576690107584
      grad_gnorm: 40.0
      policy_entropy: 2.2575299739837646
      policy_loss: -9.078866958618164
      var_gnorm: 25.628368377685547
      vf_explained_var: -0.0909888744354248
      vf_loss: 25835.6484375
    num_steps_sampled: 40000
    num_steps_trained: 40000
    wait_time_ms: 71.136
  iterations_since_restore: 8
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 81.25174355506897
  time_this_iter_s: 8.540172100067139
  time_total_s: 81.25174355506897
  timestamp: 1594858372
  timesteps_since_restore: 40000
  timesteps_this_iter: 5000
  timesteps_total: 40000
  training_iteration: 8
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 10.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 81 s, 8 iter, 40000 ts, -5.49e+06 rew

agent-1: -136321.1005926794
agent-2: -252662.5246431155
agent-3: -310202.66924172634
agent-4: -300022.93819325656
agent-5: -373000.37867360865
Extrinsic Rewards:
-3519
-4880
-4123
-5006
-5547
Sum Reward: -23075
Avg Reward: -4615.0
Min Reward: -5547
Max Reward: -3519
Gini Coefficient: -0.08561646803900325
20:20 Ratio: 0.6343969713358573
Max-min Ratio: 0.6343969713358573
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-13-00
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -1372209.6113443861
  episode_reward_mean: -4974553.112651326
  episode_reward_min: -13984699.942280233
  episodes_this_iter: 1
  episodes_total: 8
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.682
    dispatch_time_ms: 8.152
    learner:
      cur_lr: 0.001357335946522653
      grad_gnorm: 40.0
      policy_entropy: 0.3322775065898895
      policy_loss: 0.12851783633232117
      var_gnorm: 25.68975257873535
      vf_explained_var: 0.0
      vf_loss: 404.15081787109375
    num_steps_sampled: 45000
    num_steps_trained: 45000
    wait_time_ms: 71.118
  iterations_since_restore: 9
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 89.57336378097534
  time_this_iter_s: 8.321620225906372
  time_total_s: 89.57336378097534
  timestamp: 1594858380
  timesteps_since_restore: 45000
  timesteps_this_iter: 5000
  timesteps_total: 45000
  training_iteration: 9
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 10.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 89 s, 9 iter, 45000 ts, -4.97e+06 rew

agent-1: -191.99079847915897
agent-2: -334.23859806059266
agent-3: -526.5136022880944
agent-4: -334.23859806059266
agent-5: 4.0
Extrinsic Rewards:
2
0
-1
0
4
Sum Reward: 5
Avg Reward: 1.0
Min Reward: -1
Max Reward: 4
Gini Coefficient: 0.96
20:20 Ratio: -4.0
Max-min Ratio: -4.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-13-08
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -1382.9815968884402
  episode_reward_mean: -4421978.653645278
  episode_reward_min: -13984699.942280233
  episodes_this_iter: 1
  episodes_total: 9
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 3.241
    dispatch_time_ms: 8.468
    learner:
      cur_lr: 0.001357002998702228
      grad_gnorm: 40.0
      policy_entropy: 0.44475775957107544
      policy_loss: 0.08631686866283417
      var_gnorm: 25.630233764648438
      vf_explained_var: -0.0002796649932861328
      vf_loss: 470.7206115722656
    num_steps_sampled: 50000
    num_steps_trained: 50000
    wait_time_ms: 71.652
  iterations_since_restore: 10
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 97.7822802066803
  time_this_iter_s: 8.208916425704956
  time_total_s: 97.7822802066803
  timestamp: 1594858388
  timesteps_since_restore: 50000
  timesteps_this_iter: 5000
  timesteps_total: 50000
  training_iteration: 10
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 10.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 97 s, 10 iter, 50000 ts, -4.42e+06 rew

agent-1: -6868.311883374557
agent-2: -395.75145258006063
agent-3: -42432.85009504852
agent-4: -4816.611726033118
agent-5: -36332.73947839966
Extrinsic Rewards:
-101
-5
-251
-53
-201
Sum Reward: -611
Avg Reward: -122.2
Min Reward: -251
Max Reward: -5
Gini Coefficient: -0.41898527004909986
20:20 Ratio: 0.0199203187250996
Max-min Ratio: 0.0199203187250996
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-13-17
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -1382.9815968884402
  episode_reward_mean: -3988865.414744293
  episode_reward_min: -13984699.942280233
  episodes_this_iter: 1
  episodes_total: 10
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.597
    dispatch_time_ms: 8.381
    learner:
      cur_lr: 0.001356670050881803
      grad_gnorm: 40.0
      policy_entropy: 0.11119052767753601
      policy_loss: 0.03205477073788643
      var_gnorm: 25.394929885864258
      vf_explained_var: 0.0
      vf_loss: 304.9432067871094
    num_steps_sampled: 55000
    num_steps_trained: 55000
    wait_time_ms: 75.888
  iterations_since_restore: 11
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 106.14405846595764
  time_this_iter_s: 8.361778259277344
  time_total_s: 106.14405846595764
  timestamp: 1594858397
  timesteps_since_restore: 55000
  timesteps_this_iter: 5000
  timesteps_total: 55000
  training_iteration: 11
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 10.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 106 s, 11 iter, 55000 ts, -3.99e+06 rew

agent-1: -149.99999999837684
agent-2: -149.99999999837684
agent-3: -149.99999999837684
agent-4: -149.99999999837684
agent-5: 3.0
Extrinsic Rewards:
0
0
0
0
3
Sum Reward: 3
Avg Reward: 0.6
Min Reward: 0
Max Reward: 3
Gini Coefficient: 0.8
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-13-25
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -596.9999999935155
  episode_reward_mean: -3626295.558858448
  episode_reward_min: -13984699.942280233
  episodes_this_iter: 1
  episodes_total: 11
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 3.235
    dispatch_time_ms: 9.09
    learner:
      cur_lr: 0.0013563369866460562
      grad_gnorm: 40.0
      policy_entropy: 0.10664675384759903
      policy_loss: 0.024272169917821884
      var_gnorm: 25.06426239013672
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 189.6189727783203
    num_steps_sampled: 60000
    num_steps_trained: 60000
    wait_time_ms: 70.146
  iterations_since_restore: 12
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 114.38132452964783
  time_this_iter_s: 8.237266063690186
  time_total_s: 114.38132452964783
  timestamp: 1594858405
  timesteps_since_restore: 60000
  timesteps_this_iter: 5000
  timesteps_total: 60000
  training_iteration: 12
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 11.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 114 s, 12 iter, 60000 ts, -3.63e+06 rew

agent-1: -299.9999999967528
agent-2: -99.2499999988536
agent-3: -500.9999997835486
agent-4: 2.75
agent-5: -299.9999999967528
Extrinsic Rewards:
0
2
-1
4
0
Sum Reward: 5
Avg Reward: 1.0
Min Reward: -1
Max Reward: 4
Gini Coefficient: 0.96
20:20 Ratio: -4.0
Max-min Ratio: -4.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-13-33
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -596.9999999935155
  episode_reward_mean: -3324204.0539535587
  episode_reward_min: -13984699.942280233
  episodes_this_iter: 1
  episodes_total: 12
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.714
    dispatch_time_ms: 9.224
    learner:
      cur_lr: 0.0013560040388256311
      grad_gnorm: 40.0
      policy_entropy: 0.11330161243677139
      policy_loss: 0.020337678492069244
      var_gnorm: 24.85729217529297
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 118.20221710205078
    num_steps_sampled: 65000
    num_steps_trained: 65000
    wait_time_ms: 69.753
  iterations_since_restore: 13
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 122.67456245422363
  time_this_iter_s: 8.293237924575806
  time_total_s: 122.67456245422363
  timestamp: 1594858413
  timesteps_since_restore: 65000
  timesteps_this_iter: 5000
  timesteps_total: 65000
  training_iteration: 13
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 11.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 122 s, 13 iter, 65000 ts, -3.32e+06 rew

agent-1: -46.99999997746306
agent-2: -497.2780960489674
agent-3: -9749.113710170626
agent-4: -349.99999991158137
agent-5: -349.99999991158137
Extrinsic Rewards:
3
-1
-46
0
0
Sum Reward: -44
Avg Reward: -8.8
Min Reward: -46
Max Reward: 3
Gini Coefficient: -0.9
20:20 Ratio: -0.06521739130434782
Max-min Ratio: -0.06521739130434782
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-13-41
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -596.9999999935155
  episode_reward_mean: -3069341.695326825
  episode_reward_min: -13984699.942280233
  episodes_this_iter: 1
  episodes_total: 13
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 3.832
    dispatch_time_ms: 9.824
    learner:
      cur_lr: 0.0013556709745898843
      grad_gnorm: 40.0
      policy_entropy: 0.106315977871418
      policy_loss: 0.016283545643091202
      var_gnorm: 24.779132843017578
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 87.36836242675781
    num_steps_sampled: 70000
    num_steps_trained: 70000
    wait_time_ms: 69.764
  iterations_since_restore: 14
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 130.85732674598694
  time_this_iter_s: 8.182764291763306
  time_total_s: 130.85732674598694
  timestamp: 1594858421
  timesteps_since_restore: 70000
  timesteps_this_iter: 5000
  timesteps_total: 70000
  training_iteration: 14
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 11.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 130 s, 14 iter, 70000 ts, -3.07e+06 rew

agent-1: 0.0
agent-2: -150.98898900002328
agent-3: 0.0
agent-4: 0.0
agent-5: -9999.269603668215
Extrinsic Rewards:
0
-1
0
0
-50
Sum Reward: -51
Avg Reward: -10.2
Min Reward: -50
Max Reward: 0
Gini Coefficient: -0.792156862745098
20:20 Ratio: -0.0
Max-min Ratio: -0.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-13-50
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -596.9999999935155
  episode_reward_mean: -2850828.021274385
  episode_reward_min: -13984699.942280233
  episodes_this_iter: 1
  episodes_total: 14
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.737
    dispatch_time_ms: 9.931
    learner:
      cur_lr: 0.0013553380267694592
      grad_gnorm: 39.999996185302734
      policy_entropy: 0.09925944358110428
      policy_loss: -0.7530436515808105
      var_gnorm: 24.68866539001465
      vf_explained_var: 0.0
      vf_loss: 1107333.75
    num_steps_sampled: 75000
    num_steps_trained: 75000
    wait_time_ms: 69.777
  iterations_since_restore: 15
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 139.08243536949158
  time_this_iter_s: 8.225108623504639
  time_total_s: 139.08243536949158
  timestamp: 1594858430
  timesteps_since_restore: 75000
  timesteps_this_iter: 5000
  timesteps_total: 75000
  training_iteration: 15
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 11.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 139 s, 15 iter, 75000 ts, -2.85e+06 rew

agent-1: -199.99999999780377
agent-2: 4.0
agent-3: -350.99977687827743
agent-4: -199.99999999780377
agent-5: -10199.985199735896
Extrinsic Rewards:
0
4
-1
0
-50
Sum Reward: -47
Avg Reward: -9.4
Min Reward: -50
Max Reward: 4
Gini Coefficient: -0.9276595744680851
20:20 Ratio: -0.08
Max-min Ratio: -0.08
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-13-58
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -596.9999999935155
  episode_reward_mean: -2661502.618854533
  episode_reward_min: -13984699.942280233
  episodes_this_iter: 1
  episodes_total: 15
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.799
    dispatch_time_ms: 6.71
    learner:
      cur_lr: 0.0013550049625337124
      grad_gnorm: 40.0
      policy_entropy: 0.1384497731924057
      policy_loss: 0.013568787835538387
      var_gnorm: 24.60359001159668
      vf_explained_var: 0.0
      vf_loss: 30.93962860107422
    num_steps_sampled: 80000
    num_steps_trained: 80000
    wait_time_ms: 73.656
  iterations_since_restore: 16
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 147.35010766983032
  time_this_iter_s: 8.267672300338745
  time_total_s: 147.35010766983032
  timestamp: 1594858438
  timesteps_since_restore: 80000
  timesteps_this_iter: 5000
  timesteps_total: 80000
  training_iteration: 16
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 11.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 147 s, 16 iter, 80000 ts, -2.66e+06 rew

agent-1: -199.99999999784504
agent-2: -199.99999999784504
agent-3: -199.99999999784504
agent-4: 2.96875
agent-5: -99.03124999890878
Extrinsic Rewards:
0
0
0
3
1
Sum Reward: 4
Avg Reward: 0.8
Min Reward: 0
Max Reward: 3
Gini Coefficient: 0.7
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-14-06
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -596.9999999935155
  episode_reward_mean: -2495202.2090823743
  episode_reward_min: -13984699.942280233
  episodes_this_iter: 1
  episodes_total: 16
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.84
    dispatch_time_ms: 9.853
    learner:
      cur_lr: 0.0013546720147132874
      grad_gnorm: 39.999996185302734
      policy_entropy: 0.12110044807195663
      policy_loss: 0.005946783348917961
      var_gnorm: 24.539400100708008
      vf_explained_var: 0.0
      vf_loss: 8.02326488494873
    num_steps_sampled: 85000
    num_steps_trained: 85000
    wait_time_ms: 69.192
  iterations_since_restore: 17
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 155.65073823928833
  time_this_iter_s: 8.300630569458008
  time_total_s: 155.65073823928833
  timestamp: 1594858446
  timesteps_since_restore: 85000
  timesteps_this_iter: 5000
  timesteps_total: 85000
  training_iteration: 17
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 11.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 155 s, 17 iter, 85000 ts, -2.5e+06 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-14-15
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -2348425.6085481173
  episode_reward_min: -13984699.942280233
  episodes_this_iter: 1
  episodes_total: 17
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.523
    dispatch_time_ms: 10.394
    learner:
      cur_lr: 0.0013543389504775405
      grad_gnorm: 2.5713820457458496
      policy_entropy: 0.1114947572350502
      policy_loss: 0.00013426625810097903
      var_gnorm: 24.519756317138672
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 0.0043870978988707066
    num_steps_sampled: 90000
    num_steps_trained: 90000
    wait_time_ms: 71.597
  iterations_since_restore: 18
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 163.91095113754272
  time_this_iter_s: 8.260212898254395
  time_total_s: 163.91095113754272
  timestamp: 1594858455
  timesteps_since_restore: 90000
  timesteps_this_iter: 5000
  timesteps_total: 90000
  training_iteration: 18
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 11.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 163 s, 18 iter, 90000 ts, -2.35e+06 rew

agent-1: 2.0
agent-2: -149.99999999841847
agent-3: -149.99999999841847
agent-4: -48.99999999948169
agent-5: -149.99999999841847
Extrinsic Rewards:
2
0
0
1
0
Sum Reward: 3
Avg Reward: 0.6
Min Reward: 0
Max Reward: 2
Gini Coefficient: 0.6666666666666666
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-14-23
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -2217985.130295444
  episode_reward_min: -13984699.942280233
  episodes_this_iter: 1
  episodes_total: 18
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.555
    dispatch_time_ms: 9.138
    learner:
      cur_lr: 0.0013540060026571155
      grad_gnorm: 1.3198344707489014
      policy_entropy: 0.11701858788728714
      policy_loss: 8.835556218400598e-05
      var_gnorm: 24.519563674926758
      vf_explained_var: 1.1920928955078125e-07
      vf_loss: 0.0011556990211829543
    num_steps_sampled: 95000
    num_steps_trained: 95000
    wait_time_ms: 71.285
  iterations_since_restore: 19
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 172.14473581314087
  time_this_iter_s: 8.233784675598145
  time_total_s: 172.14473581314087
  timestamp: 1594858463
  timesteps_since_restore: 95000
  timesteps_this_iter: 5000
  timesteps_total: 95000
  training_iteration: 19
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 12.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 172 s, 19 iter, 95000 ts, -2.22e+06 rew

agent-1: -149.99999999840443
agent-2: -149.99999999840443
agent-3: 3.0
agent-4: -149.99999999840443
agent-5: -149.99999999840443
Extrinsic Rewards:
0
0
3
0
0
Sum Reward: 3
Avg Reward: 0.6
Min Reward: 0
Max Reward: 3
Gini Coefficient: 0.8
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-14-31
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -2101280.4918588414
  episode_reward_min: -13984699.942280233
  episodes_this_iter: 1
  episodes_total: 19
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.942
    dispatch_time_ms: 8.301
    learner:
      cur_lr: 0.0013536730548366904
      grad_gnorm: 40.000003814697266
      policy_entropy: 0.1188880205154419
      policy_loss: -0.12897032499313354
      var_gnorm: 24.519906997680664
      vf_explained_var: 0.0
      vf_loss: 7025.93212890625
    num_steps_sampled: 100000
    num_steps_trained: 100000
    wait_time_ms: 72.479
  iterations_since_restore: 20
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 180.40880584716797
  time_this_iter_s: 8.2640700340271
  time_total_s: 180.40880584716797
  timestamp: 1594858471
  timesteps_since_restore: 100000
  timesteps_this_iter: 5000
  timesteps_total: 100000
  training_iteration: 20
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 12.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 180 s, 20 iter, 100000 ts, -2.1e+06 rew

agent-1: -9999.339949679608
agent-2: 0.0
agent-3: 0.0
agent-4: -150.99004949265733
agent-5: 0.0
Extrinsic Rewards:
-50
0
0
-1
0
Sum Reward: -51
Avg Reward: -10.2
Min Reward: -50
Max Reward: 0
Gini Coefficient: -0.792156862745098
20:20 Ratio: -0.0
Max-min Ratio: -0.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-14-39
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -1996723.9837658578
  episode_reward_min: -13984699.942280233
  episodes_this_iter: 1
  episodes_total: 20
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.464
    dispatch_time_ms: 7.9
    learner:
      cur_lr: 0.0013533399906009436
      grad_gnorm: 6.219924449920654
      policy_entropy: 0.17038759589195251
      policy_loss: 0.000628124107606709
      var_gnorm: 24.5179443359375
      vf_explained_var: 1.7881393432617188e-07
      vf_loss: 0.02566699869930744
    num_steps_sampled: 105000
    num_steps_trained: 105000
    wait_time_ms: 70.654
  iterations_since_restore: 21
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 188.6688268184662
  time_this_iter_s: 8.260020971298218
  time_total_s: 188.6688268184662
  timestamp: 1594858479
  timesteps_since_restore: 105000
  timesteps_this_iter: 5000
  timesteps_total: 105000
  training_iteration: 21
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 12.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 188 s, 21 iter, 105000 ts, -2e+06 rew

agent-1: -49.249999999427196
agent-2: -299.9999999967949
agent-3: -299.9999999967949
agent-4: -149.03124999839068
agent-5: 1.71875
Extrinsic Rewards:
2
0
0
1
3
Sum Reward: 6
Avg Reward: 1.2
Min Reward: 0
Max Reward: 3
Gini Coefficient: 0.5333333333333333
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-14-48
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -1901679.8208484352
  episode_reward_min: -13984699.942280233
  episodes_this_iter: 1
  episodes_total: 21
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.834
    dispatch_time_ms: 10.051
    learner:
      cur_lr: 0.0013530070427805185
      grad_gnorm: 40.000003814697266
      policy_entropy: 0.17770890891551971
      policy_loss: -0.09802751988172531
      var_gnorm: 24.518390655517578
      vf_explained_var: 0.0
      vf_loss: 1292.2724609375
    num_steps_sampled: 110000
    num_steps_trained: 110000
    wait_time_ms: 68.982
  iterations_since_restore: 22
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 196.90539360046387
  time_this_iter_s: 8.23656678199768
  time_total_s: 196.90539360046387
  timestamp: 1594858488
  timesteps_since_restore: 110000
  timesteps_this_iter: 5000
  timesteps_total: 110000
  training_iteration: 22
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 12.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 196 s, 22 iter, 110000 ts, -1.9e+06 rew

agent-1: -199.9999873971772
agent-2: -199.9999873971772
agent-3: 0.75
agent-4: -10199.171036314072
agent-5: -150.23747785861246
Extrinsic Rewards:
0
0
2
-50
1
Sum Reward: -47
Avg Reward: -9.4
Min Reward: -50
Max Reward: 2
Gini Coefficient: -0.8936170212765957
20:20 Ratio: -0.04
Max-min Ratio: -0.04
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-14-56
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -1815728.4043775501
  episode_reward_min: -13984699.942280233
  episodes_this_iter: 1
  episodes_total: 22
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 3.402
    dispatch_time_ms: 10.39
    learner:
      cur_lr: 0.0013526739785447717
      grad_gnorm: 17.87831687927246
      policy_entropy: 0.17015522718429565
      policy_loss: 0.0012177644530311227
      var_gnorm: 24.5180721282959
      vf_explained_var: 0.0
      vf_loss: 0.21207700669765472
    num_steps_sampled: 115000
    num_steps_trained: 115000
    wait_time_ms: 70.213
  iterations_since_restore: 23
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 205.15708017349243
  time_this_iter_s: 8.251686573028564
  time_total_s: 205.15708017349243
  timestamp: 1594858496
  timesteps_since_restore: 115000
  timesteps_this_iter: 5000
  timesteps_total: 115000
  training_iteration: 23
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 12.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 205 s, 23 iter, 115000 ts, -1.82e+06 rew

agent-1: -207.61721502342408
agent-2: -99.99999999894987
agent-3: 2.0
agent-4: -99.99999999894987
agent-5: -7222.275263289072
Extrinsic Rewards:
-1
0
2
0
-50
Sum Reward: -49
Avg Reward: -9.8
Min Reward: -50
Max Reward: 2
Gini Coefficient: -0.8571428571428571
20:20 Ratio: -0.04
Max-min Ratio: -0.04
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-15-04
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -1737115.338642801
  episode_reward_min: -13984699.942280233
  episodes_this_iter: 1
  episodes_total: 23
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.497
    dispatch_time_ms: 6.978
    learner:
      cur_lr: 0.0013523410307243466
      grad_gnorm: 29.15793228149414
      policy_entropy: 0.171256422996521
      policy_loss: 0.002178081776946783
      var_gnorm: 24.51887321472168
      vf_explained_var: 0.0
      vf_loss: 0.5734172463417053
    num_steps_sampled: 120000
    num_steps_trained: 120000
    wait_time_ms: 75.89
  iterations_since_restore: 24
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 213.45632410049438
  time_this_iter_s: 8.299243927001953
  time_total_s: 213.45632410049438
  timestamp: 1594858504
  timesteps_since_restore: 120000
  timesteps_this_iter: 5000
  timesteps_total: 120000
  training_iteration: 24
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 12.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 213 s, 24 iter, 120000 ts, -1.74e+06 rew

agent-1: -250.5674906994517
agent-2: -10078.37438498855
agent-3: -10088.830364096659
agent-4: -239.96912323643232
agent-5: 2.0
Extrinsic Rewards:
-1
-50
-50
-1
2
Sum Reward: -100
Avg Reward: -20.0
Min Reward: -50
Max Reward: 2
Gini Coefficient: -0.612
20:20 Ratio: -0.04
Max-min Ratio: -0.04
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-15-13
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -1665596.1887561437
  episode_reward_min: -13984699.942280233
  episodes_this_iter: 1
  episodes_total: 24
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.915
    dispatch_time_ms: 7.51
    learner:
      cur_lr: 0.0013520079664885998
      grad_gnorm: 40.0
      policy_entropy: 0.20774264633655548
      policy_loss: -179.44833374023438
      var_gnorm: 24.520065307617188
      vf_explained_var: 1.1920928955078125e-07
      vf_loss: 453.4446105957031
    num_steps_sampled: 125000
    num_steps_trained: 125000
    wait_time_ms: 71.737
  iterations_since_restore: 25
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 221.68480014801025
  time_this_iter_s: 8.22847604751587
  time_total_s: 221.68480014801025
  timestamp: 1594858513
  timesteps_since_restore: 125000
  timesteps_this_iter: 5000
  timesteps_total: 125000
  training_iteration: 25
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 13.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 221 s, 25 iter, 125000 ts, -1.67e+06 rew

agent-1: -97.35639144155944
agent-2: -20099.999943771796
agent-3: -292.06917348018226
agent-4: -97.35639144155944
agent-5: -97.35639144155944
Extrinsic Rewards:
0
-100
0
0
0
Sum Reward: -100
Avg Reward: -20.0
Min Reward: -100
Max Reward: 0
Gini Coefficient: -0.8
20:20 Ratio: -0.0
Max-min Ratio: -0.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-15-21
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -1599799.7067375607
  episode_reward_min: -13984699.942280233
  episodes_this_iter: 1
  episodes_total: 25
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 3.205
    dispatch_time_ms: 10.257
    learner:
      cur_lr: 0.0013516750186681747
      grad_gnorm: 0.4266987442970276
      policy_entropy: 0.0335284098982811
      policy_loss: -1.3680229130841326e-05
      var_gnorm: 24.533300399780273
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 0.0001207951208925806
    num_steps_sampled: 130000
    num_steps_trained: 130000
    wait_time_ms: 67.805
  iterations_since_restore: 26
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 229.9168176651001
  time_this_iter_s: 8.232017517089844
  time_total_s: 229.9168176651001
  timestamp: 1594858521
  timesteps_since_restore: 130000
  timesteps_this_iter: 5000
  timesteps_total: 130000
  training_iteration: 26
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 13.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 229 s, 26 iter, 130000 ts, -1.6e+06 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: -200.99991395958716
Extrinsic Rewards:
0
0
0
0
-1
Sum Reward: -1
Avg Reward: -0.2
Min Reward: -1
Max Reward: 0
Gini Coefficient: -0.8
20:20 Ratio: -0.0
Max-min Ratio: -0.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-15-29
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -1538276.6795520375
  episode_reward_min: -13984699.942280233
  episodes_this_iter: 1
  episodes_total: 26
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 3.044
    dispatch_time_ms: 8.9
    learner:
      cur_lr: 0.0013513419544324279
      grad_gnorm: 4.164653301239014
      policy_entropy: 0.03361276909708977
      policy_loss: 6.521829345729202e-05
      var_gnorm: 24.533174514770508
      vf_explained_var: 0.0
      vf_loss: 0.011506211943924427
    num_steps_sampled: 135000
    num_steps_trained: 135000
    wait_time_ms: 70.398
  iterations_since_restore: 27
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 238.16443824768066
  time_this_iter_s: 8.247620582580566
  time_total_s: 238.16443824768066
  timestamp: 1594858529
  timesteps_since_restore: 135000
  timesteps_this_iter: 5000
  timesteps_total: 135000
  training_iteration: 27
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 13.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 238 s, 27 iter, 135000 ts, -1.54e+06 rew

agent-1: -199.99999999780377
agent-2: -199.99999999780377
agent-3: -199.99999999780377
agent-4: 4.0
agent-5: -199.99999999780377
Extrinsic Rewards:
0
0
0
4
0
Sum Reward: 4
Avg Reward: 0.8
Min Reward: 0
Max Reward: 4
Gini Coefficient: 0.8
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-15-37
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -1481332.9506797397
  episode_reward_min: -13984699.942280233
  episodes_this_iter: 1
  episodes_total: 27
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.42
    dispatch_time_ms: 9.958
    learner:
      cur_lr: 0.0013510090066120028
      grad_gnorm: 0.9942536950111389
      policy_entropy: 0.033599115908145905
      policy_loss: 1.3180426321923733e-05
      var_gnorm: 24.53325080871582
      vf_explained_var: 1.7881393432617188e-07
      vf_loss: 0.0006559198955073953
    num_steps_sampled: 140000
    num_steps_trained: 140000
    wait_time_ms: 71.909
  iterations_since_restore: 28
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 246.45062685012817
  time_this_iter_s: 8.28618860244751
  time_total_s: 246.45062685012817
  timestamp: 1594858537
  timesteps_since_restore: 140000
  timesteps_this_iter: 5000
  timesteps_total: 140000
  training_iteration: 28
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 13.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 246 s, 28 iter, 140000 ts, -1.48e+06 rew

agent-1: -98.9999999988954
agent-2: 3.0
agent-3: -199.999999997859
agent-4: -199.999999997859
agent-5: -199.999999997859
Extrinsic Rewards:
1
3
0
0
0
Sum Reward: 4
Avg Reward: 0.8
Min Reward: 0
Max Reward: 3
Gini Coefficient: 0.7
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-15-46
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -1428453.0595840344
  episode_reward_min: -13984699.942280233
  episodes_this_iter: 1
  episodes_total: 28
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.605
    dispatch_time_ms: 8.573
    learner:
      cur_lr: 0.001350675942376256
      grad_gnorm: 0.060969334095716476
      policy_entropy: 0.03370007500052452
      policy_loss: 4.783356871485012e-06
      var_gnorm: 24.533245086669922
      vf_explained_var: 0.0
      vf_loss: 2.4661455881869188e-06
    num_steps_sampled: 145000
    num_steps_trained: 145000
    wait_time_ms: 73.22
  iterations_since_restore: 29
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 254.76064586639404
  time_this_iter_s: 8.31001901626587
  time_total_s: 254.76064586639404
  timestamp: 1594858546
  timesteps_since_restore: 145000
  timesteps_this_iter: 5000
  timesteps_total: 145000
  training_iteration: 29
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 13.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 254 s, 29 iter, 145000 ts, -1.43e+06 rew

agent-1: -149.99999999840443
agent-2: -149.99999999840443
agent-3: -149.99999999840443
agent-4: -149.99999999840443
agent-5: 3.0
Extrinsic Rewards:
0
0
0
0
3
Sum Reward: 3
Avg Reward: 0.6
Min Reward: 0
Max Reward: 3
Gini Coefficient: 0.8
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-15-54
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -1379216.6437363087
  episode_reward_min: -13984699.942280233
  episodes_this_iter: 1
  episodes_total: 29
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.8
    dispatch_time_ms: 8.15
    learner:
      cur_lr: 0.001350342994555831
      grad_gnorm: 1.6653366088867188
      policy_entropy: 0.033834271132946014
      policy_loss: 1.0646640475897584e-06
      var_gnorm: 24.533172607421875
      vf_explained_var: 1.1920928955078125e-07
      vf_loss: 0.0018401328707113862
    num_steps_sampled: 150000
    num_steps_trained: 150000
    wait_time_ms: 73.508
  iterations_since_restore: 30
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 262.98113894462585
  time_this_iter_s: 8.220493078231812
  time_total_s: 262.98113894462585
  timestamp: 1594858554
  timesteps_since_restore: 150000
  timesteps_this_iter: 5000
  timesteps_total: 150000
  training_iteration: 30
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 13.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 262 s, 30 iter, 150000 ts, -1.38e+06 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-16-02
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -1333242.7556117652
  episode_reward_min: -13984699.942280233
  episodes_this_iter: 1
  episodes_total: 30
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.578
    dispatch_time_ms: 8.89
    learner:
      cur_lr: 0.001350010046735406
      grad_gnorm: 0.6430982947349548
      policy_entropy: 0.03383803740143776
      policy_loss: 5.1340917707420886e-05
      var_gnorm: 24.533180236816406
      vf_explained_var: 0.0
      vf_loss: 0.000274263002211228
    num_steps_sampled: 155000
    num_steps_trained: 155000
    wait_time_ms: 70.778
  iterations_since_restore: 31
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 271.20043540000916
  time_this_iter_s: 8.2192964553833
  time_total_s: 271.20043540000916
  timestamp: 1594858562
  timesteps_since_restore: 155000
  timesteps_this_iter: 5000
  timesteps_total: 155000
  training_iteration: 31
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 13.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 271 s, 31 iter, 155000 ts, -1.33e+06 rew

agent-1: 3.0
agent-2: -149.99999999840443
agent-3: -149.99999999840443
agent-4: -149.99999999840443
agent-5: -149.99999999840443
Extrinsic Rewards:
3
0
0
0
0
Sum Reward: 3
Avg Reward: 0.6
Min Reward: 0
Max Reward: 3
Gini Coefficient: 0.8
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-16-11
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -1290254.182850095
  episode_reward_min: -13984699.942280233
  episodes_this_iter: 1
  episodes_total: 31
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 3.14
    dispatch_time_ms: 7.745
    learner:
      cur_lr: 0.001349676982499659
      grad_gnorm: 40.0
      policy_entropy: 0.033963270485401154
      policy_loss: -0.023188335821032524
      var_gnorm: 24.533130645751953
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 2683.818603515625
    num_steps_sampled: 160000
    num_steps_trained: 160000
    wait_time_ms: 72.519
  iterations_since_restore: 32
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 279.4490065574646
  time_this_iter_s: 8.248571157455444
  time_total_s: 279.4490065574646
  timestamp: 1594858571
  timesteps_since_restore: 160000
  timesteps_this_iter: 5000
  timesteps_total: 160000
  training_iteration: 32
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 14.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 279 s, 32 iter, 160000 ts, -1.29e+06 rew

agent-1: -99.99999999894987
agent-2: 2.0
agent-3: -99.99999999894987
agent-4: -99.99999999894987
agent-5: -99.99999999894987
Extrinsic Rewards:
0
2
0
0
0
Sum Reward: 2
Avg Reward: 0.4
Min Reward: 0
Max Reward: 2
Gini Coefficient: 0.8
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-16-19
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -1249946.1771360296
  episode_reward_min: -13984699.942280233
  episodes_this_iter: 1
  episodes_total: 32
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 3.208
    dispatch_time_ms: 9.902
    learner:
      cur_lr: 0.001349344034679234
      grad_gnorm: 1.3569685220718384
      policy_entropy: 0.03395678475499153
      policy_loss: 3.8158712413860485e-05
      var_gnorm: 24.533117294311523
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 0.0012212905567139387
    num_steps_sampled: 165000
    num_steps_trained: 165000
    wait_time_ms: 69.459
  iterations_since_restore: 33
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 287.69262862205505
  time_this_iter_s: 8.243622064590454
  time_total_s: 287.69262862205505
  timestamp: 1594858579
  timesteps_since_restore: 165000
  timesteps_this_iter: 5000
  timesteps_total: 165000
  training_iteration: 33
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 14.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 287 s, 33 iter, 165000 ts, -1.25e+06 rew

agent-1: -98.99999999893653
agent-2: -199.99999999787352
agent-3: 3.0
agent-4: -199.99999999787352
agent-5: -199.99999999787352
Extrinsic Rewards:
1
0
3
0
0
Sum Reward: 4
Avg Reward: 0.8
Min Reward: 0
Max Reward: 3
Gini Coefficient: 0.7
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-16-27
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -1212090.1111622103
  episode_reward_min: -13984699.942280233
  episodes_this_iter: 1
  episodes_total: 33
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.721
    dispatch_time_ms: 5.515
    learner:
      cur_lr: 0.0013490109704434872
      grad_gnorm: 1.9381431341171265
      policy_entropy: 0.03407585248351097
      policy_loss: 3.715820412253379e-06
      var_gnorm: 24.533082962036133
      vf_explained_var: 0.0
      vf_loss: 0.0024923300370573997
    num_steps_sampled: 170000
    num_steps_trained: 170000
    wait_time_ms: 72.65
  iterations_since_restore: 34
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 295.92695808410645
  time_this_iter_s: 8.234329462051392
  time_total_s: 295.92695808410645
  timestamp: 1594858587
  timesteps_since_restore: 170000
  timesteps_this_iter: 5000
  timesteps_total: 170000
  training_iteration: 34
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 14.3/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 295 s, 34 iter, 170000 ts, -1.21e+06 rew

agent-1: -199.99999999787352
agent-2: 3.0
agent-3: -199.99999999787352
agent-4: -98.99999999893653
agent-5: -199.99999999787352
Extrinsic Rewards:
0
3
0
1
0
Sum Reward: 4
Avg Reward: 0.8
Min Reward: 0
Max Reward: 3
Gini Coefficient: 0.7
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-16-35
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -1176460.8725986157
  episode_reward_min: -13984699.942280233
  episodes_this_iter: 1
  episodes_total: 34
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.896
    dispatch_time_ms: 10.148
    learner:
      cur_lr: 0.0013486780226230621
      grad_gnorm: 0.8615826368331909
      policy_entropy: 0.03417820855975151
      policy_loss: -1.1633595931925811e-05
      var_gnorm: 24.533130645751953
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 0.0004925655666738749
    num_steps_sampled: 175000
    num_steps_trained: 175000
    wait_time_ms: 71.629
  iterations_since_restore: 35
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 304.2456567287445
  time_this_iter_s: 8.318698644638062
  time_total_s: 304.2456567287445
  timestamp: 1594858595
  timesteps_since_restore: 175000
  timesteps_this_iter: 5000
  timesteps_total: 175000
  training_iteration: 35
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 14.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 304 s, 35 iter, 175000 ts, -1.18e+06 rew

agent-1: -47.89881804350594
agent-2: -149.89881856022112
agent-3: -149.89881856022112
agent-4: -149.89881856022112
agent-5: -98.99999948118453
Extrinsic Rewards:
2
0
0
0
1
Sum Reward: 3
Avg Reward: 0.6
Min Reward: 0
Max Reward: 2
Gini Coefficient: 0.6666666666666666
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-16-44
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -1142864.7503893182
  episode_reward_min: -13984699.942280233
  episodes_this_iter: 1
  episodes_total: 35
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.496
    dispatch_time_ms: 7.426
    learner:
      cur_lr: 0.0013483449583873153
      grad_gnorm: 40.0
      policy_entropy: 0.03933913633227348
      policy_loss: -0.030301325023174286
      var_gnorm: 24.53250503540039
      vf_explained_var: 0.0
      vf_loss: 3494.82177734375
    num_steps_sampled: 180000
    num_steps_trained: 180000
    wait_time_ms: 74.182
  iterations_since_restore: 36
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 312.5187683105469
  time_this_iter_s: 8.273111581802368
  time_total_s: 312.5187683105469
  timestamp: 1594858604
  timesteps_since_restore: 180000
  timesteps_this_iter: 5000
  timesteps_total: 180000
  training_iteration: 36
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 14.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 312 s, 36 iter, 180000 ts, -1.14e+06 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-16-52
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -1111118.5073229482
  episode_reward_min: -13984699.942280233
  episodes_this_iter: 1
  episodes_total: 36
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.666
    dispatch_time_ms: 11.356
    learner:
      cur_lr: 0.0013480120105668902
      grad_gnorm: 0.31010037660598755
      policy_entropy: 0.03888858109712601
      policy_loss: -4.8397882892459165e-06
      var_gnorm: 24.532642364501953
      vf_explained_var: 0.0
      vf_loss: 6.384643347701058e-05
    num_steps_sampled: 185000
    num_steps_trained: 185000
    wait_time_ms: 69.548
  iterations_since_restore: 37
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 320.79875898361206
  time_this_iter_s: 8.279990673065186
  time_total_s: 320.79875898361206
  timestamp: 1594858612
  timesteps_since_restore: 185000
  timesteps_this_iter: 5000
  timesteps_total: 185000
  training_iteration: 37
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 14.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 320 s, 37 iter, 185000 ts, -1.11e+06 rew

agent-1: -299.9999999967948
agent-2: 4.0
agent-3: -299.9999999967948
agent-4: -299.9999999967948
agent-5: -97.9999999988953
Extrinsic Rewards:
0
4
0
0
2
Sum Reward: 6
Avg Reward: 1.2
Min Reward: 0
Max Reward: 4
Gini Coefficient: 0.6666666666666666
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-17-00
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -1081115.1422601657
  episode_reward_min: -13984699.942280233
  episodes_this_iter: 1
  episodes_total: 37
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.643
    dispatch_time_ms: 8.819
    learner:
      cur_lr: 0.0013476789463311434
      grad_gnorm: 0.2951647639274597
      policy_entropy: 0.03907273709774017
      policy_loss: 3.7157813039812027e-06
      var_gnorm: 24.5325927734375
      vf_explained_var: 0.0
      vf_loss: 5.780999345006421e-05
    num_steps_sampled: 190000
    num_steps_trained: 190000
    wait_time_ms: 71.848
  iterations_since_restore: 38
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 329.0797839164734
  time_this_iter_s: 8.281024932861328
  time_total_s: 329.0797839164734
  timestamp: 1594858620
  timesteps_since_restore: 190000
  timesteps_this_iter: 5000
  timesteps_total: 190000
  training_iteration: 38
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 14.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 329 s, 38 iter, 190000 ts, -1.08e+06 rew

agent-1: -149.99999999837684
agent-2: 3.0
agent-3: -149.99999999837684
agent-4: -149.99999999837684
agent-5: -149.99999999837684
Extrinsic Rewards:
0
3
0
0
0
Sum Reward: 3
Avg Reward: 0.6
Min Reward: 0
Max Reward: 3
Gini Coefficient: 0.8
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-17-09
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -1052680.4543059506
  episode_reward_min: -13984699.942280233
  episodes_this_iter: 1
  episodes_total: 38
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.401
    dispatch_time_ms: 5.629
    learner:
      cur_lr: 0.0013473459985107183
      grad_gnorm: 0.009245768189430237
      policy_entropy: 0.03944619372487068
      policy_loss: -2.4440529955427337e-07
      var_gnorm: 24.532533645629883
      vf_explained_var: 1.1920928955078125e-07
      vf_loss: 5.6835986583791964e-08
    num_steps_sampled: 195000
    num_steps_trained: 195000
    wait_time_ms: 71.713
  iterations_since_restore: 39
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 337.2209596633911
  time_this_iter_s: 8.141175746917725
  time_total_s: 337.2209596633911
  timestamp: 1594858629
  timesteps_since_restore: 195000
  timesteps_this_iter: 5000
  timesteps_total: 195000
  training_iteration: 39
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 15.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 337 s, 39 iter, 195000 ts, -1.05e+06 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-17-17
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -1025688.6477852851
  episode_reward_min: -13984699.942280233
  episodes_this_iter: 1
  episodes_total: 39
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.867
    dispatch_time_ms: 8.208
    learner:
      cur_lr: 0.0013470130506902933
      grad_gnorm: 40.0
      policy_entropy: 0.03981650248169899
      policy_loss: -0.021470755338668823
      var_gnorm: 24.532405853271484
      vf_explained_var: 5.960464477539063e-08
      vf_loss: 1614.551513671875
    num_steps_sampled: 200000
    num_steps_trained: 200000
    wait_time_ms: 72.134
  iterations_since_restore: 40
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 345.4581182003021
  time_this_iter_s: 8.23715853691101
  time_total_s: 345.4581182003021
  timestamp: 1594858637
  timesteps_since_restore: 200000
  timesteps_this_iter: 5000
  timesteps_total: 200000
  training_iteration: 40
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 15.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 345 s, 40 iter, 200000 ts, -1.03e+06 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-17-25
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -1000046.4315906533
  episode_reward_min: -13984699.942280233
  episodes_this_iter: 1
  episodes_total: 40
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.704
    dispatch_time_ms: 8.466
    learner:
      cur_lr: 0.0013466799864545465
      grad_gnorm: 2.8506321907043457
      policy_entropy: 0.03962533548474312
      policy_loss: -4.5425269490806386e-05
      var_gnorm: 24.5325927734375
      vf_explained_var: 0.0
      vf_loss: 0.005391858983784914
    num_steps_sampled: 205000
    num_steps_trained: 205000
    wait_time_ms: 71.939
  iterations_since_restore: 41
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 353.7342872619629
  time_this_iter_s: 8.276169061660767
  time_total_s: 353.7342872619629
  timestamp: 1594858645
  timesteps_since_restore: 205000
  timesteps_this_iter: 5000
  timesteps_total: 205000
  training_iteration: 41
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 15.3/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 353 s, 41 iter, 205000 ts, -1e+06 rew

agent-1: -199.99999999787352
agent-2: -199.99999999787352
agent-3: -199.99999999787352
agent-4: -98.99999999893653
agent-5: 3.0
Extrinsic Rewards:
0
0
0
1
3
Sum Reward: 4
Avg Reward: 0.8
Min Reward: 0
Max Reward: 3
Gini Coefficient: 0.7
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-17-33
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -975672.0308201491
  episode_reward_min: -13984699.942280233
  episodes_this_iter: 1
  episodes_total: 41
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.797
    dispatch_time_ms: 8.599
    learner:
      cur_lr: 0.0013463470386341214
      grad_gnorm: 3.8176090717315674
      policy_entropy: 0.04015873000025749
      policy_loss: 2.4814149583107792e-05
      var_gnorm: 24.532320022583008
      vf_explained_var: 0.0
      vf_loss: 0.009669984690845013
    num_steps_sampled: 210000
    num_steps_trained: 210000
    wait_time_ms: 71.533
  iterations_since_restore: 42
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 362.0853190422058
  time_this_iter_s: 8.35103178024292
  time_total_s: 362.0853190422058
  timestamp: 1594858653
  timesteps_since_restore: 210000
  timesteps_this_iter: 5000
  timesteps_total: 210000
  training_iteration: 42
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 13.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 362 s, 42 iter, 210000 ts, -9.76e+05 rew

agent-1: -49.99999999946836
agent-2: -49.99999999946836
agent-3: -49.99999999946836
agent-4: 1.0
agent-5: -49.99999999946836
Extrinsic Rewards:
0
0
0
1
0
Sum Reward: 1
Avg Reward: 0.2
Min Reward: 0
Max Reward: 1
Gini Coefficient: 0.8
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-17-42
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -952446.4824672886
  episode_reward_min: -13984699.942280233
  episodes_this_iter: 1
  episodes_total: 42
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.796
    dispatch_time_ms: 6.405
    learner:
      cur_lr: 0.0013460139743983746
      grad_gnorm: 35.63655471801758
      policy_entropy: 0.040680430829524994
      policy_loss: 0.0006324677960947156
      var_gnorm: 24.53377342224121
      vf_explained_var: 0.0
      vf_loss: 0.8426213264465332
    num_steps_sampled: 215000
    num_steps_trained: 215000
    wait_time_ms: 74.194
  iterations_since_restore: 43
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 370.22319078445435
  time_this_iter_s: 8.137871742248535
  time_total_s: 370.22319078445435
  timestamp: 1594858662
  timesteps_since_restore: 215000
  timesteps_this_iter: 5000
  timesteps_total: 215000
  training_iteration: 43
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 13.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 370 s, 43 iter, 215000 ts, -9.52e+05 rew

agent-1: -151.46874999830928
agent-2: 3.0
agent-3: -299.9999999967537
agent-4: -299.9999999967537
agent-5: -50.4687499994817
Extrinsic Rewards:
1
3
0
0
2
Sum Reward: 6
Avg Reward: 1.2
Min Reward: 0
Max Reward: 3
Gini Coefficient: 0.5333333333333333
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-17-50
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -930315.144212235
  episode_reward_min: -13984699.942280233
  episodes_this_iter: 1
  episodes_total: 43
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 3.354
    dispatch_time_ms: 7.363
    learner:
      cur_lr: 0.0013456810265779495
      grad_gnorm: 39.999996185302734
      policy_entropy: 0.039247337728738785
      policy_loss: -0.01158045418560505
      var_gnorm: 24.532445907592773
      vf_explained_var: 0.0
      vf_loss: 511.751953125
    num_steps_sampled: 220000
    num_steps_trained: 220000
    wait_time_ms: 71.127
  iterations_since_restore: 44
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 378.36746048927307
  time_this_iter_s: 8.144269704818726
  time_total_s: 378.36746048927307
  timestamp: 1594858670
  timesteps_since_restore: 220000
  timesteps_this_iter: 5000
  timesteps_total: 220000
  training_iteration: 44
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 13.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 378 s, 44 iter, 220000 ts, -9.3e+05 rew

agent-1: -150.99999996992744
agent-2: -9999.99999800522
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
-1
-50
0
0
0
Sum Reward: -51
Avg Reward: -10.2
Min Reward: -50
Max Reward: 0
Gini Coefficient: -0.792156862745098
20:20 Ratio: -0.0
Max-min Ratio: -0.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-17-58
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -909402.3227528202
  episode_reward_min: -13984699.942280233
  episodes_this_iter: 1
  episodes_total: 44
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.827
    dispatch_time_ms: 10.084
    learner:
      cur_lr: 0.0013453479623422027
      grad_gnorm: 1.0622353553771973
      policy_entropy: 0.039297644048929214
      policy_loss: -1.9911196432076395e-05
      var_gnorm: 24.532554626464844
      vf_explained_var: 0.0
      vf_loss: 0.0007486508111469448
    num_steps_sampled: 225000
    num_steps_trained: 225000
    wait_time_ms: 69.746
  iterations_since_restore: 45
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 386.519011259079
  time_this_iter_s: 8.151550769805908
  time_total_s: 386.519011259079
  timestamp: 1594858678
  timesteps_since_restore: 225000
  timesteps_this_iter: 5000
  timesteps_total: 225000
  training_iteration: 45
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 13.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 386 s, 45 iter, 225000 ts, -9.09e+05 rew

agent-1: -149.99999999841847
agent-2: -149.99999999841847
agent-3: -149.99999999841847
agent-4: 2.0
agent-5: -48.99999999948169
Extrinsic Rewards:
0
0
0
2
1
Sum Reward: 3
Avg Reward: 0.6
Min Reward: 0
Max Reward: 2
Gini Coefficient: 0.6666666666666666
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-18-06
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -889204.4266916462
  episode_reward_min: -13984699.942280233
  episodes_this_iter: 1
  episodes_total: 45
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.943
    dispatch_time_ms: 8.646
    learner:
      cur_lr: 0.0013450150145217776
      grad_gnorm: 5.497809410095215
      policy_entropy: 0.03900491073727608
      policy_loss: 8.610579243395478e-05
      var_gnorm: 24.53239631652832
      vf_explained_var: 0.0
      vf_loss: 0.02005479671061039
    num_steps_sampled: 230000
    num_steps_trained: 230000
    wait_time_ms: 71.45
  iterations_since_restore: 46
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 394.8384072780609
  time_this_iter_s: 8.319396018981934
  time_total_s: 394.8384072780609
  timestamp: 1594858686
  timesteps_since_restore: 230000
  timesteps_this_iter: 5000
  timesteps_total: 230000
  training_iteration: 46
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 14.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 394 s, 46 iter, 230000 ts, -8.89e+05 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-18-15
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -869873.8956766104
  episode_reward_min: -13984699.942280233
  episodes_this_iter: 1
  episodes_total: 46
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.439
    dispatch_time_ms: 7.61
    learner:
      cur_lr: 0.0013446819502860308
      grad_gnorm: 10.080379486083984
      policy_entropy: 0.06822437793016434
      policy_loss: 0.0002967341570183635
      var_gnorm: 24.53061866760254
      vf_explained_var: 1.1920928955078125e-07
      vf_loss: 0.06743530184030533
    num_steps_sampled: 235000
    num_steps_trained: 235000
    wait_time_ms: 74.277
  iterations_since_restore: 47
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 403.0628137588501
  time_this_iter_s: 8.224406480789185
  time_total_s: 403.0628137588501
  timestamp: 1594858695
  timesteps_since_restore: 235000
  timesteps_this_iter: 5000
  timesteps_total: 235000
  training_iteration: 47
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 14.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 403 s, 47 iter, 235000 ts, -8.7e+05 rew

agent-1: 2.0
agent-2: -99.99999999894987
agent-3: -99.99999999894987
agent-4: -99.99999999894987
agent-5: -99.99999999894987
Extrinsic Rewards:
2
0
0
0
0
Sum Reward: 2
Avg Reward: 0.4
Min Reward: 0
Max Reward: 2
Gini Coefficient: 0.8
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-18-23
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -851374.4085345548
  episode_reward_min: -13984699.942280233
  episodes_this_iter: 1
  episodes_total: 47
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.536
    dispatch_time_ms: 11.468
    learner:
      cur_lr: 0.0013443490024656057
      grad_gnorm: 40.0
      policy_entropy: 0.005973989609628916
      policy_loss: -0.000941888487432152
      var_gnorm: 24.550628662109375
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 173.8359375
    num_steps_sampled: 240000
    num_steps_trained: 240000
    wait_time_ms: 69.058
  iterations_since_restore: 48
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 411.34708046913147
  time_this_iter_s: 8.284266710281372
  time_total_s: 411.34708046913147
  timestamp: 1594858703
  timesteps_since_restore: 240000
  timesteps_this_iter: 5000
  timesteps_total: 240000
  training_iteration: 48
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 16.3/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 411 s, 48 iter, 240000 ts, -8.51e+05 rew

agent-1: -47.98683349917959
agent-2: -248.98495848693776
agent-3: -99.9994362756756
agent-4: -99.9994362756756
agent-5: -99.9994362756756
Extrinsic Rewards:
1
0
0
0
0
Sum Reward: 1
Avg Reward: 0.2
Min Reward: 0
Max Reward: 1
Gini Coefficient: 0.8
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-18-31
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -833649.8785671849
  episode_reward_min: -13984699.942280233
  episodes_this_iter: 1
  episodes_total: 48
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.645
    dispatch_time_ms: 8.657
    learner:
      cur_lr: 0.0013440160546451807
      grad_gnorm: 2.3126845359802246
      policy_entropy: 0.005972888320684433
      policy_loss: -4.8043093556771055e-06
      var_gnorm: 24.550804138183594
      vf_explained_var: 1.1920928955078125e-07
      vf_loss: 0.003548843553289771
    num_steps_sampled: 245000
    num_steps_trained: 245000
    wait_time_ms: 72.101
  iterations_since_restore: 49
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 419.65585827827454
  time_this_iter_s: 8.308777809143066
  time_total_s: 419.65585827827454
  timestamp: 1594858711
  timesteps_since_restore: 245000
  timesteps_this_iter: 5000
  timesteps_total: 245000
  training_iteration: 49
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 16.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 419 s, 49 iter, 245000 ts, -8.34e+05 rew

agent-1: -99.99999999894987
agent-2: -99.99999999894987
agent-3: -99.99999999894987
agent-4: -99.99999999894987
agent-5: 2.0
Extrinsic Rewards:
0
0
0
0
2
Sum Reward: 2
Avg Reward: 0.4
Min Reward: 0
Max Reward: 2
Gini Coefficient: 0.8
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-18-40
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -816644.7381882628
  episode_reward_min: -13984699.942280233
  episodes_this_iter: 1
  episodes_total: 49
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.846
    dispatch_time_ms: 10.072
    learner:
      cur_lr: 0.0013436829904094338
      grad_gnorm: 0.4156736731529236
      policy_entropy: 0.0059913997538387775
      policy_loss: 8.748715458750667e-07
      var_gnorm: 24.550682067871094
      vf_explained_var: 5.960464477539063e-08
      vf_loss: 0.00011463701957836747
    num_steps_sampled: 250000
    num_steps_trained: 250000
    wait_time_ms: 69.876
  iterations_since_restore: 50
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 427.8925747871399
  time_this_iter_s: 8.236716508865356
  time_total_s: 427.8925747871399
  timestamp: 1594858720
  timesteps_since_restore: 250000
  timesteps_this_iter: 5000
  timesteps_total: 250000
  training_iteration: 50
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 16.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 427 s, 50 iter, 250000 ts, -8.17e+05 rew

agent-1: -49.99999999946836
agent-2: 1.0
agent-3: -49.99999999946836
agent-4: -49.99999999946836
agent-5: -49.99999999946836
Extrinsic Rewards:
0
1
0
0
0
Sum Reward: 1
Avg Reward: 0.2
Min Reward: 0
Max Reward: 1
Gini Coefficient: 0.8
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-18-48
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -800315.8234244975
  episode_reward_min: -13984699.942280233
  episodes_this_iter: 1
  episodes_total: 50
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.797
    dispatch_time_ms: 8.482
    learner:
      cur_lr: 0.0013433500425890088
      grad_gnorm: 0.42174679040908813
      policy_entropy: 0.0060022673569619656
      policy_loss: 9.650446372688748e-06
      var_gnorm: 24.550655364990234
      vf_explained_var: 0.0
      vf_loss: 0.00011802343942690641
    num_steps_sampled: 255000
    num_steps_trained: 255000
    wait_time_ms: 68.998
  iterations_since_restore: 51
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 436.10856437683105
  time_this_iter_s: 8.215989589691162
  time_total_s: 436.10856437683105
  timestamp: 1594858728
  timesteps_since_restore: 255000
  timesteps_this_iter: 5000
  timesteps_total: 255000
  training_iteration: 51
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 16.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 436 s, 51 iter, 255000 ts, -8e+05 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-18-56
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -784623.356298527
  episode_reward_min: -13984699.942280233
  episodes_this_iter: 1
  episodes_total: 51
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 3.046
    dispatch_time_ms: 8.212
    learner:
      cur_lr: 0.001343016978353262
      grad_gnorm: 8.600998878479004
      policy_entropy: 0.006018416490405798
      policy_loss: 1.10937198769534e-05
      var_gnorm: 24.550512313842773
      vf_explained_var: 0.0
      vf_loss: 0.04908417537808418
    num_steps_sampled: 260000
    num_steps_trained: 260000
    wait_time_ms: 73.95
  iterations_since_restore: 52
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 444.36995458602905
  time_this_iter_s: 8.261390209197998
  time_total_s: 444.36995458602905
  timestamp: 1594858736
  timesteps_since_restore: 260000
  timesteps_this_iter: 5000
  timesteps_total: 260000
  training_iteration: 52
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 16.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 444 s, 52 iter, 260000 ts, -7.85e+05 rew

agent-1: -299.9999999967948
agent-2: -299.9999999967948
agent-3: 4.0
agent-4: -299.9999999967948
agent-5: -97.9999999988953
Extrinsic Rewards:
0
0
4
0
2
Sum Reward: 6
Avg Reward: 1.2
Min Reward: 0
Max Reward: 4
Gini Coefficient: 0.6666666666666666
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-19-04
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -769553.5609850935
  episode_reward_min: -13984699.942280233
  episodes_this_iter: 1
  episodes_total: 52
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 3.278
    dispatch_time_ms: 10.905
    learner:
      cur_lr: 0.001342684030532837
      grad_gnorm: 0.29169028997421265
      policy_entropy: 0.006015340331941843
      policy_loss: 1.3766242773272097e-05
      var_gnorm: 24.550617218017578
      vf_explained_var: 0.0
      vf_loss: 6.920428131707013e-05
    num_steps_sampled: 265000
    num_steps_trained: 265000
    wait_time_ms: 69.912
  iterations_since_restore: 53
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 452.61410689353943
  time_this_iter_s: 8.244152307510376
  time_total_s: 452.61410689353943
  timestamp: 1594858744
  timesteps_since_restore: 265000
  timesteps_this_iter: 5000
  timesteps_total: 265000
  training_iteration: 53
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 17.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 452 s, 53 iter, 265000 ts, -7.7e+05 rew

agent-1: 0.7500000000136119
agent-2: 0.7500000000136119
agent-3: -299.9999999968351
agent-4: -299.9999999968351
agent-5: -0.5
Extrinsic Rewards:
2
2
0
0
2
Sum Reward: 6
Avg Reward: 1.2
Min Reward: 0
Max Reward: 2
Gini Coefficient: 0.4
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-19-13
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -755044.9843627332
  episode_reward_min: -13984699.942280233
  episodes_this_iter: 1
  episodes_total: 53
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.812
    dispatch_time_ms: 8.18
    learner:
      cur_lr: 0.00134235096629709
      grad_gnorm: 7.164794921875
      policy_entropy: 0.006030103657394648
      policy_loss: 1.5079802324180491e-05
      var_gnorm: 24.550479888916016
      vf_explained_var: 0.0
      vf_loss: 0.03406047821044922
    num_steps_sampled: 270000
    num_steps_trained: 270000
    wait_time_ms: 70.709
  iterations_since_restore: 54
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 460.8122470378876
  time_this_iter_s: 8.198140144348145
  time_total_s: 460.8122470378876
  timestamp: 1594858753
  timesteps_since_restore: 270000
  timesteps_this_iter: 5000
  timesteps_total: 270000
  training_iteration: 54
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 17.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 460 s, 54 iter, 270000 ts, -7.55e+05 rew

agent-1: -399.99999999564886
agent-2: -48.24999999941309
agent-3: -250.24999999720438
agent-4: -399.99999999564886
agent-5: 1.5
Extrinsic Rewards:
0
3
1
0
4
Sum Reward: 8
Avg Reward: 1.6
Min Reward: 0
Max Reward: 4
Gini Coefficient: 0.55
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-19-21
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -741082.984652312
  episode_reward_min: -13984699.942280233
  episodes_this_iter: 1
  episodes_total: 54
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 3.108
    dispatch_time_ms: 8.314
    learner:
      cur_lr: 0.001342018018476665
      grad_gnorm: 1.4005619287490845
      policy_entropy: 0.006030602380633354
      policy_loss: -2.1220228063612012e-06
      var_gnorm: 24.550642013549805
      vf_explained_var: 1.7881393432617188e-07
      vf_loss: 0.0013015753356739879
    num_steps_sampled: 275000
    num_steps_trained: 275000
    wait_time_ms: 71.975
  iterations_since_restore: 55
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 469.0368962287903
  time_this_iter_s: 8.22464919090271
  time_total_s: 469.0368962287903
  timestamp: 1594858761
  timesteps_since_restore: 275000
  timesteps_this_iter: 5000
  timesteps_total: 275000
  training_iteration: 55
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 17.3/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 469 s, 55 iter, 275000 ts, -7.41e+05 rew

agent-1: 1.0
agent-2: -49.999999999481645
agent-3: -49.999999999481645
agent-4: -49.999999999481645
agent-5: -49.999999999481645
Extrinsic Rewards:
1
0
0
0
0
Sum Reward: 1
Avg Reward: 0.2
Min Reward: 0
Max Reward: 1
Gini Coefficient: 0.8
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-19-29
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -727612.3667495426
  episode_reward_min: -13984699.942280233
  episodes_this_iter: 1
  episodes_total: 55
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.727
    dispatch_time_ms: 8.328
    learner:
      cur_lr: 0.0013416849542409182
      grad_gnorm: 39.999996185302734
      policy_entropy: 0.006054348777979612
      policy_loss: -0.0008657824946567416
      var_gnorm: 24.550439834594727
      vf_explained_var: 0.0
      vf_loss: 142.64866638183594
    num_steps_sampled: 280000
    num_steps_trained: 280000
    wait_time_ms: 69.636
  iterations_since_restore: 56
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 477.26837372779846
  time_this_iter_s: 8.231477499008179
  time_total_s: 477.26837372779846
  timestamp: 1594858769
  timesteps_since_restore: 280000
  timesteps_this_iter: 5000
  timesteps_total: 280000
  training_iteration: 56
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 17.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 477 s, 56 iter, 280000 ts, -7.28e+05 rew

agent-1: -99.99999999894987
agent-2: 2.0
agent-3: -99.99999999894987
agent-4: -99.99999999894987
agent-5: -99.99999999894987
Extrinsic Rewards:
0
2
0
0
0
Sum Reward: 2
Avg Reward: 0.4
Min Reward: 0
Max Reward: 2
Gini Coefficient: 0.8
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-19-37
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -714626.3959147293
  episode_reward_min: -13984699.942280233
  episodes_this_iter: 1
  episodes_total: 56
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.572
    dispatch_time_ms: 7.118
    learner:
      cur_lr: 0.0013413520064204931
      grad_gnorm: 2.559553861618042
      policy_entropy: 0.006048593670129776
      policy_loss: -5.387112651078496e-06
      var_gnorm: 24.550649642944336
      vf_explained_var: 0.0
      vf_loss: 0.004346937406808138
    num_steps_sampled: 285000
    num_steps_trained: 285000
    wait_time_ms: 74.292
  iterations_since_restore: 57
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 485.5046534538269
  time_this_iter_s: 8.236279726028442
  time_total_s: 485.5046534538269
  timestamp: 1594858777
  timesteps_since_restore: 285000
  timesteps_this_iter: 5000
  timesteps_total: 285000
  training_iteration: 57
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 17.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 485 s, 57 iter, 285000 ts, -7.15e+05 rew

agent-1: 3.0
agent-2: -149.99999999840443
agent-3: -149.99999999840443
agent-4: -149.99999999840443
agent-5: -149.99999999840443
Extrinsic Rewards:
3
0
0
0
0
Sum Reward: 3
Avg Reward: 0.6
Min Reward: 0
Max Reward: 3
Gini Coefficient: 0.8
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-19-46
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -702099.5644074532
  episode_reward_min: -13984699.942280233
  episodes_this_iter: 1
  episodes_total: 57
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.362
    dispatch_time_ms: 10.157
    learner:
      cur_lr: 0.0013410189421847463
      grad_gnorm: 40.0
      policy_entropy: 0.006083630956709385
      policy_loss: -0.00027588719967752695
      var_gnorm: 24.550397872924805
      vf_explained_var: 5.960464477539063e-08
      vf_loss: 14.673648834228516
    num_steps_sampled: 290000
    num_steps_trained: 290000
    wait_time_ms: 71.266
  iterations_since_restore: 58
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 493.7655897140503
  time_this_iter_s: 8.260936260223389
  time_total_s: 493.7655897140503
  timestamp: 1594858786
  timesteps_since_restore: 290000
  timesteps_this_iter: 5000
  timesteps_total: 290000
  training_iteration: 58
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 17.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 493 s, 58 iter, 290000 ts, -7.02e+05 rew

agent-1: -49.99999999946836
agent-2: -49.99999999946836
agent-3: -49.99999999946836
agent-4: 1.0
agent-5: -49.99999999946836
Extrinsic Rewards:
0
0
0
1
0
Sum Reward: 1
Avg Reward: 0.2
Min Reward: 0
Max Reward: 1
Gini Coefficient: 0.8
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-19-54
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -689997.8305383592
  episode_reward_min: -13984699.942280233
  episodes_this_iter: 1
  episodes_total: 58
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.436
    dispatch_time_ms: 5.914
    learner:
      cur_lr: 0.0013406859943643212
      grad_gnorm: 0.1512075513601303
      policy_entropy: 0.006089267320930958
      policy_loss: 1.024244829750387e-05
      var_gnorm: 24.550500869750977
      vf_explained_var: 0.0
      vf_loss: 1.5171342056419235e-05
    num_steps_sampled: 295000
    num_steps_trained: 295000
    wait_time_ms: 74.889
  iterations_since_restore: 59
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 501.988623380661
  time_this_iter_s: 8.223033666610718
  time_total_s: 501.988623380661
  timestamp: 1594858794
  timesteps_since_restore: 295000
  timesteps_this_iter: 5000
  timesteps_total: 295000
  training_iteration: 59
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 17.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 501 s, 59 iter, 295000 ts, -6.9e+05 rew

agent-1: 1.0
agent-2: -49.99999999946836
agent-3: -49.99999999946836
agent-4: -49.99999999946836
agent-5: -49.99999999946836
Extrinsic Rewards:
1
0
0
0
0
Sum Reward: 1
Avg Reward: 0.2
Min Reward: 0
Max Reward: 1
Gini Coefficient: 0.8
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-20-02
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -678306.3249360141
  episode_reward_min: -13984699.942280233
  episodes_this_iter: 1
  episodes_total: 59
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.926
    dispatch_time_ms: 9.841
    learner:
      cur_lr: 0.0013403530465438962
      grad_gnorm: 9.155921936035156
      policy_entropy: 0.006112889852374792
      policy_loss: 1.9520801288308576e-05
      var_gnorm: 24.550352096557617
      vf_explained_var: 5.960464477539063e-08
      vf_loss: 0.05562199279665947
    num_steps_sampled: 300000
    num_steps_trained: 300000
    wait_time_ms: 68.21
  iterations_since_restore: 60
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 510.23330092430115
  time_this_iter_s: 8.244677543640137
  time_total_s: 510.23330092430115
  timestamp: 1594858802
  timesteps_since_restore: 300000
  timesteps_this_iter: 5000
  timesteps_total: 300000
  training_iteration: 60
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 18.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 510 s, 60 iter, 300000 ts, -6.78e+05 rew

agent-1: -199.99999999780377
agent-2: -199.99999999780377
agent-3: -199.99999999780377
agent-4: -199.99999999780377
agent-5: 4.0
Extrinsic Rewards:
0
0
0
0
4
Sum Reward: 4
Avg Reward: 0.8
Min Reward: 0
Max Reward: 4
Gini Coefficient: 0.8
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-20-10
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -667014.4861870803
  episode_reward_min: -13984699.942280233
  episodes_this_iter: 1
  episodes_total: 60
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 3.067
    dispatch_time_ms: 7.545
    learner:
      cur_lr: 0.0013400199823081493
      grad_gnorm: 0.685736358165741
      policy_entropy: 0.006107007153332233
      policy_loss: 4.9281779865850694e-06
      var_gnorm: 24.550491333007812
      vf_explained_var: 0.0
      vf_loss: 0.00031202781246975064
    num_steps_sampled: 305000
    num_steps_trained: 305000
    wait_time_ms: 73.276
  iterations_since_restore: 61
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 518.4106497764587
  time_this_iter_s: 8.177348852157593
  time_total_s: 518.4106497764587
  timestamp: 1594858810
  timesteps_since_restore: 305000
  timesteps_this_iter: 5000
  timesteps_total: 305000
  training_iteration: 61
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 18.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 518 s, 61 iter, 305000 ts, -6.67e+05 rew

agent-1: -149.99999999837684
agent-2: 3.0
agent-3: -149.99999999837684
agent-4: -149.99999999837684
agent-5: -149.99999999837684
Extrinsic Rewards:
0
3
0
0
0
Sum Reward: 3
Avg Reward: 0.6
Min Reward: 0
Max Reward: 3
Gini Coefficient: 0.8
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-20-19
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -656089.6093643411
  episode_reward_min: -13984699.942280233
  episodes_this_iter: 1
  episodes_total: 61
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 3.05
    dispatch_time_ms: 9.295
    learner:
      cur_lr: 0.0013396870344877243
      grad_gnorm: 10.311152458190918
      policy_entropy: 0.006150057539343834
      policy_loss: 4.60269120594603e-07
      var_gnorm: 24.550317764282227
      vf_explained_var: 0.0
      vf_loss: 0.07054371386766434
    num_steps_sampled: 310000
    num_steps_trained: 310000
    wait_time_ms: 70.971
  iterations_since_restore: 62
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 526.6882884502411
  time_this_iter_s: 8.277638673782349
  time_total_s: 526.6882884502411
  timestamp: 1594858819
  timesteps_since_restore: 310000
  timesteps_this_iter: 5000
  timesteps_total: 310000
  training_iteration: 62
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 18.3/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 526 s, 62 iter, 310000 ts, -6.56e+05 rew

agent-1: -149.99999999837684
agent-2: -149.99999999837684
agent-3: -149.99999999837684
agent-4: 3.0
agent-5: -149.99999999837684
Extrinsic Rewards:
0
0
0
3
0
Sum Reward: 3
Avg Reward: 0.6
Min Reward: 0
Max Reward: 3
Gini Coefficient: 0.8
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-20-27
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -645517.1479229807
  episode_reward_min: -13984699.942280233
  episodes_this_iter: 1
  episodes_total: 62
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 3.218
    dispatch_time_ms: 9.775
    learner:
      cur_lr: 0.0013393539702519774
      grad_gnorm: 0.7709001302719116
      policy_entropy: 0.0061323451809585094
      policy_loss: -1.6646617950755171e-06
      var_gnorm: 24.550453186035156
      vf_explained_var: 0.0
      vf_loss: 0.00039859951357357204
    num_steps_sampled: 315000
    num_steps_trained: 315000
    wait_time_ms: 69.117
  iterations_since_restore: 63
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 534.9461421966553
  time_this_iter_s: 8.257853746414185
  time_total_s: 534.9461421966553
  timestamp: 1594858827
  timesteps_since_restore: 315000
  timesteps_this_iter: 5000
  timesteps_total: 315000
  training_iteration: 63
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 18.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 534 s, 63 iter, 315000 ts, -6.46e+05 rew

agent-1: -249.9999999972722
agent-2: 3.96875
agent-3: -149.03124999833577
agent-4: -249.9999999972722
agent-5: -249.9999999972722
Extrinsic Rewards:
0
4
1
0
0
Sum Reward: 5
Avg Reward: 1.0
Min Reward: 0
Max Reward: 4
Gini Coefficient: 0.72
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-20-35
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -635285.051328965
  episode_reward_min: -13984699.942280233
  episodes_this_iter: 1
  episodes_total: 63
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.503
    dispatch_time_ms: 6.891
    learner:
      cur_lr: 0.0013390210224315524
      grad_gnorm: 10.411527633666992
      policy_entropy: 0.006172496359795332
      policy_loss: 2.2766971596865915e-05
      var_gnorm: 24.550281524658203
      vf_explained_var: 0.0
      vf_loss: 0.07192385941743851
    num_steps_sampled: 320000
    num_steps_trained: 320000
    wait_time_ms: 76.544
  iterations_since_restore: 64
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 543.2403676509857
  time_this_iter_s: 8.294225454330444
  time_total_s: 543.2403676509857
  timestamp: 1594858835
  timesteps_since_restore: 320000
  timesteps_this_iter: 5000
  timesteps_total: 320000
  training_iteration: 64
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 18.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 543 s, 64 iter, 320000 ts, -6.35e+05 rew

agent-1: -149.99999999837684
agent-2: -149.99999999837684
agent-3: -149.99999999837684
agent-4: 3.0
agent-5: -149.99999999837684
Extrinsic Rewards:
0
0
0
3
0
Sum Reward: 3
Avg Reward: 0.6
Min Reward: 0
Max Reward: 3
Gini Coefficient: 0.8
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-20-44
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -625368.0505269498
  episode_reward_min: -13984699.942280233
  episodes_this_iter: 1
  episodes_total: 64
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.579
    dispatch_time_ms: 6.791
    learner:
      cur_lr: 0.0013386879581958055
      grad_gnorm: 0.7753329277038574
      policy_entropy: 0.006173397414386272
      policy_loss: -2.9066320621495834e-06
      var_gnorm: 24.55039405822754
      vf_explained_var: 0.0
      vf_loss: 0.00039886939339339733
    num_steps_sampled: 325000
    num_steps_trained: 325000
    wait_time_ms: 75.793
  iterations_since_restore: 65
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 551.5233218669891
  time_this_iter_s: 8.282954216003418
  time_total_s: 551.5233218669891
  timestamp: 1594858844
  timesteps_since_restore: 325000
  timesteps_this_iter: 5000
  timesteps_total: 325000
  training_iteration: 65
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 18.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 551 s, 65 iter, 325000 ts, -6.25e+05 rew

agent-1: -249.99999999735493
agent-2: 3.0
agent-3: -249.99999999735493
agent-4: -47.99999999945478
agent-5: -249.99999999735493
Extrinsic Rewards:
0
3
0
2
0
Sum Reward: 5
Avg Reward: 1.0
Min Reward: 0
Max Reward: 3
Gini Coefficient: 0.64
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-20-52
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -615759.2343649967
  episode_reward_min: -13984699.942280233
  episodes_this_iter: 1
  episodes_total: 65
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.634
    dispatch_time_ms: 9.626
    learner:
      cur_lr: 0.0013383550103753805
      grad_gnorm: 0.4995075762271881
      policy_entropy: 0.006203596945852041
      policy_loss: 1.1270568620602717e-06
      var_gnorm: 24.550315856933594
      vf_explained_var: 0.0
      vf_loss: 0.0001655454543652013
    num_steps_sampled: 330000
    num_steps_trained: 330000
    wait_time_ms: 70.01
  iterations_since_restore: 66
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 559.8090617656708
  time_this_iter_s: 8.28573989868164
  time_total_s: 559.8090617656708
  timestamp: 1594858852
  timesteps_since_restore: 330000
  timesteps_this_iter: 5000
  timesteps_total: 330000
  training_iteration: 66
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 18.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 559 s, 66 iter, 330000 ts, -6.16e+05 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-21-00
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -606429.54899583
  episode_reward_min: -13984699.942280233
  episodes_this_iter: 1
  episodes_total: 66
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.582
    dispatch_time_ms: 10.831
    learner:
      cur_lr: 0.0013380219461396337
      grad_gnorm: 0.8797481656074524
      policy_entropy: 0.006232312880456448
      policy_loss: 3.8425923776230775e-06
      var_gnorm: 24.55027198791504
      vf_explained_var: 0.0
      vf_loss: 0.0005135443643666804
    num_steps_sampled: 335000
    num_steps_trained: 335000
    wait_time_ms: 69.801
  iterations_since_restore: 67
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 568.0294389724731
  time_this_iter_s: 8.220377206802368
  time_total_s: 568.0294389724731
  timestamp: 1594858860
  timesteps_since_restore: 335000
  timesteps_this_iter: 5000
  timesteps_total: 335000
  training_iteration: 67
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 19.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 568 s, 67 iter, 335000 ts, -6.06e+05 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-21-08
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -597378.3616973847
  episode_reward_min: -13984699.942280233
  episodes_this_iter: 1
  episodes_total: 67
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.985
    dispatch_time_ms: 13.549
    learner:
      cur_lr: 0.0013376889983192086
      grad_gnorm: 40.0
      policy_entropy: 0.006274986546486616
      policy_loss: -0.0009499845909886062
      var_gnorm: 24.550172805786133
      vf_explained_var: 0.0
      vf_loss: 155.50839233398438
    num_steps_sampled: 340000
    num_steps_trained: 340000
    wait_time_ms: 67.308
  iterations_since_restore: 68
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 576.2435762882233
  time_this_iter_s: 8.214137315750122
  time_total_s: 576.2435762882233
  timestamp: 1594858868
  timesteps_since_restore: 340000
  timesteps_this_iter: 5000
  timesteps_total: 340000
  training_iteration: 68
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 19.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 576 s, 68 iter, 340000 ts, -5.97e+05 rew

agent-1: -199.999999997859
agent-2: -199.999999997859
agent-3: 3.0
agent-4: -98.9999999988954
agent-5: -199.999999997859
Extrinsic Rewards:
0
0
3
1
0
Sum Reward: 4
Avg Reward: 0.8
Min Reward: 0
Max Reward: 3
Gini Coefficient: 0.7
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-21-17
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -588603.6210841879
  episode_reward_min: -13984699.942280233
  episodes_this_iter: 1
  episodes_total: 68
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.647
    dispatch_time_ms: 9.88
    learner:
      cur_lr: 0.0013373560504987836
      grad_gnorm: 0.46572303771972656
      policy_entropy: 0.0062787411734461784
      policy_loss: -1.351941364191589e-06
      var_gnorm: 24.550243377685547
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 0.00014392052253242582
    num_steps_sampled: 345000
    num_steps_trained: 345000
    wait_time_ms: 70.378
  iterations_since_restore: 69
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 584.5739631652832
  time_this_iter_s: 8.330386877059937
  time_total_s: 584.5739631652832
  timestamp: 1594858877
  timesteps_since_restore: 345000
  timesteps_this_iter: 5000
  timesteps_total: 345000
  training_iteration: 69
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 19.3/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 584 s, 69 iter, 345000 ts, -5.89e+05 rew

agent-1: -199.99999999784504
agent-2: -199.99999999784504
agent-3: 4.0
agent-4: -199.99999999784504
agent-5: -199.99999999784504
Extrinsic Rewards:
0
0
4
0
0
Sum Reward: 4
Avg Reward: 0.8
Min Reward: 0
Max Reward: 4
Gini Coefficient: 0.8
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-21-25
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -580084.6700539821
  episode_reward_min: -13984699.942280233
  episodes_this_iter: 1
  episodes_total: 69
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.712
    dispatch_time_ms: 9.686
    learner:
      cur_lr: 0.0013370229862630367
      grad_gnorm: 12.478959083557129
      policy_entropy: 0.006345008499920368
      policy_loss: 2.4796148863970302e-05
      var_gnorm: 24.55009651184082
      vf_explained_var: -2.384185791015625e-07
      vf_loss: 0.10332328826189041
    num_steps_sampled: 350000
    num_steps_trained: 350000
    wait_time_ms: 69.598
  iterations_since_restore: 70
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 592.7791159152985
  time_this_iter_s: 8.205152750015259
  time_total_s: 592.7791159152985
  timestamp: 1594858885
  timesteps_since_restore: 350000
  timesteps_this_iter: 5000
  timesteps_total: 350000
  training_iteration: 70
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 19.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 592 s, 70 iter, 350000 ts, -5.8e+05 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-21-33
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -571797.7461960681
  episode_reward_min: -13984699.942280233
  episodes_this_iter: 1
  episodes_total: 70
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 3.222
    dispatch_time_ms: 11.985
    learner:
      cur_lr: 0.0013366900384426117
      grad_gnorm: 0.27167749404907227
      policy_entropy: 0.006345945410430431
      policy_loss: -9.102467970478756e-07
      var_gnorm: 24.55015754699707
      vf_explained_var: 5.960464477539063e-08
      vf_loss: 4.897464896203019e-05
    num_steps_sampled: 355000
    num_steps_trained: 355000
    wait_time_ms: 66.974
  iterations_since_restore: 71
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 601.0121595859528
  time_this_iter_s: 8.233043670654297
  time_total_s: 601.0121595859528
  timestamp: 1594858893
  timesteps_since_restore: 355000
  timesteps_this_iter: 5000
  timesteps_total: 355000
  training_iteration: 71
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 19.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 601 s, 71 iter, 355000 ts, -5.72e+05 rew

agent-1: -149.99999999837684
agent-2: -149.99999999837684
agent-3: -149.99999999837684
agent-4: -149.99999999837684
agent-5: 3.0
Extrinsic Rewards:
0
0
0
0
3
Sum Reward: 3
Avg Reward: 0.6
Min Reward: 0
Max Reward: 3
Gini Coefficient: 0.8
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-21-42
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -563752.6652637289
  episode_reward_min: -13984699.942280233
  episodes_this_iter: 1
  episodes_total: 71
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.469
    dispatch_time_ms: 9.473
    learner:
      cur_lr: 0.0013363569742068648
      grad_gnorm: 39.999996185302734
      policy_entropy: 0.006421008612960577
      policy_loss: -0.00021832135098520666
      var_gnorm: 24.55002212524414
      vf_explained_var: 0.0
      vf_loss: 7.672031402587891
    num_steps_sampled: 360000
    num_steps_trained: 360000
    wait_time_ms: 69.366
  iterations_since_restore: 72
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 609.2248384952545
  time_this_iter_s: 8.212678909301758
  time_total_s: 609.2248384952545
  timestamp: 1594858902
  timesteps_since_restore: 360000
  timesteps_this_iter: 5000
  timesteps_total: 360000
  training_iteration: 72
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 19.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 609 s, 72 iter, 360000 ts, -5.64e+05 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-21-50
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -555922.7671350661
  episode_reward_min: -13984699.942280233
  episodes_this_iter: 1
  episodes_total: 72
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.901
    dispatch_time_ms: 7.962
    learner:
      cur_lr: 0.0013360240263864398
      grad_gnorm: 1.8123849630355835
      policy_entropy: 0.00641918508335948
      policy_loss: -4.111775979254162e-06
      var_gnorm: 24.550138473510742
      vf_explained_var: 0.0
      vf_loss: 0.0021899263374507427
    num_steps_sampled: 365000
    num_steps_trained: 365000
    wait_time_ms: 73.937
  iterations_since_restore: 73
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 617.492996931076
  time_this_iter_s: 8.268158435821533
  time_total_s: 617.492996931076
  timestamp: 1594858910
  timesteps_since_restore: 365000
  timesteps_this_iter: 5000
  timesteps_total: 365000
  training_iteration: 73
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 19.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 617 s, 73 iter, 365000 ts, -5.56e+05 rew

agent-1: 1.0
agent-2: -49.999999999481645
agent-3: -49.999999999481645
agent-4: -49.999999999481645
agent-5: -49.999999999481645
Extrinsic Rewards:
1
0
0
0
0
Sum Reward: 1
Avg Reward: 0.2
Min Reward: 0
Max Reward: 1
Gini Coefficient: 0.8
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-21-58
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -548310.1127907501
  episode_reward_min: -13984699.942280233
  episodes_this_iter: 1
  episodes_total: 73
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 3.266
    dispatch_time_ms: 8.818
    learner:
      cur_lr: 0.001335690962150693
      grad_gnorm: 13.53333568572998
      policy_entropy: 0.006495013367384672
      policy_loss: 2.5339550120406784e-06
      var_gnorm: 24.549962997436523
      vf_explained_var: 0.0
      vf_loss: 0.12152088433504105
    num_steps_sampled: 370000
    num_steps_trained: 370000
    wait_time_ms: 68.091
  iterations_since_restore: 74
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 625.6432566642761
  time_this_iter_s: 8.150259733200073
  time_total_s: 625.6432566642761
  timestamp: 1594858918
  timesteps_since_restore: 370000
  timesteps_this_iter: 5000
  timesteps_total: 370000
  training_iteration: 74
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 20.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 625 s, 74 iter, 370000 ts, -5.48e+05 rew

agent-1: 0.7500000000136119
agent-2: -199.99999999788645
agent-3: 0.75
agent-4: -199.99999999788645
agent-5: -199.99999999788645
Extrinsic Rewards:
2
0
2
0
0
Sum Reward: 4
Avg Reward: 0.8
Min Reward: 0
Max Reward: 2
Gini Coefficient: 0.6
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-22-06
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -540908.604509794
  episode_reward_min: -13984699.942280233
  episodes_this_iter: 1
  episodes_total: 74
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.546
    dispatch_time_ms: 8.523
    learner:
      cur_lr: 0.001335358014330268
      grad_gnorm: 0.19563902914524078
      policy_entropy: 0.006498501170426607
      policy_loss: 2.1166615127299337e-09
      var_gnorm: 24.549983978271484
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 2.539525848987978e-05
    num_steps_sampled: 375000
    num_steps_trained: 375000
    wait_time_ms: 74.407
  iterations_since_restore: 75
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 633.890780210495
  time_this_iter_s: 8.247523546218872
  time_total_s: 633.890780210495
  timestamp: 1594858926
  timesteps_since_restore: 375000
  timesteps_this_iter: 5000
  timesteps_total: 375000
  training_iteration: 75
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 20.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 633 s, 75 iter, 375000 ts, -5.41e+05 rew

agent-1: -49.999999999481645
agent-2: -49.999999999481645
agent-3: -49.999999999481645
agent-4: -49.999999999481645
agent-5: 1.0
Extrinsic Rewards:
0
0
0
0
1
Sum Reward: 1
Avg Reward: 0.2
Min Reward: 0
Max Reward: 1
Gini Coefficient: 0.8
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-22-15
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -533699.14311633
  episode_reward_min: -13984699.942280233
  episodes_this_iter: 1
  episodes_total: 75
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 3.174
    dispatch_time_ms: 6.273
    learner:
      cur_lr: 0.001335024950094521
      grad_gnorm: 14.65911865234375
      policy_entropy: 0.006597885861992836
      policy_loss: 1.6104106180137023e-05
      var_gnorm: 24.549896240234375
      vf_explained_var: 0.0
      vf_loss: 0.14258022606372833
    num_steps_sampled: 380000
    num_steps_trained: 380000
    wait_time_ms: 72.743
  iterations_since_restore: 76
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 642.1677579879761
  time_this_iter_s: 8.276977777481079
  time_total_s: 642.1677579879761
  timestamp: 1594858935
  timesteps_since_restore: 380000
  timesteps_this_iter: 5000
  timesteps_total: 380000
  training_iteration: 76
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 20.3/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 642 s, 76 iter, 380000 ts, -5.34e+05 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-22-23
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -526676.7859700625
  episode_reward_min: -13984699.942280233
  episodes_this_iter: 1
  episodes_total: 76
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.56
    dispatch_time_ms: 8.523
    learner:
      cur_lr: 0.001334692002274096
      grad_gnorm: 0.07769503444433212
      policy_entropy: 0.006580306217074394
      policy_loss: -4.870815928370575e-07
      var_gnorm: 24.549903869628906
      vf_explained_var: 0.0
      vf_loss: 4.004176389571512e-06
    num_steps_sampled: 385000
    num_steps_trained: 385000
    wait_time_ms: 70.816
  iterations_since_restore: 77
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 650.3594968318939
  time_this_iter_s: 8.191738843917847
  time_total_s: 650.3594968318939
  timestamp: 1594858943
  timesteps_since_restore: 385000
  timesteps_this_iter: 5000
  timesteps_total: 385000
  training_iteration: 77
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 18.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 650 s, 77 iter, 385000 ts, -5.27e+05 rew

agent-1: -199.999999997859
agent-2: -199.999999997859
agent-3: -98.9999999988954
agent-4: 3.0
agent-5: -199.999999997859
Extrinsic Rewards:
0
0
1
3
0
Sum Reward: 4
Avg Reward: 0.8
Min Reward: 0
Max Reward: 3
Gini Coefficient: 0.7
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-22-31
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -519845.8666717499
  episode_reward_min: -13984699.942280233
  episodes_this_iter: 1
  episodes_total: 77
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.748
    dispatch_time_ms: 7.516
    learner:
      cur_lr: 0.001334359054453671
      grad_gnorm: 0.5368396639823914
      policy_entropy: 0.006646581459790468
      policy_loss: 1.3902672435506247e-06
      var_gnorm: 24.549829483032227
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 0.00019122501544188708
    num_steps_sampled: 390000
    num_steps_trained: 390000
    wait_time_ms: 72.517
  iterations_since_restore: 78
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 658.5915451049805
  time_this_iter_s: 8.232048273086548
  time_total_s: 658.5915451049805
  timestamp: 1594858951
  timesteps_since_restore: 390000
  timesteps_this_iter: 5000
  timesteps_total: 390000
  training_iteration: 78
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 20.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 658 s, 78 iter, 390000 ts, -5.2e+05 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-22-39
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -513181.17607339413
  episode_reward_min: -13984699.942280233
  episodes_this_iter: 1
  episodes_total: 78
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.796
    dispatch_time_ms: 8.459
    learner:
      cur_lr: 0.0013340259902179241
      grad_gnorm: 1.842669129371643
      policy_entropy: 0.006674545351415873
      policy_loss: 2.9557390917034354e-06
      var_gnorm: 24.54987144470215
      vf_explained_var: 0.0
      vf_loss: 0.002274089492857456
    num_steps_sampled: 395000
    num_steps_trained: 395000
    wait_time_ms: 73.334
  iterations_since_restore: 79
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 666.8089027404785
  time_this_iter_s: 8.217357635498047
  time_total_s: 666.8089027404785
  timestamp: 1594858959
  timesteps_since_restore: 395000
  timesteps_this_iter: 5000
  timesteps_total: 395000
  training_iteration: 79
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 20.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 666 s, 79 iter, 395000 ts, -5.13e+05 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-22-48
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -506685.21181930054
  episode_reward_min: -13984699.942280233
  episodes_this_iter: 1
  episodes_total: 79
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.491
    dispatch_time_ms: 10.2
    learner:
      cur_lr: 0.001333693042397499
      grad_gnorm: 40.0
      policy_entropy: 0.006784407887607813
      policy_loss: -0.0005794943426735699
      var_gnorm: 24.54974365234375
      vf_explained_var: 0.0
      vf_loss: 48.62085723876953
    num_steps_sampled: 400000
    num_steps_trained: 400000
    wait_time_ms: 70.456
  iterations_since_restore: 80
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 675.1160082817078
  time_this_iter_s: 8.307105541229248
  time_total_s: 675.1160082817078
  timestamp: 1594858968
  timesteps_since_restore: 400000
  timesteps_this_iter: 5000
  timesteps_total: 400000
  training_iteration: 80
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 20.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 675 s, 80 iter, 400000 ts, -5.07e+05 rew

agent-1: -47.99999999945478
agent-2: -249.99999999735493
agent-3: 3.0
agent-4: -249.99999999735493
agent-5: -249.99999999735493
Extrinsic Rewards:
2
0
3
0
0
Sum Reward: 5
Avg Reward: 1.0
Min Reward: 0
Max Reward: 3
Gini Coefficient: 0.64
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-22-56
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -500361.5841715592
  episode_reward_min: -13984699.942280233
  episodes_this_iter: 1
  episodes_total: 80
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 3.247
    dispatch_time_ms: 8.192
    learner:
      cur_lr: 0.0013333599781617522
      grad_gnorm: 3.1928915977478027
      policy_entropy: 0.006755421403795481
      policy_loss: -7.666257261007559e-06
      var_gnorm: 24.549861907958984
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 0.006764182820916176
    num_steps_sampled: 405000
    num_steps_trained: 405000
    wait_time_ms: 72.363
  iterations_since_restore: 81
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 683.376939535141
  time_this_iter_s: 8.260931253433228
  time_total_s: 683.376939535141
  timestamp: 1594858976
  timesteps_since_restore: 405000
  timesteps_this_iter: 5000
  timesteps_total: 405000
  training_iteration: 81
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 21.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 683 s, 81 iter, 405000 ts, -5e+05 rew

agent-1: -149.99999999840443
agent-2: -149.99999999840443
agent-3: -149.99999999840443
agent-4: 3.0
agent-5: -149.99999999840443
Extrinsic Rewards:
0
0
0
3
0
Sum Reward: 3
Avg Reward: 0.6
Min Reward: 0
Max Reward: 3
Gini Coefficient: 0.8
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-23-04
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -494191.6510336386
  episode_reward_min: -13984699.942280233
  episodes_this_iter: 1
  episodes_total: 81
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.734
    dispatch_time_ms: 10.55
    learner:
      cur_lr: 0.0013330270303413272
      grad_gnorm: 15.351386070251465
      policy_entropy: 0.006912759970873594
      policy_loss: 3.4182510717073455e-05
      var_gnorm: 24.549646377563477
      vf_explained_var: 0.0
      vf_loss: 0.1563643217086792
    num_steps_sampled: 410000
    num_steps_trained: 410000
    wait_time_ms: 70.244
  iterations_since_restore: 82
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 691.6315803527832
  time_this_iter_s: 8.254640817642212
  time_total_s: 691.6315803527832
  timestamp: 1594858984
  timesteps_since_restore: 410000
  timesteps_this_iter: 5000
  timesteps_total: 410000
  training_iteration: 82
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 21.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 691 s, 82 iter, 410000 ts, -4.94e+05 rew

agent-1: -49.99999999946836
agent-2: -49.99999999946836
agent-3: -49.99999999946836
agent-4: -49.99999999946836
agent-5: 1.0
Extrinsic Rewards:
0
0
0
0
1
Sum Reward: 1
Avg Reward: 0.2
Min Reward: 0
Max Reward: 1
Gini Coefficient: 0.8
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-23-13
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -488167.35041127715
  episode_reward_min: -13984699.942280233
  episodes_this_iter: 1
  episodes_total: 82
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.446
    dispatch_time_ms: 8.06
    learner:
      cur_lr: 0.0013326939661055803
      grad_gnorm: 1.0158464908599854
      policy_entropy: 0.006864767987281084
      policy_loss: -2.59122089119046e-07
      var_gnorm: 24.549684524536133
      vf_explained_var: 1.1920928955078125e-07
      vf_loss: 0.0007006992236711085
    num_steps_sampled: 415000
    num_steps_trained: 415000
    wait_time_ms: 72.395
  iterations_since_restore: 83
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 699.8553354740143
  time_this_iter_s: 8.223755121231079
  time_total_s: 699.8553354740143
  timestamp: 1594858993
  timesteps_since_restore: 415000
  timesteps_this_iter: 5000
  timesteps_total: 415000
  training_iteration: 83
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 21.3/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 699 s, 83 iter, 415000 ts, -4.88e+05 rew

agent-1: -299.9999999968079
agent-2: -299.9999999968079
agent-3: -148.99999999836348
agent-4: -148.99999999836348
agent-5: 4.0
Extrinsic Rewards:
0
0
1
1
4
Sum Reward: 6
Avg Reward: 1.2
Min Reward: 0
Max Reward: 4
Gini Coefficient: 0.6
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-23-21
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -482296.5871533098
  episode_reward_min: -13984699.942280233
  episodes_this_iter: 1
  episodes_total: 83
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.905
    dispatch_time_ms: 9.742
    learner:
      cur_lr: 0.0013323610182851553
      grad_gnorm: 39.999996185302734
      policy_entropy: 0.006997561547905207
      policy_loss: -0.00039503880543634295
      var_gnorm: 24.549558639526367
      vf_explained_var: 1.7881393432617188e-07
      vf_loss: 20.15747833251953
    num_steps_sampled: 420000
    num_steps_trained: 420000
    wait_time_ms: 70.49
  iterations_since_restore: 84
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 708.0645830631256
  time_this_iter_s: 8.209247589111328
  time_total_s: 708.0645830631256
  timestamp: 1594859001
  timesteps_since_restore: 420000
  timesteps_this_iter: 5000
  timesteps_total: 420000
  training_iteration: 84
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 21.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 708 s, 84 iter, 420000 ts, -4.82e+05 rew

agent-1: 4.0
agent-2: -249.99999999731412
agent-3: -249.99999999731412
agent-4: -249.99999999731412
agent-5: -148.99999999837678
Extrinsic Rewards:
4
0
0
0
1
Sum Reward: 5
Avg Reward: 1.0
Min Reward: 0
Max Reward: 4
Gini Coefficient: 0.72
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-23-29
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -476565.61587767507
  episode_reward_min: -13984699.942280233
  episodes_this_iter: 1
  episodes_total: 84
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.647
    dispatch_time_ms: 6.955
    learner:
      cur_lr: 0.0013320279540494084
      grad_gnorm: 0.035346806049346924
      policy_entropy: 0.007014646660536528
      policy_loss: -3.257346463669819e-07
      var_gnorm: 24.549545288085938
      vf_explained_var: 5.960464477539063e-08
      vf_loss: 8.291281119454652e-07
    num_steps_sampled: 425000
    num_steps_trained: 425000
    wait_time_ms: 74.229
  iterations_since_restore: 85
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 716.3011319637299
  time_this_iter_s: 8.236548900604248
  time_total_s: 716.3011319637299
  timestamp: 1594859009
  timesteps_since_restore: 425000
  timesteps_this_iter: 5000
  timesteps_total: 425000
  training_iteration: 85
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 21.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 716 s, 85 iter, 425000 ts, -4.77e+05 rew

agent-1: -99.99999999894987
agent-2: -99.99999999894987
agent-3: -99.99999999894987
agent-4: 2.0
agent-5: -99.99999999894987
Extrinsic Rewards:
0
0
0
2
0
Sum Reward: 2
Avg Reward: 0.4
Min Reward: 0
Max Reward: 2
Gini Coefficient: 0.8
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-23-37
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -470963.6439261731
  episode_reward_min: -13984699.942280233
  episodes_this_iter: 1
  episodes_total: 85
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 3.5
    dispatch_time_ms: 7.703
    learner:
      cur_lr: 0.0013316950062289834
      grad_gnorm: 0.4784846007823944
      policy_entropy: 0.007127641700208187
      policy_loss: 1.384152824357443e-06
      var_gnorm: 24.549461364746094
      vf_explained_var: 0.0
      vf_loss: 0.00015191224520094693
    num_steps_sampled: 430000
    num_steps_trained: 430000
    wait_time_ms: 72.124
  iterations_since_restore: 86
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 724.5829002857208
  time_this_iter_s: 8.281768321990967
  time_total_s: 724.5829002857208
  timestamp: 1594859017
  timesteps_since_restore: 430000
  timesteps_this_iter: 5000
  timesteps_total: 430000
  training_iteration: 86
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 21.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 724 s, 86 iter, 430000 ts, -4.71e+05 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-23-46
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -465487.322485171
  episode_reward_min: -13984699.942280233
  episodes_this_iter: 1
  episodes_total: 86
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.708
    dispatch_time_ms: 8.799
    learner:
      cur_lr: 0.0013313619419932365
      grad_gnorm: 1.5728116035461426
      policy_entropy: 0.007192987948656082
      policy_loss: -7.56493079734355e-07
      var_gnorm: 24.549476623535156
      vf_explained_var: 1.1920928955078125e-07
      vf_loss: 0.0016508173430338502
    num_steps_sampled: 435000
    num_steps_trained: 435000
    wait_time_ms: 72.897
  iterations_since_restore: 87
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 732.7544691562653
  time_this_iter_s: 8.171568870544434
  time_total_s: 732.7544691562653
  timestamp: 1594859026
  timesteps_since_restore: 435000
  timesteps_this_iter: 5000
  timesteps_total: 435000
  training_iteration: 87
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 21.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 732 s, 87 iter, 435000 ts, -4.65e+05 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-23-54
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -460136.8934910886
  episode_reward_min: -13984699.942280233
  episodes_this_iter: 1
  episodes_total: 87
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.862
    dispatch_time_ms: 8.133
    learner:
      cur_lr: 0.0013310289941728115
      grad_gnorm: 40.0
      policy_entropy: 0.007473703473806381
      policy_loss: -0.0004340382874943316
      var_gnorm: 24.549421310424805
      vf_explained_var: 0.0
      vf_loss: 24.29993438720703
    num_steps_sampled: 440000
    num_steps_trained: 440000
    wait_time_ms: 71.041
  iterations_since_restore: 88
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 741.0270328521729
  time_this_iter_s: 8.272563695907593
  time_total_s: 741.0270328521729
  timestamp: 1594859034
  timesteps_since_restore: 440000
  timesteps_this_iter: 5000
  timesteps_total: 440000
  training_iteration: 88
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 22.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 741 s, 88 iter, 440000 ts, -4.6e+05 rew

agent-1: 2.0
agent-2: -99.99999999894987
agent-3: -99.99999999894987
agent-4: -99.99999999894987
agent-5: -99.99999999894987
Extrinsic Rewards:
2
0
0
0
0
Sum Reward: 2
Avg Reward: 0.4
Min Reward: 0
Max Reward: 2
Gini Coefficient: 0.8
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-24-02
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -454912.5878832352
  episode_reward_min: -13984699.942280233
  episodes_this_iter: 1
  episodes_total: 88
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.608
    dispatch_time_ms: 6.499
    learner:
      cur_lr: 0.0013306960463523865
      grad_gnorm: 0.2553156018257141
      policy_entropy: 0.0074402824975550175
      policy_loss: 3.277762345987867e-07
      var_gnorm: 24.54924201965332
      vf_explained_var: 5.960464477539063e-08
      vf_loss: 4.3252905015833676e-05
    num_steps_sampled: 445000
    num_steps_trained: 445000
    wait_time_ms: 79.434
  iterations_since_restore: 89
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 749.2806587219238
  time_this_iter_s: 8.253625869750977
  time_total_s: 749.2806587219238
  timestamp: 1594859042
  timesteps_since_restore: 445000
  timesteps_this_iter: 5000
  timesteps_total: 445000
  training_iteration: 89
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 22.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 749 s, 89 iter, 445000 ts, -4.55e+05 rew

agent-1: -98.9999999988954
agent-2: -199.999999997859
agent-3: -199.999999997859
agent-4: 3.0
agent-5: -199.999999997859
Extrinsic Rewards:
1
0
0
3
0
Sum Reward: 4
Avg Reward: 0.8
Min Reward: 0
Max Reward: 3
Gini Coefficient: 0.7
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-24-11
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -449809.03071600775
  episode_reward_min: -13984699.942280233
  episodes_this_iter: 1
  episodes_total: 89
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.691
    dispatch_time_ms: 7.768
    learner:
      cur_lr: 0.0013303629821166396
      grad_gnorm: 0.361403226852417
      policy_entropy: 0.007590062916278839
      policy_loss: 1.1147377563247574e-06
      var_gnorm: 24.54915428161621
      vf_explained_var: 2.384185791015625e-07
      vf_loss: 8.666019857628271e-05
    num_steps_sampled: 450000
    num_steps_trained: 450000
    wait_time_ms: 76.23
  iterations_since_restore: 90
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 757.5485291481018
  time_this_iter_s: 8.267870426177979
  time_total_s: 757.5485291481018
  timestamp: 1594859051
  timesteps_since_restore: 450000
  timesteps_this_iter: 5000
  timesteps_total: 450000
  training_iteration: 90
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 22.3/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 757 s, 90 iter, 450000 ts, -4.5e+05 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-24-19
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -444811.1525969409
  episode_reward_min: -13984699.942280233
  episodes_this_iter: 1
  episodes_total: 90
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.828
    dispatch_time_ms: 10.669
    learner:
      cur_lr: 0.0013300300342962146
      grad_gnorm: 1.4395763874053955
      policy_entropy: 0.007726950105279684
      policy_loss: 4.013611032860354e-06
      var_gnorm: 24.549043655395508
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 0.001399770611897111
    num_steps_sampled: 455000
    num_steps_trained: 455000
    wait_time_ms: 69.268
  iterations_since_restore: 91
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 765.7150232791901
  time_this_iter_s: 8.166494131088257
  time_total_s: 765.7150232791901
  timestamp: 1594859059
  timesteps_since_restore: 455000
  timesteps_this_iter: 5000
  timesteps_total: 455000
  training_iteration: 91
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 22.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 765 s, 91 iter, 455000 ts, -4.45e+05 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-24-27
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -439923.1179530185
  episode_reward_min: -13984699.942280233
  episodes_this_iter: 1
  episodes_total: 91
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.695
    dispatch_time_ms: 9.784
    learner:
      cur_lr: 0.0013296969700604677
      grad_gnorm: 23.653959274291992
      policy_entropy: 0.008037394843995571
      policy_loss: 6.472328095696867e-05
      var_gnorm: 24.54935073852539
      vf_explained_var: 0.0
      vf_loss: 0.37123599648475647
    num_steps_sampled: 460000
    num_steps_trained: 460000
    wait_time_ms: 71.193
  iterations_since_restore: 92
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 774.0899407863617
  time_this_iter_s: 8.37491750717163
  time_total_s: 774.0899407863617
  timestamp: 1594859067
  timesteps_since_restore: 460000
  timesteps_this_iter: 5000
  timesteps_total: 460000
  training_iteration: 92
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 22.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 774 s, 92 iter, 460000 ts, -4.4e+05 rew

agent-1: -149.99999999840443
agent-2: -149.99999999840443
agent-3: -149.99999999840443
agent-4: 3.0
agent-5: -149.99999999840443
Extrinsic Rewards:
0
0
0
3
0
Sum Reward: 3
Avg Reward: 0.6
Min Reward: 0
Max Reward: 3
Gini Coefficient: 0.8
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-24-35
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -435147.83406222484
  episode_reward_min: -13984699.942280233
  episodes_this_iter: 1
  episodes_total: 92
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.43
    dispatch_time_ms: 8.528
    learner:
      cur_lr: 0.0013293640222400427
      grad_gnorm: 4.710728645324707
      policy_entropy: 0.036689117550849915
      policy_loss: 0.0001169459501397796
      var_gnorm: 24.538888931274414
      vf_explained_var: 0.0
      vf_loss: 0.01472378708422184
    num_steps_sampled: 465000
    num_steps_trained: 465000
    wait_time_ms: 69.805
  iterations_since_restore: 93
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 782.2650203704834
  time_this_iter_s: 8.175079584121704
  time_total_s: 782.2650203704834
  timestamp: 1594859075
  timesteps_since_restore: 465000
  timesteps_this_iter: 5000
  timesteps_total: 465000
  training_iteration: 93
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 22.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 782 s, 93 iter, 465000 ts, -4.35e+05 rew

agent-1: 4.0
agent-2: -199.99999999780377
agent-3: -199.99999999780377
agent-4: -199.99999999780377
agent-5: -199.99999999780377
Extrinsic Rewards:
4
0
0
0
0
Sum Reward: 4
Avg Reward: 0.8
Min Reward: 0
Max Reward: 4
Gini Coefficient: 0.8
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-24-44
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -430477.38423359866
  episode_reward_min: -13984699.942280233
  episodes_this_iter: 1
  episodes_total: 93
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 3.134
    dispatch_time_ms: 10.535
    learner:
      cur_lr: 0.0013290309580042958
      grad_gnorm: 40.0
      policy_entropy: 0.050350770354270935
      policy_loss: -0.002088563982397318
      var_gnorm: 24.53826141357422
      vf_explained_var: 0.0
      vf_loss: 9.504055976867676
    num_steps_sampled: 470000
    num_steps_trained: 470000
    wait_time_ms: 68.746
  iterations_since_restore: 94
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 790.5220589637756
  time_this_iter_s: 8.257038593292236
  time_total_s: 790.5220589637756
  timestamp: 1594859084
  timesteps_since_restore: 470000
  timesteps_this_iter: 5000
  timesteps_total: 470000
  training_iteration: 94
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 22.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 790 s, 94 iter, 470000 ts, -4.3e+05 rew

agent-1: -47.99999999945478
agent-2: -249.99999999735493
agent-3: -249.99999999735493
agent-4: 3.0
agent-5: -249.99999999735493
Extrinsic Rewards:
2
0
0
3
0
Sum Reward: 5
Avg Reward: 1.0
Min Reward: 0
Max Reward: 3
Gini Coefficient: 0.64
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-24-52
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -425906.29503962415
  episode_reward_min: -13984699.942280233
  episodes_this_iter: 1
  episodes_total: 94
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.947
    dispatch_time_ms: 6.945
    learner:
      cur_lr: 0.0013286980101838708
      grad_gnorm: 0.27998867630958557
      policy_entropy: 0.04453766345977783
      policy_loss: 3.3374324175383663e-06
      var_gnorm: 24.538190841674805
      vf_explained_var: 0.0
      vf_loss: 5.201732346904464e-05
    num_steps_sampled: 475000
    num_steps_trained: 475000
    wait_time_ms: 72.672
  iterations_since_restore: 95
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 798.696527004242
  time_this_iter_s: 8.174468040466309
  time_total_s: 798.696527004242
  timestamp: 1594859092
  timesteps_since_restore: 475000
  timesteps_this_iter: 5000
  timesteps_total: 475000
  training_iteration: 95
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 23.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 798 s, 95 iter, 475000 ts, -4.26e+05 rew

agent-1: -199.99999999784504
agent-2: 4.0
agent-3: -199.99999999784504
agent-4: -199.99999999784504
agent-5: -199.99999999784504
Extrinsic Rewards:
0
4
0
0
0
Sum Reward: 4
Avg Reward: 0.8
Min Reward: 0
Max Reward: 4
Gini Coefficient: 0.8
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-25-00
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -421431.44982868066
  episode_reward_min: -13984699.942280233
  episodes_this_iter: 1
  episodes_total: 95
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.468
    dispatch_time_ms: 7.798
    learner:
      cur_lr: 0.001328364945948124
      grad_gnorm: 20.987369537353516
      policy_entropy: 0.06566447019577026
      policy_loss: -0.0006834325613453984
      var_gnorm: 24.537723541259766
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 0.6782703995704651
    num_steps_sampled: 480000
    num_steps_trained: 480000
    wait_time_ms: 72.468
  iterations_since_restore: 96
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 806.9527838230133
  time_this_iter_s: 8.256256818771362
  time_total_s: 806.9527838230133
  timestamp: 1594859100
  timesteps_since_restore: 480000
  timesteps_this_iter: 5000
  timesteps_total: 480000
  training_iteration: 96
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 23.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 806 s, 96 iter, 480000 ts, -4.21e+05 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-25-08
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -417041.53889296524
  episode_reward_min: -13984699.942280233
  episodes_this_iter: 1
  episodes_total: 96
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 3.224
    dispatch_time_ms: 10.399
    learner:
      cur_lr: 0.001328031998127699
      grad_gnorm: 6.532899379730225
      policy_entropy: 0.1041925698518753
      policy_loss: 0.0004523184907156974
      var_gnorm: 24.535314559936523
      vf_explained_var: 0.0
      vf_loss: 0.02831759862601757
    num_steps_sampled: 485000
    num_steps_trained: 485000
    wait_time_ms: 68.511
  iterations_since_restore: 97
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 815.238566160202
  time_this_iter_s: 8.28578233718872
  time_total_s: 815.238566160202
  timestamp: 1594859108
  timesteps_since_restore: 485000
  timesteps_this_iter: 5000
  timesteps_total: 485000
  training_iteration: 97
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 23.3/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 815 s, 97 iter, 485000 ts, -4.17e+05 rew

agent-1: 2.0
agent-2: -99.99999999894987
agent-3: -99.99999999894987
agent-4: -99.99999999894987
agent-5: -99.99999999894987
Extrinsic Rewards:
2
0
0
0
0
Sum Reward: 2
Avg Reward: 0.4
Min Reward: 0
Max Reward: 2
Gini Coefficient: 0.8
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-25-17
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -412746.24467757373
  episode_reward_min: -13984699.942280233
  episodes_this_iter: 1
  episodes_total: 97
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 3.126
    dispatch_time_ms: 10.165
    learner:
      cur_lr: 0.0013276990503072739
      grad_gnorm: 10.644001007080078
      policy_entropy: 0.11511850357055664
      policy_loss: -0.0008806656114757061
      var_gnorm: 24.535642623901367
      vf_explained_var: 0.0
      vf_loss: 0.3047977089881897
    num_steps_sampled: 490000
    num_steps_trained: 490000
    wait_time_ms: 68.971
  iterations_since_restore: 98
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 823.4927670955658
  time_this_iter_s: 8.25420093536377
  time_total_s: 823.4927670955658
  timestamp: 1594859117
  timesteps_since_restore: 490000
  timesteps_this_iter: 5000
  timesteps_total: 490000
  training_iteration: 98
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 23.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 823 s, 98 iter, 490000 ts, -4.13e+05 rew

agent-1: 0.7500000000136119
agent-2: -199.99999999788645
agent-3: 0.75
agent-4: -199.99999999788645
agent-5: -199.99999999788645
Extrinsic Rewards:
2
0
2
0
0
Sum Reward: 4
Avg Reward: 0.8
Min Reward: 0
Max Reward: 2
Gini Coefficient: 0.6
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-25-25
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -408540.65544616984
  episode_reward_min: -13984699.942280233
  episodes_this_iter: 1
  episodes_total: 98
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.694
    dispatch_time_ms: 7.322
    learner:
      cur_lr: 0.001327365986071527
      grad_gnorm: 0.3995897173881531
      policy_entropy: 0.059101056307554245
      policy_loss: 1.2825204066757578e-05
      var_gnorm: 24.536823272705078
      vf_explained_var: 0.0
      vf_loss: 0.00010595400090096518
    num_steps_sampled: 495000
    num_steps_trained: 495000
    wait_time_ms: 70.37
  iterations_since_restore: 99
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 831.7351386547089
  time_this_iter_s: 8.242371559143066
  time_total_s: 831.7351386547089
  timestamp: 1594859125
  timesteps_since_restore: 495000
  timesteps_this_iter: 5000
  timesteps_total: 495000
  training_iteration: 99
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 23.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 831 s, 99 iter, 495000 ts, -4.09e+05 rew

agent-1: 2.0
agent-2: -99.99999999894987
agent-3: -99.99999999894987
agent-4: -99.99999999894987
agent-5: -99.99999999894987
Extrinsic Rewards:
2
0
0
0
0
Sum Reward: 2
Avg Reward: 0.4
Min Reward: 0
Max Reward: 2
Gini Coefficient: 0.8
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-25-33
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -404418.00236085494
  episode_reward_min: -13984699.942280233
  episodes_this_iter: 1
  episodes_total: 99
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 3.582
    dispatch_time_ms: 9.961
    learner:
      cur_lr: 0.001327033038251102
      grad_gnorm: 6.478680610656738
      policy_entropy: 0.10741546750068665
      policy_loss: 0.00021070599905215204
      var_gnorm: 24.535919189453125
      vf_explained_var: 1.1920928955078125e-07
      vf_loss: 0.10709891468286514
    num_steps_sampled: 500000
    num_steps_trained: 500000
    wait_time_ms: 70.5
  iterations_since_restore: 100
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 840.0777423381805
  time_this_iter_s: 8.34260368347168
  time_total_s: 840.0777423381805
  timestamp: 1594859133
  timesteps_since_restore: 500000
  timesteps_this_iter: 5000
  timesteps_total: 500000
  training_iteration: 100
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 23.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 840 s, 100 iter, 500000 ts, -4.04e+05 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-25-42
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -400373.8223372464
  episode_reward_min: -13984699.942280233
  episodes_this_iter: 1
  episodes_total: 100
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.977
    dispatch_time_ms: 8.142
    learner:
      cur_lr: 0.0013266999740153551
      grad_gnorm: 0.1548970490694046
      policy_entropy: 0.10089278966188431
      policy_loss: 0.007075910456478596
      var_gnorm: 24.53548240661621
      vf_explained_var: 1.1920928955078125e-07
      vf_loss: 1.58531402121298e-05
    num_steps_sampled: 505000
    num_steps_trained: 505000
    wait_time_ms: 71.181
  iterations_since_restore: 101
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 848.2878894805908
  time_this_iter_s: 8.210147142410278
  time_total_s: 848.2878894805908
  timestamp: 1594859142
  timesteps_since_restore: 505000
  timesteps_this_iter: 5000
  timesteps_total: 505000
  training_iteration: 101
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 23.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 848 s, 101 iter, 505000 ts, -4e+05 rew

agent-1: -99.99999999894987
agent-2: 2.0
agent-3: -99.99999999894987
agent-4: -99.99999999894987
agent-5: -99.99999999894987
Extrinsic Rewards:
0
2
0
0
0
Sum Reward: 2
Avg Reward: 0.4
Min Reward: 0
Max Reward: 2
Gini Coefficient: 0.8
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-25-50
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -385467.3468229235
  episode_reward_min: -13984699.942280233
  episodes_this_iter: 1
  episodes_total: 101
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 3.157
    dispatch_time_ms: 7.858
    learner:
      cur_lr: 0.00132636702619493
      grad_gnorm: 9.115674018859863
      policy_entropy: 0.01616661809384823
      policy_loss: -5.556366886594333e-05
      var_gnorm: 24.54778289794922
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 0.3761959373950958
    num_steps_sampled: 510000
    num_steps_trained: 510000
    wait_time_ms: 72.034
  iterations_since_restore: 102
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 856.5908145904541
  time_this_iter_s: 8.302925109863281
  time_total_s: 856.5908145904541
  timestamp: 1594859150
  timesteps_since_restore: 510000
  timesteps_this_iter: 5000
  timesteps_total: 510000
  training_iteration: 102
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 24.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 856 s, 102 iter, 510000 ts, -3.85e+05 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-25-58
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -371550.86019628606
  episode_reward_min: -13984699.942280233
  episodes_this_iter: 1
  episodes_total: 102
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.449
    dispatch_time_ms: 5.564
    learner:
      cur_lr: 0.0013260339619591832
      grad_gnorm: 0.2657186686992645
      policy_entropy: 0.0086748618632555
      policy_loss: 1.1004029829564388e-06
      var_gnorm: 24.551469802856445
      vf_explained_var: 0.0
      vf_loss: 4.6842276788083836e-05
    num_steps_sampled: 515000
    num_steps_trained: 515000
    wait_time_ms: 72.058
  iterations_since_restore: 103
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 864.8126790523529
  time_this_iter_s: 8.221864461898804
  time_total_s: 864.8126790523529
  timestamp: 1594859158
  timesteps_since_restore: 515000
  timesteps_this_iter: 5000
  timesteps_total: 515000
  training_iteration: 103
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 24.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 864 s, 103 iter, 515000 ts, -3.72e+05 rew

agent-1: -150.24999999830888
agent-2: -249.99999999727223
agent-3: 2.75
agent-4: -249.99999999727223
agent-5: -249.99999999727223
Extrinsic Rewards:
1
0
4
0
0
Sum Reward: 5
Avg Reward: 1.0
Min Reward: 0
Max Reward: 4
Gini Coefficient: 0.72
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-26-07
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -231712.83577348373
  episode_reward_min: -12435990.68204988
  episodes_this_iter: 1
  episodes_total: 103
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 3.241
    dispatch_time_ms: 9.361
    learner:
      cur_lr: 0.0013257010141387582
      grad_gnorm: 31.528705596923828
      policy_entropy: 0.00941456388682127
      policy_loss: 0.00010650284821167588
      var_gnorm: 24.552457809448242
      vf_explained_var: 1.7881393432617188e-07
      vf_loss: 0.6595607399940491
    num_steps_sampled: 520000
    num_steps_trained: 520000
    wait_time_ms: 67.684
  iterations_since_restore: 104
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 873.0705459117889
  time_this_iter_s: 8.257866859436035
  time_total_s: 873.0705459117889
  timestamp: 1594859167
  timesteps_since_restore: 520000
  timesteps_this_iter: 5000
  timesteps_total: 520000
  training_iteration: 104
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 24.3/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 873 s, 104 iter, 520000 ts, -2.32e+05 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-26-15
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -107352.92895298489
  episode_reward_min: -3948748.0827754145
  episodes_this_iter: 1
  episodes_total: 104
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 3.314
    dispatch_time_ms: 8.946
    learner:
      cur_lr: 0.0013253679499030113
      grad_gnorm: 12.81597900390625
      policy_entropy: 0.009267834015190601
      policy_loss: 0.00013385998317971826
      var_gnorm: 24.551420211791992
      vf_explained_var: 1.1920928955078125e-07
      vf_loss: 0.10980081558227539
    num_steps_sampled: 525000
    num_steps_trained: 525000
    wait_time_ms: 70.017
  iterations_since_restore: 105
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 881.2421953678131
  time_this_iter_s: 8.17164945602417
  time_total_s: 881.2421953678131
  timestamp: 1594859175
  timesteps_since_restore: 525000
  timesteps_this_iter: 5000
  timesteps_total: 525000
  training_iteration: 105
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 24.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 881 s, 105 iter, 525000 ts, -1.07e+05 rew

agent-1: 4.0
agent-2: -199.99999999780377
agent-3: -199.99999999780377
agent-4: -199.99999999780377
agent-5: -199.99999999780377
Extrinsic Rewards:
4
0
0
0
0
Sum Reward: 4
Avg Reward: 0.8
Min Reward: 0
Max Reward: 4
Gini Coefficient: 0.8
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-26-23
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -67873.40812523064
  episode_reward_min: -3776350.0298649017
  episodes_this_iter: 1
  episodes_total: 105
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.669
    dispatch_time_ms: 8.893
    learner:
      cur_lr: 0.0013250350020825863
      grad_gnorm: 0.11870980262756348
      policy_entropy: 0.009048367850482464
      policy_loss: 7.67855055983091e-07
      var_gnorm: 24.5513973236084
      vf_explained_var: 0.0
      vf_loss: 9.351354492537212e-06
    num_steps_sampled: 530000
    num_steps_trained: 530000
    wait_time_ms: 71.898
  iterations_since_restore: 106
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 889.4789209365845
  time_this_iter_s: 8.236725568771362
  time_total_s: 889.4789209365845
  timestamp: 1594859183
  timesteps_since_restore: 530000
  timesteps_this_iter: 5000
  timesteps_total: 530000
  training_iteration: 106
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 24.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 889 s, 106 iter, 530000 ts, -6.79e+04 rew

agent-1: 3.0
agent-2: -199.999999997859
agent-3: -98.9999999988954
agent-4: -199.999999997859
agent-5: -199.999999997859
Extrinsic Rewards:
3
0
1
0
0
Sum Reward: 4
Avg Reward: 0.8
Min Reward: 0
Max Reward: 3
Gini Coefficient: 0.7
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-26-31
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -30116.86782658155
  episode_reward_min: -1395732.338799766
  episodes_this_iter: 1
  episodes_total: 106
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.995
    dispatch_time_ms: 8.924
    learner:
      cur_lr: 0.0013247020542621613
      grad_gnorm: 10.392906188964844
      policy_entropy: 0.009596552699804306
      policy_loss: 6.676669727312401e-05
      var_gnorm: 24.551294326782227
      vf_explained_var: 0.0
      vf_loss: 0.07206782698631287
    num_steps_sampled: 535000
    num_steps_trained: 535000
    wait_time_ms: 70.394
  iterations_since_restore: 107
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 897.6879830360413
  time_this_iter_s: 8.209062099456787
  time_total_s: 897.6879830360413
  timestamp: 1594859191
  timesteps_since_restore: 535000
  timesteps_this_iter: 5000
  timesteps_total: 535000
  training_iteration: 107
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 24.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 897 s, 107 iter, 535000 ts, -3.01e+04 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-26-40
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -16159.544438583893
  episode_reward_min: -1372209.6113443861
  episodes_this_iter: 1
  episodes_total: 107
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.653
    dispatch_time_ms: 10.2
    learner:
      cur_lr: 0.0013243689900264144
      grad_gnorm: 30.096128463745117
      policy_entropy: 0.010188452899456024
      policy_loss: 9.860576392384246e-05
      var_gnorm: 24.55222511291504
      vf_explained_var: 0.0
      vf_loss: 0.6009842753410339
    num_steps_sampled: 540000
    num_steps_trained: 540000
    wait_time_ms: 70.925
  iterations_since_restore: 108
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 906.0182120800018
  time_this_iter_s: 8.330229043960571
  time_total_s: 906.0182120800018
  timestamp: 1594859200
  timesteps_since_restore: 540000
  timesteps_this_iter: 5000
  timesteps_total: 540000
  training_iteration: 108
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 24.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 906 s, 108 iter, 540000 ts, -1.62e+04 rew

agent-1: -149.99999999840443
agent-2: 3.0
agent-3: -149.99999999840443
agent-4: -149.99999999840443
agent-5: -149.99999999840443
Extrinsic Rewards:
0
3
0
0
0
Sum Reward: 3
Avg Reward: 0.6
Min Reward: 0
Max Reward: 3
Gini Coefficient: 0.8
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-26-48
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -2443.4183251399645
  episode_reward_min: -90846.2646354362
  episodes_this_iter: 1
  episodes_total: 108
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 3.385
    dispatch_time_ms: 9.497
    learner:
      cur_lr: 0.0013240360422059894
      grad_gnorm: 0.1385727971792221
      policy_entropy: 0.009577590972185135
      policy_loss: 6.265056526899571e-07
      var_gnorm: 24.551313400268555
      vf_explained_var: 5.960464477539063e-08
      vf_loss: 1.2738363693642896e-05
    num_steps_sampled: 545000
    num_steps_trained: 545000
    wait_time_ms: 70.83
  iterations_since_restore: 109
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 914.3350930213928
  time_this_iter_s: 8.316880941390991
  time_total_s: 914.3350930213928
  timestamp: 1594859208
  timesteps_since_restore: 545000
  timesteps_this_iter: 5000
  timesteps_total: 545000
  training_iteration: 109
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 914 s, 109 iter, 545000 ts, -2.44e+03 rew

agent-1: 3.0
agent-2: -299.9999999968351
agent-3: -47.99999999945478
agent-4: -148.99999999839173
agent-5: -299.9999999968351
Extrinsic Rewards:
3
0
2
1
0
Sum Reward: 6
Avg Reward: 1.2
Min Reward: 0
Max Reward: 3
Gini Coefficient: 0.5333333333333333
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-26-56
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -2437.528509170995
  episode_reward_min: -90846.2646354362
  episodes_this_iter: 1
  episodes_total: 109
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.865
    dispatch_time_ms: 10.87
    learner:
      cur_lr: 0.0013237029779702425
      grad_gnorm: 11.665531158447266
      policy_entropy: 0.010859442874789238
      policy_loss: 4.6950444811955094e-05
      var_gnorm: 24.552040100097656
      vf_explained_var: 1.7881393432617188e-07
      vf_loss: 0.13639330863952637
    num_steps_sampled: 550000
    num_steps_trained: 550000
    wait_time_ms: 66.525
  iterations_since_restore: 110
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 922.549587726593
  time_this_iter_s: 8.214494705200195
  time_total_s: 922.549587726593
  timestamp: 1594859216
  timesteps_since_restore: 550000
  timesteps_this_iter: 5000
  timesteps_total: 550000
  training_iteration: 110
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 922 s, 110 iter, 550000 ts, -2.44e+03 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-27-04
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -1529.0658628166334
  episode_reward_min: -20684.138291576648
  episodes_this_iter: 1
  episodes_total: 110
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.867
    dispatch_time_ms: 9.25
    learner:
      cur_lr: 0.0013233700301498175
      grad_gnorm: 7.010469913482666
      policy_entropy: 0.010401226580142975
      policy_loss: 4.0932911360869184e-05
      var_gnorm: 24.5511417388916
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 0.032957885414361954
    num_steps_sampled: 555000
    num_steps_trained: 555000
    wait_time_ms: 70.57
  iterations_since_restore: 111
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 930.7067668437958
  time_this_iter_s: 8.157179117202759
  time_total_s: 930.7067668437958
  timestamp: 1594859224
  timesteps_since_restore: 555000
  timesteps_this_iter: 5000
  timesteps_total: 555000
  training_iteration: 111
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.3/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 930 s, 111 iter, 555000 ts, -1.53e+03 rew

agent-1: -99.99999999894987
agent-2: -99.99999999894987
agent-3: -99.99999999894987
agent-4: 2.0
agent-5: -99.99999999894987
Extrinsic Rewards:
0
0
0
2
0
Sum Reward: 2
Avg Reward: 0.4
Min Reward: 0
Max Reward: 2
Gini Coefficient: 0.8
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-27-15
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -1527.075862816656
  episode_reward_min: -20684.138291576648
  episodes_this_iter: 1
  episodes_total: 111
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.745
    dispatch_time_ms: 8.831
    learner:
      cur_lr: 0.0013230369659140706
      grad_gnorm: 0.47949454188346863
      policy_entropy: 0.012154700234532356
      policy_loss: -4.592756795318564e-06
      var_gnorm: 24.55204200744629
      vf_explained_var: 0.0
      vf_loss: 0.3096848726272583
    num_steps_sampled: 560000
    num_steps_trained: 560000
    wait_time_ms: 62.602
  iterations_since_restore: 112
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 940.7955167293549
  time_this_iter_s: 10.088749885559082
  time_total_s: 940.7955167293549
  timestamp: 1594859235
  timesteps_since_restore: 560000
  timesteps_this_iter: 5000
  timesteps_total: 560000
  training_iteration: 112
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 940 s, 112 iter, 560000 ts, -1.53e+03 rew

agent-1: 1.0
agent-2: -99.99999999896329
agent-3: 1.0
agent-4: -99.99999999896329
agent-5: -99.99999999896329
Extrinsic Rewards:
1
0
1
0
0
Sum Reward: 2
Avg Reward: 0.4
Min Reward: 0
Max Reward: 1
Gini Coefficient: 0.6
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-27-23
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -1518.080862818866
  episode_reward_min: -20684.138291576648
  episodes_this_iter: 1
  episodes_total: 112
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 3.086
    dispatch_time_ms: 12.99
    learner:
      cur_lr: 0.0013227040180936456
      grad_gnorm: 18.864961624145508
      policy_entropy: 0.00042675057193264365
      policy_loss: 2.4315477276104502e-06
      var_gnorm: 24.561857223510742
      vf_explained_var: 1.1920928955078125e-07
      vf_loss: 0.2437308430671692
    num_steps_sampled: 565000
    num_steps_trained: 565000
    wait_time_ms: 69.482
  iterations_since_restore: 113
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 949.0832059383392
  time_this_iter_s: 8.287689208984375
  time_total_s: 949.0832059383392
  timestamp: 1594859243
  timesteps_since_restore: 565000
  timesteps_this_iter: 5000
  timesteps_total: 565000
  training_iteration: 113
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 949 s, 113 iter, 565000 ts, -1.52e+03 rew

agent-1: -49.46874999938334
agent-2: -349.99999999613846
agent-3: 1.53125
agent-4: -349.99999999613846
agent-5: -349.99999999613846
Extrinsic Rewards:
3
0
4
0
0
Sum Reward: 7
Avg Reward: 1.4
Min Reward: 0
Max Reward: 4
Gini Coefficient: 0.6285714285714286
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-27-32
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -1419.1263197585417
  episode_reward_min: -20684.138291576648
  episodes_this_iter: 1
  episodes_total: 113
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.742
    dispatch_time_ms: 11.147
    learner:
      cur_lr: 0.0013223709538578987
      grad_gnorm: 29.875350952148438
      policy_entropy: 0.00042351637966930866
      policy_loss: 3.309452267785673e-06
      var_gnorm: 24.56230354309082
      vf_explained_var: 0.0
      vf_loss: 0.5922005772590637
    num_steps_sampled: 570000
    num_steps_trained: 570000
    wait_time_ms: 72.519
  iterations_since_restore: 114
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 957.5698018074036
  time_this_iter_s: 8.486595869064331
  time_total_s: 957.5698018074036
  timestamp: 1594859252
  timesteps_since_restore: 570000
  timesteps_this_iter: 5000
  timesteps_total: 570000
  training_iteration: 114
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 957 s, 114 iter, 570000 ts, -1.42e+03 rew

agent-1: -299.9999999967398
agent-2: -97.99999999895044
agent-3: -299.9999999967398
agent-4: -299.9999999967398
agent-5: 4.0
Extrinsic Rewards:
0
2
0
0
4
Sum Reward: 6
Avg Reward: 1.2
Min Reward: 0
Max Reward: 4
Gini Coefficient: 0.6666666666666666
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-27-40
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -1327.563733831751
  episode_reward_min: -20684.138291576648
  episodes_this_iter: 1
  episodes_total: 114
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.608
    dispatch_time_ms: 9.527
    learner:
      cur_lr: 0.0013220380060374737
      grad_gnorm: 21.476123809814453
      policy_entropy: 0.00042362656677141786
      policy_loss: 2.7505955131346127e-06
      var_gnorm: 24.561681747436523
      vf_explained_var: 0.0
      vf_loss: 0.306022971868515
    num_steps_sampled: 575000
    num_steps_trained: 575000
    wait_time_ms: 71.65
  iterations_since_restore: 115
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 965.9926760196686
  time_this_iter_s: 8.422874212265015
  time_total_s: 965.9926760196686
  timestamp: 1594859260
  timesteps_since_restore: 575000
  timesteps_this_iter: 5000
  timesteps_total: 575000
  training_iteration: 115
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 965 s, 115 iter, 575000 ts, -1.33e+03 rew

agent-1: 3.0
agent-2: -199.99999999788645
agent-3: -199.99999999788645
agent-4: -199.99999999788645
agent-5: -98.999999998923
Extrinsic Rewards:
3
0
0
0
1
Sum Reward: 4
Avg Reward: 0.8
Min Reward: 0
Max Reward: 3
Gini Coefficient: 0.7
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-27-48
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -1225.053884065579
  episode_reward_min: -20684.138291576648
  episodes_this_iter: 1
  episodes_total: 115
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 3.016
    dispatch_time_ms: 11.232
    learner:
      cur_lr: 0.0013217049418017268
      grad_gnorm: 15.606822967529297
      policy_entropy: 0.00042377127101644874
      policy_loss: 2.0103107090108097e-06
      var_gnorm: 24.56156349182129
      vf_explained_var: 0.0
      vf_loss: 0.16332431137561798
    num_steps_sampled: 580000
    num_steps_trained: 580000
    wait_time_ms: 69.667
  iterations_since_restore: 116
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 974.3230292797089
  time_this_iter_s: 8.330353260040283
  time_total_s: 974.3230292797089
  timestamp: 1594859268
  timesteps_since_restore: 580000
  timesteps_this_iter: 5000
  timesteps_total: 580000
  training_iteration: 116
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 974 s, 116 iter, 580000 ts, -1.23e+03 rew

agent-1: 3.0
agent-2: -199.99999999788645
agent-3: -98.999999998923
agent-4: -199.99999999788645
agent-5: -199.99999999788645
Extrinsic Rewards:
3
0
1
0
0
Sum Reward: 4
Avg Reward: 0.8
Min Reward: 0
Max Reward: 3
Gini Coefficient: 0.7
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-27-57
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -1225.0532590655803
  episode_reward_min: -20684.138291576648
  episodes_this_iter: 1
  episodes_total: 116
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.349
    dispatch_time_ms: 9.887
    learner:
      cur_lr: 0.0013213719939813018
      grad_gnorm: 20.3018856048584
      policy_entropy: 0.00042401367682032287
      policy_loss: 2.632586983963847e-06
      var_gnorm: 24.561586380004883
      vf_explained_var: 0.0
      vf_loss: 0.27347272634506226
    num_steps_sampled: 585000
    num_steps_trained: 585000
    wait_time_ms: 74.737
  iterations_since_restore: 117
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 982.740202665329
  time_this_iter_s: 8.417173385620117
  time_total_s: 982.740202665329
  timestamp: 1594859277
  timesteps_since_restore: 585000
  timesteps_this_iter: 5000
  timesteps_total: 585000
  training_iteration: 117
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 982 s, 117 iter, 585000 ts, -1.23e+03 rew

agent-1: -49.999999999481645
agent-2: -49.999999999481645
agent-3: 1.0
agent-4: -49.999999999481645
agent-5: -49.999999999481645
Extrinsic Rewards:
0
0
1
0
0
Sum Reward: 1
Avg Reward: 0.2
Min Reward: 0
Max Reward: 1
Gini Coefficient: 0.8
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-28-05
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -1227.0432590655596
  episode_reward_min: -20684.138291576648
  episodes_this_iter: 1
  episodes_total: 117
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 3.404
    dispatch_time_ms: 8.551
    learner:
      cur_lr: 0.0013210390461608768
      grad_gnorm: 13.226984024047852
      policy_entropy: 0.0004243472358211875
      policy_loss: 1.490459794695198e-06
      var_gnorm: 24.56223487854004
      vf_explained_var: 1.7881393432617188e-07
      vf_loss: 0.15980207920074463
    num_steps_sampled: 590000
    num_steps_trained: 590000
    wait_time_ms: 73.452
  iterations_since_restore: 118
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 991.173469543457
  time_this_iter_s: 8.433266878128052
  time_total_s: 991.173469543457
  timestamp: 1594859285
  timesteps_since_restore: 590000
  timesteps_this_iter: 5000
  timesteps_total: 590000
  training_iteration: 118
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 991 s, 118 iter, 590000 ts, -1.23e+03 rew

agent-1: 3.0
agent-2: -149.99999999837684
agent-3: -149.99999999837684
agent-4: -149.99999999837684
agent-5: -149.99999999837684
Extrinsic Rewards:
3
0
0
0
0
Sum Reward: 3
Avg Reward: 0.6
Min Reward: 0
Max Reward: 3
Gini Coefficient: 0.8
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-28-14
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -1228.0432590655475
  episode_reward_min: -20684.138291576648
  episodes_this_iter: 1
  episodes_total: 118
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.63
    dispatch_time_ms: 9.153
    learner:
      cur_lr: 0.0013207059819251299
      grad_gnorm: 19.352813720703125
      policy_entropy: 0.00042438507080078125
      policy_loss: 2.3020902517600916e-06
      var_gnorm: 24.561508178710938
      vf_explained_var: 0.0
      vf_loss: 0.24850164353847504
    num_steps_sampled: 595000
    num_steps_trained: 595000
    wait_time_ms: 71.224
  iterations_since_restore: 119
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 999.5981163978577
  time_this_iter_s: 8.424646854400635
  time_total_s: 999.5981163978577
  timestamp: 1594859294
  timesteps_since_restore: 595000
  timesteps_this_iter: 5000
  timesteps_total: 595000
  training_iteration: 119
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 999 s, 119 iter, 595000 ts, -1.23e+03 rew

agent-1: -199.99999999780377
agent-2: -199.99999999780377
agent-3: -199.99999999780377
agent-4: 4.0
agent-5: -199.99999999780377
Extrinsic Rewards:
0
0
0
4
0
Sum Reward: 4
Avg Reward: 0.8
Min Reward: 0
Max Reward: 4
Gini Coefficient: 0.8
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-28-23
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -1230.0332590655232
  episode_reward_min: -20684.138291576648
  episodes_this_iter: 1
  episodes_total: 119
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.97
    dispatch_time_ms: 9.323
    learner:
      cur_lr: 0.0013203730341047049
      grad_gnorm: 0.48597368597984314
      policy_entropy: 0.00042333651799708605
      policy_loss: -9.417619395435395e-08
      var_gnorm: 24.56135368347168
      vf_explained_var: 0.0
      vf_loss: 0.00015669967979192734
    num_steps_sampled: 600000
    num_steps_trained: 600000
    wait_time_ms: 70.731
  iterations_since_restore: 120
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 1007.6408865451813
  time_this_iter_s: 8.042770147323608
  time_total_s: 1007.6408865451813
  timestamp: 1594859303
  timesteps_since_restore: 600000
  timesteps_this_iter: 5000
  timesteps_total: 600000
  training_iteration: 120
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 1007 s, 120 iter, 600000 ts, -1.23e+03 rew

agent-1: -48.99999999948169
agent-2: -149.99999999841847
agent-3: -149.99999999841847
agent-4: 2.0
agent-5: -149.99999999841847
Extrinsic Rewards:
1
0
0
2
0
Sum Reward: 3
Avg Reward: 0.6
Min Reward: 0
Max Reward: 2
Gini Coefficient: 0.6666666666666666
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-28-32
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -1133.499959073748
  episode_reward_min: -20684.138291576648
  episodes_this_iter: 1
  episodes_total: 120
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.802
    dispatch_time_ms: 13.147
    learner:
      cur_lr: 0.001320039969868958
      grad_gnorm: 14.779623985290527
      policy_entropy: 0.0004244831798132509
      policy_loss: 2.7855762709805276e-06
      var_gnorm: 24.561397552490234
      vf_explained_var: 1.1920928955078125e-07
      vf_loss: 0.14572060108184814
    num_steps_sampled: 605000
    num_steps_trained: 605000
    wait_time_ms: 70.477
  iterations_since_restore: 121
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 1015.7347354888916
  time_this_iter_s: 8.093848943710327
  time_total_s: 1015.7347354888916
  timestamp: 1594859312
  timesteps_since_restore: 605000
  timesteps_this_iter: 5000
  timesteps_total: 605000
  training_iteration: 121
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 1015 s, 121 iter, 605000 ts, -1.13e+03 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-28-45
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -1125.5343340738336
  episode_reward_min: -20684.138291576648
  episodes_this_iter: 1
  episodes_total: 121
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 3.053
    dispatch_time_ms: 22.3
    learner:
      cur_lr: 0.001319707022048533
      grad_gnorm: 4.69474458694458
      policy_entropy: 0.00042536010732874274
      policy_loss: -5.752970650974021e-07
      var_gnorm: 24.56151008605957
      vf_explained_var: 5.960464477539063e-08
      vf_loss: 0.08114125579595566
    num_steps_sampled: 610000
    num_steps_trained: 610000
    wait_time_ms: 62.462
  iterations_since_restore: 122
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 1029.6219494342804
  time_this_iter_s: 13.887213945388794
  time_total_s: 1029.6219494342804
  timestamp: 1594859325
  timesteps_since_restore: 610000
  timesteps_this_iter: 5000
  timesteps_total: 610000
  training_iteration: 122
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 1029 s, 122 iter, 610000 ts, -1.13e+03 rew

agent-1: -99.99999999894987
agent-2: -99.99999999894987
agent-3: -99.99999999894987
agent-4: -99.99999999894987
agent-5: 2.0
Extrinsic Rewards:
0
0
0
0
2
Sum Reward: 2
Avg Reward: 0.4
Min Reward: 0
Max Reward: 2
Gini Coefficient: 0.8
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-28-54
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -1022.0277491841214
  episode_reward_min: -20684.138291576648
  episodes_this_iter: 1
  episodes_total: 122
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.828
    dispatch_time_ms: 27.31
    learner:
      cur_lr: 0.001319373957812786
      grad_gnorm: 24.015430450439453
      policy_entropy: 0.0004260545829311013
      policy_loss: 3.1569848033541348e-06
      var_gnorm: 24.561687469482422
      vf_explained_var: 0.0
      vf_loss: 0.38266831636428833
    num_steps_sampled: 615000
    num_steps_trained: 615000
    wait_time_ms: 60.891
  iterations_since_restore: 123
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 1038.3018794059753
  time_this_iter_s: 8.679929971694946
  time_total_s: 1038.3018794059753
  timestamp: 1594859334
  timesteps_since_restore: 615000
  timesteps_this_iter: 5000
  timesteps_total: 615000
  training_iteration: 123
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 1038 s, 123 iter, 615000 ts, -1.02e+03 rew

agent-1: 2.75
agent-2: -299.9999999967528
agent-3: -299.9999999967528
agent-4: -299.9999999967528
agent-5: -99.2499999988536
Extrinsic Rewards:
4
0
0
0
2
Sum Reward: 6
Avg Reward: 1.2
Min Reward: 0
Max Reward: 4
Gini Coefficient: 0.6666666666666666
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-29-03
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -955.7138244009086
  episode_reward_min: -20684.138291576648
  episodes_this_iter: 1
  episodes_total: 123
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.8
    dispatch_time_ms: 18.692
    learner:
      cur_lr: 0.001319041009992361
      grad_gnorm: 12.285785675048828
      policy_entropy: 0.0004260689893271774
      policy_loss: 1.4789641227253014e-06
      var_gnorm: 24.56131362915039
      vf_explained_var: 0.0
      vf_loss: 0.10318008065223694
    num_steps_sampled: 620000
    num_steps_trained: 620000
    wait_time_ms: 67.514
  iterations_since_restore: 124
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 1047.0370478630066
  time_this_iter_s: 8.73516845703125
  time_total_s: 1047.0370478630066
  timestamp: 1594859343
  timesteps_since_restore: 620000
  timesteps_this_iter: 5000
  timesteps_total: 620000
  training_iteration: 124
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 1047 s, 124 iter, 620000 ts, -956 rew

agent-1: -199.99999999780377
agent-2: -199.99999999780377
agent-3: -199.99999999780377
agent-4: 4.0
agent-5: -199.99999999780377
Extrinsic Rewards:
0
0
0
4
0
Sum Reward: 4
Avg Reward: 0.8
Min Reward: 0
Max Reward: 4
Gini Coefficient: 0.8
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-29-12
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -757.1164107706096
  episode_reward_min: -20684.138291576648
  episodes_this_iter: 1
  episodes_total: 124
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.817
    dispatch_time_ms: 23.335
    learner:
      cur_lr: 0.0013187079457566142
      grad_gnorm: 13.701386451721191
      policy_entropy: 0.0004263287701178342
      policy_loss: 2.2248907498578774e-06
      var_gnorm: 24.56148338317871
      vf_explained_var: 0.0
      vf_loss: 0.13237473368644714
    num_steps_sampled: 625000
    num_steps_trained: 625000
    wait_time_ms: 66.867
  iterations_since_restore: 125
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 1055.745798110962
  time_this_iter_s: 8.708750247955322
  time_total_s: 1055.745798110962
  timestamp: 1594859352
  timesteps_since_restore: 625000
  timesteps_this_iter: 5000
  timesteps_total: 625000
  training_iteration: 125
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 1055 s, 125 iter, 625000 ts, -757 rew

agent-1: -99.99999999894987
agent-2: -99.99999999894987
agent-3: -99.99999999894987
agent-4: -99.99999999894987
agent-5: 2.0
Extrinsic Rewards:
0
0
0
0
2
Sum Reward: 2
Avg Reward: 0.4
Min Reward: 0
Max Reward: 2
Gini Coefficient: 0.8
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-29-21
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -554.2550278548011
  episode_reward_min: -10150.999997975141
  episodes_this_iter: 1
  episodes_total: 125
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.525
    dispatch_time_ms: 23.216
    learner:
      cur_lr: 0.0013183749979361892
      grad_gnorm: 23.162490844726562
      policy_entropy: 0.0004266475443728268
      policy_loss: 2.7562566629057983e-06
      var_gnorm: 24.561586380004883
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 0.35597026348114014
    num_steps_sampled: 630000
    num_steps_trained: 630000
    wait_time_ms: 74.889
  iterations_since_restore: 126
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 1064.5683665275574
  time_this_iter_s: 8.822568416595459
  time_total_s: 1064.5683665275574
  timestamp: 1594859361
  timesteps_since_restore: 630000
  timesteps_this_iter: 5000
  timesteps_total: 630000
  training_iteration: 126
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 1064 s, 126 iter, 630000 ts, -554 rew

agent-1: -149.99999999837684
agent-2: -149.99999999837684
agent-3: -149.99999999837684
agent-4: -149.99999999837684
agent-5: 3.0
Extrinsic Rewards:
0
0
0
0
3
Sum Reward: 3
Avg Reward: 0.6
Min Reward: 0
Max Reward: 3
Gini Coefficient: 0.8
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-29-29
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -558.2150287151404
  episode_reward_min: -10150.999997975141
  episodes_this_iter: 1
  episodes_total: 126
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 3.26
    dispatch_time_ms: 22.529
    learner:
      cur_lr: 0.0013180420501157641
      grad_gnorm: 23.03548240661621
      policy_entropy: 0.0004264707677066326
      policy_loss: 2.5661036033852724e-06
      var_gnorm: 24.561594009399414
      vf_explained_var: 5.960464477539063e-08
      vf_loss: 0.3548595607280731
    num_steps_sampled: 635000
    num_steps_trained: 635000
    wait_time_ms: 68.692
  iterations_since_restore: 127
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 1073.3479301929474
  time_this_iter_s: 8.779563665390015
  time_total_s: 1073.3479301929474
  timestamp: 1594859369
  timesteps_since_restore: 635000
  timesteps_this_iter: 5000
  timesteps_total: 635000
  training_iteration: 127
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 1073 s, 127 iter, 635000 ts, -558 rew

agent-1: 2.75
agent-2: -449.99999999510266
agent-3: -449.99999999510266
agent-4: -151.71874999825206
agent-5: -49.468749999454744
Extrinsic Rewards:
4
0
0
2
3
Sum Reward: 9
Avg Reward: 1.8
Min Reward: 0
Max Reward: 4
Gini Coefficient: 0.4888888888888889
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-29-38
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -561.2394037151074
  episode_reward_min: -10150.999997975141
  episodes_this_iter: 1
  episodes_total: 127
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 3.032
    dispatch_time_ms: 27.075
    learner:
      cur_lr: 0.0013177089858800173
      grad_gnorm: 13.140276908874512
      policy_entropy: 0.00042707016109488904
      policy_loss: 3.6158523926133057e-06
      var_gnorm: 24.561208724975586
      vf_explained_var: 1.1920928955078125e-07
      vf_loss: 0.11612768471240997
    num_steps_sampled: 640000
    num_steps_trained: 640000
    wait_time_ms: 49.497
  iterations_since_restore: 128
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 1081.9447507858276
  time_this_iter_s: 8.596820592880249
  time_total_s: 1081.9447507858276
  timestamp: 1594859378
  timesteps_since_restore: 640000
  timesteps_this_iter: 5000
  timesteps_total: 640000
  training_iteration: 128
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 1081 s, 128 iter, 640000 ts, -561 rew

agent-1: -149.99999999837684
agent-2: -149.99999999837684
agent-3: -149.99999999837684
agent-4: -149.99999999837684
agent-5: 3.0
Extrinsic Rewards:
0
0
0
0
3
Sum Reward: 3
Avg Reward: 0.6
Min Reward: 0
Max Reward: 3
Gini Coefficient: 0.8
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-29-47
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -560.2494037151178
  episode_reward_min: -10150.999997975141
  episodes_this_iter: 1
  episodes_total: 128
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 3.247
    dispatch_time_ms: 16.965
    learner:
      cur_lr: 0.0013173760380595922
      grad_gnorm: 0.046686045825481415
      policy_entropy: 0.00042647530790418386
      policy_loss: 1.1256976684137499e-08
      var_gnorm: 24.56116485595703
      vf_explained_var: 0.0
      vf_loss: 1.4458203168032924e-06
    num_steps_sampled: 645000
    num_steps_trained: 645000
    wait_time_ms: 68.051
  iterations_since_restore: 129
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 1090.7380878925323
  time_this_iter_s: 8.793337106704712
  time_total_s: 1090.7380878925323
  timestamp: 1594859387
  timesteps_since_restore: 645000
  timesteps_this_iter: 5000
  timesteps_total: 645000
  training_iteration: 129
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 1090 s, 129 iter, 645000 ts, -560 rew

agent-1: -48.9999999994684
agent-2: 2.0
agent-3: -149.9999999984318
agent-4: -149.9999999984318
agent-5: -149.9999999984318
Extrinsic Rewards:
1
2
0
0
0
Sum Reward: 3
Avg Reward: 0.6
Min Reward: 0
Max Reward: 2
Gini Coefficient: 0.6666666666666666
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-29-56
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -559.2494037151292
  episode_reward_min: -10150.999997975141
  episodes_this_iter: 1
  episodes_total: 129
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.554
    dispatch_time_ms: 18.296
    learner:
      cur_lr: 0.0013170429738238454
      grad_gnorm: 0.07156584411859512
      policy_entropy: 0.00042744434904307127
      policy_loss: 1.5115370288754093e-08
      var_gnorm: 24.561128616333008
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 3.3997778245975496e-06
    num_steps_sampled: 650000
    num_steps_trained: 650000
    wait_time_ms: 67.692
  iterations_since_restore: 130
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 1099.5675597190857
  time_this_iter_s: 8.829471826553345
  time_total_s: 1099.5675597190857
  timestamp: 1594859396
  timesteps_since_restore: 650000
  timesteps_this_iter: 5000
  timesteps_total: 650000
  training_iteration: 130
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 1099 s, 130 iter, 650000 ts, -559 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-30-05
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -559.2494037151293
  episode_reward_min: -10150.999997975141
  episodes_this_iter: 1
  episodes_total: 130
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 3.842
    dispatch_time_ms: 30.573
    learner:
      cur_lr: 0.0013167100260034204
      grad_gnorm: 0.17654813826084137
      policy_entropy: 0.0004284758470021188
      policy_loss: 8.913035642876821e-09
      var_gnorm: 24.561092376708984
      vf_explained_var: 0.0
      vf_loss: 1.73019780049799e-05
    num_steps_sampled: 655000
    num_steps_trained: 655000
    wait_time_ms: 52.958
  iterations_since_restore: 131
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 1108.3607597351074
  time_this_iter_s: 8.793200016021729
  time_total_s: 1108.3607597351074
  timestamp: 1594859405
  timesteps_since_restore: 655000
  timesteps_this_iter: 5000
  timesteps_total: 655000
  training_iteration: 131
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 1108 s, 131 iter, 655000 ts, -559 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-30-13
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -553.279403715193
  episode_reward_min: -10150.999997975141
  episodes_this_iter: 1
  episodes_total: 131
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.865
    dispatch_time_ms: 26.116
    learner:
      cur_lr: 0.0013163769617676735
      grad_gnorm: 0.09134702384471893
      policy_entropy: 0.000429549312684685
      policy_loss: 1.165431862126809e-09
      var_gnorm: 24.56105613708496
      vf_explained_var: 5.960464477539063e-08
      vf_loss: 4.4029120545019396e-06
    num_steps_sampled: 660000
    num_steps_trained: 660000
    wait_time_ms: 67.088
  iterations_since_restore: 132
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 1117.1343615055084
  time_this_iter_s: 8.773601770401001
  time_total_s: 1117.1343615055084
  timestamp: 1594859413
  timesteps_since_restore: 660000
  timesteps_this_iter: 5000
  timesteps_total: 660000
  training_iteration: 132
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 1117 s, 132 iter, 660000 ts, -553 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-30-22
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -549.2994037152349
  episode_reward_min: -10150.999997975141
  episodes_this_iter: 1
  episodes_total: 132
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 3.502
    dispatch_time_ms: 31.913
    learner:
      cur_lr: 0.0013160440139472485
      grad_gnorm: 29.459980010986328
      policy_entropy: 0.00043221883242949843
      policy_loss: 2.5680458293209085e-06
      var_gnorm: 24.56142807006836
      vf_explained_var: 0.0
      vf_loss: 0.532289981842041
    num_steps_sampled: 665000
    num_steps_trained: 665000
    wait_time_ms: 44.303
  iterations_since_restore: 133
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 1125.821257352829
  time_this_iter_s: 8.686895847320557
  time_total_s: 1125.821257352829
  timestamp: 1594859422
  timesteps_since_restore: 665000
  timesteps_this_iter: 5000
  timesteps_total: 665000
  training_iteration: 133
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 1125 s, 133 iter, 665000 ts, -549 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-30-31
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -542.3394037153093
  episode_reward_min: -10150.999997975141
  episodes_this_iter: 1
  episodes_total: 133
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 4.163
    dispatch_time_ms: 30.52
    learner:
      cur_lr: 0.0013157109497115016
      grad_gnorm: 13.014842987060547
      policy_entropy: 0.00043289989116601646
      policy_loss: 2.354167691009934e-06
      var_gnorm: 24.560997009277344
      vf_explained_var: 0.0
      vf_loss: 0.11309588700532913
    num_steps_sampled: 670000
    num_steps_trained: 670000
    wait_time_ms: 47.214
  iterations_since_restore: 134
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 1134.3566133975983
  time_this_iter_s: 8.535356044769287
  time_total_s: 1134.3566133975983
  timestamp: 1594859431
  timesteps_since_restore: 670000
  timesteps_this_iter: 5000
  timesteps_total: 670000
  training_iteration: 134
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 1134 s, 134 iter, 670000 ts, -542 rew

agent-1: -199.99999999780377
agent-2: -199.99999999780377
agent-3: 4.0
agent-4: -199.99999999780377
agent-5: -199.99999999780377
Extrinsic Rewards:
0
0
4
0
0
Sum Reward: 4
Avg Reward: 0.8
Min Reward: 0
Max Reward: 4
Gini Coefficient: 0.8
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-30-39
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -543.3394037152959
  episode_reward_min: -10150.999997975141
  episodes_this_iter: 1
  episodes_total: 134
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 3.21
    dispatch_time_ms: 24.566
    learner:
      cur_lr: 0.0013153780018910766
      grad_gnorm: 22.245946884155273
      policy_entropy: 0.0004330557130742818
      policy_loss: 1.5356273479483207e-06
      var_gnorm: 24.56129264831543
      vf_explained_var: 0.0
      vf_loss: 0.3283557891845703
    num_steps_sampled: 675000
    num_steps_trained: 675000
    wait_time_ms: 58.834
  iterations_since_restore: 135
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 1142.9903645515442
  time_this_iter_s: 8.633751153945923
  time_total_s: 1142.9903645515442
  timestamp: 1594859439
  timesteps_since_restore: 675000
  timesteps_this_iter: 5000
  timesteps_total: 675000
  training_iteration: 135
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 1142 s, 135 iter, 675000 ts, -543 rew

agent-1: 4.0
agent-2: -249.99999999731412
agent-3: -249.99999999731412
agent-4: -148.99999999837678
agent-5: -249.99999999731412
Extrinsic Rewards:
4
0
0
1
0
Sum Reward: 5
Avg Reward: 1.0
Min Reward: 0
Max Reward: 4
Gini Coefficient: 0.72
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-30-48
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -546.3234509831456
  episode_reward_min: -10150.999997975141
  episodes_this_iter: 1
  episodes_total: 135
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.963
    dispatch_time_ms: 21.097
    learner:
      cur_lr: 0.0013150450540706515
      grad_gnorm: 6.97044038772583
      policy_entropy: 0.00043290609028190374
      policy_loss: 1.1692687849063077e-06
      var_gnorm: 24.560867309570312
      vf_explained_var: 0.0
      vf_loss: 0.04136938601732254
    num_steps_sampled: 680000
    num_steps_trained: 680000
    wait_time_ms: 66.435
  iterations_since_restore: 136
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 1151.7459406852722
  time_this_iter_s: 8.755576133728027
  time_total_s: 1151.7459406852722
  timestamp: 1594859448
  timesteps_since_restore: 680000
  timesteps_this_iter: 5000
  timesteps_total: 680000
  training_iteration: 136
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 1151 s, 136 iter, 680000 ts, -546 rew

agent-1: -149.99999999837684
agent-2: -149.99999999837684
agent-3: 3.0
agent-4: -149.99999999837684
agent-5: -149.99999999837684
Extrinsic Rewards:
0
0
3
0
0
Sum Reward: 3
Avg Reward: 0.6
Min Reward: 0
Max Reward: 3
Gini Coefficient: 0.8
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-30-57
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -552.2934509830808
  episode_reward_min: -10150.999997975141
  episodes_this_iter: 1
  episodes_total: 136
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 3.186
    dispatch_time_ms: 20.696
    learner:
      cur_lr: 0.0013147119898349047
      grad_gnorm: 19.20573616027832
      policy_entropy: 0.00043333086068741977
      policy_loss: 6.380383297255321e-07
      var_gnorm: 24.561098098754883
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 0.24473948776721954
    num_steps_sampled: 685000
    num_steps_trained: 685000
    wait_time_ms: 58.115
  iterations_since_restore: 137
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 1160.3549587726593
  time_this_iter_s: 8.609018087387085
  time_total_s: 1160.3549587726593
  timestamp: 1594859457
  timesteps_since_restore: 685000
  timesteps_this_iter: 5000
  timesteps_total: 685000
  training_iteration: 137
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 1160 s, 137 iter, 685000 ts, -552 rew

agent-1: -149.99999999837684
agent-2: -149.99999999837684
agent-3: 3.0
agent-4: -149.99999999837684
agent-5: -149.99999999837684
Extrinsic Rewards:
0
0
3
0
0
Sum Reward: 3
Avg Reward: 0.6
Min Reward: 0
Max Reward: 3
Gini Coefficient: 0.8
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-31-06
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -548.323450983123
  episode_reward_min: -10150.999997975141
  episodes_this_iter: 1
  episodes_total: 137
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.595
    dispatch_time_ms: 19.394
    learner:
      cur_lr: 0.0013143790420144796
      grad_gnorm: 12.826861381530762
      policy_entropy: 0.0004399054159875959
      policy_loss: 4.6988452595542185e-06
      var_gnorm: 24.56085968017578
      vf_explained_var: 0.0
      vf_loss: 0.10916464775800705
    num_steps_sampled: 690000
    num_steps_trained: 690000
    wait_time_ms: 67.342
  iterations_since_restore: 138
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 1169.1073772907257
  time_this_iter_s: 8.752418518066406
  time_total_s: 1169.1073772907257
  timestamp: 1594859466
  timesteps_since_restore: 690000
  timesteps_this_iter: 5000
  timesteps_total: 690000
  training_iteration: 138
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 1169 s, 138 iter, 690000 ts, -548 rew

agent-1: -199.99999999788645
agent-2: -199.99999999788645
agent-3: -98.999999998923
agent-4: -199.99999999788645
agent-5: 3.0
Extrinsic Rewards:
0
0
1
0
3
Sum Reward: 4
Avg Reward: 0.8
Min Reward: 0
Max Reward: 3
Gini Coefficient: 0.7
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-31-14
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -549.3134509831137
  episode_reward_min: -10150.999997975141
  episodes_this_iter: 1
  episodes_total: 138
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.667
    dispatch_time_ms: 26.651
    learner:
      cur_lr: 0.0013140459777787328
      grad_gnorm: 40.0
      policy_entropy: 0.00043336712406016886
      policy_loss: -6.484605364676099e-06
      var_gnorm: 24.561290740966797
      vf_explained_var: 0.0
      vf_loss: 2.05047869682312
    num_steps_sampled: 695000
    num_steps_trained: 695000
    wait_time_ms: 56.964
  iterations_since_restore: 139
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 1177.8096404075623
  time_this_iter_s: 8.702263116836548
  time_total_s: 1177.8096404075623
  timestamp: 1594859474
  timesteps_since_restore: 695000
  timesteps_this_iter: 5000
  timesteps_total: 695000
  training_iteration: 139
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 1177 s, 139 iter, 695000 ts, -549 rew

agent-1: 4.0
agent-2: -199.99999999784504
agent-3: -199.99999999784504
agent-4: -199.99999999784504
agent-5: -199.99999999784504
Extrinsic Rewards:
4
0
0
0
0
Sum Reward: 4
Avg Reward: 0.8
Min Reward: 0
Max Reward: 4
Gini Coefficient: 0.8
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-31-23
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -557.2734509830275
  episode_reward_min: -10150.999997975141
  episodes_this_iter: 1
  episodes_total: 139
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 3.363
    dispatch_time_ms: 21.935
    learner:
      cur_lr: 0.0013137130299583077
      grad_gnorm: 16.882946014404297
      policy_entropy: 0.0004331539385020733
      policy_loss: 2.311811158506316e-06
      var_gnorm: 24.56096839904785
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 0.1891205757856369
    num_steps_sampled: 700000
    num_steps_trained: 700000
    wait_time_ms: 55.705
  iterations_since_restore: 140
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 1186.6315240859985
  time_this_iter_s: 8.82188367843628
  time_total_s: 1186.6315240859985
  timestamp: 1594859483
  timesteps_since_restore: 700000
  timesteps_this_iter: 5000
  timesteps_total: 700000
  training_iteration: 140
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 1186 s, 140 iter, 700000 ts, -557 rew

agent-1: 3.0
agent-2: -199.99999999788645
agent-3: -98.999999998923
agent-4: -199.99999999788645
agent-5: -199.99999999788645
Extrinsic Rewards:
3
0
1
0
0
Sum Reward: 4
Avg Reward: 0.8
Min Reward: 0
Max Reward: 3
Gini Coefficient: 0.7
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-31-33
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -564.2334509829533
  episode_reward_min: -10150.999997975141
  episodes_this_iter: 1
  episodes_total: 140
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 3.19
    dispatch_time_ms: 29.791
    learner:
      cur_lr: 0.0013133799657225609
      grad_gnorm: 0.5332457423210144
      policy_entropy: 0.00043035310227423906
      policy_loss: 1.2162992391040461e-07
      var_gnorm: 24.560901641845703
      vf_explained_var: 0.0
      vf_loss: 0.00018867501057684422
    num_steps_sampled: 705000
    num_steps_trained: 705000
    wait_time_ms: 50.073
  iterations_since_restore: 141
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 1196.118816614151
  time_this_iter_s: 9.487292528152466
  time_total_s: 1196.118816614151
  timestamp: 1594859493
  timesteps_since_restore: 705000
  timesteps_this_iter: 5000
  timesteps_total: 705000
  training_iteration: 141
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 1196 s, 141 iter, 705000 ts, -564 rew

agent-1: 4.0
agent-2: -199.99999999784504
agent-3: -199.99999999784504
agent-4: -199.99999999784504
agent-5: -199.99999999784504
Extrinsic Rewards:
4
0
0
0
0
Sum Reward: 4
Avg Reward: 0.8
Min Reward: 0
Max Reward: 4
Gini Coefficient: 0.8
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-31-42
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -565.2334509829417
  episode_reward_min: -10150.999997975141
  episodes_this_iter: 1
  episodes_total: 141
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.958
    dispatch_time_ms: 25.639
    learner:
      cur_lr: 0.0013130470179021358
      grad_gnorm: 8.812644958496094
      policy_entropy: 0.00043311668559908867
      policy_loss: 1.6050927342803334e-06
      var_gnorm: 24.560762405395508
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 0.051528528332710266
    num_steps_sampled: 710000
    num_steps_trained: 710000
    wait_time_ms: 62.526
  iterations_since_restore: 142
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 1204.8393363952637
  time_this_iter_s: 8.720519781112671
  time_total_s: 1204.8393363952637
  timestamp: 1594859502
  timesteps_since_restore: 710000
  timesteps_this_iter: 5000
  timesteps_total: 710000
  training_iteration: 142
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 1204 s, 142 iter, 710000 ts, -565 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-31-51
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -563.2434509829628
  episode_reward_min: -10150.999997975141
  episodes_this_iter: 1
  episodes_total: 142
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.65
    dispatch_time_ms: 20.077
    learner:
      cur_lr: 0.001312713953666389
      grad_gnorm: 11.635110855102539
      policy_entropy: 0.0004403114435262978
      policy_loss: -2.4320629563590046e-06
      var_gnorm: 24.56098747253418
      vf_explained_var: 0.0
      vf_loss: 0.25310230255126953
    num_steps_sampled: 715000
    num_steps_trained: 715000
    wait_time_ms: 66.022
  iterations_since_restore: 143
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 1213.4910023212433
  time_this_iter_s: 8.651665925979614
  time_total_s: 1213.4910023212433
  timestamp: 1594859511
  timesteps_since_restore: 715000
  timesteps_this_iter: 5000
  timesteps_total: 715000
  training_iteration: 143
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 1213 s, 143 iter, 715000 ts, -563 rew

agent-1: 2.0
agent-2: -48.9999999994684
agent-3: -149.9999999984318
agent-4: -149.9999999984318
agent-5: -149.9999999984318
Extrinsic Rewards:
2
1
0
0
0
Sum Reward: 3
Avg Reward: 0.6
Min Reward: 0
Max Reward: 2
Gini Coefficient: 0.6666666666666666
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-32-00
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -560.2240759829974
  episode_reward_min: -10150.999997975141
  episodes_this_iter: 1
  episodes_total: 143
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.617
    dispatch_time_ms: 16.978
    learner:
      cur_lr: 0.001312381005845964
      grad_gnorm: 6.068060874938965
      policy_entropy: 0.0004336070560384542
      policy_loss: 1.6958000514932792e-06
      var_gnorm: 24.560726165771484
      vf_explained_var: 0.0
      vf_loss: 0.024430956691503525
    num_steps_sampled: 720000
    num_steps_trained: 720000
    wait_time_ms: 70.805
  iterations_since_restore: 144
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 1222.1968388557434
  time_this_iter_s: 8.705836534500122
  time_total_s: 1222.1968388557434
  timestamp: 1594859520
  timesteps_since_restore: 720000
  timesteps_this_iter: 5000
  timesteps_total: 720000
  training_iteration: 144
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 1222 s, 144 iter, 720000 ts, -560 rew

agent-1: -49.99999999946836
agent-2: -49.99999999946836
agent-3: 1.0
agent-4: -49.99999999946836
agent-5: -49.99999999946836
Extrinsic Rewards:
0
0
1
0
0
Sum Reward: 1
Avg Reward: 0.2
Min Reward: 0
Max Reward: 1
Gini Coefficient: 0.8
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-32-08
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -460.7040760032248
  episode_reward_min: -1098.4374999878994
  episodes_this_iter: 1
  episodes_total: 144
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 3.128
    dispatch_time_ms: 30.886
    learner:
      cur_lr: 0.001312048058025539
      grad_gnorm: 17.217817306518555
      policy_entropy: 0.0004410852852743119
      policy_loss: -1.9002065982931526e-06
      var_gnorm: 24.560884475708008
      vf_explained_var: 1.1920928955078125e-07
      vf_loss: 0.19669751822948456
    num_steps_sampled: 725000
    num_steps_trained: 725000
    wait_time_ms: 52.433
  iterations_since_restore: 145
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 1230.9456858634949
  time_this_iter_s: 8.748847007751465
  time_total_s: 1230.9456858634949
  timestamp: 1594859528
  timesteps_since_restore: 725000
  timesteps_this_iter: 5000
  timesteps_total: 725000
  training_iteration: 145
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 1230 s, 145 iter, 725000 ts, -461 rew

agent-1: -99.99999999894987
agent-2: -99.99999999894987
agent-3: 2.0
agent-4: -99.99999999894987
agent-5: -99.99999999894987
Extrinsic Rewards:
0
0
2
0
0
Sum Reward: 2
Avg Reward: 0.4
Min Reward: 0
Max Reward: 2
Gini Coefficient: 0.8
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-32-17
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -459.7140760032355
  episode_reward_min: -1098.4374999878994
  episodes_this_iter: 1
  episodes_total: 145
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.569
    dispatch_time_ms: 26.645
    learner:
      cur_lr: 0.001311714993789792
      grad_gnorm: 0.1532943844795227
      policy_entropy: 0.0004400979378260672
      policy_loss: 7.23781639067056e-08
      var_gnorm: 24.560779571533203
      vf_explained_var: 1.1920928955078125e-07
      vf_loss: 1.559342308610212e-05
    num_steps_sampled: 730000
    num_steps_trained: 730000
    wait_time_ms: 58.868
  iterations_since_restore: 146
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 1239.6098093986511
  time_this_iter_s: 8.66412353515625
  time_total_s: 1239.6098093986511
  timestamp: 1594859537
  timesteps_since_restore: 730000
  timesteps_this_iter: 5000
  timesteps_total: 730000
  training_iteration: 146
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 1239 s, 146 iter, 730000 ts, -460 rew

agent-1: -149.9999999984318
agent-2: -48.9999999994684
agent-3: 2.0
agent-4: -149.9999999984318
agent-5: -149.9999999984318
Extrinsic Rewards:
0
1
2
0
0
Sum Reward: 3
Avg Reward: 0.6
Min Reward: 0
Max Reward: 2
Gini Coefficient: 0.6666666666666666
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-32-26
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -464.6840760031833
  episode_reward_min: -1098.4374999878994
  episodes_this_iter: 1
  episodes_total: 146
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.418
    dispatch_time_ms: 25.382
    learner:
      cur_lr: 0.001311382045969367
      grad_gnorm: 0.3782796561717987
      policy_entropy: 0.000442348828073591
      policy_loss: 1.2684354544489906e-07
      var_gnorm: 24.56072425842285
      vf_explained_var: 5.960464477539063e-08
      vf_loss: 9.493609832134098e-05
    num_steps_sampled: 735000
    num_steps_trained: 735000
    wait_time_ms: 63.661
  iterations_since_restore: 147
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 1248.2959523200989
  time_this_iter_s: 8.686142921447754
  time_total_s: 1248.2959523200989
  timestamp: 1594859546
  timesteps_since_restore: 735000
  timesteps_this_iter: 5000
  timesteps_total: 735000
  training_iteration: 147
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 1248 s, 147 iter, 735000 ts, -465 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-32-35
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -460.7040760032253
  episode_reward_min: -1098.4374999878994
  episodes_this_iter: 1
  episodes_total: 147
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.947
    dispatch_time_ms: 23.093
    learner:
      cur_lr: 0.0013110489817336202
      grad_gnorm: 5.267348289489746
      policy_entropy: 0.0004449890402611345
      policy_loss: 4.554360657493817e-06
      var_gnorm: 24.56058120727539
      vf_explained_var: 0.0
      vf_loss: 0.01845516450703144
    num_steps_sampled: 740000
    num_steps_trained: 740000
    wait_time_ms: 68.779
  iterations_since_restore: 148
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 1257.1872341632843
  time_this_iter_s: 8.891281843185425
  time_total_s: 1257.1872341632843
  timestamp: 1594859555
  timesteps_since_restore: 740000
  timesteps_this_iter: 5000
  timesteps_total: 740000
  training_iteration: 148
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 1257 s, 148 iter, 740000 ts, -461 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-32-44
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -454.73437499509384
  episode_reward_min: -1098.4374999878994
  episodes_this_iter: 1
  episodes_total: 148
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.504
    dispatch_time_ms: 23.639
    learner:
      cur_lr: 0.0013107160339131951
      grad_gnorm: 15.900788307189941
      policy_entropy: 0.0004452303401194513
      policy_loss: -1.3036202517469064e-06
      var_gnorm: 24.560707092285156
      vf_explained_var: 0.0
      vf_loss: 0.16775664687156677
    num_steps_sampled: 745000
    num_steps_trained: 745000
    wait_time_ms: 65.097
  iterations_since_restore: 149
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 1266.0215871334076
  time_this_iter_s: 8.834352970123291
  time_total_s: 1266.0215871334076
  timestamp: 1594859564
  timesteps_since_restore: 745000
  timesteps_this_iter: 5000
  timesteps_total: 745000
  training_iteration: 149
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 1266 s, 149 iter, 745000 ts, -455 rew

agent-1: 4.0
agent-2: -299.9999999967948
agent-3: -299.9999999967948
agent-4: -299.9999999967948
agent-5: -97.9999999988953
Extrinsic Rewards:
4
0
0
0
2
Sum Reward: 6
Avg Reward: 1.2
Min Reward: 0
Max Reward: 4
Gini Coefficient: 0.6666666666666666
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-33-00
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -460.6943749950286
  episode_reward_min: -1098.4374999878994
  episodes_this_iter: 1
  episodes_total: 149
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.52
    dispatch_time_ms: 16.686
    learner:
      cur_lr: 0.0013103829696774483
      grad_gnorm: 24.825233459472656
      policy_entropy: 0.0004486411635298282
      policy_loss: 4.9408986342314165e-06
      var_gnorm: 24.561111450195312
      vf_explained_var: 0.0
      vf_loss: 0.4089106619358063
    num_steps_sampled: 750000
    num_steps_trained: 750000
    wait_time_ms: 53.358
  iterations_since_restore: 150
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 1281.8675360679626
  time_this_iter_s: 15.845948934555054
  time_total_s: 1281.8675360679626
  timestamp: 1594859580
  timesteps_since_restore: 750000
  timesteps_this_iter: 5000
  timesteps_total: 750000
  training_iteration: 150
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 1281 s, 150 iter, 750000 ts, -461 rew

agent-1: -299.9999999967948
agent-2: -97.9999999988953
agent-3: -299.9999999967948
agent-4: 4.0
agent-5: -299.9999999967948
Extrinsic Rewards:
0
2
0
4
0
Sum Reward: 6
Avg Reward: 1.2
Min Reward: 0
Max Reward: 4
Gini Coefficient: 0.6666666666666666
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-33-08
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -468.6443749949427
  episode_reward_min: -1098.4374999878994
  episodes_this_iter: 1
  episodes_total: 150
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.753
    dispatch_time_ms: 22.044
    learner:
      cur_lr: 0.0013100500218570232
      grad_gnorm: 10.928564071655273
      policy_entropy: 0.00044549780432134867
      policy_loss: -4.469442842491844e-07
      var_gnorm: 24.560558319091797
      vf_explained_var: 5.960464477539063e-08
      vf_loss: 0.07924438267946243
    num_steps_sampled: 755000
    num_steps_trained: 755000
    wait_time_ms: 67.129
  iterations_since_restore: 151
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 1290.5232903957367
  time_this_iter_s: 8.655754327774048
  time_total_s: 1290.5232903957367
  timestamp: 1594859588
  timesteps_since_restore: 755000
  timesteps_this_iter: 5000
  timesteps_total: 755000
  training_iteration: 151
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 1290 s, 151 iter, 755000 ts, -469 rew

agent-1: -349.99999999622224
agent-2: -349.99999999622224
agent-3: -100.46874999884024
agent-4: -200.24999999777688
agent-5: 0.28125
Extrinsic Rewards:
0
0
2
1
4
Sum Reward: 7
Avg Reward: 1.4
Min Reward: 0
Max Reward: 4
Gini Coefficient: 0.5714285714285714
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-33-18
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -478.6487499948332
  episode_reward_min: -1098.4374999878994
  episodes_this_iter: 1
  episodes_total: 151
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 3.36
    dispatch_time_ms: 31.429
    learner:
      cur_lr: 0.0013097169576212764
      grad_gnorm: 0.27980533242225647
      policy_entropy: 0.007026917301118374
      policy_loss: -3.229178275887534e-07
      var_gnorm: 24.549251556396484
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 4.353501572040841e-05
    num_steps_sampled: 760000
    num_steps_trained: 760000
    wait_time_ms: 108.73
  iterations_since_restore: 152
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 1299.7046649456024
  time_this_iter_s: 9.181374549865723
  time_total_s: 1299.7046649456024
  timestamp: 1594859598
  timesteps_since_restore: 760000
  timesteps_this_iter: 5000
  timesteps_total: 760000
  training_iteration: 152
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 23.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 1299 s, 152 iter, 760000 ts, -479 rew

agent-1: -199.99999999788645
agent-2: 0.75
agent-3: 0.7500000000136119
agent-4: -199.99999999788645
agent-5: -199.99999999788645
Extrinsic Rewards:
0
2
2
0
0
Sum Reward: 4
Avg Reward: 0.8
Min Reward: 0
Max Reward: 2
Gini Coefficient: 0.6
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-33-26
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -474.6937499948768
  episode_reward_min: -1098.4374999878994
  episodes_this_iter: 1
  episodes_total: 152
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.927
    dispatch_time_ms: 23.189
    learner:
      cur_lr: 0.0013093840098008513
      grad_gnorm: 11.14356803894043
      policy_entropy: 0.008986957371234894
      policy_loss: 9.087691068998538e-06
      var_gnorm: 24.548377990722656
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 0.08239303529262543
    num_steps_sampled: 765000
    num_steps_trained: 765000
    wait_time_ms: 57.299
  iterations_since_restore: 153
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 1307.8311445713043
  time_this_iter_s: 8.126479625701904
  time_total_s: 1307.8311445713043
  timestamp: 1594859606
  timesteps_since_restore: 765000
  timesteps_this_iter: 5000
  timesteps_total: 765000
  training_iteration: 153
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 23.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 1307 s, 153 iter, 765000 ts, -475 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-33-34
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -468.7037499949403
  episode_reward_min: -1098.4374999878994
  episodes_this_iter: 1
  episodes_total: 153
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 3.178
    dispatch_time_ms: 25.472
    learner:
      cur_lr: 0.0013090509455651045
      grad_gnorm: 4.700704574584961
      policy_entropy: 0.008711953647434711
      policy_loss: 6.124506035121158e-05
      var_gnorm: 24.54837989807129
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 0.014661113731563091
    num_steps_sampled: 770000
    num_steps_trained: 770000
    wait_time_ms: 56.349
  iterations_since_restore: 154
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 1316.5385179519653
  time_this_iter_s: 8.70737338066101
  time_total_s: 1316.5385179519653
  timestamp: 1594859614
  timesteps_since_restore: 770000
  timesteps_this_iter: 5000
  timesteps_total: 770000
  training_iteration: 154
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 1316 s, 154 iter, 770000 ts, -469 rew

agent-1: -199.999999997859
agent-2: -98.9999999988954
agent-3: 3.0
agent-4: -199.999999997859
agent-5: -199.999999997859
Extrinsic Rewards:
0
1
3
0
0
Sum Reward: 4
Avg Reward: 0.8
Min Reward: 0
Max Reward: 3
Gini Coefficient: 0.7
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-33-43
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -464.6937499949859
  episode_reward_min: -1098.4374999878994
  episodes_this_iter: 1
  episodes_total: 154
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.743
    dispatch_time_ms: 26.196
    learner:
      cur_lr: 0.0013087179977446795
      grad_gnorm: 11.44828987121582
      policy_entropy: 0.008289393037557602
      policy_loss: 1.8850343622034416e-05
      var_gnorm: 24.54850959777832
      vf_explained_var: 5.960464477539063e-08
      vf_loss: 0.08696122467517853
    num_steps_sampled: 775000
    num_steps_trained: 775000
    wait_time_ms: 54.716
  iterations_since_restore: 155
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 1325.211557149887
  time_this_iter_s: 8.673039197921753
  time_total_s: 1325.211557149887
  timestamp: 1594859623
  timesteps_since_restore: 775000
  timesteps_this_iter: 5000
  timesteps_total: 775000
  training_iteration: 155
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 1325 s, 155 iter, 775000 ts, -465 rew

agent-1: -249.99999999735493
agent-2: -249.99999999735493
agent-3: 3.0
agent-4: -47.99999999945478
agent-5: -249.99999999735493
Extrinsic Rewards:
0
0
3
2
0
Sum Reward: 5
Avg Reward: 1.0
Min Reward: 0
Max Reward: 3
Gini Coefficient: 0.64
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-33-52
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -470.6537499949219
  episode_reward_min: -1098.4374999878994
  episodes_this_iter: 1
  episodes_total: 155
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 3.197
    dispatch_time_ms: 27.549
    learner:
      cur_lr: 0.0013083850499242544
      grad_gnorm: 15.377243041992188
      policy_entropy: 0.006155627779662609
      policy_loss: 5.656830035150051e-05
      var_gnorm: 24.54947853088379
      vf_explained_var: 0.0
      vf_loss: 0.15689131617546082
    num_steps_sampled: 780000
    num_steps_trained: 780000
    wait_time_ms: 47.793
  iterations_since_restore: 156
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 1334.0051872730255
  time_this_iter_s: 8.793630123138428
  time_total_s: 1334.0051872730255
  timestamp: 1594859632
  timesteps_since_restore: 780000
  timesteps_this_iter: 5000
  timesteps_total: 780000
  training_iteration: 156
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 1334 s, 156 iter, 780000 ts, -471 rew

agent-1: -199.99999999784504
agent-2: 4.0
agent-3: -199.99999999784504
agent-4: -199.99999999784504
agent-5: -199.99999999784504
Extrinsic Rewards:
0
4
0
0
0
Sum Reward: 4
Avg Reward: 0.8
Min Reward: 0
Max Reward: 4
Gini Coefficient: 0.8
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-34-01
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -474.63374999487775
  episode_reward_min: -1098.4374999878994
  episodes_this_iter: 1
  episodes_total: 156
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.823
    dispatch_time_ms: 20.99
    learner:
      cur_lr: 0.0013080519856885076
      grad_gnorm: 39.999996185302734
      policy_entropy: 0.0049658361822366714
      policy_loss: -0.0003579086042009294
      var_gnorm: 24.550060272216797
      vf_explained_var: 1.1920928955078125e-07
      vf_loss: 36.03721237182617
    num_steps_sampled: 785000
    num_steps_trained: 785000
    wait_time_ms: 55.554
  iterations_since_restore: 157
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 1342.7313494682312
  time_this_iter_s: 8.726162195205688
  time_total_s: 1342.7313494682312
  timestamp: 1594859641
  timesteps_since_restore: 785000
  timesteps_this_iter: 5000
  timesteps_total: 785000
  training_iteration: 157
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 1342 s, 157 iter, 785000 ts, -475 rew

agent-1: -99.99999999894987
agent-2: -99.99999999894987
agent-3: -99.99999999894987
agent-4: -99.99999999894987
agent-5: 2.0
Extrinsic Rewards:
0
0
0
0
2
Sum Reward: 2
Avg Reward: 0.4
Min Reward: 0
Max Reward: 2
Gini Coefficient: 0.8
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-34-10
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -472.6437499948995
  episode_reward_min: -1098.4374999878994
  episodes_this_iter: 1
  episodes_total: 157
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.707
    dispatch_time_ms: 25.18
    learner:
      cur_lr: 0.0013077190378680825
      grad_gnorm: 6.952899932861328
      policy_entropy: 0.0053138635121285915
      policy_loss: 3.326607111375779e-05
      var_gnorm: 24.549766540527344
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 0.03207544982433319
    num_steps_sampled: 790000
    num_steps_trained: 790000
    wait_time_ms: 58.652
  iterations_since_restore: 158
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 1351.6420209407806
  time_this_iter_s: 8.910671472549438
  time_total_s: 1351.6420209407806
  timestamp: 1594859650
  timesteps_since_restore: 790000
  timesteps_this_iter: 5000
  timesteps_total: 790000
  training_iteration: 158
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 1351 s, 158 iter, 790000 ts, -473 rew

agent-1: -99.99999999894987
agent-2: 2.0
agent-3: -99.99999999894987
agent-4: -99.99999999894987
agent-5: -99.99999999894987
Extrinsic Rewards:
0
2
0
0
0
Sum Reward: 2
Avg Reward: 0.4
Min Reward: 0
Max Reward: 2
Gini Coefficient: 0.8
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-34-18
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -474.6337499948788
  episode_reward_min: -1098.4374999878994
  episodes_this_iter: 1
  episodes_total: 158
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 3.086
    dispatch_time_ms: 29.216
    learner:
      cur_lr: 0.0013073859736323357
      grad_gnorm: 39.999996185302734
      policy_entropy: 0.005113510414958
      policy_loss: -0.000718369847163558
      var_gnorm: 24.54990005493164
      vf_explained_var: 0.0
      vf_loss: 123.37469482421875
    num_steps_sampled: 795000
    num_steps_trained: 795000
    wait_time_ms: 58.891
  iterations_since_restore: 159
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 1360.388135433197
  time_this_iter_s: 8.746114492416382
  time_total_s: 1360.388135433197
  timestamp: 1594859658
  timesteps_since_restore: 795000
  timesteps_this_iter: 5000
  timesteps_total: 795000
  training_iteration: 159
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 1360 s, 159 iter, 795000 ts, -475 rew

agent-1: -199.99999999784504
agent-2: -199.99999999784504
agent-3: -199.99999999784504
agent-4: -199.99999999784504
agent-5: 4.0
Extrinsic Rewards:
0
0
0
0
4
Sum Reward: 4
Avg Reward: 0.8
Min Reward: 0
Max Reward: 4
Gini Coefficient: 0.8
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-34-27
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -480.6037499948138
  episode_reward_min: -1098.4374999878994
  episodes_this_iter: 1
  episodes_total: 159
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.693
    dispatch_time_ms: 45.208
    learner:
      cur_lr: 0.0013070530258119106
      grad_gnorm: 7.393918037414551
      policy_entropy: 0.004973692819476128
      policy_loss: 1.8211896531283855e-05
      var_gnorm: 24.5499210357666
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 0.03306572139263153
    num_steps_sampled: 800000
    num_steps_trained: 800000
    wait_time_ms: 42.701
  iterations_since_restore: 160
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 1369.1109795570374
  time_this_iter_s: 8.722844123840332
  time_total_s: 1369.1109795570374
  timestamp: 1594859667
  timesteps_since_restore: 800000
  timesteps_this_iter: 5000
  timesteps_total: 800000
  training_iteration: 160
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 1369 s, 160 iter, 800000 ts, -481 rew

agent-1: -98.99999999893653
agent-2: 3.0
agent-3: -199.99999999787352
agent-4: -199.99999999787352
agent-5: -199.99999999787352
Extrinsic Rewards:
1
3
0
0
0
Sum Reward: 4
Avg Reward: 0.8
Min Reward: 0
Max Reward: 3
Gini Coefficient: 0.7
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-34-36
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -479.60374999482735
  episode_reward_min: -1098.4374999878994
  episodes_this_iter: 1
  episodes_total: 160
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 3.073
    dispatch_time_ms: 37.459
    learner:
      cur_lr: 0.0013067199615761638
      grad_gnorm: 11.814861297607422
      policy_entropy: 0.004735959693789482
      policy_loss: -3.39302969223354e-05
      var_gnorm: 24.550098419189453
      vf_explained_var: 0.0
      vf_loss: 0.092618927359581
    num_steps_sampled: 805000
    num_steps_trained: 805000
    wait_time_ms: 52.803
  iterations_since_restore: 161
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 1377.705374956131
  time_this_iter_s: 8.594395399093628
  time_total_s: 1377.705374956131
  timestamp: 1594859676
  timesteps_since_restore: 805000
  timesteps_this_iter: 5000
  timesteps_total: 805000
  training_iteration: 161
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 1377 s, 161 iter, 805000 ts, -480 rew

agent-1: 2.75
agent-2: -249.99999999727223
agent-3: -249.99999999727223
agent-4: -249.99999999727223
agent-5: -150.24999999830888
Extrinsic Rewards:
4
0
0
0
1
Sum Reward: 5
Avg Reward: 1.0
Min Reward: 0
Max Reward: 4
Gini Coefficient: 0.72
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-34-45
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -482.6087499947934
  episode_reward_min: -1098.4374999878994
  episodes_this_iter: 1
  episodes_total: 161
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 3.451
    dispatch_time_ms: 32.019
    learner:
      cur_lr: 0.0013063870137557387
      grad_gnorm: 1.467578649520874
      policy_entropy: 0.004144154489040375
      policy_loss: 4.237236680637579e-06
      var_gnorm: 24.550554275512695
      vf_explained_var: 5.960464477539063e-08
      vf_loss: 0.001428392599336803
    num_steps_sampled: 810000
    num_steps_trained: 810000
    wait_time_ms: 44.472
  iterations_since_restore: 162
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 1386.4332342147827
  time_this_iter_s: 8.727859258651733
  time_total_s: 1386.4332342147827
  timestamp: 1594859685
  timesteps_since_restore: 810000
  timesteps_this_iter: 5000
  timesteps_total: 810000
  training_iteration: 162
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 1386 s, 162 iter, 810000 ts, -483 rew

agent-1: -47.99999999945478
agent-2: -249.99999999735493
agent-3: -249.99999999735493
agent-4: 3.0
agent-5: -249.99999999735493
Extrinsic Rewards:
2
0
0
3
0
Sum Reward: 5
Avg Reward: 1.0
Min Reward: 0
Max Reward: 3
Gini Coefficient: 0.64
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-34-53
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -484.58874999477337
  episode_reward_min: -1098.4374999878994
  episodes_this_iter: 1
  episodes_total: 162
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.999
    dispatch_time_ms: 29.398
    learner:
      cur_lr: 0.0013060539495199919
      grad_gnorm: 10.720505714416504
      policy_entropy: 0.0044606514275074005
      policy_loss: -2.082106948364526e-05
      var_gnorm: 24.550203323364258
      vf_explained_var: 0.0
      vf_loss: 0.07625576108694077
    num_steps_sampled: 815000
    num_steps_trained: 815000
    wait_time_ms: 50.193
  iterations_since_restore: 163
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 1395.1296739578247
  time_this_iter_s: 8.696439743041992
  time_total_s: 1395.1296739578247
  timestamp: 1594859693
  timesteps_since_restore: 815000
  timesteps_this_iter: 5000
  timesteps_total: 815000
  training_iteration: 163
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 1395 s, 163 iter, 815000 ts, -485 rew

agent-1: 1.0
agent-2: -49.999999999481645
agent-3: -49.999999999481645
agent-4: -49.999999999481645
agent-5: -49.999999999481645
Extrinsic Rewards:
1
0
0
0
0
Sum Reward: 1
Avg Reward: 0.2
Min Reward: 0
Max Reward: 1
Gini Coefficient: 0.8
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-35-02
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -477.6281249948512
  episode_reward_min: -1098.4374999878994
  episodes_this_iter: 1
  episodes_total: 163
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.736
    dispatch_time_ms: 20.586
    learner:
      cur_lr: 0.0013057210016995668
      grad_gnorm: 0.44939014315605164
      policy_entropy: 0.0002648228546604514
      policy_loss: 9.196528338861754e-08
      var_gnorm: 24.564565658569336
      vf_explained_var: 0.0
      vf_loss: 0.00013400166062638164
    num_steps_sampled: 820000
    num_steps_trained: 820000
    wait_time_ms: 55.612
  iterations_since_restore: 164
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 1403.7480680942535
  time_this_iter_s: 8.618394136428833
  time_total_s: 1403.7480680942535
  timestamp: 1594859702
  timesteps_since_restore: 820000
  timesteps_this_iter: 5000
  timesteps_total: 820000
  training_iteration: 164
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 1403 s, 164 iter, 820000 ts, -478 rew

agent-1: -99.99999999894987
agent-2: -99.99999999894987
agent-3: -99.99999999894987
agent-4: -99.99999999894987
agent-5: 2.0
Extrinsic Rewards:
0
0
0
0
2
Sum Reward: 2
Avg Reward: 0.4
Min Reward: 0
Max Reward: 2
Gini Coefficient: 0.8
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-35-11
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -475.6381249948739
  episode_reward_min: -1098.4374999878994
  episodes_this_iter: 1
  episodes_total: 164
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.654
    dispatch_time_ms: 29.599
    learner:
      cur_lr: 0.0013053880538791418
      grad_gnorm: 35.100101470947266
      policy_entropy: 0.00021792649931740016
      policy_loss: 4.2823705825867364e-07
      var_gnorm: 24.56606674194336
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 0.651499330997467
    num_steps_sampled: 825000
    num_steps_trained: 825000
    wait_time_ms: 51.272
  iterations_since_restore: 165
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 1412.4091804027557
  time_this_iter_s: 8.661112308502197
  time_total_s: 1412.4091804027557
  timestamp: 1594859711
  timesteps_since_restore: 825000
  timesteps_this_iter: 5000
  timesteps_total: 825000
  training_iteration: 165
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 1412 s, 165 iter, 825000 ts, -476 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-35-19
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -467.6881249949588
  episode_reward_min: -1098.4374999878994
  episodes_this_iter: 1
  episodes_total: 165
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 4.31
    dispatch_time_ms: 25.812
    learner:
      cur_lr: 0.001305054989643395
      grad_gnorm: 0.14635586738586426
      policy_entropy: 0.00021848769392818213
      policy_loss: -2.926363684707667e-08
      var_gnorm: 24.566143035888672
      vf_explained_var: 0.0
      vf_loss: 1.421538763679564e-05
    num_steps_sampled: 830000
    num_steps_trained: 830000
    wait_time_ms: 55.182
  iterations_since_restore: 166
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 1421.1402673721313
  time_this_iter_s: 8.73108696937561
  time_total_s: 1421.1402673721313
  timestamp: 1594859719
  timesteps_since_restore: 830000
  timesteps_this_iter: 5000
  timesteps_total: 830000
  training_iteration: 166
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 1421 s, 166 iter, 830000 ts, -468 rew

agent-1: -149.99999999837684
agent-2: -149.99999999837684
agent-3: -149.99999999837684
agent-4: -149.99999999837684
agent-5: 3.0
Extrinsic Rewards:
0
0
0
0
3
Sum Reward: 3
Avg Reward: 0.6
Min Reward: 0
Max Reward: 3
Gini Coefficient: 0.8
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-35-28
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -473.658124994894
  episode_reward_min: -1098.4374999878994
  episodes_this_iter: 1
  episodes_total: 166
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.804
    dispatch_time_ms: 19.465
    learner:
      cur_lr: 0.00130472204182297
      grad_gnorm: 40.0
      policy_entropy: 0.0002199089212808758
      policy_loss: -7.849033863749355e-05
      var_gnorm: 24.565990447998047
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 764.0860595703125
    num_steps_sampled: 835000
    num_steps_trained: 835000
    wait_time_ms: 67.535
  iterations_since_restore: 167
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 1429.9355161190033
  time_this_iter_s: 8.795248746871948
  time_total_s: 1429.9355161190033
  timestamp: 1594859728
  timesteps_since_restore: 835000
  timesteps_this_iter: 5000
  timesteps_total: 835000
  training_iteration: 167
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 1429 s, 167 iter, 835000 ts, -474 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-35-37
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -473.658124994894
  episode_reward_min: -1098.4374999878994
  episodes_this_iter: 1
  episodes_total: 167
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 3.139
    dispatch_time_ms: 29.827
    learner:
      cur_lr: 0.001304388977587223
      grad_gnorm: 1.757005214691162
      policy_entropy: 0.00021778659720439464
      policy_loss: 5.863568048880552e-07
      var_gnorm: 24.566091537475586
      vf_explained_var: 1.1920928955078125e-07
      vf_loss: 0.0020482041873037815
    num_steps_sampled: 840000
    num_steps_trained: 840000
    wait_time_ms: 52.688
  iterations_since_restore: 168
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 1438.7863335609436
  time_this_iter_s: 8.850817441940308
  time_total_s: 1438.7863335609436
  timestamp: 1594859737
  timesteps_since_restore: 840000
  timesteps_this_iter: 5000
  timesteps_total: 840000
  training_iteration: 168
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 1438 s, 168 iter, 840000 ts, -474 rew

agent-1: -199.99999999780377
agent-2: -199.99999999780377
agent-3: 4.0
agent-4: -199.99999999780377
agent-5: -199.99999999780377
Extrinsic Rewards:
0
0
4
0
0
Sum Reward: 4
Avg Reward: 0.8
Min Reward: 0
Max Reward: 4
Gini Coefficient: 0.8
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-35-46
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -474.65812499488135
  episode_reward_min: -1098.4374999878994
  episodes_this_iter: 1
  episodes_total: 168
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.763
    dispatch_time_ms: 18.276
    learner:
      cur_lr: 0.001304056029766798
      grad_gnorm: 40.00000762939453
      policy_entropy: 0.00021823351562488824
      policy_loss: -7.630416803294793e-05
      var_gnorm: 24.566011428833008
      vf_explained_var: 0.0
      vf_loss: 843.1988525390625
    num_steps_sampled: 845000
    num_steps_trained: 845000
    wait_time_ms: 66.694
  iterations_since_restore: 169
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 1447.4690964221954
  time_this_iter_s: 8.682762861251831
  time_total_s: 1447.4690964221954
  timestamp: 1594859746
  timesteps_since_restore: 845000
  timesteps_this_iter: 5000
  timesteps_total: 845000
  training_iteration: 169
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 1447 s, 169 iter, 845000 ts, -475 rew

agent-1: -149.99999999840443
agent-2: -149.99999999840443
agent-3: -149.99999999840443
agent-4: 3.0
agent-5: -149.99999999840443
Extrinsic Rewards:
0
0
0
3
0
Sum Reward: 3
Avg Reward: 0.6
Min Reward: 0
Max Reward: 3
Gini Coefficient: 0.8
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-35-55
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -472.6681249949037
  episode_reward_min: -1098.4374999878994
  episodes_this_iter: 1
  episodes_total: 169
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.694
    dispatch_time_ms: 25.423
    learner:
      cur_lr: 0.0013037229655310512
      grad_gnorm: 0.9062971472740173
      policy_entropy: 0.00021781798568554223
      policy_loss: -1.0399148919759682e-07
      var_gnorm: 24.566133499145508
      vf_explained_var: 1.1920928955078125e-07
      vf_loss: 0.0005449839518405497
    num_steps_sampled: 850000
    num_steps_trained: 850000
    wait_time_ms: 41.795
  iterations_since_restore: 170
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 1456.2057321071625
  time_this_iter_s: 8.736635684967041
  time_total_s: 1456.2057321071625
  timestamp: 1594859755
  timesteps_since_restore: 850000
  timesteps_this_iter: 5000
  timesteps_total: 850000
  training_iteration: 170
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 1456 s, 170 iter, 850000 ts, -473 rew

agent-1: -249.99999999735493
agent-2: -249.99999999735493
agent-3: -47.99999999945478
agent-4: -249.99999999735493
agent-5: 3.0
Extrinsic Rewards:
0
0
2
0
3
Sum Reward: 5
Avg Reward: 1.0
Min Reward: 0
Max Reward: 3
Gini Coefficient: 0.64
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-36-03
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -480.6181249948189
  episode_reward_min: -1098.4374999878994
  episodes_this_iter: 1
  episodes_total: 170
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 3.058
    dispatch_time_ms: 18.641
    learner:
      cur_lr: 0.0013033900177106261
      grad_gnorm: 0.4211789071559906
      policy_entropy: 0.00021935789845883846
      policy_loss: -1.126093884806778e-08
      var_gnorm: 24.566043853759766
      vf_explained_var: 0.0
      vf_loss: 0.00011768913827836514
    num_steps_sampled: 855000
    num_steps_trained: 855000
    wait_time_ms: 64.94
  iterations_since_restore: 171
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 1464.9272482395172
  time_this_iter_s: 8.721516132354736
  time_total_s: 1464.9272482395172
  timestamp: 1594859763
  timesteps_since_restore: 855000
  timesteps_this_iter: 5000
  timesteps_total: 855000
  training_iteration: 171
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 1464 s, 171 iter, 855000 ts, -481 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-36-12
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -474.64812499488374
  episode_reward_min: -1098.4374999878994
  episodes_this_iter: 1
  episodes_total: 171
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 3.044
    dispatch_time_ms: 15.862
    learner:
      cur_lr: 0.0013030569534748793
      grad_gnorm: 1.4864017963409424
      policy_entropy: 0.0002206521457992494
      policy_loss: 7.352712572128439e-08
      var_gnorm: 24.566051483154297
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 0.0014659514417871833
    num_steps_sampled: 860000
    num_steps_trained: 860000
    wait_time_ms: 69.318
  iterations_since_restore: 172
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 1473.6349425315857
  time_this_iter_s: 8.707694292068481
  time_total_s: 1473.6349425315857
  timestamp: 1594859772
  timesteps_since_restore: 860000
  timesteps_this_iter: 5000
  timesteps_total: 860000
  training_iteration: 172
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 1473 s, 172 iter, 860000 ts, -475 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-36-21
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -474.6481249948837
  episode_reward_min: -1098.4374999878994
  episodes_this_iter: 1
  episodes_total: 172
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.56
    dispatch_time_ms: 18.695
    learner:
      cur_lr: 0.0013027240056544542
      grad_gnorm: 4.337043762207031
      policy_entropy: 0.00022213732881937176
      policy_loss: -5.947494514657592e-07
      var_gnorm: 24.565874099731445
      vf_explained_var: 1.1920928955078125e-07
      vf_loss: 0.012480372563004494
    num_steps_sampled: 865000
    num_steps_trained: 865000
    wait_time_ms: 62.79
  iterations_since_restore: 173
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 1482.2800879478455
  time_this_iter_s: 8.645145416259766
  time_total_s: 1482.2800879478455
  timestamp: 1594859781
  timesteps_since_restore: 865000
  timesteps_this_iter: 5000
  timesteps_total: 865000
  training_iteration: 173
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 1482 s, 173 iter, 865000 ts, -475 rew

agent-1: -199.99999999774747
agent-2: -199.99999999774747
agent-3: -199.99999999774747
agent-4: 4.0
agent-5: -199.99999999774747
Extrinsic Rewards:
0
0
0
4
0
Sum Reward: 4
Avg Reward: 0.8
Min Reward: 0
Max Reward: 4
Gini Coefficient: 0.8
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-36-30
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -480.61812499481437
  episode_reward_min: -1098.4374999878994
  episodes_this_iter: 1
  episodes_total: 173
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.667
    dispatch_time_ms: 15.661
    learner:
      cur_lr: 0.0013023910578340292
      grad_gnorm: 1.470668077468872
      policy_entropy: 0.00022236464428715408
      policy_loss: -2.0074797646429943e-07
      var_gnorm: 24.565977096557617
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 0.001435179146938026
    num_steps_sampled: 870000
    num_steps_trained: 870000
    wait_time_ms: 75.104
  iterations_since_restore: 174
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 1491.1104674339294
  time_this_iter_s: 8.830379486083984
  time_total_s: 1491.1104674339294
  timestamp: 1594859790
  timesteps_since_restore: 870000
  timesteps_this_iter: 5000
  timesteps_total: 870000
  training_iteration: 174
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 1491 s, 174 iter, 870000 ts, -481 rew

agent-1: -349.99999999613846
agent-2: -349.99999999613846
agent-3: -349.99999999613846
agent-4: -49.46874999938334
agent-5: 1.53125
Extrinsic Rewards:
0
0
0
3
4
Sum Reward: 7
Avg Reward: 1.4
Min Reward: 0
Max Reward: 4
Gini Coefficient: 0.6285714285714286
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-36-38
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -485.61249999475586
  episode_reward_min: -1098.4374999878994
  episodes_this_iter: 1
  episodes_total: 174
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.986
    dispatch_time_ms: 25.083
    learner:
      cur_lr: 0.0013020579935982823
      grad_gnorm: 39.999996185302734
      policy_entropy: 0.00022453695419244468
      policy_loss: -3.276216011727229e-05
      var_gnorm: 24.565793991088867
      vf_explained_var: 0.0
      vf_loss: 122.76729583740234
    num_steps_sampled: 875000
    num_steps_trained: 875000
    wait_time_ms: 65.307
  iterations_since_restore: 175
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 1499.8068840503693
  time_this_iter_s: 8.69641661643982
  time_total_s: 1499.8068840503693
  timestamp: 1594859798
  timesteps_since_restore: 875000
  timesteps_this_iter: 5000
  timesteps_total: 875000
  training_iteration: 175
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 1499 s, 175 iter, 875000 ts, -486 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-37-06
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -483.6224999947766
  episode_reward_min: -1098.4374999878994
  episodes_this_iter: 1
  episodes_total: 175
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 3.247
    dispatch_time_ms: 36.406
    learner:
      cur_lr: 0.0013017250457778573
      grad_gnorm: 40.0
      policy_entropy: 0.00022487682872451842
      policy_loss: 4.4331568460620474e-07
      var_gnorm: 24.565759658813477
      vf_explained_var: 0.0
      vf_loss: 3.3212196826934814
    num_steps_sampled: 880000
    num_steps_trained: 880000
    wait_time_ms: 42.453
  iterations_since_restore: 176
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 1527.6754395961761
  time_this_iter_s: 27.868555545806885
  time_total_s: 1527.6754395961761
  timestamp: 1594859826
  timesteps_since_restore: 880000
  timesteps_this_iter: 5000
  timesteps_total: 880000
  training_iteration: 176
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 1527 s, 176 iter, 880000 ts, -484 rew

agent-1: -49.99999999946836
agent-2: -49.99999999946836
agent-3: -49.99999999946836
agent-4: -49.99999999946836
agent-5: 1.0
Extrinsic Rewards:
0
0
0
0
1
Sum Reward: 1
Avg Reward: 0.2
Min Reward: 0
Max Reward: 1
Gini Coefficient: 0.8
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-37-15
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -485.61249999475535
  episode_reward_min: -1098.4374999878994
  episodes_this_iter: 1
  episodes_total: 176
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 3.474
    dispatch_time_ms: 27.679
    learner:
      cur_lr: 0.0013013919815421104
      grad_gnorm: 40.0
      policy_entropy: 0.00022361682204063982
      policy_loss: -0.00010343443136662245
      var_gnorm: 24.56585121154785
      vf_explained_var: 0.0
      vf_loss: 1335.953369140625
    num_steps_sampled: 885000
    num_steps_trained: 885000
    wait_time_ms: 57.629
  iterations_since_restore: 177
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 1536.17653632164
  time_this_iter_s: 8.501096725463867
  time_total_s: 1536.17653632164
  timestamp: 1594859835
  timesteps_since_restore: 885000
  timesteps_this_iter: 5000
  timesteps_total: 885000
  training_iteration: 177
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 1536 s, 177 iter, 885000 ts, -486 rew

agent-1: -149.99999999840443
agent-2: -149.99999999840443
agent-3: -149.99999999840443
agent-4: 3.0
agent-5: -149.99999999840443
Extrinsic Rewards:
0
0
0
3
0
Sum Reward: 3
Avg Reward: 0.6
Min Reward: 0
Max Reward: 3
Gini Coefficient: 0.8
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-37-24
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -484.6224999947668
  episode_reward_min: -1098.4374999878994
  episodes_this_iter: 1
  episodes_total: 177
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 3.324
    dispatch_time_ms: 21.144
    learner:
      cur_lr: 0.0013010590337216854
      grad_gnorm: 1.5228239297866821
      policy_entropy: 0.00022287796309683472
      policy_loss: 4.810241307495744e-07
      var_gnorm: 24.565834045410156
      vf_explained_var: 1.1920928955078125e-07
      vf_loss: 0.0015385488513857126
    num_steps_sampled: 890000
    num_steps_trained: 890000
    wait_time_ms: 61.079
  iterations_since_restore: 178
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 1544.887851715088
  time_this_iter_s: 8.711315393447876
  time_total_s: 1544.887851715088
  timestamp: 1594859844
  timesteps_since_restore: 890000
  timesteps_this_iter: 5000
  timesteps_total: 890000
  training_iteration: 178
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 1544 s, 178 iter, 890000 ts, -485 rew

agent-1: 3.0
agent-2: -149.99999999840443
agent-3: -149.99999999840443
agent-4: -149.99999999840443
agent-5: -149.99999999840443
Extrinsic Rewards:
3
0
0
0
0
Sum Reward: 3
Avg Reward: 0.6
Min Reward: 0
Max Reward: 3
Gini Coefficient: 0.8
20:20 Ratio: Undefined
Max-min Ratio: Undefined
agent-1: -99.99999999894987
agent-2: 2.0
agent-3: -99.99999999894987
agent-4: -99.99999999894987
agent-5: -99.99999999894987
Extrinsic Rewards:
0
2
0
0
0
Sum Reward: 2
Avg Reward: 0.4
Min Reward: 0
Max Reward: 2
Gini Coefficient: 0.8
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-37-39
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -494.57249999466103
  episode_reward_min: -1098.4374999878994
  episodes_this_iter: 2
  episodes_total: 179
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 3.322
    dispatch_time_ms: 26.468
    learner:
      cur_lr: 0.0013007259694859385
      grad_gnorm: 2.920224189758301
      policy_entropy: 0.00022298569092527032
      policy_loss: 2.558369942562422e-07
      var_gnorm: 24.565868377685547
      vf_explained_var: -1.0
      vf_loss: 0.00448351027444005
    num_steps_sampled: 895000
    num_steps_trained: 895000
    wait_time_ms: 64.85
  iterations_since_restore: 179
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 1559.7904253005981
  time_this_iter_s: 14.902573585510254
  time_total_s: 1559.7904253005981
  timestamp: 1594859859
  timesteps_since_restore: 895000
  timesteps_this_iter: 5000
  timesteps_total: 895000
  training_iteration: 179
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 1559 s, 179 iter, 895000 ts, -495 rew

Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-37-47
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -494.57249999466114
  episode_reward_min: -1098.4374999878994
  episodes_this_iter: 0
  episodes_total: 179
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.646
    dispatch_time_ms: 14.359
    learner:
      cur_lr: 0.0013003930216655135
      grad_gnorm: 1.8027383089065552
      policy_entropy: 0.00022486223315354437
      policy_loss: 2.823337581503438e-07
      var_gnorm: 24.565753936767578
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 0.0021562655456364155
    num_steps_sampled: 900000
    num_steps_trained: 900000
    wait_time_ms: 71.999
  iterations_since_restore: 180
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 1568.5267860889435
  time_this_iter_s: 8.736360788345337
  time_total_s: 1568.5267860889435
  timestamp: 1594859867
  timesteps_since_restore: 900000
  timesteps_this_iter: 5000
  timesteps_total: 900000
  training_iteration: 180
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 1568 s, 180 iter, 900000 ts, -495 rew

agent-1: -299.9999999967949
agent-2: 1.71875
agent-3: -149.03124999839068
agent-4: -299.9999999967949
agent-5: -49.249999999427196
Extrinsic Rewards:
0
3
1
0
2
Sum Reward: 6
Avg Reward: 1.2
Min Reward: 0
Max Reward: 3
Gini Coefficient: 0.5333333333333333
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-37-56
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -494.58812499466
  episode_reward_min: -1098.4374999878994
  episodes_this_iter: 1
  episodes_total: 180
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.514
    dispatch_time_ms: 24.459
    learner:
      cur_lr: 0.0013000599574297667
      grad_gnorm: 9.693909645080566
      policy_entropy: 0.00022562997764907777
      policy_loss: -4.4465364723578205e-10
      var_gnorm: 24.56576919555664
      vf_explained_var: -0.012264370918273926
      vf_loss: 0.04940645396709442
    num_steps_sampled: 905000
    num_steps_trained: 905000
    wait_time_ms: 61.048
  iterations_since_restore: 181
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 1577.2694535255432
  time_this_iter_s: 8.742667436599731
  time_total_s: 1577.2694535255432
  timestamp: 1594859876
  timesteps_since_restore: 905000
  timesteps_this_iter: 5000
  timesteps_total: 905000
  training_iteration: 181
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 1577 s, 181 iter, 905000 ts, -495 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-38-05
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -488.61812499472376
  episode_reward_min: -1098.4374999878994
  episodes_this_iter: 1
  episodes_total: 181
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.828
    dispatch_time_ms: 31.776
    learner:
      cur_lr: 0.0012997270096093416
      grad_gnorm: 9.44085693359375
      policy_entropy: 0.00022160612570587546
      policy_loss: 8.486300657750689e-07
      var_gnorm: 24.565765380859375
      vf_explained_var: 0.0
      vf_loss: 0.06160781532526016
    num_steps_sampled: 910000
    num_steps_trained: 910000
    wait_time_ms: 54.81
  iterations_since_restore: 182
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 1586.0322740077972
  time_this_iter_s: 8.762820482254028
  time_total_s: 1586.0322740077972
  timestamp: 1594859885
  timesteps_since_restore: 910000
  timesteps_this_iter: 5000
  timesteps_total: 910000
  training_iteration: 182
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 1586 s, 182 iter, 910000 ts, -489 rew

agent-1: -349.9999999961529
agent-2: 4.0
agent-3: -349.9999999961529
agent-4: -349.9999999961529
agent-5: -46.99999999945473
Extrinsic Rewards:
0
4
0
0
3
Sum Reward: 7
Avg Reward: 1.4
Min Reward: 0
Max Reward: 4
Gini Coefficient: 0.6285714285714286
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-38-14
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -497.558124994624
  episode_reward_min: -1098.4374999878994
  episodes_this_iter: 1
  episodes_total: 182
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.677
    dispatch_time_ms: 22.134
    learner:
      cur_lr: 0.0012993939453735948
      grad_gnorm: 40.0
      policy_entropy: 0.0002178879949497059
      policy_loss: -0.0001648163888603449
      var_gnorm: 24.565908432006836
      vf_explained_var: 0.0
      vf_loss: 3389.026123046875
    num_steps_sampled: 915000
    num_steps_trained: 915000
    wait_time_ms: 61.812
  iterations_since_restore: 183
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 1594.7235660552979
  time_this_iter_s: 8.69129204750061
  time_total_s: 1594.7235660552979
  timestamp: 1594859894
  timesteps_since_restore: 915000
  timesteps_this_iter: 5000
  timesteps_total: 915000
  training_iteration: 183
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 1594 s, 183 iter, 915000 ts, -498 rew

agent-1: -499.9999999945141
agent-2: -499.9999999945141
agent-3: -0.9375
agent-4: -50.780468749384056
agent-5: -50.780468749382614
Extrinsic Rewards:
0
0
4
3
3
Sum Reward: 10
Avg Reward: 2.0
Min Reward: 0
Max Reward: 4
Gini Coefficient: 0.44
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-38-23
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -499.64310936959845
  episode_reward_min: -1102.4984374877972
  episodes_this_iter: 1
  episodes_total: 183
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 3.022
    dispatch_time_ms: 27.592
    learner:
      cur_lr: 0.0012990609975531697
      grad_gnorm: 4.2649407386779785
      policy_entropy: 0.00021358100639190525
      policy_loss: 1.934574584083748e-06
      var_gnorm: 24.56595230102539
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 0.023378878831863403
    num_steps_sampled: 920000
    num_steps_trained: 920000
    wait_time_ms: 64.79
  iterations_since_restore: 184
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 1603.5674045085907
  time_this_iter_s: 8.843838453292847
  time_total_s: 1603.5674045085907
  timestamp: 1594859903
  timesteps_since_restore: 920000
  timesteps_this_iter: 5000
  timesteps_total: 920000
  training_iteration: 184
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 1603 s, 184 iter, 920000 ts, -500 rew

agent-1: -199.99999999784504
agent-2: -199.99999999784504
agent-3: -199.99999999784504
agent-4: -199.99999999784504
agent-5: 4.0
Extrinsic Rewards:
0
0
0
0
4
Sum Reward: 4
Avg Reward: 0.8
Min Reward: 0
Max Reward: 4
Gini Coefficient: 0.8
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-38-31
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -498.6531093696092
  episode_reward_min: -1102.4984374877972
  episodes_this_iter: 1
  episodes_total: 184
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 3.905
    dispatch_time_ms: 26.557
    learner:
      cur_lr: 0.0012987280497327447
      grad_gnorm: 0.4690772593021393
      policy_entropy: 0.00021087219647597522
      policy_loss: -4.692444122156303e-07
      var_gnorm: 24.56612205505371
      vf_explained_var: 1.1920928955078125e-07
      vf_loss: 0.00014598433335777372
    num_steps_sampled: 925000
    num_steps_trained: 925000
    wait_time_ms: 54.696
  iterations_since_restore: 185
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 1612.4149837493896
  time_this_iter_s: 8.84757924079895
  time_total_s: 1612.4149837493896
  timestamp: 1594859911
  timesteps_since_restore: 925000
  timesteps_this_iter: 5000
  timesteps_total: 925000
  training_iteration: 185
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 1612 s, 185 iter, 925000 ts, -499 rew

agent-1: 3.0
agent-2: -149.99999999840443
agent-3: -149.99999999840443
agent-4: -149.99999999840443
agent-5: -149.99999999840443
Extrinsic Rewards:
3
0
0
0
0
Sum Reward: 3
Avg Reward: 0.6
Min Reward: 0
Max Reward: 3
Gini Coefficient: 0.8
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-38-41
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -500.6431093695874
  episode_reward_min: -1102.4984374877972
  episodes_this_iter: 1
  episodes_total: 185
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.567
    dispatch_time_ms: 15.933
    learner:
      cur_lr: 0.0012983949854969978
      grad_gnorm: 0.21379131078720093
      policy_entropy: 0.00021153365378268063
      policy_loss: 2.0332082328877732e-07
      var_gnorm: 24.56610107421875
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 3.034799374290742e-05
    num_steps_sampled: 930000
    num_steps_trained: 930000
    wait_time_ms: 63.929
  iterations_since_restore: 186
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 1621.8456356525421
  time_this_iter_s: 9.430651903152466
  time_total_s: 1621.8456356525421
  timestamp: 1594859921
  timesteps_since_restore: 930000
  timesteps_this_iter: 5000
  timesteps_total: 930000
  training_iteration: 186
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 1621 s, 186 iter, 930000 ts, -501 rew

agent-1: 2.0
agent-2: -99.99999999894987
agent-3: -99.99999999894987
agent-4: -99.99999999894987
agent-5: -99.99999999894987
Extrinsic Rewards:
2
0
0
0
0
Sum Reward: 2
Avg Reward: 0.4
Min Reward: 0
Max Reward: 2
Gini Coefficient: 0.8
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-38-50
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -504.6231093695455
  episode_reward_min: -1102.4984374877972
  episodes_this_iter: 1
  episodes_total: 186
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.706
    dispatch_time_ms: 39.449
    learner:
      cur_lr: 0.0012980620376765728
      grad_gnorm: 0.6392214894294739
      policy_entropy: 0.00021323584951460361
      policy_loss: 2.965906276131136e-08
      var_gnorm: 24.5660343170166
      vf_explained_var: 0.0
      vf_loss: 0.0002710936823859811
    num_steps_sampled: 935000
    num_steps_trained: 935000
    wait_time_ms: 49.46
  iterations_since_restore: 187
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 1630.6431894302368
  time_this_iter_s: 8.797553777694702
  time_total_s: 1630.6431894302368
  timestamp: 1594859930
  timesteps_since_restore: 935000
  timesteps_this_iter: 5000
  timesteps_total: 935000
  training_iteration: 187
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 1630 s, 187 iter, 935000 ts, -505 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-38-58
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -504.6231093695455
  episode_reward_min: -1102.4984374877972
  episodes_this_iter: 1
  episodes_total: 187
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.865
    dispatch_time_ms: 29.429
    learner:
      cur_lr: 0.001297728973440826
      grad_gnorm: 0.7871350646018982
      policy_entropy: 0.00021036394173279405
      policy_loss: 2.93413251029051e-07
      var_gnorm: 24.566085815429688
      vf_explained_var: 0.0
      vf_loss: 0.0004108975699637085
    num_steps_sampled: 940000
    num_steps_trained: 940000
    wait_time_ms: 59.297
  iterations_since_restore: 188
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 1639.3539774417877
  time_this_iter_s: 8.710788011550903
  time_total_s: 1639.3539774417877
  timestamp: 1594859938
  timesteps_since_restore: 940000
  timesteps_this_iter: 5000
  timesteps_total: 940000
  training_iteration: 188
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 1639 s, 188 iter, 940000 ts, -505 rew

agent-1: -149.99999999840443
agent-2: -149.99999999840443
agent-3: 3.0
agent-4: -149.99999999840443
agent-5: -149.99999999840443
Extrinsic Rewards:
0
0
3
0
0
Sum Reward: 3
Avg Reward: 0.6
Min Reward: 0
Max Reward: 3
Gini Coefficient: 0.8
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-39-07
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -506.6131093695238
  episode_reward_min: -1102.4984374877972
  episodes_this_iter: 1
  episodes_total: 188
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 3.012
    dispatch_time_ms: 21.939
    learner:
      cur_lr: 0.001297396025620401
      grad_gnorm: 1.406296968460083
      policy_entropy: 0.00021096902491990477
      policy_loss: -1.1528913290703713e-07
      var_gnorm: 24.566057205200195
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 0.0013121338561177254
    num_steps_sampled: 945000
    num_steps_trained: 945000
    wait_time_ms: 66.879
  iterations_since_restore: 189
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 1648.0667281150818
  time_this_iter_s: 8.712750673294067
  time_total_s: 1648.0667281150818
  timestamp: 1594859947
  timesteps_since_restore: 945000
  timesteps_this_iter: 5000
  timesteps_total: 945000
  training_iteration: 189
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 1648 s, 189 iter, 945000 ts, -507 rew

agent-1: -199.99999999784504
agent-2: -199.99999999784504
agent-3: -199.99999999784504
agent-4: -199.99999999784504
agent-5: 4.0
Extrinsic Rewards:
0
0
0
0
4
Sum Reward: 4
Avg Reward: 0.8
Min Reward: 0
Max Reward: 4
Gini Coefficient: 0.8
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-39-16
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -507.61310936951287
  episode_reward_min: -1102.4984374877972
  episodes_this_iter: 1
  episodes_total: 189
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 3.715
    dispatch_time_ms: 30.655
    learner:
      cur_lr: 0.001297062961384654
      grad_gnorm: 0.012260040268301964
      policy_entropy: 0.00020978339307475835
      policy_loss: 1.2094822068320354e-06
      var_gnorm: 24.566102981567383
      vf_explained_var: 0.0
      vf_loss: 1.0719401188907796e-07
    num_steps_sampled: 950000
    num_steps_trained: 950000
    wait_time_ms: 54.326
  iterations_since_restore: 190
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 1656.7196021080017
  time_this_iter_s: 8.652873992919922
  time_total_s: 1656.7196021080017
  timestamp: 1594859956
  timesteps_since_restore: 950000
  timesteps_this_iter: 5000
  timesteps_total: 950000
  training_iteration: 190
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 1656 s, 190 iter, 950000 ts, -508 rew

agent-1: 2.75
agent-2: -249.99999999727223
agent-3: -249.99999999727223
agent-4: -150.24999999830888
agent-5: -249.99999999727223
Extrinsic Rewards:
4
0
0
1
0
Sum Reward: 5
Avg Reward: 1.0
Min Reward: 0
Max Reward: 4
Gini Coefficient: 0.72
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-39-25
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -516.588109369414
  episode_reward_min: -1102.4984374877972
  episodes_this_iter: 1
  episodes_total: 190
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 3.168
    dispatch_time_ms: 35.049
    learner:
      cur_lr: 0.001296730013564229
      grad_gnorm: 40.0
      policy_entropy: 0.0002114745875587687
      policy_loss: -4.834463106817566e-05
      var_gnorm: 24.56597328186035
      vf_explained_var: 0.0
      vf_loss: 289.6018371582031
    num_steps_sampled: 955000
    num_steps_trained: 955000
    wait_time_ms: 53.027
  iterations_since_restore: 191
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 1665.4590969085693
  time_this_iter_s: 8.739494800567627
  time_total_s: 1665.4590969085693
  timestamp: 1594859965
  timesteps_since_restore: 955000
  timesteps_this_iter: 5000
  timesteps_total: 955000
  training_iteration: 191
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 1665 s, 191 iter, 955000 ts, -517 rew

agent-1: -199.99999999780377
agent-2: -199.99999999780377
agent-3: -199.99999999780377
agent-4: -199.99999999780377
agent-5: 4.0
Extrinsic Rewards:
0
0
0
0
4
Sum Reward: 4
Avg Reward: 0.8
Min Reward: 0
Max Reward: 4
Gini Coefficient: 0.8
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-39-33
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -524.5481093693261
  episode_reward_min: -1102.4984374877972
  episodes_this_iter: 1
  episodes_total: 191
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 3.078
    dispatch_time_ms: 34.921
    learner:
      cur_lr: 0.0012963969493284822
      grad_gnorm: 0.6624016761779785
      policy_entropy: 0.00021479939459823072
      policy_loss: -1.2631468848667282e-07
      var_gnorm: 24.565967559814453
      vf_explained_var: 0.0
      vf_loss: 0.00029114526114426553
    num_steps_sampled: 960000
    num_steps_trained: 960000
    wait_time_ms: 51.313
  iterations_since_restore: 192
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 1674.1298983097076
  time_this_iter_s: 8.670801401138306
  time_total_s: 1674.1298983097076
  timestamp: 1594859973
  timesteps_since_restore: 960000
  timesteps_this_iter: 5000
  timesteps_total: 960000
  training_iteration: 192
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 1674 s, 192 iter, 960000 ts, -525 rew

agent-1: 2.0
agent-2: -99.99999999894987
agent-3: -99.99999999894987
agent-4: -99.99999999894987
agent-5: -99.99999999894987
Extrinsic Rewards:
2
0
0
0
0
Sum Reward: 2
Avg Reward: 0.4
Min Reward: 0
Max Reward: 2
Gini Coefficient: 0.8
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-39-42
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -522.5581093693479
  episode_reward_min: -1102.4984374877972
  episodes_this_iter: 1
  episodes_total: 192
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.522
    dispatch_time_ms: 27.686
    learner:
      cur_lr: 0.0012960640015080571
      grad_gnorm: 6.260311603546143
      policy_entropy: 0.00022052135318517685
      policy_loss: -2.7071038743997633e-07
      var_gnorm: 24.565698623657227
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 0.0260037612169981
    num_steps_sampled: 965000
    num_steps_trained: 965000
    wait_time_ms: 60.328
  iterations_since_restore: 193
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 1682.8527836799622
  time_this_iter_s: 8.722885370254517
  time_total_s: 1682.8527836799622
  timestamp: 1594859982
  timesteps_since_restore: 965000
  timesteps_this_iter: 5000
  timesteps_total: 965000
  training_iteration: 193
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 1682 s, 193 iter, 965000 ts, -523 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-39-51
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -514.5981093694357
  episode_reward_min: -1102.4984374877972
  episodes_this_iter: 1
  episodes_total: 193
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 3.248
    dispatch_time_ms: 31.039
    learner:
      cur_lr: 0.001295731053687632
      grad_gnorm: 4.048041343688965
      policy_entropy: 0.00021955165721010417
      policy_loss: 5.990462454974477e-07
      var_gnorm: 24.565719604492188
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 0.010872453451156616
    num_steps_sampled: 970000
    num_steps_trained: 970000
    wait_time_ms: 50.907
  iterations_since_restore: 194
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 1691.6014289855957
  time_this_iter_s: 8.748645305633545
  time_total_s: 1691.6014289855957
  timestamp: 1594859991
  timesteps_since_restore: 970000
  timesteps_this_iter: 5000
  timesteps_total: 970000
  training_iteration: 194
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 1691 s, 194 iter, 970000 ts, -515 rew

agent-1: -49.99999999946836
agent-2: 1.0
agent-3: -49.99999999946836
agent-4: -49.99999999946836
agent-5: -49.99999999946836
Extrinsic Rewards:
0
1
0
0
0
Sum Reward: 1
Avg Reward: 0.2
Min Reward: 0
Max Reward: 1
Gini Coefficient: 0.8
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-40-00
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -508.6381093694994
  episode_reward_min: -1102.4984374877972
  episodes_this_iter: 1
  episodes_total: 194
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.544
    dispatch_time_ms: 25.611
    learner:
      cur_lr: 0.0012953979894518852
      grad_gnorm: 6.274033069610596
      policy_entropy: 0.000220720874494873
      policy_loss: -1.4991304908562597e-07
      var_gnorm: 24.565675735473633
      vf_explained_var: 5.960464477539063e-08
      vf_loss: 0.02611781284213066
    num_steps_sampled: 975000
    num_steps_trained: 975000
    wait_time_ms: 59.43
  iterations_since_restore: 195
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 1700.4873504638672
  time_this_iter_s: 8.885921478271484
  time_total_s: 1700.4873504638672
  timestamp: 1594860000
  timesteps_since_restore: 975000
  timesteps_this_iter: 5000
  timesteps_total: 975000
  training_iteration: 195
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 1700 s, 195 iter, 975000 ts, -509 rew

agent-1: -149.99999999840443
agent-2: -149.99999999840443
agent-3: -149.99999999840443
agent-4: -149.99999999840443
agent-5: 3.0
Extrinsic Rewards:
0
0
0
0
3
Sum Reward: 3
Avg Reward: 0.6
Min Reward: 0
Max Reward: 3
Gini Coefficient: 0.8
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-40-09
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -506.64810936952176
  episode_reward_min: -1102.4984374877972
  episodes_this_iter: 1
  episodes_total: 195
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.477
    dispatch_time_ms: 16.646
    learner:
      cur_lr: 0.0012950650416314602
      grad_gnorm: 10.902769088745117
      policy_entropy: 0.0002173862449126318
      policy_loss: 1.419194404661539e-06
      var_gnorm: 24.56576156616211
      vf_explained_var: 0.0
      vf_loss: 0.0788705125451088
    num_steps_sampled: 980000
    num_steps_trained: 980000
    wait_time_ms: 63.598
  iterations_since_restore: 196
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 1709.234470129013
  time_this_iter_s: 8.747119665145874
  time_total_s: 1709.234470129013
  timestamp: 1594860009
  timesteps_since_restore: 980000
  timesteps_this_iter: 5000
  timesteps_total: 980000
  training_iteration: 196
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 1709 s, 196 iter, 980000 ts, -507 rew

agent-1: 2.96875
agent-2: -199.99999999784504
agent-3: -199.99999999784504
agent-4: -199.99999999784504
agent-5: -99.03124999890878
Extrinsic Rewards:
3
0
0
0
1
Sum Reward: 4
Avg Reward: 0.8
Min Reward: 0
Max Reward: 3
Gini Coefficient: 0.7
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-40-17
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -513.6087343694462
  episode_reward_min: -1102.4984374877972
  episodes_this_iter: 1
  episodes_total: 196
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.692
    dispatch_time_ms: 29.286
    learner:
      cur_lr: 0.0012947319773957133
      grad_gnorm: 0.2739149034023285
      policy_entropy: 0.00021221593488007784
      policy_loss: 2.8065999302384625e-08
      var_gnorm: 24.565969467163086
      vf_explained_var: 0.0
      vf_loss: 4.978411379852332e-05
    num_steps_sampled: 985000
    num_steps_trained: 985000
    wait_time_ms: 59.491
  iterations_since_restore: 197
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 1717.9454958438873
  time_this_iter_s: 8.711025714874268
  time_total_s: 1717.9454958438873
  timestamp: 1594860017
  timesteps_since_restore: 985000
  timesteps_this_iter: 5000
  timesteps_total: 985000
  training_iteration: 197
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 23.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 1717 s, 197 iter, 985000 ts, -514 rew

agent-1: 1.0
agent-2: -49.99999999946836
agent-3: -49.99999999946836
agent-4: -49.99999999946836
agent-5: -49.99999999946836
Extrinsic Rewards:
1
0
0
0
0
Sum Reward: 1
Avg Reward: 0.2
Min Reward: 0
Max Reward: 1
Gini Coefficient: 0.8
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-40-26
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -511.618734369467
  episode_reward_min: -1102.4984374877972
  episodes_this_iter: 1
  episodes_total: 197
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 3.935
    dispatch_time_ms: 26.84
    learner:
      cur_lr: 0.0012943990295752883
      grad_gnorm: 6.801108360290527
      policy_entropy: 0.0002205180935561657
      policy_loss: 2.346717565160361e-06
      var_gnorm: 24.565643310546875
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 0.030694205313920975
    num_steps_sampled: 990000
    num_steps_trained: 990000
    wait_time_ms: 68.331
  iterations_since_restore: 198
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 1726.6529078483582
  time_this_iter_s: 8.707412004470825
  time_total_s: 1726.6529078483582
  timestamp: 1594860026
  timesteps_since_restore: 990000
  timesteps_this_iter: 5000
  timesteps_total: 990000
  training_iteration: 198
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 23.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 1726 s, 198 iter, 990000 ts, -512 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-40-35
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -505.6337343695306
  episode_reward_min: -1102.4984374877972
  episodes_this_iter: 1
  episodes_total: 198
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.915
    dispatch_time_ms: 32.398
    learner:
      cur_lr: 0.0012940659653395414
      grad_gnorm: 8.101153373718262
      policy_entropy: 0.00021872126671951264
      policy_loss: -2.2411566646951542e-07
      var_gnorm: 24.565696716308594
      vf_explained_var: 1.7881393432617188e-07
      vf_loss: 0.04354461655020714
    num_steps_sampled: 995000
    num_steps_trained: 995000
    wait_time_ms: 37.426
  iterations_since_restore: 199
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 1735.2391684055328
  time_this_iter_s: 8.586260557174683
  time_total_s: 1735.2391684055328
  timestamp: 1594860035
  timesteps_since_restore: 995000
  timesteps_this_iter: 5000
  timesteps_total: 995000
  training_iteration: 199
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 24.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 1735 s, 199 iter, 995000 ts, -506 rew

agent-1: -399.9999999956487
agent-2: -399.9999999956487
agent-3: 0.34296875004196875
agent-4: -399.9999999956487
agent-5: 0.3429687499999998
Extrinsic Rewards:
0
0
4
0
4
Sum Reward: 8
Avg Reward: 1.6
Min Reward: 0
Max Reward: 4
Gini Coefficient: 0.6
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-40-44
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -513.6468749944416
  episode_reward_min: -1199.3140624869059
  episodes_this_iter: 1
  episodes_total: 199
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.716
    dispatch_time_ms: 30.048
    learner:
      cur_lr: 0.0012937330175191164
      grad_gnorm: 12.925097465515137
      policy_entropy: 0.00022628155420534313
      policy_loss: 1.2341918136371532e-06
      var_gnorm: 24.565568923950195
      vf_explained_var: 0.0
      vf_loss: 0.1190342828631401
    num_steps_sampled: 1000000
    num_steps_trained: 1000000
    wait_time_ms: 53.79
  iterations_since_restore: 200
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 1744.0864298343658
  time_this_iter_s: 8.847261428833008
  time_total_s: 1744.0864298343658
  timestamp: 1594860044
  timesteps_since_restore: 1000000
  timesteps_this_iter: 5000
  timesteps_total: 1000000
  training_iteration: 200
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 1744 s, 200 iter, 1000000 ts, -514 rew

agent-1: -199.99999999788645
agent-2: -199.99999999788645
agent-3: 3.0
agent-4: -199.99999999788645
agent-5: -98.999999998923
Extrinsic Rewards:
0
0
3
0
1
Sum Reward: 4
Avg Reward: 0.8
Min Reward: 0
Max Reward: 3
Gini Coefficient: 0.7
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-40-52
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -520.6068749943674
  episode_reward_min: -1199.3140624869059
  episodes_this_iter: 1
  episodes_total: 200
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 3.526
    dispatch_time_ms: 25.679
    learner:
      cur_lr: 0.0012933999532833695
      grad_gnorm: 0.23618920147418976
      policy_entropy: 0.00021344533888623118
      policy_loss: 2.7536774638292627e-08
      var_gnorm: 24.565908432006836
      vf_explained_var: 0.0
      vf_loss: 3.701450623339042e-05
    num_steps_sampled: 1005000
    num_steps_trained: 1005000
    wait_time_ms: 59.874
  iterations_since_restore: 201
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 1752.7198486328125
  time_this_iter_s: 8.633418798446655
  time_total_s: 1752.7198486328125
  timestamp: 1594860052
  timesteps_since_restore: 1005000
  timesteps_this_iter: 5000
  timesteps_total: 1005000
  training_iteration: 201
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 1752 s, 201 iter, 1005000 ts, -521 rew

agent-1: 0.34296875004196875
agent-2: -399.9999999956487
agent-3: -399.9999999956487
agent-4: 0.3429687499999998
agent-5: -399.9999999956487
Extrinsic Rewards:
4
0
0
4
0
Sum Reward: 8
Avg Reward: 1.6
Min Reward: 0
Max Reward: 4
Gini Coefficient: 0.6
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-41-01
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -528.6200156192784
  episode_reward_min: -1199.314062486906
  episodes_this_iter: 1
  episodes_total: 201
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 3.737
    dispatch_time_ms: 27.63
    learner:
      cur_lr: 0.0012930670054629445
      grad_gnorm: 4.3073296546936035
      policy_entropy: 0.00022369025100488216
      policy_loss: 1.7008537724905182e-06
      var_gnorm: 24.5655517578125
      vf_explained_var: 0.0
      vf_loss: 0.012310580350458622
    num_steps_sampled: 1010000
    num_steps_trained: 1010000
    wait_time_ms: 67.025
  iterations_since_restore: 202
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 1761.561033964157
  time_this_iter_s: 8.841185331344604
  time_total_s: 1761.561033964157
  timestamp: 1594860061
  timesteps_since_restore: 1010000
  timesteps_this_iter: 5000
  timesteps_total: 1010000
  training_iteration: 202
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 1761 s, 202 iter, 1010000 ts, -529 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-41-10
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -528.6200156192783
  episode_reward_min: -1199.314062486906
  episodes_this_iter: 1
  episodes_total: 202
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.574
    dispatch_time_ms: 18.339
    learner:
      cur_lr: 0.0012927340576425195
      grad_gnorm: 0.2647171914577484
      policy_entropy: 0.0002207602228736505
      policy_loss: 3.095729539381864e-08
      var_gnorm: 24.565706253051758
      vf_explained_var: 0.0
      vf_loss: 4.649691982194781e-05
    num_steps_sampled: 1015000
    num_steps_trained: 1015000
    wait_time_ms: 63.549
  iterations_since_restore: 203
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 1770.3279252052307
  time_this_iter_s: 8.766891241073608
  time_total_s: 1770.3279252052307
  timestamp: 1594860070
  timesteps_since_restore: 1015000
  timesteps_this_iter: 5000
  timesteps_total: 1015000
  training_iteration: 203
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 1770 s, 203 iter, 1015000 ts, -529 rew

agent-1: -199.99999999774747
agent-2: 4.0
agent-3: -199.99999999774747
agent-4: -199.99999999774747
agent-5: -199.99999999774747
Extrinsic Rewards:
0
4
0
0
0
Sum Reward: 4
Avg Reward: 0.8
Min Reward: 0
Max Reward: 4
Gini Coefficient: 0.8
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-41-19
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -527.605015619287
  episode_reward_min: -1199.314062486906
  episodes_this_iter: 1
  episodes_total: 203
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.815
    dispatch_time_ms: 20.844
    learner:
      cur_lr: 0.0012924009934067726
      grad_gnorm: 5.752565383911133
      policy_entropy: 0.00023765608784742653
      policy_loss: 1.614749521650083e-06
      var_gnorm: 24.565210342407227
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 0.021956667304039
    num_steps_sampled: 1020000
    num_steps_trained: 1020000
    wait_time_ms: 71.83
  iterations_since_restore: 204
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 1779.2911579608917
  time_this_iter_s: 8.96323275566101
  time_total_s: 1779.2911579608917
  timestamp: 1594860079
  timesteps_since_restore: 1020000
  timesteps_this_iter: 5000
  timesteps_total: 1020000
  training_iteration: 204
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 1779 s, 204 iter, 1020000 ts, -528 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-41-28
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -527.605015619287
  episode_reward_min: -1199.314062486906
  episodes_this_iter: 1
  episodes_total: 204
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.799
    dispatch_time_ms: 15.715
    learner:
      cur_lr: 0.0012920680455863476
      grad_gnorm: 20.29712677001953
      policy_entropy: 0.0002496441302355379
      policy_loss: -1.2534294455690542e-06
      var_gnorm: 24.565317153930664
      vf_explained_var: 0.0
      vf_loss: 0.27334538102149963
    num_steps_sampled: 1025000
    num_steps_trained: 1025000
    wait_time_ms: 66.341
  iterations_since_restore: 205
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 1787.9539260864258
  time_this_iter_s: 8.662768125534058
  time_total_s: 1787.9539260864258
  timestamp: 1594860088
  timesteps_since_restore: 1025000
  timesteps_this_iter: 5000
  timesteps_total: 1025000
  training_iteration: 205
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 1787 s, 205 iter, 1025000 ts, -528 rew

agent-1: -98.999999998923
agent-2: -199.99999999788645
agent-3: -199.99999999788645
agent-4: 3.0
agent-5: -199.99999999788645
Extrinsic Rewards:
1
0
0
3
0
Sum Reward: 4
Avg Reward: 0.8
Min Reward: 0
Max Reward: 3
Gini Coefficient: 0.7
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-41-37
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -526.6050156193008
  episode_reward_min: -1199.314062486906
  episodes_this_iter: 1
  episodes_total: 205
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.848
    dispatch_time_ms: 25.21
    learner:
      cur_lr: 0.0012917349813506007
      grad_gnorm: 0.09426131844520569
      policy_entropy: 0.00023982682614587247
      policy_loss: -1.090528467528884e-08
      var_gnorm: 24.56523895263672
      vf_explained_var: 0.0
      vf_loss: 5.893200523132691e-06
    num_steps_sampled: 1030000
    num_steps_trained: 1030000
    wait_time_ms: 50.628
  iterations_since_restore: 206
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 1796.7473058700562
  time_this_iter_s: 8.793379783630371
  time_total_s: 1796.7473058700562
  timestamp: 1594860097
  timesteps_since_restore: 1030000
  timesteps_this_iter: 5000
  timesteps_total: 1030000
  training_iteration: 206
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 1796 s, 206 iter, 1030000 ts, -527 rew

agent-1: -99.99999999894987
agent-2: -99.99999999894987
agent-3: -99.99999999894987
agent-4: 2.0
agent-5: -99.99999999894987
Extrinsic Rewards:
0
0
0
2
0
Sum Reward: 2
Avg Reward: 0.4
Min Reward: 0
Max Reward: 2
Gini Coefficient: 0.8
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-41-52
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -523.625015619334
  episode_reward_min: -1199.314062486906
  episodes_this_iter: 1
  episodes_total: 206
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.818
    dispatch_time_ms: 37.013
    learner:
      cur_lr: 0.0012914020335301757
      grad_gnorm: 29.070213317871094
      policy_entropy: 0.00028142009978182614
      policy_loss: 1.373605186927307e-06
      var_gnorm: 24.5648136138916
      vf_explained_var: 0.0
      vf_loss: 0.5018912553787231
    num_steps_sampled: 1035000
    num_steps_trained: 1035000
    wait_time_ms: 49.249
  iterations_since_restore: 207
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 1811.702069759369
  time_this_iter_s: 14.954763889312744
  time_total_s: 1811.702069759369
  timestamp: 1594860112
  timesteps_since_restore: 1035000
  timesteps_this_iter: 5000
  timesteps_total: 1035000
  training_iteration: 207
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 1811 s, 207 iter, 1035000 ts, -524 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-42-00
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -523.6250156193341
  episode_reward_min: -1199.314062486906
  episodes_this_iter: 1
  episodes_total: 207
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.802
    dispatch_time_ms: 14.011
    learner:
      cur_lr: 0.0012910689692944288
      grad_gnorm: 9.180450439453125
      policy_entropy: 0.0002858812513295561
      policy_loss: 2.721464397836826e-06
      var_gnorm: 24.5643367767334
      vf_explained_var: 1.1920928955078125e-07
      vf_loss: 0.05605095624923706
    num_steps_sampled: 1040000
    num_steps_trained: 1040000
    wait_time_ms: 72.062
  iterations_since_restore: 208
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 1820.3493807315826
  time_this_iter_s: 8.647310972213745
  time_total_s: 1820.3493807315826
  timestamp: 1594860120
  timesteps_since_restore: 1040000
  timesteps_this_iter: 5000
  timesteps_total: 1040000
  training_iteration: 208
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 1820 s, 208 iter, 1040000 ts, -524 rew

agent-1: -49.999999999481645
agent-2: 1.0
agent-3: -49.999999999481645
agent-4: -49.999999999481645
agent-5: -49.999999999481645
Extrinsic Rewards:
0
1
0
0
0
Sum Reward: 1
Avg Reward: 0.2
Min Reward: 0
Max Reward: 1
Gini Coefficient: 0.8
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-42-09
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -519.6450156193771
  episode_reward_min: -1199.314062486906
  episodes_this_iter: 1
  episodes_total: 208
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 3.045
    dispatch_time_ms: 25.218
    learner:
      cur_lr: 0.0012907360214740038
      grad_gnorm: 0.4730667769908905
      policy_entropy: 0.00027387397130951285
      policy_loss: 2.103201879322114e-08
      var_gnorm: 24.56453514099121
      vf_explained_var: 0.0
      vf_loss: 0.00012671797594521195
    num_steps_sampled: 1045000
    num_steps_trained: 1045000
    wait_time_ms: 65.076
  iterations_since_restore: 209
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 1829.0785458087921
  time_this_iter_s: 8.729165077209473
  time_total_s: 1829.0785458087921
  timestamp: 1594860129
  timesteps_since_restore: 1045000
  timesteps_this_iter: 5000
  timesteps_total: 1045000
  training_iteration: 209
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 1829 s, 209 iter, 1045000 ts, -520 rew

agent-1: 2.96875
agent-2: -199.99999999784504
agent-3: -99.03124999890878
agent-4: -199.99999999784504
agent-5: -199.99999999784504
Extrinsic Rewards:
3
0
1
0
0
Sum Reward: 4
Avg Reward: 0.8
Min Reward: 0
Max Reward: 3
Gini Coefficient: 0.7
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-42-18
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -518.6656406193863
  episode_reward_min: -1199.314062486906
  episodes_this_iter: 1
  episodes_total: 209
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.753
    dispatch_time_ms: 18.629
    learner:
      cur_lr: 0.001290402957238257
      grad_gnorm: 9.780478477478027
      policy_entropy: 0.00031090134871192276
      policy_loss: 1.6650117231620243e-06
      var_gnorm: 24.563961029052734
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 0.0634690374135971
    num_steps_sampled: 1050000
    num_steps_trained: 1050000
    wait_time_ms: 67.402
  iterations_since_restore: 210
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 1837.7159821987152
  time_this_iter_s: 8.637436389923096
  time_total_s: 1837.7159821987152
  timestamp: 1594860138
  timesteps_since_restore: 1050000
  timesteps_this_iter: 5000
  timesteps_total: 1050000
  training_iteration: 210
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 1837 s, 210 iter, 1050000 ts, -519 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-42-26
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -518.6656406193863
  episode_reward_min: -1199.314062486906
  episodes_this_iter: 1
  episodes_total: 210
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.493
    dispatch_time_ms: 25.263
    learner:
      cur_lr: 0.001290070009417832
      grad_gnorm: 25.767093658447266
      policy_entropy: 0.0003369432524777949
      policy_loss: 2.3010461518424563e-06
      var_gnorm: 24.564346313476562
      vf_explained_var: 0.0
      vf_loss: 0.4405275285243988
    num_steps_sampled: 1055000
    num_steps_trained: 1055000
    wait_time_ms: 46.064
  iterations_since_restore: 211
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 1846.3605012893677
  time_this_iter_s: 8.644519090652466
  time_total_s: 1846.3605012893677
  timestamp: 1594860146
  timesteps_since_restore: 1055000
  timesteps_this_iter: 5000
  timesteps_total: 1055000
  training_iteration: 211
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 1846 s, 211 iter, 1055000 ts, -519 rew

agent-1: -149.99999999840443
agent-2: 3.0
agent-3: -149.99999999840443
agent-4: -149.99999999840443
agent-5: -149.99999999840443
Extrinsic Rewards:
0
3
0
0
0
Sum Reward: 3
Avg Reward: 0.6
Min Reward: 0
Max Reward: 3
Gini Coefficient: 0.8
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-42-35
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -520.6556406193646
  episode_reward_min: -1199.314062486906
  episodes_this_iter: 1
  episodes_total: 211
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.67
    dispatch_time_ms: 30.957
    learner:
      cur_lr: 0.001289736945182085
      grad_gnorm: 17.31797218322754
      policy_entropy: 0.00034088591928593814
      policy_loss: 2.107938598783221e-06
      var_gnorm: 24.563703536987305
      vf_explained_var: 1.1920928955078125e-07
      vf_loss: 0.19899263978004456
    num_steps_sampled: 1060000
    num_steps_trained: 1060000
    wait_time_ms: 58.364
  iterations_since_restore: 212
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 1855.2087969779968
  time_this_iter_s: 8.84829568862915
  time_total_s: 1855.2087969779968
  timestamp: 1594860155
  timesteps_since_restore: 1060000
  timesteps_this_iter: 5000
  timesteps_total: 1060000
  training_iteration: 212
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 1855 s, 212 iter, 1060000 ts, -521 rew

agent-1: -99.99999999894987
agent-2: -99.99999999894987
agent-3: -99.99999999894987
agent-4: -99.99999999894987
agent-5: 2.0
Extrinsic Rewards:
0
0
0
0
2
Sum Reward: 2
Avg Reward: 0.4
Min Reward: 0
Max Reward: 2
Gini Coefficient: 0.8
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-42-44
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -521.6556406193537
  episode_reward_min: -1199.314062486906
  episodes_this_iter: 1
  episodes_total: 212
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.759
    dispatch_time_ms: 28.328
    learner:
      cur_lr: 0.00128940399736166
      grad_gnorm: 21.70963478088379
      policy_entropy: 0.00034818294807337224
      policy_loss: 1.138991251536936e-06
      var_gnorm: 24.563772201538086
      vf_explained_var: 0.0
      vf_loss: 0.31271451711654663
    num_steps_sampled: 1065000
    num_steps_trained: 1065000
    wait_time_ms: 59.712
  iterations_since_restore: 213
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 1864.084746837616
  time_this_iter_s: 8.87594985961914
  time_total_s: 1864.084746837616
  timestamp: 1594860164
  timesteps_since_restore: 1065000
  timesteps_this_iter: 5000
  timesteps_total: 1065000
  training_iteration: 213
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 1864 s, 213 iter, 1065000 ts, -522 rew

agent-1: -249.99999999731412
agent-2: -249.99999999731412
agent-3: -249.99999999731412
agent-4: 4.0
agent-5: -148.99999999837678
Extrinsic Rewards:
0
0
0
4
1
Sum Reward: 5
Avg Reward: 1.0
Min Reward: 0
Max Reward: 4
Gini Coefficient: 0.72
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-42-53
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -519.626265619379
  episode_reward_min: -1199.314062486906
  episodes_this_iter: 1
  episodes_total: 213
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.578
    dispatch_time_ms: 25.808
    learner:
      cur_lr: 0.001289071049541235
      grad_gnorm: 15.511274337768555
      policy_entropy: 0.00034144282108172774
      policy_loss: 3.3786934636736987e-06
      var_gnorm: 24.563520431518555
      vf_explained_var: 0.0
      vf_loss: 0.15963831543922424
    num_steps_sampled: 1070000
    num_steps_trained: 1070000
    wait_time_ms: 58.415
  iterations_since_restore: 214
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 1872.8396768569946
  time_this_iter_s: 8.754930019378662
  time_total_s: 1872.8396768569946
  timestamp: 1594860173
  timesteps_since_restore: 1070000
  timesteps_this_iter: 5000
  timesteps_total: 1070000
  training_iteration: 214
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 1872 s, 214 iter, 1070000 ts, -520 rew

agent-1: -99.99999999894987
agent-2: -99.99999999894987
agent-3: -99.99999999894987
agent-4: -99.99999999894987
agent-5: 2.0
Extrinsic Rewards:
0
0
0
0
2
Sum Reward: 2
Avg Reward: 0.4
Min Reward: 0
Max Reward: 2
Gini Coefficient: 0.8
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-43-02
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -513.6662656194453
  episode_reward_min: -1199.314062486906
  episodes_this_iter: 1
  episodes_total: 214
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.853
    dispatch_time_ms: 29.71
    learner:
      cur_lr: 0.0012887379853054881
      grad_gnorm: 24.004165649414062
      policy_entropy: 0.0003419581626076251
      policy_loss: 1.9453107142908266e-06
      var_gnorm: 24.56385612487793
      vf_explained_var: 5.960464477539063e-08
      vf_loss: 0.3823104798793793
    num_steps_sampled: 1075000
    num_steps_trained: 1075000
    wait_time_ms: 63.687
  iterations_since_restore: 215
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 1881.6346111297607
  time_this_iter_s: 8.794934272766113
  time_total_s: 1881.6346111297607
  timestamp: 1594860182
  timesteps_since_restore: 1075000
  timesteps_this_iter: 5000
  timesteps_total: 1075000
  training_iteration: 215
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 1881 s, 215 iter, 1075000 ts, -514 rew

agent-1: -98.99999999893653
agent-2: -199.99999999787352
agent-3: -199.99999999787352
agent-4: -199.99999999787352
agent-5: 3.0
Extrinsic Rewards:
1
0
0
0
3
Sum Reward: 4
Avg Reward: 0.8
Min Reward: 0
Max Reward: 3
Gini Coefficient: 0.7
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-43-10
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -513.666265619445
  episode_reward_min: -1199.314062486906
  episodes_this_iter: 1
  episodes_total: 215
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.646
    dispatch_time_ms: 37.238
    learner:
      cur_lr: 0.001288405037485063
      grad_gnorm: 18.12738800048828
      policy_entropy: 0.0003267870924901217
      policy_loss: 1.3203182334109442e-06
      var_gnorm: 24.563364028930664
      vf_explained_var: 0.0
      vf_loss: 0.20847445726394653
    num_steps_sampled: 1080000
    num_steps_trained: 1080000
    wait_time_ms: 50.013
  iterations_since_restore: 216
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 1890.3424725532532
  time_this_iter_s: 8.707861423492432
  time_total_s: 1890.3424725532532
  timestamp: 1594860190
  timesteps_since_restore: 1080000
  timesteps_this_iter: 5000
  timesteps_total: 1080000
  training_iteration: 216
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 1890 s, 216 iter, 1080000 ts, -514 rew

agent-1: -149.99999999840443
agent-2: -149.99999999840443
agent-3: 3.0
agent-4: -149.99999999840443
agent-5: -149.99999999840443
Extrinsic Rewards:
0
0
3
0
0
Sum Reward: 3
Avg Reward: 0.6
Min Reward: 0
Max Reward: 3
Gini Coefficient: 0.8
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-43-19
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -512.6762656194554
  episode_reward_min: -1199.314062486906
  episodes_this_iter: 1
  episodes_total: 216
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 3.27
    dispatch_time_ms: 28.784
    learner:
      cur_lr: 0.0012880719732493162
      grad_gnorm: 0.1837216168642044
      policy_entropy: 0.00028230593306943774
      policy_loss: 3.0348299873139695e-08
      var_gnorm: 24.563791275024414
      vf_explained_var: 5.960464477539063e-08
      vf_loss: 2.2392294340534136e-05
    num_steps_sampled: 1085000
    num_steps_trained: 1085000
    wait_time_ms: 58.644
  iterations_since_restore: 217
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 1899.059870481491
  time_this_iter_s: 8.717397928237915
  time_total_s: 1899.059870481491
  timestamp: 1594860199
  timesteps_since_restore: 1085000
  timesteps_this_iter: 5000
  timesteps_total: 1085000
  training_iteration: 217
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 1899 s, 217 iter, 1085000 ts, -513 rew

agent-1: 3.0
agent-2: -299.9999999967398
agent-3: -299.9999999967398
agent-4: -151.46874999833582
agent-5: -50.468749999537614
Extrinsic Rewards:
3
0
0
1
2
Sum Reward: 6
Avg Reward: 1.2
Min Reward: 0
Max Reward: 3
Gini Coefficient: 0.5333333333333333
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-43-28
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -518.6756406193897
  episode_reward_min: -1199.314062486906
  episodes_this_iter: 1
  episodes_total: 217
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.904
    dispatch_time_ms: 29.132
    learner:
      cur_lr: 0.0012877390254288912
      grad_gnorm: 0.14683778584003448
      policy_entropy: 0.0003172145807184279
      policy_loss: 5.051287388369019e-08
      var_gnorm: 24.563322067260742
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 1.4305992408480961e-05
    num_steps_sampled: 1090000
    num_steps_trained: 1090000
    wait_time_ms: 65.974
  iterations_since_restore: 218
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 1907.8434917926788
  time_this_iter_s: 8.783621311187744
  time_total_s: 1907.8434917926788
  timestamp: 1594860208
  timesteps_since_restore: 1090000
  timesteps_this_iter: 5000
  timesteps_total: 1090000
  training_iteration: 218
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 1907 s, 218 iter, 1090000 ts, -519 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-43-37
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -512.7056406194546
  episode_reward_min: -1199.314062486906
  episodes_this_iter: 1
  episodes_total: 218
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 3.13
    dispatch_time_ms: 23.345
    learner:
      cur_lr: 0.0012874059611931443
      grad_gnorm: 30.131731033325195
      policy_entropy: 0.0005213062977418303
      policy_loss: 2.4053319975791965e-06
      var_gnorm: 24.56324005126953
      vf_explained_var: 0.0
      vf_loss: 0.6024056673049927
    num_steps_sampled: 1095000
    num_steps_trained: 1095000
    wait_time_ms: 60.633
  iterations_since_restore: 219
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 1916.4566621780396
  time_this_iter_s: 8.613170385360718
  time_total_s: 1916.4566621780396
  timestamp: 1594860217
  timesteps_since_restore: 1095000
  timesteps_this_iter: 5000
  timesteps_total: 1095000
  training_iteration: 219
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 1916 s, 219 iter, 1095000 ts, -513 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-43-46
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -504.74564061954237
  episode_reward_min: -1199.314062486906
  episodes_this_iter: 1
  episodes_total: 219
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.618
    dispatch_time_ms: 19.591
    learner:
      cur_lr: 0.0012870730133727193
      grad_gnorm: 12.785740852355957
      policy_entropy: 0.00037171586882323027
      policy_loss: 1.5490350051550195e-06
      var_gnorm: 24.562551498413086
      vf_explained_var: 0.0
      vf_loss: 0.1351012885570526
    num_steps_sampled: 1100000
    num_steps_trained: 1100000
    wait_time_ms: 69.414
  iterations_since_restore: 220
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 1925.278421163559
  time_this_iter_s: 8.82175898551941
  time_total_s: 1925.278421163559
  timestamp: 1594860226
  timesteps_since_restore: 1100000
  timesteps_this_iter: 5000
  timesteps_total: 1100000
  training_iteration: 220
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 1925 s, 220 iter, 1100000 ts, -505 rew

agent-1: -349.99999999613846
agent-2: 1.53125
agent-3: -349.99999999613846
agent-4: -349.99999999613846
agent-5: -49.46874999938334
Extrinsic Rewards:
0
4
0
0
3
Sum Reward: 7
Avg Reward: 1.4
Min Reward: 0
Max Reward: 4
Gini Coefficient: 0.6285714285714286
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-43-54
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -510.755015619473
  episode_reward_min: -1199.314062486906
  episodes_this_iter: 1
  episodes_total: 220
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.835
    dispatch_time_ms: 25.601
    learner:
      cur_lr: 0.0012867399491369724
      grad_gnorm: 7.083014965057373
      policy_entropy: 0.00035612485953606665
      policy_loss: 2.912619834205543e-07
      var_gnorm: 24.563085556030273
      vf_explained_var: 5.960464477539063e-08
      vf_loss: 0.09939432144165039
    num_steps_sampled: 1105000
    num_steps_trained: 1105000
    wait_time_ms: 62.321
  iterations_since_restore: 221
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 1934.0528254508972
  time_this_iter_s: 8.774404287338257
  time_total_s: 1934.0528254508972
  timestamp: 1594860234
  timesteps_since_restore: 1105000
  timesteps_this_iter: 5000
  timesteps_total: 1105000
  training_iteration: 221
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 1934 s, 221 iter, 1105000 ts, -511 rew

agent-1: 4.0
agent-2: -148.99999999837678
agent-3: -249.99999999731412
agent-4: -249.99999999731412
agent-5: -249.99999999731412
Extrinsic Rewards:
4
1
0
0
0
Sum Reward: 5
Avg Reward: 1.0
Min Reward: 0
Max Reward: 4
Gini Coefficient: 0.72
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-44-03
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -519.705015619376
  episode_reward_min: -1199.314062486906
  episodes_this_iter: 1
  episodes_total: 221
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 3.149
    dispatch_time_ms: 26.17
    learner:
      cur_lr: 0.0012864070013165474
      grad_gnorm: 13.028605461120605
      policy_entropy: 0.0003268549626227468
      policy_loss: 2.020348119913251e-06
      var_gnorm: 24.562414169311523
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 0.11299893260002136
    num_steps_sampled: 1110000
    num_steps_trained: 1110000
    wait_time_ms: 64.964
  iterations_since_restore: 222
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 1942.9258196353912
  time_this_iter_s: 8.872994184494019
  time_total_s: 1942.9258196353912
  timestamp: 1594860243
  timesteps_since_restore: 1110000
  timesteps_this_iter: 5000
  timesteps_total: 1110000
  training_iteration: 222
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 1942 s, 222 iter, 1110000 ts, -520 rew

agent-1: -149.99999999840443
agent-2: -149.99999999840443
agent-3: -149.99999999840443
agent-4: -149.99999999840443
agent-5: 3.0
Extrinsic Rewards:
0
0
0
0
3
Sum Reward: 3
Avg Reward: 0.6
Min Reward: 0
Max Reward: 3
Gini Coefficient: 0.8
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-44-12
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -521.6950156193543
  episode_reward_min: -1199.314062486906
  episodes_this_iter: 1
  episodes_total: 222
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.649
    dispatch_time_ms: 18.347
    learner:
      cur_lr: 0.0012860740534961224
      grad_gnorm: 23.134254455566406
      policy_entropy: 0.0003261523961555213
      policy_loss: 7.884752903919434e-07
      var_gnorm: 24.562673568725586
      vf_explained_var: 0.0
      vf_loss: 0.35510286688804626
    num_steps_sampled: 1115000
    num_steps_trained: 1115000
    wait_time_ms: 71.619
  iterations_since_restore: 223
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 1951.7006433010101
  time_this_iter_s: 8.774823665618896
  time_total_s: 1951.7006433010101
  timestamp: 1594860252
  timesteps_since_restore: 1115000
  timesteps_this_iter: 5000
  timesteps_total: 1115000
  training_iteration: 223
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 1951 s, 223 iter, 1115000 ts, -522 rew

agent-1: -199.99999999784504
agent-2: -199.99999999784504
agent-3: -199.99999999784504
agent-4: -199.99999999784504
agent-5: 4.0
Extrinsic Rewards:
0
0
0
0
4
Sum Reward: 4
Avg Reward: 0.8
Min Reward: 0
Max Reward: 4
Gini Coefficient: 0.8
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-44-21
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -519.690015619377
  episode_reward_min: -1199.314062486906
  episodes_this_iter: 1
  episodes_total: 223
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.868
    dispatch_time_ms: 21.451
    learner:
      cur_lr: 0.0012857409892603755
      grad_gnorm: 15.267448425292969
      policy_entropy: 0.0003179220948368311
      policy_loss: 2.6723002974904375e-06
      var_gnorm: 24.562185287475586
      vf_explained_var: 0.0
      vf_loss: 0.15465869009494781
    num_steps_sampled: 1120000
    num_steps_trained: 1120000
    wait_time_ms: 62.086
  iterations_since_restore: 224
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 1960.3850231170654
  time_this_iter_s: 8.684379816055298
  time_total_s: 1960.3850231170654
  timestamp: 1594860261
  timesteps_since_restore: 1120000
  timesteps_this_iter: 5000
  timesteps_total: 1120000
  training_iteration: 224
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 1960 s, 224 iter, 1120000 ts, -520 rew

agent-1: -249.99999999727225
agent-2: -47.9999999995376
agent-3: -249.99999999727225
agent-4: 3.0
agent-5: -249.99999999727225
Extrinsic Rewards:
0
2
0
3
0
Sum Reward: 5
Avg Reward: 1.0
Min Reward: 0
Max Reward: 3
Gini Coefficient: 0.64
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-44-30
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -519.6800156193784
  episode_reward_min: -1199.314062486906
  episodes_this_iter: 1
  episodes_total: 224
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.701
    dispatch_time_ms: 29.556
    learner:
      cur_lr: 0.0012854080414399505
      grad_gnorm: 0.09076972305774689
      policy_entropy: 0.00026909049483947456
      policy_loss: 1.1338843641794938e-08
      var_gnorm: 24.56290054321289
      vf_explained_var: 0.0
      vf_loss: 6.7857763497158885e-06
    num_steps_sampled: 1125000
    num_steps_trained: 1125000
    wait_time_ms: 45.614
  iterations_since_restore: 225
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 1969.109674692154
  time_this_iter_s: 8.724651575088501
  time_total_s: 1969.109674692154
  timestamp: 1594860270
  timesteps_since_restore: 1125000
  timesteps_this_iter: 5000
  timesteps_total: 1125000
  training_iteration: 225
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 1969 s, 225 iter, 1125000 ts, -520 rew

agent-1: -149.99999999840443
agent-2: -149.99999999840443
agent-3: -149.99999999840443
agent-4: -149.99999999840443
agent-5: 3.0
Extrinsic Rewards:
0
0
0
0
3
Sum Reward: 3
Avg Reward: 0.6
Min Reward: 0
Max Reward: 3
Gini Coefficient: 0.8
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-44-38
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -521.6700156193568
  episode_reward_min: -1199.314062486906
  episodes_this_iter: 1
  episodes_total: 225
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.711
    dispatch_time_ms: 29.088
    learner:
      cur_lr: 0.0012850749772042036
      grad_gnorm: 0.030455153435468674
      policy_entropy: 0.0003102476184722036
      policy_loss: 6.752377323948622e-09
      var_gnorm: 24.56215476989746
      vf_explained_var: 0.0
      vf_loss: 6.160637440189021e-07
    num_steps_sampled: 1130000
    num_steps_trained: 1130000
    wait_time_ms: 62.888
  iterations_since_restore: 226
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 1977.8188798427582
  time_this_iter_s: 8.709205150604248
  time_total_s: 1977.8188798427582
  timestamp: 1594860278
  timesteps_since_restore: 1130000
  timesteps_this_iter: 5000
  timesteps_total: 1130000
  training_iteration: 226
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 23.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 1977 s, 226 iter, 1130000 ts, -522 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-44-47
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -515.7000156194215
  episode_reward_min: -1199.314062486906
  episodes_this_iter: 1
  episodes_total: 226
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.877
    dispatch_time_ms: 20.032
    learner:
      cur_lr: 0.0012847420293837786
      grad_gnorm: 0.027938468381762505
      policy_entropy: 0.0003788704052567482
      policy_loss: 4.7861457019848785e-09
      var_gnorm: 24.56130027770996
      vf_explained_var: 0.0
      vf_loss: 5.177017214919033e-07
    num_steps_sampled: 1135000
    num_steps_trained: 1135000
    wait_time_ms: 61.676
  iterations_since_restore: 227
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 1986.5108017921448
  time_this_iter_s: 8.691921949386597
  time_total_s: 1986.5108017921448
  timestamp: 1594860287
  timesteps_since_restore: 1135000
  timesteps_this_iter: 5000
  timesteps_total: 1135000
  training_iteration: 227
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 23.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 1986 s, 227 iter, 1135000 ts, -516 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-44-56
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -504.7156406195426
  episode_reward_min: -1199.314062486906
  episodes_this_iter: 1
  episodes_total: 227
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 3.13
    dispatch_time_ms: 19.33
    learner:
      cur_lr: 0.0012844089651480317
      grad_gnorm: 8.461484909057617
      policy_entropy: 0.00041302863974124193
      policy_loss: 3.0249216251831967e-06
      var_gnorm: 24.560619354248047
      vf_explained_var: 5.960464477539063e-08
      vf_loss: 0.04802966117858887
    num_steps_sampled: 1140000
    num_steps_trained: 1140000
    wait_time_ms: 67.167
  iterations_since_restore: 228
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 1995.2068319320679
  time_this_iter_s: 8.696030139923096
  time_total_s: 1995.2068319320679
  timestamp: 1594860296
  timesteps_since_restore: 1140000
  timesteps_this_iter: 5000
  timesteps_total: 1140000
  training_iteration: 228
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 23.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 1995 s, 228 iter, 1140000 ts, -505 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-45-04
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -498.74564061960746
  episode_reward_min: -1199.314062486906
  episodes_this_iter: 1
  episodes_total: 228
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 4.097
    dispatch_time_ms: 31.407
    learner:
      cur_lr: 0.0012840760173276067
      grad_gnorm: 28.541526794433594
      policy_entropy: 0.0003465161717031151
      policy_loss: 2.3450047592632473e-06
      var_gnorm: 24.562116622924805
      vf_explained_var: 0.0
      vf_loss: 0.5405018329620361
    num_steps_sampled: 1145000
    num_steps_trained: 1145000
    wait_time_ms: 52.953
  iterations_since_restore: 229
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 2003.9253027439117
  time_this_iter_s: 8.718470811843872
  time_total_s: 2003.9253027439117
  timestamp: 1594860304
  timesteps_since_restore: 1145000
  timesteps_this_iter: 5000
  timesteps_total: 1145000
  training_iteration: 229
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 23.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 2003 s, 229 iter, 1145000 ts, -499 rew

agent-1: 0.75
agent-2: -199.99999999788645
agent-3: -199.99999999788645
agent-4: 0.7500000000136119
agent-5: -199.99999999788645
Extrinsic Rewards:
2
0
0
2
0
Sum Reward: 4
Avg Reward: 0.8
Min Reward: 0
Max Reward: 2
Gini Coefficient: 0.6
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-45-13
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -499.76064061959624
  episode_reward_min: -1199.314062486906
  episodes_this_iter: 1
  episodes_total: 229
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.83
    dispatch_time_ms: 21.748
    learner:
      cur_lr: 0.0012837429530918598
      grad_gnorm: 0.07410191744565964
      policy_entropy: 0.00021590541291516274
      policy_loss: 6.241280914309755e-08
      var_gnorm: 24.563983917236328
      vf_explained_var: 0.0
      vf_loss: 3.6443461794988252e-06
    num_steps_sampled: 1150000
    num_steps_trained: 1150000
    wait_time_ms: 68.498
  iterations_since_restore: 230
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 2012.8148310184479
  time_this_iter_s: 8.889528274536133
  time_total_s: 2012.8148310184479
  timestamp: 1594860313
  timesteps_since_restore: 1150000
  timesteps_this_iter: 5000
  timesteps_total: 1150000
  training_iteration: 230
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 2012 s, 230 iter, 1150000 ts, -500 rew

agent-1: 2.96875
agent-2: -199.99999999784504
agent-3: -199.99999999784504
agent-4: -99.03124999890878
agent-5: -199.99999999784504
Extrinsic Rewards:
3
0
0
1
0
Sum Reward: 4
Avg Reward: 0.8
Min Reward: 0
Max Reward: 3
Gini Coefficient: 0.7
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-45-22
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -506.7212656195207
  episode_reward_min: -1199.314062486906
  episodes_this_iter: 1
  episodes_total: 230
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 3.932
    dispatch_time_ms: 44.843
    learner:
      cur_lr: 0.0012834100052714348
      grad_gnorm: 0.18972790241241455
      policy_entropy: 0.00024274742463603616
      policy_loss: 1.8601752360680734e-09
      var_gnorm: 24.563133239746094
      vf_explained_var: 0.0
      vf_loss: 1.9084287487203255e-05
    num_steps_sampled: 1155000
    num_steps_trained: 1155000
    wait_time_ms: 62.48
  iterations_since_restore: 231
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 2021.8149642944336
  time_this_iter_s: 9.000133275985718
  time_total_s: 2021.8149642944336
  timestamp: 1594860322
  timesteps_since_restore: 1155000
  timesteps_this_iter: 5000
  timesteps_total: 1155000
  training_iteration: 231
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 2021 s, 231 iter, 1155000 ts, -507 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-45-31
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -506.7212656195207
  episode_reward_min: -1199.314062486906
  episodes_this_iter: 1
  episodes_total: 231
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 3.538
    dispatch_time_ms: 22.663
    learner:
      cur_lr: 0.0012830770574510098
      grad_gnorm: 14.269505500793457
      policy_entropy: 0.00036245211958885193
      policy_loss: 4.538537268672371e-06
      var_gnorm: 24.560880661010742
      vf_explained_var: 0.0
      vf_loss: 0.13591034710407257
    num_steps_sampled: 1160000
    num_steps_trained: 1160000
    wait_time_ms: 62.211
  iterations_since_restore: 232
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 2030.2783119678497
  time_this_iter_s: 8.463347673416138
  time_total_s: 2030.2783119678497
  timestamp: 1594860331
  timesteps_since_restore: 1160000
  timesteps_this_iter: 5000
  timesteps_total: 1160000
  training_iteration: 232
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 2030 s, 232 iter, 1160000 ts, -507 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-45-40
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -506.7212656195207
  episode_reward_min: -1199.314062486906
  episodes_this_iter: 1
  episodes_total: 232
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.751
    dispatch_time_ms: 28.359
    learner:
      cur_lr: 0.0012827439932152629
      grad_gnorm: 9.169731140136719
      policy_entropy: 0.0003517727891448885
      policy_loss: 1.3783728718408383e-06
      var_gnorm: 24.561683654785156
      vf_explained_var: 5.960464477539063e-08
      vf_loss: 0.2068326771259308
    num_steps_sampled: 1165000
    num_steps_trained: 1165000
    wait_time_ms: 62.645
  iterations_since_restore: 233
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 2039.0752129554749
  time_this_iter_s: 8.796900987625122
  time_total_s: 2039.0752129554749
  timestamp: 1594860340
  timesteps_since_restore: 1165000
  timesteps_this_iter: 5000
  timesteps_total: 1165000
  training_iteration: 233
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 2039 s, 233 iter, 1165000 ts, -507 rew

agent-1: 2.0
agent-2: -99.99999999894987
agent-3: -99.99999999894987
agent-4: -99.99999999894987
agent-5: -99.99999999894987
Extrinsic Rewards:
2
0
0
0
0
Sum Reward: 2
Avg Reward: 0.4
Min Reward: 0
Max Reward: 2
Gini Coefficient: 0.8
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-45-49
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -510.70126561947865
  episode_reward_min: -1199.314062486906
  episodes_this_iter: 1
  episodes_total: 233
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 3.04
    dispatch_time_ms: 30.407
    learner:
      cur_lr: 0.0012824110453948379
      grad_gnorm: 20.332534790039062
      policy_entropy: 0.00028454334824346006
      policy_loss: 3.659607045847224e-06
      var_gnorm: 24.56245231628418
      vf_explained_var: 0.0
      vf_loss: 0.27429884672164917
    num_steps_sampled: 1170000
    num_steps_trained: 1170000
    wait_time_ms: 57.752
  iterations_since_restore: 234
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 2047.8000462055206
  time_this_iter_s: 8.724833250045776
  time_total_s: 2047.8000462055206
  timestamp: 1594860349
  timesteps_since_restore: 1170000
  timesteps_this_iter: 5000
  timesteps_total: 1170000
  training_iteration: 234
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 2047 s, 234 iter, 1170000 ts, -511 rew

agent-1: -299.9999999967528
agent-2: 1.6882812500007653
agent-3: -299.9999999967528
agent-4: 1.6882812500000002
agent-5: -299.9999999967528
Extrinsic Rewards:
0
3
0
3
0
Sum Reward: 6
Avg Reward: 1.2
Min Reward: 0
Max Reward: 3
Gini Coefficient: 0.6
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-46-04
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -511.7074999944692
  episode_reward_min: -1199.314062486906
  episodes_this_iter: 1
  episodes_total: 234
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 4.425
    dispatch_time_ms: 7.029
    learner:
      cur_lr: 0.001282077981159091
      grad_gnorm: 0.8886748552322388
      policy_entropy: 0.00020394839521031827
      policy_loss: -7.04263527495641e-08
      var_gnorm: 24.564172744750977
      vf_explained_var: 0.0
      vf_loss: 0.0005239937454462051
    num_steps_sampled: 1175000
    num_steps_trained: 1175000
    wait_time_ms: 72.401
  iterations_since_restore: 235
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 2063.4991538524628
  time_this_iter_s: 15.699107646942139
  time_total_s: 2063.4991538524628
  timestamp: 1594860364
  timesteps_since_restore: 1175000
  timesteps_this_iter: 5000
  timesteps_total: 1175000
  training_iteration: 235
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 2063 s, 235 iter, 1175000 ts, -512 rew

agent-1: -199.99999999780377
agent-2: -199.99999999780377
agent-3: -199.99999999780377
agent-4: -199.99999999780377
agent-5: 4.0
Extrinsic Rewards:
0
0
0
0
4
Sum Reward: 4
Avg Reward: 0.8
Min Reward: 0
Max Reward: 4
Gini Coefficient: 0.8
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-46-13
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -510.71749999447803
  episode_reward_min: -1199.314062486906
  episodes_this_iter: 1
  episodes_total: 235
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 3.463
    dispatch_time_ms: 7.448
    learner:
      cur_lr: 0.001281745033338666
      grad_gnorm: 11.184490203857422
      policy_entropy: 0.0002512428327463567
      policy_loss: 8.137602094393515e-07
      var_gnorm: 24.562686920166016
      vf_explained_var: 0.0
      vf_loss: 0.08326906710863113
    num_steps_sampled: 1180000
    num_steps_trained: 1180000
    wait_time_ms: 72.574
  iterations_since_restore: 236
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 2071.6757588386536
  time_this_iter_s: 8.176604986190796
  time_total_s: 2071.6757588386536
  timestamp: 1594860373
  timesteps_since_restore: 1180000
  timesteps_this_iter: 5000
  timesteps_total: 1180000
  training_iteration: 236
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 2071 s, 236 iter, 1180000 ts, -511 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-46-21
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -504.747499994543
  episode_reward_min: -1199.314062486906
  episodes_this_iter: 1
  episodes_total: 236
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.688
    dispatch_time_ms: 8.826
    learner:
      cur_lr: 0.001281411969102919
      grad_gnorm: 12.936461448669434
      policy_entropy: 0.0003207548870705068
      policy_loss: 1.9502035684126895e-06
      var_gnorm: 24.56239128112793
      vf_explained_var: 0.0
      vf_loss: 0.2283114641904831
    num_steps_sampled: 1185000
    num_steps_trained: 1185000
    wait_time_ms: 71.947
  iterations_since_restore: 237
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 2079.815229177475
  time_this_iter_s: 8.139470338821411
  time_total_s: 2079.815229177475
  timestamp: 1594860381
  timesteps_since_restore: 1185000
  timesteps_this_iter: 5000
  timesteps_total: 1185000
  training_iteration: 237
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 2079 s, 237 iter, 1185000 ts, -505 rew

agent-1: -49.999999999481645
agent-2: 1.0
agent-3: -49.999999999481645
agent-4: -49.999999999481645
agent-5: -49.999999999481645
Extrinsic Rewards:
0
1
0
0
0
Sum Reward: 1
Avg Reward: 0.2
Min Reward: 0
Max Reward: 1
Gini Coefficient: 0.8
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-46-29
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -500.76749999458707
  episode_reward_min: -1199.314062486906
  episodes_this_iter: 1
  episodes_total: 237
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 3.484
    dispatch_time_ms: 7.426
    learner:
      cur_lr: 0.001281079021282494
      grad_gnorm: 19.108531951904297
      policy_entropy: 0.00031603602110408247
      policy_loss: 2.389348537690239e-06
      var_gnorm: 24.56219482421875
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 0.25851377844810486
    num_steps_sampled: 1190000
    num_steps_trained: 1190000
    wait_time_ms: 71.506
  iterations_since_restore: 238
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 2087.994724750519
  time_this_iter_s: 8.179495573043823
  time_total_s: 2087.994724750519
  timestamp: 1594860389
  timesteps_since_restore: 1190000
  timesteps_this_iter: 5000
  timesteps_total: 1190000
  training_iteration: 238
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 2087 s, 238 iter, 1190000 ts, -501 rew

agent-1: -399.9999999956769
agent-2: -0.9070312500000002
agent-3: -399.9999999956769
agent-4: -250.2499999972315
agent-5: -50.65703124938548
Extrinsic Rewards:
0
4
0
1
3
Sum Reward: 8
Avg Reward: 1.6
Min Reward: 0
Max Reward: 4
Gini Coefficient: 0.55
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-46-37
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -504.82564061954093
  episode_reward_min: -1199.314062486906
  episodes_this_iter: 1
  episodes_total: 238
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.876
    dispatch_time_ms: 9.116
    learner:
      cur_lr: 0.0012807459570467472
      grad_gnorm: 17.281248092651367
      policy_entropy: 0.0003287257859483361
      policy_loss: 2.090271664201282e-06
      var_gnorm: 24.5622501373291
      vf_explained_var: 2.384185791015625e-07
      vf_loss: 0.23574332892894745
    num_steps_sampled: 1195000
    num_steps_trained: 1195000
    wait_time_ms: 70.738
  iterations_since_restore: 239
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 2096.295018196106
  time_this_iter_s: 8.300293445587158
  time_total_s: 2096.295018196106
  timestamp: 1594860397
  timesteps_since_restore: 1195000
  timesteps_this_iter: 5000
  timesteps_total: 1195000
  training_iteration: 239
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 2096 s, 239 iter, 1195000 ts, -505 rew

agent-1: -249.99999999735493
agent-2: -249.99999999735493
agent-3: -249.99999999735493
agent-4: 3.0
agent-5: -47.99999999945478
Extrinsic Rewards:
0
0
0
3
2
Sum Reward: 5
Avg Reward: 1.0
Min Reward: 0
Max Reward: 3
Gini Coefficient: 0.64
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-46-46
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -504.81564061954225
  episode_reward_min: -1199.314062486906
  episodes_this_iter: 1
  episodes_total: 239
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.783
    dispatch_time_ms: 6.835
    learner:
      cur_lr: 0.0012804130092263222
      grad_gnorm: 14.764984130859375
      policy_entropy: 0.0002559850981924683
      policy_loss: 8.989692332761479e-07
      var_gnorm: 24.56268310546875
      vf_explained_var: 1.1920928955078125e-07
      vf_loss: 0.14464645087718964
    num_steps_sampled: 1200000
    num_steps_trained: 1200000
    wait_time_ms: 71.926
  iterations_since_restore: 240
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 2104.483337879181
  time_this_iter_s: 8.188319683074951
  time_total_s: 2104.483337879181
  timestamp: 1594860406
  timesteps_since_restore: 1200000
  timesteps_this_iter: 5000
  timesteps_total: 1200000
  training_iteration: 240
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 2104 s, 240 iter, 1200000 ts, -505 rew

agent-1: -99.2499999988536
agent-2: -299.9999999967528
agent-3: -299.9999999967528
agent-4: -299.9999999967528
agent-5: 2.75
Extrinsic Rewards:
2
0
0
0
4
Sum Reward: 6
Avg Reward: 1.2
Min Reward: 0
Max Reward: 4
Gini Coefficient: 0.6666666666666666
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-46-54
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -507.82064061950746
  episode_reward_min: -1199.314062486906
  episodes_this_iter: 1
  episodes_total: 240
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 3.239
    dispatch_time_ms: 9.486
    learner:
      cur_lr: 0.0012800799449905753
      grad_gnorm: 0.0724472850561142
      policy_entropy: 0.00023809552658349276
      policy_loss: 8.281493713013788e-09
      var_gnorm: 24.562957763671875
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 3.481680550976307e-06
    num_steps_sampled: 1205000
    num_steps_trained: 1205000
    wait_time_ms: 70.665
  iterations_since_restore: 241
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 2112.578831911087
  time_this_iter_s: 8.095494031906128
  time_total_s: 2112.578831911087
  timestamp: 1594860414
  timesteps_since_restore: 1205000
  timesteps_this_iter: 5000
  timesteps_total: 1205000
  training_iteration: 241
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 2112 s, 241 iter, 1205000 ts, -508 rew

agent-1: -49.99999999946836
agent-2: -49.99999999946836
agent-3: 1.0
agent-4: -49.99999999946836
agent-5: -49.99999999946836
Extrinsic Rewards:
0
0
1
0
0
Sum Reward: 1
Avg Reward: 0.2
Min Reward: 0
Max Reward: 1
Gini Coefficient: 0.8
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-47-02
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -501.85064061957235
  episode_reward_min: -1199.314062486906
  episodes_this_iter: 1
  episodes_total: 241
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.777
    dispatch_time_ms: 8.306
    learner:
      cur_lr: 0.0012797469971701503
      grad_gnorm: 16.057098388671875
      policy_entropy: 0.0004094610339961946
      policy_loss: 2.0960462734365137e-06
      var_gnorm: 24.56024169921875
      vf_explained_var: 5.960464477539063e-08
      vf_loss: 0.17834678292274475
    num_steps_sampled: 1210000
    num_steps_trained: 1210000
    wait_time_ms: 70.663
  iterations_since_restore: 242
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 2120.6986994743347
  time_this_iter_s: 8.11986756324768
  time_total_s: 2120.6986994743347
  timestamp: 1594860422
  timesteps_since_restore: 1210000
  timesteps_this_iter: 5000
  timesteps_total: 1210000
  training_iteration: 242
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 2120 s, 242 iter, 1210000 ts, -502 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-47-10
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -501.85064061957235
  episode_reward_min: -1199.314062486906
  episodes_this_iter: 1
  episodes_total: 242
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.458
    dispatch_time_ms: 8.611
    learner:
      cur_lr: 0.0012794140493497252
      grad_gnorm: 21.994409561157227
      policy_entropy: 0.00040934979915618896
      policy_loss: 2.5919146082742373e-06
      var_gnorm: 24.55999183654785
      vf_explained_var: 0.0
      vf_loss: 0.32097116112709045
    num_steps_sampled: 1215000
    num_steps_trained: 1215000
    wait_time_ms: 71.484
  iterations_since_restore: 243
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 2128.925358772278
  time_this_iter_s: 8.226659297943115
  time_total_s: 2128.925358772278
  timestamp: 1594860430
  timesteps_since_restore: 1215000
  timesteps_this_iter: 5000
  timesteps_total: 1215000
  training_iteration: 243
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 2128 s, 243 iter, 1215000 ts, -502 rew

agent-1: -149.99999999840443
agent-2: 3.0
agent-3: -149.99999999840443
agent-4: -149.99999999840443
agent-5: -149.99999999840443
Extrinsic Rewards:
0
3
0
0
0
Sum Reward: 3
Avg Reward: 0.6
Min Reward: 0
Max Reward: 3
Gini Coefficient: 0.8
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-47-19
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -502.85064061956103
  episode_reward_min: -1199.314062486906
  episodes_this_iter: 1
  episodes_total: 243
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 3.019
    dispatch_time_ms: 7.681
    learner:
      cur_lr: 0.0012790809851139784
      grad_gnorm: 17.225662231445312
      policy_entropy: 0.00041793478885665536
      policy_loss: 1.8833831063602702e-06
      var_gnorm: 24.559688568115234
      vf_explained_var: 0.0
      vf_loss: 0.1995590180158615
    num_steps_sampled: 1220000
    num_steps_trained: 1220000
    wait_time_ms: 71.807
  iterations_since_restore: 244
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 2137.2174801826477
  time_this_iter_s: 8.292121410369873
  time_total_s: 2137.2174801826477
  timestamp: 1594860439
  timesteps_since_restore: 1220000
  timesteps_this_iter: 5000
  timesteps_total: 1220000
  training_iteration: 244
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 2137 s, 244 iter, 1220000 ts, -503 rew

agent-1: 2.0
agent-2: -99.99999999894987
agent-3: -99.99999999894987
agent-4: -99.99999999894987
agent-5: -99.99999999894987
Extrinsic Rewards:
2
0
0
0
0
Sum Reward: 2
Avg Reward: 0.4
Min Reward: 0
Max Reward: 2
Gini Coefficient: 0.8
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-47-27
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -504.8406406195403
  episode_reward_min: -1199.314062486906
  episodes_this_iter: 1
  episodes_total: 244
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.907
    dispatch_time_ms: 5.683
    learner:
      cur_lr: 0.0012787480372935534
      grad_gnorm: 0.062159400433301926
      policy_entropy: 0.0003123816568404436
      policy_loss: 1.9487782054739e-08
      var_gnorm: 24.560932159423828
      vf_explained_var: 5.960464477539063e-08
      vf_loss: 2.564302803875762e-06
    num_steps_sampled: 1225000
    num_steps_trained: 1225000
    wait_time_ms: 77.147
  iterations_since_restore: 245
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 2145.3952882289886
  time_this_iter_s: 8.177808046340942
  time_total_s: 2145.3952882289886
  timestamp: 1594860447
  timesteps_since_restore: 1225000
  timesteps_this_iter: 5000
  timesteps_total: 1225000
  training_iteration: 245
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 2145 s, 245 iter, 1225000 ts, -505 rew

agent-1: -99.99999999894987
agent-2: -99.99999999894987
agent-3: -99.99999999894987
agent-4: 2.0
agent-5: -99.99999999894987
Extrinsic Rewards:
0
0
0
2
0
Sum Reward: 2
Avg Reward: 0.4
Min Reward: 0
Max Reward: 2
Gini Coefficient: 0.8
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-47-35
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -504.84064061954035
  episode_reward_min: -1199.314062486906
  episodes_this_iter: 1
  episodes_total: 245
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.966
    dispatch_time_ms: 7.778
    learner:
      cur_lr: 0.0012784149730578065
      grad_gnorm: 16.678110122680664
      policy_entropy: 0.0009493983234278858
      policy_loss: 4.558788987196749e-06
      var_gnorm: 24.556217193603516
      vf_explained_var: 1.1920928955078125e-07
      vf_loss: 0.20838810503482819
    num_steps_sampled: 1230000
    num_steps_trained: 1230000
    wait_time_ms: 72.447
  iterations_since_restore: 246
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 2153.681776046753
  time_this_iter_s: 8.286487817764282
  time_total_s: 2153.681776046753
  timestamp: 1594860455
  timesteps_since_restore: 1230000
  timesteps_this_iter: 5000
  timesteps_total: 1230000
  training_iteration: 246
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 2153 s, 246 iter, 1230000 ts, -505 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-47-43
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -499.87064061959273
  episode_reward_min: -1199.314062486906
  episodes_this_iter: 1
  episodes_total: 246
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 3.087
    dispatch_time_ms: 8.089
    learner:
      cur_lr: 0.0012780820252373815
      grad_gnorm: 25.554840087890625
      policy_entropy: 0.00047873478615656495
      policy_loss: 4.3743903006543405e-06
      var_gnorm: 24.558759689331055
      vf_explained_var: 1.1920928955078125e-07
      vf_loss: 0.433299720287323
    num_steps_sampled: 1235000
    num_steps_trained: 1235000
    wait_time_ms: 70.765
  iterations_since_restore: 247
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 2161.7987608909607
  time_this_iter_s: 8.116984844207764
  time_total_s: 2161.7987608909607
  timestamp: 1594860463
  timesteps_since_restore: 1235000
  timesteps_this_iter: 5000
  timesteps_total: 1235000
  training_iteration: 247
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 2161 s, 247 iter, 1235000 ts, -500 rew

agent-1: -199.99999999787352
agent-2: -199.99999999787352
agent-3: 3.0
agent-4: -199.99999999787352
agent-5: -98.99999999893653
Extrinsic Rewards:
0
0
3
0
1
Sum Reward: 4
Avg Reward: 0.8
Min Reward: 0
Max Reward: 3
Gini Coefficient: 0.7
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-47-52
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -506.83064061951825
  episode_reward_min: -1199.314062486906
  episodes_this_iter: 1
  episodes_total: 247
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 3.096
    dispatch_time_ms: 11.452
    learner:
      cur_lr: 0.0012777489610016346
      grad_gnorm: 0.18908318877220154
      policy_entropy: 0.00031192321330308914
      policy_loss: 2.959011702330372e-08
      var_gnorm: 24.560565948486328
      vf_explained_var: 1.1920928955078125e-07
      vf_loss: 2.3719803721178323e-05
    num_steps_sampled: 1240000
    num_steps_trained: 1240000
    wait_time_ms: 68.565
  iterations_since_restore: 248
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 2170.0072872638702
  time_this_iter_s: 8.208526372909546
  time_total_s: 2170.0072872638702
  timestamp: 1594860472
  timesteps_since_restore: 1240000
  timesteps_this_iter: 5000
  timesteps_total: 1240000
  training_iteration: 248
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 2170 s, 248 iter, 1240000 ts, -507 rew

agent-1: 4.0
agent-2: -299.9999999967528
agent-3: -299.9999999967528
agent-4: -97.99999999893765
agent-5: -299.9999999967528
Extrinsic Rewards:
4
0
0
2
0
Sum Reward: 6
Avg Reward: 1.2
Min Reward: 0
Max Reward: 4
Gini Coefficient: 0.6666666666666666
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-48-00
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -516.7706406194102
  episode_reward_min: -1199.314062486906
  episodes_this_iter: 1
  episodes_total: 248
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 3.928
    dispatch_time_ms: 9.027
    learner:
      cur_lr: 0.0012774160131812096
      grad_gnorm: 24.432907104492188
      policy_entropy: 0.0008179474389180541
      policy_loss: 6.835688964201836e-06
      var_gnorm: 24.555543899536133
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 0.39608946442604065
    num_steps_sampled: 1245000
    num_steps_trained: 1245000
    wait_time_ms: 68.226
  iterations_since_restore: 249
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 2178.2152769565582
  time_this_iter_s: 8.207989692687988
  time_total_s: 2178.2152769565582
  timestamp: 1594860480
  timesteps_since_restore: 1245000
  timesteps_this_iter: 5000
  timesteps_total: 1245000
  training_iteration: 249
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 2178 s, 249 iter, 1245000 ts, -517 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-48-08
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -506.8306406195173
  episode_reward_min: -1199.314062486906
  episodes_this_iter: 1
  episodes_total: 249
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 3.035
    dispatch_time_ms: 8.142
    learner:
      cur_lr: 0.0012770829489454627
      grad_gnorm: 29.09488868713379
      policy_entropy: 0.0005008411244489253
      policy_loss: 4.8440460886922665e-06
      var_gnorm: 24.55845832824707
      vf_explained_var: 0.0
      vf_loss: 0.5616614818572998
    num_steps_sampled: 1250000
    num_steps_trained: 1250000
    wait_time_ms: 70.797
  iterations_since_restore: 250
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 2186.5205550193787
  time_this_iter_s: 8.305278062820435
  time_total_s: 2186.5205550193787
  timestamp: 1594860488
  timesteps_since_restore: 1250000
  timesteps_this_iter: 5000
  timesteps_total: 1250000
  training_iteration: 250
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 2186 s, 250 iter, 1250000 ts, -507 rew

agent-1: 4.0
agent-2: -199.99999999780377
agent-3: -199.99999999780377
agent-4: -199.99999999780377
agent-5: -199.99999999780377
Extrinsic Rewards:
4
0
0
0
0
Sum Reward: 4
Avg Reward: 0.8
Min Reward: 0
Max Reward: 4
Gini Coefficient: 0.8
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-48-16
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -504.8506406195366
  episode_reward_min: -1199.314062486906
  episodes_this_iter: 1
  episodes_total: 250
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.667
    dispatch_time_ms: 7.25
    learner:
      cur_lr: 0.0012767500011250377
      grad_gnorm: 19.938444137573242
      policy_entropy: 0.00036921343416906893
      policy_loss: 1.934930651259492e-06
      var_gnorm: 24.559524536132812
      vf_explained_var: 1.1920928955078125e-07
      vf_loss: 0.2637692987918854
    num_steps_sampled: 1255000
    num_steps_trained: 1255000
    wait_time_ms: 72.404
  iterations_since_restore: 251
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 2194.739164829254
  time_this_iter_s: 8.218609809875488
  time_total_s: 2194.739164829254
  timestamp: 1594860496
  timesteps_since_restore: 1255000
  timesteps_this_iter: 5000
  timesteps_total: 1255000
  training_iteration: 251
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 2194 s, 251 iter, 1255000 ts, -505 rew

agent-1: -47.99999999945478
agent-2: -249.99999999735493
agent-3: -249.99999999735493
agent-4: -249.99999999735493
agent-5: 3.0
Extrinsic Rewards:
2
0
0
0
3
Sum Reward: 5
Avg Reward: 1.0
Min Reward: 0
Max Reward: 3
Gini Coefficient: 0.64
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-48-25
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -502.79626561956115
  episode_reward_min: -1199.314062486906
  episodes_this_iter: 1
  episodes_total: 251
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 3.25
    dispatch_time_ms: 6.292
    learner:
      cur_lr: 0.0012764170533046126
      grad_gnorm: 0.9730545282363892
      policy_entropy: 0.00042166904313489795
      policy_loss: -2.5035501494130585e-07
      var_gnorm: 24.55931854248047
      vf_explained_var: 5.960464477539063e-08
      vf_loss: 0.2986186146736145
    num_steps_sampled: 1260000
    num_steps_trained: 1260000
    wait_time_ms: 76.132
  iterations_since_restore: 252
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 2202.9808723926544
  time_this_iter_s: 8.241707563400269
  time_total_s: 2202.9808723926544
  timestamp: 1594860505
  timesteps_since_restore: 1260000
  timesteps_this_iter: 5000
  timesteps_total: 1260000
  training_iteration: 252
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 2202 s, 252 iter, 1260000 ts, -503 rew

agent-1: -149.99999999840443
agent-2: -149.99999999840443
agent-3: -149.99999999840443
agent-4: -149.99999999840443
agent-5: 3.0
Extrinsic Rewards:
0
0
0
0
3
Sum Reward: 3
Avg Reward: 0.6
Min Reward: 0
Max Reward: 3
Gini Coefficient: 0.8
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-48-33
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -502.781265619561
  episode_reward_min: -1199.314062486906
  episodes_this_iter: 1
  episodes_total: 252
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.847
    dispatch_time_ms: 9.365
    learner:
      cur_lr: 0.0012760839890688658
      grad_gnorm: 19.16971206665039
      policy_entropy: 0.00032762394403107464
      policy_loss: 1.869082893790619e-06
      var_gnorm: 24.559818267822266
      vf_explained_var: -2.384185791015625e-07
      vf_loss: 0.2438225895166397
    num_steps_sampled: 1265000
    num_steps_trained: 1265000
    wait_time_ms: 72.441
  iterations_since_restore: 253
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 2211.2523868083954
  time_this_iter_s: 8.271514415740967
  time_total_s: 2211.2523868083954
  timestamp: 1594860513
  timesteps_since_restore: 1265000
  timesteps_this_iter: 5000
  timesteps_total: 1265000
  training_iteration: 253
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 2211 s, 253 iter, 1265000 ts, -503 rew

agent-1: 1.53125
agent-2: -349.9999999962086
agent-3: -349.9999999962086
agent-4: -349.9999999962086
agent-5: -49.46874999939871
Extrinsic Rewards:
4
0
0
0
3
Sum Reward: 7
Avg Reward: 1.4
Min Reward: 0
Max Reward: 4
Gini Coefficient: 0.6285714285714286
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-48-41
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -513.7606406194411
  episode_reward_min: -1199.314062486906
  episodes_this_iter: 1
  episodes_total: 253
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 3.647
    dispatch_time_ms: 8.724
    learner:
      cur_lr: 0.0012757510412484407
      grad_gnorm: 9.033246994018555
      policy_entropy: 0.0003430742071941495
      policy_loss: 7.12349503828591e-07
      var_gnorm: 24.559720993041992
      vf_explained_var: 0.0
      vf_loss: 0.10090187937021255
    num_steps_sampled: 1270000
    num_steps_trained: 1270000
    wait_time_ms: 72.54
  iterations_since_restore: 254
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 2219.457363128662
  time_this_iter_s: 8.204976320266724
  time_total_s: 2219.457363128662
  timestamp: 1594860521
  timesteps_since_restore: 1270000
  timesteps_this_iter: 5000
  timesteps_total: 1270000
  training_iteration: 254
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 2219 s, 254 iter, 1270000 ts, -514 rew

agent-1: -98.999999998923
agent-2: -199.99999999788645
agent-3: 3.0
agent-4: -199.99999999788645
agent-5: -199.99999999788645
Extrinsic Rewards:
1
0
3
0
0
Sum Reward: 4
Avg Reward: 0.8
Min Reward: 0
Max Reward: 3
Gini Coefficient: 0.7
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-48-50
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -513.7606406194421
  episode_reward_min: -1199.314062486906
  episodes_this_iter: 1
  episodes_total: 254
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.797
    dispatch_time_ms: 25.324
    learner:
      cur_lr: 0.0012754179770126939
      grad_gnorm: 6.866700649261475
      policy_entropy: 0.0003301103424746543
      policy_loss: 2.4855021365510765e-06
      var_gnorm: 24.55940818786621
      vf_explained_var: 0.0
      vf_loss: 0.11789795756340027
    num_steps_sampled: 1275000
    num_steps_trained: 1275000
    wait_time_ms: 49.249
  iterations_since_restore: 255
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 2227.93523979187
  time_this_iter_s: 8.477876663208008
  time_total_s: 2227.93523979187
  timestamp: 1594860530
  timesteps_since_restore: 1275000
  timesteps_this_iter: 5000
  timesteps_total: 1275000
  training_iteration: 255
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 2227 s, 255 iter, 1275000 ts, -514 rew

agent-1: -99.99999999894987
agent-2: -99.99999999894987
agent-3: -99.99999999894987
agent-4: 2.0
agent-5: -99.99999999894987
Extrinsic Rewards:
0
0
0
2
0
Sum Reward: 2
Avg Reward: 0.4
Min Reward: 0
Max Reward: 2
Gini Coefficient: 0.8
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-48-58
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -509.7906406194849
  episode_reward_min: -1199.314062486906
  episodes_this_iter: 1
  episodes_total: 255
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 3.881
    dispatch_time_ms: 36.104
    learner:
      cur_lr: 0.0012750850291922688
      grad_gnorm: 0.11131664365530014
      policy_entropy: 0.00014823437959421426
      policy_loss: -1.0830214058898946e-08
      var_gnorm: 24.56516456604004
      vf_explained_var: 0.0
      vf_loss: 8.22093352326192e-06
    num_steps_sampled: 1280000
    num_steps_trained: 1280000
    wait_time_ms: 58.133
  iterations_since_restore: 256
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 2236.689352750778
  time_this_iter_s: 8.754112958908081
  time_total_s: 2236.689352750778
  timestamp: 1594860538
  timesteps_since_restore: 1280000
  timesteps_this_iter: 5000
  timesteps_total: 1280000
  training_iteration: 256
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 2236 s, 256 iter, 1280000 ts, -510 rew

agent-1: -149.99999999840443
agent-2: 3.0
agent-3: -149.99999999840443
agent-4: -149.99999999840443
agent-5: -149.99999999840443
Extrinsic Rewards:
0
3
0
0
0
Sum Reward: 3
Avg Reward: 0.6
Min Reward: 0
Max Reward: 3
Gini Coefficient: 0.8
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-49-07
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -507.8006406195074
  episode_reward_min: -1199.314062486906
  episodes_this_iter: 1
  episodes_total: 256
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.851
    dispatch_time_ms: 42.277
    learner:
      cur_lr: 0.001274751964956522
      grad_gnorm: 23.206836700439453
      policy_entropy: 0.00022559503850061446
      policy_loss: 8.629660328551836e-07
      var_gnorm: 24.561573028564453
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 0.31747451424598694
    num_steps_sampled: 1285000
    num_steps_trained: 1285000
    wait_time_ms: 56.997
  iterations_since_restore: 257
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 2245.4129598140717
  time_this_iter_s: 8.723607063293457
  time_total_s: 2245.4129598140717
  timestamp: 1594860547
  timesteps_since_restore: 1285000
  timesteps_this_iter: 5000
  timesteps_total: 1285000
  training_iteration: 257
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 2245 s, 257 iter, 1285000 ts, -508 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-49-16
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -503.82064061954947
  episode_reward_min: -1199.314062486906
  episodes_this_iter: 1
  episodes_total: 257
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.529
    dispatch_time_ms: 18.1
    learner:
      cur_lr: 0.001274419017136097
      grad_gnorm: 22.009889602661133
      policy_entropy: 0.00015922694001346827
      policy_loss: 1.0593171282380354e-06
      var_gnorm: 24.564693450927734
      vf_explained_var: 0.0
      vf_loss: 0.32142436504364014
    num_steps_sampled: 1290000
    num_steps_trained: 1290000
    wait_time_ms: 71.473
  iterations_since_restore: 258
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 2254.0632271766663
  time_this_iter_s: 8.650267362594604
  time_total_s: 2254.0632271766663
  timestamp: 1594860556
  timesteps_since_restore: 1290000
  timesteps_this_iter: 5000
  timesteps_total: 1290000
  training_iteration: 258
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 2254 s, 258 iter, 1290000 ts, -504 rew

agent-1: 3.0
agent-2: -249.99999999735493
agent-3: -249.99999999735493
agent-4: -249.99999999735493
agent-5: -47.99999999945478
Extrinsic Rewards:
3
0
0
0
2
Sum Reward: 5
Avg Reward: 1.0
Min Reward: 0
Max Reward: 3
Gini Coefficient: 0.64
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-49-25
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -507.7906406195066
  episode_reward_min: -1199.314062486906
  episodes_this_iter: 1
  episodes_total: 258
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.815
    dispatch_time_ms: 22.978
    learner:
      cur_lr: 0.00127408595290035
      grad_gnorm: 0.04174124076962471
      policy_entropy: 9.984114149119705e-05
      policy_loss: -0.0
      var_gnorm: 24.567304611206055
      vf_explained_var: 0.0
      vf_loss: 1.1561900237211375e-06
    num_steps_sampled: 1295000
    num_steps_trained: 1295000
    wait_time_ms: 62.49
  iterations_since_restore: 259
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 2262.985008955002
  time_this_iter_s: 8.921781778335571
  time_total_s: 2262.985008955002
  timestamp: 1594860565
  timesteps_since_restore: 1295000
  timesteps_this_iter: 5000
  timesteps_total: 1295000
  training_iteration: 259
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 2262 s, 259 iter, 1295000 ts, -508 rew

agent-1: 3.0
agent-2: -149.99999999837684
agent-3: -149.99999999837684
agent-4: -149.99999999837684
agent-5: -149.99999999837684
Extrinsic Rewards:
3
0
0
0
0
Sum Reward: 3
Avg Reward: 0.6
Min Reward: 0
Max Reward: 3
Gini Coefficient: 0.8
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-49-34
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -505.80064061952794
  episode_reward_min: -1199.314062486906
  episodes_this_iter: 1
  episodes_total: 259
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.546
    dispatch_time_ms: 28.096
    learner:
      cur_lr: 0.001273753005079925
      grad_gnorm: 23.817935943603516
      policy_entropy: 0.00020539220713544637
      policy_loss: 2.845266067197372e-07
      var_gnorm: 24.562454223632812
      vf_explained_var: 0.0
      vf_loss: 0.37640106678009033
    num_steps_sampled: 1300000
    num_steps_trained: 1300000
    wait_time_ms: 51.592
  iterations_since_restore: 260
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 2271.698730945587
  time_this_iter_s: 8.713721990585327
  time_total_s: 2271.698730945587
  timestamp: 1594860574
  timesteps_since_restore: 1300000
  timesteps_this_iter: 5000
  timesteps_total: 1300000
  training_iteration: 260
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 2271 s, 260 iter, 1300000 ts, -506 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-49-42
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -498.84064061960237
  episode_reward_min: -1199.314062486906
  episodes_this_iter: 1
  episodes_total: 260
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.66
    dispatch_time_ms: 15.543
    learner:
      cur_lr: 0.0012734200572595
      grad_gnorm: 7.478498935699463
      policy_entropy: 0.00010952070442726836
      policy_loss: -0.0
      var_gnorm: 24.56617546081543
      vf_explained_var: 0.0
      vf_loss: 0.037108421325683594
    num_steps_sampled: 1305000
    num_steps_trained: 1305000
    wait_time_ms: 68.053
  iterations_since_restore: 261
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 2280.429465532303
  time_this_iter_s: 8.730734586715698
  time_total_s: 2280.429465532303
  timestamp: 1594860582
  timesteps_since_restore: 1305000
  timesteps_this_iter: 5000
  timesteps_total: 1305000
  training_iteration: 261
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 2280 s, 261 iter, 1305000 ts, -499 rew

agent-1: 4.0
agent-2: -199.99999999780377
agent-3: -199.99999999780377
agent-4: -199.99999999780377
agent-5: -199.99999999780377
Extrinsic Rewards:
4
0
0
0
0
Sum Reward: 4
Avg Reward: 0.8
Min Reward: 0
Max Reward: 4
Gini Coefficient: 0.8
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-49-51
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -497.82564061961324
  episode_reward_min: -1199.314062486906
  episodes_this_iter: 1
  episodes_total: 261
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.601
    dispatch_time_ms: 17.467
    learner:
      cur_lr: 0.0012730869930237532
      grad_gnorm: 0.2176920771598816
      policy_entropy: 0.0001081416048691608
      policy_loss: -0.0
      var_gnorm: 24.566137313842773
      vf_explained_var: 1.1920928955078125e-07
      vf_loss: 3.143782669212669e-05
    num_steps_sampled: 1310000
    num_steps_trained: 1310000
    wait_time_ms: 46.521
  iterations_since_restore: 262
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 2289.1062746047974
  time_this_iter_s: 8.676809072494507
  time_total_s: 2289.1062746047974
  timestamp: 1594860591
  timesteps_since_restore: 1310000
  timesteps_this_iter: 5000
  timesteps_total: 1310000
  training_iteration: 262
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 2289 s, 262 iter, 1310000 ts, -498 rew

agent-1: -49.99999999946836
agent-2: 1.0
agent-3: -49.99999999946836
agent-4: -49.99999999946836
agent-5: -49.99999999946836
Extrinsic Rewards:
0
1
0
0
0
Sum Reward: 1
Avg Reward: 0.2
Min Reward: 0
Max Reward: 1
Gini Coefficient: 0.8
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-50-00
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -491.86564061967675
  episode_reward_min: -1199.314062486906
  episodes_this_iter: 1
  episodes_total: 262
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.751
    dispatch_time_ms: 20.427
    learner:
      cur_lr: 0.0012727540452033281
      grad_gnorm: 0.13202938437461853
      policy_entropy: 0.000159797869855538
      policy_loss: 2.9021702818710082e-09
      var_gnorm: 24.563467025756836
      vf_explained_var: 0.0
      vf_loss: 9.55327141127782e-06
    num_steps_sampled: 1315000
    num_steps_trained: 1315000
    wait_time_ms: 124.445
  iterations_since_restore: 263
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 2298.3742439746857
  time_this_iter_s: 9.267969369888306
  time_total_s: 2298.3742439746857
  timestamp: 1594860600
  timesteps_since_restore: 1315000
  timesteps_this_iter: 5000
  timesteps_total: 1315000
  training_iteration: 263
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 2298 s, 263 iter, 1315000 ts, -492 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-50-08
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -489.8756406196976
  episode_reward_min: -1199.314062486906
  episodes_this_iter: 1
  episodes_total: 263
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.735
    dispatch_time_ms: 7.561
    learner:
      cur_lr: 0.0012724209809675813
      grad_gnorm: 2.7313458919525146
      policy_entropy: 0.000520407862495631
      policy_loss: -6.424373850677512e-07
      var_gnorm: 24.556154251098633
      vf_explained_var: 1.1920928955078125e-07
      vf_loss: 0.362958699464798
    num_steps_sampled: 1320000
    num_steps_trained: 1320000
    wait_time_ms: 71.373
  iterations_since_restore: 264
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 2306.240259408951
  time_this_iter_s: 7.866015434265137
  time_total_s: 2306.240259408951
  timestamp: 1594860608
  timesteps_since_restore: 1320000
  timesteps_this_iter: 5000
  timesteps_total: 1320000
  training_iteration: 264
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 2306 s, 264 iter, 1320000 ts, -490 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-50-17
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -485.8956406197396
  episode_reward_min: -1199.314062486906
  episodes_this_iter: 1
  episodes_total: 264
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.557
    dispatch_time_ms: 7.449
    learner:
      cur_lr: 0.0012720880331471562
      grad_gnorm: 15.846030235290527
      policy_entropy: 0.00027188198873773217
      policy_loss: 1.0705615522965672e-06
      var_gnorm: 24.559309005737305
      vf_explained_var: 0.0
      vf_loss: 0.1698022484779358
    num_steps_sampled: 1325000
    num_steps_trained: 1325000
    wait_time_ms: 71.932
  iterations_since_restore: 265
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 2314.5144827365875
  time_this_iter_s: 8.274223327636719
  time_total_s: 2314.5144827365875
  timestamp: 1594860617
  timesteps_since_restore: 1325000
  timesteps_this_iter: 5000
  timesteps_total: 1325000
  training_iteration: 265
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 2314 s, 265 iter, 1325000 ts, -486 rew

agent-1: -349.9999999962774
agent-2: -97.9999999988953
agent-3: -198.99999999783225
agent-4: -349.9999999962774
agent-5: 4.0
Extrinsic Rewards:
0
2
1
0
4
Sum Reward: 7
Avg Reward: 1.4
Min Reward: 0
Max Reward: 4
Gini Coefficient: 0.5714285714285714
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-50-25
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -495.82564061963234
  episode_reward_min: -1199.314062486906
  episodes_this_iter: 1
  episodes_total: 265
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.357
    dispatch_time_ms: 6.595
    learner:
      cur_lr: 0.0012717549689114094
      grad_gnorm: 0.22642776370048523
      policy_entropy: 0.00019486564269755036
      policy_loss: 2.0977621417728187e-08
      var_gnorm: 24.561363220214844
      vf_explained_var: 0.0
      vf_loss: 3.401580033823848e-05
    num_steps_sampled: 1330000
    num_steps_trained: 1330000
    wait_time_ms: 79.669
  iterations_since_restore: 266
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 2322.769504547119
  time_this_iter_s: 8.255021810531616
  time_total_s: 2322.769504547119
  timestamp: 1594860625
  timesteps_since_restore: 1330000
  timesteps_this_iter: 5000
  timesteps_total: 1330000
  training_iteration: 266
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 2322 s, 266 iter, 1330000 ts, -496 rew

agent-1: -249.99999999735493
agent-2: -249.99999999735493
agent-3: -47.99999999945478
agent-4: 3.0
agent-5: -249.99999999735493
Extrinsic Rewards:
0
0
2
3
0
Sum Reward: 5
Avg Reward: 1.0
Min Reward: 0
Max Reward: 3
Gini Coefficient: 0.64
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-50-33
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -497.8056406196124
  episode_reward_min: -1199.314062486906
  episodes_this_iter: 1
  episodes_total: 266
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.878
    dispatch_time_ms: 8.331
    learner:
      cur_lr: 0.0012714220210909843
      grad_gnorm: 12.633102416992188
      policy_entropy: 0.00027869417681358755
      policy_loss: 1.3253011275082827e-06
      var_gnorm: 24.558612823486328
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 0.10589168220758438
    num_steps_sampled: 1335000
    num_steps_trained: 1335000
    wait_time_ms: 70.863
  iterations_since_restore: 267
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 2330.9420626163483
  time_this_iter_s: 8.172558069229126
  time_total_s: 2330.9420626163483
  timestamp: 1594860633
  timesteps_since_restore: 1335000
  timesteps_this_iter: 5000
  timesteps_total: 1335000
  training_iteration: 267
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 2330 s, 267 iter, 1335000 ts, -498 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-50-41
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -497.8056406196124
  episode_reward_min: -1199.314062486906
  episodes_this_iter: 1
  episodes_total: 267
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.896
    dispatch_time_ms: 8.951
    learner:
      cur_lr: 0.0012710889568552375
      grad_gnorm: 13.338162422180176
      policy_entropy: 0.0003197612822987139
      policy_loss: 7.68933603012556e-07
      var_gnorm: 24.55820655822754
      vf_explained_var: 0.0
      vf_loss: 0.1449940800666809
    num_steps_sampled: 1340000
    num_steps_trained: 1340000
    wait_time_ms: 72.856
  iterations_since_restore: 268
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 2339.249410390854
  time_this_iter_s: 8.307347774505615
  time_total_s: 2339.249410390854
  timestamp: 1594860641
  timesteps_since_restore: 1340000
  timesteps_this_iter: 5000
  timesteps_total: 1340000
  training_iteration: 268
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 2339 s, 268 iter, 1340000 ts, -498 rew

agent-1: -99.99999999894987
agent-2: -99.99999999894987
agent-3: -99.99999999894987
agent-4: -99.99999999894987
agent-5: 2.0
Extrinsic Rewards:
0
0
0
0
2
Sum Reward: 2
Avg Reward: 0.4
Min Reward: 0
Max Reward: 2
Gini Coefficient: 0.8
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-50-50
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -493.8256406196583
  episode_reward_min: -1199.314062486906
  episodes_this_iter: 1
  episodes_total: 268
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.658
    dispatch_time_ms: 11.605
    learner:
      cur_lr: 0.0012707560090348125
      grad_gnorm: 15.272457122802734
      policy_entropy: 0.00026593738584779203
      policy_loss: 8.349143740815634e-07
      var_gnorm: 24.558446884155273
      vf_explained_var: 0.0
      vf_loss: 0.15544185042381287
    num_steps_sampled: 1345000
    num_steps_trained: 1345000
    wait_time_ms: 69.048
  iterations_since_restore: 269
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 2347.477400779724
  time_this_iter_s: 8.22799038887024
  time_total_s: 2347.477400779724
  timestamp: 1594860650
  timesteps_since_restore: 1345000
  timesteps_this_iter: 5000
  timesteps_total: 1345000
  training_iteration: 269
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 2347 s, 269 iter, 1345000 ts, -494 rew

agent-1: -99.99999999894987
agent-2: -99.99999999894987
agent-3: -99.99999999894987
agent-4: -99.99999999894987
agent-5: 2.0
Extrinsic Rewards:
0
0
0
0
2
Sum Reward: 2
Avg Reward: 0.4
Min Reward: 0
Max Reward: 2
Gini Coefficient: 0.8
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-50-58
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -491.8356406196801
  episode_reward_min: -1199.314062486906
  episodes_this_iter: 1
  episodes_total: 269
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.854
    dispatch_time_ms: 7.452
    learner:
      cur_lr: 0.0012704229447990656
      grad_gnorm: 11.53902816772461
      policy_entropy: 0.00021312622993718833
      policy_loss: 6.144650797068607e-07
      var_gnorm: 24.56074333190918
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 0.16024106740951538
    num_steps_sampled: 1350000
    num_steps_trained: 1350000
    wait_time_ms: 70.298
  iterations_since_restore: 270
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 2355.703233242035
  time_this_iter_s: 8.225832462310791
  time_total_s: 2355.703233242035
  timestamp: 1594860658
  timesteps_since_restore: 1350000
  timesteps_this_iter: 5000
  timesteps_total: 1350000
  training_iteration: 270
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 2355 s, 270 iter, 1350000 ts, -492 rew

agent-1: -199.99999999784504
agent-2: -199.99999999784504
agent-3: 4.0
agent-4: -199.99999999784504
agent-5: -199.99999999784504
Extrinsic Rewards:
0
0
4
0
0
Sum Reward: 4
Avg Reward: 0.8
Min Reward: 0
Max Reward: 4
Gini Coefficient: 0.8
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-51-06
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -491.84564061967876
  episode_reward_min: -1199.314062486906
  episodes_this_iter: 1
  episodes_total: 270
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.604
    dispatch_time_ms: 7.295
    learner:
      cur_lr: 0.0012700899969786406
      grad_gnorm: 10.336507797241211
      policy_entropy: 0.00013484097144100815
      policy_loss: 7.581485874652572e-07
      var_gnorm: 24.563932418823242
      vf_explained_var: 0.0
      vf_loss: 0.07099501043558121
    num_steps_sampled: 1355000
    num_steps_trained: 1355000
    wait_time_ms: 75.651
  iterations_since_restore: 271
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 2363.9174134731293
  time_this_iter_s: 8.21418023109436
  time_total_s: 2363.9174134731293
  timestamp: 1594860666
  timesteps_since_restore: 1355000
  timesteps_this_iter: 5000
  timesteps_total: 1355000
  training_iteration: 271
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 2363 s, 271 iter, 1355000 ts, -492 rew

agent-1: -149.99999999841847
agent-2: -149.99999999841847
agent-3: 2.0
agent-4: -48.99999999948169
agent-5: -149.99999999841847
Extrinsic Rewards:
0
0
2
1
0
Sum Reward: 3
Avg Reward: 0.6
Min Reward: 0
Max Reward: 2
Gini Coefficient: 0.6666666666666666
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-51-15
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -496.81564061962615
  episode_reward_min: -1199.314062486906
  episodes_this_iter: 1
  episodes_total: 271
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 3.174
    dispatch_time_ms: 8.62
    learner:
      cur_lr: 0.0012697570491582155
      grad_gnorm: 0.19232802093029022
      policy_entropy: 0.00013201827823650092
      policy_loss: 1.0514184189958087e-08
      var_gnorm: 24.563932418823242
      vf_explained_var: 0.0
      vf_loss: 2.4541577658965252e-05
    num_steps_sampled: 1360000
    num_steps_trained: 1360000
    wait_time_ms: 80.408
  iterations_since_restore: 272
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 2372.177528858185
  time_this_iter_s: 8.260115385055542
  time_total_s: 2372.177528858185
  timestamp: 1594860675
  timesteps_since_restore: 1360000
  timesteps_this_iter: 5000
  timesteps_total: 1360000
  training_iteration: 272
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 2372 s, 272 iter, 1360000 ts, -497 rew

agent-1: 2.0
agent-2: -99.99999999894987
agent-3: -99.99999999894987
agent-4: -99.99999999894987
agent-5: -99.99999999894987
Extrinsic Rewards:
2
0
0
0
0
Sum Reward: 2
Avg Reward: 0.4
Min Reward: 0
Max Reward: 2
Gini Coefficient: 0.8
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-51-23
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -500.7956406195841
  episode_reward_min: -1199.314062486906
  episodes_this_iter: 1
  episodes_total: 272
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.918
    dispatch_time_ms: 7.155
    learner:
      cur_lr: 0.0012694239849224687
      grad_gnorm: 0.05145912244915962
      policy_entropy: 0.00022568089480046183
      policy_loss: -2.6089281845997903e-09
      var_gnorm: 24.55893898010254
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 1.7573487411937094e-06
    num_steps_sampled: 1365000
    num_steps_trained: 1365000
    wait_time_ms: 71.579
  iterations_since_restore: 273
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 2380.3145682811737
  time_this_iter_s: 8.137039422988892
  time_total_s: 2380.3145682811737
  timestamp: 1594860683
  timesteps_since_restore: 1365000
  timesteps_this_iter: 5000
  timesteps_total: 1365000
  training_iteration: 273
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 2380 s, 273 iter, 1365000 ts, -501 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-51-31
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -492.8356406196743
  episode_reward_min: -1199.314062486906
  episodes_this_iter: 1
  episodes_total: 273
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.854
    dispatch_time_ms: 8.161
    learner:
      cur_lr: 0.0012690910371020436
      grad_gnorm: 0.09875500202178955
      policy_entropy: 0.000876883277669549
      policy_loss: 3.987889485301821e-08
      var_gnorm: 24.548908233642578
      vf_explained_var: 0.0
      vf_loss: 6.473314442700939e-06
    num_steps_sampled: 1370000
    num_steps_trained: 1370000
    wait_time_ms: 71.024
  iterations_since_restore: 274
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 2388.5935003757477
  time_this_iter_s: 8.278932094573975
  time_total_s: 2388.5935003757477
  timestamp: 1594860691
  timesteps_since_restore: 1370000
  timesteps_this_iter: 5000
  timesteps_total: 1370000
  training_iteration: 274
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 2388 s, 274 iter, 1370000 ts, -493 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-51-39
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -481.8562656197963
  episode_reward_min: -1199.314062486906
  episodes_this_iter: 1
  episodes_total: 274
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.817
    dispatch_time_ms: 6.585
    learner:
      cur_lr: 0.0012687579728662968
      grad_gnorm: 40.0
      policy_entropy: 2.6129162311553955
      policy_loss: -6429.6064453125
      var_gnorm: 24.74128532409668
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 16259963904.0
    num_steps_sampled: 1375000
    num_steps_trained: 1375000
    wait_time_ms: 81.2
  iterations_since_restore: 275
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 2396.909495830536
  time_this_iter_s: 8.315995454788208
  time_total_s: 2396.909495830536
  timestamp: 1594860699
  timesteps_since_restore: 1375000
  timesteps_this_iter: 5000
  timesteps_total: 1375000
  training_iteration: 275
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 2396 s, 275 iter, 1375000 ts, -482 rew

agent-1: -6140.021387092112
agent-2: -1477374.151350927
agent-3: -30742.21993855495
agent-4: -1481854.406876242
agent-5: -4446495.253812107
Extrinsic Rewards:
-636
-17130
-839
-17139
-33882
Sum Reward: -69626
Avg Reward: -13925.2
Min Reward: -33882
Max Reward: -636
Gini Coefficient: -0.47563841093844256
20:20 Ratio: 0.01877102886488401
Max-min Ratio: 0.01877102886488401
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-51-48
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -74907.91679926914
  episode_reward_min: -7442606.053364935
  episodes_this_iter: 1
  episodes_total: 275
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.84
    dispatch_time_ms: 7.991
    learner:
      cur_lr: 0.0012684250250458717
      grad_gnorm: 40.0
      policy_entropy: 0.027855193242430687
      policy_loss: -25.479755401611328
      var_gnorm: 24.99456787109375
      vf_explained_var: 0.0
      vf_loss: 17915090944.0
    num_steps_sampled: 1380000
    num_steps_trained: 1380000
    wait_time_ms: 77.46
  iterations_since_restore: 276
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 2405.779262304306
  time_this_iter_s: 8.869766473770142
  time_total_s: 2405.779262304306
  timestamp: 1594860708
  timesteps_since_restore: 1380000
  timesteps_this_iter: 5000
  timesteps_total: 1380000
  training_iteration: 276
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 2405 s, 276 iter, 1380000 ts, -7.49e+04 rew

agent-1: -78100.79455881589
agent-2: -3008.4503122945944
agent-3: -5245696.415182469
agent-4: -7916.845983448131
agent-5: -11991874.666708264
Extrinsic Rewards:
-1529
-778
-37679
-870
-73163
Sum Reward: -114019
Avg Reward: -22803.8
Min Reward: -73163
Max Reward: -778
Gini Coefficient: -0.6370131293907156
20:20 Ratio: 0.010633790303842107
Max-min Ratio: 0.010633790303842107
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-51-57
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -248171.89852672193
  episode_reward_min: -17326597.172745273
  episodes_this_iter: 1
  episodes_total: 276
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.444
    dispatch_time_ms: 7.848
    learner:
      cur_lr: 0.0012680919608101249
      grad_gnorm: 39.999996185302734
      policy_entropy: 0.08616070449352264
      policy_loss: -88.58167266845703
      var_gnorm: 25.39404296875
      vf_explained_var: 0.0
      vf_loss: 16572476416.0
    num_steps_sampled: 1385000
    num_steps_trained: 1385000
    wait_time_ms: 74.822
  iterations_since_restore: 277
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 2414.4642403125763
  time_this_iter_s: 8.684978008270264
  time_total_s: 2414.4642403125763
  timestamp: 1594860717
  timesteps_since_restore: 1385000
  timesteps_this_iter: 5000
  timesteps_total: 1385000
  training_iteration: 277
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 2414 s, 277 iter, 1385000 ts, -2.48e+05 rew

agent-1: -1049.999539654401
agent-2: -13863903.682308367
agent-3: -999.0
agent-4: -1049.999539654401
agent-5: -1049.999539654401
Extrinsic Rewards:
-1000
-73850
-999
-1000
-1000
Sum Reward: -77849
Avg Reward: -15569.8
Min Reward: -73850
Max Reward: -999
Gini Coefficient: -0.7486390319721512
20:20 Ratio: 0.013527420446851726
Max-min Ratio: 0.013527420446851726
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-52-06
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -386846.455335995
  episode_reward_min: -17326597.172745273
  episodes_this_iter: 1
  episodes_total: 277
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.639
    dispatch_time_ms: 8.248
    learner:
      cur_lr: 0.0012677590129896998
      grad_gnorm: 40.0
      policy_entropy: 0.2550693154335022
      policy_loss: -347.7030944824219
      var_gnorm: 25.921165466308594
      vf_explained_var: 0.0
      vf_loss: 17028655104.0
    num_steps_sampled: 1390000
    num_steps_trained: 1390000
    wait_time_ms: 73.018
  iterations_since_restore: 278
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 2423.0535502433777
  time_this_iter_s: 8.589309930801392
  time_total_s: 2423.0535502433777
  timestamp: 1594860726
  timesteps_since_restore: 1390000
  timesteps_this_iter: 5000
  timesteps_total: 1390000
  training_iteration: 278
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 2423 s, 278 iter, 1390000 ts, -3.87e+05 rew

agent-1: -1099.9885184365812
agent-2: -1048.7482701683725
agent-3: -1099.9885184365812
agent-4: -1721887.7929337416
agent-5: -7140984.365093135
Extrinsic Rewards:
-1000
-999
-1000
-12399
-41297
Sum Reward: -56695
Avg Reward: -11339.0
Min Reward: -41297
Max Reward: -999
Gini Coefficient: -0.6490519446159273
20:20 Ratio: 0.024190619173305568
Max-min Ratio: 0.024190619173305568
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-52-14
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -475503.6841693345
  episode_reward_min: -17326597.172745273
  episodes_this_iter: 1
  episodes_total: 278
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 3.837
    dispatch_time_ms: 7.757
    learner:
      cur_lr: 0.001267425948753953
      grad_gnorm: 40.0
      policy_entropy: 0.27445152401924133
      policy_loss: -847.203369140625
      var_gnorm: 26.50604248046875
      vf_explained_var: 0.0
      vf_loss: 45961183232.0
    num_steps_sampled: 1395000
    num_steps_trained: 1395000
    wait_time_ms: 69.691
  iterations_since_restore: 279
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 2431.5696818828583
  time_this_iter_s: 8.51613163948059
  time_total_s: 2431.5696818828583
  timestamp: 1594860734
  timesteps_since_restore: 1395000
  timesteps_this_iter: 5000
  timesteps_total: 1395000
  training_iteration: 279
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 2431 s, 279 iter, 1395000 ts, -4.76e+05 rew

agent-1: -999.0
agent-2: -1906855.1994180977
agent-3: -10106907.797830246
agent-4: -6315896.404193452
agent-5: -1049.9999999965369
Extrinsic Rewards:
-999
-21800
-71800
-50999
-1000
Sum Reward: -146598
Avg Reward: -29319.6
Min Reward: -71800
Max Reward: -999
Gini Coefficient: -0.5227929439692219
20:20 Ratio: 0.013913649025069637
Max-min Ratio: 0.013913649025069637
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-52-23
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -658814.7981837523
  episode_reward_min: -18331708.40144178
  episodes_this_iter: 1
  episodes_total: 279
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.554
    dispatch_time_ms: 6.478
    learner:
      cur_lr: 0.001267093000933528
      grad_gnorm: 40.0
      policy_entropy: 0.07496345043182373
      policy_loss: -120.36807250976562
      var_gnorm: 27.153440475463867
      vf_explained_var: 0.0
      vf_loss: 20035213312.0
    num_steps_sampled: 1400000
    num_steps_trained: 1400000
    wait_time_ms: 80.867
  iterations_since_restore: 280
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 2440.2125816345215
  time_this_iter_s: 8.642899751663208
  time_total_s: 2440.2125816345215
  timestamp: 1594860743
  timesteps_since_restore: 1400000
  timesteps_this_iter: 5000
  timesteps_total: 1400000
  training_iteration: 280
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 2440 s, 280 iter, 1400000 ts, -6.59e+05 rew

agent-1: -1583563.6801559725
agent-2: -2528669.781455779
agent-3: -1113890.8485513758
agent-4: -2969316.7006973443
agent-5: -4120255.9757554303
Extrinsic Rewards:
-26100
-35549
-17199
-37998
-50998
Sum Reward: -167844
Avg Reward: -33568.8
Min Reward: -50998
Max Reward: -17199
Gini Coefficient: -0.18945211029289102
20:20 Ratio: 0.33724851954978624
Max-min Ratio: 0.33724851954978624
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-52-32
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -781963.8024249115
  episode_reward_min: -18331708.40144178
  episodes_this_iter: 1
  episodes_total: 280
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.521
    dispatch_time_ms: 7.396
    learner:
      cur_lr: 0.001266760053113103
      grad_gnorm: 40.0
      policy_entropy: 0.00905399490147829
      policy_loss: -11.624349594116211
      var_gnorm: 27.853727340698242
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 20491055104.0
    num_steps_sampled: 1405000
    num_steps_trained: 1405000
    wait_time_ms: 73.764
  iterations_since_restore: 281
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 2448.916223049164
  time_this_iter_s: 8.703641414642334
  time_total_s: 2448.916223049164
  timestamp: 1594860752
  timesteps_since_restore: 1405000
  timesteps_this_iter: 5000
  timesteps_total: 1405000
  training_iteration: 281
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 2448 s, 281 iter, 1405000 ts, -7.82e+05 rew

agent-1: -1000.0
agent-2: -3926998.457090066
agent-3: -1000.0
agent-4: -1000.0
agent-5: -8360799.515362226
Extrinsic Rewards:
-1000
-27000
-1000
-1000
-50999
Sum Reward: -80999
Avg Reward: -16199.8
Min Reward: -50999
Max Reward: -1000
Gini Coefficient: -0.6222200274077457
20:20 Ratio: 0.019608227612306125
Max-min Ratio: 0.019608227612306125
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-52-40
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -904871.7821494347
  episode_reward_min: -18331708.40144178
  episodes_this_iter: 1
  episodes_total: 281
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.531
    dispatch_time_ms: 8.096
    learner:
      cur_lr: 0.001266426988877356
      grad_gnorm: 39.999996185302734
      policy_entropy: 0.008233095519244671
      policy_loss: -10.473098754882812
      var_gnorm: 28.59683609008789
      vf_explained_var: 1.1920928955078125e-07
      vf_loss: 20498458624.0
    num_steps_sampled: 1410000
    num_steps_trained: 1410000
    wait_time_ms: 75.731
  iterations_since_restore: 282
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 2457.6761186122894
  time_this_iter_s: 8.75989556312561
  time_total_s: 2457.6761186122894
  timestamp: 1594860760
  timesteps_since_restore: 1410000
  timesteps_this_iter: 5000
  timesteps_total: 1410000
  training_iteration: 282
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 2457 s, 282 iter, 1410000 ts, -9.05e+05 rew

agent-1: -7258500.000002949
agent-2: -1000.0
agent-3: -7258500.000002949
agent-4: -1000.0
agent-5: -1000.0
Extrinsic Rewards:
-51000
-1000
-51000
-1000
-1000
Sum Reward: -105000
Avg Reward: -21000.0
Min Reward: -51000
Max Reward: -1000
Gini Coefficient: -0.5714285714285714
20:20 Ratio: 0.0196078431372549
Max-min Ratio: 0.0196078431372549
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-52-49
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -1050060.8521494938
  episode_reward_min: -18331708.40144178
  episodes_this_iter: 1
  episodes_total: 282
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.747
    dispatch_time_ms: 7.543
    learner:
      cur_lr: 0.001266094041056931
      grad_gnorm: 40.0
      policy_entropy: 0.00849155243486166
      policy_loss: -10.891297340393066
      var_gnorm: 29.375486373901367
      vf_explained_var: 0.0
      vf_loss: 13750922240.0
    num_steps_sampled: 1415000
    num_steps_trained: 1415000
    wait_time_ms: 76.68
  iterations_since_restore: 283
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 2466.3649609088898
  time_this_iter_s: 8.688842296600342
  time_total_s: 2466.3649609088898
  timestamp: 1594860769
  timesteps_since_restore: 1415000
  timesteps_this_iter: 5000
  timesteps_total: 1415000
  training_iteration: 283
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 2466 s, 283 iter, 1415000 ts, -1.05e+06 rew

agent-1: -9130880.417810207
agent-2: -1604108.40758626
agent-3: -999.0
agent-4: -1049.9152512775036
agent-5: -1049.9152512775036
Extrinsic Rewards:
-51000
-13550
-999
-1000
-1000
Sum Reward: -67549
Avg Reward: -13509.8
Min Reward: -51000
Max Reward: -999
Gini Coefficient: -0.6664909917245259
20:20 Ratio: 0.019588235294117646
Max-min Ratio: 0.019588235294117646
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-52-58
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -1157430.703724109
  episode_reward_min: -18331708.40144178
  episodes_this_iter: 1
  episodes_total: 283
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.501
    dispatch_time_ms: 8.085
    learner:
      cur_lr: 0.0012657609768211842
      grad_gnorm: 40.0
      policy_entropy: 0.00878079328685999
      policy_loss: -11.278042793273926
      var_gnorm: 30.184391021728516
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 13754456064.0
    num_steps_sampled: 1420000
    num_steps_trained: 1420000
    wait_time_ms: 74.126
  iterations_since_restore: 284
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 2475.06222820282
  time_this_iter_s: 8.697267293930054
  time_total_s: 2475.06222820282
  timestamp: 1594860778
  timesteps_since_restore: 1420000
  timesteps_this_iter: 5000
  timesteps_total: 1420000
  training_iteration: 284
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 2475 s, 284 iter, 1420000 ts, -1.16e+06 rew

agent-1: -4856000.00000197
agent-2: -4856000.00000197
agent-3: -1000.0
agent-4: -1000.0
agent-5: -4856000.00000197
Extrinsic Rewards:
-51000
-51000
-1000
-1000
-51000
Sum Reward: -155000
Avg Reward: -31000.0
Min Reward: -51000
Max Reward: -1000
Gini Coefficient: -0.3870967741935484
20:20 Ratio: 0.0196078431372549
Max-min Ratio: 0.0196078431372549
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-53-07
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -1303122.7437241676
  episode_reward_min: -18331708.40144178
  episodes_this_iter: 1
  episodes_total: 284
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.852
    dispatch_time_ms: 7.52
    learner:
      cur_lr: 0.0012654280290007591
      grad_gnorm: 39.999996185302734
      policy_entropy: 0.009110739454627037
      policy_loss: -11.759526252746582
      var_gnorm: 31.019357681274414
      vf_explained_var: 0.0
      vf_loss: 13753782272.0
    num_steps_sampled: 1425000
    num_steps_trained: 1425000
    wait_time_ms: 77.866
  iterations_since_restore: 285
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 2483.8257551193237
  time_this_iter_s: 8.763526916503906
  time_total_s: 2483.8257551193237
  timestamp: 1594860787
  timesteps_since_restore: 1425000
  timesteps_this_iter: 5000
  timesteps_total: 1425000
  training_iteration: 285
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 2483 s, 285 iter, 1425000 ts, -1.3e+06 rew

agent-1: -1000.0
agent-2: -4856000.00000197
agent-3: -4856000.00000197
agent-4: -1000.0
agent-5: -4856000.00000197
Extrinsic Rewards:
-1000
-51000
-51000
-1000
-51000
Sum Reward: -155000
Avg Reward: -31000.0
Min Reward: -51000
Max Reward: -1000
Gini Coefficient: -0.3870967741935484
20:20 Ratio: 0.0196078431372549
Max-min Ratio: 0.0196078431372549
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-53-15
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -1448816.773724226
  episode_reward_min: -18331708.40144178
  episodes_this_iter: 1
  episodes_total: 285
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 3.282
    dispatch_time_ms: 6.968
    learner:
      cur_lr: 0.0012650949647650123
      grad_gnorm: 40.0
      policy_entropy: 0.009482619352638721
      policy_loss: -24.444541931152344
      var_gnorm: 31.87700653076172
      vf_explained_var: 0.0
      vf_loss: 61672411136.0
    num_steps_sampled: 1430000
    num_steps_trained: 1430000
    wait_time_ms: 77.478
  iterations_since_restore: 286
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 2492.576819419861
  time_this_iter_s: 8.75106430053711
  time_total_s: 2492.576819419861
  timestamp: 1594860795
  timesteps_since_restore: 1430000
  timesteps_this_iter: 5000
  timesteps_total: 1430000
  training_iteration: 286
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 2492 s, 286 iter, 1430000 ts, -1.45e+06 rew

agent-1: -1000.0
agent-2: -12113500.000004921
agent-3: -1000.0
agent-4: -4856000.00000197
agent-5: -12113500.000004921
Extrinsic Rewards:
-1000
-101000
-1000
-51000
-101000
Sum Reward: -255000
Avg Reward: -51000.0
Min Reward: -101000
Max Reward: -1000
Gini Coefficient: -0.47058823529411764
20:20 Ratio: 0.009900990099009901
Max-min Ratio: 0.009900990099009901
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-53-24
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -1739662.7937243439
  episode_reward_min: -29085000.00001179
  episodes_this_iter: 1
  episodes_total: 286
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 4.552
    dispatch_time_ms: 10.859
    learner:
      cur_lr: 0.0012647620169445872
      grad_gnorm: 39.999996185302734
      policy_entropy: 0.009912258945405483
      policy_loss: -29.830768585205078
      var_gnorm: 32.75460433959961
      vf_explained_var: 0.0
      vf_loss: 122897367040.0
    num_steps_sampled: 1435000
    num_steps_trained: 1435000
    wait_time_ms: 73.809
  iterations_since_restore: 287
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 2501.3687040805817
  time_this_iter_s: 8.791884660720825
  time_total_s: 2501.3687040805817
  timestamp: 1594860804
  timesteps_since_restore: 1435000
  timesteps_this_iter: 5000
  timesteps_total: 1435000
  training_iteration: 287
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 2501 s, 287 iter, 1435000 ts, -1.74e+06 rew

agent-1: -24176000.000009835
agent-2: -1000.0
agent-3: -4856000.00000197
agent-4: -4856000.00000197
agent-5: -1000.0
Extrinsic Rewards:
-151000
-1000
-51000
-51000
-1000
Sum Reward: -255000
Avg Reward: -51000.0
Min Reward: -151000
Max Reward: -1000
Gini Coefficient: -0.5490196078431373
20:20 Ratio: 0.006622516556291391
Max-min Ratio: 0.006622516556291391
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-53-33
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -2078562.793724482
  episode_reward_min: -33890000.000013836
  episodes_this_iter: 1
  episodes_total: 287
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 3.365
    dispatch_time_ms: 9.802
    learner:
      cur_lr: 0.0012644289527088404
      grad_gnorm: 40.0
      policy_entropy: 0.010423332452774048
      policy_loss: -22.17403793334961
      var_gnorm: 33.64984893798828
      vf_explained_var: 0.0
      vf_loss: 62763548672.0
    num_steps_sampled: 1440000
    num_steps_trained: 1440000
    wait_time_ms: 74.217
  iterations_since_restore: 288
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 2510.178653240204
  time_this_iter_s: 8.809949159622192
  time_total_s: 2510.178653240204
  timestamp: 1594860813
  timesteps_since_restore: 1440000
  timesteps_this_iter: 5000
  timesteps_total: 1440000
  training_iteration: 288
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 2510 s, 288 iter, 1440000 ts, -2.08e+06 rew

agent-1: -4856000.00000197
agent-2: -4856000.00000197
agent-3: -1000.0
agent-4: -4856000.00000197
agent-5: -1000.0
Extrinsic Rewards:
-51000
-51000
-1000
-51000
-1000
Sum Reward: -155000
Avg Reward: -31000.0
Min Reward: -51000
Max Reward: -1000
Gini Coefficient: -0.3870967741935484
20:20 Ratio: 0.0196078431372549
Max-min Ratio: 0.0196078431372549
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-53-42
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -2224256.823724541
  episode_reward_min: -33890000.000013836
  episodes_this_iter: 1
  episodes_total: 288
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 3.346
    dispatch_time_ms: 8.163
    learner:
      cur_lr: 0.0012640960048884153
      grad_gnorm: 40.0
      policy_entropy: 0.011010104790329933
      policy_loss: -24.001605987548828
      var_gnorm: 34.560855865478516
      vf_explained_var: 1.1920928955078125e-07
      vf_loss: 65939378176.0
    num_steps_sampled: 1445000
    num_steps_trained: 1445000
    wait_time_ms: 76.752
  iterations_since_restore: 289
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 2518.8600087165833
  time_this_iter_s: 8.681355476379395
  time_total_s: 2518.8600087165833
  timestamp: 1594860822
  timesteps_since_restore: 1445000
  timesteps_this_iter: 5000
  timesteps_total: 1445000
  training_iteration: 289
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 2518 s, 289 iter, 1445000 ts, -2.22e+06 rew

agent-1: -1000.0
agent-2: -16918500.00000688
agent-3: -1000.0
agent-4: -1000.0
agent-5: -7258500.000002949
Extrinsic Rewards:
-1000
-101000
-1000
-1000
-51000
Sum Reward: -155000
Avg Reward: -31000.0
Min Reward: -101000
Max Reward: -1000
Gini Coefficient: -0.6451612903225806
20:20 Ratio: 0.009900990099009901
Max-min Ratio: 0.009900990099009901
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-53-51
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -2466048.863724639
  episode_reward_min: -33890000.000013836
  episodes_this_iter: 1
  episodes_total: 289
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.683
    dispatch_time_ms: 6.676
    learner:
      cur_lr: 0.0012637630570679903
      grad_gnorm: 40.0
      policy_entropy: 0.011716905049979687
      policy_loss: -9.970379829406738
      var_gnorm: 35.486026763916016
      vf_explained_var: 1.1920928955078125e-07
      vf_loss: 17033552896.0
    num_steps_sampled: 1450000
    num_steps_trained: 1450000
    wait_time_ms: 80.923
  iterations_since_restore: 290
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 2527.5205042362213
  time_this_iter_s: 8.660495519638062
  time_total_s: 2527.5205042362213
  timestamp: 1594860831
  timesteps_since_restore: 1450000
  timesteps_this_iter: 5000
  timesteps_total: 1450000
  training_iteration: 290
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 2527 s, 290 iter, 1450000 ts, -2.47e+06 rew

agent-1: -14516000.0000059
agent-2: -4856000.00000197
agent-3: -1000.0
agent-4: -4856000.00000197
agent-5: -1000.0
Extrinsic Rewards:
-101000
-51000
-1000
-51000
-1000
Sum Reward: -205000
Avg Reward: -41000.0
Min Reward: -101000
Max Reward: -1000
Gini Coefficient: -0.4878048780487805
20:20 Ratio: 0.009900990099009901
Max-min Ratio: 0.009900990099009901
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-54-00
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -2708339.8887247383
  episode_reward_min: -33890000.000013836
  episodes_this_iter: 1
  episodes_total: 290
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.77
    dispatch_time_ms: 8.899
    learner:
      cur_lr: 0.0012634299928322434
      grad_gnorm: 40.00000762939453
      policy_entropy: 0.012571210972964764
      policy_loss: -16.711332321166992
      var_gnorm: 36.424007415771484
      vf_explained_var: 0.0
      vf_loss: 20489660416.0
    num_steps_sampled: 1455000
    num_steps_trained: 1455000
    wait_time_ms: 75.827
  iterations_since_restore: 291
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 2536.479641199112
  time_this_iter_s: 8.959136962890625
  time_total_s: 2536.479641199112
  timestamp: 1594860840
  timesteps_since_restore: 1455000
  timesteps_this_iter: 5000
  timesteps_total: 1455000
  training_iteration: 291
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 2536 s, 291 iter, 1455000 ts, -2.71e+06 rew

agent-1: -1000.0
agent-2: -1000.0
agent-3: -1000.0
agent-4: -1000.0
agent-5: -9661000.000003938
Extrinsic Rewards:
-1000
-1000
-1000
-1000
-51000
Sum Reward: -55000
Avg Reward: -11000.0
Min Reward: -51000
Max Reward: -1000
Gini Coefficient: -0.7272727272727273
20:20 Ratio: 0.0196078431372549
Max-min Ratio: 0.0196078431372549
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-54-09
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -2804981.928724778
  episode_reward_min: -33890000.000013836
  episodes_this_iter: 1
  episodes_total: 291
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.908
    dispatch_time_ms: 7.265
    learner:
      cur_lr: 0.0012630970450118184
      grad_gnorm: 39.999996185302734
      policy_entropy: 0.013625193387269974
      policy_loss: -18.24863052368164
      var_gnorm: 37.37361526489258
      vf_explained_var: 0.0
      vf_loss: 20492013568.0
    num_steps_sampled: 1460000
    num_steps_trained: 1460000
    wait_time_ms: 77.209
  iterations_since_restore: 292
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 2545.6314494609833
  time_this_iter_s: 9.151808261871338
  time_total_s: 2545.6314494609833
  timestamp: 1594860849
  timesteps_since_restore: 1460000
  timesteps_this_iter: 5000
  timesteps_total: 1460000
  training_iteration: 292
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 2545 s, 292 iter, 1460000 ts, -2.8e+06 rew

agent-1: -1000.0
agent-2: -7258500.000002949
agent-3: -1000.0
agent-4: -1000.0
agent-5: -7258500.000002949
Extrinsic Rewards:
-1000
-51000
-1000
-1000
-51000
Sum Reward: -105000
Avg Reward: -21000.0
Min Reward: -51000
Max Reward: -1000
Gini Coefficient: -0.5714285714285714
20:20 Ratio: 0.0196078431372549
Max-min Ratio: 0.0196078431372549
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-54-17
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -2950177.9487248366
  episode_reward_min: -33890000.000013836
  episodes_this_iter: 1
  episodes_total: 292
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 4.46
    dispatch_time_ms: 6.037
    learner:
      cur_lr: 0.0012627639807760715
      grad_gnorm: 39.999996185302734
      policy_entropy: 0.005110754631459713
      policy_loss: -4.026121616363525
      var_gnorm: 38.3861198425293
      vf_explained_var: 1.1920928955078125e-07
      vf_loss: 18154975232.0
    num_steps_sampled: 1465000
    num_steps_trained: 1465000
    wait_time_ms: 72.931
  iterations_since_restore: 293
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 2554.242380619049
  time_this_iter_s: 8.610931158065796
  time_total_s: 2554.242380619049
  timestamp: 1594860857
  timesteps_since_restore: 1465000
  timesteps_this_iter: 5000
  timesteps_total: 1465000
  training_iteration: 293
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 2554 s, 293 iter, 1465000 ts, -2.95e+06 rew

agent-1: -7660276.221324464
agent-2: -1000.0
agent-3: -1000.0
agent-4: -8944210.390758153
agent-5: -4855899.000120403
Extrinsic Rewards:
-69600
-1000
-1000
-77899
-50999
Sum Reward: -200498
Avg Reward: -40099.6
Min Reward: -77899
Max Reward: -1000
Gini Coefficient: -0.44369120888986424
20:20 Ratio: 0.012837135264894287
Max-min Ratio: 0.012837135264894287
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-54-26
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -3164801.804846866
  episode_reward_min: -33890000.000013836
  episodes_this_iter: 1
  episodes_total: 293
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.512
    dispatch_time_ms: 8.008
    learner:
      cur_lr: 0.0012624310329556465
      grad_gnorm: 40.0
      policy_entropy: 0.0021314406767487526
      policy_loss: -2.264943838119507
      var_gnorm: 39.38993453979492
      vf_explained_var: -8.094310760498047e-05
      vf_loss: 16183271424.0
    num_steps_sampled: 1470000
    num_steps_trained: 1470000
    wait_time_ms: 77.215
  iterations_since_restore: 294
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 2562.807019472122
  time_this_iter_s: 8.56463885307312
  time_total_s: 2562.807019472122
  timestamp: 1594860866
  timesteps_since_restore: 1470000
  timesteps_this_iter: 5000
  timesteps_total: 1470000
  training_iteration: 294
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 2562 s, 294 iter, 1470000 ts, -3.16e+06 rew

agent-1: -1000.0
agent-2: -1000.0
agent-3: -1000.0
agent-4: -9661000.000003938
agent-5: -1000.0
Extrinsic Rewards:
-1000
-1000
-1000
-51000
-1000
Sum Reward: -55000
Avg Reward: -11000.0
Min Reward: -51000
Max Reward: -1000
Gini Coefficient: -0.7272727272727273
20:20 Ratio: 0.0196078431372549
Max-min Ratio: 0.0196078431372549
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-54-35
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -3261449.8148469054
  episode_reward_min: -33890000.000013836
  episodes_this_iter: 1
  episodes_total: 294
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.387
    dispatch_time_ms: 5.972
    learner:
      cur_lr: 0.0012620979687198997
      grad_gnorm: 40.0
      policy_entropy: 0.007213728968054056
      policy_loss: -8.835553169250488
      var_gnorm: 40.438575744628906
      vf_explained_var: 0.0
      vf_loss: 20490760192.0
    num_steps_sampled: 1475000
    num_steps_trained: 1475000
    wait_time_ms: 79.414
  iterations_since_restore: 295
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 2571.421135187149
  time_this_iter_s: 8.614115715026855
  time_total_s: 2571.421135187149
  timestamp: 1594860875
  timesteps_since_restore: 1475000
  timesteps_this_iter: 5000
  timesteps_total: 1475000
  training_iteration: 295
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 2571 s, 295 iter, 1475000 ts, -3.26e+06 rew

agent-1: -1000.0
agent-2: -1000.0
agent-3: -7258500.000002949
agent-4: -7258500.000002949
agent-5: -1000.0
Extrinsic Rewards:
-1000
-1000
-51000
-51000
-1000
Sum Reward: -105000
Avg Reward: -21000.0
Min Reward: -51000
Max Reward: -1000
Gini Coefficient: -0.5714285714285714
20:20 Ratio: 0.0196078431372549
Max-min Ratio: 0.0196078431372549
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-54-43
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -3406643.8448469653
  episode_reward_min: -33890000.000013836
  episodes_this_iter: 1
  episodes_total: 295
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.903
    dispatch_time_ms: 6.902
    learner:
      cur_lr: 0.0012617650208994746
      grad_gnorm: 40.0
      policy_entropy: 0.02216433919966221
      policy_loss: -30.154674530029297
      var_gnorm: 41.45400619506836
      vf_explained_var: 0.0
      vf_loss: 20490174464.0
    num_steps_sampled: 1480000
    num_steps_trained: 1480000
    wait_time_ms: 74.131
  iterations_since_restore: 296
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 2579.921468257904
  time_this_iter_s: 8.500333070755005
  time_total_s: 2579.921468257904
  timestamp: 1594860883
  timesteps_since_restore: 1480000
  timesteps_this_iter: 5000
  timesteps_total: 1480000
  training_iteration: 296
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 2579 s, 296 iter, 1480000 ts, -3.41e+06 rew

agent-1: -1000.0
agent-2: -7258500.000002949
agent-3: -1000.0
agent-4: -1000.0
agent-5: -7258500.000002949
Extrinsic Rewards:
-1000
-51000
-1000
-1000
-51000
Sum Reward: -105000
Avg Reward: -21000.0
Min Reward: -51000
Max Reward: -1000
Gini Coefficient: -0.5714285714285714
20:20 Ratio: 0.0196078431372549
Max-min Ratio: 0.0196078431372549
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-54-52
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -3551836.884222024
  episode_reward_min: -33890000.000013836
  episodes_this_iter: 1
  episodes_total: 296
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 3.008
    dispatch_time_ms: 8.892
    learner:
      cur_lr: 0.0012614319566637278
      grad_gnorm: 40.0
      policy_entropy: 0.03129070997238159
      policy_loss: -73.41899108886719
      var_gnorm: 41.7396354675293
      vf_explained_var: 0.0
      vf_loss: 50154655744.0
    num_steps_sampled: 1485000
    num_steps_trained: 1485000
    wait_time_ms: 75.105
  iterations_since_restore: 297
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 2588.561764717102
  time_this_iter_s: 8.640296459197998
  time_total_s: 2588.561764717102
  timestamp: 1594860892
  timesteps_since_restore: 1485000
  timesteps_this_iter: 5000
  timesteps_total: 1485000
  training_iteration: 297
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 2588 s, 297 iter, 1485000 ts, -3.55e+06 rew

agent-1: -12347173.843884036
agent-2: -5573374.420085029
agent-3: -1000.0
agent-4: -3404649.2379313344
agent-5: -1000.0
Extrinsic Rewards:
-84700
-50999
-1000
-34700
-1000
Sum Reward: -172399
Avg Reward: -34479.8
Min Reward: -84700
Max Reward: -1000
Gini Coefficient: -0.5044089582886212
20:20 Ratio: 0.011806375442739079
Max-min Ratio: 0.011806375442739079
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-55-00
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -3765106.869241027
  episode_reward_min: -33890000.000013836
  episodes_this_iter: 1
  episodes_total: 297
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.574
    dispatch_time_ms: 6.039
    learner:
      cur_lr: 0.0012610990088433027
      grad_gnorm: 39.999996185302734
      policy_entropy: 0.018558641895651817
      policy_loss: 0.01487365085631609
      var_gnorm: 41.74185562133789
      vf_explained_var: 5.960464477539063e-08
      vf_loss: 2906.4423828125
    num_steps_sampled: 1490000
    num_steps_trained: 1490000
    wait_time_ms: 75.362
  iterations_since_restore: 298
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 2597.140252351761
  time_this_iter_s: 8.578487634658813
  time_total_s: 2597.140252351761
  timestamp: 1594860900
  timesteps_since_restore: 1490000
  timesteps_this_iter: 5000
  timesteps_total: 1490000
  training_iteration: 298
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 2597 s, 298 iter, 1490000 ts, -3.77e+06 rew

agent-1: -1000.0
agent-2: -1000.0
agent-3: -1000.0
agent-4: -1000.0
agent-5: -1000.0
Extrinsic Rewards:
-1000
-1000
-1000
-1000
-1000
Sum Reward: -5000
Avg Reward: -1000.0
Min Reward: -1000
Max Reward: -1000
Gini Coefficient: -0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-55-09
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -3765156.869241027
  episode_reward_min: -33890000.000013836
  episodes_this_iter: 1
  episodes_total: 298
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.758
    dispatch_time_ms: 8.242
    learner:
      cur_lr: 0.0012607659446075559
      grad_gnorm: 40.0
      policy_entropy: 0.00636351527646184
      policy_loss: -7.6116437911987305
      var_gnorm: 42.43788528442383
      vf_explained_var: 0.0
      vf_loss: 13746939904.0
    num_steps_sampled: 1495000
    num_steps_trained: 1495000
    wait_time_ms: 79.83
  iterations_since_restore: 299
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 2605.9724078178406
  time_this_iter_s: 8.832155466079712
  time_total_s: 2605.9724078178406
  timestamp: 1594860909
  timesteps_since_restore: 1495000
  timesteps_this_iter: 5000
  timesteps_total: 1495000
  training_iteration: 299
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 2605 s, 299 iter, 1495000 ts, -3.77e+06 rew

agent-1: -4856000.00000197
agent-2: -1000.0
agent-3: -4856000.00000197
agent-4: -1000.0
agent-5: -4856000.00000197
Extrinsic Rewards:
-51000
-1000
-51000
-1000
-51000
Sum Reward: -155000
Avg Reward: -31000.0
Min Reward: -51000
Max Reward: -1000
Gini Coefficient: -0.3870967741935484
20:20 Ratio: 0.0196078431372549
Max-min Ratio: 0.0196078431372549
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-55-18
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -3910844.87610046
  episode_reward_min: -33890000.000013836
  episodes_this_iter: 1
  episodes_total: 299
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 3.482
    dispatch_time_ms: 7.703
    learner:
      cur_lr: 0.0012604329967871308
      grad_gnorm: 40.0
      policy_entropy: 0.006774026434868574
      policy_loss: -8.093120574951172
      var_gnorm: 43.34428024291992
      vf_explained_var: 0.0
      vf_loss: 13746407424.0
    num_steps_sampled: 1500000
    num_steps_trained: 1500000
    wait_time_ms: 74.644
  iterations_since_restore: 300
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 2614.7796511650085
  time_this_iter_s: 8.807243347167969
  time_total_s: 2614.7796511650085
  timestamp: 1594860918
  timesteps_since_restore: 1500000
  timesteps_this_iter: 5000
  timesteps_total: 1500000
  training_iteration: 300
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 2614 s, 300 iter, 1500000 ts, -3.91e+06 rew

agent-1: -4149477.121518351
agent-2: -1000.0
agent-3: -4858550.00000134
agent-4: -4858349.00000139
agent-5: -572127.1214233558
Extrinsic Rewards:
-44650
-1000
-51000
-50999
-7300
Sum Reward: -154949
Avg Reward: -30989.8
Min Reward: -51000
Max Reward: -1000
Gini Coefficient: -0.3709581862419248
20:20 Ratio: 0.0196078431372549
Max-min Ratio: 0.0196078431372549
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-55-27
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -4055232.9485299056
  episode_reward_min: -33890000.000013836
  episodes_this_iter: 1
  episodes_total: 300
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 3.108
    dispatch_time_ms: 8.512
    learner:
      cur_lr: 0.0012601000489667058
      grad_gnorm: 40.0
      policy_entropy: 0.006801601033657789
      policy_loss: -8.162245750427246
      var_gnorm: 43.36817932128906
      vf_explained_var: 0.0
      vf_loss: 20488198144.0
    num_steps_sampled: 1505000
    num_steps_trained: 1505000
    wait_time_ms: 74.452
  iterations_since_restore: 301
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 2623.5079367160797
  time_this_iter_s: 8.728285551071167
  time_total_s: 2623.5079367160797
  timestamp: 1594860927
  timesteps_since_restore: 1505000
  timesteps_this_iter: 5000
  timesteps_total: 1505000
  training_iteration: 301
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 2623 s, 301 iter, 1505000 ts, -4.06e+06 rew

agent-1: -1000.0
agent-2: -1000.0
agent-3: -1000.0
agent-4: -1000.0
agent-5: -1000.0
Extrinsic Rewards:
-1000
-1000
-1000
-1000
-1000
Sum Reward: -5000
Avg Reward: -1000.0
Min Reward: -1000
Max Reward: -1000
Gini Coefficient: -0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-55-36
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -4055270.955389281
  episode_reward_min: -33890000.000013836
  episodes_this_iter: 1
  episodes_total: 301
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.883
    dispatch_time_ms: 11.642
    learner:
      cur_lr: 0.001259766984730959
      grad_gnorm: 39.999996185302734
      policy_entropy: 0.006816172040998936
      policy_loss: -8.1624116897583
      var_gnorm: 43.3669548034668
      vf_explained_var: -2.384185791015625e-07
      vf_loss: 20489031680.0
    num_steps_sampled: 1510000
    num_steps_trained: 1510000
    wait_time_ms: 72.492
  iterations_since_restore: 302
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 2632.163707971573
  time_this_iter_s: 8.655771255493164
  time_total_s: 2632.163707971573
  timestamp: 1594860936
  timesteps_since_restore: 1510000
  timesteps_this_iter: 5000
  timesteps_total: 1510000
  training_iteration: 302
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 2632 s, 302 iter, 1510000 ts, -4.06e+06 rew

agent-1: -7258500.000002949
agent-2: -1000.0
agent-3: -1000.0
agent-4: -7258500.000002949
agent-5: -1000.0
Extrinsic Rewards:
-51000
-1000
-1000
-51000
-1000
Sum Reward: -105000
Avg Reward: -21000.0
Min Reward: -51000
Max Reward: -1000
Gini Coefficient: -0.5714285714285714
20:20 Ratio: 0.0196078431372549
Max-min Ratio: 0.0196078431372549
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-55-44
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -4200470.9553893395
  episode_reward_min: -33890000.000013836
  episodes_this_iter: 1
  episodes_total: 302
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.975
    dispatch_time_ms: 8.149
    learner:
      cur_lr: 0.001259434036910534
      grad_gnorm: 40.0
      policy_entropy: 0.006821664981544018
      policy_loss: 0.005348313599824905
      var_gnorm: 43.356327056884766
      vf_explained_var: 0.0
      vf_loss: 3515.22705078125
    num_steps_sampled: 1515000
    num_steps_trained: 1515000
    wait_time_ms: 75.266
  iterations_since_restore: 303
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 2640.8069639205933
  time_this_iter_s: 8.643255949020386
  time_total_s: 2640.8069639205933
  timestamp: 1594860944
  timesteps_since_restore: 1515000
  timesteps_this_iter: 5000
  timesteps_total: 1515000
  training_iteration: 303
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 23.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 2640 s, 303 iter, 1515000 ts, -4.2e+06 rew

agent-1: -1000.0
agent-2: -1000.0
agent-3: -1000.0
agent-4: -1000.0
agent-5: -1000.0
Extrinsic Rewards:
-1000
-1000
-1000
-1000
-1000
Sum Reward: -5000
Avg Reward: -1000.0
Min Reward: -1000
Max Reward: -1000
Gini Coefficient: -0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-55-53
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -4200512.9953893395
  episode_reward_min: -33890000.000013836
  episodes_this_iter: 1
  episodes_total: 303
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 3.212
    dispatch_time_ms: 6.388
    learner:
      cur_lr: 0.001259100972674787
      grad_gnorm: 40.000003814697266
      policy_entropy: 0.006868770811706781
      policy_loss: -8.258424758911133
      var_gnorm: 43.424537658691406
      vf_explained_var: 1.1920928955078125e-07
      vf_loss: 20488994816.0
    num_steps_sampled: 1520000
    num_steps_trained: 1520000
    wait_time_ms: 81.375
  iterations_since_restore: 304
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 2649.606512069702
  time_this_iter_s: 8.799548149108887
  time_total_s: 2649.606512069702
  timestamp: 1594860953
  timesteps_since_restore: 1520000
  timesteps_this_iter: 5000
  timesteps_total: 1520000
  training_iteration: 304
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 23.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 2649 s, 304 iter, 1520000 ts, -4.2e+06 rew

agent-1: -1000.0
agent-2: -7258500.000002949
agent-3: -1000.0
agent-4: -7258500.000002949
agent-5: -1000.0
Extrinsic Rewards:
-1000
-51000
-1000
-51000
-1000
Sum Reward: -105000
Avg Reward: -21000.0
Min Reward: -51000
Max Reward: -1000
Gini Coefficient: -0.5714285714285714
20:20 Ratio: 0.0196078431372549
Max-min Ratio: 0.0196078431372549
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-56-02
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -4345712.995389399
  episode_reward_min: -33890000.000013836
  episodes_this_iter: 1
  episodes_total: 304
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 3.079
    dispatch_time_ms: 10.049
    learner:
      cur_lr: 0.001258768024854362
      grad_gnorm: 40.000003814697266
      policy_entropy: 0.007501511834561825
      policy_loss: -9.056242942810059
      var_gnorm: 44.362667083740234
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 13745795072.0
    num_steps_sampled: 1525000
    num_steps_trained: 1525000
    wait_time_ms: 72.059
  iterations_since_restore: 305
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 2658.1016998291016
  time_this_iter_s: 8.495187759399414
  time_total_s: 2658.1016998291016
  timestamp: 1594860962
  timesteps_since_restore: 1525000
  timesteps_this_iter: 5000
  timesteps_total: 1525000
  training_iteration: 305
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 23.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 2658 s, 305 iter, 1525000 ts, -4.35e+06 rew

agent-1: -1000.0
agent-2: -4856000.00000197
agent-3: -1000.0
agent-4: -4856000.00000197
agent-5: -4856000.00000197
Extrinsic Rewards:
-1000
-51000
-1000
-51000
-51000
Sum Reward: -155000
Avg Reward: -31000.0
Min Reward: -51000
Max Reward: -1000
Gini Coefficient: -0.3870967741935484
20:20 Ratio: 0.0196078431372549
Max-min Ratio: 0.0196078431372549
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-56-10
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -4491406.035389458
  episode_reward_min: -33890000.000013836
  episodes_this_iter: 1
  episodes_total: 305
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.691
    dispatch_time_ms: 7.717
    learner:
      cur_lr: 0.0012584349606186152
      grad_gnorm: 39.999996185302734
      policy_entropy: 0.008375447243452072
      policy_loss: -6.771823406219482
      var_gnorm: 45.34184265136719
      vf_explained_var: 2.384185791015625e-07
      vf_loss: 18153814016.0
    num_steps_sampled: 1530000
    num_steps_trained: 1530000
    wait_time_ms: 75.837
  iterations_since_restore: 306
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 2666.7014331817627
  time_this_iter_s: 8.599733352661133
  time_total_s: 2666.7014331817627
  timestamp: 1594860970
  timesteps_since_restore: 1530000
  timesteps_this_iter: 5000
  timesteps_total: 1530000
  training_iteration: 306
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 24.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 2666 s, 306 iter, 1530000 ts, -4.49e+06 rew

agent-1: -1000.0
agent-2: -1000.0
agent-3: -1000.0
agent-4: -1000.0
agent-5: -9661000.000003938
Extrinsic Rewards:
-1000
-1000
-1000
-1000
-51000
Sum Reward: -55000
Avg Reward: -11000.0
Min Reward: -51000
Max Reward: -1000
Gini Coefficient: -0.7272727272727273
20:20 Ratio: 0.0196078431372549
Max-min Ratio: 0.0196078431372549
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-56-19
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -4588052.055389497
  episode_reward_min: -33890000.000013836
  episodes_this_iter: 1
  episodes_total: 306
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.608
    dispatch_time_ms: 7.116
    learner:
      cur_lr: 0.0012581020127981901
      grad_gnorm: 40.0
      policy_entropy: 0.009624116122722626
      policy_loss: -11.753026008605957
      var_gnorm: 46.34432601928711
      vf_explained_var: 0.0
      vf_loss: 13744648192.0
    num_steps_sampled: 1535000
    num_steps_trained: 1535000
    wait_time_ms: 78.602
  iterations_since_restore: 307
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 2675.4546270370483
  time_this_iter_s: 8.753193855285645
  time_total_s: 2675.4546270370483
  timestamp: 1594860979
  timesteps_since_restore: 1535000
  timesteps_this_iter: 5000
  timesteps_total: 1535000
  training_iteration: 307
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 2675 s, 307 iter, 1535000 ts, -4.59e+06 rew

agent-1: -1000.0
agent-2: -4856000.00000197
agent-3: -1000.0
agent-4: -4856000.00000197
agent-5: -4856000.00000197
Extrinsic Rewards:
-1000
-51000
-1000
-51000
-51000
Sum Reward: -155000
Avg Reward: -31000.0
Min Reward: -51000
Max Reward: -1000
Gini Coefficient: -0.3870967741935484
20:20 Ratio: 0.0196078431372549
Max-min Ratio: 0.0196078431372549
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-56-28
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -4733752.055389555
  episode_reward_min: -33890000.000013836
  episodes_this_iter: 1
  episodes_total: 307
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.743
    dispatch_time_ms: 8.6
    learner:
      cur_lr: 0.0012577689485624433
      grad_gnorm: 40.0
      policy_entropy: 0.011499491520226002
      policy_loss: -14.210162162780762
      var_gnorm: 47.35091781616211
      vf_explained_var: 0.0
      vf_loss: 20486737920.0
    num_steps_sampled: 1540000
    num_steps_trained: 1540000
    wait_time_ms: 76.339
  iterations_since_restore: 308
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 2684.1818935871124
  time_this_iter_s: 8.727266550064087
  time_total_s: 2684.1818935871124
  timestamp: 1594860988
  timesteps_since_restore: 1540000
  timesteps_this_iter: 5000
  timesteps_total: 1540000
  training_iteration: 308
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 2684 s, 308 iter, 1540000 ts, -4.73e+06 rew

agent-1: -1000.0
agent-2: -7258500.000002949
agent-3: -1000.0
agent-4: -7258500.000002949
agent-5: -1000.0
Extrinsic Rewards:
-1000
-51000
-1000
-51000
-1000
Sum Reward: -105000
Avg Reward: -21000.0
Min Reward: -51000
Max Reward: -1000
Gini Coefficient: -0.5714285714285714
20:20 Ratio: 0.0196078431372549
Max-min Ratio: 0.0196078431372549
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-56-36
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -4878950.065389615
  episode_reward_min: -33890000.000013836
  episodes_this_iter: 1
  episodes_total: 308
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.987
    dispatch_time_ms: 10.101
    learner:
      cur_lr: 0.0012574360007420182
      grad_gnorm: 40.0
      policy_entropy: 0.014567451551556587
      policy_loss: -18.241727828979492
      var_gnorm: 48.36250305175781
      vf_explained_var: 1.1920928955078125e-07
      vf_loss: 20485343232.0
    num_steps_sampled: 1545000
    num_steps_trained: 1545000
    wait_time_ms: 72.929
  iterations_since_restore: 309
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 2692.6493752002716
  time_this_iter_s: 8.46748161315918
  time_total_s: 2692.6493752002716
  timestamp: 1594860996
  timesteps_since_restore: 1545000
  timesteps_this_iter: 5000
  timesteps_total: 1545000
  training_iteration: 309
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 2692 s, 309 iter, 1545000 ts, -4.88e+06 rew

agent-1: -4856000.00000197
agent-2: -1000.0
agent-3: -1000.0
agent-4: -4856000.00000197
agent-5: -4856000.00000197
Extrinsic Rewards:
-51000
-1000
-1000
-51000
-51000
Sum Reward: -155000
Avg Reward: -31000.0
Min Reward: -51000
Max Reward: -1000
Gini Coefficient: -0.3870967741935484
20:20 Ratio: 0.0196078431372549
Max-min Ratio: 0.0196078431372549
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-56-45
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -5024643.104764673
  episode_reward_min: -33890000.000013836
  episodes_this_iter: 1
  episodes_total: 309
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.872
    dispatch_time_ms: 7.776
    learner:
      cur_lr: 0.0012571030529215932
      grad_gnorm: 40.0
      policy_entropy: 0.020152106881141663
      policy_loss: -25.922014236450195
      var_gnorm: 49.350669860839844
      vf_explained_var: 1.1920928955078125e-07
      vf_loss: 20485640192.0
    num_steps_sampled: 1550000
    num_steps_trained: 1550000
    wait_time_ms: 74.087
  iterations_since_restore: 310
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 2701.201200723648
  time_this_iter_s: 8.551825523376465
  time_total_s: 2701.201200723648
  timestamp: 1594861005
  timesteps_since_restore: 1550000
  timesteps_this_iter: 5000
  timesteps_total: 1550000
  training_iteration: 310
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 2701 s, 310 iter, 1550000 ts, -5.02e+06 rew

agent-1: -1000.0
agent-2: -1000.0
agent-3: -7258500.000002949
agent-4: -1000.0
agent-5: -7258500.000002949
Extrinsic Rewards:
-1000
-1000
-51000
-1000
-51000
Sum Reward: -105000
Avg Reward: -21000.0
Min Reward: -51000
Max Reward: -1000
Gini Coefficient: -0.5714285714285714
20:20 Ratio: 0.0196078431372549
Max-min Ratio: 0.0196078431372549
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-56-53
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -5169843.1047647325
  episode_reward_min: -33890000.000013836
  episodes_this_iter: 1
  episodes_total: 310
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 3.074
    dispatch_time_ms: 6.515
    learner:
      cur_lr: 0.0012567699886858463
      grad_gnorm: 40.0
      policy_entropy: 0.020525794476270676
      policy_loss: 0.022804658859968185
      var_gnorm: 49.38534927368164
      vf_explained_var: 0.0
      vf_loss: 6107.75830078125
    num_steps_sampled: 1555000
    num_steps_trained: 1555000
    wait_time_ms: 73.481
  iterations_since_restore: 311
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 2709.682029247284
  time_this_iter_s: 8.480828523635864
  time_total_s: 2709.682029247284
  timestamp: 1594861013
  timesteps_since_restore: 1555000
  timesteps_this_iter: 5000
  timesteps_total: 1555000
  training_iteration: 311
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 2709 s, 311 iter, 1555000 ts, -5.17e+06 rew

agent-1: -1000.0
agent-2: -1000.0
agent-3: -1000.0
agent-4: -1000.0
agent-5: -1000.0
Extrinsic Rewards:
-1000
-1000
-1000
-1000
-1000
Sum Reward: -5000
Avg Reward: -1000.0
Min Reward: -1000
Max Reward: -1000
Gini Coefficient: -0.0
20:20 Ratio: 1.0
Max-min Ratio: 1.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-57-02
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -5169887.134764732
  episode_reward_min: -33890000.000013836
  episodes_this_iter: 1
  episodes_total: 311
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.517
    dispatch_time_ms: 5.933
    learner:
      cur_lr: 0.0012564370408654213
      grad_gnorm: 40.0
      policy_entropy: 0.02095496468245983
      policy_loss: -34.36164093017578
      var_gnorm: 49.43585968017578
      vf_explained_var: 1.1920928955078125e-07
      vf_loss: 38270603264.0
    num_steps_sampled: 1560000
    num_steps_trained: 1560000
    wait_time_ms: 73.948
  iterations_since_restore: 312
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 2718.2153401374817
  time_this_iter_s: 8.533310890197754
  time_total_s: 2718.2153401374817
  timestamp: 1594861022
  timesteps_since_restore: 1560000
  timesteps_this_iter: 5000
  timesteps_total: 1560000
  training_iteration: 312
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 2718 s, 312 iter, 1560000 ts, -5.17e+06 rew

agent-1: -7258500.000002949
agent-2: -1000.0
agent-3: -1000.0
agent-4: -1000.0
agent-5: -26578500.000010803
Extrinsic Rewards:
-51000
-1000
-1000
-1000
-151000
Sum Reward: -205000
Avg Reward: -41000.0
Min Reward: -151000
Max Reward: -1000
Gini Coefficient: -0.6829268292682927
20:20 Ratio: 0.006622516556291391
Max-min Ratio: 0.006622516556291391
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-57-11
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -5508283.154764869
  episode_reward_min: -33890000.000013836
  episodes_this_iter: 1
  episodes_total: 312
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.55
    dispatch_time_ms: 7.428
    learner:
      cur_lr: 0.0012561039766296744
      grad_gnorm: 40.0
      policy_entropy: 0.034732040017843246
      policy_loss: -78.05856323242188
      var_gnorm: 50.45303726196289
      vf_explained_var: 5.960464477539063e-08
      vf_loss: 65924628480.0
    num_steps_sampled: 1565000
    num_steps_trained: 1565000
    wait_time_ms: 76.239
  iterations_since_restore: 313
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 2726.8536179065704
  time_this_iter_s: 8.638277769088745
  time_total_s: 2726.8536179065704
  timestamp: 1594861031
  timesteps_since_restore: 1565000
  timesteps_this_iter: 5000
  timesteps_total: 1565000
  training_iteration: 313
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 2726 s, 313 iter, 1565000 ts, -5.51e+06 rew

agent-1: -7256226.619600334
agent-2: -1014.922016124927
agent-3: -16894952.748603687
agent-4: -1014.922016124927
agent-5: -999.0
Extrinsic Rewards:
-50950
-1000
-100300
-1000
-999
Sum Reward: -154249
Avg Reward: -30849.8
Min Reward: -100300
Max Reward: -999
Gini Coefficient: -0.6445474524956402
20:20 Ratio: 0.00996011964107677
Max-min Ratio: 0.00996011964107677
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-57-19
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -5749816.286887233
  episode_reward_min: -33890000.000013836
  episodes_this_iter: 1
  episodes_total: 313
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.64
    dispatch_time_ms: 6.257
    learner:
      cur_lr: 0.0012557710288092494
      grad_gnorm: 40.0
      policy_entropy: 0.14465346932411194
      policy_loss: -236.15060424804688
      var_gnorm: 51.53150939941406
      vf_explained_var: 0.0
      vf_loss: 18386685952.0
    num_steps_sampled: 1570000
    num_steps_trained: 1570000
    wait_time_ms: 78.547
  iterations_since_restore: 314
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 2735.544973373413
  time_this_iter_s: 8.691355466842651
  time_total_s: 2735.544973373413
  timestamp: 1594861039
  timesteps_since_restore: 1570000
  timesteps_this_iter: 5000
  timesteps_total: 1570000
  training_iteration: 314
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 2735 s, 314 iter, 1570000 ts, -5.75e+06 rew

agent-1: -7258500.000002949
agent-2: -1000.0
agent-3: -1000.0
agent-4: -1000.0
agent-5: -7258500.000002949
Extrinsic Rewards:
-51000
-1000
-1000
-1000
-51000
Sum Reward: -105000
Avg Reward: -21000.0
Min Reward: -51000
Max Reward: -1000
Gini Coefficient: -0.5714285714285714
20:20 Ratio: 0.0196078431372549
Max-min Ratio: 0.0196078431372549
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-57-28
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -5895012.306887291
  episode_reward_min: -33890000.000013836
  episodes_this_iter: 1
  episodes_total: 314
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.942
    dispatch_time_ms: 7.321
    learner:
      cur_lr: 0.0012554379645735025
      grad_gnorm: 39.999996185302734
      policy_entropy: 0.009541948325932026
      policy_loss: 0.007777096703648567
      var_gnorm: 52.543365478515625
      vf_explained_var: 0.0
      vf_loss: 7370.91552734375
    num_steps_sampled: 1575000
    num_steps_trained: 1575000
    wait_time_ms: 70.241
  iterations_since_restore: 315
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 2743.869753599167
  time_this_iter_s: 8.324780225753784
  time_total_s: 2743.869753599167
  timestamp: 1594861048
  timesteps_since_restore: 1575000
  timesteps_this_iter: 5000
  timesteps_total: 1575000
  training_iteration: 315
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 2743 s, 315 iter, 1575000 ts, -5.9e+06 rew

agent-1: -224.7362876246879
agent-2: -326.7362873151506
agent-3: -1092366.141404939
agent-4: -3239364.9986100798
agent-5: -1099765.1414136407
Extrinsic Rewards:
-211
-213
-11017
-21715
-11066
Sum Reward: -44222
Avg Reward: -8844.4
Min Reward: -21715
Max Reward: -211
Gini Coefficient: -0.4871873728008683
20:20 Ratio: 0.009716785632051578
Max-min Ratio: 0.009716785632051578
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-57-36
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -5949325.824427328
  episode_reward_min: -33890000.000013836
  episodes_this_iter: 1
  episodes_total: 315
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.902
    dispatch_time_ms: 8.057
    learner:
      cur_lr: 0.0012551050167530775
      grad_gnorm: 40.0
      policy_entropy: 0.008272111415863037
      policy_loss: 0.012882065959274769
      var_gnorm: 51.610107421875
      vf_explained_var: 0.0
      vf_loss: 13089.4912109375
    num_steps_sampled: 1580000
    num_steps_trained: 1580000
    wait_time_ms: 71.898
  iterations_since_restore: 316
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 2752.008541584015
  time_this_iter_s: 8.138787984848022
  time_total_s: 2752.008541584015
  timestamp: 1594861056
  timesteps_since_restore: 1580000
  timesteps_this_iter: 5000
  timesteps_total: 1580000
  training_iteration: 316
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 2752 s, 316 iter, 1580000 ts, -5.95e+06 rew

agent-1: -593.3604553916175
agent-2: -1437893.999849157
agent-3: -384.4504734727579
agent-4: -289.70970947702693
agent-5: -331.25544301665855
Extrinsic Rewards:
-143
-7294
-141
-140
-140
Sum Reward: -7858
Avg Reward: -1571.6
Min Reward: -7294
Max Reward: -140
Gini Coefficient: -0.7284805293967931
20:20 Ratio: 0.019193857965451054
Max-min Ratio: 0.019193857965451054
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-57-44
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -5963714.782186633
  episode_reward_min: -33890000.000013836
  episodes_this_iter: 1
  episodes_total: 316
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.658
    dispatch_time_ms: 9.824
    learner:
      cur_lr: 0.0012547719525173306
      grad_gnorm: 39.999996185302734
      policy_entropy: 0.007354613393545151
      policy_loss: 0.010997320525348186
      var_gnorm: 50.60846710205078
      vf_explained_var: 0.0
      vf_loss: 12392.15625
    num_steps_sampled: 1585000
    num_steps_trained: 1585000
    wait_time_ms: 69.03
  iterations_since_restore: 317
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 2760.229208946228
  time_this_iter_s: 8.220667362213135
  time_total_s: 2760.229208946228
  timestamp: 1594861064
  timesteps_since_restore: 1585000
  timesteps_this_iter: 5000
  timesteps_total: 1585000
  training_iteration: 317
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 2760 s, 317 iter, 1585000 ts, -5.96e+06 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-57-52
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -5963706.792811633
  episode_reward_min: -33890000.000013836
  episodes_this_iter: 1
  episodes_total: 317
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 3.048
    dispatch_time_ms: 8.067
    learner:
      cur_lr: 0.0012544390046969056
      grad_gnorm: 40.0
      policy_entropy: 0.006653188727796078
      policy_loss: 0.009555898606777191
      var_gnorm: 49.62581253051758
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 11721.2802734375
    num_steps_sampled: 1590000
    num_steps_trained: 1590000
    wait_time_ms: 71.347
  iterations_since_restore: 318
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 2768.2978117465973
  time_this_iter_s: 8.068602800369263
  time_total_s: 2768.2978117465973
  timestamp: 1594861072
  timesteps_since_restore: 1590000
  timesteps_this_iter: 5000
  timesteps_total: 1590000
  training_iteration: 318
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 2768 s, 318 iter, 1590000 ts, -5.96e+06 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-58-01
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -5963706.792811633
  episode_reward_min: -33890000.000013836
  episodes_this_iter: 1
  episodes_total: 318
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.512
    dispatch_time_ms: 9.271
    learner:
      cur_lr: 0.0012541060568764806
      grad_gnorm: 40.0
      policy_entropy: 0.006108696572482586
      policy_loss: 0.008484802208840847
      var_gnorm: 48.63307571411133
      vf_explained_var: 0.0
      vf_loss: 11056.5439453125
    num_steps_sampled: 1595000
    num_steps_trained: 1595000
    wait_time_ms: 68.395
  iterations_since_restore: 319
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 2776.486742258072
  time_this_iter_s: 8.18893051147461
  time_total_s: 2776.486742258072
  timestamp: 1594861081
  timesteps_since_restore: 1595000
  timesteps_this_iter: 5000
  timesteps_total: 1595000
  training_iteration: 319
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 2776 s, 319 iter, 1595000 ts, -5.96e+06 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-58-09
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -5963706.792811633
  episode_reward_min: -33890000.000013836
  episodes_this_iter: 1
  episodes_total: 319
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.515
    dispatch_time_ms: 7.291
    learner:
      cur_lr: 0.0012537729926407337
      grad_gnorm: 39.999996185302734
      policy_entropy: 0.0031941449269652367
      policy_loss: 0.004008748102933168
      var_gnorm: 47.66717529296875
      vf_explained_var: 0.0
      vf_loss: 10424.4306640625
    num_steps_sampled: 1600000
    num_steps_trained: 1600000
    wait_time_ms: 73.249
  iterations_since_restore: 320
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 2784.971358060837
  time_this_iter_s: 8.484615802764893
  time_total_s: 2784.971358060837
  timestamp: 1594861089
  timesteps_since_restore: 1600000
  timesteps_this_iter: 5000
  timesteps_total: 1600000
  training_iteration: 320
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 2784 s, 320 iter, 1600000 ts, -5.96e+06 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-58-17
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -5963695.813436633
  episode_reward_min: -33890000.000013836
  episodes_this_iter: 1
  episodes_total: 320
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.851
    dispatch_time_ms: 8.707
    learner:
      cur_lr: 0.0012534400448203087
      grad_gnorm: 40.0
      policy_entropy: 0.0016887650126591325
      policy_loss: 0.001998160732910037
      var_gnorm: 46.692142486572266
      vf_explained_var: 0.0
      vf_loss: 9798.9580078125
    num_steps_sampled: 1605000
    num_steps_trained: 1605000
    wait_time_ms: 74.17
  iterations_since_restore: 321
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 2793.1700098514557
  time_this_iter_s: 8.198651790618896
  time_total_s: 2793.1700098514557
  timestamp: 1594861097
  timesteps_since_restore: 1605000
  timesteps_this_iter: 5000
  timesteps_total: 1605000
  training_iteration: 321
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 2793 s, 321 iter, 1605000 ts, -5.96e+06 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-58-26
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -5963686.863436634
  episode_reward_min: -33890000.000013836
  episodes_this_iter: 1
  episodes_total: 321
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 3.182
    dispatch_time_ms: 9.95
    learner:
      cur_lr: 0.0012531069805845618
      grad_gnorm: 39.999996185302734
      policy_entropy: 0.0016791548114269972
      policy_loss: 0.0019349586218595505
      var_gnorm: 45.74178695678711
      vf_explained_var: 0.0
      vf_loss: 9199.23828125
    num_steps_sampled: 1610000
    num_steps_trained: 1610000
    wait_time_ms: 70.246
  iterations_since_restore: 322
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 2801.3416743278503
  time_this_iter_s: 8.171664476394653
  time_total_s: 2801.3416743278503
  timestamp: 1594861106
  timesteps_since_restore: 1610000
  timesteps_this_iter: 5000
  timesteps_total: 1610000
  training_iteration: 322
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 2801 s, 322 iter, 1610000 ts, -5.96e+06 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-58-34
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -5963680.893436633
  episode_reward_min: -33890000.000013836
  episodes_this_iter: 1
  episodes_total: 322
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.578
    dispatch_time_ms: 6.266
    learner:
      cur_lr: 0.0012527740327641368
      grad_gnorm: 40.00000762939453
      policy_entropy: 0.001669584191404283
      policy_loss: 0.0018718037754297256
      var_gnorm: 44.80303955078125
      vf_explained_var: 0.0
      vf_loss: 8618.8720703125
    num_steps_sampled: 1615000
    num_steps_trained: 1615000
    wait_time_ms: 73.529
  iterations_since_restore: 323
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 2809.550497531891
  time_this_iter_s: 8.208823204040527
  time_total_s: 2809.550497531891
  timestamp: 1594861114
  timesteps_since_restore: 1615000
  timesteps_this_iter: 5000
  timesteps_total: 1615000
  training_iteration: 323
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 2809 s, 323 iter, 1615000 ts, -5.96e+06 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-58-42
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -5963672.933436633
  episode_reward_min: -33890000.000013836
  episodes_this_iter: 1
  episodes_total: 323
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.939
    dispatch_time_ms: 7.98
    learner:
      cur_lr: 0.00125244096852839
      grad_gnorm: 40.00000762939453
      policy_entropy: 0.001659194938838482
      policy_loss: 0.0018121524481102824
      var_gnorm: 43.87636947631836
      vf_explained_var: 0.0
      vf_loss: 8057.6181640625
    num_steps_sampled: 1620000
    num_steps_trained: 1620000
    wait_time_ms: 70.913
  iterations_since_restore: 324
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 2817.7036612033844
  time_this_iter_s: 8.15316367149353
  time_total_s: 2817.7036612033844
  timestamp: 1594861122
  timesteps_since_restore: 1620000
  timesteps_this_iter: 5000
  timesteps_total: 1620000
  training_iteration: 324
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 2817 s, 324 iter, 1620000 ts, -5.96e+06 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-58-50
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -5963664.983436633
  episode_reward_min: -33890000.000013836
  episodes_this_iter: 1
  episodes_total: 324
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 3.355
    dispatch_time_ms: 8.138
    learner:
      cur_lr: 0.001252108020707965
      grad_gnorm: 40.0
      policy_entropy: 0.0016487735556438565
      policy_loss: 0.001751395408064127
      var_gnorm: 42.962646484375
      vf_explained_var: 0.0
      vf_loss: 7515.72900390625
    num_steps_sampled: 1625000
    num_steps_trained: 1625000
    wait_time_ms: 69.479
  iterations_since_restore: 325
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 2825.763357400894
  time_this_iter_s: 8.059696197509766
  time_total_s: 2825.763357400894
  timestamp: 1594861130
  timesteps_since_restore: 1625000
  timesteps_this_iter: 5000
  timesteps_total: 1625000
  training_iteration: 325
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 2825 s, 325 iter, 1625000 ts, -5.96e+06 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-58-58
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -5963659.013436633
  episode_reward_min: -33890000.000013836
  episodes_this_iter: 1
  episodes_total: 325
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.57
    dispatch_time_ms: 6.365
    learner:
      cur_lr: 0.001251774956472218
      grad_gnorm: 40.0
      policy_entropy: 0.0016374862752854824
      policy_loss: 0.0016883363714441657
      var_gnorm: 42.06244659423828
      vf_explained_var: 5.960464477539063e-08
      vf_loss: 6992.85791015625
    num_steps_sampled: 1630000
    num_steps_trained: 1630000
    wait_time_ms: 72.666
  iterations_since_restore: 326
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 2833.9683561325073
  time_this_iter_s: 8.20499873161316
  time_total_s: 2833.9683561325073
  timestamp: 1594861138
  timesteps_since_restore: 1630000
  timesteps_this_iter: 5000
  timesteps_total: 1630000
  training_iteration: 326
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 2833 s, 326 iter, 1630000 ts, -5.96e+06 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-59-06
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -5963659.013436633
  episode_reward_min: -33890000.000013836
  episodes_this_iter: 1
  episodes_total: 326
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.707
    dispatch_time_ms: 9.639
    learner:
      cur_lr: 0.001251442008651793
      grad_gnorm: 40.0
      policy_entropy: 0.0016263083089143038
      policy_loss: 0.0016264896839857101
      var_gnorm: 41.176788330078125
      vf_explained_var: 0.0
      vf_loss: 6489.2548828125
    num_steps_sampled: 1635000
    num_steps_trained: 1635000
    wait_time_ms: 69.391
  iterations_since_restore: 327
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 2842.1293580532074
  time_this_iter_s: 8.161001920700073
  time_total_s: 2842.1293580532074
  timestamp: 1594861146
  timesteps_since_restore: 1635000
  timesteps_this_iter: 5000
  timesteps_total: 1635000
  training_iteration: 327
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 2842 s, 327 iter, 1635000 ts, -5.96e+06 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-59-15
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -5963659.013436633
  episode_reward_min: -33890000.000013836
  episodes_this_iter: 1
  episodes_total: 327
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.699
    dispatch_time_ms: 10.896
    learner:
      cur_lr: 0.0012511089444160461
      grad_gnorm: 39.999996185302734
      policy_entropy: 0.0016143082175403833
      policy_loss: 0.00156296044588089
      var_gnorm: 40.31496810913086
      vf_explained_var: 0.0
      vf_loss: 6009.33251953125
    num_steps_sampled: 1640000
    num_steps_trained: 1640000
    wait_time_ms: 65.816
  iterations_since_restore: 328
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 2850.2355260849
  time_this_iter_s: 8.106168031692505
  time_total_s: 2850.2355260849
  timestamp: 1594861155
  timesteps_since_restore: 1640000
  timesteps_this_iter: 5000
  timesteps_total: 1640000
  training_iteration: 328
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 2850 s, 328 iter, 1640000 ts, -5.96e+06 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-59-23
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -5963659.013436633
  episode_reward_min: -33890000.000013836
  episodes_this_iter: 1
  episodes_total: 328
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 3.178
    dispatch_time_ms: 7.89
    learner:
      cur_lr: 0.0012507759965956211
      grad_gnorm: 40.0
      policy_entropy: 0.0015962577890604734
      policy_loss: 0.0014226667117327452
      var_gnorm: 39.452247619628906
      vf_explained_var: 5.960464477539063e-08
      vf_loss: 5538.96728515625
    num_steps_sampled: 1645000
    num_steps_trained: 1645000
    wait_time_ms: 70.921
  iterations_since_restore: 329
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 2858.4090774059296
  time_this_iter_s: 8.173551321029663
  time_total_s: 2858.4090774059296
  timestamp: 1594861163
  timesteps_since_restore: 1645000
  timesteps_this_iter: 5000
  timesteps_total: 1645000
  training_iteration: 329
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 2858 s, 329 iter, 1645000 ts, -5.96e+06 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-59-31
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -5963653.028436634
  episode_reward_min: -33890000.000013836
  episodes_this_iter: 1
  episodes_total: 329
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 3.221
    dispatch_time_ms: 9.499
    learner:
      cur_lr: 0.001250443048775196
      grad_gnorm: 39.999996185302734
      policy_entropy: 0.0015835323138162494
      policy_loss: 0.0013652449706569314
      var_gnorm: 38.61531066894531
      vf_explained_var: 0.0
      vf_loss: 5092.33935546875
    num_steps_sampled: 1650000
    num_steps_trained: 1650000
    wait_time_ms: 67.902
  iterations_since_restore: 330
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 2866.537723302841
  time_this_iter_s: 8.128645896911621
  time_total_s: 2866.537723302841
  timestamp: 1594861171
  timesteps_since_restore: 1650000
  timesteps_this_iter: 5000
  timesteps_total: 1650000
  training_iteration: 330
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 2866 s, 330 iter, 1650000 ts, -5.96e+06 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-59-39
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -5963646.067811633
  episode_reward_min: -33890000.000013836
  episodes_this_iter: 1
  episodes_total: 330
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.898
    dispatch_time_ms: 6.156
    learner:
      cur_lr: 0.0012501099845394492
      grad_gnorm: 40.000003814697266
      policy_entropy: 0.0015709723811596632
      policy_loss: 0.0013045506784692407
      var_gnorm: 37.79682159423828
      vf_explained_var: 0.0
      vf_loss: 4664.599609375
    num_steps_sampled: 1655000
    num_steps_trained: 1655000
    wait_time_ms: 77.922
  iterations_since_restore: 331
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 2874.738374710083
  time_this_iter_s: 8.200651407241821
  time_total_s: 2874.738374710083
  timestamp: 1594861179
  timesteps_since_restore: 1655000
  timesteps_this_iter: 5000
  timesteps_total: 1655000
  training_iteration: 331
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 2874 s, 331 iter, 1655000 ts, -5.96e+06 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-59-47
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -5963646.067811633
  episode_reward_min: -33890000.000013836
  episodes_this_iter: 1
  episodes_total: 331
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.73
    dispatch_time_ms: 7.461
    learner:
      cur_lr: 0.0012497770367190242
      grad_gnorm: 40.0
      policy_entropy: 0.0015514716506004333
      policy_loss: 0.0011789303971454501
      var_gnorm: 36.99773025512695
      vf_explained_var: 1.1920928955078125e-07
      vf_loss: 4255.88525390625
    num_steps_sampled: 1660000
    num_steps_trained: 1660000
    wait_time_ms: 73.066
  iterations_since_restore: 332
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 2882.936535358429
  time_this_iter_s: 8.198160648345947
  time_total_s: 2882.936535358429
  timestamp: 1594861187
  timesteps_since_restore: 1660000
  timesteps_this_iter: 5000
  timesteps_total: 1660000
  training_iteration: 332
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 2882 s, 332 iter, 1660000 ts, -5.96e+06 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-59-56
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -5963646.067811633
  episode_reward_min: -33890000.000013836
  episodes_this_iter: 1
  episodes_total: 332
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.799
    dispatch_time_ms: 7.983
    learner:
      cur_lr: 0.0012494439724832773
      grad_gnorm: 40.0
      policy_entropy: 0.0015384044963866472
      policy_loss: 0.0011216594139114022
      var_gnorm: 36.219482421875
      vf_explained_var: 1.1920928955078125e-07
      vf_loss: 3865.99365234375
    num_steps_sampled: 1665000
    num_steps_trained: 1665000
    wait_time_ms: 71.23
  iterations_since_restore: 333
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 2891.089416027069
  time_this_iter_s: 8.152880668640137
  time_total_s: 2891.089416027069
  timestamp: 1594861196
  timesteps_since_restore: 1665000
  timesteps_this_iter: 5000
  timesteps_total: 1665000
  training_iteration: 333
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 2891 s, 333 iter, 1665000 ts, -5.96e+06 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-00-04
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -5963633.121577258
  episode_reward_min: -33890000.000013836
  episodes_this_iter: 2
  episodes_total: 334
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 3.348
    dispatch_time_ms: 9.058
    learner:
      cur_lr: 0.0012491110246628523
      grad_gnorm: 40.0
      policy_entropy: 0.00318641378544271
      policy_loss: -0.0014631017111241817
      var_gnorm: 35.46316909790039
      vf_explained_var: -1.0
      vf_loss: 2866.072998046875
    num_steps_sampled: 1670000
    num_steps_trained: 1670000
    wait_time_ms: 69.089
  iterations_since_restore: 334
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 2899.2651512622833
  time_this_iter_s: 8.175735235214233
  time_total_s: 2899.2651512622833
  timestamp: 1594861204
  timesteps_since_restore: 1670000
  timesteps_this_iter: 5000
  timesteps_total: 1670000
  training_iteration: 334
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 2899 s, 334 iter, 1670000 ts, -5.96e+06 rew

Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-00-12
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -5963633.121577258
  episode_reward_min: -33890000.000013836
  episodes_this_iter: 0
  episodes_total: 334
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.647
    dispatch_time_ms: 9.482
    learner:
      cur_lr: 0.0012487779604271054
      grad_gnorm: 40.0
      policy_entropy: 0.0015101570170372725
      policy_loss: 0.001012365217320621
      var_gnorm: 34.730403900146484
      vf_explained_var: 0.0
      vf_loss: 3142.87646484375
    num_steps_sampled: 1675000
    num_steps_trained: 1675000
    wait_time_ms: 70.089
  iterations_since_restore: 335
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 2907.384343624115
  time_this_iter_s: 8.119192361831665
  time_total_s: 2907.384343624115
  timestamp: 1594861212
  timesteps_since_restore: 1675000
  timesteps_this_iter: 5000
  timesteps_total: 1675000
  training_iteration: 335
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 2907 s, 335 iter, 1675000 ts, -5.96e+06 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-00-20
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -5963625.161577258
  episode_reward_min: -33890000.000013836
  episodes_this_iter: 2
  episodes_total: 336
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 3.064
    dispatch_time_ms: 10.09
    learner:
      cur_lr: 0.0012484450126066804
      grad_gnorm: 39.999996185302734
      policy_entropy: 0.0014948933385312557
      policy_loss: 0.01791415549814701
      var_gnorm: 34.02244186401367
      vf_explained_var: -1.0
      vf_loss: 781223.5625
    num_steps_sampled: 1680000
    num_steps_trained: 1680000
    wait_time_ms: 69.429
  iterations_since_restore: 336
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 2915.5136954784393
  time_this_iter_s: 8.12935185432434
  time_total_s: 2915.5136954784393
  timestamp: 1594861220
  timesteps_since_restore: 1680000
  timesteps_this_iter: 5000
  timesteps_total: 1680000
  training_iteration: 336
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 2915 s, 336 iter, 1680000 ts, -5.96e+06 rew

Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-00-28
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -5963625.161577258
  episode_reward_min: -33890000.000013836
  episodes_this_iter: 0
  episodes_total: 336
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.551
    dispatch_time_ms: 7.475
    learner:
      cur_lr: 0.0012481119483709335
      grad_gnorm: 40.0
      policy_entropy: 0.001474212040193379
      policy_loss: 0.0008505387231707573
      var_gnorm: 33.34770202636719
      vf_explained_var: 0.0
      vf_loss: 2498.0361328125
    num_steps_sampled: 1685000
    num_steps_trained: 1685000
    wait_time_ms: 71.598
  iterations_since_restore: 337
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 2923.6464512348175
  time_this_iter_s: 8.132755756378174
  time_total_s: 2923.6464512348175
  timestamp: 1594861228
  timesteps_since_restore: 1685000
  timesteps_this_iter: 5000
  timesteps_total: 1685000
  training_iteration: 337
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 2923 s, 337 iter, 1685000 ts, -5.96e+06 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-00-36
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -5963612.153436635
  episode_reward_min: -33890000.000013836
  episodes_this_iter: 2
  episodes_total: 338
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.893
    dispatch_time_ms: 6.631
    learner:
      cur_lr: 0.0012477790005505085
      grad_gnorm: 40.0
      policy_entropy: 0.00145843590144068
      policy_loss: 0.014925096184015274
      var_gnorm: 32.69394302368164
      vf_explained_var: -1.0
      vf_loss: 612315.125
    num_steps_sampled: 1690000
    num_steps_trained: 1690000
    wait_time_ms: 72.324
  iterations_since_restore: 338
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 2931.799827337265
  time_this_iter_s: 8.15337610244751
  time_total_s: 2931.799827337265
  timestamp: 1594861236
  timesteps_since_restore: 1690000
  timesteps_this_iter: 5000
  timesteps_total: 1690000
  training_iteration: 338
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 2931 s, 338 iter, 1690000 ts, -5.96e+06 rew

Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-00-45
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -5963612.153436635
  episode_reward_min: -33890000.000013836
  episodes_this_iter: 0
  episodes_total: 338
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.719
    dispatch_time_ms: 10.185
    learner:
      cur_lr: 0.0012474460527300835
      grad_gnorm: 40.0
      policy_entropy: 0.0014428741997107863
      policy_loss: 0.0007472984725609422
      var_gnorm: 32.063865661621094
      vf_explained_var: 5.960464477539063e-08
      vf_loss: 1922.175537109375
    num_steps_sampled: 1695000
    num_steps_trained: 1695000
    wait_time_ms: 68.378
  iterations_since_restore: 339
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 2939.9566144943237
  time_this_iter_s: 8.156787157058716
  time_total_s: 2939.9566144943237
  timestamp: 1594861245
  timesteps_since_restore: 1695000
  timesteps_this_iter: 5000
  timesteps_total: 1695000
  training_iteration: 339
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 2939 s, 339 iter, 1695000 ts, -5.96e+06 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-00-53
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -5963594.238436635
  episode_reward_min: -33890000.000013836
  episodes_this_iter: 2
  episodes_total: 340
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.525
    dispatch_time_ms: 8.647
    learner:
      cur_lr: 0.0012471129884943366
      grad_gnorm: 39.999996185302734
      policy_entropy: 0.0014260958414524794
      policy_loss: 0.012976556085050106
      var_gnorm: 31.471494674682617
      vf_explained_var: -1.0
      vf_loss: 462662.84375
    num_steps_sampled: 1700000
    num_steps_trained: 1700000
    wait_time_ms: 72.099
  iterations_since_restore: 340
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 2948.0836927890778
  time_this_iter_s: 8.127078294754028
  time_total_s: 2948.0836927890778
  timestamp: 1594861253
  timesteps_since_restore: 1700000
  timesteps_this_iter: 5000
  timesteps_total: 1700000
  training_iteration: 340
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 2948 s, 340 iter, 1700000 ts, -5.96e+06 rew

Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-01-01
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -5963594.238436635
  episode_reward_min: -33890000.000013836
  episodes_this_iter: 0
  episodes_total: 340
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.929
    dispatch_time_ms: 7.374
    learner:
      cur_lr: 0.0012467800406739116
      grad_gnorm: 40.000003814697266
      policy_entropy: 0.0014097035164013505
      policy_loss: 0.0006407650071196258
      var_gnorm: 30.912397384643555
      vf_explained_var: 0.0
      vf_loss: 1424.27880859375
    num_steps_sampled: 1705000
    num_steps_trained: 1705000
    wait_time_ms: 72.02
  iterations_since_restore: 341
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 2956.297779560089
  time_this_iter_s: 8.214086771011353
  time_total_s: 2956.297779560089
  timestamp: 1594861261
  timesteps_since_restore: 1705000
  timesteps_this_iter: 5000
  timesteps_total: 1705000
  training_iteration: 341
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 2956 s, 341 iter, 1705000 ts, -5.96e+06 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-01-09
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -5963592.248436634
  episode_reward_min: -33890000.000013836
  episodes_this_iter: 2
  episodes_total: 342
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.738
    dispatch_time_ms: 7.645
    learner:
      cur_lr: 0.0012464469764381647
      grad_gnorm: 40.0
      policy_entropy: 0.002932970644906163
      policy_loss: -0.0008455304196104407
      var_gnorm: 30.388174057006836
      vf_explained_var: -1.0
      vf_loss: 1007.17626953125
    num_steps_sampled: 1710000
    num_steps_trained: 1710000
    wait_time_ms: 70.061
  iterations_since_restore: 342
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 2964.4642221927643
  time_this_iter_s: 8.166442632675171
  time_total_s: 2964.4642221927643
  timestamp: 1594861269
  timesteps_since_restore: 1710000
  timesteps_this_iter: 5000
  timesteps_total: 1710000
  training_iteration: 342
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 2964 s, 342 iter, 1710000 ts, -5.96e+06 rew

Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-01-17
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -5963592.248436634
  episode_reward_min: -33890000.000013836
  episodes_this_iter: 0
  episodes_total: 342
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 3.121
    dispatch_time_ms: 8.097
    learner:
      cur_lr: 0.0012461140286177397
      grad_gnorm: 40.0
      policy_entropy: 0.001374492421746254
      policy_loss: 0.000541091721970588
      var_gnorm: 29.900779724121094
      vf_explained_var: 0.0
      vf_loss: 1001.1281127929688
    num_steps_sampled: 1715000
    num_steps_trained: 1715000
    wait_time_ms: 69.019
  iterations_since_restore: 343
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 2972.5886561870575
  time_this_iter_s: 8.124433994293213
  time_total_s: 2972.5886561870575
  timestamp: 1594861277
  timesteps_since_restore: 1715000
  timesteps_this_iter: 5000
  timesteps_total: 1715000
  training_iteration: 343
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 2972 s, 343 iter, 1715000 ts, -5.96e+06 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-01-26
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -5963586.278436635
  episode_reward_min: -33890000.000013836
  episodes_this_iter: 1
  episodes_total: 343
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.88
    dispatch_time_ms: 8.933
    learner:
      cur_lr: 0.0012457809643819928
      grad_gnorm: 39.999996185302734
      policy_entropy: 0.0013500163331627846
      policy_loss: 0.000456936308182776
      var_gnorm: 29.45181655883789
      vf_explained_var: 0.0
      vf_loss: 817.53076171875
    num_steps_sampled: 1720000
    num_steps_trained: 1720000
    wait_time_ms: 71.267
  iterations_since_restore: 344
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 2980.742565393448
  time_this_iter_s: 8.15390920639038
  time_total_s: 2980.742565393448
  timestamp: 1594861286
  timesteps_since_restore: 1720000
  timesteps_this_iter: 5000
  timesteps_total: 1720000
  training_iteration: 344
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 2980 s, 344 iter, 1720000 ts, -5.96e+06 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-01-34
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -5963582.298436634
  episode_reward_min: -33890000.000013836
  episodes_this_iter: 1
  episodes_total: 344
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.889
    dispatch_time_ms: 8.705
    learner:
      cur_lr: 0.0012454480165615678
      grad_gnorm: 39.999996185302734
      policy_entropy: 0.0013323661405593157
      policy_loss: 0.00040752594941295683
      var_gnorm: 29.04322624206543
      vf_explained_var: 0.0
      vf_loss: 652.5687866210938
    num_steps_sampled: 1725000
    num_steps_trained: 1725000
    wait_time_ms: 70.17
  iterations_since_restore: 345
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 2988.9680111408234
  time_this_iter_s: 8.225445747375488
  time_total_s: 2988.9680111408234
  timestamp: 1594861294
  timesteps_since_restore: 1725000
  timesteps_this_iter: 5000
  timesteps_total: 1725000
  training_iteration: 345
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 2988 s, 345 iter, 1725000 ts, -5.96e+06 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-01-42
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -5963578.318436635
  episode_reward_min: -33890000.000013836
  episodes_this_iter: 1
  episodes_total: 345
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.789
    dispatch_time_ms: 9.453
    learner:
      cur_lr: 0.001245114952325821
      grad_gnorm: 40.0
      policy_entropy: 0.001313233864493668
      policy_loss: 0.0003617606416810304
      var_gnorm: 28.676509857177734
      vf_explained_var: 0.0
      vf_loss: 506.2127685546875
    num_steps_sampled: 1730000
    num_steps_trained: 1730000
    wait_time_ms: 73.363
  iterations_since_restore: 346
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 2997.1311540603638
  time_this_iter_s: 8.163142919540405
  time_total_s: 2997.1311540603638
  timestamp: 1594861302
  timesteps_since_restore: 1730000
  timesteps_this_iter: 5000
  timesteps_total: 1730000
  training_iteration: 346
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 2997 s, 346 iter, 1730000 ts, -5.96e+06 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-01-50
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -5963578.318436635
  episode_reward_min: -33890000.000013836
  episodes_this_iter: 1
  episodes_total: 346
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 3.079
    dispatch_time_ms: 8.788
    learner:
      cur_lr: 0.0012447820045053959
      grad_gnorm: 40.0
      policy_entropy: 0.0012944919290021062
      policy_loss: 0.00031147562549449503
      var_gnorm: 28.353382110595703
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 378.4627990722656
    num_steps_sampled: 1735000
    num_steps_trained: 1735000
    wait_time_ms: 69.409
  iterations_since_restore: 347
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 3005.303339958191
  time_this_iter_s: 8.172185897827148
  time_total_s: 3005.303339958191
  timestamp: 1594861310
  timesteps_since_restore: 1735000
  timesteps_this_iter: 5000
  timesteps_total: 1735000
  training_iteration: 347
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 3005 s, 347 iter, 1735000 ts, -5.96e+06 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-02-05
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -5963571.358436635
  episode_reward_min: -33890000.000013836
  episodes_this_iter: 1
  episodes_total: 347
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 6.19
    dispatch_time_ms: 8.095
    learner:
      cur_lr: 0.0012444490566849709
      grad_gnorm: 40.000003814697266
      policy_entropy: 0.0012682919623330235
      policy_loss: 0.000247173011302948
      var_gnorm: 28.075172424316406
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 269.27435302734375
    num_steps_sampled: 1740000
    num_steps_trained: 1740000
    wait_time_ms: 49.51
  iterations_since_restore: 348
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 3020.2142436504364
  time_this_iter_s: 14.910903692245483
  time_total_s: 3020.2142436504364
  timestamp: 1594861325
  timesteps_since_restore: 1740000
  timesteps_this_iter: 5000
  timesteps_total: 1740000
  training_iteration: 348
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 3020 s, 348 iter, 1740000 ts, -5.96e+06 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-02-14
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -5963561.418436634
  episode_reward_min: -33890000.000013836
  episodes_this_iter: 1
  episodes_total: 348
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 3.033
    dispatch_time_ms: 22.066
    learner:
      cur_lr: 0.001244115992449224
      grad_gnorm: 39.999996185302734
      policy_entropy: 0.0012487699277698994
      policy_loss: 0.0002070419432129711
      var_gnorm: 27.84331512451172
      vf_explained_var: 5.960464477539063e-08
      vf_loss: 178.65574645996094
    num_steps_sampled: 1745000
    num_steps_trained: 1745000
    wait_time_ms: 64.848
  iterations_since_restore: 349
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 3028.6509425640106
  time_this_iter_s: 8.436698913574219
  time_total_s: 3028.6509425640106
  timestamp: 1594861334
  timesteps_since_restore: 1745000
  timesteps_this_iter: 5000
  timesteps_total: 1745000
  training_iteration: 349
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 3028 s, 349 iter, 1745000 ts, -5.96e+06 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-02-22
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -5963561.418436634
  episode_reward_min: -33890000.000013836
  episodes_this_iter: 1
  episodes_total: 349
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.731
    dispatch_time_ms: 30.931
    learner:
      cur_lr: 0.001243783044628799
      grad_gnorm: 40.0
      policy_entropy: 0.0012222271179780364
      policy_loss: 0.00015855618403293192
      var_gnorm: 27.65880584716797
      vf_explained_var: 0.0
      vf_loss: 98.11531829833984
    num_steps_sampled: 1750000
    num_steps_trained: 1750000
    wait_time_ms: 46.868
  iterations_since_restore: 350
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 3037.2955017089844
  time_this_iter_s: 8.644559144973755
  time_total_s: 3037.2955017089844
  timestamp: 1594861342
  timesteps_since_restore: 1750000
  timesteps_this_iter: 5000
  timesteps_total: 1750000
  training_iteration: 350
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 3037 s, 350 iter, 1750000 ts, -5.96e+06 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-02-31
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -5963553.458436634
  episode_reward_min: -33890000.000013836
  episodes_this_iter: 1
  episodes_total: 350
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.881
    dispatch_time_ms: 28.516
    learner:
      cur_lr: 0.001243449980393052
      grad_gnorm: 40.000003814697266
      policy_entropy: 0.0012024876195937395
      policy_loss: 0.00011345314123900607
      var_gnorm: 27.523805618286133
      vf_explained_var: 1.7881393432617188e-07
      vf_loss: 53.4722785949707
    num_steps_sampled: 1755000
    num_steps_trained: 1755000
    wait_time_ms: 52.93
  iterations_since_restore: 351
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 3045.9831812381744
  time_this_iter_s: 8.687679529190063
  time_total_s: 3045.9831812381744
  timestamp: 1594861351
  timesteps_since_restore: 1755000
  timesteps_this_iter: 5000
  timesteps_total: 1755000
  training_iteration: 351
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 3045 s, 351 iter, 1755000 ts, -5.96e+06 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-02-40
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -5963545.508436634
  episode_reward_min: -33890000.000013836
  episodes_this_iter: 1
  episodes_total: 351
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.96
    dispatch_time_ms: 30.409
    learner:
      cur_lr: 0.001243117032572627
      grad_gnorm: 40.0
      policy_entropy: 0.001181167084723711
      policy_loss: 6.478426075773314e-05
      var_gnorm: 27.435670852661133
      vf_explained_var: 0.0
      vf_loss: 18.041915893554688
    num_steps_sampled: 1760000
    num_steps_trained: 1760000
    wait_time_ms: 51.688
  iterations_since_restore: 352
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 3054.67613863945
  time_this_iter_s: 8.692957401275635
  time_total_s: 3054.67613863945
  timestamp: 1594861360
  timesteps_since_restore: 1760000
  timesteps_this_iter: 5000
  timesteps_total: 1760000
  training_iteration: 352
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 3054 s, 352 iter, 1760000 ts, -5.96e+06 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-02-49
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -5963539.5384366345
  episode_reward_min: -33890000.000013836
  episodes_this_iter: 1
  episodes_total: 352
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.853
    dispatch_time_ms: 24.025
    learner:
      cur_lr: 0.0012427839683368802
      grad_gnorm: 39.999996185302734
      policy_entropy: 0.0011538037797436118
      policy_loss: 2.4290633518830873e-05
      var_gnorm: 27.398815155029297
      vf_explained_var: 0.0
      vf_loss: 2.0119926929473877
    num_steps_sampled: 1765000
    num_steps_trained: 1765000
    wait_time_ms: 60.778
  iterations_since_restore: 353
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 3063.4009153842926
  time_this_iter_s: 8.72477674484253
  time_total_s: 3063.4009153842926
  timestamp: 1594861369
  timesteps_since_restore: 1765000
  timesteps_this_iter: 5000
  timesteps_total: 1765000
  training_iteration: 353
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 23.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 3063 s, 353 iter, 1765000 ts, -5.96e+06 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-02-57
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -5963528.559061634
  episode_reward_min: -33890000.000013836
  episodes_this_iter: 1
  episodes_total: 353
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 3.166
    dispatch_time_ms: 22.649
    learner:
      cur_lr: 0.0012424510205164552
      grad_gnorm: 1.3930944204330444
      policy_entropy: 0.0011395302135497332
      policy_loss: 7.603713356729713e-07
      var_gnorm: 27.396406173706055
      vf_explained_var: 0.0
      vf_loss: 0.001277943723835051
    num_steps_sampled: 1770000
    num_steps_trained: 1770000
    wait_time_ms: 66.278
  iterations_since_restore: 354
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 3072.184093952179
  time_this_iter_s: 8.783178567886353
  time_total_s: 3072.184093952179
  timestamp: 1594861377
  timesteps_since_restore: 1770000
  timesteps_this_iter: 5000
  timesteps_total: 1770000
  training_iteration: 354
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 23.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 3072 s, 354 iter, 1770000 ts, -5.96e+06 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-03-06
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -5963521.599061634
  episode_reward_min: -33890000.000013836
  episodes_this_iter: 1
  episodes_total: 354
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 3.622
    dispatch_time_ms: 20.128
    learner:
      cur_lr: 0.0012421179562807083
      grad_gnorm: 0.040149081498384476
      policy_entropy: 0.0011419560760259628
      policy_loss: 2.1417108087007364e-08
      var_gnorm: 27.39655303955078
      vf_explained_var: 0.0
      vf_loss: 1.0614385246299207e-06
    num_steps_sampled: 1775000
    num_steps_trained: 1775000
    wait_time_ms: 62.927
  iterations_since_restore: 355
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 3080.7643160820007
  time_this_iter_s: 8.580222129821777
  time_total_s: 3080.7643160820007
  timestamp: 1594861386
  timesteps_since_restore: 1775000
  timesteps_this_iter: 5000
  timesteps_total: 1775000
  training_iteration: 355
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 23.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 3080 s, 355 iter, 1775000 ts, -5.96e+06 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-03-14
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -5963517.619061635
  episode_reward_min: -33890000.000013836
  episodes_this_iter: 1
  episodes_total: 355
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.777
    dispatch_time_ms: 5.563
    learner:
      cur_lr: 0.0012417850084602833
      grad_gnorm: 0.5597670674324036
      policy_entropy: 0.001144508016295731
      policy_loss: 1.9815455232219392e-07
      var_gnorm: 27.39657974243164
      vf_explained_var: 5.960464477539063e-08
      vf_loss: 0.00020634416432585567
    num_steps_sampled: 1780000
    num_steps_trained: 1780000
    wait_time_ms: 72.138
  iterations_since_restore: 356
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 3089.12623667717
  time_this_iter_s: 8.361920595169067
  time_total_s: 3089.12623667717
  timestamp: 1594861394
  timesteps_since_restore: 1780000
  timesteps_this_iter: 5000
  timesteps_total: 1780000
  training_iteration: 356
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 3089 s, 356 iter, 1780000 ts, -5.96e+06 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-03-23
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -5963511.649061634
  episode_reward_min: -33890000.000013836
  episodes_this_iter: 1
  episodes_total: 356
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.844
    dispatch_time_ms: 8.876
    learner:
      cur_lr: 0.0012414519442245364
      grad_gnorm: 0.0066666207276284695
      policy_entropy: 0.001147742266766727
      policy_loss: 4.43978454001126e-09
      var_gnorm: 27.39668846130371
      vf_explained_var: 0.0
      vf_loss: 2.879912486264402e-08
    num_steps_sampled: 1785000
    num_steps_trained: 1785000
    wait_time_ms: 71.685
  iterations_since_restore: 357
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 3097.2970695495605
  time_this_iter_s: 8.170832872390747
  time_total_s: 3097.2970695495605
  timestamp: 1594861403
  timesteps_since_restore: 1785000
  timesteps_this_iter: 5000
  timesteps_total: 1785000
  training_iteration: 357
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 3097 s, 357 iter, 1785000 ts, -5.96e+06 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-03-31
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -5963511.649061634
  episode_reward_min: -33890000.000013836
  episodes_this_iter: 1
  episodes_total: 357
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.772
    dispatch_time_ms: 6.425
    learner:
      cur_lr: 0.0012411189964041114
      grad_gnorm: 0.6298238635063171
      policy_entropy: 0.0011505784932523966
      policy_loss: 2.1097557123539445e-07
      var_gnorm: 27.39671516418457
      vf_explained_var: 0.0
      vf_loss: 0.0002611964591778815
    num_steps_sampled: 1790000
    num_steps_trained: 1790000
    wait_time_ms: 73.003
  iterations_since_restore: 358
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 3105.4356248378754
  time_this_iter_s: 8.13855528831482
  time_total_s: 3105.4356248378754
  timestamp: 1594861411
  timesteps_since_restore: 1790000
  timesteps_this_iter: 5000
  timesteps_total: 1790000
  training_iteration: 358
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 3105 s, 358 iter, 1790000 ts, -5.96e+06 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-03-39
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -5963503.699061635
  episode_reward_min: -33890000.000013836
  episodes_this_iter: 1
  episodes_total: 358
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 3.291
    dispatch_time_ms: 6.561
    learner:
      cur_lr: 0.0012407860485836864
      grad_gnorm: 0.006551133468747139
      policy_entropy: 0.0011540621053427458
      policy_loss: 2.101902207840567e-09
      var_gnorm: 27.396825790405273
      vf_explained_var: 1.1920928955078125e-07
      vf_loss: 2.8074792268739657e-08
    num_steps_sampled: 1795000
    num_steps_trained: 1795000
    wait_time_ms: 72.943
  iterations_since_restore: 359
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 3113.6498444080353
  time_this_iter_s: 8.214219570159912
  time_total_s: 3113.6498444080353
  timestamp: 1594861419
  timesteps_since_restore: 1795000
  timesteps_this_iter: 5000
  timesteps_total: 1795000
  training_iteration: 359
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 3113 s, 359 iter, 1795000 ts, -5.96e+06 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-03-47
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -5963497.729061634
  episode_reward_min: -33890000.000013836
  episodes_this_iter: 1
  episodes_total: 359
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.785
    dispatch_time_ms: 9.33
    learner:
      cur_lr: 0.0012404529843479395
      grad_gnorm: 0.6870150566101074
      policy_entropy: 0.0011572763323783875
      policy_loss: 2.431996222185262e-07
      var_gnorm: 27.396848678588867
      vf_explained_var: 0.0
      vf_loss: 0.0003108357486780733
    num_steps_sampled: 1800000
    num_steps_trained: 1800000
    wait_time_ms: 69.789
  iterations_since_restore: 360
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 3121.8336827754974
  time_this_iter_s: 8.183838367462158
  time_total_s: 3121.8336827754974
  timestamp: 1594861427
  timesteps_since_restore: 1800000
  timesteps_this_iter: 5000
  timesteps_total: 1800000
  training_iteration: 360
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 3121 s, 360 iter, 1800000 ts, -5.96e+06 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-03-56
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -5963497.729061634
  episode_reward_min: -33890000.000013836
  episodes_this_iter: 1
  episodes_total: 360
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 3.881
    dispatch_time_ms: 21.191
    learner:
      cur_lr: 0.0012401200365275145
      grad_gnorm: 0.015482488088309765
      policy_entropy: 0.0011611052323132753
      policy_loss: 1.2756624201415434e-08
      var_gnorm: 27.396957397460938
      vf_explained_var: 0.0
      vf_loss: 1.571837628944195e-07
    num_steps_sampled: 1805000
    num_steps_trained: 1805000
    wait_time_ms: 62.013
  iterations_since_restore: 361
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 3130.453273296356
  time_this_iter_s: 8.619590520858765
  time_total_s: 3130.453273296356
  timestamp: 1594861436
  timesteps_since_restore: 1805000
  timesteps_this_iter: 5000
  timesteps_total: 1805000
  training_iteration: 361
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 3130 s, 361 iter, 1805000 ts, -5.96e+06 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-04-05
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -5963489.769061636
  episode_reward_min: -33890000.000013836
  episodes_this_iter: 1
  episodes_total: 361
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.781
    dispatch_time_ms: 31.787
    learner:
      cur_lr: 0.0012397869722917676
      grad_gnorm: 0.6203707456588745
      policy_entropy: 0.0011649758089333773
      policy_loss: 3.5250320706836646e-07
      var_gnorm: 27.396984100341797
      vf_explained_var: 0.0
      vf_loss: 0.00025340550928376615
    num_steps_sampled: 1810000
    num_steps_trained: 1810000
    wait_time_ms: 46.467
  iterations_since_restore: 362
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 3139.1486604213715
  time_this_iter_s: 8.695387125015259
  time_total_s: 3139.1486604213715
  timestamp: 1594861445
  timesteps_since_restore: 1810000
  timesteps_this_iter: 5000
  timesteps_total: 1810000
  training_iteration: 362
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 3139 s, 362 iter, 1810000 ts, -5.96e+06 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-04-14
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -5963487.779061636
  episode_reward_min: -33890000.000013836
  episodes_this_iter: 1
  episodes_total: 362
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.729
    dispatch_time_ms: 17.593
    learner:
      cur_lr: 0.0012394540244713426
      grad_gnorm: 0.05049561709165573
      policy_entropy: 0.0011691759573295712
      policy_loss: 4.058609093249288e-08
      var_gnorm: 27.397083282470703
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 1.6790031622804236e-06
    num_steps_sampled: 1815000
    num_steps_trained: 1815000
    wait_time_ms: 66.436
  iterations_since_restore: 363
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 3148.4462084770203
  time_this_iter_s: 9.297548055648804
  time_total_s: 3148.4462084770203
  timestamp: 1594861454
  timesteps_since_restore: 1815000
  timesteps_this_iter: 5000
  timesteps_total: 1815000
  training_iteration: 363
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 3148 s, 363 iter, 1815000 ts, -5.96e+06 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-04-23
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -5963487.779061634
  episode_reward_min: -33890000.000013836
  episodes_this_iter: 1
  episodes_total: 363
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 3.794
    dispatch_time_ms: 64.397
    learner:
      cur_lr: 0.0012391209602355957
      grad_gnorm: 0.16025027632713318
      policy_entropy: 0.0011734891450032592
      policy_loss: 5.12581948441948e-07
      var_gnorm: 27.39710807800293
      vf_explained_var: 1.1920928955078125e-07
      vf_loss: 0.00011190227087354288
    num_steps_sampled: 1820000
    num_steps_trained: 1820000
    wait_time_ms: 32.982
  iterations_since_restore: 364
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 3157.206988096237
  time_this_iter_s: 8.760779619216919
  time_total_s: 3157.206988096237
  timestamp: 1594861463
  timesteps_since_restore: 1820000
  timesteps_this_iter: 5000
  timesteps_total: 1820000
  training_iteration: 364
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 3157 s, 364 iter, 1820000 ts, -5.96e+06 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-04-32
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -5963487.779061634
  episode_reward_min: -33890000.000013836
  episodes_this_iter: 1
  episodes_total: 364
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 3.254
    dispatch_time_ms: 20.975
    learner:
      cur_lr: 0.0012387880124151707
      grad_gnorm: 0.012716497294604778
      policy_entropy: 0.001177969970740378
      policy_loss: 5.780670164767798e-09
      var_gnorm: 27.397212982177734
      vf_explained_var: 0.0
      vf_loss: 1.0666438754469709e-07
    num_steps_sampled: 1825000
    num_steps_trained: 1825000
    wait_time_ms: 63.612
  iterations_since_restore: 365
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 3165.8580865859985
  time_this_iter_s: 8.651098489761353
  time_total_s: 3165.8580865859985
  timestamp: 1594861472
  timesteps_since_restore: 1825000
  timesteps_this_iter: 5000
  timesteps_total: 1825000
  training_iteration: 365
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 3165 s, 365 iter, 1825000 ts, -5.96e+06 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-04-40
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -5963477.849061635
  episode_reward_min: -33890000.000013836
  episodes_this_iter: 1
  episodes_total: 365
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.823
    dispatch_time_ms: 27.117
    learner:
      cur_lr: 0.0012384549481794238
      grad_gnorm: 0.7285875082015991
      policy_entropy: 0.001182982581667602
      policy_loss: 3.117368407856702e-07
      var_gnorm: 27.397233963012695
      vf_explained_var: 0.0
      vf_loss: 0.00034951724228449166
    num_steps_sampled: 1830000
    num_steps_trained: 1830000
    wait_time_ms: 58.238
  iterations_since_restore: 366
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 3174.5686054229736
  time_this_iter_s: 8.710518836975098
  time_total_s: 3174.5686054229736
  timestamp: 1594861480
  timesteps_since_restore: 1830000
  timesteps_this_iter: 5000
  timesteps_total: 1830000
  training_iteration: 366
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 3174 s, 366 iter, 1830000 ts, -5.96e+06 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-04-49
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -5963469.899061636
  episode_reward_min: -33890000.000013836
  episodes_this_iter: 1
  episodes_total: 366
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 3.831
    dispatch_time_ms: 37.811
    learner:
      cur_lr: 0.0012381220003589988
      grad_gnorm: 0.01654883660376072
      policy_entropy: 0.0011881267419084907
      policy_loss: 1.2589237208260329e-08
      var_gnorm: 27.3973388671875
      vf_explained_var: 0.0
      vf_loss: 1.8080821462262975e-07
    num_steps_sampled: 1835000
    num_steps_trained: 1835000
    wait_time_ms: 42.02
  iterations_since_restore: 367
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 3183.286600828171
  time_this_iter_s: 8.717995405197144
  time_total_s: 3183.286600828171
  timestamp: 1594861489
  timesteps_since_restore: 1835000
  timesteps_this_iter: 5000
  timesteps_total: 1835000
  training_iteration: 367
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 3183 s, 367 iter, 1835000 ts, -5.96e+06 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-04-58
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -5963469.899061636
  episode_reward_min: -33890000.000013836
  episodes_this_iter: 1
  episodes_total: 367
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.944
    dispatch_time_ms: 7.531
    learner:
      cur_lr: 0.0012377890525385737
      grad_gnorm: 0.5176573991775513
      policy_entropy: 0.0011937409872189164
      policy_loss: 2.290313858566151e-07
      var_gnorm: 27.397367477416992
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 0.00017644539184402674
    num_steps_sampled: 1840000
    num_steps_trained: 1840000
    wait_time_ms: 70.733
  iterations_since_restore: 368
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 3191.81405711174
  time_this_iter_s: 8.527456283569336
  time_total_s: 3191.81405711174
  timestamp: 1594861498
  timesteps_since_restore: 1840000
  timesteps_this_iter: 5000
  timesteps_total: 1840000
  training_iteration: 368
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 3191 s, 368 iter, 1840000 ts, -5.96e+06 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-05-06
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -5963465.919061636
  episode_reward_min: -33890000.000013836
  episodes_this_iter: 1
  episodes_total: 368
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 3.937
    dispatch_time_ms: 8.256
    learner:
      cur_lr: 0.0012374559883028269
      grad_gnorm: 0.08290372788906097
      policy_entropy: 0.0011994939995929599
      policy_loss: -2.9347473784469003e-08
      var_gnorm: 27.397459030151367
      vf_explained_var: 0.0
      vf_loss: 4.5281303755473346e-06
    num_steps_sampled: 1845000
    num_steps_trained: 1845000
    wait_time_ms: 70.499
  iterations_since_restore: 369
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 3199.9811658859253
  time_this_iter_s: 8.16710877418518
  time_total_s: 3199.9811658859253
  timestamp: 1594861506
  timesteps_since_restore: 1845000
  timesteps_this_iter: 5000
  timesteps_total: 1845000
  training_iteration: 369
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 3199 s, 369 iter, 1845000 ts, -5.96e+06 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-05-14
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -5963461.939061636
  episode_reward_min: -33890000.000013836
  episodes_this_iter: 1
  episodes_total: 369
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.985
    dispatch_time_ms: 7.378
    learner:
      cur_lr: 0.0012371230404824018
      grad_gnorm: 0.4980710744857788
      policy_entropy: 0.0012057058047503233
      policy_loss: 1.7631451498800743e-07
      var_gnorm: 27.397483825683594
      vf_explained_var: 0.0
      vf_loss: 0.00016337410488631576
    num_steps_sampled: 1850000
    num_steps_trained: 1850000
    wait_time_ms: 71.508
  iterations_since_restore: 370
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 3207.8233621120453
  time_this_iter_s: 7.842196226119995
  time_total_s: 3207.8233621120453
  timestamp: 1594861514
  timesteps_since_restore: 1850000
  timesteps_this_iter: 5000
  timesteps_total: 1850000
  training_iteration: 370
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 3207 s, 370 iter, 1850000 ts, -5.96e+06 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-05-26
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -5963453.979061636
  episode_reward_min: -33890000.000013836
  episodes_this_iter: 1
  episodes_total: 370
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.626
    dispatch_time_ms: 6.069
    learner:
      cur_lr: 0.001236789976246655
      grad_gnorm: 0.06088821962475777
      policy_entropy: 0.001206564949825406
      policy_loss: -1.8240662313928624e-08
      var_gnorm: 27.39752769470215
      vf_explained_var: 0.0
      vf_loss: 2.4447199393762276e-06
    num_steps_sampled: 1855000
    num_steps_trained: 1855000
    wait_time_ms: 255.235
  iterations_since_restore: 371
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 3219.587743997574
  time_this_iter_s: 11.764381885528564
  time_total_s: 3219.587743997574
  timestamp: 1594861526
  timesteps_since_restore: 1855000
  timesteps_this_iter: 5000
  timesteps_total: 1855000
  training_iteration: 371
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 3219 s, 371 iter, 1855000 ts, -5.96e+06 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-05-33
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -5963449.009061637
  episode_reward_min: -33890000.000013836
  episodes_this_iter: 1
  episodes_total: 371
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.736
    dispatch_time_ms: 7.685
    learner:
      cur_lr: 0.00123645702842623
      grad_gnorm: 0.4230476915836334
      policy_entropy: 0.0012189646949991584
      policy_loss: 2.7824955850519473e-07
      var_gnorm: 27.397598266601562
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 0.00011784811795223504
    num_steps_sampled: 1860000
    num_steps_trained: 1860000
    wait_time_ms: 71.082
  iterations_since_restore: 372
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 3227.0762836933136
  time_this_iter_s: 7.488539695739746
  time_total_s: 3227.0762836933136
  timestamp: 1594861533
  timesteps_since_restore: 1860000
  timesteps_this_iter: 5000
  timesteps_total: 1860000
  training_iteration: 372
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 3227 s, 372 iter, 1860000 ts, -5.96e+06 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-05-42
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -5963445.029061636
  episode_reward_min: -33890000.000013836
  episodes_this_iter: 1
  episodes_total: 372
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.511
    dispatch_time_ms: 7.207
    learner:
      cur_lr: 0.001236123964190483
      grad_gnorm: 0.12246536463499069
      policy_entropy: 0.0012263497337698936
      policy_loss: -6.980410915957691e-08
      var_gnorm: 27.397682189941406
      vf_explained_var: 0.0
      vf_loss: 9.875760042632464e-06
    num_steps_sampled: 1865000
    num_steps_trained: 1865000
    wait_time_ms: 69.092
  iterations_since_restore: 373
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 3235.2786655426025
  time_this_iter_s: 8.20238184928894
  time_total_s: 3235.2786655426025
  timestamp: 1594861542
  timesteps_since_restore: 1865000
  timesteps_this_iter: 5000
  timesteps_total: 1865000
  training_iteration: 373
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 3235 s, 373 iter, 1865000 ts, -5.96e+06 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-05-50
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -5963445.029061636
  episode_reward_min: -33890000.000013836
  episodes_this_iter: 1
  episodes_total: 373
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.895
    dispatch_time_ms: 8.907
    learner:
      cur_lr: 0.001235791016370058
      grad_gnorm: 0.42049509286880493
      policy_entropy: 0.001234227092936635
      policy_loss: 1.85234355853936e-07
      var_gnorm: 27.397705078125
      vf_explained_var: 0.0
      vf_loss: 0.00011643623292911798
    num_steps_sampled: 1870000
    num_steps_trained: 1870000
    wait_time_ms: 69.724
  iterations_since_restore: 374
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 3243.4056951999664
  time_this_iter_s: 8.127029657363892
  time_total_s: 3243.4056951999664
  timestamp: 1594861550
  timesteps_since_restore: 1870000
  timesteps_this_iter: 5000
  timesteps_total: 1870000
  training_iteration: 374
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 3243 s, 374 iter, 1870000 ts, -5.96e+06 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-05-58
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -5963445.029061636
  episode_reward_min: -33890000.000013836
  episodes_this_iter: 1
  episodes_total: 374
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.87
    dispatch_time_ms: 9.021
    learner:
      cur_lr: 0.0012354579521343112
      grad_gnorm: 0.10019614547491074
      policy_entropy: 0.0012484234757721424
      policy_loss: -5.229661681482867e-08
      var_gnorm: 27.39777946472168
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 6.609243428101763e-06
    num_steps_sampled: 1875000
    num_steps_trained: 1875000
    wait_time_ms: 70.32
  iterations_since_restore: 375
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 3251.560214281082
  time_this_iter_s: 8.154519081115723
  time_total_s: 3251.560214281082
  timestamp: 1594861558
  timesteps_since_restore: 1875000
  timesteps_this_iter: 5000
  timesteps_total: 1875000
  training_iteration: 375
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 3251 s, 375 iter, 1875000 ts, -5.96e+06 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-06-06
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -5889018.968527987
  episode_reward_min: -33890000.000013836
  episodes_this_iter: 1
  episodes_total: 375
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 3.532
    dispatch_time_ms: 8.752
    learner:
      cur_lr: 0.0012351250043138862
      grad_gnorm: 0.3573484420776367
      policy_entropy: 0.001257436815649271
      policy_loss: 4.96181769449322e-07
      var_gnorm: 27.397798538208008
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 8.408679423155263e-05
    num_steps_sampled: 1880000
    num_steps_trained: 1880000
    wait_time_ms: 66.986
  iterations_since_restore: 376
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 3259.647705078125
  time_this_iter_s: 8.087490797042847
  time_total_s: 3259.647705078125
  timestamp: 1594861566
  timesteps_since_restore: 1880000
  timesteps_this_iter: 5000
  timesteps_total: 1880000
  training_iteration: 376
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 3259 s, 376 iter, 1880000 ts, -5.89e+06 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-06-21
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -5715752.9968005335
  episode_reward_min: -33890000.000013836
  episodes_this_iter: 1
  episodes_total: 376
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.745
    dispatch_time_ms: 9.07
    learner:
      cur_lr: 0.0012347920564934611
      grad_gnorm: 0.07648949325084686
      policy_entropy: 0.0012668482959270477
      policy_loss: -4.6682888665827704e-08
      var_gnorm: 27.39786148071289
      vf_explained_var: 0.0
      vf_loss: 3.85363318855525e-06
    num_steps_sampled: 1885000
    num_steps_trained: 1885000
    wait_time_ms: 67.625
  iterations_since_restore: 377
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 3274.445102930069
  time_this_iter_s: 14.79739785194397
  time_total_s: 3274.445102930069
  timestamp: 1594861581
  timesteps_since_restore: 1885000
  timesteps_this_iter: 5000
  timesteps_total: 1885000
  training_iteration: 377
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 3274 s, 377 iter, 1885000 ts, -5.72e+06 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-06-29
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -5577072.469991262
  episode_reward_min: -33890000.000013836
  episodes_this_iter: 1
  episodes_total: 377
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.619
    dispatch_time_ms: 7.887
    learner:
      cur_lr: 0.0012344589922577143
      grad_gnorm: 0.27728861570358276
      policy_entropy: 0.0012830074410885572
      policy_loss: 1.1326001470024494e-07
      var_gnorm: 27.39788246154785
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 5.0630005716811866e-05
    num_steps_sampled: 1890000
    num_steps_trained: 1890000
    wait_time_ms: 73.165
  iterations_since_restore: 378
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 3282.540806531906
  time_this_iter_s: 8.095703601837158
  time_total_s: 3282.540806531906
  timestamp: 1594861589
  timesteps_since_restore: 1890000
  timesteps_this_iter: 5000
  timesteps_total: 1890000
  training_iteration: 378
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 3282 s, 378 iter, 1890000 ts, -5.58e+06 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-06-37
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -5488411.2611579215
  episode_reward_min: -33890000.000013836
  episodes_this_iter: 1
  episodes_total: 378
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.595
    dispatch_time_ms: 5.748
    learner:
      cur_lr: 0.0012341260444372892
      grad_gnorm: 0.03845919668674469
      policy_entropy: 0.0012938730651512742
      policy_loss: -3.951154425863024e-08
      var_gnorm: 27.39793586730957
      vf_explained_var: 0.0
      vf_loss: 9.734192190080648e-07
    num_steps_sampled: 1895000
    num_steps_trained: 1895000
    wait_time_ms: 71.569
  iterations_since_restore: 379
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 3290.704989671707
  time_this_iter_s: 8.164183139801025
  time_total_s: 3290.704989671707
  timestamp: 1594861597
  timesteps_since_restore: 1895000
  timesteps_this_iter: 5000
  timesteps_total: 1895000
  training_iteration: 379
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 3290 s, 379 iter, 1895000 ts, -5.49e+06 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-06-46
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -5305094.177143503
  episode_reward_min: -33890000.000013836
  episodes_this_iter: 1
  episodes_total: 379
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 3.068
    dispatch_time_ms: 7.653
    learner:
      cur_lr: 0.0012337929802015424
      grad_gnorm: 0.2541750371456146
      policy_entropy: 0.0013054471928626299
      policy_loss: 1.0381914705703821e-07
      var_gnorm: 27.3979549407959
      vf_explained_var: 0.0
      vf_loss: 4.253394217812456e-05
    num_steps_sampled: 1900000
    num_steps_trained: 1900000
    wait_time_ms: 71.157
  iterations_since_restore: 380
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 3298.902328014374
  time_this_iter_s: 8.197338342666626
  time_total_s: 3298.902328014374
  timestamp: 1594861606
  timesteps_since_restore: 1900000
  timesteps_this_iter: 5000
  timesteps_total: 1900000
  training_iteration: 380
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 3298 s, 380 iter, 1900000 ts, -5.31e+06 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-06-54
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -5181937.207277345
  episode_reward_min: -33890000.000013836
  episodes_this_iter: 1
  episodes_total: 380
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.884
    dispatch_time_ms: 8.969
    learner:
      cur_lr: 0.0012334600323811173
      grad_gnorm: 0.002255804371088743
      policy_entropy: 0.0013178985100239515
      policy_loss: -1.1210497419256171e-08
      var_gnorm: 27.397998809814453
      vf_explained_var: 0.0
      vf_loss: 3.287848882038702e-09
    num_steps_sampled: 1905000
    num_steps_trained: 1905000
    wait_time_ms: 70.335
  iterations_since_restore: 381
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 3307.0704979896545
  time_this_iter_s: 8.168169975280762
  time_total_s: 3307.0704979896545
  timestamp: 1594861614
  timesteps_since_restore: 1905000
  timesteps_this_iter: 5000
  timesteps_total: 1905000
  training_iteration: 381
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 3307 s, 381 iter, 1905000 ts, -5.18e+06 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-07-02
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -5059029.227552821
  episode_reward_min: -33890000.000013836
  episodes_this_iter: 1
  episodes_total: 381
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.709
    dispatch_time_ms: 7.97
    learner:
      cur_lr: 0.0012331269681453705
      grad_gnorm: 0.062478844076395035
      policy_entropy: 0.0013312686933204532
      policy_loss: 4.002305615813384e-07
      var_gnorm: 27.39803123474121
      vf_explained_var: 0.0
      vf_loss: 2.5713454760989407e-06
    num_steps_sampled: 1910000
    num_steps_trained: 1910000
    wait_time_ms: 74.255
  iterations_since_restore: 382
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 3315.28231883049
  time_this_iter_s: 8.211820840835571
  time_total_s: 3315.28231883049
  timestamp: 1594861622
  timesteps_since_restore: 1910000
  timesteps_this_iter: 5000
  timesteps_total: 1910000
  training_iteration: 382
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 3315 s, 382 iter, 1910000 ts, -5.06e+06 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-07-10
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -4913829.227552762
  episode_reward_min: -33890000.000013836
  episodes_this_iter: 1
  episodes_total: 382
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.59
    dispatch_time_ms: 7.09
    learner:
      cur_lr: 0.0012327940203249454
      grad_gnorm: 0.08734846860170364
      policy_entropy: 0.0013456162996590137
      policy_loss: 2.988591418784381e-08
      var_gnorm: 27.398059844970703
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 5.025300652050646e-06
    num_steps_sampled: 1915000
    num_steps_trained: 1915000
    wait_time_ms: 77.154
  iterations_since_restore: 383
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 3323.48544716835
  time_this_iter_s: 8.203128337860107
  time_total_s: 3323.48544716835
  timestamp: 1594861630
  timesteps_since_restore: 1915000
  timesteps_this_iter: 5000
  timesteps_total: 1915000
  training_iteration: 383
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 23.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 3323 s, 383 iter, 1915000 ts, -4.91e+06 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-07-18
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -4806448.350993772
  episode_reward_min: -33890000.000013836
  episodes_this_iter: 1
  episodes_total: 383
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.633
    dispatch_time_ms: 9.599
    learner:
      cur_lr: 0.0012324609560891986
      grad_gnorm: 0.09900233149528503
      policy_entropy: 0.0013610362075269222
      policy_loss: 1.925010479908451e-07
      var_gnorm: 27.39809226989746
      vf_explained_var: 1.1920928955078125e-07
      vf_loss: 6.455504262703471e-06
    num_steps_sampled: 1920000
    num_steps_trained: 1920000
    wait_time_ms: 69.144
  iterations_since_restore: 384
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 3331.6450316905975
  time_this_iter_s: 8.159584522247314
  time_total_s: 3331.6450316905975
  timestamp: 1594861638
  timesteps_since_restore: 1920000
  timesteps_this_iter: 5000
  timesteps_total: 1920000
  training_iteration: 384
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 3331 s, 384 iter, 1920000 ts, -4.81e+06 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-07-27
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -4660748.350993713
  episode_reward_min: -33890000.000013836
  episodes_this_iter: 1
  episodes_total: 384
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 3.849
    dispatch_time_ms: 8.263
    learner:
      cur_lr: 0.0012321280082687736
      grad_gnorm: 0.12899410724639893
      policy_entropy: 0.0013834672281518579
      policy_loss: 5.047775530897525e-08
      var_gnorm: 27.398115158081055
      vf_explained_var: 1.7881393432617188e-07
      vf_loss: 1.09549555418198e-05
    num_steps_sampled: 1925000
    num_steps_trained: 1925000
    wait_time_ms: 68.124
  iterations_since_restore: 385
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 3339.7874953746796
  time_this_iter_s: 8.142463684082031
  time_total_s: 3339.7874953746796
  timestamp: 1594861647
  timesteps_since_restore: 1925000
  timesteps_this_iter: 5000
  timesteps_total: 1925000
  training_iteration: 385
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 3339 s, 385 iter, 1925000 ts, -4.66e+06 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-07-35
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -4515048.350993655
  episode_reward_min: -33890000.000013836
  episodes_this_iter: 1
  episodes_total: 385
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.655
    dispatch_time_ms: 23.774
    learner:
      cur_lr: 0.0012317949440330267
      grad_gnorm: 0.43061548471450806
      policy_entropy: 0.0014013124164193869
      policy_loss: -8.285043406885961e-08
      var_gnorm: 27.398174285888672
      vf_explained_var: 0.0
      vf_loss: 0.00012210835120640695
    num_steps_sampled: 1930000
    num_steps_trained: 1930000
    wait_time_ms: 61.759
  iterations_since_restore: 386
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 3348.1387135982513
  time_this_iter_s: 8.351218223571777
  time_total_s: 3348.1387135982513
  timestamp: 1594861655
  timesteps_since_restore: 1930000
  timesteps_this_iter: 5000
  timesteps_total: 1930000
  training_iteration: 386
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 3348 s, 386 iter, 1930000 ts, -4.52e+06 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-07-44
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -4224198.350993537
  episode_reward_min: -33890000.000013836
  episodes_this_iter: 1
  episodes_total: 386
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.711
    dispatch_time_ms: 18.935
    learner:
      cur_lr: 0.0012314619962126017
      grad_gnorm: 0.14378388226032257
      policy_entropy: 0.0014211466768756509
      policy_loss: 6.467772095675173e-08
      var_gnorm: 27.39816665649414
      vf_explained_var: 5.960464477539063e-08
      vf_loss: 1.3609222150989808e-05
    num_steps_sampled: 1935000
    num_steps_trained: 1935000
    wait_time_ms: 66.145
  iterations_since_restore: 387
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 3356.615257501602
  time_this_iter_s: 8.47654390335083
  time_total_s: 3356.615257501602
  timestamp: 1594861664
  timesteps_since_restore: 1935000
  timesteps_this_iter: 5000
  timesteps_total: 1935000
  training_iteration: 387
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 3356 s, 387 iter, 1935000 ts, -4.22e+06 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-07-52
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -3885298.350993399
  episode_reward_min: -33840000.00001373
  episodes_this_iter: 1
  episodes_total: 387
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.934
    dispatch_time_ms: 21.107
    learner:
      cur_lr: 0.0012311290483921766
      grad_gnorm: 0.01290248241275549
      policy_entropy: 0.001441883621737361
      policy_loss: 8.546674621356942e-07
      var_gnorm: 27.39820098876953
      vf_explained_var: -2.384185791015625e-07
      vf_loss: 1.0888943080544777e-07
    num_steps_sampled: 1940000
    num_steps_trained: 1940000
    wait_time_ms: 58.763
  iterations_since_restore: 388
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 3365.0965564250946
  time_this_iter_s: 8.481298923492432
  time_total_s: 3365.0965564250946
  timestamp: 1594861672
  timesteps_since_restore: 1940000
  timesteps_this_iter: 5000
  timesteps_total: 1940000
  training_iteration: 388
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 3365 s, 388 iter, 1940000 ts, -3.89e+06 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-08-01
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -3739598.350993341
  episode_reward_min: -33840000.00001373
  episodes_this_iter: 1
  episodes_total: 388
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 3.071
    dispatch_time_ms: 17.76
    learner:
      cur_lr: 0.0012307959841564298
      grad_gnorm: 0.12043310701847076
      policy_entropy: 0.0014642393216490746
      policy_loss: 8.943464990807115e-08
      var_gnorm: 27.398212432861328
      vf_explained_var: 0.0
      vf_loss: 9.552429219183978e-06
    num_steps_sampled: 1945000
    num_steps_trained: 1945000
    wait_time_ms: 63.725
  iterations_since_restore: 389
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 3373.5975551605225
  time_this_iter_s: 8.500998735427856
  time_total_s: 3373.5975551605225
  timestamp: 1594861681
  timesteps_since_restore: 1945000
  timesteps_this_iter: 5000
  timesteps_total: 1945000
  training_iteration: 389
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 3373 s, 389 iter, 1945000 ts, -3.74e+06 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-08-09
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -3497798.350993242
  episode_reward_min: -33840000.00001373
  episodes_this_iter: 1
  episodes_total: 389
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.563
    dispatch_time_ms: 26.497
    learner:
      cur_lr: 0.0012304630363360047
      grad_gnorm: 0.13290826976299286
      policy_entropy: 0.0014942348934710026
      policy_loss: -3.0289842811725975e-07
      var_gnorm: 27.398250579833984
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 1.1633722351689357e-05
    num_steps_sampled: 1950000
    num_steps_trained: 1950000
    wait_time_ms: 62.422
  iterations_since_restore: 390
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 3382.305469274521
  time_this_iter_s: 8.707914113998413
  time_total_s: 3382.305469274521
  timestamp: 1594861689
  timesteps_since_restore: 1950000
  timesteps_this_iter: 5000
  timesteps_total: 1950000
  training_iteration: 390
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 3382 s, 390 iter, 1950000 ts, -3.5e+06 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-08-18
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -3255498.3509931434
  episode_reward_min: -33840000.00001373
  episodes_this_iter: 1
  episodes_total: 390
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.904
    dispatch_time_ms: 16.153
    learner:
      cur_lr: 0.0012301299721002579
      grad_gnorm: 0.02040056511759758
      policy_entropy: 0.0015216517494991422
      policy_loss: 3.187320629649548e-08
      var_gnorm: 27.398265838623047
      vf_explained_var: 0.0
      vf_loss: 2.7492549747876183e-07
    num_steps_sampled: 1955000
    num_steps_trained: 1955000
    wait_time_ms: 67.003
  iterations_since_restore: 391
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 3390.917034626007
  time_this_iter_s: 8.611565351486206
  time_total_s: 3390.917034626007
  timestamp: 1594861698
  timesteps_since_restore: 1955000
  timesteps_this_iter: 5000
  timesteps_total: 1955000
  training_iteration: 391
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 3390 s, 391 iter, 1955000 ts, -3.26e+06 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-08-27
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -3158848.350993104
  episode_reward_min: -33840000.00001373
  episodes_this_iter: 1
  episodes_total: 391
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.438
    dispatch_time_ms: 16.583
    learner:
      cur_lr: 0.0012297970242798328
      grad_gnorm: 0.10444176197052002
      policy_entropy: 0.0015565187204629183
      policy_loss: 7.137961119951797e-07
      var_gnorm: 27.39829444885254
      vf_explained_var: 0.0
      vf_loss: 7.187244136730442e-06
    num_steps_sampled: 1960000
    num_steps_trained: 1960000
    wait_time_ms: 65.186
  iterations_since_restore: 392
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 3399.733731508255
  time_this_iter_s: 8.816696882247925
  time_total_s: 3399.733731508255
  timestamp: 1594861707
  timesteps_since_restore: 1960000
  timesteps_this_iter: 5000
  timesteps_total: 1960000
  training_iteration: 392
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 3399 s, 392 iter, 1960000 ts, -3.16e+06 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-08-36
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -3013648.350993044
  episode_reward_min: -33840000.00001373
  episodes_this_iter: 1
  episodes_total: 392
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 5.055
    dispatch_time_ms: 47.809
    learner:
      cur_lr: 0.001229463960044086
      grad_gnorm: 0.5058783888816833
      policy_entropy: 0.0015872843796387315
      policy_loss: 3.161508743687591e-08
      var_gnorm: 27.398313522338867
      vf_explained_var: 0.0
      vf_loss: 0.00013365806080400944
    num_steps_sampled: 1965000
    num_steps_trained: 1965000
    wait_time_ms: 34.311
  iterations_since_restore: 393
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 3408.5917584896088
  time_this_iter_s: 8.85802698135376
  time_total_s: 3408.5917584896088
  timestamp: 1594861716
  timesteps_since_restore: 1965000
  timesteps_this_iter: 5000
  timesteps_total: 1965000
  training_iteration: 393
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 3408 s, 393 iter, 1965000 ts, -3.01e+06 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-08-44
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -2799024.4948710147
  episode_reward_min: -33840000.00001373
  episodes_this_iter: 1
  episodes_total: 393
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 3.116
    dispatch_time_ms: 28.297
    learner:
      cur_lr: 0.001229131012223661
      grad_gnorm: 0.6578777432441711
      policy_entropy: 0.0016281083226203918
      policy_loss: 2.4192324872274185e-06
      var_gnorm: 27.398319244384766
      vf_explained_var: 0.0
      vf_loss: 0.00028494620346464217
    num_steps_sampled: 1970000
    num_steps_trained: 1970000
    wait_time_ms: 60.899
  iterations_since_restore: 394
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 3417.2541484832764
  time_this_iter_s: 8.662389993667603
  time_total_s: 3417.2541484832764
  timestamp: 1594861724
  timesteps_since_restore: 1970000
  timesteps_this_iter: 5000
  timesteps_total: 1970000
  training_iteration: 394
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 3417 s, 394 iter, 1970000 ts, -2.8e+06 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-08-53
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -2702374.4948709756
  episode_reward_min: -33840000.00001373
  episodes_this_iter: 1
  episodes_total: 394
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 3.376
    dispatch_time_ms: 29.558
    learner:
      cur_lr: 0.001228797947987914
      grad_gnorm: 0.000423992401920259
      policy_entropy: 0.0016664504073560238
      policy_loss: -1.211046929405768e-09
      var_gnorm: 27.398366928100586
      vf_explained_var: 0.0
      vf_loss: 1.0349473361648265e-10
    num_steps_sampled: 1975000
    num_steps_trained: 1975000
    wait_time_ms: 59.74
  iterations_since_restore: 395
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 3425.9649872779846
  time_this_iter_s: 8.710838794708252
  time_total_s: 3425.9649872779846
  timestamp: 1594861733
  timesteps_since_restore: 1975000
  timesteps_this_iter: 5000
  timesteps_total: 1975000
  training_iteration: 395
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 3425 s, 395 iter, 1975000 ts, -2.7e+06 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-09-02
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -2557174.4948709165
  episode_reward_min: -33840000.00001373
  episodes_this_iter: 1
  episodes_total: 395
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 3.308
    dispatch_time_ms: 19.098
    learner:
      cur_lr: 0.001228465000167489
      grad_gnorm: 0.9934136271476746
      policy_entropy: 0.0017090324545279145
      policy_loss: 1.6452847830805695e-06
      var_gnorm: 27.398374557495117
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 0.0006498085567727685
    num_steps_sampled: 1980000
    num_steps_trained: 1980000
    wait_time_ms: 74.659
  iterations_since_restore: 396
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 3434.7338898181915
  time_this_iter_s: 8.76890254020691
  time_total_s: 3434.7338898181915
  timestamp: 1594861742
  timesteps_since_restore: 1980000
  timesteps_this_iter: 5000
  timesteps_total: 1980000
  training_iteration: 396
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 3434 s, 396 iter, 1980000 ts, -2.56e+06 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-09-10
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -2411974.494870858
  episode_reward_min: -33840000.00001373
  episodes_this_iter: 1
  episodes_total: 396
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.986
    dispatch_time_ms: 10.066
    learner:
      cur_lr: 0.001228132052347064
      grad_gnorm: 0.12339179962873459
      policy_entropy: 0.0017620077123865485
      policy_loss: -8.999175094004386e-08
      var_gnorm: 27.398448944091797
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 1.002398676064331e-05
    num_steps_sampled: 1985000
    num_steps_trained: 1985000
    wait_time_ms: 66.899
  iterations_since_restore: 397
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 3442.9099736213684
  time_this_iter_s: 8.17608380317688
  time_total_s: 3442.9099736213684
  timestamp: 1594861750
  timesteps_since_restore: 1985000
  timesteps_this_iter: 5000
  timesteps_total: 1985000
  training_iteration: 397
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 3442 s, 397 iter, 1985000 ts, -2.41e+06 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-09-18
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -2198702.519851854
  episode_reward_min: -33840000.00001373
  episodes_this_iter: 1
  episodes_total: 397
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.668
    dispatch_time_ms: 7.828
    learner:
      cur_lr: 0.0012277989881113172
      grad_gnorm: 0.9846546053886414
      policy_entropy: 0.0018183795036748052
      policy_loss: 8.448652693004988e-07
      var_gnorm: 27.398468017578125
      vf_explained_var: 5.960464477539063e-08
      vf_loss: 0.0006384414155036211
    num_steps_sampled: 1990000
    num_steps_trained: 1990000
    wait_time_ms: 71.254
  iterations_since_restore: 398
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 3451.1122167110443
  time_this_iter_s: 8.202243089675903
  time_total_s: 3451.1122167110443
  timestamp: 1594861758
  timesteps_since_restore: 1990000
  timesteps_this_iter: 5000
  timesteps_total: 1990000
  training_iteration: 398
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 3451 s, 398 iter, 1990000 ts, -2.2e+06 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-09-27
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -2198652.519851854
  episode_reward_min: -33840000.00001373
  episodes_this_iter: 1
  episodes_total: 398
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.73
    dispatch_time_ms: 8.479
    learner:
      cur_lr: 0.0012274660402908921
      grad_gnorm: 0.05437515303492546
      policy_entropy: 0.001880729105323553
      policy_loss: -1.1136356903307387e-07
      var_gnorm: 27.39854621887207
      vf_explained_var: 0.0
      vf_loss: 1.946905740624061e-06
    num_steps_sampled: 1995000
    num_steps_trained: 1995000
    wait_time_ms: 69.398
  iterations_since_restore: 399
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 3459.2459003925323
  time_this_iter_s: 8.133683681488037
  time_total_s: 3459.2459003925323
  timestamp: 1594861767
  timesteps_since_restore: 1995000
  timesteps_this_iter: 5000
  timesteps_total: 1995000
  training_iteration: 399
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 3459 s, 399 iter, 1995000 ts, -2.2e+06 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-09-35
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -2052952.5198517954
  episode_reward_min: -33840000.00001373
  episodes_this_iter: 1
  episodes_total: 399
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 4.089
    dispatch_time_ms: 9.623
    learner:
      cur_lr: 0.0012271329760551453
      grad_gnorm: 1.4271560907363892
      policy_entropy: 0.0019425931386649609
      policy_loss: 1.4418708360608434e-06
      var_gnorm: 27.398576736450195
      vf_explained_var: 5.960464477539063e-08
      vf_loss: 0.0013412400148808956
    num_steps_sampled: 2000000
    num_steps_trained: 2000000
    wait_time_ms: 69.314
  iterations_since_restore: 400
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 3467.507468223572
  time_this_iter_s: 8.261567831039429
  time_total_s: 3467.507468223572
  timestamp: 1594861775
  timesteps_since_restore: 2000000
  timesteps_this_iter: 5000
  timesteps_total: 2000000
  training_iteration: 400
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 3467 s, 400 iter, 2000000 ts, -2.05e+06 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-09-43
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -1908557.4874223513
  episode_reward_min: -33840000.00001373
  episodes_this_iter: 1
  episodes_total: 400
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 3.014
    dispatch_time_ms: 8.822
    learner:
      cur_lr: 0.0012268000282347202
      grad_gnorm: 0.020858392119407654
      policy_entropy: 0.0020274166017770767
      policy_loss: -7.937514645561805e-09
      var_gnorm: 27.398685455322266
      vf_explained_var: 0.0
      vf_loss: 2.8589363409992075e-07
    num_steps_sampled: 2005000
    num_steps_trained: 2005000
    wait_time_ms: 69.927
  iterations_since_restore: 401
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 3475.6282238960266
  time_this_iter_s: 8.120755672454834
  time_total_s: 3475.6282238960266
  timestamp: 1594861783
  timesteps_since_restore: 2005000
  timesteps_this_iter: 5000
  timesteps_total: 2005000
  training_iteration: 401
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 3475 s, 401 iter, 2005000 ts, -1.91e+06 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-09-51
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -1908507.4874223513
  episode_reward_min: -33840000.00001373
  episodes_this_iter: 1
  episodes_total: 401
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.922
    dispatch_time_ms: 8.383
    learner:
      cur_lr: 0.0012264669639989734
      grad_gnorm: 1.3352874517440796
      policy_entropy: 0.002108152024447918
      policy_loss: 2.3163734113040846e-06
      var_gnorm: 27.39876365661621
      vf_explained_var: 0.0
      vf_loss: 0.0011741636553779244
    num_steps_sampled: 2010000
    num_steps_trained: 2010000
    wait_time_ms: 69.927
  iterations_since_restore: 402
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 3483.7616889476776
  time_this_iter_s: 8.133465051651001
  time_total_s: 3483.7616889476776
  timestamp: 1594861791
  timesteps_since_restore: 2010000
  timesteps_this_iter: 5000
  timesteps_total: 2010000
  training_iteration: 402
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 3483 s, 402 iter, 2010000 ts, -1.91e+06 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-09-59
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -1763307.4874222921
  episode_reward_min: -33840000.00001373
  episodes_this_iter: 1
  episodes_total: 402
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.804
    dispatch_time_ms: 8.542
    learner:
      cur_lr: 0.0012261340161785483
      grad_gnorm: 0.060057178139686584
      policy_entropy: 0.0022189454175531864
      policy_loss: -3.148784011308692e-10
      var_gnorm: 27.39891815185547
      vf_explained_var: 0.0
      vf_loss: 2.37334370467579e-06
    num_steps_sampled: 2015000
    num_steps_trained: 2015000
    wait_time_ms: 69.17
  iterations_since_restore: 403
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 3491.881714820862
  time_this_iter_s: 8.120025873184204
  time_total_s: 3491.881714820862
  timestamp: 1594861799
  timesteps_since_restore: 2015000
  timesteps_this_iter: 5000
  timesteps_total: 2015000
  training_iteration: 403
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 3491 s, 403 iter, 2015000 ts, -1.76e+06 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-10-08
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -1763257.4874222921
  episode_reward_min: -33840000.00001373
  episodes_this_iter: 1
  episodes_total: 403
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 3.37
    dispatch_time_ms: 9.307
    learner:
      cur_lr: 0.0012258009519428015
      grad_gnorm: 1.5739045143127441
      policy_entropy: 0.0023301804903894663
      policy_loss: 2.778481757559348e-06
      var_gnorm: 27.3990421295166
      vf_explained_var: 0.0
      vf_loss: 0.0016311312792822719
    num_steps_sampled: 2020000
    num_steps_trained: 2020000
    wait_time_ms: 69.208
  iterations_since_restore: 404
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 3500.05850148201
  time_this_iter_s: 8.176786661148071
  time_total_s: 3500.05850148201
  timestamp: 1594861808
  timesteps_since_restore: 2020000
  timesteps_this_iter: 5000
  timesteps_total: 2020000
  training_iteration: 404
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 3500 s, 404 iter, 2020000 ts, -1.76e+06 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-10-16
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -1618057.4874222332
  episode_reward_min: -33840000.00001373
  episodes_this_iter: 1
  episodes_total: 404
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.807
    dispatch_time_ms: 6.409
    learner:
      cur_lr: 0.0012254680041223764
      grad_gnorm: 1.5099833011627197
      policy_entropy: 0.0024879537522792816
      policy_loss: -1.2456373497116147e-06
      var_gnorm: 27.399389266967773
      vf_explained_var: 5.960464477539063e-08
      vf_loss: 0.0015013071242719889
    num_steps_sampled: 2025000
    num_steps_trained: 2025000
    wait_time_ms: 72.173
  iterations_since_restore: 405
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 3508.645325899124
  time_this_iter_s: 8.586824417114258
  time_total_s: 3508.645325899124
  timestamp: 1594861816
  timesteps_since_restore: 2025000
  timesteps_this_iter: 5000
  timesteps_total: 2025000
  training_iteration: 405
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 3508 s, 405 iter, 2025000 ts, -1.62e+06 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-10-24
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -1472357.4874221745
  episode_reward_min: -33840000.00001373
  episodes_this_iter: 1
  episodes_total: 405
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.824
    dispatch_time_ms: 8.338
    learner:
      cur_lr: 0.0012251350563019514
      grad_gnorm: 2.378998041152954
      policy_entropy: 0.0026454611215740442
      policy_loss: 2.0824104467465077e-06
      var_gnorm: 27.399547576904297
      vf_explained_var: 0.0
      vf_loss: 0.003726899391040206
    num_steps_sampled: 2030000
    num_steps_trained: 2030000
    wait_time_ms: 70.023
  iterations_since_restore: 406
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 3516.8793485164642
  time_this_iter_s: 8.234022617340088
  time_total_s: 3516.8793485164642
  timestamp: 1594861824
  timesteps_since_restore: 2030000
  timesteps_this_iter: 5000
  timesteps_total: 2030000
  training_iteration: 406
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 3516 s, 406 iter, 2030000 ts, -1.47e+06 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-10-33
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -1375707.4874221352
  episode_reward_min: -33840000.00001373
  episodes_this_iter: 1
  episodes_total: 406
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.728
    dispatch_time_ms: 7.72
    learner:
      cur_lr: 0.0012248019920662045
      grad_gnorm: 0.0037761214189231396
      policy_entropy: 0.0028792202938348055
      policy_loss: -4.2425199353601784e-08
      var_gnorm: 27.40003204345703
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 9.55406509461909e-09
    num_steps_sampled: 2035000
    num_steps_trained: 2035000
    wait_time_ms: 74.822
  iterations_since_restore: 407
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 3525.0631415843964
  time_this_iter_s: 8.183793067932129
  time_total_s: 3525.0631415843964
  timestamp: 1594861833
  timesteps_since_restore: 2035000
  timesteps_this_iter: 5000
  timesteps_total: 2035000
  training_iteration: 407
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 3525 s, 407 iter, 2035000 ts, -1.38e+06 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-10-41
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -1230007.4874220768
  episode_reward_min: -33840000.00001373
  episodes_this_iter: 1
  episodes_total: 407
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.941
    dispatch_time_ms: 6.698
    learner:
      cur_lr: 0.0012244690442457795
      grad_gnorm: 2.4381442070007324
      policy_entropy: 0.0031081275083124638
      policy_loss: 2.2321967207972193e-06
      var_gnorm: 27.400381088256836
      vf_explained_var: 2.384185791015625e-07
      vf_loss: 0.003914481494575739
    num_steps_sampled: 2040000
    num_steps_trained: 2040000
    wait_time_ms: 70.85
  iterations_since_restore: 408
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 3533.195850610733
  time_this_iter_s: 8.13270902633667
  time_total_s: 3533.195850610733
  timestamp: 1594861841
  timesteps_since_restore: 2040000
  timesteps_this_iter: 5000
  timesteps_total: 2040000
  training_iteration: 408
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 3533 s, 408 iter, 2040000 ts, -1.23e+06 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-10-49
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -1084807.4874220178
  episode_reward_min: -33840000.00001373
  episodes_this_iter: 1
  episodes_total: 408
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 3.172
    dispatch_time_ms: 6.547
    learner:
      cur_lr: 0.0012241359800100327
      grad_gnorm: 0.004643566440790892
      policy_entropy: 0.003496011719107628
      policy_loss: -1.3774138274413872e-08
      var_gnorm: 27.401113510131836
      vf_explained_var: 5.960464477539063e-08
      vf_loss: 1.3876321425243532e-08
    num_steps_sampled: 2045000
    num_steps_trained: 2045000
    wait_time_ms: 76.311
  iterations_since_restore: 409
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 3541.360140800476
  time_this_iter_s: 8.164290189743042
  time_total_s: 3541.360140800476
  timestamp: 1594861849
  timesteps_since_restore: 2045000
  timesteps_this_iter: 5000
  timesteps_total: 2045000
  training_iteration: 409
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 3541 s, 409 iter, 2045000 ts, -1.08e+06 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-10-57
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -939107.4874219593
  episode_reward_min: -33840000.00001373
  episodes_this_iter: 1
  episodes_total: 409
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.716
    dispatch_time_ms: 8.443
    learner:
      cur_lr: 0.0012238030321896076
      grad_gnorm: 2.173769235610962
      policy_entropy: 0.0038425929378718138
      policy_loss: 1.2020846043014899e-06
      var_gnorm: 27.401657104492188
      vf_explained_var: 0.0
      vf_loss: 0.0031113214790821075
    num_steps_sampled: 2050000
    num_steps_trained: 2050000
    wait_time_ms: 70.948
  iterations_since_restore: 410
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 3549.5172855854034
  time_this_iter_s: 8.157144784927368
  time_total_s: 3549.5172855854034
  timestamp: 1594861857
  timesteps_since_restore: 2050000
  timesteps_this_iter: 5000
  timesteps_total: 2050000
  training_iteration: 410
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 3549 s, 410 iter, 2050000 ts, -9.39e+05 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-11-05
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -793907.4874219002
  episode_reward_min: -33840000.00001373
  episodes_this_iter: 1
  episodes_total: 410
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.843
    dispatch_time_ms: 5.447
    learner:
      cur_lr: 0.0012234699679538608
      grad_gnorm: 0.0008899311651475728
      policy_entropy: 0.004650935065001249
      policy_loss: -9.232186926055874e-08
      var_gnorm: 27.402938842773438
      vf_explained_var: 0.0
      vf_loss: 6.103502148135931e-10
    num_steps_sampled: 2055000
    num_steps_trained: 2055000
    wait_time_ms: 76.085
  iterations_since_restore: 411
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 3557.695833683014
  time_this_iter_s: 8.178548097610474
  time_total_s: 3557.695833683014
  timestamp: 1594861865
  timesteps_since_restore: 2055000
  timesteps_this_iter: 5000
  timesteps_total: 2055000
  training_iteration: 411
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 3557 s, 411 iter, 2055000 ts, -7.94e+05 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-11-14
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -793857.4874219002
  episode_reward_min: -33840000.00001373
  episodes_this_iter: 1
  episodes_total: 411
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.566
    dispatch_time_ms: 6.24
    learner:
      cur_lr: 0.0012231370201334357
      grad_gnorm: 1.9760745763778687
      policy_entropy: 0.005390420090407133
      policy_loss: 6.957266123208683e-07
      var_gnorm: 27.404001235961914
      vf_explained_var: 5.960464477539063e-08
      vf_loss: 0.0025712873321026564
    num_steps_sampled: 2060000
    num_steps_trained: 2060000
    wait_time_ms: 74.858
  iterations_since_restore: 412
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 3565.857403755188
  time_this_iter_s: 8.161570072174072
  time_total_s: 3565.857403755188
  timestamp: 1594861874
  timesteps_since_restore: 2060000
  timesteps_this_iter: 5000
  timesteps_total: 2060000
  training_iteration: 412
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 3565 s, 412 iter, 2060000 ts, -7.94e+05 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-11-22
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -455457.4874217629
  episode_reward_min: -24154208.212236285
  episodes_this_iter: 1
  episodes_total: 412
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.515
    dispatch_time_ms: 7.739
    learner:
      cur_lr: 0.0012228039558976889
      grad_gnorm: 31.35429573059082
      policy_entropy: 0.0008251002873294055
      policy_loss: -7.684102456551045e-06
      var_gnorm: 27.42407989501953
      vf_explained_var: 0.0
      vf_loss: 18.10403823852539
    num_steps_sampled: 2065000
    num_steps_trained: 2065000
    wait_time_ms: 70.838
  iterations_since_restore: 413
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 3573.9623334407806
  time_this_iter_s: 8.104929685592651
  time_total_s: 3573.9623334407806
  timestamp: 1594861882
  timesteps_since_restore: 2065000
  timesteps_this_iter: 5000
  timesteps_total: 2065000
  training_iteration: 413
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 3573 s, 413 iter, 2065000 ts, -4.55e+05 rew

agent-1: -150.9999987250905
agent-2: 0.0
agent-3: -9999.999915431026
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
-1
0
-50
0
0
Sum Reward: -51
Avg Reward: -10.2
Min Reward: -50
Max Reward: 0
Gini Coefficient: -0.792156862745098
20:20 Ratio: -0.0
Max-min Ratio: -0.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-11-30
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -214016.9152985416
  episode_reward_min: -14520000.000005912
  episodes_this_iter: 1
  episodes_total: 413
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.577
    dispatch_time_ms: 7.15
    learner:
      cur_lr: 0.0012224710080772638
      grad_gnorm: 0.40124964714050293
      policy_entropy: 0.0007523877429775894
      policy_loss: 8.740934731576999e-08
      var_gnorm: 27.42136001586914
      vf_explained_var: 1.1920928955078125e-07
      vf_loss: 0.0001060106951626949
    num_steps_sampled: 2070000
    num_steps_trained: 2070000
    wait_time_ms: 74.338
  iterations_since_restore: 414
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 3582.19682097435
  time_this_iter_s: 8.234487533569336
  time_total_s: 3582.19682097435
  timestamp: 1594861890
  timesteps_since_restore: 2070000
  timesteps_this_iter: 5000
  timesteps_total: 2070000
  training_iteration: 414
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 3582 s, 414 iter, 2070000 ts, -2.14e+05 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-11-38
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -68816.91529848248
  episode_reward_min: -5432047.754003576
  episodes_this_iter: 1
  episodes_total: 414
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 3.201
    dispatch_time_ms: 9.07
    learner:
      cur_lr: 0.001222137943841517
      grad_gnorm: 0.006876657716929913
      policy_entropy: 0.0008648158982396126
      policy_loss: -1.181890696422272e-09
      var_gnorm: 27.42232894897461
      vf_explained_var: 0.0
      vf_loss: 3.153696326307909e-08
    num_steps_sampled: 2075000
    num_steps_trained: 2075000
    wait_time_ms: 70.04
  iterations_since_restore: 415
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 3590.4042706489563
  time_this_iter_s: 8.207449674606323
  time_total_s: 3590.4042706489563
  timestamp: 1594861898
  timesteps_since_restore: 2075000
  timesteps_this_iter: 5000
  timesteps_total: 2075000
  training_iteration: 415
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 3590 s, 415 iter, 2075000 ts, -6.88e+04 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-11-46
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -14496.43775844672
  episode_reward_min: -1439492.775930516
  episodes_this_iter: 1
  episodes_total: 415
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.979
    dispatch_time_ms: 9.37
    learner:
      cur_lr: 0.001221804996021092
      grad_gnorm: 0.5016091465950012
      policy_entropy: 0.0009258446516469121
      policy_loss: 1.365900033079015e-07
      var_gnorm: 27.422889709472656
      vf_explained_var: 5.960464477539063e-08
      vf_loss: 0.00016566748672630638
    num_steps_sampled: 2080000
    num_steps_trained: 2080000
    wait_time_ms: 69.645
  iterations_since_restore: 416
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 3598.5757834911346
  time_this_iter_s: 8.171512842178345
  time_total_s: 3598.5757834911346
  timestamp: 1594861906
  timesteps_since_restore: 2080000
  timesteps_this_iter: 5000
  timesteps_total: 2080000
  training_iteration: 416
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 3598 s, 416 iter, 2080000 ts, -1.45e+04 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-11-55
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -101.50999914156111
  episode_reward_min: -10150.999914156111
  episodes_this_iter: 1
  episodes_total: 416
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 3.046
    dispatch_time_ms: 8.54
    learner:
      cur_lr: 0.001221472048200667
      grad_gnorm: 0.012640435248613358
      policy_entropy: 0.0011328075779601932
      policy_loss: -4.336321968168022e-09
      var_gnorm: 27.424339294433594
      vf_explained_var: 0.0
      vf_loss: 1.0449715404092785e-07
    num_steps_sampled: 2085000
    num_steps_trained: 2085000
    wait_time_ms: 70.124
  iterations_since_restore: 417
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 3606.7195432186127
  time_this_iter_s: 8.143759727478027
  time_total_s: 3606.7195432186127
  timestamp: 1594861915
  timesteps_since_restore: 2085000
  timesteps_this_iter: 5000
  timesteps_total: 2085000
  training_iteration: 417
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 3606 s, 417 iter, 2085000 ts, -102 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-12-03
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -101.50999914156111
  episode_reward_min: -10150.999914156111
  episodes_this_iter: 1
  episodes_total: 417
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.8
    dispatch_time_ms: 7.494
    learner:
      cur_lr: 0.00122113898396492
      grad_gnorm: 0.7748851776123047
      policy_entropy: 0.0012812443310394883
      policy_loss: -5.64684334847243e-08
      var_gnorm: 27.42525863647461
      vf_explained_var: 5.960464477539063e-08
      vf_loss: 0.0003953611012548208
    num_steps_sampled: 2090000
    num_steps_trained: 2090000
    wait_time_ms: 73.024
  iterations_since_restore: 418
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 3614.9015102386475
  time_this_iter_s: 8.18196702003479
  time_total_s: 3614.9015102386475
  timestamp: 1594861923
  timesteps_since_restore: 2090000
  timesteps_this_iter: 5000
  timesteps_total: 2090000
  training_iteration: 418
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 3614 s, 418 iter, 2090000 ts, -102 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-12-11
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -101.50999914156111
  episode_reward_min: -10150.999914156111
  episodes_this_iter: 1
  episodes_total: 418
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.758
    dispatch_time_ms: 7.131
    learner:
      cur_lr: 0.001220806036144495
      grad_gnorm: 0.0039793276228010654
      policy_entropy: 0.001749637071043253
      policy_loss: -5.24803978052546e-09
      var_gnorm: 27.427593231201172
      vf_explained_var: 1.1920928955078125e-07
      vf_loss: 1.0842661879451043e-08
    num_steps_sampled: 2095000
    num_steps_trained: 2095000
    wait_time_ms: 74.522
  iterations_since_restore: 419
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 3623.0995683670044
  time_this_iter_s: 8.198058128356934
  time_total_s: 3623.0995683670044
  timestamp: 1594861931
  timesteps_since_restore: 2095000
  timesteps_this_iter: 5000
  timesteps_total: 2095000
  training_iteration: 419
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 3623 s, 419 iter, 2095000 ts, -102 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-12-19
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -101.50999914156111
  episode_reward_min: -10150.999914156111
  episodes_this_iter: 1
  episodes_total: 419
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 3.0
    dispatch_time_ms: 8.532
    learner:
      cur_lr: 0.0012204729719087481
      grad_gnorm: 19.846511840820312
      policy_entropy: 0.003946866374462843
      policy_loss: -0.00015801347035448998
      var_gnorm: 27.429004669189453
      vf_explained_var: -1.0
      vf_loss: 2.1494863033294678
    num_steps_sampled: 2100000
    num_steps_trained: 2100000
    wait_time_ms: 70.421
  iterations_since_restore: 420
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 3631.2260353565216
  time_this_iter_s: 8.126466989517212
  time_total_s: 3631.2260353565216
  timestamp: 1594861939
  timesteps_since_restore: 2100000
  timesteps_this_iter: 5000
  timesteps_total: 2100000
  training_iteration: 420
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 3631 s, 420 iter, 2100000 ts, -102 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-12-27
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -101.50999914156111
  episode_reward_min: -10150.999914156111
  episodes_this_iter: 1
  episodes_total: 420
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.73
    dispatch_time_ms: 7.416
    learner:
      cur_lr: 0.0012201400240883231
      grad_gnorm: 0.04693378135561943
      policy_entropy: 0.004174742382019758
      policy_loss: -1.0826283869391773e-07
      var_gnorm: 27.43429183959961
      vf_explained_var: 5.960464477539063e-08
      vf_loss: 1.4471503391177976e-06
    num_steps_sampled: 2105000
    num_steps_trained: 2105000
    wait_time_ms: 68.642
  iterations_since_restore: 421
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 3639.3500452041626
  time_this_iter_s: 8.124009847640991
  time_total_s: 3639.3500452041626
  timestamp: 1594861947
  timesteps_since_restore: 2105000
  timesteps_this_iter: 5000
  timesteps_total: 2105000
  training_iteration: 421
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 3639 s, 421 iter, 2105000 ts, -102 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-12-36
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -101.50999914156111
  episode_reward_min: -10150.999914156111
  episodes_this_iter: 2
  episodes_total: 422
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.423
    dispatch_time_ms: 7.039
    learner:
      cur_lr: 0.0012198069598525763
      grad_gnorm: 0.011517273262143135
      policy_entropy: 0.00743835186585784
      policy_loss: -3.1361395258500124e-08
      var_gnorm: 27.438989639282227
      vf_explained_var: -1.0
      vf_loss: 6.921109019231153e-08
    num_steps_sampled: 2110000
    num_steps_trained: 2110000
    wait_time_ms: 71.675
  iterations_since_restore: 422
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 3647.499782562256
  time_this_iter_s: 8.149737358093262
  time_total_s: 3647.499782562256
  timestamp: 1594861956
  timesteps_since_restore: 2110000
  timesteps_this_iter: 5000
  timesteps_total: 2110000
  training_iteration: 422
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 3647 s, 422 iter, 2110000 ts, -102 rew

Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-12-44
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -101.50999914156111
  episode_reward_min: -10150.999914156111
  episodes_this_iter: 0
  episodes_total: 422
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.638
    dispatch_time_ms: 8.805
    learner:
      cur_lr: 0.0012194740120321512
      grad_gnorm: 0.020487874746322632
      policy_entropy: 0.6151453256607056
      policy_loss: -2.582943307061214e-05
      var_gnorm: 27.529830932617188
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 2.60710692145949e-07
    num_steps_sampled: 2115000
    num_steps_trained: 2115000
    wait_time_ms: 70.763
  iterations_since_restore: 423
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 3655.6253666877747
  time_this_iter_s: 8.125584125518799
  time_total_s: 3655.6253666877747
  timestamp: 1594861964
  timesteps_since_restore: 2115000
  timesteps_this_iter: 5000
  timesteps_total: 2115000
  training_iteration: 423
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 3655 s, 423 iter, 2115000 ts, -102 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-12-52
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -101.50999914156111
  episode_reward_min: -10150.999914156111
  episodes_this_iter: 2
  episodes_total: 424
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.563
    dispatch_time_ms: 9.021
    learner:
      cur_lr: 0.0012191409477964044
      grad_gnorm: 0.009469132870435715
      policy_entropy: 0.010722804814577103
      policy_loss: 3.89332157624267e-08
      var_gnorm: 27.543630599975586
      vf_explained_var: -1.0
      vf_loss: 4.6781515550264885e-08
    num_steps_sampled: 2120000
    num_steps_trained: 2120000
    wait_time_ms: 67.638
  iterations_since_restore: 424
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 3663.515332698822
  time_this_iter_s: 7.889966011047363
  time_total_s: 3663.515332698822
  timestamp: 1594861972
  timesteps_since_restore: 2120000
  timesteps_this_iter: 5000
  timesteps_total: 2120000
  training_iteration: 424
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 3663 s, 424 iter, 2120000 ts, -102 rew

Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-13-00
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -101.50999914156111
  episode_reward_min: -10150.999914156111
  episodes_this_iter: 0
  episodes_total: 424
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.838
    dispatch_time_ms: 9.042
    learner:
      cur_lr: 0.0012188079999759793
      grad_gnorm: 0.04964931309223175
      policy_entropy: 0.01462707482278347
      policy_loss: 2.86613300204408e-07
      var_gnorm: 27.542091369628906
      vf_explained_var: 0.0
      vf_loss: 1.625315121600579e-06
    num_steps_sampled: 2125000
    num_steps_trained: 2125000
    wait_time_ms: 67.854
  iterations_since_restore: 425
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 3671.5027816295624
  time_this_iter_s: 7.9874489307403564
  time_total_s: 3671.5027816295624
  timestamp: 1594861980
  timesteps_since_restore: 2125000
  timesteps_this_iter: 5000
  timesteps_total: 2125000
  training_iteration: 425
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 3671 s, 425 iter, 2125000 ts, -102 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-13-08
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -101.50999914156111
  episode_reward_min: -10150.999914156111
  episodes_this_iter: 1
  episodes_total: 425
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.539
    dispatch_time_ms: 8.128
    learner:
      cur_lr: 0.0012184750521555543
      grad_gnorm: 0.0005974270752631128
      policy_entropy: 0.018405206501483917
      policy_loss: 7.671032697942337e-09
      var_gnorm: 27.541217803955078
      vf_explained_var: 5.960464477539063e-08
      vf_loss: 1.9447048138498957e-10
    num_steps_sampled: 2130000
    num_steps_trained: 2130000
    wait_time_ms: 71.113
  iterations_since_restore: 426
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 3679.476799964905
  time_this_iter_s: 7.974018335342407
  time_total_s: 3679.476799964905
  timestamp: 1594861988
  timesteps_since_restore: 2130000
  timesteps_this_iter: 5000
  timesteps_total: 2130000
  training_iteration: 426
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 3679 s, 426 iter, 2130000 ts, -102 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-13-16
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -101.50999914156111
  episode_reward_min: -10150.999914156111
  episodes_this_iter: 1
  episodes_total: 426
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.907
    dispatch_time_ms: 9.667
    learner:
      cur_lr: 0.0012181419879198074
      grad_gnorm: 0.01671869121491909
      policy_entropy: 0.03830239921808243
      policy_loss: 1.8027077430815552e-07
      var_gnorm: 27.53815460205078
      vf_explained_var: 0.0
      vf_loss: 1.835234968439181e-07
    num_steps_sampled: 2135000
    num_steps_trained: 2135000
    wait_time_ms: 67.922
  iterations_since_restore: 427
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 3687.353854894638
  time_this_iter_s: 7.877054929733276
  time_total_s: 3687.353854894638
  timestamp: 1594861996
  timesteps_since_restore: 2135000
  timesteps_this_iter: 5000
  timesteps_total: 2135000
  training_iteration: 427
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 3687 s, 427 iter, 2135000 ts, -102 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-13-24
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -101.50999914156111
  episode_reward_min: -10150.999914156111
  episodes_this_iter: 1
  episodes_total: 427
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.795
    dispatch_time_ms: 7.684
    learner:
      cur_lr: 0.0012178090400993824
      grad_gnorm: 0.8026032447814941
      policy_entropy: 0.09740259498357773
      policy_loss: 4.654557869798737e-06
      var_gnorm: 27.534847259521484
      vf_explained_var: 0.0
      vf_loss: 0.00042418696102686226
    num_steps_sampled: 2140000
    num_steps_trained: 2140000
    wait_time_ms: 70.954
  iterations_since_restore: 428
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 3695.329288959503
  time_this_iter_s: 7.975434064865112
  time_total_s: 3695.329288959503
  timestamp: 1594862004
  timesteps_since_restore: 2140000
  timesteps_this_iter: 5000
  timesteps_total: 2140000
  training_iteration: 428
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 3695 s, 428 iter, 2140000 ts, -102 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-13-32
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -101.50999914156111
  episode_reward_min: -10150.999914156111
  episodes_this_iter: 1
  episodes_total: 428
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.387
    dispatch_time_ms: 8.005
    learner:
      cur_lr: 0.0012174759758636355
      grad_gnorm: 0.04914341866970062
      policy_entropy: 34.276702880859375
      policy_loss: -0.00509435823187232
      var_gnorm: 27.518856048583984
      vf_explained_var: 0.0
      vf_loss: 5.08727680426091e-07
    num_steps_sampled: 2145000
    num_steps_trained: 2145000
    wait_time_ms: 70.789
  iterations_since_restore: 429
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 3703.3371758461
  time_this_iter_s: 8.00788688659668
  time_total_s: 3703.3371758461
  timestamp: 1594862012
  timesteps_since_restore: 2145000
  timesteps_this_iter: 5000
  timesteps_total: 2145000
  training_iteration: 429
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 3703 s, 429 iter, 2145000 ts, -102 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-13-40
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -101.50999914156111
  episode_reward_min: -10150.999914156111
  episodes_this_iter: 1
  episodes_total: 429
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.7
    dispatch_time_ms: 8.225
    learner:
      cur_lr: 0.0012171430280432105
      grad_gnorm: 2.8415212631225586
      policy_entropy: 23.802112579345703
      policy_loss: -0.3448247015476227
      var_gnorm: 27.519287109375
      vf_explained_var: 0.0
      vf_loss: 0.0009788621682673693
    num_steps_sampled: 2150000
    num_steps_trained: 2150000
    wait_time_ms: 70.5
  iterations_since_restore: 430
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 3711.442773103714
  time_this_iter_s: 8.105597257614136
  time_total_s: 3711.442773103714
  timestamp: 1594862020
  timesteps_since_restore: 2150000
  timesteps_this_iter: 5000
  timesteps_total: 2150000
  training_iteration: 430
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 3711 s, 430 iter, 2150000 ts, -102 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-13-48
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -101.50999914156111
  episode_reward_min: -10150.999914156111
  episodes_this_iter: 1
  episodes_total: 430
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.441
    dispatch_time_ms: 6.785
    learner:
      cur_lr: 0.0012168099638074636
      grad_gnorm: 0.043062347918748856
      policy_entropy: 0.0032345864456146955
      policy_loss: -5.14377731519744e-08
      var_gnorm: 27.536666870117188
      vf_explained_var: 0.0
      vf_loss: 1.2229131698404672e-06
    num_steps_sampled: 2155000
    num_steps_trained: 2155000
    wait_time_ms: 70.91
  iterations_since_restore: 431
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 3719.5092449188232
  time_this_iter_s: 8.066471815109253
  time_total_s: 3719.5092449188232
  timestamp: 1594862028
  timesteps_since_restore: 2155000
  timesteps_this_iter: 5000
  timesteps_total: 2155000
  training_iteration: 431
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 3719 s, 431 iter, 2155000 ts, -102 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-13-56
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -101.50999914156111
  episode_reward_min: -10150.999914156111
  episodes_this_iter: 1
  episodes_total: 431
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.844
    dispatch_time_ms: 7.082
    learner:
      cur_lr: 0.0012164770159870386
      grad_gnorm: 0.4782937169075012
      policy_entropy: 0.0032365391962230206
      policy_loss: -4.6522472985088825e-07
      var_gnorm: 27.536630630493164
      vf_explained_var: 0.0
      vf_loss: 0.000150644380482845
    num_steps_sampled: 2160000
    num_steps_trained: 2160000
    wait_time_ms: 67.923
  iterations_since_restore: 432
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 3727.7031350135803
  time_this_iter_s: 8.19389009475708
  time_total_s: 3727.7031350135803
  timestamp: 1594862036
  timesteps_since_restore: 2160000
  timesteps_this_iter: 5000
  timesteps_total: 2160000
  training_iteration: 432
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 3727 s, 432 iter, 2160000 ts, -102 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-14-05
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -101.50999914156111
  episode_reward_min: -10150.999914156111
  episodes_this_iter: 1
  episodes_total: 432
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.614
    dispatch_time_ms: 8.589
    learner:
      cur_lr: 0.0012161439517512918
      grad_gnorm: 0.012544517405331135
      policy_entropy: 0.0032441557850688696
      policy_loss: 6.590236267811633e-08
      var_gnorm: 27.53627586364746
      vf_explained_var: 5.960464477539063e-08
      vf_loss: 1.0326502319912834e-07
    num_steps_sampled: 2165000
    num_steps_trained: 2165000
    wait_time_ms: 69.173
  iterations_since_restore: 433
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 3736.2112708091736
  time_this_iter_s: 8.508135795593262
  time_total_s: 3736.2112708091736
  timestamp: 1594862045
  timesteps_since_restore: 2165000
  timesteps_this_iter: 5000
  timesteps_total: 2165000
  training_iteration: 433
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 3736 s, 433 iter, 2165000 ts, -102 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-14-13
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -101.50999914156111
  episode_reward_min: -10150.999914156111
  episodes_this_iter: 1
  episodes_total: 433
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.568
    dispatch_time_ms: 8.285
    learner:
      cur_lr: 0.0012158110039308667
      grad_gnorm: 0.00046915418352000415
      policy_entropy: 0.003247323911637068
      policy_loss: -2.8024331744092024e-09
      var_gnorm: 27.53627586364746
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 1.3262624332099904e-10
    num_steps_sampled: 2170000
    num_steps_trained: 2170000
    wait_time_ms: 71.875
  iterations_since_restore: 434
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 3744.388090610504
  time_this_iter_s: 8.176819801330566
  time_total_s: 3744.388090610504
  timestamp: 1594862053
  timesteps_since_restore: 2170000
  timesteps_this_iter: 5000
  timesteps_total: 2170000
  training_iteration: 434
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 3744 s, 434 iter, 2170000 ts, -102 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-14-21
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -101.50999914156111
  episode_reward_min: -10150.999914156111
  episodes_this_iter: 1
  episodes_total: 434
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 3.451
    dispatch_time_ms: 7.846
    learner:
      cur_lr: 0.0012154780561104417
      grad_gnorm: 0.0024172496050596237
      policy_entropy: 0.0032558897510170937
      policy_loss: 5.453741636074483e-08
      var_gnorm: 27.53586769104004
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 3.847159923964227e-09
    num_steps_sampled: 2175000
    num_steps_trained: 2175000
    wait_time_ms: 73.85
  iterations_since_restore: 435
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 3752.5718290805817
  time_this_iter_s: 8.183738470077515
  time_total_s: 3752.5718290805817
  timestamp: 1594862061
  timesteps_since_restore: 2175000
  timesteps_this_iter: 5000
  timesteps_total: 2175000
  training_iteration: 435
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 3752 s, 435 iter, 2175000 ts, -102 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-14-29
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -101.50999914156111
  episode_reward_min: -10150.999914156111
  episodes_this_iter: 1
  episodes_total: 435
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.68
    dispatch_time_ms: 6.01
    learner:
      cur_lr: 0.0012151449918746948
      grad_gnorm: 0.0004337581049185246
      policy_entropy: 0.0032595559023320675
      policy_loss: 2.4767912165657435e-09
      var_gnorm: 27.535863876342773
      vf_explained_var: 1.1920928955078125e-07
      vf_loss: 1.4534451420189498e-10
    num_steps_sampled: 2180000
    num_steps_trained: 2180000
    wait_time_ms: 75.131
  iterations_since_restore: 436
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 3760.754645586014
  time_this_iter_s: 8.182816505432129
  time_total_s: 3760.754645586014
  timestamp: 1594862069
  timesteps_since_restore: 2180000
  timesteps_this_iter: 5000
  timesteps_total: 2180000
  training_iteration: 436
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 3760 s, 436 iter, 2180000 ts, -102 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-14-37
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -101.50999914156111
  episode_reward_min: -10150.999914156111
  episodes_this_iter: 1
  episodes_total: 436
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.798
    dispatch_time_ms: 7.066
    learner:
      cur_lr: 0.0012148120440542698
      grad_gnorm: 0.04415164515376091
      policy_entropy: 0.0032750798854976892
      policy_loss: -2.8125686668545313e-08
      var_gnorm: 27.535442352294922
      vf_explained_var: 0.0
      vf_loss: 1.283622850678512e-06
    num_steps_sampled: 2185000
    num_steps_trained: 2185000
    wait_time_ms: 72.996
  iterations_since_restore: 437
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 3768.866355895996
  time_this_iter_s: 8.1117103099823
  time_total_s: 3768.866355895996
  timestamp: 1594862077
  timesteps_since_restore: 2185000
  timesteps_this_iter: 5000
  timesteps_total: 2185000
  training_iteration: 437
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 3768 s, 437 iter, 2185000 ts, -102 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-14-46
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -101.50999914156111
  episode_reward_min: -10150.999914156111
  episodes_this_iter: 1
  episodes_total: 437
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 3.12
    dispatch_time_ms: 8.327
    learner:
      cur_lr: 0.001214478979818523
      grad_gnorm: 0.5604851841926575
      policy_entropy: 0.0032793667633086443
      policy_loss: -5.588774456555257e-07
      var_gnorm: 27.535396575927734
      vf_explained_var: 0.0
      vf_loss: 0.00020689792290795594
    num_steps_sampled: 2190000
    num_steps_trained: 2190000
    wait_time_ms: 70.463
  iterations_since_restore: 438
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 3776.9762678146362
  time_this_iter_s: 8.109911918640137
  time_total_s: 3776.9762678146362
  timestamp: 1594862086
  timesteps_since_restore: 2190000
  timesteps_this_iter: 5000
  timesteps_total: 2190000
  training_iteration: 438
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 3776 s, 438 iter, 2190000 ts, -102 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-14-54
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -101.50999914156111
  episode_reward_min: -10150.999914156111
  episodes_this_iter: 1
  episodes_total: 438
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.387
    dispatch_time_ms: 6.629
    learner:
      cur_lr: 0.001214146031998098
      grad_gnorm: 0.014195981435477734
      policy_entropy: 0.0032892453018575907
      policy_loss: -7.877839891534677e-08
      var_gnorm: 27.535009384155273
      vf_explained_var: 0.0
      vf_loss: 1.329036223296498e-07
    num_steps_sampled: 2195000
    num_steps_trained: 2195000
    wait_time_ms: 72.765
  iterations_since_restore: 439
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 3785.208189725876
  time_this_iter_s: 8.231921911239624
  time_total_s: 3785.208189725876
  timestamp: 1594862094
  timesteps_since_restore: 2195000
  timesteps_this_iter: 5000
  timesteps_total: 2195000
  training_iteration: 439
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 3785 s, 439 iter, 2195000 ts, -102 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-15-02
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -101.50999914156111
  episode_reward_min: -10150.999914156111
  episodes_this_iter: 1
  episodes_total: 439
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.594
    dispatch_time_ms: 8.458
    learner:
      cur_lr: 0.001213812967762351
      grad_gnorm: 1.5082567930221558
      policy_entropy: 0.0032946120481938124
      policy_loss: 8.106098903226666e-07
      var_gnorm: 27.534900665283203
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 0.0014979835832491517
    num_steps_sampled: 2200000
    num_steps_trained: 2200000
    wait_time_ms: 70.791
  iterations_since_restore: 440
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 3793.406423807144
  time_this_iter_s: 8.19823408126831
  time_total_s: 3793.406423807144
  timestamp: 1594862102
  timesteps_since_restore: 2200000
  timesteps_this_iter: 5000
  timesteps_total: 2200000
  training_iteration: 440
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 3793 s, 440 iter, 2200000 ts, -102 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-15-10
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -101.50999914156111
  episode_reward_min: -10150.999914156111
  episodes_this_iter: 1
  episodes_total: 440
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.612
    dispatch_time_ms: 6.576
    learner:
      cur_lr: 0.001213480019941926
      grad_gnorm: 0.09166537970304489
      policy_entropy: 0.003305460326373577
      policy_loss: 7.886607988893957e-08
      var_gnorm: 27.534576416015625
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 5.539473022508901e-06
    num_steps_sampled: 2205000
    num_steps_trained: 2205000
    wait_time_ms: 72.208
  iterations_since_restore: 441
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 3801.5223300457
  time_this_iter_s: 8.115906238555908
  time_total_s: 3801.5223300457
  timestamp: 1594862110
  timesteps_since_restore: 2205000
  timesteps_this_iter: 5000
  timesteps_total: 2205000
  training_iteration: 441
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 3801 s, 441 iter, 2205000 ts, -102 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-15-18
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -101.50999914156111
  episode_reward_min: -10150.999914156111
  episodes_this_iter: 1
  episodes_total: 441
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 3.635
    dispatch_time_ms: 7.533
    learner:
      cur_lr: 0.0012131469557061791
      grad_gnorm: 1.9288957118988037
      policy_entropy: 0.003311905777081847
      policy_loss: 4.4212524130671227e-07
      var_gnorm: 27.53444480895996
      vf_explained_var: 0.0
      vf_loss: 0.0024498915299773216
    num_steps_sampled: 2210000
    num_steps_trained: 2210000
    wait_time_ms: 70.922
  iterations_since_restore: 442
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 3809.655856370926
  time_this_iter_s: 8.13352632522583
  time_total_s: 3809.655856370926
  timestamp: 1594862118
  timesteps_since_restore: 2210000
  timesteps_this_iter: 5000
  timesteps_total: 2210000
  training_iteration: 442
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 3809 s, 442 iter, 2210000 ts, -102 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-15-27
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -101.50999914156111
  episode_reward_min: -10150.999914156111
  episodes_this_iter: 1
  episodes_total: 442
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.88
    dispatch_time_ms: 6.268
    learner:
      cur_lr: 0.0012128140078857541
      grad_gnorm: 0.04101817309856415
      policy_entropy: 0.0033221908379346132
      policy_loss: -2.1221299562057538e-07
      var_gnorm: 27.53414535522461
      vf_explained_var: 0.0
      vf_loss: 1.1084740663136472e-06
    num_steps_sampled: 2215000
    num_steps_trained: 2215000
    wait_time_ms: 69.242
  iterations_since_restore: 443
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 3817.7896111011505
  time_this_iter_s: 8.13375473022461
  time_total_s: 3817.7896111011505
  timestamp: 1594862127
  timesteps_since_restore: 2215000
  timesteps_this_iter: 5000
  timesteps_total: 2215000
  training_iteration: 443
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 3817 s, 443 iter, 2215000 ts, -102 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-15-35
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -101.50999914156111
  episode_reward_min: -10150.999914156111
  episodes_this_iter: 1
  episodes_total: 443
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.513
    dispatch_time_ms: 7.28
    learner:
      cur_lr: 0.0012124809436500072
      grad_gnorm: 2.2093961238861084
      policy_entropy: 0.0033293557353317738
      policy_loss: 2.5268270746892085e-06
      var_gnorm: 27.533992767333984
      vf_explained_var: 0.0
      vf_loss: 0.0032143674325197935
    num_steps_sampled: 2220000
    num_steps_trained: 2220000
    wait_time_ms: 71.951
  iterations_since_restore: 444
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 3825.977053165436
  time_this_iter_s: 8.187442064285278
  time_total_s: 3825.977053165436
  timestamp: 1594862135
  timesteps_since_restore: 2220000
  timesteps_this_iter: 5000
  timesteps_total: 2220000
  training_iteration: 444
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 3825 s, 444 iter, 2220000 ts, -102 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-15-43
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -101.50999914156111
  episode_reward_min: -10150.999914156111
  episodes_this_iter: 1
  episodes_total: 444
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.621
    dispatch_time_ms: 7.386
    learner:
      cur_lr: 0.0012121479958295822
      grad_gnorm: 0.041926734149456024
      policy_entropy: 0.0033476068638265133
      policy_loss: 7.049469985531687e-08
      var_gnorm: 27.533710479736328
      vf_explained_var: 0.0
      vf_loss: 1.15751220164384e-06
    num_steps_sampled: 2225000
    num_steps_trained: 2225000
    wait_time_ms: 71.382
  iterations_since_restore: 445
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 3834.097395658493
  time_this_iter_s: 8.120342493057251
  time_total_s: 3834.097395658493
  timestamp: 1594862143
  timesteps_since_restore: 2225000
  timesteps_this_iter: 5000
  timesteps_total: 2225000
  training_iteration: 445
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 3834 s, 445 iter, 2225000 ts, -102 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-15-52
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -101.50999914156111
  episode_reward_min: -10150.999914156111
  episodes_this_iter: 1
  episodes_total: 445
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.37
    dispatch_time_ms: 7.192
    learner:
      cur_lr: 0.0012118150480091572
      grad_gnorm: 1.5841081142425537
      policy_entropy: 0.0033552017994225025
      policy_loss: -2.5205849851772655e-06
      var_gnorm: 27.533601760864258
      vf_explained_var: 0.0
      vf_loss: 0.0016523486701771617
    num_steps_sampled: 2230000
    num_steps_trained: 2230000
    wait_time_ms: 71.245
  iterations_since_restore: 446
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 3842.7232167720795
  time_this_iter_s: 8.625821113586426
  time_total_s: 3842.7232167720795
  timestamp: 1594862152
  timesteps_since_restore: 2230000
  timesteps_this_iter: 5000
  timesteps_total: 2230000
  training_iteration: 446
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 3842 s, 446 iter, 2230000 ts, -102 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-16-00
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -101.50999914156111
  episode_reward_min: -10150.999914156111
  episodes_this_iter: 1
  episodes_total: 446
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 3.394
    dispatch_time_ms: 8.205
    learner:
      cur_lr: 0.0012114819837734103
      grad_gnorm: 0.10218307375907898
      policy_entropy: 0.0033687367103993893
      policy_loss: -1.7965387399954125e-08
      var_gnorm: 27.53326988220215
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 6.871083769510733e-06
    num_steps_sampled: 2235000
    num_steps_trained: 2235000
    wait_time_ms: 69.552
  iterations_since_restore: 447
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 3850.8139476776123
  time_this_iter_s: 8.090730905532837
  time_total_s: 3850.8139476776123
  timestamp: 1594862160
  timesteps_since_restore: 2235000
  timesteps_this_iter: 5000
  timesteps_total: 2235000
  training_iteration: 447
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 3850 s, 447 iter, 2235000 ts, -102 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-16-08
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -101.50999914156111
  episode_reward_min: -10150.999914156111
  episodes_this_iter: 1
  episodes_total: 447
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.957
    dispatch_time_ms: 6.34
    learner:
      cur_lr: 0.0012111490359529853
      grad_gnorm: 1.992205262184143
      policy_entropy: 0.0033773991744965315
      policy_loss: -1.3799356111121597e-06
      var_gnorm: 27.533140182495117
      vf_explained_var: 0.0
      vf_loss: 0.0026135228108614683
    num_steps_sampled: 2240000
    num_steps_trained: 2240000
    wait_time_ms: 76.696
  iterations_since_restore: 448
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 3858.9965114593506
  time_this_iter_s: 8.182563781738281
  time_total_s: 3858.9965114593506
  timestamp: 1594862168
  timesteps_since_restore: 2240000
  timesteps_this_iter: 5000
  timesteps_total: 2240000
  training_iteration: 448
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 3858 s, 448 iter, 2240000 ts, -102 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-16-16
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -101.50999914156111
  episode_reward_min: -10150.999914156111
  episodes_this_iter: 1
  episodes_total: 448
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.901
    dispatch_time_ms: 7.368
    learner:
      cur_lr: 0.0012108159717172384
      grad_gnorm: 0.059794798493385315
      policy_entropy: 0.00339285796508193
      policy_loss: 1.6389643064940174e-07
      var_gnorm: 27.532835006713867
      vf_explained_var: 0.0
      vf_loss: 2.3560551198897883e-06
    num_steps_sampled: 2245000
    num_steps_trained: 2245000
    wait_time_ms: 70.821
  iterations_since_restore: 449
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 3867.120439529419
  time_this_iter_s: 8.12392807006836
  time_total_s: 3867.120439529419
  timestamp: 1594862176
  timesteps_since_restore: 2245000
  timesteps_this_iter: 5000
  timesteps_total: 2245000
  training_iteration: 449
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 3867 s, 449 iter, 2245000 ts, -102 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-16-24
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -101.50999914156111
  episode_reward_min: -10150.999914156111
  episodes_this_iter: 1
  episodes_total: 449
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.953
    dispatch_time_ms: 6.75
    learner:
      cur_lr: 0.0012104830238968134
      grad_gnorm: 2.0354323387145996
      policy_entropy: 0.00340274372138083
      policy_loss: 4.862733362642757e-07
      var_gnorm: 27.532703399658203
      vf_explained_var: 0.0
      vf_loss: 0.0027280794456601143
    num_steps_sampled: 2250000
    num_steps_trained: 2250000
    wait_time_ms: 69.662
  iterations_since_restore: 450
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 3875.3228974342346
  time_this_iter_s: 8.202457904815674
  time_total_s: 3875.3228974342346
  timestamp: 1594862184
  timesteps_since_restore: 2250000
  timesteps_this_iter: 5000
  timesteps_total: 2250000
  training_iteration: 450
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 3875 s, 450 iter, 2250000 ts, -102 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-16-33
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -101.50999914156111
  episode_reward_min: -10150.999914156111
  episodes_this_iter: 1
  episodes_total: 450
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.895
    dispatch_time_ms: 8.244
    learner:
      cur_lr: 0.0012101499596610665
      grad_gnorm: 0.013046996667981148
      policy_entropy: 0.0034259085077792406
      policy_loss: 8.716124000329728e-08
      var_gnorm: 27.532392501831055
      vf_explained_var: 1.1920928955078125e-07
      vf_loss: 1.1190321203002895e-07
    num_steps_sampled: 2255000
    num_steps_trained: 2255000
    wait_time_ms: 70.852
  iterations_since_restore: 451
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 3883.435767173767
  time_this_iter_s: 8.11286973953247
  time_total_s: 3883.435767173767
  timestamp: 1594862193
  timesteps_since_restore: 2255000
  timesteps_this_iter: 5000
  timesteps_total: 2255000
  training_iteration: 451
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 3883 s, 451 iter, 2255000 ts, -102 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-16-41
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -101.50999914156111
  episode_reward_min: -10150.999914156111
  episodes_this_iter: 1
  episodes_total: 451
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.55
    dispatch_time_ms: 7.782
    learner:
      cur_lr: 0.0012098170118406415
      grad_gnorm: 2.4176201820373535
      policy_entropy: 0.0034372336231172085
      policy_loss: 1.3376434253586922e-06
      var_gnorm: 27.532236099243164
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 0.0038487177807837725
    num_steps_sampled: 2260000
    num_steps_trained: 2260000
    wait_time_ms: 71.717
  iterations_since_restore: 452
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 3891.517162799835
  time_this_iter_s: 8.081395626068115
  time_total_s: 3891.517162799835
  timestamp: 1594862201
  timesteps_since_restore: 2260000
  timesteps_this_iter: 5000
  timesteps_total: 2260000
  training_iteration: 452
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 3891 s, 452 iter, 2260000 ts, -102 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-16-49
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -101.50999914156111
  episode_reward_min: -10150.999914156111
  episodes_this_iter: 1
  episodes_total: 452
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.784
    dispatch_time_ms: 7.633
    learner:
      cur_lr: 0.0012094839476048946
      grad_gnorm: 0.05356374755501747
      policy_entropy: 0.003455654950812459
      policy_loss: 3.0601801093155245e-09
      var_gnorm: 27.53193473815918
      vf_explained_var: 0.0
      vf_loss: 1.8884696828536107e-06
    num_steps_sampled: 2265000
    num_steps_trained: 2265000
    wait_time_ms: 67.822
  iterations_since_restore: 453
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 3899.634616613388
  time_this_iter_s: 8.117453813552856
  time_total_s: 3899.634616613388
  timestamp: 1594862209
  timesteps_since_restore: 2265000
  timesteps_this_iter: 5000
  timesteps_total: 2265000
  training_iteration: 453
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 3899 s, 453 iter, 2265000 ts, -102 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-16-57
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -101.50999914156111
  episode_reward_min: -10150.999914156111
  episodes_this_iter: 1
  episodes_total: 453
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.507
    dispatch_time_ms: 7.326
    learner:
      cur_lr: 0.0012091509997844696
      grad_gnorm: 2.6670053005218506
      policy_entropy: 0.003468818962574005
      policy_loss: -2.7179964945389656e-06
      var_gnorm: 27.531761169433594
      vf_explained_var: 1.1920928955078125e-07
      vf_loss: 0.004683840554207563
    num_steps_sampled: 2270000
    num_steps_trained: 2270000
    wait_time_ms: 72.327
  iterations_since_restore: 454
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 3907.732969045639
  time_this_iter_s: 8.098352432250977
  time_total_s: 3907.732969045639
  timestamp: 1594862217
  timesteps_since_restore: 2270000
  timesteps_this_iter: 5000
  timesteps_total: 2270000
  training_iteration: 454
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 3907 s, 454 iter, 2270000 ts, -102 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-17-05
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -101.50999914156111
  episode_reward_min: -10150.999914156111
  episodes_this_iter: 1
  episodes_total: 454
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.666
    dispatch_time_ms: 9.972
    learner:
      cur_lr: 0.0012088180519640446
      grad_gnorm: 0.07266790419816971
      policy_entropy: 0.003493269206956029
      policy_loss: 2.747531766544853e-07
      var_gnorm: 27.531469345092773
      vf_explained_var: 0.0
      vf_loss: 3.472021489869803e-06
    num_steps_sampled: 2275000
    num_steps_trained: 2275000
    wait_time_ms: 72.008
  iterations_since_restore: 455
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 3915.943588733673
  time_this_iter_s: 8.210619688034058
  time_total_s: 3915.943588733673
  timestamp: 1594862225
  timesteps_since_restore: 2275000
  timesteps_this_iter: 5000
  timesteps_total: 2275000
  training_iteration: 455
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 3915 s, 455 iter, 2275000 ts, -102 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-17-13
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -101.50999914156111
  episode_reward_min: -10150.999914156111
  episodes_this_iter: 1
  episodes_total: 455
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.762
    dispatch_time_ms: 7.059
    learner:
      cur_lr: 0.0012084849877282977
      grad_gnorm: 2.694277763366699
      policy_entropy: 0.003508768044412136
      policy_loss: 3.195515546394745e-06
      var_gnorm: 27.53128433227539
      vf_explained_var: 0.0
      vf_loss: 0.004779969807714224
    num_steps_sampled: 2280000
    num_steps_trained: 2280000
    wait_time_ms: 72.36
  iterations_since_restore: 456
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 3924.186599254608
  time_this_iter_s: 8.243010520935059
  time_total_s: 3924.186599254608
  timestamp: 1594862233
  timesteps_since_restore: 2280000
  timesteps_this_iter: 5000
  timesteps_total: 2280000
  training_iteration: 456
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 3924 s, 456 iter, 2280000 ts, -102 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-17-22
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -101.50999914156111
  episode_reward_min: -10150.999914156111
  episodes_this_iter: 1
  episodes_total: 456
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.686
    dispatch_time_ms: 6.792
    learner:
      cur_lr: 0.0012081520399078727
      grad_gnorm: 0.13793908059597015
      policy_entropy: 0.0035299232695251703
      policy_loss: -2.1865137966869952e-07
      var_gnorm: 27.531002044677734
      vf_explained_var: 0.0
      vf_loss: 1.2529064406407997e-05
    num_steps_sampled: 2285000
    num_steps_trained: 2285000
    wait_time_ms: 72.578
  iterations_since_restore: 457
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 3932.3158779144287
  time_this_iter_s: 8.129278659820557
  time_total_s: 3932.3158779144287
  timestamp: 1594862242
  timesteps_since_restore: 2285000
  timesteps_this_iter: 5000
  timesteps_total: 2285000
  training_iteration: 457
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 3932 s, 457 iter, 2285000 ts, -102 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-17-30
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -101.50999914156111
  episode_reward_min: -10150.999914156111
  episodes_this_iter: 1
  episodes_total: 457
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.375
    dispatch_time_ms: 7.318
    learner:
      cur_lr: 0.0012078189756721258
      grad_gnorm: 2.7888238430023193
      policy_entropy: 0.003547419561073184
      policy_loss: 2.459550159983337e-06
      var_gnorm: 27.530807495117188
      vf_explained_var: 5.960464477539063e-08
      vf_loss: 0.005121566355228424
    num_steps_sampled: 2290000
    num_steps_trained: 2290000
    wait_time_ms: 71.906
  iterations_since_restore: 458
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 3940.408420562744
  time_this_iter_s: 8.09254264831543
  time_total_s: 3940.408420562744
  timestamp: 1594862250
  timesteps_since_restore: 2290000
  timesteps_this_iter: 5000
  timesteps_total: 2290000
  training_iteration: 458
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 3940 s, 458 iter, 2290000 ts, -102 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-17-38
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -101.50999914156111
  episode_reward_min: -10150.999914156111
  episodes_this_iter: 1
  episodes_total: 458
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.451
    dispatch_time_ms: 6.832
    learner:
      cur_lr: 0.0012074860278517008
      grad_gnorm: 0.05928391218185425
      policy_entropy: 0.0035766558721661568
      policy_loss: -9.242818066468317e-08
      var_gnorm: 27.530513763427734
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 2.3125996904127533e-06
    num_steps_sampled: 2295000
    num_steps_trained: 2295000
    wait_time_ms: 70.882
  iterations_since_restore: 459
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 3948.563637495041
  time_this_iter_s: 8.155216932296753
  time_total_s: 3948.563637495041
  timestamp: 1594862258
  timesteps_since_restore: 2295000
  timesteps_this_iter: 5000
  timesteps_total: 2295000
  training_iteration: 459
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 3948 s, 459 iter, 2295000 ts, -102 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-17-46
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -101.50999914156111
  episode_reward_min: -10150.999914156111
  episodes_this_iter: 1
  episodes_total: 459
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.656
    dispatch_time_ms: 6.788
    learner:
      cur_lr: 0.001207152963615954
      grad_gnorm: 2.749941110610962
      policy_entropy: 0.0035966821014881134
      policy_loss: 3.663889401650522e-06
      var_gnorm: 27.530311584472656
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 0.004979477263987064
    num_steps_sampled: 2300000
    num_steps_trained: 2300000
    wait_time_ms: 70.087
  iterations_since_restore: 460
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 3956.770775794983
  time_this_iter_s: 8.207138299942017
  time_total_s: 3956.770775794983
  timestamp: 1594862266
  timesteps_since_restore: 2300000
  timesteps_this_iter: 5000
  timesteps_total: 2300000
  training_iteration: 460
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 3956 s, 460 iter, 2300000 ts, -102 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-17-55
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -101.50999914156111
  episode_reward_min: -10150.999914156111
  episodes_this_iter: 1
  episodes_total: 460
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 3.248
    dispatch_time_ms: 16.642
    learner:
      cur_lr: 0.0012068200157955289
      grad_gnorm: 2.362407922744751
      policy_entropy: 0.0036202985793352127
      policy_loss: -1.2758087564179732e-07
      var_gnorm: 27.5300235748291
      vf_explained_var: 5.960464477539063e-08
      vf_loss: 0.0029134543146938086
    num_steps_sampled: 2305000
    num_steps_trained: 2305000
    wait_time_ms: 169.414
  iterations_since_restore: 461
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 3966.003319501877
  time_this_iter_s: 9.232543706893921
  time_total_s: 3966.003319501877
  timestamp: 1594862275
  timesteps_since_restore: 2305000
  timesteps_this_iter: 5000
  timesteps_total: 2305000
  training_iteration: 461
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 3966 s, 461 iter, 2305000 ts, -102 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-18-03
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -101.50999914156111
  episode_reward_min: -10150.999914156111
  episodes_this_iter: 1
  episodes_total: 461
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 3.189
    dispatch_time_ms: 8.7
    learner:
      cur_lr: 0.001206486951559782
      grad_gnorm: 3.537670612335205
      policy_entropy: 0.003651013132184744
      policy_loss: 5.591019998973934e-06
      var_gnorm: 27.529815673828125
      vf_explained_var: 0.0
      vf_loss: 0.008241233415901661
    num_steps_sampled: 2310000
    num_steps_trained: 2310000
    wait_time_ms: 73.517
  iterations_since_restore: 462
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 3973.6867575645447
  time_this_iter_s: 7.683438062667847
  time_total_s: 3973.6867575645447
  timestamp: 1594862283
  timesteps_since_restore: 2310000
  timesteps_this_iter: 5000
  timesteps_total: 2310000
  training_iteration: 462
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 3973 s, 462 iter, 2310000 ts, -102 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-18-11
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -101.50999914156111
  episode_reward_min: -10150.999914156111
  episodes_this_iter: 1
  episodes_total: 462
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 3.413
    dispatch_time_ms: 9.103
    learner:
      cur_lr: 0.001206154003739357
      grad_gnorm: 0.24017944931983948
      policy_entropy: 0.003679897403344512
      policy_loss: 7.749979999971401e-07
      var_gnorm: 27.52962875366211
      vf_explained_var: 1.1920928955078125e-07
      vf_loss: 3.7995570892235264e-05
    num_steps_sampled: 2315000
    num_steps_trained: 2315000
    wait_time_ms: 69.972
  iterations_since_restore: 463
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 3981.784399032593
  time_this_iter_s: 8.097641468048096
  time_total_s: 3981.784399032593
  timestamp: 1594862291
  timesteps_since_restore: 2315000
  timesteps_this_iter: 5000
  timesteps_total: 2315000
  training_iteration: 463
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 3981 s, 463 iter, 2315000 ts, -102 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-18-19
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -101.50999914156111
  episode_reward_min: -10150.999914156111
  episodes_this_iter: 1
  episodes_total: 463
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.959
    dispatch_time_ms: 8.126
    learner:
      cur_lr: 0.001205821055918932
      grad_gnorm: 1.9611457586288452
      policy_entropy: 0.003712036646902561
      policy_loss: 3.2580430797679583e-06
      var_gnorm: 27.529441833496094
      vf_explained_var: 5.960464477539063e-08
      vf_loss: 0.0025324977468699217
    num_steps_sampled: 2320000
    num_steps_trained: 2320000
    wait_time_ms: 70.679
  iterations_since_restore: 464
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 3989.901247739792
  time_this_iter_s: 8.116848707199097
  time_total_s: 3989.901247739792
  timestamp: 1594862299
  timesteps_since_restore: 2320000
  timesteps_this_iter: 5000
  timesteps_total: 2320000
  training_iteration: 464
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 3989 s, 464 iter, 2320000 ts, -102 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-18-28
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -101.50999914156111
  episode_reward_min: -10150.999914156111
  episodes_this_iter: 1
  episodes_total: 464
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.821
    dispatch_time_ms: 6.827
    learner:
      cur_lr: 0.001205487991683185
      grad_gnorm: 0.2747567296028137
      policy_entropy: 0.0037448944058269262
      policy_loss: -1.3526769748750667e-07
      var_gnorm: 27.529245376586914
      vf_explained_var: 0.0
      vf_loss: 4.9721413233783096e-05
    num_steps_sampled: 2325000
    num_steps_trained: 2325000
    wait_time_ms: 71.012
  iterations_since_restore: 465
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 3998.1154465675354
  time_this_iter_s: 8.21419882774353
  time_total_s: 3998.1154465675354
  timestamp: 1594862308
  timesteps_since_restore: 2325000
  timesteps_this_iter: 5000
  timesteps_total: 2325000
  training_iteration: 465
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 3998 s, 465 iter, 2325000 ts, -102 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-18-36
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -101.50999914156111
  episode_reward_min: -10150.999914156111
  episodes_this_iter: 1
  episodes_total: 465
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 3.441
    dispatch_time_ms: 6.536
    learner:
      cur_lr: 0.00120515504386276
      grad_gnorm: 2.0395164489746094
      policy_entropy: 0.003774645971134305
      policy_loss: 3.1423141990671866e-06
      var_gnorm: 27.529052734375
      vf_explained_var: 0.0
      vf_loss: 0.00273895263671875
    num_steps_sampled: 2330000
    num_steps_trained: 2330000
    wait_time_ms: 73.556
  iterations_since_restore: 466
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 4006.2951622009277
  time_this_iter_s: 8.179715633392334
  time_total_s: 4006.2951622009277
  timestamp: 1594862316
  timesteps_since_restore: 2330000
  timesteps_this_iter: 5000
  timesteps_total: 2330000
  training_iteration: 466
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 4006 s, 466 iter, 2330000 ts, -102 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-18-44
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -101.50999914156111
  episode_reward_min: -10150.999914156111
  episodes_this_iter: 1
  episodes_total: 466
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.746
    dispatch_time_ms: 6.482
    learner:
      cur_lr: 0.0012048219796270132
      grad_gnorm: 0.10426168888807297
      policy_entropy: 0.003813831601291895
      policy_loss: 1.6360206700483104e-07
      var_gnorm: 27.528846740722656
      vf_explained_var: 0.0
      vf_loss: 7.163987447711406e-06
    num_steps_sampled: 2335000
    num_steps_trained: 2335000
    wait_time_ms: 74.184
  iterations_since_restore: 467
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 4014.5057260990143
  time_this_iter_s: 8.210563898086548
  time_total_s: 4014.5057260990143
  timestamp: 1594862324
  timesteps_since_restore: 2335000
  timesteps_this_iter: 5000
  timesteps_total: 2335000
  training_iteration: 467
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 4014 s, 467 iter, 2335000 ts, -102 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-18-52
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -101.50999914156111
  episode_reward_min: -10150.999914156111
  episodes_this_iter: 1
  episodes_total: 467
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.629
    dispatch_time_ms: 6.29
    learner:
      cur_lr: 0.0012044890318065882
      grad_gnorm: 2.235705614089966
      policy_entropy: 0.0038534358609467745
      policy_loss: 3.512345529088634e-06
      var_gnorm: 27.52866554260254
      vf_explained_var: 5.960464477539063e-08
      vf_loss: 0.003291374072432518
    num_steps_sampled: 2340000
    num_steps_trained: 2340000
    wait_time_ms: 75.468
  iterations_since_restore: 468
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 4022.6787962913513
  time_this_iter_s: 8.173070192337036
  time_total_s: 4022.6787962913513
  timestamp: 1594862332
  timesteps_since_restore: 2340000
  timesteps_this_iter: 5000
  timesteps_total: 2340000
  training_iteration: 468
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 4022 s, 468 iter, 2340000 ts, -102 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-19-01
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -101.50999914156111
  episode_reward_min: -10150.999914156111
  episodes_this_iter: 1
  episodes_total: 468
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.987
    dispatch_time_ms: 8.896
    learner:
      cur_lr: 0.0012041559675708413
      grad_gnorm: 0.46003490686416626
      policy_entropy: 0.0038973847404122353
      policy_loss: -3.542048716553836e-07
      var_gnorm: 27.528467178344727
      vf_explained_var: 0.0
      vf_loss: 0.00013935599417891353
    num_steps_sampled: 2345000
    num_steps_trained: 2345000
    wait_time_ms: 69.346
  iterations_since_restore: 469
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 4030.8860986232758
  time_this_iter_s: 8.207302331924438
  time_total_s: 4030.8860986232758
  timestamp: 1594862341
  timesteps_since_restore: 2345000
  timesteps_this_iter: 5000
  timesteps_total: 2345000
  training_iteration: 469
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 4030 s, 469 iter, 2345000 ts, -102 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-19-09
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -101.50999914156111
  episode_reward_min: -10150.999914156111
  episodes_this_iter: 1
  episodes_total: 469
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.45
    dispatch_time_ms: 7.147
    learner:
      cur_lr: 0.0012038230197504163
      grad_gnorm: 1.6967724561691284
      policy_entropy: 0.0039434004575014114
      policy_loss: 4.486773832468316e-06
      var_gnorm: 27.528270721435547
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 0.001895818510092795
    num_steps_sampled: 2350000
    num_steps_trained: 2350000
    wait_time_ms: 72.132
  iterations_since_restore: 470
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 4039.0156650543213
  time_this_iter_s: 8.129566431045532
  time_total_s: 4039.0156650543213
  timestamp: 1594862349
  timesteps_since_restore: 2350000
  timesteps_this_iter: 5000
  timesteps_total: 2350000
  training_iteration: 470
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 4039 s, 470 iter, 2350000 ts, -102 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-19-17
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -101.50999914156111
  episode_reward_min: -10150.999914156111
  episodes_this_iter: 1
  episodes_total: 470
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.882
    dispatch_time_ms: 8.248
    learner:
      cur_lr: 0.0012034899555146694
      grad_gnorm: 0.4949961006641388
      policy_entropy: 0.004119476303458214
      policy_loss: -3.173065366013361e-09
      var_gnorm: 27.527984619140625
      vf_explained_var: 0.0
      vf_loss: 0.00016134903125930578
    num_steps_sampled: 2355000
    num_steps_trained: 2355000
    wait_time_ms: 73.686
  iterations_since_restore: 471
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 4047.167734861374
  time_this_iter_s: 8.152069807052612
  time_total_s: 4047.167734861374
  timestamp: 1594862357
  timesteps_since_restore: 2355000
  timesteps_this_iter: 5000
  timesteps_total: 2355000
  training_iteration: 471
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 4047 s, 471 iter, 2355000 ts, -102 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-19-25
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -101.50999914156111
  episode_reward_min: -10150.999914156111
  episodes_this_iter: 1
  episodes_total: 471
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 3.461
    dispatch_time_ms: 7.946
    learner:
      cur_lr: 0.0012031570076942444
      grad_gnorm: 1.339565634727478
      policy_entropy: 0.004238457418978214
      policy_loss: 3.769216164073441e-06
      var_gnorm: 27.52774429321289
      vf_explained_var: 0.0
      vf_loss: 0.0011816039914265275
    num_steps_sampled: 2360000
    num_steps_trained: 2360000
    wait_time_ms: 72.568
  iterations_since_restore: 472
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 4055.386006116867
  time_this_iter_s: 8.218271255493164
  time_total_s: 4055.386006116867
  timestamp: 1594862365
  timesteps_since_restore: 2360000
  timesteps_this_iter: 5000
  timesteps_total: 2360000
  training_iteration: 472
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 4055 s, 472 iter, 2360000 ts, -102 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-19-34
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -101.50999914156111
  episode_reward_min: -10150.999914156111
  episodes_this_iter: 1
  episodes_total: 472
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.981
    dispatch_time_ms: 19.71
    learner:
      cur_lr: 0.0012028239434584975
      grad_gnorm: 0.12231375277042389
      policy_entropy: 0.004296634346246719
      policy_loss: 2.1871608169021783e-07
      var_gnorm: 27.52754020690918
      vf_explained_var: 5.960464477539063e-08
      vf_loss: 1.0031991223513614e-05
    num_steps_sampled: 2365000
    num_steps_trained: 2365000
    wait_time_ms: 70.752
  iterations_since_restore: 473
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 4063.936135530472
  time_this_iter_s: 8.550129413604736
  time_total_s: 4063.936135530472
  timestamp: 1594862374
  timesteps_since_restore: 2365000
  timesteps_this_iter: 5000
  timesteps_total: 2365000
  training_iteration: 473
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 4063 s, 473 iter, 2365000 ts, -102 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-19-42
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -101.50999914156111
  episode_reward_min: -10150.999914156111
  episodes_this_iter: 1
  episodes_total: 473
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 3.97
    dispatch_time_ms: 6.069
    learner:
      cur_lr: 0.0012024909956380725
      grad_gnorm: 0.7140284180641174
      policy_entropy: 0.0043387142941355705
      policy_loss: 1.3976872423882014e-06
      var_gnorm: 27.52739715576172
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 0.0003357079694978893
    num_steps_sampled: 2370000
    num_steps_trained: 2370000
    wait_time_ms: 67.533
  iterations_since_restore: 474
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 4072.182055234909
  time_this_iter_s: 8.245919704437256
  time_total_s: 4072.182055234909
  timestamp: 1594862382
  timesteps_since_restore: 2370000
  timesteps_this_iter: 5000
  timesteps_total: 2370000
  training_iteration: 474
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 4072 s, 474 iter, 2370000 ts, -102 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-19-50
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -101.50999914156111
  episode_reward_min: -10150.999914156111
  episodes_this_iter: 1
  episodes_total: 474
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.54
    dispatch_time_ms: 9.68
    learner:
      cur_lr: 0.0012021580478176475
      grad_gnorm: 0.19804945588111877
      policy_entropy: 0.00442379480227828
      policy_loss: -3.1279068934964016e-07
      var_gnorm: 27.527196884155273
      vf_explained_var: 0.0
      vf_loss: 2.581955232017208e-05
    num_steps_sampled: 2375000
    num_steps_trained: 2375000
    wait_time_ms: 70.215
  iterations_since_restore: 475
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 4080.4069554805756
  time_this_iter_s: 8.224900245666504
  time_total_s: 4080.4069554805756
  timestamp: 1594862390
  timesteps_since_restore: 2375000
  timesteps_this_iter: 5000
  timesteps_total: 2375000
  training_iteration: 475
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 4080 s, 475 iter, 2375000 ts, -102 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-19-59
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -101.50999914156111
  episode_reward_min: -10150.999914156111
  episodes_this_iter: 1
  episodes_total: 475
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.919
    dispatch_time_ms: 5.35
    learner:
      cur_lr: 0.0012018249835819006
      grad_gnorm: 1.6515452861785889
      policy_entropy: 0.004496821667999029
      policy_loss: 4.097874352737563e-06
      var_gnorm: 27.527009963989258
      vf_explained_var: 5.960464477539063e-08
      vf_loss: 0.0017960043624043465
    num_steps_sampled: 2380000
    num_steps_trained: 2380000
    wait_time_ms: 72.508
  iterations_since_restore: 476
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 4088.5317952632904
  time_this_iter_s: 8.124839782714844
  time_total_s: 4088.5317952632904
  timestamp: 1594862399
  timesteps_since_restore: 2380000
  timesteps_this_iter: 5000
  timesteps_total: 2380000
  training_iteration: 476
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 4088 s, 476 iter, 2380000 ts, -102 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-20-07
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -101.50999914156111
  episode_reward_min: -10150.999914156111
  episodes_this_iter: 1
  episodes_total: 476
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.63
    dispatch_time_ms: 7.823
    learner:
      cur_lr: 0.0012014920357614756
      grad_gnorm: 0.4176357686519623
      policy_entropy: 0.004578424151986837
      policy_loss: -2.422994782591559e-07
      var_gnorm: 27.526836395263672
      vf_explained_var: 0.0
      vf_loss: 0.00011485815775813535
    num_steps_sampled: 2385000
    num_steps_trained: 2385000
    wait_time_ms: 67.121
  iterations_since_restore: 477
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 4096.7369339466095
  time_this_iter_s: 8.205138683319092
  time_total_s: 4096.7369339466095
  timestamp: 1594862407
  timesteps_since_restore: 2385000
  timesteps_this_iter: 5000
  timesteps_total: 2385000
  training_iteration: 477
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 4096 s, 477 iter, 2385000 ts, -102 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-20-15
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -101.50999914156111
  episode_reward_min: -10150.999914156111
  episodes_this_iter: 1
  episodes_total: 477
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.967
    dispatch_time_ms: 8.967
    learner:
      cur_lr: 0.0012011589715257287
      grad_gnorm: 0.5733762383460999
      policy_entropy: 0.0046664755791425705
      policy_loss: 1.980379465749138e-06
      var_gnorm: 27.526655197143555
      vf_explained_var: 1.1920928955078125e-07
      vf_loss: 0.00021653994917869568
    num_steps_sampled: 2390000
    num_steps_trained: 2390000
    wait_time_ms: 72.176
  iterations_since_restore: 478
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 4104.941924333572
  time_this_iter_s: 8.20499038696289
  time_total_s: 4104.941924333572
  timestamp: 1594862415
  timesteps_since_restore: 2390000
  timesteps_this_iter: 5000
  timesteps_total: 2390000
  training_iteration: 478
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 4104 s, 478 iter, 2390000 ts, -102 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-20-23
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -101.50999914156111
  episode_reward_min: -10150.999914156111
  episodes_this_iter: 1
  episodes_total: 478
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.906
    dispatch_time_ms: 7.206
    learner:
      cur_lr: 0.0012008260237053037
      grad_gnorm: 0.11787251383066177
      policy_entropy: 0.004764800891280174
      policy_loss: 3.177933365350327e-07
      var_gnorm: 27.526447296142578
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 9.150586265604943e-06
    num_steps_sampled: 2395000
    num_steps_trained: 2395000
    wait_time_ms: 70.501
  iterations_since_restore: 479
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 4113.086043357849
  time_this_iter_s: 8.144119024276733
  time_total_s: 4113.086043357849
  timestamp: 1594862423
  timesteps_since_restore: 2395000
  timesteps_this_iter: 5000
  timesteps_total: 2395000
  training_iteration: 479
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 4113 s, 479 iter, 2395000 ts, -102 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-20-31
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -101.50999914156111
  episode_reward_min: -10150.999914156111
  episodes_this_iter: 1
  episodes_total: 479
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.729
    dispatch_time_ms: 9.348
    learner:
      cur_lr: 0.0012004929594695568
      grad_gnorm: 0.9370816349983215
      policy_entropy: 0.004874468315392733
      policy_loss: 4.575468210532563e-06
      var_gnorm: 27.526294708251953
      vf_explained_var: 1.1920928955078125e-07
      vf_loss: 0.0005782272201031446
    num_steps_sampled: 2400000
    num_steps_trained: 2400000
    wait_time_ms: 70.081
  iterations_since_restore: 480
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 4121.309547901154
  time_this_iter_s: 8.223504543304443
  time_total_s: 4121.309547901154
  timestamp: 1594862431
  timesteps_since_restore: 2400000
  timesteps_this_iter: 5000
  timesteps_total: 2400000
  training_iteration: 480
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 4121 s, 480 iter, 2400000 ts, -102 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-20-40
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -101.50999914156111
  episode_reward_min: -10150.999914156111
  episodes_this_iter: 1
  episodes_total: 480
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.55
    dispatch_time_ms: 5.708
    learner:
      cur_lr: 0.0012001600116491318
      grad_gnorm: 0.09350693225860596
      policy_entropy: 0.004996607080101967
      policy_loss: 9.304672943244441e-08
      var_gnorm: 27.526050567626953
      vf_explained_var: 0.0
      vf_loss: 5.7587967603467405e-06
    num_steps_sampled: 2405000
    num_steps_trained: 2405000
    wait_time_ms: 68.674
  iterations_since_restore: 481
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 4129.507876634598
  time_this_iter_s: 8.198328733444214
  time_total_s: 4129.507876634598
  timestamp: 1594862440
  timesteps_since_restore: 2405000
  timesteps_this_iter: 5000
  timesteps_total: 2405000
  training_iteration: 481
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 4129 s, 481 iter, 2405000 ts, -102 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-20-48
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -101.50999914156111
  episode_reward_min: -10150.999914156111
  episodes_this_iter: 1
  episodes_total: 481
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 3.414
    dispatch_time_ms: 7.947
    learner:
      cur_lr: 0.001199826947413385
      grad_gnorm: 1.3381317853927612
      policy_entropy: 0.005129312630742788
      policy_loss: -2.4777632461336907e-06
      var_gnorm: 27.525901794433594
      vf_explained_var: 0.0
      vf_loss: 0.0011790379649028182
    num_steps_sampled: 2410000
    num_steps_trained: 2410000
    wait_time_ms: 74.216
  iterations_since_restore: 482
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 4137.673095703125
  time_this_iter_s: 8.165219068527222
  time_total_s: 4137.673095703125
  timestamp: 1594862448
  timesteps_since_restore: 2410000
  timesteps_this_iter: 5000
  timesteps_total: 2410000
  training_iteration: 482
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 4137 s, 482 iter, 2410000 ts, -102 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-20-56
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -101.50999914156111
  episode_reward_min: -10150.999914156111
  episodes_this_iter: 1
  episodes_total: 482
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.496
    dispatch_time_ms: 8.603
    learner:
      cur_lr: 0.0011994939995929599
      grad_gnorm: 0.09044149518013
      policy_entropy: 0.005274307448416948
      policy_loss: 1.7239220539977396e-07
      var_gnorm: 27.5256404876709
      vf_explained_var: 1.7881393432617188e-07
      vf_loss: 5.3835783546674065e-06
    num_steps_sampled: 2415000
    num_steps_trained: 2415000
    wait_time_ms: 69.688
  iterations_since_restore: 483
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 4145.835457086563
  time_this_iter_s: 8.16236138343811
  time_total_s: 4145.835457086563
  timestamp: 1594862456
  timesteps_since_restore: 2415000
  timesteps_this_iter: 5000
  timesteps_total: 2415000
  training_iteration: 483
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 23.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 4145 s, 483 iter, 2415000 ts, -102 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-21-04
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -101.50999914156111
  episode_reward_min: -10150.999914156111
  episodes_this_iter: 1
  episodes_total: 483
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.708
    dispatch_time_ms: 7.121
    learner:
      cur_lr: 0.0011991610517725348
      grad_gnorm: 1.6669880151748657
      policy_entropy: 0.005431520752608776
      policy_loss: -3.1638355721952394e-06
      var_gnorm: 27.525489807128906
      vf_explained_var: 0.0
      vf_loss: 0.0018299182411283255
    num_steps_sampled: 2420000
    num_steps_trained: 2420000
    wait_time_ms: 71.374
  iterations_since_restore: 484
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 4153.932686805725
  time_this_iter_s: 8.097229719161987
  time_total_s: 4153.932686805725
  timestamp: 1594862464
  timesteps_since_restore: 2420000
  timesteps_this_iter: 5000
  timesteps_total: 2420000
  training_iteration: 484
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 23.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 4153 s, 484 iter, 2420000 ts, -102 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-21-12
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -101.50999914156111
  episode_reward_min: -10150.999914156111
  episodes_this_iter: 1
  episodes_total: 484
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.972
    dispatch_time_ms: 7.456
    learner:
      cur_lr: 0.001198827987536788
      grad_gnorm: 0.19269102811813354
      policy_entropy: 0.005630651954561472
      policy_loss: 1.0401543448779194e-07
      var_gnorm: 27.52521514892578
      vf_explained_var: 0.0
      vf_loss: 2.4468590709147975e-05
    num_steps_sampled: 2425000
    num_steps_trained: 2425000
    wait_time_ms: 71.094
  iterations_since_restore: 485
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 4162.116982221603
  time_this_iter_s: 8.184295415878296
  time_total_s: 4162.116982221603
  timestamp: 1594862472
  timesteps_since_restore: 2425000
  timesteps_this_iter: 5000
  timesteps_total: 2425000
  training_iteration: 485
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 23.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 4162 s, 485 iter, 2425000 ts, -102 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-21-21
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -101.50999914156111
  episode_reward_min: -10150.999914156111
  episodes_this_iter: 1
  episodes_total: 485
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 3.618
    dispatch_time_ms: 8.405
    learner:
      cur_lr: 0.001198495039716363
      grad_gnorm: 1.834727168083191
      policy_entropy: 0.005826193373650312
      policy_loss: -3.007686245837249e-06
      var_gnorm: 27.52505874633789
      vf_explained_var: 0.0
      vf_loss: 0.0022167812567204237
    num_steps_sampled: 2430000
    num_steps_trained: 2430000
    wait_time_ms: 68.158
  iterations_since_restore: 486
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 4170.237966775894
  time_this_iter_s: 8.120984554290771
  time_total_s: 4170.237966775894
  timestamp: 1594862481
  timesteps_since_restore: 2430000
  timesteps_this_iter: 5000
  timesteps_total: 2430000
  training_iteration: 486
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 4170 s, 486 iter, 2430000 ts, -102 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-21-29
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -101.50999914156111
  episode_reward_min: -10150.999914156111
  episodes_this_iter: 1
  episodes_total: 486
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.94
    dispatch_time_ms: 10.438
    learner:
      cur_lr: 0.001198161975480616
      grad_gnorm: 0.31657201051712036
      policy_entropy: 0.006062645465135574
      policy_loss: 2.632103530686436e-07
      var_gnorm: 27.524776458740234
      vf_explained_var: 0.0
      vf_loss: 6.599160406040028e-05
    num_steps_sampled: 2435000
    num_steps_trained: 2435000
    wait_time_ms: 68.1
  iterations_since_restore: 487
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 4178.41130900383
  time_this_iter_s: 8.173342227935791
  time_total_s: 4178.41130900383
  timestamp: 1594862489
  timesteps_since_restore: 2435000
  timesteps_this_iter: 5000
  timesteps_total: 2435000
  training_iteration: 487
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 4178 s, 487 iter, 2435000 ts, -102 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-21-37
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -101.50999914156111
  episode_reward_min: -10150.999914156111
  episodes_this_iter: 1
  episodes_total: 487
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 3.378
    dispatch_time_ms: 6.294
    learner:
      cur_lr: 0.001197829027660191
      grad_gnorm: 0.8357314467430115
      policy_entropy: 0.00630571274086833
      policy_loss: -1.9343588064657524e-06
      var_gnorm: 27.524574279785156
      vf_explained_var: 1.1920928955078125e-07
      vf_loss: 0.00045985469478182495
    num_steps_sampled: 2440000
    num_steps_trained: 2440000
    wait_time_ms: 72.341
  iterations_since_restore: 488
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 4186.529030799866
  time_this_iter_s: 8.117721796035767
  time_total_s: 4186.529030799866
  timestamp: 1594862497
  timesteps_since_restore: 2440000
  timesteps_this_iter: 5000
  timesteps_total: 2440000
  training_iteration: 488
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 4186 s, 488 iter, 2440000 ts, -102 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-21-45
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -101.50999914156111
  episode_reward_min: -10150.999914156111
  episodes_this_iter: 1
  episodes_total: 488
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.832
    dispatch_time_ms: 7.028
    learner:
      cur_lr: 0.0011974959634244442
      grad_gnorm: 0.017399931326508522
      policy_entropy: 0.006601642817258835
      policy_loss: -4.216839499804337e-08
      var_gnorm: 27.524316787719727
      vf_explained_var: 0.0
      vf_loss: 1.9861724354086618e-07
    num_steps_sampled: 2445000
    num_steps_trained: 2445000
    wait_time_ms: 71.923
  iterations_since_restore: 489
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 4194.597904443741
  time_this_iter_s: 8.068873643875122
  time_total_s: 4194.597904443741
  timestamp: 1594862505
  timesteps_since_restore: 2445000
  timesteps_this_iter: 5000
  timesteps_total: 2445000
  training_iteration: 489
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 4194 s, 489 iter, 2445000 ts, -102 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-22-02
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -101.50999914156111
  episode_reward_min: -10150.999914156111
  episodes_this_iter: 1
  episodes_total: 489
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.756
    dispatch_time_ms: 7.403
    learner:
      cur_lr: 0.0011971630156040192
      grad_gnorm: 2.1925668716430664
      policy_entropy: 0.007000752259045839
      policy_loss: 5.671888629876776e-06
      var_gnorm: 27.524059295654297
      vf_explained_var: 1.7881393432617188e-07
      vf_loss: 0.003165645059198141
    num_steps_sampled: 2450000
    num_steps_trained: 2450000
    wait_time_ms: 71.958
  iterations_since_restore: 490
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 4211.478154420853
  time_this_iter_s: 16.880249977111816
  time_total_s: 4211.478154420853
  timestamp: 1594862522
  timesteps_since_restore: 2450000
  timesteps_this_iter: 5000
  timesteps_total: 2450000
  training_iteration: 490
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 4211 s, 490 iter, 2450000 ts, -102 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-22-10
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -101.50999914156111
  episode_reward_min: -10150.999914156111
  episodes_this_iter: 1
  episodes_total: 490
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.739
    dispatch_time_ms: 7.74
    learner:
      cur_lr: 0.0011968299513682723
      grad_gnorm: 0.2840128540992737
      policy_entropy: 0.003407067619264126
      policy_loss: 8.829434250401391e-08
      var_gnorm: 27.52623748779297
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 5.312345456331968e-05
    num_steps_sampled: 2455000
    num_steps_trained: 2455000
    wait_time_ms: 73.323
  iterations_since_restore: 491
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 4219.612304210663
  time_this_iter_s: 8.13414978981018
  time_total_s: 4219.612304210663
  timestamp: 1594862530
  timesteps_since_restore: 2455000
  timesteps_this_iter: 5000
  timesteps_total: 2455000
  training_iteration: 491
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 4219 s, 491 iter, 2455000 ts, -102 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-22-18
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -101.50999914156111
  episode_reward_min: -10150.999914156111
  episodes_this_iter: 1
  episodes_total: 491
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 3.01
    dispatch_time_ms: 6.917
    learner:
      cur_lr: 0.0011964970035478473
      grad_gnorm: 1.045986294746399
      policy_entropy: 0.003481237217783928
      policy_loss: -1.268253754460602e-06
      var_gnorm: 27.526151657104492
      vf_explained_var: 0.0
      vf_loss: 0.0007204518187791109
    num_steps_sampled: 2460000
    num_steps_trained: 2460000
    wait_time_ms: 71.706
  iterations_since_restore: 492
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 4227.753453016281
  time_this_iter_s: 8.141148805618286
  time_total_s: 4227.753453016281
  timestamp: 1594862538
  timesteps_since_restore: 2460000
  timesteps_this_iter: 5000
  timesteps_total: 2460000
  training_iteration: 492
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 4227 s, 492 iter, 2460000 ts, -102 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-22-27
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -101.50999914156111
  episode_reward_min: -10150.999914156111
  episodes_this_iter: 1
  episodes_total: 492
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.657
    dispatch_time_ms: 6.792
    learner:
      cur_lr: 0.0011961640557274222
      grad_gnorm: 0.32023462653160095
      policy_entropy: 0.0036037378013134003
      policy_loss: 1.8890922603986837e-07
      var_gnorm: 27.52594566345215
      vf_explained_var: 0.0
      vf_loss: 6.75091941957362e-05
    num_steps_sampled: 2465000
    num_steps_trained: 2465000
    wait_time_ms: 70.3
  iterations_since_restore: 493
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 4235.929648399353
  time_this_iter_s: 8.1761953830719
  time_total_s: 4235.929648399353
  timestamp: 1594862547
  timesteps_since_restore: 2465000
  timesteps_this_iter: 5000
  timesteps_total: 2465000
  training_iteration: 493
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 4235 s, 493 iter, 2465000 ts, -102 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-22-35
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -101.50999914156111
  episode_reward_min: -10150.999914156111
  episodes_this_iter: 1
  episodes_total: 493
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 3.107
    dispatch_time_ms: 7.719
    learner:
      cur_lr: 0.0011958309914916754
      grad_gnorm: 0.7787612080574036
      policy_entropy: 0.0037282893899828196
      policy_loss: -1.81302641522052e-06
      var_gnorm: 27.52581787109375
      vf_explained_var: 0.0
      vf_loss: 0.0003993711434304714
    num_steps_sampled: 2470000
    num_steps_trained: 2470000
    wait_time_ms: 73.867
  iterations_since_restore: 494
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 4244.073007106781
  time_this_iter_s: 8.143358707427979
  time_total_s: 4244.073007106781
  timestamp: 1594862555
  timesteps_since_restore: 2470000
  timesteps_this_iter: 5000
  timesteps_total: 2470000
  training_iteration: 494
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 4244 s, 494 iter, 2470000 ts, -102 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-22-43
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -101.50999914156111
  episode_reward_min: -10150.999914156111
  episodes_this_iter: 1
  episodes_total: 494
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 3.315
    dispatch_time_ms: 6.567
    learner:
      cur_lr: 0.0011954980436712503
      grad_gnorm: 0.49906495213508606
      policy_entropy: 0.0038805336225777864
      policy_loss: 6.794846285629319e-07
      var_gnorm: 27.525606155395508
      vf_explained_var: 0.0
      vf_loss: 0.00016397700528614223
    num_steps_sampled: 2475000
    num_steps_trained: 2475000
    wait_time_ms: 70.461
  iterations_since_restore: 495
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 4252.303721904755
  time_this_iter_s: 8.230714797973633
  time_total_s: 4252.303721904755
  timestamp: 1594862563
  timesteps_since_restore: 2475000
  timesteps_this_iter: 5000
  timesteps_total: 2475000
  training_iteration: 495
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 4252 s, 495 iter, 2475000 ts, -102 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-22-51
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -101.50999914156111
  episode_reward_min: -10150.999914156111
  episodes_this_iter: 1
  episodes_total: 495
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 4.349
    dispatch_time_ms: 7.847
    learner:
      cur_lr: 0.0011951649794355035
      grad_gnorm: 0.6920037269592285
      policy_entropy: 0.0040356493555009365
      policy_loss: -1.9468532173050335e-06
      var_gnorm: 27.525466918945312
      vf_explained_var: 0.0
      vf_loss: 0.00031530694104731083
    num_steps_sampled: 2480000
    num_steps_trained: 2480000
    wait_time_ms: 68.669
  iterations_since_restore: 496
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 4260.43165230751
  time_this_iter_s: 8.127930402755737
  time_total_s: 4260.43165230751
  timestamp: 1594862571
  timesteps_since_restore: 2480000
  timesteps_this_iter: 5000
  timesteps_total: 2480000
  training_iteration: 496
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 4260 s, 496 iter, 2480000 ts, -102 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-22-59
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -101.50999914156111
  episode_reward_min: -10150.999914156111
  episodes_this_iter: 1
  episodes_total: 496
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.471
    dispatch_time_ms: 8.405
    learner:
      cur_lr: 0.0011948320316150784
      grad_gnorm: 0.13445542752742767
      policy_entropy: 0.004230777733027935
      policy_loss: 2.0136936029757635e-07
      var_gnorm: 27.525251388549805
      vf_explained_var: 0.0
      vf_loss: 1.1900373465323355e-05
    num_steps_sampled: 2485000
    num_steps_trained: 2485000
    wait_time_ms: 73.173
  iterations_since_restore: 497
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 4268.5893342494965
  time_this_iter_s: 8.157681941986084
  time_total_s: 4268.5893342494965
  timestamp: 1594862579
  timesteps_since_restore: 2485000
  timesteps_this_iter: 5000
  timesteps_total: 2485000
  training_iteration: 497
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 4268 s, 497 iter, 2485000 ts, -102 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-23-08
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -101.50999914156111
  episode_reward_min: -10150.999914156111
  episodes_this_iter: 1
  episodes_total: 497
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 3.383
    dispatch_time_ms: 6.245
    learner:
      cur_lr: 0.0011944989673793316
      grad_gnorm: 0.28984585404396057
      policy_entropy: 0.004435164853930473
      policy_loss: -4.577699144192593e-07
      var_gnorm: 27.525074005126953
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 5.5311178584815934e-05
    num_steps_sampled: 2490000
    num_steps_trained: 2490000
    wait_time_ms: 76.523
  iterations_since_restore: 498
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 4276.758056640625
  time_this_iter_s: 8.16872239112854
  time_total_s: 4276.758056640625
  timestamp: 1594862588
  timesteps_since_restore: 2490000
  timesteps_this_iter: 5000
  timesteps_total: 2490000
  training_iteration: 498
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 4276 s, 498 iter, 2490000 ts, -102 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-23-16
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -101.50999914156111
  episode_reward_min: -10150.999914156111
  episodes_this_iter: 1
  episodes_total: 498
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.988
    dispatch_time_ms: 6.368
    learner:
      cur_lr: 0.0011941660195589066
      grad_gnorm: 0.1941494643688202
      policy_entropy: 0.004686920903623104
      policy_loss: 3.2167653785108996e-07
      var_gnorm: 27.524852752685547
      vf_explained_var: 1.1920928955078125e-07
      vf_loss: 2.4831910195644014e-05
    num_steps_sampled: 2495000
    num_steps_trained: 2495000
    wait_time_ms: 70.367
  iterations_since_restore: 499
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 4284.887801408768
  time_this_iter_s: 8.1297447681427
  time_total_s: 4284.887801408768
  timestamp: 1594862596
  timesteps_since_restore: 2495000
  timesteps_this_iter: 5000
  timesteps_total: 2495000
  training_iteration: 499
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 4284 s, 499 iter, 2495000 ts, -102 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-23-24
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -101.50999914156111
  episode_reward_min: -10150.999914156111
  episodes_this_iter: 1
  episodes_total: 499
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 3.118
    dispatch_time_ms: 9.138
    learner:
      cur_lr: 0.0011938329553231597
      grad_gnorm: 0.15976238250732422
      policy_entropy: 0.004958523903042078
      policy_loss: 2.827743514899339e-07
      var_gnorm: 27.52465057373047
      vf_explained_var: 1.1920928955078125e-07
      vf_loss: 1.6813957699923776e-05
    num_steps_sampled: 2500000
    num_steps_trained: 2500000
    wait_time_ms: 71.3
  iterations_since_restore: 500
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 4293.025746583939
  time_this_iter_s: 8.137945175170898
  time_total_s: 4293.025746583939
  timestamp: 1594862604
  timesteps_since_restore: 2500000
  timesteps_this_iter: 5000
  timesteps_total: 2500000
  training_iteration: 500
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 4293 s, 500 iter, 2500000 ts, -102 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-23-36
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -101.50999914156111
  episode_reward_min: -10150.999914156111
  episodes_this_iter: 1
  episodes_total: 500
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 3.094
    dispatch_time_ms: 20.666
    learner:
      cur_lr: 0.0011935000075027347
      grad_gnorm: 29.48525047302246
      policy_entropy: 0.005285540129989386
      policy_loss: 4.142823328834311e-08
      var_gnorm: 27.52439308166504
      vf_explained_var: -8.106231689453125e-05
      vf_loss: 0.453624963760376
    num_steps_sampled: 2505000
    num_steps_trained: 2505000
    wait_time_ms: 26.067
  iterations_since_restore: 501
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 4304.970572471619
  time_this_iter_s: 11.944825887680054
  time_total_s: 4304.970572471619
  timestamp: 1594862616
  timesteps_since_restore: 2505000
  timesteps_this_iter: 5000
  timesteps_total: 2505000
  training_iteration: 501
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 4304 s, 501 iter, 2505000 ts, -102 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-23-44
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -101.50999914156111
  episode_reward_min: -10150.999914156111
  episodes_this_iter: 1
  episodes_total: 501
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.593
    dispatch_time_ms: 18.152
    learner:
      cur_lr: 0.0011931669432669878
      grad_gnorm: 0.5321609973907471
      policy_entropy: 0.005778404884040356
      policy_loss: 6.465593742177589e-06
      var_gnorm: 27.524253845214844
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 0.00018651713617146015
    num_steps_sampled: 2510000
    num_steps_trained: 2510000
    wait_time_ms: 62.428
  iterations_since_restore: 502
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 4313.15573143959
  time_this_iter_s: 8.185158967971802
  time_total_s: 4313.15573143959
  timestamp: 1594862624
  timesteps_since_restore: 2510000
  timesteps_this_iter: 5000
  timesteps_total: 2510000
  training_iteration: 502
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 4313 s, 502 iter, 2510000 ts, -102 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-23-53
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -101.50999914156111
  episode_reward_min: -10150.999914156111
  episodes_this_iter: 1
  episodes_total: 502
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.845
    dispatch_time_ms: 18.583
    learner:
      cur_lr: 0.0011928339954465628
      grad_gnorm: 0.0033881706185638905
      policy_entropy: 0.006244503892958164
      policy_loss: -1.1688318757308025e-08
      var_gnorm: 27.524070739746094
      vf_explained_var: 0.0
      vf_loss: 7.370197341316498e-09
    num_steps_sampled: 2515000
    num_steps_trained: 2515000
    wait_time_ms: 67.111
  iterations_since_restore: 503
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 4321.79163813591
  time_this_iter_s: 8.63590669631958
  time_total_s: 4321.79163813591
  timestamp: 1594862633
  timesteps_since_restore: 2515000
  timesteps_this_iter: 5000
  timesteps_total: 2515000
  training_iteration: 503
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 4321 s, 503 iter, 2515000 ts, -102 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-24-01
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -101.50999914156111
  episode_reward_min: -10150.999914156111
  episodes_this_iter: 1
  episodes_total: 503
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 3.149
    dispatch_time_ms: 26.837
    learner:
      cur_lr: 0.0011925010476261377
      grad_gnorm: 0.2970646023750305
      policy_entropy: 0.006821413990110159
      policy_loss: -8.470665306958836e-06
      var_gnorm: 27.523895263671875
      vf_explained_var: 0.0
      vf_loss: 5.8100849855691195e-05
    num_steps_sampled: 2520000
    num_steps_trained: 2520000
    wait_time_ms: 56.151
  iterations_since_restore: 504
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 4330.451442480087
  time_this_iter_s: 8.659804344177246
  time_total_s: 4330.451442480087
  timestamp: 1594862641
  timesteps_since_restore: 2520000
  timesteps_this_iter: 5000
  timesteps_total: 2520000
  training_iteration: 504
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 4330 s, 504 iter, 2520000 ts, -102 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-24-10
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -101.50999914156111
  episode_reward_min: -10150.999914156111
  episodes_this_iter: 1
  episodes_total: 504
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.563
    dispatch_time_ms: 19.184
    learner:
      cur_lr: 0.0011921679833903909
      grad_gnorm: 7.528589048888534e-05
      policy_entropy: 0.007668747566640377
      policy_loss: -9.19717253744512e-12
      var_gnorm: 27.523643493652344
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 1.3703663854711112e-12
    num_steps_sampled: 2525000
    num_steps_trained: 2525000
    wait_time_ms: 64.381
  iterations_since_restore: 505
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 4339.143088340759
  time_this_iter_s: 8.691645860671997
  time_total_s: 4339.143088340759
  timestamp: 1594862650
  timesteps_since_restore: 2525000
  timesteps_this_iter: 5000
  timesteps_total: 2525000
  training_iteration: 505
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 4339 s, 505 iter, 2525000 ts, -102 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-24-19
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -101.50999914156111
  episode_reward_min: -10150.999914156111
  episodes_this_iter: 1
  episodes_total: 505
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.761
    dispatch_time_ms: 31.399
    learner:
      cur_lr: 0.0011918350355699658
      grad_gnorm: 0.5979589819908142
      policy_entropy: 0.008738039992749691
      policy_loss: 6.191304237290751e-06
      var_gnorm: 27.523361206054688
      vf_explained_var: 0.0
      vf_loss: 0.00023549485194962472
    num_steps_sampled: 2530000
    num_steps_trained: 2530000
    wait_time_ms: 54.173
  iterations_since_restore: 506
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 4347.853072166443
  time_this_iter_s: 8.709983825683594
  time_total_s: 4347.853072166443
  timestamp: 1594862659
  timesteps_since_restore: 2530000
  timesteps_this_iter: 5000
  timesteps_total: 2530000
  training_iteration: 506
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 4347 s, 506 iter, 2530000 ts, -102 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-24-28
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -101.50999914156111
  episode_reward_min: -10150.999914156111
  episodes_this_iter: 1
  episodes_total: 506
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.573
    dispatch_time_ms: 36.693
    learner:
      cur_lr: 0.001191501971334219
      grad_gnorm: 0.07754150778055191
      policy_entropy: 0.009861133061349392
      policy_loss: 3.9584918454238505e-07
      var_gnorm: 27.52314567565918
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 3.958132765546907e-06
    num_steps_sampled: 2535000
    num_steps_trained: 2535000
    wait_time_ms: 47.117
  iterations_since_restore: 507
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 4356.600950241089
  time_this_iter_s: 8.747878074645996
  time_total_s: 4356.600950241089
  timestamp: 1594862668
  timesteps_since_restore: 2535000
  timesteps_this_iter: 5000
  timesteps_total: 2535000
  training_iteration: 507
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 4356 s, 507 iter, 2535000 ts, -102 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-24-36
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -101.50999914156111
  episode_reward_min: -10150.999914156111
  episodes_this_iter: 1
  episodes_total: 507
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.659
    dispatch_time_ms: 7.539
    learner:
      cur_lr: 0.001191169023513794
      grad_gnorm: 0.65925133228302
      policy_entropy: 0.011715675704181194
      policy_loss: -2.271910716444836e-06
      var_gnorm: 27.5228328704834
      vf_explained_var: 0.0
      vf_loss: 0.0002861655957531184
    num_steps_sampled: 2540000
    num_steps_trained: 2540000
    wait_time_ms: 71.647
  iterations_since_restore: 508
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 4364.799187660217
  time_this_iter_s: 8.198237419128418
  time_total_s: 4364.799187660217
  timestamp: 1594862676
  timesteps_since_restore: 2540000
  timesteps_this_iter: 5000
  timesteps_total: 2540000
  training_iteration: 508
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 4364 s, 508 iter, 2540000 ts, -102 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-24-44
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -101.50999914156111
  episode_reward_min: -10150.999914156111
  episodes_this_iter: 1
  episodes_total: 508
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.76
    dispatch_time_ms: 7.066
    learner:
      cur_lr: 0.001190835959278047
      grad_gnorm: 0.0687607154250145
      policy_entropy: 0.01481891144067049
      policy_loss: -4.025560542686435e-07
      var_gnorm: 27.522361755371094
      vf_explained_var: 1.1920928955078125e-07
      vf_loss: 3.113317688985262e-06
    num_steps_sampled: 2545000
    num_steps_trained: 2545000
    wait_time_ms: 71.142
  iterations_since_restore: 509
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 4372.99645781517
  time_this_iter_s: 8.197270154953003
  time_total_s: 4372.99645781517
  timestamp: 1594862684
  timesteps_since_restore: 2545000
  timesteps_this_iter: 5000
  timesteps_total: 2545000
  training_iteration: 509
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 4372 s, 509 iter, 2545000 ts, -102 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-24-52
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -101.50999914156111
  episode_reward_min: -10150.999914156111
  episodes_this_iter: 1
  episodes_total: 509
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.787
    dispatch_time_ms: 7.413
    learner:
      cur_lr: 0.001190503011457622
      grad_gnorm: 0.6831072568893433
      policy_entropy: 0.020063333213329315
      policy_loss: -7.2160278250521515e-06
      var_gnorm: 27.52180290222168
      vf_explained_var: 0.0
      vf_loss: 0.00030727111152373254
    num_steps_sampled: 2550000
    num_steps_trained: 2550000
    wait_time_ms: 73.077
  iterations_since_restore: 510
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 4381.185948610306
  time_this_iter_s: 8.189490795135498
  time_total_s: 4381.185948610306
  timestamp: 1594862692
  timesteps_since_restore: 2550000
  timesteps_this_iter: 5000
  timesteps_total: 2550000
  training_iteration: 510
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 4381 s, 510 iter, 2550000 ts, -102 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-25-01
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -101.50999914156111
  episode_reward_min: -10150.999914156111
  episodes_this_iter: 1
  episodes_total: 510
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.733
    dispatch_time_ms: 8.532
    learner:
      cur_lr: 0.0011901699472218752
      grad_gnorm: 0.1315726637840271
      policy_entropy: 0.032555922865867615
      policy_loss: -2.938240868388675e-06
      var_gnorm: 27.520875930786133
      vf_explained_var: 1.7881393432617188e-07
      vf_loss: 1.1401047231629491e-05
    num_steps_sampled: 2555000
    num_steps_trained: 2555000
    wait_time_ms: 69.295
  iterations_since_restore: 511
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 4389.332476615906
  time_this_iter_s: 8.146528005599976
  time_total_s: 4389.332476615906
  timestamp: 1594862701
  timesteps_since_restore: 2555000
  timesteps_this_iter: 5000
  timesteps_total: 2555000
  training_iteration: 511
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 4389 s, 511 iter, 2555000 ts, -102 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-25-09
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -101.50999914156111
  episode_reward_min: -10150.999914156111
  episodes_this_iter: 1
  episodes_total: 511
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.962
    dispatch_time_ms: 8.486
    learner:
      cur_lr: 0.0011898369994014502
      grad_gnorm: 0.513370931148529
      policy_entropy: 0.07615197449922562
      policy_loss: -4.436207746039145e-05
      var_gnorm: 27.519357681274414
      vf_explained_var: 0.0
      vf_loss: 0.00017355640011373907
    num_steps_sampled: 2560000
    num_steps_trained: 2560000
    wait_time_ms: 70.695
  iterations_since_restore: 512
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 4397.48869228363
  time_this_iter_s: 8.15621566772461
  time_total_s: 4397.48869228363
  timestamp: 1594862709
  timesteps_since_restore: 2560000
  timesteps_this_iter: 5000
  timesteps_total: 2560000
  training_iteration: 512
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 4397 s, 512 iter, 2560000 ts, -102 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-25-17
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -101.50999914156111
  episode_reward_min: -10150.999914156111
  episodes_this_iter: 1
  episodes_total: 512
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 3.409
    dispatch_time_ms: 8.191
    learner:
      cur_lr: 0.0011895040515810251
      grad_gnorm: 0.23666876554489136
      policy_entropy: 13.213766098022461
      policy_loss: -0.016322795301675797
      var_gnorm: 27.512237548828125
      vf_explained_var: 0.0
      vf_loss: 8.80063817021437e-06
    num_steps_sampled: 2565000
    num_steps_trained: 2565000
    wait_time_ms: 69.533
  iterations_since_restore: 513
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 4405.671142816544
  time_this_iter_s: 8.182450532913208
  time_total_s: 4405.671142816544
  timestamp: 1594862717
  timesteps_since_restore: 2565000
  timesteps_this_iter: 5000
  timesteps_total: 2565000
  training_iteration: 513
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 4405 s, 513 iter, 2565000 ts, -102 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-25-25
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: 0.0
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 513
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.585
    dispatch_time_ms: 10.484
    learner:
      cur_lr: 0.0011891709873452783
      grad_gnorm: 0.5307809114456177
      policy_entropy: 0.007914099842309952
      policy_loss: -2.8258239126444096e-06
      var_gnorm: 27.528949737548828
      vf_explained_var: 0.0
      vf_loss: 0.00018548282969277352
    num_steps_sampled: 2570000
    num_steps_trained: 2570000
    wait_time_ms: 66.035
  iterations_since_restore: 514
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 4413.640643596649
  time_this_iter_s: 7.969500780105591
  time_total_s: 4413.640643596649
  timestamp: 1594862725
  timesteps_since_restore: 2570000
  timesteps_this_iter: 5000
  timesteps_total: 2570000
  training_iteration: 514
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 4413 s, 514 iter, 2570000 ts, 0 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-25-33
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: 0.0
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 514
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.892
    dispatch_time_ms: 8.943
    learner:
      cur_lr: 0.0011888380395248532
      grad_gnorm: 0.014452400617301464
      policy_entropy: 0.008610013872385025
      policy_loss: -1.533908147166585e-07
      var_gnorm: 27.529033660888672
      vf_explained_var: 0.0
      vf_loss: 1.3774190676940634e-07
    num_steps_sampled: 2575000
    num_steps_trained: 2575000
    wait_time_ms: 66.309
  iterations_since_restore: 515
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 4421.548075437546
  time_this_iter_s: 7.9074318408966064
  time_total_s: 4421.548075437546
  timestamp: 1594862733
  timesteps_since_restore: 2575000
  timesteps_this_iter: 5000
  timesteps_total: 2575000
  training_iteration: 515
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 4421 s, 515 iter, 2575000 ts, 0 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-25-41
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: 0.0
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 515
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.52
    dispatch_time_ms: 6.621
    learner:
      cur_lr: 0.0011885049752891064
      grad_gnorm: 0.3979007303714752
      policy_entropy: 0.009387628175318241
      policy_loss: -6.939421382412547e-06
      var_gnorm: 27.52918243408203
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 0.00010427118104416877
    num_steps_sampled: 2580000
    num_steps_trained: 2580000
    wait_time_ms: 68.807
  iterations_since_restore: 516
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 4429.372430801392
  time_this_iter_s: 7.824355363845825
  time_total_s: 4429.372430801392
  timestamp: 1594862741
  timesteps_since_restore: 2580000
  timesteps_this_iter: 5000
  timesteps_total: 2580000
  training_iteration: 516
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 4429 s, 516 iter, 2580000 ts, 0 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-25-49
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: 0.0
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 516
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.703
    dispatch_time_ms: 6.956
    learner:
      cur_lr: 0.0011881720274686813
      grad_gnorm: 0.23316462337970734
      policy_entropy: 0.010418618097901344
      policy_loss: -2.0540762761811493e-06
      var_gnorm: 27.529327392578125
      vf_explained_var: 0.0
      vf_loss: 3.5808843676932156e-05
    num_steps_sampled: 2585000
    num_steps_trained: 2585000
    wait_time_ms: 71.815
  iterations_since_restore: 517
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 4437.293762922287
  time_this_iter_s: 7.921332120895386
  time_total_s: 4437.293762922287
  timestamp: 1594862749
  timesteps_since_restore: 2585000
  timesteps_this_iter: 5000
  timesteps_total: 2585000
  training_iteration: 517
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 4437 s, 517 iter, 2585000 ts, 0 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-26-07
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: 0.0
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 517
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 3.238
    dispatch_time_ms: 7.566
    learner:
      cur_lr: 0.0011878389632329345
      grad_gnorm: 0.4311043918132782
      policy_entropy: 0.011583657935261726
      policy_loss: -8.92978368938202e-06
      var_gnorm: 27.529525756835938
      vf_explained_var: 0.0
      vf_loss: 0.00012233032612130046
    num_steps_sampled: 2590000
    num_steps_trained: 2590000
    wait_time_ms: 69.372
  iterations_since_restore: 518
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 4455.347291946411
  time_this_iter_s: 18.053529024124146
  time_total_s: 4455.347291946411
  timestamp: 1594862767
  timesteps_since_restore: 2590000
  timesteps_this_iter: 5000
  timesteps_total: 2590000
  training_iteration: 518
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 4455 s, 518 iter, 2590000 ts, 0 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-26-15
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: 0.0
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 518
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.503
    dispatch_time_ms: 10.543
    learner:
      cur_lr: 0.0011875060154125094
      grad_gnorm: 0.40688541531562805
      policy_entropy: 0.013532220385968685
      policy_loss: 8.865227414389665e-07
      var_gnorm: 27.52977180480957
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 0.0001089980432880111
    num_steps_sampled: 2595000
    num_steps_trained: 2595000
    wait_time_ms: 68.723
  iterations_since_restore: 519
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 4463.253959417343
  time_this_iter_s: 7.906667470932007
  time_total_s: 4463.253959417343
  timestamp: 1594862775
  timesteps_since_restore: 2595000
  timesteps_this_iter: 5000
  timesteps_total: 2595000
  training_iteration: 519
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 4463 s, 519 iter, 2595000 ts, 0 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-26-23
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: 0.0
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 519
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.727
    dispatch_time_ms: 9.029
    learner:
      cur_lr: 0.0011871729511767626
      grad_gnorm: 0.07534057646989822
      policy_entropy: 0.016023442149162292
      policy_loss: 4.800559736395371e-07
      var_gnorm: 27.53012466430664
      vf_explained_var: 0.0
      vf_loss: 3.735518703251728e-06
    num_steps_sampled: 2600000
    num_steps_trained: 2600000
    wait_time_ms: 68.031
  iterations_since_restore: 520
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 4471.202716827393
  time_this_iter_s: 7.9487574100494385
  time_total_s: 4471.202716827393
  timestamp: 1594862783
  timesteps_since_restore: 2600000
  timesteps_this_iter: 5000
  timesteps_total: 2600000
  training_iteration: 520
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 4471 s, 520 iter, 2600000 ts, 0 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-26-31
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: 0.0
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 520
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.638
    dispatch_time_ms: 8.544
    learner:
      cur_lr: 0.0011868400033563375
      grad_gnorm: 0.35160914063453674
      policy_entropy: 0.020148223266005516
      policy_loss: 4.2987494452972896e-07
      var_gnorm: 27.53061294555664
      vf_explained_var: 0.0
      vf_loss: 8.140742284012958e-05
    num_steps_sampled: 2605000
    num_steps_trained: 2605000
    wait_time_ms: 68.762
  iterations_since_restore: 521
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 4479.068959951401
  time_this_iter_s: 7.866243124008179
  time_total_s: 4479.068959951401
  timestamp: 1594862791
  timesteps_since_restore: 2605000
  timesteps_this_iter: 5000
  timesteps_total: 2605000
  training_iteration: 521
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 4479 s, 521 iter, 2605000 ts, 0 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-26-39
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: 0.0
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 521
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.764
    dispatch_time_ms: 7.758
    learner:
      cur_lr: 0.0011865070555359125
      grad_gnorm: 0.6731652021408081
      policy_entropy: 0.026847217231988907
      policy_loss: 5.470993983180961e-06
      var_gnorm: 27.531335830688477
      vf_explained_var: 0.0
      vf_loss: 0.00029839196940883994
    num_steps_sampled: 2610000
    num_steps_trained: 2610000
    wait_time_ms: 68.893
  iterations_since_restore: 522
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 4486.939942121506
  time_this_iter_s: 7.8709821701049805
  time_total_s: 4486.939942121506
  timestamp: 1594862799
  timesteps_since_restore: 2610000
  timesteps_this_iter: 5000
  timesteps_total: 2610000
  training_iteration: 522
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 4486 s, 522 iter, 2610000 ts, 0 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-26-47
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: 0.0
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 522
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.765
    dispatch_time_ms: 8.298
    learner:
      cur_lr: 0.0011861739913001657
      grad_gnorm: 0.25612369179725647
      policy_entropy: 0.04076187685132027
      policy_loss: -2.1889405843467102e-07
      var_gnorm: 27.532590866088867
      vf_explained_var: 1.7881393432617188e-07
      vf_loss: 4.319228537497111e-05
    num_steps_sampled: 2615000
    num_steps_trained: 2615000
    wait_time_ms: 68.077
  iterations_since_restore: 523
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 4494.888568639755
  time_this_iter_s: 7.948626518249512
  time_total_s: 4494.888568639755
  timestamp: 1594862807
  timesteps_since_restore: 2615000
  timesteps_this_iter: 5000
  timesteps_total: 2615000
  training_iteration: 523
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 4494 s, 523 iter, 2615000 ts, 0 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-26-54
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: 0.0
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 523
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.748
    dispatch_time_ms: 7.781
    learner:
      cur_lr: 0.0011858410434797406
      grad_gnorm: 0.9725296497344971
      policy_entropy: 0.08171818405389786
      policy_loss: 3.248855864512734e-05
      var_gnorm: 27.535465240478516
      vf_explained_var: 0.0
      vf_loss: 0.0006228705169633031
    num_steps_sampled: 2620000
    num_steps_trained: 2620000
    wait_time_ms: 73.498
  iterations_since_restore: 524
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 4502.808760404587
  time_this_iter_s: 7.920191764831543
  time_total_s: 4502.808760404587
  timestamp: 1594862814
  timesteps_since_restore: 2620000
  timesteps_this_iter: 5000
  timesteps_total: 2620000
  training_iteration: 524
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 4502 s, 524 iter, 2620000 ts, 0 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-27-02
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: 0.0
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 524
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 3.131
    dispatch_time_ms: 7.98
    learner:
      cur_lr: 0.0011855079792439938
      grad_gnorm: 0.6257140636444092
      policy_entropy: 0.5957563519477844
      policy_loss: 0.0002263368369312957
      var_gnorm: 27.56931495666504
      vf_explained_var: 1.1920928955078125e-07
      vf_loss: 0.0002578149433247745
    num_steps_sampled: 2625000
    num_steps_trained: 2625000
    wait_time_ms: 68.792
  iterations_since_restore: 525
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 4510.775083780289
  time_this_iter_s: 7.966323375701904
  time_total_s: 4510.775083780289
  timestamp: 1594862822
  timesteps_since_restore: 2625000
  timesteps_this_iter: 5000
  timesteps_total: 2625000
  training_iteration: 525
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 4510 s, 525 iter, 2625000 ts, 0 rew

agent-1: -167.38315290882966
agent-2: -745.9626944231109
agent-3: -553.1520829675289
agent-4: -553.2926922055922
agent-5: -15.879388822624584
Extrinsic Rewards:
5
0
1
1
8
Sum Reward: 15
Avg Reward: 3.0
Min Reward: 0
Max Reward: 8
Gini Coefficient: 0.5333333333333333
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-27-11
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -20.356700113276844
  episode_reward_min: -2035.6700113276845
  episodes_this_iter: 1
  episodes_total: 525
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.747
    dispatch_time_ms: 9.299
    learner:
      cur_lr: 0.0011851750314235687
      grad_gnorm: 40.000003814697266
      policy_entropy: 0.3254249691963196
      policy_loss: 0.033412471413612366
      var_gnorm: 27.743186950683594
      vf_explained_var: 1.1920928955078125e-07
      vf_loss: 19.611095428466797
    num_steps_sampled: 2630000
    num_steps_trained: 2630000
    wait_time_ms: 69.629
  iterations_since_restore: 526
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 4518.9401161670685
  time_this_iter_s: 8.165032386779785
  time_total_s: 4518.9401161670685
  timestamp: 1594862831
  timesteps_since_restore: 2630000
  timesteps_this_iter: 5000
  timesteps_total: 2630000
  training_iteration: 526
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 4518 s, 526 iter, 2630000 ts, -20.4 rew

agent-1: -6.679416268110295
agent-2: -298.27949153547695
agent-3: -163.50365476721723
agent-4: -699.9997647880576
agent-5: -57.145740548201886
Extrinsic Rewards:
5
2
3
0
4
Sum Reward: 14
Avg Reward: 2.8
Min Reward: 0
Max Reward: 5
Gini Coefficient: 0.34285714285714286
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-27-19
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -32.61278079234744
  episode_reward_min: -2035.6700113276845
  episodes_this_iter: 1
  episodes_total: 526
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.715
    dispatch_time_ms: 6.202
    learner:
      cur_lr: 0.0011848419671878219
      grad_gnorm: 14.62479305267334
      policy_entropy: 0.18124879896640778
      policy_loss: 0.0017719250172376633
      var_gnorm: 27.694690704345703
      vf_explained_var: 0.0
      vf_loss: 0.14520657062530518
    num_steps_sampled: 2635000
    num_steps_trained: 2635000
    wait_time_ms: 74.589
  iterations_since_restore: 527
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 4527.126665592194
  time_this_iter_s: 8.186549425125122
  time_total_s: 4527.126665592194
  timestamp: 1594862839
  timesteps_since_restore: 2635000
  timesteps_this_iter: 5000
  timesteps_total: 2635000
  training_iteration: 527
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 4527 s, 527 iter, 2635000 ts, -32.6 rew

agent-1: 2.96875
agent-2: -99.03124999890878
agent-3: -199.99999999784504
agent-4: -199.99999999784504
agent-5: -199.99999999784504
Extrinsic Rewards:
3
1
0
0
0
Sum Reward: 4
Avg Reward: 0.8
Min Reward: 0
Max Reward: 3
Gini Coefficient: 0.7
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-27-27
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -39.57340579227193
  episode_reward_min: -2035.6700113276845
  episodes_this_iter: 1
  episodes_total: 527
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.656
    dispatch_time_ms: 6.397
    learner:
      cur_lr: 0.0011845090193673968
      grad_gnorm: 10.994047164916992
      policy_entropy: 0.22246766090393066
      policy_loss: 0.0012967322254553437
      var_gnorm: 27.6956844329834
      vf_explained_var: 0.0
      vf_loss: 0.14455358684062958
    num_steps_sampled: 2640000
    num_steps_trained: 2640000
    wait_time_ms: 72.672
  iterations_since_restore: 528
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 4535.269288301468
  time_this_iter_s: 8.142622709274292
  time_total_s: 4535.269288301468
  timestamp: 1594862847
  timesteps_since_restore: 2640000
  timesteps_this_iter: 5000
  timesteps_total: 2640000
  training_iteration: 528
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 4535 s, 528 iter, 2640000 ts, -39.6 rew

agent-1: -349.9999999962086
agent-2: -49.46874999939871
agent-3: -349.9999999962086
agent-4: 1.53125
agent-5: -349.9999999962086
Extrinsic Rewards:
0
3
0
4
0
Sum Reward: 7
Avg Reward: 1.4
Min Reward: 0
Max Reward: 4
Gini Coefficient: 0.6285714285714286
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-27-35
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -50.55278079215203
  episode_reward_min: -2035.6700113276845
  episodes_this_iter: 1
  episodes_total: 528
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 3.094
    dispatch_time_ms: 8.526
    learner:
      cur_lr: 0.00118417595513165
      grad_gnorm: 14.709864616394043
      policy_entropy: 0.25713881850242615
      policy_loss: 0.0026241519954055548
      var_gnorm: 27.695005416870117
      vf_explained_var: 1.1920928955078125e-07
      vf_loss: 0.14309914410114288
    num_steps_sampled: 2645000
    num_steps_trained: 2645000
    wait_time_ms: 70.968
  iterations_since_restore: 529
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 4543.4951293468475
  time_this_iter_s: 8.225841045379639
  time_total_s: 4543.4951293468475
  timestamp: 1594862855
  timesteps_since_restore: 2645000
  timesteps_this_iter: 5000
  timesteps_total: 2645000
  training_iteration: 529
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 4543 s, 529 iter, 2645000 ts, -50.6 rew

agent-1: -149.99999999840443
agent-2: -149.99999999840443
agent-3: 3.0
agent-4: -149.99999999840443
agent-5: -149.99999999840443
Extrinsic Rewards:
0
0
3
0
0
Sum Reward: 3
Avg Reward: 0.6
Min Reward: 0
Max Reward: 3
Gini Coefficient: 0.8
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-27-43
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -56.52278079208828
  episode_reward_min: -2035.6700113276845
  episodes_this_iter: 1
  episodes_total: 529
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 3.017
    dispatch_time_ms: 7.602
    learner:
      cur_lr: 0.001183843007311225
      grad_gnorm: 30.265737533569336
      policy_entropy: 0.3431863784790039
      policy_loss: 0.005895919166505337
      var_gnorm: 27.696094512939453
      vf_explained_var: 0.0
      vf_loss: 0.6031767129898071
    num_steps_sampled: 2650000
    num_steps_trained: 2650000
    wait_time_ms: 69.333
  iterations_since_restore: 530
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 4551.590985059738
  time_this_iter_s: 8.095855712890625
  time_total_s: 4551.590985059738
  timestamp: 1594862863
  timesteps_since_restore: 2650000
  timesteps_this_iter: 5000
  timesteps_total: 2650000
  training_iteration: 530
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 4551 s, 530 iter, 2650000 ts, -56.5 rew

agent-1: -149.99999999840443
agent-2: -149.99999999840443
agent-3: 3.0
agent-4: -149.99999999840443
agent-5: -149.99999999840443
Extrinsic Rewards:
0
0
3
0
0
Sum Reward: 3
Avg Reward: 0.6
Min Reward: 0
Max Reward: 3
Gini Coefficient: 0.8
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-27-52
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -62.49278079202453
  episode_reward_min: -2035.6700113276845
  episodes_this_iter: 1
  episodes_total: 530
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 3.237
    dispatch_time_ms: 9.541
    learner:
      cur_lr: 0.001183509943075478
      grad_gnorm: 16.171907424926758
      policy_entropy: 0.22025349736213684
      policy_loss: 0.002342608291655779
      var_gnorm: 27.695127487182617
      vf_explained_var: -2.384185791015625e-07
      vf_loss: 0.17471101880073547
    num_steps_sampled: 2655000
    num_steps_trained: 2655000
    wait_time_ms: 71.155
  iterations_since_restore: 531
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 4559.8100163936615
  time_this_iter_s: 8.21903133392334
  time_total_s: 4559.8100163936615
  timestamp: 1594862872
  timesteps_since_restore: 2655000
  timesteps_this_iter: 5000
  timesteps_total: 2655000
  training_iteration: 531
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 4559 s, 531 iter, 2655000 ts, -62.5 rew

agent-1: 3.0
agent-2: -249.99999999735493
agent-3: -249.99999999735493
agent-4: -249.99999999735493
agent-5: -47.99999999945478
Extrinsic Rewards:
3
0
0
0
2
Sum Reward: 5
Avg Reward: 1.0
Min Reward: 0
Max Reward: 3
Gini Coefficient: 0.64
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-28-00
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -70.44278079193971
  episode_reward_min: -2035.6700113276845
  episodes_this_iter: 1
  episodes_total: 531
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.382
    dispatch_time_ms: 6.76
    learner:
      cur_lr: 0.001183176995255053
      grad_gnorm: 0.18050025403499603
      policy_entropy: 0.2010970562696457
      policy_loss: 1.901163523143623e-05
      var_gnorm: 27.694875717163086
      vf_explained_var: 0.0
      vf_loss: 2.146540100511629e-05
    num_steps_sampled: 2660000
    num_steps_trained: 2660000
    wait_time_ms: 75.046
  iterations_since_restore: 532
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 4568.117224216461
  time_this_iter_s: 8.307207822799683
  time_total_s: 4568.117224216461
  timestamp: 1594862880
  timesteps_since_restore: 2660000
  timesteps_this_iter: 5000
  timesteps_total: 2660000
  training_iteration: 532
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 4568 s, 532 iter, 2660000 ts, -70.4 rew

agent-1: -199.99999999788645
agent-2: -199.99999999788645
agent-3: -98.999999998923
agent-4: 3.0
agent-5: -199.99999999788645
Extrinsic Rewards:
0
0
1
3
0
Sum Reward: 4
Avg Reward: 0.8
Min Reward: 0
Max Reward: 3
Gini Coefficient: 0.7
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-28-08
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -77.40278079186554
  episode_reward_min: -2035.6700113276845
  episodes_this_iter: 1
  episodes_total: 532
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.558
    dispatch_time_ms: 8.071
    learner:
      cur_lr: 0.001182844047434628
      grad_gnorm: 21.227294921875
      policy_entropy: 0.13143138587474823
      policy_loss: 0.0016294699162244797
      var_gnorm: 27.695016860961914
      vf_explained_var: 1.1920928955078125e-07
      vf_loss: 0.29671064019203186
    num_steps_sampled: 2665000
    num_steps_trained: 2665000
    wait_time_ms: 70.562
  iterations_since_restore: 533
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 4576.304114818573
  time_this_iter_s: 8.186890602111816
  time_total_s: 4576.304114818573
  timestamp: 1594862888
  timesteps_since_restore: 2665000
  timesteps_this_iter: 5000
  timesteps_total: 2665000
  training_iteration: 533
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 4576 s, 533 iter, 2665000 ts, -77.4 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-28-17
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -77.40278079186554
  episode_reward_min: -2035.6700113276845
  episodes_this_iter: 1
  episodes_total: 533
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.754
    dispatch_time_ms: 6.883
    learner:
      cur_lr: 0.0011825109831988811
      grad_gnorm: 0.1933833360671997
      policy_entropy: 0.12175525724887848
      policy_loss: 1.1562317013158463e-05
      var_gnorm: 27.694725036621094
      vf_explained_var: 0.0
      vf_loss: 2.4630466214148328e-05
    num_steps_sampled: 2670000
    num_steps_trained: 2670000
    wait_time_ms: 72.943
  iterations_since_restore: 534
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 4584.493913412094
  time_this_iter_s: 8.189798593521118
  time_total_s: 4584.493913412094
  timestamp: 1594862897
  timesteps_since_restore: 2670000
  timesteps_this_iter: 5000
  timesteps_total: 2670000
  training_iteration: 534
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 4584 s, 534 iter, 2670000 ts, -77.4 rew

agent-1: 3.0
agent-2: -249.99999999736787
agent-3: -98.999999998923
agent-4: -98.999999998923
agent-5: -249.99999999736787
Extrinsic Rewards:
3
0
1
1
0
Sum Reward: 5
Avg Reward: 1.0
Min Reward: 0
Max Reward: 3
Gini Coefficient: 0.56
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-28-25
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -84.35278079179142
  episode_reward_min: -2035.6700113276845
  episodes_this_iter: 1
  episodes_total: 534
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 3.103
    dispatch_time_ms: 8.489
    learner:
      cur_lr: 0.0011821780353784561
      grad_gnorm: 0.04892432317137718
      policy_entropy: 0.12442442774772644
      policy_loss: -2.9965158319100738e-06
      var_gnorm: 27.6948299407959
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 1.5699490631959634e-06
    num_steps_sampled: 2675000
    num_steps_trained: 2675000
    wait_time_ms: 72.129
  iterations_since_restore: 535
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 4592.7447826862335
  time_this_iter_s: 8.250869274139404
  time_total_s: 4592.7447826862335
  timestamp: 1594862905
  timesteps_since_restore: 2675000
  timesteps_this_iter: 5000
  timesteps_total: 2675000
  training_iteration: 535
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 4592 s, 535 iter, 2675000 ts, -84.4 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-28-33
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -84.35278079179142
  episode_reward_min: -2035.6700113276845
  episodes_this_iter: 1
  episodes_total: 535
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 3.171
    dispatch_time_ms: 8.953
    learner:
      cur_lr: 0.0011818449711427093
      grad_gnorm: 11.124411582946777
      policy_entropy: 0.13989654183387756
      policy_loss: 0.0007777842110954225
      var_gnorm: 27.696016311645508
      vf_explained_var: 0.0
      vf_loss: 0.19032758474349976
    num_steps_sampled: 2680000
    num_steps_trained: 2680000
    wait_time_ms: 70.131
  iterations_since_restore: 536
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 4600.922299861908
  time_this_iter_s: 8.177517175674438
  time_total_s: 4600.922299861908
  timestamp: 1594862913
  timesteps_since_restore: 2680000
  timesteps_this_iter: 5000
  timesteps_total: 2680000
  training_iteration: 536
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 4600 s, 536 iter, 2680000 ts, -84.4 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-28-42
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -84.35278079179139
  episode_reward_min: -2035.6700113276845
  episodes_this_iter: 1
  episodes_total: 536
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.695
    dispatch_time_ms: 19.556
    learner:
      cur_lr: 0.0011815120233222842
      grad_gnorm: 11.060171127319336
      policy_entropy: 0.445576012134552
      policy_loss: 0.006484252400696278
      var_gnorm: 27.695802688598633
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 0.08054575324058533
    num_steps_sampled: 2685000
    num_steps_trained: 2685000
    wait_time_ms: 62.711
  iterations_since_restore: 537
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 4609.527187585831
  time_this_iter_s: 8.60488772392273
  time_total_s: 4609.527187585831
  timestamp: 1594862922
  timesteps_since_restore: 2685000
  timesteps_this_iter: 5000
  timesteps_total: 2685000
  training_iteration: 537
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 4609 s, 537 iter, 2685000 ts, -84.4 rew

agent-1: -99.2499999988536
agent-2: 2.75
agent-3: -299.9999999967528
agent-4: -299.9999999967528
agent-5: -299.9999999967528
Extrinsic Rewards:
2
4
0
0
0
Sum Reward: 6
Avg Reward: 1.2
Min Reward: 0
Max Reward: 4
Gini Coefficient: 0.6666666666666666
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-28-50
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -94.31778079168251
  episode_reward_min: -2035.6700113276845
  episodes_this_iter: 1
  episodes_total: 537
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 3.043
    dispatch_time_ms: 22.09
    learner:
      cur_lr: 0.0011811789590865374
      grad_gnorm: 0.0123693672940135
      policy_entropy: 0.7312018871307373
      policy_loss: 0.00010539862705627456
      var_gnorm: 27.696395874023438
      vf_explained_var: 0.0
      vf_loss: 3.975517756771296e-06
    num_steps_sampled: 2690000
    num_steps_trained: 2690000
    wait_time_ms: 63.904
  iterations_since_restore: 538
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 4618.203072786331
  time_this_iter_s: 8.675885200500488
  time_total_s: 4618.203072786331
  timestamp: 1594862930
  timesteps_since_restore: 2690000
  timesteps_this_iter: 5000
  timesteps_total: 2690000
  training_iteration: 538
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 4618 s, 538 iter, 2690000 ts, -94.3 rew

agent-1: -49.99999999946836
agent-2: -49.99999999946836
agent-3: -49.99999999946836
agent-4: -49.99999999946836
agent-5: 1.0
Extrinsic Rewards:
0
0
0
0
1
Sum Reward: 1
Avg Reward: 0.2
Min Reward: 0
Max Reward: 1
Gini Coefficient: 0.8
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-29-00
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -96.30778079166124
  episode_reward_min: -2035.6700113276845
  episodes_this_iter: 1
  episodes_total: 538
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.685
    dispatch_time_ms: 20.722
    learner:
      cur_lr: 0.0011808460112661123
      grad_gnorm: 14.501541137695312
      policy_entropy: 8.075482368469238
      policy_loss: 1.2519989013671875
      var_gnorm: 27.700685501098633
      vf_explained_var: 0.0
      vf_loss: 0.1651860773563385
    num_steps_sampled: 2695000
    num_steps_trained: 2695000
    wait_time_ms: 80.611
  iterations_since_restore: 539
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 4627.331290006638
  time_this_iter_s: 9.128217220306396
  time_total_s: 4627.331290006638
  timestamp: 1594862940
  timesteps_since_restore: 2695000
  timesteps_this_iter: 5000
  timesteps_total: 2695000
  training_iteration: 539
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 4627 s, 539 iter, 2695000 ts, -96.3 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-29-08
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -96.30778079166124
  episode_reward_min: -2035.6700113276845
  episodes_this_iter: 1
  episodes_total: 539
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.954
    dispatch_time_ms: 34.917
    learner:
      cur_lr: 0.0011805129470303655
      grad_gnorm: 13.346990585327148
      policy_entropy: 0.5232039093971252
      policy_loss: 0.25213348865509033
      var_gnorm: 27.699878692626953
      vf_explained_var: 5.960464477539063e-08
      vf_loss: 0.1318570077419281
    num_steps_sampled: 2700000
    num_steps_trained: 2700000
    wait_time_ms: 49.512
  iterations_since_restore: 540
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 4635.8886868953705
  time_this_iter_s: 8.55739688873291
  time_total_s: 4635.8886868953705
  timestamp: 1594862948
  timesteps_since_restore: 2700000
  timesteps_this_iter: 5000
  timesteps_total: 2700000
  training_iteration: 540
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 4635 s, 540 iter, 2700000 ts, -96.3 rew

agent-1: -199.99999999784504
agent-2: -199.99999999784504
agent-3: 4.0
agent-4: -199.99999999784504
agent-5: -199.99999999784504
Extrinsic Rewards:
0
0
4
0
0
Sum Reward: 4
Avg Reward: 0.8
Min Reward: 0
Max Reward: 4
Gini Coefficient: 0.8
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-29-17
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -104.26778079157509
  episode_reward_min: -2035.6700113276845
  episodes_this_iter: 1
  episodes_total: 540
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 3.117
    dispatch_time_ms: 22.074
    learner:
      cur_lr: 0.0011801799992099404
      grad_gnorm: 9.948511123657227
      policy_entropy: 0.47215935587882996
      policy_loss: 0.006667823996394873
      var_gnorm: 27.699556350708008
      vf_explained_var: 0.0
      vf_loss: 0.06516819447278976
    num_steps_sampled: 2705000
    num_steps_trained: 2705000
    wait_time_ms: 61.715
  iterations_since_restore: 541
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 4644.520980834961
  time_this_iter_s: 8.632293939590454
  time_total_s: 4644.520980834961
  timestamp: 1594862957
  timesteps_since_restore: 2705000
  timesteps_this_iter: 5000
  timesteps_total: 2705000
  training_iteration: 541
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 4644 s, 541 iter, 2705000 ts, -104 rew

agent-1: -199.99999999784504
agent-2: -99.03124999890878
agent-3: 2.96875
agent-4: -199.99999999784504
agent-5: -199.99999999784504
Extrinsic Rewards:
0
1
3
0
0
Sum Reward: 4
Avg Reward: 0.8
Min Reward: 0
Max Reward: 3
Gini Coefficient: 0.7
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-29-26
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -111.22840579149957
  episode_reward_min: -2035.6700113276845
  episodes_this_iter: 1
  episodes_total: 541
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 4.445
    dispatch_time_ms: 32.972
    learner:
      cur_lr: 0.0011798470513895154
      grad_gnorm: 0.09079638868570328
      policy_entropy: 0.7942157983779907
      policy_loss: 2.1339781596907414e-05
      var_gnorm: 27.69961929321289
      vf_explained_var: 0.0
      vf_loss: 4.524410996964434e-06
    num_steps_sampled: 2710000
    num_steps_trained: 2710000
    wait_time_ms: 47.915
  iterations_since_restore: 542
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 4653.229610443115
  time_this_iter_s: 8.708629608154297
  time_total_s: 4653.229610443115
  timestamp: 1594862966
  timesteps_since_restore: 2710000
  timesteps_this_iter: 5000
  timesteps_total: 2710000
  training_iteration: 542
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 4653 s, 542 iter, 2710000 ts, -111 rew

agent-1: -49.99999999946836
agent-2: -49.99999999946836
agent-3: -49.99999999946836
agent-4: 1.0
agent-5: -49.99999999946836
Extrinsic Rewards:
0
0
0
1
0
Sum Reward: 1
Avg Reward: 0.2
Min Reward: 0
Max Reward: 1
Gini Coefficient: 0.8
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-29-34
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -113.21840579147829
  episode_reward_min: -2035.6700113276845
  episodes_this_iter: 1
  episodes_total: 542
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.637
    dispatch_time_ms: 29.006
    learner:
      cur_lr: 0.0011795139871537685
      grad_gnorm: 5.752955913543701
      policy_entropy: 4.660993576049805
      policy_loss: 1.024112582206726
      var_gnorm: 27.70093536376953
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 0.0802268460392952
    num_steps_sampled: 2715000
    num_steps_trained: 2715000
    wait_time_ms: 50.457
  iterations_since_restore: 543
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 4661.9590973854065
  time_this_iter_s: 8.72948694229126
  time_total_s: 4661.9590973854065
  timestamp: 1594862974
  timesteps_since_restore: 2715000
  timesteps_this_iter: 5000
  timesteps_total: 2715000
  training_iteration: 543
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 4661 s, 543 iter, 2715000 ts, -113 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-29-43
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -113.21840579147829
  episode_reward_min: -2035.6700113276845
  episodes_this_iter: 1
  episodes_total: 543
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.608
    dispatch_time_ms: 23.595
    learner:
      cur_lr: 0.0011791810393333435
      grad_gnorm: 0.032919034361839294
      policy_entropy: 4.973086357116699
      policy_loss: -7.258667756104842e-05
      var_gnorm: 27.700044631958008
      vf_explained_var: 0.0
      vf_loss: 4.288707611266318e-09
    num_steps_sampled: 2720000
    num_steps_trained: 2720000
    wait_time_ms: 58.618
  iterations_since_restore: 544
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 4670.548414468765
  time_this_iter_s: 8.589317083358765
  time_total_s: 4670.548414468765
  timestamp: 1594862983
  timesteps_since_restore: 2720000
  timesteps_this_iter: 5000
  timesteps_total: 2720000
  training_iteration: 544
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 4670 s, 544 iter, 2720000 ts, -113 rew

agent-1: -299.9999999968351
agent-2: 0.7500000000136119
agent-3: 0.7500000000136119
agent-4: -0.5
agent-5: -299.9999999968351
Extrinsic Rewards:
0
2
2
2
0
Sum Reward: 6
Avg Reward: 1.2
Min Reward: 0
Max Reward: 2
Gini Coefficient: 0.4
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-29-52
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -119.20840579141473
  episode_reward_min: -2035.6700113276845
  episodes_this_iter: 1
  episodes_total: 544
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 4.104
    dispatch_time_ms: 24.798
    learner:
      cur_lr: 0.0011788479750975966
      grad_gnorm: 0.14800624549388885
      policy_entropy: 14.736128807067871
      policy_loss: 0.016188913956284523
      var_gnorm: 27.701520919799805
      vf_explained_var: 0.0
      vf_loss: 1.0163886145164724e-05
    num_steps_sampled: 2725000
    num_steps_trained: 2725000
    wait_time_ms: 58.399
  iterations_since_restore: 545
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 4679.280701637268
  time_this_iter_s: 8.732287168502808
  time_total_s: 4679.280701637268
  timestamp: 1594862992
  timesteps_since_restore: 2725000
  timesteps_this_iter: 5000
  timesteps_total: 2725000
  training_iteration: 545
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 4679 s, 545 iter, 2725000 ts, -119 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-30-10
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -119.20840579141475
  episode_reward_min: -2035.6700113276845
  episodes_this_iter: 1
  episodes_total: 545
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.534
    dispatch_time_ms: 30.961
    learner:
      cur_lr: 0.0011785150272771716
      grad_gnorm: 21.481054306030273
      policy_entropy: 0.001466250279918313
      policy_loss: 1.9512086510076188e-05
      var_gnorm: 27.733518600463867
      vf_explained_var: 1.1920928955078125e-07
      vf_loss: 0.3311505913734436
    num_steps_sampled: 2730000
    num_steps_trained: 2730000
    wait_time_ms: 36.521
  iterations_since_restore: 546
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 4697.228769302368
  time_this_iter_s: 17.948067665100098
  time_total_s: 4697.228769302368
  timestamp: 1594863010
  timesteps_since_restore: 2730000
  timesteps_this_iter: 5000
  timesteps_total: 2730000
  training_iteration: 546
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 4697 s, 546 iter, 2730000 ts, -119 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-30-18
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -119.20840579141478
  episode_reward_min: -2035.6700113276845
  episodes_this_iter: 1
  episodes_total: 546
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.621
    dispatch_time_ms: 36.834
    learner:
      cur_lr: 0.0011781819630414248
      grad_gnorm: 0.10225217044353485
      policy_entropy: 0.001327379373833537
      policy_loss: -4.501930561673362e-07
      var_gnorm: 27.733402252197266
      vf_explained_var: 0.0
      vf_loss: 0.00015225698007270694
    num_steps_sampled: 2735000
    num_steps_trained: 2735000
    wait_time_ms: 61.767
  iterations_since_restore: 547
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 4705.678292512894
  time_this_iter_s: 8.449523210525513
  time_total_s: 4705.678292512894
  timestamp: 1594863018
  timesteps_since_restore: 2735000
  timesteps_this_iter: 5000
  timesteps_total: 2735000
  training_iteration: 547
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 4705 s, 547 iter, 2735000 ts, -119 rew

agent-1: -199.99999999784504
agent-2: -199.99999999784504
agent-3: 4.0
agent-4: -199.99999999784504
agent-5: -199.99999999784504
Extrinsic Rewards:
0
0
4
0
0
Sum Reward: 4
Avg Reward: 0.8
Min Reward: 0
Max Reward: 4
Gini Coefficient: 0.8
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-30-27
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -127.16840579132861
  episode_reward_min: -2035.6700113276845
  episodes_this_iter: 1
  episodes_total: 547
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 3.989
    dispatch_time_ms: 46.213
    learner:
      cur_lr: 0.0011778490152209997
      grad_gnorm: 0.036966513842344284
      policy_entropy: 0.001327625708654523
      policy_loss: -1.6996729357288132e-08
      var_gnorm: 27.733388900756836
      vf_explained_var: 1.1920928955078125e-07
      vf_loss: 9.008871302285115e-07
    num_steps_sampled: 2740000
    num_steps_trained: 2740000
    wait_time_ms: 36.005
  iterations_since_restore: 548
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 4714.690507173538
  time_this_iter_s: 9.012214660644531
  time_total_s: 4714.690507173538
  timestamp: 1594863027
  timesteps_since_restore: 2740000
  timesteps_this_iter: 5000
  timesteps_total: 2740000
  training_iteration: 548
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 4714 s, 548 iter, 2740000 ts, -127 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-30-36
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -127.16840579132858
  episode_reward_min: -2035.6700113276845
  episodes_this_iter: 1
  episodes_total: 548
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 3.009
    dispatch_time_ms: 20.742
    learner:
      cur_lr: 0.0011775159509852529
      grad_gnorm: 0.12527531385421753
      policy_entropy: 0.001327816629782319
      policy_loss: 1.4585486951546045e-07
      var_gnorm: 27.733388900756836
      vf_explained_var: 1.7881393432617188e-07
      vf_loss: 1.0337719686503988e-05
    num_steps_sampled: 2745000
    num_steps_trained: 2745000
    wait_time_ms: 59.74
  iterations_since_restore: 549
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 4723.200869560242
  time_this_iter_s: 8.510362386703491
  time_total_s: 4723.200869560242
  timestamp: 1594863036
  timesteps_since_restore: 2745000
  timesteps_this_iter: 5000
  timesteps_total: 2745000
  training_iteration: 549
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 4723 s, 549 iter, 2745000 ts, -127 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-30-45
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -127.16840579132858
  episode_reward_min: -2035.6700113276845
  episodes_this_iter: 1
  episodes_total: 549
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.811
    dispatch_time_ms: 27.858
    learner:
      cur_lr: 0.0011771830031648278
      grad_gnorm: 0.04488663375377655
      policy_entropy: 0.0013279985869303346
      policy_loss: -2.9334968232319625e-08
      var_gnorm: 27.733394622802734
      vf_explained_var: 5.960464477539063e-08
      vf_loss: 1.3286399962453288e-06
    num_steps_sampled: 2750000
    num_steps_trained: 2750000
    wait_time_ms: 57.685
  iterations_since_restore: 550
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 4731.906210422516
  time_this_iter_s: 8.70534086227417
  time_total_s: 4731.906210422516
  timestamp: 1594863045
  timesteps_since_restore: 2750000
  timesteps_this_iter: 5000
  timesteps_total: 2750000
  training_iteration: 550
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 4731 s, 550 iter, 2750000 ts, -127 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-30-53
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -127.16840579132858
  episode_reward_min: -2035.6700113276845
  episodes_this_iter: 1
  episodes_total: 550
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.981
    dispatch_time_ms: 27.995
    learner:
      cur_lr: 0.0011768500553444028
      grad_gnorm: 0.11783348768949509
      policy_entropy: 0.001328045385889709
      policy_loss: 6.52445635296317e-08
      var_gnorm: 27.7333927154541
      vf_explained_var: 0.0
      vf_loss: 9.14453175937524e-06
    num_steps_sampled: 2755000
    num_steps_trained: 2755000
    wait_time_ms: 57.949
  iterations_since_restore: 551
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 4740.647212028503
  time_this_iter_s: 8.741001605987549
  time_total_s: 4740.647212028503
  timestamp: 1594863053
  timesteps_since_restore: 2755000
  timesteps_this_iter: 5000
  timesteps_total: 2755000
  training_iteration: 551
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 4740 s, 551 iter, 2755000 ts, -127 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-31-02
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -127.16840579132858
  episode_reward_min: -2035.6700113276845
  episodes_this_iter: 1
  episodes_total: 551
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.761
    dispatch_time_ms: 42.329
    learner:
      cur_lr: 0.001176516991108656
      grad_gnorm: 0.013623656705021858
      policy_entropy: 0.0013282723957672715
      policy_loss: 3.4469419318838845e-08
      var_gnorm: 27.733396530151367
      vf_explained_var: 0.0
      vf_loss: 3.3673495636321604e-07
    num_steps_sampled: 2760000
    num_steps_trained: 2760000
    wait_time_ms: 44.411
  iterations_since_restore: 552
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 4749.326066970825
  time_this_iter_s: 8.678854942321777
  time_total_s: 4749.326066970825
  timestamp: 1594863062
  timesteps_since_restore: 2760000
  timesteps_this_iter: 5000
  timesteps_total: 2760000
  training_iteration: 552
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 4749 s, 552 iter, 2760000 ts, -127 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-31-11
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -127.16840579132858
  episode_reward_min: -2035.6700113276845
  episodes_this_iter: 1
  episodes_total: 552
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 3.078
    dispatch_time_ms: 22.18
    learner:
      cur_lr: 0.001176184043288231
      grad_gnorm: 0.008762616664171219
      policy_entropy: 0.0013286805478855968
      policy_loss: 3.1514750808980807e-09
      var_gnorm: 27.733396530151367
      vf_explained_var: 5.960464477539063e-08
      vf_loss: 5.119491675031895e-08
    num_steps_sampled: 2765000
    num_steps_trained: 2765000
    wait_time_ms: 61.2
  iterations_since_restore: 553
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 4758.033651828766
  time_this_iter_s: 8.707584857940674
  time_total_s: 4758.033651828766
  timestamp: 1594863071
  timesteps_since_restore: 2765000
  timesteps_this_iter: 5000
  timesteps_total: 2765000
  training_iteration: 553
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 4758 s, 553 iter, 2765000 ts, -127 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-31-19
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -127.16840579132858
  episode_reward_min: -2035.6700113276845
  episodes_this_iter: 1
  episodes_total: 553
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 3.287
    dispatch_time_ms: 26.867
    learner:
      cur_lr: 0.001175850979052484
      grad_gnorm: 0.04342656582593918
      policy_entropy: 0.0013350928202271461
      policy_loss: 5.013568671330404e-09
      var_gnorm: 27.733394622802734
      vf_explained_var: 0.0
      vf_loss: 1.0024384664575337e-06
    num_steps_sampled: 2770000
    num_steps_trained: 2770000
    wait_time_ms: 58.184
  iterations_since_restore: 554
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 4766.645755529404
  time_this_iter_s: 8.612103700637817
  time_total_s: 4766.645755529404
  timestamp: 1594863079
  timesteps_since_restore: 2770000
  timesteps_this_iter: 5000
  timesteps_total: 2770000
  training_iteration: 554
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 4766 s, 554 iter, 2770000 ts, -127 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-31-28
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -127.16840579132858
  episode_reward_min: -2035.6700113276845
  episodes_this_iter: 1
  episodes_total: 554
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.701
    dispatch_time_ms: 9.101
    learner:
      cur_lr: 0.001175518031232059
      grad_gnorm: 0.032082363963127136
      policy_entropy: 0.001335618318989873
      policy_loss: -1.3977826007760541e-08
      var_gnorm: 27.733396530151367
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 6.782186687814828e-07
    num_steps_sampled: 2775000
    num_steps_trained: 2775000
    wait_time_ms: 68.926
  iterations_since_restore: 555
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 4774.881195068359
  time_this_iter_s: 8.235439538955688
  time_total_s: 4774.881195068359
  timestamp: 1594863088
  timesteps_since_restore: 2775000
  timesteps_this_iter: 5000
  timesteps_total: 2775000
  training_iteration: 555
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 4774 s, 555 iter, 2775000 ts, -127 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-31-36
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -127.16840579132858
  episode_reward_min: -2035.6700113276845
  episodes_this_iter: 1
  episodes_total: 555
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.633
    dispatch_time_ms: 9.886
    learner:
      cur_lr: 0.0011751849669963121
      grad_gnorm: 0.03500988334417343
      policy_entropy: 0.0013361715245991945
      policy_loss: -2.6270686959151135e-08
      var_gnorm: 27.7333984375
      vf_explained_var: 1.1920928955078125e-07
      vf_loss: 8.085987133199524e-07
    num_steps_sampled: 2780000
    num_steps_trained: 2780000
    wait_time_ms: 68.864
  iterations_since_restore: 556
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 4783.0457808971405
  time_this_iter_s: 8.164585828781128
  time_total_s: 4783.0457808971405
  timestamp: 1594863096
  timesteps_since_restore: 2780000
  timesteps_this_iter: 5000
  timesteps_total: 2780000
  training_iteration: 556
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 4783 s, 556 iter, 2780000 ts, -127 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-31-44
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -127.16840579132858
  episode_reward_min: -2035.6700113276845
  episodes_this_iter: 1
  episodes_total: 556
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.943
    dispatch_time_ms: 8.544
    learner:
      cur_lr: 0.001174852019175887
      grad_gnorm: 0.0017173250671476126
      policy_entropy: 0.0013367190258577466
      policy_loss: 4.120134633467387e-08
      var_gnorm: 27.733396530151367
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 2.018793132663177e-09
    num_steps_sampled: 2785000
    num_steps_trained: 2785000
    wait_time_ms: 70.483
  iterations_since_restore: 557
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 4791.134429693222
  time_this_iter_s: 8.088648796081543
  time_total_s: 4791.134429693222
  timestamp: 1594863104
  timesteps_since_restore: 2785000
  timesteps_this_iter: 5000
  timesteps_total: 2785000
  training_iteration: 557
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 4791 s, 557 iter, 2785000 ts, -127 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-31-52
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -127.16840579132858
  episode_reward_min: -2035.6700113276845
  episodes_this_iter: 1
  episodes_total: 557
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.968
    dispatch_time_ms: 8.023
    learner:
      cur_lr: 0.0011745189549401402
      grad_gnorm: 0.0013382710749283433
      policy_entropy: 0.0013372752582654357
      policy_loss: -1.7862008760971548e-08
      var_gnorm: 27.733400344848633
      vf_explained_var: 0.0
      vf_loss: 1.1605278960047372e-09
    num_steps_sampled: 2790000
    num_steps_trained: 2790000
    wait_time_ms: 72.759
  iterations_since_restore: 558
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 4799.256307125092
  time_this_iter_s: 8.121877431869507
  time_total_s: 4799.256307125092
  timestamp: 1594863112
  timesteps_since_restore: 2790000
  timesteps_this_iter: 5000
  timesteps_total: 2790000
  training_iteration: 558
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 4799 s, 558 iter, 2790000 ts, -127 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-32-00
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -127.16840579132858
  episode_reward_min: -2035.6700113276845
  episodes_this_iter: 1
  episodes_total: 558
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 3.03
    dispatch_time_ms: 8.048
    learner:
      cur_lr: 0.0011741860071197152
      grad_gnorm: 0.09213491529226303
      policy_entropy: 0.0013378444127738476
      policy_loss: 9.683245139058272e-08
      var_gnorm: 27.7334041595459
      vf_explained_var: 5.960464477539063e-08
      vf_loss: 5.58318470211816e-06
    num_steps_sampled: 2795000
    num_steps_trained: 2795000
    wait_time_ms: 71.499
  iterations_since_restore: 559
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 4807.413346290588
  time_this_iter_s: 8.157039165496826
  time_total_s: 4807.413346290588
  timestamp: 1594863120
  timesteps_since_restore: 2795000
  timesteps_this_iter: 5000
  timesteps_total: 2795000
  training_iteration: 559
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 4807 s, 559 iter, 2795000 ts, -127 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-32-09
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -127.16840579132858
  episode_reward_min: -2035.6700113276845
  episodes_this_iter: 1
  episodes_total: 559
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 3.048
    dispatch_time_ms: 8.453
    learner:
      cur_lr: 0.0011738529428839684
      grad_gnorm: 0.022709762677550316
      policy_entropy: 0.0013384300982579589
      policy_loss: -9.958792013264883e-09
      var_gnorm: 27.7334041595459
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 3.409033126899885e-07
    num_steps_sampled: 2800000
    num_steps_trained: 2800000
    wait_time_ms: 70.761
  iterations_since_restore: 560
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 4815.544780731201
  time_this_iter_s: 8.131434440612793
  time_total_s: 4815.544780731201
  timestamp: 1594863129
  timesteps_since_restore: 2800000
  timesteps_this_iter: 5000
  timesteps_total: 2800000
  training_iteration: 560
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 4815 s, 560 iter, 2800000 ts, -127 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-32-17
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -127.16840579132858
  episode_reward_min: -2035.6700113276845
  episodes_this_iter: 1
  episodes_total: 560
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.632
    dispatch_time_ms: 7.851
    learner:
      cur_lr: 0.0011735199950635433
      grad_gnorm: 0.14257457852363586
      policy_entropy: 0.0013390193926170468
      policy_loss: -1.1002148525562916e-08
      var_gnorm: 27.733409881591797
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 1.3393431800068356e-05
    num_steps_sampled: 2805000
    num_steps_trained: 2805000
    wait_time_ms: 72.03
  iterations_since_restore: 561
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 4823.665261268616
  time_this_iter_s: 8.12048053741455
  time_total_s: 4823.665261268616
  timestamp: 1594863137
  timesteps_since_restore: 2805000
  timesteps_this_iter: 5000
  timesteps_total: 2805000
  training_iteration: 561
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 4823 s, 561 iter, 2805000 ts, -127 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-32-25
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -127.16840579132858
  episode_reward_min: -2035.6700113276845
  episodes_this_iter: 1
  episodes_total: 561
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.514
    dispatch_time_ms: 8.045
    learner:
      cur_lr: 0.0011731870472431183
      grad_gnorm: 0.04177883267402649
      policy_entropy: 0.0013396436115726829
      policy_loss: 1.4334814224525871e-08
      var_gnorm: 27.73340606689453
      vf_explained_var: 0.0
      vf_loss: 1.1499570291562122e-06
    num_steps_sampled: 2810000
    num_steps_trained: 2810000
    wait_time_ms: 67.422
  iterations_since_restore: 562
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 4831.808466911316
  time_this_iter_s: 8.143205642700195
  time_total_s: 4831.808466911316
  timestamp: 1594863145
  timesteps_since_restore: 2810000
  timesteps_this_iter: 5000
  timesteps_total: 2810000
  training_iteration: 562
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 4831 s, 562 iter, 2810000 ts, -127 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-32-33
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -127.16840579132858
  episode_reward_min: -2035.6700113276845
  episodes_this_iter: 1
  episodes_total: 562
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.386
    dispatch_time_ms: 8.294
    learner:
      cur_lr: 0.0011728539830073714
      grad_gnorm: 0.1422284096479416
      policy_entropy: 0.0013402837794274092
      policy_loss: -6.196688673298922e-08
      var_gnorm: 27.733417510986328
      vf_explained_var: 0.0
      vf_loss: 1.3318345736479387e-05
    num_steps_sampled: 2815000
    num_steps_trained: 2815000
    wait_time_ms: 70.247
  iterations_since_restore: 563
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 4839.949743747711
  time_this_iter_s: 8.141276836395264
  time_total_s: 4839.949743747711
  timestamp: 1594863153
  timesteps_since_restore: 2815000
  timesteps_this_iter: 5000
  timesteps_total: 2815000
  training_iteration: 563
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 4839 s, 563 iter, 2815000 ts, -127 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-32-41
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -127.16840579132858
  episode_reward_min: -2035.6700113276845
  episodes_this_iter: 1
  episodes_total: 563
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.668
    dispatch_time_ms: 8.343
    learner:
      cur_lr: 0.0011725210351869464
      grad_gnorm: 0.06287233531475067
      policy_entropy: 0.001340947113931179
      policy_loss: 2.708789637040354e-08
      var_gnorm: 27.733413696289062
      vf_explained_var: 5.960464477539063e-08
      vf_loss: 2.6047296159958933e-06
    num_steps_sampled: 2820000
    num_steps_trained: 2820000
    wait_time_ms: 71.526
  iterations_since_restore: 564
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 4848.125862121582
  time_this_iter_s: 8.17611837387085
  time_total_s: 4848.125862121582
  timestamp: 1594863161
  timesteps_since_restore: 2820000
  timesteps_this_iter: 5000
  timesteps_total: 2820000
  training_iteration: 564
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 4848 s, 564 iter, 2820000 ts, -127 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-32-49
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -127.16840579132858
  episode_reward_min: -2035.6700113276845
  episodes_this_iter: 1
  episodes_total: 564
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.581
    dispatch_time_ms: 8.416
    learner:
      cur_lr: 0.0011721879709511995
      grad_gnorm: 0.2050439864397049
      policy_entropy: 0.0013415964785963297
      policy_loss: -4.6373646256370193e-08
      var_gnorm: 27.733423233032227
      vf_explained_var: 0.0
      vf_loss: 2.7681648134603165e-05
    num_steps_sampled: 2825000
    num_steps_trained: 2825000
    wait_time_ms: 69.697
  iterations_since_restore: 565
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 4856.193067550659
  time_this_iter_s: 8.067205429077148
  time_total_s: 4856.193067550659
  timestamp: 1594863169
  timesteps_since_restore: 2825000
  timesteps_this_iter: 5000
  timesteps_total: 2825000
  training_iteration: 565
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 4856 s, 565 iter, 2825000 ts, -127 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-32-58
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -127.16840579132858
  episode_reward_min: -2035.6700113276845
  episodes_this_iter: 1
  episodes_total: 565
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.82
    dispatch_time_ms: 6.94
    learner:
      cur_lr: 0.0011718550231307745
      grad_gnorm: 0.06239090859889984
      policy_entropy: 0.0013422954361885786
      policy_loss: 4.1691521346365334e-08
      var_gnorm: 27.733421325683594
      vf_explained_var: 5.960464477539063e-08
      vf_loss: 2.565896693340619e-06
    num_steps_sampled: 2830000
    num_steps_trained: 2830000
    wait_time_ms: 71.01
  iterations_since_restore: 566
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 4864.325297117233
  time_this_iter_s: 8.132229566574097
  time_total_s: 4864.325297117233
  timestamp: 1594863178
  timesteps_since_restore: 2830000
  timesteps_this_iter: 5000
  timesteps_total: 2830000
  training_iteration: 566
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 4864 s, 566 iter, 2830000 ts, -127 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-33-06
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -127.16840579132858
  episode_reward_min: -2035.6700113276845
  episodes_this_iter: 1
  episodes_total: 566
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.654
    dispatch_time_ms: 9.424
    learner:
      cur_lr: 0.0011715219588950276
      grad_gnorm: 0.2305428832769394
      policy_entropy: 0.0013430044054985046
      policy_loss: -6.686495801488945e-09
      var_gnorm: 27.73343276977539
      vf_explained_var: 0.0
      vf_loss: 3.4981898352270946e-05
    num_steps_sampled: 2835000
    num_steps_trained: 2835000
    wait_time_ms: 68.83
  iterations_since_restore: 567
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 4872.449598073959
  time_this_iter_s: 8.124300956726074
  time_total_s: 4872.449598073959
  timestamp: 1594863186
  timesteps_since_restore: 2835000
  timesteps_this_iter: 5000
  timesteps_total: 2835000
  training_iteration: 567
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 4872 s, 567 iter, 2835000 ts, -127 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-33-14
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -127.16840579132858
  episode_reward_min: -2035.6700113276845
  episodes_this_iter: 1
  episodes_total: 567
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.924
    dispatch_time_ms: 6.567
    learner:
      cur_lr: 0.0011711890110746026
      grad_gnorm: 0.03129178285598755
      policy_entropy: 0.001343721873126924
      policy_loss: 1.3633377982102957e-08
      var_gnorm: 27.73343276977539
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 6.443228812713642e-07
    num_steps_sampled: 2840000
    num_steps_trained: 2840000
    wait_time_ms: 73.432
  iterations_since_restore: 568
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 4880.613341093063
  time_this_iter_s: 8.163743019104004
  time_total_s: 4880.613341093063
  timestamp: 1594863194
  timesteps_since_restore: 2840000
  timesteps_this_iter: 5000
  timesteps_total: 2840000
  training_iteration: 568
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 4880 s, 568 iter, 2840000 ts, -127 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-33-22
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -127.16840579132858
  episode_reward_min: -2035.6700113276845
  episodes_this_iter: 1
  episodes_total: 568
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.521
    dispatch_time_ms: 11.662
    learner:
      cur_lr: 0.0011708559468388557
      grad_gnorm: 0.3008524775505066
      policy_entropy: 0.0013444788055494428
      policy_loss: -8.163731024524168e-08
      var_gnorm: 27.73344612121582
      vf_explained_var: 0.0
      vf_loss: 5.95963720115833e-05
    num_steps_sampled: 2845000
    num_steps_trained: 2845000
    wait_time_ms: 67.492
  iterations_since_restore: 569
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 4888.749224185944
  time_this_iter_s: 8.135883092880249
  time_total_s: 4888.749224185944
  timestamp: 1594863202
  timesteps_since_restore: 2845000
  timesteps_this_iter: 5000
  timesteps_total: 2845000
  training_iteration: 569
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 4888 s, 569 iter, 2845000 ts, -127 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-33-30
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -127.16840579132858
  episode_reward_min: -2035.6700113276845
  episodes_this_iter: 1
  episodes_total: 569
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.694
    dispatch_time_ms: 6.598
    learner:
      cur_lr: 0.0011705229990184307
      grad_gnorm: 0.006259330082684755
      policy_entropy: 0.0013452257262542844
      policy_loss: 5.328743668542302e-09
      var_gnorm: 27.733444213867188
      vf_explained_var: 0.0
      vf_loss: 2.5978849294006068e-08
    num_steps_sampled: 2850000
    num_steps_trained: 2850000
    wait_time_ms: 73.079
  iterations_since_restore: 570
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 4896.891798496246
  time_this_iter_s: 8.142574310302734
  time_total_s: 4896.891798496246
  timestamp: 1594863210
  timesteps_since_restore: 2850000
  timesteps_this_iter: 5000
  timesteps_total: 2850000
  training_iteration: 570
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 4896 s, 570 iter, 2850000 ts, -127 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-33-38
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -127.16840579132858
  episode_reward_min: -2035.6700113276845
  episodes_this_iter: 1
  episodes_total: 570
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 3.197
    dispatch_time_ms: 9.114
    learner:
      cur_lr: 0.0011701900511980057
      grad_gnorm: 0.24310342967510223
      policy_entropy: 0.0013459967449307442
      policy_loss: -3.279182259063873e-09
      var_gnorm: 27.733455657958984
      vf_explained_var: 0.0
      vf_loss: 3.8919260987313464e-05
    num_steps_sampled: 2855000
    num_steps_trained: 2855000
    wait_time_ms: 71.629
  iterations_since_restore: 571
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 4904.9501576423645
  time_this_iter_s: 8.058359146118164
  time_total_s: 4904.9501576423645
  timestamp: 1594863218
  timesteps_since_restore: 2855000
  timesteps_this_iter: 5000
  timesteps_total: 2855000
  training_iteration: 571
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 4904 s, 571 iter, 2855000 ts, -127 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-33-47
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -127.16840579132858
  episode_reward_min: -2035.6700113276845
  episodes_this_iter: 1
  episodes_total: 571
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 3.045
    dispatch_time_ms: 7.189
    learner:
      cur_lr: 0.0011698569869622588
      grad_gnorm: 0.04975303262472153
      policy_entropy: 0.0013469167752191424
      policy_loss: -2.1676681782878404e-08
      var_gnorm: 27.733457565307617
      vf_explained_var: 0.0
      vf_loss: 1.6314038475684356e-06
    num_steps_sampled: 2860000
    num_steps_trained: 2860000
    wait_time_ms: 71.885
  iterations_since_restore: 572
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 4913.183743476868
  time_this_iter_s: 8.233585834503174
  time_total_s: 4913.183743476868
  timestamp: 1594863227
  timesteps_since_restore: 2860000
  timesteps_this_iter: 5000
  timesteps_total: 2860000
  training_iteration: 572
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 4913 s, 572 iter, 2860000 ts, -127 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-33-55
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -127.16840579132858
  episode_reward_min: -2035.6700113276845
  episodes_this_iter: 1
  episodes_total: 572
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 3.164
    dispatch_time_ms: 9.487
    learner:
      cur_lr: 0.0011695240391418338
      grad_gnorm: 0.2896946966648102
      policy_entropy: 0.0013477642787620425
      policy_loss: -1.2621578093785502e-07
      var_gnorm: 27.733470916748047
      vf_explained_var: -2.384185791015625e-07
      vf_loss: 5.52617602807004e-05
    num_steps_sampled: 2865000
    num_steps_trained: 2865000
    wait_time_ms: 67.961
  iterations_since_restore: 573
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 4921.333767175674
  time_this_iter_s: 8.150023698806763
  time_total_s: 4921.333767175674
  timestamp: 1594863235
  timesteps_since_restore: 2865000
  timesteps_this_iter: 5000
  timesteps_total: 2865000
  training_iteration: 573
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 4921 s, 573 iter, 2865000 ts, -127 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-34-03
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -127.16840579132858
  episode_reward_min: -2035.6700113276845
  episodes_this_iter: 1
  episodes_total: 573
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 3.095
    dispatch_time_ms: 7.643
    learner:
      cur_lr: 0.001169190974906087
      grad_gnorm: 0.07542214542627335
      policy_entropy: 0.0013488223776221275
      policy_loss: -4.221506344492809e-08
      var_gnorm: 27.733474731445312
      vf_explained_var: 0.0
      vf_loss: 3.750086762011051e-06
    num_steps_sampled: 2870000
    num_steps_trained: 2870000
    wait_time_ms: 70.449
  iterations_since_restore: 574
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 4929.433952093124
  time_this_iter_s: 8.100184917449951
  time_total_s: 4929.433952093124
  timestamp: 1594863243
  timesteps_since_restore: 2870000
  timesteps_this_iter: 5000
  timesteps_total: 2870000
  training_iteration: 574
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 4929 s, 574 iter, 2870000 ts, -127 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-34-11
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -127.16840579132858
  episode_reward_min: -2035.6700113276845
  episodes_this_iter: 1
  episodes_total: 574
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.961
    dispatch_time_ms: 10.04
    learner:
      cur_lr: 0.0011688580270856619
      grad_gnorm: 0.43069708347320557
      policy_entropy: 0.0013499479973688722
      policy_loss: -1.8764862375064695e-07
      var_gnorm: 27.733489990234375
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 0.00012214234448038042
    num_steps_sampled: 2875000
    num_steps_trained: 2875000
    wait_time_ms: 69.114
  iterations_since_restore: 575
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 4937.931855916977
  time_this_iter_s: 8.497903823852539
  time_total_s: 4937.931855916977
  timestamp: 1594863251
  timesteps_since_restore: 2875000
  timesteps_this_iter: 5000
  timesteps_total: 2875000
  training_iteration: 575
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 4937 s, 575 iter, 2875000 ts, -127 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-34-20
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -127.16840579132858
  episode_reward_min: -2035.6700113276845
  episodes_this_iter: 1
  episodes_total: 575
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.747
    dispatch_time_ms: 7.259
    learner:
      cur_lr: 0.001168524962849915
      grad_gnorm: 0.07766134291887283
      policy_entropy: 0.001351110520772636
      policy_loss: -4.103117134945933e-08
      var_gnorm: 27.733488082885742
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 3.971493697463302e-06
    num_steps_sampled: 2880000
    num_steps_trained: 2880000
    wait_time_ms: 72.222
  iterations_since_restore: 576
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 4946.03690123558
  time_this_iter_s: 8.105045318603516
  time_total_s: 4946.03690123558
  timestamp: 1594863260
  timesteps_since_restore: 2880000
  timesteps_this_iter: 5000
  timesteps_total: 2880000
  training_iteration: 576
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 4946 s, 576 iter, 2880000 ts, -127 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-34-28
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -127.16840579132858
  episode_reward_min: -2035.6700113276845
  episodes_this_iter: 1
  episodes_total: 576
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.748
    dispatch_time_ms: 6.802
    learner:
      cur_lr: 0.00116819201502949
      grad_gnorm: 0.5067928433418274
      policy_entropy: 0.0013523864326998591
      policy_loss: -2.208023488492472e-07
      var_gnorm: 27.733510971069336
      vf_explained_var: 0.0
      vf_loss: 0.0001691095094429329
    num_steps_sampled: 2885000
    num_steps_trained: 2885000
    wait_time_ms: 71.611
  iterations_since_restore: 577
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 4954.095319509506
  time_this_iter_s: 8.058418273925781
  time_total_s: 4954.095319509506
  timestamp: 1594863268
  timesteps_since_restore: 2885000
  timesteps_this_iter: 5000
  timesteps_total: 2885000
  training_iteration: 577
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 4954 s, 577 iter, 2885000 ts, -127 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-34-36
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -127.16840579132858
  episode_reward_min: -2035.6700113276845
  episodes_this_iter: 1
  episodes_total: 577
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.843
    dispatch_time_ms: 8.838
    learner:
      cur_lr: 0.0011678589507937431
      grad_gnorm: 0.018798846751451492
      policy_entropy: 0.0013536668848246336
      policy_loss: -2.641977481232516e-08
      var_gnorm: 27.733509063720703
      vf_explained_var: 0.0
      vf_loss: 2.3270530391528155e-07
    num_steps_sampled: 2890000
    num_steps_trained: 2890000
    wait_time_ms: 70.147
  iterations_since_restore: 578
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 4962.178335428238
  time_this_iter_s: 8.08301591873169
  time_total_s: 4962.178335428238
  timestamp: 1594863276
  timesteps_since_restore: 2890000
  timesteps_this_iter: 5000
  timesteps_total: 2890000
  training_iteration: 578
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 4962 s, 578 iter, 2890000 ts, -127 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-34-44
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -127.16840579132858
  episode_reward_min: -2035.6700113276845
  episodes_this_iter: 1
  episodes_total: 578
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.839
    dispatch_time_ms: 8.309
    learner:
      cur_lr: 0.001167526002973318
      grad_gnorm: 0.5731263160705566
      policy_entropy: 0.0013550316216424108
      policy_loss: -1.3742454996190645e-07
      var_gnorm: 27.733537673950195
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 0.00021628601825796068
    num_steps_sampled: 2895000
    num_steps_trained: 2895000
    wait_time_ms: 70.254
  iterations_since_restore: 579
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 4970.284205675125
  time_this_iter_s: 8.105870246887207
  time_total_s: 4970.284205675125
  timestamp: 1594863284
  timesteps_since_restore: 2895000
  timesteps_this_iter: 5000
  timesteps_total: 2895000
  training_iteration: 579
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 4970 s, 579 iter, 2895000 ts, -127 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-34-52
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -127.16840579132858
  episode_reward_min: -2035.6700113276845
  episodes_this_iter: 1
  episodes_total: 579
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.481
    dispatch_time_ms: 9.047
    learner:
      cur_lr: 0.001167193055152893
      grad_gnorm: 0.006704309489578009
      policy_entropy: 0.0013563837856054306
      policy_loss: 2.9209681340347515e-09
      var_gnorm: 27.733537673950195
      vf_explained_var: 0.0
      vf_loss: 2.969324164325826e-08
    num_steps_sampled: 2900000
    num_steps_trained: 2900000
    wait_time_ms: 68.969
  iterations_since_restore: 580
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 4978.44891500473
  time_this_iter_s: 8.164709329605103
  time_total_s: 4978.44891500473
  timestamp: 1594863292
  timesteps_since_restore: 2900000
  timesteps_this_iter: 5000
  timesteps_total: 2900000
  training_iteration: 580
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 4978 s, 580 iter, 2900000 ts, -127 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-35-00
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -127.16840579132858
  episode_reward_min: -2035.6700113276845
  episodes_this_iter: 1
  episodes_total: 580
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 3.015
    dispatch_time_ms: 7.596
    learner:
      cur_lr: 0.0011668599909171462
      grad_gnorm: 0.6668488383293152
      policy_entropy: 0.0013577990466728806
      policy_loss: -2.905365477090527e-07
      var_gnorm: 27.73356819152832
      vf_explained_var: 0.0
      vf_loss: 0.00029281870229169726
    num_steps_sampled: 2905000
    num_steps_trained: 2905000
    wait_time_ms: 70.677
  iterations_since_restore: 581
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 4986.654433727264
  time_this_iter_s: 8.20551872253418
  time_total_s: 4986.654433727264
  timestamp: 1594863300
  timesteps_since_restore: 2905000
  timesteps_this_iter: 5000
  timesteps_total: 2905000
  training_iteration: 581
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 4986 s, 581 iter, 2905000 ts, -127 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-35-09
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -127.16840579132858
  episode_reward_min: -2035.6700113276845
  episodes_this_iter: 1
  episodes_total: 581
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.518
    dispatch_time_ms: 6.484
    learner:
      cur_lr: 0.0011665270430967212
      grad_gnorm: 0.1309375911951065
      policy_entropy: 0.0013593572657555342
      policy_loss: 3.317084917853208e-08
      var_gnorm: 27.73356819152832
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 1.1293181159999222e-05
    num_steps_sampled: 2910000
    num_steps_trained: 2910000
    wait_time_ms: 72.23
  iterations_since_restore: 582
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 4994.756148099899
  time_this_iter_s: 8.101714372634888
  time_total_s: 4994.756148099899
  timestamp: 1594863309
  timesteps_since_restore: 2910000
  timesteps_this_iter: 5000
  timesteps_total: 2910000
  training_iteration: 582
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 4994 s, 582 iter, 2910000 ts, -127 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-35-17
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -127.16840579132858
  episode_reward_min: -2035.6700113276845
  episodes_this_iter: 1
  episodes_total: 582
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.58
    dispatch_time_ms: 7.547
    learner:
      cur_lr: 0.0011661939788609743
      grad_gnorm: 0.7732756733894348
      policy_entropy: 0.0013608200242742896
      policy_loss: -3.369049750290287e-07
      var_gnorm: 27.73360824584961
      vf_explained_var: 0.0
      vf_loss: 0.00039373169420287013
    num_steps_sampled: 2915000
    num_steps_trained: 2915000
    wait_time_ms: 71.117
  iterations_since_restore: 583
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 5002.843695402145
  time_this_iter_s: 8.087547302246094
  time_total_s: 5002.843695402145
  timestamp: 1594863317
  timesteps_since_restore: 2915000
  timesteps_this_iter: 5000
  timesteps_total: 2915000
  training_iteration: 583
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 5002 s, 583 iter, 2915000 ts, -127 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-35-25
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -127.16840579132858
  episode_reward_min: -2035.6700113276845
  episodes_this_iter: 1
  episodes_total: 583
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.586
    dispatch_time_ms: 5.444
    learner:
      cur_lr: 0.0011658610310405493
      grad_gnorm: 0.17669324576854706
      policy_entropy: 0.0013626022264361382
      policy_loss: 7.69827224189612e-08
      var_gnorm: 27.733610153198242
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 2.0560657503665425e-05
    num_steps_sampled: 2920000
    num_steps_trained: 2920000
    wait_time_ms: 76.156
  iterations_since_restore: 584
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 5011.063359975815
  time_this_iter_s: 8.219664573669434
  time_total_s: 5011.063359975815
  timestamp: 1594863325
  timesteps_since_restore: 2920000
  timesteps_this_iter: 5000
  timesteps_total: 2920000
  training_iteration: 584
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 5011 s, 584 iter, 2920000 ts, -127 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-35-33
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -127.16840579132858
  episode_reward_min: -2035.6700113276845
  episodes_this_iter: 1
  episodes_total: 584
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 3.4
    dispatch_time_ms: 7.563
    learner:
      cur_lr: 0.0011655279668048024
      grad_gnorm: 0.7720081210136414
      policy_entropy: 0.0013643386773765087
      policy_loss: -3.363528549016337e-07
      var_gnorm: 27.733654022216797
      vf_explained_var: 0.0
      vf_loss: 0.0003924529592040926
    num_steps_sampled: 2925000
    num_steps_trained: 2925000
    wait_time_ms: 69.941
  iterations_since_restore: 585
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 5019.124801397324
  time_this_iter_s: 8.061441421508789
  time_total_s: 5019.124801397324
  timestamp: 1594863333
  timesteps_since_restore: 2925000
  timesteps_this_iter: 5000
  timesteps_total: 2925000
  training_iteration: 585
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 5019 s, 585 iter, 2925000 ts, -127 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-35-41
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -127.16840579132858
  episode_reward_min: -2035.6700113276845
  episodes_this_iter: 1
  episodes_total: 585
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.804
    dispatch_time_ms: 7.72
    learner:
      cur_lr: 0.0011651950189843774
      grad_gnorm: 0.12696394324302673
      policy_entropy: 0.0013662457931786776
      policy_loss: 5.5316387914672305e-08
      var_gnorm: 27.733657836914062
      vf_explained_var: 0.0
      vf_loss: 1.0611007382976823e-05
    num_steps_sampled: 2930000
    num_steps_trained: 2930000
    wait_time_ms: 70.734
  iterations_since_restore: 586
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 5027.328812122345
  time_this_iter_s: 8.204010725021362
  time_total_s: 5027.328812122345
  timestamp: 1594863341
  timesteps_since_restore: 2930000
  timesteps_this_iter: 5000
  timesteps_total: 2930000
  training_iteration: 586
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 5027 s, 586 iter, 2930000 ts, -127 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-35-49
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -127.16840579132858
  episode_reward_min: -2035.6700113276845
  episodes_this_iter: 1
  episodes_total: 586
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 3.303
    dispatch_time_ms: 10.672
    learner:
      cur_lr: 0.0011648619547486305
      grad_gnorm: 0.858403742313385
      policy_entropy: 0.0013681951677426696
      policy_loss: -4.1975297904173203e-07
      var_gnorm: 27.73370933532715
      vf_explained_var: 0.0
      vf_loss: 0.00048523108125664294
    num_steps_sampled: 2935000
    num_steps_trained: 2935000
    wait_time_ms: 67.676
  iterations_since_restore: 587
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 5035.46235370636
  time_this_iter_s: 8.133541584014893
  time_total_s: 5035.46235370636
  timestamp: 1594863349
  timesteps_since_restore: 2935000
  timesteps_this_iter: 5000
  timesteps_total: 2935000
  training_iteration: 587
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 5035 s, 587 iter, 2935000 ts, -127 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-35-58
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -127.16840579132858
  episode_reward_min: -2035.6700113276845
  episodes_this_iter: 1
  episodes_total: 587
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.569
    dispatch_time_ms: 7.093
    learner:
      cur_lr: 0.0011645290069282055
      grad_gnorm: 0.07234508544206619
      policy_entropy: 0.0013704096199944615
      policy_loss: 3.151971483816851e-08
      var_gnorm: 27.733722686767578
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 3.4443064578226767e-06
    num_steps_sampled: 2940000
    num_steps_trained: 2940000
    wait_time_ms: 73.122
  iterations_since_restore: 588
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 5043.588618993759
  time_this_iter_s: 8.126265287399292
  time_total_s: 5043.588618993759
  timestamp: 1594863358
  timesteps_since_restore: 2940000
  timesteps_this_iter: 5000
  timesteps_total: 2940000
  training_iteration: 588
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 5043 s, 588 iter, 2940000 ts, -127 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-36-06
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -127.16840579132858
  episode_reward_min: -2035.6700113276845
  episodes_this_iter: 1
  episodes_total: 588
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 3.036
    dispatch_time_ms: 8.564
    learner:
      cur_lr: 0.0011641959426924586
      grad_gnorm: 1.0439670085906982
      policy_entropy: 0.0013724662130698562
      policy_loss: -4.64248387288535e-07
      var_gnorm: 27.733779907226562
      vf_explained_var: 0.0
      vf_loss: 0.0007176276994869113
    num_steps_sampled: 2945000
    num_steps_trained: 2945000
    wait_time_ms: 70.082
  iterations_since_restore: 589
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 5051.704172372818
  time_this_iter_s: 8.115553379058838
  time_total_s: 5051.704172372818
  timestamp: 1594863366
  timesteps_since_restore: 2945000
  timesteps_this_iter: 5000
  timesteps_total: 2945000
  training_iteration: 589
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 5051 s, 589 iter, 2945000 ts, -127 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-36-14
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -127.16840579132858
  episode_reward_min: -2035.6700113276845
  episodes_this_iter: 1
  episodes_total: 589
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 3.058
    dispatch_time_ms: 6.873
    learner:
      cur_lr: 0.0011638629948720336
      grad_gnorm: 0.44570672512054443
      policy_entropy: 0.001374808489345014
      policy_loss: -5.306923256398477e-08
      var_gnorm: 27.73381233215332
      vf_explained_var: 0.0
      vf_loss: 0.0001308611681452021
    num_steps_sampled: 2950000
    num_steps_trained: 2950000
    wait_time_ms: 71.106
  iterations_since_restore: 590
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 5059.877176523209
  time_this_iter_s: 8.173004150390625
  time_total_s: 5059.877176523209
  timestamp: 1594863374
  timesteps_since_restore: 2950000
  timesteps_this_iter: 5000
  timesteps_total: 2950000
  training_iteration: 590
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 5059 s, 590 iter, 2950000 ts, -127 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-36-22
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -127.16840579132858
  episode_reward_min: -2035.6700113276845
  episodes_this_iter: 1
  episodes_total: 590
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.698
    dispatch_time_ms: 7.213
    learner:
      cur_lr: 0.0011635300470516086
      grad_gnorm: 0.9659262299537659
      policy_entropy: 0.0013771498342975974
      policy_loss: -5.301284318193211e-07
      var_gnorm: 27.733863830566406
      vf_explained_var: 0.0
      vf_loss: 0.0006144693470560014
    num_steps_sampled: 2955000
    num_steps_trained: 2955000
    wait_time_ms: 73.688
  iterations_since_restore: 591
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 5068.005352020264
  time_this_iter_s: 8.128175497055054
  time_total_s: 5068.005352020264
  timestamp: 1594863382
  timesteps_since_restore: 2955000
  timesteps_this_iter: 5000
  timesteps_total: 2955000
  training_iteration: 591
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 5068 s, 591 iter, 2955000 ts, -127 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-36-30
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -127.16840579132858
  episode_reward_min: -2035.6700113276845
  episodes_this_iter: 1
  episodes_total: 591
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.702
    dispatch_time_ms: 7.01
    learner:
      cur_lr: 0.0011631969828158617
      grad_gnorm: 0.09363245964050293
      policy_entropy: 0.0013797926949337125
      policy_loss: 4.0794326139348414e-08
      var_gnorm: 27.733884811401367
      vf_explained_var: 0.0
      vf_loss: 5.7796241890173405e-06
    num_steps_sampled: 2960000
    num_steps_trained: 2960000
    wait_time_ms: 72.578
  iterations_since_restore: 592
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 5076.105832576752
  time_this_iter_s: 8.100480556488037
  time_total_s: 5076.105832576752
  timestamp: 1594863390
  timesteps_since_restore: 2960000
  timesteps_this_iter: 5000
  timesteps_total: 2960000
  training_iteration: 592
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 5076 s, 592 iter, 2960000 ts, -127 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-36-38
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -127.16840579132858
  episode_reward_min: -2035.6700113276845
  episodes_this_iter: 1
  episodes_total: 592
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.411
    dispatch_time_ms: 7.981
    learner:
      cur_lr: 0.0011628640349954367
      grad_gnorm: 1.0178115367889404
      policy_entropy: 0.0013823836343362927
      policy_loss: -6.71698785481567e-07
      var_gnorm: 27.733957290649414
      vf_explained_var: 0.0
      vf_loss: 0.0006821482093073428
    num_steps_sampled: 2965000
    num_steps_trained: 2965000
    wait_time_ms: 71.126
  iterations_since_restore: 593
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 5084.132671117783
  time_this_iter_s: 8.026838541030884
  time_total_s: 5084.132671117783
  timestamp: 1594863398
  timesteps_since_restore: 2965000
  timesteps_this_iter: 5000
  timesteps_total: 2965000
  training_iteration: 593
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 5084 s, 593 iter, 2965000 ts, -127 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-36-47
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -127.16840579132858
  episode_reward_min: -2035.6700113276845
  episodes_this_iter: 1
  episodes_total: 593
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.566
    dispatch_time_ms: 7.942
    learner:
      cur_lr: 0.0011625309707596898
      grad_gnorm: 0.812679648399353
      policy_entropy: 0.0013854361604899168
      policy_loss: -4.942484679304471e-07
      var_gnorm: 27.7340145111084
      vf_explained_var: 1.1920928955078125e-07
      vf_loss: 0.00043488162918947637
    num_steps_sampled: 2970000
    num_steps_trained: 2970000
    wait_time_ms: 72.152
  iterations_since_restore: 594
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 5092.2841556072235
  time_this_iter_s: 8.151484489440918
  time_total_s: 5092.2841556072235
  timestamp: 1594863407
  timesteps_since_restore: 2970000
  timesteps_this_iter: 5000
  timesteps_total: 2970000
  training_iteration: 594
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 5092 s, 594 iter, 2970000 ts, -127 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-36-55
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -127.16840579132858
  episode_reward_min: -2035.6700113276845
  episodes_this_iter: 1
  episodes_total: 594
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.983
    dispatch_time_ms: 6.631
    learner:
      cur_lr: 0.0011621980229392648
      grad_gnorm: 1.5720643997192383
      policy_entropy: 0.001388464355841279
      policy_loss: -8.211447948269779e-07
      var_gnorm: 27.734102249145508
      vf_explained_var: 0.0
      vf_loss: 0.0016273404471576214
    num_steps_sampled: 2975000
    num_steps_trained: 2975000
    wait_time_ms: 71.186
  iterations_since_restore: 595
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 5100.460156679153
  time_this_iter_s: 8.176001071929932
  time_total_s: 5100.460156679153
  timestamp: 1594863415
  timesteps_since_restore: 2975000
  timesteps_this_iter: 5000
  timesteps_total: 2975000
  training_iteration: 595
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 5100 s, 595 iter, 2975000 ts, -127 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-37-03
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -127.16840579132858
  episode_reward_min: -2035.6700113276845
  episodes_this_iter: 1
  episodes_total: 595
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.586
    dispatch_time_ms: 7.927
    learner:
      cur_lr: 0.001161864958703518
      grad_gnorm: 0.4631202518939972
      policy_entropy: 0.00139182573184371
      policy_loss: -2.017748386151652e-07
      var_gnorm: 27.73416519165039
      vf_explained_var: 0.0
      vf_loss: 0.00014121820277068764
    num_steps_sampled: 2980000
    num_steps_trained: 2980000
    wait_time_ms: 72.396
  iterations_since_restore: 596
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 5108.558012485504
  time_this_iter_s: 8.097855806350708
  time_total_s: 5108.558012485504
  timestamp: 1594863423
  timesteps_since_restore: 2980000
  timesteps_this_iter: 5000
  timesteps_total: 2980000
  training_iteration: 596
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 5108 s, 596 iter, 2980000 ts, -127 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-37-11
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -127.16840579132858
  episode_reward_min: -2035.6700113276845
  episodes_this_iter: 1
  episodes_total: 596
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.894
    dispatch_time_ms: 9.522
    learner:
      cur_lr: 0.0011615320108830929
      grad_gnorm: 1.2053550481796265
      policy_entropy: 0.0013951810542494059
      policy_loss: -1.6933472579694353e-07
      var_gnorm: 27.73426055908203
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 0.0009566960507072508
    num_steps_sampled: 2985000
    num_steps_trained: 2985000
    wait_time_ms: 71.132
  iterations_since_restore: 597
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 5116.719437360764
  time_this_iter_s: 8.1614248752594
  time_total_s: 5116.719437360764
  timestamp: 1594863431
  timesteps_since_restore: 2985000
  timesteps_this_iter: 5000
  timesteps_total: 2985000
  training_iteration: 597
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 5116 s, 597 iter, 2985000 ts, -127 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-37-19
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -127.16840579132858
  episode_reward_min: -2035.6700113276845
  episodes_this_iter: 1
  episodes_total: 597
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.812
    dispatch_time_ms: 8.973
    learner:
      cur_lr: 0.001161198946647346
      grad_gnorm: 0.030992088839411736
      policy_entropy: 0.0013986836420372128
      policy_loss: -1.3502806872622841e-08
      var_gnorm: 27.73432159423828
      vf_explained_var: 0.0
      vf_loss: 6.315952418844972e-07
    num_steps_sampled: 2990000
    num_steps_trained: 2990000
    wait_time_ms: 70.375
  iterations_since_restore: 598
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 5124.789131402969
  time_this_iter_s: 8.06969404220581
  time_total_s: 5124.789131402969
  timestamp: 1594863439
  timesteps_since_restore: 2990000
  timesteps_this_iter: 5000
  timesteps_total: 2990000
  training_iteration: 598
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 5124 s, 598 iter, 2990000 ts, -127 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-37-27
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -127.16840579132858
  episode_reward_min: -2035.6700113276845
  episodes_this_iter: 1
  episodes_total: 598
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 3.138
    dispatch_time_ms: 7.841
    learner:
      cur_lr: 0.001160865998826921
      grad_gnorm: 0.9552007913589478
      policy_entropy: 0.0014023714466020465
      policy_loss: -1.6662070834172482e-07
      var_gnorm: 27.73443031311035
      vf_explained_var: 0.0
      vf_loss: 0.0006008183700032532
    num_steps_sampled: 2995000
    num_steps_trained: 2995000
    wait_time_ms: 69.751
  iterations_since_restore: 599
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 5132.945816993713
  time_this_iter_s: 8.156685590744019
  time_total_s: 5132.945816993713
  timestamp: 1594863447
  timesteps_since_restore: 2995000
  timesteps_this_iter: 5000
  timesteps_total: 2995000
  training_iteration: 599
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 5132 s, 599 iter, 2995000 ts, -127 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-37-35
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -127.16840579132858
  episode_reward_min: -2035.6700113276845
  episodes_this_iter: 1
  episodes_total: 599
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.728
    dispatch_time_ms: 5.578
    learner:
      cur_lr: 0.001160533051006496
      grad_gnorm: 0.07889210432767868
      policy_entropy: 0.0014062069822102785
      policy_loss: -6.855555767515398e-08
      var_gnorm: 27.734508514404297
      vf_explained_var: 0.0
      vf_loss: 4.0916229409049265e-06
    num_steps_sampled: 3000000
    num_steps_trained: 3000000
    wait_time_ms: 69.649
  iterations_since_restore: 600
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 5141.0666444301605
  time_this_iter_s: 8.120827436447144
  time_total_s: 5141.0666444301605
  timestamp: 1594863455
  timesteps_since_restore: 3000000
  timesteps_this_iter: 5000
  timesteps_total: 3000000
  training_iteration: 600
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 5141 s, 600 iter, 3000000 ts, -127 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-37-44
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -127.16840579132858
  episode_reward_min: -2035.6700113276845
  episodes_this_iter: 1
  episodes_total: 600
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.498
    dispatch_time_ms: 6.795
    learner:
      cur_lr: 0.001160199986770749
      grad_gnorm: 1.040094017982483
      policy_entropy: 0.0014160642167553306
      policy_loss: 5.875938313693041e-08
      var_gnorm: 27.73463249206543
      vf_explained_var: 0.0
      vf_loss: 0.0007123130490072072
    num_steps_sampled: 3005000
    num_steps_trained: 3005000
    wait_time_ms: 71.147
  iterations_since_restore: 601
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 5149.153588056564
  time_this_iter_s: 8.086943626403809
  time_total_s: 5149.153588056564
  timestamp: 1594863464
  timesteps_since_restore: 3005000
  timesteps_this_iter: 5000
  timesteps_total: 3005000
  training_iteration: 601
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 5149 s, 601 iter, 3005000 ts, -127 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-37-52
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -127.16840579132858
  episode_reward_min: -2035.6700113276845
  episodes_this_iter: 1
  episodes_total: 601
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.999
    dispatch_time_ms: 5.943
    learner:
      cur_lr: 0.001159867038950324
      grad_gnorm: 0.1012347936630249
      policy_entropy: 0.0014204878825694323
      policy_loss: -1.7872878288471838e-07
      var_gnorm: 27.734743118286133
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 6.741231572959805e-06
    num_steps_sampled: 3010000
    num_steps_trained: 3010000
    wait_time_ms: 73.357
  iterations_since_restore: 602
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 5157.295987129211
  time_this_iter_s: 8.142399072647095
  time_total_s: 5157.295987129211
  timestamp: 1594863472
  timesteps_since_restore: 3010000
  timesteps_this_iter: 5000
  timesteps_total: 3010000
  training_iteration: 602
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 5157 s, 602 iter, 3010000 ts, -127 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-38-00
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -127.16840579132858
  episode_reward_min: -2035.6700113276845
  episodes_this_iter: 1
  episodes_total: 602
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 3.081
    dispatch_time_ms: 7.302
    learner:
      cur_lr: 0.0011595339747145772
      grad_gnorm: 1.0835174322128296
      policy_entropy: 0.0014244935009628534
      policy_loss: 1.3417902664514259e-06
      var_gnorm: 27.73487091064453
      vf_explained_var: 0.0
      vf_loss: 0.0007730805082246661
    num_steps_sampled: 3015000
    num_steps_trained: 3015000
    wait_time_ms: 71.731
  iterations_since_restore: 603
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 5165.782943248749
  time_this_iter_s: 8.486956119537354
  time_total_s: 5165.782943248749
  timestamp: 1594863480
  timesteps_since_restore: 3015000
  timesteps_this_iter: 5000
  timesteps_total: 3015000
  training_iteration: 603
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 5165 s, 603 iter, 3015000 ts, -127 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-38-09
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -127.16840579132858
  episode_reward_min: -2035.6700113276845
  episodes_this_iter: 1
  episodes_total: 603
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.44
    dispatch_time_ms: 7.717
    learner:
      cur_lr: 0.0011592010268941522
      grad_gnorm: 0.06753021478652954
      policy_entropy: 0.0014292023843154311
      policy_loss: 3.1260807276112246e-08
      var_gnorm: 27.735095977783203
      vf_explained_var: 5.960464477539063e-08
      vf_loss: 2.9971265576023143e-06
    num_steps_sampled: 3020000
    num_steps_trained: 3020000
    wait_time_ms: 71.85
  iterations_since_restore: 604
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 5173.990508556366
  time_this_iter_s: 8.207565307617188
  time_total_s: 5173.990508556366
  timestamp: 1594863489
  timesteps_since_restore: 3020000
  timesteps_this_iter: 5000
  timesteps_total: 3020000
  training_iteration: 604
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 5173 s, 604 iter, 3020000 ts, -127 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-38-17
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -127.16840579132858
  episode_reward_min: -2035.6700113276845
  episodes_this_iter: 1
  episodes_total: 604
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.446
    dispatch_time_ms: 8.137
    learner:
      cur_lr: 0.0011588679626584053
      grad_gnorm: 0.461536705493927
      policy_entropy: 0.0014340541092678905
      policy_loss: 4.364505343801284e-07
      var_gnorm: 27.735260009765625
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 0.00014028701116330922
    num_steps_sampled: 3025000
    num_steps_trained: 3025000
    wait_time_ms: 70.788
  iterations_since_restore: 605
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 5182.04034280777
  time_this_iter_s: 8.049834251403809
  time_total_s: 5182.04034280777
  timestamp: 1594863497
  timesteps_since_restore: 3025000
  timesteps_this_iter: 5000
  timesteps_total: 3025000
  training_iteration: 605
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 5182 s, 605 iter, 3025000 ts, -127 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-38-25
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -127.16840579132858
  episode_reward_min: -2035.6700113276845
  episodes_this_iter: 1
  episodes_total: 605
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.747
    dispatch_time_ms: 7.056
    learner:
      cur_lr: 0.0011585350148379803
      grad_gnorm: 0.09465241432189941
      policy_entropy: 0.001439852872863412
      policy_loss: 5.27212549172873e-08
      var_gnorm: 27.735509872436523
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 5.895342383155366e-06
    num_steps_sampled: 3030000
    num_steps_trained: 3030000
    wait_time_ms: 68.258
  iterations_since_restore: 606
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 5190.122137784958
  time_this_iter_s: 8.08179497718811
  time_total_s: 5190.122137784958
  timestamp: 1594863505
  timesteps_since_restore: 3030000
  timesteps_this_iter: 5000
  timesteps_total: 3030000
  training_iteration: 606
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 5190 s, 606 iter, 3030000 ts, -127 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-38-33
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -127.16840579132858
  episode_reward_min: -2035.6700113276845
  episodes_this_iter: 1
  episodes_total: 606
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.616
    dispatch_time_ms: 8.235
    learner:
      cur_lr: 0.0011582019506022334
      grad_gnorm: 0.22487697005271912
      policy_entropy: 0.00144554628059268
      policy_loss: 1.2968883993380587e-06
      var_gnorm: 27.735700607299805
      vf_explained_var: 0.0
      vf_loss: 3.3312022424070165e-05
    num_steps_sampled: 3035000
    num_steps_trained: 3035000
    wait_time_ms: 73.15
  iterations_since_restore: 607
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 5198.26114487648
  time_this_iter_s: 8.139007091522217
  time_total_s: 5198.26114487648
  timestamp: 1594863513
  timesteps_since_restore: 3035000
  timesteps_this_iter: 5000
  timesteps_total: 3035000
  training_iteration: 607
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 5198 s, 607 iter, 3035000 ts, -127 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-38-41
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -127.16840579132858
  episode_reward_min: -2035.6700113276845
  episodes_this_iter: 1
  episodes_total: 607
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.485
    dispatch_time_ms: 6.78
    learner:
      cur_lr: 0.0011578690027818084
      grad_gnorm: 0.20749865472316742
      policy_entropy: 0.0014516275841742754
      policy_loss: -5.149905391022003e-08
      var_gnorm: 27.735979080200195
      vf_explained_var: 0.0
      vf_loss: 2.834844053722918e-05
    num_steps_sampled: 3040000
    num_steps_trained: 3040000
    wait_time_ms: 74.418
  iterations_since_restore: 608
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 5206.439930677414
  time_this_iter_s: 8.178785800933838
  time_total_s: 5206.439930677414
  timestamp: 1594863521
  timesteps_since_restore: 3040000
  timesteps_this_iter: 5000
  timesteps_total: 3040000
  training_iteration: 608
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 5206 s, 608 iter, 3040000 ts, -127 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-38-49
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -127.16840579132858
  episode_reward_min: -2035.6700113276845
  episodes_this_iter: 1
  episodes_total: 608
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 3.263
    dispatch_time_ms: 6.975
    learner:
      cur_lr: 0.0011575360549613833
      grad_gnorm: 0.5185445547103882
      policy_entropy: 0.0014579554554075003
      policy_loss: 3.8894933140909416e-07
      var_gnorm: 27.73619842529297
      vf_explained_var: 1.7881393432617188e-07
      vf_loss: 0.00017707288498058915
    num_steps_sampled: 3045000
    num_steps_trained: 3045000
    wait_time_ms: 71.75
  iterations_since_restore: 609
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 5214.622979402542
  time_this_iter_s: 8.183048725128174
  time_total_s: 5214.622979402542
  timestamp: 1594863529
  timesteps_since_restore: 3045000
  timesteps_this_iter: 5000
  timesteps_total: 3045000
  training_iteration: 609
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 5214 s, 609 iter, 3045000 ts, -127 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-38-58
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -127.16840579132858
  episode_reward_min: -2035.6700113276845
  episodes_this_iter: 1
  episodes_total: 609
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.649
    dispatch_time_ms: 6.596
    learner:
      cur_lr: 0.0011572029907256365
      grad_gnorm: 0.19314508140087128
      policy_entropy: 0.0014638935681432486
      policy_loss: 8.94099727588582e-08
      var_gnorm: 27.736446380615234
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 2.4561923055443913e-05
    num_steps_sampled: 3050000
    num_steps_trained: 3050000
    wait_time_ms: 76.038
  iterations_since_restore: 610
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 5222.802210330963
  time_this_iter_s: 8.17923092842102
  time_total_s: 5222.802210330963
  timestamp: 1594863538
  timesteps_since_restore: 3050000
  timesteps_this_iter: 5000
  timesteps_total: 3050000
  training_iteration: 610
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 5222 s, 610 iter, 3050000 ts, -127 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-39-06
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -127.16840579132858
  episode_reward_min: -2035.6700113276845
  episodes_this_iter: 1
  episodes_total: 610
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.519
    dispatch_time_ms: 5.904
    learner:
      cur_lr: 0.0011568700429052114
      grad_gnorm: 0.45072269439697266
      policy_entropy: 0.0014708612579852343
      policy_loss: 8.654539556118834e-07
      var_gnorm: 27.736709594726562
      vf_explained_var: 0.0
      vf_loss: 0.00013379682786762714
    num_steps_sampled: 3055000
    num_steps_trained: 3055000
    wait_time_ms: 71.963
  iterations_since_restore: 611
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 5230.856316328049
  time_this_iter_s: 8.054105997085571
  time_total_s: 5230.856316328049
  timestamp: 1594863546
  timesteps_since_restore: 3055000
  timesteps_this_iter: 5000
  timesteps_total: 3055000
  training_iteration: 611
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 5230 s, 611 iter, 3055000 ts, -127 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-39-14
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -127.16840579132858
  episode_reward_min: -2035.6700113276845
  episodes_this_iter: 1
  episodes_total: 611
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.837
    dispatch_time_ms: 7.136
    learner:
      cur_lr: 0.0011565369786694646
      grad_gnorm: 0.0006315514910966158
      policy_entropy: 0.001478560734540224
      policy_loss: 2.9230812215175206e-10
      var_gnorm: 27.73708152770996
      vf_explained_var: 0.0
      vf_loss: 2.8206431634814066e-10
    num_steps_sampled: 3060000
    num_steps_trained: 3060000
    wait_time_ms: 72.863
  iterations_since_restore: 612
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 5238.978328466415
  time_this_iter_s: 8.1220121383667
  time_total_s: 5238.978328466415
  timestamp: 1594863554
  timesteps_since_restore: 3060000
  timesteps_this_iter: 5000
  timesteps_total: 3060000
  training_iteration: 612
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 5238 s, 612 iter, 3060000 ts, -127 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-39-22
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -127.16840579132858
  episode_reward_min: -2035.6700113276845
  episodes_this_iter: 1
  episodes_total: 612
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.656
    dispatch_time_ms: 10.009
    learner:
      cur_lr: 0.0011562040308490396
      grad_gnorm: 0.5409011840820312
      policy_entropy: 0.0014866963028907776
      policy_loss: 5.372414193516306e-07
      var_gnorm: 27.737394332885742
      vf_explained_var: 2.384185791015625e-07
      vf_loss: 0.00019269331824034452
    num_steps_sampled: 3065000
    num_steps_trained: 3065000
    wait_time_ms: 69.396
  iterations_since_restore: 613
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 5247.183782577515
  time_this_iter_s: 8.205454111099243
  time_total_s: 5247.183782577515
  timestamp: 1594863562
  timesteps_since_restore: 3065000
  timesteps_this_iter: 5000
  timesteps_total: 3065000
  training_iteration: 613
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 5247 s, 613 iter, 3065000 ts, -127 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-39-30
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -127.16840579132858
  episode_reward_min: -2035.6700113276845
  episodes_this_iter: 1
  episodes_total: 613
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.468
    dispatch_time_ms: 9.31
    learner:
      cur_lr: 0.0011558709666132927
      grad_gnorm: 0.23681198060512543
      policy_entropy: 0.001500900718383491
      policy_loss: -3.846043838962032e-08
      var_gnorm: 27.737802505493164
      vf_explained_var: 1.7881393432617188e-07
      vf_loss: 3.6924211599398404e-05
    num_steps_sampled: 3070000
    num_steps_trained: 3070000
    wait_time_ms: 70.086
  iterations_since_restore: 614
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 5255.268815755844
  time_this_iter_s: 8.085033178329468
  time_total_s: 5255.268815755844
  timestamp: 1594863570
  timesteps_since_restore: 3070000
  timesteps_this_iter: 5000
  timesteps_total: 3070000
  training_iteration: 614
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 5255 s, 614 iter, 3070000 ts, -127 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-39-38
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -127.16840579132858
  episode_reward_min: -2035.6700113276845
  episodes_this_iter: 1
  episodes_total: 614
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.867
    dispatch_time_ms: 7.866
    learner:
      cur_lr: 0.0011555380187928677
      grad_gnorm: 0.7570945024490356
      policy_entropy: 0.0015097468858584762
      policy_loss: 5.313982569532527e-07
      var_gnorm: 27.738161087036133
      vf_explained_var: 1.1920928955078125e-07
      vf_loss: 0.0003774045908357948
    num_steps_sampled: 3075000
    num_steps_trained: 3075000
    wait_time_ms: 71.388
  iterations_since_restore: 615
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 5263.368168354034
  time_this_iter_s: 8.099352598190308
  time_total_s: 5263.368168354034
  timestamp: 1594863578
  timesteps_since_restore: 3075000
  timesteps_this_iter: 5000
  timesteps_total: 3075000
  training_iteration: 615
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 5263 s, 615 iter, 3075000 ts, -127 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-39-46
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -127.16840579132858
  episode_reward_min: -2035.6700113276845
  episodes_this_iter: 1
  episodes_total: 615
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.887
    dispatch_time_ms: 7.49
    learner:
      cur_lr: 0.0011552049545571208
      grad_gnorm: 0.3682059645652771
      policy_entropy: 0.0015182258794084191
      policy_loss: -1.804748279710111e-07
      var_gnorm: 27.73856544494629
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 8.926887676352635e-05
    num_steps_sampled: 3080000
    num_steps_trained: 3080000
    wait_time_ms: 72.414
  iterations_since_restore: 616
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 5271.483322620392
  time_this_iter_s: 8.115154266357422
  time_total_s: 5271.483322620392
  timestamp: 1594863586
  timesteps_since_restore: 3080000
  timesteps_this_iter: 5000
  timesteps_total: 3080000
  training_iteration: 616
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 5271 s, 616 iter, 3080000 ts, -127 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-39-55
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -127.16840579132858
  episode_reward_min: -2035.6700113276845
  episodes_this_iter: 1
  episodes_total: 616
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 3.193
    dispatch_time_ms: 8.446
    learner:
      cur_lr: 0.0011548720067366958
      grad_gnorm: 0.40525388717651367
      policy_entropy: 0.0015281426021829247
      policy_loss: 4.872399586020038e-07
      var_gnorm: 27.739013671875
      vf_explained_var: 5.960464477539063e-08
      vf_loss: 0.000108125495899003
    num_steps_sampled: 3085000
    num_steps_trained: 3085000
    wait_time_ms: 71.723
  iterations_since_restore: 617
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 5279.636258125305
  time_this_iter_s: 8.15293550491333
  time_total_s: 5279.636258125305
  timestamp: 1594863595
  timesteps_since_restore: 3085000
  timesteps_this_iter: 5000
  timesteps_total: 3085000
  training_iteration: 617
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 5279 s, 617 iter, 3085000 ts, -127 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-40-03
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -127.16840579132858
  episode_reward_min: -2035.6700113276845
  episodes_this_iter: 1
  episodes_total: 617
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 3.049
    dispatch_time_ms: 7.462
    learner:
      cur_lr: 0.001154538942500949
      grad_gnorm: 0.40526947379112244
      policy_entropy: 0.0015383934369310737
      policy_loss: -1.0178608533806255e-07
      var_gnorm: 27.739582061767578
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 0.00010816872236318886
    num_steps_sampled: 3090000
    num_steps_trained: 3090000
    wait_time_ms: 73.516
  iterations_since_restore: 618
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 5287.7787272930145
  time_this_iter_s: 8.14246916770935
  time_total_s: 5287.7787272930145
  timestamp: 1594863603
  timesteps_since_restore: 3090000
  timesteps_this_iter: 5000
  timesteps_total: 3090000
  training_iteration: 618
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 5287 s, 618 iter, 3090000 ts, -127 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-40-11
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -127.16840579132858
  episode_reward_min: -2035.6700113276845
  episodes_this_iter: 1
  episodes_total: 618
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.487
    dispatch_time_ms: 9.376
    learner:
      cur_lr: 0.0011542059946805239
      grad_gnorm: 0.7071923613548279
      policy_entropy: 0.0015497927088290453
      policy_loss: 6.50794561352086e-07
      var_gnorm: 27.740140914916992
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 0.000329350761603564
    num_steps_sampled: 3095000
    num_steps_trained: 3095000
    wait_time_ms: 72.252
  iterations_since_restore: 619
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 5295.899390220642
  time_this_iter_s: 8.120662927627563
  time_total_s: 5295.899390220642
  timestamp: 1594863611
  timesteps_since_restore: 3095000
  timesteps_this_iter: 5000
  timesteps_total: 3095000
  training_iteration: 619
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 5295 s, 619 iter, 3095000 ts, -127 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-40-19
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -127.16840579132858
  episode_reward_min: -2035.6700113276845
  episodes_this_iter: 1
  episodes_total: 619
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 3.56
    dispatch_time_ms: 7.036
    learner:
      cur_lr: 0.0011538730468600988
      grad_gnorm: 0.3578929901123047
      policy_entropy: 0.0015617578756064177
      policy_loss: -5.647432743671743e-08
      var_gnorm: 27.740982055664062
      vf_explained_var: 0.0
      vf_loss: 8.436365897068754e-05
    num_steps_sampled: 3100000
    num_steps_trained: 3100000
    wait_time_ms: 73.046
  iterations_since_restore: 620
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 5303.942033529282
  time_this_iter_s: 8.042643308639526
  time_total_s: 5303.942033529282
  timestamp: 1594863619
  timesteps_since_restore: 3100000
  timesteps_this_iter: 5000
  timesteps_total: 3100000
  training_iteration: 620
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 5303 s, 620 iter, 3100000 ts, -127 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-40-27
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -127.16840579132858
  episode_reward_min: -2035.6700113276845
  episodes_this_iter: 1
  episodes_total: 620
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 3.106
    dispatch_time_ms: 5.548
    learner:
      cur_lr: 0.001153539982624352
      grad_gnorm: 0.47912630438804626
      policy_entropy: 0.0015808063326403499
      policy_loss: 6.682964226456534e-07
      var_gnorm: 27.74175453186035
      vf_explained_var: 0.0
      vf_loss: 0.00015118303417693824
    num_steps_sampled: 3105000
    num_steps_trained: 3105000
    wait_time_ms: 70.51
  iterations_since_restore: 621
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 5312.079229831696
  time_this_iter_s: 8.13719630241394
  time_total_s: 5312.079229831696
  timestamp: 1594863627
  timesteps_since_restore: 3105000
  timesteps_this_iter: 5000
  timesteps_total: 3105000
  training_iteration: 621
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 5312 s, 621 iter, 3105000 ts, -127 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-40-35
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -127.16840579132858
  episode_reward_min: -2035.6700113276845
  episodes_this_iter: 1
  episodes_total: 621
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.831
    dispatch_time_ms: 8.135
    learner:
      cur_lr: 0.001153207034803927
      grad_gnorm: 0.45218992233276367
      policy_entropy: 0.001594998175278306
      policy_loss: 2.339524769467971e-07
      var_gnorm: 27.742881774902344
      vf_explained_var: 0.0
      vf_loss: 0.00013463065261021256
    num_steps_sampled: 3110000
    num_steps_trained: 3110000
    wait_time_ms: 72.071
  iterations_since_restore: 622
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 5320.183208942413
  time_this_iter_s: 8.103979110717773
  time_total_s: 5320.183208942413
  timestamp: 1594863635
  timesteps_since_restore: 3110000
  timesteps_this_iter: 5000
  timesteps_total: 3110000
  training_iteration: 622
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 5320 s, 622 iter, 3110000 ts, -127 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-40-44
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -127.16840579132858
  episode_reward_min: -2035.6700113276845
  episodes_this_iter: 1
  episodes_total: 622
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.782
    dispatch_time_ms: 6.254
    learner:
      cur_lr: 0.00115287397056818
      grad_gnorm: 0.0522003136575222
      policy_entropy: 0.0016100741922855377
      policy_loss: 6.608174203392991e-07
      var_gnorm: 27.744007110595703
      vf_explained_var: 1.7881393432617188e-07
      vf_loss: 1.7942786598723615e-06
    num_steps_sampled: 3115000
    num_steps_trained: 3115000
    wait_time_ms: 74.231
  iterations_since_restore: 623
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 5328.365406751633
  time_this_iter_s: 8.18219780921936
  time_total_s: 5328.365406751633
  timestamp: 1594863644
  timesteps_since_restore: 3115000
  timesteps_this_iter: 5000
  timesteps_total: 3115000
  training_iteration: 623
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 5328 s, 623 iter, 3115000 ts, -127 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-40-52
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -127.16840579132858
  episode_reward_min: -2035.6700113276845
  episodes_this_iter: 1
  episodes_total: 623
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 3.401
    dispatch_time_ms: 6.372
    learner:
      cur_lr: 0.001152541022747755
      grad_gnorm: 0.13012169301509857
      policy_entropy: 0.0016264949226751924
      policy_loss: 6.732194890446408e-08
      var_gnorm: 27.74565315246582
      vf_explained_var: 0.0
      vf_loss: 1.115105169446906e-05
    num_steps_sampled: 3120000
    num_steps_trained: 3120000
    wait_time_ms: 74.567
  iterations_since_restore: 624
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 5336.528769493103
  time_this_iter_s: 8.163362741470337
  time_total_s: 5336.528769493103
  timestamp: 1594863652
  timesteps_since_restore: 3120000
  timesteps_this_iter: 5000
  timesteps_total: 3120000
  training_iteration: 624
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 5336 s, 624 iter, 3120000 ts, -127 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-41-00
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -127.16840579132858
  episode_reward_min: -2035.6700113276845
  episodes_this_iter: 1
  episodes_total: 624
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 3.122
    dispatch_time_ms: 7.207
    learner:
      cur_lr: 0.0011522079585120082
      grad_gnorm: 0.04956495016813278
      policy_entropy: 0.0016435806173831224
      policy_loss: 2.544718995522999e-07
      var_gnorm: 27.74739646911621
      vf_explained_var: 5.960464477539063e-08
      vf_loss: 1.613453264326381e-06
    num_steps_sampled: 3125000
    num_steps_trained: 3125000
    wait_time_ms: 70.175
  iterations_since_restore: 625
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 5344.727271080017
  time_this_iter_s: 8.198501586914062
  time_total_s: 5344.727271080017
  timestamp: 1594863660
  timesteps_since_restore: 3125000
  timesteps_this_iter: 5000
  timesteps_total: 3125000
  training_iteration: 625
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 5344 s, 625 iter, 3125000 ts, -127 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-41-08
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -106.81170567805175
  episode_reward_min: -1225.6080679070599
  episodes_this_iter: 1
  episodes_total: 625
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.426
    dispatch_time_ms: 7.647
    learner:
      cur_lr: 0.0011518750106915832
      grad_gnorm: 0.9877236485481262
      policy_entropy: 0.0016618024092167616
      policy_loss: -5.164142748981249e-07
      var_gnorm: 27.748804092407227
      vf_explained_var: 0.0
      vf_loss: 0.0006424138555303216
    num_steps_sampled: 3130000
    num_steps_trained: 3130000
    wait_time_ms: 70.387
  iterations_since_restore: 626
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 5352.855718612671
  time_this_iter_s: 8.128447532653809
  time_total_s: 5352.855718612671
  timestamp: 1594863668
  timesteps_since_restore: 3130000
  timesteps_this_iter: 5000
  timesteps_total: 3130000
  training_iteration: 626
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 5352 s, 626 iter, 3130000 ts, -107 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-41-16
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -94.55562499898114
  episode_reward_min: -1097.93749998801
  episodes_this_iter: 1
  episodes_total: 626
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.427
    dispatch_time_ms: 9.379
    learner:
      cur_lr: 0.0011515419464558363
      grad_gnorm: 0.30114030838012695
      policy_entropy: 0.00168269919231534
      policy_loss: 1.800448217181838e-07
      var_gnorm: 27.751834869384766
      vf_explained_var: 0.0
      vf_loss: 5.969757694401778e-05
    num_steps_sampled: 3135000
    num_steps_trained: 3135000
    wait_time_ms: 72.467
  iterations_since_restore: 627
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 5360.99583530426
  time_this_iter_s: 8.140116691589355
  time_total_s: 5360.99583530426
  timestamp: 1594863676
  timesteps_since_restore: 3135000
  timesteps_this_iter: 5000
  timesteps_total: 3135000
  training_iteration: 627
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 5360 s, 627 iter, 3135000 ts, -94.6 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-41-25
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -87.59499999905667
  episode_reward_min: -1097.93749998801
  episodes_this_iter: 1
  episodes_total: 627
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.773
    dispatch_time_ms: 7.537
    learner:
      cur_lr: 0.0011512089986354113
      grad_gnorm: 0.5721412897109985
      policy_entropy: 0.001703746384009719
      policy_loss: 1.9091628278289363e-09
      var_gnorm: 27.75725746154785
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 0.0002155512775061652
    num_steps_sampled: 3140000
    num_steps_trained: 3140000
    wait_time_ms: 71.393
  iterations_since_restore: 628
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 5369.145595550537
  time_this_iter_s: 8.149760246276855
  time_total_s: 5369.145595550537
  timestamp: 1594863685
  timesteps_since_restore: 3140000
  timesteps_this_iter: 5000
  timesteps_total: 3140000
  training_iteration: 628
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 5369 s, 628 iter, 3140000 ts, -87.6 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-41-33
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -76.61562499917656
  episode_reward_min: -996.499999989111
  episodes_this_iter: 1
  episodes_total: 628
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 3.132
    dispatch_time_ms: 11.357
    learner:
      cur_lr: 0.0011508760508149862
      grad_gnorm: 0.19042888283729553
      policy_entropy: 0.0017400169745087624
      policy_loss: 5.696676339539408e-07
      var_gnorm: 27.769062042236328
      vf_explained_var: 5.960464477539063e-08
      vf_loss: 2.3875929400674067e-05
    num_steps_sampled: 3145000
    num_steps_trained: 3145000
    wait_time_ms: 67.755
  iterations_since_restore: 629
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 5377.247520446777
  time_this_iter_s: 8.101924896240234
  time_total_s: 5377.247520446777
  timestamp: 1594863693
  timesteps_since_restore: 3145000
  timesteps_this_iter: 5000
  timesteps_total: 3145000
  training_iteration: 629
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 5377 s, 629 iter, 3145000 ts, -76.6 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-41-41
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -70.64562499924031
  episode_reward_min: -996.499999989111
  episodes_this_iter: 1
  episodes_total: 629
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.811
    dispatch_time_ms: 7.044
    learner:
      cur_lr: 0.0011505429865792394
      grad_gnorm: 40.0
      policy_entropy: 0.07091987878084183
      policy_loss: 0.0017057800432667136
      var_gnorm: 27.95396614074707
      vf_explained_var: 0.0
      vf_loss: 1.8631246089935303
    num_steps_sampled: 3150000
    num_steps_trained: 3150000
    wait_time_ms: 72.97
  iterations_since_restore: 630
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 5385.366512775421
  time_this_iter_s: 8.118992328643799
  time_total_s: 5385.366512775421
  timestamp: 1594863701
  timesteps_since_restore: 3150000
  timesteps_this_iter: 5000
  timesteps_total: 3150000
  training_iteration: 630
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 5385 s, 630 iter, 3150000 ts, -70.6 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-41-57
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -64.67562499930408
  episode_reward_min: -996.499999989111
  episodes_this_iter: 1
  episodes_total: 630
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.55
    dispatch_time_ms: 9.389
    learner:
      cur_lr: 0.0011502100387588143
      grad_gnorm: 1.9382821321487427
      policy_entropy: 0.0012916731648147106
      policy_loss: -1.087000669031113e-06
      var_gnorm: 27.961071014404297
      vf_explained_var: 1.1920928955078125e-07
      vf_loss: 0.10117470473051071
    num_steps_sampled: 3155000
    num_steps_trained: 3155000
    wait_time_ms: 72.405
  iterations_since_restore: 631
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 5401.77702999115
  time_this_iter_s: 16.41051721572876
  time_total_s: 5401.77702999115
  timestamp: 1594863717
  timesteps_since_restore: 3155000
  timesteps_this_iter: 5000
  timesteps_total: 3155000
  training_iteration: 631
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 5401 s, 631 iter, 3155000 ts, -64.7 rew

agent-1: -262.18722085543163
agent-2: 0.0
agent-3: -19960.112361527743
agent-4: -322.0955864924238
agent-5: 0.0
Extrinsic Rewards:
-2
0
-100
-2
0
Sum Reward: -104
Avg Reward: -20.8
Min Reward: -100
Max Reward: 0
Gini Coefficient: -0.7769230769230769
20:20 Ratio: -0.0
Max-min Ratio: -0.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-42-05
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -262.16957668814507
  episode_reward_min: -20544.395168875617
  episodes_this_iter: 1
  episodes_total: 631
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.458
    dispatch_time_ms: 7.516
    learner:
      cur_lr: 0.0011498769745230675
      grad_gnorm: 0.041734203696250916
      policy_entropy: 0.0012254751054570079
      policy_loss: -9.041557724742688e-09
      var_gnorm: 27.961273193359375
      vf_explained_var: 0.0
      vf_loss: 1.1445304153312463e-06
    num_steps_sampled: 3160000
    num_steps_trained: 3160000
    wait_time_ms: 69.762
  iterations_since_restore: 632
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 5409.942134380341
  time_this_iter_s: 8.165104389190674
  time_total_s: 5409.942134380341
  timestamp: 1594863725
  timesteps_since_restore: 3160000
  timesteps_this_iter: 5000
  timesteps_total: 3160000
  training_iteration: 632
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 5409 s, 632 iter, 3160000 ts, -262 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-42-14
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -255.20957668821924
  episode_reward_min: -20544.395168875617
  episodes_this_iter: 1
  episodes_total: 632
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.592
    dispatch_time_ms: 7.884
    learner:
      cur_lr: 0.0011495440267026424
      grad_gnorm: 0.2523311972618103
      policy_entropy: 0.0012260049115866423
      policy_loss: 7.064982554538801e-08
      var_gnorm: 27.961265563964844
      vf_explained_var: 0.0
      vf_loss: 4.194064240437001e-05
    num_steps_sampled: 3165000
    num_steps_trained: 3165000
    wait_time_ms: 70.021
  iterations_since_restore: 633
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 5418.047795295715
  time_this_iter_s: 8.105660915374756
  time_total_s: 5418.047795295715
  timestamp: 1594863734
  timesteps_since_restore: 3165000
  timesteps_this_iter: 5000
  timesteps_total: 3165000
  training_iteration: 633
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 5418 s, 633 iter, 3165000 ts, -255 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-42-22
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -255.20957668821924
  episode_reward_min: -20544.395168875617
  episodes_this_iter: 1
  episodes_total: 633
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 3.178
    dispatch_time_ms: 8.241
    learner:
      cur_lr: 0.0011492109624668956
      grad_gnorm: 0.0007696684333495796
      policy_entropy: 0.0012265422847121954
      policy_loss: 9.459559802138529e-10
      var_gnorm: 27.961265563964844
      vf_explained_var: 0.0
      vf_loss: 3.900169631698702e-10
    num_steps_sampled: 3170000
    num_steps_trained: 3170000
    wait_time_ms: 68.836
  iterations_since_restore: 634
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 5426.13349032402
  time_this_iter_s: 8.085695028305054
  time_total_s: 5426.13349032402
  timestamp: 1594863742
  timesteps_since_restore: 3170000
  timesteps_this_iter: 5000
  timesteps_total: 3170000
  training_iteration: 634
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 5426 s, 634 iter, 3170000 ts, -255 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-42-30
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -248.25957668829338
  episode_reward_min: -20544.395168875617
  episodes_this_iter: 1
  episodes_total: 634
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.873
    dispatch_time_ms: 31.306
    learner:
      cur_lr: 0.0011488780146464705
      grad_gnorm: 0.2579483985900879
      policy_entropy: 0.0012270656879991293
      policy_loss: 8.418604480198155e-09
      var_gnorm: 27.961261749267578
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 4.3802603613585234e-05
    num_steps_sampled: 3175000
    num_steps_trained: 3175000
    wait_time_ms: 55.861
  iterations_since_restore: 635
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 5434.40335059166
  time_this_iter_s: 8.26986026763916
  time_total_s: 5434.40335059166
  timestamp: 1594863750
  timesteps_since_restore: 3175000
  timesteps_this_iter: 5000
  timesteps_total: 3175000
  training_iteration: 635
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 5434 s, 635 iter, 3175000 ts, -248 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-42-39
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -248.25957668829338
  episode_reward_min: -20544.395168875617
  episodes_this_iter: 1
  episodes_total: 635
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 3.234
    dispatch_time_ms: 38.613
    learner:
      cur_lr: 0.0011485449504107237
      grad_gnorm: 0.0024277204647660255
      policy_entropy: 0.0012276575434952974
      policy_loss: -2.4582838542563934e-10
      var_gnorm: 27.961259841918945
      vf_explained_var: 0.0
      vf_loss: 3.1151607959856165e-09
    num_steps_sampled: 3180000
    num_steps_trained: 3180000
    wait_time_ms: 111.989
  iterations_since_restore: 636
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 5443.728813171387
  time_this_iter_s: 9.325462579727173
  time_total_s: 5443.728813171387
  timestamp: 1594863759
  timesteps_since_restore: 3180000
  timesteps_this_iter: 5000
  timesteps_total: 3180000
  training_iteration: 636
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 5443 s, 636 iter, 3180000 ts, -248 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-42-48
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -248.25957668829335
  episode_reward_min: -20544.395168875617
  episodes_this_iter: 1
  episodes_total: 636
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.474
    dispatch_time_ms: 28.978
    learner:
      cur_lr: 0.0011482120025902987
      grad_gnorm: 0.19624461233615875
      policy_entropy: 0.001228185137733817
      policy_loss: -1.725056364421107e-07
      var_gnorm: 27.96125602722168
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 2.5384633772773668e-05
    num_steps_sampled: 3185000
    num_steps_trained: 3185000
    wait_time_ms: 56.718
  iterations_since_restore: 637
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 5452.03361082077
  time_this_iter_s: 8.304797649383545
  time_total_s: 5452.03361082077
  timestamp: 1594863768
  timesteps_since_restore: 3185000
  timesteps_this_iter: 5000
  timesteps_total: 3185000
  training_iteration: 637
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 5452 s, 637 iter, 3185000 ts, -248 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-42-57
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -238.29457668840226
  episode_reward_min: -20544.395168875617
  episodes_this_iter: 1
  episodes_total: 637
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.879
    dispatch_time_ms: 31.818
    learner:
      cur_lr: 0.0011478790547698736
      grad_gnorm: 0.0011123704025521874
      policy_entropy: 0.0012288241414353251
      policy_loss: 8.756680935917416e-10
      var_gnorm: 27.961252212524414
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 7.329002960076991e-10
    num_steps_sampled: 3190000
    num_steps_trained: 3190000
    wait_time_ms: 56.452
  iterations_since_restore: 638
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 5460.797082662582
  time_this_iter_s: 8.763471841812134
  time_total_s: 5460.797082662582
  timestamp: 1594863777
  timesteps_since_restore: 3190000
  timesteps_this_iter: 5000
  timesteps_total: 3190000
  training_iteration: 638
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 5460 s, 638 iter, 3190000 ts, -238 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-43-05
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -236.3045766884235
  episode_reward_min: -20544.395168875617
  episodes_this_iter: 1
  episodes_total: 638
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.364
    dispatch_time_ms: 21.206
    learner:
      cur_lr: 0.0011475459905341268
      grad_gnorm: 0.21079762279987335
      policy_entropy: 0.0012294213520362973
      policy_loss: 8.17684409071262e-08
      var_gnorm: 27.961246490478516
      vf_explained_var: 0.0
      vf_loss: 2.9254075343487784e-05
    num_steps_sampled: 3195000
    num_steps_trained: 3195000
    wait_time_ms: 61.889
  iterations_since_restore: 639
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 5469.682070016861
  time_this_iter_s: 8.884987354278564
  time_total_s: 5469.682070016861
  timestamp: 1594863785
  timesteps_since_restore: 3195000
  timesteps_this_iter: 5000
  timesteps_total: 3195000
  training_iteration: 639
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 5469 s, 639 iter, 3195000 ts, -236 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-43-14
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -236.3045766884235
  episode_reward_min: -20544.395168875617
  episodes_this_iter: 1
  episodes_total: 639
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 4.535
    dispatch_time_ms: 22.407
    learner:
      cur_lr: 0.0011472130427137017
      grad_gnorm: 0.0024846477899700403
      policy_entropy: 0.0012301416136324406
      policy_loss: 1.9633492609472114e-09
      var_gnorm: 27.961240768432617
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 4.029978128983203e-09
    num_steps_sampled: 3200000
    num_steps_trained: 3200000
    wait_time_ms: 45.213
  iterations_since_restore: 640
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 5478.294269561768
  time_this_iter_s: 8.612199544906616
  time_total_s: 5478.294269561768
  timestamp: 1594863794
  timesteps_since_restore: 3200000
  timesteps_this_iter: 5000
  timesteps_total: 3200000
  training_iteration: 640
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 5478 s, 640 iter, 3200000 ts, -236 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-43-23
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -228.34457668850965
  episode_reward_min: -20544.395168875617
  episodes_this_iter: 1
  episodes_total: 640
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.42
    dispatch_time_ms: 26.585
    learner:
      cur_lr: 0.0011468799784779549
      grad_gnorm: 0.13260823488235474
      policy_entropy: 0.0012307174038141966
      policy_loss: -1.3913255259012658e-07
      var_gnorm: 27.96123695373535
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 1.1586937944230158e-05
    num_steps_sampled: 3205000
    num_steps_trained: 3205000
    wait_time_ms: 50.182
  iterations_since_restore: 641
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 5486.967190980911
  time_this_iter_s: 8.672921419143677
  time_total_s: 5486.967190980911
  timestamp: 1594863803
  timesteps_since_restore: 3205000
  timesteps_this_iter: 5000
  timesteps_total: 3205000
  training_iteration: 641
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 5486 s, 641 iter, 3205000 ts, -228 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-43-32
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -221.38395168858517
  episode_reward_min: -20544.395168875617
  episodes_this_iter: 1
  episodes_total: 641
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 3.623
    dispatch_time_ms: 32.746
    learner:
      cur_lr: 0.0011465470306575298
      grad_gnorm: 8.311041165143251e-05
      policy_entropy: 0.0012315036728978157
      policy_loss: -5.3831845231444575e-11
      var_gnorm: 27.961225509643555
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 8.229673886805955e-12
    num_steps_sampled: 3210000
    num_steps_trained: 3210000
    wait_time_ms: 52.428
  iterations_since_restore: 642
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 5495.661315441132
  time_this_iter_s: 8.694124460220337
  time_total_s: 5495.661315441132
  timestamp: 1594863812
  timesteps_since_restore: 3210000
  timesteps_this_iter: 5000
  timesteps_total: 3210000
  training_iteration: 642
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 5495 s, 642 iter, 3210000 ts, -221 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-43-40
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -219.39395168860648
  episode_reward_min: -20544.395168875617
  episodes_this_iter: 1
  episodes_total: 642
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.613
    dispatch_time_ms: 7.439
    learner:
      cur_lr: 0.001146213966421783
      grad_gnorm: 9.770048563950695e-06
      policy_entropy: 0.001232062466442585
      policy_loss: -5.310270994630939e-13
      var_gnorm: 27.961227416992188
      vf_explained_var: 0.0
      vf_loss: 1.2776576154956902e-15
    num_steps_sampled: 3215000
    num_steps_trained: 3215000
    wait_time_ms: 70.701
  iterations_since_restore: 643
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 5503.965311765671
  time_this_iter_s: 8.303996324539185
  time_total_s: 5503.965311765671
  timestamp: 1594863820
  timesteps_since_restore: 3215000
  timesteps_this_iter: 5000
  timesteps_total: 3215000
  training_iteration: 643
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 5503 s, 643 iter, 3215000 ts, -219 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-43-48
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -219.39395168860648
  episode_reward_min: -20544.395168875617
  episodes_this_iter: 1
  episodes_total: 643
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.771
    dispatch_time_ms: 6.373
    learner:
      cur_lr: 0.001145881018601358
      grad_gnorm: 0.0007805106579326093
      policy_entropy: 0.0012329625897109509
      policy_loss: -3.198244558078045e-09
      var_gnorm: 27.961214065551758
      vf_explained_var: 0.0
      vf_loss: 4.125911001739979e-10
    num_steps_sampled: 3220000
    num_steps_trained: 3220000
    wait_time_ms: 69.104
  iterations_since_restore: 644
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 5512.0150101184845
  time_this_iter_s: 8.04969835281372
  time_total_s: 5512.0150101184845
  timestamp: 1594863828
  timesteps_since_restore: 3220000
  timesteps_this_iter: 5000
  timesteps_total: 3220000
  training_iteration: 644
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 5512 s, 644 iter, 3220000 ts, -219 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-43-56
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -213.40395168867002
  episode_reward_min: -20544.395168875617
  episodes_this_iter: 1
  episodes_total: 644
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.891
    dispatch_time_ms: 6.305
    learner:
      cur_lr: 0.001145547954365611
      grad_gnorm: 0.15931932628154755
      policy_entropy: 0.0012335525825619698
      policy_loss: 6.073652514260175e-08
      var_gnorm: 27.961212158203125
      vf_explained_var: 0.0
      vf_loss: 1.672767393756658e-05
    num_steps_sampled: 3225000
    num_steps_trained: 3225000
    wait_time_ms: 75.426
  iterations_since_restore: 645
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 5520.201199531555
  time_this_iter_s: 8.186189413070679
  time_total_s: 5520.201199531555
  timestamp: 1594863836
  timesteps_since_restore: 3225000
  timesteps_this_iter: 5000
  timesteps_total: 3225000
  training_iteration: 645
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 5520 s, 645 iter, 3225000 ts, -213 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-44-04
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -213.40395168867002
  episode_reward_min: -20544.395168875617
  episodes_this_iter: 1
  episodes_total: 645
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.491
    dispatch_time_ms: 5.939
    learner:
      cur_lr: 0.001145215006545186
      grad_gnorm: 0.0016817604191601276
      policy_entropy: 0.001234538503922522
      policy_loss: 6.411187136734497e-10
      var_gnorm: 27.961200714111328
      vf_explained_var: 1.1920928955078125e-07
      vf_loss: 1.911815150634766e-09
    num_steps_sampled: 3230000
    num_steps_trained: 3230000
    wait_time_ms: 75.908
  iterations_since_restore: 646
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 5528.3321487903595
  time_this_iter_s: 8.130949258804321
  time_total_s: 5528.3321487903595
  timestamp: 1594863844
  timesteps_since_restore: 3230000
  timesteps_this_iter: 5000
  timesteps_total: 3230000
  training_iteration: 646
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 5528 s, 646 iter, 3230000 ts, -213 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-44-13
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -213.40395168867002
  episode_reward_min: -20544.395168875617
  episodes_this_iter: 1
  episodes_total: 646
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.829
    dispatch_time_ms: 7.659
    learner:
      cur_lr: 0.0011448819423094392
      grad_gnorm: 0.09171312302350998
      policy_entropy: 0.0012354494538158178
      policy_loss: -3.064822351461771e-08
      var_gnorm: 27.961196899414062
      vf_explained_var: 0.0
      vf_loss: 5.542616236198228e-06
    num_steps_sampled: 3235000
    num_steps_trained: 3235000
    wait_time_ms: 73.945
  iterations_since_restore: 647
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 5536.417659521103
  time_this_iter_s: 8.085510730743408
  time_total_s: 5536.417659521103
  timestamp: 1594863853
  timesteps_since_restore: 3235000
  timesteps_this_iter: 5000
  timesteps_total: 3235000
  training_iteration: 647
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 23.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 5536 s, 647 iter, 3235000 ts, -213 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-44-21
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -205.44395168875616
  episode_reward_min: -20544.395168875617
  episodes_this_iter: 1
  episodes_total: 647
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.772
    dispatch_time_ms: 11.464
    learner:
      cur_lr: 0.0011445489944890141
      grad_gnorm: 0.001007160753943026
      policy_entropy: 0.0012367535382509232
      policy_loss: 7.181760186547592e-10
      var_gnorm: 27.961181640625
      vf_explained_var: -2.384185791015625e-07
      vf_loss: 5.855386731035139e-10
    num_steps_sampled: 3240000
    num_steps_trained: 3240000
    wait_time_ms: 71.191
  iterations_since_restore: 648
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 5544.516205072403
  time_this_iter_s: 8.098545551300049
  time_total_s: 5544.516205072403
  timestamp: 1594863861
  timesteps_since_restore: 3240000
  timesteps_this_iter: 5000
  timesteps_total: 3240000
  training_iteration: 648
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 23.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 5544 s, 648 iter, 3240000 ts, -205 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-44-29
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -205.44395168875616
  episode_reward_min: -20544.395168875617
  episodes_this_iter: 1
  episodes_total: 648
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.712
    dispatch_time_ms: 8.241
    learner:
      cur_lr: 0.0011442160466685891
      grad_gnorm: 0.10024932771921158
      policy_entropy: 0.001237792312167585
      policy_loss: 3.821755001354177e-08
      var_gnorm: 27.961181640625
      vf_explained_var: 0.0
      vf_loss: 6.62342608848121e-06
    num_steps_sampled: 3245000
    num_steps_trained: 3245000
    wait_time_ms: 70.178
  iterations_since_restore: 649
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 5552.647417783737
  time_this_iter_s: 8.131212711334229
  time_total_s: 5552.647417783737
  timestamp: 1594863869
  timesteps_since_restore: 3245000
  timesteps_this_iter: 5000
  timesteps_total: 3245000
  training_iteration: 649
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 23.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 5552 s, 649 iter, 3245000 ts, -205 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-44-37
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -205.44395168875616
  episode_reward_min: -20544.395168875617
  episodes_this_iter: 1
  episodes_total: 649
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.758
    dispatch_time_ms: 10.074
    learner:
      cur_lr: 0.0011438829824328423
      grad_gnorm: 0.003180879633873701
      policy_entropy: 0.0012391499476507306
      policy_loss: -1.6194817709092035e-09
      var_gnorm: 27.961166381835938
      vf_explained_var: 0.0
      vf_loss: 6.403546581879027e-09
    num_steps_sampled: 3250000
    num_steps_trained: 3250000
    wait_time_ms: 69.306
  iterations_since_restore: 650
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 5560.784732341766
  time_this_iter_s: 8.137314558029175
  time_total_s: 5560.784732341766
  timestamp: 1594863877
  timesteps_since_restore: 3250000
  timesteps_this_iter: 5000
  timesteps_total: 3250000
  training_iteration: 650
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 23.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 5560 s, 650 iter, 3250000 ts, -205 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-44-45
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -205.44395168875616
  episode_reward_min: -20544.395168875617
  episodes_this_iter: 2
  episodes_total: 651
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.971
    dispatch_time_ms: 6.641
    learner:
      cur_lr: 0.0011435500346124172
      grad_gnorm: 0.0015265153488144279
      policy_entropy: 0.001240162062458694
      policy_loss: -5.699969385375425e-10
      var_gnorm: 27.961166381835938
      vf_explained_var: -1.0
      vf_loss: 1.2158274387275014e-09
    num_steps_sampled: 3255000
    num_steps_trained: 3255000
    wait_time_ms: 71.56
  iterations_since_restore: 651
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 5568.932112693787
  time_this_iter_s: 8.147380352020264
  time_total_s: 5568.932112693787
  timestamp: 1594863885
  timesteps_since_restore: 3255000
  timesteps_this_iter: 5000
  timesteps_total: 3255000
  training_iteration: 651
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 23.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 5568 s, 651 iter, 3255000 ts, -205 rew

Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-44-53
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -205.44395168875616
  episode_reward_min: -20544.395168875617
  episodes_this_iter: 0
  episodes_total: 651
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.512
    dispatch_time_ms: 8.92
    learner:
      cur_lr: 0.0011432169703766704
      grad_gnorm: 0.010130188427865505
      policy_entropy: 0.0012415798846632242
      policy_loss: 1.6043449235780827e-08
      var_gnorm: 27.961145401000977
      vf_explained_var: 1.1920928955078125e-07
      vf_loss: 6.845444033842796e-08
    num_steps_sampled: 3260000
    num_steps_trained: 3260000
    wait_time_ms: 69.271
  iterations_since_restore: 652
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 5577.016260623932
  time_this_iter_s: 8.084147930145264
  time_total_s: 5577.016260623932
  timestamp: 1594863893
  timesteps_since_restore: 3260000
  timesteps_this_iter: 5000
  timesteps_total: 3260000
  training_iteration: 652
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 23.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 5577 s, 652 iter, 3260000 ts, -205 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-45-02
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -205.44395168875616
  episode_reward_min: -20544.395168875617
  episodes_this_iter: 1
  episodes_total: 652
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.928
    dispatch_time_ms: 9.83
    learner:
      cur_lr: 0.0011428840225562453
      grad_gnorm: 0.12010937184095383
      policy_entropy: 0.001242642174474895
      policy_loss: 4.578869194915569e-08
      var_gnorm: 27.961145401000977
      vf_explained_var: 0.0
      vf_loss: 9.499431143922266e-06
    num_steps_sampled: 3265000
    num_steps_trained: 3265000
    wait_time_ms: 69.275
  iterations_since_restore: 653
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 5585.221424102783
  time_this_iter_s: 8.205163478851318
  time_total_s: 5585.221424102783
  timestamp: 1594863902
  timesteps_since_restore: 3265000
  timesteps_this_iter: 5000
  timesteps_total: 3265000
  training_iteration: 653
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 23.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 5585 s, 653 iter, 3265000 ts, -205 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-45-10
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -205.44395168875616
  episode_reward_min: -20544.395168875617
  episodes_this_iter: 1
  episodes_total: 653
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.669
    dispatch_time_ms: 6.542
    learner:
      cur_lr: 0.0011425509583204985
      grad_gnorm: 0.006164880469441414
      policy_entropy: 0.0012442038860172033
      policy_loss: -7.476981533915961e-11
      var_gnorm: 27.96112823486328
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 2.5114367474543542e-08
    num_steps_sampled: 3270000
    num_steps_trained: 3270000
    wait_time_ms: 73.096
  iterations_since_restore: 654
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 5593.313602685928
  time_this_iter_s: 8.092178583145142
  time_total_s: 5593.313602685928
  timestamp: 1594863910
  timesteps_since_restore: 3270000
  timesteps_this_iter: 5000
  timesteps_total: 3270000
  training_iteration: 654
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 23.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 5593 s, 654 iter, 3270000 ts, -205 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-45-18
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -205.44395168875616
  episode_reward_min: -20544.395168875617
  episodes_this_iter: 1
  episodes_total: 654
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 3.418
    dispatch_time_ms: 7.182
    learner:
      cur_lr: 0.0011422180105000734
      grad_gnorm: 0.1299869865179062
      policy_entropy: 0.0012452610535547137
      policy_loss: -4.3501170665649624e-08
      var_gnorm: 27.96112823486328
      vf_explained_var: 0.0
      vf_loss: 1.1131688552268315e-05
    num_steps_sampled: 3275000
    num_steps_trained: 3275000
    wait_time_ms: 71.528
  iterations_since_restore: 655
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 5601.466272115707
  time_this_iter_s: 8.152669429779053
  time_total_s: 5601.466272115707
  timestamp: 1594863918
  timesteps_since_restore: 3275000
  timesteps_this_iter: 5000
  timesteps_total: 3275000
  training_iteration: 655
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 24.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 5601 s, 655 iter, 3275000 ts, -205 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-45-26
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -205.44395168875616
  episode_reward_min: -20544.395168875617
  episodes_this_iter: 1
  episodes_total: 655
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.566
    dispatch_time_ms: 9.176
    learner:
      cur_lr: 0.0011418849462643266
      grad_gnorm: 0.011361544020473957
      policy_entropy: 0.0012469349894672632
      policy_loss: 2.756102679413175e-09
      var_gnorm: 27.961109161376953
      vf_explained_var: 0.0
      vf_loss: 8.581972821275485e-08
    num_steps_sampled: 3280000
    num_steps_trained: 3280000
    wait_time_ms: 70.857
  iterations_since_restore: 656
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 5609.730170249939
  time_this_iter_s: 8.263898134231567
  time_total_s: 5609.730170249939
  timestamp: 1594863926
  timesteps_since_restore: 3280000
  timesteps_this_iter: 5000
  timesteps_total: 3280000
  training_iteration: 656
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 5609 s, 656 iter, 3280000 ts, -205 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-45-34
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -205.44395168875616
  episode_reward_min: -20544.395168875617
  episodes_this_iter: 1
  episodes_total: 656
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 3.192
    dispatch_time_ms: 8.231
    learner:
      cur_lr: 0.0011415519984439015
      grad_gnorm: 6.186812242958695e-05
      policy_entropy: 0.0012483395403251052
      policy_loss: 2.650140662474598e-10
      var_gnorm: 27.96111297607422
      vf_explained_var: 0.0
      vf_loss: 8.422766824278671e-12
    num_steps_sampled: 3285000
    num_steps_trained: 3285000
    wait_time_ms: 68.098
  iterations_since_restore: 657
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 5617.78610253334
  time_this_iter_s: 8.05593228340149
  time_total_s: 5617.78610253334
  timestamp: 1594863934
  timesteps_since_restore: 3285000
  timesteps_this_iter: 5000
  timesteps_total: 3285000
  training_iteration: 657
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 5617 s, 657 iter, 3285000 ts, -205 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-45-42
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -205.44395168875616
  episode_reward_min: -20544.395168875617
  episodes_this_iter: 1
  episodes_total: 657
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.666
    dispatch_time_ms: 6.515
    learner:
      cur_lr: 0.0011412190506234765
      grad_gnorm: 0.01395845040678978
      policy_entropy: 0.001250346307642758
      policy_loss: 6.940528152199477e-09
      var_gnorm: 27.96108627319336
      vf_explained_var: 0.0
      vf_loss: 1.284970636561411e-07
    num_steps_sampled: 3290000
    num_steps_trained: 3290000
    wait_time_ms: 74.788
  iterations_since_restore: 658
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 5625.882446050644
  time_this_iter_s: 8.096343517303467
  time_total_s: 5625.882446050644
  timestamp: 1594863942
  timesteps_since_restore: 3290000
  timesteps_this_iter: 5000
  timesteps_total: 3290000
  training_iteration: 658
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 5625 s, 658 iter, 3290000 ts, -205 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-46-01
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -205.44395168875616
  episode_reward_min: -20544.395168875617
  episodes_this_iter: 2
  episodes_total: 659
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.796
    dispatch_time_ms: 8.327
    learner:
      cur_lr: 0.0011408859863877296
      grad_gnorm: 4.142121315002441
      policy_entropy: 0.002477904548868537
      policy_loss: -2.1237578039290383e-05
      var_gnorm: 27.961090087890625
      vf_explained_var: -1.0
      vf_loss: 0.09337242692708969
    num_steps_sampled: 3295000
    num_steps_trained: 3295000
    wait_time_ms: 1103.802
  iterations_since_restore: 659
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 5644.321731805801
  time_this_iter_s: 18.43928575515747
  time_total_s: 5644.321731805801
  timestamp: 1594863961
  timesteps_since_restore: 3295000
  timesteps_this_iter: 5000
  timesteps_total: 3295000
  training_iteration: 659
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 5644 s, 659 iter, 3295000 ts, -205 rew

Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-46-08
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -205.44395168875616
  episode_reward_min: -20544.395168875617
  episodes_this_iter: 0
  episodes_total: 659
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.632
    dispatch_time_ms: 7.479
    learner:
      cur_lr: 0.0011405530385673046
      grad_gnorm: 0.07900585234165192
      policy_entropy: 0.0012537462171167135
      policy_loss: 1.2082661271506367e-07
      var_gnorm: 27.961063385009766
      vf_explained_var: 0.0
      vf_loss: 4.11470909966738e-06
    num_steps_sampled: 3300000
    num_steps_trained: 3300000
    wait_time_ms: 71.669
  iterations_since_restore: 660
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 5651.805691242218
  time_this_iter_s: 7.483959436416626
  time_total_s: 5651.805691242218
  timestamp: 1594863968
  timesteps_since_restore: 3300000
  timesteps_this_iter: 5000
  timesteps_total: 3300000
  training_iteration: 660
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 5651 s, 660 iter, 3300000 ts, -205 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-46-17
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -205.44395168875616
  episode_reward_min: -20544.395168875617
  episodes_this_iter: 2
  episodes_total: 661
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 3.231
    dispatch_time_ms: 7.253
    learner:
      cur_lr: 0.0011402199743315578
      grad_gnorm: 0.018409142270684242
      policy_entropy: 0.0012612955179065466
      policy_loss: -5.335194064315374e-09
      var_gnorm: 27.96106719970703
      vf_explained_var: -1.0
      vf_loss: 1.7682930320006562e-07
    num_steps_sampled: 3305000
    num_steps_trained: 3305000
    wait_time_ms: 71.288
  iterations_since_restore: 661
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 5659.979030609131
  time_this_iter_s: 8.173339366912842
  time_total_s: 5659.979030609131
  timestamp: 1594863977
  timesteps_since_restore: 3305000
  timesteps_this_iter: 5000
  timesteps_total: 3305000
  training_iteration: 661
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 5659 s, 661 iter, 3305000 ts, -205 rew

Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-46-25
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -205.44395168875616
  episode_reward_min: -20544.395168875617
  episodes_this_iter: 0
  episodes_total: 661
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.392
    dispatch_time_ms: 7.904
    learner:
      cur_lr: 0.0011398870265111327
      grad_gnorm: 0.01597294583916664
      policy_entropy: 0.001263685873709619
      policy_loss: -1.2409669736257456e-08
      var_gnorm: 27.961040496826172
      vf_explained_var: 0.0
      vf_loss: 1.6822991710796487e-07
    num_steps_sampled: 3310000
    num_steps_trained: 3310000
    wait_time_ms: 71.616
  iterations_since_restore: 662
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 5668.08145570755
  time_this_iter_s: 8.10242509841919
  time_total_s: 5668.08145570755
  timestamp: 1594863985
  timesteps_since_restore: 3310000
  timesteps_this_iter: 5000
  timesteps_total: 3310000
  training_iteration: 662
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 5668 s, 662 iter, 3310000 ts, -205 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-46-33
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -205.44395168875616
  episode_reward_min: -20544.395168875617
  episodes_this_iter: 1
  episodes_total: 662
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.784
    dispatch_time_ms: 7.952
    learner:
      cur_lr: 0.0011395539622753859
      grad_gnorm: 0.0021293554455041885
      policy_entropy: 0.001265412662178278
      policy_loss: 6.665561880225823e-09
      var_gnorm: 27.961040496826172
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 2.897802664492133e-09
    num_steps_sampled: 3315000
    num_steps_trained: 3315000
    wait_time_ms: 71.464
  iterations_since_restore: 663
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 5676.239056110382
  time_this_iter_s: 8.157600402832031
  time_total_s: 5676.239056110382
  timestamp: 1594863993
  timesteps_since_restore: 3315000
  timesteps_this_iter: 5000
  timesteps_total: 3315000
  training_iteration: 663
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 5676 s, 663 iter, 3315000 ts, -205 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-46-41
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -205.44395168875616
  episode_reward_min: -20544.395168875617
  episodes_this_iter: 1
  episodes_total: 663
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.662
    dispatch_time_ms: 9.927
    learner:
      cur_lr: 0.0011392210144549608
      grad_gnorm: 0.015476034954190254
      policy_entropy: 0.0012681689113378525
      policy_loss: 6.55867893328832e-09
      var_gnorm: 27.96101188659668
      vf_explained_var: 0.0
      vf_loss: 1.5771151140597794e-07
    num_steps_sampled: 3320000
    num_steps_trained: 3320000
    wait_time_ms: 71.728
  iterations_since_restore: 664
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 5684.415385007858
  time_this_iter_s: 8.176328897476196
  time_total_s: 5684.415385007858
  timestamp: 1594864001
  timesteps_since_restore: 3320000
  timesteps_this_iter: 5000
  timesteps_total: 3320000
  training_iteration: 664
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 5684 s, 664 iter, 3320000 ts, -205 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-46-49
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -205.44395168875616
  episode_reward_min: -20544.395168875617
  episodes_this_iter: 2
  episodes_total: 665
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.989
    dispatch_time_ms: 8.205
    learner:
      cur_lr: 0.001138887950219214
      grad_gnorm: 0.015375745482742786
      policy_entropy: 0.0012702613603323698
      policy_loss: -6.15533757297726e-09
      var_gnorm: 27.961015701293945
      vf_explained_var: -1.0
      vf_loss: 1.233557469504376e-07
    num_steps_sampled: 3325000
    num_steps_trained: 3325000
    wait_time_ms: 70.206
  iterations_since_restore: 665
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 5692.654548406601
  time_this_iter_s: 8.239163398742676
  time_total_s: 5692.654548406601
  timestamp: 1594864009
  timesteps_since_restore: 3325000
  timesteps_this_iter: 5000
  timesteps_total: 3325000
  training_iteration: 665
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 5692 s, 665 iter, 3325000 ts, -205 rew

Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-46-58
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -205.44395168875616
  episode_reward_min: -20544.395168875617
  episodes_this_iter: 0
  episodes_total: 665
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 3.004
    dispatch_time_ms: 8.573
    learner:
      cur_lr: 0.001138555002398789
      grad_gnorm: 0.09925521910190582
      policy_entropy: 0.0012731179594993591
      policy_loss: 6.882721237388978e-08
      var_gnorm: 27.960987091064453
      vf_explained_var: 5.960464477539063e-08
      vf_loss: 6.491348813142395e-06
    num_steps_sampled: 3330000
    num_steps_trained: 3330000
    wait_time_ms: 71.348
  iterations_since_restore: 666
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 5700.789200305939
  time_this_iter_s: 8.134651899337769
  time_total_s: 5700.789200305939
  timestamp: 1594864018
  timesteps_since_restore: 3330000
  timesteps_this_iter: 5000
  timesteps_total: 3330000
  training_iteration: 666
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 5700 s, 666 iter, 3330000 ts, -205 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-47-06
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -205.44395168875616
  episode_reward_min: -20544.395168875617
  episodes_this_iter: 1
  episodes_total: 666
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 4.139
    dispatch_time_ms: 7.794
    learner:
      cur_lr: 0.001138222054578364
      grad_gnorm: 3.8538239002227783
      policy_entropy: 0.002513348590582609
      policy_loss: -2.008837145694997e-05
      var_gnorm: 27.96099281311035
      vf_explained_var: -1.0
      vf_loss: 0.08118109405040741
    num_steps_sampled: 3335000
    num_steps_trained: 3335000
    wait_time_ms: 69.408
  iterations_since_restore: 667
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 5709.023955345154
  time_this_iter_s: 8.234755039215088
  time_total_s: 5709.023955345154
  timestamp: 1594864026
  timesteps_since_restore: 3335000
  timesteps_this_iter: 5000
  timesteps_total: 3335000
  training_iteration: 667
  
agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 5709 s, 667 iter, 3335000 ts, -205 rew

Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-47-14
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -205.44395168875616
  episode_reward_min: -20544.395168875617
  episodes_this_iter: 1
  episodes_total: 667
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 3.183
    dispatch_time_ms: 8.826
    learner:
      cur_lr: 0.001137888990342617
      grad_gnorm: 0.02326245792210102
      policy_entropy: 0.0012785871513187885
      policy_loss: 7.614413988221713e-08
      var_gnorm: 27.960962295532227
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 3.576657832127239e-07
    num_steps_sampled: 3340000
    num_steps_trained: 3340000
    wait_time_ms: 69.382
  iterations_since_restore: 668
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 5717.218989372253
  time_this_iter_s: 8.19503402709961
  time_total_s: 5717.218989372253
  timestamp: 1594864034
  timesteps_since_restore: 3340000
  timesteps_this_iter: 5000
  timesteps_total: 3340000
  training_iteration: 668
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 5717 s, 668 iter, 3340000 ts, -205 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-47-22
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -205.44395168875616
  episode_reward_min: -20544.395168875617
  episodes_this_iter: 1
  episodes_total: 668
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 3.425
    dispatch_time_ms: 7.907
    learner:
      cur_lr: 0.001137556042522192
      grad_gnorm: 0.007444358896464109
      policy_entropy: 0.001281087868846953
      policy_loss: -3.0406854811815265e-09
      var_gnorm: 27.960966110229492
      vf_explained_var: 0.0
      vf_loss: 3.670591652848998e-08
    num_steps_sampled: 3345000
    num_steps_trained: 3345000
    wait_time_ms: 70.308
  iterations_since_restore: 669
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 5725.308956623077
  time_this_iter_s: 8.089967250823975
  time_total_s: 5725.308956623077
  timestamp: 1594864042
  timesteps_since_restore: 3345000
  timesteps_this_iter: 5000
  timesteps_total: 3345000
  training_iteration: 669
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 5725 s, 669 iter, 3345000 ts, -205 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-47-30
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -205.44395168875616
  episode_reward_min: -20544.395168875617
  episodes_this_iter: 1
  episodes_total: 669
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 3.148
    dispatch_time_ms: 10.006
    learner:
      cur_lr: 0.0011372229782864451
      grad_gnorm: 0.019990796223282814
      policy_entropy: 0.001284763216972351
      policy_loss: -8.5450020392841e-09
      var_gnorm: 27.960933685302734
      vf_explained_var: 0.0
      vf_loss: 2.622981867261842e-07
    num_steps_sampled: 3350000
    num_steps_trained: 3350000
    wait_time_ms: 69.008
  iterations_since_restore: 670
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 5733.451295614243
  time_this_iter_s: 8.142338991165161
  time_total_s: 5733.451295614243
  timestamp: 1594864050
  timesteps_since_restore: 3350000
  timesteps_this_iter: 5000
  timesteps_total: 3350000
  training_iteration: 670
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 5733 s, 670 iter, 3350000 ts, -205 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-47-39
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -205.44395168875616
  episode_reward_min: -20544.395168875617
  episodes_this_iter: 1
  episodes_total: 670
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 3.492
    dispatch_time_ms: 8.397
    learner:
      cur_lr: 0.00113689003046602
      grad_gnorm: 0.2365088313817978
      policy_entropy: 0.0012875066604465246
      policy_loss: -8.27066983788427e-08
      var_gnorm: 27.9609317779541
      vf_explained_var: 0.0
      vf_loss: 3.682637543533929e-05
    num_steps_sampled: 3355000
    num_steps_trained: 3355000
    wait_time_ms: 69.69
  iterations_since_restore: 671
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 5741.672474145889
  time_this_iter_s: 8.221178531646729
  time_total_s: 5741.672474145889
  timestamp: 1594864059
  timesteps_since_restore: 3355000
  timesteps_this_iter: 5000
  timesteps_total: 3355000
  training_iteration: 671
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 5741 s, 671 iter, 3355000 ts, -205 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-47-47
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -205.44395168875616
  episode_reward_min: -20544.395168875617
  episodes_this_iter: 1
  episodes_total: 671
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.665
    dispatch_time_ms: 24.934
    learner:
      cur_lr: 0.0011365569662302732
      grad_gnorm: 0.14508365094661713
      policy_entropy: 0.0012914680410176516
      policy_loss: -9.922249688543161e-08
      var_gnorm: 27.960901260375977
      vf_explained_var: 0.0
      vf_loss: 1.3864693755749613e-05
    num_steps_sampled: 3360000
    num_steps_trained: 3360000
    wait_time_ms: 58.19
  iterations_since_restore: 672
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 5749.921337604523
  time_this_iter_s: 8.248863458633423
  time_total_s: 5749.921337604523
  timestamp: 1594864067
  timesteps_since_restore: 3360000
  timesteps_this_iter: 5000
  timesteps_total: 3360000
  training_iteration: 672
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 5749 s, 672 iter, 3360000 ts, -205 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-47-56
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -205.44395168875616
  episode_reward_min: -20544.395168875617
  episodes_this_iter: 1
  episodes_total: 672
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 3.194
    dispatch_time_ms: 23.091
    learner:
      cur_lr: 0.0011362240184098482
      grad_gnorm: 1.2837153673171997
      policy_entropy: 0.00129309028852731
      policy_loss: 7.481767205774759e-09
      var_gnorm: 27.960893630981445
      vf_explained_var: 0.0
      vf_loss: 0.001085220486856997
    num_steps_sampled: 3365000
    num_steps_trained: 3365000
    wait_time_ms: 58.787
  iterations_since_restore: 673
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 5759.249842166901
  time_this_iter_s: 9.32850456237793
  time_total_s: 5759.249842166901
  timestamp: 1594864076
  timesteps_since_restore: 3365000
  timesteps_this_iter: 5000
  timesteps_total: 3365000
  training_iteration: 673
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 5759 s, 673 iter, 3365000 ts, -205 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-48-05
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -205.44395168875616
  episode_reward_min: -20544.395168875617
  episodes_this_iter: 1
  episodes_total: 673
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.793
    dispatch_time_ms: 30.814
    learner:
      cur_lr: 0.0011358909541741014
      grad_gnorm: 0.02609708160161972
      policy_entropy: 0.0012978148879483342
      policy_loss: 1.2925632786320307e-10
      var_gnorm: 27.96090316772461
      vf_explained_var: 1.9669532775878906e-06
      vf_loss: 3.553681153789512e-07
    num_steps_sampled: 3370000
    num_steps_trained: 3370000
    wait_time_ms: 68.351
  iterations_since_restore: 674
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 5768.023484945297
  time_this_iter_s: 8.773642778396606
  time_total_s: 5768.023484945297
  timestamp: 1594864085
  timesteps_since_restore: 3370000
  timesteps_this_iter: 5000
  timesteps_total: 3370000
  training_iteration: 674
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 5768 s, 674 iter, 3370000 ts, -205 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-48-14
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -205.44395168875616
  episode_reward_min: -20544.395168875617
  episodes_this_iter: 1
  episodes_total: 674
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.824
    dispatch_time_ms: 18.312
    learner:
      cur_lr: 0.0011355580063536763
      grad_gnorm: 0.290373831987381
      policy_entropy: 0.001301453565247357
      policy_loss: -1.3850137747795088e-07
      var_gnorm: 27.960901260375977
      vf_explained_var: 1.1920928955078125e-07
      vf_loss: 5.551288268179633e-05
    num_steps_sampled: 3375000
    num_steps_trained: 3375000
    wait_time_ms: 60.186
  iterations_since_restore: 675
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 5776.574167966843
  time_this_iter_s: 8.55068302154541
  time_total_s: 5776.574167966843
  timestamp: 1594864094
  timesteps_since_restore: 3375000
  timesteps_this_iter: 5000
  timesteps_total: 3375000
  training_iteration: 675
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 5776 s, 675 iter, 3375000 ts, -205 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-48-23
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -205.44395168875616
  episode_reward_min: -20544.395168875617
  episodes_this_iter: 1
  episodes_total: 675
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.926
    dispatch_time_ms: 35.501
    learner:
      cur_lr: 0.0011352249421179295
      grad_gnorm: 0.14370067417621613
      policy_entropy: 0.0013058017939329147
      policy_loss: 3.6471146103167484e-08
      var_gnorm: 27.96089744567871
      vf_explained_var: 0.0
      vf_loss: 1.186586177936988e-05
    num_steps_sampled: 3380000
    num_steps_trained: 3380000
    wait_time_ms: 67.97
  iterations_since_restore: 676
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 5785.443981170654
  time_this_iter_s: 8.869813203811646
  time_total_s: 5785.443981170654
  timestamp: 1594864103
  timesteps_since_restore: 3380000
  timesteps_this_iter: 5000
  timesteps_total: 3380000
  training_iteration: 676
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 23.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 5785 s, 676 iter, 3380000 ts, -205 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-48-31
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -205.44395168875616
  episode_reward_min: -20544.395168875617
  episodes_this_iter: 1
  episodes_total: 676
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.787
    dispatch_time_ms: 25.56
    learner:
      cur_lr: 0.0011348919942975044
      grad_gnorm: 0.4269988238811493
      policy_entropy: 0.0013101458316668868
      policy_loss: 1.3898549866553367e-07
      var_gnorm: 27.960893630981445
      vf_explained_var: 0.0
      vf_loss: 0.0001200535916723311
    num_steps_sampled: 3385000
    num_steps_trained: 3385000
    wait_time_ms: 70.513
  iterations_since_restore: 677
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 5794.007740736008
  time_this_iter_s: 8.563759565353394
  time_total_s: 5794.007740736008
  timestamp: 1594864111
  timesteps_since_restore: 3385000
  timesteps_this_iter: 5000
  timesteps_total: 3385000
  training_iteration: 677
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 23.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 5794 s, 677 iter, 3385000 ts, -205 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-48-40
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -205.44395168875616
  episode_reward_min: -20544.395168875617
  episodes_this_iter: 1
  episodes_total: 677
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.909
    dispatch_time_ms: 28.219
    learner:
      cur_lr: 0.0011345590464770794
      grad_gnorm: 7.464410009561107e-05
      policy_entropy: 0.001315059489570558
      policy_loss: -3.9265395379572965e-09
      var_gnorm: 27.960893630981445
      vf_explained_var: 0.0
      vf_loss: 7.1967002669703906e-12
    num_steps_sampled: 3390000
    num_steps_trained: 3390000
    wait_time_ms: 59.78
  iterations_since_restore: 678
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 5802.645900249481
  time_this_iter_s: 8.63815951347351
  time_total_s: 5802.645900249481
  timestamp: 1594864120
  timesteps_since_restore: 3390000
  timesteps_this_iter: 5000
  timesteps_total: 3390000
  training_iteration: 678
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 23.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 5802 s, 678 iter, 3390000 ts, -205 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-48-48
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -205.44395168875616
  episode_reward_min: -20544.395168875617
  episodes_this_iter: 1
  episodes_total: 678
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 3.314
    dispatch_time_ms: 21.508
    learner:
      cur_lr: 0.0011342259822413325
      grad_gnorm: 0.38393524289131165
      policy_entropy: 0.0013201034162193537
      policy_loss: 1.5682036291764234e-07
      var_gnorm: 27.960887908935547
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 9.706979471957311e-05
    num_steps_sampled: 3395000
    num_steps_trained: 3395000
    wait_time_ms: 52.937
  iterations_since_restore: 679
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 5811.250933408737
  time_this_iter_s: 8.605033159255981
  time_total_s: 5811.250933408737
  timestamp: 1594864128
  timesteps_since_restore: 3395000
  timesteps_this_iter: 5000
  timesteps_total: 3395000
  training_iteration: 679
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 23.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 5811 s, 679 iter, 3395000 ts, -205 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-48-57
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -205.44395168875616
  episode_reward_min: -20544.395168875617
  episodes_this_iter: 1
  episodes_total: 679
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.484
    dispatch_time_ms: 5.673
    learner:
      cur_lr: 0.0011338930344209075
      grad_gnorm: 0.04114200919866562
      policy_entropy: 0.0013259066035971045
      policy_loss: 3.056378972132734e-08
      var_gnorm: 27.96088218688965
      vf_explained_var: 0.0
      vf_loss: 1.1169436220370699e-06
    num_steps_sampled: 3400000
    num_steps_trained: 3400000
    wait_time_ms: 75.629
  iterations_since_restore: 680
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 5819.405343532562
  time_this_iter_s: 8.154410123825073
  time_total_s: 5819.405343532562
  timestamp: 1594864137
  timesteps_since_restore: 3400000
  timesteps_this_iter: 5000
  timesteps_total: 3400000
  training_iteration: 680
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 23.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 5819 s, 680 iter, 3400000 ts, -205 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-49-09
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -205.44395168875616
  episode_reward_min: -20544.395168875617
  episodes_this_iter: 1
  episodes_total: 680
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 3.155
    dispatch_time_ms: 7.188
    learner:
      cur_lr: 0.0011335599701851606
      grad_gnorm: 0.24986504018306732
      policy_entropy: 0.0013316363329067826
      policy_loss: 1.6854146167588624e-07
      var_gnorm: 27.960872650146484
      vf_explained_var: 0.0
      vf_loss: 4.1100003727478907e-05
    num_steps_sampled: 3405000
    num_steps_trained: 3405000
    wait_time_ms: 70.643
  iterations_since_restore: 681
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 5827.191130399704
  time_this_iter_s: 7.785786867141724
  time_total_s: 5827.191130399704
  timestamp: 1594864149
  timesteps_since_restore: 3405000
  timesteps_this_iter: 5000
  timesteps_total: 3405000
  training_iteration: 681
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 23.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 5827 s, 681 iter, 3405000 ts, -205 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-49-17
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -205.44395168875616
  episode_reward_min: -20544.395168875617
  episodes_this_iter: 1
  episodes_total: 681
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.901
    dispatch_time_ms: 8.472
    learner:
      cur_lr: 0.0011332270223647356
      grad_gnorm: 0.0501563660800457
      policy_entropy: 0.0013440347975119948
      policy_loss: 4.0773858955844844e-08
      var_gnorm: 27.96086883544922
      vf_explained_var: 0.0
      vf_loss: 1.6550870896026026e-06
    num_steps_sampled: 3410000
    num_steps_trained: 3410000
    wait_time_ms: 68.277
  iterations_since_restore: 682
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 5835.3810222148895
  time_this_iter_s: 8.189891815185547
  time_total_s: 5835.3810222148895
  timestamp: 1594864157
  timesteps_since_restore: 3410000
  timesteps_this_iter: 5000
  timesteps_total: 3410000
  training_iteration: 682
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 23.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 5835 s, 682 iter, 3410000 ts, -205 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-49-25
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -205.44395168875616
  episode_reward_min: -20544.395168875617
  episodes_this_iter: 1
  episodes_total: 682
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 3.052
    dispatch_time_ms: 8.035
    learner:
      cur_lr: 0.0011328939581289887
      grad_gnorm: 0.1991758495569229
      policy_entropy: 0.0013503768714144826
      policy_loss: 2.0034480030517443e-07
      var_gnorm: 27.960861206054688
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 2.6108429665328003e-05
    num_steps_sampled: 3415000
    num_steps_trained: 3415000
    wait_time_ms: 70.995
  iterations_since_restore: 683
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 5843.462463617325
  time_this_iter_s: 8.081441402435303
  time_total_s: 5843.462463617325
  timestamp: 1594864165
  timesteps_since_restore: 3415000
  timesteps_this_iter: 5000
  timesteps_total: 3415000
  training_iteration: 683
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 23.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 5843 s, 683 iter, 3415000 ts, -205 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
W0715 21:49:29.463297  8997 client_connection.cc:255] [worker]ProcessMessage with type 8 took 118 ms.
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-49-33
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -205.44395168875616
  episode_reward_min: -20544.395168875617
  episodes_this_iter: 1
  episodes_total: 683
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.77
    dispatch_time_ms: 10.841
    learner:
      cur_lr: 0.0011325610103085637
      grad_gnorm: 0.030315740033984184
      policy_entropy: 0.0013576411874964833
      policy_loss: 4.7552419779606225e-09
      var_gnorm: 27.960857391357422
      vf_explained_var: 0.0
      vf_loss: 6.043104008313094e-07
    num_steps_sampled: 3420000
    num_steps_trained: 3420000
    wait_time_ms: 67.642
  iterations_since_restore: 684
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 5851.574804067612
  time_this_iter_s: 8.112340450286865
  time_total_s: 5851.574804067612
  timestamp: 1594864173
  timesteps_since_restore: 3420000
  timesteps_this_iter: 5000
  timesteps_total: 3420000
  training_iteration: 684
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 23.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 5851 s, 684 iter, 3420000 ts, -205 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-49-41
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -205.44395168875616
  episode_reward_min: -20544.395168875617
  episodes_this_iter: 1
  episodes_total: 684
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 4.434
    dispatch_time_ms: 8.228
    learner:
      cur_lr: 0.0011322279460728168
      grad_gnorm: 0.24878820776939392
      policy_entropy: 0.0013647114392369986
      policy_loss: 1.73739948650109e-07
      var_gnorm: 27.960847854614258
      vf_explained_var: 0.0
      vf_loss: 4.076064578839578e-05
    num_steps_sampled: 3425000
    num_steps_trained: 3425000
    wait_time_ms: 68.738
  iterations_since_restore: 685
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 5859.696639537811
  time_this_iter_s: 8.121835470199585
  time_total_s: 5859.696639537811
  timestamp: 1594864181
  timesteps_since_restore: 3425000
  timesteps_this_iter: 5000
  timesteps_total: 3425000
  training_iteration: 685
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 23.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 5859 s, 685 iter, 3425000 ts, -205 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-49-49
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -205.44395168875616
  episode_reward_min: -20544.395168875617
  episodes_this_iter: 1
  episodes_total: 685
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 3.616
    dispatch_time_ms: 8.074
    learner:
      cur_lr: 0.0011318949982523918
      grad_gnorm: 0.07923538982868195
      policy_entropy: 0.0013725868193432689
      policy_loss: -6.825648490860203e-09
      var_gnorm: 27.960847854614258
      vf_explained_var: 0.0
      vf_loss: 4.132982667215401e-06
    num_steps_sampled: 3430000
    num_steps_trained: 3430000
    wait_time_ms: 73.826
  iterations_since_restore: 686
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 5867.813365936279
  time_this_iter_s: 8.116726398468018
  time_total_s: 5867.813365936279
  timestamp: 1594864189
  timesteps_since_restore: 3430000
  timesteps_this_iter: 5000
  timesteps_total: 3430000
  training_iteration: 686
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 23.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 5867 s, 686 iter, 3430000 ts, -205 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-49-58
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -205.44395168875616
  episode_reward_min: -20544.395168875617
  episodes_this_iter: 1
  episodes_total: 686
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 3.78
    dispatch_time_ms: 8.125
    learner:
      cur_lr: 0.0011315620504319668
      grad_gnorm: 0.10745376348495483
      policy_entropy: 0.001380613655783236
      policy_loss: 2.6407369091430155e-07
      var_gnorm: 27.96084213256836
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 7.5999773798685055e-06
    num_steps_sampled: 3435000
    num_steps_trained: 3435000
    wait_time_ms: 70.45
  iterations_since_restore: 687
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 5875.890386581421
  time_this_iter_s: 8.077020645141602
  time_total_s: 5875.890386581421
  timestamp: 1594864198
  timesteps_since_restore: 3435000
  timesteps_this_iter: 5000
  timesteps_total: 3435000
  training_iteration: 687
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 23.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 5875 s, 687 iter, 3435000 ts, -205 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-50-14
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -205.44395168875616
  episode_reward_min: -20544.395168875617
  episodes_this_iter: 1
  episodes_total: 687
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.764
    dispatch_time_ms: 7.42
    learner:
      cur_lr: 0.00113122898619622
      grad_gnorm: 0.9770004153251648
      policy_entropy: 0.0013890533009544015
      policy_loss: -2.3696408391060686e-07
      var_gnorm: 27.960851669311523
      vf_explained_var: 5.960464477539063e-08
      vf_loss: 0.0006286381976678967
    num_steps_sampled: 3440000
    num_steps_trained: 3440000
    wait_time_ms: 73.427
  iterations_since_restore: 688
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 5892.701943635941
  time_this_iter_s: 16.811557054519653
  time_total_s: 5892.701943635941
  timestamp: 1594864214
  timesteps_since_restore: 3440000
  timesteps_this_iter: 5000
  timesteps_total: 3440000
  training_iteration: 688
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 23.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 5892 s, 688 iter, 3440000 ts, -205 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-50-23
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -205.44395168875616
  episode_reward_min: -20544.395168875617
  episodes_this_iter: 1
  episodes_total: 688
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 3.027
    dispatch_time_ms: 7.285
    learner:
      cur_lr: 0.0011308960383757949
      grad_gnorm: 0.303404837846756
      policy_entropy: 0.0013982300879433751
      policy_loss: 1.3218918581969774e-07
      var_gnorm: 27.960840225219727
      vf_explained_var: 0.0
      vf_loss: 6.05902387178503e-05
    num_steps_sampled: 3445000
    num_steps_trained: 3445000
    wait_time_ms: 71.391
  iterations_since_restore: 689
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 5900.816880702972
  time_this_iter_s: 8.11493706703186
  time_total_s: 5900.816880702972
  timestamp: 1594864223
  timesteps_since_restore: 3445000
  timesteps_this_iter: 5000
  timesteps_total: 3445000
  training_iteration: 689
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 23.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 5900 s, 689 iter, 3445000 ts, -205 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-50-31
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -205.44395168875616
  episode_reward_min: -20544.395168875617
  episodes_this_iter: 1
  episodes_total: 689
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.557
    dispatch_time_ms: 8.057
    learner:
      cur_lr: 0.001130562974140048
      grad_gnorm: 0.007784095127135515
      policy_entropy: 0.001408001291565597
      policy_loss: 1.8950132574246936e-09
      var_gnorm: 27.960847854614258
      vf_explained_var: 0.0
      vf_loss: 3.97880484115376e-08
    num_steps_sampled: 3450000
    num_steps_trained: 3450000
    wait_time_ms: 69.738
  iterations_since_restore: 690
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 5908.914733171463
  time_this_iter_s: 8.0978524684906
  time_total_s: 5908.914733171463
  timestamp: 1594864231
  timesteps_since_restore: 3450000
  timesteps_this_iter: 5000
  timesteps_total: 3450000
  training_iteration: 690
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 23.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 5908 s, 690 iter, 3450000 ts, -205 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-50-39
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -205.44395168875616
  episode_reward_min: -20544.395168875617
  episodes_this_iter: 1
  episodes_total: 690
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 3.083
    dispatch_time_ms: 7.624
    learner:
      cur_lr: 0.001130230026319623
      grad_gnorm: 0.05945759266614914
      policy_entropy: 0.0014244100311771035
      policy_loss: 1.4794247249483305e-07
      var_gnorm: 27.960851669311523
      vf_explained_var: 0.0
      vf_loss: 2.334680630156072e-06
    num_steps_sampled: 3455000
    num_steps_trained: 3455000
    wait_time_ms: 72.779
  iterations_since_restore: 691
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 5916.995917081833
  time_this_iter_s: 8.081183910369873
  time_total_s: 5916.995917081833
  timestamp: 1594864239
  timesteps_since_restore: 3455000
  timesteps_this_iter: 5000
  timesteps_total: 3455000
  training_iteration: 691
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 23.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 5916 s, 691 iter, 3455000 ts, -205 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-50-47
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -205.44395168875616
  episode_reward_min: -20544.395168875617
  episodes_this_iter: 1
  episodes_total: 691
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.738
    dispatch_time_ms: 7.534
    learner:
      cur_lr: 0.0011298969620838761
      grad_gnorm: 0.033797647804021835
      policy_entropy: 0.0014357247855514288
      policy_loss: 2.6074056691527403e-08
      var_gnorm: 27.960857391357422
      vf_explained_var: 0.0
      vf_loss: 7.536210659964127e-07
    num_steps_sampled: 3460000
    num_steps_trained: 3460000
    wait_time_ms: 72.17
  iterations_since_restore: 692
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 5925.172198295593
  time_this_iter_s: 8.176281213760376
  time_total_s: 5925.172198295593
  timestamp: 1594864247
  timesteps_since_restore: 3460000
  timesteps_this_iter: 5000
  timesteps_total: 3460000
  training_iteration: 692
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 23.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 5925 s, 692 iter, 3460000 ts, -205 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-50-55
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -205.44395168875616
  episode_reward_min: -20544.395168875617
  episodes_this_iter: 1
  episodes_total: 692
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.737
    dispatch_time_ms: 6.685
    learner:
      cur_lr: 0.001129564014263451
      grad_gnorm: 0.005396212451159954
      policy_entropy: 0.0014475786592811346
      policy_loss: 2.7030930027649447e-07
      var_gnorm: 27.960865020751953
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 1.9021898722826336e-08
    num_steps_sampled: 3465000
    num_steps_trained: 3465000
    wait_time_ms: 70.6
  iterations_since_restore: 693
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 5933.264225482941
  time_this_iter_s: 8.092027187347412
  time_total_s: 5933.264225482941
  timestamp: 1594864255
  timesteps_since_restore: 3465000
  timesteps_this_iter: 5000
  timesteps_total: 3465000
  training_iteration: 693
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 23.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 5933 s, 693 iter, 3465000 ts, -205 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-51-03
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -205.44395168875616
  episode_reward_min: -20544.395168875617
  episodes_this_iter: 1
  episodes_total: 693
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.481
    dispatch_time_ms: 7.107
    learner:
      cur_lr: 0.0011292309500277042
      grad_gnorm: 0.01801757514476776
      policy_entropy: 0.0014603208983317018
      policy_loss: 1.8245881250322782e-08
      var_gnorm: 27.960872650146484
      vf_explained_var: 0.0
      vf_loss: 2.1453942622429167e-07
    num_steps_sampled: 3470000
    num_steps_trained: 3470000
    wait_time_ms: 75.351
  iterations_since_restore: 694
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 5941.477392435074
  time_this_iter_s: 8.213166952133179
  time_total_s: 5941.477392435074
  timestamp: 1594864263
  timesteps_since_restore: 3470000
  timesteps_this_iter: 5000
  timesteps_total: 3470000
  training_iteration: 694
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 23.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 5941 s, 694 iter, 3470000 ts, -205 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-51-12
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -205.44395168875616
  episode_reward_min: -20544.395168875617
  episodes_this_iter: 1
  episodes_total: 694
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.504
    dispatch_time_ms: 9.687
    learner:
      cur_lr: 0.0011288980022072792
      grad_gnorm: 0.2036236673593521
      policy_entropy: 0.0014739084290340543
      policy_loss: 3.093525791086904e-08
      var_gnorm: 27.96088218688965
      vf_explained_var: 1.1920928955078125e-07
      vf_loss: 2.7313997634337284e-05
    num_steps_sampled: 3475000
    num_steps_trained: 3475000
    wait_time_ms: 69.48
  iterations_since_restore: 695
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 5949.647868394852
  time_this_iter_s: 8.170475959777832
  time_total_s: 5949.647868394852
  timestamp: 1594864272
  timesteps_since_restore: 3475000
  timesteps_this_iter: 5000
  timesteps_total: 3475000
  training_iteration: 695
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 23.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 5949 s, 695 iter, 3475000 ts, -205 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-51-20
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -205.44395168875616
  episode_reward_min: -20544.395168875617
  episodes_this_iter: 1
  episodes_total: 695
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.746
    dispatch_time_ms: 7.084
    learner:
      cur_lr: 0.0011285650543868542
      grad_gnorm: 0.004396014381200075
      policy_entropy: 0.0014885240234434605
      policy_loss: 2.0349779639161625e-09
      var_gnorm: 27.960887908935547
      vf_explained_var: 5.960464477539063e-08
      vf_loss: 1.2981892005825557e-08
    num_steps_sampled: 3480000
    num_steps_trained: 3480000
    wait_time_ms: 70.459
  iterations_since_restore: 696
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 5957.706518173218
  time_this_iter_s: 8.058649778366089
  time_total_s: 5957.706518173218
  timestamp: 1594864280
  timesteps_since_restore: 3480000
  timesteps_this_iter: 5000
  timesteps_total: 3480000
  training_iteration: 696
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 21.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 5957 s, 696 iter, 3480000 ts, -205 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-51-28
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -205.44395168875616
  episode_reward_min: -20544.395168875617
  episodes_this_iter: 1
  episodes_total: 696
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.784
    dispatch_time_ms: 7.621
    learner:
      cur_lr: 0.0011282319901511073
      grad_gnorm: 0.27148351073265076
      policy_entropy: 0.0015098165022209287
      policy_loss: -1.330666350440879e-07
      var_gnorm: 27.960901260375977
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 4.851679113926366e-05
    num_steps_sampled: 3485000
    num_steps_trained: 3485000
    wait_time_ms: 70.028
  iterations_since_restore: 697
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 5965.706274986267
  time_this_iter_s: 7.999756813049316
  time_total_s: 5965.706274986267
  timestamp: 1594864288
  timesteps_since_restore: 3485000
  timesteps_this_iter: 5000
  timesteps_total: 3485000
  training_iteration: 697
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 21.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 5965 s, 697 iter, 3485000 ts, -205 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-51-36
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -205.44395168875616
  episode_reward_min: -20544.395168875617
  episodes_this_iter: 1
  episodes_total: 697
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 3.613
    dispatch_time_ms: 7.075
    learner:
      cur_lr: 0.0011278990423306823
      grad_gnorm: 0.010552036575973034
      policy_entropy: 0.0015269162831827998
      policy_loss: 9.36676070040221e-09
      var_gnorm: 27.960901260375977
      vf_explained_var: 0.0
      vf_loss: 7.362152842915748e-08
    num_steps_sampled: 3490000
    num_steps_trained: 3490000
    wait_time_ms: 70.505
  iterations_since_restore: 698
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 5973.837978839874
  time_this_iter_s: 8.131703853607178
  time_total_s: 5973.837978839874
  timestamp: 1594864296
  timesteps_since_restore: 3490000
  timesteps_this_iter: 5000
  timesteps_total: 3490000
  training_iteration: 698
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 21.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 5973 s, 698 iter, 3490000 ts, -205 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-51-44
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -205.44395168875616
  episode_reward_min: -20544.395168875617
  episodes_this_iter: 1
  episodes_total: 698
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 3.054
    dispatch_time_ms: 6.683
    learner:
      cur_lr: 0.0011275659780949354
      grad_gnorm: 0.40500375628471375
      policy_entropy: 0.001545171719044447
      policy_loss: -1.498547419487295e-07
      var_gnorm: 27.96091079711914
      vf_explained_var: 1.1920928955078125e-07
      vf_loss: 0.00010798060975503176
    num_steps_sampled: 3495000
    num_steps_trained: 3495000
    wait_time_ms: 68.199
  iterations_since_restore: 699
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 5981.959120512009
  time_this_iter_s: 8.1211416721344
  time_total_s: 5981.959120512009
  timestamp: 1594864304
  timesteps_since_restore: 3495000
  timesteps_this_iter: 5000
  timesteps_total: 3495000
  training_iteration: 699
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 21.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 5981 s, 699 iter, 3495000 ts, -205 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-51-52
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -205.44395168875616
  episode_reward_min: -20544.395168875617
  episodes_this_iter: 1
  episodes_total: 699
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.65
    dispatch_time_ms: 9.005
    learner:
      cur_lr: 0.0011272330302745104
      grad_gnorm: 0.06936685740947723
      policy_entropy: 0.0015653575537726283
      policy_loss: -3.399991754804432e-08
      var_gnorm: 27.960912704467773
      vf_explained_var: 0.0
      vf_loss: 3.169449655615608e-06
    num_steps_sampled: 3500000
    num_steps_trained: 3500000
    wait_time_ms: 73.153
  iterations_since_restore: 700
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 5990.189870357513
  time_this_iter_s: 8.23074984550476
  time_total_s: 5990.189870357513
  timestamp: 1594864312
  timesteps_since_restore: 3500000
  timesteps_this_iter: 5000
  timesteps_total: 3500000
  training_iteration: 700
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 21.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 5990 s, 700 iter, 3500000 ts, -205 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-52-00
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -205.44395168875616
  episode_reward_min: -20544.395168875617
  episodes_this_iter: 1
  episodes_total: 700
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 3.652
    dispatch_time_ms: 7.345
    learner:
      cur_lr: 0.0011268999660387635
      grad_gnorm: 0.43572497367858887
      policy_entropy: 0.0015924321487545967
      policy_loss: -2.50749053520849e-07
      var_gnorm: 27.960918426513672
      vf_explained_var: 0.0
      vf_loss: 0.00012499207514338195
    num_steps_sampled: 3505000
    num_steps_trained: 3505000
    wait_time_ms: 68.127
  iterations_since_restore: 701
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 5998.280171632767
  time_this_iter_s: 8.090301275253296
  time_total_s: 5998.280171632767
  timestamp: 1594864320
  timesteps_since_restore: 3505000
  timesteps_this_iter: 5000
  timesteps_total: 3505000
  training_iteration: 701
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 21.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 5998 s, 701 iter, 3505000 ts, -205 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-52-09
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -205.44395168875616
  episode_reward_min: -20544.395168875617
  episodes_this_iter: 1
  episodes_total: 701
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.577
    dispatch_time_ms: 8.44
    learner:
      cur_lr: 0.0011265670182183385
      grad_gnorm: 0.009011476300656796
      policy_entropy: 0.0016160630621016026
      policy_loss: 5.635023825334429e-08
      var_gnorm: 27.960920333862305
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 5.386214851910154e-08
    num_steps_sampled: 3510000
    num_steps_trained: 3510000
    wait_time_ms: 70.935
  iterations_since_restore: 702
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 6006.427509069443
  time_this_iter_s: 8.147337436676025
  time_total_s: 6006.427509069443
  timestamp: 1594864329
  timesteps_since_restore: 3510000
  timesteps_this_iter: 5000
  timesteps_total: 3510000
  training_iteration: 702
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 21.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 6006 s, 702 iter, 3510000 ts, -205 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-52-17
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -205.44395168875616
  episode_reward_min: -20544.395168875617
  episodes_this_iter: 1
  episodes_total: 702
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.779
    dispatch_time_ms: 9.392
    learner:
      cur_lr: 0.0011262339539825916
      grad_gnorm: 0.2906450927257538
      policy_entropy: 0.0016405399655923247
      policy_loss: -2.6260977392666973e-07
      var_gnorm: 27.960933685302734
      vf_explained_var: 0.0
      vf_loss: 5.562082151300274e-05
    num_steps_sampled: 3515000
    num_steps_trained: 3515000
    wait_time_ms: 69.642
  iterations_since_restore: 703
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 6014.552924633026
  time_this_iter_s: 8.125415563583374
  time_total_s: 6014.552924633026
  timestamp: 1594864337
  timesteps_since_restore: 3515000
  timesteps_this_iter: 5000
  timesteps_total: 3515000
  training_iteration: 703
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 21.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 6014 s, 703 iter, 3515000 ts, -205 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-52-25
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -205.44395168875616
  episode_reward_min: -20544.395168875617
  episodes_this_iter: 1
  episodes_total: 703
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.77
    dispatch_time_ms: 7.09
    learner:
      cur_lr: 0.0011259010061621666
      grad_gnorm: 0.27225345373153687
      policy_entropy: 0.0016733765369281173
      policy_loss: 1.482711979861051e-07
      var_gnorm: 27.960935592651367
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 4.882739085587673e-05
    num_steps_sampled: 3520000
    num_steps_trained: 3520000
    wait_time_ms: 71.638
  iterations_since_restore: 704
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 6022.691958189011
  time_this_iter_s: 8.139033555984497
  time_total_s: 6022.691958189011
  timestamp: 1594864345
  timesteps_since_restore: 3520000
  timesteps_this_iter: 5000
  timesteps_total: 3520000
  training_iteration: 704
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 21.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 6022 s, 704 iter, 3520000 ts, -205 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-52-33
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -205.44395168875616
  episode_reward_min: -20544.395168875617
  episodes_this_iter: 1
  episodes_total: 704
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.828
    dispatch_time_ms: 8.707
    learner:
      cur_lr: 0.0011255679419264197
      grad_gnorm: 0.10314703732728958
      policy_entropy: 0.0017034385818988085
      policy_loss: -3.4246781410729454e-07
      var_gnorm: 27.96095085144043
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 7.008738975855522e-06
    num_steps_sampled: 3525000
    num_steps_trained: 3525000
    wait_time_ms: 69.919
  iterations_since_restore: 705
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 6030.835183620453
  time_this_iter_s: 8.14322543144226
  time_total_s: 6030.835183620453
  timestamp: 1594864353
  timesteps_since_restore: 3525000
  timesteps_this_iter: 5000
  timesteps_total: 3525000
  training_iteration: 705
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 21.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 6030 s, 705 iter, 3525000 ts, -205 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-52-41
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -205.44395168875616
  episode_reward_min: -20544.395168875617
  episodes_this_iter: 1
  episodes_total: 705
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 3.13
    dispatch_time_ms: 8.874
    learner:
      cur_lr: 0.0011252349941059947
      grad_gnorm: 0.2808481752872467
      policy_entropy: 0.0017368780681863427
      policy_loss: -4.5158802208788984e-07
      var_gnorm: 27.960960388183594
      vf_explained_var: 0.0
      vf_loss: 5.194628829485737e-05
    num_steps_sampled: 3530000
    num_steps_trained: 3530000
    wait_time_ms: 69.683
  iterations_since_restore: 706
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 6038.875905275345
  time_this_iter_s: 8.040721654891968
  time_total_s: 6038.875905275345
  timestamp: 1594864361
  timesteps_since_restore: 3530000
  timesteps_this_iter: 5000
  timesteps_total: 3530000
  training_iteration: 706
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 21.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 6038 s, 706 iter, 3530000 ts, -205 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-52-49
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -205.44395168875616
  episode_reward_min: -20544.395168875617
  episodes_this_iter: 1
  episodes_total: 706
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.923
    dispatch_time_ms: 7.49
    learner:
      cur_lr: 0.0011249020462855697
      grad_gnorm: 0.10689669102430344
      policy_entropy: 0.001773414551280439
      policy_loss: -1.168215320035415e-07
      var_gnorm: 27.960979461669922
      vf_explained_var: 0.0
      vf_loss: 7.528989954153076e-06
    num_steps_sampled: 3535000
    num_steps_trained: 3535000
    wait_time_ms: 71.999
  iterations_since_restore: 707
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 6047.025520324707
  time_this_iter_s: 8.149615049362183
  time_total_s: 6047.025520324707
  timestamp: 1594864369
  timesteps_since_restore: 3535000
  timesteps_this_iter: 5000
  timesteps_total: 3535000
  training_iteration: 707
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 21.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 6047 s, 707 iter, 3535000 ts, -205 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-52-58
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -205.44395168875616
  episode_reward_min: -20544.395168875617
  episodes_this_iter: 1
  episodes_total: 707
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.686
    dispatch_time_ms: 15.524
    learner:
      cur_lr: 0.0011245689820498228
      grad_gnorm: 0.031172314658761024
      policy_entropy: 0.0018177333986386657
      policy_loss: 1.5026226662939735e-07
      var_gnorm: 27.960996627807617
      vf_explained_var: 0.0
      vf_loss: 6.38524340956792e-07
    num_steps_sampled: 3540000
    num_steps_trained: 3540000
    wait_time_ms: 69.361
  iterations_since_restore: 708
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 6055.356484413147
  time_this_iter_s: 8.330964088439941
  time_total_s: 6055.356484413147
  timestamp: 1594864378
  timesteps_since_restore: 3540000
  timesteps_this_iter: 5000
  timesteps_total: 3540000
  training_iteration: 708
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 21.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 6055 s, 708 iter, 3540000 ts, -205 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-53-06
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -205.44395168875616
  episode_reward_min: -20544.395168875617
  episodes_this_iter: 1
  episodes_total: 708
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.749
    dispatch_time_ms: 14.214
    learner:
      cur_lr: 0.0011242360342293978
      grad_gnorm: 0.10205631703138351
      policy_entropy: 0.0018591014668345451
      policy_loss: -9.893967671814607e-07
      var_gnorm: 27.961017608642578
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 6.8511353674693964e-06
    num_steps_sampled: 3545000
    num_steps_trained: 3545000
    wait_time_ms: 66.679
  iterations_since_restore: 709
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 6063.795506477356
  time_this_iter_s: 8.439022064208984
  time_total_s: 6063.795506477356
  timestamp: 1594864386
  timesteps_since_restore: 3545000
  timesteps_this_iter: 5000
  timesteps_total: 3545000
  training_iteration: 709
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 21.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 6063 s, 709 iter, 3545000 ts, -205 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-53-15
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -205.44395168875616
  episode_reward_min: -20544.395168875617
  episodes_this_iter: 1
  episodes_total: 709
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.552
    dispatch_time_ms: 27.428
    learner:
      cur_lr: 0.001123902969993651
      grad_gnorm: 4.220853328704834
      policy_entropy: 0.0019152737222611904
      policy_loss: 4.156754940254359e-08
      var_gnorm: 27.961042404174805
      vf_explained_var: -2.384185791015625e-07
      vf_loss: 0.009296422824263573
    num_steps_sampled: 3550000
    num_steps_trained: 3550000
    wait_time_ms: 59.353
  iterations_since_restore: 710
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 6072.594232082367
  time_this_iter_s: 8.798725605010986
  time_total_s: 6072.594232082367
  timestamp: 1594864395
  timesteps_since_restore: 3550000
  timesteps_this_iter: 5000
  timesteps_total: 3550000
  training_iteration: 710
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 21.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 6072 s, 710 iter, 3550000 ts, -205 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-53-24
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -205.44395168875616
  episode_reward_min: -20544.395168875617
  episodes_this_iter: 1
  episodes_total: 710
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 3.203
    dispatch_time_ms: 41.153
    learner:
      cur_lr: 0.0011235700221732259
      grad_gnorm: 1.8796998262405396
      policy_entropy: 0.0019711863715201616
      policy_loss: -5.252563369140262e-06
      var_gnorm: 27.961091995239258
      vf_explained_var: 0.0
      vf_loss: 0.0023265692871063948
    num_steps_sampled: 3555000
    num_steps_trained: 3555000
    wait_time_ms: 56.807
  iterations_since_restore: 711
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 6081.405128240585
  time_this_iter_s: 8.810896158218384
  time_total_s: 6081.405128240585
  timestamp: 1594864404
  timesteps_since_restore: 3555000
  timesteps_this_iter: 5000
  timesteps_total: 3555000
  training_iteration: 711
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 21.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 6081 s, 711 iter, 3555000 ts, -205 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-53-33
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -205.44395168875616
  episode_reward_min: -20544.395168875617
  episodes_this_iter: 1
  episodes_total: 711
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.739
    dispatch_time_ms: 19.641
    learner:
      cur_lr: 0.001123236957937479
      grad_gnorm: 0.04313666746020317
      policy_entropy: 0.0020680315792560577
      policy_loss: -1.35053369376692e-07
      var_gnorm: 27.961103439331055
      vf_explained_var: 0.0
      vf_loss: 1.2271336800040444e-06
    num_steps_sampled: 3560000
    num_steps_trained: 3560000
    wait_time_ms: 69.695
  iterations_since_restore: 712
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 6090.062425136566
  time_this_iter_s: 8.657296895980835
  time_total_s: 6090.062425136566
  timestamp: 1594864413
  timesteps_since_restore: 3560000
  timesteps_this_iter: 5000
  timesteps_total: 3560000
  training_iteration: 712
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 21.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 6090 s, 712 iter, 3560000 ts, -205 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-53-41
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -205.44395168875616
  episode_reward_min: -20544.395168875617
  episodes_this_iter: 1
  episodes_total: 712
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 3.183
    dispatch_time_ms: 19.203
    learner:
      cur_lr: 0.001122904010117054
      grad_gnorm: 0.009463313035666943
      policy_entropy: 0.002139314543455839
      policy_loss: -3.508147869979439e-07
      var_gnorm: 27.961137771606445
      vf_explained_var: 0.0
      vf_loss: 5.8834860539036526e-08
    num_steps_sampled: 3565000
    num_steps_trained: 3565000
    wait_time_ms: 68.267
  iterations_since_restore: 713
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 6098.818132162094
  time_this_iter_s: 8.755707025527954
  time_total_s: 6098.818132162094
  timestamp: 1594864421
  timesteps_since_restore: 3565000
  timesteps_this_iter: 5000
  timesteps_total: 3565000
  training_iteration: 713
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 21.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 6098 s, 713 iter, 3565000 ts, -205 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-53-50
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -205.44395168875616
  episode_reward_min: -20544.395168875617
  episodes_this_iter: 1
  episodes_total: 713
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.612
    dispatch_time_ms: 22.96
    learner:
      cur_lr: 0.0011225709458813071
      grad_gnorm: 0.06375396251678467
      policy_entropy: 0.002220477443188429
      policy_loss: 1.4304238682427695e-08
      var_gnorm: 27.961172103881836
      vf_explained_var: 0.0
      vf_loss: 2.6746263301902218e-06
    num_steps_sampled: 3570000
    num_steps_trained: 3570000
    wait_time_ms: 64.09
  iterations_since_restore: 714
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 6107.440140008926
  time_this_iter_s: 8.622007846832275
  time_total_s: 6107.440140008926
  timestamp: 1594864430
  timesteps_since_restore: 3570000
  timesteps_this_iter: 5000
  timesteps_total: 3570000
  training_iteration: 714
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 21.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 6107 s, 714 iter, 3570000 ts, -205 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-53-59
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -205.44395168875616
  episode_reward_min: -20544.395168875617
  episodes_this_iter: 1
  episodes_total: 714
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 3.138
    dispatch_time_ms: 25.825
    learner:
      cur_lr: 0.001122237998060882
      grad_gnorm: 0.19486777484416962
      policy_entropy: 0.002312988042831421
      policy_loss: 1.2083538649676484e-06
      var_gnorm: 27.961206436157227
      vf_explained_var: 0.0
      vf_loss: 2.4999268134706654e-05
    num_steps_sampled: 3575000
    num_steps_trained: 3575000
    wait_time_ms: 66.126
  iterations_since_restore: 715
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 6116.13059091568
  time_this_iter_s: 8.69045090675354
  time_total_s: 6116.13059091568
  timestamp: 1594864439
  timesteps_since_restore: 3575000
  timesteps_this_iter: 5000
  timesteps_total: 3575000
  training_iteration: 715
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 21.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 6116 s, 715 iter, 3575000 ts, -205 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-54-15
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -205.44395168875616
  episode_reward_min: -20544.395168875617
  episodes_this_iter: 1
  episodes_total: 715
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 3.533
    dispatch_time_ms: 7.536
    learner:
      cur_lr: 0.001121905050240457
      grad_gnorm: 0.22368201613426208
      policy_entropy: 0.0023895911872386932
      policy_loss: 1.5732064184703631e-06
      var_gnorm: 27.961244583129883
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 3.292713518021628e-05
    num_steps_sampled: 3580000
    num_steps_trained: 3580000
    wait_time_ms: 70.138
  iterations_since_restore: 716
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 6132.286864519119
  time_this_iter_s: 16.15627360343933
  time_total_s: 6132.286864519119
  timestamp: 1594864455
  timesteps_since_restore: 3580000
  timesteps_this_iter: 5000
  timesteps_total: 3580000
  training_iteration: 716
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 21.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 6132 s, 716 iter, 3580000 ts, -205 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-54-23
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -205.44395168875616
  episode_reward_min: -20544.395168875617
  episodes_this_iter: 1
  episodes_total: 716
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.814
    dispatch_time_ms: 6.174
    learner:
      cur_lr: 0.0011215719860047102
      grad_gnorm: 0.05509554594755173
      policy_entropy: 0.0024815404321998358
      policy_loss: -7.258402234811001e-08
      var_gnorm: 27.961294174194336
      vf_explained_var: 1.1920928955078125e-07
      vf_loss: 1.9988349322375143e-06
    num_steps_sampled: 3585000
    num_steps_trained: 3585000
    wait_time_ms: 75.792
  iterations_since_restore: 717
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 6140.379086732864
  time_this_iter_s: 8.092222213745117
  time_total_s: 6140.379086732864
  timestamp: 1594864463
  timesteps_since_restore: 3585000
  timesteps_this_iter: 5000
  timesteps_total: 3585000
  training_iteration: 717
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 21.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 6140 s, 717 iter, 3585000 ts, -205 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-54-31
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -205.44395168875616
  episode_reward_min: -20544.395168875617
  episodes_this_iter: 1
  episodes_total: 717
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.963
    dispatch_time_ms: 7.809
    learner:
      cur_lr: 0.0011212390381842852
      grad_gnorm: 0.05068587511777878
      policy_entropy: 0.0026195559184998274
      policy_loss: -3.2160315299734066e-08
      var_gnorm: 27.961341857910156
      vf_explained_var: 0.0
      vf_loss: 1.6909560827116366e-06
    num_steps_sampled: 3590000
    num_steps_trained: 3590000
    wait_time_ms: 69.321
  iterations_since_restore: 718
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 6148.486685037613
  time_this_iter_s: 8.107598304748535
  time_total_s: 6148.486685037613
  timestamp: 1594864471
  timesteps_since_restore: 3590000
  timesteps_this_iter: 5000
  timesteps_total: 3590000
  training_iteration: 718
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 21.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 6148 s, 718 iter, 3590000 ts, -205 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-54-39
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -205.44395168875616
  episode_reward_min: -20544.395168875617
  episodes_this_iter: 1
  episodes_total: 718
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.621
    dispatch_time_ms: 6.062
    learner:
      cur_lr: 0.0011209059739485383
      grad_gnorm: 0.12235081940889359
      policy_entropy: 0.0027776933275163174
      policy_loss: 7.271179214285439e-08
      var_gnorm: 27.961395263671875
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 9.862538718152791e-06
    num_steps_sampled: 3595000
    num_steps_trained: 3595000
    wait_time_ms: 76.726
  iterations_since_restore: 719
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 6156.620097398758
  time_this_iter_s: 8.13341236114502
  time_total_s: 6156.620097398758
  timestamp: 1594864479
  timesteps_since_restore: 3595000
  timesteps_this_iter: 5000
  timesteps_total: 3595000
  training_iteration: 719
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 21.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 6156 s, 719 iter, 3595000 ts, -205 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-54-47
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -205.44395168875616
  episode_reward_min: -20544.395168875617
  episodes_this_iter: 1
  episodes_total: 719
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.997
    dispatch_time_ms: 12.292
    learner:
      cur_lr: 0.0011205730261281133
      grad_gnorm: 0.08207406103610992
      policy_entropy: 0.0029681785963475704
      policy_loss: -4.585845303495262e-08
      var_gnorm: 27.96145248413086
      vf_explained_var: 1.1920928955078125e-07
      vf_loss: 4.434463789948495e-06
    num_steps_sampled: 3600000
    num_steps_trained: 3600000
    wait_time_ms: 66.568
  iterations_since_restore: 720
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 6164.645781755447
  time_this_iter_s: 8.025684356689453
  time_total_s: 6164.645781755447
  timestamp: 1594864487
  timesteps_since_restore: 3600000
  timesteps_this_iter: 5000
  timesteps_total: 3600000
  training_iteration: 720
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 21.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 6164 s, 720 iter, 3600000 ts, -205 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-54-56
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -205.44395168875616
  episode_reward_min: -20544.395168875617
  episodes_this_iter: 1
  episodes_total: 720
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.63
    dispatch_time_ms: 8.471
    learner:
      cur_lr: 0.0011202399618923664
      grad_gnorm: 0.10543777048587799
      policy_entropy: 0.003200528211891651
      policy_loss: 2.2016006084868422e-07
      var_gnorm: 27.96151351928711
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 7.315918082895223e-06
    num_steps_sampled: 3605000
    num_steps_trained: 3605000
    wait_time_ms: 76.143
  iterations_since_restore: 721
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 6172.794639825821
  time_this_iter_s: 8.148858070373535
  time_total_s: 6172.794639825821
  timestamp: 1594864496
  timesteps_since_restore: 3605000
  timesteps_this_iter: 5000
  timesteps_total: 3605000
  training_iteration: 721
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 21.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 6172 s, 721 iter, 3605000 ts, -205 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-55-04
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -205.44395168875616
  episode_reward_min: -20544.395168875617
  episodes_this_iter: 1
  episodes_total: 721
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 3.091
    dispatch_time_ms: 8.611
    learner:
      cur_lr: 0.0011199070140719414
      grad_gnorm: 0.09069860726594925
      policy_entropy: 0.0034707654267549515
      policy_loss: -9.437758308195043e-08
      var_gnorm: 27.961580276489258
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 5.418123237177497e-06
    num_steps_sampled: 3610000
    num_steps_trained: 3610000
    wait_time_ms: 71.979
  iterations_since_restore: 722
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 6181.0366241931915
  time_this_iter_s: 8.241984367370605
  time_total_s: 6181.0366241931915
  timestamp: 1594864504
  timesteps_since_restore: 3610000
  timesteps_this_iter: 5000
  timesteps_total: 3610000
  training_iteration: 722
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 22.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 6181 s, 722 iter, 3610000 ts, -205 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-55-12
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -205.44395168875616
  episode_reward_min: -20544.395168875617
  episodes_this_iter: 1
  episodes_total: 722
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.807
    dispatch_time_ms: 5.605
    learner:
      cur_lr: 0.0011195739498361945
      grad_gnorm: 0.053887173533439636
      policy_entropy: 0.0038208356127142906
      policy_loss: 2.3007821425835573e-07
      var_gnorm: 27.961650848388672
      vf_explained_var: 0.0
      vf_loss: 1.91288631867792e-06
    num_steps_sampled: 3615000
    num_steps_trained: 3615000
    wait_time_ms: 71.137
  iterations_since_restore: 723
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 6189.156433343887
  time_this_iter_s: 8.1198091506958
  time_total_s: 6189.156433343887
  timestamp: 1594864512
  timesteps_since_restore: 3615000
  timesteps_this_iter: 5000
  timesteps_total: 3615000
  training_iteration: 723
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 23.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 6189 s, 723 iter, 3615000 ts, -205 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-55-20
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -205.44395168875616
  episode_reward_min: -20544.395168875617
  episodes_this_iter: 1
  episodes_total: 723
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 3.461
    dispatch_time_ms: 7.799
    learner:
      cur_lr: 0.0011192410020157695
      grad_gnorm: 0.13476069271564484
      policy_entropy: 0.004266394302248955
      policy_loss: -2.433350516639621e-07
      var_gnorm: 27.96173095703125
      vf_explained_var: 0.0
      vf_loss: 1.1956407433899585e-05
    num_steps_sampled: 3620000
    num_steps_trained: 3620000
    wait_time_ms: 72.997
  iterations_since_restore: 724
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 6197.326731443405
  time_this_iter_s: 8.170298099517822
  time_total_s: 6197.326731443405
  timestamp: 1594864520
  timesteps_since_restore: 3620000
  timesteps_this_iter: 5000
  timesteps_total: 3620000
  training_iteration: 724
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 23.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 6197 s, 724 iter, 3620000 ts, -205 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-55-28
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -205.44395168875616
  episode_reward_min: -20544.395168875617
  episodes_this_iter: 1
  episodes_total: 724
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.505
    dispatch_time_ms: 5.574
    learner:
      cur_lr: 0.0011189080541953444
      grad_gnorm: 0.030296873301267624
      policy_entropy: 0.004865873139351606
      policy_loss: -5.279946080349873e-08
      var_gnorm: 27.961814880371094
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 6.039878712726932e-07
    num_steps_sampled: 3625000
    num_steps_trained: 3625000
    wait_time_ms: 74.544
  iterations_since_restore: 725
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 6205.512330055237
  time_this_iter_s: 8.185598611831665
  time_total_s: 6205.512330055237
  timestamp: 1594864528
  timesteps_since_restore: 3625000
  timesteps_this_iter: 5000
  timesteps_total: 3625000
  training_iteration: 725
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 6205 s, 725 iter, 3625000 ts, -205 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-55-37
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -205.44395168875616
  episode_reward_min: -20544.395168875617
  episodes_this_iter: 1
  episodes_total: 725
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.796
    dispatch_time_ms: 7.555
    learner:
      cur_lr: 0.0011185749899595976
      grad_gnorm: 0.08909661322832108
      policy_entropy: 0.005677633918821812
      policy_loss: -1.9502077464039758e-07
      var_gnorm: 27.96190643310547
      vf_explained_var: 5.960464477539063e-08
      vf_loss: 5.2271643653512e-06
    num_steps_sampled: 3630000
    num_steps_trained: 3630000
    wait_time_ms: 67.283
  iterations_since_restore: 726
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 6213.66268992424
  time_this_iter_s: 8.150359869003296
  time_total_s: 6213.66268992424
  timestamp: 1594864537
  timesteps_since_restore: 3630000
  timesteps_this_iter: 5000
  timesteps_total: 3630000
  training_iteration: 726
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 6213 s, 726 iter, 3630000 ts, -205 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-55-45
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -205.44395168875616
  episode_reward_min: -20544.395168875617
  episodes_this_iter: 1
  episodes_total: 726
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.787
    dispatch_time_ms: 6.507
    learner:
      cur_lr: 0.0011182420421391726
      grad_gnorm: 0.11440461128950119
      policy_entropy: 0.006909054704010487
      policy_loss: -2.8971942356292857e-07
      var_gnorm: 27.961999893188477
      vf_explained_var: 1.1920928955078125e-07
      vf_loss: 8.61521766637452e-06
    num_steps_sampled: 3635000
    num_steps_trained: 3635000
    wait_time_ms: 71.223
  iterations_since_restore: 727
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 6221.722273349762
  time_this_iter_s: 8.05958342552185
  time_total_s: 6221.722273349762
  timestamp: 1594864545
  timesteps_since_restore: 3635000
  timesteps_this_iter: 5000
  timesteps_total: 3635000
  training_iteration: 727
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 6221 s, 727 iter, 3635000 ts, -205 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-55-53
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -205.44395168875616
  episode_reward_min: -20544.395168875617
  episodes_this_iter: 1
  episodes_total: 727
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 3.078
    dispatch_time_ms: 7.195
    learner:
      cur_lr: 0.0011179089779034257
      grad_gnorm: 0.15787754952907562
      policy_entropy: 0.00892532616853714
      policy_loss: -5.944222607467964e-07
      var_gnorm: 27.96209716796875
      vf_explained_var: 0.0
      vf_loss: 1.6415122445323505e-05
    num_steps_sampled: 3640000
    num_steps_trained: 3640000
    wait_time_ms: 71.164
  iterations_since_restore: 728
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 6229.896706104279
  time_this_iter_s: 8.174432754516602
  time_total_s: 6229.896706104279
  timestamp: 1594864553
  timesteps_since_restore: 3640000
  timesteps_this_iter: 5000
  timesteps_total: 3640000
  training_iteration: 728
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 6229 s, 728 iter, 3640000 ts, -205 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-56-01
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -205.44395168875616
  episode_reward_min: -20544.395168875617
  episodes_this_iter: 1
  episodes_total: 728
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.704
    dispatch_time_ms: 9.238
    learner:
      cur_lr: 0.0011175760300830007
      grad_gnorm: 0.13480782508850098
      policy_entropy: 0.01259708683937788
      policy_loss: -7.411765636788914e-07
      var_gnorm: 27.96218490600586
      vf_explained_var: 0.0
      vf_loss: 1.1978241673205048e-05
    num_steps_sampled: 3645000
    num_steps_trained: 3645000
    wait_time_ms: 70.425
  iterations_since_restore: 729
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 6238.025433540344
  time_this_iter_s: 8.128727436065674
  time_total_s: 6238.025433540344
  timestamp: 1594864561
  timesteps_since_restore: 3645000
  timesteps_this_iter: 5000
  timesteps_total: 3645000
  training_iteration: 729
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 6238 s, 729 iter, 3645000 ts, -205 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-56-09
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -205.44395168875616
  episode_reward_min: -20544.395168875617
  episodes_this_iter: 1
  episodes_total: 729
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.452
    dispatch_time_ms: 5.854
    learner:
      cur_lr: 0.0011172429658472538
      grad_gnorm: 0.18702611327171326
      policy_entropy: 0.02241121605038643
      policy_loss: -5.136143954587169e-06
      var_gnorm: 27.962209701538086
      vf_explained_var: 1.1920928955078125e-07
      vf_loss: 2.3035510821500793e-05
    num_steps_sampled: 3650000
    num_steps_trained: 3650000
    wait_time_ms: 78.112
  iterations_since_restore: 730
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 6246.220673561096
  time_this_iter_s: 8.195240020751953
  time_total_s: 6246.220673561096
  timestamp: 1594864569
  timesteps_since_restore: 3650000
  timesteps_this_iter: 5000
  timesteps_total: 3650000
  training_iteration: 730
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 6246 s, 730 iter, 3650000 ts, -205 rew

agent-1: 0.0
agent-2: -148.72733674137223
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
-1
0
0
0
Sum Reward: -1
Avg Reward: -0.2
Min Reward: -1
Max Reward: 0
Gini Coefficient: -0.8
20:20 Ratio: -0.0
Max-min Ratio: -0.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-56-17
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -206.9312250561699
  episode_reward_min: -20544.395168875617
  episodes_this_iter: 1
  episodes_total: 730
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.376
    dispatch_time_ms: 8.914
    learner:
      cur_lr: 0.0011169100180268288
      grad_gnorm: 3.033468008041382
      policy_entropy: 0.0001751417585182935
      policy_loss: 1.6520495194072282e-07
      var_gnorm: 27.9805908203125
      vf_explained_var: 0.0
      vf_loss: 0.006059177685528994
    num_steps_sampled: 3655000
    num_steps_trained: 3655000
    wait_time_ms: 69.616
  iterations_since_restore: 731
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 6254.357171297073
  time_this_iter_s: 8.136497735977173
  time_total_s: 6254.357171297073
  timestamp: 1594864577
  timesteps_since_restore: 3655000
  timesteps_this_iter: 5000
  timesteps_total: 3655000
  training_iteration: 731
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 6254 s, 731 iter, 3655000 ts, -207 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-56-26
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -1.4872733674137222
  episode_reward_min: -148.72733674137223
  episodes_this_iter: 1
  episodes_total: 731
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 3.237
    dispatch_time_ms: 7.853
    learner:
      cur_lr: 0.001116576953791082
      grad_gnorm: 0.1472996026277542
      policy_entropy: 0.00017393111193086952
      policy_loss: -3.284534644265591e-09
      var_gnorm: 27.980836868286133
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 1.427879851689795e-05
    num_steps_sampled: 3660000
    num_steps_trained: 3660000
    wait_time_ms: 73.281
  iterations_since_restore: 732
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 6262.543339967728
  time_this_iter_s: 8.186168670654297
  time_total_s: 6262.543339967728
  timestamp: 1594864586
  timesteps_since_restore: 3660000
  timesteps_this_iter: 5000
  timesteps_total: 3660000
  training_iteration: 732
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 6262 s, 732 iter, 3660000 ts, -1.49 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-56-34
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -1.4872733674137222
  episode_reward_min: -148.72733674137223
  episodes_this_iter: 1
  episodes_total: 732
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.944
    dispatch_time_ms: 7.383
    learner:
      cur_lr: 0.0011162440059706569
      grad_gnorm: 0.034531060606241226
      policy_entropy: 0.0001743014872772619
      policy_loss: 2.0340651385453157e-09
      var_gnorm: 27.98107147216797
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 7.866517535148887e-07
    num_steps_sampled: 3665000
    num_steps_trained: 3665000
    wait_time_ms: 71.33
  iterations_since_restore: 733
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 6270.710372686386
  time_this_iter_s: 8.167032718658447
  time_total_s: 6270.710372686386
  timestamp: 1594864594
  timesteps_since_restore: 3665000
  timesteps_this_iter: 5000
  timesteps_total: 3665000
  training_iteration: 733
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 6270 s, 733 iter, 3665000 ts, -1.49 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-56-42
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -1.4872733674137222
  episode_reward_min: -148.72733674137223
  episodes_this_iter: 1
  episodes_total: 733
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.917
    dispatch_time_ms: 7.261
    learner:
      cur_lr: 0.0011159110581502318
      grad_gnorm: 0.05788417533040047
      policy_entropy: 0.00017470159218646586
      policy_loss: 2.104187935003665e-09
      var_gnorm: 27.981319427490234
      vf_explained_var: 0.0
      vf_loss: 2.206295221185428e-06
    num_steps_sampled: 3670000
    num_steps_trained: 3670000
    wait_time_ms: 74.207
  iterations_since_restore: 734
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 6278.985135555267
  time_this_iter_s: 8.274762868881226
  time_total_s: 6278.985135555267
  timestamp: 1594864602
  timesteps_since_restore: 3670000
  timesteps_this_iter: 5000
  timesteps_total: 3670000
  training_iteration: 734
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 6278 s, 734 iter, 3670000 ts, -1.49 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-56-50
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -1.4872733674137222
  episode_reward_min: -148.72733674137223
  episodes_this_iter: 1
  episodes_total: 734
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.633
    dispatch_time_ms: 7.001
    learner:
      cur_lr: 0.001115577993914485
      grad_gnorm: 0.041449882090091705
      policy_entropy: 0.0001751402160152793
      policy_loss: 4.6937720377115966e-09
      var_gnorm: 27.98158836364746
      vf_explained_var: 0.0
      vf_loss: 1.1289733947705827e-06
    num_steps_sampled: 3675000
    num_steps_trained: 3675000
    wait_time_ms: 71.189
  iterations_since_restore: 735
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 6287.12787604332
  time_this_iter_s: 8.142740488052368
  time_total_s: 6287.12787604332
  timestamp: 1594864610
  timesteps_since_restore: 3675000
  timesteps_this_iter: 5000
  timesteps_total: 3675000
  training_iteration: 735
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 6287 s, 735 iter, 3675000 ts, -1.49 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-56-59
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -1.4872733674137222
  episode_reward_min: -148.72733674137223
  episodes_this_iter: 1
  episodes_total: 735
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 3.095
    dispatch_time_ms: 30.4
    learner:
      cur_lr: 0.00111524504609406
      grad_gnorm: 0.06687350571155548
      policy_entropy: 0.00017560871492605656
      policy_loss: 3.530235881399335e-09
      var_gnorm: 27.981868743896484
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 2.9438208457577275e-06
    num_steps_sampled: 3680000
    num_steps_trained: 3680000
    wait_time_ms: 61.352
  iterations_since_restore: 736
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 6295.515696763992
  time_this_iter_s: 8.387820720672607
  time_total_s: 6295.515696763992
  timestamp: 1594864619
  timesteps_since_restore: 3680000
  timesteps_this_iter: 5000
  timesteps_total: 3680000
  training_iteration: 736
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 6295 s, 736 iter, 3680000 ts, -1.49 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-57-08
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -1.4872733674137222
  episode_reward_min: -148.72733674137223
  episodes_this_iter: 1
  episodes_total: 736
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.708
    dispatch_time_ms: 33.52
    learner:
      cur_lr: 0.001114911981858313
      grad_gnorm: 0.005348771344870329
      policy_entropy: 0.0001761348103173077
      policy_loss: 9.092150143885647e-09
      var_gnorm: 27.982177734375
      vf_explained_var: 0.0
      vf_loss: 1.914998115637445e-08
    num_steps_sampled: 3685000
    num_steps_trained: 3685000
    wait_time_ms: 65.252
  iterations_since_restore: 737
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 6304.390267372131
  time_this_iter_s: 8.874570608139038
  time_total_s: 6304.390267372131
  timestamp: 1594864628
  timesteps_since_restore: 3685000
  timesteps_this_iter: 5000
  timesteps_total: 3685000
  training_iteration: 737
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 6304 s, 737 iter, 3685000 ts, -1.49 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-57-16
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -1.4872733674137222
  episode_reward_min: -148.72733674137223
  episodes_this_iter: 1
  episodes_total: 737
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 3.262
    dispatch_time_ms: 38.98
    learner:
      cur_lr: 0.001114579034037888
      grad_gnorm: 0.5542119145393372
      policy_entropy: 0.0001767116045812145
      policy_loss: -7.160910797665565e-08
      var_gnorm: 27.982507705688477
      vf_explained_var: 0.0
      vf_loss: 0.00016053607396315783
    num_steps_sampled: 3690000
    num_steps_trained: 3690000
    wait_time_ms: 40.614
  iterations_since_restore: 738
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 6313.107180595398
  time_this_iter_s: 8.716913223266602
  time_total_s: 6313.107180595398
  timestamp: 1594864636
  timesteps_since_restore: 3690000
  timesteps_this_iter: 5000
  timesteps_total: 3690000
  training_iteration: 738
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 6313 s, 738 iter, 3690000 ts, -1.49 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-57-25
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -1.4872733674137222
  episode_reward_min: -148.72733674137223
  episodes_this_iter: 1
  episodes_total: 738
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.628
    dispatch_time_ms: 28.938
    learner:
      cur_lr: 0.0011142459698021412
      grad_gnorm: 0.040355537086725235
      policy_entropy: 0.00017729715909808874
      policy_loss: -4.2334001193466975e-08
      var_gnorm: 27.982833862304688
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 1.0746913403636427e-06
    num_steps_sampled: 3695000
    num_steps_trained: 3695000
    wait_time_ms: 56.047
  iterations_since_restore: 739
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 6322.058754444122
  time_this_iter_s: 8.951573848724365
  time_total_s: 6322.058754444122
  timestamp: 1594864645
  timesteps_since_restore: 3695000
  timesteps_this_iter: 5000
  timesteps_total: 3695000
  training_iteration: 739
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 6322 s, 739 iter, 3695000 ts, -1.49 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-57-34
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -1.4872733674137222
  episode_reward_min: -148.72733674137223
  episodes_this_iter: 1
  episodes_total: 739
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 3.105
    dispatch_time_ms: 14.557
    learner:
      cur_lr: 0.0011139130219817162
      grad_gnorm: 3.6769564151763916
      policy_entropy: 0.00017804834351409227
      policy_loss: -3.747868859704795e-08
      var_gnorm: 27.983230590820312
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 0.008902362547814846
    num_steps_sampled: 3700000
    num_steps_trained: 3700000
    wait_time_ms: 55.493
  iterations_since_restore: 740
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 6330.806139707565
  time_this_iter_s: 8.747385263442993
  time_total_s: 6330.806139707565
  timestamp: 1594864654
  timesteps_since_restore: 3700000
  timesteps_this_iter: 5000
  timesteps_total: 3700000
  training_iteration: 740
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 6330 s, 740 iter, 3700000 ts, -1.49 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-57-43
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -1.4872733674137222
  episode_reward_min: -148.72733674137223
  episodes_this_iter: 1
  episodes_total: 740
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 3.976
    dispatch_time_ms: 21.516
    learner:
      cur_lr: 0.0011135799577459693
      grad_gnorm: 0.015820179134607315
      policy_entropy: 0.00017852551536634564
      policy_loss: 7.387973011141469e-10
      var_gnorm: 27.983495712280273
      vf_explained_var: 5.960464477539063e-08
      vf_loss: 1.6346257325494662e-07
    num_steps_sampled: 3705000
    num_steps_trained: 3705000
    wait_time_ms: 57.654
  iterations_since_restore: 741
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 6339.522749185562
  time_this_iter_s: 8.716609477996826
  time_total_s: 6339.522749185562
  timestamp: 1594864663
  timesteps_since_restore: 3705000
  timesteps_this_iter: 5000
  timesteps_total: 3705000
  training_iteration: 741
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 6339 s, 741 iter, 3705000 ts, -1.49 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-57-52
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -1.4872733674137222
  episode_reward_min: -148.72733674137223
  episodes_this_iter: 1
  episodes_total: 741
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.896
    dispatch_time_ms: 25.669
    learner:
      cur_lr: 0.0011132470099255443
      grad_gnorm: 0.07738833874464035
      policy_entropy: 0.00017938220116775483
      policy_loss: -1.7510887184712942e-09
      var_gnorm: 27.983938217163086
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 3.266242629251792e-06
    num_steps_sampled: 3710000
    num_steps_trained: 3710000
    wait_time_ms: 73.919
  iterations_since_restore: 742
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 6348.412504911423
  time_this_iter_s: 8.889755725860596
  time_total_s: 6348.412504911423
  timestamp: 1594864672
  timesteps_since_restore: 3710000
  timesteps_this_iter: 5000
  timesteps_total: 3710000
  training_iteration: 742
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 6348 s, 742 iter, 3710000 ts, -1.49 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-58-01
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -1.4872733674137222
  episode_reward_min: -148.72733674137223
  episodes_this_iter: 1
  episodes_total: 742
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 3.23
    dispatch_time_ms: 26.378
    learner:
      cur_lr: 0.0011129139456897974
      grad_gnorm: 0.2504526972770691
      policy_entropy: 0.00018034914683084935
      policy_loss: -7.359886922131409e-09
      var_gnorm: 27.984420776367188
      vf_explained_var: 0.0
      vf_loss: 3.520682730595581e-05
    num_steps_sampled: 3715000
    num_steps_trained: 3715000
    wait_time_ms: 56.927
  iterations_since_restore: 743
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 6356.983573675156
  time_this_iter_s: 8.57106876373291
  time_total_s: 6356.983573675156
  timestamp: 1594864681
  timesteps_since_restore: 3715000
  timesteps_this_iter: 5000
  timesteps_total: 3715000
  training_iteration: 743
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 6356 s, 743 iter, 3715000 ts, -1.49 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-58-10
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -1.4872733674137222
  episode_reward_min: -148.72733674137223
  episodes_this_iter: 1
  episodes_total: 743
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.967
    dispatch_time_ms: 13.213
    learner:
      cur_lr: 0.0011125809978693724
      grad_gnorm: 40.00000762939453
      policy_entropy: 0.00018145654757972807
      policy_loss: 7.308370300052047e-07
      var_gnorm: 27.984939575195312
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 1.0461677312850952
    num_steps_sampled: 3720000
    num_steps_trained: 3720000
    wait_time_ms: 19.554
  iterations_since_restore: 744
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 6366.0006330013275
  time_this_iter_s: 9.017059326171875
  time_total_s: 6366.0006330013275
  timestamp: 1594864690
  timesteps_since_restore: 3720000
  timesteps_this_iter: 5000
  timesteps_total: 3720000
  training_iteration: 744
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 6366 s, 744 iter, 3720000 ts, -1.49 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-58-18
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -1.4872733674137222
  episode_reward_min: -148.72733674137223
  episodes_this_iter: 1
  episodes_total: 744
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 3.117
    dispatch_time_ms: 8.502
    learner:
      cur_lr: 0.0011122480500489473
      grad_gnorm: 0.49062538146972656
      policy_entropy: 0.00018266499682795256
      policy_loss: 2.6719828127852452e-08
      var_gnorm: 27.985498428344727
      vf_explained_var: 0.0
      vf_loss: 0.0001584982528584078
    num_steps_sampled: 3725000
    num_steps_trained: 3725000
    wait_time_ms: 69.937
  iterations_since_restore: 745
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 6374.148551702499
  time_this_iter_s: 8.147918701171875
  time_total_s: 6374.148551702499
  timestamp: 1594864698
  timesteps_since_restore: 3725000
  timesteps_this_iter: 5000
  timesteps_total: 3725000
  training_iteration: 745
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 6374 s, 745 iter, 3725000 ts, -1.49 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-58-26
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -1.4872733674137222
  episode_reward_min: -148.72733674137223
  episodes_this_iter: 1
  episodes_total: 745
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.769
    dispatch_time_ms: 7.312
    learner:
      cur_lr: 0.0011119149858132005
      grad_gnorm: 0.1094086542725563
      policy_entropy: 0.00018406109302304685
      policy_loss: -7.350183128806975e-09
      var_gnorm: 27.986122131347656
      vf_explained_var: 0.0
      vf_loss: 7.882199497544207e-06
    num_steps_sampled: 3730000
    num_steps_trained: 3730000
    wait_time_ms: 71.663
  iterations_since_restore: 746
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 6382.294893741608
  time_this_iter_s: 8.146342039108276
  time_total_s: 6382.294893741608
  timestamp: 1594864706
  timesteps_since_restore: 3730000
  timesteps_this_iter: 5000
  timesteps_total: 3730000
  training_iteration: 746
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 6382 s, 746 iter, 3730000 ts, -1.49 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-58-34
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -1.4872733674137222
  episode_reward_min: -148.72733674137223
  episodes_this_iter: 1
  episodes_total: 746
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.459
    dispatch_time_ms: 8.913
    learner:
      cur_lr: 0.0011115820379927754
      grad_gnorm: 0.008543610572814941
      policy_entropy: 0.00018572030239738524
      policy_loss: -2.2839257152185155e-09
      var_gnorm: 27.986818313598633
      vf_explained_var: 0.0
      vf_loss: 4.794324226509161e-08
    num_steps_sampled: 3735000
    num_steps_trained: 3735000
    wait_time_ms: 69.862
  iterations_since_restore: 747
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 6390.371209383011
  time_this_iter_s: 8.076315641403198
  time_total_s: 6390.371209383011
  timestamp: 1594864714
  timesteps_since_restore: 3735000
  timesteps_this_iter: 5000
  timesteps_total: 3735000
  training_iteration: 747
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 6390 s, 747 iter, 3735000 ts, -1.49 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-58-42
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -1.4872733674137222
  episode_reward_min: -148.72733674137223
  episodes_this_iter: 1
  episodes_total: 747
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.869
    dispatch_time_ms: 9.55
    learner:
      cur_lr: 0.0011112489737570286
      grad_gnorm: 0.1547122448682785
      policy_entropy: 0.00018760986858978868
      policy_loss: -8.425743658335705e-09
      var_gnorm: 27.987571716308594
      vf_explained_var: 0.0
      vf_loss: 1.5761335816932842e-05
    num_steps_sampled: 3740000
    num_steps_trained: 3740000
    wait_time_ms: 72.737
  iterations_since_restore: 748
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 6398.550931692123
  time_this_iter_s: 8.179722309112549
  time_total_s: 6398.550931692123
  timestamp: 1594864722
  timesteps_since_restore: 3740000
  timesteps_this_iter: 5000
  timesteps_total: 3740000
  training_iteration: 748
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 6398 s, 748 iter, 3740000 ts, -1.49 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-58-51
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -1.4872733674137222
  episode_reward_min: -148.72733674137223
  episodes_this_iter: 1
  episodes_total: 748
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.707
    dispatch_time_ms: 6.552
    learner:
      cur_lr: 0.0011109160259366035
      grad_gnorm: 0.016477003693580627
      policy_entropy: 0.00018989549425896257
      policy_loss: -3.382480406877164e-10
      var_gnorm: 27.98843002319336
      vf_explained_var: 0.0
      vf_loss: 1.7948106290077703e-07
    num_steps_sampled: 3745000
    num_steps_trained: 3745000
    wait_time_ms: 73.301
  iterations_since_restore: 749
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 6406.702561855316
  time_this_iter_s: 8.151630163192749
  time_total_s: 6406.702561855316
  timestamp: 1594864731
  timesteps_since_restore: 3745000
  timesteps_this_iter: 5000
  timesteps_total: 3745000
  training_iteration: 749
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 6406 s, 749 iter, 3745000 ts, -1.49 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-58-59
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -1.4872733674137222
  episode_reward_min: -148.72733674137223
  episodes_this_iter: 1
  episodes_total: 749
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.832
    dispatch_time_ms: 6.557
    learner:
      cur_lr: 0.0011105829617008567
      grad_gnorm: 0.14458461105823517
      policy_entropy: 0.00019259525288362056
      policy_loss: -1.3524919850738115e-08
      var_gnorm: 27.989381790161133
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 1.3757129636360332e-05
    num_steps_sampled: 3750000
    num_steps_trained: 3750000
    wait_time_ms: 69.919
  iterations_since_restore: 750
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 6414.859390258789
  time_this_iter_s: 8.1568284034729
  time_total_s: 6414.859390258789
  timestamp: 1594864739
  timesteps_since_restore: 3750000
  timesteps_this_iter: 5000
  timesteps_total: 3750000
  training_iteration: 750
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 6414 s, 750 iter, 3750000 ts, -1.49 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-59-07
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -1.4872733674137222
  episode_reward_min: -148.72733674137223
  episodes_this_iter: 1
  episodes_total: 750
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.766
    dispatch_time_ms: 7.582
    learner:
      cur_lr: 0.0011102500138804317
      grad_gnorm: 0.07809241861104965
      policy_entropy: 0.00019601668464019895
      policy_loss: 4.01120869852889e-09
      var_gnorm: 27.990495681762695
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 4.016816546936752e-06
    num_steps_sampled: 3755000
    num_steps_trained: 3755000
    wait_time_ms: 70.415
  iterations_since_restore: 751
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 6423.121897697449
  time_this_iter_s: 8.262507438659668
  time_total_s: 6423.121897697449
  timestamp: 1594864747
  timesteps_since_restore: 3755000
  timesteps_this_iter: 5000
  timesteps_total: 3755000
  training_iteration: 751
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 6423 s, 751 iter, 3755000 ts, -1.49 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-59-15
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -1.4872733674137222
  episode_reward_min: -148.72733674137223
  episodes_this_iter: 1
  episodes_total: 751
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 3.051
    dispatch_time_ms: 10.215
    learner:
      cur_lr: 0.0011099169496446848
      grad_gnorm: 0.13787870109081268
      policy_entropy: 0.00020010731532238424
      policy_loss: -1.254267267825071e-08
      var_gnorm: 27.991722106933594
      vf_explained_var: 0.0
      vf_loss: 1.251023422810249e-05
    num_steps_sampled: 3760000
    num_steps_trained: 3760000
    wait_time_ms: 71.644
  iterations_since_restore: 752
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 6431.334411144257
  time_this_iter_s: 8.212513446807861
  time_total_s: 6431.334411144257
  timestamp: 1594864755
  timesteps_since_restore: 3760000
  timesteps_this_iter: 5000
  timesteps_total: 3760000
  training_iteration: 752
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 6431 s, 752 iter, 3760000 ts, -1.49 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-59-23
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -1.4872733674137222
  episode_reward_min: -148.72733674137223
  episodes_this_iter: 1
  episodes_total: 752
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.571
    dispatch_time_ms: 5.939
    learner:
      cur_lr: 0.0011095840018242598
      grad_gnorm: 0.02472343109548092
      policy_entropy: 0.0002114063681801781
      policy_loss: 2.035246193798912e-09
      var_gnorm: 27.993165969848633
      vf_explained_var: 0.0
      vf_loss: 4.0144107060768874e-07
    num_steps_sampled: 3765000
    num_steps_trained: 3765000
    wait_time_ms: 71.637
  iterations_since_restore: 753
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 6439.4890785217285
  time_this_iter_s: 8.154667377471924
  time_total_s: 6439.4890785217285
  timestamp: 1594864763
  timesteps_since_restore: 3765000
  timesteps_this_iter: 5000
  timesteps_total: 3765000
  training_iteration: 753
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 6439 s, 753 iter, 3765000 ts, -1.49 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-59-32
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -1.4872733674137222
  episode_reward_min: -148.72733674137223
  episodes_this_iter: 1
  episodes_total: 753
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 3.262
    dispatch_time_ms: 8.661
    learner:
      cur_lr: 0.0011092510540038347
      grad_gnorm: 0.18804433941841125
      policy_entropy: 0.00021821248810738325
      policy_loss: -1.5361559135840253e-08
      var_gnorm: 27.994813919067383
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 2.329511335119605e-05
    num_steps_sampled: 3770000
    num_steps_trained: 3770000
    wait_time_ms: 66.636
  iterations_since_restore: 754
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 6447.646010875702
  time_this_iter_s: 8.156932353973389
  time_total_s: 6447.646010875702
  timestamp: 1594864772
  timesteps_since_restore: 3770000
  timesteps_this_iter: 5000
  timesteps_total: 3770000
  training_iteration: 754
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 6447 s, 754 iter, 3770000 ts, -1.49 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-59-40
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -1.4872733674137222
  episode_reward_min: -148.72733674137223
  episodes_this_iter: 1
  episodes_total: 754
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.626
    dispatch_time_ms: 8.772
    learner:
      cur_lr: 0.0011089179897680879
      grad_gnorm: 0.02572811022400856
      policy_entropy: 0.00022786927002016455
      policy_loss: 2.1017585449811804e-09
      var_gnorm: 27.996854782104492
      vf_explained_var: 1.1920928955078125e-07
      vf_loss: 4.362398726698302e-07
    num_steps_sampled: 3775000
    num_steps_trained: 3775000
    wait_time_ms: 71.057
  iterations_since_restore: 755
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 6455.808283805847
  time_this_iter_s: 8.162272930145264
  time_total_s: 6455.808283805847
  timestamp: 1594864780
  timesteps_since_restore: 3775000
  timesteps_this_iter: 5000
  timesteps_total: 3775000
  training_iteration: 755
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 6455 s, 755 iter, 3775000 ts, -1.49 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-59-48
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -1.4872733674137222
  episode_reward_min: -148.72733674137223
  episodes_this_iter: 1
  episodes_total: 755
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.745
    dispatch_time_ms: 6.592
    learner:
      cur_lr: 0.0011085850419476628
      grad_gnorm: 0.13135471940040588
      policy_entropy: 0.0002416491333860904
      policy_loss: -1.9617431235019467e-08
      var_gnorm: 27.999332427978516
      vf_explained_var: 1.7881393432617188e-07
      vf_loss: 1.1363364137650933e-05
    num_steps_sampled: 3780000
    num_steps_trained: 3780000
    wait_time_ms: 74.928
  iterations_since_restore: 756
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 6464.022549629211
  time_this_iter_s: 8.214265823364258
  time_total_s: 6464.022549629211
  timestamp: 1594864788
  timesteps_since_restore: 3780000
  timesteps_this_iter: 5000
  timesteps_total: 3780000
  training_iteration: 756
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 6464 s, 756 iter, 3780000 ts, -1.49 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-59-56
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -1.4872733674137222
  episode_reward_min: -148.72733674137223
  episodes_this_iter: 1
  episodes_total: 756
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 3.302
    dispatch_time_ms: 7.696
    learner:
      cur_lr: 0.001108251977711916
      grad_gnorm: 0.04739045724272728
      policy_entropy: 0.00026362534845247865
      policy_loss: 5.4061519705328465e-09
      var_gnorm: 28.002553939819336
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 1.4802095620325417e-06
    num_steps_sampled: 3785000
    num_steps_trained: 3785000
    wait_time_ms: 70.522
  iterations_since_restore: 757
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 6472.229932308197
  time_this_iter_s: 8.207382678985596
  time_total_s: 6472.229932308197
  timestamp: 1594864796
  timesteps_since_restore: 3785000
  timesteps_this_iter: 5000
  timesteps_total: 3785000
  training_iteration: 757
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 6472 s, 757 iter, 3785000 ts, -1.49 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-00-04
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -1.4872733674137222
  episode_reward_min: -148.72733674137223
  episodes_this_iter: 1
  episodes_total: 757
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 3.593
    dispatch_time_ms: 10.338
    learner:
      cur_lr: 0.001107919029891491
      grad_gnorm: 0.3210827112197876
      policy_entropy: 0.00030798852094449103
      policy_loss: -3.843819840199103e-08
      var_gnorm: 28.006874084472656
      vf_explained_var: 0.0
      vf_loss: 6.789018516428769e-05
    num_steps_sampled: 3790000
    num_steps_trained: 3790000
    wait_time_ms: 68.646
  iterations_since_restore: 758
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 6480.3605234622955
  time_this_iter_s: 8.13059115409851
  time_total_s: 6480.3605234622955
  timestamp: 1594864804
  timesteps_since_restore: 3790000
  timesteps_this_iter: 5000
  timesteps_total: 3790000
  training_iteration: 758
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 6480 s, 758 iter, 3790000 ts, -1.49 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-00-13
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -1.4872733674137222
  episode_reward_min: -148.72733674137223
  episodes_this_iter: 1
  episodes_total: 758
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.526
    dispatch_time_ms: 8.513
    learner:
      cur_lr: 0.001107585965655744
      grad_gnorm: 0.030399784445762634
      policy_entropy: 0.00040603475645184517
      policy_loss: -2.945570365397998e-08
      var_gnorm: 28.01382827758789
      vf_explained_var: 0.0
      vf_loss: 6.063743285267265e-07
    num_steps_sampled: 3795000
    num_steps_trained: 3795000
    wait_time_ms: 70.541
  iterations_since_restore: 759
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 6488.514432668686
  time_this_iter_s: 8.15390920639038
  time_total_s: 6488.514432668686
  timestamp: 1594864813
  timesteps_since_restore: 3795000
  timesteps_this_iter: 5000
  timesteps_total: 3795000
  training_iteration: 759
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 6488 s, 759 iter, 3795000 ts, -1.49 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-00-21
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -1.4872733674137222
  episode_reward_min: -148.72733674137223
  episodes_this_iter: 1
  episodes_total: 759
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 3.155
    dispatch_time_ms: 8.34
    learner:
      cur_lr: 0.001107253017835319
      grad_gnorm: 0.3452727794647217
      policy_entropy: 0.0008491452899761498
      policy_loss: -1.4828266614586028e-07
      var_gnorm: 28.028430938720703
      vf_explained_var: 0.0
      vf_loss: 7.851458940422162e-05
    num_steps_sampled: 3800000
    num_steps_trained: 3800000
    wait_time_ms: 70.775
  iterations_since_restore: 760
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 6496.672008514404
  time_this_iter_s: 8.157575845718384
  time_total_s: 6496.672008514404
  timestamp: 1594864821
  timesteps_since_restore: 3800000
  timesteps_this_iter: 5000
  timesteps_total: 3800000
  training_iteration: 760
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 6496 s, 760 iter, 3800000 ts, -1.49 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-00-29
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -1.4872733674137222
  episode_reward_min: -148.72733674137223
  episodes_this_iter: 1
  episodes_total: 760
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.74
    dispatch_time_ms: 6.506
    learner:
      cur_lr: 0.0011069199535995722
      grad_gnorm: 40.0
      policy_entropy: 0.011393302120268345
      policy_loss: -0.00308535760268569
      var_gnorm: 28.230897903442383
      vf_explained_var: 1.1920928955078125e-07
      vf_loss: 459.5086364746094
    num_steps_sampled: 3805000
    num_steps_trained: 3805000
    wait_time_ms: 77.419
  iterations_since_restore: 761
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 6504.879128217697
  time_this_iter_s: 8.207119703292847
  time_total_s: 6504.879128217697
  timestamp: 1594864829
  timesteps_since_restore: 3805000
  timesteps_this_iter: 5000
  timesteps_total: 3805000
  training_iteration: 761
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 6504 s, 761 iter, 3805000 ts, -1.49 rew

agent-1: -71.60773825816305
agent-2: -14.673964595234995
agent-3: -349.9979139910219
agent-4: -70.20740151562555
agent-5: -349.9979139910219
Extrinsic Rewards:
2
3
0
2
0
Sum Reward: 7
Avg Reward: 1.4
Min Reward: 0
Max Reward: 3
Gini Coefficient: 0.45714285714285713
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-00-37
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -10.052122690924387
  episode_reward_min: -856.4849323510664
  episodes_this_iter: 1
  episodes_total: 761
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.524
    dispatch_time_ms: 6.69
    learner:
      cur_lr: 0.0011065870057791471
      grad_gnorm: 8.904450416564941
      policy_entropy: 6.289601878961548e-05
      policy_loss: 8.958011221693596e-08
      var_gnorm: 28.235801696777344
      vf_explained_var: 1.1920928955078125e-07
      vf_loss: 0.05220993608236313
    num_steps_sampled: 3810000
    num_steps_trained: 3810000
    wait_time_ms: 79.179
  iterations_since_restore: 762
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 6513.049577713013
  time_this_iter_s: 8.170449495315552
  time_total_s: 6513.049577713013
  timestamp: 1594864837
  timesteps_since_restore: 3810000
  timesteps_this_iter: 5000
  timesteps_total: 3810000
  training_iteration: 762
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 6513 s, 762 iter, 3810000 ts, -10.1 rew

agent-1: -199.99999141969897
agent-2: -109.18821932649256
agent-3: -7.188224571464728
agent-4: -199.99999141969897
agent-5: -199.99999141969897
Extrinsic Rewards:
0
1
3
0
0
Sum Reward: 4
Avg Reward: 0.8
Min Reward: 0
Max Reward: 3
Gini Coefficient: 0.7
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-00-45
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -17.215886872494906
  episode_reward_min: -856.4849323510664
  episodes_this_iter: 1
  episodes_total: 762
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.668
    dispatch_time_ms: 7.877
    learner:
      cur_lr: 0.0011062540579587221
      grad_gnorm: 3.1304585933685303
      policy_entropy: 6.289093289524317e-05
      policy_loss: -8.524359884631849e-08
      var_gnorm: 28.235776901245117
      vf_explained_var: 0.0
      vf_loss: 0.006465241312980652
    num_steps_sampled: 3815000
    num_steps_trained: 3815000
    wait_time_ms: 70.466
  iterations_since_restore: 763
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 6521.1944098472595
  time_this_iter_s: 8.144832134246826
  time_total_s: 6521.1944098472595
  timestamp: 1594864845
  timesteps_since_restore: 3815000
  timesteps_this_iter: 5000
  timesteps_total: 3815000
  training_iteration: 763
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 6521 s, 763 iter, 3815000 ts, -17.2 rew

agent-1: -99.99999999894987
agent-2: -99.99999999894987
agent-3: -99.99999999894987
agent-4: 2.0
agent-5: -99.99999999894987
Extrinsic Rewards:
0
0
0
2
0
Sum Reward: 2
Avg Reward: 0.4
Min Reward: 0
Max Reward: 2
Gini Coefficient: 0.8
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-01-09
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -21.195886872452892
  episode_reward_min: -856.4849323510664
  episodes_this_iter: 1
  episodes_total: 763
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.508
    dispatch_time_ms: 6.472
    learner:
      cur_lr: 0.0011059209937229753
      grad_gnorm: 15.16672420501709
      policy_entropy: 6.289093289524317e-05
      policy_loss: 4.129957176246535e-07
      var_gnorm: 28.236003875732422
      vf_explained_var: 1.1920928955078125e-07
      vf_loss: 0.1514703333377838
    num_steps_sampled: 3820000
    num_steps_trained: 3820000
    wait_time_ms: 72.192
  iterations_since_restore: 764
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 6545.077208995819
  time_this_iter_s: 23.88279914855957
  time_total_s: 6545.077208995819
  timestamp: 1594864869
  timesteps_since_restore: 3820000
  timesteps_this_iter: 5000
  timesteps_total: 3820000
  training_iteration: 764
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 6545 s, 764 iter, 3820000 ts, -21.2 rew

agent-1: -149.99999999837684
agent-2: -149.99999999837684
agent-3: -149.99999999837684
agent-4: -149.99999999837684
agent-5: 3.0
Extrinsic Rewards:
0
0
0
0
3
Sum Reward: 3
Avg Reward: 0.6
Min Reward: 0
Max Reward: 3
Gini Coefficient: 0.8
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-01-17
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -27.16588687238805
  episode_reward_min: -856.4849323510664
  episodes_this_iter: 1
  episodes_total: 764
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.839
    dispatch_time_ms: 10.842
    learner:
      cur_lr: 0.0011055880459025502
      grad_gnorm: 0.17881351709365845
      policy_entropy: 6.289093289524317e-05
      policy_loss: -7.714663352587081e-10
      var_gnorm: 28.23573112487793
      vf_explained_var: 0.0
      vf_loss: 2.1044839741080068e-05
    num_steps_sampled: 3825000
    num_steps_trained: 3825000
    wait_time_ms: 67.018
  iterations_since_restore: 765
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 6553.118857622147
  time_this_iter_s: 8.041648626327515
  time_total_s: 6553.118857622147
  timestamp: 1594864877
  timesteps_since_restore: 3825000
  timesteps_this_iter: 5000
  timesteps_total: 3825000
  training_iteration: 765
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 6553 s, 765 iter, 3825000 ts, -27.2 rew

agent-1: -149.99999999840443
agent-2: -149.99999999840443
agent-3: -149.99999999840443
agent-4: -149.99999999840443
agent-5: 3.0
Extrinsic Rewards:
0
0
0
0
3
Sum Reward: 3
Avg Reward: 0.6
Min Reward: 0
Max Reward: 3
Gini Coefficient: 0.8
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-01-26
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -33.1358868723243
  episode_reward_min: -856.4849323510664
  episodes_this_iter: 1
  episodes_total: 765
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.64
    dispatch_time_ms: 7.275
    learner:
      cur_lr: 0.0011052549816668034
      grad_gnorm: 39.999996185302734
      policy_entropy: 6.289093289524317e-05
      policy_loss: -7.707944860158022e-06
      var_gnorm: 28.236162185668945
      vf_explained_var: 0.0
      vf_loss: 70.19652557373047
    num_steps_sampled: 3830000
    num_steps_trained: 3830000
    wait_time_ms: 70.6
  iterations_since_restore: 766
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 6561.31968331337
  time_this_iter_s: 8.200825691223145
  time_total_s: 6561.31968331337
  timestamp: 1594864886
  timesteps_since_restore: 3830000
  timesteps_this_iter: 5000
  timesteps_total: 3830000
  training_iteration: 766
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 6561 s, 766 iter, 3830000 ts, -33.1 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-01-34
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -33.135886872324306
  episode_reward_min: -856.4849323510664
  episodes_this_iter: 1
  episodes_total: 766
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.454
    dispatch_time_ms: 7.642
    learner:
      cur_lr: 0.0011049220338463783
      grad_gnorm: 0.04441213235259056
      policy_entropy: 6.289093289524317e-05
      policy_loss: -4.921007601410565e-09
      var_gnorm: 28.235729217529297
      vf_explained_var: 0.0
      vf_loss: 1.298182041864493e-06
    num_steps_sampled: 3835000
    num_steps_trained: 3835000
    wait_time_ms: 76.49
  iterations_since_restore: 767
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 6569.46257185936
  time_this_iter_s: 8.14288854598999
  time_total_s: 6569.46257185936
  timestamp: 1594864894
  timesteps_since_restore: 3835000
  timesteps_this_iter: 5000
  timesteps_total: 3835000
  training_iteration: 767
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 6569 s, 767 iter, 3835000 ts, -33.1 rew

agent-1: -148.99999999837678
agent-2: -249.99999999731412
agent-3: 4.0
agent-4: -249.99999999731412
agent-5: -249.99999999731412
Extrinsic Rewards:
1
0
4
0
0
Sum Reward: 5
Avg Reward: 1.0
Min Reward: 0
Max Reward: 4
Gini Coefficient: 0.72
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-01-42
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -42.085886872227455
  episode_reward_min: -894.9999999903151
  episodes_this_iter: 1
  episodes_total: 767
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.48
    dispatch_time_ms: 5.272
    learner:
      cur_lr: 0.0011045889696106315
      grad_gnorm: 19.04343605041504
      policy_entropy: 6.289093289524317e-05
      policy_loss: 4.1040590303964564e-07
      var_gnorm: 28.23619270324707
      vf_explained_var: 0.0
      vf_loss: 0.23880094289779663
    num_steps_sampled: 3840000
    num_steps_trained: 3840000
    wait_time_ms: 76.926
  iterations_since_restore: 768
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 6577.655065774918
  time_this_iter_s: 8.192493915557861
  time_total_s: 6577.655065774918
  timestamp: 1594864902
  timesteps_since_restore: 3840000
  timesteps_this_iter: 5000
  timesteps_total: 3840000
  training_iteration: 768
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 6577 s, 768 iter, 3840000 ts, -42.1 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-01-50
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -42.08588687222745
  episode_reward_min: -894.9999999903151
  episodes_this_iter: 1
  episodes_total: 768
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.898
    dispatch_time_ms: 8.278
    learner:
      cur_lr: 0.0011042560217902064
      grad_gnorm: 0.292343407869339
      policy_entropy: 6.289093289524317e-05
      policy_loss: 6.8646079931511395e-09
      var_gnorm: 28.2357234954834
      vf_explained_var: 5.960464477539063e-08
      vf_loss: 5.626682468573563e-05
    num_steps_sampled: 3845000
    num_steps_trained: 3845000
    wait_time_ms: 70.904
  iterations_since_restore: 769
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 6585.8216984272
  time_this_iter_s: 8.166632652282715
  time_total_s: 6585.8216984272
  timestamp: 1594864910
  timesteps_since_restore: 3845000
  timesteps_this_iter: 5000
  timesteps_total: 3845000
  training_iteration: 769
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 6585 s, 769 iter, 3845000 ts, -42.1 rew

agent-1: -99.99999999894987
agent-2: -99.99999999894987
agent-3: 2.0
agent-4: -99.99999999894987
agent-5: -99.99999999894987
Extrinsic Rewards:
0
0
2
0
0
Sum Reward: 2
Avg Reward: 0.4
Min Reward: 0
Max Reward: 2
Gini Coefficient: 0.8
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-01-59
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -46.06588687218544
  episode_reward_min: -894.9999999903151
  episodes_this_iter: 1
  episodes_total: 769
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.435
    dispatch_time_ms: 9.585
    learner:
      cur_lr: 0.0011039229575544596
      grad_gnorm: 30.985347747802734
      policy_entropy: 6.289093289524317e-05
      policy_loss: -8.437427823082544e-07
      var_gnorm: 28.23623275756836
      vf_explained_var: 0.0
      vf_loss: 1.0903477668762207
    num_steps_sampled: 3850000
    num_steps_trained: 3850000
    wait_time_ms: 72.123
  iterations_since_restore: 770
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 6594.106588602066
  time_this_iter_s: 8.284890174865723
  time_total_s: 6594.106588602066
  timestamp: 1594864919
  timesteps_since_restore: 3850000
  timesteps_this_iter: 5000
  timesteps_total: 3850000
  training_iteration: 770
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 6594 s, 770 iter, 3850000 ts, -46.1 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-02-07
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -46.06588687218544
  episode_reward_min: -894.9999999903151
  episodes_this_iter: 1
  episodes_total: 770
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.748
    dispatch_time_ms: 7.343
    learner:
      cur_lr: 0.0011035900097340345
      grad_gnorm: 3.216534376144409
      policy_entropy: 6.289093289524317e-05
      policy_loss: 1.6171490813121636e-07
      var_gnorm: 28.235715866088867
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 0.0068127065896987915
    num_steps_sampled: 3855000
    num_steps_trained: 3855000
    wait_time_ms: 69.712
  iterations_since_restore: 771
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 6602.257124662399
  time_this_iter_s: 8.150536060333252
  time_total_s: 6602.257124662399
  timestamp: 1594864927
  timesteps_since_restore: 3855000
  timesteps_this_iter: 5000
  timesteps_total: 3855000
  training_iteration: 771
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 6602 s, 771 iter, 3855000 ts, -46.1 rew

agent-1: -49.99999999946836
agent-2: -49.99999999946836
agent-3: 1.0
agent-4: -49.99999999946836
agent-5: -49.99999999946836
Extrinsic Rewards:
0
0
1
0
0
Sum Reward: 1
Avg Reward: 0.2
Min Reward: 0
Max Reward: 1
Gini Coefficient: 0.8
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-02-15
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -48.05588687216417
  episode_reward_min: -894.9999999903151
  episodes_this_iter: 1
  episodes_total: 771
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.996
    dispatch_time_ms: 8.331
    learner:
      cur_lr: 0.0011032569454982877
      grad_gnorm: 16.016569137573242
      policy_entropy: 6.289093289524317e-05
      policy_loss: 3.4421793770889053e-07
      var_gnorm: 28.236032485961914
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 0.16892066597938538
    num_steps_sampled: 3860000
    num_steps_trained: 3860000
    wait_time_ms: 70.091
  iterations_since_restore: 772
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 6610.5541932582855
  time_this_iter_s: 8.29706859588623
  time_total_s: 6610.5541932582855
  timestamp: 1594864935
  timesteps_since_restore: 3860000
  timesteps_this_iter: 5000
  timesteps_total: 3860000
  training_iteration: 772
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 6610 s, 772 iter, 3860000 ts, -48.1 rew

agent-1: -249.99999999735493
agent-2: -249.99999999735493
agent-3: 3.0
agent-4: -47.99999999945478
agent-5: -249.99999999735493
Extrinsic Rewards:
0
0
3
2
0
Sum Reward: 5
Avg Reward: 1.0
Min Reward: 0
Max Reward: 3
Gini Coefficient: 0.64
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-02-25
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -56.005886872079365
  episode_reward_min: -894.9999999903151
  episodes_this_iter: 1
  episodes_total: 772
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.845
    dispatch_time_ms: 8.988
    learner:
      cur_lr: 0.0011029239976778626
      grad_gnorm: 0.919423520565033
      policy_entropy: 6.289093289524317e-05
      policy_loss: 2.5036246853460398e-08
      var_gnorm: 28.2357120513916
      vf_explained_var: 1.1920928955078125e-07
      vf_loss: 0.000566572358366102
    num_steps_sampled: 3865000
    num_steps_trained: 3865000
    wait_time_ms: 70.08
  iterations_since_restore: 773
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 6620.031589746475
  time_this_iter_s: 9.477396488189697
  time_total_s: 6620.031589746475
  timestamp: 1594864945
  timesteps_since_restore: 3865000
  timesteps_this_iter: 5000
  timesteps_total: 3865000
  training_iteration: 773
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 6620 s, 773 iter, 3865000 ts, -56 rew

agent-1: -299.9999999967528
agent-2: -299.9999999967528
agent-3: 4.0
agent-4: -97.99999999893765
agent-5: -299.9999999967528
Extrinsic Rewards:
0
0
4
2
0
Sum Reward: 6
Avg Reward: 1.2
Min Reward: 0
Max Reward: 4
Gini Coefficient: 0.6666666666666666
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-02-33
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -65.94588687197131
  episode_reward_min: -993.9999999891946
  episodes_this_iter: 1
  episodes_total: 773
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.61
    dispatch_time_ms: 9.789
    learner:
      cur_lr: 0.0011025910498574376
      grad_gnorm: 12.952916145324707
      policy_entropy: 6.289093289524317e-05
      policy_loss: 3.1284949386645167e-07
      var_gnorm: 28.23590087890625
      vf_explained_var: 0.0
      vf_loss: 0.1104782223701477
    num_steps_sampled: 3870000
    num_steps_trained: 3870000
    wait_time_ms: 69.98
  iterations_since_restore: 774
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 6628.259247541428
  time_this_iter_s: 8.227657794952393
  time_total_s: 6628.259247541428
  timestamp: 1594864953
  timesteps_since_restore: 3870000
  timesteps_this_iter: 5000
  timesteps_total: 3870000
  training_iteration: 774
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 6628 s, 774 iter, 3870000 ts, -65.9 rew

agent-1: 3.0
agent-2: -199.99999999787352
agent-3: -199.99999999787352
agent-4: -199.99999999787352
agent-5: -98.99999999893653
Extrinsic Rewards:
3
0
0
0
1
Sum Reward: 4
Avg Reward: 0.8
Min Reward: 0
Max Reward: 3
Gini Coefficient: 0.7
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-02-41
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -72.90588687189684
  episode_reward_min: -993.9999999891946
  episodes_this_iter: 1
  episodes_total: 774
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 3.454
    dispatch_time_ms: 31.177
    learner:
      cur_lr: 0.0011022579856216908
      grad_gnorm: 0.3424001634120941
      policy_entropy: 6.288400618359447e-05
      policy_loss: 1.525444588423852e-07
      var_gnorm: 28.235715866088867
      vf_explained_var: 0.0
      vf_loss: 7.721350266365334e-05
    num_steps_sampled: 3875000
    num_steps_trained: 3875000
    wait_time_ms: 51.391
  iterations_since_restore: 775
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 6636.757989406586
  time_this_iter_s: 8.498741865158081
  time_total_s: 6636.757989406586
  timestamp: 1594864961
  timesteps_since_restore: 3875000
  timesteps_this_iter: 5000
  timesteps_total: 3875000
  training_iteration: 775
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 6636 s, 775 iter, 3875000 ts, -72.9 rew

agent-1: -149.99999999840443
agent-2: -149.99999999840443
agent-3: -149.99999999840443
agent-4: -149.99999999840443
agent-5: 3.0
Extrinsic Rewards:
0
0
0
0
3
Sum Reward: 3
Avg Reward: 0.6
Min Reward: 0
Max Reward: 3
Gini Coefficient: 0.8
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-02-50
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -78.87588687183309
  episode_reward_min: -993.9999999891946
  episodes_this_iter: 1
  episodes_total: 775
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.943
    dispatch_time_ms: 7.091
    learner:
      cur_lr: 0.0011019250378012657
      grad_gnorm: 0.06632112711668015
      policy_entropy: 6.288400618359447e-05
      policy_loss: 1.8575523341723965e-09
      var_gnorm: 28.2357177734375
      vf_explained_var: 0.0
      vf_loss: 2.894434601330431e-06
    num_steps_sampled: 3880000
    num_steps_trained: 3880000
    wait_time_ms: 70.658
  iterations_since_restore: 776
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 6645.268613576889
  time_this_iter_s: 8.510624170303345
  time_total_s: 6645.268613576889
  timestamp: 1594864970
  timesteps_since_restore: 3880000
  timesteps_this_iter: 5000
  timesteps_total: 3880000
  training_iteration: 776
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 6645 s, 776 iter, 3880000 ts, -78.9 rew

agent-1: -99.99999999894987
agent-2: -99.99999999894987
agent-3: 2.0
agent-4: -99.99999999894987
agent-5: -99.99999999894987
Extrinsic Rewards:
0
0
2
0
0
Sum Reward: 2
Avg Reward: 0.4
Min Reward: 0
Max Reward: 2
Gini Coefficient: 0.8
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-02-58
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -82.85588687179109
  episode_reward_min: -993.9999999891946
  episodes_this_iter: 1
  episodes_total: 776
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.574
    dispatch_time_ms: 8.225
    learner:
      cur_lr: 0.0011015919735655189
      grad_gnorm: 1.3353708982467651
      policy_entropy: 6.288420991040766e-05
      policy_loss: 8.275776508526178e-08
      var_gnorm: 28.235708236694336
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 0.0011741577181965113
    num_steps_sampled: 3885000
    num_steps_trained: 3885000
    wait_time_ms: 71.929
  iterations_since_restore: 777
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 6653.45080947876
  time_this_iter_s: 8.182195901870728
  time_total_s: 6653.45080947876
  timestamp: 1594864978
  timesteps_since_restore: 3885000
  timesteps_this_iter: 5000
  timesteps_total: 3885000
  training_iteration: 777
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 6653 s, 777 iter, 3885000 ts, -82.9 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-03-06
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -82.85588687179109
  episode_reward_min: -993.9999999891946
  episodes_this_iter: 1
  episodes_total: 777
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.887
    dispatch_time_ms: 7.622
    learner:
      cur_lr: 0.0011012590257450938
      grad_gnorm: 10.848735809326172
      policy_entropy: 6.288420991040766e-05
      policy_loss: 2.0930248467720958e-07
      var_gnorm: 28.235830307006836
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 0.07750023901462555
    num_steps_sampled: 3890000
    num_steps_trained: 3890000
    wait_time_ms: 71.737
  iterations_since_restore: 778
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 6661.660396099091
  time_this_iter_s: 8.20958662033081
  time_total_s: 6661.660396099091
  timestamp: 1594864986
  timesteps_since_restore: 3890000
  timesteps_this_iter: 5000
  timesteps_total: 3890000
  training_iteration: 778
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 6661 s, 778 iter, 3890000 ts, -82.9 rew

agent-1: -149.99999999840443
agent-2: -149.99999999840443
agent-3: -149.99999999840443
agent-4: 3.0
agent-5: -149.99999999840443
Extrinsic Rewards:
0
0
0
3
0
Sum Reward: 3
Avg Reward: 0.6
Min Reward: 0
Max Reward: 3
Gini Coefficient: 0.8
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-03-15
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -88.82588687172732
  episode_reward_min: -993.9999999891946
  episodes_this_iter: 1
  episodes_total: 778
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.572
    dispatch_time_ms: 7.485
    learner:
      cur_lr: 0.001100925961509347
      grad_gnorm: 0.9674412608146667
      policy_entropy: 6.288420991040766e-05
      policy_loss: 4.8790461448788847e-08
      var_gnorm: 28.235706329345703
      vf_explained_var: 1.7881393432617188e-07
      vf_loss: 0.0006186115206219256
    num_steps_sampled: 3895000
    num_steps_trained: 3895000
    wait_time_ms: 73.379
  iterations_since_restore: 779
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 6669.835821390152
  time_this_iter_s: 8.175425291061401
  time_total_s: 6669.835821390152
  timestamp: 1594864995
  timesteps_since_restore: 3895000
  timesteps_this_iter: 5000
  timesteps_total: 3895000
  training_iteration: 779
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 6669 s, 779 iter, 3895000 ts, -88.8 rew

agent-1: -49.99999999946836
agent-2: 1.0
agent-3: -49.99999999946836
agent-4: -49.99999999946836
agent-5: -49.99999999946836
Extrinsic Rewards:
0
1
0
0
0
Sum Reward: 1
Avg Reward: 0.2
Min Reward: 0
Max Reward: 1
Gini Coefficient: 0.8
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-03-23
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -90.81588687170606
  episode_reward_min: -993.9999999891946
  episodes_this_iter: 1
  episodes_total: 779
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.675
    dispatch_time_ms: 6.316
    learner:
      cur_lr: 0.001100593013688922
      grad_gnorm: 39.999996185302734
      policy_entropy: 6.288420991040766e-05
      policy_loss: -8.621626875537913e-06
      var_gnorm: 28.235828399658203
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 84.56565856933594
    num_steps_sampled: 3900000
    num_steps_trained: 3900000
    wait_time_ms: 72.131
  iterations_since_restore: 780
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 6677.985906124115
  time_this_iter_s: 8.150084733963013
  time_total_s: 6677.985906124115
  timestamp: 1594865003
  timesteps_since_restore: 3900000
  timesteps_this_iter: 5000
  timesteps_total: 3900000
  training_iteration: 780
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 6677 s, 780 iter, 3900000 ts, -90.8 rew

agent-1: -149.99999999837684
agent-2: -149.99999999837684
agent-3: -149.99999999837684
agent-4: -149.99999999837684
agent-5: 3.0
Extrinsic Rewards:
0
0
0
0
3
Sum Reward: 3
Avg Reward: 0.6
Min Reward: 0
Max Reward: 3
Gini Coefficient: 0.8
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-03-31
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -96.78588687164124
  episode_reward_min: -993.9999999891946
  episodes_this_iter: 1
  episodes_total: 780
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 3.203
    dispatch_time_ms: 7.479
    learner:
      cur_lr: 0.001100259949453175
      grad_gnorm: 2.4969215393066406
      policy_entropy: 6.288278382271528e-05
      policy_loss: 2.5567806005710736e-07
      var_gnorm: 28.235700607299805
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 0.004105700179934502
    num_steps_sampled: 3905000
    num_steps_trained: 3905000
    wait_time_ms: 71.39
  iterations_since_restore: 781
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 6686.165889501572
  time_this_iter_s: 8.179983377456665
  time_total_s: 6686.165889501572
  timestamp: 1594865011
  timesteps_since_restore: 3905000
  timesteps_this_iter: 5000
  timesteps_total: 3905000
  training_iteration: 781
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 6686 s, 781 iter, 3905000 ts, -96.8 rew

agent-1: -149.99999999840443
agent-2: -149.99999999840443
agent-3: -149.99999999840443
agent-4: -149.99999999840443
agent-5: 3.0
Extrinsic Rewards:
0
0
0
0
3
Sum Reward: 3
Avg Reward: 0.6
Min Reward: 0
Max Reward: 3
Gini Coefficient: 0.8
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-03-39
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -102.75588687157747
  episode_reward_min: -993.9999999891946
  episodes_this_iter: 1
  episodes_total: 781
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.667
    dispatch_time_ms: 6.89
    learner:
      cur_lr: 0.00109992700163275
      grad_gnorm: 0.0005828546127304435
      policy_entropy: 6.288278382271528e-05
      policy_loss: 2.8896923742749436e-10
      var_gnorm: 28.23571014404297
      vf_explained_var: 0.0
      vf_loss: 2.085556727315918e-10
    num_steps_sampled: 3910000
    num_steps_trained: 3910000
    wait_time_ms: 72.021
  iterations_since_restore: 782
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 6694.445074796677
  time_this_iter_s: 8.27918529510498
  time_total_s: 6694.445074796677
  timestamp: 1594865019
  timesteps_since_restore: 3910000
  timesteps_this_iter: 5000
  timesteps_total: 3910000
  training_iteration: 782
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 6694 s, 782 iter, 3910000 ts, -103 rew

agent-1: 4.0
agent-2: -299.9999999967948
agent-3: -299.9999999967948
agent-4: -97.9999999988953
agent-5: -299.9999999967948
Extrinsic Rewards:
4
0
0
2
0
Sum Reward: 6
Avg Reward: 1.2
Min Reward: 0
Max Reward: 4
Gini Coefficient: 0.6666666666666666
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-03-48
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -112.69588687147032
  episode_reward_min: -993.9999999892849
  episodes_this_iter: 1
  episodes_total: 782
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.619
    dispatch_time_ms: 5.877
    learner:
      cur_lr: 0.001099594053812325
      grad_gnorm: 0.14121168851852417
      policy_entropy: 6.288380245678127e-05
      policy_loss: 2.4282861943447642e-08
      var_gnorm: 28.23571014404297
      vf_explained_var: 5.960464477539063e-08
      vf_loss: 1.31346505440888e-05
    num_steps_sampled: 3915000
    num_steps_trained: 3915000
    wait_time_ms: 76.656
  iterations_since_restore: 783
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 6702.698166131973
  time_this_iter_s: 8.25309133529663
  time_total_s: 6702.698166131973
  timestamp: 1594865028
  timesteps_since_restore: 3915000
  timesteps_this_iter: 5000
  timesteps_total: 3915000
  training_iteration: 783
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 6702 s, 783 iter, 3915000 ts, -113 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-03-56
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -112.69588687147032
  episode_reward_min: -993.9999999892849
  episodes_this_iter: 1
  episodes_total: 783
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.341
    dispatch_time_ms: 8.424
    learner:
      cur_lr: 0.0010992609895765781
      grad_gnorm: 39.999996185302734
      policy_entropy: 6.288503209361807e-05
      policy_loss: -1.4971761629567482e-05
      var_gnorm: 28.235782623291016
      vf_explained_var: 1.7881393432617188e-07
      vf_loss: 302.7081604003906
    num_steps_sampled: 3920000
    num_steps_trained: 3920000
    wait_time_ms: 72.097
  iterations_since_restore: 784
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 6710.967395544052
  time_this_iter_s: 8.269229412078857
  time_total_s: 6710.967395544052
  timestamp: 1594865036
  timesteps_since_restore: 3920000
  timesteps_this_iter: 5000
  timesteps_total: 3920000
  training_iteration: 784
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 6710 s, 784 iter, 3920000 ts, -113 rew

agent-1: 2.0
agent-2: -99.99999999894987
agent-3: -99.99999999894987
agent-4: -99.99999999894987
agent-5: -99.99999999894987
Extrinsic Rewards:
2
0
0
0
0
Sum Reward: 2
Avg Reward: 0.4
Min Reward: 0
Max Reward: 2
Gini Coefficient: 0.8
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-04-04
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -116.6758868714283
  episode_reward_min: -993.9999999892849
  episodes_this_iter: 1
  episodes_total: 784
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.608
    dispatch_time_ms: 6.7
    learner:
      cur_lr: 0.001098928041756153
      grad_gnorm: 0.9353583455085754
      policy_entropy: 6.288827717071399e-05
      policy_loss: -3.215322408323118e-08
      var_gnorm: 28.235719680786133
      vf_explained_var: 0.0
      vf_loss: 0.0005761355860158801
    num_steps_sampled: 3925000
    num_steps_trained: 3925000
    wait_time_ms: 77.602
  iterations_since_restore: 785
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 6719.186286449432
  time_this_iter_s: 8.218890905380249
  time_total_s: 6719.186286449432
  timestamp: 1594865044
  timesteps_since_restore: 3925000
  timesteps_this_iter: 5000
  timesteps_total: 3925000
  training_iteration: 785
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 6719 s, 785 iter, 3925000 ts, -117 rew

agent-1: -47.99999999945478
agent-2: -249.99999999735493
agent-3: 3.0
agent-4: -249.99999999735493
agent-5: -249.99999999735493
Extrinsic Rewards:
2
0
3
0
0
Sum Reward: 5
Avg Reward: 1.0
Min Reward: 0
Max Reward: 3
Gini Coefficient: 0.64
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-04-12
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -124.6258868713435
  episode_reward_min: -993.9999999892849
  episodes_this_iter: 1
  episodes_total: 785
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.547
    dispatch_time_ms: 7.341
    learner:
      cur_lr: 0.0010985949775204062
      grad_gnorm: 40.000003814697266
      policy_entropy: 6.288888107519597e-05
      policy_loss: -1.934367355715949e-05
      var_gnorm: 28.235727310180664
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 415.6410827636719
    num_steps_sampled: 3930000
    num_steps_trained: 3930000
    wait_time_ms: 71.304
  iterations_since_restore: 786
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 6727.389489889145
  time_this_iter_s: 8.203203439712524
  time_total_s: 6727.389489889145
  timestamp: 1594865052
  timesteps_since_restore: 3930000
  timesteps_this_iter: 5000
  timesteps_total: 3930000
  training_iteration: 786
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 6727 s, 786 iter, 3930000 ts, -125 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-04-21
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -124.6258868713435
  episode_reward_min: -993.9999999892849
  episodes_this_iter: 1
  episodes_total: 786
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.709
    dispatch_time_ms: 7.738
    learner:
      cur_lr: 0.0010982620296999812
      grad_gnorm: 1.1671022176742554
      policy_entropy: 6.288805889198557e-05
      policy_loss: 6.986999867564236e-09
      var_gnorm: 28.235721588134766
      vf_explained_var: 5.960464477539063e-08
      vf_loss: 0.0008970087510533631
    num_steps_sampled: 3935000
    num_steps_trained: 3935000
    wait_time_ms: 75.866
  iterations_since_restore: 787
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 6735.675212144852
  time_this_iter_s: 8.285722255706787
  time_total_s: 6735.675212144852
  timestamp: 1594865061
  timesteps_since_restore: 3935000
  timesteps_this_iter: 5000
  timesteps_total: 3935000
  training_iteration: 787
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 6735 s, 787 iter, 3935000 ts, -125 rew

agent-1: -149.99999999837684
agent-2: -149.99999999837684
agent-3: 3.0
agent-4: -149.99999999837684
agent-5: -149.99999999837684
Extrinsic Rewards:
0
0
3
0
0
Sum Reward: 3
Avg Reward: 0.6
Min Reward: 0
Max Reward: 3
Gini Coefficient: 0.8
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-04-29
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -130.59588687127865
  episode_reward_min: -993.9999999892849
  episodes_this_iter: 1
  episodes_total: 787
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.849
    dispatch_time_ms: 8.236
    learner:
      cur_lr: 0.0010979289654642344
      grad_gnorm: 0.01838868483901024
      policy_entropy: 6.288805889198557e-05
      policy_loss: 4.758618499245415e-10
      var_gnorm: 28.23571014404297
      vf_explained_var: 0.0
      vf_loss: 2.2371690988620685e-07
    num_steps_sampled: 3940000
    num_steps_trained: 3940000
    wait_time_ms: 69.769
  iterations_since_restore: 788
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 6743.945022106171
  time_this_iter_s: 8.26980996131897
  time_total_s: 6743.945022106171
  timestamp: 1594865069
  timesteps_since_restore: 3940000
  timesteps_this_iter: 5000
  timesteps_total: 3940000
  training_iteration: 788
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 6743 s, 788 iter, 3940000 ts, -131 rew

agent-1: -199.99999999784504
agent-2: -199.99999999784504
agent-3: -199.99999999784504
agent-4: -199.99999999784504
agent-5: 4.0
Extrinsic Rewards:
0
0
0
0
4
Sum Reward: 4
Avg Reward: 0.8
Min Reward: 0
Max Reward: 4
Gini Coefficient: 0.8
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-04-37
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -138.5558868711925
  episode_reward_min: -993.9999999892849
  episodes_this_iter: 1
  episodes_total: 788
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.544
    dispatch_time_ms: 5.828
    learner:
      cur_lr: 0.0010975960176438093
      grad_gnorm: 0.4948897361755371
      policy_entropy: 6.289091834332794e-05
      policy_loss: 1.4012160320930889e-08
      var_gnorm: 28.235713958740234
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 0.0001639914116822183
    num_steps_sampled: 3945000
    num_steps_trained: 3945000
    wait_time_ms: 75.144
  iterations_since_restore: 789
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 6752.126471281052
  time_this_iter_s: 8.181449174880981
  time_total_s: 6752.126471281052
  timestamp: 1594865077
  timesteps_since_restore: 3945000
  timesteps_this_iter: 5000
  timesteps_total: 3945000
  training_iteration: 789
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 6752 s, 789 iter, 3945000 ts, -139 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-04-45
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -138.5558868711925
  episode_reward_min: -993.9999999892849
  episodes_this_iter: 1
  episodes_total: 789
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 3.291
    dispatch_time_ms: 9.166
    learner:
      cur_lr: 0.0010972629534080625
      grad_gnorm: 4.930856227874756
      policy_entropy: 6.289232987910509e-05
      policy_loss: -1.0244198023201534e-07
      var_gnorm: 28.23571014404297
      vf_explained_var: 0.0
      vf_loss: 0.016009973362088203
    num_steps_sampled: 3950000
    num_steps_trained: 3950000
    wait_time_ms: 69.244
  iterations_since_restore: 790
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 6760.25465130806
  time_this_iter_s: 8.128180027008057
  time_total_s: 6760.25465130806
  timestamp: 1594865085
  timesteps_since_restore: 3950000
  timesteps_this_iter: 5000
  timesteps_total: 3950000
  training_iteration: 790
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 6760 s, 790 iter, 3950000 ts, -139 rew

agent-1: -299.9999999967528
agent-2: -299.9999999967528
agent-3: 1.6882812500007653
agent-4: 1.6882812500000002
agent-5: -299.9999999967528
Extrinsic Rewards:
0
0
3
3
0
Sum Reward: 6
Avg Reward: 1.2
Min Reward: 0
Max Reward: 3
Gini Coefficient: 0.6
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-04-54
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -147.52212124609505
  episode_reward_min: -993.9999999892849
  episodes_this_iter: 1
  episodes_total: 790
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.757
    dispatch_time_ms: 8.382
    learner:
      cur_lr: 0.0010969300055876374
      grad_gnorm: 0.5420663356781006
      policy_entropy: 6.28986454103142e-05
      policy_loss: -2.0236077702406874e-08
      var_gnorm: 28.235713958740234
      vf_explained_var: 0.0
      vf_loss: 0.00019350861839484423
    num_steps_sampled: 3955000
    num_steps_trained: 3955000
    wait_time_ms: 69.109
  iterations_since_restore: 791
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 6768.411774635315
  time_this_iter_s: 8.157123327255249
  time_total_s: 6768.411774635315
  timestamp: 1594865094
  timesteps_since_restore: 3955000
  timesteps_this_iter: 5000
  timesteps_total: 3955000
  training_iteration: 791
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 6768 s, 791 iter, 3955000 ts, -148 rew

agent-1: -49.999999999481645
agent-2: -49.999999999481645
agent-3: -49.999999999481645
agent-4: -49.999999999481645
agent-5: 1.0
Extrinsic Rewards:
0
0
0
0
1
Sum Reward: 1
Avg Reward: 0.2
Min Reward: 0
Max Reward: 1
Gini Coefficient: 0.8
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-05-02
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -149.51212124607434
  episode_reward_min: -993.9999999892849
  episodes_this_iter: 1
  episodes_total: 791
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.875
    dispatch_time_ms: 8.97
    learner:
      cur_lr: 0.0010965970577672124
      grad_gnorm: 3.972203016281128
      policy_entropy: 6.29002825007774e-05
      policy_loss: 1.0816459905527154e-07
      var_gnorm: 28.23570442199707
      vf_explained_var: 0.0
      vf_loss: 0.010389672592282295
    num_steps_sampled: 3960000
    num_steps_trained: 3960000
    wait_time_ms: 71.087
  iterations_since_restore: 792
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 6776.627665758133
  time_this_iter_s: 8.215891122817993
  time_total_s: 6776.627665758133
  timestamp: 1594865102
  timesteps_since_restore: 3960000
  timesteps_this_iter: 5000
  timesteps_total: 3960000
  training_iteration: 792
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 6776 s, 792 iter, 3960000 ts, -150 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-05-10
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -149.51212124607434
  episode_reward_min: -993.9999999892849
  episodes_this_iter: 1
  episodes_total: 792
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.869
    dispatch_time_ms: 8.28
    learner:
      cur_lr: 0.0010962639935314655
      grad_gnorm: 1.4072239398956299
      policy_entropy: 6.290333112701774e-05
      policy_loss: -5.4727422593714437e-08
      var_gnorm: 28.2357234954834
      vf_explained_var: 1.7881393432617188e-07
      vf_loss: 0.0013039893237873912
    num_steps_sampled: 3965000
    num_steps_trained: 3965000
    wait_time_ms: 71.422
  iterations_since_restore: 793
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 6784.794714689255
  time_this_iter_s: 8.167048931121826
  time_total_s: 6784.794714689255
  timestamp: 1594865110
  timesteps_since_restore: 3965000
  timesteps_this_iter: 5000
  timesteps_total: 3965000
  training_iteration: 793
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 6784 s, 793 iter, 3965000 ts, -150 rew

agent-1: -349.9999999962086
agent-2: -349.9999999962086
agent-3: -349.9999999962086
agent-4: 1.53125
agent-5: -49.46874999939871
Extrinsic Rewards:
0
0
0
4
3
Sum Reward: 7
Avg Reward: 1.4
Min Reward: 0
Max Reward: 4
Gini Coefficient: 0.6285714285714286
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-05-18
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -160.49149624595444
  episode_reward_min: -1097.9374999880097
  episodes_this_iter: 1
  episodes_total: 793
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.917
    dispatch_time_ms: 7.72
    learner:
      cur_lr: 0.0010959310457110405
      grad_gnorm: 40.0
      policy_entropy: 6.290639430517331e-05
      policy_loss: -1.2302891263971105e-05
      var_gnorm: 28.2357234954834
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 172.86001586914062
    num_steps_sampled: 3970000
    num_steps_trained: 3970000
    wait_time_ms: 71.792
  iterations_since_restore: 794
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 6792.8729910850525
  time_this_iter_s: 8.07827639579773
  time_total_s: 6792.8729910850525
  timestamp: 1594865118
  timesteps_since_restore: 3970000
  timesteps_this_iter: 5000
  timesteps_total: 3970000
  training_iteration: 794
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 6792 s, 794 iter, 3970000 ts, -160 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-05-26
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -160.49149624595444
  episode_reward_min: -1097.9374999880097
  episodes_this_iter: 1
  episodes_total: 794
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.442
    dispatch_time_ms: 6.532
    learner:
      cur_lr: 0.0010955979814752936
      grad_gnorm: 0.7115702629089355
      policy_entropy: 6.290863530011848e-05
      policy_loss: -2.3036667684550594e-08
      var_gnorm: 28.235713958740234
      vf_explained_var: 5.960464477539063e-08
      vf_loss: 0.00033342064125463367
    num_steps_sampled: 3975000
    num_steps_trained: 3975000
    wait_time_ms: 74.069
  iterations_since_restore: 795
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 6801.077870845795
  time_this_iter_s: 8.204879760742188
  time_total_s: 6801.077870845795
  timestamp: 1594865126
  timesteps_since_restore: 3975000
  timesteps_this_iter: 5000
  timesteps_total: 3975000
  training_iteration: 795
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 6801 s, 795 iter, 3975000 ts, -160 rew

agent-1: -99.99999999894987
agent-2: 2.0
agent-3: -99.99999999894987
agent-4: -99.99999999894987
agent-5: -99.99999999894987
Extrinsic Rewards:
0
2
0
0
0
Sum Reward: 2
Avg Reward: 0.4
Min Reward: 0
Max Reward: 2
Gini Coefficient: 0.8
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-05-35
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -164.47149624591245
  episode_reward_min: -1097.9374999880097
  episodes_this_iter: 1
  episodes_total: 795
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 3.152
    dispatch_time_ms: 8.192
    learner:
      cur_lr: 0.0010952650336548686
      grad_gnorm: 0.058150481432676315
      policy_entropy: 6.290863530011848e-05
      policy_loss: 7.551801961547255e-10
      var_gnorm: 28.235706329345703
      vf_explained_var: 0.0
      vf_loss: 2.224155423391494e-06
    num_steps_sampled: 3980000
    num_steps_trained: 3980000
    wait_time_ms: 70.16
  iterations_since_restore: 796
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 6809.3035526275635
  time_this_iter_s: 8.225681781768799
  time_total_s: 6809.3035526275635
  timestamp: 1594865135
  timesteps_since_restore: 3980000
  timesteps_this_iter: 5000
  timesteps_total: 3980000
  training_iteration: 796
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 6809 s, 796 iter, 3980000 ts, -164 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-05-43
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -164.47149624591242
  episode_reward_min: -1097.9374999880097
  episodes_this_iter: 1
  episodes_total: 796
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.465
    dispatch_time_ms: 7.939
    learner:
      cur_lr: 0.0010949319694191217
      grad_gnorm: 2.0533056259155273
      policy_entropy: 6.291230238275602e-05
      policy_loss: -5.591228813273119e-08
      var_gnorm: 28.235727310180664
      vf_explained_var: 0.0
      vf_loss: 0.00277848937548697
    num_steps_sampled: 3985000
    num_steps_trained: 3985000
    wait_time_ms: 73.032
  iterations_since_restore: 797
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 6817.589230775833
  time_this_iter_s: 8.285678148269653
  time_total_s: 6817.589230775833
  timestamp: 1594865143
  timesteps_since_restore: 3985000
  timesteps_this_iter: 5000
  timesteps_total: 3985000
  training_iteration: 797
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 6817 s, 797 iter, 3985000 ts, -164 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-05-51
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -164.47149624591242
  episode_reward_min: -1097.9374999880097
  episodes_this_iter: 1
  episodes_total: 797
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.985
    dispatch_time_ms: 8.258
    learner:
      cur_lr: 0.0010945990215986967
      grad_gnorm: 4.400580883026123
      policy_entropy: 6.291494355536997e-05
      policy_loss: 8.574210141887306e-08
      var_gnorm: 28.235702514648438
      vf_explained_var: 0.0
      vf_loss: 0.01275126077234745
    num_steps_sampled: 3990000
    num_steps_trained: 3990000
    wait_time_ms: 73.471
  iterations_since_restore: 798
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 6825.812956809998
  time_this_iter_s: 8.223726034164429
  time_total_s: 6825.812956809998
  timestamp: 1594865151
  timesteps_since_restore: 3990000
  timesteps_this_iter: 5000
  timesteps_total: 3990000
  training_iteration: 798
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 6825 s, 798 iter, 3990000 ts, -164 rew

agent-1: -199.99999999787352
agent-2: -98.99999999893653
agent-3: -199.99999999787352
agent-4: -199.99999999787352
agent-5: 3.0
Extrinsic Rewards:
0
1
0
0
3
Sum Reward: 4
Avg Reward: 0.8
Min Reward: 0
Max Reward: 3
Gini Coefficient: 0.7
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-06-00
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -171.43149624583796
  episode_reward_min: -1097.9374999880097
  episodes_this_iter: 1
  episodes_total: 798
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.752
    dispatch_time_ms: 8.785
    learner:
      cur_lr: 0.0010942659573629498
      grad_gnorm: 3.341639995574951
      policy_entropy: 6.2912906287238e-05
      policy_loss: -7.914605504311112e-08
      var_gnorm: 28.235748291015625
      vf_explained_var: 0.0
      vf_loss: 0.007353675551712513
    num_steps_sampled: 3995000
    num_steps_trained: 3995000
    wait_time_ms: 70.656
  iterations_since_restore: 799
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 6834.002687215805
  time_this_iter_s: 8.189730405807495
  time_total_s: 6834.002687215805
  timestamp: 1594865160
  timesteps_since_restore: 3995000
  timesteps_this_iter: 5000
  timesteps_total: 3995000
  training_iteration: 799
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 6834 s, 799 iter, 3995000 ts, -171 rew

agent-1: 1.53125
agent-2: -349.9999999962086
agent-3: -49.46874999939871
agent-4: -349.9999999962086
agent-5: -349.9999999962086
Extrinsic Rewards:
4
0
3
0
0
Sum Reward: 7
Avg Reward: 1.4
Min Reward: 0
Max Reward: 4
Gini Coefficient: 0.6285714285714286
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-06-13
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -182.41087124571808
  episode_reward_min: -1097.93749998801
  episodes_this_iter: 1
  episodes_total: 799
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.875
    dispatch_time_ms: 7.056
    learner:
      cur_lr: 0.0010939330095425248
      grad_gnorm: 0.03512577712535858
      policy_entropy: 6.2912906287238e-05
      policy_loss: 1.0639932268574626e-09
      var_gnorm: 28.235702514648438
      vf_explained_var: 0.0
      vf_loss: 8.144588150571508e-07
    num_steps_sampled: 4000000
    num_steps_trained: 4000000
    wait_time_ms: 69.744
  iterations_since_restore: 800
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 6847.096065044403
  time_this_iter_s: 13.093377828598022
  time_total_s: 6847.096065044403
  timestamp: 1594865173
  timesteps_since_restore: 4000000
  timesteps_this_iter: 5000
  timesteps_total: 4000000
  training_iteration: 800
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 6847 s, 800 iter, 4000000 ts, -182 rew

agent-1: 0.7500000000136119
agent-2: 0.75
agent-3: -199.99999999788645
agent-4: -199.99999999788645
agent-5: -199.99999999788645
Extrinsic Rewards:
2
2
0
0
0
Sum Reward: 4
Avg Reward: 0.8
Min Reward: 0
Max Reward: 2
Gini Coefficient: 0.6
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-06-21
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -188.39587124565446
  episode_reward_min: -1097.93749998801
  episodes_this_iter: 1
  episodes_total: 800
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.842
    dispatch_time_ms: 5.846
    learner:
      cur_lr: 0.001093599945306778
      grad_gnorm: 0.4919065833091736
      policy_entropy: 6.292514444794506e-05
      policy_loss: 2.6917128082004638e-08
      var_gnorm: 28.235706329345703
      vf_explained_var: 1.7881393432617188e-07
      vf_loss: 0.00016256982053164393
    num_steps_sampled: 4005000
    num_steps_trained: 4005000
    wait_time_ms: 73.925
  iterations_since_restore: 801
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 6855.664541244507
  time_this_iter_s: 8.56847620010376
  time_total_s: 6855.664541244507
  timestamp: 1594865181
  timesteps_since_restore: 4005000
  timesteps_this_iter: 5000
  timesteps_total: 4005000
  training_iteration: 801
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 6855 s, 801 iter, 4005000 ts, -188 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-06-29
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -188.39587124565446
  episode_reward_min: -1097.93749998801
  episodes_this_iter: 1
  episodes_total: 801
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.566
    dispatch_time_ms: 6.506
    learner:
      cur_lr: 0.001093266997486353
      grad_gnorm: 39.999996185302734
      policy_entropy: 6.292738544289023e-05
      policy_loss: -2.669447349035181e-05
      var_gnorm: 28.235694885253906
      vf_explained_var: 0.0
      vf_loss: 803.618408203125
    num_steps_sampled: 4010000
    num_steps_trained: 4010000
    wait_time_ms: 73.56
  iterations_since_restore: 802
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 6863.792892217636
  time_this_iter_s: 8.128350973129272
  time_total_s: 6863.792892217636
  timestamp: 1594865189
  timesteps_since_restore: 4010000
  timesteps_this_iter: 5000
  timesteps_total: 4010000
  training_iteration: 802
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 6863 s, 802 iter, 4010000 ts, -188 rew

agent-1: -49.46874999939871
agent-2: -349.9999999962086
agent-3: -349.9999999962086
agent-4: -349.9999999962086
agent-5: 1.53125
Extrinsic Rewards:
3
0
0
0
4
Sum Reward: 7
Avg Reward: 1.4
Min Reward: 0
Max Reward: 4
Gini Coefficient: 0.6285714285714286
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-06-38
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -199.37524624553456
  episode_reward_min: -1097.93749998801
  episodes_this_iter: 1
  episodes_total: 802
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.441
    dispatch_time_ms: 9.569
    learner:
      cur_lr: 0.0010929340496659279
      grad_gnorm: 3.266145944595337
      policy_entropy: 6.292697798926383e-05
      policy_loss: -8.582016164382367e-08
      var_gnorm: 28.23574447631836
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 0.007025351747870445
    num_steps_sampled: 4015000
    num_steps_trained: 4015000
    wait_time_ms: 70.036
  iterations_since_restore: 803
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 6872.059744596481
  time_this_iter_s: 8.266852378845215
  time_total_s: 6872.059744596481
  timestamp: 1594865198
  timesteps_since_restore: 4015000
  timesteps_this_iter: 5000
  timesteps_total: 4015000
  training_iteration: 803
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 6872 s, 803 iter, 4015000 ts, -199 rew

agent-1: -99.99999999894987
agent-2: -99.99999999894987
agent-3: -99.99999999894987
agent-4: 2.0
agent-5: -99.99999999894987
Extrinsic Rewards:
0
0
0
2
0
Sum Reward: 2
Avg Reward: 0.4
Min Reward: 0
Max Reward: 2
Gini Coefficient: 0.8
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-06-46
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -203.35524624549254
  episode_reward_min: -1097.93749998801
  episodes_this_iter: 1
  episodes_total: 803
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.95
    dispatch_time_ms: 8.051
    learner:
      cur_lr: 0.001092600985430181
      grad_gnorm: 40.0
      policy_entropy: 6.29286005278118e-05
      policy_loss: -6.931459938641638e-05
      var_gnorm: 28.235694885253906
      vf_explained_var: 0.0
      vf_loss: 6454.00390625
    num_steps_sampled: 4020000
    num_steps_trained: 4020000
    wait_time_ms: 71.163
  iterations_since_restore: 804
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 6880.2150366306305
  time_this_iter_s: 8.15529203414917
  time_total_s: 6880.2150366306305
  timestamp: 1594865206
  timesteps_since_restore: 4020000
  timesteps_this_iter: 5000
  timesteps_total: 4020000
  training_iteration: 804
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 6880 s, 804 iter, 4020000 ts, -203 rew

agent-1: -48.9999999994684
agent-2: -149.9999999984318
agent-3: 2.0
agent-4: -149.9999999984318
agent-5: -149.9999999984318
Extrinsic Rewards:
1
0
2
0
0
Sum Reward: 3
Avg Reward: 0.6
Min Reward: 0
Max Reward: 2
Gini Coefficient: 0.6666666666666666
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-06-54
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -208.32524624544018
  episode_reward_min: -1097.93749998801
  episodes_this_iter: 1
  episodes_total: 804
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.363
    dispatch_time_ms: 6.676
    learner:
      cur_lr: 0.001092268037609756
      grad_gnorm: 3.1194262504577637
      policy_entropy: 6.293023034231737e-05
      policy_loss: -8.362848546994428e-08
      var_gnorm: 28.235740661621094
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 0.00640773493796587
    num_steps_sampled: 4025000
    num_steps_trained: 4025000
    wait_time_ms: 75.365
  iterations_since_restore: 805
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 6888.399984836578
  time_this_iter_s: 8.184948205947876
  time_total_s: 6888.399984836578
  timestamp: 1594865214
  timesteps_since_restore: 4025000
  timesteps_this_iter: 5000
  timesteps_total: 4025000
  training_iteration: 805
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 6888 s, 805 iter, 4025000 ts, -208 rew

agent-1: -249.99999999735493
agent-2: 3.0
agent-3: -249.99999999735493
agent-4: -249.99999999735493
agent-5: -47.99999999945478
Extrinsic Rewards:
0
3
0
0
2
Sum Reward: 5
Avg Reward: 1.0
Min Reward: 0
Max Reward: 3
Gini Coefficient: 0.64
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-07-02
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -216.27524624535542
  episode_reward_min: -1097.93749998801
  episodes_this_iter: 1
  episodes_total: 805
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.665
    dispatch_time_ms: 7.584
    learner:
      cur_lr: 0.0010919349733740091
      grad_gnorm: 40.0
      policy_entropy: 6.293105252552778e-05
      policy_loss: -5.21233887411654e-05
      var_gnorm: 28.235698699951172
      vf_explained_var: -2.384185791015625e-07
      vf_loss: 3085.968505859375
    num_steps_sampled: 4030000
    num_steps_trained: 4030000
    wait_time_ms: 72.546
  iterations_since_restore: 806
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 6896.615028619766
  time_this_iter_s: 8.215043783187866
  time_total_s: 6896.615028619766
  timestamp: 1594865222
  timesteps_since_restore: 4030000
  timesteps_this_iter: 5000
  timesteps_total: 4030000
  training_iteration: 806
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 6896 s, 806 iter, 4030000 ts, -216 rew

agent-1: -49.999999999481645
agent-2: -49.999999999481645
agent-3: -49.999999999481645
agent-4: -49.999999999481645
agent-5: 1.0
Extrinsic Rewards:
0
0
0
0
1
Sum Reward: 1
Avg Reward: 0.2
Min Reward: 0
Max Reward: 1
Gini Coefficient: 0.8
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-07-11
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -218.26524624533468
  episode_reward_min: -1097.93749998801
  episodes_this_iter: 1
  episodes_total: 806
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.442
    dispatch_time_ms: 9.62
    learner:
      cur_lr: 0.001091602025553584
      grad_gnorm: 2.1348202228546143
      policy_entropy: 6.293105252552778e-05
      policy_loss: -3.382792712613991e-08
      var_gnorm: 28.23572540283203
      vf_explained_var: 5.960464477539063e-08
      vf_loss: 0.003002083394676447
    num_steps_sampled: 4035000
    num_steps_trained: 4035000
    wait_time_ms: 65.967
  iterations_since_restore: 807
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 6904.728999614716
  time_this_iter_s: 8.11397099494934
  time_total_s: 6904.728999614716
  timestamp: 1594865231
  timesteps_since_restore: 4035000
  timesteps_this_iter: 5000
  timesteps_total: 4035000
  training_iteration: 807
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 6904 s, 807 iter, 4035000 ts, -218 rew

agent-1: -149.99999999840443
agent-2: 3.0
agent-3: -149.99999999840443
agent-4: -149.99999999840443
agent-5: -149.99999999840443
Extrinsic Rewards:
0
3
0
0
0
Sum Reward: 3
Avg Reward: 0.6
Min Reward: 0
Max Reward: 3
Gini Coefficient: 0.8
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-07-19
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -224.23524624527093
  episode_reward_min: -1097.93749998801
  episodes_this_iter: 1
  episodes_total: 807
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 3.909
    dispatch_time_ms: 7.121
    learner:
      cur_lr: 0.0010912689613178372
      grad_gnorm: 0.4259730279445648
      policy_entropy: 6.293226033449173e-05
      policy_loss: -9.793181376949178e-09
      var_gnorm: 28.235698699951172
      vf_explained_var: 0.0
      vf_loss: 0.00011946530867135152
    num_steps_sampled: 4040000
    num_steps_trained: 4040000
    wait_time_ms: 73.589
  iterations_since_restore: 808
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 6912.886920452118
  time_this_iter_s: 8.157920837402344
  time_total_s: 6912.886920452118
  timestamp: 1594865239
  timesteps_since_restore: 4040000
  timesteps_this_iter: 5000
  timesteps_total: 4040000
  training_iteration: 808
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 6912 s, 808 iter, 4040000 ts, -224 rew

agent-1: -199.99999999780377
agent-2: 4.0
agent-3: -199.99999999780377
agent-4: -199.99999999780377
agent-5: -199.99999999780377
Extrinsic Rewards:
0
4
0
0
0
Sum Reward: 4
Avg Reward: 0.8
Min Reward: 0
Max Reward: 4
Gini Coefficient: 0.8
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-07-27
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -232.19524624518306
  episode_reward_min: -1097.93749998801
  episodes_this_iter: 1
  episodes_total: 808
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.524
    dispatch_time_ms: 8.732
    learner:
      cur_lr: 0.0010909360134974122
      grad_gnorm: 2.1486854553222656
      policy_entropy: 6.293144542723894e-05
      policy_loss: -2.7426573012689914e-08
      var_gnorm: 28.235727310180664
      vf_explained_var: 0.0
      vf_loss: 0.0030408017337322235
    num_steps_sampled: 4045000
    num_steps_trained: 4045000
    wait_time_ms: 70.07
  iterations_since_restore: 809
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 6921.0239470005035
  time_this_iter_s: 8.13702654838562
  time_total_s: 6921.0239470005035
  timestamp: 1594865247
  timesteps_since_restore: 4045000
  timesteps_this_iter: 5000
  timesteps_total: 4045000
  training_iteration: 809
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 6921 s, 809 iter, 4045000 ts, -232 rew

agent-1: -198.99999999778979
agent-2: -349.99999999623503
agent-3: -99.2499999988536
agent-4: 2.75
agent-5: -349.99999999623503
Extrinsic Rewards:
1
0
2
4
0
Sum Reward: 7
Avg Reward: 1.4
Min Reward: 0
Max Reward: 4
Gini Coefficient: 0.5714285714285714
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-07-35
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -242.1502462450742
  episode_reward_min: -1097.93749998801
  episodes_this_iter: 1
  episodes_total: 809
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 3.215
    dispatch_time_ms: 7.681
    learner:
      cur_lr: 0.0010906029492616653
      grad_gnorm: 0.014664716087281704
      policy_entropy: 6.293164915405214e-05
      policy_loss: 3.9932576689771793e-10
      var_gnorm: 28.23570442199707
      vf_explained_var: 0.0
      vf_loss: 1.418187309809582e-07
    num_steps_sampled: 4050000
    num_steps_trained: 4050000
    wait_time_ms: 70.721
  iterations_since_restore: 810
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 6929.160148382187
  time_this_iter_s: 8.13620138168335
  time_total_s: 6929.160148382187
  timestamp: 1594865255
  timesteps_since_restore: 4050000
  timesteps_this_iter: 5000
  timesteps_total: 4050000
  training_iteration: 810
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 6929 s, 810 iter, 4050000 ts, -242 rew

agent-1: -99.99999999894987
agent-2: -99.99999999894987
agent-3: -99.99999999894987
agent-4: 2.0
agent-5: -99.99999999894987
Extrinsic Rewards:
0
0
0
2
0
Sum Reward: 2
Avg Reward: 0.4
Min Reward: 0
Max Reward: 2
Gini Coefficient: 0.8
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-07-43
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -246.13024624503217
  episode_reward_min: -1097.93749998801
  episodes_this_iter: 1
  episodes_total: 810
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 3.017
    dispatch_time_ms: 8.153
    learner:
      cur_lr: 0.0010902700014412403
      grad_gnorm: 0.0008054695790633559
      policy_entropy: 6.293226033449173e-05
      policy_loss: -2.193324341592806e-11
      var_gnorm: 28.235706329345703
      vf_explained_var: 0.0
      vf_loss: 4.2721082227359375e-10
    num_steps_sampled: 4055000
    num_steps_trained: 4055000
    wait_time_ms: 70.455
  iterations_since_restore: 811
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 6937.383753061295
  time_this_iter_s: 8.223604679107666
  time_total_s: 6937.383753061295
  timestamp: 1594865263
  timesteps_since_restore: 4055000
  timesteps_this_iter: 5000
  timesteps_total: 4055000
  training_iteration: 811
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 6937 s, 811 iter, 4055000 ts, -246 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-07-52
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -246.13024624503217
  episode_reward_min: -1097.93749998801
  episodes_this_iter: 1
  episodes_total: 811
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.558
    dispatch_time_ms: 8.456
    learner:
      cur_lr: 0.0010899370536208153
      grad_gnorm: 0.00010084556561196223
      policy_entropy: 6.293266051216051e-05
      policy_loss: 2.746031700640028e-12
      var_gnorm: 28.235708236694336
      vf_explained_var: 0.0
      vf_loss: 5.730681987975439e-12
    num_steps_sampled: 4060000
    num_steps_trained: 4060000
    wait_time_ms: 70.445
  iterations_since_restore: 812
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 6945.5304844379425
  time_this_iter_s: 8.14673137664795
  time_total_s: 6945.5304844379425
  timestamp: 1594865272
  timesteps_since_restore: 4060000
  timesteps_this_iter: 5000
  timesteps_total: 4060000
  training_iteration: 812
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 6945 s, 812 iter, 4060000 ts, -246 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-08-00
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -246.13024624503217
  episode_reward_min: -1097.93749998801
  episodes_this_iter: 1
  episodes_total: 812
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.335
    dispatch_time_ms: 7.616
    learner:
      cur_lr: 0.0010896039893850684
      grad_gnorm: 4.153938061790541e-05
      policy_entropy: 6.293408659985289e-05
      policy_loss: -7.739103628778832e-12
      var_gnorm: 28.23571014404297
      vf_explained_var: 0.0
      vf_loss: 3.810631064166126e-12
    num_steps_sampled: 4065000
    num_steps_trained: 4065000
    wait_time_ms: 70.433
  iterations_since_restore: 813
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 6953.5958795547485
  time_this_iter_s: 8.06539511680603
  time_total_s: 6953.5958795547485
  timestamp: 1594865280
  timesteps_since_restore: 4065000
  timesteps_this_iter: 5000
  timesteps_total: 4065000
  training_iteration: 813
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 6953 s, 813 iter, 4065000 ts, -246 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-08-08
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -246.13024624503214
  episode_reward_min: -1097.93749998801
  episodes_this_iter: 2
  episodes_total: 814
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.649
    dispatch_time_ms: 6.132
    learner:
      cur_lr: 0.0010892710415646434
      grad_gnorm: 0.00015003983571659774
      policy_entropy: 6.293408659985289e-05
      policy_loss: 4.085620296939707e-12
      var_gnorm: 28.23571014404297
      vf_explained_var: -1.0
      vf_loss: 1.1746159600534156e-11
    num_steps_sampled: 4070000
    num_steps_trained: 4070000
    wait_time_ms: 72.145
  iterations_since_restore: 814
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 6961.745238780975
  time_this_iter_s: 8.149359226226807
  time_total_s: 6961.745238780975
  timestamp: 1594865288
  timesteps_since_restore: 4070000
  timesteps_this_iter: 5000
  timesteps_total: 4070000
  training_iteration: 814
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 6961 s, 814 iter, 4070000 ts, -246 rew

Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-08-16
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -246.13024624503217
  episode_reward_min: -1097.93749998801
  episodes_this_iter: 0
  episodes_total: 814
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 3.302
    dispatch_time_ms: 8.011
    learner:
      cur_lr: 0.0010889379773288965
      grad_gnorm: 2.023808240890503
      policy_entropy: 6.29408095846884e-05
      policy_loss: -5.7307978806875326e-08
      var_gnorm: 28.235733032226562
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 0.002697249408811331
    num_steps_sampled: 4075000
    num_steps_trained: 4075000
    wait_time_ms: 68.813
  iterations_since_restore: 815
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 6969.862347364426
  time_this_iter_s: 8.117108583450317
  time_total_s: 6969.862347364426
  timestamp: 1594865296
  timesteps_since_restore: 4075000
  timesteps_this_iter: 5000
  timesteps_total: 4075000
  training_iteration: 815
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 6969 s, 815 iter, 4075000 ts, -246 rew

agent-1: -149.99999999840443
agent-2: -149.99999999840443
agent-3: -149.99999999840443
agent-4: -149.99999999840443
agent-5: 3.0
Extrinsic Rewards:
0
0
0
0
3
Sum Reward: 3
Avg Reward: 0.6
Min Reward: 0
Max Reward: 3
Gini Coefficient: 0.8
20:20 Ratio: Undefined
Max-min Ratio: Undefined
agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-08-24
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -252.10024624496845
  episode_reward_min: -1097.93749998801
  episodes_this_iter: 2
  episodes_total: 816
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.704
    dispatch_time_ms: 8.53
    learner:
      cur_lr: 0.0010886050295084715
      grad_gnorm: 0.28513291478157043
      policy_entropy: 6.29416317678988e-05
      policy_loss: -7.858939277127774e-09
      var_gnorm: 28.23571014404297
      vf_explained_var: -1.0
      vf_loss: 4.2421102989465e-05
    num_steps_sampled: 4080000
    num_steps_trained: 4080000
    wait_time_ms: 70.433
  iterations_since_restore: 816
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 6978.022873163223
  time_this_iter_s: 8.160525798797607
  time_total_s: 6978.022873163223
  timestamp: 1594865304
  timesteps_since_restore: 4080000
  timesteps_this_iter: 5000
  timesteps_total: 4080000
  training_iteration: 816
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 6978 s, 816 iter, 4080000 ts, -252 rew

Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-08-32
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -252.10024624496845
  episode_reward_min: -1097.93749998801
  episodes_this_iter: 0
  episodes_total: 816
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.764
    dispatch_time_ms: 9.59
    learner:
      cur_lr: 0.0010882719652727246
      grad_gnorm: 4.055492877960205
      policy_entropy: 6.293652404565364e-05
      policy_loss: -8.222770020438475e-08
      var_gnorm: 28.23577117919922
      vf_explained_var: 1.7881393432617188e-07
      vf_loss: 0.010831174440681934
    num_steps_sampled: 4085000
    num_steps_trained: 4085000
    wait_time_ms: 70.886
  iterations_since_restore: 817
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 6986.194356679916
  time_this_iter_s: 8.171483516693115
  time_total_s: 6986.194356679916
  timestamp: 1594865312
  timesteps_since_restore: 4085000
  timesteps_this_iter: 5000
  timesteps_total: 4085000
  training_iteration: 817
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 6986 s, 817 iter, 4085000 ts, -252 rew

agent-1: -2.1875
agent-2: -101.71874999879704
agent-3: -101.74999999882424
agent-4: -499.9999999945971
agent-5: -101.71874999879704
Extrinsic Rewards:
4
2
2
0
2
Sum Reward: 10
Avg Reward: 2.0
Min Reward: 0
Max Reward: 4
Gini Coefficient: 0.32
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-08-41
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -260.1739962448786
  episode_reward_min: -1097.93749998801
  episodes_this_iter: 1
  episodes_total: 817
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 3.102
    dispatch_time_ms: 7.289
    learner:
      cur_lr: 0.0010879390174522996
      grad_gnorm: 1.2350903749465942
      policy_entropy: 0.00015885938773863018
      policy_loss: -3.751254382677871e-07
      var_gnorm: 28.235715866088867
      vf_explained_var: -1.0
      vf_loss: 0.008058221079409122
    num_steps_sampled: 4090000
    num_steps_trained: 4090000
    wait_time_ms: 66.157
  iterations_since_restore: 818
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 6994.359577178955
  time_this_iter_s: 8.165220499038696
  time_total_s: 6994.359577178955
  timestamp: 1594865321
  timesteps_since_restore: 4090000
  timesteps_this_iter: 5000
  timesteps_total: 4090000
  training_iteration: 818
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 6994 s, 818 iter, 4090000 ts, -260 rew

agent-1: 0.71875
agent-2: -249.99999999735493
agent-3: 0.7500000000136119
agent-4: -249.99999999735493
agent-5: -99.03124999894982
Extrinsic Rewards:
2
0
2
0
1
Sum Reward: 5
Avg Reward: 1.0
Min Reward: 0
Max Reward: 2
Gini Coefficient: 0.48
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-08-49
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -266.1496212448151
  episode_reward_min: -1097.93749998801
  episodes_this_iter: 1
  episodes_total: 818
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.742
    dispatch_time_ms: 8.197
    learner:
      cur_lr: 0.0010876059532165527
      grad_gnorm: 1.857314109802246
      policy_entropy: 6.295078492257744e-05
      policy_loss: -4.359823435606813e-08
      var_gnorm: 28.235736846923828
      vf_explained_var: 0.0
      vf_loss: 0.002272599609568715
    num_steps_sampled: 4095000
    num_steps_trained: 4095000
    wait_time_ms: 71.806
  iterations_since_restore: 819
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 7002.6543345451355
  time_this_iter_s: 8.29475736618042
  time_total_s: 7002.6543345451355
  timestamp: 1594865329
  timesteps_since_restore: 4095000
  timesteps_this_iter: 5000
  timesteps_total: 4095000
  training_iteration: 819
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 7002 s, 819 iter, 4095000 ts, -266 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-08-57
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -266.149621244815
  episode_reward_min: -1097.93749998801
  episodes_this_iter: 1
  episodes_total: 819
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 3.125
    dispatch_time_ms: 9.087
    learner:
      cur_lr: 0.0010872730053961277
      grad_gnorm: 40.00000762939453
      policy_entropy: 6.295444472925738e-05
      policy_loss: -0.00012662442168220878
      var_gnorm: 28.2357177734375
      vf_explained_var: 1.1920928955078125e-07
      vf_loss: 22859.8828125
    num_steps_sampled: 4100000
    num_steps_trained: 4100000
    wait_time_ms: 69.565
  iterations_since_restore: 820
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 7010.76008605957
  time_this_iter_s: 8.105751514434814
  time_total_s: 7010.76008605957
  timestamp: 1594865337
  timesteps_since_restore: 4100000
  timesteps_this_iter: 5000
  timesteps_total: 4100000
  training_iteration: 820
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 7010 s, 820 iter, 4100000 ts, -266 rew

agent-1: -399.99999999571816
agent-2: -46.99999999944068
agent-3: 4.0
agent-4: -248.99999999731384
agent-5: -399.99999999571816
Extrinsic Rewards:
0
3
4
1
0
Sum Reward: 8
Avg Reward: 1.6
Min Reward: 0
Max Reward: 4
Gini Coefficient: 0.55
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-09-05
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -277.0696212446969
  episode_reward_min: -1097.93749998801
  episodes_this_iter: 1
  episodes_total: 820
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.574
    dispatch_time_ms: 8.551
    learner:
      cur_lr: 0.0010869400575757027
      grad_gnorm: 3.403582811355591
      policy_entropy: 6.295402999967337e-05
      policy_loss: -6.40476898183806e-08
      var_gnorm: 28.235767364501953
      vf_explained_var: 0.0
      vf_loss: 0.00762947928160429
    num_steps_sampled: 4105000
    num_steps_trained: 4105000
    wait_time_ms: 71.429
  iterations_since_restore: 821
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 7018.945435523987
  time_this_iter_s: 8.185349464416504
  time_total_s: 7018.945435523987
  timestamp: 1594865345
  timesteps_since_restore: 4105000
  timesteps_this_iter: 5000
  timesteps_total: 4105000
  training_iteration: 821
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 7018 s, 821 iter, 4105000 ts, -277 rew

agent-1: -399.9999999956769
agent-2: -0.9070312500000002
agent-3: -50.65703124938548
agent-4: -250.2499999972315
agent-5: -399.9999999956769
Extrinsic Rewards:
0
4
3
1
0
Sum Reward: 8
Avg Reward: 1.6
Min Reward: 0
Max Reward: 4
Gini Coefficient: 0.55
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-09-13
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -288.0877618695766
  episode_reward_min: -1101.8140624879697
  episodes_this_iter: 1
  episodes_total: 821
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.943
    dispatch_time_ms: 6.722
    learner:
      cur_lr: 0.0010866069933399558
      grad_gnorm: 1.199764370918274
      policy_entropy: 0.0001589098828844726
      policy_loss: -3.6468404118750186e-07
      var_gnorm: 28.23572540283203
      vf_explained_var: -1.0
      vf_loss: 0.007717028725892305
    num_steps_sampled: 4110000
    num_steps_trained: 4110000
    wait_time_ms: 70.062
  iterations_since_restore: 822
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 7027.127589941025
  time_this_iter_s: 8.182154417037964
  time_total_s: 7027.127589941025
  timestamp: 1594865353
  timesteps_since_restore: 4110000
  timesteps_this_iter: 5000
  timesteps_total: 4110000
  training_iteration: 822
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 7027 s, 822 iter, 4110000 ts, -288 rew

agent-1: -99.99999999894987
agent-2: -99.99999999894987
agent-3: 2.0
agent-4: -99.99999999894987
agent-5: -99.99999999894987
Extrinsic Rewards:
0
0
2
0
0
Sum Reward: 2
Avg Reward: 0.4
Min Reward: 0
Max Reward: 2
Gini Coefficient: 0.8
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-09-22
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -292.06776186953465
  episode_reward_min: -1101.8140624879697
  episodes_this_iter: 1
  episodes_total: 822
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.563
    dispatch_time_ms: 8.139
    learner:
      cur_lr: 0.0010862740455195308
      grad_gnorm: 0.0005829498986713588
      policy_entropy: 6.296870560618117e-05
      policy_loss: -3.3424343154342395e-11
      var_gnorm: 28.235727310180664
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 2.2377207031798463e-10
    num_steps_sampled: 4115000
    num_steps_trained: 4115000
    wait_time_ms: 71.023
  iterations_since_restore: 823
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 7035.297701120377
  time_this_iter_s: 8.170111179351807
  time_total_s: 7035.297701120377
  timestamp: 1594865362
  timesteps_since_restore: 4115000
  timesteps_this_iter: 5000
  timesteps_total: 4115000
  training_iteration: 823
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 7035 s, 823 iter, 4115000 ts, -292 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-09-30
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -292.0677618695346
  episode_reward_min: -1101.8140624879697
  episodes_this_iter: 1
  episodes_total: 823
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.562
    dispatch_time_ms: 7.82
    learner:
      cur_lr: 0.001085940981283784
      grad_gnorm: 1.1879713535308838
      policy_entropy: 0.00015892076771706343
      policy_loss: -3.654584475043521e-07
      var_gnorm: 28.235729217529297
      vf_explained_var: -1.0
      vf_loss: 0.007700617890805006
    num_steps_sampled: 4120000
    num_steps_trained: 4120000
    wait_time_ms: 69.597
  iterations_since_restore: 824
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 7043.536525249481
  time_this_iter_s: 8.238824129104614
  time_total_s: 7043.536525249481
  timestamp: 1594865370
  timesteps_since_restore: 4120000
  timesteps_this_iter: 5000
  timesteps_total: 4120000
  training_iteration: 824
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 23.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 7043 s, 824 iter, 4120000 ts, -292 rew

Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-09-38
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -292.0677618695346
  episode_reward_min: -1101.8140624879697
  episodes_this_iter: 1
  episodes_total: 824
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.528
    dispatch_time_ms: 8.875
    learner:
      cur_lr: 0.0010856080334633589
      grad_gnorm: 1.7884552478790283
      policy_entropy: 6.298276275629178e-05
      policy_loss: -5.169829364604084e-08
      var_gnorm: 28.235750198364258
      vf_explained_var: 0.0
      vf_loss: 0.002106565749272704
    num_steps_sampled: 4125000
    num_steps_trained: 4125000
    wait_time_ms: 71.176
  iterations_since_restore: 825
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 7051.8037123680115
  time_this_iter_s: 8.267187118530273
  time_total_s: 7051.8037123680115
  timestamp: 1594865378
  timesteps_since_restore: 4125000
  timesteps_this_iter: 5000
  timesteps_total: 4125000
  training_iteration: 825
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.3/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 7051 s, 825 iter, 4125000 ts, -292 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-09-46
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -292.0677618695346
  episode_reward_min: -1101.8140624879697
  episodes_this_iter: 1
  episodes_total: 825
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.629
    dispatch_time_ms: 6.183
    learner:
      cur_lr: 0.001085274969227612
      grad_gnorm: 39.999996185302734
      policy_entropy: 0.00015898706624284387
      policy_loss: -7.273916708072647e-05
      var_gnorm: 28.235734939575195
      vf_explained_var: -0.0029724836349487305
      vf_loss: 847.825439453125
    num_steps_sampled: 4130000
    num_steps_trained: 4130000
    wait_time_ms: 71.352
  iterations_since_restore: 826
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 7059.956411600113
  time_this_iter_s: 8.15269923210144
  time_total_s: 7059.956411600113
  timestamp: 1594865386
  timesteps_since_restore: 4130000
  timesteps_this_iter: 5000
  timesteps_total: 4130000
  training_iteration: 826
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 7059 s, 826 iter, 4130000 ts, -292 rew

agent-1: -99.99999999894987
agent-2: 2.0
agent-3: -99.99999999894987
agent-4: -99.99999999894987
agent-5: -99.99999999894987
Extrinsic Rewards:
0
2
0
0
0
Sum Reward: 2
Avg Reward: 0.4
Min Reward: 0
Max Reward: 2
Gini Coefficient: 0.8
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-09-55
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -296.04776186949255
  episode_reward_min: -1101.8140624879697
  episodes_this_iter: 1
  episodes_total: 826
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 3.453
    dispatch_time_ms: 8.659
    learner:
      cur_lr: 0.001084942021407187
      grad_gnorm: 3.771678924560547
      policy_entropy: 6.30010908935219e-05
      policy_loss: -1.0417777218663105e-07
      var_gnorm: 28.23579216003418
      vf_explained_var: 0.0
      vf_loss: 0.009368347935378551
    num_steps_sampled: 4135000
    num_steps_trained: 4135000
    wait_time_ms: 69.958
  iterations_since_restore: 827
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 7068.18331861496
  time_this_iter_s: 8.226907014846802
  time_total_s: 7068.18331861496
  timestamp: 1594865395
  timesteps_since_restore: 4135000
  timesteps_this_iter: 5000
  timesteps_total: 4135000
  training_iteration: 827
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 7068 s, 827 iter, 4135000 ts, -296 rew

agent-1: -49.999999999481645
agent-2: 1.0
agent-3: -49.999999999481645
agent-4: -49.999999999481645
agent-5: -49.999999999481645
Extrinsic Rewards:
0
1
0
0
0
Sum Reward: 1
Avg Reward: 0.2
Min Reward: 0
Max Reward: 1
Gini Coefficient: 0.8
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-10-03
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -298.0377618694718
  episode_reward_min: -1101.8140624879697
  episodes_this_iter: 1
  episodes_total: 827
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.796
    dispatch_time_ms: 8.888
    learner:
      cur_lr: 0.0010846089571714401
      grad_gnorm: 39.999996185302734
      policy_entropy: 6.302169640548527e-05
      policy_loss: -0.00011458672815933824
      var_gnorm: 28.235742568969727
      vf_explained_var: 0.0
      vf_loss: 16573.330078125
    num_steps_sampled: 4140000
    num_steps_trained: 4140000
    wait_time_ms: 69.46
  iterations_since_restore: 828
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 7076.31459069252
  time_this_iter_s: 8.131272077560425
  time_total_s: 7076.31459069252
  timestamp: 1594865403
  timesteps_since_restore: 4140000
  timesteps_this_iter: 5000
  timesteps_total: 4140000
  training_iteration: 828
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 7076 s, 828 iter, 4140000 ts, -298 rew

agent-1: -98.9999999988954
agent-2: 3.0
agent-3: -199.999999997859
agent-4: -199.999999997859
agent-5: -199.999999997859
Extrinsic Rewards:
1
3
0
0
0
Sum Reward: 4
Avg Reward: 0.8
Min Reward: 0
Max Reward: 3
Gini Coefficient: 0.7
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-10-23
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -304.9977618693966
  episode_reward_min: -1101.8140624879697
  episodes_this_iter: 1
  episodes_total: 828
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 3.247
    dispatch_time_ms: 10.164
    learner:
      cur_lr: 0.001084276009351015
      grad_gnorm: 17.768535614013672
      policy_entropy: 6.300800305325538e-05
      policy_loss: 5.555058919526346e-07
      var_gnorm: 28.236167907714844
      vf_explained_var: 0.0
      vf_loss: 0.2078927904367447
    num_steps_sampled: 4145000
    num_steps_trained: 4145000
    wait_time_ms: 67.976
  iterations_since_restore: 829
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 7096.768536567688
  time_this_iter_s: 20.453945875167847
  time_total_s: 7096.768536567688
  timestamp: 1594865423
  timesteps_since_restore: 4145000
  timesteps_this_iter: 5000
  timesteps_total: 4145000
  training_iteration: 829
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 7096 s, 829 iter, 4145000 ts, -305 rew

agent-1: -299.9999999967528
agent-2: -299.9999999967528
agent-3: 2.75
agent-4: -299.9999999967528
agent-5: -99.2499999988536
Extrinsic Rewards:
0
0
4
0
2
Sum Reward: 6
Avg Reward: 1.2
Min Reward: 0
Max Reward: 4
Gini Coefficient: 0.6666666666666666
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-10-32
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -314.9627618692877
  episode_reward_min: -1101.8140624879697
  episodes_this_iter: 1
  episodes_total: 829
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.934
    dispatch_time_ms: 6.356
    learner:
      cur_lr: 0.0010839429451152682
      grad_gnorm: 40.0
      policy_entropy: 6.298023072304204e-05
      policy_loss: -6.173821748234332e-05
      var_gnorm: 28.23575782775879
      vf_explained_var: -2.384185791015625e-07
      vf_loss: 4582.470703125
    num_steps_sampled: 4150000
    num_steps_trained: 4150000
    wait_time_ms: 74.92
  iterations_since_restore: 830
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 7104.943722009659
  time_this_iter_s: 8.175185441970825
  time_total_s: 7104.943722009659
  timestamp: 1594865432
  timesteps_since_restore: 4150000
  timesteps_this_iter: 5000
  timesteps_total: 4150000
  training_iteration: 830
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 7104 s, 830 iter, 4150000 ts, -315 rew

agent-1: -199.99999999780377
agent-2: -199.99999999780377
agent-3: 4.0
agent-4: -199.99999999780377
agent-5: -199.99999999780377
Extrinsic Rewards:
0
0
4
0
0
Sum Reward: 4
Avg Reward: 0.8
Min Reward: 0
Max Reward: 4
Gini Coefficient: 0.8
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-10-40
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -321.43548850178604
  episode_reward_min: -1101.8140624879697
  episodes_this_iter: 1
  episodes_total: 830
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.723
    dispatch_time_ms: 8.283
    learner:
      cur_lr: 0.0010836099972948432
      grad_gnorm: 1.4015967845916748
      policy_entropy: 6.299592496361583e-05
      policy_loss: -3.7579045653046705e-08
      var_gnorm: 28.23577880859375
      vf_explained_var: 0.0
      vf_loss: 0.0012937596766278148
    num_steps_sampled: 4155000
    num_steps_trained: 4155000
    wait_time_ms: 70.725
  iterations_since_restore: 831
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 7113.0796711444855
  time_this_iter_s: 8.13594913482666
  time_total_s: 7113.0796711444855
  timestamp: 1594865440
  timesteps_since_restore: 4155000
  timesteps_this_iter: 5000
  timesteps_total: 4155000
  training_iteration: 831
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 7113 s, 831 iter, 4155000 ts, -321 rew

agent-1: -199.99999999784504
agent-2: 2.96875
agent-3: -99.03124999890878
agent-4: -199.99999999784504
agent-5: -199.99999999784504
Extrinsic Rewards:
0
3
1
0
0
Sum Reward: 4
Avg Reward: 0.8
Min Reward: 0
Max Reward: 3
Gini Coefficient: 0.7
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-10-48
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -328.39611350171054
  episode_reward_min: -1101.8140624879697
  episodes_this_iter: 1
  episodes_total: 831
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 3.476
    dispatch_time_ms: 7.99
    learner:
      cur_lr: 0.0010832770494744182
      grad_gnorm: 0.007163822650909424
      policy_entropy: 6.30167342023924e-05
      policy_loss: -4.707936263059764e-10
      var_gnorm: 28.235767364501953
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 3.3590552561690856e-08
    num_steps_sampled: 4160000
    num_steps_trained: 4160000
    wait_time_ms: 71.35
  iterations_since_restore: 832
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 7121.256369829178
  time_this_iter_s: 8.176698684692383
  time_total_s: 7121.256369829178
  timestamp: 1594865448
  timesteps_since_restore: 4160000
  timesteps_this_iter: 5000
  timesteps_total: 4160000
  training_iteration: 832
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 7121 s, 832 iter, 4160000 ts, -328 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-10-56
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -328.39611350171054
  episode_reward_min: -1101.8140624879697
  episodes_this_iter: 1
  episodes_total: 832
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 3.065
    dispatch_time_ms: 9.169
    learner:
      cur_lr: 0.0010829439852386713
      grad_gnorm: 1.4428120851516724
      policy_entropy: 6.303285044850782e-05
      policy_loss: -2.902831397477712e-08
      var_gnorm: 28.23578643798828
      vf_explained_var: 0.0
      vf_loss: 0.0013707255711778998
    num_steps_sampled: 4165000
    num_steps_trained: 4165000
    wait_time_ms: 70.921
  iterations_since_restore: 833
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 7129.671755075455
  time_this_iter_s: 8.415385246276855
  time_total_s: 7129.671755075455
  timestamp: 1594865456
  timesteps_since_restore: 4165000
  timesteps_this_iter: 5000
  timesteps_total: 4165000
  training_iteration: 833
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 7129 s, 833 iter, 4165000 ts, -328 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-11-05
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -328.39611350171054
  episode_reward_min: -1101.8140624879697
  episodes_this_iter: 1
  episodes_total: 833
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.878
    dispatch_time_ms: 9.471
    learner:
      cur_lr: 0.0010826110374182463
      grad_gnorm: 0.45532941818237305
      policy_entropy: 6.305386341409758e-05
      policy_loss: -1.1135229627257104e-08
      var_gnorm: 28.23577117919922
      vf_explained_var: 0.0
      vf_loss: 0.00013651973858941346
    num_steps_sampled: 4170000
    num_steps_trained: 4170000
    wait_time_ms: 69.141
  iterations_since_restore: 834
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 7137.851309299469
  time_this_iter_s: 8.179554224014282
  time_total_s: 7137.851309299469
  timestamp: 1594865465
  timesteps_since_restore: 4170000
  timesteps_this_iter: 5000
  timesteps_total: 4170000
  training_iteration: 834
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 7137 s, 834 iter, 4170000 ts, -328 rew

agent-1: -249.99999999735493
agent-2: -249.99999999735493
agent-3: 3.0
agent-4: -47.99999999945478
agent-5: -249.99999999735493
Extrinsic Rewards:
0
0
3
2
0
Sum Reward: 5
Avg Reward: 1.0
Min Reward: 0
Max Reward: 3
Gini Coefficient: 0.64
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-11-13
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -336.3461135016257
  episode_reward_min: -1101.8140624879697
  episodes_this_iter: 1
  episodes_total: 834
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 3.017
    dispatch_time_ms: 23.604
    learner:
      cur_lr: 0.0010822779731824994
      grad_gnorm: 3.572721242904663
      policy_entropy: 6.300892709987238e-05
      policy_loss: 1.7385274020398356e-07
      var_gnorm: 28.23578643798828
      vf_explained_var: 0.0
      vf_loss: 0.008404076099395752
    num_steps_sampled: 4175000
    num_steps_trained: 4175000
    wait_time_ms: 65.335
  iterations_since_restore: 835
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 7146.470500230789
  time_this_iter_s: 8.61919093132019
  time_total_s: 7146.470500230789
  timestamp: 1594865473
  timesteps_since_restore: 4175000
  timesteps_this_iter: 5000
  timesteps_total: 4175000
  training_iteration: 835
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 7146 s, 835 iter, 4175000 ts, -336 rew

agent-1: -299.9999999968351
agent-2: -47.99999999945478
agent-3: -299.9999999968351
agent-4: 3.0
agent-5: -148.99999999839173
Extrinsic Rewards:
0
2
0
3
1
Sum Reward: 6
Avg Reward: 1.2
Min Reward: 0
Max Reward: 3
Gini Coefficient: 0.5333333333333333
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-11-22
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -344.28611350154097
  episode_reward_min: -1101.8140624879697
  episodes_this_iter: 1
  episodes_total: 835
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.646
    dispatch_time_ms: 36.503
    learner:
      cur_lr: 0.0010819450253620744
      grad_gnorm: 0.01729576289653778
      policy_entropy: 6.299440428847447e-05
      policy_loss: -1.4590768593336634e-09
      var_gnorm: 28.235795974731445
      vf_explained_var: 0.0
      vf_loss: 1.964884432936742e-07
    num_steps_sampled: 4180000
    num_steps_trained: 4180000
    wait_time_ms: 59.306
  iterations_since_restore: 836
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 7155.325269937515
  time_this_iter_s: 8.854769706726074
  time_total_s: 7155.325269937515
  timestamp: 1594865482
  timesteps_since_restore: 4180000
  timesteps_this_iter: 5000
  timesteps_total: 4180000
  training_iteration: 836
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 7155 s, 836 iter, 4180000 ts, -344 rew

agent-1: -99.99999999894987
agent-2: -99.99999999894987
agent-3: 2.0
agent-4: -99.99999999894987
agent-5: -99.99999999894987
Extrinsic Rewards:
0
0
2
0
0
Sum Reward: 2
Avg Reward: 0.4
Min Reward: 0
Max Reward: 2
Gini Coefficient: 0.8
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-11-31
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -348.266113501499
  episode_reward_min: -1101.8140624879697
  episodes_this_iter: 1
  episodes_total: 836
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.694
    dispatch_time_ms: 24.537
    learner:
      cur_lr: 0.0010816119611263275
      grad_gnorm: 1.0511306524276733
      policy_entropy: 6.301929533947259e-05
      policy_loss: 1.7515381500743388e-07
      var_gnorm: 28.235797882080078
      vf_explained_var: 0.0
      vf_loss: 0.000727525562979281
    num_steps_sampled: 4185000
    num_steps_trained: 4185000
    wait_time_ms: 59.131
  iterations_since_restore: 837
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 7164.046883106232
  time_this_iter_s: 8.72161316871643
  time_total_s: 7164.046883106232
  timestamp: 1594865491
  timesteps_since_restore: 4185000
  timesteps_this_iter: 5000
  timesteps_total: 4185000
  training_iteration: 837
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 7164 s, 837 iter, 4185000 ts, -348 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-11-40
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -348.266113501499
  episode_reward_min: -1101.8140624879697
  episodes_this_iter: 1
  episodes_total: 837
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.525
    dispatch_time_ms: 21.446
    learner:
      cur_lr: 0.0010812790133059025
      grad_gnorm: 40.0
      policy_entropy: 6.303560076048598e-05
      policy_loss: -3.201036452082917e-05
      var_gnorm: 28.235803604125977
      vf_explained_var: 0.0
      vf_loss: 1155.8536376953125
    num_steps_sampled: 4190000
    num_steps_trained: 4190000
    wait_time_ms: 65.483
  iterations_since_restore: 838
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 7172.874541521072
  time_this_iter_s: 8.827658414840698
  time_total_s: 7172.874541521072
  timestamp: 1594865500
  timesteps_since_restore: 4190000
  timesteps_this_iter: 5000
  timesteps_total: 4190000
  training_iteration: 838
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 7172 s, 838 iter, 4190000 ts, -348 rew

agent-1: -99.99999999896329
agent-2: 1.0
agent-3: 1.0
agent-4: -99.99999999896329
agent-5: -99.99999999896329
Extrinsic Rewards:
0
1
1
0
0
Sum Reward: 2
Avg Reward: 0.4
Min Reward: 0
Max Reward: 1
Gini Coefficient: 0.6
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-11-49
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -351.2461135014679
  episode_reward_min: -1101.8140624879697
  episodes_this_iter: 1
  episodes_total: 838
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 3.339
    dispatch_time_ms: 30.215
    learner:
      cur_lr: 0.0010809459490701556
      grad_gnorm: 7.2506608963012695
      policy_entropy: 6.30429494776763e-05
      policy_loss: 4.001185516244732e-07
      var_gnorm: 28.235855102539062
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 0.034617550671100616
    num_steps_sampled: 4195000
    num_steps_trained: 4195000
    wait_time_ms: 57.275
  iterations_since_restore: 839
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 7181.633607625961
  time_this_iter_s: 8.759066104888916
  time_total_s: 7181.633607625961
  timestamp: 1594865509
  timesteps_since_restore: 4195000
  timesteps_this_iter: 5000
  timesteps_total: 4195000
  training_iteration: 839
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 7181 s, 839 iter, 4195000 ts, -351 rew

agent-1: 3.0
agent-2: -149.99999999837684
agent-3: -149.99999999837684
agent-4: -149.99999999837684
agent-5: -149.99999999837684
Extrinsic Rewards:
3
0
0
0
0
Sum Reward: 3
Avg Reward: 0.6
Min Reward: 0
Max Reward: 3
Gini Coefficient: 0.8
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-11-57
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -357.216113501403
  episode_reward_min: -1101.8140624879697
  episodes_this_iter: 1
  episodes_total: 839
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.772
    dispatch_time_ms: 33.608
    learner:
      cur_lr: 0.0010806130012497306
      grad_gnorm: 0.18876181542873383
      policy_entropy: 6.29804635536857e-05
      policy_loss: -8.172186538590864e-11
      var_gnorm: 28.235828399658203
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 1.8592781998449937e-05
    num_steps_sampled: 4200000
    num_steps_trained: 4200000
    wait_time_ms: 58.425
  iterations_since_restore: 840
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 7190.4683582782745
  time_this_iter_s: 8.834750652313232
  time_total_s: 7190.4683582782745
  timestamp: 1594865517
  timesteps_since_restore: 4200000
  timesteps_this_iter: 5000
  timesteps_total: 4200000
  training_iteration: 840
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 7190 s, 840 iter, 4200000 ts, -357 rew

agent-1: -49.999999999481645
agent-2: -49.999999999481645
agent-3: -49.999999999481645
agent-4: 1.0
agent-5: -49.999999999481645
Extrinsic Rewards:
0
0
0
1
0
Sum Reward: 1
Avg Reward: 0.2
Min Reward: 0
Max Reward: 1
Gini Coefficient: 0.8
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-12-06
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -359.20611350138233
  episode_reward_min: -1101.8140624879697
  episodes_this_iter: 1
  episodes_total: 840
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.714
    dispatch_time_ms: 7.406
    learner:
      cur_lr: 0.0010802800534293056
      grad_gnorm: 0.9702484607696533
      policy_entropy: 6.307334842858836e-05
      policy_loss: -5.324798380001994e-09
      var_gnorm: 28.235837936401367
      vf_explained_var: 0.0
      vf_loss: 0.0006198695045895875
    num_steps_sampled: 4205000
    num_steps_trained: 4205000
    wait_time_ms: 75.385
  iterations_since_restore: 841
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 7198.853857517242
  time_this_iter_s: 8.385499238967896
  time_total_s: 7198.853857517242
  timestamp: 1594865526
  timesteps_since_restore: 4205000
  timesteps_this_iter: 5000
  timesteps_total: 4205000
  training_iteration: 841
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 7198 s, 841 iter, 4205000 ts, -359 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-12-15
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -359.2061135013823
  episode_reward_min: -1101.8140624879697
  episodes_this_iter: 1
  episodes_total: 841
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.856
    dispatch_time_ms: 23.682
    learner:
      cur_lr: 0.0010799469891935587
      grad_gnorm: 39.999996185302734
      policy_entropy: 6.31224102107808e-05
      policy_loss: -6.158056203275919e-05
      var_gnorm: 28.23581886291504
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 5984.72900390625
    num_steps_sampled: 4210000
    num_steps_trained: 4210000
    wait_time_ms: 57.215
  iterations_since_restore: 842
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 7207.645765066147
  time_this_iter_s: 8.791907548904419
  time_total_s: 7207.645765066147
  timestamp: 1594865535
  timesteps_since_restore: 4210000
  timesteps_this_iter: 5000
  timesteps_total: 4210000
  training_iteration: 842
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 7207 s, 842 iter, 4210000 ts, -359 rew

agent-1: -149.99999999840443
agent-2: -149.99999999840443
agent-3: 3.0
agent-4: -149.99999999840443
agent-5: -149.99999999840443
Extrinsic Rewards:
0
0
3
0
0
Sum Reward: 3
Avg Reward: 0.6
Min Reward: 0
Max Reward: 3
Gini Coefficient: 0.8
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-12-23
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -365.17611350131847
  episode_reward_min: -1101.8140624879697
  episodes_this_iter: 1
  episodes_total: 842
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.937
    dispatch_time_ms: 22.147
    learner:
      cur_lr: 0.0010796140413731337
      grad_gnorm: 5.103496074676514
      policy_entropy: 6.304022099357098e-05
      policy_loss: 5.352486027732084e-07
      var_gnorm: 28.235857009887695
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 0.017146479338407516
    num_steps_sampled: 4215000
    num_steps_trained: 4215000
    wait_time_ms: 60.076
  iterations_since_restore: 843
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 7216.384425640106
  time_this_iter_s: 8.73866057395935
  time_total_s: 7216.384425640106
  timestamp: 1594865543
  timesteps_since_restore: 4215000
  timesteps_this_iter: 5000
  timesteps_total: 4215000
  training_iteration: 843
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 7216 s, 843 iter, 4215000 ts, -365 rew

agent-1: -349.9999999962501
agent-2: 0.5312500000275931
agent-3: -349.9999999962501
agent-4: -199.03124999784518
agent-5: 0.5
Extrinsic Rewards:
0
3
0
1
3
Sum Reward: 7
Avg Reward: 1.4
Min Reward: 0
Max Reward: 3
Gini Coefficient: 0.5142857142857142
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-12-32
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -374.1561135012217
  episode_reward_min: -1101.8140624879697
  episodes_this_iter: 1
  episodes_total: 843
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.45
    dispatch_time_ms: 27.184
    learner:
      cur_lr: 0.0010792809771373868
      grad_gnorm: 3.3237056732177734
      policy_entropy: 6.301346002146602e-05
      policy_loss: -9.986030136133195e-08
      var_gnorm: 28.23585319519043
      vf_explained_var: 0.0
      vf_loss: 0.007274310104548931
    num_steps_sampled: 4220000
    num_steps_trained: 4220000
    wait_time_ms: 59.044
  iterations_since_restore: 844
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 7225.209664821625
  time_this_iter_s: 8.825239181518555
  time_total_s: 7225.209664821625
  timestamp: 1594865552
  timesteps_since_restore: 4220000
  timesteps_this_iter: 5000
  timesteps_total: 4220000
  training_iteration: 844
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 7225 s, 844 iter, 4220000 ts, -374 rew

agent-1: -199.99999999784504
agent-2: -199.99999999784504
agent-3: 4.0
agent-4: -199.99999999784504
agent-5: -199.99999999784504
Extrinsic Rewards:
0
0
4
0
0
Sum Reward: 4
Avg Reward: 0.8
Min Reward: 0
Max Reward: 4
Gini Coefficient: 0.8
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-12-41
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -382.11611350113554
  episode_reward_min: -1101.8140624879697
  episodes_this_iter: 1
  episodes_total: 844
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 3.026
    dispatch_time_ms: 35.882
    learner:
      cur_lr: 0.0010789480293169618
      grad_gnorm: 6.49253511428833
      policy_entropy: 6.299750384641811e-05
      policy_loss: 3.1873571515461663e-07
      var_gnorm: 28.235919952392578
      vf_explained_var: 0.0
      vf_loss: 0.031781792640686035
    num_steps_sampled: 4225000
    num_steps_trained: 4225000
    wait_time_ms: 50.89
  iterations_since_restore: 845
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 7234.048380374908
  time_this_iter_s: 8.838715553283691
  time_total_s: 7234.048380374908
  timestamp: 1594865561
  timesteps_since_restore: 4225000
  timesteps_this_iter: 5000
  timesteps_total: 4225000
  training_iteration: 845
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 7234 s, 845 iter, 4225000 ts, -382 rew

agent-1: 2.0
agent-2: -99.99999999894987
agent-3: -99.99999999894987
agent-4: -99.99999999894987
agent-5: -99.99999999894987
Extrinsic Rewards:
2
0
0
0
0
Sum Reward: 2
Avg Reward: 0.4
Min Reward: 0
Max Reward: 2
Gini Coefficient: 0.8
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-12-50
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -386.09611350109355
  episode_reward_min: -1101.8140624879697
  episodes_this_iter: 1
  episodes_total: 845
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.515
    dispatch_time_ms: 26.318
    learner:
      cur_lr: 0.001078614965081215
      grad_gnorm: 40.0
      policy_entropy: 6.293098704190925e-05
      policy_loss: -4.507671474129893e-05
      var_gnorm: 28.235889434814453
      vf_explained_var: 0.0
      vf_loss: 3212.0078125
    num_steps_sampled: 4230000
    num_steps_trained: 4230000
    wait_time_ms: 58.121
  iterations_since_restore: 846
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 7242.855203866959
  time_this_iter_s: 8.806823492050171
  time_total_s: 7242.855203866959
  timestamp: 1594865570
  timesteps_since_restore: 4230000
  timesteps_this_iter: 5000
  timesteps_total: 4230000
  training_iteration: 846
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 7242 s, 846 iter, 4230000 ts, -386 rew

agent-1: -149.9999999984318
agent-2: -48.9999999994684
agent-3: -149.9999999984318
agent-4: 2.0
agent-5: -149.9999999984318
Extrinsic Rewards:
0
1
0
2
0
Sum Reward: 3
Avg Reward: 0.6
Min Reward: 0
Max Reward: 2
Gini Coefficient: 0.6666666666666666
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-12-59
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -391.06611350104123
  episode_reward_min: -1101.8140624879697
  episodes_this_iter: 1
  episodes_total: 846
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 3.217
    dispatch_time_ms: 30.986
    learner:
      cur_lr: 0.0010782820172607899
      grad_gnorm: 1.007330060005188
      policy_entropy: 6.294422200880945e-05
      policy_loss: 4.9676614821692056e-08
      var_gnorm: 28.235897064208984
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 0.0006682136445306242
    num_steps_sampled: 4235000
    num_steps_trained: 4235000
    wait_time_ms: 62.271
  iterations_since_restore: 847
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 7251.615003585815
  time_this_iter_s: 8.759799718856812
  time_total_s: 7251.615003585815
  timestamp: 1594865579
  timesteps_since_restore: 4235000
  timesteps_this_iter: 5000
  timesteps_total: 4235000
  training_iteration: 847
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 7251 s, 847 iter, 4235000 ts, -391 rew

agent-1: 4.0
agent-2: -147.9999999983504
agent-3: -449.99999999520065
agent-4: -46.99999999944068
agent-5: -449.99999999520065
Extrinsic Rewards:
4
2
0
3
0
Sum Reward: 9
Avg Reward: 1.8
Min Reward: 0
Max Reward: 4
Gini Coefficient: 0.4888888888888889
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-13-08
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -401.9761135009232
  episode_reward_min: -1101.8140624879697
  episodes_this_iter: 1
  episodes_total: 847
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.993
    dispatch_time_ms: 34.378
    learner:
      cur_lr: 0.001077948953025043
      grad_gnorm: 31.01723289489746
      policy_entropy: 6.297459185589105e-05
      policy_loss: 1.1759956564105778e-08
      var_gnorm: 28.235898971557617
      vf_explained_var: -2.1457672119140625e-06
      vf_loss: 0.5020133852958679
    num_steps_sampled: 4240000
    num_steps_trained: 4240000
    wait_time_ms: 48.719
  iterations_since_restore: 848
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 7260.364289999008
  time_this_iter_s: 8.749286413192749
  time_total_s: 7260.364289999008
  timestamp: 1594865588
  timesteps_since_restore: 4240000
  timesteps_this_iter: 5000
  timesteps_total: 4240000
  training_iteration: 848
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 7260 s, 848 iter, 4240000 ts, -402 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-13-16
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -401.9761135009232
  episode_reward_min: -1101.8140624879697
  episodes_this_iter: 1
  episodes_total: 848
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.985
    dispatch_time_ms: 7.896
    learner:
      cur_lr: 0.001077616005204618
      grad_gnorm: 0.026963792741298676
      policy_entropy: 6.304275302682072e-05
      policy_loss: 3.4154485462067896e-08
      var_gnorm: 28.235912322998047
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 2.729376774368575e-06
    num_steps_sampled: 4245000
    num_steps_trained: 4245000
    wait_time_ms: 76.133
  iterations_since_restore: 849
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 7268.941245555878
  time_this_iter_s: 8.576955556869507
  time_total_s: 7268.941245555878
  timestamp: 1594865596
  timesteps_since_restore: 4245000
  timesteps_this_iter: 5000
  timesteps_total: 4245000
  training_iteration: 849
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 7268 s, 849 iter, 4245000 ts, -402 rew

agent-1: -49.999999999481645
agent-2: 1.0
agent-3: -49.999999999481645
agent-4: -49.999999999481645
agent-5: -49.999999999481645
Extrinsic Rewards:
0
1
0
0
0
Sum Reward: 1
Avg Reward: 0.2
Min Reward: 0
Max Reward: 1
Gini Coefficient: 0.8
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-13-24
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -403.96611350090245
  episode_reward_min: -1101.8140624879697
  episodes_this_iter: 1
  episodes_total: 849
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 3.108
    dispatch_time_ms: 9.681
    learner:
      cur_lr: 0.001077283057384193
      grad_gnorm: 0.019090458750724792
      policy_entropy: 6.306928116828203e-05
      policy_loss: 5.426487037496486e-10
      var_gnorm: 28.235918045043945
      vf_explained_var: 0.0
      vf_loss: 2.4052707203736645e-07
    num_steps_sampled: 4250000
    num_steps_trained: 4250000
    wait_time_ms: 67.813
  iterations_since_restore: 850
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 7277.084042310715
  time_this_iter_s: 8.142796754837036
  time_total_s: 7277.084042310715
  timestamp: 1594865604
  timesteps_since_restore: 4250000
  timesteps_this_iter: 5000
  timesteps_total: 4250000
  training_iteration: 850
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 7277 s, 850 iter, 4250000 ts, -404 rew

agent-1: -449.9999999951579
agent-2: -449.9999999951579
agent-3: -149.2499999983085
agent-4: -49.46874999939871
agent-5: 0.28125
Extrinsic Rewards:
0
0
2
3
4
Sum Reward: 9
Avg Reward: 1.8
Min Reward: 0
Max Reward: 4
Gini Coefficient: 0.4888888888888889
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-13-33
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -414.95048850078257
  episode_reward_min: -1101.8140624879697
  episodes_this_iter: 1
  episodes_total: 850
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.475
    dispatch_time_ms: 9.033
    learner:
      cur_lr: 0.001076949993148446
      grad_gnorm: 0.056893955916166306
      policy_entropy: 6.31220027571544e-05
      policy_loss: 1.4561766903398166e-08
      var_gnorm: 28.23592185974121
      vf_explained_var: 5.960464477539063e-08
      vf_loss: 3.0819048788544023e-06
    num_steps_sampled: 4255000
    num_steps_trained: 4255000
    wait_time_ms: 70.759
  iterations_since_restore: 851
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 7285.297023773193
  time_this_iter_s: 8.212981462478638
  time_total_s: 7285.297023773193
  timestamp: 1594865613
  timesteps_since_restore: 4255000
  timesteps_this_iter: 5000
  timesteps_total: 4255000
  training_iteration: 851
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 7285 s, 851 iter, 4255000 ts, -415 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-13-41
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -414.9504885007825
  episode_reward_min: -1101.8140624879697
  episodes_this_iter: 1
  episodes_total: 851
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.609
    dispatch_time_ms: 7.292
    learner:
      cur_lr: 0.001076617045328021
      grad_gnorm: 0.02265588939189911
      policy_entropy: 6.315491191344336e-05
      policy_loss: 5.561237581552803e-10
      var_gnorm: 28.23592758178711
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 3.3961731560339103e-07
    num_steps_sampled: 4260000
    num_steps_trained: 4260000
    wait_time_ms: 74.394
  iterations_since_restore: 852
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 7293.486775636673
  time_this_iter_s: 8.189751863479614
  time_total_s: 7293.486775636673
  timestamp: 1594865621
  timesteps_since_restore: 4260000
  timesteps_this_iter: 5000
  timesteps_total: 4260000
  training_iteration: 852
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 7293 s, 852 iter, 4260000 ts, -415 rew

agent-1: -299.9999999967528
agent-2: 4.0
agent-3: -299.9999999967528
agent-4: -299.9999999967528
agent-5: -97.99999999893765
Extrinsic Rewards:
0
4
0
0
2
Sum Reward: 6
Avg Reward: 1.2
Min Reward: 0
Max Reward: 4
Gini Coefficient: 0.6666666666666666
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-13-49
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -424.89048850067456
  episode_reward_min: -1101.8140624879697
  episodes_this_iter: 1
  episodes_total: 852
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.58
    dispatch_time_ms: 9.348
    learner:
      cur_lr: 0.0010762839810922742
      grad_gnorm: 0.19099192321300507
      policy_entropy: 6.319890235317871e-05
      policy_loss: 5.450521456396018e-08
      var_gnorm: 28.23593521118164
      vf_explained_var: 5.960464477539063e-08
      vf_loss: 2.4022760044317693e-05
    num_steps_sampled: 4265000
    num_steps_trained: 4265000
    wait_time_ms: 70.294
  iterations_since_restore: 853
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 7301.6456735134125
  time_this_iter_s: 8.158897876739502
  time_total_s: 7301.6456735134125
  timestamp: 1594865629
  timesteps_since_restore: 4265000
  timesteps_this_iter: 5000
  timesteps_total: 4265000
  training_iteration: 853
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 7301 s, 853 iter, 4265000 ts, -425 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-13-57
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -424.89048850067445
  episode_reward_min: -1101.8140624879697
  episodes_this_iter: 1
  episodes_total: 853
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.935
    dispatch_time_ms: 8.873
    learner:
      cur_lr: 0.0010759510332718492
      grad_gnorm: 2.7736542224884033
      policy_entropy: 6.326526636257768e-05
      policy_loss: 5.292575977478009e-08
      var_gnorm: 28.235933303833008
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 0.005065685138106346
    num_steps_sampled: 4270000
    num_steps_trained: 4270000
    wait_time_ms: 70.304
  iterations_since_restore: 854
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 7309.906300544739
  time_this_iter_s: 8.260627031326294
  time_total_s: 7309.906300544739
  timestamp: 1594865637
  timesteps_since_restore: 4270000
  timesteps_this_iter: 5000
  timesteps_total: 4270000
  training_iteration: 854
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 7309 s, 854 iter, 4270000 ts, -425 rew

agent-1: -49.46874999939871
agent-2: -149.2499999983085
agent-3: 0.28125
agent-4: -449.9999999951579
agent-5: -449.9999999951579
Extrinsic Rewards:
3
2
4
0
0
Sum Reward: 9
Avg Reward: 1.8
Min Reward: 0
Max Reward: 4
Gini Coefficient: 0.4888888888888889
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-14-06
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -435.8748635005546
  episode_reward_min: -1101.8140624879697
  episodes_this_iter: 1
  episodes_total: 854
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 3.167
    dispatch_time_ms: 6.268
    learner:
      cur_lr: 0.0010756179690361023
      grad_gnorm: 0.7670286297798157
      policy_entropy: 6.323530396912247e-05
      policy_loss: -2.088648010101224e-08
      var_gnorm: 28.235965728759766
      vf_explained_var: 0.0
      vf_loss: 0.0003882684395648539
    num_steps_sampled: 4275000
    num_steps_trained: 4275000
    wait_time_ms: 72.442
  iterations_since_restore: 855
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 7318.075504541397
  time_this_iter_s: 8.169203996658325
  time_total_s: 7318.075504541397
  timestamp: 1594865646
  timesteps_since_restore: 4275000
  timesteps_this_iter: 5000
  timesteps_total: 4275000
  training_iteration: 855
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 7318 s, 855 iter, 4275000 ts, -436 rew

agent-1: 3.0
agent-2: -151.46874999830928
agent-3: -50.4687499994817
agent-4: -299.9999999967537
agent-5: -299.9999999967537
Extrinsic Rewards:
3
1
2
0
0
Sum Reward: 6
Avg Reward: 1.2
Min Reward: 0
Max Reward: 3
Gini Coefficient: 0.5333333333333333
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-14-14
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -443.8642385004676
  episode_reward_min: -1101.8140624879697
  episodes_this_iter: 1
  episodes_total: 855
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.714
    dispatch_time_ms: 6.925
    learner:
      cur_lr: 0.0010752850212156773
      grad_gnorm: 39.999996185302734
      policy_entropy: 6.330313044600189e-05
      policy_loss: -1.5354629795183428e-05
      var_gnorm: 28.235958099365234
      vf_explained_var: 0.0
      vf_loss: 353.0872497558594
    num_steps_sampled: 4280000
    num_steps_trained: 4280000
    wait_time_ms: 69.78
  iterations_since_restore: 856
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 7326.217463493347
  time_this_iter_s: 8.141958951950073
  time_total_s: 7326.217463493347
  timestamp: 1594865654
  timesteps_since_restore: 4280000
  timesteps_this_iter: 5000
  timesteps_total: 4280000
  training_iteration: 856
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 7326 s, 856 iter, 4280000 ts, -444 rew

agent-1: -199.999999997859
agent-2: -98.9999999988954
agent-3: -199.999999997859
agent-4: -199.999999997859
agent-5: 3.0
Extrinsic Rewards:
0
1
0
0
3
Sum Reward: 4
Avg Reward: 0.8
Min Reward: 0
Max Reward: 3
Gini Coefficient: 0.7
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-14-22
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -450.82423850039237
  episode_reward_min: -1101.8140624879697
  episodes_this_iter: 1
  episodes_total: 856
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 3.81
    dispatch_time_ms: 7.921
    learner:
      cur_lr: 0.0010749519569799304
      grad_gnorm: 0.909527063369751
      policy_entropy: 6.335277430480346e-05
      policy_loss: -3.810441029372669e-08
      var_gnorm: 28.235979080200195
      vf_explained_var: 0.0
      vf_loss: 0.0005447610164992511
    num_steps_sampled: 4285000
    num_steps_trained: 4285000
    wait_time_ms: 68.226
  iterations_since_restore: 857
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 7334.385939121246
  time_this_iter_s: 8.16847562789917
  time_total_s: 7334.385939121246
  timestamp: 1594865662
  timesteps_since_restore: 4285000
  timesteps_this_iter: 5000
  timesteps_total: 4285000
  training_iteration: 857
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 7334 s, 857 iter, 4285000 ts, -451 rew

agent-1: -99.99999999896329
agent-2: 1.0
agent-3: -99.99999999896329
agent-4: -99.99999999896329
agent-5: 1.0
Extrinsic Rewards:
0
1
0
0
1
Sum Reward: 2
Avg Reward: 0.4
Min Reward: 0
Max Reward: 1
Gini Coefficient: 0.6
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-14-41
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -453.8042385003613
  episode_reward_min: -1101.8140624879697
  episodes_this_iter: 1
  episodes_total: 857
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.651
    dispatch_time_ms: 7.232
    learner:
      cur_lr: 0.0010746190091595054
      grad_gnorm: 0.022056356072425842
      policy_entropy: 6.343657878460363e-05
      policy_loss: 6.006029562577453e-10
      var_gnorm: 28.235971450805664
      vf_explained_var: 0.0
      vf_loss: 3.2065517530099896e-07
    num_steps_sampled: 4290000
    num_steps_trained: 4290000
    wait_time_ms: 71.77
  iterations_since_restore: 858
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 7353.1116778850555
  time_this_iter_s: 18.725738763809204
  time_total_s: 7353.1116778850555
  timestamp: 1594865681
  timesteps_since_restore: 4290000
  timesteps_this_iter: 5000
  timesteps_total: 4290000
  training_iteration: 858
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 7353 s, 858 iter, 4290000 ts, -454 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-14-49
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -453.80423850036124
  episode_reward_min: -1101.8140624879697
  episodes_this_iter: 1
  episodes_total: 858
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.863
    dispatch_time_ms: 7.91
    learner:
      cur_lr: 0.0010742859449237585
      grad_gnorm: 1.3186144828796387
      policy_entropy: 6.351742194965482e-05
      policy_loss: -3.590637476236225e-08
      var_gnorm: 28.235990524291992
      vf_explained_var: 0.0
      vf_loss: 0.0011453864863142371
    num_steps_sampled: 4295000
    num_steps_trained: 4295000
    wait_time_ms: 71.577
  iterations_since_restore: 859
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 7361.236020326614
  time_this_iter_s: 8.124342441558838
  time_total_s: 7361.236020326614
  timestamp: 1594865689
  timesteps_since_restore: 4295000
  timesteps_this_iter: 5000
  timesteps_total: 4295000
  training_iteration: 859
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 7361 s, 859 iter, 4295000 ts, -454 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-14-57
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -453.80423850036124
  episode_reward_min: -1101.8140624879697
  episodes_this_iter: 1
  episodes_total: 859
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 3.827
    dispatch_time_ms: 8.831
    learner:
      cur_lr: 0.0010739529971033335
      grad_gnorm: 4.158144474029541
      policy_entropy: 6.364353612298146e-05
      policy_loss: 4.9703771765052807e-08
      var_gnorm: 28.235977172851562
      vf_explained_var: 0.0
      vf_loss: 0.011385628022253513
    num_steps_sampled: 4300000
    num_steps_trained: 4300000
    wait_time_ms: 71.906
  iterations_since_restore: 860
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 7369.374401330948
  time_this_iter_s: 8.138381004333496
  time_total_s: 7369.374401330948
  timestamp: 1594865697
  timesteps_since_restore: 4300000
  timesteps_this_iter: 5000
  timesteps_total: 4300000
  training_iteration: 860
  
agent-1: -49.999999999481645
agent-2: -49.999999999481645
agent-3: -49.999999999481645
agent-4: 1.0
agent-5: -49.999999999481645
Extrinsic Rewards:
0
0
0
1
0
Sum Reward: 1
Avg Reward: 0.2
Min Reward: 0
Max Reward: 1
Gini Coefficient: 0.8
20:20 Ratio: Undefined
Max-min Ratio: Undefined
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 7369 s, 860 iter, 4300000 ts, -454 rew

Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-15-06
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -455.79423850034055
  episode_reward_min: -1101.8140624879697
  episodes_this_iter: 1
  episodes_total: 860
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.685
    dispatch_time_ms: 6.81
    learner:
      cur_lr: 0.0010736200492829084
      grad_gnorm: 1.074973464012146
      policy_entropy: 6.387574831023812e-05
      policy_loss: -3.358286804200361e-08
      var_gnorm: 28.235977172851562
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 0.0007609848398715258
    num_steps_sampled: 4305000
    num_steps_trained: 4305000
    wait_time_ms: 68.886
  iterations_since_restore: 861
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 7376.974923849106
  time_this_iter_s: 7.600522518157959
  time_total_s: 7376.974923849106
  timestamp: 1594865706
  timesteps_since_restore: 4305000
  timesteps_this_iter: 5000
  timesteps_total: 4305000
  training_iteration: 861
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 7376 s, 861 iter, 4305000 ts, -456 rew

agent-1: -249.99999999735493
agent-2: 3.0
agent-3: -249.99999999735493
agent-4: -47.99999999945478
agent-5: -249.99999999735493
Extrinsic Rewards:
0
3
0
2
0
Sum Reward: 5
Avg Reward: 1.0
Min Reward: 0
Max Reward: 3
Gini Coefficient: 0.64
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-15-14
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -455.1793891767451
  episode_reward_min: -1101.8140624879697
  episodes_this_iter: 1
  episodes_total: 861
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 3.379
    dispatch_time_ms: 8.216
    learner:
      cur_lr: 0.0010732869850471616
      grad_gnorm: 39.999996185302734
      policy_entropy: 6.4047533669509e-05
      policy_loss: -2.5646886570029892e-05
      var_gnorm: 28.235986709594727
      vf_explained_var: 0.0
      vf_loss: 735.0748901367188
    num_steps_sampled: 4310000
    num_steps_trained: 4310000
    wait_time_ms: 72.15
  iterations_since_restore: 862
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 7385.133071184158
  time_this_iter_s: 8.15814733505249
  time_total_s: 7385.133071184158
  timestamp: 1594865714
  timesteps_since_restore: 4310000
  timesteps_this_iter: 5000
  timesteps_total: 4310000
  training_iteration: 862
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 7385 s, 862 iter, 4310000 ts, -455 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-15-23
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -448.0156249951745
  episode_reward_min: -1101.8140624879697
  episodes_this_iter: 1
  episodes_total: 862
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.475
    dispatch_time_ms: 6.806
    learner:
      cur_lr: 0.0010729540372267365
      grad_gnorm: 0.4525686502456665
      policy_entropy: 6.403293809853494e-05
      policy_loss: 1.0531359784238248e-08
      var_gnorm: 28.23598289489746
      vf_explained_var: 0.0
      vf_loss: 0.00013979969662614167
    num_steps_sampled: 4315000
    num_steps_trained: 4315000
    wait_time_ms: 72.11
  iterations_since_restore: 863
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 7393.290041923523
  time_this_iter_s: 8.156970739364624
  time_total_s: 7393.290041923523
  timestamp: 1594865723
  timesteps_since_restore: 4315000
  timesteps_this_iter: 5000
  timesteps_total: 4315000
  training_iteration: 863
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 7393 s, 863 iter, 4315000 ts, -448 rew

agent-1: -199.99999999784504
agent-2: -199.99999999784504
agent-3: -199.99999999784504
agent-4: -199.99999999784504
agent-5: 4.0
Extrinsic Rewards:
0
0
0
0
4
Sum Reward: 4
Avg Reward: 0.8
Min Reward: 0
Max Reward: 4
Gini Coefficient: 0.8
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-15-31
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -451.9956249951304
  episode_reward_min: -1101.8140624879697
  episodes_this_iter: 1
  episodes_total: 863
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 3.033
    dispatch_time_ms: 6.02
    learner:
      cur_lr: 0.0010726209729909897
      grad_gnorm: 39.999996185302734
      policy_entropy: 6.41874794382602e-05
      policy_loss: -1.246000192622887e-05
      var_gnorm: 28.235994338989258
      vf_explained_var: 0.0
      vf_loss: 172.92430114746094
    num_steps_sampled: 4320000
    num_steps_trained: 4320000
    wait_time_ms: 73.909
  iterations_since_restore: 864
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 7401.46378993988
  time_this_iter_s: 8.173748016357422
  time_total_s: 7401.46378993988
  timestamp: 1594865731
  timesteps_since_restore: 4320000
  timesteps_this_iter: 5000
  timesteps_total: 4320000
  training_iteration: 864
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 7401 s, 864 iter, 4320000 ts, -452 rew

agent-1: -149.03124999839068
agent-2: -49.249999999427196
agent-3: -299.9999999967949
agent-4: -299.9999999967949
agent-5: 1.71875
Extrinsic Rewards:
1
2
0
0
3
Sum Reward: 6
Avg Reward: 1.2
Min Reward: 0
Max Reward: 3
Gini Coefficient: 0.5333333333333333
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-15-39
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -453.9912499951094
  episode_reward_min: -1101.8140624879697
  episodes_this_iter: 1
  episodes_total: 864
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 3.073
    dispatch_time_ms: 8.648
    learner:
      cur_lr: 0.0010722880251705647
      grad_gnorm: 0.8063170313835144
      policy_entropy: 6.426768231904134e-05
      policy_loss: -3.003637516485469e-08
      var_gnorm: 28.23599624633789
      vf_explained_var: 5.960464477539063e-08
      vf_loss: 0.00042811641469597816
    num_steps_sampled: 4325000
    num_steps_trained: 4325000
    wait_time_ms: 68.658
  iterations_since_restore: 865
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 7409.636594295502
  time_this_iter_s: 8.172804355621338
  time_total_s: 7409.636594295502
  timestamp: 1594865739
  timesteps_since_restore: 4325000
  timesteps_this_iter: 5000
  timesteps_total: 4325000
  training_iteration: 865
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 7409 s, 865 iter, 4325000 ts, -454 rew

agent-1: 2.0
agent-2: -99.99999999894987
agent-3: -99.99999999894987
agent-4: -99.99999999894987
agent-5: -99.99999999894987
Extrinsic Rewards:
2
0
0
0
0
Sum Reward: 2
Avg Reward: 0.4
Min Reward: 0
Max Reward: 2
Gini Coefficient: 0.8
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-15-47
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -452.00124999513105
  episode_reward_min: -1101.8140624879697
  episodes_this_iter: 1
  episodes_total: 865
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 3.06
    dispatch_time_ms: 7.484
    learner:
      cur_lr: 0.0010719549609348178
      grad_gnorm: 5.538586139678955
      policy_entropy: 6.446426414186135e-05
      policy_loss: 7.816341707211905e-08
      var_gnorm: 28.235994338989258
      vf_explained_var: 0.0
      vf_loss: 0.02019970864057541
    num_steps_sampled: 4330000
    num_steps_trained: 4330000
    wait_time_ms: 71.083
  iterations_since_restore: 866
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 7417.8410658836365
  time_this_iter_s: 8.204471588134766
  time_total_s: 7417.8410658836365
  timestamp: 1594865747
  timesteps_since_restore: 4330000
  timesteps_this_iter: 5000
  timesteps_total: 4330000
  training_iteration: 866
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 7417 s, 866 iter, 4330000 ts, -452 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-15-55
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -452.00124999513116
  episode_reward_min: -1101.8140624879697
  episodes_this_iter: 1
  episodes_total: 866
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.993
    dispatch_time_ms: 6.714
    learner:
      cur_lr: 0.0010716220131143928
      grad_gnorm: 0.8078164458274841
      policy_entropy: 6.45494437776506e-05
      policy_loss: -2.1997152543917764e-08
      var_gnorm: 28.236003875732422
      vf_explained_var: 0.0
      vf_loss: 0.00042975638643838465
    num_steps_sampled: 4335000
    num_steps_trained: 4335000
    wait_time_ms: 71.313
  iterations_since_restore: 867
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 7426.054882526398
  time_this_iter_s: 8.21381664276123
  time_total_s: 7426.054882526398
  timestamp: 1594865755
  timesteps_since_restore: 4335000
  timesteps_this_iter: 5000
  timesteps_total: 4335000
  training_iteration: 867
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 7426 s, 867 iter, 4335000 ts, -452 rew

agent-1: 2.0
agent-2: -99.99999999894987
agent-3: -99.99999999894987
agent-4: -99.99999999894987
agent-5: -99.99999999894987
Extrinsic Rewards:
2
0
0
0
0
Sum Reward: 2
Avg Reward: 0.4
Min Reward: 0
Max Reward: 2
Gini Coefficient: 0.8
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-16-04
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -447.03124999518593
  episode_reward_min: -1101.8140624879697
  episodes_this_iter: 1
  episodes_total: 867
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.901
    dispatch_time_ms: 8.238
    learner:
      cur_lr: 0.001071288948878646
      grad_gnorm: 7.548725605010986
      policy_entropy: 6.479115836555138e-05
      policy_loss: 2.0555474122829764e-07
      var_gnorm: 28.23603057861328
      vf_explained_var: 0.0
      vf_loss: 0.03752235695719719
    num_steps_sampled: 4340000
    num_steps_trained: 4340000
    wait_time_ms: 71.052
  iterations_since_restore: 868
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 7434.318911075592
  time_this_iter_s: 8.264028549194336
  time_total_s: 7434.318911075592
  timestamp: 1594865764
  timesteps_since_restore: 4340000
  timesteps_this_iter: 5000
  timesteps_total: 4340000
  training_iteration: 868
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 7434 s, 868 iter, 4340000 ts, -447 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-16-12
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -447.031249995186
  episode_reward_min: -1101.8140624879697
  episodes_this_iter: 1
  episodes_total: 868
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 3.122
    dispatch_time_ms: 31.983
    learner:
      cur_lr: 0.0010709560010582209
      grad_gnorm: 7.357265472412109
      policy_entropy: 6.459838186856359e-05
      policy_loss: 3.877318022205145e-07
      var_gnorm: 28.236080169677734
      vf_explained_var: 0.0
      vf_loss: 0.0356430858373642
    num_steps_sampled: 4345000
    num_steps_trained: 4345000
    wait_time_ms: 67.664
  iterations_since_restore: 869
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 7442.797793388367
  time_this_iter_s: 8.478882312774658
  time_total_s: 7442.797793388367
  timestamp: 1594865772
  timesteps_since_restore: 4345000
  timesteps_this_iter: 5000
  timesteps_total: 4345000
  training_iteration: 869
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 7442 s, 869 iter, 4345000 ts, -447 rew

agent-1: -99.99999999894987
agent-2: -99.99999999894987
agent-3: -99.99999999894987
agent-4: -99.99999999894987
agent-5: 2.0
Extrinsic Rewards:
0
0
0
0
2
Sum Reward: 2
Avg Reward: 0.4
Min Reward: 0
Max Reward: 2
Gini Coefficient: 0.8
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-16-21
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -447.031249995186
  episode_reward_min: -1101.8140624879697
  episodes_this_iter: 1
  episodes_total: 869
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.534
    dispatch_time_ms: 27.618
    learner:
      cur_lr: 0.0010706230532377958
      grad_gnorm: 6.847723007202148
      policy_entropy: 6.451108492910862e-05
      policy_loss: -1.8009822611020354e-07
      var_gnorm: 28.236106872558594
      vf_explained_var: 0.0
      vf_loss: 0.03087754361331463
    num_steps_sampled: 4350000
    num_steps_trained: 4350000
    wait_time_ms: 55.297
  iterations_since_restore: 870
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 7451.462029695511
  time_this_iter_s: 8.664236307144165
  time_total_s: 7451.462029695511
  timestamp: 1594865781
  timesteps_since_restore: 4350000
  timesteps_this_iter: 5000
  timesteps_total: 4350000
  training_iteration: 870
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 7451 s, 870 iter, 4350000 ts, -447 rew

agent-1: -0.9023632812223709
agent-2: -0.8117187499708365
agent-3: -2.1211132812500004
agent-4: -350.342968746124
agent-5: -149.49378906091636
Extrinsic Rewards:
3
3
3
1
2
Sum Reward: 12
Avg Reward: 2.4
Min Reward: 1
Max Reward: 3
Gini Coefficient: 0.16666666666666666
20:20 Ratio: 3.0
Max-min Ratio: 3.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-16-30
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -452.06796952638086
  episode_reward_min: -1101.8140624879697
  episodes_this_iter: 1
  episodes_total: 870
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 3.029
    dispatch_time_ms: 25.288
    learner:
      cur_lr: 0.001070289989002049
      grad_gnorm: 8.499226570129395
      policy_entropy: 6.483474135166034e-05
      policy_loss: 4.039210637074575e-07
      var_gnorm: 28.23611831665039
      vf_explained_var: 0.0
      vf_loss: 0.04756631329655647
    num_steps_sampled: 4355000
    num_steps_trained: 4355000
    wait_time_ms: 60.323
  iterations_since_restore: 871
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 7460.224612951279
  time_this_iter_s: 8.762583255767822
  time_total_s: 7460.224612951279
  timestamp: 1594865790
  timesteps_since_restore: 4355000
  timesteps_this_iter: 5000
  timesteps_total: 4355000
  training_iteration: 871
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 7460 s, 871 iter, 4355000 ts, -452 rew

agent-1: -249.99999999735493
agent-2: 0.7500000000136119
agent-3: 0.71875
agent-4: -99.03124999894982
agent-5: -249.99999999735493
Extrinsic Rewards:
0
2
2
1
0
Sum Reward: 5
Avg Reward: 1.0
Min Reward: 0
Max Reward: 2
Gini Coefficient: 0.48
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-16-39
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -456.05359452633854
  episode_reward_min: -1101.8140624879697
  episodes_this_iter: 1
  episodes_total: 871
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.494
    dispatch_time_ms: 31.767
    learner:
      cur_lr: 0.001069957041181624
      grad_gnorm: 11.736276626586914
      policy_entropy: 6.481781019829214e-05
      policy_loss: -8.440102305939945e-08
      var_gnorm: 28.236238479614258
      vf_explained_var: 0.0
      vf_loss: 0.09069916605949402
    num_steps_sampled: 4360000
    num_steps_trained: 4360000
    wait_time_ms: 46.246
  iterations_since_restore: 872
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 7468.9275324344635
  time_this_iter_s: 8.702919483184814
  time_total_s: 7468.9275324344635
  timestamp: 1594865799
  timesteps_since_restore: 4360000
  timesteps_this_iter: 5000
  timesteps_total: 4360000
  training_iteration: 872
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 7468 s, 872 iter, 4360000 ts, -456 rew

agent-1: 1.53125
agent-2: -349.9999999962086
agent-3: -49.46874999939871
agent-4: -349.9999999962086
agent-5: -349.9999999962086
Extrinsic Rewards:
4
0
3
0
0
Sum Reward: 7
Avg Reward: 1.4
Min Reward: 0
Max Reward: 4
Gini Coefficient: 0.6285714285714286
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-16-48
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -459.0829695263035
  episode_reward_min: -1101.8140624879697
  episodes_this_iter: 1
  episodes_total: 872
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.718
    dispatch_time_ms: 38.333
    learner:
      cur_lr: 0.001069623976945877
      grad_gnorm: 0.3899982273578644
      policy_entropy: 6.462263263529167e-05
      policy_loss: 4.209988802017506e-08
      var_gnorm: 28.236129760742188
      vf_explained_var: 0.0
      vf_loss: 0.00010014866711571813
    num_steps_sampled: 4365000
    num_steps_trained: 4365000
    wait_time_ms: 58.96
  iterations_since_restore: 873
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 7477.915924549103
  time_this_iter_s: 8.988392114639282
  time_total_s: 7477.915924549103
  timestamp: 1594865808
  timesteps_since_restore: 4365000
  timesteps_this_iter: 5000
  timesteps_total: 4365000
  training_iteration: 873
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 7477 s, 873 iter, 4365000 ts, -459 rew

agent-1: 3.0
agent-2: -249.99999999735493
agent-3: -249.99999999735493
agent-4: -249.99999999735493
agent-5: -47.99999999945478
Extrinsic Rewards:
3
0
0
0
2
Sum Reward: 5
Avg Reward: 1.0
Min Reward: 0
Max Reward: 3
Gini Coefficient: 0.64
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-16-56
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -457.0929695263267
  episode_reward_min: -1101.8140624879697
  episodes_this_iter: 1
  episodes_total: 873
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.747
    dispatch_time_ms: 17.624
    learner:
      cur_lr: 0.001069291029125452
      grad_gnorm: 14.53345012664795
      policy_entropy: 6.507932994281873e-05
      policy_loss: 5.260321245259547e-08
      var_gnorm: 28.236358642578125
      vf_explained_var: 0.0
      vf_loss: 0.1390855461359024
    num_steps_sampled: 4370000
    num_steps_trained: 4370000
    wait_time_ms: 72.685
  iterations_since_restore: 874
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 7486.720705509186
  time_this_iter_s: 8.804780960083008
  time_total_s: 7486.720705509186
  timestamp: 1594865816
  timesteps_since_restore: 4370000
  timesteps_this_iter: 5000
  timesteps_total: 4370000
  training_iteration: 874
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 7486 s, 874 iter, 4370000 ts, -457 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-17-05
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -450.13296952640104
  episode_reward_min: -1101.8140624879697
  episodes_this_iter: 1
  episodes_total: 874
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.857
    dispatch_time_ms: 29.592
    learner:
      cur_lr: 0.0010689579648897052
      grad_gnorm: 0.3571382164955139
      policy_entropy: 6.485399353550747e-05
      policy_loss: 1.0455178767188045e-07
      var_gnorm: 28.236141204833984
      vf_explained_var: 0.0
      vf_loss: 0.0010493104346096516
    num_steps_sampled: 4375000
    num_steps_trained: 4375000
    wait_time_ms: 48.587
  iterations_since_restore: 875
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 7495.623326063156
  time_this_iter_s: 8.902620553970337
  time_total_s: 7495.623326063156
  timestamp: 1594865825
  timesteps_since_restore: 4375000
  timesteps_this_iter: 5000
  timesteps_total: 4375000
  training_iteration: 875
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 21.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 7495 s, 875 iter, 4375000 ts, -450 rew

agent-1: -199.99999999774747
agent-2: -199.99999999774747
agent-3: 4.0
agent-4: -199.99999999774747
agent-5: -199.99999999774747
Extrinsic Rewards:
0
0
4
0
0
Sum Reward: 4
Avg Reward: 0.8
Min Reward: 0
Max Reward: 4
Gini Coefficient: 0.8
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-17-14
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -452.12296952637473
  episode_reward_min: -1101.8140624879697
  episodes_this_iter: 1
  episodes_total: 875
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 3.024
    dispatch_time_ms: 21.411
    learner:
      cur_lr: 0.0010686250170692801
      grad_gnorm: 0.014377984218299389
      policy_entropy: 6.490070518339053e-05
      policy_loss: 6.184653900120907e-10
      var_gnorm: 28.236162185668945
      vf_explained_var: 0.0
      vf_loss: 1.359208710027815e-07
    num_steps_sampled: 4380000
    num_steps_trained: 4380000
    wait_time_ms: 60.39
  iterations_since_restore: 876
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 7504.266146183014
  time_this_iter_s: 8.642820119857788
  time_total_s: 7504.266146183014
  timestamp: 1594865834
  timesteps_since_restore: 4380000
  timesteps_this_iter: 5000
  timesteps_total: 4380000
  training_iteration: 876
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 21.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 7504 s, 876 iter, 4380000 ts, -452 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-17-23
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -448.14296952641666
  episode_reward_min: -1101.8140624879697
  episodes_this_iter: 1
  episodes_total: 876
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 4.115
    dispatch_time_ms: 50.421
    learner:
      cur_lr: 0.0010682919528335333
      grad_gnorm: 0.8491858243942261
      policy_entropy: 6.539058813359588e-05
      policy_loss: 4.977784442417033e-07
      var_gnorm: 28.2362117767334
      vf_explained_var: 0.0
      vf_loss: 0.013614054769277573
    num_steps_sampled: 4385000
    num_steps_trained: 4385000
    wait_time_ms: 35.368
  iterations_since_restore: 877
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 7513.108875989914
  time_this_iter_s: 8.842729806900024
  time_total_s: 7513.108875989914
  timestamp: 1594865843
  timesteps_since_restore: 4385000
  timesteps_this_iter: 5000
  timesteps_total: 4385000
  training_iteration: 877
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 21.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 7513 s, 877 iter, 4385000 ts, -448 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-17-31
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -448.1429695264167
  episode_reward_min: -1101.8140624879697
  episodes_this_iter: 1
  episodes_total: 877
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 3.482
    dispatch_time_ms: 6.603
    learner:
      cur_lr: 0.0010679590050131083
      grad_gnorm: 20.9248104095459
      policy_entropy: 6.562011549249291e-05
      policy_loss: 4.901880856778007e-07
      var_gnorm: 28.236738204956055
      vf_explained_var: 0.0
      vf_loss: 0.288314551115036
    num_steps_sampled: 4390000
    num_steps_trained: 4390000
    wait_time_ms: 74.107
  iterations_since_restore: 878
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 7521.310675621033
  time_this_iter_s: 8.201799631118774
  time_total_s: 7521.310675621033
  timestamp: 1594865851
  timesteps_since_restore: 4390000
  timesteps_this_iter: 5000
  timesteps_total: 4390000
  training_iteration: 878
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 21.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 7521 s, 878 iter, 4390000 ts, -448 rew

agent-1: -99.99999999894987
agent-2: 2.0
agent-3: -99.99999999894987
agent-4: -99.99999999894987
agent-5: -99.99999999894987
Extrinsic Rewards:
0
2
0
0
0
Sum Reward: 2
Avg Reward: 0.4
Min Reward: 0
Max Reward: 2
Gini Coefficient: 0.8
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-17-39
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -446.1529695264385
  episode_reward_min: -1101.8140624879697
  episodes_this_iter: 1
  episodes_total: 878
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.679
    dispatch_time_ms: 7.912
    learner:
      cur_lr: 0.0010676260571926832
      grad_gnorm: 3.538851737976074
      policy_entropy: 6.55675248708576e-05
      policy_loss: 1.2143021876909188e-07
      var_gnorm: 28.236169815063477
      vf_explained_var: 0.0
      vf_loss: 0.008243554271757603
    num_steps_sampled: 4395000
    num_steps_trained: 4395000
    wait_time_ms: 73.576
  iterations_since_restore: 879
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 7529.464113950729
  time_this_iter_s: 8.153438329696655
  time_total_s: 7529.464113950729
  timestamp: 1594865859
  timesteps_since_restore: 4395000
  timesteps_this_iter: 5000
  timesteps_total: 4395000
  training_iteration: 879
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 21.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 7529 s, 879 iter, 4395000 ts, -446 rew

agent-1: -149.99999999840443
agent-2: -149.99999999840443
agent-3: -149.99999999840443
agent-4: 3.0
agent-5: -149.99999999840443
Extrinsic Rewards:
0
0
0
3
0
Sum Reward: 3
Avg Reward: 0.6
Min Reward: 0
Max Reward: 3
Gini Coefficient: 0.8
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-17-47
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -450.13296952639604
  episode_reward_min: -1101.8140624879697
  episodes_this_iter: 1
  episodes_total: 879
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.668
    dispatch_time_ms: 7.426
    learner:
      cur_lr: 0.0010672929929569364
      grad_gnorm: 0.015248791314661503
      policy_entropy: 6.564956129295751e-05
      policy_loss: 9.301960313123914e-10
      var_gnorm: 28.236181259155273
      vf_explained_var: 0.0
      vf_loss: 1.5377004558558838e-07
    num_steps_sampled: 4400000
    num_steps_trained: 4400000
    wait_time_ms: 73.057
  iterations_since_restore: 880
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 7537.631260633469
  time_this_iter_s: 8.167146682739258
  time_total_s: 7537.631260633469
  timestamp: 1594865867
  timesteps_since_restore: 4400000
  timesteps_this_iter: 5000
  timesteps_total: 4400000
  training_iteration: 880
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 21.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 7537 s, 880 iter, 4400000 ts, -450 rew

agent-1: 1.0
agent-2: -49.999999999481645
agent-3: -49.999999999481645
agent-4: -49.999999999481645
agent-5: -49.999999999481645
Extrinsic Rewards:
1
0
0
0
0
Sum Reward: 1
Avg Reward: 0.2
Min Reward: 0
Max Reward: 1
Gini Coefficient: 0.8
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-17-56
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -446.15296952644013
  episode_reward_min: -1101.8140624879697
  episodes_this_iter: 1
  episodes_total: 880
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.982
    dispatch_time_ms: 9.951
    learner:
      cur_lr: 0.0010669600451365113
      grad_gnorm: 12.021178245544434
      policy_entropy: 6.627258699154481e-05
      policy_loss: 4.288178843125934e-07
      var_gnorm: 28.23635482788086
      vf_explained_var: 0.0
      vf_loss: 0.09592729806900024
    num_steps_sampled: 4405000
    num_steps_trained: 4405000
    wait_time_ms: 69.948
  iterations_since_restore: 881
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 7545.755565643311
  time_this_iter_s: 8.124305009841919
  time_total_s: 7545.755565643311
  timestamp: 1594865876
  timesteps_since_restore: 4405000
  timesteps_this_iter: 5000
  timesteps_total: 4405000
  training_iteration: 881
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 21.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 7545 s, 881 iter, 4405000 ts, -446 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-18-04
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -440.1829695265039
  episode_reward_min: -1101.8140624879697
  episodes_this_iter: 1
  episodes_total: 881
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 3.078
    dispatch_time_ms: 7.158
    learner:
      cur_lr: 0.0010666269809007645
      grad_gnorm: 39.999996185302734
      policy_entropy: 6.658872007392347e-05
      policy_loss: -2.3627321752428543e-06
      var_gnorm: 28.23676300048828
      vf_explained_var: 0.0
      vf_loss: 10.986903190612793
    num_steps_sampled: 4410000
    num_steps_trained: 4410000
    wait_time_ms: 71.003
  iterations_since_restore: 882
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 7553.916330337524
  time_this_iter_s: 8.160764694213867
  time_total_s: 7553.916330337524
  timestamp: 1594865884
  timesteps_since_restore: 4410000
  timesteps_this_iter: 5000
  timesteps_total: 4410000
  training_iteration: 882
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 21.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 7553 s, 882 iter, 4410000 ts, -440 rew

agent-1: -399.9999999956487
agent-2: -399.9999999956487
agent-3: 0.34296875004196875
agent-4: 0.3429687499999998
agent-5: -399.9999999956487
Extrinsic Rewards:
0
0
4
4
0
Sum Reward: 8
Avg Reward: 1.6
Min Reward: 0
Max Reward: 4
Gini Coefficient: 0.6
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-18-12
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -442.2361101514801
  episode_reward_min: -1199.3140624869059
  episodes_this_iter: 1
  episodes_total: 882
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.745
    dispatch_time_ms: 9.452
    learner:
      cur_lr: 0.0010662940330803394
      grad_gnorm: 9.033140182495117
      policy_entropy: 6.673017196590081e-05
      policy_loss: 3.7050887158329715e-07
      var_gnorm: 28.236221313476562
      vf_explained_var: 0.0
      vf_loss: 0.05373063310980797
    num_steps_sampled: 4415000
    num_steps_trained: 4415000
    wait_time_ms: 69.229
  iterations_since_restore: 883
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 7561.942104101181
  time_this_iter_s: 8.025773763656616
  time_total_s: 7561.942104101181
  timestamp: 1594865892
  timesteps_since_restore: 4415000
  timesteps_this_iter: 5000
  timesteps_total: 4415000
  training_iteration: 883
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 21.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 7561 s, 883 iter, 4415000 ts, -442 rew

agent-1: 0.5312500000275931
agent-2: 0.5
agent-3: -199.03124999784518
agent-4: -349.9999999962501
agent-5: -349.9999999962501
Extrinsic Rewards:
3
3
1
0
0
Sum Reward: 7
Avg Reward: 1.4
Min Reward: 0
Max Reward: 3
Gini Coefficient: 0.5142857142857142
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-18-20
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -451.21611015138325
  episode_reward_min: -1199.3140624869059
  episodes_this_iter: 1
  episodes_total: 883
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.808
    dispatch_time_ms: 7.459
    learner:
      cur_lr: 0.0010659609688445926
      grad_gnorm: 0.0949496254324913
      policy_entropy: 6.662578380201012e-05
      policy_loss: 3.5285996347056425e-09
      var_gnorm: 28.23618507385254
      vf_explained_var: 0.0
      vf_loss: 5.933791271672817e-06
    num_steps_sampled: 4420000
    num_steps_trained: 4420000
    wait_time_ms: 70.913
  iterations_since_restore: 884
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 7570.024699926376
  time_this_iter_s: 8.082595825195312
  time_total_s: 7570.024699926376
  timestamp: 1594865900
  timesteps_since_restore: 4420000
  timesteps_this_iter: 5000
  timesteps_total: 4420000
  training_iteration: 884
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 21.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 7570 s, 884 iter, 4420000 ts, -451 rew

agent-1: -199.99999999784504
agent-2: 4.0
agent-3: -199.99999999784504
agent-4: -199.99999999784504
agent-5: -199.99999999784504
Extrinsic Rewards:
0
4
0
0
0
Sum Reward: 4
Avg Reward: 0.8
Min Reward: 0
Max Reward: 4
Gini Coefficient: 0.8
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-18-28
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -455.19611015133904
  episode_reward_min: -1199.3140624869059
  episodes_this_iter: 1
  episodes_total: 884
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 3.205
    dispatch_time_ms: 6.457
    learner:
      cur_lr: 0.0010656280210241675
      grad_gnorm: 0.0028035619761794806
      policy_entropy: 6.693786417599767e-05
      policy_loss: -7.547162894638859e-11
      var_gnorm: 28.236173629760742
      vf_explained_var: 0.0
      vf_loss: 5.097127164788162e-09
    num_steps_sampled: 4425000
    num_steps_trained: 4425000
    wait_time_ms: 71.389
  iterations_since_restore: 885
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 7578.225883722305
  time_this_iter_s: 8.201183795928955
  time_total_s: 7578.225883722305
  timestamp: 1594865908
  timesteps_since_restore: 4425000
  timesteps_this_iter: 5000
  timesteps_total: 4425000
  training_iteration: 885
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 21.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 7578 s, 885 iter, 4425000 ts, -455 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-18-37
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -447.2461101514239
  episode_reward_min: -1199.3140624869059
  episodes_this_iter: 1
  episodes_total: 885
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 3.222
    dispatch_time_ms: 7.922
    learner:
      cur_lr: 0.0010652949567884207
      grad_gnorm: 20.04833221435547
      policy_entropy: 6.794161163270473e-05
      policy_loss: 5.459237399918493e-07
      var_gnorm: 28.23664093017578
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 0.26466643810272217
    num_steps_sampled: 4430000
    num_steps_trained: 4430000
    wait_time_ms: 68.504
  iterations_since_restore: 886
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 7586.644558429718
  time_this_iter_s: 8.41867470741272
  time_total_s: 7586.644558429718
  timestamp: 1594865917
  timesteps_since_restore: 4430000
  timesteps_this_iter: 5000
  timesteps_total: 4430000
  training_iteration: 886
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 21.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 7586 s, 886 iter, 4430000 ts, -447 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-18-45
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -447.2461101514239
  episode_reward_min: -1199.3140624869059
  episodes_this_iter: 1
  episodes_total: 886
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.456
    dispatch_time_ms: 6.972
    learner:
      cur_lr: 0.0010649620089679956
      grad_gnorm: 4.791614055633545
      policy_entropy: 6.795386434532702e-05
      policy_loss: 1.3047744573668751e-07
      var_gnorm: 28.236135482788086
      vf_explained_var: 0.0
      vf_loss: 0.015116306021809578
    num_steps_sampled: 4435000
    num_steps_trained: 4435000
    wait_time_ms: 71.751
  iterations_since_restore: 887
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 7594.7561621665955
  time_this_iter_s: 8.111603736877441
  time_total_s: 7594.7561621665955
  timestamp: 1594865925
  timesteps_since_restore: 4435000
  timesteps_this_iter: 5000
  timesteps_total: 4435000
  training_iteration: 887
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 21.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 7594 s, 887 iter, 4435000 ts, -447 rew

agent-1: -199.99999999789975
agent-2: -48.999999999454765
agent-3: -48.999999999454765
agent-4: 2.0
agent-5: -199.99999999789975
Extrinsic Rewards:
0
1
1
2
0
Sum Reward: 4
Avg Reward: 0.8
Min Reward: 0
Max Reward: 2
Gini Coefficient: 0.5
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-18-53
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -446.2361101514358
  episode_reward_min: -1199.3140624869059
  episodes_this_iter: 1
  episodes_total: 887
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.55
    dispatch_time_ms: 7.028
    learner:
      cur_lr: 0.0010646289447322488
      grad_gnorm: 39.999996185302734
      policy_entropy: 6.878816930111498e-05
      policy_loss: -2.4823009425745113e-06
      var_gnorm: 28.23663330078125
      vf_explained_var: 0.0
      vf_loss: 7.786910057067871
    num_steps_sampled: 4440000
    num_steps_trained: 4440000
    wait_time_ms: 68.67
  iterations_since_restore: 888
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 7602.8479998111725
  time_this_iter_s: 8.091837644577026
  time_total_s: 7602.8479998111725
  timestamp: 1594865933
  timesteps_since_restore: 4440000
  timesteps_this_iter: 5000
  timesteps_total: 4440000
  training_iteration: 888
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 21.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 7602 s, 888 iter, 4440000 ts, -446 rew

agent-1: -99.99999999894987
agent-2: 2.0
agent-3: -99.99999999894987
agent-4: -99.99999999894987
agent-5: -99.99999999894987
Extrinsic Rewards:
0
2
0
0
0
Sum Reward: 2
Avg Reward: 0.4
Min Reward: 0
Max Reward: 2
Gini Coefficient: 0.8
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-19-01
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -442.25611015148
  episode_reward_min: -1199.3140624869059
  episodes_this_iter: 1
  episodes_total: 888
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 3.067
    dispatch_time_ms: 6.418
    learner:
      cur_lr: 0.0010642959969118237
      grad_gnorm: 8.680062294006348
      policy_entropy: 6.891463999636471e-05
      policy_loss: 2.3636133050786157e-07
      var_gnorm: 28.23618507385254
      vf_explained_var: 0.0
      vf_loss: 0.049618758261203766
    num_steps_sampled: 4445000
    num_steps_trained: 4445000
    wait_time_ms: 78.097
  iterations_since_restore: 889
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 7611.053763151169
  time_this_iter_s: 8.205763339996338
  time_total_s: 7611.053763151169
  timestamp: 1594865941
  timesteps_since_restore: 4445000
  timesteps_this_iter: 5000
  timesteps_total: 4445000
  training_iteration: 889
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 21.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 7611 s, 889 iter, 4445000 ts, -442 rew

agent-1: -98.9999999988954
agent-2: -199.999999997859
agent-3: 3.0
agent-4: -199.999999997859
agent-5: -199.999999997859
Extrinsic Rewards:
1
0
3
0
0
Sum Reward: 4
Avg Reward: 0.8
Min Reward: 0
Max Reward: 3
Gini Coefficient: 0.7
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-19-09
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -449.21611015140473
  episode_reward_min: -1199.3140624869059
  episodes_this_iter: 1
  episodes_total: 889
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.783
    dispatch_time_ms: 7.3
    learner:
      cur_lr: 0.0010639630490913987
      grad_gnorm: 40.0
      policy_entropy: 6.962069164728746e-05
      policy_loss: -1.4005699995323084e-06
      var_gnorm: 28.236677169799805
      vf_explained_var: 0.0
      vf_loss: 2.684183120727539
    num_steps_sampled: 4450000
    num_steps_trained: 4450000
    wait_time_ms: 71.452
  iterations_since_restore: 890
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 7619.189610481262
  time_this_iter_s: 8.135847330093384
  time_total_s: 7619.189610481262
  timestamp: 1594865949
  timesteps_since_restore: 4450000
  timesteps_this_iter: 5000
  timesteps_total: 4450000
  training_iteration: 890
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 21.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 7619 s, 890 iter, 4450000 ts, -449 rew

agent-1: -199.99999999780377
agent-2: -199.99999999780377
agent-3: -199.99999999780377
agent-4: -199.99999999780377
agent-5: 4.0
Extrinsic Rewards:
0
0
0
0
4
Sum Reward: 4
Avg Reward: 0.8
Min Reward: 0
Max Reward: 4
Gini Coefficient: 0.8
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-19-18
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -448.20987577641426
  episode_reward_min: -1199.3140624869059
  episodes_this_iter: 1
  episodes_total: 890
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.673
    dispatch_time_ms: 8.314
    learner:
      cur_lr: 0.0010636299848556519
      grad_gnorm: 4.337874412536621
      policy_entropy: 6.948197551537305e-05
      policy_loss: 1.699114591247053e-07
      var_gnorm: 28.236127853393555
      vf_explained_var: 1.1920928955078125e-07
      vf_loss: 0.012390803545713425
    num_steps_sampled: 4455000
    num_steps_trained: 4455000
    wait_time_ms: 71.045
  iterations_since_restore: 891
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 7627.4143698215485
  time_this_iter_s: 8.224759340286255
  time_total_s: 7627.4143698215485
  timestamp: 1594865958
  timesteps_since_restore: 4455000
  timesteps_this_iter: 5000
  timesteps_total: 4455000
  training_iteration: 891
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 21.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 7627 s, 891 iter, 4455000 ts, -448 rew

agent-1: -149.99999999837684
agent-2: -149.99999999837684
agent-3: 3.0
agent-4: -149.99999999837684
agent-5: -149.99999999837684
Extrinsic Rewards:
0
0
3
0
0
Sum Reward: 3
Avg Reward: 0.6
Min Reward: 0
Max Reward: 3
Gini Coefficient: 0.8
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-19-26
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -452.1898757763702
  episode_reward_min: -1199.3140624869059
  episodes_this_iter: 1
  episodes_total: 891
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 3.193
    dispatch_time_ms: 9.737
    learner:
      cur_lr: 0.0010632970370352268
      grad_gnorm: 21.035276412963867
      policy_entropy: 7.064271630952135e-05
      policy_loss: 4.0974546777761134e-07
      var_gnorm: 28.23666000366211
      vf_explained_var: 1.1920928955078125e-07
      vf_loss: 0.29136666655540466
    num_steps_sampled: 4460000
    num_steps_trained: 4460000
    wait_time_ms: 72.083
  iterations_since_restore: 892
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 7635.543612957001
  time_this_iter_s: 8.12924313545227
  time_total_s: 7635.543612957001
  timestamp: 1594865966
  timesteps_since_restore: 4460000
  timesteps_this_iter: 5000
  timesteps_total: 4460000
  training_iteration: 892
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 21.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 7635 s, 892 iter, 4460000 ts, -452 rew

agent-1: -49.999999999481645
agent-2: -49.999999999481645
agent-3: -49.999999999481645
agent-4: 1.0
agent-5: -49.999999999481645
Extrinsic Rewards:
0
0
0
1
0
Sum Reward: 1
Avg Reward: 0.2
Min Reward: 0
Max Reward: 1
Gini Coefficient: 0.8
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-19-34
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -454.17987577634943
  episode_reward_min: -1199.3140624869059
  episodes_this_iter: 1
  episodes_total: 892
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.557
    dispatch_time_ms: 6.961
    learner:
      cur_lr: 0.00106296397279948
      grad_gnorm: 13.204959869384766
      policy_entropy: 7.103023381205276e-05
      policy_loss: 3.5957600630354136e-07
      var_gnorm: 28.236310958862305
      vf_explained_var: 0.0
      vf_loss: 0.1159844622015953
    num_steps_sampled: 4465000
    num_steps_trained: 4465000
    wait_time_ms: 70.753
  iterations_since_restore: 893
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 7643.596361398697
  time_this_iter_s: 8.052748441696167
  time_total_s: 7643.596361398697
  timestamp: 1594865974
  timesteps_since_restore: 4465000
  timesteps_this_iter: 5000
  timesteps_total: 4465000
  training_iteration: 893
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 21.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 7643 s, 893 iter, 4465000 ts, -454 rew

agent-1: -349.9999999962086
agent-2: -49.46874999939871
agent-3: 1.53125
agent-4: -349.9999999962086
agent-5: -349.9999999962086
Extrinsic Rewards:
0
3
4
0
0
Sum Reward: 7
Avg Reward: 1.4
Min Reward: 0
Max Reward: 4
Gini Coefficient: 0.6285714285714286
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-19-42
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -454.1798757763494
  episode_reward_min: -1199.3140624869059
  episodes_this_iter: 1
  episodes_total: 893
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.492
    dispatch_time_ms: 8.32
    learner:
      cur_lr: 0.001062631024979055
      grad_gnorm: 40.0
      policy_entropy: 7.167545845732093e-05
      policy_loss: -1.791568024600565e-06
      var_gnorm: 28.236568450927734
      vf_explained_var: 0.0
      vf_loss: 4.180237293243408
    num_steps_sampled: 4470000
    num_steps_trained: 4470000
    wait_time_ms: 71.631
  iterations_since_restore: 894
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 7651.6954753398895
  time_this_iter_s: 8.099113941192627
  time_total_s: 7651.6954753398895
  timestamp: 1594865982
  timesteps_since_restore: 4470000
  timesteps_this_iter: 5000
  timesteps_total: 4470000
  training_iteration: 894
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 21.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 7651 s, 894 iter, 4470000 ts, -454 rew

agent-1: -499.9999999945141
agent-2: -50.780468749382614
agent-3: -50.780468749384056
agent-4: -0.9375
agent-5: -499.9999999945141
Extrinsic Rewards:
0
3
3
4
0
Sum Reward: 10
Avg Reward: 2.0
Min Reward: 0
Max Reward: 4
Gini Coefficient: 0.44
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-19-50
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -465.2048601512273
  episode_reward_min: -1199.3140624869059
  episodes_this_iter: 1
  episodes_total: 894
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 3.198
    dispatch_time_ms: 10.832
    learner:
      cur_lr: 0.001062297960743308
      grad_gnorm: 11.078479766845703
      policy_entropy: 7.204949361039326e-05
      policy_loss: 3.0167120712576434e-07
      var_gnorm: 28.236202239990234
      vf_explained_var: 0.0
      vf_loss: 0.0809757262468338
    num_steps_sampled: 4475000
    num_steps_trained: 4475000
    wait_time_ms: 68.825
  iterations_since_restore: 895
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 7659.921639442444
  time_this_iter_s: 8.226164102554321
  time_total_s: 7659.921639442444
  timestamp: 1594865990
  timesteps_since_restore: 4475000
  timesteps_this_iter: 5000
  timesteps_total: 4475000
  training_iteration: 895
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 21.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 7659 s, 895 iter, 4475000 ts, -465 rew

agent-1: -98.999999998923
agent-2: -199.99999999788645
agent-3: -199.99999999788645
agent-4: 3.0
agent-5: -199.99999999788645
Extrinsic Rewards:
1
0
0
3
0
Sum Reward: 4
Avg Reward: 0.8
Min Reward: 0
Max Reward: 3
Gini Coefficient: 0.7
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-19-58
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -468.18486015119515
  episode_reward_min: -1199.3140624869059
  episodes_this_iter: 1
  episodes_total: 895
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 3.286
    dispatch_time_ms: 7.163
    learner:
      cur_lr: 0.001061965012922883
      grad_gnorm: 1.534538984298706
      policy_entropy: 7.272099901456386e-05
      policy_loss: -7.866563578318164e-08
      var_gnorm: 28.2365665435791
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 0.058545179665088654
    num_steps_sampled: 4480000
    num_steps_trained: 4480000
    wait_time_ms: 72.619
  iterations_since_restore: 896
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 7668.052966594696
  time_this_iter_s: 8.131327152252197
  time_total_s: 7668.052966594696
  timestamp: 1594865998
  timesteps_since_restore: 4480000
  timesteps_this_iter: 5000
  timesteps_total: 4480000
  training_iteration: 896
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 21.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 7668 s, 896 iter, 4480000 ts, -468 rew

agent-1: -249.99999999735493
agent-2: 3.0
agent-3: -47.99999999945478
agent-4: -249.99999999735493
agent-5: -249.99999999735493
Extrinsic Rewards:
0
3
2
0
0
Sum Reward: 5
Avg Reward: 1.0
Min Reward: 0
Max Reward: 3
Gini Coefficient: 0.64
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-20-07
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -476.13486015111033
  episode_reward_min: -1199.3140624869059
  episodes_this_iter: 1
  episodes_total: 896
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.974
    dispatch_time_ms: 6.954
    learner:
      cur_lr: 0.0010616319486871362
      grad_gnorm: 8.577695846557617
      policy_entropy: 7.292565715033561e-05
      policy_loss: 2.3357392819889355e-07
      var_gnorm: 28.236135482788086
      vf_explained_var: 0.0
      vf_loss: 0.04847344011068344
    num_steps_sampled: 4485000
    num_steps_trained: 4485000
    wait_time_ms: 74.463
  iterations_since_restore: 897
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 7676.268594264984
  time_this_iter_s: 8.215627670288086
  time_total_s: 7676.268594264984
  timestamp: 1594866007
  timesteps_since_restore: 4485000
  timesteps_this_iter: 5000
  timesteps_total: 4485000
  training_iteration: 897
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 21.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 7676 s, 897 iter, 4485000 ts, -476 rew

agent-1: -49.99999999946836
agent-2: -49.99999999946836
agent-3: -49.99999999946836
agent-4: 1.0
agent-5: -49.99999999946836
Extrinsic Rewards:
0
0
0
1
0
Sum Reward: 1
Avg Reward: 0.2
Min Reward: 0
Max Reward: 1
Gini Coefficient: 0.8
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-20-15
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -478.124860151089
  episode_reward_min: -1199.3140624869059
  episodes_this_iter: 1
  episodes_total: 897
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.777
    dispatch_time_ms: 7.187
    learner:
      cur_lr: 0.0010612990008667111
      grad_gnorm: 40.0
      policy_entropy: 7.421460759360343e-05
      policy_loss: -1.2492321275203722e-06
      var_gnorm: 28.236589431762695
      vf_explained_var: 5.960464477539063e-08
      vf_loss: 2.260132312774658
    num_steps_sampled: 4490000
    num_steps_trained: 4490000
    wait_time_ms: 71.801
  iterations_since_restore: 898
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 7684.371500492096
  time_this_iter_s: 8.102906227111816
  time_total_s: 7684.371500492096
  timestamp: 1594866015
  timesteps_since_restore: 4490000
  timesteps_this_iter: 5000
  timesteps_total: 4490000
  training_iteration: 898
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 21.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 7684 s, 898 iter, 4490000 ts, -478 rew

agent-1: -149.9999999984318
agent-2: -149.9999999984318
agent-3: -48.9999999994684
agent-4: 2.0
agent-5: -149.9999999984318
Extrinsic Rewards:
0
0
1
2
0
Sum Reward: 3
Avg Reward: 0.6
Min Reward: 0
Max Reward: 2
Gini Coefficient: 0.6666666666666666
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-20-23
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -476.1348601511112
  episode_reward_min: -1199.3140624869059
  episodes_this_iter: 1
  episodes_total: 898
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 3.176
    dispatch_time_ms: 6.383
    learner:
      cur_lr: 0.001060966053046286
      grad_gnorm: 7.756390571594238
      policy_entropy: 7.448800897691399e-05
      policy_loss: 4.0704736647967366e-07
      var_gnorm: 28.236059188842773
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 0.03961494565010071
    num_steps_sampled: 4495000
    num_steps_trained: 4495000
    wait_time_ms: 70.989
  iterations_since_restore: 899
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 7692.430533885956
  time_this_iter_s: 8.059033393859863
  time_total_s: 7692.430533885956
  timestamp: 1594866023
  timesteps_since_restore: 4495000
  timesteps_this_iter: 5000
  timesteps_total: 4495000
  training_iteration: 899
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 21.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 7692 s, 899 iter, 4495000 ts, -476 rew

agent-1: 3.0
agent-2: -199.999999997859
agent-3: -199.999999997859
agent-4: -98.9999999988954
agent-5: -199.999999997859
Extrinsic Rewards:
3
0
0
1
0
Sum Reward: 4
Avg Reward: 0.8
Min Reward: 0
Max Reward: 3
Gini Coefficient: 0.7
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-20-31
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -472.1154851511558
  episode_reward_min: -1199.3140624869059
  episodes_this_iter: 1
  episodes_total: 899
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 3.363
    dispatch_time_ms: 5.905
    learner:
      cur_lr: 0.0010606329888105392
      grad_gnorm: 24.533458709716797
      policy_entropy: 7.631511107319966e-05
      policy_loss: -7.374334245469072e-07
      var_gnorm: 28.23650360107422
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 0.964735746383667
    num_steps_sampled: 4500000
    num_steps_trained: 4500000
    wait_time_ms: 73.249
  iterations_since_restore: 900
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 7700.630931377411
  time_this_iter_s: 8.200397491455078
  time_total_s: 7700.630931377411
  timestamp: 1594866031
  timesteps_since_restore: 4500000
  timesteps_this_iter: 5000
  timesteps_total: 4500000
  training_iteration: 900
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 21.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 7700 s, 900 iter, 4500000 ts, -472 rew

agent-1: 2.0
agent-2: -99.99999999894987
agent-3: -99.99999999894987
agent-4: -99.99999999894987
agent-5: -99.99999999894987
Extrinsic Rewards:
2
0
0
0
0
Sum Reward: 2
Avg Reward: 0.4
Min Reward: 0
Max Reward: 2
Gini Coefficient: 0.8
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-20-39
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -470.1104851511775
  episode_reward_min: -1199.3140624869059
  episodes_this_iter: 1
  episodes_total: 900
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.896
    dispatch_time_ms: 7.976
    learner:
      cur_lr: 0.0010603000409901142
      grad_gnorm: 0.1295185536146164
      policy_entropy: 7.527927664341405e-05
      policy_loss: -6.6263865505789e-09
      var_gnorm: 28.236032485961914
      vf_explained_var: 0.0
      vf_loss: 1.1042658115911763e-05
    num_steps_sampled: 4505000
    num_steps_trained: 4505000
    wait_time_ms: 71.934
  iterations_since_restore: 901
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 7708.800346136093
  time_this_iter_s: 8.169414758682251
  time_total_s: 7708.800346136093
  timestamp: 1594866039
  timesteps_since_restore: 4505000
  timesteps_this_iter: 5000
  timesteps_total: 4505000
  training_iteration: 901
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 21.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 7708 s, 901 iter, 4505000 ts, -470 rew

agent-1: -48.9999999994684
agent-2: -149.9999999984318
agent-3: -149.9999999984318
agent-4: -149.9999999984318
agent-5: 2.0
Extrinsic Rewards:
1
0
0
0
2
Sum Reward: 3
Avg Reward: 0.6
Min Reward: 0
Max Reward: 2
Gini Coefficient: 0.6666666666666666
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-20-48
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -475.0804851511252
  episode_reward_min: -1199.3140624869059
  episodes_this_iter: 1
  episodes_total: 901
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.683
    dispatch_time_ms: 8.523
    learner:
      cur_lr: 0.0010599669767543674
      grad_gnorm: 0.01286220084875822
      policy_entropy: 7.62721465434879e-05
      policy_loss: 3.502426682011617e-10
      var_gnorm: 28.23598289489746
      vf_explained_var: 5.960464477539063e-08
      vf_loss: 1.0912064141166411e-07
    num_steps_sampled: 4510000
    num_steps_trained: 4510000
    wait_time_ms: 71.487
  iterations_since_restore: 902
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 7716.957094192505
  time_this_iter_s: 8.156748056411743
  time_total_s: 7716.957094192505
  timestamp: 1594866048
  timesteps_since_restore: 4510000
  timesteps_this_iter: 5000
  timesteps_total: 4510000
  training_iteration: 902
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 21.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 7716 s, 902 iter, 4510000 ts, -475 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-20-56
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -464.10111015124517
  episode_reward_min: -1199.3140624869059
  episodes_this_iter: 1
  episodes_total: 902
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.856
    dispatch_time_ms: 6.156
    learner:
      cur_lr: 0.0010596340289339423
      grad_gnorm: 0.0021627142559736967
      policy_entropy: 7.731231744401157e-05
      policy_loss: -2.585129679766318e-11
      var_gnorm: 28.235933303833008
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 2.9624638298031414e-09
    num_steps_sampled: 4515000
    num_steps_trained: 4515000
    wait_time_ms: 76.046
  iterations_since_restore: 903
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 7725.109943151474
  time_this_iter_s: 8.152848958969116
  time_total_s: 7725.109943151474
  timestamp: 1594866056
  timesteps_since_restore: 4515000
  timesteps_this_iter: 5000
  timesteps_total: 4515000
  training_iteration: 903
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 21.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 7725 s, 903 iter, 4515000 ts, -464 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-21-04
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -460.12111015128704
  episode_reward_min: -1199.3140624869059
  episodes_this_iter: 1
  episodes_total: 903
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.642
    dispatch_time_ms: 8.451
    learner:
      cur_lr: 0.0010593009646981955
      grad_gnorm: 0.010749280452728271
      policy_entropy: 7.842191553208977e-05
      policy_loss: 2.927069142621974e-10
      var_gnorm: 28.235885620117188
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 7.686179515076219e-08
    num_steps_sampled: 4520000
    num_steps_trained: 4520000
    wait_time_ms: 69.207
  iterations_since_restore: 904
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 7733.201796531677
  time_this_iter_s: 8.091853380203247
  time_total_s: 7733.201796531677
  timestamp: 1594866064
  timesteps_since_restore: 4520000
  timesteps_this_iter: 5000
  timesteps_total: 4520000
  training_iteration: 904
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 21.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 7733 s, 904 iter, 4520000 ts, -460 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-21-12
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -455.15111015133937
  episode_reward_min: -1199.3140624869059
  episodes_this_iter: 1
  episodes_total: 904
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 3.003
    dispatch_time_ms: 8.328
    learner:
      cur_lr: 0.0010589680168777704
      grad_gnorm: 15.482234954833984
      policy_entropy: 8.162605809047818e-05
      policy_loss: 5.251894208413432e-07
      var_gnorm: 28.235984802246094
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 0.15783782303333282
    num_steps_sampled: 4525000
    num_steps_trained: 4525000
    wait_time_ms: 69.647
  iterations_since_restore: 905
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 7741.375930070877
  time_this_iter_s: 8.174133539199829
  time_total_s: 7741.375930070877
  timestamp: 1594866072
  timesteps_since_restore: 4525000
  timesteps_this_iter: 5000
  timesteps_total: 4525000
  training_iteration: 905
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 21.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 7741 s, 905 iter, 4525000 ts, -455 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-21-20
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -447.20111015142413
  episode_reward_min: -1199.3140624869059
  episodes_this_iter: 1
  episodes_total: 905
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 3.978
    dispatch_time_ms: 8.164
    learner:
      cur_lr: 0.0010586349526420236
      grad_gnorm: 0.21986520290374756
      policy_entropy: 8.020737732294947e-05
      policy_loss: 6.954383291457589e-09
      var_gnorm: 28.235837936401367
      vf_explained_var: 0.0
      vf_loss: 3.182523505529389e-05
    num_steps_sampled: 4530000
    num_steps_trained: 4530000
    wait_time_ms: 70.66
  iterations_since_restore: 906
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 7749.497433185577
  time_this_iter_s: 8.121503114700317
  time_total_s: 7749.497433185577
  timestamp: 1594866080
  timesteps_since_restore: 4530000
  timesteps_this_iter: 5000
  timesteps_total: 4530000
  training_iteration: 906
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 21.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 7749 s, 906 iter, 4530000 ts, -447 rew

agent-1: -249.99999999731412
agent-2: -148.99999999837678
agent-3: -249.99999999731412
agent-4: 4.0
agent-5: -249.99999999731412
Extrinsic Rewards:
0
1
0
4
0
Sum Reward: 5
Avg Reward: 1.0
Min Reward: 0
Max Reward: 4
Gini Coefficient: 0.72
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-21-28
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -454.16111015134805
  episode_reward_min: -1199.3140624869059
  episodes_this_iter: 1
  episodes_total: 906
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 3.629
    dispatch_time_ms: 10.029
    learner:
      cur_lr: 0.0010583020048215985
      grad_gnorm: 18.77712059020996
      policy_entropy: 8.439263910986483e-05
      policy_loss: 7.184122523540282e-07
      var_gnorm: 28.23605728149414
      vf_explained_var: 1.1920928955078125e-07
      vf_loss: 0.2321653813123703
    num_steps_sampled: 4535000
    num_steps_trained: 4535000
    wait_time_ms: 71.3
  iterations_since_restore: 907
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 7757.617332696915
  time_this_iter_s: 8.11989951133728
  time_total_s: 7757.617332696915
  timestamp: 1594866088
  timesteps_since_restore: 4535000
  timesteps_this_iter: 5000
  timesteps_total: 4535000
  training_iteration: 907
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 21.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 7757 s, 907 iter, 4535000 ts, -454 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-21-37
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -448.19111015141175
  episode_reward_min: -1199.3140624869059
  episodes_this_iter: 1
  episodes_total: 907
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.896
    dispatch_time_ms: 7.231
    learner:
      cur_lr: 0.0010579690570011735
      grad_gnorm: 0.25338035821914673
      policy_entropy: 8.25495008029975e-05
      policy_loss: 1.4360392874834815e-08
      var_gnorm: 28.235755920410156
      vf_explained_var: 0.0
      vf_loss: 4.229005571687594e-05
    num_steps_sampled: 4540000
    num_steps_trained: 4540000
    wait_time_ms: 70.908
  iterations_since_restore: 908
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 7765.749566316605
  time_this_iter_s: 8.132233619689941
  time_total_s: 7765.749566316605
  timestamp: 1594866097
  timesteps_since_restore: 4540000
  timesteps_this_iter: 5000
  timesteps_total: 4540000
  training_iteration: 908
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 21.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 7765 s, 908 iter, 4540000 ts, -448 rew

agent-1: -349.99999999625004
agent-2: -46.99999999944068
agent-3: -349.99999999625004
agent-4: 4.0
agent-5: -349.99999999625004
Extrinsic Rewards:
0
3
0
4
0
Sum Reward: 7
Avg Reward: 1.4
Min Reward: 0
Max Reward: 4
Gini Coefficient: 0.6285714285714286
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-21-45
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -451.16111015138154
  episode_reward_min: -1199.3140624869059
  episodes_this_iter: 1
  episodes_total: 908
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.95
    dispatch_time_ms: 8.658
    learner:
      cur_lr: 0.0010576359927654266
      grad_gnorm: 12.125307083129883
      policy_entropy: 8.607317431597039e-05
      policy_loss: 3.301767321772786e-07
      var_gnorm: 28.235734939575195
      vf_explained_var: 2.384185791015625e-07
      vf_loss: 0.0968121811747551
    num_steps_sampled: 4545000
    num_steps_trained: 4545000
    wait_time_ms: 72.43
  iterations_since_restore: 909
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 7773.988023757935
  time_this_iter_s: 8.238457441329956
  time_total_s: 7773.988023757935
  timestamp: 1594866105
  timesteps_since_restore: 4545000
  timesteps_this_iter: 5000
  timesteps_total: 4545000
  training_iteration: 909
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 21.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 7773 s, 909 iter, 4545000 ts, -451 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-21-53
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -441.20611015149035
  episode_reward_min: -1199.3140624869059
  episodes_this_iter: 1
  episodes_total: 909
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 3.036
    dispatch_time_ms: 7.033
    learner:
      cur_lr: 0.0010573030449450016
      grad_gnorm: 26.481433868408203
      policy_entropy: 8.901351247914135e-05
      policy_loss: 7.002767574704194e-07
      var_gnorm: 28.236461639404297
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 0.4617708623409271
    num_steps_sampled: 4550000
    num_steps_trained: 4550000
    wait_time_ms: 71.285
  iterations_since_restore: 910
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 7782.061062812805
  time_this_iter_s: 8.073039054870605
  time_total_s: 7782.061062812805
  timestamp: 1594866113
  timesteps_since_restore: 4550000
  timesteps_this_iter: 5000
  timesteps_total: 4550000
  training_iteration: 910
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 21.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 7782 s, 910 iter, 4550000 ts, -441 rew

agent-1: -199.99999999788645
agent-2: -199.99999999788645
agent-3: -199.99999999788645
agent-4: 0.75
agent-5: 0.7500000000136119
Extrinsic Rewards:
0
0
0
2
2
Sum Reward: 4
Avg Reward: 0.8
Min Reward: 0
Max Reward: 2
Gini Coefficient: 0.6
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-22-01
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -443.2111101514688
  episode_reward_min: -1199.3140624869059
  episodes_this_iter: 1
  episodes_total: 910
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.69
    dispatch_time_ms: 7.444
    learner:
      cur_lr: 0.0010569699807092547
      grad_gnorm: 14.924193382263184
      policy_entropy: 8.97871796041727e-05
      policy_loss: 5.810832703900815e-07
      var_gnorm: 28.235713958740234
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 0.14666488766670227
    num_steps_sampled: 4555000
    num_steps_trained: 4555000
    wait_time_ms: 71.151
  iterations_since_restore: 911
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 7790.306654453278
  time_this_iter_s: 8.245591640472412
  time_total_s: 7790.306654453278
  timestamp: 1594866121
  timesteps_since_restore: 4555000
  timesteps_this_iter: 5000
  timesteps_total: 4555000
  training_iteration: 911
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 21.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 7790 s, 911 iter, 4555000 ts, -443 rew

agent-1: -199.99999999784504
agent-2: -199.99999999784504
agent-3: -199.99999999784504
agent-4: -199.99999999784504
agent-5: 4.0
Extrinsic Rewards:
0
0
0
0
4
Sum Reward: 4
Avg Reward: 0.8
Min Reward: 0
Max Reward: 4
Gini Coefficient: 0.8
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-22-09
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -451.1711101513826
  episode_reward_min: -1199.3140624869059
  episodes_this_iter: 1
  episodes_total: 911
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.701
    dispatch_time_ms: 9.128
    learner:
      cur_lr: 0.0010566370328888297
      grad_gnorm: 26.721176147460938
      policy_entropy: 9.346493607154116e-05
      policy_loss: 6.129658345344069e-07
      var_gnorm: 28.236328125
      vf_explained_var: 0.0
      vf_loss: 0.47016847133636475
    num_steps_sampled: 4560000
    num_steps_trained: 4560000
    wait_time_ms: 64.383
  iterations_since_restore: 912
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 7798.439108371735
  time_this_iter_s: 8.132453918457031
  time_total_s: 7798.439108371735
  timestamp: 1594866129
  timesteps_since_restore: 4560000
  timesteps_this_iter: 5000
  timesteps_total: 4560000
  training_iteration: 912
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 21.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 7798 s, 912 iter, 4560000 ts, -451 rew

agent-1: -98.999999998923
agent-2: -199.99999999788645
agent-3: -199.99999999788645
agent-4: -199.99999999788645
agent-5: 3.0
Extrinsic Rewards:
1
0
0
0
3
Sum Reward: 4
Avg Reward: 0.8
Min Reward: 0
Max Reward: 3
Gini Coefficient: 0.7
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-22-18
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -458.1311101513084
  episode_reward_min: -1199.3140624869059
  episodes_this_iter: 1
  episodes_total: 912
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 3.838
    dispatch_time_ms: 9.354
    learner:
      cur_lr: 0.0010563039686530828
      grad_gnorm: 16.66858673095703
      policy_entropy: 9.523866174276918e-05
      policy_loss: 4.914480769002694e-07
      var_gnorm: 28.23577880859375
      vf_explained_var: 1.1920928955078125e-07
      vf_loss: 0.19398324191570282
    num_steps_sampled: 4565000
    num_steps_trained: 4565000
    wait_time_ms: 70.433
  iterations_since_restore: 913
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 7806.597095012665
  time_this_iter_s: 8.157986640930176
  time_total_s: 7806.597095012665
  timestamp: 1594866138
  timesteps_since_restore: 4565000
  timesteps_this_iter: 5000
  timesteps_total: 4565000
  training_iteration: 913
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 21.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 7806 s, 913 iter, 4565000 ts, -458 rew

agent-1: 1.75
agent-2: -299.999999996808
agent-3: -148.9999999983636
agent-4: -49.249999999427196
agent-5: -299.999999996808
Extrinsic Rewards:
3
0
1
2
0
Sum Reward: 6
Avg Reward: 1.2
Min Reward: 0
Max Reward: 3
Gini Coefficient: 0.5333333333333333
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-22-34
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -466.09611015122255
  episode_reward_min: -1199.3140624869059
  episodes_this_iter: 1
  episodes_total: 913
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 3.549
    dispatch_time_ms: 9.351
    learner:
      cur_lr: 0.0010559710208326578
      grad_gnorm: 16.840085983276367
      policy_entropy: 9.947529906639829e-05
      policy_loss: 2.595084254153335e-07
      var_gnorm: 28.235422134399414
      vf_explained_var: 0.0
      vf_loss: 0.18673725426197052
    num_steps_sampled: 4570000
    num_steps_trained: 4570000
    wait_time_ms: 69.833
  iterations_since_restore: 914
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 7822.460508346558
  time_this_iter_s: 15.863413333892822
  time_total_s: 7822.460508346558
  timestamp: 1594866154
  timesteps_since_restore: 4570000
  timesteps_this_iter: 5000
  timesteps_total: 4570000
  training_iteration: 914
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 21.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 7822 s, 914 iter, 4570000 ts, -466 rew

agent-1: -99.46874999883967
agent-2: -249.2499999972039
agent-3: -649.9999999930051
agent-4: 0.34296875004196875
agent-5: -3.37578125
Extrinsic Rewards:
3
2
0
4
4
Sum Reward: 13
Avg Reward: 2.6
Min Reward: 0
Max Reward: 4
Gini Coefficient: 0.3076923076923077
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-22-42
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -476.1136257761126
  episode_reward_min: -1199.3140624869059
  episodes_this_iter: 1
  episodes_total: 914
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.989
    dispatch_time_ms: 23.428
    learner:
      cur_lr: 0.001055637956596911
      grad_gnorm: 21.085792541503906
      policy_entropy: 0.00010469052358530462
      policy_loss: 8.250861469605297e-07
      var_gnorm: 28.235462188720703
      vf_explained_var: 0.0
      vf_loss: 0.29276835918426514
    num_steps_sampled: 4575000
    num_steps_trained: 4575000
    wait_time_ms: 58.678
  iterations_since_restore: 915
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 7831.073577404022
  time_this_iter_s: 8.6130690574646
  time_total_s: 7831.073577404022
  timestamp: 1594866162
  timesteps_since_restore: 4575000
  timesteps_this_iter: 5000
  timesteps_total: 4575000
  training_iteration: 915
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 21.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 7831 s, 915 iter, 4575000 ts, -476 rew

agent-1: -249.99999999735493
agent-2: 3.0
agent-3: -249.99999999735493
agent-4: -249.99999999735493
agent-5: -47.99999999945478
Extrinsic Rewards:
0
3
0
0
2
Sum Reward: 5
Avg Reward: 1.0
Min Reward: 0
Max Reward: 3
Gini Coefficient: 0.64
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-22-51
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -478.0936257760916
  episode_reward_min: -1199.3140624869059
  episodes_this_iter: 1
  episodes_total: 915
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 3.034
    dispatch_time_ms: 34.236
    learner:
      cur_lr: 0.001055305008776486
      grad_gnorm: 0.35490310192108154
      policy_entropy: 9.333758498542011e-05
      policy_loss: -2.2028654456107688e-08
      var_gnorm: 28.235305786132812
      vf_explained_var: 5.960464477539063e-08
      vf_loss: 0.00010831420513568446
    num_steps_sampled: 4580000
    num_steps_trained: 4580000
    wait_time_ms: 51.702
  iterations_since_restore: 916
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 7839.871619224548
  time_this_iter_s: 8.798041820526123
  time_total_s: 7839.871619224548
  timestamp: 1594866171
  timesteps_since_restore: 4580000
  timesteps_this_iter: 5000
  timesteps_total: 4580000
  training_iteration: 916
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 21.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 7839 s, 916 iter, 4580000 ts, -478 rew

agent-1: -349.99999999625004
agent-2: 4.0
agent-3: -349.99999999625004
agent-4: -46.99999999944068
agent-5: -349.99999999625004
Extrinsic Rewards:
0
4
0
3
0
Sum Reward: 7
Avg Reward: 1.4
Min Reward: 0
Max Reward: 4
Gini Coefficient: 0.6285714285714286
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-23-00
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -489.02362577597336
  episode_reward_min: -1199.3140624869059
  episodes_this_iter: 1
  episodes_total: 916
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.931
    dispatch_time_ms: 20.414
    learner:
      cur_lr: 0.001054971944540739
      grad_gnorm: 0.00032729541999287903
      policy_entropy: 9.695177868707106e-05
      policy_loss: 3.307080650993832e-11
      var_gnorm: 28.235157012939453
      vf_explained_var: 1.7881393432617188e-07
      vf_loss: 6.624012449663041e-11
    num_steps_sampled: 4585000
    num_steps_trained: 4585000
    wait_time_ms: 66.901
  iterations_since_restore: 917
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 7848.599080562592
  time_this_iter_s: 8.727461338043213
  time_total_s: 7848.599080562592
  timestamp: 1594866180
  timesteps_since_restore: 4585000
  timesteps_this_iter: 5000
  timesteps_total: 4585000
  training_iteration: 917
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 21.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 7848 s, 917 iter, 4585000 ts, -489 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-23-09
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -480.9498757760632
  episode_reward_min: -1199.3140624869059
  episodes_this_iter: 1
  episodes_total: 917
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.812
    dispatch_time_ms: 25.536
    learner:
      cur_lr: 0.001054638996720314
      grad_gnorm: 12.031588554382324
      policy_entropy: 0.00011386028199922293
      policy_loss: 4.513275655426696e-07
      var_gnorm: 28.235204696655273
      vf_explained_var: 5.960464477539063e-08
      vf_loss: 0.11805398762226105
    num_steps_sampled: 4590000
    num_steps_trained: 4590000
    wait_time_ms: 62.24
  iterations_since_restore: 918
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 7857.273536205292
  time_this_iter_s: 8.674455642700195
  time_total_s: 7857.273536205292
  timestamp: 1594866189
  timesteps_since_restore: 4590000
  timesteps_this_iter: 5000
  timesteps_total: 4590000
  training_iteration: 918
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 21.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 7857 s, 918 iter, 4590000 ts, -481 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-23-17
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -474.9742507761268
  episode_reward_min: -1199.3140624869059
  episodes_this_iter: 1
  episodes_total: 918
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 3.794
    dispatch_time_ms: 40.741
    learner:
      cur_lr: 0.001054306048899889
      grad_gnorm: 8.237261772155762
      policy_entropy: 0.00011516267841216177
      policy_loss: 4.81756103454245e-07
      var_gnorm: 28.23505210876465
      vf_explained_var: 0.0
      vf_loss: 0.08266667276620865
    num_steps_sampled: 4595000
    num_steps_trained: 4595000
    wait_time_ms: 51.94
  iterations_since_restore: 919
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 7866.227037191391
  time_this_iter_s: 8.953500986099243
  time_total_s: 7866.227037191391
  timestamp: 1594866197
  timesteps_since_restore: 4595000
  timesteps_this_iter: 5000
  timesteps_total: 4595000
  training_iteration: 919
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 21.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 7866 s, 919 iter, 4595000 ts, -475 rew

agent-1: 2.0
agent-2: -99.99999999894987
agent-3: -99.99999999894987
agent-4: -99.99999999894987
agent-5: -99.99999999894987
Extrinsic Rewards:
2
0
0
0
0
Sum Reward: 2
Avg Reward: 0.4
Min Reward: 0
Max Reward: 2
Gini Coefficient: 0.8
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-23-26
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -478.9542507760848
  episode_reward_min: -1199.3140624869059
  episodes_this_iter: 1
  episodes_total: 919
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.573
    dispatch_time_ms: 32.177
    learner:
      cur_lr: 0.0010539729846641421
      grad_gnorm: 0.09976424276828766
      policy_entropy: 0.00011074270150857046
      policy_loss: 4.000587239261222e-07
      var_gnorm: 28.234960556030273
      vf_explained_var: 0.0
      vf_loss: 0.03464845195412636
    num_steps_sampled: 4600000
    num_steps_trained: 4600000
    wait_time_ms: 54.586
  iterations_since_restore: 920
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 7874.886310815811
  time_this_iter_s: 8.659273624420166
  time_total_s: 7874.886310815811
  timestamp: 1594866206
  timesteps_since_restore: 4600000
  timesteps_this_iter: 5000
  timesteps_total: 4600000
  training_iteration: 920
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 21.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 7874 s, 920 iter, 4600000 ts, -479 rew

agent-1: 3.0
agent-2: -199.99999999787352
agent-3: -199.99999999787352
agent-4: -98.99999999893653
agent-5: -199.99999999787352
Extrinsic Rewards:
3
0
0
1
0
Sum Reward: 4
Avg Reward: 0.8
Min Reward: 0
Max Reward: 3
Gini Coefficient: 0.7
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-23-35
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -474.99425077612847
  episode_reward_min: -1199.3140624869059
  episodes_this_iter: 1
  episodes_total: 920
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.917
    dispatch_time_ms: 25.493
    learner:
      cur_lr: 0.001053640036843717
      grad_gnorm: 0.8572888970375061
      policy_entropy: 9.585832594893873e-05
      policy_loss: -9.003681356034576e-09
      var_gnorm: 28.234872817993164
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 0.00039841522811912
    num_steps_sampled: 4605000
    num_steps_trained: 4605000
    wait_time_ms: 70.614
  iterations_since_restore: 921
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 7883.70538687706
  time_this_iter_s: 8.81907606124878
  time_total_s: 7883.70538687706
  timestamp: 1594866215
  timesteps_since_restore: 4605000
  timesteps_this_iter: 5000
  timesteps_total: 4605000
  training_iteration: 921
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 21.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 7883 s, 921 iter, 4605000 ts, -475 rew

agent-1: -99.99999999894987
agent-2: -99.99999999894987
agent-3: 2.0
agent-4: -99.99999999894987
agent-5: -99.99999999894987
Extrinsic Rewards:
0
0
2
0
0
Sum Reward: 2
Avg Reward: 0.4
Min Reward: 0
Max Reward: 2
Gini Coefficient: 0.8
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-23-44
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -467.9561101512068
  episode_reward_min: -1199.3140624869059
  episodes_this_iter: 1
  episodes_total: 921
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 3.037
    dispatch_time_ms: 19.313
    learner:
      cur_lr: 0.0010533069726079702
      grad_gnorm: 13.479016304016113
      policy_entropy: 0.00011561159044504166
      policy_loss: 6.108395496084995e-07
      var_gnorm: 28.234500885009766
      vf_explained_var: 0.0
      vf_loss: 0.12015383690595627
    num_steps_sampled: 4610000
    num_steps_trained: 4610000
    wait_time_ms: 56.946
  iterations_since_restore: 922
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 7892.274716615677
  time_this_iter_s: 8.569329738616943
  time_total_s: 7892.274716615677
  timestamp: 1594866224
  timesteps_since_restore: 4610000
  timesteps_this_iter: 5000
  timesteps_total: 4610000
  training_iteration: 922
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 21.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 7892 s, 922 iter, 4610000 ts, -468 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-23-52
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -463.9761101512488
  episode_reward_min: -1199.3140624869059
  episodes_this_iter: 1
  episodes_total: 922
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 3.142
    dispatch_time_ms: 31.483
    learner:
      cur_lr: 0.0010529740247875452
      grad_gnorm: 15.958486557006836
      policy_entropy: 0.00012074155529262498
      policy_loss: 5.486988925440528e-07
      var_gnorm: 28.234703063964844
      vf_explained_var: 0.0
      vf_loss: 0.17499159276485443
    num_steps_sampled: 4615000
    num_steps_trained: 4615000
    wait_time_ms: 56.321
  iterations_since_restore: 923
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 7901.036718845367
  time_this_iter_s: 8.762002229690552
  time_total_s: 7901.036718845367
  timestamp: 1594866232
  timesteps_since_restore: 4615000
  timesteps_this_iter: 5000
  timesteps_total: 4615000
  training_iteration: 923
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 21.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 7901 s, 923 iter, 4615000 ts, -464 rew

agent-1: -49.99999999946836
agent-2: -49.99999999946836
agent-3: 1.0
agent-4: -49.99999999946836
agent-5: -49.99999999946836
Extrinsic Rewards:
0
0
1
0
0
Sum Reward: 1
Avg Reward: 0.2
Min Reward: 0
Max Reward: 1
Gini Coefficient: 0.8
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-24-01
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -465.96611015122755
  episode_reward_min: -1199.3140624869059
  episodes_this_iter: 1
  episodes_total: 923
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 4.101
    dispatch_time_ms: 19.045
    learner:
      cur_lr: 0.0010526409605517983
      grad_gnorm: 0.23848994076251984
      policy_entropy: 9.787264571059495e-05
      policy_loss: 1.1404167388207043e-08
      var_gnorm: 28.234426498413086
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 3.745960202650167e-05
    num_steps_sampled: 4620000
    num_steps_trained: 4620000
    wait_time_ms: 64.739
  iterations_since_restore: 924
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 7909.664811134338
  time_this_iter_s: 8.628092288970947
  time_total_s: 7909.664811134338
  timestamp: 1594866241
  timesteps_since_restore: 4620000
  timesteps_this_iter: 5000
  timesteps_total: 4620000
  training_iteration: 924
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 21.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 7909 s, 924 iter, 4620000 ts, -466 rew

agent-1: -149.99999999840443
agent-2: -149.99999999840443
agent-3: -149.99999999840443
agent-4: -149.99999999840443
agent-5: 3.0
Extrinsic Rewards:
0
0
0
0
3
Sum Reward: 3
Avg Reward: 0.6
Min Reward: 0
Max Reward: 3
Gini Coefficient: 0.8
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-24-10
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -471.9361101511638
  episode_reward_min: -1199.3140624869059
  episodes_this_iter: 1
  episodes_total: 924
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 3.568
    dispatch_time_ms: 41.7
    learner:
      cur_lr: 0.0010523080127313733
      grad_gnorm: 18.18033218383789
      policy_entropy: 0.00012365641305223107
      policy_loss: 5.256104032014264e-07
      var_gnorm: 28.234102249145508
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 0.21764451265335083
    num_steps_sampled: 4625000
    num_steps_trained: 4625000
    wait_time_ms: 41.266
  iterations_since_restore: 925
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 7918.472423315048
  time_this_iter_s: 8.807612180709839
  time_total_s: 7918.472423315048
  timestamp: 1594866250
  timesteps_since_restore: 4625000
  timesteps_this_iter: 5000
  timesteps_total: 4625000
  training_iteration: 925
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 21.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 7918 s, 925 iter, 4625000 ts, -472 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-24-18
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -471.9361101511638
  episode_reward_min: -1199.3140624869059
  episodes_this_iter: 1
  episodes_total: 925
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.595
    dispatch_time_ms: 8.271
    learner:
      cur_lr: 0.0010519749484956264
      grad_gnorm: 14.216076850891113
      policy_entropy: 0.00012857084220740944
      policy_loss: 3.871092246754415e-07
      var_gnorm: 28.23366355895996
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 0.13346166908740997
    num_steps_sampled: 4630000
    num_steps_trained: 4630000
    wait_time_ms: 79.208
  iterations_since_restore: 926
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 7926.790605306625
  time_this_iter_s: 8.318181991577148
  time_total_s: 7926.790605306625
  timestamp: 1594866258
  timesteps_since_restore: 4630000
  timesteps_this_iter: 5000
  timesteps_total: 4630000
  training_iteration: 926
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 21.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 7926 s, 926 iter, 4630000 ts, -472 rew

agent-1: -149.99999999840443
agent-2: -149.99999999840443
agent-3: -149.99999999840443
agent-4: -149.99999999840443
agent-5: 3.0
Extrinsic Rewards:
0
0
0
0
3
Sum Reward: 3
Avg Reward: 0.6
Min Reward: 0
Max Reward: 3
Gini Coefficient: 0.8
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-24-27
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -473.92611015114204
  episode_reward_min: -1199.3140624869059
  episodes_this_iter: 1
  episodes_total: 926
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 3.336
    dispatch_time_ms: 21.547
    learner:
      cur_lr: 0.0010516420006752014
      grad_gnorm: 0.10542434453964233
      policy_entropy: 0.00010854929132619873
      policy_loss: 1.510806768578732e-08
      var_gnorm: 28.233461380004883
      vf_explained_var: 0.0
      vf_loss: 7.312555226235418e-06
    num_steps_sampled: 4635000
    num_steps_trained: 4635000
    wait_time_ms: 62.023
  iterations_since_restore: 927
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 7935.468675374985
  time_this_iter_s: 8.678070068359375
  time_total_s: 7935.468675374985
  timestamp: 1594866267
  timesteps_since_restore: 4635000
  timesteps_this_iter: 5000
  timesteps_total: 4635000
  training_iteration: 927
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 21.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 7935 s, 927 iter, 4635000 ts, -474 rew

agent-1: 2.0
agent-2: -99.99999999894987
agent-3: -99.99999999894987
agent-4: -99.99999999894987
agent-5: -99.99999999894987
Extrinsic Rewards:
2
0
0
0
0
Sum Reward: 2
Avg Reward: 0.4
Min Reward: 0
Max Reward: 2
Gini Coefficient: 0.8
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-24-36
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -475.9161101511208
  episode_reward_min: -1199.3140624869059
  episodes_this_iter: 1
  episodes_total: 927
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 3.024
    dispatch_time_ms: 35.094
    learner:
      cur_lr: 0.0010513090528547764
      grad_gnorm: 0.0032163062132894993
      policy_entropy: 0.00011621782323345542
      policy_loss: 1.7693195519807858e-10
      var_gnorm: 28.23319435119629
      vf_explained_var: 1.1920928955078125e-07
      vf_loss: 1.016224970840085e-08
    num_steps_sampled: 4640000
    num_steps_trained: 4640000
    wait_time_ms: 47.083
  iterations_since_restore: 928
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 7944.232352733612
  time_this_iter_s: 8.76367735862732
  time_total_s: 7944.232352733612
  timestamp: 1594866276
  timesteps_since_restore: 4640000
  timesteps_this_iter: 5000
  timesteps_total: 4640000
  training_iteration: 928
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 21.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 7944 s, 928 iter, 4640000 ts, -476 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-24-45
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -468.95611015119607
  episode_reward_min: -1199.3140624869059
  episodes_this_iter: 1
  episodes_total: 928
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 3.381
    dispatch_time_ms: 31.656
    learner:
      cur_lr: 0.0010509759886190295
      grad_gnorm: 23.374866485595703
      policy_entropy: 0.00017442673561163247
      policy_loss: 1.5110204003576655e-06
      var_gnorm: 28.23305320739746
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 0.3597831130027771
    num_steps_sampled: 4645000
    num_steps_trained: 4645000
    wait_time_ms: 61.17
  iterations_since_restore: 929
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 7953.09318113327
  time_this_iter_s: 8.860828399658203
  time_total_s: 7953.09318113327
  timestamp: 1594866285
  timesteps_since_restore: 4645000
  timesteps_this_iter: 5000
  timesteps_total: 4645000
  training_iteration: 929
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 21.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 7953 s, 929 iter, 4645000 ts, -469 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-24-53
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -458.99111015130495
  episode_reward_min: -1199.3140624869059
  episodes_this_iter: 1
  episodes_total: 929
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.747
    dispatch_time_ms: 26.142
    learner:
      cur_lr: 0.0010506430407986045
      grad_gnorm: 17.368621826171875
      policy_entropy: 0.00015700790390837938
      policy_loss: 1.9397025425860193e-06
      var_gnorm: 28.23438262939453
      vf_explained_var: 0.0
      vf_loss: 0.19864381849765778
    num_steps_sampled: 4650000
    num_steps_trained: 4650000
    wait_time_ms: 59.241
  iterations_since_restore: 930
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 7961.795969963074
  time_this_iter_s: 8.702788829803467
  time_total_s: 7961.795969963074
  timestamp: 1594866293
  timesteps_since_restore: 4650000
  timesteps_this_iter: 5000
  timesteps_total: 4650000
  training_iteration: 930
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 21.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 7961 s, 930 iter, 4650000 ts, -459 rew

agent-1: -199.99999999784504
agent-2: -199.99999999784504
agent-3: 4.0
agent-4: -199.99999999784504
agent-5: -199.99999999784504
Extrinsic Rewards:
0
0
4
0
0
Sum Reward: 4
Avg Reward: 0.8
Min Reward: 0
Max Reward: 4
Gini Coefficient: 0.8
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-25-02
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -458.9911101513067
  episode_reward_min: -1199.3140624869059
  episodes_this_iter: 1
  episodes_total: 930
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.574
    dispatch_time_ms: 19.861
    learner:
      cur_lr: 0.0010503099765628576
      grad_gnorm: 0.0004713694506790489
      policy_entropy: 0.00011789146810770035
      policy_loss: 3.5750541416135206e-11
      var_gnorm: 28.234962463378906
      vf_explained_var: 1.1920928955078125e-07
      vf_loss: 1.294808704699335e-10
    num_steps_sampled: 4655000
    num_steps_trained: 4655000
    wait_time_ms: 55.624
  iterations_since_restore: 931
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 7970.667644023895
  time_this_iter_s: 8.871674060821533
  time_total_s: 7970.667644023895
  timestamp: 1594866302
  timesteps_since_restore: 4655000
  timesteps_this_iter: 5000
  timesteps_total: 4655000
  training_iteration: 931
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 21.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 7970 s, 931 iter, 4655000 ts, -459 rew

agent-1: -199.99999999788645
agent-2: -199.99999999788645
agent-3: 3.0
agent-4: -98.999999998923
agent-5: -199.99999999788645
Extrinsic Rewards:
0
0
3
1
0
Sum Reward: 4
Avg Reward: 0.8
Min Reward: 0
Max Reward: 3
Gini Coefficient: 0.7
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-25-11
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -458.990485151308
  episode_reward_min: -1199.3140624869059
  episodes_this_iter: 1
  episodes_total: 931
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 3.426
    dispatch_time_ms: 30.479
    learner:
      cur_lr: 0.0010499770287424326
      grad_gnorm: 0.0013732059160247445
      policy_entropy: 0.00012981837789993733
      policy_loss: 1.0080884738083995e-10
      var_gnorm: 28.234588623046875
      vf_explained_var: 0.0
      vf_loss: 1.1530363330791715e-09
    num_steps_sampled: 4660000
    num_steps_trained: 4660000
    wait_time_ms: 53.564
  iterations_since_restore: 932
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 7979.352610826492
  time_this_iter_s: 8.684966802597046
  time_total_s: 7979.352610826492
  timestamp: 1594866311
  timesteps_since_restore: 4660000
  timesteps_this_iter: 5000
  timesteps_total: 4660000
  training_iteration: 932
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 21.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 7979 s, 932 iter, 4660000 ts, -459 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-25-20
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -458.99048515130795
  episode_reward_min: -1199.3140624869059
  episodes_this_iter: 1
  episodes_total: 932
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 3.448
    dispatch_time_ms: 23.778
    learner:
      cur_lr: 0.0010496439645066857
      grad_gnorm: 0.3629095256328583
      policy_entropy: 0.00021997418662067503
      policy_loss: -2.48054959683941e-07
      var_gnorm: 28.233285903930664
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 0.12392963469028473
    num_steps_sampled: 4665000
    num_steps_trained: 4665000
    wait_time_ms: 64.548
  iterations_since_restore: 933
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 7988.123838663101
  time_this_iter_s: 8.771227836608887
  time_total_s: 7988.123838663101
  timestamp: 1594866320
  timesteps_since_restore: 4665000
  timesteps_this_iter: 5000
  timesteps_total: 4665000
  training_iteration: 933
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 21.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 7988 s, 933 iter, 4665000 ts, -459 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-25-28
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -458.99048515130795
  episode_reward_min: -1199.3140624869059
  episodes_this_iter: 1
  episodes_total: 933
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 3.003
    dispatch_time_ms: 6.576
    learner:
      cur_lr: 0.0010493110166862607
      grad_gnorm: 0.21468855440616608
      policy_entropy: 0.00014298858877737075
      policy_loss: -6.930267026916681e-09
      var_gnorm: 28.233854293823242
      vf_explained_var: 0.0
      vf_loss: 3.03501892631175e-05
    num_steps_sampled: 4670000
    num_steps_trained: 4670000
    wait_time_ms: 69.428
  iterations_since_restore: 934
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 7996.553665161133
  time_this_iter_s: 8.429826498031616
  time_total_s: 7996.553665161133
  timestamp: 1594866328
  timesteps_since_restore: 4670000
  timesteps_this_iter: 5000
  timesteps_total: 4670000
  training_iteration: 934
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 21.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 7996 s, 934 iter, 4670000 ts, -459 rew

agent-1: -149.99999999841847
agent-2: 2.0
agent-3: -48.99999999948169
agent-4: -149.99999999841847
agent-5: -149.99999999841847
Extrinsic Rewards:
0
2
1
0
0
Sum Reward: 3
Avg Reward: 0.6
Min Reward: 0
Max Reward: 2
Gini Coefficient: 0.6666666666666666
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-25-37
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -456.0104851513401
  episode_reward_min: -1199.3140624869059
  episodes_this_iter: 1
  episodes_total: 934
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.614
    dispatch_time_ms: 7.014
    learner:
      cur_lr: 0.0010489779524505138
      grad_gnorm: 23.32578468322754
      policy_entropy: 0.00023558050452265888
      policy_loss: 1.1612229400270735e-06
      var_gnorm: 28.23263168334961
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 0.35827600955963135
    num_steps_sampled: 4675000
    num_steps_trained: 4675000
    wait_time_ms: 72.305
  iterations_since_restore: 935
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 8004.717216968536
  time_this_iter_s: 8.163551807403564
  time_total_s: 8004.717216968536
  timestamp: 1594866337
  timesteps_since_restore: 4675000
  timesteps_this_iter: 5000
  timesteps_total: 4675000
  training_iteration: 935
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 21.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 8004 s, 935 iter, 4675000 ts, -456 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-25-45
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -448.07048515142486
  episode_reward_min: -1199.3140624869059
  episodes_this_iter: 1
  episodes_total: 935
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.635
    dispatch_time_ms: 7.096
    learner:
      cur_lr: 0.0010486450046300888
      grad_gnorm: 4.584582805633545
      policy_entropy: 0.00019847924704663455
      policy_loss: 3.780745601034141e-07
      var_gnorm: 28.232378005981445
      vf_explained_var: -2.384185791015625e-07
      vf_loss: 0.013840303756296635
    num_steps_sampled: 4680000
    num_steps_trained: 4680000
    wait_time_ms: 73.328
  iterations_since_restore: 936
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 8012.859534502029
  time_this_iter_s: 8.142317533493042
  time_total_s: 8012.859534502029
  timestamp: 1594866345
  timesteps_since_restore: 4680000
  timesteps_this_iter: 5000
  timesteps_total: 4680000
  training_iteration: 936
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 21.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 8012 s, 936 iter, 4680000 ts, -448 rew

agent-1: -49.99999999946836
agent-2: -49.99999999946836
agent-3: -49.99999999946836
agent-4: 1.0
agent-5: -49.99999999946836
Extrinsic Rewards:
0
0
0
1
0
Sum Reward: 1
Avg Reward: 0.2
Min Reward: 0
Max Reward: 1
Gini Coefficient: 0.8
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-25-53
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -446.08048515144566
  episode_reward_min: -1199.3140624869059
  episodes_this_iter: 1
  episodes_total: 936
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 3.221
    dispatch_time_ms: 8.597
    learner:
      cur_lr: 0.0010483120568096638
      grad_gnorm: 18.428625106811523
      policy_entropy: 0.00034676812356337905
      policy_loss: -2.0072736788279144e-06
      var_gnorm: 28.231447219848633
      vf_explained_var: 1.1920928955078125e-07
      vf_loss: 0.5578263401985168
    num_steps_sampled: 4685000
    num_steps_trained: 4685000
    wait_time_ms: 67.641
  iterations_since_restore: 937
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 8020.987085103989
  time_this_iter_s: 8.127550601959229
  time_total_s: 8020.987085103989
  timestamp: 1594866353
  timesteps_since_restore: 4685000
  timesteps_this_iter: 5000
  timesteps_total: 4685000
  training_iteration: 937
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 21.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 8020 s, 937 iter, 4685000 ts, -446 rew

agent-1: 1.0
agent-2: -49.999999999481645
agent-3: -49.999999999481645
agent-4: -49.999999999481645
agent-5: -49.999999999481645
Extrinsic Rewards:
1
0
0
0
0
Sum Reward: 1
Avg Reward: 0.2
Min Reward: 0
Max Reward: 1
Gini Coefficient: 0.8
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-26-01
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -448.0704851514249
  episode_reward_min: -1199.3140624869059
  episodes_this_iter: 1
  episodes_total: 937
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.766
    dispatch_time_ms: 6.435
    learner:
      cur_lr: 0.001047978992573917
      grad_gnorm: 13.650086402893066
      policy_entropy: 0.00027092196978628635
      policy_loss: 1.6678716292517493e-06
      var_gnorm: 28.232074737548828
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 0.12269273400306702
    num_steps_sampled: 4690000
    num_steps_trained: 4690000
    wait_time_ms: 75.414
  iterations_since_restore: 938
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 8029.139676332474
  time_this_iter_s: 8.152591228485107
  time_total_s: 8029.139676332474
  timestamp: 1594866361
  timesteps_since_restore: 4690000
  timesteps_this_iter: 5000
  timesteps_total: 4690000
  training_iteration: 938
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 21.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 8029 s, 938 iter, 4690000 ts, -448 rew

agent-1: -149.99999999837684
agent-2: 3.0
agent-3: -149.99999999837684
agent-4: -149.99999999837684
agent-5: -149.99999999837684
Extrinsic Rewards:
0
3
0
0
0
Sum Reward: 3
Avg Reward: 0.6
Min Reward: 0
Max Reward: 3
Gini Coefficient: 0.8
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-26-09
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -451.06048515139116
  episode_reward_min: -1199.3140624869059
  episodes_this_iter: 1
  episodes_total: 938
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 3.006
    dispatch_time_ms: 8.681
    learner:
      cur_lr: 0.0010476460447534919
      grad_gnorm: 7.875791072845459
      policy_entropy: 0.0003368644102010876
      policy_loss: 7.82382016950578e-07
      var_gnorm: 28.23200798034668
      vf_explained_var: 0.0
      vf_loss: 0.07379385083913803
    num_steps_sampled: 4695000
    num_steps_trained: 4695000
    wait_time_ms: 69.882
  iterations_since_restore: 939
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 8037.230543613434
  time_this_iter_s: 8.090867280960083
  time_total_s: 8037.230543613434
  timestamp: 1594866369
  timesteps_since_restore: 4695000
  timesteps_this_iter: 5000
  timesteps_total: 4695000
  training_iteration: 939
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 21.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 8037 s, 939 iter, 4695000 ts, -451 rew

agent-1: -249.99999999727268
agent-2: -249.99999999727268
agent-3: -249.99999999727268
agent-4: 3.0
agent-5: -47.9999999994817
Extrinsic Rewards:
0
0
0
3
2
Sum Reward: 5
Avg Reward: 1.0
Min Reward: 0
Max Reward: 3
Gini Coefficient: 0.64
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-26-17
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -453.04048515136907
  episode_reward_min: -1199.3140624869059
  episodes_this_iter: 1
  episodes_total: 939
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 3.45
    dispatch_time_ms: 8.365
    learner:
      cur_lr: 0.001047312980517745
      grad_gnorm: 11.01989459991455
      policy_entropy: 0.0002744144876487553
      policy_loss: 1.1651112572508282e-06
      var_gnorm: 28.232118606567383
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 0.08040808886289597
    num_steps_sampled: 4700000
    num_steps_trained: 4700000
    wait_time_ms: 67.859
  iterations_since_restore: 940
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 8045.372906208038
  time_this_iter_s: 8.142362594604492
  time_total_s: 8045.372906208038
  timestamp: 1594866377
  timesteps_since_restore: 4700000
  timesteps_this_iter: 5000
  timesteps_total: 4700000
  training_iteration: 940
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 21.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 8045 s, 940 iter, 4700000 ts, -453 rew

agent-1: -49.99999999946836
agent-2: -49.99999999946836
agent-3: -49.99999999946836
agent-4: -49.99999999946836
agent-5: 1.0
Extrinsic Rewards:
0
0
0
0
1
Sum Reward: 1
Avg Reward: 0.2
Min Reward: 0
Max Reward: 1
Gini Coefficient: 0.8
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-26-26
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -453.0404851513685
  episode_reward_min: -1199.3140624869059
  episodes_this_iter: 1
  episodes_total: 940
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 3.959
    dispatch_time_ms: 8.147
    learner:
      cur_lr: 0.00104698003269732
      grad_gnorm: 0.17978307604789734
      policy_entropy: 0.00019277284445706755
      policy_loss: 1.206652733287683e-08
      var_gnorm: 28.233121871948242
      vf_explained_var: 0.0
      vf_loss: 2.1288544303388335e-05
    num_steps_sampled: 4705000
    num_steps_trained: 4705000
    wait_time_ms: 71.766
  iterations_since_restore: 941
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 8053.451882362366
  time_this_iter_s: 8.078976154327393
  time_total_s: 8053.451882362366
  timestamp: 1594866386
  timesteps_since_restore: 4705000
  timesteps_this_iter: 5000
  timesteps_total: 4705000
  training_iteration: 941
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 21.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 8053 s, 941 iter, 4705000 ts, -453 rew

agent-1: -152.65703124835082
agent-2: -349.99999999627744
agent-3: -152.65703124847397
agent-4: -47.99999999945478
agent-5: 3.0
Extrinsic Rewards:
1
0
1
2
3
Sum Reward: 7
Avg Reward: 1.4
Min Reward: 0
Max Reward: 3
Gini Coefficient: 0.4
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-26-38
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -460.04362577629405
  episode_reward_min: -1199.3140624869059
  episodes_this_iter: 1
  episodes_total: 941
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.639
    dispatch_time_ms: 25.993
    learner:
      cur_lr: 0.0010466469684615731
      grad_gnorm: 40.000003814697266
      policy_entropy: 0.0002955020172521472
      policy_loss: 3.896073849318782e-06
      var_gnorm: 28.232561111450195
      vf_explained_var: 0.0
      vf_loss: 3.294236421585083
    num_steps_sampled: 4710000
    num_steps_trained: 4710000
    wait_time_ms: 25.328
  iterations_since_restore: 942
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 8066.080675125122
  time_this_iter_s: 12.628792762756348
  time_total_s: 8066.080675125122
  timestamp: 1594866398
  timesteps_since_restore: 4710000
  timesteps_this_iter: 5000
  timesteps_total: 4710000
  training_iteration: 942
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 21.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 8066 s, 942 iter, 4710000 ts, -460 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-26-47
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -454.0736257763578
  episode_reward_min: -1199.3140624869059
  episodes_this_iter: 1
  episodes_total: 942
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 3.176
    dispatch_time_ms: 27.644
    learner:
      cur_lr: 0.001046314020641148
      grad_gnorm: 0.12216172367334366
      policy_entropy: 0.00011147768964292482
      policy_loss: 9.231723829827843e-09
      var_gnorm: 28.23540687561035
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 9.825088454817887e-06
    num_steps_sampled: 4715000
    num_steps_trained: 4715000
    wait_time_ms: 54.957
  iterations_since_restore: 943
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 8074.444180965424
  time_this_iter_s: 8.363505840301514
  time_total_s: 8074.444180965424
  timestamp: 1594866407
  timesteps_since_restore: 4715000
  timesteps_this_iter: 5000
  timesteps_total: 4715000
  training_iteration: 943
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 21.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 8074 s, 943 iter, 4715000 ts, -454 rew

agent-1: 3.0
agent-2: -149.99999999837684
agent-3: -149.99999999837684
agent-4: -149.99999999837684
agent-5: -149.99999999837684
Extrinsic Rewards:
3
0
0
0
0
Sum Reward: 3
Avg Reward: 0.6
Min Reward: 0
Max Reward: 3
Gini Coefficient: 0.8
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-26-55
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -451.06362577638976
  episode_reward_min: -1199.3140624869059
  episodes_this_iter: 1
  episodes_total: 943
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 3.532
    dispatch_time_ms: 24.56
    learner:
      cur_lr: 0.0010459809564054012
      grad_gnorm: 8.577973365783691
      policy_entropy: 0.00021065137116238475
      policy_loss: 9.426687483937712e-07
      var_gnorm: 28.23372459411621
      vf_explained_var: 0.0
      vf_loss: 0.11778882890939713
    num_steps_sampled: 4720000
    num_steps_trained: 4720000
    wait_time_ms: 56.676
  iterations_since_restore: 944
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 8083.135047912598
  time_this_iter_s: 8.690866947174072
  time_total_s: 8083.135047912598
  timestamp: 1594866415
  timesteps_since_restore: 4720000
  timesteps_this_iter: 5000
  timesteps_total: 4720000
  training_iteration: 944
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 21.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 8083 s, 944 iter, 4720000 ts, -451 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-27-04
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -443.10362577647595
  episode_reward_min: -1199.3140624869059
  episodes_this_iter: 1
  episodes_total: 944
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 3.5
    dispatch_time_ms: 36.577
    learner:
      cur_lr: 0.0010456480085849762
      grad_gnorm: 20.743736267089844
      policy_entropy: 0.0001721404114505276
      policy_loss: -2.573192887211917e-06
      var_gnorm: 28.23533058166504
      vf_explained_var: 0.0
      vf_loss: 1.68240225315094
    num_steps_sampled: 4725000
    num_steps_trained: 4725000
    wait_time_ms: 48.119
  iterations_since_restore: 945
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 8091.93963599205
  time_this_iter_s: 8.804588079452515
  time_total_s: 8091.93963599205
  timestamp: 1594866424
  timesteps_since_restore: 4725000
  timesteps_this_iter: 5000
  timesteps_total: 4725000
  training_iteration: 945
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 21.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 8091 s, 945 iter, 4725000 ts, -443 rew

agent-1: -47.99999999945478
agent-2: -148.99999999841833
agent-3: -299.9999999968223
agent-4: -299.9999999968223
agent-5: 3.0
Extrinsic Rewards:
2
1
0
0
3
Sum Reward: 6
Avg Reward: 1.2
Min Reward: 0
Max Reward: 3
Gini Coefficient: 0.5333333333333333
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-27-12
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -447.0636257764331
  episode_reward_min: -1199.3140624869059
  episodes_this_iter: 1
  episodes_total: 945
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 3.233
    dispatch_time_ms: 9.612
    learner:
      cur_lr: 0.0010453149443492293
      grad_gnorm: 4.861573219299316
      policy_entropy: 0.0001566501596244052
      policy_loss: 6.091993896006898e-07
      var_gnorm: 28.233478546142578
      vf_explained_var: 0.0
      vf_loss: 0.01556368451565504
    num_steps_sampled: 4730000
    num_steps_trained: 4730000
    wait_time_ms: 67.922
  iterations_since_restore: 946
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 8100.144078016281
  time_this_iter_s: 8.204442024230957
  time_total_s: 8100.144078016281
  timestamp: 1594866432
  timesteps_since_restore: 4730000
  timesteps_this_iter: 5000
  timesteps_total: 4730000
  training_iteration: 946
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 21.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 8100 s, 946 iter, 4730000 ts, -447 rew

agent-1: -148.99999999832153
agent-2: -299.9999999967667
agent-3: 4.0
agent-4: -299.9999999967667
agent-5: -148.99999999832153
Extrinsic Rewards:
1
0
4
0
1
Sum Reward: 6
Avg Reward: 1.2
Min Reward: 0
Max Reward: 4
Gini Coefficient: 0.6
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-27-21
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -451.0336257763873
  episode_reward_min: -1199.3140624869059
  episodes_this_iter: 1
  episodes_total: 946
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.444
    dispatch_time_ms: 7.072
    learner:
      cur_lr: 0.0010449819965288043
      grad_gnorm: 23.41026496887207
      policy_entropy: 0.00029691943200305104
      policy_loss: -2.113947630277835e-06
      var_gnorm: 28.231779098510742
      vf_explained_var: 0.0
      vf_loss: 0.9285261034965515
    num_steps_sampled: 4735000
    num_steps_trained: 4735000
    wait_time_ms: 75.6
  iterations_since_restore: 947
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 8108.316146373749
  time_this_iter_s: 8.172068357467651
  time_total_s: 8108.316146373749
  timestamp: 1594866441
  timesteps_since_restore: 4735000
  timesteps_this_iter: 5000
  timesteps_total: 4735000
  training_iteration: 947
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 21.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 8108 s, 947 iter, 4735000 ts, -451 rew

agent-1: -49.999999999481645
agent-2: -49.999999999481645
agent-3: -49.999999999481645
agent-4: -49.999999999481645
agent-5: 1.0
Extrinsic Rewards:
0
0
0
0
1
Sum Reward: 1
Avg Reward: 0.2
Min Reward: 0
Max Reward: 1
Gini Coefficient: 0.8
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-27-29
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -442.11362577648464
  episode_reward_min: -1199.3140624869059
  episodes_this_iter: 1
  episodes_total: 947
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.959
    dispatch_time_ms: 12.084
    learner:
      cur_lr: 0.0010446490487083793
      grad_gnorm: 12.707493782043457
      policy_entropy: 0.00021345623827073723
      policy_loss: 6.920596433701576e-07
      var_gnorm: 28.232810974121094
      vf_explained_var: 0.0
      vf_loss: 0.10633217543363571
    num_steps_sampled: 4740000
    num_steps_trained: 4740000
    wait_time_ms: 68.676
  iterations_since_restore: 948
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 8116.53697013855
  time_this_iter_s: 8.220823764801025
  time_total_s: 8116.53697013855
  timestamp: 1594866449
  timesteps_since_restore: 4740000
  timesteps_this_iter: 5000
  timesteps_total: 4740000
  training_iteration: 948
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 21.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 8116 s, 948 iter, 4740000 ts, -442 rew

agent-1: -149.9999999984318
agent-2: 2.0
agent-3: -149.9999999984318
agent-4: -48.9999999994684
agent-5: -149.9999999984318
Extrinsic Rewards:
0
2
0
1
0
Sum Reward: 3
Avg Reward: 0.6
Min Reward: 0
Max Reward: 2
Gini Coefficient: 0.6666666666666666
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-27-37
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -447.08362577643226
  episode_reward_min: -1199.3140624869059
  episodes_this_iter: 1
  episodes_total: 948
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 3.254
    dispatch_time_ms: 6.671
    learner:
      cur_lr: 0.0010443159844726324
      grad_gnorm: 20.90831756591797
      policy_entropy: 0.000229369688895531
      policy_loss: 9.934776699083159e-07
      var_gnorm: 28.23333740234375
      vf_explained_var: 0.0
      vf_loss: 0.2878614366054535
    num_steps_sampled: 4745000
    num_steps_trained: 4745000
    wait_time_ms: 70.741
  iterations_since_restore: 949
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 8124.711429357529
  time_this_iter_s: 8.174459218978882
  time_total_s: 8124.711429357529
  timestamp: 1594866457
  timesteps_since_restore: 4745000
  timesteps_this_iter: 5000
  timesteps_total: 4745000
  training_iteration: 949
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 21.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 8124 s, 949 iter, 4745000 ts, -447 rew

agent-1: -249.99999999731412
agent-2: -249.99999999731412
agent-3: -148.99999999837678
agent-4: -249.99999999731412
agent-5: 4.0
Extrinsic Rewards:
0
0
1
0
4
Sum Reward: 5
Avg Reward: 1.0
Min Reward: 0
Max Reward: 4
Gini Coefficient: 0.72
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-27-45
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -454.0436257763561
  episode_reward_min: -1199.3140624869059
  episodes_this_iter: 1
  episodes_total: 949
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.696
    dispatch_time_ms: 7.317
    learner:
      cur_lr: 0.0010439830366522074
      grad_gnorm: 12.967299461364746
      policy_entropy: 0.00020352979481685907
      policy_loss: 7.062087661324767e-07
      var_gnorm: 28.233623504638672
      vf_explained_var: 5.960464477539063e-08
      vf_loss: 0.1109103113412857
    num_steps_sampled: 4750000
    num_steps_trained: 4750000
    wait_time_ms: 70.566
  iterations_since_restore: 950
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 8132.936871051788
  time_this_iter_s: 8.225441694259644
  time_total_s: 8132.936871051788
  timestamp: 1594866465
  timesteps_since_restore: 4750000
  timesteps_this_iter: 5000
  timesteps_total: 4750000
  training_iteration: 950
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 21.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 8132 s, 950 iter, 4750000 ts, -454 rew

agent-1: -99.99999999894987
agent-2: -99.99999999894987
agent-3: -99.99999999894987
agent-4: 2.0
agent-5: -99.99999999894987
Extrinsic Rewards:
0
0
0
2
0
Sum Reward: 2
Avg Reward: 0.4
Min Reward: 0
Max Reward: 2
Gini Coefficient: 0.8
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-27-54
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -447.03925077643396
  episode_reward_min: -1199.3140624869059
  episodes_this_iter: 1
  episodes_total: 950
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.579
    dispatch_time_ms: 9.009
    learner:
      cur_lr: 0.0010436499724164605
      grad_gnorm: 0.19043348729610443
      policy_entropy: 0.0001319407601840794
      policy_loss: 6.036132926823257e-09
      var_gnorm: 28.235027313232422
      vf_explained_var: 0.0
      vf_loss: 2.3874374164734036e-05
    num_steps_sampled: 4755000
    num_steps_trained: 4755000
    wait_time_ms: 69.469
  iterations_since_restore: 951
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 8141.176113367081
  time_this_iter_s: 8.239242315292358
  time_total_s: 8141.176113367081
  timestamp: 1594866474
  timesteps_since_restore: 4755000
  timesteps_this_iter: 5000
  timesteps_total: 4755000
  training_iteration: 951
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 21.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 8141 s, 951 iter, 4755000 ts, -447 rew

agent-1: -299.9999999967528
agent-2: -299.9999999967528
agent-3: -99.2499999988536
agent-4: 2.75
agent-5: -299.9999999967528
Extrinsic Rewards:
0
0
2
4
0
Sum Reward: 6
Avg Reward: 1.2
Min Reward: 0
Max Reward: 4
Gini Coefficient: 0.6666666666666666
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-28-02
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -457.00425077632514
  episode_reward_min: -1199.3140624869059
  episodes_this_iter: 1
  episodes_total: 951
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 3.318
    dispatch_time_ms: 8.318
    learner:
      cur_lr: 0.0010433170245960355
      grad_gnorm: 7.8580732345581055
      policy_entropy: 0.00017120443226303905
      policy_loss: 7.360092126873496e-07
      var_gnorm: 28.232980728149414
      vf_explained_var: 0.0
      vf_loss: 0.04065169394016266
    num_steps_sampled: 4760000
    num_steps_trained: 4760000
    wait_time_ms: 72.129
  iterations_since_restore: 952
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 8149.32709813118
  time_this_iter_s: 8.150984764099121
  time_total_s: 8149.32709813118
  timestamp: 1594866482
  timesteps_since_restore: 4760000
  timesteps_this_iter: 5000
  timesteps_total: 4760000
  training_iteration: 952
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 21.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 8149 s, 952 iter, 4760000 ts, -457 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-28-10
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -447.0642507764332
  episode_reward_min: -1199.3140624869059
  episodes_this_iter: 1
  episodes_total: 952
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.733
    dispatch_time_ms: 7.783
    learner:
      cur_lr: 0.0010429839603602886
      grad_gnorm: 19.735319137573242
      policy_entropy: 0.00021914762328378856
      policy_loss: 5.866501737727958e-07
      var_gnorm: 28.232860565185547
      vf_explained_var: 0.0
      vf_loss: 0.2564680874347687
    num_steps_sampled: 4765000
    num_steps_trained: 4765000
    wait_time_ms: 72.859
  iterations_since_restore: 953
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 8157.51037478447
  time_this_iter_s: 8.183276653289795
  time_total_s: 8157.51037478447
  timestamp: 1594866490
  timesteps_since_restore: 4765000
  timesteps_this_iter: 5000
  timesteps_total: 4765000
  training_iteration: 953
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 21.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 8157 s, 953 iter, 4765000 ts, -447 rew

agent-1: -149.99999999837684
agent-2: 3.0
agent-3: -149.99999999837684
agent-4: -149.99999999837684
agent-5: -149.99999999837684
Extrinsic Rewards:
0
3
0
0
0
Sum Reward: 3
Avg Reward: 0.6
Min Reward: 0
Max Reward: 3
Gini Coefficient: 0.8
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-28-18
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -453.0342507763682
  episode_reward_min: -1199.3140624869059
  episodes_this_iter: 1
  episodes_total: 953
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.881
    dispatch_time_ms: 6.55
    learner:
      cur_lr: 0.0010426510125398636
      grad_gnorm: 5.698152542114258
      policy_entropy: 0.00013101936201564968
      policy_loss: 2.1802949845550756e-07
      var_gnorm: 28.23406219482422
      vf_explained_var: 1.7881393432617188e-07
      vf_loss: 0.021380338817834854
    num_steps_sampled: 4770000
    num_steps_trained: 4770000
    wait_time_ms: 73.061
  iterations_since_restore: 954
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 8165.724111318588
  time_this_iter_s: 8.213736534118652
  time_total_s: 8165.724111318588
  timestamp: 1594866498
  timesteps_since_restore: 4770000
  timesteps_this_iter: 5000
  timesteps_total: 4770000
  training_iteration: 954
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 21.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 8165 s, 954 iter, 4770000 ts, -453 rew

agent-1: -99.99999999894987
agent-2: -99.99999999894987
agent-3: -99.99999999894987
agent-4: -99.99999999894987
agent-5: 2.0
Extrinsic Rewards:
0
0
0
0
2
Sum Reward: 2
Avg Reward: 0.4
Min Reward: 0
Max Reward: 2
Gini Coefficient: 0.8
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-28-27
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -446.02987577644615
  episode_reward_min: -1199.3140624869059
  episodes_this_iter: 1
  episodes_total: 954
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 3.051
    dispatch_time_ms: 6.387
    learner:
      cur_lr: 0.0010423179483041167
      grad_gnorm: 16.1569881439209
      policy_entropy: 0.00021246417600195855
      policy_loss: 7.189275379460014e-07
      var_gnorm: 28.232715606689453
      vf_explained_var: 5.960464477539063e-08
      vf_loss: 0.17189481854438782
    num_steps_sampled: 4775000
    num_steps_trained: 4775000
    wait_time_ms: 74.279
  iterations_since_restore: 955
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 8174.008006334305
  time_this_iter_s: 8.283895015716553
  time_total_s: 8174.008006334305
  timestamp: 1594866507
  timesteps_since_restore: 4775000
  timesteps_this_iter: 5000
  timesteps_total: 4775000
  training_iteration: 955
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 21.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 8174 s, 955 iter, 4775000 ts, -446 rew

agent-1: 2.0
agent-2: -149.9999999984318
agent-3: -48.9999999994684
agent-4: -149.9999999984318
agent-5: -149.9999999984318
Extrinsic Rewards:
2
0
1
0
0
Sum Reward: 3
Avg Reward: 0.6
Min Reward: 0
Max Reward: 2
Gini Coefficient: 0.6666666666666666
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-28-35
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -443.01050077648074
  episode_reward_min: -1199.3140624869059
  episodes_this_iter: 1
  episodes_total: 955
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.546
    dispatch_time_ms: 6.568
    learner:
      cur_lr: 0.0010419850004836917
      grad_gnorm: 0.3777824342250824
      policy_entropy: 0.00011053061462007463
      policy_loss: -1.0287156904098538e-08
      var_gnorm: 28.234912872314453
      vf_explained_var: 0.0
      vf_loss: 9.398902329849079e-05
    num_steps_sampled: 4780000
    num_steps_trained: 4780000
    wait_time_ms: 73.781
  iterations_since_restore: 956
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 8182.169999837875
  time_this_iter_s: 8.161993503570557
  time_total_s: 8182.169999837875
  timestamp: 1594866515
  timesteps_since_restore: 4780000
  timesteps_this_iter: 5000
  timesteps_total: 4780000
  training_iteration: 956
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 21.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 8182 s, 956 iter, 4780000 ts, -443 rew

agent-1: -149.99999999840443
agent-2: -149.99999999840443
agent-3: 3.0
agent-4: -149.99999999840443
agent-5: -149.99999999840443
Extrinsic Rewards:
0
0
3
0
0
Sum Reward: 3
Avg Reward: 0.6
Min Reward: 0
Max Reward: 3
Gini Coefficient: 0.8
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-28-43
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -442.0205007764923
  episode_reward_min: -1199.3140624869059
  episodes_this_iter: 1
  episodes_total: 956
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 3.125
    dispatch_time_ms: 7.286
    learner:
      cur_lr: 0.0010416520526632667
      grad_gnorm: 17.080785751342773
      policy_entropy: 0.00032227017800323665
      policy_loss: 1.1778719226640533e-06
      var_gnorm: 28.23138999938965
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 0.19211414456367493
    num_steps_sampled: 4785000
    num_steps_trained: 4785000
    wait_time_ms: 73.801
  iterations_since_restore: 957
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 8190.388186454773
  time_this_iter_s: 8.218186616897583
  time_total_s: 8190.388186454773
  timestamp: 1594866523
  timesteps_since_restore: 4785000
  timesteps_this_iter: 5000
  timesteps_total: 4785000
  training_iteration: 957
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 21.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 8190 s, 957 iter, 4785000 ts, -442 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-28-51
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -439.04050077652346
  episode_reward_min: -1199.3140624869059
  episodes_this_iter: 1
  episodes_total: 957
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.704
    dispatch_time_ms: 6.043
    learner:
      cur_lr: 0.0010413189884275198
      grad_gnorm: 3.5579371452331543
      policy_entropy: 8.868186705512926e-05
      policy_loss: 1.52705339928616e-07
      var_gnorm: 28.23543930053711
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 0.008332320488989353
    num_steps_sampled: 4790000
    num_steps_trained: 4790000
    wait_time_ms: 71.581
  iterations_since_restore: 958
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 8198.447309494019
  time_this_iter_s: 8.059123039245605
  time_total_s: 8198.447309494019
  timestamp: 1594866531
  timesteps_since_restore: 4790000
  timesteps_this_iter: 5000
  timesteps_total: 4790000
  training_iteration: 958
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 21.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 8198 s, 958 iter, 4790000 ts, -439 rew

agent-1: -199.99999999780377
agent-2: 4.0
agent-3: -199.99999999780377
agent-4: -199.99999999780377
agent-5: -199.99999999780377
Extrinsic Rewards:
0
4
0
0
0
Sum Reward: 4
Avg Reward: 0.8
Min Reward: 0
Max Reward: 4
Gini Coefficient: 0.8
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-28-59
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -447.0005007764355
  episode_reward_min: -1199.3140624869059
  episodes_this_iter: 1
  episodes_total: 958
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 3.075
    dispatch_time_ms: 8.453
    learner:
      cur_lr: 0.0010409860406070948
      grad_gnorm: 40.0
      policy_entropy: 0.00011918280506506562
      policy_loss: -2.461029680489446e-06
      var_gnorm: 28.234224319458008
      vf_explained_var: 0.0
      vf_loss: 6.536339282989502
    num_steps_sampled: 4795000
    num_steps_trained: 4795000
    wait_time_ms: 70.846
  iterations_since_restore: 959
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 8206.520749092102
  time_this_iter_s: 8.073439598083496
  time_total_s: 8206.520749092102
  timestamp: 1594866539
  timesteps_since_restore: 4795000
  timesteps_this_iter: 5000
  timesteps_total: 4795000
  training_iteration: 959
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 21.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 8206 s, 959 iter, 4795000 ts, -447 rew

agent-1: -99.99999999894987
agent-2: -99.99999999894987
agent-3: -99.99999999894987
agent-4: -99.99999999894987
agent-5: 2.0
Extrinsic Rewards:
0
0
0
0
2
Sum Reward: 2
Avg Reward: 0.4
Min Reward: 0
Max Reward: 2
Gini Coefficient: 0.8
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-29-07
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -450.9805007763935
  episode_reward_min: -1199.3140624869059
  episodes_this_iter: 1
  episodes_total: 959
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 3.05
    dispatch_time_ms: 8.138
    learner:
      cur_lr: 0.001040652976371348
      grad_gnorm: 5.380195140838623
      policy_entropy: 9.41202015383169e-05
      policy_loss: 2.098775837566791e-07
      var_gnorm: 28.234729766845703
      vf_explained_var: 0.0
      vf_loss: 0.019060729071497917
    num_steps_sampled: 4800000
    num_steps_trained: 4800000
    wait_time_ms: 70.705
  iterations_since_restore: 960
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 8214.68171787262
  time_this_iter_s: 8.160968780517578
  time_total_s: 8214.68171787262
  timestamp: 1594866547
  timesteps_since_restore: 4800000
  timesteps_this_iter: 5000
  timesteps_total: 4800000
  training_iteration: 960
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 21.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 8214 s, 960 iter, 4800000 ts, -451 rew

agent-1: -99.99999999894987
agent-2: -99.99999999894987
agent-3: -99.99999999894987
agent-4: -99.99999999894987
agent-5: 2.0
Extrinsic Rewards:
0
0
0
0
2
Sum Reward: 2
Avg Reward: 0.4
Min Reward: 0
Max Reward: 2
Gini Coefficient: 0.8
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-29-16
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -452.97050077637226
  episode_reward_min: -1199.3140624869059
  episodes_this_iter: 1
  episodes_total: 960
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 3.306
    dispatch_time_ms: 7.627
    learner:
      cur_lr: 0.0010403200285509229
      grad_gnorm: 40.0
      policy_entropy: 0.00013826139911543578
      policy_loss: -5.205876732361503e-06
      var_gnorm: 28.23340606689453
      vf_explained_var: 5.960464477539063e-08
      vf_loss: 36.81822967529297
    num_steps_sampled: 4805000
    num_steps_trained: 4805000
    wait_time_ms: 70.808
  iterations_since_restore: 961
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 8222.761072158813
  time_this_iter_s: 8.079354286193848
  time_total_s: 8222.761072158813
  timestamp: 1594866556
  timesteps_since_restore: 4805000
  timesteps_this_iter: 5000
  timesteps_total: 4805000
  training_iteration: 961
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 21.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 8222 s, 961 iter, 4805000 ts, -453 rew

agent-1: 3.0
agent-2: -149.99999999837684
agent-3: -149.99999999837684
agent-4: -149.99999999837684
agent-5: -149.99999999837684
Extrinsic Rewards:
3
0
0
0
0
Sum Reward: 3
Avg Reward: 0.6
Min Reward: 0
Max Reward: 3
Gini Coefficient: 0.8
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-29-24
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -450.9905007763922
  episode_reward_min: -1199.3140624869059
  episodes_this_iter: 1
  episodes_total: 961
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 4.394
    dispatch_time_ms: 7.969
    learner:
      cur_lr: 0.001039986964315176
      grad_gnorm: 0.5758025050163269
      policy_entropy: 9.469203359913081e-05
      policy_loss: -3.4966003426006864e-08
      var_gnorm: 28.234010696411133
      vf_explained_var: 0.0
      vf_loss: 0.0002182941243518144
    num_steps_sampled: 4810000
    num_steps_trained: 4810000
    wait_time_ms: 68.857
  iterations_since_restore: 962
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 8230.997126340866
  time_this_iter_s: 8.236054182052612
  time_total_s: 8230.997126340866
  timestamp: 1594866564
  timesteps_since_restore: 4810000
  timesteps_this_iter: 5000
  timesteps_total: 4810000
  training_iteration: 962
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 21.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 8230 s, 962 iter, 4810000 ts, -451 rew

agent-1: -249.99999999735493
agent-2: -47.99999999945478
agent-3: -249.99999999735493
agent-4: -249.99999999735493
agent-5: 3.0
Extrinsic Rewards:
0
2
0
0
3
Sum Reward: 5
Avg Reward: 1.0
Min Reward: 0
Max Reward: 3
Gini Coefficient: 0.64
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-29-32
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -458.94050077630743
  episode_reward_min: -1199.3140624869059
  episodes_this_iter: 1
  episodes_total: 962
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.787
    dispatch_time_ms: 7.696
    learner:
      cur_lr: 0.001039654016494751
      grad_gnorm: 0.004024887923151255
      policy_entropy: 0.0001368099037790671
      policy_loss: 1.2681207472997613e-10
      var_gnorm: 28.23255729675293
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 1.0610161638169302e-08
    num_steps_sampled: 4815000
    num_steps_trained: 4815000
    wait_time_ms: 70.437
  iterations_since_restore: 963
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 8239.12360239029
  time_this_iter_s: 8.126476049423218
  time_total_s: 8239.12360239029
  timestamp: 1594866572
  timesteps_since_restore: 4815000
  timesteps_this_iter: 5000
  timesteps_total: 4815000
  training_iteration: 963
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 21.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 8239 s, 963 iter, 4815000 ts, -459 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-29-40
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -450.9805007763935
  episode_reward_min: -1199.3140624869059
  episodes_this_iter: 1
  episodes_total: 963
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.753
    dispatch_time_ms: 8.783
    learner:
      cur_lr: 0.0010393209522590041
      grad_gnorm: 0.6212941408157349
      policy_entropy: 5.63538633286953e-05
      policy_loss: 4.818736698553039e-08
      var_gnorm: 28.235870361328125
      vf_explained_var: -2.384185791015625e-07
      vf_loss: 0.00025416043354198337
    num_steps_sampled: 4820000
    num_steps_trained: 4820000
    wait_time_ms: 69.891
  iterations_since_restore: 964
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 8247.244142532349
  time_this_iter_s: 8.120540142059326
  time_total_s: 8247.244142532349
  timestamp: 1594866580
  timesteps_since_restore: 4820000
  timesteps_this_iter: 5000
  timesteps_total: 4820000
  training_iteration: 964
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 21.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 8247 s, 964 iter, 4820000 ts, -451 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-29-48
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -443.01487577647947
  episode_reward_min: -1199.3140624869059
  episodes_this_iter: 1
  episodes_total: 964
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.873
    dispatch_time_ms: 5.677
    learner:
      cur_lr: 0.001038988004438579
      grad_gnorm: 40.0
      policy_entropy: 7.493454904761165e-05
      policy_loss: -5.982872608001344e-06
      var_gnorm: 28.23443031311035
      vf_explained_var: 0.0
      vf_loss: 43.245418548583984
    num_steps_sampled: 4825000
    num_steps_trained: 4825000
    wait_time_ms: 76.582
  iterations_since_restore: 965
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 8255.418148994446
  time_this_iter_s: 8.174006462097168
  time_total_s: 8255.418148994446
  timestamp: 1594866588
  timesteps_since_restore: 4825000
  timesteps_this_iter: 5000
  timesteps_total: 4825000
  training_iteration: 965
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 21.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 8255 s, 965 iter, 4825000 ts, -443 rew

agent-1: -49.999999999481645
agent-2: 1.0
agent-3: -49.999999999481645
agent-4: -49.999999999481645
agent-5: -49.999999999481645
Extrinsic Rewards:
0
1
0
0
0
Sum Reward: 1
Avg Reward: 0.2
Min Reward: 0
Max Reward: 1
Gini Coefficient: 0.8
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-29-57
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -441.0248757765006
  episode_reward_min: -1199.3140624869059
  episodes_this_iter: 1
  episodes_total: 965
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 3.416
    dispatch_time_ms: 8.69
    learner:
      cur_lr: 0.001038655056618154
      grad_gnorm: 5.707123756408691
      policy_entropy: 6.049968578736298e-05
      policy_loss: 1.5540716447048908e-07
      var_gnorm: 28.233108520507812
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 0.021447530016303062
    num_steps_sampled: 4830000
    num_steps_trained: 4830000
    wait_time_ms: 67.172
  iterations_since_restore: 966
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 8263.609254598618
  time_this_iter_s: 8.191105604171753
  time_total_s: 8263.609254598618
  timestamp: 1594866597
  timesteps_since_restore: 4830000
  timesteps_this_iter: 5000
  timesteps_total: 4830000
  training_iteration: 966
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 21.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 8263 s, 966 iter, 4830000 ts, -441 rew

agent-1: -199.999999997859
agent-2: -199.999999997859
agent-3: 3.0
agent-4: -199.999999997859
agent-5: -98.9999999988954
Extrinsic Rewards:
0
0
3
0
1
Sum Reward: 4
Avg Reward: 0.8
Min Reward: 0
Max Reward: 3
Gini Coefficient: 0.7
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-30-05
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -447.9848757764254
  episode_reward_min: -1199.3140624869059
  episodes_this_iter: 1
  episodes_total: 966
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.837
    dispatch_time_ms: 6.81
    learner:
      cur_lr: 0.0010383219923824072
      grad_gnorm: 0.03397710993885994
      policy_entropy: 4.586834256770089e-05
      policy_loss: -0.0
      var_gnorm: 28.234411239624023
      vf_explained_var: 5.960464477539063e-08
      vf_loss: 7.601806260026933e-07
    num_steps_sampled: 4835000
    num_steps_trained: 4835000
    wait_time_ms: 71.367
  iterations_since_restore: 967
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 8271.754393100739
  time_this_iter_s: 8.145138502120972
  time_total_s: 8271.754393100739
  timestamp: 1594866605
  timesteps_since_restore: 4835000
  timesteps_this_iter: 5000
  timesteps_total: 4835000
  training_iteration: 967
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 21.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 8271 s, 967 iter, 4835000 ts, -448 rew

agent-1: 4.0
agent-2: -349.99999999625004
agent-3: -349.99999999625004
agent-4: -46.99999999944068
agent-5: -349.99999999625004
Extrinsic Rewards:
4
0
0
3
0
Sum Reward: 7
Avg Reward: 1.4
Min Reward: 0
Max Reward: 4
Gini Coefficient: 0.6285714285714286
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-30-13
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -454.9348757763494
  episode_reward_min: -1199.3140624869059
  episodes_this_iter: 1
  episodes_total: 967
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 3.013
    dispatch_time_ms: 7.132
    learner:
      cur_lr: 0.0010379890445619822
      grad_gnorm: 2.075319766998291
      policy_entropy: 6.288896838668734e-05
      policy_loss: 7.78600792727957e-08
      var_gnorm: 28.231534957885742
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 0.002836022060364485
    num_steps_sampled: 4840000
    num_steps_trained: 4840000
    wait_time_ms: 72.3
  iterations_since_restore: 968
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 8279.901543617249
  time_this_iter_s: 8.14715051651001
  time_total_s: 8279.901543617249
  timestamp: 1594866613
  timesteps_since_restore: 4840000
  timesteps_this_iter: 5000
  timesteps_total: 4840000
  training_iteration: 968
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 21.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 8279 s, 968 iter, 4840000 ts, -455 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-30-21
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -454.9348757763493
  episode_reward_min: -1199.3140624869059
  episodes_this_iter: 1
  episodes_total: 968
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 3.322
    dispatch_time_ms: 9.974
    learner:
      cur_lr: 0.0010376559803262353
      grad_gnorm: 13.761076927185059
      policy_entropy: 0.00010104200191562995
      policy_loss: 3.747193773051549e-07
      var_gnorm: 28.22920036315918
      vf_explained_var: 0.0
      vf_loss: 0.12469610571861267
    num_steps_sampled: 4845000
    num_steps_trained: 4845000
    wait_time_ms: 69.432
  iterations_since_restore: 969
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 8288.0800344944
  time_this_iter_s: 8.17849087715149
  time_total_s: 8288.0800344944
  timestamp: 1594866621
  timesteps_since_restore: 4845000
  timesteps_this_iter: 5000
  timesteps_total: 4845000
  training_iteration: 969
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 21.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 8288 s, 969 iter, 4845000 ts, -455 rew

agent-1: -99.99999999894987
agent-2: -99.99999999894987
agent-3: -99.99999999894987
agent-4: 2.0
agent-5: -99.99999999894987
Extrinsic Rewards:
0
0
0
2
0
Sum Reward: 2
Avg Reward: 0.4
Min Reward: 0
Max Reward: 2
Gini Coefficient: 0.8
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-30-29
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -454.9348757763493
  episode_reward_min: -1199.3140624869059
  episodes_this_iter: 1
  episodes_total: 969
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 3.877
    dispatch_time_ms: 8.885
    learner:
      cur_lr: 0.0010373230325058103
      grad_gnorm: 5.567564487457275
      policy_entropy: 1.7549591575516388e-05
      policy_loss: -0.0
      var_gnorm: 28.23693084716797
      vf_explained_var: 0.0
      vf_loss: 0.02041175588965416
    num_steps_sampled: 4850000
    num_steps_trained: 4850000
    wait_time_ms: 75.048
  iterations_since_restore: 970
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 8296.240722179413
  time_this_iter_s: 8.160687685012817
  time_total_s: 8296.240722179413
  timestamp: 1594866629
  timesteps_since_restore: 4850000
  timesteps_this_iter: 5000
  timesteps_total: 4850000
  training_iteration: 970
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 21.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 8296 s, 970 iter, 4850000 ts, -455 rew

agent-1: -97.9999999988953
agent-2: -299.9999999967948
agent-3: -299.9999999967948
agent-4: -299.9999999967948
agent-5: 4.0
Extrinsic Rewards:
2
0
0
0
4
Sum Reward: 6
Avg Reward: 1.2
Min Reward: 0
Max Reward: 4
Gini Coefficient: 0.6666666666666666
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-30-41
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -459.83815624504734
  episode_reward_min: -1199.3140624869059
  episodes_this_iter: 1
  episodes_total: 970
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 3.028
    dispatch_time_ms: 27.405
    learner:
      cur_lr: 0.0010369899682700634
      grad_gnorm: 0.024325355887413025
      policy_entropy: 1.4792721231060568e-05
      policy_loss: -0.0
      var_gnorm: 28.236949920654297
      vf_explained_var: 1.7881393432617188e-07
      vf_loss: 3.8998638274279074e-07
    num_steps_sampled: 4855000
    num_steps_trained: 4855000
    wait_time_ms: 63.691
  iterations_since_restore: 971
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 8307.365093708038
  time_this_iter_s: 11.124371528625488
  time_total_s: 8307.365093708038
  timestamp: 1594866641
  timesteps_since_restore: 4855000
  timesteps_this_iter: 5000
  timesteps_total: 4855000
  training_iteration: 971
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 21.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 8307 s, 971 iter, 4855000 ts, -460 rew

agent-1: 2.75
agent-2: -299.9999999967528
agent-3: -299.9999999967528
agent-4: -99.2499999988536
agent-5: -299.9999999967528
Extrinsic Rewards:
4
0
0
2
0
Sum Reward: 6
Avg Reward: 1.2
Min Reward: 0
Max Reward: 4
Gini Coefficient: 0.6666666666666666
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-30-49
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -463.82753124500204
  episode_reward_min: -1199.3140624869059
  episodes_this_iter: 1
  episodes_total: 971
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 3.981
    dispatch_time_ms: 25.008
    learner:
      cur_lr: 0.0010366570204496384
      grad_gnorm: 5.119116394780576e-05
      policy_entropy: 1.584860910952557e-05
      policy_loss: -0.0
      var_gnorm: 28.23672866821289
      vf_explained_var: 0.0
      vf_loss: 1.7255631602416943e-12
    num_steps_sampled: 4860000
    num_steps_trained: 4860000
    wait_time_ms: 59.58
  iterations_since_restore: 972
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 8316.116746902466
  time_this_iter_s: 8.75165319442749
  time_total_s: 8316.116746902466
  timestamp: 1594866649
  timesteps_since_restore: 4860000
  timesteps_this_iter: 5000
  timesteps_total: 4860000
  training_iteration: 972
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 21.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 8316 s, 972 iter, 4860000 ts, -464 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-30-58
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -452.84815624512186
  episode_reward_min: -1199.3140624869059
  episodes_this_iter: 1
  episodes_total: 972
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.707
    dispatch_time_ms: 5.93
    learner:
      cur_lr: 0.0010363239562138915
      grad_gnorm: 13.87187671661377
      policy_entropy: 1.8211769202025607e-05
      policy_loss: -0.0
      var_gnorm: 28.237356185913086
      vf_explained_var: 0.0
      vf_loss: 0.12670977413654327
    num_steps_sampled: 4865000
    num_steps_trained: 4865000
    wait_time_ms: 70.014
  iterations_since_restore: 973
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 8324.62229514122
  time_this_iter_s: 8.505548238754272
  time_total_s: 8324.62229514122
  timestamp: 1594866658
  timesteps_since_restore: 4865000
  timesteps_this_iter: 5000
  timesteps_total: 4865000
  training_iteration: 973
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 21.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 8324 s, 973 iter, 4865000 ts, -453 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-31-06
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -444.8981562452067
  episode_reward_min: -1199.3140624869059
  episodes_this_iter: 1
  episodes_total: 973
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 3.432
    dispatch_time_ms: 7.491
    learner:
      cur_lr: 0.0010359910083934665
      grad_gnorm: 0.7475768327713013
      policy_entropy: 1.9441713448031805e-05
      policy_loss: -0.0
      var_gnorm: 28.23567008972168
      vf_explained_var: 0.0
      vf_loss: 0.0003680278023239225
    num_steps_sampled: 4870000
    num_steps_trained: 4870000
    wait_time_ms: 71.961
  iterations_since_restore: 974
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 8332.787257909775
  time_this_iter_s: 8.164962768554688
  time_total_s: 8332.787257909775
  timestamp: 1594866666
  timesteps_since_restore: 4870000
  timesteps_this_iter: 5000
  timesteps_total: 4870000
  training_iteration: 974
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 21.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 8332 s, 974 iter, 4870000 ts, -445 rew

agent-1: -198.99999999778979
agent-2: -99.2499999988536
agent-3: -349.99999999623503
agent-4: 2.75
agent-5: -349.99999999623503
Extrinsic Rewards:
1
2
0
4
0
Sum Reward: 7
Avg Reward: 1.4
Min Reward: 0
Max Reward: 4
Gini Coefficient: 0.5714285714285714
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-31-14
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -454.8531562450978
  episode_reward_min: -1199.3140624869059
  episodes_this_iter: 1
  episodes_total: 974
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.431
    dispatch_time_ms: 7.324
    learner:
      cur_lr: 0.0010356579441577196
      grad_gnorm: 39.999996185302734
      policy_entropy: 2.3729608074063435e-05
      policy_loss: -0.0
      var_gnorm: 28.23643684387207
      vf_explained_var: 0.0
      vf_loss: 20.45440673828125
    num_steps_sampled: 4875000
    num_steps_trained: 4875000
    wait_time_ms: 71.226
  iterations_since_restore: 975
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 8340.824522018433
  time_this_iter_s: 8.037264108657837
  time_total_s: 8340.824522018433
  timestamp: 1594866674
  timesteps_since_restore: 4875000
  timesteps_this_iter: 5000
  timesteps_total: 4875000
  training_iteration: 975
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 21.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 8340 s, 975 iter, 4875000 ts, -455 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-31-22
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -446.8931562451879
  episode_reward_min: -1199.3140624869059
  episodes_this_iter: 1
  episodes_total: 975
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 3.06
    dispatch_time_ms: 8.572
    learner:
      cur_lr: 0.0010353249963372946
      grad_gnorm: 6.903623580932617
      policy_entropy: 2.6117106244782917e-05
      policy_loss: -0.0
      var_gnorm: 28.23405647277832
      vf_explained_var: 0.0
      vf_loss: 0.03138351812958717
    num_steps_sampled: 4880000
    num_steps_trained: 4880000
    wait_time_ms: 70.457
  iterations_since_restore: 976
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 8348.95947766304
  time_this_iter_s: 8.134955644607544
  time_total_s: 8348.95947766304
  timestamp: 1594866682
  timesteps_since_restore: 4880000
  timesteps_this_iter: 5000
  timesteps_total: 4880000
  training_iteration: 976
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 21.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 8348 s, 976 iter, 4880000 ts, -447 rew

agent-1: 2.0
agent-2: -99.99999999894987
agent-3: -99.99999999894987
agent-4: -99.99999999894987
agent-5: -99.99999999894987
Extrinsic Rewards:
2
0
0
0
0
Sum Reward: 2
Avg Reward: 0.4
Min Reward: 0
Max Reward: 2
Gini Coefficient: 0.8
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-31-31
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -450.87315624514594
  episode_reward_min: -1199.3140624869059
  episodes_this_iter: 1
  episodes_total: 976
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.395
    dispatch_time_ms: 8.651
    learner:
      cur_lr: 0.0010349920485168695
      grad_gnorm: 11.861796379089355
      policy_entropy: 3.2205898605752736e-05
      policy_loss: -0.0
      var_gnorm: 28.233665466308594
      vf_explained_var: 0.0
      vf_loss: 0.0926494151353836
    num_steps_sampled: 4885000
    num_steps_trained: 4885000
    wait_time_ms: 68.527
  iterations_since_restore: 977
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 8357.100077867508
  time_this_iter_s: 8.140600204467773
  time_total_s: 8357.100077867508
  timestamp: 1594866691
  timesteps_since_restore: 4885000
  timesteps_this_iter: 5000
  timesteps_total: 4885000
  training_iteration: 977
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 21.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 8357 s, 977 iter, 4885000 ts, -451 rew

agent-1: -249.99999999735493
agent-2: -249.99999999735493
agent-3: -249.99999999735493
agent-4: -47.99999999945478
agent-5: 3.0
Extrinsic Rewards:
0
0
0
2
3
Sum Reward: 5
Avg Reward: 1.0
Min Reward: 0
Max Reward: 3
Gini Coefficient: 0.64
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-31-39
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -458.82315624506117
  episode_reward_min: -1199.3140624869059
  episodes_this_iter: 1
  episodes_total: 977
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 3.48
    dispatch_time_ms: 8.296
    learner:
      cur_lr: 0.0010346589842811227
      grad_gnorm: 3.2856364250183105
      policy_entropy: 3.93152040487621e-05
      policy_loss: -0.0
      var_gnorm: 28.230621337890625
      vf_explained_var: 0.0
      vf_loss: 0.007108562625944614
    num_steps_sampled: 4890000
    num_steps_trained: 4890000
    wait_time_ms: 69.283
  iterations_since_restore: 978
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 8365.242370605469
  time_this_iter_s: 8.142292737960815
  time_total_s: 8365.242370605469
  timestamp: 1594866699
  timesteps_since_restore: 4890000
  timesteps_this_iter: 5000
  timesteps_total: 4890000
  training_iteration: 978
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 21.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 8365 s, 978 iter, 4890000 ts, -459 rew

agent-1: -49.999999999481645
agent-2: -49.999999999481645
agent-3: -49.999999999481645
agent-4: -49.999999999481645
agent-5: 1.0
Extrinsic Rewards:
0
0
0
0
1
Sum Reward: 1
Avg Reward: 0.2
Min Reward: 0
Max Reward: 1
Gini Coefficient: 0.8
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-31-47
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -456.8331562450824
  episode_reward_min: -1199.3140624869059
  episodes_this_iter: 1
  episodes_total: 978
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.669
    dispatch_time_ms: 7.446
    learner:
      cur_lr: 0.0010343260364606977
      grad_gnorm: 11.119963645935059
      policy_entropy: 7.171334436861798e-05
      policy_loss: 2.094393636298264e-07
      var_gnorm: 28.228168487548828
      vf_explained_var: 5.960464477539063e-08
      vf_loss: 0.08142239600419998
    num_steps_sampled: 4895000
    num_steps_trained: 4895000
    wait_time_ms: 69.865
  iterations_since_restore: 979
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 8373.368208885193
  time_this_iter_s: 8.125838279724121
  time_total_s: 8373.368208885193
  timestamp: 1594866707
  timesteps_since_restore: 4895000
  timesteps_this_iter: 5000
  timesteps_total: 4895000
  training_iteration: 979
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 21.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 8373 s, 979 iter, 4895000 ts, -457 rew

agent-1: -199.99999999784504
agent-2: 2.96875
agent-3: -99.03124999890878
agent-4: -199.99999999784504
agent-5: -199.99999999784504
Extrinsic Rewards:
0
3
1
0
0
Sum Reward: 4
Avg Reward: 0.8
Min Reward: 0
Max Reward: 3
Gini Coefficient: 0.7
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-31-55
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -457.82378124507073
  episode_reward_min: -1199.3140624869059
  episodes_this_iter: 1
  episodes_total: 979
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.511
    dispatch_time_ms: 6.086
    learner:
      cur_lr: 0.0010339929722249508
      grad_gnorm: 0.7108404040336609
      policy_entropy: 4.54025503131561e-05
      policy_loss: -0.0
      var_gnorm: 28.225305557250977
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 0.0003326965670567006
    num_steps_sampled: 4900000
    num_steps_trained: 4900000
    wait_time_ms: 74.936
  iterations_since_restore: 980
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 8381.551715373993
  time_this_iter_s: 8.183506488800049
  time_total_s: 8381.551715373993
  timestamp: 1594866715
  timesteps_since_restore: 4900000
  timesteps_this_iter: 5000
  timesteps_total: 4900000
  training_iteration: 980
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 21.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 8381 s, 980 iter, 4900000 ts, -458 rew

agent-1: -149.99999999840443
agent-2: -149.99999999840443
agent-3: 3.0
agent-4: -149.99999999840443
agent-5: -149.99999999840443
Extrinsic Rewards:
0
0
3
0
0
Sum Reward: 3
Avg Reward: 0.6
Min Reward: 0
Max Reward: 3
Gini Coefficient: 0.8
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-32-03
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -461.80378124502766
  episode_reward_min: -1199.3140624869059
  episodes_this_iter: 1
  episodes_total: 980
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.56
    dispatch_time_ms: 8.955
    learner:
      cur_lr: 0.0010336600244045258
      grad_gnorm: 0.00046818811097182333
      policy_entropy: 7.179313979577273e-05
      policy_loss: 7.56196667783815e-12
      var_gnorm: 28.22446060180664
      vf_explained_var: 0.0
      vf_loss: 1.2357515011274245e-10
    num_steps_sampled: 4905000
    num_steps_trained: 4905000
    wait_time_ms: 69.036
  iterations_since_restore: 981
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 8389.785161495209
  time_this_iter_s: 8.23344612121582
  time_total_s: 8389.785161495209
  timestamp: 1594866723
  timesteps_since_restore: 4905000
  timesteps_this_iter: 5000
  timesteps_total: 4905000
  training_iteration: 981
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 23.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 8389 s, 981 iter, 4905000 ts, -462 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-32-12
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -461.8037812450277
  episode_reward_min: -1199.3140624869059
  episodes_this_iter: 1
  episodes_total: 981
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.856
    dispatch_time_ms: 6.997
    learner:
      cur_lr: 0.001033326960168779
      grad_gnorm: 2.4559693336486816
      policy_entropy: 8.773641638981644e-06
      policy_loss: -0.0
      var_gnorm: 28.233047485351562
      vf_explained_var: 1.1920928955078125e-07
      vf_loss: 0.003971681464463472
    num_steps_sampled: 4910000
    num_steps_trained: 4910000
    wait_time_ms: 78.645
  iterations_since_restore: 982
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 8397.999476194382
  time_this_iter_s: 8.214314699172974
  time_total_s: 8397.999476194382
  timestamp: 1594866732
  timesteps_since_restore: 4910000
  timesteps_this_iter: 5000
  timesteps_total: 4910000
  training_iteration: 982
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 23.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 8397 s, 982 iter, 4910000 ts, -462 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-32-20
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -449.81064062015867
  episode_reward_min: -1102.4984374877972
  episodes_this_iter: 1
  episodes_total: 982
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 3.301
    dispatch_time_ms: 6.586
    learner:
      cur_lr: 0.0010329940123483539
      grad_gnorm: 10.92115306854248
      policy_entropy: 7.792314136167988e-06
      policy_loss: -0.0
      var_gnorm: 28.233959197998047
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 0.07853925973176956
    num_steps_sampled: 4915000
    num_steps_trained: 4915000
    wait_time_ms: 75.262
  iterations_since_restore: 983
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 8406.265254735947
  time_this_iter_s: 8.265778541564941
  time_total_s: 8406.265254735947
  timestamp: 1594866740
  timesteps_since_restore: 4915000
  timesteps_this_iter: 5000
  timesteps_total: 4915000
  training_iteration: 983
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 23.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 8406 s, 983 iter, 4915000 ts, -450 rew

agent-1: -349.9999999962633
agent-2: -49.31171874944016
agent-3: -349.9999999962633
agent-4: -49.249999999412836
agent-5: 2.93828125
Extrinsic Rewards:
0
2
0
2
3
Sum Reward: 7
Avg Reward: 1.4
Min Reward: 0
Max Reward: 3
Gini Coefficient: 0.45714285714285713
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-32-28
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -448.7868749951692
  episode_reward_min: -1102.4984374877972
  episodes_this_iter: 1
  episodes_total: 983
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.682
    dispatch_time_ms: 8.343
    learner:
      cur_lr: 0.001032660948112607
      grad_gnorm: 0.8894379138946533
      policy_entropy: 8.268953934020828e-06
      policy_loss: -0.0
      var_gnorm: 28.233434677124023
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 0.0005284526268951595
    num_steps_sampled: 4920000
    num_steps_trained: 4920000
    wait_time_ms: 70.166
  iterations_since_restore: 984
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 8414.443178653717
  time_this_iter_s: 8.177923917770386
  time_total_s: 8414.443178653717
  timestamp: 1594866748
  timesteps_since_restore: 4920000
  timesteps_this_iter: 5000
  timesteps_total: 4920000
  training_iteration: 984
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 23.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 8414 s, 984 iter, 4920000 ts, -449 rew

agent-1: -49.99999999946836
agent-2: 1.0
agent-3: -49.99999999946836
agent-4: -49.99999999946836
agent-5: -49.99999999946836
Extrinsic Rewards:
0
1
0
0
0
Sum Reward: 1
Avg Reward: 0.2
Min Reward: 0
Max Reward: 1
Gini Coefficient: 0.8
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-32-36
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -442.8168749952341
  episode_reward_min: -1102.4984374877972
  episodes_this_iter: 1
  episodes_total: 984
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.793
    dispatch_time_ms: 9.176
    learner:
      cur_lr: 0.001032328000292182
      grad_gnorm: 40.0
      policy_entropy: 9.031019544636365e-06
      policy_loss: -0.0
      var_gnorm: 28.233739852905273
      vf_explained_var: 0.0
      vf_loss: 84.79412841796875
    num_steps_sampled: 4925000
    num_steps_trained: 4925000
    wait_time_ms: 70.118
  iterations_since_restore: 985
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 8422.60535979271
  time_this_iter_s: 8.16218113899231
  time_total_s: 8422.60535979271
  timestamp: 1594866756
  timesteps_since_restore: 4925000
  timesteps_this_iter: 5000
  timesteps_total: 4925000
  training_iteration: 985
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 23.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 8422 s, 985 iter, 4925000 ts, -443 rew

agent-1: -249.99999999738205
agent-2: 2.0
agent-3: -249.99999999738205
agent-4: 2.0
agent-5: -98.99999999893677
Extrinsic Rewards:
0
2
0
2
1
Sum Reward: 5
Avg Reward: 1.0
Min Reward: 0
Max Reward: 2
Gini Coefficient: 0.48
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-32-44
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -448.76687499517107
  episode_reward_min: -1102.4984374877972
  episodes_this_iter: 1
  episodes_total: 985
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.666
    dispatch_time_ms: 6.93
    learner:
      cur_lr: 0.001031995052471757
      grad_gnorm: 0.7328895330429077
      policy_entropy: 9.66603693086654e-06
      policy_loss: -0.0
      var_gnorm: 28.233097076416016
      vf_explained_var: 0.0
      vf_loss: 0.00035369276884011924
    num_steps_sampled: 4930000
    num_steps_trained: 4930000
    wait_time_ms: 74.307
  iterations_since_restore: 986
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 8430.72414135933
  time_this_iter_s: 8.118781566619873
  time_total_s: 8430.72414135933
  timestamp: 1594866764
  timesteps_since_restore: 4930000
  timesteps_this_iter: 5000
  timesteps_total: 4930000
  training_iteration: 986
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 23.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 8430 s, 986 iter, 4930000 ts, -449 rew

agent-1: -149.99999999840443
agent-2: 3.0
agent-3: -149.99999999840443
agent-4: -149.99999999840443
agent-5: -149.99999999840443
Extrinsic Rewards:
0
3
0
0
0
Sum Reward: 3
Avg Reward: 0.6
Min Reward: 0
Max Reward: 3
Gini Coefficient: 0.8
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-32-53
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -454.73687499510737
  episode_reward_min: -1102.4984374877972
  episodes_this_iter: 1
  episodes_total: 986
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.703
    dispatch_time_ms: 6.089
    learner:
      cur_lr: 0.00103166198823601
      grad_gnorm: 0.004534879233688116
      policy_entropy: 1.0453868526383303e-05
      policy_loss: -0.0
      var_gnorm: 28.233003616333008
      vf_explained_var: 0.0
      vf_loss: 1.3739231974341237e-08
    num_steps_sampled: 4935000
    num_steps_trained: 4935000
    wait_time_ms: 76.095
  iterations_since_restore: 987
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 8438.942163705826
  time_this_iter_s: 8.218022346496582
  time_total_s: 8438.942163705826
  timestamp: 1594866773
  timesteps_since_restore: 4935000
  timesteps_this_iter: 5000
  timesteps_total: 4935000
  training_iteration: 987
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 23.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 8438 s, 987 iter, 4935000 ts, -455 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-33-01
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -449.7768749951603
  episode_reward_min: -1102.4984374877972
  episodes_this_iter: 1
  episodes_total: 987
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.959
    dispatch_time_ms: 8.874
    learner:
      cur_lr: 0.001031329040415585
      grad_gnorm: 1.1875234842300415
      policy_entropy: 1.1766025636461563e-05
      policy_loss: -0.0
      var_gnorm: 28.232566833496094
      vf_explained_var: 0.0
      vf_loss: 0.0009293465409427881
    num_steps_sampled: 4940000
    num_steps_trained: 4940000
    wait_time_ms: 70.204
  iterations_since_restore: 988
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 8447.14502453804
  time_this_iter_s: 8.202860832214355
  time_total_s: 8447.14502453804
  timestamp: 1594866781
  timesteps_since_restore: 4940000
  timesteps_this_iter: 5000
  timesteps_total: 4940000
  training_iteration: 988
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 24.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 8447 s, 988 iter, 4940000 ts, -450 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-33-09
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -445.7968749952023
  episode_reward_min: -1102.4984374877972
  episodes_this_iter: 1
  episodes_total: 988
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.73
    dispatch_time_ms: 6.683
    learner:
      cur_lr: 0.0010309959761798382
      grad_gnorm: 40.0
      policy_entropy: 1.3914387636759784e-05
      policy_loss: -0.0
      var_gnorm: 28.233142852783203
      vf_explained_var: 1.1920928955078125e-07
      vf_loss: 229.21664428710938
    num_steps_sampled: 4945000
    num_steps_trained: 4945000
    wait_time_ms: 71.861
  iterations_since_restore: 989
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 8455.375530004501
  time_this_iter_s: 8.230505466461182
  time_total_s: 8455.375530004501
  timestamp: 1594866789
  timesteps_since_restore: 4945000
  timesteps_this_iter: 5000
  timesteps_total: 4945000
  training_iteration: 989
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 8455 s, 989 iter, 4945000 ts, -446 rew

agent-1: -49.999999999481645
agent-2: -49.999999999481645
agent-3: 1.0
agent-4: -49.999999999481645
agent-5: -49.999999999481645
Extrinsic Rewards:
0
0
1
0
0
Sum Reward: 1
Avg Reward: 0.2
Min Reward: 0
Max Reward: 1
Gini Coefficient: 0.8
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-33-17
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -440.8268749952568
  episode_reward_min: -1102.4984374877972
  episodes_this_iter: 1
  episodes_total: 989
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.87
    dispatch_time_ms: 9.08
    learner:
      cur_lr: 0.0010306630283594131
      grad_gnorm: 0.13329003751277924
      policy_entropy: 1.5104184967640322e-05
      policy_loss: -0.0
      var_gnorm: 28.230661392211914
      vf_explained_var: 1.7881393432617188e-07
      vf_loss: 1.701551809674129e-05
    num_steps_sampled: 4950000
    num_steps_trained: 4950000
    wait_time_ms: 71.443
  iterations_since_restore: 990
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 8463.539053678513
  time_this_iter_s: 8.16352367401123
  time_total_s: 8463.539053678513
  timestamp: 1594866797
  timesteps_since_restore: 4950000
  timesteps_this_iter: 5000
  timesteps_total: 4950000
  training_iteration: 990
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 8463 s, 990 iter, 4950000 ts, -441 rew

agent-1: -98.999999998923
agent-2: -249.99999999736787
agent-3: -98.999999998923
agent-4: -249.99999999736787
agent-5: 3.0
Extrinsic Rewards:
1
0
1
0
3
Sum Reward: 5
Avg Reward: 1.0
Min Reward: 0
Max Reward: 3
Gini Coefficient: 0.56
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-33-26
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -439.81687499527055
  episode_reward_min: -1102.4984374877972
  episodes_this_iter: 1
  episodes_total: 990
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.405
    dispatch_time_ms: 7.258
    learner:
      cur_lr: 0.0010303299641236663
      grad_gnorm: 0.029998106881976128
      policy_entropy: 1.692162550170906e-05
      policy_loss: -0.0
      var_gnorm: 28.22977066040039
      vf_explained_var: 5.960464477539063e-08
      vf_loss: 5.938472327216004e-07
    num_steps_sampled: 4955000
    num_steps_trained: 4955000
    wait_time_ms: 73.933
  iterations_since_restore: 991
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 8471.67744398117
  time_this_iter_s: 8.138390302658081
  time_total_s: 8471.67744398117
  timestamp: 1594866806
  timesteps_since_restore: 4955000
  timesteps_this_iter: 5000
  timesteps_total: 4955000
  training_iteration: 991
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 8471 s, 991 iter, 4955000 ts, -440 rew

agent-1: -47.99999999945478
agent-2: -249.99999999735493
agent-3: -249.99999999735493
agent-4: -249.99999999735493
agent-5: 3.0
Extrinsic Rewards:
2
0
0
0
3
Sum Reward: 5
Avg Reward: 1.0
Min Reward: 0
Max Reward: 3
Gini Coefficient: 0.64
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-33-34
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -441.7968749952506
  episode_reward_min: -1102.4984374877972
  episodes_this_iter: 1
  episodes_total: 991
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.412
    dispatch_time_ms: 7.493
    learner:
      cur_lr: 0.0010299970163032413
      grad_gnorm: 2.0661637783050537
      policy_entropy: 2.106894680764526e-05
      policy_loss: -0.0
      var_gnorm: 28.229066848754883
      vf_explained_var: 0.0
      vf_loss: 0.002813514554873109
    num_steps_sampled: 4960000
    num_steps_trained: 4960000
    wait_time_ms: 71.266
  iterations_since_restore: 992
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 8479.872334480286
  time_this_iter_s: 8.19489049911499
  time_total_s: 8479.872334480286
  timestamp: 1594866814
  timesteps_since_restore: 4960000
  timesteps_this_iter: 5000
  timesteps_total: 4960000
  training_iteration: 992
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 8479 s, 992 iter, 4960000 ts, -442 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-33-42
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -439.80687499527136
  episode_reward_min: -1102.4984374877972
  episodes_this_iter: 1
  episodes_total: 992
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 3.117
    dispatch_time_ms: 8.495
    learner:
      cur_lr: 0.0010296639520674944
      grad_gnorm: 40.0
      policy_entropy: 2.955041236418765e-05
      policy_loss: -0.0
      var_gnorm: 28.229257583618164
      vf_explained_var: 0.0
      vf_loss: 206.02926635742188
    num_steps_sampled: 4965000
    num_steps_trained: 4965000
    wait_time_ms: 71.678
  iterations_since_restore: 993
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 8488.077562570572
  time_this_iter_s: 8.205228090286255
  time_total_s: 8488.077562570572
  timestamp: 1594866822
  timesteps_since_restore: 4965000
  timesteps_this_iter: 5000
  timesteps_total: 4965000
  training_iteration: 993
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 8488 s, 993 iter, 4965000 ts, -440 rew

agent-1: -299.9999999967948
agent-2: -299.9999999967948
agent-3: 4.0
agent-4: -97.9999999988953
agent-5: -299.9999999967948
Extrinsic Rewards:
0
0
4
2
0
Sum Reward: 6
Avg Reward: 1.2
Min Reward: 0
Max Reward: 4
Gini Coefficient: 0.6666666666666666
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-33-50
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -438.7674999952841
  episode_reward_min: -1102.4984374877972
  episodes_this_iter: 1
  episodes_total: 993
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.826
    dispatch_time_ms: 9.38
    learner:
      cur_lr: 0.0010293310042470694
      grad_gnorm: 0.06262917071580887
      policy_entropy: 1.5213208826025948e-05
      policy_loss: -0.0
      var_gnorm: 28.240896224975586
      vf_explained_var: 2.384185791015625e-07
      vf_loss: 4.136499683227157e-06
    num_steps_sampled: 4970000
    num_steps_trained: 4970000
    wait_time_ms: 69.483
  iterations_since_restore: 994
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 8496.262069225311
  time_this_iter_s: 8.18450665473938
  time_total_s: 8496.262069225311
  timestamp: 1594866830
  timesteps_since_restore: 4970000
  timesteps_this_iter: 5000
  timesteps_total: 4970000
  training_iteration: 994
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 8496 s, 994 iter, 4970000 ts, -439 rew

agent-1: -199.99999999788645
agent-2: -199.99999999788645
agent-3: -98.999999998923
agent-4: -199.99999999788645
agent-5: 3.0
Extrinsic Rewards:
0
0
1
0
3
Sum Reward: 4
Avg Reward: 0.8
Min Reward: 0
Max Reward: 3
Gini Coefficient: 0.7
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-33-59
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -434.70251562033184
  episode_reward_min: -1092.9999999881866
  episodes_this_iter: 1
  episodes_total: 994
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.721
    dispatch_time_ms: 8.654
    learner:
      cur_lr: 0.0010289980564266443
      grad_gnorm: 40.0
      policy_entropy: 1.904560485854745e-05
      policy_loss: -0.0
      var_gnorm: 28.2413387298584
      vf_explained_var: 0.0
      vf_loss: 1174.4876708984375
    num_steps_sampled: 4975000
    num_steps_trained: 4975000
    wait_time_ms: 71.665
  iterations_since_restore: 995
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 8504.451561689377
  time_this_iter_s: 8.189492464065552
  time_total_s: 8504.451561689377
  timestamp: 1594866839
  timesteps_since_restore: 4975000
  timesteps_this_iter: 5000
  timesteps_total: 4975000
  training_iteration: 995
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 8504 s, 995 iter, 4975000 ts, -435 rew

agent-1: -149.99999999840443
agent-2: -149.99999999840443
agent-3: -149.99999999840443
agent-4: -149.99999999840443
agent-5: 3.0
Extrinsic Rewards:
0
0
0
0
3
Sum Reward: 3
Avg Reward: 0.6
Min Reward: 0
Max Reward: 3
Gini Coefficient: 0.8
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-34-07
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -433.71251562034223
  episode_reward_min: -1092.9999999881866
  episodes_this_iter: 1
  episodes_total: 995
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.496
    dispatch_time_ms: 7.854
    learner:
      cur_lr: 0.0010286649921908975
      grad_gnorm: 1.2146282196044922
      policy_entropy: 2.2403353796107695e-05
      policy_loss: -0.0
      var_gnorm: 28.237211227416992
      vf_explained_var: 0.0
      vf_loss: 0.0009715519263409078
    num_steps_sampled: 4980000
    num_steps_trained: 4980000
    wait_time_ms: 75.074
  iterations_since_restore: 996
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 8512.66715145111
  time_this_iter_s: 8.215589761734009
  time_total_s: 8512.66715145111
  timestamp: 1594866847
  timesteps_since_restore: 4980000
  timesteps_this_iter: 5000
  timesteps_total: 4980000
  training_iteration: 996
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 8512 s, 996 iter, 4980000 ts, -434 rew

agent-1: -449.99999999520065
agent-2: -449.99999999520065
agent-3: 4.0
agent-4: -46.99999999944068
agent-5: -147.9999999983504
Extrinsic Rewards:
0
0
4
3
2
Sum Reward: 9
Avg Reward: 1.8
Min Reward: 0
Max Reward: 4
Gini Coefficient: 0.4888888888888889
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-34-15
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -436.67251562030907
  episode_reward_min: -1092.9999999881866
  episodes_this_iter: 1
  episodes_total: 996
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.904
    dispatch_time_ms: 9.211
    learner:
      cur_lr: 0.0010283320443704724
      grad_gnorm: 6.577185153961182
      policy_entropy: 3.749175084521994e-05
      policy_loss: -0.0
      var_gnorm: 28.238710403442383
      vf_explained_var: 0.0
      vf_loss: 0.028485601767897606
    num_steps_sampled: 4985000
    num_steps_trained: 4985000
    wait_time_ms: 68.965
  iterations_since_restore: 997
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 8520.823293209076
  time_this_iter_s: 8.156141757965088
  time_total_s: 8520.823293209076
  timestamp: 1594866855
  timesteps_since_restore: 4985000
  timesteps_this_iter: 5000
  timesteps_total: 4985000
  training_iteration: 997
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 8520 s, 997 iter, 4985000 ts, -437 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-34-23
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -434.6825156203303
  episode_reward_min: -1092.9999999881866
  episodes_this_iter: 1
  episodes_total: 997
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 3.099
    dispatch_time_ms: 10.294
    learner:
      cur_lr: 0.0010279989801347256
      grad_gnorm: 1.8907678127288818
      policy_entropy: 2.131316477971268e-06
      policy_loss: -0.0
      var_gnorm: 28.25487518310547
      vf_explained_var: 0.0
      vf_loss: 0.002354194177314639
    num_steps_sampled: 4990000
    num_steps_trained: 4990000
    wait_time_ms: 69.435
  iterations_since_restore: 998
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 8529.025291442871
  time_this_iter_s: 8.201998233795166
  time_total_s: 8529.025291442871
  timestamp: 1594866863
  timesteps_since_restore: 4990000
  timesteps_this_iter: 5000
  timesteps_total: 4990000
  training_iteration: 998
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 8529 s, 998 iter, 4990000 ts, -435 rew

agent-1: -349.99999999625004
agent-2: -349.99999999625004
agent-3: -46.99999999944068
agent-4: -349.99999999625004
agent-5: 4.0
Extrinsic Rewards:
0
0
3
0
4
Sum Reward: 7
Avg Reward: 1.4
Min Reward: 0
Max Reward: 4
Gini Coefficient: 0.6285714285714286
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-34-33
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -440.64251562026453
  episode_reward_min: -1092.9999999881868
  episodes_this_iter: 1
  episodes_total: 998
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.701
    dispatch_time_ms: 6.336
    learner:
      cur_lr: 0.0010276660323143005
      grad_gnorm: 6.916773796081543
      policy_entropy: 2.1608818769891514e-06
      policy_loss: -0.0
      var_gnorm: 28.255338668823242
      vf_explained_var: 0.0
      vf_loss: 0.0315033383667469
    num_steps_sampled: 4995000
    num_steps_trained: 4995000
    wait_time_ms: 71.036
  iterations_since_restore: 999
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 8538.907891750336
  time_this_iter_s: 9.8826003074646
  time_total_s: 8538.907891750336
  timestamp: 1594866873
  timesteps_since_restore: 4995000
  timesteps_this_iter: 5000
  timesteps_total: 4995000
  training_iteration: 999
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 8538 s, 999 iter, 4995000 ts, -441 rew

agent-1: -49.999999999481645
agent-2: -49.999999999481645
agent-3: -49.999999999481645
agent-4: 1.0
agent-5: -49.999999999481645
Extrinsic Rewards:
0
0
0
1
0
Sum Reward: 1
Avg Reward: 0.2
Min Reward: 0
Max Reward: 1
Gini Coefficient: 0.8
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-34-41
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -435.6725156203191
  episode_reward_min: -1092.9999999881868
  episodes_this_iter: 1
  episodes_total: 999
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.89
    dispatch_time_ms: 8.677
    learner:
      cur_lr: 0.0010273329680785537
      grad_gnorm: 0.8501179218292236
      policy_entropy: 2.2348340280586854e-06
      policy_loss: -0.0
      var_gnorm: 28.255311965942383
      vf_explained_var: 0.0
      vf_loss: 0.0004758124123327434
    num_steps_sampled: 5000000
    num_steps_trained: 5000000
    wait_time_ms: 72.078
  iterations_since_restore: 1000
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 8547.06995177269
  time_this_iter_s: 8.162060022354126
  time_total_s: 8547.06995177269
  timestamp: 1594866881
  timesteps_since_restore: 5000000
  timesteps_this_iter: 5000
  timesteps_total: 5000000
  training_iteration: 1000
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 8547 s, 1000 iter, 5000000 ts, -436 rew

agent-1: -149.99999999841847
agent-2: -48.99999999948169
agent-3: 2.0
agent-4: -149.99999999841847
agent-5: -149.99999999841847
Extrinsic Rewards:
0
1
2
0
0
Sum Reward: 3
Avg Reward: 0.6
Min Reward: 0
Max Reward: 2
Gini Coefficient: 0.6666666666666666
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-34-50
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -436.6625156203084
  episode_reward_min: -1092.9999999881868
  episodes_this_iter: 1
  episodes_total: 1000
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.685
    dispatch_time_ms: 6.353
    learner:
      cur_lr: 0.0010270000202581286
      grad_gnorm: 0.003003254998475313
      policy_entropy: 2.2930919385544257e-06
      policy_loss: -0.0
      var_gnorm: 28.2554874420166
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 5.982428774586879e-09
    num_steps_sampled: 5005000
    num_steps_trained: 5005000
    wait_time_ms: 72.55
  iterations_since_restore: 1001
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 8555.294404506683
  time_this_iter_s: 8.22445273399353
  time_total_s: 8555.294404506683
  timestamp: 1594866890
  timesteps_since_restore: 5005000
  timesteps_this_iter: 5000
  timesteps_total: 5005000
  training_iteration: 1001
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 23.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 8555 s, 1001 iter, 5005000 ts, -437 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-34-58
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -431.69251562036084
  episode_reward_min: -1092.9999999881868
  episodes_this_iter: 1
  episodes_total: 1001
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.55
    dispatch_time_ms: 8.025
    learner:
      cur_lr: 0.0010266669560223818
      grad_gnorm: 1.6617259979248047
      policy_entropy: 2.3879499622125877e-06
      policy_loss: -0.0
      var_gnorm: 28.255699157714844
      vf_explained_var: 0.0
      vf_loss: 0.0018181934719905257
    num_steps_sampled: 5010000
    num_steps_trained: 5010000
    wait_time_ms: 74.755
  iterations_since_restore: 1002
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 8563.458149909973
  time_this_iter_s: 8.163745403289795
  time_total_s: 8563.458149909973
  timestamp: 1594866898
  timesteps_since_restore: 5010000
  timesteps_this_iter: 5000
  timesteps_total: 5010000
  training_iteration: 1002
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 8563 s, 1002 iter, 5010000 ts, -432 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-35-06
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -431.6925156203608
  episode_reward_min: -1092.9999999881868
  episodes_this_iter: 1
  episodes_total: 1002
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.651
    dispatch_time_ms: 6.145
    learner:
      cur_lr: 0.0010263340082019567
      grad_gnorm: 40.0
      policy_entropy: 2.5114486561506055e-06
      policy_loss: -0.0
      var_gnorm: 28.25627326965332
      vf_explained_var: 0.0
      vf_loss: 142.8195037841797
    num_steps_sampled: 5015000
    num_steps_trained: 5015000
    wait_time_ms: 75.046
  iterations_since_restore: 1003
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 8571.649846076965
  time_this_iter_s: 8.191696166992188
  time_total_s: 8571.649846076965
  timestamp: 1594866906
  timesteps_since_restore: 5015000
  timesteps_this_iter: 5000
  timesteps_total: 5015000
  training_iteration: 1003
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 8571 s, 1003 iter, 5015000 ts, -432 rew

agent-1: -98.99999999886708
agent-2: -199.99999999780408
agent-3: -199.99999999780408
agent-4: -199.99999999780408
agent-5: 3.0
Extrinsic Rewards:
1
0
0
0
3
Sum Reward: 4
Avg Reward: 0.8
Min Reward: 0
Max Reward: 3
Gini Coefficient: 0.7
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-35-14
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -438.6525156202837
  episode_reward_min: -1092.9999999881868
  episodes_this_iter: 1
  episodes_total: 1003
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 3.154
    dispatch_time_ms: 8.811
    learner:
      cur_lr: 0.0010260009439662099
      grad_gnorm: 1.6133495569229126
      policy_entropy: 2.612011940072989e-06
      policy_loss: -0.0
      var_gnorm: 28.256080627441406
      vf_explained_var: 0.0
      vf_loss: 0.0017147798789665103
    num_steps_sampled: 5020000
    num_steps_trained: 5020000
    wait_time_ms: 69.727
  iterations_since_restore: 1004
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 8579.880138635635
  time_this_iter_s: 8.230292558670044
  time_total_s: 8579.880138635635
  timestamp: 1594866914
  timesteps_since_restore: 5020000
  timesteps_this_iter: 5000
  timesteps_total: 5020000
  training_iteration: 1004
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 8579 s, 1004 iter, 5020000 ts, -439 rew

agent-1: -149.99999999840443
agent-2: -149.99999999840443
agent-3: -149.99999999840443
agent-4: -149.99999999840443
agent-5: 3.0
Extrinsic Rewards:
0
0
0
0
3
Sum Reward: 3
Avg Reward: 0.6
Min Reward: 0
Max Reward: 3
Gini Coefficient: 0.8
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-35-22
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -444.62251562021993
  episode_reward_min: -1092.9999999881868
  episodes_this_iter: 1
  episodes_total: 1004
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 3.173
    dispatch_time_ms: 6.895
    learner:
      cur_lr: 0.0010256679961457849
      grad_gnorm: 7.739348888397217
      policy_entropy: 2.7606306503002997e-06
      policy_loss: -0.0
      var_gnorm: 28.2565860748291
      vf_explained_var: 0.0
      vf_loss: 0.03944162279367447
    num_steps_sampled: 5025000
    num_steps_trained: 5025000
    wait_time_ms: 71.886
  iterations_since_restore: 1005
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 8588.031158447266
  time_this_iter_s: 8.151019811630249
  time_total_s: 8588.031158447266
  timestamp: 1594866922
  timesteps_since_restore: 5025000
  timesteps_this_iter: 5000
  timesteps_total: 5025000
  training_iteration: 1005
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 8588 s, 1005 iter, 5025000 ts, -445 rew

agent-1: -249.9999999972851
agent-2: -148.99999999832153
agent-3: -249.9999999972851
agent-4: -249.9999999972851
agent-5: 4.0
Extrinsic Rewards:
0
1
0
0
4
Sum Reward: 5
Avg Reward: 1.0
Min Reward: 0
Max Reward: 4
Gini Coefficient: 0.72
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-35-31
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -453.5725156201217
  episode_reward_min: -1092.9999999881868
  episodes_this_iter: 1
  episodes_total: 1005
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.473
    dispatch_time_ms: 8.215
    learner:
      cur_lr: 0.0010253350483253598
      grad_gnorm: 0.5230796933174133
      policy_entropy: 2.907737325585913e-06
      policy_loss: -0.0
      var_gnorm: 28.25651741027832
      vf_explained_var: 5.960464477539063e-08
      vf_loss: 0.00018221508071292192
    num_steps_sampled: 5030000
    num_steps_trained: 5030000
    wait_time_ms: 70.936
  iterations_since_restore: 1006
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 8596.230772733688
  time_this_iter_s: 8.19961428642273
  time_total_s: 8596.230772733688
  timestamp: 1594866931
  timesteps_since_restore: 5030000
  timesteps_this_iter: 5000
  timesteps_total: 5030000
  training_iteration: 1006
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 8596 s, 1006 iter, 5030000 ts, -454 rew

agent-1: -99.99999999894987
agent-2: 2.0
agent-3: -99.99999999894987
agent-4: -99.99999999894987
agent-5: -99.99999999894987
Extrinsic Rewards:
0
2
0
0
0
Sum Reward: 2
Avg Reward: 0.4
Min Reward: 0
Max Reward: 2
Gini Coefficient: 0.8
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-35-39
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -448.6025156201765
  episode_reward_min: -1092.9999999881868
  episodes_this_iter: 1
  episodes_total: 1006
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.862
    dispatch_time_ms: 9.571
    learner:
      cur_lr: 0.001025001984089613
      grad_gnorm: 40.0
      policy_entropy: 3.109054205197026e-06
      policy_loss: -0.0
      var_gnorm: 28.2571964263916
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 194.38973999023438
    num_steps_sampled: 5035000
    num_steps_trained: 5035000
    wait_time_ms: 69.006
  iterations_since_restore: 1007
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 8604.36201453209
  time_this_iter_s: 8.131241798400879
  time_total_s: 8604.36201453209
  timestamp: 1594866939
  timesteps_since_restore: 5035000
  timesteps_this_iter: 5000
  timesteps_total: 5035000
  training_iteration: 1007
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 8604 s, 1007 iter, 5035000 ts, -449 rew

agent-1: 0.7500000000136119
agent-2: -199.99999999788645
agent-3: 0.75
agent-4: -199.99999999788645
agent-5: -199.99999999788645
Extrinsic Rewards:
2
0
2
0
0
Sum Reward: 4
Avg Reward: 0.8
Min Reward: 0
Max Reward: 2
Gini Coefficient: 0.6
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-35-47
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -454.587515620113
  episode_reward_min: -1092.9999999881868
  episodes_this_iter: 1
  episodes_total: 1007
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.42
    dispatch_time_ms: 7.078
    learner:
      cur_lr: 0.001024669036269188
      grad_gnorm: 1.3406106233596802
      policy_entropy: 3.321290478197625e-06
      policy_loss: -0.0
      var_gnorm: 28.257333755493164
      vf_explained_var: 0.0
      vf_loss: 0.001185741275548935
    num_steps_sampled: 5040000
    num_steps_trained: 5040000
    wait_time_ms: 72.935
  iterations_since_restore: 1008
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 8612.562499761581
  time_this_iter_s: 8.200485229492188
  time_total_s: 8612.562499761581
  timestamp: 1594866947
  timesteps_since_restore: 5040000
  timesteps_this_iter: 5000
  timesteps_total: 5040000
  training_iteration: 1008
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 8612 s, 1008 iter, 5040000 ts, -455 rew

agent-1: -0.2499999999867109
agent-2: -0.2499999999867109
agent-3: -1.5
agent-4: -149.9999999984318
agent-5: -149.9999999984318
Extrinsic Rewards:
1
1
1
0
0
Sum Reward: 3
Avg Reward: 0.6
Min Reward: 0
Max Reward: 1
Gini Coefficient: 0.4
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-35-55
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -446.6775156201995
  episode_reward_min: -1092.9999999881868
  episodes_this_iter: 1
  episodes_total: 1008
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.669
    dispatch_time_ms: 8.001
    learner:
      cur_lr: 0.001024335972033441
      grad_gnorm: 40.0
      policy_entropy: 3.5798789213004056e-06
      policy_loss: -0.0
      var_gnorm: 28.258020401000977
      vf_explained_var: 0.0
      vf_loss: 289.5147399902344
    num_steps_sampled: 5045000
    num_steps_trained: 5045000
    wait_time_ms: 74.555
  iterations_since_restore: 1009
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 8620.687109470367
  time_this_iter_s: 8.12460970878601
  time_total_s: 8620.687109470367
  timestamp: 1594866955
  timesteps_since_restore: 5045000
  timesteps_this_iter: 5000
  timesteps_total: 5045000
  training_iteration: 1009
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 8620 s, 1009 iter, 5045000 ts, -447 rew

agent-1: -349.9999999962501
agent-2: -199.03124999784518
agent-3: 0.5
agent-4: -349.9999999962501
agent-5: 0.5312500000275931
Extrinsic Rewards:
0
1
3
0
3
Sum Reward: 7
Avg Reward: 1.4
Min Reward: 0
Max Reward: 3
Gini Coefficient: 0.5142857142857142
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-36-04
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -455.65751562010263
  episode_reward_min: -1092.9999999881868
  episodes_this_iter: 1
  episodes_total: 1009
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.47
    dispatch_time_ms: 9.149
    learner:
      cur_lr: 0.001024003024213016
      grad_gnorm: 0.08815784752368927
      policy_entropy: 3.8661396501993295e-06
      policy_loss: -0.0
      var_gnorm: 28.257999420166016
      vf_explained_var: -2.384185791015625e-07
      vf_loss: 6.1122577790229116e-06
    num_steps_sampled: 5050000
    num_steps_trained: 5050000
    wait_time_ms: 70.123
  iterations_since_restore: 1010
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 8628.868062019348
  time_this_iter_s: 8.180952548980713
  time_total_s: 8628.868062019348
  timestamp: 1594866964
  timesteps_since_restore: 5050000
  timesteps_this_iter: 5000
  timesteps_total: 5050000
  training_iteration: 1010
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 8628 s, 1010 iter, 5050000 ts, -456 rew

agent-1: -99.99999999894987
agent-2: -99.99999999894987
agent-3: 2.0
agent-4: -99.99999999894987
agent-5: -99.99999999894987
Extrinsic Rewards:
0
0
2
0
0
Sum Reward: 2
Avg Reward: 0.4
Min Reward: 0
Max Reward: 2
Gini Coefficient: 0.8
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-36-12
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -453.6525156201242
  episode_reward_min: -1092.9999999881868
  episodes_this_iter: 1
  episodes_total: 1010
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 3.495
    dispatch_time_ms: 48.747
    learner:
      cur_lr: 0.0010236699599772692
      grad_gnorm: 0.011538569815456867
      policy_entropy: 4.137672931392444e-06
      policy_loss: -0.0
      var_gnorm: 28.2584228515625
      vf_explained_var: 0.0
      vf_loss: 1.6688800030806306e-07
    num_steps_sampled: 5055000
    num_steps_trained: 5055000
    wait_time_ms: 40.224
  iterations_since_restore: 1011
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 8637.619050264359
  time_this_iter_s: 8.750988245010376
  time_total_s: 8637.619050264359
  timestamp: 1594866972
  timesteps_since_restore: 5055000
  timesteps_this_iter: 5000
  timesteps_total: 5055000
  training_iteration: 1011
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 8637 s, 1011 iter, 5055000 ts, -454 rew

agent-1: -199.99999999788645
agent-2: -199.99999999788645
agent-3: 0.75
agent-4: 0.7500000000136119
agent-5: -199.99999999788645
Extrinsic Rewards:
0
0
2
2
0
Sum Reward: 4
Avg Reward: 0.8
Min Reward: 0
Max Reward: 2
Gini Coefficient: 0.6
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-36-21
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -451.6775156201467
  episode_reward_min: -1092.9999999881868
  episodes_this_iter: 1
  episodes_total: 1011
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.604
    dispatch_time_ms: 8.311
    learner:
      cur_lr: 0.0010233370121568441
      grad_gnorm: 0.00017536725499667227
      policy_entropy: 4.491496838454623e-06
      policy_loss: -0.0
      var_gnorm: 28.25911521911621
      vf_explained_var: 0.0
      vf_loss: 1.6094993393611645e-11
    num_steps_sampled: 5060000
    num_steps_trained: 5060000
    wait_time_ms: 71.73
  iterations_since_restore: 1012
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 8646.120577096939
  time_this_iter_s: 8.501526832580566
  time_total_s: 8646.120577096939
  timestamp: 1594866981
  timesteps_since_restore: 5060000
  timesteps_this_iter: 5000
  timesteps_total: 5060000
  training_iteration: 1012
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 8646 s, 1012 iter, 5060000 ts, -452 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-36-29
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -444.7175156202209
  episode_reward_min: -1092.9999999881868
  episodes_this_iter: 1
  episodes_total: 1012
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.85
    dispatch_time_ms: 8.354
    learner:
      cur_lr: 0.0010230039479210973
      grad_gnorm: 40.000003814697266
      policy_entropy: 5.086862529424252e-06
      policy_loss: -0.0
      var_gnorm: 28.260725021362305
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 2446.314453125
    num_steps_sampled: 5065000
    num_steps_trained: 5065000
    wait_time_ms: 71.601
  iterations_since_restore: 1013
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 8654.334361076355
  time_this_iter_s: 8.213783979415894
  time_total_s: 8654.334361076355
  timestamp: 1594866989
  timesteps_since_restore: 5065000
  timesteps_this_iter: 5000
  timesteps_total: 5065000
  training_iteration: 1013
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 8654 s, 1013 iter, 5065000 ts, -445 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-36-37
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -436.75251562030695
  episode_reward_min: -1092.9999999881868
  episodes_this_iter: 1
  episodes_total: 1013
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 3.047
    dispatch_time_ms: 8.749
    learner:
      cur_lr: 0.0010226710001006722
      grad_gnorm: 1.9676392078399658
      policy_entropy: 5.516823875950649e-06
      policy_loss: -0.0
      var_gnorm: 28.25832748413086
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 0.0025493863504379988
    num_steps_sampled: 5070000
    num_steps_trained: 5070000
    wait_time_ms: 69.311
  iterations_since_restore: 1014
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 8662.596943378448
  time_this_iter_s: 8.262582302093506
  time_total_s: 8662.596943378448
  timestamp: 1594866997
  timesteps_since_restore: 5070000
  timesteps_this_iter: 5000
  timesteps_total: 5070000
  training_iteration: 1014
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 8662 s, 1014 iter, 5070000 ts, -437 rew

agent-1: -199.99999999788645
agent-2: -199.99999999788645
agent-3: -199.99999999788645
agent-4: 0.7500000000136119
agent-5: 0.75
Extrinsic Rewards:
0
0
0
2
2
Sum Reward: 4
Avg Reward: 0.8
Min Reward: 0
Max Reward: 2
Gini Coefficient: 0.6
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-36-46
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -432.7199999953532
  episode_reward_min: -1092.9999999881868
  episodes_this_iter: 1
  episodes_total: 1014
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.777
    dispatch_time_ms: 7.667
    learner:
      cur_lr: 0.0010223380522802472
      grad_gnorm: 40.000003814697266
      policy_entropy: 6.418110842787428e-06
      policy_loss: -0.0
      var_gnorm: 28.259727478027344
      vf_explained_var: 5.960464477539063e-08
      vf_loss: 3085.606689453125
    num_steps_sampled: 5075000
    num_steps_trained: 5075000
    wait_time_ms: 73.948
  iterations_since_restore: 1015
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 8670.716495275497
  time_this_iter_s: 8.11955189704895
  time_total_s: 8670.716495275497
  timestamp: 1594867006
  timesteps_since_restore: 5075000
  timesteps_this_iter: 5000
  timesteps_total: 5075000
  training_iteration: 1015
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 8670 s, 1015 iter, 5075000 ts, -433 rew

agent-1: -149.9999999984318
agent-2: -149.9999999984318
agent-3: -149.9999999984318
agent-4: 2.0
agent-5: -48.9999999994684
Extrinsic Rewards:
0
0
0
2
1
Sum Reward: 3
Avg Reward: 0.6
Min Reward: 0
Max Reward: 2
Gini Coefficient: 0.6666666666666666
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-36-54
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -429.7399999953856
  episode_reward_min: -1092.9999999881868
  episodes_this_iter: 1
  episodes_total: 1015
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 3.257
    dispatch_time_ms: 7.876
    learner:
      cur_lr: 0.0010220049880445004
      grad_gnorm: 1.2298892736434937
      policy_entropy: 7.953828571771737e-06
      policy_loss: -0.0
      var_gnorm: 28.260183334350586
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 0.0009960830211639404
    num_steps_sampled: 5080000
    num_steps_trained: 5080000
    wait_time_ms: 70.918
  iterations_since_restore: 1016
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 8678.967812299728
  time_this_iter_s: 8.251317024230957
  time_total_s: 8678.967812299728
  timestamp: 1594867014
  timesteps_since_restore: 5080000
  timesteps_this_iter: 5000
  timesteps_total: 5080000
  training_iteration: 1016
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 8678 s, 1016 iter, 5080000 ts, -430 rew

agent-1: -149.99999999840443
agent-2: -149.99999999840443
agent-3: 3.0
agent-4: -149.99999999840443
agent-5: -149.99999999840443
Extrinsic Rewards:
0
0
3
0
0
Sum Reward: 3
Avg Reward: 0.6
Min Reward: 0
Max Reward: 3
Gini Coefficient: 0.8
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-37-02
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -424.7799999954401
  episode_reward_min: -1092.9999999881868
  episodes_this_iter: 1
  episodes_total: 1016
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 4.817
    dispatch_time_ms: 8.81
    learner:
      cur_lr: 0.0010216720402240753
      grad_gnorm: 0.4283803403377533
      policy_entropy: 1.026707195705967e-05
      policy_loss: -0.0
      var_gnorm: 28.263553619384766
      vf_explained_var: 1.1920928955078125e-07
      vf_loss: 0.00012081956083420664
    num_steps_sampled: 5085000
    num_steps_trained: 5085000
    wait_time_ms: 68.818
  iterations_since_restore: 1017
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 8687.120921611786
  time_this_iter_s: 8.153109312057495
  time_total_s: 8687.120921611786
  timestamp: 1594867022
  timesteps_since_restore: 5085000
  timesteps_this_iter: 5000
  timesteps_total: 5085000
  training_iteration: 1017
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 8687 s, 1017 iter, 5085000 ts, -425 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-37-10
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -424.7799999954401
  episode_reward_min: -1092.9999999881868
  episodes_this_iter: 1
  episodes_total: 1017
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.577
    dispatch_time_ms: 9.074
    learner:
      cur_lr: 0.0010213389759883285
      grad_gnorm: 1.752182960510254
      policy_entropy: 2.985572336910991e-06
      policy_loss: -0.0
      var_gnorm: 28.304210662841797
      vf_explained_var: 0.0
      vf_loss: 0.0020219061989337206
    num_steps_sampled: 5090000
    num_steps_trained: 5090000
    wait_time_ms: 71.983
  iterations_since_restore: 1018
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 8695.31664276123
  time_this_iter_s: 8.19572114944458
  time_total_s: 8695.31664276123
  timestamp: 1594867030
  timesteps_since_restore: 5090000
  timesteps_this_iter: 5000
  timesteps_total: 5090000
  training_iteration: 1018
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 8695 s, 1018 iter, 5090000 ts, -425 rew

agent-1: -99.03124999890878
agent-2: 2.96875
agent-3: -199.99999999784504
agent-4: -199.99999999784504
agent-5: -199.99999999784504
Extrinsic Rewards:
1
3
0
0
0
Sum Reward: 4
Avg Reward: 0.8
Min Reward: 0
Max Reward: 3
Gini Coefficient: 0.7
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-37-19
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -431.74062499536456
  episode_reward_min: -1092.9999999881868
  episodes_this_iter: 1
  episodes_total: 1018
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.658
    dispatch_time_ms: 7.346
    learner:
      cur_lr: 0.0010210060281679034
      grad_gnorm: 40.0
      policy_entropy: 3.227981778763933e-06
      policy_loss: -0.0
      var_gnorm: 28.303836822509766
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 5629.2607421875
    num_steps_sampled: 5095000
    num_steps_trained: 5095000
    wait_time_ms: 71.714
  iterations_since_restore: 1019
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 8703.588444709778
  time_this_iter_s: 8.271801948547363
  time_total_s: 8703.588444709778
  timestamp: 1594867039
  timesteps_since_restore: 5095000
  timesteps_this_iter: 5000
  timesteps_total: 5095000
  training_iteration: 1019
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 8703 s, 1019 iter, 5095000 ts, -432 rew

agent-1: -149.99999999840443
agent-2: 3.0
agent-3: -149.99999999840443
agent-4: -149.99999999840443
agent-5: -149.99999999840443
Extrinsic Rewards:
0
3
0
0
0
Sum Reward: 3
Avg Reward: 0.6
Min Reward: 0
Max Reward: 3
Gini Coefficient: 0.8
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-37-27
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -433.73062499534285
  episode_reward_min: -1092.9999999881868
  episodes_this_iter: 1
  episodes_total: 1019
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.775
    dispatch_time_ms: 6.4
    learner:
      cur_lr: 0.0010206729639321566
      grad_gnorm: 1.1246726512908936
      policy_entropy: 3.54653934664384e-06
      policy_loss: -0.0
      var_gnorm: 28.302322387695312
      vf_explained_var: 0.0
      vf_loss: 0.0008330693235620856
    num_steps_sampled: 5100000
    num_steps_trained: 5100000
    wait_time_ms: 72.968
  iterations_since_restore: 1020
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 8711.767278909683
  time_this_iter_s: 8.178834199905396
  time_total_s: 8711.767278909683
  timestamp: 1594867047
  timesteps_since_restore: 5100000
  timesteps_this_iter: 5000
  timesteps_total: 5100000
  training_iteration: 1020
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 8711 s, 1020 iter, 5100000 ts, -434 rew

agent-1: -199.99999999784504
agent-2: -199.99999999784504
agent-3: -199.99999999784504
agent-4: 4.0
agent-5: -199.99999999784504
Extrinsic Rewards:
0
0
0
4
0
Sum Reward: 4
Avg Reward: 0.8
Min Reward: 0
Max Reward: 4
Gini Coefficient: 0.8
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-37-35
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -434.73062499533114
  episode_reward_min: -1092.9999999881868
  episodes_this_iter: 1
  episodes_total: 1020
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 3.332
    dispatch_time_ms: 7.636
    learner:
      cur_lr: 0.0010203400161117315
      grad_gnorm: 0.003879514057189226
      policy_entropy: 3.878408733726246e-06
      policy_loss: -0.0
      var_gnorm: 28.301904678344727
      vf_explained_var: 0.0
      vf_loss: 1.0079983958632965e-08
    num_steps_sampled: 5105000
    num_steps_trained: 5105000
    wait_time_ms: 71.501
  iterations_since_restore: 1021
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 8719.955679416656
  time_this_iter_s: 8.188400506973267
  time_total_s: 8719.955679416656
  timestamp: 1594867055
  timesteps_since_restore: 5105000
  timesteps_this_iter: 5000
  timesteps_total: 5105000
  training_iteration: 1021
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 8719 s, 1021 iter, 5105000 ts, -435 rew

agent-1: -149.99999999837684
agent-2: -149.99999999837684
agent-3: -149.99999999837684
agent-4: 3.0
agent-5: -149.99999999837684
Extrinsic Rewards:
0
0
0
3
0
Sum Reward: 3
Avg Reward: 0.6
Min Reward: 0
Max Reward: 3
Gini Coefficient: 0.8
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-37-43
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -436.7206249953083
  episode_reward_min: -1092.9999999881868
  episodes_this_iter: 1
  episodes_total: 1021
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.538
    dispatch_time_ms: 5.455
    learner:
      cur_lr: 0.0010200069518759847
      grad_gnorm: 1.970505945791956e-05
      policy_entropy: 4.336285655881511e-06
      policy_loss: -0.0
      var_gnorm: 28.301523208618164
      vf_explained_var: 0.0
      vf_loss: 2.7630278707363454e-12
    num_steps_sampled: 5110000
    num_steps_trained: 5110000
    wait_time_ms: 76.01
  iterations_since_restore: 1022
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 8728.12617945671
  time_this_iter_s: 8.170500040054321
  time_total_s: 8728.12617945671
  timestamp: 1594867063
  timesteps_since_restore: 5110000
  timesteps_this_iter: 5000
  timesteps_total: 5110000
  training_iteration: 1022
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 8728 s, 1022 iter, 5110000 ts, -437 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-37-51
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -436.7206249953083
  episode_reward_min: -1092.9999999881868
  episodes_this_iter: 1
  episodes_total: 1022
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.709
    dispatch_time_ms: 8.289
    learner:
      cur_lr: 0.0010196740040555596
      grad_gnorm: 0.0007381171453744173
      policy_entropy: 4.9342938837071415e-06
      policy_loss: -0.0
      var_gnorm: 28.301090240478516
      vf_explained_var: 0.0
      vf_loss: 3.305080376048153e-10
    num_steps_sampled: 5115000
    num_steps_trained: 5115000
    wait_time_ms: 68.602
  iterations_since_restore: 1023
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 8736.336805582047
  time_this_iter_s: 8.210626125335693
  time_total_s: 8736.336805582047
  timestamp: 1594867071
  timesteps_since_restore: 5115000
  timesteps_this_iter: 5000
  timesteps_total: 5115000
  training_iteration: 1023
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 8736 s, 1023 iter, 5115000 ts, -437 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-38-00
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -434.73062499532955
  episode_reward_min: -1092.9999999881868
  episodes_this_iter: 1
  episodes_total: 1023
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 5.167
    dispatch_time_ms: 8.386
    learner:
      cur_lr: 0.0010193410562351346
      grad_gnorm: 1.3867237567901611
      policy_entropy: 5.964242063782876e-06
      policy_loss: -0.0
      var_gnorm: 28.299888610839844
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 0.0012662422377616167
    num_steps_sampled: 5120000
    num_steps_trained: 5120000
    wait_time_ms: 68.977
  iterations_since_restore: 1024
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 8744.52436542511
  time_this_iter_s: 8.187559843063354
  time_total_s: 8744.52436542511
  timestamp: 1594867080
  timesteps_since_restore: 5120000
  timesteps_this_iter: 5000
  timesteps_total: 5120000
  training_iteration: 1024
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 8744 s, 1024 iter, 5120000 ts, -435 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-38-08
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -428.7606249953933
  episode_reward_min: -1092.9999999881868
  episodes_this_iter: 1
  episodes_total: 1024
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 3.067
    dispatch_time_ms: 7.462
    learner:
      cur_lr: 0.0010190079919993877
      grad_gnorm: 40.0
      policy_entropy: 7.4531185418891255e-06
      policy_loss: -0.0
      var_gnorm: 28.29932975769043
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 1622.336181640625
    num_steps_sampled: 5125000
    num_steps_trained: 5125000
    wait_time_ms: 69.263
  iterations_since_restore: 1025
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 8752.689447164536
  time_this_iter_s: 8.16508173942566
  time_total_s: 8752.689447164536
  timestamp: 1594867088
  timesteps_since_restore: 5125000
  timesteps_this_iter: 5000
  timesteps_total: 5125000
  training_iteration: 1025
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 8752 s, 1025 iter, 5125000 ts, -429 rew

agent-1: 2.0
agent-2: -99.99999999894987
agent-3: -99.99999999894987
agent-4: -99.99999999894987
agent-5: -99.99999999894987
Extrinsic Rewards:
2
0
0
0
0
Sum Reward: 2
Avg Reward: 0.4
Min Reward: 0
Max Reward: 2
Gini Coefficient: 0.8
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-38-16
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -432.74062499535125
  episode_reward_min: -1092.9999999881868
  episodes_this_iter: 1
  episodes_total: 1025
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.697
    dispatch_time_ms: 8.556
    learner:
      cur_lr: 0.0010186750441789627
      grad_gnorm: 1.2174102067947388
      policy_entropy: 1.0982038475049194e-05
      policy_loss: -0.0
      var_gnorm: 28.295303344726562
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 0.0009759331587702036
    num_steps_sampled: 5130000
    num_steps_trained: 5130000
    wait_time_ms: 69.667
  iterations_since_restore: 1026
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 8760.85684299469
  time_this_iter_s: 8.167395830154419
  time_total_s: 8760.85684299469
  timestamp: 1594867096
  timesteps_since_restore: 5130000
  timesteps_this_iter: 5000
  timesteps_total: 5130000
  training_iteration: 1026
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 8760 s, 1026 iter, 5130000 ts, -433 rew

agent-1: -99.99999999896329
agent-2: -99.99999999896329
agent-3: -99.99999999896329
agent-4: 1.0
agent-5: 1.0
Extrinsic Rewards:
0
0
0
1
1
Sum Reward: 2
Avg Reward: 0.4
Min Reward: 0
Max Reward: 1
Gini Coefficient: 0.6
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-38-36
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -429.75062499538393
  episode_reward_min: -1092.9999999881868
  episodes_this_iter: 1
  episodes_total: 1026
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.736
    dispatch_time_ms: 7.132
    learner:
      cur_lr: 0.0010183419799432158
      grad_gnorm: 40.0
      policy_entropy: 1.8389473552815616e-05
      policy_loss: -0.0
      var_gnorm: 28.294189453125
      vf_explained_var: 0.0
      vf_loss: 568.7236328125
    num_steps_sampled: 5135000
    num_steps_trained: 5135000
    wait_time_ms: 62.827
  iterations_since_restore: 1027
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 8780.680260419846
  time_this_iter_s: 19.82341742515564
  time_total_s: 8780.680260419846
  timestamp: 1594867116
  timesteps_since_restore: 5135000
  timesteps_this_iter: 5000
  timesteps_total: 5135000
  training_iteration: 1027
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 8780 s, 1027 iter, 5135000 ts, -430 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-38-44
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -425.7706249954259
  episode_reward_min: -1092.9999999881868
  episodes_this_iter: 1
  episodes_total: 1027
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 4.482
    dispatch_time_ms: 9.788
    learner:
      cur_lr: 0.0010180090321227908
      grad_gnorm: 1.0346550941467285
      policy_entropy: 1.1682182048389222e-05
      policy_loss: -0.0
      var_gnorm: 28.31121253967285
      vf_explained_var: 0.0
      vf_loss: 0.0007048975094221532
    num_steps_sampled: 5140000
    num_steps_trained: 5140000
    wait_time_ms: 66.281
  iterations_since_restore: 1028
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 8788.892358064651
  time_this_iter_s: 8.212097644805908
  time_total_s: 8788.892358064651
  timestamp: 1594867124
  timesteps_since_restore: 5140000
  timesteps_this_iter: 5000
  timesteps_total: 5140000
  training_iteration: 1028
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 8788 s, 1028 iter, 5140000 ts, -426 rew

agent-1: -49.99999999946836
agent-2: -49.99999999946836
agent-3: 1.0
agent-4: -49.99999999946836
agent-5: -49.99999999946836
Extrinsic Rewards:
0
0
1
0
0
Sum Reward: 1
Avg Reward: 0.2
Min Reward: 0
Max Reward: 1
Gini Coefficient: 0.8
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-38-52
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -427.76062499540456
  episode_reward_min: -1092.9999999881868
  episodes_this_iter: 1
  episodes_total: 1028
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.552
    dispatch_time_ms: 6.376
    learner:
      cur_lr: 0.001017675967887044
      grad_gnorm: 40.0
      policy_entropy: 6.992375710979104e-05
      policy_loss: -7.551962335128337e-05
      var_gnorm: 28.309743881225586
      vf_explained_var: 7.218122482299805e-05
      vf_loss: 11657.2373046875
    num_steps_sampled: 5145000
    num_steps_trained: 5145000
    wait_time_ms: 76.891
  iterations_since_restore: 1029
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 8797.031468391418
  time_this_iter_s: 8.139110326766968
  time_total_s: 8797.031468391418
  timestamp: 1594867132
  timesteps_since_restore: 5145000
  timesteps_this_iter: 5000
  timesteps_total: 5145000
  training_iteration: 1029
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 8797 s, 1029 iter, 5145000 ts, -428 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-39-01
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -427.76062499540467
  episode_reward_min: -1092.9999999881868
  episodes_this_iter: 1
  episodes_total: 1029
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.631
    dispatch_time_ms: 7.073
    learner:
      cur_lr: 0.001017343020066619
      grad_gnorm: 3.5007991790771484
      policy_entropy: 0.00142517383210361
      policy_loss: -1.6205759720833157e-06
      var_gnorm: 28.279512405395508
      vf_explained_var: 0.0
      vf_loss: 0.008070665411651134
    num_steps_sampled: 5150000
    num_steps_trained: 5150000
    wait_time_ms: 72.268
  iterations_since_restore: 1030
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 8805.274953365326
  time_this_iter_s: 8.24348497390747
  time_total_s: 8805.274953365326
  timestamp: 1594867141
  timesteps_since_restore: 5150000
  timesteps_this_iter: 5000
  timesteps_total: 5150000
  training_iteration: 1030
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 8805 s, 1030 iter, 5150000 ts, -428 rew

agent-1: -199.99999999784504
agent-2: -199.99999999784504
agent-3: 4.0
agent-4: -199.99999999784504
agent-5: -199.99999999784504
Extrinsic Rewards:
0
0
4
0
0
Sum Reward: 4
Avg Reward: 0.8
Min Reward: 0
Max Reward: 4
Gini Coefficient: 0.8
20:20 Ratio: Undefined
Max-min Ratio: Undefined
agent-1: -99.99999999894987
agent-2: -99.99999999894987
agent-3: -99.99999999894987
agent-4: -99.99999999894987
agent-5: 2.0
Extrinsic Rewards:
0
0
0
0
2
Sum Reward: 2
Avg Reward: 0.4
Min Reward: 0
Max Reward: 2
Gini Coefficient: 0.8
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-39-09
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -424.7806249954368
  episode_reward_min: -1092.9999999881868
  episodes_this_iter: 2
  episodes_total: 1031
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.723
    dispatch_time_ms: 8.093
    learner:
      cur_lr: 0.001017009955830872
      grad_gnorm: 40.000003814697266
      policy_entropy: 0.002783376257866621
      policy_loss: -0.0012534823035821319
      var_gnorm: 28.279600143432617
      vf_explained_var: 0.0003355741500854492
      vf_loss: 793.8443603515625
    num_steps_sampled: 5155000
    num_steps_trained: 5155000
    wait_time_ms: 72.611
  iterations_since_restore: 1031
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 8813.49656033516
  time_this_iter_s: 8.221606969833374
  time_total_s: 8813.49656033516
  timestamp: 1594867149
  timesteps_since_restore: 5155000
  timesteps_this_iter: 5000
  timesteps_total: 5155000
  training_iteration: 1031
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 8813 s, 1031 iter, 5155000 ts, -425 rew

Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-39-17
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -424.7806249954369
  episode_reward_min: -1092.9999999881868
  episodes_this_iter: 0
  episodes_total: 1031
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.637
    dispatch_time_ms: 6.611
    learner:
      cur_lr: 0.001016677008010447
      grad_gnorm: 2.7911581993103027
      policy_entropy: 0.0014234264381229877
      policy_loss: -1.21026937449642e-06
      var_gnorm: 28.280092239379883
      vf_explained_var: 5.960464477539063e-08
      vf_loss: 0.005130334757268429
    num_steps_sampled: 5160000
    num_steps_trained: 5160000
    wait_time_ms: 71.716
  iterations_since_restore: 1032
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 8821.662799835205
  time_this_iter_s: 8.166239500045776
  time_total_s: 8821.662799835205
  timestamp: 1594867157
  timesteps_since_restore: 5160000
  timesteps_this_iter: 5000
  timesteps_total: 5160000
  training_iteration: 1032
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 8821 s, 1032 iter, 5160000 ts, -425 rew

agent-1: 3.0
agent-2: -149.99999999840443
agent-3: -149.99999999840443
agent-4: -149.99999999840443
agent-5: -149.99999999840443
Extrinsic Rewards:
3
0
0
0
0
Sum Reward: 3
Avg Reward: 0.6
Min Reward: 0
Max Reward: 3
Gini Coefficient: 0.8
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-39-25
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -430.75062499537313
  episode_reward_min: -1092.9999999881868
  episodes_this_iter: 1
  episodes_total: 1032
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.344
    dispatch_time_ms: 8.323
    learner:
      cur_lr: 0.0010163439437747002
      grad_gnorm: 0.008656409569084644
      policy_entropy: 0.0014257010770961642
      policy_loss: -2.65220156947521e-09
      var_gnorm: 28.280426025390625
      vf_explained_var: 0.0
      vf_loss: 4.909670536790145e-08
    num_steps_sampled: 5165000
    num_steps_trained: 5165000
    wait_time_ms: 71.265
  iterations_since_restore: 1033
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 8829.82055234909
  time_this_iter_s: 8.157752513885498
  time_total_s: 8829.82055234909
  timestamp: 1594867165
  timesteps_since_restore: 5165000
  timesteps_this_iter: 5000
  timesteps_total: 5165000
  training_iteration: 1033
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 8829 s, 1033 iter, 5165000 ts, -431 rew

agent-1: -49.99999999946836
agent-2: 1.0
agent-3: -49.99999999946836
agent-4: -49.99999999946836
agent-5: -49.99999999946836
Extrinsic Rewards:
0
1
0
0
0
Sum Reward: 1
Avg Reward: 0.2
Min Reward: 0
Max Reward: 1
Gini Coefficient: 0.8
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-39-34
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -432.7406249953518
  episode_reward_min: -1092.9999999881868
  episodes_this_iter: 1
  episodes_total: 1033
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 3.782
    dispatch_time_ms: 10.273
    learner:
      cur_lr: 0.0010160109959542751
      grad_gnorm: 1.2248603105545044
      policy_entropy: 0.0014274605782702565
      policy_loss: -6.218132284629974e-07
      var_gnorm: 28.28101348876953
      vf_explained_var: 0.0
      vf_loss: 0.0009879260323941708
    num_steps_sampled: 5170000
    num_steps_trained: 5170000
    wait_time_ms: 71.24
  iterations_since_restore: 1034
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 8838.039660453796
  time_this_iter_s: 8.21910810470581
  time_total_s: 8838.039660453796
  timestamp: 1594867174
  timesteps_since_restore: 5170000
  timesteps_this_iter: 5000
  timesteps_total: 5170000
  training_iteration: 1034
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 8838 s, 1034 iter, 5170000 ts, -433 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-39-42
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -427.77062499540443
  episode_reward_min: -1092.9999999881868
  episodes_this_iter: 1
  episodes_total: 1034
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.615
    dispatch_time_ms: 7.64
    learner:
      cur_lr: 0.00101567804813385
      grad_gnorm: 0.008036863058805466
      policy_entropy: 0.0014297651359811425
      policy_loss: -3.406932513883021e-09
      var_gnorm: 28.281402587890625
      vf_explained_var: 0.0
      vf_loss: 4.230418682027448e-08
    num_steps_sampled: 5175000
    num_steps_trained: 5175000
    wait_time_ms: 71.39
  iterations_since_restore: 1035
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 8846.239621400833
  time_this_iter_s: 8.199960947036743
  time_total_s: 8846.239621400833
  timestamp: 1594867182
  timesteps_since_restore: 5175000
  timesteps_this_iter: 5000
  timesteps_total: 5175000
  training_iteration: 1035
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 8846 s, 1035 iter, 5175000 ts, -428 rew

agent-1: -49.999999999481645
agent-2: -49.999999999481645
agent-3: -49.999999999481645
agent-4: -49.999999999481645
agent-5: 1.0
Extrinsic Rewards:
0
0
0
0
1
Sum Reward: 1
Avg Reward: 0.2
Min Reward: 0
Max Reward: 1
Gini Coefficient: 0.8
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-39-50
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -429.76062499538375
  episode_reward_min: -1092.9999999881868
  episodes_this_iter: 1
  episodes_total: 1035
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.6
    dispatch_time_ms: 8.343
    learner:
      cur_lr: 0.0010153449838981032
      grad_gnorm: 2.6665263175964355
      policy_entropy: 0.0014296324225142598
      policy_loss: -6.637935712205945e-07
      var_gnorm: 28.281978607177734
      vf_explained_var: 0.0
      vf_loss: 0.004683003760874271
    num_steps_sampled: 5180000
    num_steps_trained: 5180000
    wait_time_ms: 71.918
  iterations_since_restore: 1036
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 8854.470515727997
  time_this_iter_s: 8.230894327163696
  time_total_s: 8854.470515727997
  timestamp: 1594867190
  timesteps_since_restore: 5180000
  timesteps_this_iter: 5000
  timesteps_total: 5180000
  training_iteration: 1036
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 8854 s, 1036 iter, 5180000 ts, -430 rew

agent-1: -199.99999999788645
agent-2: 0.75
agent-3: -199.99999999788645
agent-4: -199.99999999788645
agent-5: 0.7500000000136119
Extrinsic Rewards:
0
2
0
0
2
Sum Reward: 4
Avg Reward: 0.8
Min Reward: 0
Max Reward: 2
Gini Coefficient: 0.6
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-39-58
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -433.7556249953414
  episode_reward_min: -1092.9999999881868
  episodes_this_iter: 1
  episodes_total: 1036
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.799
    dispatch_time_ms: 6.902
    learner:
      cur_lr: 0.0010150120360776782
      grad_gnorm: 40.00000762939453
      policy_entropy: 0.0014326892560347915
      policy_loss: -0.0009018880664370954
      var_gnorm: 28.282564163208008
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 3193.33642578125
    num_steps_sampled: 5185000
    num_steps_trained: 5185000
    wait_time_ms: 74.28
  iterations_since_restore: 1037
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 8862.686835765839
  time_this_iter_s: 8.216320037841797
  time_total_s: 8862.686835765839
  timestamp: 1594867198
  timesteps_since_restore: 5185000
  timesteps_this_iter: 5000
  timesteps_total: 5185000
  training_iteration: 1037
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 8862 s, 1037 iter, 5185000 ts, -434 rew

agent-1: -149.99999999840443
agent-2: -149.99999999840443
agent-3: 3.0
agent-4: -149.99999999840443
agent-5: -149.99999999840443
Extrinsic Rewards:
0
0
3
0
0
Sum Reward: 3
Avg Reward: 0.6
Min Reward: 0
Max Reward: 3
Gini Coefficient: 0.8
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-40-07
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -437.73562499529834
  episode_reward_min: -1092.9999999881868
  episodes_this_iter: 1
  episodes_total: 1037
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 3.167
    dispatch_time_ms: 7.688
    learner:
      cur_lr: 0.0010146789718419313
      grad_gnorm: 0.43872714042663574
      policy_entropy: 0.0014329282566905022
      policy_loss: -2.0309386172812083e-07
      var_gnorm: 28.283090591430664
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 0.00012680441432166845
    num_steps_sampled: 5190000
    num_steps_trained: 5190000
    wait_time_ms: 73.429
  iterations_since_restore: 1038
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 8870.96175456047
  time_this_iter_s: 8.274918794631958
  time_total_s: 8870.96175456047
  timestamp: 1594867207
  timesteps_since_restore: 5190000
  timesteps_this_iter: 5000
  timesteps_total: 5190000
  training_iteration: 1038
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 8870 s, 1038 iter, 5190000 ts, -438 rew

agent-1: -149.99999999837684
agent-2: -149.99999999837684
agent-3: -149.99999999837684
agent-4: 3.0
agent-5: -149.99999999837684
Extrinsic Rewards:
0
0
0
3
0
Sum Reward: 3
Avg Reward: 0.6
Min Reward: 0
Max Reward: 3
Gini Coefficient: 0.8
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-40-15
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -437.73562499529834
  episode_reward_min: -1092.9999999881868
  episodes_this_iter: 1
  episodes_total: 1038
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 3.507
    dispatch_time_ms: 7.96
    learner:
      cur_lr: 0.0010143460240215063
      grad_gnorm: 0.5827890634536743
      policy_entropy: 0.0014346535317599773
      policy_loss: -1.869285881639371e-08
      var_gnorm: 28.283601760864258
      vf_explained_var: 1.1920928955078125e-07
      vf_loss: 0.00022362380695994943
    num_steps_sampled: 5195000
    num_steps_trained: 5195000
    wait_time_ms: 69.847
  iterations_since_restore: 1039
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 8879.09181857109
  time_this_iter_s: 8.130064010620117
  time_total_s: 8879.09181857109
  timestamp: 1594867215
  timesteps_since_restore: 5195000
  timesteps_this_iter: 5000
  timesteps_total: 5195000
  training_iteration: 1039
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 8879 s, 1039 iter, 5195000 ts, -438 rew

agent-1: -349.99999999613846
agent-2: 1.53125
agent-3: -349.99999999613846
agent-4: -349.99999999613846
agent-5: -49.46874999938334
Extrinsic Rewards:
0
4
0
0
3
Sum Reward: 7
Avg Reward: 1.4
Min Reward: 0
Max Reward: 4
Gini Coefficient: 0.6285714285714286
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-40-23
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -440.7649999952633
  episode_reward_min: -1097.9374999877934
  episodes_this_iter: 1
  episodes_total: 1039
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.611
    dispatch_time_ms: 9.547
    learner:
      cur_lr: 0.0010140129597857594
      grad_gnorm: 0.028693657368421555
      policy_entropy: 0.0014356898609548807
      policy_loss: 6.148858915366873e-07
      var_gnorm: 28.284303665161133
      vf_explained_var: 1.1920928955078125e-07
      vf_loss: 7.967119017848745e-07
    num_steps_sampled: 5200000
    num_steps_trained: 5200000
    wait_time_ms: 70.847
  iterations_since_restore: 1040
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 8887.385937929153
  time_this_iter_s: 8.294119358062744
  time_total_s: 8887.385937929153
  timestamp: 1594867223
  timesteps_since_restore: 5200000
  timesteps_this_iter: 5000
  timesteps_total: 5200000
  training_iteration: 1040
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 8887 s, 1040 iter, 5200000 ts, -441 rew

agent-1: -199.999999997859
agent-2: -199.999999997859
agent-3: -98.9999999988954
agent-4: 3.0
agent-5: -199.999999997859
Extrinsic Rewards:
0
0
1
3
0
Sum Reward: 4
Avg Reward: 0.8
Min Reward: 0
Max Reward: 3
Gini Coefficient: 0.7
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-40-31
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -445.7349999952093
  episode_reward_min: -1097.9374999877934
  episodes_this_iter: 1
  episodes_total: 1040
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.732
    dispatch_time_ms: 10.082
    learner:
      cur_lr: 0.0010136800119653344
      grad_gnorm: 39.999996185302734
      policy_entropy: 0.0014381438959389925
      policy_loss: -0.000688317755702883
      var_gnorm: 28.285049438476562
      vf_explained_var: 5.960464477539063e-08
      vf_loss: 1857.4638671875
    num_steps_sampled: 5205000
    num_steps_trained: 5205000
    wait_time_ms: 69.969
  iterations_since_restore: 1041
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 8895.462184906006
  time_this_iter_s: 8.076246976852417
  time_total_s: 8895.462184906006
  timestamp: 1594867231
  timesteps_since_restore: 5205000
  timesteps_this_iter: 5000
  timesteps_total: 5205000
  training_iteration: 1041
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 8895 s, 1041 iter, 5205000 ts, -446 rew

agent-1: -199.99999999784504
agent-2: -199.99999999784504
agent-3: -199.99999999784504
agent-4: 4.0
agent-5: -199.99999999784504
Extrinsic Rewards:
0
0
0
4
0
Sum Reward: 4
Avg Reward: 0.8
Min Reward: 0
Max Reward: 4
Gini Coefficient: 0.8
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-40-40
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -446.69185937019756
  episode_reward_min: -1097.9374999877934
  episodes_this_iter: 1
  episodes_total: 1041
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 3.003
    dispatch_time_ms: 6.964
    learner:
      cur_lr: 0.0010133469477295876
      grad_gnorm: 1.4231243133544922
      policy_entropy: 0.00143909000325948
      policy_loss: -4.443104444362689e-07
      var_gnorm: 28.285869598388672
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 0.0013338165590539575
    num_steps_sampled: 5210000
    num_steps_trained: 5210000
    wait_time_ms: 71.769
  iterations_since_restore: 1042
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 8903.654663801193
  time_this_iter_s: 8.192478895187378
  time_total_s: 8903.654663801193
  timestamp: 1594867240
  timesteps_since_restore: 5210000
  timesteps_this_iter: 5000
  timesteps_total: 5210000
  training_iteration: 1042
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 8903 s, 1042 iter, 5210000 ts, -447 rew

agent-1: -149.99999999840443
agent-2: -149.99999999840443
agent-3: 3.0
agent-4: -149.99999999840443
agent-5: -149.99999999840443
Extrinsic Rewards:
0
0
3
0
0
Sum Reward: 3
Avg Reward: 0.6
Min Reward: 0
Max Reward: 3
Gini Coefficient: 0.8
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-40-48
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -452.6618593701338
  episode_reward_min: -1097.9374999877934
  episodes_this_iter: 1
  episodes_total: 1042
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 3.022
    dispatch_time_ms: 7.155
    learner:
      cur_lr: 0.0010130139999091625
      grad_gnorm: 40.0
      policy_entropy: 0.0014440387021750212
      policy_loss: -0.00026000308571383357
      var_gnorm: 28.2872314453125
      vf_explained_var: 0.0
      vf_loss: 353.2156982421875
    num_steps_sampled: 5215000
    num_steps_trained: 5215000
    wait_time_ms: 72.015
  iterations_since_restore: 1043
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 8911.871297359467
  time_this_iter_s: 8.216633558273315
  time_total_s: 8911.871297359467
  timestamp: 1594867248
  timesteps_since_restore: 5215000
  timesteps_this_iter: 5000
  timesteps_total: 5215000
  training_iteration: 1043
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 8911 s, 1043 iter, 5215000 ts, -453 rew

agent-1: -49.999999999481645
agent-2: 1.0
agent-3: -49.999999999481645
agent-4: -49.999999999481645
agent-5: -49.999999999481645
Extrinsic Rewards:
0
1
0
0
0
Sum Reward: 1
Avg Reward: 0.2
Min Reward: 0
Max Reward: 1
Gini Coefficient: 0.8
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-40-56
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -448.681859370178
  episode_reward_min: -1097.9374999877934
  episodes_this_iter: 1
  episodes_total: 1043
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 3.555
    dispatch_time_ms: 7.512
    learner:
      cur_lr: 0.0010126810520887375
      grad_gnorm: 0.06543023139238358
      policy_entropy: 0.001445711124688387
      policy_loss: 9.571269856678555e-07
      var_gnorm: 28.288225173950195
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 2.8204390218888875e-06
    num_steps_sampled: 5220000
    num_steps_trained: 5220000
    wait_time_ms: 70.602
  iterations_since_restore: 1044
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 8920.098462104797
  time_this_iter_s: 8.22716474533081
  time_total_s: 8920.098462104797
  timestamp: 1594867256
  timesteps_since_restore: 5220000
  timesteps_this_iter: 5000
  timesteps_total: 5220000
  training_iteration: 1044
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 8920 s, 1044 iter, 5220000 ts, -449 rew

agent-1: 1.0
agent-2: -99.99999999896329
agent-3: -99.99999999896329
agent-4: -99.99999999896329
agent-5: 1.0
Extrinsic Rewards:
1
0
0
0
1
Sum Reward: 2
Avg Reward: 0.4
Min Reward: 0
Max Reward: 1
Gini Coefficient: 0.6
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-41-04
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -451.66185937014694
  episode_reward_min: -1097.9374999877934
  episodes_this_iter: 1
  episodes_total: 1044
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.801
    dispatch_time_ms: 7.258
    learner:
      cur_lr: 0.0010123479878529906
      grad_gnorm: 4.6946611404418945
      policy_entropy: 0.0014509338652715087
      policy_loss: 2.1732337245339295e-06
      var_gnorm: 28.289995193481445
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 0.014512509107589722
    num_steps_sampled: 5225000
    num_steps_trained: 5225000
    wait_time_ms: 72.237
  iterations_since_restore: 1045
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 8928.297568321228
  time_this_iter_s: 8.199106216430664
  time_total_s: 8928.297568321228
  timestamp: 1594867264
  timesteps_since_restore: 5225000
  timesteps_this_iter: 5000
  timesteps_total: 5225000
  training_iteration: 1045
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 8928 s, 1045 iter, 5225000 ts, -452 rew

agent-1: -149.9999999984318
agent-2: -149.9999999984318
agent-3: 2.0
agent-4: -149.9999999984318
agent-5: -48.9999999994684
Extrinsic Rewards:
0
0
2
0
1
Sum Reward: 3
Avg Reward: 0.6
Min Reward: 0
Max Reward: 2
Gini Coefficient: 0.6666666666666666
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-41-13
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -448.6918593701793
  episode_reward_min: -1097.9374999877934
  episodes_this_iter: 1
  episodes_total: 1045
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 3.162
    dispatch_time_ms: 10.015
    learner:
      cur_lr: 0.0010120150400325656
      grad_gnorm: 0.9446095824241638
      policy_entropy: 0.001452708151191473
      policy_loss: -4.495332746046188e-07
      var_gnorm: 28.291156768798828
      vf_explained_var: 1.1920928955078125e-07
      vf_loss: 0.0005875415517948568
    num_steps_sampled: 5230000
    num_steps_trained: 5230000
    wait_time_ms: 70.21
  iterations_since_restore: 1046
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 8936.512371778488
  time_this_iter_s: 8.214803457260132
  time_total_s: 8936.512371778488
  timestamp: 1594867273
  timesteps_since_restore: 5230000
  timesteps_this_iter: 5000
  timesteps_total: 5230000
  training_iteration: 1046
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 8936 s, 1046 iter, 5230000 ts, -449 rew

agent-1: -149.99999999840443
agent-2: -149.99999999840443
agent-3: -149.99999999840443
agent-4: 3.0
agent-5: -149.99999999840443
Extrinsic Rewards:
0
0
0
3
0
Sum Reward: 3
Avg Reward: 0.6
Min Reward: 0
Max Reward: 3
Gini Coefficient: 0.8
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-41-21
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -445.7218593702138
  episode_reward_min: -1097.9374999877934
  episodes_this_iter: 1
  episodes_total: 1046
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 3.333
    dispatch_time_ms: 20.514
    learner:
      cur_lr: 0.0010116819757968187
      grad_gnorm: 0.05689350515604019
      policy_entropy: 0.001457066973671317
      policy_loss: 1.0821765705770758e-08
      var_gnorm: 28.292617797851562
      vf_explained_var: 0.0
      vf_loss: 1.6980005739242188e-06
    num_steps_sampled: 5235000
    num_steps_trained: 5235000
    wait_time_ms: 102.534
  iterations_since_restore: 1047
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 8945.179169654846
  time_this_iter_s: 8.666797876358032
  time_total_s: 8945.179169654846
  timestamp: 1594867281
  timesteps_since_restore: 5235000
  timesteps_this_iter: 5000
  timesteps_total: 5235000
  training_iteration: 1047
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 8945 s, 1047 iter, 5235000 ts, -446 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-41-30
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -443.7318593702345
  episode_reward_min: -1097.9374999877934
  episodes_this_iter: 1
  episodes_total: 1047
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.705
    dispatch_time_ms: 32.642
    learner:
      cur_lr: 0.0010113490279763937
      grad_gnorm: 12.238436698913574
      policy_entropy: 0.0014671544777229428
      policy_loss: 8.079267900029663e-06
      var_gnorm: 28.296096801757812
      vf_explained_var: 0.0
      vf_loss: 0.09862856566905975
    num_steps_sampled: 5240000
    num_steps_trained: 5240000
    wait_time_ms: 47.664
  iterations_since_restore: 1048
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 8953.779214382172
  time_this_iter_s: 8.60004472732544
  time_total_s: 8953.779214382172
  timestamp: 1594867290
  timesteps_since_restore: 5240000
  timesteps_this_iter: 5000
  timesteps_total: 5240000
  training_iteration: 1048
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 8953 s, 1048 iter, 5240000 ts, -444 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-41-39
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -438.7618593702869
  episode_reward_min: -1097.9374999877934
  episodes_this_iter: 1
  episodes_total: 1048
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.975
    dispatch_time_ms: 32.434
    learner:
      cur_lr: 0.0010110159637406468
      grad_gnorm: 0.41536349058151245
      policy_entropy: 0.0014536335365846753
      policy_loss: 3.71403501731038e-07
      var_gnorm: 28.29266357421875
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 0.00011361160431988537
    num_steps_sampled: 5245000
    num_steps_trained: 5245000
    wait_time_ms: 56.843
  iterations_since_restore: 1049
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 8962.587567090988
  time_this_iter_s: 8.808352708816528
  time_total_s: 8962.587567090988
  timestamp: 1594867299
  timesteps_since_restore: 5245000
  timesteps_this_iter: 5000
  timesteps_total: 5245000
  training_iteration: 1049
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 8962 s, 1049 iter, 5245000 ts, -439 rew

agent-1: -299.9999999967528
agent-2: -299.9999999967528
agent-3: 4.0
agent-4: -97.99999999893765
agent-5: -299.9999999967528
Extrinsic Rewards:
0
0
4
2
0
Sum Reward: 6
Avg Reward: 1.2
Min Reward: 0
Max Reward: 4
Gini Coefficient: 0.6666666666666666
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-41-48
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -439.7518593702757
  episode_reward_min: -1097.9374999877934
  episodes_this_iter: 1
  episodes_total: 1049
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 3.182
    dispatch_time_ms: 24.654
    learner:
      cur_lr: 0.0010106830159202218
      grad_gnorm: 6.767868995666504
      policy_entropy: 0.00146157993003726
      policy_loss: 5.515235443454003e-06
      var_gnorm: 28.295452117919922
      vf_explained_var: 1.1920928955078125e-07
      vf_loss: 0.030152874067425728
    num_steps_sampled: 5250000
    num_steps_trained: 5250000
    wait_time_ms: 68.296
  iterations_since_restore: 1050
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 8971.410358905792
  time_this_iter_s: 8.822791814804077
  time_total_s: 8971.410358905792
  timestamp: 1594867308
  timesteps_since_restore: 5250000
  timesteps_this_iter: 5000
  timesteps_total: 5250000
  training_iteration: 1050
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 8971 s, 1050 iter, 5250000 ts, -440 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-41-56
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -435.7718593703177
  episode_reward_min: -1097.9374999877934
  episodes_this_iter: 1
  episodes_total: 1050
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 3.234
    dispatch_time_ms: 32.148
    learner:
      cur_lr: 0.001010349951684475
      grad_gnorm: 0.07269611209630966
      policy_entropy: 0.001454034587368369
      policy_loss: 2.209478378034646e-09
      var_gnorm: 28.29377555847168
      vf_explained_var: 0.0
      vf_loss: 3.4830118238460273e-06
    num_steps_sampled: 5255000
    num_steps_trained: 5255000
    wait_time_ms: 66.082
  iterations_since_restore: 1051
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 8980.209485054016
  time_this_iter_s: 8.799126148223877
  time_total_s: 8980.209485054016
  timestamp: 1594867316
  timesteps_since_restore: 5255000
  timesteps_this_iter: 5000
  timesteps_total: 5255000
  training_iteration: 1051
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 8980 s, 1051 iter, 5255000 ts, -436 rew

agent-1: -199.99999999784504
agent-2: -199.99999999784504
agent-3: 4.0
agent-4: -199.99999999784504
agent-5: -199.99999999784504
Extrinsic Rewards:
0
0
4
0
0
Sum Reward: 4
Avg Reward: 0.8
Min Reward: 0
Max Reward: 4
Gini Coefficient: 0.8
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-42-05
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -433.7668593703404
  episode_reward_min: -1097.9374999877934
  episodes_this_iter: 1
  episodes_total: 1051
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 3.842
    dispatch_time_ms: 28.917
    learner:
      cur_lr: 0.00101001700386405
      grad_gnorm: 7.5816521644592285
      policy_entropy: 0.0014680711319670081
      policy_loss: 2.9631789857376134e-06
      var_gnorm: 28.298717498779297
      vf_explained_var: 0.0
      vf_loss: 0.035594016313552856
    num_steps_sampled: 5260000
    num_steps_trained: 5260000
    wait_time_ms: 61.833
  iterations_since_restore: 1052
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 8988.983419418335
  time_this_iter_s: 8.773934364318848
  time_total_s: 8988.983419418335
  timestamp: 1594867325
  timesteps_since_restore: 5260000
  timesteps_this_iter: 5000
  timesteps_total: 5260000
  training_iteration: 1052
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 8988 s, 1052 iter, 5260000 ts, -434 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-42-14
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -433.76685937034046
  episode_reward_min: -1097.9374999877934
  episodes_this_iter: 1
  episodes_total: 1052
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.764
    dispatch_time_ms: 26.944
    learner:
      cur_lr: 0.0010096840560436249
      grad_gnorm: 12.214362144470215
      policy_entropy: 0.0014767857501283288
      policy_loss: -8.32862588140415e-06
      var_gnorm: 28.30166244506836
      vf_explained_var: 0.0
      vf_loss: 0.09823987632989883
    num_steps_sampled: 5265000
    num_steps_trained: 5265000
    wait_time_ms: 66.328
  iterations_since_restore: 1053
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 8997.779228925705
  time_this_iter_s: 8.795809507369995
  time_total_s: 8997.779228925705
  timestamp: 1594867334
  timesteps_since_restore: 5265000
  timesteps_this_iter: 5000
  timesteps_total: 5265000
  training_iteration: 1053
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 8997 s, 1053 iter, 5265000 ts, -434 rew

agent-1: -149.9999999984318
agent-2: -149.9999999984318
agent-3: -149.9999999984318
agent-4: -48.9999999994684
agent-5: 2.0
Extrinsic Rewards:
0
0
0
1
2
Sum Reward: 3
Avg Reward: 0.6
Min Reward: 0
Max Reward: 2
Gini Coefficient: 0.6666666666666666
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-42-23
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -432.7668593703529
  episode_reward_min: -1097.9374999877934
  episodes_this_iter: 1
  episodes_total: 1053
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 3.617
    dispatch_time_ms: 32.449
    learner:
      cur_lr: 0.001009350991807878
      grad_gnorm: 6.152005195617676
      policy_entropy: 0.0014802865916863084
      policy_loss: 5.2303512347862124e-06
      var_gnorm: 28.297170639038086
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 0.02491753175854683
    num_steps_sampled: 5270000
    num_steps_trained: 5270000
    wait_time_ms: 58.53
  iterations_since_restore: 1054
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 9006.545316934586
  time_this_iter_s: 8.766088008880615
  time_total_s: 9006.545316934586
  timestamp: 1594867343
  timesteps_since_restore: 5270000
  timesteps_this_iter: 5000
  timesteps_total: 5270000
  training_iteration: 1054
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 9006 s, 1054 iter, 5270000 ts, -433 rew

agent-1: -149.99999999840443
agent-2: -149.99999999840443
agent-3: 3.0
agent-4: -149.99999999840443
agent-5: -149.99999999840443
Extrinsic Rewards:
0
0
3
0
0
Sum Reward: 3
Avg Reward: 0.6
Min Reward: 0
Max Reward: 3
Gini Coefficient: 0.8
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-42-32
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -434.7568593703312
  episode_reward_min: -1097.9374999877934
  episodes_this_iter: 1
  episodes_total: 1054
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 3.392
    dispatch_time_ms: 21.127
    learner:
      cur_lr: 0.001009018043987453
      grad_gnorm: 39.999996185302734
      policy_entropy: 0.0014804272213950753
      policy_loss: -0.00012779429380316287
      var_gnorm: 28.29774284362793
      vf_explained_var: 0.0
      vf_loss: 54.87699508666992
    num_steps_sampled: 5275000
    num_steps_trained: 5275000
    wait_time_ms: 66.515
  iterations_since_restore: 1055
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 9015.3159263134
  time_this_iter_s: 8.770609378814697
  time_total_s: 9015.3159263134
  timestamp: 1594867352
  timesteps_since_restore: 5275000
  timesteps_this_iter: 5000
  timesteps_total: 5275000
  training_iteration: 1055
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 9015 s, 1055 iter, 5275000 ts, -435 rew

agent-1: 1.0
agent-2: -99.99999999896329
agent-3: 1.0
agent-4: -99.99999999896329
agent-5: -99.99999999896329
Extrinsic Rewards:
1
0
1
0
0
Sum Reward: 2
Avg Reward: 0.4
Min Reward: 0
Max Reward: 1
Gini Coefficient: 0.6
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-42-40
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -432.76685937035245
  episode_reward_min: -1097.9374999877934
  episodes_this_iter: 1
  episodes_total: 1055
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.693
    dispatch_time_ms: 9.039
    learner:
      cur_lr: 0.0010086849797517061
      grad_gnorm: 5.987275123596191
      policy_entropy: 0.0015033949166536331
      policy_loss: 4.118914603168378e-06
      var_gnorm: 28.304166793823242
      vf_explained_var: 0.0
      vf_loss: 0.023599280044436455
    num_steps_sampled: 5280000
    num_steps_trained: 5280000
    wait_time_ms: 68.488
  iterations_since_restore: 1056
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 9023.751243114471
  time_this_iter_s: 8.435316801071167
  time_total_s: 9023.751243114471
  timestamp: 1594867360
  timesteps_since_restore: 5280000
  timesteps_this_iter: 5000
  timesteps_total: 5280000
  training_iteration: 1056
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 9023 s, 1056 iter, 5280000 ts, -433 rew

agent-1: -199.99999999784504
agent-2: -199.99999999784504
agent-3: -199.99999999784504
agent-4: 4.0
agent-5: -199.99999999784504
Extrinsic Rewards:
0
0
0
4
0
Sum Reward: 4
Avg Reward: 0.8
Min Reward: 0
Max Reward: 4
Gini Coefficient: 0.8
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-42-48
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -434.75685937033006
  episode_reward_min: -1097.9374999877934
  episodes_this_iter: 1
  episodes_total: 1056
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 4.421
    dispatch_time_ms: 8.666
    learner:
      cur_lr: 0.001008352031931281
      grad_gnorm: 40.0
      policy_entropy: 0.001518787583336234
      policy_loss: -6.74808252369985e-05
      var_gnorm: 28.312885284423828
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 16.705827713012695
    num_steps_sampled: 5285000
    num_steps_trained: 5285000
    wait_time_ms: 69.968
  iterations_since_restore: 1057
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 9032.026843070984
  time_this_iter_s: 8.275599956512451
  time_total_s: 9032.026843070984
  timestamp: 1594867368
  timesteps_since_restore: 5285000
  timesteps_this_iter: 5000
  timesteps_total: 5285000
  training_iteration: 1057
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 9032 s, 1057 iter, 5285000 ts, -435 rew

agent-1: 3.0
agent-2: -98.99999999893653
agent-3: -199.99999999787352
agent-4: -199.99999999787352
agent-5: -199.99999999787352
Extrinsic Rewards:
3
1
0
0
0
Sum Reward: 4
Avg Reward: 0.8
Min Reward: 0
Max Reward: 3
Gini Coefficient: 0.7
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-42-57
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -441.7168593702556
  episode_reward_min: -1097.9374999877934
  episodes_this_iter: 1
  episodes_total: 1057
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.982
    dispatch_time_ms: 8.621
    learner:
      cur_lr: 0.0010080189676955342
      grad_gnorm: 4.132058143615723
      policy_entropy: 0.0015184413641691208
      policy_loss: 3.393835640963516e-06
      var_gnorm: 28.299448013305664
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 0.01124283391982317
    num_steps_sampled: 5290000
    num_steps_trained: 5290000
    wait_time_ms: 72.873
  iterations_since_restore: 1058
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 9040.227155208588
  time_this_iter_s: 8.20031213760376
  time_total_s: 9040.227155208588
  timestamp: 1594867377
  timesteps_since_restore: 5290000
  timesteps_this_iter: 5000
  timesteps_total: 5290000
  training_iteration: 1058
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 9040 s, 1058 iter, 5290000 ts, -442 rew

agent-1: -149.99999999840443
agent-2: -149.99999999840443
agent-3: -149.99999999840443
agent-4: -149.99999999840443
agent-5: 3.0
Extrinsic Rewards:
0
0
0
0
3
Sum Reward: 3
Avg Reward: 0.6
Min Reward: 0
Max Reward: 3
Gini Coefficient: 0.8
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-43-05
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -439.7268593702797
  episode_reward_min: -1097.9374999877934
  episodes_this_iter: 1
  episodes_total: 1058
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.758
    dispatch_time_ms: 9.591
    learner:
      cur_lr: 0.0010076860198751092
      grad_gnorm: 0.03563957288861275
      policy_entropy: 0.0015181974740698934
      policy_loss: 1.9312892618472688e-08
      var_gnorm: 28.297517776489258
      vf_explained_var: 1.1920928955078125e-07
      vf_loss: 8.389412187170819e-07
    num_steps_sampled: 5295000
    num_steps_trained: 5295000
    wait_time_ms: 69.675
  iterations_since_restore: 1059
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 9048.361914634705
  time_this_iter_s: 8.134759426116943
  time_total_s: 9048.361914634705
  timestamp: 1594867385
  timesteps_since_restore: 5295000
  timesteps_this_iter: 5000
  timesteps_total: 5295000
  training_iteration: 1059
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 9048 s, 1059 iter, 5295000 ts, -440 rew

agent-1: 2.0
agent-2: -99.99999999894987
agent-3: -99.99999999894987
agent-4: -99.99999999894987
agent-5: -99.99999999894987
Extrinsic Rewards:
2
0
0
0
0
Sum Reward: 2
Avg Reward: 0.4
Min Reward: 0
Max Reward: 2
Gini Coefficient: 0.8
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-43-13
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -439.7268593702797
  episode_reward_min: -1097.9374999877934
  episodes_this_iter: 1
  episodes_total: 1059
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.866
    dispatch_time_ms: 8.192
    learner:
      cur_lr: 0.0010073529556393623
      grad_gnorm: 8.074034690856934
      policy_entropy: 0.0015349236782640219
      policy_loss: 5.192920980334748e-06
      var_gnorm: 28.301916122436523
      vf_explained_var: 0.0
      vf_loss: 0.04292643070220947
    num_steps_sampled: 5300000
    num_steps_trained: 5300000
    wait_time_ms: 70.367
  iterations_since_restore: 1060
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 9056.615761995316
  time_this_iter_s: 8.253847360610962
  time_total_s: 9056.615761995316
  timestamp: 1594867393
  timesteps_since_restore: 5300000
  timesteps_this_iter: 5000
  timesteps_total: 5300000
  training_iteration: 1060
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 9056 s, 1060 iter, 5300000 ts, -440 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-43-22
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -435.7468593703218
  episode_reward_min: -1097.9374999877934
  episodes_this_iter: 1
  episodes_total: 1060
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.468
    dispatch_time_ms: 7.736
    learner:
      cur_lr: 0.0010070200078189373
      grad_gnorm: 40.0
      policy_entropy: 0.001556558534502983
      policy_loss: -7.528582500526682e-05
      var_gnorm: 28.307842254638672
      vf_explained_var: 0.0
      vf_loss: 18.082624435424805
    num_steps_sampled: 5305000
    num_steps_trained: 5305000
    wait_time_ms: 72.293
  iterations_since_restore: 1061
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 9064.841101884842
  time_this_iter_s: 8.225339889526367
  time_total_s: 9064.841101884842
  timestamp: 1594867402
  timesteps_since_restore: 5305000
  timesteps_this_iter: 5000
  timesteps_total: 5305000
  training_iteration: 1061
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 9064 s, 1061 iter, 5305000 ts, -436 rew

agent-1: -149.99999999840443
agent-2: -149.99999999840443
agent-3: -149.99999999840443
agent-4: -149.99999999840443
agent-5: 3.0
Extrinsic Rewards:
0
0
0
0
3
Sum Reward: 3
Avg Reward: 0.6
Min Reward: 0
Max Reward: 3
Gini Coefficient: 0.8
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-43-30
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -435.74685937032285
  episode_reward_min: -1097.9374999877934
  episodes_this_iter: 1
  episodes_total: 1061
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.499
    dispatch_time_ms: 7.518
    learner:
      cur_lr: 0.0010066869435831904
      grad_gnorm: 2.761198043823242
      policy_entropy: 0.0015480732545256615
      policy_loss: 2.1098876459291205e-06
      var_gnorm: 28.30689811706543
      vf_explained_var: 0.0
      vf_loss: 0.005020350683480501
    num_steps_sampled: 5310000
    num_steps_trained: 5310000
    wait_time_ms: 72.379
  iterations_since_restore: 1062
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 9073.136802196503
  time_this_iter_s: 8.295700311660767
  time_total_s: 9073.136802196503
  timestamp: 1594867410
  timesteps_since_restore: 5310000
  timesteps_this_iter: 5000
  timesteps_total: 5310000
  training_iteration: 1062
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 9073 s, 1062 iter, 5310000 ts, -436 rew

agent-1: -199.99999999784504
agent-2: 4.0
agent-3: -199.99999999784504
agent-4: -199.99999999784504
agent-5: -199.99999999784504
Extrinsic Rewards:
0
4
0
0
0
Sum Reward: 4
Avg Reward: 0.8
Min Reward: 0
Max Reward: 4
Gini Coefficient: 0.8
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-43-38
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -435.75685937032154
  episode_reward_min: -1097.9374999877934
  episodes_this_iter: 1
  episodes_total: 1062
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.926
    dispatch_time_ms: 6.177
    learner:
      cur_lr: 0.0010063539957627654
      grad_gnorm: 16.959087371826172
      policy_entropy: 0.001583981211297214
      policy_loss: 4.129761236981722e-06
      var_gnorm: 28.31993865966797
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 0.18938620388507843
    num_steps_sampled: 5315000
    num_steps_trained: 5315000
    wait_time_ms: 74.437
  iterations_since_restore: 1063
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 9081.297391414642
  time_this_iter_s: 8.160589218139648
  time_total_s: 9081.297391414642
  timestamp: 1594867418
  timesteps_since_restore: 5315000
  timesteps_this_iter: 5000
  timesteps_total: 5315000
  training_iteration: 1063
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 9081 s, 1063 iter, 5315000 ts, -436 rew

agent-1: -49.99999999946836
agent-2: -49.99999999946836
agent-3: -49.99999999946836
agent-4: 1.0
agent-5: -49.99999999946836
Extrinsic Rewards:
0
0
0
1
0
Sum Reward: 1
Avg Reward: 0.2
Min Reward: 0
Max Reward: 1
Gini Coefficient: 0.8
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-43-46
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -437.7468593703002
  episode_reward_min: -1097.9374999877934
  episodes_this_iter: 1
  episodes_total: 1063
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.718
    dispatch_time_ms: 8.291
    learner:
      cur_lr: 0.0010060210479423404
      grad_gnorm: 7.714193820953369
      policy_entropy: 0.0015809419564902782
      policy_loss: 3.991144239989808e-06
      var_gnorm: 28.310443878173828
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 0.03918543830513954
    num_steps_sampled: 5320000
    num_steps_trained: 5320000
    wait_time_ms: 71.34
  iterations_since_restore: 1064
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 9089.557520866394
  time_this_iter_s: 8.260129451751709
  time_total_s: 9089.557520866394
  timestamp: 1594867426
  timesteps_since_restore: 5320000
  timesteps_this_iter: 5000
  timesteps_total: 5320000
  training_iteration: 1064
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 9089 s, 1064 iter, 5320000 ts, -438 rew

agent-1: 2.0
agent-2: -48.99999999948169
agent-3: -149.99999999841847
agent-4: -149.99999999841847
agent-5: -149.99999999841847
Extrinsic Rewards:
2
1
0
0
0
Sum Reward: 3
Avg Reward: 0.6
Min Reward: 0
Max Reward: 2
Gini Coefficient: 0.6666666666666666
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-43-55
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -442.7168593702476
  episode_reward_min: -1097.9374999877934
  episodes_this_iter: 1
  episodes_total: 1064
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.659
    dispatch_time_ms: 6.693
    learner:
      cur_lr: 0.0010056879837065935
      grad_gnorm: 39.999996185302734
      policy_entropy: 0.0016020872863009572
      policy_loss: -3.975250729126856e-05
      var_gnorm: 28.3153133392334
      vf_explained_var: 0.0
      vf_loss: 5.139253616333008
    num_steps_sampled: 5325000
    num_steps_trained: 5325000
    wait_time_ms: 71.576
  iterations_since_restore: 1065
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 9097.719607591629
  time_this_iter_s: 8.162086725234985
  time_total_s: 9097.719607591629
  timestamp: 1594867435
  timesteps_since_restore: 5325000
  timesteps_this_iter: 5000
  timesteps_total: 5325000
  training_iteration: 1065
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 9097 s, 1065 iter, 5325000 ts, -443 rew

agent-1: -149.99999999837684
agent-2: -149.99999999837684
agent-3: -149.99999999837684
agent-4: -149.99999999837684
agent-5: 3.0
Extrinsic Rewards:
0
0
0
0
3
Sum Reward: 3
Avg Reward: 0.6
Min Reward: 0
Max Reward: 3
Gini Coefficient: 0.8
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-44-03
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -446.6968593702035
  episode_reward_min: -1097.9374999877934
  episodes_this_iter: 1
  episodes_total: 1065
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.37
    dispatch_time_ms: 5.663
    learner:
      cur_lr: 0.0010053550358861685
      grad_gnorm: 0.38015902042388916
      policy_entropy: 0.0015838990220800042
      policy_loss: -2.6782859663398995e-07
      var_gnorm: 28.306177139282227
      vf_explained_var: 0.0
      vf_loss: 9.514441626379266e-05
    num_steps_sampled: 5330000
    num_steps_trained: 5330000
    wait_time_ms: 73.881
  iterations_since_restore: 1066
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 9105.949791193008
  time_this_iter_s: 8.230183601379395
  time_total_s: 9105.949791193008
  timestamp: 1594867443
  timesteps_since_restore: 5330000
  timesteps_this_iter: 5000
  timesteps_total: 5330000
  training_iteration: 1066
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 9105 s, 1066 iter, 5330000 ts, -447 rew

agent-1: -149.99999999840443
agent-2: 3.0
agent-3: -149.99999999840443
agent-4: -149.99999999840443
agent-5: -149.99999999840443
Extrinsic Rewards:
0
3
0
0
0
Sum Reward: 3
Avg Reward: 0.6
Min Reward: 0
Max Reward: 3
Gini Coefficient: 0.8
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-44-11
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -445.706859370215
  episode_reward_min: -1097.9374999877934
  episodes_this_iter: 1
  episodes_total: 1066
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.734
    dispatch_time_ms: 6.971
    learner:
      cur_lr: 0.0010050219716504216
      grad_gnorm: 40.0
      policy_entropy: 0.001637152279727161
      policy_loss: -8.036559302126989e-05
      var_gnorm: 28.326021194458008
      vf_explained_var: 0.0
      vf_loss: 25.790821075439453
    num_steps_sampled: 5335000
    num_steps_trained: 5335000
    wait_time_ms: 71.42
  iterations_since_restore: 1067
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 9114.203805446625
  time_this_iter_s: 8.254014253616333
  time_total_s: 9114.203805446625
  timestamp: 1594867451
  timesteps_since_restore: 5335000
  timesteps_this_iter: 5000
  timesteps_total: 5335000
  training_iteration: 1067
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 9114 s, 1067 iter, 5335000 ts, -446 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-44-19
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -434.7768593703331
  episode_reward_min: -1097.9374999877934
  episodes_this_iter: 1
  episodes_total: 1067
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.653
    dispatch_time_ms: 9.682
    learner:
      cur_lr: 0.0010046890238299966
      grad_gnorm: 0.5569635629653931
      policy_entropy: 0.001610248233191669
      policy_loss: -4.6400273845392803e-07
      var_gnorm: 28.30394744873047
      vf_explained_var: 0.0
      vf_loss: 0.00020428271091077477
    num_steps_sampled: 5340000
    num_steps_trained: 5340000
    wait_time_ms: 71.024
  iterations_since_restore: 1068
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 9122.416067838669
  time_this_iter_s: 8.212262392044067
  time_total_s: 9122.416067838669
  timestamp: 1594867459
  timesteps_since_restore: 5340000
  timesteps_this_iter: 5000
  timesteps_total: 5340000
  training_iteration: 1068
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 9122 s, 1068 iter, 5340000 ts, -435 rew

agent-1: -349.99999999625004
agent-2: -349.99999999625004
agent-3: -46.99999999944068
agent-4: 4.0
agent-5: -349.99999999625004
Extrinsic Rewards:
0
0
3
4
0
Sum Reward: 7
Avg Reward: 1.4
Min Reward: 0
Max Reward: 4
Gini Coefficient: 0.6285714285714286
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-44-27
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -445.70685937021494
  episode_reward_min: -1097.9374999877934
  episodes_this_iter: 1
  episodes_total: 1068
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.614
    dispatch_time_ms: 9.076
    learner:
      cur_lr: 0.0010043559595942497
      grad_gnorm: 40.0
      policy_entropy: 0.0016716462559998035
      policy_loss: -2.4077338821371086e-05
      var_gnorm: 28.319896697998047
      vf_explained_var: 0.0
      vf_loss: 1.800808072090149
    num_steps_sampled: 5345000
    num_steps_trained: 5345000
    wait_time_ms: 71.514
  iterations_since_restore: 1069
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 9130.543008804321
  time_this_iter_s: 8.126940965652466
  time_total_s: 9130.543008804321
  timestamp: 1594867467
  timesteps_since_restore: 5345000
  timesteps_this_iter: 5000
  timesteps_total: 5345000
  training_iteration: 1069
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 9130 s, 1069 iter, 5345000 ts, -446 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-44-36
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -441.72685937025693
  episode_reward_min: -1097.9374999877934
  episodes_this_iter: 1
  episodes_total: 1069
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.652
    dispatch_time_ms: 12.028
    learner:
      cur_lr: 0.0010040230117738247
      grad_gnorm: 9.367254257202148
      policy_entropy: 0.0016761082224547863
      policy_loss: 6.637492788286181e-06
      var_gnorm: 28.313297271728516
      vf_explained_var: 0.0
      vf_loss: 0.05791287496685982
    num_steps_sampled: 5350000
    num_steps_trained: 5350000
    wait_time_ms: 69.848
  iterations_since_restore: 1070
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 9138.726133823395
  time_this_iter_s: 8.183125019073486
  time_total_s: 9138.726133823395
  timestamp: 1594867476
  timesteps_since_restore: 5350000
  timesteps_this_iter: 5000
  timesteps_total: 5350000
  training_iteration: 1070
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 9138 s, 1070 iter, 5350000 ts, -442 rew

agent-1: -99.99999999894987
agent-2: -99.99999999894987
agent-3: -99.99999999894987
agent-4: 2.0
agent-5: -99.99999999894987
Extrinsic Rewards:
0
0
0
2
0
Sum Reward: 2
Avg Reward: 0.4
Min Reward: 0
Max Reward: 2
Gini Coefficient: 0.8
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-44-44
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -435.76685937032204
  episode_reward_min: -1097.9374999877934
  episodes_this_iter: 1
  episodes_total: 1070
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.824
    dispatch_time_ms: 8.246
    learner:
      cur_lr: 0.0010036899475380778
      grad_gnorm: 40.0
      policy_entropy: 0.0017026960849761963
      policy_loss: -3.616081812651828e-05
      var_gnorm: 28.3150634765625
      vf_explained_var: 5.960464477539063e-08
      vf_loss: 4.398388862609863
    num_steps_sampled: 5355000
    num_steps_trained: 5355000
    wait_time_ms: 71.242
  iterations_since_restore: 1071
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 9146.95657491684
  time_this_iter_s: 8.230441093444824
  time_total_s: 9146.95657491684
  timestamp: 1594867484
  timesteps_since_restore: 5355000
  timesteps_this_iter: 5000
  timesteps_total: 5355000
  training_iteration: 1071
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 9146 s, 1071 iter, 5355000 ts, -436 rew

agent-1: 3.0
agent-2: -299.9999999968223
agent-3: -47.99999999945478
agent-4: -299.9999999968223
agent-5: -148.99999999841833
Extrinsic Rewards:
3
0
2
0
1
Sum Reward: 6
Avg Reward: 1.2
Min Reward: 0
Max Reward: 3
Gini Coefficient: 0.5333333333333333
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-44-52
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -433.74185937034616
  episode_reward_min: -1097.9374999877934
  episodes_this_iter: 1
  episodes_total: 1071
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.826
    dispatch_time_ms: 6.061
    learner:
      cur_lr: 0.0010033569997176528
      grad_gnorm: 13.91563606262207
      policy_entropy: 0.0017276019789278507
      policy_loss: 9.72601628745906e-06
      var_gnorm: 28.315385818481445
      vf_explained_var: 0.0
      vf_loss: 0.12751086056232452
    num_steps_sampled: 5360000
    num_steps_trained: 5360000
    wait_time_ms: 70.652
  iterations_since_restore: 1072
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 9155.10387468338
  time_this_iter_s: 8.147299766540527
  time_total_s: 9155.10387468338
  timestamp: 1594867492
  timesteps_since_restore: 5360000
  timesteps_this_iter: 5000
  timesteps_total: 5360000
  training_iteration: 1072
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 9155 s, 1072 iter, 5360000 ts, -434 rew

agent-1: -199.99999999784504
agent-2: -199.99999999784504
agent-3: -199.99999999784504
agent-4: 2.96875
agent-5: -99.03124999890878
Extrinsic Rewards:
0
0
0
3
1
Sum Reward: 4
Avg Reward: 0.8
Min Reward: 0
Max Reward: 3
Gini Coefficient: 0.7
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-45-00
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -440.7024843702706
  episode_reward_min: -1097.9374999877934
  episodes_this_iter: 1
  episodes_total: 1072
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.716
    dispatch_time_ms: 8.806
    learner:
      cur_lr: 0.0010030240518972278
      grad_gnorm: 34.84599304199219
      policy_entropy: 0.0017548706382513046
      policy_loss: -2.1435615053633228e-05
      var_gnorm: 28.316774368286133
      vf_explained_var: 0.0
      vf_loss: 1.3446789979934692
    num_steps_sampled: 5365000
    num_steps_trained: 5365000
    wait_time_ms: 68.708
  iterations_since_restore: 1073
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 9163.301195383072
  time_this_iter_s: 8.197320699691772
  time_total_s: 9163.301195383072
  timestamp: 1594867500
  timesteps_since_restore: 5365000
  timesteps_this_iter: 5000
  timesteps_total: 5365000
  training_iteration: 1073
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 9163 s, 1073 iter, 5365000 ts, -441 rew

agent-1: -399.9999999956487
agent-2: 0.34296875004196875
agent-3: 0.3429687499999998
agent-4: -399.9999999956487
agent-5: -399.9999999956487
Extrinsic Rewards:
0
4
4
0
0
Sum Reward: 8
Avg Reward: 1.6
Min Reward: 0
Max Reward: 4
Gini Coefficient: 0.6
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-45-09
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -452.6956249951397
  episode_reward_min: -1199.3140624869059
  episodes_this_iter: 1
  episodes_total: 1073
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.395
    dispatch_time_ms: 6.98
    learner:
      cur_lr: 0.001002690987661481
      grad_gnorm: 0.23776349425315857
      policy_entropy: 0.0017212119419127703
      policy_loss: -1.35962011427182e-07
      var_gnorm: 28.307044982910156
      vf_explained_var: 0.0
      vf_loss: 3.723915870068595e-05
    num_steps_sampled: 5370000
    num_steps_trained: 5370000
    wait_time_ms: 74.665
  iterations_since_restore: 1074
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 9171.49063873291
  time_this_iter_s: 8.189443349838257
  time_total_s: 9171.49063873291
  timestamp: 1594867509
  timesteps_since_restore: 5370000
  timesteps_this_iter: 5000
  timesteps_total: 5370000
  training_iteration: 1074
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 9171 s, 1074 iter, 5370000 ts, -453 rew

agent-1: -149.99999999840443
agent-2: -149.99999999840443
agent-3: -149.99999999840443
agent-4: -149.99999999840443
agent-5: 3.0
Extrinsic Rewards:
0
0
0
0
3
Sum Reward: 3
Avg Reward: 0.6
Min Reward: 0
Max Reward: 3
Gini Coefficient: 0.8
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-45-17
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -448.7106249951848
  episode_reward_min: -1199.3140624869059
  episodes_this_iter: 1
  episodes_total: 1074
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 3.043
    dispatch_time_ms: 6.781
    learner:
      cur_lr: 0.0010023580398410559
      grad_gnorm: 40.0
      policy_entropy: 0.0018287544371560216
      policy_loss: -3.47061941283755e-05
      var_gnorm: 28.333053588867188
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 3.056710720062256
    num_steps_sampled: 5375000
    num_steps_trained: 5375000
    wait_time_ms: 71.654
  iterations_since_restore: 1075
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 9179.670701265335
  time_this_iter_s: 8.180062532424927
  time_total_s: 9179.670701265335
  timestamp: 1594867517
  timesteps_since_restore: 5375000
  timesteps_this_iter: 5000
  timesteps_total: 5375000
  training_iteration: 1075
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 9179 s, 1075 iter, 5375000 ts, -449 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-45-25
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -448.7106249951847
  episode_reward_min: -1199.3140624869059
  episodes_this_iter: 1
  episodes_total: 1075
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.508
    dispatch_time_ms: 6.427
    learner:
      cur_lr: 0.001002024975605309
      grad_gnorm: 10.416199684143066
      policy_entropy: 0.0018128444207832217
      policy_loss: 7.889576409070287e-06
      var_gnorm: 28.310394287109375
      vf_explained_var: 1.1920928955078125e-07
      vf_loss: 0.07170581072568893
    num_steps_sampled: 5380000
    num_steps_trained: 5380000
    wait_time_ms: 77.203
  iterations_since_restore: 1076
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 9187.860050916672
  time_this_iter_s: 8.18934965133667
  time_total_s: 9187.860050916672
  timestamp: 1594867525
  timesteps_since_restore: 5380000
  timesteps_this_iter: 5000
  timesteps_total: 5380000
  training_iteration: 1076
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 9187 s, 1076 iter, 5380000 ts, -449 rew

agent-1: -199.99999999780377
agent-2: -199.99999999780377
agent-3: -199.99999999780377
agent-4: -199.99999999780377
agent-5: 4.0
Extrinsic Rewards:
0
0
0
0
4
Sum Reward: 4
Avg Reward: 0.8
Min Reward: 0
Max Reward: 4
Gini Coefficient: 0.8
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-45-33
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -452.6906249951389
  episode_reward_min: -1199.3140624869059
  episodes_this_iter: 1
  episodes_total: 1076
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.729
    dispatch_time_ms: 5.593
    learner:
      cur_lr: 0.001001692027784884
      grad_gnorm: 21.078407287597656
      policy_entropy: 0.0018596589798107743
      policy_loss: 9.708533980301581e-06
      var_gnorm: 28.31926727294922
      vf_explained_var: 1.1920928955078125e-07
      vf_loss: 0.2925630509853363
    num_steps_sampled: 5385000
    num_steps_trained: 5385000
    wait_time_ms: 72.057
  iterations_since_restore: 1077
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 9195.987284898758
  time_this_iter_s: 8.127233982086182
  time_total_s: 9195.987284898758
  timestamp: 1594867533
  timesteps_since_restore: 5385000
  timesteps_this_iter: 5000
  timesteps_total: 5385000
  training_iteration: 1077
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 9195 s, 1077 iter, 5385000 ts, -453 rew

agent-1: -199.99999999788645
agent-2: -199.99999999788645
agent-3: 0.75
agent-4: -199.99999999788645
agent-5: 0.7500000000136119
Extrinsic Rewards:
0
0
2
0
2
Sum Reward: 4
Avg Reward: 0.8
Min Reward: 0
Max Reward: 2
Gini Coefficient: 0.6
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-45-42
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -450.72562499516016
  episode_reward_min: -1199.3140624869059
  episodes_this_iter: 1
  episodes_total: 1077
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.962
    dispatch_time_ms: 8.357
    learner:
      cur_lr: 0.0010013589635491371
      grad_gnorm: 0.18983764946460724
      policy_entropy: 0.001809844863601029
      policy_loss: -1.8777751620291383e-07
      var_gnorm: 28.306623458862305
      vf_explained_var: 5.960464477539063e-08
      vf_loss: 2.373109782638494e-05
    num_steps_sampled: 5390000
    num_steps_trained: 5390000
    wait_time_ms: 70.273
  iterations_since_restore: 1078
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 9204.251024484634
  time_this_iter_s: 8.263739585876465
  time_total_s: 9204.251024484634
  timestamp: 1594867542
  timesteps_since_restore: 5390000
  timesteps_this_iter: 5000
  timesteps_total: 5390000
  training_iteration: 1078
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 9204 s, 1078 iter, 5390000 ts, -451 rew

agent-1: 3.0
agent-2: -149.99999999837684
agent-3: -149.99999999837684
agent-4: -149.99999999837684
agent-5: -149.99999999837684
Extrinsic Rewards:
3
0
0
0
0
Sum Reward: 3
Avg Reward: 0.6
Min Reward: 0
Max Reward: 3
Gini Coefficient: 0.8
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-45-50
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -454.705624995116
  episode_reward_min: -1199.3140624869059
  episodes_this_iter: 1
  episodes_total: 1078
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 3.354
    dispatch_time_ms: 7.188
    learner:
      cur_lr: 0.001001026015728712
      grad_gnorm: 20.11663818359375
      policy_entropy: 0.0019416153663769364
      policy_loss: 1.1064009413530584e-05
      var_gnorm: 28.33158302307129
      vf_explained_var: 1.1920928955078125e-07
      vf_loss: 0.2664744257926941
    num_steps_sampled: 5395000
    num_steps_trained: 5395000
    wait_time_ms: 73.131
  iterations_since_restore: 1079
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 9212.446695327759
  time_this_iter_s: 8.19567084312439
  time_total_s: 9212.446695327759
  timestamp: 1594867550
  timesteps_since_restore: 5395000
  timesteps_this_iter: 5000
  timesteps_total: 5395000
  training_iteration: 1079
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 9212 s, 1079 iter, 5395000 ts, -455 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-45-58
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -447.74499999519156
  episode_reward_min: -1199.3140624869059
  episodes_this_iter: 1
  episodes_total: 1079
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.529
    dispatch_time_ms: 8.359
    learner:
      cur_lr: 0.0010006929514929652
      grad_gnorm: 13.193188667297363
      policy_entropy: 0.0019491532584652305
      policy_loss: 1.058496673067566e-05
      var_gnorm: 28.30681037902832
      vf_explained_var: 0.0
      vf_loss: 0.11512752622365952
    num_steps_sampled: 5400000
    num_steps_trained: 5400000
    wait_time_ms: 72.163
  iterations_since_restore: 1080
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 9220.608045339584
  time_this_iter_s: 8.161350011825562
  time_total_s: 9220.608045339584
  timestamp: 1594867558
  timesteps_since_restore: 5400000
  timesteps_this_iter: 5000
  timesteps_total: 5400000
  training_iteration: 1080
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 9220 s, 1080 iter, 5400000 ts, -448 rew

agent-1: -299.9999999967528
agent-2: -299.9999999967528
agent-3: 4.0
agent-4: -97.99999999893765
agent-5: -299.9999999967528
Extrinsic Rewards:
0
0
4
2
0
Sum Reward: 6
Avg Reward: 1.2
Min Reward: 0
Max Reward: 4
Gini Coefficient: 0.6666666666666666
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-46-06
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -451.7149999951473
  episode_reward_min: -1199.3140624869059
  episodes_this_iter: 1
  episodes_total: 1080
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 3.342
    dispatch_time_ms: 8.979
    learner:
      cur_lr: 0.0010003600036725402
      grad_gnorm: 19.8536434173584
      policy_entropy: 0.0019904603250324726
      policy_loss: 1.1349928172421642e-05
      var_gnorm: 28.3118953704834
      vf_explained_var: 0.0
      vf_loss: 0.2595515251159668
    num_steps_sampled: 5405000
    num_steps_trained: 5405000
    wait_time_ms: 69.437
  iterations_since_restore: 1081
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 9228.718744277954
  time_this_iter_s: 8.110698938369751
  time_total_s: 9228.718744277954
  timestamp: 1594867566
  timesteps_since_restore: 5405000
  timesteps_this_iter: 5000
  timesteps_total: 5405000
  training_iteration: 1081
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 9228 s, 1081 iter, 5405000 ts, -452 rew

agent-1: 4.0
agent-2: -349.999999996264
agent-3: -97.9999999988953
agent-4: -198.99999999785896
agent-5: -349.999999996264
Extrinsic Rewards:
4
0
2
1
0
Sum Reward: 7
Avg Reward: 1.4
Min Reward: 0
Max Reward: 4
Gini Coefficient: 0.5714285714285714
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-46-14
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -461.6449999950401
  episode_reward_min: -1199.3140624869059
  episodes_this_iter: 1
  episodes_total: 1081
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 3.246
    dispatch_time_ms: 7.067
    learner:
      cur_lr: 0.0010000270558521152
      grad_gnorm: 14.368306159973145
      policy_entropy: 0.002037170808762312
      policy_loss: 9.781348126125522e-06
      var_gnorm: 28.315343856811523
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 0.13733850419521332
    num_steps_sampled: 5410000
    num_steps_trained: 5410000
    wait_time_ms: 77.213
  iterations_since_restore: 1082
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 9236.939999818802
  time_this_iter_s: 8.221255540847778
  time_total_s: 9236.939999818802
  timestamp: 1594867574
  timesteps_since_restore: 5410000
  timesteps_this_iter: 5000
  timesteps_total: 5410000
  training_iteration: 1082
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 9236 s, 1082 iter, 5410000 ts, -462 rew

agent-1: -299.9999999967948
agent-2: 4.0
agent-3: -97.9999999988953
agent-4: -299.9999999967948
agent-5: -299.9999999967948
Extrinsic Rewards:
0
4
2
0
0
Sum Reward: 6
Avg Reward: 1.2
Min Reward: 0
Max Reward: 4
Gini Coefficient: 0.6666666666666666
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-46-23
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -471.58499999493296
  episode_reward_min: -1199.3140624869059
  episodes_this_iter: 1
  episodes_total: 1082
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.693
    dispatch_time_ms: 6.119
    learner:
      cur_lr: 0.0009996939916163683
      grad_gnorm: 23.09131622314453
      policy_entropy: 0.0020926163997501135
      policy_loss: 1.4360310160554945e-05
      var_gnorm: 28.319910049438477
      vf_explained_var: 0.0
      vf_loss: 0.3511086702346802
    num_steps_sampled: 5415000
    num_steps_trained: 5415000
    wait_time_ms: 77.286
  iterations_since_restore: 1083
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 9245.143198251724
  time_this_iter_s: 8.203198432922363
  time_total_s: 9245.143198251724
  timestamp: 1594867583
  timesteps_since_restore: 5415000
  timesteps_this_iter: 5000
  timesteps_total: 5415000
  training_iteration: 1083
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 9245 s, 1083 iter, 5415000 ts, -472 rew

agent-1: -49.46874999939871
agent-2: -349.9999999962086
agent-3: -349.9999999962086
agent-4: -349.9999999962086
agent-5: 1.53125
Extrinsic Rewards:
3
0
0
0
4
Sum Reward: 7
Avg Reward: 1.4
Min Reward: 0
Max Reward: 4
Gini Coefficient: 0.6285714285714286
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-46-38
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -474.6081406198992
  episode_reward_min: -1199.3140624869059
  episodes_this_iter: 1
  episodes_total: 1083
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.735
    dispatch_time_ms: 6.068
    learner:
      cur_lr: 0.0009993610437959433
      grad_gnorm: 0.30343228578567505
      policy_entropy: 0.0019399152370169759
      policy_loss: 1.2679340954946383e-07
      var_gnorm: 28.304075241088867
      vf_explained_var: 0.0
      vf_loss: 6.0631886299233884e-05
    num_steps_sampled: 5420000
    num_steps_trained: 5420000
    wait_time_ms: 72.065
  iterations_since_restore: 1084
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 9260.900682926178
  time_this_iter_s: 15.757484674453735
  time_total_s: 9260.900682926178
  timestamp: 1594867598
  timesteps_since_restore: 5420000
  timesteps_this_iter: 5000
  timesteps_total: 5420000
  training_iteration: 1084
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 9260 s, 1084 iter, 5420000 ts, -475 rew

agent-1: 3.0
agent-2: -149.99999999837684
agent-3: -149.99999999837684
agent-4: -149.99999999837684
agent-5: -149.99999999837684
Extrinsic Rewards:
3
0
0
0
0
Sum Reward: 3
Avg Reward: 0.6
Min Reward: 0
Max Reward: 3
Gini Coefficient: 0.8
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-46-47
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -478.5881406198557
  episode_reward_min: -1199.3140624869059
  episodes_this_iter: 1
  episodes_total: 1084
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.755
    dispatch_time_ms: 7.351
    learner:
      cur_lr: 0.0009990279795601964
      grad_gnorm: 0.007479486055672169
      policy_entropy: 0.001986161572858691
      policy_loss: -5.7782112428128585e-09
      var_gnorm: 28.308382034301758
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 3.694418992949977e-08
    num_steps_sampled: 5425000
    num_steps_trained: 5425000
    wait_time_ms: 72.246
  iterations_since_restore: 1085
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 9269.088640451431
  time_this_iter_s: 8.187957525253296
  time_total_s: 9269.088640451431
  timestamp: 1594867607
  timesteps_since_restore: 5425000
  timesteps_this_iter: 5000
  timesteps_total: 5425000
  training_iteration: 1085
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 9269 s, 1085 iter, 5425000 ts, -479 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-46-55
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -472.6381406199187
  episode_reward_min: -1199.3140624869059
  episodes_this_iter: 1
  episodes_total: 1085
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.715
    dispatch_time_ms: 7.172
    learner:
      cur_lr: 0.0009986950317397714
      grad_gnorm: 0.00041685174801386893
      policy_entropy: 0.002046718494966626
      policy_loss: -9.68766289410894e-10
      var_gnorm: 28.31516456604004
      vf_explained_var: 0.0
      vf_loss: 1.205661126491009e-10
    num_steps_sampled: 5430000
    num_steps_trained: 5430000
    wait_time_ms: 70.672
  iterations_since_restore: 1086
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 9277.373094558716
  time_this_iter_s: 8.284454107284546
  time_total_s: 9277.373094558716
  timestamp: 1594867615
  timesteps_since_restore: 5430000
  timesteps_this_iter: 5000
  timesteps_total: 5430000
  training_iteration: 1086
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 9277 s, 1086 iter, 5430000 ts, -473 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-47-04
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -466.66814061998247
  episode_reward_min: -1199.3140624869059
  episodes_this_iter: 1
  episodes_total: 1086
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 3.268
    dispatch_time_ms: 49.615
    learner:
      cur_lr: 0.0009983619675040245
      grad_gnorm: 18.280132293701172
      policy_entropy: 0.03894021362066269
      policy_loss: 0.00043621379882097244
      var_gnorm: 28.45635414123535
      vf_explained_var: 0.0
      vf_loss: 0.22004257142543793
    num_steps_sampled: 5435000
    num_steps_trained: 5435000
    wait_time_ms: 32.851
  iterations_since_restore: 1087
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 9286.42474079132
  time_this_iter_s: 9.05164623260498
  time_total_s: 9286.42474079132
  timestamp: 1594867624
  timesteps_since_restore: 5435000
  timesteps_this_iter: 5000
  timesteps_total: 5435000
  training_iteration: 1087
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 9286 s, 1087 iter, 5435000 ts, -467 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-47-13
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -466.66814061998247
  episode_reward_min: -1199.3140624869059
  episodes_this_iter: 1
  episodes_total: 1087
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.848
    dispatch_time_ms: 6.575
    learner:
      cur_lr: 0.0009980290196835995
      grad_gnorm: 14.81677532196045
      policy_entropy: 0.0018348006997257471
      policy_loss: 1.2348064046818763e-05
      var_gnorm: 28.36270523071289
      vf_explained_var: 0.0
      vf_loss: 0.14596746861934662
    num_steps_sampled: 5440000
    num_steps_trained: 5440000
    wait_time_ms: 78.0
  iterations_since_restore: 1088
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 9294.933984041214
  time_this_iter_s: 8.509243249893188
  time_total_s: 9294.933984041214
  timestamp: 1594867633
  timesteps_since_restore: 5440000
  timesteps_this_iter: 5000
  timesteps_total: 5440000
  training_iteration: 1088
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 9294 s, 1088 iter, 5440000 ts, -467 rew

agent-1: -49.99999999946836
agent-2: -49.99999999946836
agent-3: -49.99999999946836
agent-4: 1.0
agent-5: -49.99999999946836
Extrinsic Rewards:
0
0
0
1
0
Sum Reward: 1
Avg Reward: 0.2
Min Reward: 0
Max Reward: 1
Gini Coefficient: 0.8
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-47-21
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -468.6581406199612
  episode_reward_min: -1199.3140624869059
  episodes_this_iter: 1
  episodes_total: 1088
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.777
    dispatch_time_ms: 8.951
    learner:
      cur_lr: 0.0009976959554478526
      grad_gnorm: 0.19848331809043884
      policy_entropy: 0.0017665988998487592
      policy_loss: 1.1350012130151299e-07
      var_gnorm: 28.36208152770996
      vf_explained_var: 1.1920928955078125e-07
      vf_loss: 2.5927163733285852e-05
    num_steps_sampled: 5445000
    num_steps_trained: 5445000
    wait_time_ms: 70.034
  iterations_since_restore: 1089
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 9303.136787176132
  time_this_iter_s: 8.202803134918213
  time_total_s: 9303.136787176132
  timestamp: 1594867641
  timesteps_since_restore: 5445000
  timesteps_this_iter: 5000
  timesteps_total: 5445000
  training_iteration: 1089
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 9303 s, 1089 iter, 5445000 ts, -469 rew

agent-1: -199.99999999788645
agent-2: -199.99999999788645
agent-3: -199.99999999788645
agent-4: -98.999999998923
agent-5: 3.0
Extrinsic Rewards:
0
0
0
1
3
Sum Reward: 4
Avg Reward: 0.8
Min Reward: 0
Max Reward: 3
Gini Coefficient: 0.7
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-47-29
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -473.6281406199077
  episode_reward_min: -1199.3140624869059
  episodes_this_iter: 1
  episodes_total: 1089
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 3.043
    dispatch_time_ms: 9.155
    learner:
      cur_lr: 0.0009973630076274276
      grad_gnorm: 16.273815155029297
      policy_entropy: 0.0019531799480319023
      policy_loss: 1.2016618711641058e-05
      var_gnorm: 28.36339569091797
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 0.17997781932353973
    num_steps_sampled: 5450000
    num_steps_trained: 5450000
    wait_time_ms: 68.357
  iterations_since_restore: 1090
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 9311.259010314941
  time_this_iter_s: 8.122223138809204
  time_total_s: 9311.259010314941
  timestamp: 1594867649
  timesteps_since_restore: 5450000
  timesteps_this_iter: 5000
  timesteps_total: 5450000
  training_iteration: 1090
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 9311 s, 1090 iter, 5450000 ts, -474 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-47-37
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -466.67814061998183
  episode_reward_min: -1199.3140624869059
  episodes_this_iter: 1
  episodes_total: 1090
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.774
    dispatch_time_ms: 7.006
    learner:
      cur_lr: 0.0009970299433916807
      grad_gnorm: 26.816377639770508
      policy_entropy: 0.0020375687163323164
      policy_loss: 1.7628701243666e-05
      var_gnorm: 28.364221572875977
      vf_explained_var: 0.0
      vf_loss: 0.4735274910926819
    num_steps_sampled: 5455000
    num_steps_trained: 5455000
    wait_time_ms: 71.819
  iterations_since_restore: 1091
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 9319.482692241669
  time_this_iter_s: 8.223681926727295
  time_total_s: 9319.482692241669
  timestamp: 1594867657
  timesteps_since_restore: 5455000
  timesteps_this_iter: 5000
  timesteps_total: 5455000
  training_iteration: 1091
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 9319 s, 1091 iter, 5455000 ts, -467 rew

agent-1: -47.99999999945478
agent-2: -249.99999999735493
agent-3: 3.0
agent-4: -249.99999999735493
agent-5: -249.99999999735493
Extrinsic Rewards:
2
0
3
0
0
Sum Reward: 5
Avg Reward: 1.0
Min Reward: 0
Max Reward: 3
Gini Coefficient: 0.64
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-47-45
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -466.67814061998183
  episode_reward_min: -1199.3140624869059
  episodes_this_iter: 1
  episodes_total: 1091
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 3.151
    dispatch_time_ms: 7.783
    learner:
      cur_lr: 0.0009966969955712557
      grad_gnorm: 18.377079010009766
      policy_entropy: 0.0020317742601037025
      policy_loss: 1.3606616448669229e-05
      var_gnorm: 28.363739013671875
      vf_explained_var: 0.0
      vf_loss: 0.22237856686115265
    num_steps_sampled: 5460000
    num_steps_trained: 5460000
    wait_time_ms: 73.864
  iterations_since_restore: 1092
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 9327.669215917587
  time_this_iter_s: 8.186523675918579
  time_total_s: 9327.669215917587
  timestamp: 1594867665
  timesteps_since_restore: 5460000
  timesteps_this_iter: 5000
  timesteps_total: 5460000
  training_iteration: 1092
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 9327 s, 1092 iter, 5460000 ts, -467 rew

agent-1: -299.999999996808
agent-2: -148.9999999983636
agent-3: -49.249999999427196
agent-4: -299.999999996808
agent-5: 1.75
Extrinsic Rewards:
0
1
2
0
3
Sum Reward: 6
Avg Reward: 1.2
Min Reward: 0
Max Reward: 3
Gini Coefficient: 0.5333333333333333
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-47-54
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -474.6431406198959
  episode_reward_min: -1199.3140624869059
  episodes_this_iter: 1
  episodes_total: 1092
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.825
    dispatch_time_ms: 7.223
    learner:
      cur_lr: 0.0009963640477508307
      grad_gnorm: 9.534390449523926
      policy_entropy: 0.002120553981512785
      policy_loss: 6.483984179794788e-06
      var_gnorm: 28.364656448364258
      vf_explained_var: 5.960464477539063e-08
      vf_loss: 0.14148083329200745
    num_steps_sampled: 5465000
    num_steps_trained: 5465000
    wait_time_ms: 72.454
  iterations_since_restore: 1093
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 9335.795420408249
  time_this_iter_s: 8.126204490661621
  time_total_s: 9335.795420408249
  timestamp: 1594867674
  timesteps_since_restore: 5465000
  timesteps_this_iter: 5000
  timesteps_total: 5465000
  training_iteration: 1093
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 9335 s, 1093 iter, 5465000 ts, -475 rew

agent-1: -48.99999999948169
agent-2: -149.99999999841847
agent-3: -149.99999999841847
agent-4: -149.99999999841847
agent-5: 2.0
Extrinsic Rewards:
1
0
0
0
2
Sum Reward: 3
Avg Reward: 0.6
Min Reward: 0
Max Reward: 2
Gini Coefficient: 0.6666666666666666
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-48-02
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -469.67314061995035
  episode_reward_min: -1199.3140624869059
  episodes_this_iter: 1
  episodes_total: 1093
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.631
    dispatch_time_ms: 7.799
    learner:
      cur_lr: 0.0009960309835150838
      grad_gnorm: 14.137260437011719
      policy_entropy: 0.002134154085069895
      policy_loss: 1.1202000678167678e-05
      var_gnorm: 28.364288330078125
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 0.13242289423942566
    num_steps_sampled: 5470000
    num_steps_trained: 5470000
    wait_time_ms: 74.481
  iterations_since_restore: 1094
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 9343.981942653656
  time_this_iter_s: 8.186522245407104
  time_total_s: 9343.981942653656
  timestamp: 1594867682
  timesteps_since_restore: 5470000
  timesteps_this_iter: 5000
  timesteps_total: 5470000
  training_iteration: 1094
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 9343 s, 1094 iter, 5470000 ts, -470 rew

agent-1: -249.99999999735493
agent-2: -249.99999999735493
agent-3: 3.0
agent-4: -249.99999999735493
agent-5: -47.99999999945478
Extrinsic Rewards:
0
0
3
0
2
Sum Reward: 5
Avg Reward: 1.0
Min Reward: 0
Max Reward: 3
Gini Coefficient: 0.64
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-48-10
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -470.6631406199398
  episode_reward_min: -1199.3140624869059
  episodes_this_iter: 1
  episodes_total: 1094
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.684
    dispatch_time_ms: 9.424
    learner:
      cur_lr: 0.0009956980356946588
      grad_gnorm: 9.415399551391602
      policy_entropy: 0.002288738964125514
      policy_loss: 7.356244168477133e-06
      var_gnorm: 28.365461349487305
      vf_explained_var: 5.960464477539063e-08
      vf_loss: 0.14002494513988495
    num_steps_sampled: 5475000
    num_steps_trained: 5475000
    wait_time_ms: 70.418
  iterations_since_restore: 1095
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 9352.112258672714
  time_this_iter_s: 8.130316019058228
  time_total_s: 9352.112258672714
  timestamp: 1594867690
  timesteps_since_restore: 5475000
  timesteps_this_iter: 5000
  timesteps_total: 5475000
  training_iteration: 1095
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 9352 s, 1095 iter, 5475000 ts, -471 rew

agent-1: 2.0
agent-2: -99.99999999894987
agent-3: -99.99999999894987
agent-4: -99.99999999894987
agent-5: -99.99999999894987
Extrinsic Rewards:
2
0
0
0
0
Sum Reward: 2
Avg Reward: 0.4
Min Reward: 0
Max Reward: 2
Gini Coefficient: 0.8
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-48-18
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -468.67314061996154
  episode_reward_min: -1199.3140624869059
  episodes_this_iter: 1
  episodes_total: 1095
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.713
    dispatch_time_ms: 7.967
    learner:
      cur_lr: 0.000995364971458912
      grad_gnorm: 0.033569227904081345
      policy_entropy: 0.002056869911029935
      policy_loss: -2.193843506859139e-08
      var_gnorm: 28.36394691467285
      vf_explained_var: 5.960464477539063e-08
      vf_loss: 7.429982815665426e-07
    num_steps_sampled: 5480000
    num_steps_trained: 5480000
    wait_time_ms: 71.091
  iterations_since_restore: 1096
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 9360.364725112915
  time_this_iter_s: 8.252466440200806
  time_total_s: 9360.364725112915
  timestamp: 1594867698
  timesteps_since_restore: 5480000
  timesteps_this_iter: 5000
  timesteps_total: 5480000
  training_iteration: 1096
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 9360 s, 1096 iter, 5480000 ts, -469 rew

agent-1: -249.99999999735493
agent-2: -47.99999999945478
agent-3: -249.99999999735493
agent-4: 3.0
agent-5: -249.99999999735493
Extrinsic Rewards:
0
2
0
3
0
Sum Reward: 5
Avg Reward: 1.0
Min Reward: 0
Max Reward: 3
Gini Coefficient: 0.64
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-48-27
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -465.7131406199949
  episode_reward_min: -1199.3140624869059
  episodes_this_iter: 1
  episodes_total: 1096
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 3.031
    dispatch_time_ms: 7.888
    learner:
      cur_lr: 0.0009950320236384869
      grad_gnorm: 22.255535125732422
      policy_entropy: 0.002496106084436178
      policy_loss: 1.979853550437838e-05
      var_gnorm: 28.366012573242188
      vf_explained_var: 1.7881393432617188e-07
      vf_loss: 0.32615047693252563
    num_steps_sampled: 5485000
    num_steps_trained: 5485000
    wait_time_ms: 75.08
  iterations_since_restore: 1097
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 9368.560174703598
  time_this_iter_s: 8.195449590682983
  time_total_s: 9368.560174703598
  timestamp: 1594867707
  timesteps_since_restore: 5485000
  timesteps_this_iter: 5000
  timesteps_total: 5485000
  training_iteration: 1097
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 9368 s, 1097 iter, 5485000 ts, -466 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-48-35
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -465.7131406199948
  episode_reward_min: -1199.3140624869059
  episodes_this_iter: 1
  episodes_total: 1097
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.628
    dispatch_time_ms: 8.143
    learner:
      cur_lr: 0.00099469895940274
      grad_gnorm: 16.8795166015625
      policy_entropy: 0.002561737084761262
      policy_loss: 1.6567571947234683e-05
      var_gnorm: 28.36638641357422
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 0.18979328870773315
    num_steps_sampled: 5490000
    num_steps_trained: 5490000
    wait_time_ms: 70.246
  iterations_since_restore: 1098
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 9376.842829227448
  time_this_iter_s: 8.282654523849487
  time_total_s: 9376.842829227448
  timestamp: 1594867715
  timesteps_since_restore: 5490000
  timesteps_this_iter: 5000
  timesteps_total: 5490000
  training_iteration: 1098
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 9376 s, 1098 iter, 5490000 ts, -466 rew

agent-1: -99.99999999894987
agent-2: 2.0
agent-3: -99.99999999894987
agent-4: -99.99999999894987
agent-5: -99.99999999894987
Extrinsic Rewards:
0
2
0
0
0
Sum Reward: 2
Avg Reward: 0.4
Min Reward: 0
Max Reward: 2
Gini Coefficient: 0.8
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-48-43
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -458.76314062007094
  episode_reward_min: -1199.3140624869059
  episodes_this_iter: 1
  episodes_total: 1098
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.428
    dispatch_time_ms: 8.306
    learner:
      cur_lr: 0.000994366011582315
      grad_gnorm: 15.46184253692627
      policy_entropy: 0.0026322118937969208
      policy_loss: 1.4582923540729098e-05
      var_gnorm: 28.366899490356445
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 0.16248925030231476
    num_steps_sampled: 5495000
    num_steps_trained: 5495000
    wait_time_ms: 71.67
  iterations_since_restore: 1099
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 9385.016535282135
  time_this_iter_s: 8.1737060546875
  time_total_s: 9385.016535282135
  timestamp: 1594867723
  timesteps_since_restore: 5495000
  timesteps_this_iter: 5000
  timesteps_total: 5495000
  training_iteration: 1099
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 9385 s, 1099 iter, 5495000 ts, -459 rew

agent-1: -149.99999999840443
agent-2: -149.99999999840443
agent-3: -149.99999999840443
agent-4: -149.99999999840443
agent-5: 3.0
Extrinsic Rewards:
0
0
0
0
3
Sum Reward: 3
Avg Reward: 0.6
Min Reward: 0
Max Reward: 3
Gini Coefficient: 0.8
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-48-51
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -462.743140620028
  episode_reward_min: -1199.3140624869059
  episodes_this_iter: 1
  episodes_total: 1099
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.905
    dispatch_time_ms: 7.532
    learner:
      cur_lr: 0.000994032947346568
      grad_gnorm: 21.725383758544922
      policy_entropy: 0.0027484388556331396
      policy_loss: 2.2033242203178816e-05
      var_gnorm: 28.36745262145996
      vf_explained_var: 0.0
      vf_loss: 0.3107987940311432
    num_steps_sampled: 5500000
    num_steps_trained: 5500000
    wait_time_ms: 71.347
  iterations_since_restore: 1100
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 9393.125801801682
  time_this_iter_s: 8.109266519546509
  time_total_s: 9393.125801801682
  timestamp: 1594867731
  timesteps_since_restore: 5500000
  timesteps_this_iter: 5000
  timesteps_total: 5500000
  training_iteration: 1100
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 9393 s, 1100 iter, 5500000 ts, -463 rew

agent-1: 2.0
agent-2: -99.99999999894987
agent-3: -99.99999999894987
agent-4: -99.99999999894987
agent-5: -99.99999999894987
Extrinsic Rewards:
2
0
0
0
0
Sum Reward: 2
Avg Reward: 0.4
Min Reward: 0
Max Reward: 2
Gini Coefficient: 0.8
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-48-59
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -461.75314062003855
  episode_reward_min: -1199.3140624869059
  episodes_this_iter: 1
  episodes_total: 1100
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.986
    dispatch_time_ms: 10.158
    learner:
      cur_lr: 0.000993699999526143
      grad_gnorm: 23.99839210510254
      policy_entropy: 0.0029009298887103796
      policy_loss: 2.4534874683013186e-05
      var_gnorm: 28.368284225463867
      vf_explained_var: 0.0
      vf_loss: 0.37923604249954224
    num_steps_sampled: 5505000
    num_steps_trained: 5505000
    wait_time_ms: 69.96
  iterations_since_restore: 1101
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 9401.3180372715
  time_this_iter_s: 8.192235469818115
  time_total_s: 9401.3180372715
  timestamp: 1594867739
  timesteps_since_restore: 5505000
  timesteps_this_iter: 5000
  timesteps_total: 5505000
  training_iteration: 1101
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 9401 s, 1101 iter, 5505000 ts, -462 rew

agent-1: -149.99999999840443
agent-2: -149.99999999840443
agent-3: -149.99999999840443
agent-4: -149.99999999840443
agent-5: 3.0
Extrinsic Rewards:
0
0
0
0
3
Sum Reward: 3
Avg Reward: 0.6
Min Reward: 0
Max Reward: 3
Gini Coefficient: 0.8
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-49-11
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -467.72314061997486
  episode_reward_min: -1199.3140624869059
  episodes_this_iter: 1
  episodes_total: 1101
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.872
    dispatch_time_ms: 6.413
    learner:
      cur_lr: 0.000993367051705718
      grad_gnorm: 0.11058388650417328
      policy_entropy: 0.002348591573536396
      policy_loss: -1.40829612860216e-07
      var_gnorm: 28.366127014160156
      vf_explained_var: 0.0
      vf_loss: 8.044564310694113e-06
    num_steps_sampled: 5510000
    num_steps_trained: 5510000
    wait_time_ms: 338.821
  iterations_since_restore: 1102
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 9412.787019729614
  time_this_iter_s: 11.468982458114624
  time_total_s: 9412.787019729614
  timestamp: 1594867751
  timesteps_since_restore: 5510000
  timesteps_this_iter: 5000
  timesteps_total: 5510000
  training_iteration: 1102
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 9412 s, 1102 iter, 5510000 ts, -468 rew

agent-1: -199.99999999784504
agent-2: 4.0
agent-3: -199.99999999784504
agent-4: -199.99999999784504
agent-5: -199.99999999784504
Extrinsic Rewards:
0
4
0
0
0
Sum Reward: 4
Avg Reward: 0.8
Min Reward: 0
Max Reward: 4
Gini Coefficient: 0.8
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-49-19
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -475.6831406198887
  episode_reward_min: -1199.3140624869059
  episodes_this_iter: 1
  episodes_total: 1102
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.549
    dispatch_time_ms: 5.419
    learner:
      cur_lr: 0.0009930339874699712
      grad_gnorm: 0.001423633424565196
      policy_entropy: 0.0025600953958928585
      policy_loss: 1.2016333483799713e-09
      var_gnorm: 28.366840362548828
      vf_explained_var: 0.0
      vf_loss: 1.2951837380370534e-09
    num_steps_sampled: 5515000
    num_steps_trained: 5515000
    wait_time_ms: 71.531
  iterations_since_restore: 1103
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 9420.454845666885
  time_this_iter_s: 7.667825937271118
  time_total_s: 9420.454845666885
  timestamp: 1594867759
  timesteps_since_restore: 5515000
  timesteps_this_iter: 5000
  timesteps_total: 5515000
  training_iteration: 1103
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 9420 s, 1103 iter, 5515000 ts, -476 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-49-28
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -468.72314061996593
  episode_reward_min: -1199.3140624869059
  episodes_this_iter: 1
  episodes_total: 1103
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.918
    dispatch_time_ms: 17.854
    learner:
      cur_lr: 0.0009927010396495461
      grad_gnorm: 20.465761184692383
      policy_entropy: 0.003911471925675869
      policy_loss: 2.2163178073242307e-05
      var_gnorm: 28.370864868164062
      vf_explained_var: 0.0
      vf_loss: 0.27580526471138
    num_steps_sampled: 5520000
    num_steps_trained: 5520000
    wait_time_ms: 60.844
  iterations_since_restore: 1104
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 9428.94023156166
  time_this_iter_s: 8.48538589477539
  time_total_s: 9428.94023156166
  timestamp: 1594867768
  timesteps_since_restore: 5520000
  timesteps_this_iter: 5000
  timesteps_total: 5520000
  training_iteration: 1104
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 9428 s, 1104 iter, 5520000 ts, -469 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-49-36
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -462.7531406200297
  episode_reward_min: -1199.3140624869059
  episodes_this_iter: 1
  episodes_total: 1104
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.623
    dispatch_time_ms: 19.796
    learner:
      cur_lr: 0.0009923679754137993
      grad_gnorm: 0.16278856992721558
      policy_entropy: 0.002937160199508071
      policy_loss: 1.3552786981563258e-07
      var_gnorm: 28.368194580078125
      vf_explained_var: 0.0
      vf_loss: 1.7440568626625463e-05
    num_steps_sampled: 5525000
    num_steps_trained: 5525000
    wait_time_ms: 63.895
  iterations_since_restore: 1105
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 9437.44215297699
  time_this_iter_s: 8.50192141532898
  time_total_s: 9437.44215297699
  timestamp: 1594867776
  timesteps_since_restore: 5525000
  timesteps_this_iter: 5000
  timesteps_total: 5525000
  training_iteration: 1105
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 9437 s, 1105 iter, 5525000 ts, -463 rew

agent-1: -49.999999999481645
agent-2: -49.999999999481645
agent-3: -49.999999999481645
agent-4: -49.999999999481645
agent-5: 1.0
Extrinsic Rewards:
0
0
0
0
1
Sum Reward: 1
Avg Reward: 0.2
Min Reward: 0
Max Reward: 1
Gini Coefficient: 0.8
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-49-45
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -455.79314062010707
  episode_reward_min: -1199.3140624869059
  episodes_this_iter: 1
  episodes_total: 1105
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.873
    dispatch_time_ms: 29.427
    learner:
      cur_lr: 0.0009920350275933743
      grad_gnorm: 16.825733184814453
      policy_entropy: 0.00028019535238854587
      policy_loss: 1.5690243344579358e-06
      var_gnorm: 28.384599685668945
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 0.1981484293937683
    num_steps_sampled: 5530000
    num_steps_trained: 5530000
    wait_time_ms: 60.69
  iterations_since_restore: 1106
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 9446.087445735931
  time_this_iter_s: 8.64529275894165
  time_total_s: 9446.087445735931
  timestamp: 1594867785
  timesteps_since_restore: 5530000
  timesteps_this_iter: 5000
  timesteps_total: 5530000
  training_iteration: 1106
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 9446 s, 1106 iter, 5530000 ts, -456 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-49-54
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -451.8131406201491
  episode_reward_min: -1199.3140624869059
  episodes_this_iter: 1
  episodes_total: 1106
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 4.37
    dispatch_time_ms: 49.196
    learner:
      cur_lr: 0.0009917019633576274
      grad_gnorm: 11.873374938964844
      policy_entropy: 7.246316090459004e-05
      policy_loss: -0.0
      var_gnorm: 28.39236068725586
      vf_explained_var: 1.1920928955078125e-07
      vf_loss: 0.1336960345506668
    num_steps_sampled: 5535000
    num_steps_trained: 5535000
    wait_time_ms: 53.404
  iterations_since_restore: 1107
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 9454.972725629807
  time_this_iter_s: 8.885279893875122
  time_total_s: 9454.972725629807
  timestamp: 1594867794
  timesteps_since_restore: 5535000
  timesteps_this_iter: 5000
  timesteps_total: 5535000
  training_iteration: 1107
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 9454 s, 1107 iter, 5535000 ts, -452 rew

agent-1: -49.999999999481645
agent-2: -49.999999999481645
agent-3: -49.999999999481645
agent-4: 1.0
agent-5: -49.999999999481645
Extrinsic Rewards:
0
0
0
1
0
Sum Reward: 1
Avg Reward: 0.2
Min Reward: 0
Max Reward: 1
Gini Coefficient: 0.8
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-50-02
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -447.8181406201919
  episode_reward_min: -1199.3140624869059
  episodes_this_iter: 1
  episodes_total: 1107
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.878
    dispatch_time_ms: 40.644
    learner:
      cur_lr: 0.0009913690155372024
      grad_gnorm: 21.06595802307129
      policy_entropy: 7.194593490567058e-05
      policy_loss: -0.0
      var_gnorm: 28.39213752746582
      vf_explained_var: 0.0
      vf_loss: 0.9037741422653198
    num_steps_sampled: 5540000
    num_steps_trained: 5540000
    wait_time_ms: 47.737
  iterations_since_restore: 1108
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 9463.468861579895
  time_this_iter_s: 8.496135950088501
  time_total_s: 9463.468861579895
  timestamp: 1594867802
  timesteps_since_restore: 5540000
  timesteps_this_iter: 5000
  timesteps_total: 5540000
  training_iteration: 1108
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 9463 s, 1108 iter, 5540000 ts, -448 rew

agent-1: -449.9999999951579
agent-2: 0.28125
agent-3: -449.9999999951579
agent-4: -149.2499999983085
agent-5: -49.46874999939871
Extrinsic Rewards:
0
4
0
2
3
Sum Reward: 9
Avg Reward: 1.8
Min Reward: 0
Max Reward: 4
Gini Coefficient: 0.4888888888888889
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-50-11
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -455.7825156201037
  episode_reward_min: -1199.3140624869059
  episodes_this_iter: 1
  episodes_total: 1108
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.794
    dispatch_time_ms: 29.819
    learner:
      cur_lr: 0.0009910359513014555
      grad_gnorm: 14.093097686767578
      policy_entropy: 7.321655721170828e-05
      policy_loss: -0.0
      var_gnorm: 28.39250373840332
      vf_explained_var: 0.0
      vf_loss: 0.131539985537529
    num_steps_sampled: 5545000
    num_steps_trained: 5545000
    wait_time_ms: 52.342
  iterations_since_restore: 1109
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 9472.127175569534
  time_this_iter_s: 8.658313989639282
  time_total_s: 9472.127175569534
  timestamp: 1594867811
  timesteps_since_restore: 5545000
  timesteps_this_iter: 5000
  timesteps_total: 5545000
  training_iteration: 1109
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 9472 s, 1109 iter, 5545000 ts, -456 rew

agent-1: -249.99999999731412
agent-2: -249.99999999731412
agent-3: -148.99999999837678
agent-4: -249.99999999731412
agent-5: 4.0
Extrinsic Rewards:
0
0
1
0
4
Sum Reward: 5
Avg Reward: 1.0
Min Reward: 0
Max Reward: 4
Gini Coefficient: 0.72
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-50-20
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -455.75251562010374
  episode_reward_min: -1199.3140624869059
  episodes_this_iter: 1
  episodes_total: 1109
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.641
    dispatch_time_ms: 22.65
    learner:
      cur_lr: 0.0009907030034810305
      grad_gnorm: 19.22694206237793
      policy_entropy: 7.327883213292807e-05
      policy_loss: -0.0
      var_gnorm: 28.392717361450195
      vf_explained_var: 1.1920928955078125e-07
      vf_loss: 0.2434241622686386
    num_steps_sampled: 5550000
    num_steps_trained: 5550000
    wait_time_ms: 68.713
  iterations_since_restore: 1110
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 9480.904675722122
  time_this_iter_s: 8.77750015258789
  time_total_s: 9480.904675722122
  timestamp: 1594867820
  timesteps_since_restore: 5550000
  timesteps_this_iter: 5000
  timesteps_total: 5550000
  training_iteration: 1110
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 9480 s, 1110 iter, 5550000 ts, -456 rew

agent-1: -349.99999999625004
agent-2: -349.99999999625004
agent-3: -349.99999999625004
agent-4: -46.99999999944068
agent-5: 4.0
Extrinsic Rewards:
0
0
0
3
4
Sum Reward: 7
Avg Reward: 1.4
Min Reward: 0
Max Reward: 4
Gini Coefficient: 0.6285714285714286
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-50-29
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -462.7025156200276
  episode_reward_min: -1199.3140624869059
  episodes_this_iter: 1
  episodes_total: 1110
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 3.105
    dispatch_time_ms: 14.492
    learner:
      cur_lr: 0.0009903700556606054
      grad_gnorm: 0.22953642904758453
      policy_entropy: 7.14669658918865e-05
      policy_loss: -0.0
      var_gnorm: 28.391332626342773
      vf_explained_var: 0.0
      vf_loss: 3.4703236451605335e-05
    num_steps_sampled: 5555000
    num_steps_trained: 5555000
    wait_time_ms: 87.017
  iterations_since_restore: 1111
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 9489.818405389786
  time_this_iter_s: 8.913729667663574
  time_total_s: 9489.818405389786
  timestamp: 1594867829
  timesteps_since_restore: 5555000
  timesteps_this_iter: 5000
  timesteps_total: 5555000
  training_iteration: 1111
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 9489 s, 1111 iter, 5555000 ts, -463 rew

agent-1: 2.0
agent-2: -149.99999999841847
agent-3: -48.99999999948169
agent-4: -149.99999999841847
agent-5: -149.99999999841847
Extrinsic Rewards:
2
0
1
0
0
Sum Reward: 3
Avg Reward: 0.6
Min Reward: 0
Max Reward: 2
Gini Coefficient: 0.6666666666666666
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-50-45
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -461.68751562003854
  episode_reward_min: -1199.3140624869059
  episodes_this_iter: 1
  episodes_total: 1111
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.866
    dispatch_time_ms: 6.076
    learner:
      cur_lr: 0.0009900369914248586
      grad_gnorm: 14.17949390411377
      policy_entropy: 7.411684782709926e-05
      policy_loss: -0.0
      var_gnorm: 28.392770767211914
      vf_explained_var: 0.0
      vf_loss: 0.1323932707309723
    num_steps_sampled: 5560000
    num_steps_trained: 5560000
    wait_time_ms: 72.676
  iterations_since_restore: 1112
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 9506.384988307953
  time_this_iter_s: 16.566582918167114
  time_total_s: 9506.384988307953
  timestamp: 1594867845
  timesteps_since_restore: 5560000
  timesteps_this_iter: 5000
  timesteps_total: 5560000
  training_iteration: 1112
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 9506 s, 1112 iter, 5560000 ts, -462 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-50-54
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -461.68751562003854
  episode_reward_min: -1199.3140624869059
  episodes_this_iter: 1
  episodes_total: 1112
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.871
    dispatch_time_ms: 7.711
    learner:
      cur_lr: 0.0009897040436044335
      grad_gnorm: 13.979718208312988
      policy_entropy: 7.57718735258095e-05
      policy_loss: -0.0
      var_gnorm: 28.393434524536133
      vf_explained_var: 0.0
      vf_loss: 0.12868891656398773
    num_steps_sampled: 5565000
    num_steps_trained: 5565000
    wait_time_ms: 72.323
  iterations_since_restore: 1113
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 9514.611225128174
  time_this_iter_s: 8.226236820220947
  time_total_s: 9514.611225128174
  timestamp: 1594867854
  timesteps_since_restore: 5565000
  timesteps_this_iter: 5000
  timesteps_total: 5565000
  training_iteration: 1113
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 9514 s, 1113 iter, 5565000 ts, -462 rew

agent-1: -149.03124999839068
agent-2: -299.9999999967949
agent-3: -299.9999999967949
agent-4: -49.249999999427196
agent-5: 1.71875
Extrinsic Rewards:
1
0
0
2
3
Sum Reward: 6
Avg Reward: 1.2
Min Reward: 0
Max Reward: 3
Gini Coefficient: 0.5333333333333333
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-51-02
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -469.65314061995264
  episode_reward_min: -1199.3140624869059
  episodes_this_iter: 1
  episodes_total: 1113
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 3.254
    dispatch_time_ms: 7.986
    learner:
      cur_lr: 0.0009893709793686867
      grad_gnorm: 21.17594337463379
      policy_entropy: 7.71678242017515e-05
      policy_loss: -0.0
      var_gnorm: 28.394384384155273
      vf_explained_var: 0.0
      vf_loss: 0.29527661204338074
    num_steps_sampled: 5570000
    num_steps_trained: 5570000
    wait_time_ms: 71.886
  iterations_since_restore: 1114
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 9522.778295993805
  time_this_iter_s: 8.167070865631104
  time_total_s: 9522.778295993805
  timestamp: 1594867862
  timesteps_since_restore: 5570000
  timesteps_this_iter: 5000
  timesteps_total: 5570000
  training_iteration: 1114
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 9522 s, 1114 iter, 5570000 ts, -470 rew

agent-1: -148.99999999847398
agent-2: -299.9999999967948
agent-3: -299.9999999967948
agent-4: 3.0
agent-5: -47.99999999945478
Extrinsic Rewards:
1
0
0
3
2
Sum Reward: 6
Avg Reward: 1.2
Min Reward: 0
Max Reward: 3
Gini Coefficient: 0.5333333333333333
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-51-10
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -471.60814061993136
  episode_reward_min: -1199.3140624869059
  episodes_this_iter: 1
  episodes_total: 1114
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 3.418
    dispatch_time_ms: 8.288
    learner:
      cur_lr: 0.0009890380315482616
      grad_gnorm: 11.285345077514648
      policy_entropy: 7.822891348041594e-05
      policy_loss: -0.0
      var_gnorm: 28.394302368164062
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 0.08386147022247314
    num_steps_sampled: 5575000
    num_steps_trained: 5575000
    wait_time_ms: 69.308
  iterations_since_restore: 1115
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 9531.023294210434
  time_this_iter_s: 8.244998216629028
  time_total_s: 9531.023294210434
  timestamp: 1594867870
  timesteps_since_restore: 5575000
  timesteps_this_iter: 5000
  timesteps_total: 5575000
  training_iteration: 1115
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 9531 s, 1115 iter, 5575000 ts, -472 rew

agent-1: -248.99999999730042
agent-2: -449.99999999522805
agent-3: -97.9999999988953
agent-4: -97.9999999988953
agent-5: 4.0
Extrinsic Rewards:
1
0
2
2
4
Sum Reward: 9
Avg Reward: 1.8
Min Reward: 0
Max Reward: 4
Gini Coefficient: 0.4
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-51-18
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -475.54814061988696
  episode_reward_min: -1199.3140624869059
  episodes_this_iter: 1
  episodes_total: 1115
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.574
    dispatch_time_ms: 6.714
    learner:
      cur_lr: 0.0009887049673125148
      grad_gnorm: 19.386409759521484
      policy_entropy: 8.025894203456119e-05
      policy_loss: -0.0
      var_gnorm: 28.39541244506836
      vf_explained_var: 0.0
      vf_loss: 0.24747824668884277
    num_steps_sampled: 5580000
    num_steps_trained: 5580000
    wait_time_ms: 70.825
  iterations_since_restore: 1116
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 9539.214289188385
  time_this_iter_s: 8.19099497795105
  time_total_s: 9539.214289188385
  timestamp: 1594867878
  timesteps_since_restore: 5580000
  timesteps_this_iter: 5000
  timesteps_total: 5580000
  training_iteration: 1116
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 9539 s, 1116 iter, 5580000 ts, -476 rew

agent-1: 3.0
agent-2: -149.99999999840443
agent-3: -149.99999999840443
agent-4: -149.99999999840443
agent-5: -149.99999999840443
Extrinsic Rewards:
3
0
0
0
0
Sum Reward: 3
Avg Reward: 0.6
Min Reward: 0
Max Reward: 3
Gini Coefficient: 0.8
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-51-27
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -475.5481406198869
  episode_reward_min: -1199.3140624869059
  episodes_this_iter: 1
  episodes_total: 1116
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.517
    dispatch_time_ms: 5.202
    learner:
      cur_lr: 0.0009883720194920897
      grad_gnorm: 15.421048164367676
      policy_entropy: 8.19805427454412e-05
      policy_loss: -0.0
      var_gnorm: 28.39579963684082
      vf_explained_var: 0.0
      vf_loss: 0.1565937101840973
    num_steps_sampled: 5585000
    num_steps_trained: 5585000
    wait_time_ms: 78.787
  iterations_since_restore: 1117
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 9547.500734329224
  time_this_iter_s: 8.286445140838623
  time_total_s: 9547.500734329224
  timestamp: 1594867887
  timesteps_since_restore: 5585000
  timesteps_this_iter: 5000
  timesteps_total: 5585000
  training_iteration: 1117
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 9547 s, 1117 iter, 5585000 ts, -476 rew

agent-1: -49.999999999481645
agent-2: -49.999999999481645
agent-3: -49.999999999481645
agent-4: -49.999999999481645
agent-5: 1.0
Extrinsic Rewards:
0
0
0
0
1
Sum Reward: 1
Avg Reward: 0.2
Min Reward: 0
Max Reward: 1
Gini Coefficient: 0.8
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-51-35
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -477.5381406198662
  episode_reward_min: -1199.3140624869059
  episodes_this_iter: 1
  episodes_total: 1117
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.839
    dispatch_time_ms: 7.299
    learner:
      cur_lr: 0.0009880389552563429
      grad_gnorm: 0.20771118998527527
      policy_entropy: 8.052097109612077e-05
      policy_loss: -0.0
      var_gnorm: 28.3948917388916
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 2.8412485335138626e-05
    num_steps_sampled: 5590000
    num_steps_trained: 5590000
    wait_time_ms: 72.334
  iterations_since_restore: 1118
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 9555.652426958084
  time_this_iter_s: 8.151692628860474
  time_total_s: 9555.652426958084
  timestamp: 1594867895
  timesteps_since_restore: 5590000
  timesteps_this_iter: 5000
  timesteps_total: 5590000
  training_iteration: 1118
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 9555 s, 1118 iter, 5590000 ts, -478 rew

agent-1: 1.53125
agent-2: -349.9999999962086
agent-3: -349.9999999962086
agent-4: -49.46874999939871
agent-5: -349.9999999962086
Extrinsic Rewards:
4
0
0
3
0
Sum Reward: 7
Avg Reward: 1.4
Min Reward: 0
Max Reward: 4
Gini Coefficient: 0.6285714285714286
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-51-43
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -481.55689061982184
  episode_reward_min: -1199.3140624869059
  episodes_this_iter: 1
  episodes_total: 1118
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.688
    dispatch_time_ms: 6.611
    learner:
      cur_lr: 0.0009877060074359179
      grad_gnorm: 10.591523170471191
      policy_entropy: 9.049721847986802e-05
      policy_loss: 3.6747076137544354e-07
      var_gnorm: 28.39649200439453
      vf_explained_var: 0.0
      vf_loss: 0.07385247200727463
    num_steps_sampled: 5595000
    num_steps_trained: 5595000
    wait_time_ms: 71.83
  iterations_since_restore: 1119
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 9563.905146598816
  time_this_iter_s: 8.252719640731812
  time_total_s: 9563.905146598816
  timestamp: 1594867903
  timesteps_since_restore: 5595000
  timesteps_this_iter: 5000
  timesteps_total: 5595000
  training_iteration: 1119
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 9563 s, 1119 iter, 5595000 ts, -482 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-51-51
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 0.0
  episode_reward_mean: -475.5868906198856
  episode_reward_min: -1199.3140624869059
  episodes_this_iter: 1
  episodes_total: 1119
  experiment_id: 143db6951fe54520bae337189ec3259c
  hostname: gpu016
  info:
    apply_time_ms: 2.66
    dispatch_time_ms: 5.664
    learner:
      cur_lr: 0.000987372943200171
      grad_gnorm: 0.14343293011188507
      policy_entropy: 8.343242370756343e-05
      policy_loss: -0.0
      var_gnorm: 28.39593505859375
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 1.3555149962485302e-05
    num_steps_sampled: 5600000
    num_steps_trained: 5600000
    wait_time_ms: 74.656
  iterations_since_restore: 1120
  node_ip: 172.17.8.16
  num_metric_batches_dropped: 0
  pid: 9004
  policy_reward_mean: {}
  time_since_restore: 9572.067184209824
  time_this_iter_s: 8.16203761100769
  time_total_s: 9572.067184209824
  timestamp: 1594867911
  timesteps_since_restore: 5600000
  timesteps_this_iter: 5000
  timesteps_total: 5600000
  training_iteration: 1120
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=9004], 9572 s, 1120 iter, 5600000 ts, -476 rew

agent-1: 4.0
agent-2: -199.99999999780377
agent-3: -199.99999999780377
agent-4: -199.99999999780377
agent-5: -199.99999999780377
Extrinsic Rewards:
4
0
0
0
0
Sum Reward: 4
Avg Reward: 0.8
Min Reward: 0
Max Reward: 4
Gini Coefficient: 0.8
20:20 Ratio: Undefined
Max-min Ratio: Undefined
