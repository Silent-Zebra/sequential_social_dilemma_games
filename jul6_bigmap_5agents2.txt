/h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:523: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint8 = np.dtype([("qint8", np.int8, 1)])
/h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:524: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint8 = np.dtype([("quint8", np.uint8, 1)])
/h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint16 = np.dtype([("qint16", np.int16, 1)])
/h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint16 = np.dtype([("quint16", np.uint16, 1)])
/h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint32 = np.dtype([("qint32", np.int32, 1)])
/h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:532: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  np_resource = np.dtype([("resource", np.ubyte, 1)])
Process STDOUT and STDERR is being redirected to /tmp/ray/session_2020-07-07_11-59-56_12070/logs.
Waiting for redis server at 127.0.0.1:56917 to respond...
Waiting for redis server at 127.0.0.1:34903 to respond...
Warning: Capping object memory store to 20.0GB. To increase this further, specify `object_store_memory` when calling ray.init() or ray start.
Starting the Plasma object store with 20.0 GB memory using /dev/shm.

======================================================================
View the web UI at http://localhost:8888/notebooks/ray_ui.ipynb?token=4e1b8ec3b3c8df96fe97ccf947fe39d2760dc9dee4ebd56c
======================================================================

== Status ==
Using FIFO scheduling algorithm.
Resources requested: 0/2 CPUs, 0/1 GPUs
Memory usage on this node: 18.3/202.5 GB

Created LogSyncer for /h/zhaostep/ray_results/harvest_A3C/A3C_harvest_env_0_2020-07-07_11-59-56t4_mox0c -> 
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 18.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING

/h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:523: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint8 = np.dtype([("qint8", np.int8, 1)])
/h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:524: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint8 = np.dtype([("quint8", np.uint8, 1)])
/h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint16 = np.dtype([("qint16", np.int16, 1)])
/h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint16 = np.dtype([("quint16", np.uint16, 1)])
/h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint32 = np.dtype([("qint32", np.int32, 1)])
/h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:532: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  np_resource = np.dtype([("resource", np.ubyte, 1)])
2020-07-07 12:00:10,839	INFO policy_evaluator.py:262 -- Creating policy evaluation worker 0 on CPU (please ignore any CUDA init errors)
2020-07-07 12:00:10.839693: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
From /h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/ray/rllib/models/lstm.py:59: BasicLSTMCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.
Instructions for updating:
This class is deprecated, please use tf.nn.rnn_cell.LSTMCell, which supports all the feature this cell currently has. Please replace the existing code with tf.nn.rnn_cell.LSTMCell(name='basic_lstm_cell').
/h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:523: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint8 = np.dtype([("qint8", np.int8, 1)])
/h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:524: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint8 = np.dtype([("quint8", np.uint8, 1)])
/h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint16 = np.dtype([("qint16", np.int16, 1)])
/h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint16 = np.dtype([("quint16", np.uint16, 1)])
/h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint32 = np.dtype([("qint32", np.int32, 1)])
/h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:532: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  np_resource = np.dtype([("resource", np.ubyte, 1)])
2020-07-07 12:00:22,734	INFO policy_evaluator.py:262 -- Creating policy evaluation worker 2 on CPU (please ignore any CUDA init errors)
2020-07-07 12:00:22.736100: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
/h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:523: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint8 = np.dtype([("qint8", np.int8, 1)])
/h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:524: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint8 = np.dtype([("quint8", np.uint8, 1)])
/h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint16 = np.dtype([("qint16", np.int16, 1)])
/h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint16 = np.dtype([("quint16", np.uint16, 1)])
/h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint32 = np.dtype([("qint32", np.int32, 1)])
/h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:532: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  np_resource = np.dtype([("resource", np.ubyte, 1)])
2020-07-07 12:00:22,861	INFO policy_evaluator.py:262 -- Creating policy evaluation worker 1 on CPU (please ignore any CUDA init errors)
2020-07-07 12:00:22.862798: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
From /h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/ray/rllib/models/lstm.py:59: BasicLSTMCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.
Instructions for updating:
This class is deprecated, please use tf.nn.rnn_cell.LSTMCell, which supports all the feature this cell currently has. Please replace the existing code with tf.nn.rnn_cell.LSTMCell(name='basic_lstm_cell').
From /h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/ray/rllib/models/lstm.py:59: BasicLSTMCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.
Instructions for updating:
This class is deprecated, please use tf.nn.rnn_cell.LSTMCell, which supports all the feature this cell currently has. Please replace the existing code with tf.nn.rnn_cell.LSTMCell(name='basic_lstm_cell').
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_12-00-39
  done: false
  episode_len_mean: .nan
  episode_reward_max: .nan
  episode_reward_mean: .nan
  episode_reward_min: .nan
  episodes_this_iter: 0
  episodes_total: 0
  experiment_id: ebedc1946062457bb682d57fae83bd74
  hostname: gpu052
  info:
    apply_time_ms: 3.254
    dispatch_time_ms: 8.122
    learner:
      cur_lr: 0.0013599999947473407
      grad_gnorm: 40.0
      policy_entropy: 60.407169342041016
      policy_loss: 26.11931800842285
      var_gnorm: 18.041057586669922
      vf_explained_var: 0.17899459600448608
      vf_loss: 42.64851760864258
    num_steps_sampled: 5000
    num_steps_trained: 5000
    wait_time_ms: 135.579
  iterations_since_restore: 1
  node_ip: 172.17.8.52
  num_metric_batches_dropped: 0
  pid: 12141
  policy_reward_mean: {}
  time_since_restore: 27.6690673828125
  time_this_iter_s: 27.6690673828125
  time_total_s: 27.6690673828125
  timestamp: 1594137639
  timesteps_since_restore: 5000
  timesteps_this_iter: 5000
  timesteps_total: 5000
  training_iteration: 1
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 19.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=12141], 27 s, 1 iter, 5000 ts, nan rew

[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.[0m
agent-1: 98.0
agent-2: 101.0
agent-3: 100.0
agent-4: 85.0
agent-5: 98.0
Sum Reward: 482.0
Avg Reward: 96.4
Min Reward: 85.0
Max Reward: 101.0
Gini Coefficient: 0.028215767634854772
20:20 Ratio: 1.188235294117647
Max-min Ratio: 1.188235294117647
[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.[0m
agent-1: -18.0
agent-2: 103.0
agent-3: 134.0
agent-4: -50.0
agent-5: 54.0
Sum Reward: 223.0
Avg Reward: 44.6
Min Reward: -50.0
Max Reward: 134.0
Gini Coefficient: 0.8771300448430494
20:20 Ratio: -2.68
Max-min Ratio: -2.68
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_12-00-53
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 482.0
  episode_reward_mean: 352.5
  episode_reward_min: 223.0
  episodes_this_iter: 2
  episodes_total: 2
  experiment_id: ebedc1946062457bb682d57fae83bd74
  hostname: gpu052
  info:
    apply_time_ms: 3.749
    dispatch_time_ms: 10.961
    learner:
      cur_lr: 0.0013596670469269156
      grad_gnorm: 40.0
      policy_entropy: 60.541015625
      policy_loss: -357.31488037109375
      var_gnorm: 18.179706573486328
      vf_explained_var: 0.28612732887268066
      vf_loss: 923.3673706054688
    num_steps_sampled: 10000
    num_steps_trained: 10000
    wait_time_ms: 97.799
  iterations_since_restore: 2
  node_ip: 172.17.8.52
  num_metric_batches_dropped: 0
  pid: 12141
  policy_reward_mean: {}
  time_since_restore: 40.98103713989258
  time_this_iter_s: 13.311969757080078
  time_total_s: 40.98103713989258
  timestamp: 1594137653
  timesteps_since_restore: 10000
  timesteps_this_iter: 5000
  timesteps_total: 10000
  training_iteration: 2
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 19.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=12141], 40 s, 2 iter, 10000 ts, 352 rew

Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_12-01-04
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 482.0
  episode_reward_mean: 352.5
  episode_reward_min: 223.0
  episodes_this_iter: 0
  episodes_total: 2
  experiment_id: ebedc1946062457bb682d57fae83bd74
  hostname: gpu052
  info:
    apply_time_ms: 2.921
    dispatch_time_ms: 12.063
    learner:
      cur_lr: 0.0013593339826911688
      grad_gnorm: 39.999996185302734
      policy_entropy: 58.13637161254883
      policy_loss: 23.147045135498047
      var_gnorm: 18.369279861450195
      vf_explained_var: -4.696846008300781e-05
      vf_loss: 58.588592529296875
    num_steps_sampled: 15000
    num_steps_trained: 15000
    wait_time_ms: 102.995
  iterations_since_restore: 3
  node_ip: 172.17.8.52
  num_metric_batches_dropped: 0
  pid: 12141
  policy_reward_mean: {}
  time_since_restore: 52.00989127159119
  time_this_iter_s: 11.028854131698608
  time_total_s: 52.00989127159119
  timestamp: 1594137664
  timesteps_since_restore: 15000
  timesteps_this_iter: 5000
  timesteps_total: 15000
  training_iteration: 3
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 19.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=12141], 52 s, 3 iter, 15000 ts, 352 rew

agent-1: 236.0
agent-2: 213.0
agent-3: 187.0
agent-4: 230.0
agent-5: 227.0
Sum Reward: 1093.0
Avg Reward: 218.6
Min Reward: 187.0
Max Reward: 236.0
Gini Coefficient: 0.042086001829826164
20:20 Ratio: 1.2620320855614973
Max-min Ratio: 1.2620320855614973
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_12-01-16
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1093.0
  episode_reward_mean: 599.3333333333334
  episode_reward_min: 223.0
  episodes_this_iter: 1
  episodes_total: 3
  experiment_id: ebedc1946062457bb682d57fae83bd74
  hostname: gpu052
  info:
    apply_time_ms: 2.796
    dispatch_time_ms: 6.532
    learner:
      cur_lr: 0.0013590010348707438
      grad_gnorm: 40.0
      policy_entropy: 44.65751647949219
      policy_loss: 57.03776550292969
      var_gnorm: 18.609323501586914
      vf_explained_var: -0.18018114566802979
      vf_loss: 64.79271697998047
    num_steps_sampled: 20000
    num_steps_trained: 20000
    wait_time_ms: 112.431
  iterations_since_restore: 4
  node_ip: 172.17.8.52
  num_metric_batches_dropped: 0
  pid: 12141
  policy_reward_mean: {}
  time_since_restore: 64.45527768135071
  time_this_iter_s: 12.445386409759521
  time_total_s: 64.45527768135071
  timestamp: 1594137676
  timesteps_since_restore: 20000
  timesteps_this_iter: 5000
  timesteps_total: 20000
  training_iteration: 4
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 19.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=12141], 64 s, 4 iter, 20000 ts, 599 rew

agent-1: 214.0
agent-2: 183.0
agent-3: 179.0
agent-4: 142.0
agent-5: 180.0
Sum Reward: 898.0
Avg Reward: 179.6
Min Reward: 142.0
Max Reward: 214.0
Gini Coefficient: 0.06592427616926504
20:20 Ratio: 1.5070422535211268
Max-min Ratio: 1.5070422535211268
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_12-01-28
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1093.0
  episode_reward_mean: 674.0
  episode_reward_min: 223.0
  episodes_this_iter: 1
  episodes_total: 4
  experiment_id: ebedc1946062457bb682d57fae83bd74
  hostname: gpu052
  info:
    apply_time_ms: 3.227
    dispatch_time_ms: 5.981
    learner:
      cur_lr: 0.0013586679706349969
      grad_gnorm: 40.0
      policy_entropy: 38.75048065185547
      policy_loss: 23.457317352294922
      var_gnorm: 18.847068786621094
      vf_explained_var: 0.20157790184020996
      vf_loss: 30.79576873779297
    num_steps_sampled: 25000
    num_steps_trained: 25000
    wait_time_ms: 117.38
  iterations_since_restore: 5
  node_ip: 172.17.8.52
  num_metric_batches_dropped: 0
  pid: 12141
  policy_reward_mean: {}
  time_since_restore: 76.29990339279175
  time_this_iter_s: 11.84462571144104
  time_total_s: 76.29990339279175
  timestamp: 1594137688
  timesteps_since_restore: 25000
  timesteps_this_iter: 5000
  timesteps_total: 25000
  training_iteration: 5
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 20.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=12141], 76 s, 5 iter, 25000 ts, 674 rew

agent-1: 257.0
agent-2: 251.0
agent-3: 283.0
agent-4: 257.0
agent-5: 253.0
Sum Reward: 1301.0
Avg Reward: 260.2
Min Reward: 251.0
Max Reward: 283.0
Gini Coefficient: 0.020906994619523445
20:20 Ratio: 1.1274900398406376
Max-min Ratio: 1.1274900398406376
agent-1: 250.0
agent-2: 240.0
agent-3: 257.0
agent-4: 248.0
agent-5: 271.0
Sum Reward: 1266.0
Avg Reward: 253.2
Min Reward: 240.0
Max Reward: 271.0
Gini Coefficient: 0.022432859399684046
20:20 Ratio: 1.1291666666666667
Max-min Ratio: 1.1291666666666667
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_12-01-41
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1301.0
  episode_reward_mean: 877.1666666666666
  episode_reward_min: 223.0
  episodes_this_iter: 2
  episodes_total: 6
  experiment_id: ebedc1946062457bb682d57fae83bd74
  hostname: gpu052
  info:
    apply_time_ms: 2.508
    dispatch_time_ms: 5.815
    learner:
      cur_lr: 0.0013583350228145719
      grad_gnorm: 39.999996185302734
      policy_entropy: 44.91712188720703
      policy_loss: -1057.4591064453125
      var_gnorm: 18.99619483947754
      vf_explained_var: -0.0015835762023925781
      vf_loss: 11338.0966796875
    num_steps_sampled: 30000
    num_steps_trained: 30000
    wait_time_ms: 120.43
  iterations_since_restore: 6
  node_ip: 172.17.8.52
  num_metric_batches_dropped: 0
  pid: 12141
  policy_reward_mean: {}
  time_since_restore: 88.83949303627014
  time_this_iter_s: 12.539589643478394
  time_total_s: 88.83949303627014
  timestamp: 1594137701
  timesteps_since_restore: 30000
  timesteps_this_iter: 5000
  timesteps_total: 30000
  training_iteration: 6
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 20.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=12141], 88 s, 6 iter, 30000 ts, 877 rew

Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_12-01-52
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1301.0
  episode_reward_mean: 877.1666666666666
  episode_reward_min: 223.0
  episodes_this_iter: 0
  episodes_total: 6
  experiment_id: ebedc1946062457bb682d57fae83bd74
  hostname: gpu052
  info:
    apply_time_ms: 3.595
    dispatch_time_ms: 10.064
    learner:
      cur_lr: 0.001358001958578825
      grad_gnorm: 40.0
      policy_entropy: 43.347503662109375
      policy_loss: -35.63272476196289
      var_gnorm: 19.253616333007812
      vf_explained_var: -0.03204524517059326
      vf_loss: 27.37347412109375
    num_steps_sampled: 35000
    num_steps_trained: 35000
    wait_time_ms: 110.017
  iterations_since_restore: 7
  node_ip: 172.17.8.52
  num_metric_batches_dropped: 0
  pid: 12141
  policy_reward_mean: {}
  time_since_restore: 100.45046830177307
  time_this_iter_s: 11.61097526550293
  time_total_s: 100.45046830177307
  timestamp: 1594137712
  timesteps_since_restore: 35000
  timesteps_this_iter: 5000
  timesteps_total: 35000
  training_iteration: 7
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 20.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=12141], 100 s, 7 iter, 35000 ts, 877 rew

agent-1: 257.0
agent-2: 248.0
agent-3: 297.0
agent-4: 229.0
agent-5: 271.0
Sum Reward: 1302.0
Avg Reward: 260.4
Min Reward: 229.0
Max Reward: 297.0
Gini Coefficient: 0.04884792626728111
20:20 Ratio: 1.296943231441048
Max-min Ratio: 1.296943231441048
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_12-02-05
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1302.0
  episode_reward_mean: 937.8571428571429
  episode_reward_min: 223.0
  episodes_this_iter: 1
  episodes_total: 7
  experiment_id: ebedc1946062457bb682d57fae83bd74
  hostname: gpu052
  info:
    apply_time_ms: 2.898
    dispatch_time_ms: 12.297
    learner:
      cur_lr: 0.0013576690107584
      grad_gnorm: 40.000003814697266
      policy_entropy: 32.71649932861328
      policy_loss: 10.169900894165039
      var_gnorm: 19.430553436279297
      vf_explained_var: -0.0008635520935058594
      vf_loss: 16.670333862304688
    num_steps_sampled: 40000
    num_steps_trained: 40000
    wait_time_ms: 111.721
  iterations_since_restore: 8
  node_ip: 172.17.8.52
  num_metric_batches_dropped: 0
  pid: 12141
  policy_reward_mean: {}
  time_since_restore: 112.91080641746521
  time_this_iter_s: 12.460338115692139
  time_total_s: 112.91080641746521
  timestamp: 1594137725
  timesteps_since_restore: 40000
  timesteps_this_iter: 5000
  timesteps_total: 40000
  training_iteration: 8
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 20.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=12141], 112 s, 8 iter, 40000 ts, 938 rew

agent-1: 260.0
agent-2: 216.0
agent-3: 300.0
agent-4: 245.0
agent-5: 229.0
Sum Reward: 1250.0
Avg Reward: 250.0
Min Reward: 216.0
Max Reward: 300.0
Gini Coefficient: 0.06368
20:20 Ratio: 1.3888888888888888
Max-min Ratio: 1.3888888888888888
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_12-02-16
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1302.0
  episode_reward_mean: 976.875
  episode_reward_min: 223.0
  episodes_this_iter: 1
  episodes_total: 8
  experiment_id: ebedc1946062457bb682d57fae83bd74
  hostname: gpu052
  info:
    apply_time_ms: 2.77
    dispatch_time_ms: 7.161
    learner:
      cur_lr: 0.001357335946522653
      grad_gnorm: 40.000003814697266
      policy_entropy: 22.314022064208984
      policy_loss: -6.579299449920654
      var_gnorm: 19.678009033203125
      vf_explained_var: -0.09956955909729004
      vf_loss: 28.384153366088867
    num_steps_sampled: 45000
    num_steps_trained: 45000
    wait_time_ms: 106.676
  iterations_since_restore: 9
  node_ip: 172.17.8.52
  num_metric_batches_dropped: 0
  pid: 12141
  policy_reward_mean: {}
  time_since_restore: 124.37698078155518
  time_this_iter_s: 11.466174364089966
  time_total_s: 124.37698078155518
  timestamp: 1594137736
  timesteps_since_restore: 45000
  timesteps_this_iter: 5000
  timesteps_total: 45000
  training_iteration: 9
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 20.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=12141], 124 s, 9 iter, 45000 ts, 977 rew

agent-1: 261.0
agent-2: 290.0
agent-3: 289.0
agent-4: 303.0
agent-5: 286.0
Sum Reward: 1429.0
Avg Reward: 285.8
Min Reward: 261.0
Max Reward: 303.0
Gini Coefficient: 0.02463261021693492
20:20 Ratio: 1.160919540229885
Max-min Ratio: 1.160919540229885
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_12-02-29
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1429.0
  episode_reward_mean: 1027.111111111111
  episode_reward_min: 223.0
  episodes_this_iter: 1
  episodes_total: 9
  experiment_id: ebedc1946062457bb682d57fae83bd74
  hostname: gpu052
  info:
    apply_time_ms: 2.53
    dispatch_time_ms: 5.86
    learner:
      cur_lr: 0.001357002998702228
      grad_gnorm: 40.000003814697266
      policy_entropy: 32.46842575073242
      policy_loss: -5.597670555114746
      var_gnorm: 19.88560676574707
      vf_explained_var: 0.22262412309646606
      vf_loss: 46.58396530151367
    num_steps_sampled: 50000
    num_steps_trained: 50000
    wait_time_ms: 114.773
  iterations_since_restore: 10
  node_ip: 172.17.8.52
  num_metric_batches_dropped: 0
  pid: 12141
  policy_reward_mean: {}
  time_since_restore: 136.63625383377075
  time_this_iter_s: 12.259273052215576
  time_total_s: 136.63625383377075
  timestamp: 1594137749
  timesteps_since_restore: 50000
  timesteps_this_iter: 5000
  timesteps_total: 50000
  training_iteration: 10
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 21.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=12141], 136 s, 10 iter, 50000 ts, 1.03e+03 rew

agent-1: 279.0
agent-2: 225.0
agent-3: 301.0
agent-4: 287.0
agent-5: 264.0
Sum Reward: 1356.0
Avg Reward: 271.2
Min Reward: 225.0
Max Reward: 301.0
Gini Coefficient: 0.051622418879056046
20:20 Ratio: 1.3377777777777777
Max-min Ratio: 1.3377777777777777
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_12-02-40
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1429.0
  episode_reward_mean: 1060.0
  episode_reward_min: 223.0
  episodes_this_iter: 1
  episodes_total: 10
  experiment_id: ebedc1946062457bb682d57fae83bd74
  hostname: gpu052
  info:
    apply_time_ms: 4.408
    dispatch_time_ms: 7.936
    learner:
      cur_lr: 0.001356670050881803
      grad_gnorm: 39.99999237060547
      policy_entropy: 39.86623764038086
      policy_loss: -32.5979118347168
      var_gnorm: 20.084218978881836
      vf_explained_var: 0.45451468229293823
      vf_loss: 20.370868682861328
    num_steps_sampled: 55000
    num_steps_trained: 55000
    wait_time_ms: 106.955
  iterations_since_restore: 11
  node_ip: 172.17.8.52
  num_metric_batches_dropped: 0
  pid: 12141
  policy_reward_mean: {}
  time_since_restore: 148.2966911792755
  time_this_iter_s: 11.66043734550476
  time_total_s: 148.2966911792755
  timestamp: 1594137760
  timesteps_since_restore: 55000
  timesteps_this_iter: 5000
  timesteps_total: 55000
  training_iteration: 11
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 21.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=12141], 148 s, 11 iter, 55000 ts, 1.06e+03 rew

agent-1: 277.0
agent-2: 321.0
agent-3: 296.0
agent-4: 302.0
agent-5: 284.0
Sum Reward: 1480.0
Avg Reward: 296.0
Min Reward: 277.0
Max Reward: 321.0
Gini Coefficient: 0.028648648648648647
20:20 Ratio: 1.1588447653429603
Max-min Ratio: 1.1588447653429603
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_12-02-53
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1480.0
  episode_reward_mean: 1098.1818181818182
  episode_reward_min: 223.0
  episodes_this_iter: 1
  episodes_total: 11
  experiment_id: ebedc1946062457bb682d57fae83bd74
  hostname: gpu052
  info:
    apply_time_ms: 3.082
    dispatch_time_ms: 11.943
    learner:
      cur_lr: 0.0013563369866460562
      grad_gnorm: 40.0000114440918
      policy_entropy: 35.04873275756836
      policy_loss: -13.02791976928711
      var_gnorm: 20.146663665771484
      vf_explained_var: 0.3573486804962158
      vf_loss: 38.519657135009766
    num_steps_sampled: 60000
    num_steps_trained: 60000
    wait_time_ms: 113.201
  iterations_since_restore: 12
  node_ip: 172.17.8.52
  num_metric_batches_dropped: 0
  pid: 12141
  policy_reward_mean: {}
  time_since_restore: 161.02554869651794
  time_this_iter_s: 12.728857517242432
  time_total_s: 161.02554869651794
  timestamp: 1594137773
  timesteps_since_restore: 60000
  timesteps_this_iter: 5000
  timesteps_total: 60000
  training_iteration: 12
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 21.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=12141], 161 s, 12 iter, 60000 ts, 1.1e+03 rew

agent-1: 278.0
agent-2: 319.0
agent-3: 261.0
agent-4: 275.0
agent-5: 283.0
Sum Reward: 1416.0
Avg Reward: 283.2
Min Reward: 261.0
Max Reward: 319.0
Gini Coefficient: 0.03502824858757062
20:20 Ratio: 1.2222222222222223
Max-min Ratio: 1.2222222222222223
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_12-03-05
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1480.0
  episode_reward_mean: 1124.6666666666667
  episode_reward_min: 223.0
  episodes_this_iter: 1
  episodes_total: 12
  experiment_id: ebedc1946062457bb682d57fae83bd74
  hostname: gpu052
  info:
    apply_time_ms: 3.347
    dispatch_time_ms: 7.276
    learner:
      cur_lr: 0.0013560040388256311
      grad_gnorm: 39.9999885559082
      policy_entropy: 50.10956954956055
      policy_loss: 21.945146560668945
      var_gnorm: 20.302762985229492
      vf_explained_var: 0.35950547456741333
      vf_loss: 54.201683044433594
    num_steps_sampled: 65000
    num_steps_trained: 65000
    wait_time_ms: 114.89
  iterations_since_restore: 13
  node_ip: 172.17.8.52
  num_metric_batches_dropped: 0
  pid: 12141
  policy_reward_mean: {}
  time_since_restore: 172.8442645072937
  time_this_iter_s: 11.818715810775757
  time_total_s: 172.8442645072937
  timestamp: 1594137785
  timesteps_since_restore: 65000
  timesteps_this_iter: 5000
  timesteps_total: 65000
  training_iteration: 13
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 19.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=12141], 172 s, 13 iter, 65000 ts, 1.12e+03 rew

agent-1: 292.0
agent-2: 305.0
agent-3: 269.0
agent-4: 280.0
agent-5: 279.0
Sum Reward: 1425.0
Avg Reward: 285.0
Min Reward: 269.0
Max Reward: 305.0
Gini Coefficient: 0.023859649122807018
20:20 Ratio: 1.1338289962825279
Max-min Ratio: 1.1338289962825279
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_12-03-18
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1480.0
  episode_reward_mean: 1147.7692307692307
  episode_reward_min: 223.0
  episodes_this_iter: 1
  episodes_total: 13
  experiment_id: ebedc1946062457bb682d57fae83bd74
  hostname: gpu052
  info:
    apply_time_ms: 3.916
    dispatch_time_ms: 6.41
    learner:
      cur_lr: 0.0013556709745898843
      grad_gnorm: 40.000003814697266
      policy_entropy: 51.224769592285156
      policy_loss: -47.75669860839844
      var_gnorm: 20.459774017333984
      vf_explained_var: 0.2753258943557739
      vf_loss: 30.070064544677734
    num_steps_sampled: 70000
    num_steps_trained: 70000
    wait_time_ms: 113.983
  iterations_since_restore: 14
  node_ip: 172.17.8.52
  num_metric_batches_dropped: 0
  pid: 12141
  policy_reward_mean: {}
  time_since_restore: 185.65147399902344
  time_this_iter_s: 12.807209491729736
  time_total_s: 185.65147399902344
  timestamp: 1594137798
  timesteps_since_restore: 70000
  timesteps_this_iter: 5000
  timesteps_total: 70000
  training_iteration: 14
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 19.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=12141], 185 s, 14 iter, 70000 ts, 1.15e+03 rew

agent-1: 290.0
agent-2: 274.0
agent-3: 296.0
agent-4: 295.0
agent-5: 318.0
Sum Reward: 1473.0
Avg Reward: 294.6
Min Reward: 274.0
Max Reward: 318.0
Gini Coefficient: 0.02552613713509844
20:20 Ratio: 1.1605839416058394
Max-min Ratio: 1.1605839416058394
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_12-03-28
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1480.0
  episode_reward_mean: 1171.0
  episode_reward_min: 223.0
  episodes_this_iter: 1
  episodes_total: 14
  experiment_id: ebedc1946062457bb682d57fae83bd74
  hostname: gpu052
  info:
    apply_time_ms: 2.878
    dispatch_time_ms: 7.855
    learner:
      cur_lr: 0.0013553380267694592
      grad_gnorm: 40.0000114440918
      policy_entropy: 43.0761833190918
      policy_loss: 2.1822149753570557
      var_gnorm: 20.45816993713379
      vf_explained_var: 0.5816073417663574
      vf_loss: 52.42247009277344
    num_steps_sampled: 75000
    num_steps_trained: 75000
    wait_time_ms: 94.759
  iterations_since_restore: 15
  node_ip: 172.17.8.52
  num_metric_batches_dropped: 0
  pid: 12141
  policy_reward_mean: {}
  time_since_restore: 196.33846068382263
  time_this_iter_s: 10.686986684799194
  time_total_s: 196.33846068382263
  timestamp: 1594137808
  timesteps_since_restore: 75000
  timesteps_this_iter: 5000
  timesteps_total: 75000
  training_iteration: 15
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 20.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=12141], 196 s, 15 iter, 75000 ts, 1.17e+03 rew

agent-1: 238.0
agent-2: 245.0
agent-3: 223.0
agent-4: 225.0
agent-5: 236.0
Sum Reward: 1167.0
Avg Reward: 233.4
Min Reward: 223.0
Max Reward: 245.0
Gini Coefficient: 0.01953727506426735
20:20 Ratio: 1.0986547085201794
Max-min Ratio: 1.0986547085201794
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_12-03-41
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1480.0
  episode_reward_mean: 1170.7333333333333
  episode_reward_min: 223.0
  episodes_this_iter: 1
  episodes_total: 15
  experiment_id: ebedc1946062457bb682d57fae83bd74
  hostname: gpu052
  info:
    apply_time_ms: 3.472
    dispatch_time_ms: 7.418
    learner:
      cur_lr: 0.0013550049625337124
      grad_gnorm: 40.000003814697266
      policy_entropy: 36.66935729980469
      policy_loss: 16.19744110107422
      var_gnorm: 20.62190818786621
      vf_explained_var: 0.22694367170333862
      vf_loss: 34.05171585083008
    num_steps_sampled: 80000
    num_steps_trained: 80000
    wait_time_ms: 102.309
  iterations_since_restore: 16
  node_ip: 172.17.8.52
  num_metric_batches_dropped: 0
  pid: 12141
  policy_reward_mean: {}
  time_since_restore: 208.5934009552002
  time_this_iter_s: 12.254940271377563
  time_total_s: 208.5934009552002
  timestamp: 1594137821
  timesteps_since_restore: 80000
  timesteps_this_iter: 5000
  timesteps_total: 80000
  training_iteration: 16
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 20.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=12141], 208 s, 16 iter, 80000 ts, 1.17e+03 rew

agent-1: 225.0
agent-2: 249.0
agent-3: 177.0
agent-4: 260.0
agent-5: 172.0
Sum Reward: 1083.0
Avg Reward: 216.6
Min Reward: 172.0
Max Reward: 260.0
Gini Coefficient: 0.09159741458910434
20:20 Ratio: 1.5116279069767442
Max-min Ratio: 1.5116279069767442
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_12-03-53
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1480.0
  episode_reward_mean: 1165.25
  episode_reward_min: 223.0
  episodes_this_iter: 1
  episodes_total: 16
  experiment_id: ebedc1946062457bb682d57fae83bd74
  hostname: gpu052
  info:
    apply_time_ms: 2.578
    dispatch_time_ms: 6.504
    learner:
      cur_lr: 0.0013546720147132874
      grad_gnorm: 40.00001525878906
      policy_entropy: 32.425445556640625
      policy_loss: 4.733212947845459
      var_gnorm: 20.851591110229492
      vf_explained_var: 0.23756623268127441
      vf_loss: 81.40460205078125
    num_steps_sampled: 85000
    num_steps_trained: 85000
    wait_time_ms: 115.708
  iterations_since_restore: 17
  node_ip: 172.17.8.52
  num_metric_batches_dropped: 0
  pid: 12141
  policy_reward_mean: {}
  time_since_restore: 220.74965453147888
  time_this_iter_s: 12.156253576278687
  time_total_s: 220.74965453147888
  timestamp: 1594137833
  timesteps_since_restore: 85000
  timesteps_this_iter: 5000
  timesteps_total: 85000
  training_iteration: 17
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 20.3/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=12141], 220 s, 17 iter, 85000 ts, 1.17e+03 rew

agent-1: 291.0
agent-2: 283.0
agent-3: 301.0
agent-4: 264.0
agent-5: 326.0
Sum Reward: 1465.0
Avg Reward: 293.0
Min Reward: 264.0
Max Reward: 326.0
Gini Coefficient: 0.038771331058020476
20:20 Ratio: 1.2348484848484849
Max-min Ratio: 1.2348484848484849
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_12-04-06
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1480.0
  episode_reward_mean: 1182.8823529411766
  episode_reward_min: 223.0
  episodes_this_iter: 1
  episodes_total: 17
  experiment_id: ebedc1946062457bb682d57fae83bd74
  hostname: gpu052
  info:
    apply_time_ms: 3.657
    dispatch_time_ms: 7.774
    learner:
      cur_lr: 0.0013543389504775405
      grad_gnorm: 40.000003814697266
      policy_entropy: 16.628389358520508
      policy_loss: -7.642350196838379
      var_gnorm: 20.933452606201172
      vf_explained_var: 0.05967754125595093
      vf_loss: 34.03034591674805
    num_steps_sampled: 90000
    num_steps_trained: 90000
    wait_time_ms: 100.977
  iterations_since_restore: 18
  node_ip: 172.17.8.52
  num_metric_batches_dropped: 0
  pid: 12141
  policy_reward_mean: {}
  time_since_restore: 233.29247379302979
  time_this_iter_s: 12.542819261550903
  time_total_s: 233.29247379302979
  timestamp: 1594137846
  timesteps_since_restore: 90000
  timesteps_this_iter: 5000
  timesteps_total: 90000
  training_iteration: 18
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 20.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=12141], 233 s, 18 iter, 90000 ts, 1.18e+03 rew

agent-1: 306.0
agent-2: 304.0
agent-3: 317.0
agent-4: 293.0
agent-5: 303.0
Sum Reward: 1523.0
Avg Reward: 304.6
Min Reward: 293.0
Max Reward: 317.0
Gini Coefficient: 0.013394615889691399
20:20 Ratio: 1.081911262798635
Max-min Ratio: 1.081911262798635
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_12-04-17
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1523.0
  episode_reward_mean: 1201.7777777777778
  episode_reward_min: 223.0
  episodes_this_iter: 1
  episodes_total: 18
  experiment_id: ebedc1946062457bb682d57fae83bd74
  hostname: gpu052
  info:
    apply_time_ms: 3.558
    dispatch_time_ms: 9.987
    learner:
      cur_lr: 0.0013540060026571155
      grad_gnorm: 39.999996185302734
      policy_entropy: 16.848432540893555
      policy_loss: 8.271856307983398
      var_gnorm: 21.097501754760742
      vf_explained_var: -0.11682188510894775
      vf_loss: 32.50422286987305
    num_steps_sampled: 95000
    num_steps_trained: 95000
    wait_time_ms: 108.245
  iterations_since_restore: 19
  node_ip: 172.17.8.52
  num_metric_batches_dropped: 0
  pid: 12141
  policy_reward_mean: {}
  time_since_restore: 245.11617755889893
  time_this_iter_s: 11.82370376586914
  time_total_s: 245.11617755889893
  timestamp: 1594137857
  timesteps_since_restore: 95000
  timesteps_this_iter: 5000
  timesteps_total: 95000
  training_iteration: 19
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 20.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=12141], 245 s, 19 iter, 95000 ts, 1.2e+03 rew

agent-1: 339.0
agent-2: 316.0
agent-3: 333.0
agent-4: 319.0
agent-5: 298.0
Sum Reward: 1605.0
Avg Reward: 321.0
Min Reward: 298.0
Max Reward: 339.0
Gini Coefficient: 0.024672897196261683
20:20 Ratio: 1.1375838926174497
Max-min Ratio: 1.1375838926174497
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_12-04-30
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1605.0
  episode_reward_mean: 1223.0
  episode_reward_min: 223.0
  episodes_this_iter: 1
  episodes_total: 19
  experiment_id: ebedc1946062457bb682d57fae83bd74
  hostname: gpu052
  info:
    apply_time_ms: 3.262
    dispatch_time_ms: 8.035
    learner:
      cur_lr: 0.0013536730548366904
      grad_gnorm: 39.999969482421875
      policy_entropy: 32.1927490234375
      policy_loss: -3.393549680709839
      var_gnorm: 21.26213836669922
      vf_explained_var: 0.21408611536026
      vf_loss: 11.33411979675293
    num_steps_sampled: 100000
    num_steps_trained: 100000
    wait_time_ms: 99.803
  iterations_since_restore: 20
  node_ip: 172.17.8.52
  num_metric_batches_dropped: 0
  pid: 12141
  policy_reward_mean: {}
  time_since_restore: 257.6297640800476
  time_this_iter_s: 12.513586521148682
  time_total_s: 257.6297640800476
  timestamp: 1594137870
  timesteps_since_restore: 100000
  timesteps_this_iter: 5000
  timesteps_total: 100000
  training_iteration: 20
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 20.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=12141], 257 s, 20 iter, 100000 ts, 1.22e+03 rew

agent-1: 320.0
agent-2: 299.0
agent-3: 331.0
agent-4: 299.0
agent-5: 312.0
Sum Reward: 1561.0
Avg Reward: 312.2
Min Reward: 299.0
Max Reward: 331.0
Gini Coefficient: 0.021780909673286355
20:20 Ratio: 1.1070234113712374
Max-min Ratio: 1.1070234113712374
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_12-04-42
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1605.0
  episode_reward_mean: 1239.9
  episode_reward_min: 223.0
  episodes_this_iter: 1
  episodes_total: 20
  experiment_id: ebedc1946062457bb682d57fae83bd74
  hostname: gpu052
  info:
    apply_time_ms: 2.643
    dispatch_time_ms: 6.767
    learner:
      cur_lr: 0.0013533399906009436
      grad_gnorm: 40.00000762939453
      policy_entropy: 30.64656639099121
      policy_loss: 9.839475631713867
      var_gnorm: 21.355859756469727
      vf_explained_var: 0.2202526330947876
      vf_loss: 19.03180503845215
    num_steps_sampled: 105000
    num_steps_trained: 105000
    wait_time_ms: 123.43
  iterations_since_restore: 21
  node_ip: 172.17.8.52
  num_metric_batches_dropped: 0
  pid: 12141
  policy_reward_mean: {}
  time_since_restore: 269.83020758628845
  time_this_iter_s: 12.200443506240845
  time_total_s: 269.83020758628845
  timestamp: 1594137882
  timesteps_since_restore: 105000
  timesteps_this_iter: 5000
  timesteps_total: 105000
  training_iteration: 21
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 21.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=12141], 269 s, 21 iter, 105000 ts, 1.24e+03 rew

agent-1: 332.0
agent-2: 324.0
agent-3: 372.0
agent-4: 318.0
agent-5: 302.0
Sum Reward: 1648.0
Avg Reward: 329.6
Min Reward: 302.0
Max Reward: 372.0
Gini Coefficient: 0.03737864077669903
20:20 Ratio: 1.2317880794701987
Max-min Ratio: 1.2317880794701987
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_12-04-55
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1648.0
  episode_reward_mean: 1259.3333333333333
  episode_reward_min: 223.0
  episodes_this_iter: 1
  episodes_total: 21
  experiment_id: ebedc1946062457bb682d57fae83bd74
  hostname: gpu052
  info:
    apply_time_ms: 4.057
    dispatch_time_ms: 8.394
    learner:
      cur_lr: 0.0013530070427805185
      grad_gnorm: 40.0
      policy_entropy: 13.13669490814209
      policy_loss: 4.535871505737305
      var_gnorm: 21.46387481689453
      vf_explained_var: -0.04369235038757324
      vf_loss: 47.140560150146484
    num_steps_sampled: 110000
    num_steps_trained: 110000
    wait_time_ms: 114.503
  iterations_since_restore: 22
  node_ip: 172.17.8.52
  num_metric_batches_dropped: 0
  pid: 12141
  policy_reward_mean: {}
  time_since_restore: 282.9043788909912
  time_this_iter_s: 13.074171304702759
  time_total_s: 282.9043788909912
  timestamp: 1594137895
  timesteps_since_restore: 110000
  timesteps_this_iter: 5000
  timesteps_total: 110000
  training_iteration: 22
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 21.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=12141], 282 s, 22 iter, 110000 ts, 1.26e+03 rew

agent-1: 283.0
agent-2: 333.0
agent-3: 319.0
agent-4: 282.0
agent-5: 342.0
Sum Reward: 1559.0
Avg Reward: 311.8
Min Reward: 282.0
Max Reward: 342.0
Gini Coefficient: 0.04361770365618987
20:20 Ratio: 1.2127659574468086
Max-min Ratio: 1.2127659574468086
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_12-05-07
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1648.0
  episode_reward_mean: 1272.9545454545455
  episode_reward_min: 223.0
  episodes_this_iter: 1
  episodes_total: 22
  experiment_id: ebedc1946062457bb682d57fae83bd74
  hostname: gpu052
  info:
    apply_time_ms: 2.966
    dispatch_time_ms: 10.438
    learner:
      cur_lr: 0.0013526739785447717
      grad_gnorm: 40.00000762939453
      policy_entropy: 16.40941047668457
      policy_loss: -0.9791226387023926
      var_gnorm: 21.63399314880371
      vf_explained_var: -0.17327189445495605
      vf_loss: 19.490461349487305
    num_steps_sampled: 115000
    num_steps_trained: 115000
    wait_time_ms: 110.373
  iterations_since_restore: 23
  node_ip: 172.17.8.52
  num_metric_batches_dropped: 0
  pid: 12141
  policy_reward_mean: {}
  time_since_restore: 295.0394423007965
  time_this_iter_s: 12.135063409805298
  time_total_s: 295.0394423007965
  timestamp: 1594137907
  timesteps_since_restore: 115000
  timesteps_this_iter: 5000
  timesteps_total: 115000
  training_iteration: 23
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 21.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=12141], 295 s, 23 iter, 115000 ts, 1.27e+03 rew

agent-1: 365.0
agent-2: 312.0
agent-3: 347.0
agent-4: 329.0
agent-5: 324.0
Sum Reward: 1677.0
Avg Reward: 335.4
Min Reward: 312.0
Max Reward: 365.0
Gini Coefficient: 0.03076923076923077
20:20 Ratio: 1.169871794871795
Max-min Ratio: 1.169871794871795
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_12-05-20
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1677.0
  episode_reward_mean: 1290.5217391304348
  episode_reward_min: 223.0
  episodes_this_iter: 1
  episodes_total: 23
  experiment_id: ebedc1946062457bb682d57fae83bd74
  hostname: gpu052
  info:
    apply_time_ms: 3.384
    dispatch_time_ms: 7.131
    learner:
      cur_lr: 0.0013523410307243466
      grad_gnorm: 40.0
      policy_entropy: 33.595008850097656
      policy_loss: -1.5188183784484863
      var_gnorm: 21.700143814086914
      vf_explained_var: -0.03142845630645752
      vf_loss: 52.33295822143555
    num_steps_sampled: 120000
    num_steps_trained: 120000
    wait_time_ms: 115.728
  iterations_since_restore: 24
  node_ip: 172.17.8.52
  num_metric_batches_dropped: 0
  pid: 12141
  policy_reward_mean: {}
  time_since_restore: 307.31279468536377
  time_this_iter_s: 12.27335238456726
  time_total_s: 307.31279468536377
  timestamp: 1594137920
  timesteps_since_restore: 120000
  timesteps_this_iter: 5000
  timesteps_total: 120000
  training_iteration: 24
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 21.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=12141], 307 s, 24 iter, 120000 ts, 1.29e+03 rew

agent-1: 325.0
agent-2: 300.0
agent-3: 282.0
agent-4: 306.0
agent-5: 275.0
Sum Reward: 1488.0
Avg Reward: 297.6
Min Reward: 275.0
Max Reward: 325.0
Gini Coefficient: 0.03333333333333333
20:20 Ratio: 1.1818181818181819
Max-min Ratio: 1.1818181818181819
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_12-05-32
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1677.0
  episode_reward_mean: 1298.75
  episode_reward_min: 223.0
  episodes_this_iter: 1
  episodes_total: 24
  experiment_id: ebedc1946062457bb682d57fae83bd74
  hostname: gpu052
  info:
    apply_time_ms: 3.084
    dispatch_time_ms: 9.351
    learner:
      cur_lr: 0.0013520079664885998
      grad_gnorm: 40.000003814697266
      policy_entropy: 32.37473678588867
      policy_loss: 20.877965927124023
      var_gnorm: 21.77649688720703
      vf_explained_var: 0.31852585077285767
      vf_loss: 86.46649932861328
    num_steps_sampled: 125000
    num_steps_trained: 125000
    wait_time_ms: 118.646
  iterations_since_restore: 25
  node_ip: 172.17.8.52
  num_metric_batches_dropped: 0
  pid: 12141
  policy_reward_mean: {}
  time_since_restore: 319.36706733703613
  time_this_iter_s: 12.054272651672363
  time_total_s: 319.36706733703613
  timestamp: 1594137932
  timesteps_since_restore: 125000
  timesteps_this_iter: 5000
  timesteps_total: 125000
  training_iteration: 25
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 21.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=12141], 319 s, 25 iter, 125000 ts, 1.3e+03 rew

agent-1: 307.0
agent-2: 303.0
agent-3: 294.0
agent-4: 286.0
agent-5: 271.0
Sum Reward: 1461.0
Avg Reward: 292.2
Min Reward: 271.0
Max Reward: 307.0
Gini Coefficient: 0.0243668720054757
20:20 Ratio: 1.132841328413284
Max-min Ratio: 1.132841328413284
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_12-05-45
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1677.0
  episode_reward_mean: 1305.24
  episode_reward_min: 223.0
  episodes_this_iter: 1
  episodes_total: 25
  experiment_id: ebedc1946062457bb682d57fae83bd74
  hostname: gpu052
  info:
    apply_time_ms: 4.296
    dispatch_time_ms: 7.986
    learner:
      cur_lr: 0.0013516750186681747
      grad_gnorm: 39.99995803833008
      policy_entropy: 45.69462203979492
      policy_loss: -5.938520908355713
      var_gnorm: 21.911312103271484
      vf_explained_var: 0.45334237813949585
      vf_loss: 28.540828704833984
    num_steps_sampled: 130000
    num_steps_trained: 130000
    wait_time_ms: 106.014
  iterations_since_restore: 26
  node_ip: 172.17.8.52
  num_metric_batches_dropped: 0
  pid: 12141
  policy_reward_mean: {}
  time_since_restore: 332.37615942955017
  time_this_iter_s: 13.009092092514038
  time_total_s: 332.37615942955017
  timestamp: 1594137945
  timesteps_since_restore: 130000
  timesteps_this_iter: 5000
  timesteps_total: 130000
  training_iteration: 26
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 22.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=12141], 332 s, 26 iter, 130000 ts, 1.31e+03 rew

agent-1: 312.0
agent-2: 317.0
agent-3: 250.0
agent-4: 323.0
agent-5: 334.0
Sum Reward: 1536.0
Avg Reward: 307.2
Min Reward: 250.0
Max Reward: 334.0
Gini Coefficient: 0.046614583333333334
20:20 Ratio: 1.336
Max-min Ratio: 1.336
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_12-05-57
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1677.0
  episode_reward_mean: 1314.1153846153845
  episode_reward_min: 223.0
  episodes_this_iter: 1
  episodes_total: 26
  experiment_id: ebedc1946062457bb682d57fae83bd74
  hostname: gpu052
  info:
    apply_time_ms: 3.683
    dispatch_time_ms: 11.316
    learner:
      cur_lr: 0.0013513419544324279
      grad_gnorm: 39.999996185302734
      policy_entropy: 37.70506286621094
      policy_loss: -1.9477784633636475
      var_gnorm: 21.97857093811035
      vf_explained_var: 0.709869384765625
      vf_loss: 37.003116607666016
    num_steps_sampled: 135000
    num_steps_trained: 135000
    wait_time_ms: 116.733
  iterations_since_restore: 27
  node_ip: 172.17.8.52
  num_metric_batches_dropped: 0
  pid: 12141
  policy_reward_mean: {}
  time_since_restore: 344.5081696510315
  time_this_iter_s: 12.132010221481323
  time_total_s: 344.5081696510315
  timestamp: 1594137957
  timesteps_since_restore: 135000
  timesteps_this_iter: 5000
  timesteps_total: 135000
  training_iteration: 27
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 22.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=12141], 344 s, 27 iter, 135000 ts, 1.31e+03 rew

agent-1: 246.0
agent-2: 318.0
agent-3: 333.0
agent-4: 329.0
agent-5: 323.0
Sum Reward: 1549.0
Avg Reward: 309.8
Min Reward: 246.0
Max Reward: 333.0
Gini Coefficient: 0.04777275661717237
20:20 Ratio: 1.353658536585366
Max-min Ratio: 1.353658536585366
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_12-06-10
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1677.0
  episode_reward_mean: 1322.8148148148148
  episode_reward_min: 223.0
  episodes_this_iter: 1
  episodes_total: 27
  experiment_id: ebedc1946062457bb682d57fae83bd74
  hostname: gpu052
  info:
    apply_time_ms: 4.034
    dispatch_time_ms: 7.412
    learner:
      cur_lr: 0.0013510090066120028
      grad_gnorm: 39.99999237060547
      policy_entropy: 36.442291259765625
      policy_loss: -9.91331958770752
      var_gnorm: 22.178251266479492
      vf_explained_var: 0.5601829290390015
      vf_loss: 34.261451721191406
    num_steps_sampled: 140000
    num_steps_trained: 140000
    wait_time_ms: 114.849
  iterations_since_restore: 28
  node_ip: 172.17.8.52
  num_metric_batches_dropped: 0
  pid: 12141
  policy_reward_mean: {}
  time_since_restore: 357.9189496040344
  time_this_iter_s: 13.41077995300293
  time_total_s: 357.9189496040344
  timestamp: 1594137970
  timesteps_since_restore: 140000
  timesteps_this_iter: 5000
  timesteps_total: 140000
  training_iteration: 28
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 22.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=12141], 357 s, 28 iter, 140000 ts, 1.32e+03 rew

agent-1: 340.0
agent-2: 346.0
agent-3: 321.0
agent-4: 263.0
agent-5: 329.0
Sum Reward: 1599.0
Avg Reward: 319.8
Min Reward: 263.0
Max Reward: 346.0
Gini Coefficient: 0.046278924327704814
20:20 Ratio: 1.3155893536121672
Max-min Ratio: 1.3155893536121672
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_12-06-24
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1677.0
  episode_reward_mean: 1332.6785714285713
  episode_reward_min: 223.0
  episodes_this_iter: 1
  episodes_total: 28
  experiment_id: ebedc1946062457bb682d57fae83bd74
  hostname: gpu052
  info:
    apply_time_ms: 3.819
    dispatch_time_ms: 8.875
    learner:
      cur_lr: 0.001350675942376256
      grad_gnorm: 40.0000114440918
      policy_entropy: 20.365741729736328
      policy_loss: 5.990347385406494
      var_gnorm: 22.471195220947266
      vf_explained_var: 0.056243717670440674
      vf_loss: 15.130661010742188
    num_steps_sampled: 145000
    num_steps_trained: 145000
    wait_time_ms: 125.452
  iterations_since_restore: 29
  node_ip: 172.17.8.52
  num_metric_batches_dropped: 0
  pid: 12141
  policy_reward_mean: {}
  time_since_restore: 371.11974906921387
  time_this_iter_s: 13.200799465179443
  time_total_s: 371.11974906921387
  timestamp: 1594137984
  timesteps_since_restore: 145000
  timesteps_this_iter: 5000
  timesteps_total: 145000
  training_iteration: 29
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 22.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=12141], 371 s, 29 iter, 145000 ts, 1.33e+03 rew

agent-1: 333.0
agent-2: 330.0
agent-3: 273.0
agent-4: 356.0
agent-5: 343.0
Sum Reward: 1635.0
Avg Reward: 327.0
Min Reward: 273.0
Max Reward: 356.0
Gini Coefficient: 0.04379204892966361
20:20 Ratio: 1.304029304029304
Max-min Ratio: 1.304029304029304
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_12-06-37
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1677.0
  episode_reward_mean: 1343.103448275862
  episode_reward_min: 223.0
  episodes_this_iter: 1
  episodes_total: 29
  experiment_id: ebedc1946062457bb682d57fae83bd74
  hostname: gpu052
  info:
    apply_time_ms: 2.93
    dispatch_time_ms: 6.371
    learner:
      cur_lr: 0.001350342994555831
      grad_gnorm: 40.00000762939453
      policy_entropy: 37.01627731323242
      policy_loss: 9.749185562133789
      var_gnorm: 22.638885498046875
      vf_explained_var: 0.3669230341911316
      vf_loss: 34.1414909362793
    num_steps_sampled: 150000
    num_steps_trained: 150000
    wait_time_ms: 117.765
  iterations_since_restore: 30
  node_ip: 172.17.8.52
  num_metric_batches_dropped: 0
  pid: 12141
  policy_reward_mean: {}
  time_since_restore: 384.8742883205414
  time_this_iter_s: 13.754539251327515
  time_total_s: 384.8742883205414
  timestamp: 1594137997
  timesteps_since_restore: 150000
  timesteps_this_iter: 5000
  timesteps_total: 150000
  training_iteration: 30
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 22.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=12141], 384 s, 30 iter, 150000 ts, 1.34e+03 rew

agent-1: 330.0
agent-2: 342.0
agent-3: 327.0
agent-4: 362.0
agent-5: 295.0
Sum Reward: 1656.0
Avg Reward: 331.2
Min Reward: 295.0
Max Reward: 362.0
Gini Coefficient: 0.03599033816425121
20:20 Ratio: 1.2271186440677966
Max-min Ratio: 1.2271186440677966
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_12-06-50
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1677.0
  episode_reward_mean: 1353.5333333333333
  episode_reward_min: 223.0
  episodes_this_iter: 1
  episodes_total: 30
  experiment_id: ebedc1946062457bb682d57fae83bd74
  hostname: gpu052
  info:
    apply_time_ms: 2.55
    dispatch_time_ms: 6.043
    learner:
      cur_lr: 0.001350010046735406
      grad_gnorm: 39.99999237060547
      policy_entropy: 18.17458724975586
      policy_loss: 23.324522018432617
      var_gnorm: 22.739404678344727
      vf_explained_var: -0.21469247341156006
      vf_loss: 44.395328521728516
    num_steps_sampled: 155000
    num_steps_trained: 155000
    wait_time_ms: 124.229
  iterations_since_restore: 31
  node_ip: 172.17.8.52
  num_metric_batches_dropped: 0
  pid: 12141
  policy_reward_mean: {}
  time_since_restore: 397.7204110622406
  time_this_iter_s: 12.846122741699219
  time_total_s: 397.7204110622406
  timestamp: 1594138010
  timesteps_since_restore: 155000
  timesteps_this_iter: 5000
  timesteps_total: 155000
  training_iteration: 31
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 22.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=12141], 397 s, 31 iter, 155000 ts, 1.35e+03 rew

agent-1: 349.0
agent-2: 384.0
agent-3: 342.0
agent-4: 284.0
agent-5: 366.0
Sum Reward: 1725.0
Avg Reward: 345.0
Min Reward: 284.0
Max Reward: 384.0
Gini Coefficient: 0.051942028985507246
20:20 Ratio: 1.352112676056338
Max-min Ratio: 1.352112676056338
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_12-07-04
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1725.0
  episode_reward_mean: 1365.516129032258
  episode_reward_min: 223.0
  episodes_this_iter: 1
  episodes_total: 31
  experiment_id: ebedc1946062457bb682d57fae83bd74
  hostname: gpu052
  info:
    apply_time_ms: 3.415
    dispatch_time_ms: 7.869
    learner:
      cur_lr: 0.001349676982499659
      grad_gnorm: 39.99997329711914
      policy_entropy: 28.049983978271484
      policy_loss: -18.484651565551758
      var_gnorm: 22.877925872802734
      vf_explained_var: 0.46296417713165283
      vf_loss: 39.70952224731445
    num_steps_sampled: 160000
    num_steps_trained: 160000
    wait_time_ms: 119.657
  iterations_since_restore: 32
  node_ip: 172.17.8.52
  num_metric_batches_dropped: 0
  pid: 12141
  policy_reward_mean: {}
  time_since_restore: 411.1983256340027
  time_this_iter_s: 13.477914571762085
  time_total_s: 411.1983256340027
  timestamp: 1594138024
  timesteps_since_restore: 160000
  timesteps_this_iter: 5000
  timesteps_total: 160000
  training_iteration: 32
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 22.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=12141], 411 s, 32 iter, 160000 ts, 1.37e+03 rew

agent-1: 365.0
agent-2: 365.0
agent-3: 355.0
agent-4: 371.0
agent-5: 389.0
Sum Reward: 1845.0
Avg Reward: 369.0
Min Reward: 355.0
Max Reward: 389.0
Gini Coefficient: 0.016043360433604336
20:20 Ratio: 1.095774647887324
Max-min Ratio: 1.095774647887324
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_12-07-17
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1845.0
  episode_reward_mean: 1380.5
  episode_reward_min: 223.0
  episodes_this_iter: 1
  episodes_total: 32
  experiment_id: ebedc1946062457bb682d57fae83bd74
  hostname: gpu052
  info:
    apply_time_ms: 2.918
    dispatch_time_ms: 8.219
    learner:
      cur_lr: 0.001349344034679234
      grad_gnorm: 40.00000762939453
      policy_entropy: 42.635379791259766
      policy_loss: -24.795574188232422
      var_gnorm: 23.05317497253418
      vf_explained_var: 0.4371883273124695
      vf_loss: 39.960609436035156
    num_steps_sampled: 165000
    num_steps_trained: 165000
    wait_time_ms: 128.044
  iterations_since_restore: 33
  node_ip: 172.17.8.52
  num_metric_batches_dropped: 0
  pid: 12141
  policy_reward_mean: {}
  time_since_restore: 424.235068321228
  time_this_iter_s: 13.036742687225342
  time_total_s: 424.235068321228
  timestamp: 1594138037
  timesteps_since_restore: 165000
  timesteps_this_iter: 5000
  timesteps_total: 165000
  training_iteration: 33
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 23.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=12141], 424 s, 33 iter, 165000 ts, 1.38e+03 rew

agent-1: 301.0
agent-2: 340.0
agent-3: 314.0
agent-4: 329.0
agent-5: 246.0
Sum Reward: 1530.0
Avg Reward: 306.0
Min Reward: 246.0
Max Reward: 340.0
Gini Coefficient: 0.05647058823529412
20:20 Ratio: 1.3821138211382114
Max-min Ratio: 1.3821138211382114
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_12-07-30
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1845.0
  episode_reward_mean: 1385.030303030303
  episode_reward_min: 223.0
  episodes_this_iter: 1
  episodes_total: 33
  experiment_id: ebedc1946062457bb682d57fae83bd74
  hostname: gpu052
  info:
    apply_time_ms: 2.949
    dispatch_time_ms: 6.86
    learner:
      cur_lr: 0.0013490109704434872
      grad_gnorm: 40.00000762939453
      policy_entropy: 31.221086502075195
      policy_loss: -9.01159954071045
      var_gnorm: 23.138225555419922
      vf_explained_var: -0.26398956775665283
      vf_loss: 37.15359115600586
    num_steps_sampled: 170000
    num_steps_trained: 170000
    wait_time_ms: 122.877
  iterations_since_restore: 34
  node_ip: 172.17.8.52
  num_metric_batches_dropped: 0
  pid: 12141
  policy_reward_mean: {}
  time_since_restore: 437.27574157714844
  time_this_iter_s: 13.04067325592041
  time_total_s: 437.27574157714844
  timestamp: 1594138050
  timesteps_since_restore: 170000
  timesteps_this_iter: 5000
  timesteps_total: 170000
  training_iteration: 34
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 23.3/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=12141], 437 s, 34 iter, 170000 ts, 1.39e+03 rew

agent-1: 346.0
agent-2: 307.0
agent-3: 336.0
agent-4: 320.0
agent-5: 362.0
Sum Reward: 1671.0
Avg Reward: 334.2
Min Reward: 307.0
Max Reward: 362.0
Gini Coefficient: 0.032555356074207065
20:20 Ratio: 1.1791530944625408
Max-min Ratio: 1.1791530944625408
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_12-07-43
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1845.0
  episode_reward_mean: 1393.4411764705883
  episode_reward_min: 223.0
  episodes_this_iter: 1
  episodes_total: 34
  experiment_id: ebedc1946062457bb682d57fae83bd74
  hostname: gpu052
  info:
    apply_time_ms: 2.788
    dispatch_time_ms: 6.196
    learner:
      cur_lr: 0.0013486780226230621
      grad_gnorm: 40.00000762939453
      policy_entropy: 23.5238094329834
      policy_loss: 8.404728889465332
      var_gnorm: 23.241121292114258
      vf_explained_var: -0.6438480615615845
      vf_loss: 18.9405460357666
    num_steps_sampled: 175000
    num_steps_trained: 175000
    wait_time_ms: 120.954
  iterations_since_restore: 35
  node_ip: 172.17.8.52
  num_metric_batches_dropped: 0
  pid: 12141
  policy_reward_mean: {}
  time_since_restore: 449.87794637680054
  time_this_iter_s: 12.6022047996521
  time_total_s: 449.87794637680054
  timestamp: 1594138063
  timesteps_since_restore: 175000
  timesteps_this_iter: 5000
  timesteps_total: 175000
  training_iteration: 35
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 23.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=12141], 449 s, 35 iter, 175000 ts, 1.39e+03 rew

agent-1: 340.0
agent-2: 336.0
agent-3: 330.0
agent-4: 370.0
agent-5: 317.0
Sum Reward: 1693.0
Avg Reward: 338.6
Min Reward: 317.0
Max Reward: 370.0
Gini Coefficient: 0.027406969875959836
20:20 Ratio: 1.167192429022082
Max-min Ratio: 1.167192429022082
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_12-07-57
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1845.0
  episode_reward_mean: 1402.0
  episode_reward_min: 223.0
  episodes_this_iter: 1
  episodes_total: 35
  experiment_id: ebedc1946062457bb682d57fae83bd74
  hostname: gpu052
  info:
    apply_time_ms: 3.063
    dispatch_time_ms: 7.078
    learner:
      cur_lr: 0.0013483449583873153
      grad_gnorm: 40.00001525878906
      policy_entropy: 28.276506423950195
      policy_loss: 1.8236329555511475
      var_gnorm: 23.341623306274414
      vf_explained_var: 0.23632222414016724
      vf_loss: 29.379684448242188
    num_steps_sampled: 180000
    num_steps_trained: 180000
    wait_time_ms: 114.796
  iterations_since_restore: 36
  node_ip: 172.17.8.52
  num_metric_batches_dropped: 0
  pid: 12141
  policy_reward_mean: {}
  time_since_restore: 463.9187219142914
  time_this_iter_s: 14.040775537490845
  time_total_s: 463.9187219142914
  timestamp: 1594138077
  timesteps_since_restore: 180000
  timesteps_this_iter: 5000
  timesteps_total: 180000
  training_iteration: 36
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 23.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=12141], 463 s, 36 iter, 180000 ts, 1.4e+03 rew

agent-1: 328.0
agent-2: 347.0
agent-3: 357.0
agent-4: 346.0
agent-5: 316.0
Sum Reward: 1694.0
Avg Reward: 338.8
Min Reward: 316.0
Max Reward: 357.0
Gini Coefficient: 0.02384887839433294
20:20 Ratio: 1.129746835443038
Max-min Ratio: 1.129746835443038
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_12-08-10
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1845.0
  episode_reward_mean: 1410.111111111111
  episode_reward_min: 223.0
  episodes_this_iter: 1
  episodes_total: 36
  experiment_id: ebedc1946062457bb682d57fae83bd74
  hostname: gpu052
  info:
    apply_time_ms: 3.354
    dispatch_time_ms: 6.365
    learner:
      cur_lr: 0.0013480120105668902
      grad_gnorm: 40.0
      policy_entropy: 25.426870346069336
      policy_loss: 15.309806823730469
      var_gnorm: 23.475479125976562
      vf_explained_var: 0.3010401129722595
      vf_loss: 35.28840255737305
    num_steps_sampled: 185000
    num_steps_trained: 185000
    wait_time_ms: 124.174
  iterations_since_restore: 37
  node_ip: 172.17.8.52
  num_metric_batches_dropped: 0
  pid: 12141
  policy_reward_mean: {}
  time_since_restore: 476.88293647766113
  time_this_iter_s: 12.964214563369751
  time_total_s: 476.88293647766113
  timestamp: 1594138090
  timesteps_since_restore: 185000
  timesteps_this_iter: 5000
  timesteps_total: 185000
  training_iteration: 37
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 23.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=12141], 476 s, 37 iter, 185000 ts, 1.41e+03 rew

agent-1: 338.0
agent-2: 366.0
agent-3: 361.0
agent-4: 334.0
agent-5: 352.0
Sum Reward: 1751.0
Avg Reward: 350.2
Min Reward: 334.0
Max Reward: 366.0
Gini Coefficient: 0.01987435750999429
20:20 Ratio: 1.095808383233533
Max-min Ratio: 1.095808383233533
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_12-08-23
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1845.0
  episode_reward_mean: 1419.3243243243244
  episode_reward_min: 223.0
  episodes_this_iter: 1
  episodes_total: 37
  experiment_id: ebedc1946062457bb682d57fae83bd74
  hostname: gpu052
  info:
    apply_time_ms: 2.823
    dispatch_time_ms: 6.74
    learner:
      cur_lr: 0.0013476789463311434
      grad_gnorm: 39.99998474121094
      policy_entropy: 30.724172592163086
      policy_loss: 16.169130325317383
      var_gnorm: 23.54049301147461
      vf_explained_var: 0.14513391256332397
      vf_loss: 81.72937774658203
    num_steps_sampled: 190000
    num_steps_trained: 190000
    wait_time_ms: 126.706
  iterations_since_restore: 38
  node_ip: 172.17.8.52
  num_metric_batches_dropped: 0
  pid: 12141
  policy_reward_mean: {}
  time_since_restore: 490.24661660194397
  time_this_iter_s: 13.363680124282837
  time_total_s: 490.24661660194397
  timestamp: 1594138103
  timesteps_since_restore: 190000
  timesteps_this_iter: 5000
  timesteps_total: 190000
  training_iteration: 38
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 24.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=12141], 490 s, 38 iter, 190000 ts, 1.42e+03 rew

agent-1: 360.0
agent-2: 345.0
agent-3: 353.0
agent-4: 350.0
agent-5: 334.0
Sum Reward: 1742.0
Avg Reward: 348.4
Min Reward: 334.0
Max Reward: 360.0
Gini Coefficient: 0.013777267508610792
20:20 Ratio: 1.0778443113772456
Max-min Ratio: 1.0778443113772456
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_12-08-37
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1845.0
  episode_reward_mean: 1427.8157894736842
  episode_reward_min: 223.0
  episodes_this_iter: 1
  episodes_total: 38
  experiment_id: ebedc1946062457bb682d57fae83bd74
  hostname: gpu052
  info:
    apply_time_ms: 3.113
    dispatch_time_ms: 14.129
    learner:
      cur_lr: 0.0013473459985107183
      grad_gnorm: 40.00000762939453
      policy_entropy: 24.98554229736328
      policy_loss: -12.470575332641602
      var_gnorm: 23.639404296875
      vf_explained_var: 0.42525702714920044
      vf_loss: 22.2182559967041
    num_steps_sampled: 195000
    num_steps_trained: 195000
    wait_time_ms: 129.248
  iterations_since_restore: 39
  node_ip: 172.17.8.52
  num_metric_batches_dropped: 0
  pid: 12141
  policy_reward_mean: {}
  time_since_restore: 503.71044874191284
  time_this_iter_s: 13.463832139968872
  time_total_s: 503.71044874191284
  timestamp: 1594138117
  timesteps_since_restore: 195000
  timesteps_this_iter: 5000
  timesteps_total: 195000
  training_iteration: 39
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 24.3/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=12141], 503 s, 39 iter, 195000 ts, 1.43e+03 rew

agent-1: 332.0
agent-2: 310.0
agent-3: 287.0
agent-4: 307.0
agent-5: 348.0
Sum Reward: 1584.0
Avg Reward: 316.8
Min Reward: 287.0
Max Reward: 348.0
Gini Coefficient: 0.037121212121212124
20:20 Ratio: 1.2125435540069687
Max-min Ratio: 1.2125435540069687
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_12-08-51
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1845.0
  episode_reward_mean: 1431.820512820513
  episode_reward_min: 223.0
  episodes_this_iter: 1
  episodes_total: 39
  experiment_id: ebedc1946062457bb682d57fae83bd74
  hostname: gpu052
  info:
    apply_time_ms: 3.57
    dispatch_time_ms: 7.197
    learner:
      cur_lr: 0.0013470130506902933
      grad_gnorm: 40.00001907348633
      policy_entropy: 30.60823631286621
      policy_loss: -2.3259634971618652
      var_gnorm: 23.832305908203125
      vf_explained_var: 0.007328331470489502
      vf_loss: 39.88962936401367
    num_steps_sampled: 200000
    num_steps_trained: 200000
    wait_time_ms: 112.109
  iterations_since_restore: 40
  node_ip: 172.17.8.52
  num_metric_batches_dropped: 0
  pid: 12141
  policy_reward_mean: {}
  time_since_restore: 518.4385793209076
  time_this_iter_s: 14.728130578994751
  time_total_s: 518.4385793209076
  timestamp: 1594138131
  timesteps_since_restore: 200000
  timesteps_this_iter: 5000
  timesteps_total: 200000
  training_iteration: 40
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 24.3/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=12141], 518 s, 40 iter, 200000 ts, 1.43e+03 rew

agent-1: 358.0
agent-2: 370.0
agent-3: 360.0
agent-4: 321.0
agent-5: 319.0
Sum Reward: 1728.0
Avg Reward: 345.6
Min Reward: 319.0
Max Reward: 370.0
Gini Coefficient: 0.03263888888888889
20:20 Ratio: 1.1598746081504703
Max-min Ratio: 1.1598746081504703
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_12-09-05
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1845.0
  episode_reward_mean: 1439.225
  episode_reward_min: 223.0
  episodes_this_iter: 1
  episodes_total: 40
  experiment_id: ebedc1946062457bb682d57fae83bd74
  hostname: gpu052
  info:
    apply_time_ms: 3.008
    dispatch_time_ms: 7.0
    learner:
      cur_lr: 0.0013466799864545465
      grad_gnorm: 40.0
      policy_entropy: 33.222957611083984
      policy_loss: -15.687356948852539
      var_gnorm: 23.928495407104492
      vf_explained_var: -0.01729452610015869
      vf_loss: 17.070085525512695
    num_steps_sampled: 205000
    num_steps_trained: 205000
    wait_time_ms: 138.159
  iterations_since_restore: 41
  node_ip: 172.17.8.52
  num_metric_batches_dropped: 0
  pid: 12141
  policy_reward_mean: {}
  time_since_restore: 531.7356188297272
  time_this_iter_s: 13.29703950881958
  time_total_s: 531.7356188297272
  timestamp: 1594138145
  timesteps_since_restore: 205000
  timesteps_this_iter: 5000
  timesteps_total: 205000
  training_iteration: 41
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 24.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=12141], 531 s, 41 iter, 205000 ts, 1.44e+03 rew

agent-1: 324.0
agent-2: 305.0
agent-3: 283.0
agent-4: 325.0
agent-5: 363.0
Sum Reward: 1600.0
Avg Reward: 320.0
Min Reward: 283.0
Max Reward: 363.0
Gini Coefficient: 0.045
20:20 Ratio: 1.2826855123674912
Max-min Ratio: 1.2826855123674912
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_12-09-19
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1845.0
  episode_reward_mean: 1443.1463414634147
  episode_reward_min: 223.0
  episodes_this_iter: 1
  episodes_total: 41
  experiment_id: ebedc1946062457bb682d57fae83bd74
  hostname: gpu052
  info:
    apply_time_ms: 4.379
    dispatch_time_ms: 7.815
    learner:
      cur_lr: 0.0013463470386341214
      grad_gnorm: 39.99999237060547
      policy_entropy: 19.296937942504883
      policy_loss: 10.722363471984863
      var_gnorm: 23.966354370117188
      vf_explained_var: 0.06537359952926636
      vf_loss: 30.33812141418457
    num_steps_sampled: 210000
    num_steps_trained: 210000
    wait_time_ms: 126.535
  iterations_since_restore: 42
  node_ip: 172.17.8.52
  num_metric_batches_dropped: 0
  pid: 12141
  policy_reward_mean: {}
  time_since_restore: 545.7056517601013
  time_this_iter_s: 13.970032930374146
  time_total_s: 545.7056517601013
  timestamp: 1594138159
  timesteps_since_restore: 210000
  timesteps_this_iter: 5000
  timesteps_total: 210000
  training_iteration: 42
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 24.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=12141], 545 s, 42 iter, 210000 ts, 1.44e+03 rew

agent-1: 313.0
agent-2: 339.0
agent-3: 342.0
agent-4: 363.0
agent-5: 365.0
Sum Reward: 1722.0
Avg Reward: 344.4
Min Reward: 313.0
Max Reward: 365.0
Gini Coefficient: 0.029732868757259
20:20 Ratio: 1.1661341853035143
Max-min Ratio: 1.1661341853035143
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_12-09-32
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1845.0
  episode_reward_mean: 1449.7857142857142
  episode_reward_min: 223.0
  episodes_this_iter: 1
  episodes_total: 42
  experiment_id: ebedc1946062457bb682d57fae83bd74
  hostname: gpu052
  info:
    apply_time_ms: 2.647
    dispatch_time_ms: 6.409
    learner:
      cur_lr: 0.0013460139743983746
      grad_gnorm: 40.000003814697266
      policy_entropy: 28.683521270751953
      policy_loss: -1.6376453638076782
      var_gnorm: 24.107969284057617
      vf_explained_var: 0.3003970980644226
      vf_loss: 90.80397033691406
    num_steps_sampled: 215000
    num_steps_trained: 215000
    wait_time_ms: 139.684
  iterations_since_restore: 43
  node_ip: 172.17.8.52
  num_metric_batches_dropped: 0
  pid: 12141
  policy_reward_mean: {}
  time_since_restore: 559.4471242427826
  time_this_iter_s: 13.741472482681274
  time_total_s: 559.4471242427826
  timestamp: 1594138172
  timesteps_since_restore: 215000
  timesteps_this_iter: 5000
  timesteps_total: 215000
  training_iteration: 43
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=12141], 559 s, 43 iter, 215000 ts, 1.45e+03 rew

agent-1: 284.0
agent-2: 337.0
agent-3: 330.0
agent-4: 344.0
agent-5: 339.0
Sum Reward: 1634.0
Avg Reward: 326.8
Min Reward: 284.0
Max Reward: 344.0
Gini Coefficient: 0.031578947368421054
20:20 Ratio: 1.2112676056338028
Max-min Ratio: 1.2112676056338028
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_12-09-47
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1845.0
  episode_reward_mean: 1454.0697674418604
  episode_reward_min: 223.0
  episodes_this_iter: 1
  episodes_total: 43
  experiment_id: ebedc1946062457bb682d57fae83bd74
  hostname: gpu052
  info:
    apply_time_ms: 3.112
    dispatch_time_ms: 7.968
    learner:
      cur_lr: 0.0013456810265779495
      grad_gnorm: 40.000003814697266
      policy_entropy: 37.250404357910156
      policy_loss: -33.48834228515625
      var_gnorm: 24.264123916625977
      vf_explained_var: 0.00968712568283081
      vf_loss: 69.96327209472656
    num_steps_sampled: 220000
    num_steps_trained: 220000
    wait_time_ms: 116.995
  iterations_since_restore: 44
  node_ip: 172.17.8.52
  num_metric_batches_dropped: 0
  pid: 12141
  policy_reward_mean: {}
  time_since_restore: 574.3938808441162
  time_this_iter_s: 14.946756601333618
  time_total_s: 574.3938808441162
  timestamp: 1594138187
  timesteps_since_restore: 220000
  timesteps_this_iter: 5000
  timesteps_total: 220000
  training_iteration: 44
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=12141], 574 s, 44 iter, 220000 ts, 1.45e+03 rew

agent-1: 323.0
agent-2: 293.0
agent-3: 315.0
agent-4: 290.0
agent-5: 236.0
Sum Reward: 1457.0
Avg Reward: 291.4
Min Reward: 236.0
Max Reward: 323.0
Gini Coefficient: 0.0546328071379547
20:20 Ratio: 1.36864406779661
Max-min Ratio: 1.36864406779661
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_12-10-00
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1845.0
  episode_reward_mean: 1454.1363636363637
  episode_reward_min: 223.0
  episodes_this_iter: 1
  episodes_total: 44
  experiment_id: ebedc1946062457bb682d57fae83bd74
  hostname: gpu052
  info:
    apply_time_ms: 3.418
    dispatch_time_ms: 8.7
    learner:
      cur_lr: 0.0013453479623422027
      grad_gnorm: 40.000030517578125
      policy_entropy: 25.403718948364258
      policy_loss: -5.778441429138184
      var_gnorm: 24.278757095336914
      vf_explained_var: 0.027757883071899414
      vf_loss: 21.909116744995117
    num_steps_sampled: 225000
    num_steps_trained: 225000
    wait_time_ms: 125.791
  iterations_since_restore: 45
  node_ip: 172.17.8.52
  num_metric_batches_dropped: 0
  pid: 12141
  policy_reward_mean: {}
  time_since_restore: 587.332540512085
  time_this_iter_s: 12.93865966796875
  time_total_s: 587.332540512085
  timestamp: 1594138200
  timesteps_since_restore: 225000
  timesteps_this_iter: 5000
  timesteps_total: 225000
  training_iteration: 45
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=12141], 587 s, 45 iter, 225000 ts, 1.45e+03 rew

agent-1: 372.0
agent-2: 392.0
agent-3: 329.0
agent-4: 299.0
agent-5: 324.0
Sum Reward: 1716.0
Avg Reward: 343.2
Min Reward: 299.0
Max Reward: 392.0
Gini Coefficient: 0.05454545454545454
20:20 Ratio: 1.3110367892976589
Max-min Ratio: 1.3110367892976589
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_12-10-14
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1845.0
  episode_reward_mean: 1459.9555555555555
  episode_reward_min: 223.0
  episodes_this_iter: 1
  episodes_total: 45
  experiment_id: ebedc1946062457bb682d57fae83bd74
  hostname: gpu052
  info:
    apply_time_ms: 3.146
    dispatch_time_ms: 6.411
    learner:
      cur_lr: 0.0013450150145217776
      grad_gnorm: 40.0
      policy_entropy: 13.2908935546875
      policy_loss: 9.530779838562012
      var_gnorm: 24.435564041137695
      vf_explained_var: 0.6199835538864136
      vf_loss: 35.4425048828125
    num_steps_sampled: 230000
    num_steps_trained: 230000
    wait_time_ms: 132.404
  iterations_since_restore: 46
  node_ip: 172.17.8.52
  num_metric_batches_dropped: 0
  pid: 12141
  policy_reward_mean: {}
  time_since_restore: 601.1092240810394
  time_this_iter_s: 13.776683568954468
  time_total_s: 601.1092240810394
  timestamp: 1594138214
  timesteps_since_restore: 230000
  timesteps_this_iter: 5000
  timesteps_total: 230000
  training_iteration: 46
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=12141], 601 s, 46 iter, 230000 ts, 1.46e+03 rew

agent-1: 353.0
agent-2: 378.0
agent-3: 339.0
agent-4: 377.0
agent-5: 337.0
Sum Reward: 1784.0
Avg Reward: 356.8
Min Reward: 337.0
Max Reward: 378.0
Gini Coefficient: 0.026905829596412557
20:20 Ratio: 1.1216617210682494
Max-min Ratio: 1.1216617210682494
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_12-10-28
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1845.0
  episode_reward_mean: 1467.0
  episode_reward_min: 223.0
  episodes_this_iter: 1
  episodes_total: 46
  experiment_id: ebedc1946062457bb682d57fae83bd74
  hostname: gpu052
  info:
    apply_time_ms: 3.614
    dispatch_time_ms: 6.602
    learner:
      cur_lr: 0.0013446819502860308
      grad_gnorm: 39.999996185302734
      policy_entropy: 17.154062271118164
      policy_loss: 1.0029923915863037
      var_gnorm: 24.636695861816406
      vf_explained_var: 0.34012162685394287
      vf_loss: 30.062728881835938
    num_steps_sampled: 235000
    num_steps_trained: 235000
    wait_time_ms: 141.276
  iterations_since_restore: 47
  node_ip: 172.17.8.52
  num_metric_batches_dropped: 0
  pid: 12141
  policy_reward_mean: {}
  time_since_restore: 614.9079129695892
  time_this_iter_s: 13.798688888549805
  time_total_s: 614.9079129695892
  timestamp: 1594138228
  timesteps_since_restore: 235000
  timesteps_this_iter: 5000
  timesteps_total: 235000
  training_iteration: 47
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=12141], 614 s, 47 iter, 235000 ts, 1.47e+03 rew

agent-1: 312.0
agent-2: 322.0
agent-3: 301.0
agent-4: 345.0
agent-5: 318.0
Sum Reward: 1598.0
Avg Reward: 319.6
Min Reward: 301.0
Max Reward: 345.0
Gini Coefficient: 0.024530663329161453
20:20 Ratio: 1.1461794019933556
Max-min Ratio: 1.1461794019933556
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_12-10-42
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1845.0
  episode_reward_mean: 1469.787234042553
  episode_reward_min: 223.0
  episodes_this_iter: 1
  episodes_total: 47
  experiment_id: ebedc1946062457bb682d57fae83bd74
  hostname: gpu052
  info:
    apply_time_ms: 4.02
    dispatch_time_ms: 11.013
    learner:
      cur_lr: 0.0013443490024656057
      grad_gnorm: 40.000003814697266
      policy_entropy: 16.889427185058594
      policy_loss: -1.0474220514297485
      var_gnorm: 24.664716720581055
      vf_explained_var: 0.48279136419296265
      vf_loss: 21.107709884643555
    num_steps_sampled: 240000
    num_steps_trained: 240000
    wait_time_ms: 115.45
  iterations_since_restore: 48
  node_ip: 172.17.8.52
  num_metric_batches_dropped: 0
  pid: 12141
  policy_reward_mean: {}
  time_since_restore: 628.6770262718201
  time_this_iter_s: 13.769113302230835
  time_total_s: 628.6770262718201
  timestamp: 1594138242
  timesteps_since_restore: 240000
  timesteps_this_iter: 5000
  timesteps_total: 240000
  training_iteration: 48
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.3/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=12141], 628 s, 48 iter, 240000 ts, 1.47e+03 rew

agent-1: 360.0
agent-2: 377.0
agent-3: 327.0
agent-4: 363.0
agent-5: 385.0
Sum Reward: 1812.0
Avg Reward: 362.4
Min Reward: 327.0
Max Reward: 385.0
Gini Coefficient: 0.029359823399558498
20:20 Ratio: 1.1773700305810397
Max-min Ratio: 1.1773700305810397
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_12-10-55
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1845.0
  episode_reward_mean: 1476.9166666666667
  episode_reward_min: 223.0
  episodes_this_iter: 1
  episodes_total: 48
  experiment_id: ebedc1946062457bb682d57fae83bd74
  hostname: gpu052
  info:
    apply_time_ms: 2.763
    dispatch_time_ms: 6.742
    learner:
      cur_lr: 0.0013440160546451807
      grad_gnorm: 40.00003433227539
      policy_entropy: 17.91069793701172
      policy_loss: 5.272520542144775
      var_gnorm: 24.76458168029785
      vf_explained_var: 0.5332281589508057
      vf_loss: 26.47269630432129
    num_steps_sampled: 245000
    num_steps_trained: 245000
    wait_time_ms: 125.162
  iterations_since_restore: 49
  node_ip: 172.17.8.52
  num_metric_batches_dropped: 0
  pid: 12141
  policy_reward_mean: {}
  time_since_restore: 641.6321399211884
  time_this_iter_s: 12.955113649368286
  time_total_s: 641.6321399211884
  timestamp: 1594138255
  timesteps_since_restore: 245000
  timesteps_this_iter: 5000
  timesteps_total: 245000
  training_iteration: 49
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=12141], 641 s, 49 iter, 245000 ts, 1.48e+03 rew

agent-1: 379.0
agent-2: 403.0
agent-3: 370.0
agent-4: 379.0
agent-5: 374.0
Sum Reward: 1905.0
Avg Reward: 381.0
Min Reward: 370.0
Max Reward: 403.0
Gini Coefficient: 0.014908136482939633
20:20 Ratio: 1.0891891891891892
Max-min Ratio: 1.0891891891891892
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_12-11-09
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1905.0
  episode_reward_mean: 1485.6530612244899
  episode_reward_min: 223.0
  episodes_this_iter: 1
  episodes_total: 49
  experiment_id: ebedc1946062457bb682d57fae83bd74
  hostname: gpu052
  info:
    apply_time_ms: 3.07
    dispatch_time_ms: 6.847
    learner:
      cur_lr: 0.0013436829904094338
      grad_gnorm: 40.000003814697266
      policy_entropy: 16.16919708251953
      policy_loss: 6.623518943786621
      var_gnorm: 24.866575241088867
      vf_explained_var: 0.5438879728317261
      vf_loss: 27.153644561767578
    num_steps_sampled: 250000
    num_steps_trained: 250000
    wait_time_ms: 138.443
  iterations_since_restore: 50
  node_ip: 172.17.8.52
  num_metric_batches_dropped: 0
  pid: 12141
  policy_reward_mean: {}
  time_since_restore: 655.6113479137421
  time_this_iter_s: 13.979207992553711
  time_total_s: 655.6113479137421
  timestamp: 1594138269
  timesteps_since_restore: 250000
  timesteps_this_iter: 5000
  timesteps_total: 250000
  training_iteration: 50
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=12141], 655 s, 50 iter, 250000 ts, 1.49e+03 rew

agent-1: 342.0
agent-2: 387.0
agent-3: 265.0
agent-4: 362.0
agent-5: 403.0
Sum Reward: 1759.0
Avg Reward: 351.8
Min Reward: 265.0
Max Reward: 403.0
Gini Coefficient: 0.07299602046617397
20:20 Ratio: 1.5207547169811322
Max-min Ratio: 1.5207547169811322
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_12-11-23
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1905.0
  episode_reward_mean: 1491.12
  episode_reward_min: 223.0
  episodes_this_iter: 1
  episodes_total: 50
  experiment_id: ebedc1946062457bb682d57fae83bd74
  hostname: gpu052
  info:
    apply_time_ms: 2.849
    dispatch_time_ms: 7.32
    learner:
      cur_lr: 0.0013433500425890088
      grad_gnorm: 39.99997329711914
      policy_entropy: 18.604169845581055
      policy_loss: -8.404901504516602
      var_gnorm: 24.928373336791992
      vf_explained_var: 0.5605618357658386
      vf_loss: 33.98405456542969
    num_steps_sampled: 255000
    num_steps_trained: 255000
    wait_time_ms: 137.095
  iterations_since_restore: 51
  node_ip: 172.17.8.52
  num_metric_batches_dropped: 0
  pid: 12141
  policy_reward_mean: {}
  time_since_restore: 669.8456878662109
  time_this_iter_s: 14.234339952468872
  time_total_s: 669.8456878662109
  timestamp: 1594138283
  timesteps_since_restore: 255000
  timesteps_this_iter: 5000
  timesteps_total: 255000
  training_iteration: 51
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=12141], 669 s, 51 iter, 255000 ts, 1.49e+03 rew

agent-1: 256.0
agent-2: 306.0
agent-3: 304.0
agent-4: 319.0
agent-5: 292.0
Sum Reward: 1477.0
Avg Reward: 295.4
Min Reward: 256.0
Max Reward: 319.0
Gini Coefficient: 0.037914691943127965
20:20 Ratio: 1.24609375
Max-min Ratio: 1.24609375
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_12-11-38
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1905.0
  episode_reward_mean: 1490.8431372549019
  episode_reward_min: 223.0
  episodes_this_iter: 1
  episodes_total: 51
  experiment_id: ebedc1946062457bb682d57fae83bd74
  hostname: gpu052
  info:
    apply_time_ms: 2.925
    dispatch_time_ms: 7.31
    learner:
      cur_lr: 0.001343016978353262
      grad_gnorm: 40.0
      policy_entropy: 21.094823837280273
      policy_loss: -13.34345817565918
      var_gnorm: 25.21360206604004
      vf_explained_var: 0.4584071636199951
      vf_loss: 46.04177474975586
    num_steps_sampled: 260000
    num_steps_trained: 260000
    wait_time_ms: 123.891
  iterations_since_restore: 52
  node_ip: 172.17.8.52
  num_metric_batches_dropped: 0
  pid: 12141
  policy_reward_mean: {}
  time_since_restore: 684.587996006012
  time_this_iter_s: 14.742308139801025
  time_total_s: 684.587996006012
  timestamp: 1594138298
  timesteps_since_restore: 260000
  timesteps_this_iter: 5000
  timesteps_total: 260000
  training_iteration: 52
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 27.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=12141], 684 s, 52 iter, 260000 ts, 1.49e+03 rew

agent-1: 368.0
agent-2: 346.0
agent-3: 345.0
agent-4: 346.0
agent-5: 386.0
Sum Reward: 1791.0
Avg Reward: 358.2
Min Reward: 345.0
Max Reward: 386.0
Gini Coefficient: 0.023227247347850363
20:20 Ratio: 1.1188405797101448
Max-min Ratio: 1.1188405797101448
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_12-11-52
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1905.0
  episode_reward_mean: 1496.6153846153845
  episode_reward_min: 223.0
  episodes_this_iter: 1
  episodes_total: 52
  experiment_id: ebedc1946062457bb682d57fae83bd74
  hostname: gpu052
  info:
    apply_time_ms: 3.087
    dispatch_time_ms: 9.483
    learner:
      cur_lr: 0.001342684030532837
      grad_gnorm: 40.00000762939453
      policy_entropy: 21.154592514038086
      policy_loss: 21.128070831298828
      var_gnorm: 25.387083053588867
      vf_explained_var: 0.30482643842697144
      vf_loss: 51.723567962646484
    num_steps_sampled: 265000
    num_steps_trained: 265000
    wait_time_ms: 135.934
  iterations_since_restore: 53
  node_ip: 172.17.8.52
  num_metric_batches_dropped: 0
  pid: 12141
  policy_reward_mean: {}
  time_since_restore: 698.2978208065033
  time_this_iter_s: 13.709824800491333
  time_total_s: 698.2978208065033
  timestamp: 1594138312
  timesteps_since_restore: 265000
  timesteps_this_iter: 5000
  timesteps_total: 265000
  training_iteration: 53
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 27.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=12141], 698 s, 53 iter, 265000 ts, 1.5e+03 rew

agent-1: 349.0
agent-2: 312.0
agent-3: 339.0
agent-4: 344.0
agent-5: 338.0
Sum Reward: 1682.0
Avg Reward: 336.4
Min Reward: 312.0
Max Reward: 349.0
Gini Coefficient: 0.019024970273483946
20:20 Ratio: 1.1185897435897436
Max-min Ratio: 1.1185897435897436
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_12-12-07
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1905.0
  episode_reward_mean: 1500.1132075471698
  episode_reward_min: 223.0
  episodes_this_iter: 1
  episodes_total: 53
  experiment_id: ebedc1946062457bb682d57fae83bd74
  hostname: gpu052
  info:
    apply_time_ms: 2.854
    dispatch_time_ms: 6.045
    learner:
      cur_lr: 0.00134235096629709
      grad_gnorm: 40.0
      policy_entropy: 44.491180419921875
      policy_loss: -31.26894187927246
      var_gnorm: 25.48554039001465
      vf_explained_var: 0.13475143909454346
      vf_loss: 78.20292663574219
    num_steps_sampled: 270000
    num_steps_trained: 270000
    wait_time_ms: 133.006
  iterations_since_restore: 54
  node_ip: 172.17.8.52
  num_metric_batches_dropped: 0
  pid: 12141
  policy_reward_mean: {}
  time_since_restore: 713.4402916431427
  time_this_iter_s: 15.142470836639404
  time_total_s: 713.4402916431427
  timestamp: 1594138327
  timesteps_since_restore: 270000
  timesteps_this_iter: 5000
  timesteps_total: 270000
  training_iteration: 54
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 27.3/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=12141], 713 s, 54 iter, 270000 ts, 1.5e+03 rew

agent-1: 271.0
agent-2: 343.0
agent-3: 295.0
agent-4: 366.0
agent-5: 293.0
Sum Reward: 1568.0
Avg Reward: 313.6
Min Reward: 271.0
Max Reward: 366.0
Gini Coefficient: 0.061224489795918366
20:20 Ratio: 1.3505535055350553
Max-min Ratio: 1.3505535055350553
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_12-12-21
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1905.0
  episode_reward_mean: 1501.3703703703704
  episode_reward_min: 223.0
  episodes_this_iter: 1
  episodes_total: 54
  experiment_id: ebedc1946062457bb682d57fae83bd74
  hostname: gpu052
  info:
    apply_time_ms: 3.467
    dispatch_time_ms: 7.521
    learner:
      cur_lr: 0.001342018018476665
      grad_gnorm: 39.99999237060547
      policy_entropy: 13.101536750793457
      policy_loss: 15.765363693237305
      var_gnorm: 25.62923240661621
      vf_explained_var: 0.02970820665359497
      vf_loss: 52.001792907714844
    num_steps_sampled: 275000
    num_steps_trained: 275000
    wait_time_ms: 126.189
  iterations_since_restore: 55
  node_ip: 172.17.8.52
  num_metric_batches_dropped: 0
  pid: 12141
  policy_reward_mean: {}
  time_since_restore: 727.7490890026093
  time_this_iter_s: 14.308797359466553
  time_total_s: 727.7490890026093
  timestamp: 1594138341
  timesteps_since_restore: 275000
  timesteps_this_iter: 5000
  timesteps_total: 275000
  training_iteration: 55
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 27.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=12141], 727 s, 55 iter, 275000 ts, 1.5e+03 rew

agent-1: 334.0
agent-2: 372.0
agent-3: 274.0
agent-4: 280.0
agent-5: 290.0
Sum Reward: 1550.0
Avg Reward: 310.0
Min Reward: 274.0
Max Reward: 372.0
Gini Coefficient: 0.06451612903225806
20:20 Ratio: 1.3576642335766422
Max-min Ratio: 1.3576642335766422
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_12-12-36
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1905.0
  episode_reward_mean: 1502.2545454545455
  episode_reward_min: 223.0
  episodes_this_iter: 1
  episodes_total: 55
  experiment_id: ebedc1946062457bb682d57fae83bd74
  hostname: gpu052
  info:
    apply_time_ms: 2.833
    dispatch_time_ms: 7.03
    learner:
      cur_lr: 0.0013416849542409182
      grad_gnorm: 40.00000762939453
      policy_entropy: 26.80534553527832
      policy_loss: -5.5971245765686035
      var_gnorm: 25.77536964416504
      vf_explained_var: 0.4172215461730957
      vf_loss: 33.14937973022461
    num_steps_sampled: 280000
    num_steps_trained: 280000
    wait_time_ms: 117.825
  iterations_since_restore: 56
  node_ip: 172.17.8.52
  num_metric_batches_dropped: 0
  pid: 12141
  policy_reward_mean: {}
  time_since_restore: 742.6783676147461
  time_this_iter_s: 14.92927861213684
  time_total_s: 742.6783676147461
  timestamp: 1594138356
  timesteps_since_restore: 280000
  timesteps_this_iter: 5000
  timesteps_total: 280000
  training_iteration: 56
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 27.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=12141], 742 s, 56 iter, 280000 ts, 1.5e+03 rew

agent-1: 275.0
agent-2: 399.0
agent-3: 385.0
agent-4: 362.0
agent-5: 387.0
Sum Reward: 1808.0
Avg Reward: 361.6
Min Reward: 275.0
Max Reward: 399.0
Gini Coefficient: 0.060398230088495576
20:20 Ratio: 1.450909090909091
Max-min Ratio: 1.450909090909091
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_12-12-50
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1905.0
  episode_reward_mean: 1507.7142857142858
  episode_reward_min: 223.0
  episodes_this_iter: 1
  episodes_total: 56
  experiment_id: ebedc1946062457bb682d57fae83bd74
  hostname: gpu052
  info:
    apply_time_ms: 2.909
    dispatch_time_ms: 6.658
    learner:
      cur_lr: 0.0013413520064204931
      grad_gnorm: 40.000003814697266
      policy_entropy: 28.15414810180664
      policy_loss: -13.756719589233398
      var_gnorm: 25.903207778930664
      vf_explained_var: 0.5004872679710388
      vf_loss: 58.712154388427734
    num_steps_sampled: 285000
    num_steps_trained: 285000
    wait_time_ms: 143.12
  iterations_since_restore: 57
  node_ip: 172.17.8.52
  num_metric_batches_dropped: 0
  pid: 12141
  policy_reward_mean: {}
  time_since_restore: 756.5585842132568
  time_this_iter_s: 13.880216598510742
  time_total_s: 756.5585842132568
  timestamp: 1594138370
  timesteps_since_restore: 285000
  timesteps_this_iter: 5000
  timesteps_total: 285000
  training_iteration: 57
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 27.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=12141], 756 s, 57 iter, 285000 ts, 1.51e+03 rew

agent-1: 303.0
agent-2: 338.0
agent-3: 302.0
agent-4: 344.0
agent-5: 281.0
Sum Reward: 1568.0
Avg Reward: 313.6
Min Reward: 281.0
Max Reward: 344.0
Gini Coefficient: 0.0413265306122449
20:20 Ratio: 1.2241992882562278
Max-min Ratio: 1.2241992882562278
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_12-13-06
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1905.0
  episode_reward_mean: 1508.7719298245613
  episode_reward_min: 223.0
  episodes_this_iter: 1
  episodes_total: 57
  experiment_id: ebedc1946062457bb682d57fae83bd74
  hostname: gpu052
  info:
    apply_time_ms: 3.935
    dispatch_time_ms: 6.541
    learner:
      cur_lr: 0.0013410189421847463
      grad_gnorm: 39.99998092651367
      policy_entropy: 25.13558578491211
      policy_loss: -40.5675048828125
      var_gnorm: 25.98531723022461
      vf_explained_var: 0.4077818989753723
      vf_loss: 78.5395736694336
    num_steps_sampled: 290000
    num_steps_trained: 290000
    wait_time_ms: 134.105
  iterations_since_restore: 58
  node_ip: 172.17.8.52
  num_metric_batches_dropped: 0
  pid: 12141
  policy_reward_mean: {}
  time_since_restore: 772.4737451076508
  time_this_iter_s: 15.915160894393921
  time_total_s: 772.4737451076508
  timestamp: 1594138386
  timesteps_since_restore: 290000
  timesteps_this_iter: 5000
  timesteps_total: 290000
  training_iteration: 58
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=12141], 772 s, 58 iter, 290000 ts, 1.51e+03 rew

agent-1: 275.0
agent-2: 315.0
agent-3: 236.0
agent-4: 321.0
agent-5: 291.0
Sum Reward: 1438.0
Avg Reward: 287.6
Min Reward: 236.0
Max Reward: 321.0
Gini Coefficient: 0.0584144645340751
20:20 Ratio: 1.3601694915254237
Max-min Ratio: 1.3601694915254237
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_12-13-21
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1905.0
  episode_reward_mean: 1507.551724137931
  episode_reward_min: 223.0
  episodes_this_iter: 1
  episodes_total: 58
  experiment_id: ebedc1946062457bb682d57fae83bd74
  hostname: gpu052
  info:
    apply_time_ms: 2.94
    dispatch_time_ms: 6.884
    learner:
      cur_lr: 0.0013406859943643212
      grad_gnorm: 40.000003814697266
      policy_entropy: 29.31599235534668
      policy_loss: -31.81886100769043
      var_gnorm: 26.104372024536133
      vf_explained_var: 0.9140923023223877
      vf_loss: 48.34991455078125
    num_steps_sampled: 295000
    num_steps_trained: 295000
    wait_time_ms: 145.247
  iterations_since_restore: 59
  node_ip: 172.17.8.52
  num_metric_batches_dropped: 0
  pid: 12141
  policy_reward_mean: {}
  time_since_restore: 787.0107889175415
  time_this_iter_s: 14.537043809890747
  time_total_s: 787.0107889175415
  timestamp: 1594138401
  timesteps_since_restore: 295000
  timesteps_this_iter: 5000
  timesteps_total: 295000
  training_iteration: 59
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=12141], 787 s, 59 iter, 295000 ts, 1.51e+03 rew

agent-1: 254.0
agent-2: 267.0
agent-3: 229.0
agent-4: 272.0
agent-5: 283.0
Sum Reward: 1305.0
Avg Reward: 261.0
Min Reward: 229.0
Max Reward: 283.0
Gini Coefficient: 0.038620689655172416
20:20 Ratio: 1.2358078602620088
Max-min Ratio: 1.2358078602620088
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_12-13-37
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1905.0
  episode_reward_mean: 1504.1186440677966
  episode_reward_min: 223.0
  episodes_this_iter: 1
  episodes_total: 59
  experiment_id: ebedc1946062457bb682d57fae83bd74
  hostname: gpu052
  info:
    apply_time_ms: 2.627
    dispatch_time_ms: 7.169
    learner:
      cur_lr: 0.0013403530465438962
      grad_gnorm: 40.00000762939453
      policy_entropy: 37.649200439453125
      policy_loss: -33.12110900878906
      var_gnorm: 26.299034118652344
      vf_explained_var: 0.8768736124038696
      vf_loss: 36.5018424987793
    num_steps_sampled: 300000
    num_steps_trained: 300000
    wait_time_ms: 123.572
  iterations_since_restore: 60
  node_ip: 172.17.8.52
  num_metric_batches_dropped: 0
  pid: 12141
  policy_reward_mean: {}
  time_since_restore: 803.1087300777435
  time_this_iter_s: 16.097941160202026
  time_total_s: 803.1087300777435
  timestamp: 1594138417
  timesteps_since_restore: 300000
  timesteps_this_iter: 5000
  timesteps_total: 300000
  training_iteration: 60
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=12141], 803 s, 60 iter, 300000 ts, 1.5e+03 rew

agent-1: 329.0
agent-2: 327.0
agent-3: 309.0
agent-4: 349.0
agent-5: 334.0
Sum Reward: 1648.0
Avg Reward: 329.6
Min Reward: 309.0
Max Reward: 349.0
Gini Coefficient: 0.02111650485436893
20:20 Ratio: 1.1294498381877023
Max-min Ratio: 1.1294498381877023
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_12-13-50
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1905.0
  episode_reward_mean: 1506.5166666666667
  episode_reward_min: 223.0
  episodes_this_iter: 1
  episodes_total: 60
  experiment_id: ebedc1946062457bb682d57fae83bd74
  hostname: gpu052
  info:
    apply_time_ms: 2.475
    dispatch_time_ms: 7.498
    learner:
      cur_lr: 0.0013400199823081493
      grad_gnorm: 40.000003814697266
      policy_entropy: 27.585060119628906
      policy_loss: 7.02699089050293
      var_gnorm: 26.414356231689453
      vf_explained_var: 0.594407320022583
      vf_loss: 78.32414245605469
    num_steps_sampled: 305000
    num_steps_trained: 305000
    wait_time_ms: 130.29
  iterations_since_restore: 61
  node_ip: 172.17.8.52
  num_metric_batches_dropped: 0
  pid: 12141
  policy_reward_mean: {}
  time_since_restore: 816.4710011482239
  time_this_iter_s: 13.362271070480347
  time_total_s: 816.4710011482239
  timestamp: 1594138430
  timesteps_since_restore: 305000
  timesteps_this_iter: 5000
  timesteps_total: 305000
  training_iteration: 61
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=12141], 816 s, 61 iter, 305000 ts, 1.51e+03 rew

agent-1: 288.0
agent-2: 303.0
agent-3: 321.0
agent-4: 254.0
agent-5: 237.0
Sum Reward: 1403.0
Avg Reward: 280.6
Min Reward: 237.0
Max Reward: 321.0
Gini Coefficient: 0.06186742694226657
20:20 Ratio: 1.3544303797468353
Max-min Ratio: 1.3544303797468353
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_12-14-06
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1905.0
  episode_reward_mean: 1504.8196721311476
  episode_reward_min: 223.0
  episodes_this_iter: 1
  episodes_total: 61
  experiment_id: ebedc1946062457bb682d57fae83bd74
  hostname: gpu052
  info:
    apply_time_ms: 2.695
    dispatch_time_ms: 6.124
    learner:
      cur_lr: 0.0013396870344877243
      grad_gnorm: 39.999977111816406
      policy_entropy: 17.041793823242188
      policy_loss: 15.84953498840332
      var_gnorm: 26.528308868408203
      vf_explained_var: -0.0736926794052124
      vf_loss: 56.211673736572266
    num_steps_sampled: 310000
    num_steps_trained: 310000
    wait_time_ms: 120.949
  iterations_since_restore: 62
  node_ip: 172.17.8.52
  num_metric_batches_dropped: 0
  pid: 12141
  policy_reward_mean: {}
  time_since_restore: 831.8979556560516
  time_this_iter_s: 15.426954507827759
  time_total_s: 831.8979556560516
  timestamp: 1594138446
  timesteps_since_restore: 310000
  timesteps_this_iter: 5000
  timesteps_total: 310000
  training_iteration: 62
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=12141], 831 s, 62 iter, 310000 ts, 1.5e+03 rew

agent-1: 346.0
agent-2: 375.0
agent-3: 335.0
agent-4: 345.0
agent-5: 350.0
Sum Reward: 1751.0
Avg Reward: 350.2
Min Reward: 335.0
Max Reward: 375.0
Gini Coefficient: 0.019417475728155338
20:20 Ratio: 1.1194029850746268
Max-min Ratio: 1.1194029850746268
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_12-14-18
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1905.0
  episode_reward_mean: 1508.7903225806451
  episode_reward_min: 223.0
  episodes_this_iter: 1
  episodes_total: 62
  experiment_id: ebedc1946062457bb682d57fae83bd74
  hostname: gpu052
  info:
    apply_time_ms: 2.841
    dispatch_time_ms: 6.461
    learner:
      cur_lr: 0.0013393539702519774
      grad_gnorm: 39.99998474121094
      policy_entropy: 17.73314094543457
      policy_loss: -9.144183158874512
      var_gnorm: 26.721166610717773
      vf_explained_var: 0.0895918607711792
      vf_loss: 22.127161026000977
    num_steps_sampled: 315000
    num_steps_trained: 315000
    wait_time_ms: 120.026
  iterations_since_restore: 63
  node_ip: 172.17.8.52
  num_metric_batches_dropped: 0
  pid: 12141
  policy_reward_mean: {}
  time_since_restore: 844.5809338092804
  time_this_iter_s: 12.68297815322876
  time_total_s: 844.5809338092804
  timestamp: 1594138458
  timesteps_since_restore: 315000
  timesteps_this_iter: 5000
  timesteps_total: 315000
  training_iteration: 63
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=12141], 844 s, 63 iter, 315000 ts, 1.51e+03 rew

agent-1: 370.0
agent-2: 344.0
agent-3: 370.0
agent-4: 386.0
agent-5: 412.0
Sum Reward: 1882.0
Avg Reward: 376.4
Min Reward: 344.0
Max Reward: 412.0
Gini Coefficient: 0.03230605738575983
20:20 Ratio: 1.197674418604651
Max-min Ratio: 1.197674418604651
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_12-14-33
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1905.0
  episode_reward_mean: 1514.7142857142858
  episode_reward_min: 223.0
  episodes_this_iter: 1
  episodes_total: 63
  experiment_id: ebedc1946062457bb682d57fae83bd74
  hostname: gpu052
  info:
    apply_time_ms: 3.12
    dispatch_time_ms: 8.429
    learner:
      cur_lr: 0.0013390210224315524
      grad_gnorm: 39.99998474121094
      policy_entropy: 23.621580123901367
      policy_loss: 0.8761783838272095
      var_gnorm: 26.770668029785156
      vf_explained_var: -0.19425678253173828
      vf_loss: 27.475107192993164
    num_steps_sampled: 320000
    num_steps_trained: 320000
    wait_time_ms: 123.245
  iterations_since_restore: 64
  node_ip: 172.17.8.52
  num_metric_batches_dropped: 0
  pid: 12141
  policy_reward_mean: {}
  time_since_restore: 858.7871518135071
  time_this_iter_s: 14.206218004226685
  time_total_s: 858.7871518135071
  timestamp: 1594138473
  timesteps_since_restore: 320000
  timesteps_this_iter: 5000
  timesteps_total: 320000
  training_iteration: 64
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 29.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=12141], 858 s, 64 iter, 320000 ts, 1.51e+03 rew

agent-1: 399.0
agent-2: 357.0
agent-3: 354.0
agent-4: 375.0
agent-5: 379.0
Sum Reward: 1864.0
Avg Reward: 372.8
Min Reward: 354.0
Max Reward: 399.0
Gini Coefficient: 0.0240343347639485
20:20 Ratio: 1.1271186440677967
Max-min Ratio: 1.1271186440677967
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_12-14-47
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1905.0
  episode_reward_mean: 1520.171875
  episode_reward_min: 223.0
  episodes_this_iter: 1
  episodes_total: 64
  experiment_id: ebedc1946062457bb682d57fae83bd74
  hostname: gpu052
  info:
    apply_time_ms: 3.721
    dispatch_time_ms: 6.962
    learner:
      cur_lr: 0.0013386879581958055
      grad_gnorm: 39.999996185302734
      policy_entropy: 25.68880271911621
      policy_loss: -18.58346939086914
      var_gnorm: 26.843656539916992
      vf_explained_var: 0.3053961396217346
      vf_loss: 47.63890838623047
    num_steps_sampled: 325000
    num_steps_trained: 325000
    wait_time_ms: 143.566
  iterations_since_restore: 65
  node_ip: 172.17.8.52
  num_metric_batches_dropped: 0
  pid: 12141
  policy_reward_mean: {}
  time_since_restore: 872.7438976764679
  time_this_iter_s: 13.956745862960815
  time_total_s: 872.7438976764679
  timestamp: 1594138487
  timesteps_since_restore: 325000
  timesteps_this_iter: 5000
  timesteps_total: 325000
  training_iteration: 65
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 29.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=12141], 872 s, 65 iter, 325000 ts, 1.52e+03 rew

agent-1: 298.0
agent-2: 292.0
agent-3: 262.0
agent-4: 212.0
agent-5: 238.0
Sum Reward: 1302.0
Avg Reward: 260.4
Min Reward: 212.0
Max Reward: 298.0
Gini Coefficient: 0.06943164362519201
20:20 Ratio: 1.4056603773584906
Max-min Ratio: 1.4056603773584906
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_12-15-02
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1905.0
  episode_reward_mean: 1516.8153846153846
  episode_reward_min: 223.0
  episodes_this_iter: 1
  episodes_total: 65
  experiment_id: ebedc1946062457bb682d57fae83bd74
  hostname: gpu052
  info:
    apply_time_ms: 3.29
    dispatch_time_ms: 6.933
    learner:
      cur_lr: 0.0013383550103753805
      grad_gnorm: 40.000003814697266
      policy_entropy: 28.666677474975586
      policy_loss: 31.488616943359375
      var_gnorm: 26.934837341308594
      vf_explained_var: -0.4390822649002075
      vf_loss: 100.2099609375
    num_steps_sampled: 330000
    num_steps_trained: 330000
    wait_time_ms: 115.524
  iterations_since_restore: 66
  node_ip: 172.17.8.52
  num_metric_batches_dropped: 0
  pid: 12141
  policy_reward_mean: {}
  time_since_restore: 888.2068405151367
  time_this_iter_s: 15.462942838668823
  time_total_s: 888.2068405151367
  timestamp: 1594138502
  timesteps_since_restore: 330000
  timesteps_this_iter: 5000
  timesteps_total: 330000
  training_iteration: 66
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 29.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=12141], 888 s, 66 iter, 330000 ts, 1.52e+03 rew

agent-1: 332.0
agent-2: 296.0
agent-3: 300.0
agent-4: 301.0
agent-5: 305.0
Sum Reward: 1534.0
Avg Reward: 306.8
Min Reward: 296.0
Max Reward: 332.0
Gini Coefficient: 0.020078226857887876
20:20 Ratio: 1.1216216216216217
Max-min Ratio: 1.1216216216216217
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_12-15-15
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1905.0
  episode_reward_mean: 1517.0757575757575
  episode_reward_min: 223.0
  episodes_this_iter: 1
  episodes_total: 66
  experiment_id: ebedc1946062457bb682d57fae83bd74
  hostname: gpu052
  info:
    apply_time_ms: 3.981
    dispatch_time_ms: 6.875
    learner:
      cur_lr: 0.0013380219461396337
      grad_gnorm: 39.999996185302734
      policy_entropy: 29.967374801635742
      policy_loss: -21.041255950927734
      var_gnorm: 26.989521026611328
      vf_explained_var: 0.23743462562561035
      vf_loss: 117.71412658691406
    num_steps_sampled: 335000
    num_steps_trained: 335000
    wait_time_ms: 123.478
  iterations_since_restore: 67
  node_ip: 172.17.8.52
  num_metric_batches_dropped: 0
  pid: 12141
  policy_reward_mean: {}
  time_since_restore: 901.246146440506
  time_this_iter_s: 13.039305925369263
  time_total_s: 901.246146440506
  timestamp: 1594138515
  timesteps_since_restore: 335000
  timesteps_this_iter: 5000
  timesteps_total: 335000
  training_iteration: 67
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 29.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=12141], 901 s, 67 iter, 335000 ts, 1.52e+03 rew

agent-1: 343.0
agent-2: 373.0
agent-3: 293.0
agent-4: 318.0
agent-5: 305.0
Sum Reward: 1632.0
Avg Reward: 326.4
Min Reward: 293.0
Max Reward: 373.0
Gini Coefficient: 0.04852941176470588
20:20 Ratio: 1.273037542662116
Max-min Ratio: 1.273037542662116
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_12-15-29
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1905.0
  episode_reward_mean: 1518.7910447761194
  episode_reward_min: 223.0
  episodes_this_iter: 1
  episodes_total: 67
  experiment_id: ebedc1946062457bb682d57fae83bd74
  hostname: gpu052
  info:
    apply_time_ms: 3.597
    dispatch_time_ms: 6.924
    learner:
      cur_lr: 0.0013376889983192086
      grad_gnorm: 40.0
      policy_entropy: 22.452754974365234
      policy_loss: 33.906883239746094
      var_gnorm: 27.067758560180664
      vf_explained_var: -1.0
      vf_loss: 201.26268005371094
    num_steps_sampled: 340000
    num_steps_trained: 340000
    wait_time_ms: 129.653
  iterations_since_restore: 68
  node_ip: 172.17.8.52
  num_metric_batches_dropped: 0
  pid: 12141
  policy_reward_mean: {}
  time_since_restore: 915.2541744709015
  time_this_iter_s: 14.008028030395508
  time_total_s: 915.2541744709015
  timestamp: 1594138529
  timesteps_since_restore: 340000
  timesteps_this_iter: 5000
  timesteps_total: 340000
  training_iteration: 68
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 29.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=12141], 915 s, 68 iter, 340000 ts, 1.52e+03 rew

agent-1: 304.0
agent-2: 334.0
agent-3: 293.0
agent-4: 280.0
agent-5: 270.0
Sum Reward: 1481.0
Avg Reward: 296.2
Min Reward: 270.0
Max Reward: 334.0
Gini Coefficient: 0.041053342336259284
20:20 Ratio: 1.237037037037037
Max-min Ratio: 1.237037037037037
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_12-15-42
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1905.0
  episode_reward_mean: 1518.235294117647
  episode_reward_min: 223.0
  episodes_this_iter: 1
  episodes_total: 68
  experiment_id: ebedc1946062457bb682d57fae83bd74
  hostname: gpu052
  info:
    apply_time_ms: 3.325
    dispatch_time_ms: 6.515
    learner:
      cur_lr: 0.0013373560504987836
      grad_gnorm: 39.999977111816406
      policy_entropy: 28.812646865844727
      policy_loss: -2.2186176776885986
      var_gnorm: 27.113527297973633
      vf_explained_var: 0.13210487365722656
      vf_loss: 24.942811965942383
    num_steps_sampled: 345000
    num_steps_trained: 345000
    wait_time_ms: 134.167
  iterations_since_restore: 69
  node_ip: 172.17.8.52
  num_metric_batches_dropped: 0
  pid: 12141
  policy_reward_mean: {}
  time_since_restore: 927.9844572544098
  time_this_iter_s: 12.7302827835083
  time_total_s: 927.9844572544098
  timestamp: 1594138542
  timesteps_since_restore: 345000
  timesteps_this_iter: 5000
  timesteps_total: 345000
  training_iteration: 69
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 29.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=12141], 927 s, 69 iter, 345000 ts, 1.52e+03 rew

agent-1: 341.0
agent-2: 350.0
agent-3: 356.0
agent-4: 379.0
agent-5: 387.0
Sum Reward: 1813.0
Avg Reward: 362.6
Min Reward: 341.0
Max Reward: 387.0
Gini Coefficient: 0.02669608383894098
20:20 Ratio: 1.1348973607038124
Max-min Ratio: 1.1348973607038124
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_12-15-56
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1905.0
  episode_reward_mean: 1522.5072463768115
  episode_reward_min: 223.0
  episodes_this_iter: 1
  episodes_total: 69
  experiment_id: ebedc1946062457bb682d57fae83bd74
  hostname: gpu052
  info:
    apply_time_ms: 2.95
    dispatch_time_ms: 5.995
    learner:
      cur_lr: 0.0013370229862630367
      grad_gnorm: 40.000003814697266
      policy_entropy: 23.760250091552734
      policy_loss: 30.918983459472656
      var_gnorm: 27.163341522216797
      vf_explained_var: -1.0
      vf_loss: 106.08824157714844
    num_steps_sampled: 350000
    num_steps_trained: 350000
    wait_time_ms: 131.817
  iterations_since_restore: 70
  node_ip: 172.17.8.52
  num_metric_batches_dropped: 0
  pid: 12141
  policy_reward_mean: {}
  time_since_restore: 942.4695653915405
  time_this_iter_s: 14.485108137130737
  time_total_s: 942.4695653915405
  timestamp: 1594138556
  timesteps_since_restore: 350000
  timesteps_this_iter: 5000
  timesteps_total: 350000
  training_iteration: 70
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=12141], 942 s, 70 iter, 350000 ts, 1.52e+03 rew

agent-1: 361.0
agent-2: 350.0
agent-3: 331.0
agent-4: 354.0
agent-5: 341.0
Sum Reward: 1737.0
Avg Reward: 347.4
Min Reward: 331.0
Max Reward: 361.0
Gini Coefficient: 0.016810592976396085
20:20 Ratio: 1.0906344410876132
Max-min Ratio: 1.0906344410876132
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_12-16-10
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1905.0
  episode_reward_mean: 1525.5714285714287
  episode_reward_min: 223.0
  episodes_this_iter: 1
  episodes_total: 70
  experiment_id: ebedc1946062457bb682d57fae83bd74
  hostname: gpu052
  info:
    apply_time_ms: 2.902
    dispatch_time_ms: 9.333
    learner:
      cur_lr: 0.0013366900384426117
      grad_gnorm: 40.0000114440918
      policy_entropy: 18.570249557495117
      policy_loss: -34.71198272705078
      var_gnorm: 27.2603702545166
      vf_explained_var: 0.3058195114135742
      vf_loss: 73.2764663696289
    num_steps_sampled: 355000
    num_steps_trained: 355000
    wait_time_ms: 137.152
  iterations_since_restore: 71
  node_ip: 172.17.8.52
  num_metric_batches_dropped: 0
  pid: 12141
  policy_reward_mean: {}
  time_since_restore: 955.7456994056702
  time_this_iter_s: 13.276134014129639
  time_total_s: 955.7456994056702
  timestamp: 1594138570
  timesteps_since_restore: 355000
  timesteps_this_iter: 5000
  timesteps_total: 355000
  training_iteration: 71
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=12141], 955 s, 71 iter, 355000 ts, 1.53e+03 rew

agent-1: 283.0
agent-2: 375.0
agent-3: 348.0
agent-4: 339.0
agent-5: 300.0
Sum Reward: 1645.0
Avg Reward: 329.0
Min Reward: 283.0
Max Reward: 375.0
Gini Coefficient: 0.05641337386018237
20:20 Ratio: 1.325088339222615
Max-min Ratio: 1.325088339222615
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_12-16-26
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1905.0
  episode_reward_mean: 1527.2535211267605
  episode_reward_min: 223.0
  episodes_this_iter: 1
  episodes_total: 71
  experiment_id: ebedc1946062457bb682d57fae83bd74
  hostname: gpu052
  info:
    apply_time_ms: 3.057
    dispatch_time_ms: 6.215
    learner:
      cur_lr: 0.0013363569742068648
      grad_gnorm: 40.00000762939453
      policy_entropy: 16.367136001586914
      policy_loss: 9.967864036560059
      var_gnorm: 27.347196578979492
      vf_explained_var: -1.0
      vf_loss: 84.90191650390625
    num_steps_sampled: 360000
    num_steps_trained: 360000
    wait_time_ms: 137.644
  iterations_since_restore: 72
  node_ip: 172.17.8.52
  num_metric_batches_dropped: 0
  pid: 12141
  policy_reward_mean: {}
  time_since_restore: 971.5845053195953
  time_this_iter_s: 15.838805913925171
  time_total_s: 971.5845053195953
  timestamp: 1594138586
  timesteps_since_restore: 360000
  timesteps_this_iter: 5000
  timesteps_total: 360000
  training_iteration: 72
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=12141], 971 s, 72 iter, 360000 ts, 1.53e+03 rew

agent-1: 213.0
agent-2: 295.0
agent-3: 380.0
agent-4: 256.0
agent-5: 319.0
Sum Reward: 1463.0
Avg Reward: 292.6
Min Reward: 213.0
Max Reward: 380.0
Gini Coefficient: 0.10854408749145592
20:20 Ratio: 1.784037558685446
Max-min Ratio: 1.784037558685446
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_12-16-39
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1905.0
  episode_reward_mean: 1526.361111111111
  episode_reward_min: 223.0
  episodes_this_iter: 1
  episodes_total: 72
  experiment_id: ebedc1946062457bb682d57fae83bd74
  hostname: gpu052
  info:
    apply_time_ms: 3.421
    dispatch_time_ms: 9.648
    learner:
      cur_lr: 0.0013360240263864398
      grad_gnorm: 40.000003814697266
      policy_entropy: 13.28026008605957
      policy_loss: -13.075167655944824
      var_gnorm: 27.364898681640625
      vf_explained_var: 0.34407079219818115
      vf_loss: 49.083919525146484
    num_steps_sampled: 365000
    num_steps_trained: 365000
    wait_time_ms: 132.249
  iterations_since_restore: 73
  node_ip: 172.17.8.52
  num_metric_batches_dropped: 0
  pid: 12141
  policy_reward_mean: {}
  time_since_restore: 984.8197886943817
  time_this_iter_s: 13.235283374786377
  time_total_s: 984.8197886943817
  timestamp: 1594138599
  timesteps_since_restore: 365000
  timesteps_this_iter: 5000
  timesteps_total: 365000
  training_iteration: 73
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=12141], 984 s, 73 iter, 365000 ts, 1.53e+03 rew

agent-1: 381.0
agent-2: 339.0
agent-3: 371.0
agent-4: 363.0
agent-5: 360.0
Sum Reward: 1814.0
Avg Reward: 362.8
Min Reward: 339.0
Max Reward: 381.0
Gini Coefficient: 0.020948180815876516
20:20 Ratio: 1.1238938053097345
Max-min Ratio: 1.1238938053097345
agent-1: 327.0
agent-2: 302.0
agent-3: 304.0
agent-4: 325.0
agent-5: 294.0
Sum Reward: 1552.0
Avg Reward: 310.4
Min Reward: 294.0
Max Reward: 327.0
Gini Coefficient: 0.022938144329896906
20:20 Ratio: 1.1122448979591837
Max-min Ratio: 1.1122448979591837
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_12-16-54
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1905.0
  episode_reward_mean: 1530.5945945945946
  episode_reward_min: 223.0
  episodes_this_iter: 2
  episodes_total: 74
  experiment_id: ebedc1946062457bb682d57fae83bd74
  hostname: gpu052
  info:
    apply_time_ms: 3.475
    dispatch_time_ms: 7.058
    learner:
      cur_lr: 0.001335690962150693
      grad_gnorm: 40.00001525878906
      policy_entropy: 43.07463455200195
      policy_loss: -1096.5670166015625
      var_gnorm: 27.48080062866211
      vf_explained_var: -0.2589399814605713
      vf_loss: 18004.3359375
    num_steps_sampled: 370000
    num_steps_trained: 370000
    wait_time_ms: 142.249
  iterations_since_restore: 74
  node_ip: 172.17.8.52
  num_metric_batches_dropped: 0
  pid: 12141
  policy_reward_mean: {}
  time_since_restore: 999.978104352951
  time_this_iter_s: 15.158315658569336
  time_total_s: 999.978104352951
  timestamp: 1594138614
  timesteps_since_restore: 370000
  timesteps_this_iter: 5000
  timesteps_total: 370000
  training_iteration: 74
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.3/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=12141], 999 s, 74 iter, 370000 ts, 1.53e+03 rew

Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_12-17-07
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1905.0
  episode_reward_mean: 1530.5945945945946
  episode_reward_min: 223.0
  episodes_this_iter: 0
  episodes_total: 74
  experiment_id: ebedc1946062457bb682d57fae83bd74
  hostname: gpu052
  info:
    apply_time_ms: 3.16
    dispatch_time_ms: 5.642
    learner:
      cur_lr: 0.001335358014330268
      grad_gnorm: 39.999996185302734
      policy_entropy: 25.65215301513672
      policy_loss: 1.6179721355438232
      var_gnorm: 27.556455612182617
      vf_explained_var: -0.2526925802230835
      vf_loss: 41.178829193115234
    num_steps_sampled: 375000
    num_steps_trained: 375000
    wait_time_ms: 129.646
  iterations_since_restore: 75
  node_ip: 172.17.8.52
  num_metric_batches_dropped: 0
  pid: 12141
  policy_reward_mean: {}
  time_since_restore: 1012.8025391101837
  time_this_iter_s: 12.824434757232666
  time_total_s: 1012.8025391101837
  timestamp: 1594138627
  timesteps_since_restore: 375000
  timesteps_this_iter: 5000
  timesteps_total: 375000
  training_iteration: 75
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=12141], 1012 s, 75 iter, 375000 ts, 1.53e+03 rew

agent-1: 340.0
agent-2: 279.0
agent-3: 373.0
agent-4: 375.0
agent-5: 256.0
Sum Reward: 1623.0
Avg Reward: 324.6
Min Reward: 256.0
Max Reward: 375.0
Gini Coefficient: 0.0818237831176833
20:20 Ratio: 1.46484375
Max-min Ratio: 1.46484375
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_12-17-23
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1905.0
  episode_reward_mean: 1531.8266666666666
  episode_reward_min: 223.0
  episodes_this_iter: 1
  episodes_total: 75
  experiment_id: ebedc1946062457bb682d57fae83bd74
  hostname: gpu052
  info:
    apply_time_ms: 2.983
    dispatch_time_ms: 6.163
    learner:
      cur_lr: 0.001335024950094521
      grad_gnorm: 40.000003814697266
      policy_entropy: 26.92678451538086
      policy_loss: 59.050193786621094
      var_gnorm: 27.616453170776367
      vf_explained_var: -1.0
      vf_loss: 209.49317932128906
    num_steps_sampled: 380000
    num_steps_trained: 380000
    wait_time_ms: 144.769
  iterations_since_restore: 76
  node_ip: 172.17.8.52
  num_metric_batches_dropped: 0
  pid: 12141
  policy_reward_mean: {}
  time_since_restore: 1028.4995458126068
  time_this_iter_s: 15.697006702423096
  time_total_s: 1028.4995458126068
  timestamp: 1594138643
  timesteps_since_restore: 380000
  timesteps_this_iter: 5000
  timesteps_total: 380000
  training_iteration: 76
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=12141], 1028 s, 76 iter, 380000 ts, 1.53e+03 rew

agent-1: 346.0
agent-2: 276.0
agent-3: 404.0
agent-4: 331.0
agent-5: 377.0
Sum Reward: 1734.0
Avg Reward: 346.8
Min Reward: 276.0
Max Reward: 404.0
Gini Coefficient: 0.06966551326412918
20:20 Ratio: 1.463768115942029
Max-min Ratio: 1.463768115942029
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_12-17-35
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1905.0
  episode_reward_mean: 1534.4868421052631
  episode_reward_min: 223.0
  episodes_this_iter: 1
  episodes_total: 76
  experiment_id: ebedc1946062457bb682d57fae83bd74
  hostname: gpu052
  info:
    apply_time_ms: 3.392
    dispatch_time_ms: 6.916
    learner:
      cur_lr: 0.001334692002274096
      grad_gnorm: 39.999996185302734
      policy_entropy: 22.885223388671875
      policy_loss: 27.819580078125
      var_gnorm: 27.752601623535156
      vf_explained_var: 0.043501198291778564
      vf_loss: 51.376197814941406
    num_steps_sampled: 385000
    num_steps_trained: 385000
    wait_time_ms: 124.4
  iterations_since_restore: 77
  node_ip: 172.17.8.52
  num_metric_batches_dropped: 0
  pid: 12141
  policy_reward_mean: {}
  time_since_restore: 1041.2275788784027
  time_this_iter_s: 12.728033065795898
  time_total_s: 1041.2275788784027
  timestamp: 1594138655
  timesteps_since_restore: 385000
  timesteps_this_iter: 5000
  timesteps_total: 385000
  training_iteration: 77
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=12141], 1041 s, 77 iter, 385000 ts, 1.53e+03 rew

agent-1: 410.0
agent-2: 411.0
agent-3: 406.0
agent-4: 399.0
agent-5: 366.0
Sum Reward: 1992.0
Avg Reward: 398.4
Min Reward: 366.0
Max Reward: 411.0
Gini Coefficient: 0.020281124497991968
20:20 Ratio: 1.1229508196721312
Max-min Ratio: 1.1229508196721312
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_12-17-50
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1992.0
  episode_reward_mean: 1540.4285714285713
  episode_reward_min: 223.0
  episodes_this_iter: 1
  episodes_total: 77
  experiment_id: ebedc1946062457bb682d57fae83bd74
  hostname: gpu052
  info:
    apply_time_ms: 3.603
    dispatch_time_ms: 6.821
    learner:
      cur_lr: 0.001334359054453671
      grad_gnorm: 40.000003814697266
      policy_entropy: 29.471546173095703
      policy_loss: 0.10770508646965027
      var_gnorm: 27.88157844543457
      vf_explained_var: 0.3625336289405823
      vf_loss: 45.35750961303711
    num_steps_sampled: 390000
    num_steps_trained: 390000
    wait_time_ms: 137.947
  iterations_since_restore: 78
  node_ip: 172.17.8.52
  num_metric_batches_dropped: 0
  pid: 12141
  policy_reward_mean: {}
  time_since_restore: 1055.299228668213
  time_this_iter_s: 14.07164978981018
  time_total_s: 1055.299228668213
  timestamp: 1594138670
  timesteps_since_restore: 390000
  timesteps_this_iter: 5000
  timesteps_total: 390000
  training_iteration: 78
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=12141], 1055 s, 78 iter, 390000 ts, 1.54e+03 rew

agent-1: 368.0
agent-2: 349.0
agent-3: 325.0
agent-4: 323.0
agent-5: 372.0
Sum Reward: 1737.0
Avg Reward: 347.4
Min Reward: 323.0
Max Reward: 372.0
Gini Coefficient: 0.03246977547495682
20:20 Ratio: 1.151702786377709
Max-min Ratio: 1.151702786377709
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_12-18-02
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1992.0
  episode_reward_mean: 1542.948717948718
  episode_reward_min: 223.0
  episodes_this_iter: 1
  episodes_total: 78
  experiment_id: ebedc1946062457bb682d57fae83bd74
  hostname: gpu052
  info:
    apply_time_ms: 2.55
    dispatch_time_ms: 6.356
    learner:
      cur_lr: 0.0013340259902179241
      grad_gnorm: 40.0
      policy_entropy: 16.56454086303711
      policy_loss: -25.509244918823242
      var_gnorm: 27.917186737060547
      vf_explained_var: 0.5833083391189575
      vf_loss: 26.44559097290039
    num_steps_sampled: 395000
    num_steps_trained: 395000
    wait_time_ms: 134.154
  iterations_since_restore: 79
  node_ip: 172.17.8.52
  num_metric_batches_dropped: 0
  pid: 12141
  policy_reward_mean: {}
  time_since_restore: 1067.7998006343842
  time_this_iter_s: 12.500571966171265
  time_total_s: 1067.7998006343842
  timestamp: 1594138682
  timesteps_since_restore: 395000
  timesteps_this_iter: 5000
  timesteps_total: 395000
  training_iteration: 79
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.3/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=12141], 1067 s, 79 iter, 395000 ts, 1.54e+03 rew

agent-1: 354.0
agent-2: 336.0
agent-3: 355.0
agent-4: 365.0
agent-5: 347.0
Sum Reward: 1757.0
Avg Reward: 351.4
Min Reward: 336.0
Max Reward: 365.0
Gini Coefficient: 0.015025611838360842
20:20 Ratio: 1.0863095238095237
Max-min Ratio: 1.0863095238095237
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_12-18-17
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1992.0
  episode_reward_mean: 1545.6582278481012
  episode_reward_min: 223.0
  episodes_this_iter: 1
  episodes_total: 79
  experiment_id: ebedc1946062457bb682d57fae83bd74
  hostname: gpu052
  info:
    apply_time_ms: 5.135
    dispatch_time_ms: 9.439
    learner:
      cur_lr: 0.001333693042397499
      grad_gnorm: 39.99999237060547
      policy_entropy: 17.597457885742188
      policy_loss: 14.4509916305542
      var_gnorm: 28.03260612487793
      vf_explained_var: 0.3414958715438843
      vf_loss: 58.9322624206543
    num_steps_sampled: 400000
    num_steps_trained: 400000
    wait_time_ms: 123.139
  iterations_since_restore: 80
  node_ip: 172.17.8.52
  num_metric_batches_dropped: 0
  pid: 12141
  policy_reward_mean: {}
  time_since_restore: 1082.7889966964722
  time_this_iter_s: 14.989196062088013
  time_total_s: 1082.7889966964722
  timestamp: 1594138697
  timesteps_since_restore: 400000
  timesteps_this_iter: 5000
  timesteps_total: 400000
  training_iteration: 80
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.3/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=12141], 1082 s, 80 iter, 400000 ts, 1.55e+03 rew

agent-1: 369.0
agent-2: 336.0
agent-3: 247.0
agent-4: 386.0
agent-5: 362.0
Sum Reward: 1700.0
Avg Reward: 340.0
Min Reward: 247.0
Max Reward: 386.0
Gini Coefficient: 0.07317647058823529
20:20 Ratio: 1.562753036437247
Max-min Ratio: 1.562753036437247
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_12-18-30
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1992.0
  episode_reward_mean: 1547.5875
  episode_reward_min: 223.0
  episodes_this_iter: 1
  episodes_total: 80
  experiment_id: ebedc1946062457bb682d57fae83bd74
  hostname: gpu052
  info:
    apply_time_ms: 2.703
    dispatch_time_ms: 8.089
    learner:
      cur_lr: 0.0013333599781617522
      grad_gnorm: 40.00000762939453
      policy_entropy: 24.633031845092773
      policy_loss: 21.091590881347656
      var_gnorm: 28.07291603088379
      vf_explained_var: 0.11875379085540771
      vf_loss: 77.68419647216797
    num_steps_sampled: 405000
    num_steps_trained: 405000
    wait_time_ms: 128.85
  iterations_since_restore: 81
  node_ip: 172.17.8.52
  num_metric_batches_dropped: 0
  pid: 12141
  policy_reward_mean: {}
  time_since_restore: 1095.316947221756
  time_this_iter_s: 12.527950525283813
  time_total_s: 1095.316947221756
  timestamp: 1594138710
  timesteps_since_restore: 405000
  timesteps_this_iter: 5000
  timesteps_total: 405000
  training_iteration: 81
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=12141], 1095 s, 81 iter, 405000 ts, 1.55e+03 rew

agent-1: 352.0
agent-2: 354.0
agent-3: 331.0
agent-4: 342.0
agent-5: 294.0
Sum Reward: 1673.0
Avg Reward: 334.6
Min Reward: 294.0
Max Reward: 354.0
Gini Coefficient: 0.03371189479976091
20:20 Ratio: 1.2040816326530612
Max-min Ratio: 1.2040816326530612
agent-1: 322.0
agent-2: 316.0
agent-3: 363.0
agent-4: 356.0
agent-5: 370.0
Sum Reward: 1727.0
Avg Reward: 345.4
Min Reward: 316.0
Max Reward: 370.0
Gini Coefficient: 0.034510712217718585
20:20 Ratio: 1.1708860759493671
Max-min Ratio: 1.1708860759493671
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_12-18-44
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1992.0
  episode_reward_mean: 1551.3048780487804
  episode_reward_min: 223.0
  episodes_this_iter: 2
  episodes_total: 82
  experiment_id: ebedc1946062457bb682d57fae83bd74
  hostname: gpu052
  info:
    apply_time_ms: 2.487
    dispatch_time_ms: 10.648
    learner:
      cur_lr: 0.0013330270303413272
      grad_gnorm: 40.00001525878906
      policy_entropy: 32.797142028808594
      policy_loss: -1105.0601806640625
      var_gnorm: 28.10689353942871
      vf_explained_var: -1.0
      vf_loss: 23452.962890625
    num_steps_sampled: 410000
    num_steps_trained: 410000
    wait_time_ms: 135.49
  iterations_since_restore: 82
  node_ip: 172.17.8.52
  num_metric_batches_dropped: 0
  pid: 12141
  policy_reward_mean: {}
  time_since_restore: 1109.713697195053
  time_this_iter_s: 14.39674997329712
  time_total_s: 1109.713697195053
  timestamp: 1594138724
  timesteps_since_restore: 410000
  timesteps_this_iter: 5000
  timesteps_total: 410000
  training_iteration: 82
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=12141], 1109 s, 82 iter, 410000 ts, 1.55e+03 rew

Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_12-18-57
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1992.0
  episode_reward_mean: 1551.3048780487804
  episode_reward_min: 223.0
  episodes_this_iter: 0
  episodes_total: 82
  experiment_id: ebedc1946062457bb682d57fae83bd74
  hostname: gpu052
  info:
    apply_time_ms: 2.406
    dispatch_time_ms: 11.01
    learner:
      cur_lr: 0.0013326939661055803
      grad_gnorm: 40.000003814697266
      policy_entropy: 25.04728126525879
      policy_loss: -22.613544464111328
      var_gnorm: 28.15686798095703
      vf_explained_var: 0.11331629753112793
      vf_loss: 78.67493438720703
    num_steps_sampled: 415000
    num_steps_trained: 415000
    wait_time_ms: 120.99
  iterations_since_restore: 83
  node_ip: 172.17.8.52
  num_metric_batches_dropped: 0
  pid: 12141
  policy_reward_mean: {}
  time_since_restore: 1122.1530792713165
  time_this_iter_s: 12.439382076263428
  time_total_s: 1122.1530792713165
  timestamp: 1594138737
  timesteps_since_restore: 415000
  timesteps_this_iter: 5000
  timesteps_total: 415000
  training_iteration: 83
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=12141], 1122 s, 83 iter, 415000 ts, 1.55e+03 rew

agent-1: 339.0
agent-2: 383.0
agent-3: 365.0
agent-4: 369.0
agent-5: 361.0
Sum Reward: 1817.0
Avg Reward: 363.4
Min Reward: 339.0
Max Reward: 383.0
Gini Coefficient: 0.021133736929003853
20:20 Ratio: 1.1297935103244838
Max-min Ratio: 1.1297935103244838
agent-1: 310.0
agent-2: 369.0
agent-3: 258.0
agent-4: 385.0
agent-5: 360.0
Sum Reward: 1682.0
Avg Reward: 336.4
Min Reward: 258.0
Max Reward: 385.0
Gini Coefficient: 0.07443519619500595
20:20 Ratio: 1.4922480620155039
Max-min Ratio: 1.4922480620155039
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_12-19-11
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1992.0
  episode_reward_mean: 1556.0238095238096
  episode_reward_min: 223.0
  episodes_this_iter: 2
  episodes_total: 84
  experiment_id: ebedc1946062457bb682d57fae83bd74
  hostname: gpu052
  info:
    apply_time_ms: 3.058
    dispatch_time_ms: 6.016
    learner:
      cur_lr: 0.0013323610182851553
      grad_gnorm: 40.000003814697266
      policy_entropy: 16.42607879638672
      policy_loss: -441.05364990234375
      var_gnorm: 28.177593231201172
      vf_explained_var: -1.0
      vf_loss: 25728.306640625
    num_steps_sampled: 420000
    num_steps_trained: 420000
    wait_time_ms: 150.586
  iterations_since_restore: 84
  node_ip: 172.17.8.52
  num_metric_batches_dropped: 0
  pid: 12141
  policy_reward_mean: {}
  time_since_restore: 1136.6563987731934
  time_this_iter_s: 14.503319501876831
  time_total_s: 1136.6563987731934
  timestamp: 1594138751
  timesteps_since_restore: 420000
  timesteps_this_iter: 5000
  timesteps_total: 420000
  training_iteration: 84
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 33.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=12141], 1136 s, 84 iter, 420000 ts, 1.56e+03 rew

Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_12-19-24
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1992.0
  episode_reward_mean: 1556.0238095238096
  episode_reward_min: 223.0
  episodes_this_iter: 0
  episodes_total: 84
  experiment_id: ebedc1946062457bb682d57fae83bd74
  hostname: gpu052
  info:
    apply_time_ms: 2.855
    dispatch_time_ms: 6.823
    learner:
      cur_lr: 0.0013320279540494084
      grad_gnorm: 40.0
      policy_entropy: 14.18819808959961
      policy_loss: 10.485686302185059
      var_gnorm: 28.283336639404297
      vf_explained_var: -0.4557732343673706
      vf_loss: 76.25688934326172
    num_steps_sampled: 425000
    num_steps_trained: 425000
    wait_time_ms: 125.103
  iterations_since_restore: 85
  node_ip: 172.17.8.52
  num_metric_batches_dropped: 0
  pid: 12141
  policy_reward_mean: {}
  time_since_restore: 1149.4465601444244
  time_this_iter_s: 12.790161371231079
  time_total_s: 1149.4465601444244
  timestamp: 1594138764
  timesteps_since_restore: 425000
  timesteps_this_iter: 5000
  timesteps_total: 425000
  training_iteration: 85
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 33.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=12141], 1149 s, 85 iter, 425000 ts, 1.56e+03 rew

agent-1: 329.0
agent-2: 376.0
agent-3: 366.0
agent-4: 378.0
agent-5: 374.0
Sum Reward: 1823.0
Avg Reward: 364.6
Min Reward: 329.0
Max Reward: 378.0
Gini Coefficient: 0.02369720241360395
20:20 Ratio: 1.148936170212766
Max-min Ratio: 1.148936170212766
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_12-19-39
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1992.0
  episode_reward_mean: 1559.164705882353
  episode_reward_min: 223.0
  episodes_this_iter: 1
  episodes_total: 85
  experiment_id: ebedc1946062457bb682d57fae83bd74
  hostname: gpu052
  info:
    apply_time_ms: 2.719
    dispatch_time_ms: 9.233
    learner:
      cur_lr: 0.0013316950062289834
      grad_gnorm: 40.000003814697266
      policy_entropy: 15.752739906311035
      policy_loss: 13.192212104797363
      var_gnorm: 28.362045288085938
      vf_explained_var: 0.13784033060073853
      vf_loss: 89.3942642211914
    num_steps_sampled: 430000
    num_steps_trained: 430000
    wait_time_ms: 128.715
  iterations_since_restore: 86
  node_ip: 172.17.8.52
  num_metric_batches_dropped: 0
  pid: 12141
  policy_reward_mean: {}
  time_since_restore: 1164.5373919010162
  time_this_iter_s: 15.090831756591797
  time_total_s: 1164.5373919010162
  timestamp: 1594138779
  timesteps_since_restore: 430000
  timesteps_this_iter: 5000
  timesteps_total: 430000
  training_iteration: 86
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 33.3/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=12141], 1164 s, 86 iter, 430000 ts, 1.56e+03 rew

agent-1: 374.0
agent-2: 346.0
agent-3: 355.0
agent-4: 380.0
agent-5: 284.0
Sum Reward: 1739.0
Avg Reward: 347.8
Min Reward: 284.0
Max Reward: 380.0
Gini Coefficient: 0.05060379528464635
20:20 Ratio: 1.3380281690140845
Max-min Ratio: 1.3380281690140845
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_12-19-52
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1992.0
  episode_reward_mean: 1561.2558139534883
  episode_reward_min: 223.0
  episodes_this_iter: 1
  episodes_total: 86
  experiment_id: ebedc1946062457bb682d57fae83bd74
  hostname: gpu052
  info:
    apply_time_ms: 3.004
    dispatch_time_ms: 6.792
    learner:
      cur_lr: 0.0013313619419932365
      grad_gnorm: 39.99998092651367
      policy_entropy: 18.142610549926758
      policy_loss: -24.251623153686523
      var_gnorm: 28.368846893310547
      vf_explained_var: -0.48069894313812256
      vf_loss: 74.69866180419922
    num_steps_sampled: 435000
    num_steps_trained: 435000
    wait_time_ms: 129.183
  iterations_since_restore: 87
  node_ip: 172.17.8.52
  num_metric_batches_dropped: 0
  pid: 12141
  policy_reward_mean: {}
  time_since_restore: 1177.7388279438019
  time_this_iter_s: 13.201436042785645
  time_total_s: 1177.7388279438019
  timestamp: 1594138792
  timesteps_since_restore: 435000
  timesteps_this_iter: 5000
  timesteps_total: 435000
  training_iteration: 87
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 33.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=12141], 1177 s, 87 iter, 435000 ts, 1.56e+03 rew

agent-1: 320.0
agent-2: 382.0
agent-3: 364.0
agent-4: 361.0
agent-5: 325.0
Sum Reward: 1752.0
Avg Reward: 350.4
Min Reward: 320.0
Max Reward: 382.0
Gini Coefficient: 0.03721461187214612
20:20 Ratio: 1.19375
Max-min Ratio: 1.19375
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_12-20-07
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1992.0
  episode_reward_mean: 1563.448275862069
  episode_reward_min: 223.0
  episodes_this_iter: 1
  episodes_total: 87
  experiment_id: ebedc1946062457bb682d57fae83bd74
  hostname: gpu052
  info:
    apply_time_ms: 3.045
    dispatch_time_ms: 6.57
    learner:
      cur_lr: 0.0013310289941728115
      grad_gnorm: 40.0000114440918
      policy_entropy: 34.21381378173828
      policy_loss: 2.6376383304595947
      var_gnorm: 28.556543350219727
      vf_explained_var: -1.0
      vf_loss: 58.58308410644531
    num_steps_sampled: 440000
    num_steps_trained: 440000
    wait_time_ms: 116.678
  iterations_since_restore: 88
  node_ip: 172.17.8.52
  num_metric_batches_dropped: 0
  pid: 12141
  policy_reward_mean: {}
  time_since_restore: 1191.9968280792236
  time_this_iter_s: 14.258000135421753
  time_total_s: 1191.9968280792236
  timestamp: 1594138807
  timesteps_since_restore: 440000
  timesteps_this_iter: 5000
  timesteps_total: 440000
  training_iteration: 88
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 33.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=12141], 1191 s, 88 iter, 440000 ts, 1.56e+03 rew

agent-1: 295.0
agent-2: 341.0
agent-3: 334.0
agent-4: 296.0
agent-5: 328.0
Sum Reward: 1594.0
Avg Reward: 318.8
Min Reward: 295.0
Max Reward: 341.0
Gini Coefficient: 0.03262233375156838
20:20 Ratio: 1.1559322033898305
Max-min Ratio: 1.1559322033898305
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_12-20-19
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1992.0
  episode_reward_mean: 1563.7954545454545
  episode_reward_min: 223.0
  episodes_this_iter: 1
  episodes_total: 88
  experiment_id: ebedc1946062457bb682d57fae83bd74
  hostname: gpu052
  info:
    apply_time_ms: 3.968
    dispatch_time_ms: 5.99
    learner:
      cur_lr: 0.0013306960463523865
      grad_gnorm: 39.999996185302734
      policy_entropy: 29.49747085571289
      policy_loss: -16.397891998291016
      var_gnorm: 28.657529830932617
      vf_explained_var: 0.554397463798523
      vf_loss: 76.9286880493164
    num_steps_sampled: 445000
    num_steps_trained: 445000
    wait_time_ms: 113.526
  iterations_since_restore: 89
  node_ip: 172.17.8.52
  num_metric_batches_dropped: 0
  pid: 12141
  policy_reward_mean: {}
  time_since_restore: 1204.2627155780792
  time_this_iter_s: 12.26588749885559
  time_total_s: 1204.2627155780792
  timestamp: 1594138819
  timesteps_since_restore: 445000
  timesteps_this_iter: 5000
  timesteps_total: 445000
  training_iteration: 89
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 34.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=12141], 1204 s, 89 iter, 445000 ts, 1.56e+03 rew

agent-1: 251.0
agent-2: 317.0
agent-3: 256.0
agent-4: 310.0
agent-5: 280.0
Sum Reward: 1414.0
Avg Reward: 282.8
Min Reward: 251.0
Max Reward: 317.0
Gini Coefficient: 0.05261669024045262
20:20 Ratio: 1.2629482071713147
Max-min Ratio: 1.2629482071713147
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_12-20-32
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1992.0
  episode_reward_mean: 1562.112359550562
  episode_reward_min: 223.0
  episodes_this_iter: 1
  episodes_total: 89
  experiment_id: ebedc1946062457bb682d57fae83bd74
  hostname: gpu052
  info:
    apply_time_ms: 3.738
    dispatch_time_ms: 10.787
    learner:
      cur_lr: 0.0013303629821166396
      grad_gnorm: 39.9999885559082
      policy_entropy: 12.409217834472656
      policy_loss: -1.4569636583328247
      var_gnorm: 28.709203720092773
      vf_explained_var: 0.5617332458496094
      vf_loss: 44.30808639526367
    num_steps_sampled: 450000
    num_steps_trained: 450000
    wait_time_ms: 95.529
  iterations_since_restore: 90
  node_ip: 172.17.8.52
  num_metric_batches_dropped: 0
  pid: 12141
  policy_reward_mean: {}
  time_since_restore: 1217.541536808014
  time_this_iter_s: 13.278821229934692
  time_total_s: 1217.541536808014
  timestamp: 1594138832
  timesteps_since_restore: 450000
  timesteps_this_iter: 5000
  timesteps_total: 450000
  training_iteration: 90
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 34.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=12141], 1217 s, 90 iter, 450000 ts, 1.56e+03 rew

agent-1: 319.0
agent-2: 325.0
agent-3: 272.0
agent-4: 338.0
agent-5: 316.0
Sum Reward: 1570.0
Avg Reward: 314.0
Min Reward: 272.0
Max Reward: 338.0
Gini Coefficient: 0.03592356687898089
20:20 Ratio: 1.2426470588235294
Max-min Ratio: 1.2426470588235294
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_12-20-45
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1992.0
  episode_reward_mean: 1562.2
  episode_reward_min: 223.0
  episodes_this_iter: 1
  episodes_total: 90
  experiment_id: ebedc1946062457bb682d57fae83bd74
  hostname: gpu052
  info:
    apply_time_ms: 2.651
    dispatch_time_ms: 8.728
    learner:
      cur_lr: 0.0013300300342962146
      grad_gnorm: 40.00000762939453
      policy_entropy: 20.40798568725586
      policy_loss: -6.89414119720459
      var_gnorm: 28.782325744628906
      vf_explained_var: 0.8367581367492676
      vf_loss: 34.1918830871582
    num_steps_sampled: 455000
    num_steps_trained: 455000
    wait_time_ms: 125.306
  iterations_since_restore: 91
  node_ip: 172.17.8.52
  num_metric_batches_dropped: 0
  pid: 12141
  policy_reward_mean: {}
  time_since_restore: 1230.2956414222717
  time_this_iter_s: 12.754104614257812
  time_total_s: 1230.2956414222717
  timestamp: 1594138845
  timesteps_since_restore: 455000
  timesteps_this_iter: 5000
  timesteps_total: 455000
  training_iteration: 91
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 34.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=12141], 1230 s, 91 iter, 455000 ts, 1.56e+03 rew

agent-1: 344.0
agent-2: 333.0
agent-3: 381.0
agent-4: 375.0
agent-5: 368.0
Sum Reward: 1801.0
Avg Reward: 360.2
Min Reward: 333.0
Max Reward: 381.0
Gini Coefficient: 0.028206551915602444
20:20 Ratio: 1.1441441441441442
Max-min Ratio: 1.1441441441441442
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_12-20-59
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1992.0
  episode_reward_mean: 1564.8241758241759
  episode_reward_min: 223.0
  episodes_this_iter: 1
  episodes_total: 91
  experiment_id: ebedc1946062457bb682d57fae83bd74
  hostname: gpu052
  info:
    apply_time_ms: 3.606
    dispatch_time_ms: 6.438
    learner:
      cur_lr: 0.0013296969700604677
      grad_gnorm: 39.99999237060547
      policy_entropy: 13.471794128417969
      policy_loss: -2.917771339416504
      var_gnorm: 28.811073303222656
      vf_explained_var: 0.4127543568611145
      vf_loss: 39.99183654785156
    num_steps_sampled: 460000
    num_steps_trained: 460000
    wait_time_ms: 113.405
  iterations_since_restore: 92
  node_ip: 172.17.8.52
  num_metric_batches_dropped: 0
  pid: 12141
  policy_reward_mean: {}
  time_since_restore: 1244.1891419887543
  time_this_iter_s: 13.893500566482544
  time_total_s: 1244.1891419887543
  timestamp: 1594138859
  timesteps_since_restore: 460000
  timesteps_this_iter: 5000
  timesteps_total: 460000
  training_iteration: 92
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 34.3/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=12141], 1244 s, 92 iter, 460000 ts, 1.56e+03 rew

agent-1: 375.0
agent-2: 326.0
agent-3: 404.0
agent-4: 342.0
agent-5: 387.0
Sum Reward: 1834.0
Avg Reward: 366.8
Min Reward: 326.0
Max Reward: 404.0
Gini Coefficient: 0.043838604143947656
20:20 Ratio: 1.2392638036809815
Max-min Ratio: 1.2392638036809815
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_12-21-12
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1992.0
  episode_reward_mean: 1567.75
  episode_reward_min: 223.0
  episodes_this_iter: 1
  episodes_total: 92
  experiment_id: ebedc1946062457bb682d57fae83bd74
  hostname: gpu052
  info:
    apply_time_ms: 3.679
    dispatch_time_ms: 10.063
    learner:
      cur_lr: 0.0013293640222400427
      grad_gnorm: 40.00001525878906
      policy_entropy: 18.468345642089844
      policy_loss: -0.36019623279571533
      var_gnorm: 28.873931884765625
      vf_explained_var: 0.07229304313659668
      vf_loss: 34.2612190246582
    num_steps_sampled: 465000
    num_steps_trained: 465000
    wait_time_ms: 131.651
  iterations_since_restore: 93
  node_ip: 172.17.8.52
  num_metric_batches_dropped: 0
  pid: 12141
  policy_reward_mean: {}
  time_since_restore: 1257.3058323860168
  time_this_iter_s: 13.116690397262573
  time_total_s: 1257.3058323860168
  timestamp: 1594138872
  timesteps_since_restore: 465000
  timesteps_this_iter: 5000
  timesteps_total: 465000
  training_iteration: 93
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 34.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=12141], 1257 s, 93 iter, 465000 ts, 1.57e+03 rew

W0707 12:21:37.663727 12134 task_dependency_manager.cc:259] Task lease to renew has already expired by -23ms
W0707 12:21:38.117648 12134 task_dependency_manager.cc:259] Task lease to renew has already expired by -462ms
W0707 12:21:38.117719 12134 task_dependency_manager.cc:259] Task lease to renew has already expired by -333ms
W0707 12:21:38.127522 12134 task_dependency_manager.cc:259] Task lease to renew has already expired by -343ms
W0707 12:21:38.337937 12134 node_manager.cc:250] Last heartbeat was sent 12745 ms ago 
W0707 12:21:53.052588 12134 node_manager.cc:250] Last heartbeat was sent 14715 ms ago 
agent-1: 306.0
agent-2: 374.0
agent-3: 315.0
agent-4: 333.0
agent-5: 303.0
Sum Reward: 1631.0
Avg Reward: 326.2
Min Reward: 303.0
Max Reward: 374.0
Gini Coefficient: 0.041446965052115266
20:20 Ratio: 1.2343234323432344
Max-min Ratio: 1.2343234323432344
agent-1: 412.0
agent-2: 387.0
agent-3: 374.0
agent-4: 395.0
agent-5: 311.0
Sum Reward: 1879.0
Avg Reward: 375.8
Min Reward: 311.0
Max Reward: 412.0
Gini Coefficient: 0.0474720596061735
20:20 Ratio: 1.32475884244373
Max-min Ratio: 1.32475884244373
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_12-22-08
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1992.0
  episode_reward_mean: 1568.4301075268818
  episode_reward_min: 223.0
  episodes_this_iter: 1
  episodes_total: 93
  experiment_id: ebedc1946062457bb682d57fae83bd74
  hostname: gpu052
  info:
    apply_time_ms: 2.523
    dispatch_time_ms: 8.446
    learner:
      cur_lr: 0.0013290309580042958
      grad_gnorm: 39.999996185302734
      policy_entropy: 11.933113098144531
      policy_loss: 10.106473922729492
      var_gnorm: 28.987632751464844
      vf_explained_var: -0.4193899631500244
      vf_loss: 51.504493713378906
    num_steps_sampled: 470000
    num_steps_trained: 470000
    wait_time_ms: 107.921
  iterations_since_restore: 94
  node_ip: 172.17.8.52
  num_metric_batches_dropped: 0
  pid: 12141
  policy_reward_mean: {}
  time_since_restore: 1313.49929022789
  time_this_iter_s: 56.19345784187317
  time_total_s: 1313.49929022789
  timestamp: 1594138928
  timesteps_since_restore: 470000
  timesteps_this_iter: 5000
  timesteps_total: 470000
  training_iteration: 94
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 34.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=12141], 1313 s, 94 iter, 470000 ts, 1.57e+03 rew

Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_12-22-23
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1992.0
  episode_reward_mean: 1571.7340425531916
  episode_reward_min: 223.0
  episodes_this_iter: 1
  episodes_total: 94
  experiment_id: ebedc1946062457bb682d57fae83bd74
  hostname: gpu052
  info:
    apply_time_ms: 4.198
    dispatch_time_ms: 9.385
    learner:
      cur_lr: 0.0013286980101838708
      grad_gnorm: 39.999996185302734
      policy_entropy: 16.354333877563477
      policy_loss: 13.018819808959961
      var_gnorm: 29.0306453704834
      vf_explained_var: 0.0013672113418579102
      vf_loss: 57.29215621948242
    num_steps_sampled: 475000
    num_steps_trained: 475000
    wait_time_ms: 126.343
  iterations_since_restore: 95
  node_ip: 172.17.8.52
  num_metric_batches_dropped: 0
  pid: 12141
  policy_reward_mean: {}
  time_since_restore: 1325.6112360954285
  time_this_iter_s: 12.111945867538452
  time_total_s: 1325.6112360954285
  timestamp: 1594138943
  timesteps_since_restore: 475000
  timesteps_this_iter: 5000
  timesteps_total: 475000
  training_iteration: 95
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 34.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=12141], 1325 s, 95 iter, 475000 ts, 1.57e+03 rew

agent-1: 312.0
agent-2: 305.0
agent-3: 364.0
agent-4: 327.0
agent-5: 310.0
Sum Reward: 1618.0
Avg Reward: 323.6
Min Reward: 305.0
Max Reward: 364.0
Gini Coefficient: 0.03337453646477132
20:20 Ratio: 1.1934426229508197
Max-min Ratio: 1.1934426229508197
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_12-22-38
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1992.0
  episode_reward_mean: 1572.221052631579
  episode_reward_min: 223.0
  episodes_this_iter: 1
  episodes_total: 95
  experiment_id: ebedc1946062457bb682d57fae83bd74
  hostname: gpu052
  info:
    apply_time_ms: 2.559
    dispatch_time_ms: 10.225
    learner:
      cur_lr: 0.001328364945948124
      grad_gnorm: 40.000003814697266
      policy_entropy: 18.323488235473633
      policy_loss: 0.8945688009262085
      var_gnorm: 29.122398376464844
      vf_explained_var: 0.2529367208480835
      vf_loss: 113.16903686523438
    num_steps_sampled: 480000
    num_steps_trained: 480000
    wait_time_ms: 134.976
  iterations_since_restore: 96
  node_ip: 172.17.8.52
  num_metric_batches_dropped: 0
  pid: 12141
  policy_reward_mean: {}
  time_since_restore: 1341.0120117664337
  time_this_iter_s: 15.400775671005249
  time_total_s: 1341.0120117664337
  timestamp: 1594138958
  timesteps_since_restore: 480000
  timesteps_this_iter: 5000
  timesteps_total: 480000
  training_iteration: 96
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 34.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=12141], 1341 s, 96 iter, 480000 ts, 1.57e+03 rew

agent-1: 363.0
agent-2: 346.0
agent-3: 389.0
agent-4: 386.0
agent-5: 383.0
Sum Reward: 1867.0
Avg Reward: 373.4
Min Reward: 346.0
Max Reward: 389.0
Gini Coefficient: 0.023352972683449384
20:20 Ratio: 1.1242774566473988
Max-min Ratio: 1.1242774566473988
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_12-22-52
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1992.0
  episode_reward_mean: 1575.2916666666667
  episode_reward_min: 223.0
  episodes_this_iter: 1
  episodes_total: 96
  experiment_id: ebedc1946062457bb682d57fae83bd74
  hostname: gpu052
  info:
    apply_time_ms: 3.215
    dispatch_time_ms: 10.171
    learner:
      cur_lr: 0.001328031998127699
      grad_gnorm: 40.00000762939453
      policy_entropy: 19.994768142700195
      policy_loss: 0.15072709321975708
      var_gnorm: 29.22905731201172
      vf_explained_var: 0.09637570381164551
      vf_loss: 50.821502685546875
    num_steps_sampled: 485000
    num_steps_trained: 485000
    wait_time_ms: 137.705
  iterations_since_restore: 97
  node_ip: 172.17.8.52
  num_metric_batches_dropped: 0
  pid: 12141
  policy_reward_mean: {}
  time_since_restore: 1354.5393509864807
  time_this_iter_s: 13.527339220046997
  time_total_s: 1354.5393509864807
  timestamp: 1594138972
  timesteps_since_restore: 485000
  timesteps_this_iter: 5000
  timesteps_total: 485000
  training_iteration: 97
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 34.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=12141], 1354 s, 97 iter, 485000 ts, 1.58e+03 rew

agent-1: 261.0
agent-2: 300.0
agent-3: 301.0
agent-4: 344.0
agent-5: 293.0
Sum Reward: 1499.0
Avg Reward: 299.8
Min Reward: 261.0
Max Reward: 344.0
Gini Coefficient: 0.04643095396931288
20:20 Ratio: 1.318007662835249
Max-min Ratio: 1.318007662835249
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_12-23-07
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1992.0
  episode_reward_mean: 1574.5051546391753
  episode_reward_min: 223.0
  episodes_this_iter: 1
  episodes_total: 97
  experiment_id: ebedc1946062457bb682d57fae83bd74
  hostname: gpu052
  info:
    apply_time_ms: 3.909
    dispatch_time_ms: 6.851
    learner:
      cur_lr: 0.0013276990503072739
      grad_gnorm: 39.99999237060547
      policy_entropy: 17.935815811157227
      policy_loss: 25.008258819580078
      var_gnorm: 29.421539306640625
      vf_explained_var: 0.5365604162216187
      vf_loss: 192.1204376220703
    num_steps_sampled: 490000
    num_steps_trained: 490000
    wait_time_ms: 123.61
  iterations_since_restore: 98
  node_ip: 172.17.8.52
  num_metric_batches_dropped: 0
  pid: 12141
  policy_reward_mean: {}
  time_since_restore: 1370.0647325515747
  time_this_iter_s: 15.525381565093994
  time_total_s: 1370.0647325515747
  timestamp: 1594138987
  timesteps_since_restore: 490000
  timesteps_this_iter: 5000
  timesteps_total: 490000
  training_iteration: 98
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 34.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=12141], 1370 s, 98 iter, 490000 ts, 1.57e+03 rew

agent-1: 306.0
agent-2: 346.0
agent-3: 251.0
agent-4: 314.0
agent-5: 283.0
Sum Reward: 1500.0
Avg Reward: 300.0
Min Reward: 251.0
Max Reward: 346.0
Gini Coefficient: 0.05893333333333333
20:20 Ratio: 1.3784860557768925
Max-min Ratio: 1.3784860557768925
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_12-23-20
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1992.0
  episode_reward_mean: 1573.7448979591836
  episode_reward_min: 223.0
  episodes_this_iter: 1
  episodes_total: 98
  experiment_id: ebedc1946062457bb682d57fae83bd74
  hostname: gpu052
  info:
    apply_time_ms: 2.727
    dispatch_time_ms: 12.199
    learner:
      cur_lr: 0.001327365986071527
      grad_gnorm: 40.0
      policy_entropy: 19.69873046875
      policy_loss: 16.64866828918457
      var_gnorm: 29.45262908935547
      vf_explained_var: 0.5988637208938599
      vf_loss: 94.83380126953125
    num_steps_sampled: 495000
    num_steps_trained: 495000
    wait_time_ms: 119.179
  iterations_since_restore: 99
  node_ip: 172.17.8.52
  num_metric_batches_dropped: 0
  pid: 12141
  policy_reward_mean: {}
  time_since_restore: 1382.5298807621002
  time_this_iter_s: 12.465148210525513
  time_total_s: 1382.5298807621002
  timestamp: 1594139000
  timesteps_since_restore: 495000
  timesteps_this_iter: 5000
  timesteps_total: 495000
  training_iteration: 99
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 34.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=12141], 1382 s, 99 iter, 495000 ts, 1.57e+03 rew

agent-1: 302.0
agent-2: 365.0
agent-3: 363.0
agent-4: 356.0
agent-5: 332.0
Sum Reward: 1718.0
Avg Reward: 343.6
Min Reward: 302.0
Max Reward: 365.0
Gini Coefficient: 0.03655413271245635
20:20 Ratio: 1.2086092715231789
Max-min Ratio: 1.2086092715231789
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_12-23-34
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1992.0
  episode_reward_mean: 1575.20202020202
  episode_reward_min: 223.0
  episodes_this_iter: 1
  episodes_total: 99
  experiment_id: ebedc1946062457bb682d57fae83bd74
  hostname: gpu052
  info:
    apply_time_ms: 3.067
    dispatch_time_ms: 9.313
    learner:
      cur_lr: 0.001327033038251102
      grad_gnorm: 40.000003814697266
      policy_entropy: 27.20340919494629
      policy_loss: -14.556694984436035
      var_gnorm: 29.496788024902344
      vf_explained_var: 0.672228217124939
      vf_loss: 123.2115707397461
    num_steps_sampled: 500000
    num_steps_trained: 500000
    wait_time_ms: 144.076
  iterations_since_restore: 100
  node_ip: 172.17.8.52
  num_metric_batches_dropped: 0
  pid: 12141
  policy_reward_mean: {}
  time_since_restore: 1396.9503037929535
  time_this_iter_s: 14.420423030853271
  time_total_s: 1396.9503037929535
  timestamp: 1594139014
  timesteps_since_restore: 500000
  timesteps_this_iter: 5000
  timesteps_total: 500000
  training_iteration: 100
  
agent-1: 391.0
agent-2: 377.0
agent-3: 317.0
agent-4: 373.0
agent-5: 377.0
Sum Reward: 1835.0
Avg Reward: 367.0
Min Reward: 317.0
Max Reward: 391.0
Gini Coefficient: 0.03313351498637602
20:20 Ratio: 1.2334384858044165
Max-min Ratio: 1.2334384858044165
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 34.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=12141], 1396 s, 100 iter, 500000 ts, 1.58e+03 rew

Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_12-23-48
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1992.0
  episode_reward_mean: 1577.8
  episode_reward_min: 223.0
  episodes_this_iter: 1
  episodes_total: 100
  experiment_id: ebedc1946062457bb682d57fae83bd74
  hostname: gpu052
  info:
    apply_time_ms: 2.515
    dispatch_time_ms: 11.649
    learner:
      cur_lr: 0.0013266999740153551
      grad_gnorm: 39.99999237060547
      policy_entropy: 19.489004135131836
      policy_loss: -14.35589599609375
      var_gnorm: 29.62226676940918
      vf_explained_var: 0.6830688714981079
      vf_loss: 73.62979888916016
    num_steps_sampled: 505000
    num_steps_trained: 505000
    wait_time_ms: 138.586
  iterations_since_restore: 101
  node_ip: 172.17.8.52
  num_metric_batches_dropped: 0
  pid: 12141
  policy_reward_mean: {}
  time_since_restore: 1410.5531032085419
  time_this_iter_s: 13.602799415588379
  time_total_s: 1410.5531032085419
  timestamp: 1594139028
  timesteps_since_restore: 505000
  timesteps_this_iter: 5000
  timesteps_total: 505000
  training_iteration: 101
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 34.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=12141], 1410 s, 101 iter, 505000 ts, 1.58e+03 rew

agent-1: 302.0
agent-2: 288.0
agent-3: 260.0
agent-4: 264.0
agent-5: 297.0
Sum Reward: 1411.0
Avg Reward: 282.2
Min Reward: 260.0
Max Reward: 302.0
Gini Coefficient: 0.03316796598157335
20:20 Ratio: 1.1615384615384616
Max-min Ratio: 1.1615384615384616
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_12-24-13
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1992.0
  episode_reward_mean: 1587.09
  episode_reward_min: 223.0
  episodes_this_iter: 1
  episodes_total: 101
  experiment_id: ebedc1946062457bb682d57fae83bd74
  hostname: gpu052
  info:
    apply_time_ms: 3.048
    dispatch_time_ms: 7.772
    learner:
      cur_lr: 0.00132636702619493
      grad_gnorm: 40.000003814697266
      policy_entropy: 36.822383880615234
      policy_loss: -9.031188011169434
      var_gnorm: 29.699169158935547
      vf_explained_var: 0.32788020372390747
      vf_loss: 44.03129196166992
    num_steps_sampled: 510000
    num_steps_trained: 510000
    wait_time_ms: 130.303
  iterations_since_restore: 102
  node_ip: 172.17.8.52
  num_metric_batches_dropped: 0
  pid: 12141
  policy_reward_mean: {}
  time_since_restore: 1434.7191910743713
  time_this_iter_s: 24.166087865829468
  time_total_s: 1434.7191910743713
  timestamp: 1594139053
  timesteps_since_restore: 510000
  timesteps_this_iter: 5000
  timesteps_total: 510000
  training_iteration: 102
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 33.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=12141], 1434 s, 102 iter, 510000 ts, 1.59e+03 rew

agent-1: 289.0
agent-2: 346.0
agent-3: 316.0
agent-4: 318.0
agent-5: 311.0
Sum Reward: 1580.0
Avg Reward: 316.0
Min Reward: 289.0
Max Reward: 346.0
Gini Coefficient: 0.030632911392405062
20:20 Ratio: 1.1972318339100345
Max-min Ratio: 1.1972318339100345
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_12-24-30
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1992.0
  episode_reward_mean: 1600.66
  episode_reward_min: 898.0
  episodes_this_iter: 1
  episodes_total: 102
  experiment_id: ebedc1946062457bb682d57fae83bd74
  hostname: gpu052
  info:
    apply_time_ms: 2.717
    dispatch_time_ms: 11.047
    learner:
      cur_lr: 0.0013260339619591832
      grad_gnorm: 40.0
      policy_entropy: 22.2224178314209
      policy_loss: 8.788056373596191
      var_gnorm: 29.774765014648438
      vf_explained_var: 0.32018619775772095
      vf_loss: 69.60709381103516
    num_steps_sampled: 515000
    num_steps_trained: 515000
    wait_time_ms: 139.319
  iterations_since_restore: 103
  node_ip: 172.17.8.52
  num_metric_batches_dropped: 0
  pid: 12141
  policy_reward_mean: {}
  time_since_restore: 1452.197031736374
  time_this_iter_s: 17.477840662002563
  time_total_s: 1452.197031736374
  timestamp: 1594139070
  timesteps_since_restore: 515000
  timesteps_this_iter: 5000
  timesteps_total: 515000
  training_iteration: 103
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 33.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=12141], 1452 s, 103 iter, 515000 ts, 1.6e+03 rew

agent-1: 278.0
agent-2: 335.0
agent-3: 306.0
agent-4: 309.0
agent-5: 345.0
Sum Reward: 1573.0
Avg Reward: 314.6
Min Reward: 278.0
Max Reward: 345.0
Gini Coefficient: 0.041449459631277816
20:20 Ratio: 1.2410071942446044
Max-min Ratio: 1.2410071942446044
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_12-24-47
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1992.0
  episode_reward_mean: 1605.46
  episode_reward_min: 898.0
  episodes_this_iter: 1
  episodes_total: 103
  experiment_id: ebedc1946062457bb682d57fae83bd74
  hostname: gpu052
  info:
    apply_time_ms: 2.798
    dispatch_time_ms: 9.423
    learner:
      cur_lr: 0.0013257010141387582
      grad_gnorm: 40.0
      policy_entropy: 18.09600257873535
      policy_loss: 6.364863395690918
      var_gnorm: 29.79957389831543
      vf_explained_var: 0.501417875289917
      vf_loss: 39.86229705810547
    num_steps_sampled: 520000
    num_steps_trained: 520000
    wait_time_ms: 144.392
  iterations_since_restore: 104
  node_ip: 172.17.8.52
  num_metric_batches_dropped: 0
  pid: 12141
  policy_reward_mean: {}
  time_since_restore: 1468.537127494812
  time_this_iter_s: 16.34009575843811
  time_total_s: 1468.537127494812
  timestamp: 1594139087
  timesteps_since_restore: 520000
  timesteps_this_iter: 5000
  timesteps_total: 520000
  training_iteration: 104
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 33.3/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=12141], 1468 s, 104 iter, 520000 ts, 1.61e+03 rew

agent-1: 338.0
agent-2: 340.0
agent-3: 328.0
agent-4: 340.0
agent-5: 329.0
Sum Reward: 1675.0
Avg Reward: 335.0
Min Reward: 328.0
Max Reward: 340.0
Gini Coefficient: 0.00835820895522388
20:20 Ratio: 1.0365853658536586
Max-min Ratio: 1.0365853658536586
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_12-24-59
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1992.0
  episode_reward_mean: 1613.23
  episode_reward_min: 1083.0
  episodes_this_iter: 1
  episodes_total: 104
  experiment_id: ebedc1946062457bb682d57fae83bd74
  hostname: gpu052
  info:
    apply_time_ms: 4.13
    dispatch_time_ms: 10.339
    learner:
      cur_lr: 0.0013253679499030113
      grad_gnorm: 40.0
      policy_entropy: 17.175216674804688
      policy_loss: 25.51123046875
      var_gnorm: 29.876073837280273
      vf_explained_var: -0.24650979042053223
      vf_loss: 84.36079406738281
    num_steps_sampled: 525000
    num_steps_trained: 525000
    wait_time_ms: 119.902
  iterations_since_restore: 105
  node_ip: 172.17.8.52
  num_metric_batches_dropped: 0
  pid: 12141
  policy_reward_mean: {}
  time_since_restore: 1481.353684425354
  time_this_iter_s: 12.816556930541992
  time_total_s: 1481.353684425354
  timestamp: 1594139099
  timesteps_since_restore: 525000
  timesteps_this_iter: 5000
  timesteps_total: 525000
  training_iteration: 105
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 33.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=12141], 1481 s, 105 iter, 525000 ts, 1.61e+03 rew

agent-1: 385.0
agent-2: 391.0
agent-3: 340.0
agent-4: 370.0
agent-5: 407.0
Sum Reward: 1893.0
Avg Reward: 378.6
Min Reward: 340.0
Max Reward: 407.0
Gini Coefficient: 0.032752245113576335
20:20 Ratio: 1.1970588235294117
Max-min Ratio: 1.1970588235294117
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_12-25-14
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1992.0
  episode_reward_mean: 1619.5
  episode_reward_min: 1083.0
  episodes_this_iter: 1
  episodes_total: 105
  experiment_id: ebedc1946062457bb682d57fae83bd74
  hostname: gpu052
  info:
    apply_time_ms: 3.253
    dispatch_time_ms: 15.501
    learner:
      cur_lr: 0.0013250350020825863
      grad_gnorm: 40.0
      policy_entropy: 35.84443283081055
      policy_loss: -19.11585807800293
      var_gnorm: 29.954946517944336
      vf_explained_var: 0.9126881957054138
      vf_loss: 38.405250549316406
    num_steps_sampled: 530000
    num_steps_trained: 530000
    wait_time_ms: 120.569
  iterations_since_restore: 106
  node_ip: 172.17.8.52
  num_metric_batches_dropped: 0
  pid: 12141
  policy_reward_mean: {}
  time_since_restore: 1496.2969567775726
  time_this_iter_s: 14.943272352218628
  time_total_s: 1496.2969567775726
  timestamp: 1594139114
  timesteps_since_restore: 530000
  timesteps_this_iter: 5000
  timesteps_total: 530000
  training_iteration: 106
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 33.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=12141], 1496 s, 106 iter, 530000 ts, 1.62e+03 rew

agent-1: 336.0
agent-2: 333.0
agent-3: 265.0
agent-4: 383.0
agent-5: 359.0
Sum Reward: 1676.0
Avg Reward: 335.2
Min Reward: 265.0
Max Reward: 383.0
Gini Coefficient: 0.06252983293556086
20:20 Ratio: 1.4452830188679244
Max-min Ratio: 1.4452830188679244
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_12-25-28
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1992.0
  episode_reward_mean: 1623.25
  episode_reward_min: 1083.0
  episodes_this_iter: 1
  episodes_total: 106
  experiment_id: ebedc1946062457bb682d57fae83bd74
  hostname: gpu052
  info:
    apply_time_ms: 2.526
    dispatch_time_ms: 23.866
    learner:
      cur_lr: 0.0013247020542621613
      grad_gnorm: 40.0
      policy_entropy: 23.055538177490234
      policy_loss: 1.5933557748794556
      var_gnorm: 30.028444290161133
      vf_explained_var: 0.6922661662101746
      vf_loss: 40.740047454833984
    num_steps_sampled: 535000
    num_steps_trained: 535000
    wait_time_ms: 132.395
  iterations_since_restore: 107
  node_ip: 172.17.8.52
  num_metric_batches_dropped: 0
  pid: 12141
  policy_reward_mean: {}
  time_since_restore: 1510.0729575157166
  time_this_iter_s: 13.776000738143921
  time_total_s: 1510.0729575157166
  timestamp: 1594139128
  timesteps_since_restore: 535000
  timesteps_this_iter: 5000
  timesteps_total: 535000
  training_iteration: 107
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 33.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=12141], 1510 s, 107 iter, 535000 ts, 1.62e+03 rew

W0707 12:25:40.163249 12134 client_connection.cc:255] [worker]ProcessMessage with type 8 took 165 ms.
W0707 12:25:42.972339 12134 client_connection.cc:255] [worker]ProcessMessage with type 8 took 177 ms.
agent-1: 293.0
agent-2: 369.0
agent-3: 339.0
agent-4: 287.0
agent-5: 287.0
Sum Reward: 1575.0
Avg Reward: 315.0
Min Reward: 287.0
Max Reward: 369.0
Gini Coefficient: 0.054857142857142854
20:20 Ratio: 1.2857142857142858
Max-min Ratio: 1.2857142857142858
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_12-25-44
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1992.0
  episode_reward_mean: 1625.98
  episode_reward_min: 1083.0
  episodes_this_iter: 1
  episodes_total: 107
  experiment_id: ebedc1946062457bb682d57fae83bd74
  hostname: gpu052
  info:
    apply_time_ms: 2.561
    dispatch_time_ms: 20.792
    learner:
      cur_lr: 0.0013243689900264144
      grad_gnorm: 40.0
      policy_entropy: 18.328182220458984
      policy_loss: 12.28466510772705
      var_gnorm: 30.095191955566406
      vf_explained_var: -0.06835484504699707
      vf_loss: 38.96769332885742
    num_steps_sampled: 540000
    num_steps_trained: 540000
    wait_time_ms: 136.639
  iterations_since_restore: 108
  node_ip: 172.17.8.52
  num_metric_batches_dropped: 0
  pid: 12141
  policy_reward_mean: {}
  time_since_restore: 1526.0594708919525
  time_this_iter_s: 15.986513376235962
  time_total_s: 1526.0594708919525
  timestamp: 1594139144
  timesteps_since_restore: 540000
  timesteps_this_iter: 5000
  timesteps_total: 540000
  training_iteration: 108
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 33.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=12141], 1526 s, 108 iter, 540000 ts, 1.63e+03 rew

agent-1: 372.0
agent-2: 308.0
agent-3: 300.0
agent-4: 339.0
agent-5: 320.0
Sum Reward: 1639.0
Avg Reward: 327.8
Min Reward: 300.0
Max Reward: 372.0
Gini Coefficient: 0.04270896888346553
20:20 Ratio: 1.24
Max-min Ratio: 1.24
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_12-25-58
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1992.0
  episode_reward_mean: 1629.87
  episode_reward_min: 1083.0
  episodes_this_iter: 1
  episodes_total: 108
  experiment_id: ebedc1946062457bb682d57fae83bd74
  hostname: gpu052
  info:
    apply_time_ms: 2.709
    dispatch_time_ms: 28.331
    learner:
      cur_lr: 0.0013240360422059894
      grad_gnorm: 40.0
      policy_entropy: 25.89321517944336
      policy_loss: 6.098848819732666
      var_gnorm: 30.16110610961914
      vf_explained_var: 0.6847324371337891
      vf_loss: 93.15231323242188
    num_steps_sampled: 545000
    num_steps_trained: 545000
    wait_time_ms: 110.571
  iterations_since_restore: 109
  node_ip: 172.17.8.52
  num_metric_batches_dropped: 0
  pid: 12141
  policy_reward_mean: {}
  time_since_restore: 1539.5618896484375
  time_this_iter_s: 13.502418756484985
  time_total_s: 1539.5618896484375
  timestamp: 1594139158
  timesteps_since_restore: 545000
  timesteps_this_iter: 5000
  timesteps_total: 545000
  training_iteration: 109
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 33.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=12141], 1539 s, 109 iter, 545000 ts, 1.63e+03 rew

agent-1: 344.0
agent-2: 354.0
agent-3: 348.0
agent-4: 363.0
agent-5: 371.0
Sum Reward: 1780.0
Avg Reward: 356.0
Min Reward: 344.0
Max Reward: 371.0
Gini Coefficient: 0.015505617977528089
20:20 Ratio: 1.0784883720930232
Max-min Ratio: 1.0784883720930232
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_12-26-13
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1992.0
  episode_reward_mean: 1633.38
  episode_reward_min: 1083.0
  episodes_this_iter: 1
  episodes_total: 109
  experiment_id: ebedc1946062457bb682d57fae83bd74
  hostname: gpu052
  info:
    apply_time_ms: 2.972
    dispatch_time_ms: 22.575
    learner:
      cur_lr: 0.0013237029779702425
      grad_gnorm: 40.0
      policy_entropy: 8.507091522216797
      policy_loss: -6.327497959136963
      var_gnorm: 30.22338104248047
      vf_explained_var: 0.4997904300689697
      vf_loss: 38.552791595458984
    num_steps_sampled: 550000
    num_steps_trained: 550000
    wait_time_ms: 99.357
  iterations_since_restore: 110
  node_ip: 172.17.8.52
  num_metric_batches_dropped: 0
  pid: 12141
  policy_reward_mean: {}
  time_since_restore: 1554.5237410068512
  time_this_iter_s: 14.961851358413696
  time_total_s: 1554.5237410068512
  timestamp: 1594139173
  timesteps_since_restore: 550000
  timesteps_this_iter: 5000
  timesteps_total: 550000
  training_iteration: 110
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 33.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=12141], 1554 s, 110 iter, 550000 ts, 1.63e+03 rew

agent-1: 300.0
agent-2: 335.0
agent-3: 291.0
agent-4: 339.0
agent-5: 382.0
Sum Reward: 1647.0
Avg Reward: 329.4
Min Reward: 291.0
Max Reward: 382.0
Gini Coefficient: 0.05367334547662417
20:20 Ratio: 1.3127147766323024
Max-min Ratio: 1.3127147766323024
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_12-26-26
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1992.0
  episode_reward_mean: 1636.29
  episode_reward_min: 1083.0
  episodes_this_iter: 1
  episodes_total: 110
  experiment_id: ebedc1946062457bb682d57fae83bd74
  hostname: gpu052
  info:
    apply_time_ms: 3.109
    dispatch_time_ms: 37.235
    learner:
      cur_lr: 0.0013233700301498175
      grad_gnorm: 40.00000762939453
      policy_entropy: 25.886802673339844
      policy_loss: -14.950334548950195
      var_gnorm: 30.244415283203125
      vf_explained_var: 0.8290574550628662
      vf_loss: 62.14669418334961
    num_steps_sampled: 555000
    num_steps_trained: 555000
    wait_time_ms: 100.572
  iterations_since_restore: 111
  node_ip: 172.17.8.52
  num_metric_batches_dropped: 0
  pid: 12141
  policy_reward_mean: {}
  time_since_restore: 1567.849374294281
  time_this_iter_s: 13.32563328742981
  time_total_s: 1567.849374294281
  timestamp: 1594139186
  timesteps_since_restore: 555000
  timesteps_this_iter: 5000
  timesteps_total: 555000
  training_iteration: 111
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 33.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=12141], 1567 s, 111 iter, 555000 ts, 1.64e+03 rew

agent-1: 350.0
agent-2: 303.0
agent-3: 331.0
agent-4: 339.0
agent-5: 351.0
Sum Reward: 1674.0
Avg Reward: 334.8
Min Reward: 303.0
Max Reward: 351.0
Gini Coefficient: 0.027479091995221028
20:20 Ratio: 1.1584158415841583
Max-min Ratio: 1.1584158415841583
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_12-26-41
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1992.0
  episode_reward_mean: 1638.23
  episode_reward_min: 1083.0
  episodes_this_iter: 1
  episodes_total: 111
  experiment_id: ebedc1946062457bb682d57fae83bd74
  hostname: gpu052
  info:
    apply_time_ms: 4.812
    dispatch_time_ms: 17.636
    learner:
      cur_lr: 0.0013230369659140706
      grad_gnorm: 40.00001525878906
      policy_entropy: 22.743099212646484
      policy_loss: -7.6785430908203125
      var_gnorm: 30.27383041381836
      vf_explained_var: -0.13852322101593018
      vf_loss: 37.660945892333984
    num_steps_sampled: 560000
    num_steps_trained: 560000
    wait_time_ms: 121.475
  iterations_since_restore: 112
  node_ip: 172.17.8.52
  num_metric_batches_dropped: 0
  pid: 12141
  policy_reward_mean: {}
  time_since_restore: 1582.783423423767
  time_this_iter_s: 14.934049129486084
  time_total_s: 1582.783423423767
  timestamp: 1594139201
  timesteps_since_restore: 560000
  timesteps_this_iter: 5000
  timesteps_total: 560000
  training_iteration: 112
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 33.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=12141], 1582 s, 112 iter, 560000 ts, 1.64e+03 rew

agent-1: 363.0
agent-2: 338.0
agent-3: 312.0
agent-4: 344.0
agent-5: 338.0
Sum Reward: 1695.0
Avg Reward: 339.0
Min Reward: 312.0
Max Reward: 363.0
Gini Coefficient: 0.025486725663716816
20:20 Ratio: 1.1634615384615385
Max-min Ratio: 1.1634615384615385
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_12-26-55
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1992.0
  episode_reward_mean: 1641.02
  episode_reward_min: 1083.0
  episodes_this_iter: 1
  episodes_total: 112
  experiment_id: ebedc1946062457bb682d57fae83bd74
  hostname: gpu052
  info:
    apply_time_ms: 2.99
    dispatch_time_ms: 30.534
    learner:
      cur_lr: 0.0013227040180936456
      grad_gnorm: 40.000003814697266
      policy_entropy: 9.996804237365723
      policy_loss: -1.9338895082473755
      var_gnorm: 30.38568878173828
      vf_explained_var: 0.7762582302093506
      vf_loss: 28.573816299438477
    num_steps_sampled: 565000
    num_steps_trained: 565000
    wait_time_ms: 125.977
  iterations_since_restore: 113
  node_ip: 172.17.8.52
  num_metric_batches_dropped: 0
  pid: 12141
  policy_reward_mean: {}
  time_since_restore: 1596.3554935455322
  time_this_iter_s: 13.572070121765137
  time_total_s: 1596.3554935455322
  timestamp: 1594139215
  timesteps_since_restore: 565000
  timesteps_this_iter: 5000
  timesteps_total: 565000
  training_iteration: 113
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 33.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=12141], 1596 s, 113 iter, 565000 ts, 1.64e+03 rew

agent-1: 368.0
agent-2: 339.0
agent-3: 354.0
agent-4: 341.0
agent-5: 362.0
Sum Reward: 1764.0
Avg Reward: 352.8
Min Reward: 339.0
Max Reward: 368.0
Gini Coefficient: 0.017913832199546485
20:20 Ratio: 1.0855457227138643
Max-min Ratio: 1.0855457227138643
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_12-27-11
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1992.0
  episode_reward_mean: 1644.41
  episode_reward_min: 1083.0
  episodes_this_iter: 1
  episodes_total: 113
  experiment_id: ebedc1946062457bb682d57fae83bd74
  hostname: gpu052
  info:
    apply_time_ms: 3.011
    dispatch_time_ms: 17.805
    learner:
      cur_lr: 0.0013223709538578987
      grad_gnorm: 40.000003814697266
      policy_entropy: 7.791236400604248
      policy_loss: -4.475305080413818
      var_gnorm: 30.49210548400879
      vf_explained_var: 0.7519680261611938
      vf_loss: 48.067359924316406
    num_steps_sampled: 570000
    num_steps_trained: 570000
    wait_time_ms: 133.06
  iterations_since_restore: 114
  node_ip: 172.17.8.52
  num_metric_batches_dropped: 0
  pid: 12141
  policy_reward_mean: {}
  time_since_restore: 1612.1077239513397
  time_this_iter_s: 15.752230405807495
  time_total_s: 1612.1077239513397
  timestamp: 1594139231
  timesteps_since_restore: 570000
  timesteps_this_iter: 5000
  timesteps_total: 570000
  training_iteration: 114
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 33.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=12141], 1612 s, 114 iter, 570000 ts, 1.64e+03 rew

agent-1: 332.0
agent-2: 299.0
agent-3: 310.0
agent-4: 314.0
agent-5: 333.0
Sum Reward: 1588.0
Avg Reward: 317.6
Min Reward: 299.0
Max Reward: 333.0
Gini Coefficient: 0.022670025188916875
20:20 Ratio: 1.1137123745819397
Max-min Ratio: 1.1137123745819397
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_12-27-24
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1992.0
  episode_reward_mean: 1645.56
  episode_reward_min: 1083.0
  episodes_this_iter: 1
  episodes_total: 114
  experiment_id: ebedc1946062457bb682d57fae83bd74
  hostname: gpu052
  info:
    apply_time_ms: 2.537
    dispatch_time_ms: 21.19
    learner:
      cur_lr: 0.0013220380060374737
      grad_gnorm: 40.0
      policy_entropy: 14.086926460266113
      policy_loss: -35.863609313964844
      var_gnorm: 30.583829879760742
      vf_explained_var: 0.6958187818527222
      vf_loss: 110.34000396728516
    num_steps_sampled: 575000
    num_steps_trained: 575000
    wait_time_ms: 123.573
  iterations_since_restore: 115
  node_ip: 172.17.8.52
  num_metric_batches_dropped: 0
  pid: 12141
  policy_reward_mean: {}
  time_since_restore: 1625.3992087841034
  time_this_iter_s: 13.291484832763672
  time_total_s: 1625.3992087841034
  timestamp: 1594139244
  timesteps_since_restore: 575000
  timesteps_this_iter: 5000
  timesteps_total: 575000
  training_iteration: 115
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 33.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=12141], 1625 s, 115 iter, 575000 ts, 1.65e+03 rew

agent-1: 304.0
agent-2: 430.0
agent-3: 323.0
agent-4: 332.0
agent-5: 394.0
Sum Reward: 1783.0
Avg Reward: 356.6
Min Reward: 304.0
Max Reward: 430.0
Gini Coefficient: 0.07246214245653393
20:20 Ratio: 1.4144736842105263
Max-min Ratio: 1.4144736842105263
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_12-27-40
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1992.0
  episode_reward_mean: 1651.72
  episode_reward_min: 1083.0
  episodes_this_iter: 1
  episodes_total: 115
  experiment_id: ebedc1946062457bb682d57fae83bd74
  hostname: gpu052
  info:
    apply_time_ms: 2.641
    dispatch_time_ms: 25.764
    learner:
      cur_lr: 0.0013217049418017268
      grad_gnorm: 40.000003814697266
      policy_entropy: 12.934921264648438
      policy_loss: 8.32911491394043
      var_gnorm: 30.7036075592041
      vf_explained_var: 0.4095311760902405
      vf_loss: 94.00591278076172
    num_steps_sampled: 580000
    num_steps_trained: 580000
    wait_time_ms: 105.683
  iterations_since_restore: 116
  node_ip: 172.17.8.52
  num_metric_batches_dropped: 0
  pid: 12141
  policy_reward_mean: {}
  time_since_restore: 1641.1549508571625
  time_this_iter_s: 15.755742073059082
  time_total_s: 1641.1549508571625
  timestamp: 1594139260
  timesteps_since_restore: 580000
  timesteps_this_iter: 5000
  timesteps_total: 580000
  training_iteration: 116
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 33.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=12141], 1641 s, 116 iter, 580000 ts, 1.65e+03 rew

agent-1: 288.0
agent-2: 292.0
agent-3: 302.0
agent-4: 323.0
agent-5: 315.0
Sum Reward: 1520.0
Avg Reward: 304.0
Min Reward: 288.0
Max Reward: 323.0
Gini Coefficient: 0.024473684210526314
20:20 Ratio: 1.1215277777777777
Max-min Ratio: 1.1215277777777777
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_12-27-53
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1992.0
  episode_reward_mean: 1656.09
  episode_reward_min: 1302.0
  episodes_this_iter: 1
  episodes_total: 116
  experiment_id: ebedc1946062457bb682d57fae83bd74
  hostname: gpu052
  info:
    apply_time_ms: 2.871
    dispatch_time_ms: 21.707
    learner:
      cur_lr: 0.0013213719939813018
      grad_gnorm: 40.00001907348633
      policy_entropy: 15.36807918548584
      policy_loss: -8.844377517700195
      var_gnorm: 30.75787925720215
      vf_explained_var: 0.7553826570510864
      vf_loss: 62.24825668334961
    num_steps_sampled: 585000
    num_steps_trained: 585000
    wait_time_ms: 112.513
  iterations_since_restore: 117
  node_ip: 172.17.8.52
  num_metric_batches_dropped: 0
  pid: 12141
  policy_reward_mean: {}
  time_since_restore: 1654.441085577011
  time_this_iter_s: 13.286134719848633
  time_total_s: 1654.441085577011
  timestamp: 1594139273
  timesteps_since_restore: 585000
  timesteps_this_iter: 5000
  timesteps_total: 585000
  training_iteration: 117
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 33.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=12141], 1654 s, 117 iter, 585000 ts, 1.66e+03 rew

agent-1: 308.0
agent-2: 361.0
agent-3: 330.0
agent-4: 351.0
agent-5: 396.0
Sum Reward: 1746.0
Avg Reward: 349.2
Min Reward: 308.0
Max Reward: 396.0
Gini Coefficient: 0.04742268041237113
20:20 Ratio: 1.2857142857142858
Max-min Ratio: 1.2857142857142858
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_12-28-07
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1992.0
  episode_reward_mean: 1658.9
  episode_reward_min: 1302.0
  episodes_this_iter: 1
  episodes_total: 117
  experiment_id: ebedc1946062457bb682d57fae83bd74
  hostname: gpu052
  info:
    apply_time_ms: 2.716
    dispatch_time_ms: 28.28
    learner:
      cur_lr: 0.0013210390461608768
      grad_gnorm: 39.99999237060547
      policy_entropy: 26.64016342163086
      policy_loss: -18.885894775390625
      var_gnorm: 30.84730339050293
      vf_explained_var: 0.4699496030807495
      vf_loss: 56.88941192626953
    num_steps_sampled: 590000
    num_steps_trained: 590000
    wait_time_ms: 91.426
  iterations_since_restore: 118
  node_ip: 172.17.8.52
  num_metric_batches_dropped: 0
  pid: 12141
  policy_reward_mean: {}
  time_since_restore: 1668.4415118694305
  time_this_iter_s: 14.000426292419434
  time_total_s: 1668.4415118694305
  timestamp: 1594139287
  timesteps_since_restore: 590000
  timesteps_this_iter: 5000
  timesteps_total: 590000
  training_iteration: 118
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 33.3/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=12141], 1668 s, 118 iter, 590000 ts, 1.66e+03 rew

agent-1: 340.0
agent-2: 394.0
agent-3: 307.0
agent-4: 347.0
agent-5: 354.0
Sum Reward: 1742.0
Avg Reward: 348.4
Min Reward: 307.0
Max Reward: 394.0
Gini Coefficient: 0.04316877152698048
20:20 Ratio: 1.283387622149837
Max-min Ratio: 1.283387622149837
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_12-28-20
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1992.0
  episode_reward_mean: 1661.09
  episode_reward_min: 1302.0
  episodes_this_iter: 1
  episodes_total: 118
  experiment_id: ebedc1946062457bb682d57fae83bd74
  hostname: gpu052
  info:
    apply_time_ms: 2.963
    dispatch_time_ms: 26.986
    learner:
      cur_lr: 0.0013207059819251299
      grad_gnorm: 40.000003814697266
      policy_entropy: 9.921867370605469
      policy_loss: -9.999690055847168
      var_gnorm: 30.924381256103516
      vf_explained_var: 0.007752716541290283
      vf_loss: 23.38446044921875
    num_steps_sampled: 595000
    num_steps_trained: 595000
    wait_time_ms: 105.846
  iterations_since_restore: 119
  node_ip: 172.17.8.52
  num_metric_batches_dropped: 0
  pid: 12141
  policy_reward_mean: {}
  time_since_restore: 1681.6699085235596
  time_this_iter_s: 13.228396654129028
  time_total_s: 1681.6699085235596
  timestamp: 1594139300
  timesteps_since_restore: 595000
  timesteps_this_iter: 5000
  timesteps_total: 595000
  training_iteration: 119
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 33.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=12141], 1681 s, 119 iter, 595000 ts, 1.66e+03 rew

agent-1: 349.0
agent-2: 388.0
agent-3: 350.0
agent-4: 403.0
agent-5: 349.0
Sum Reward: 1839.0
Avg Reward: 367.8
Min Reward: 349.0
Max Reward: 403.0
Gini Coefficient: 0.03197389885807504
20:20 Ratio: 1.154727793696275
Max-min Ratio: 1.154727793696275
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_12-28-34
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1992.0
  episode_reward_mean: 1663.43
  episode_reward_min: 1302.0
  episodes_this_iter: 1
  episodes_total: 119
  experiment_id: ebedc1946062457bb682d57fae83bd74
  hostname: gpu052
  info:
    apply_time_ms: 2.523
    dispatch_time_ms: 22.104
    learner:
      cur_lr: 0.0013203730341047049
      grad_gnorm: 39.99999237060547
      policy_entropy: 12.38337516784668
      policy_loss: 4.356130599975586
      var_gnorm: 31.024276733398438
      vf_explained_var: 0.464360773563385
      vf_loss: 29.51666259765625
    num_steps_sampled: 600000
    num_steps_trained: 600000
    wait_time_ms: 100.124
  iterations_since_restore: 120
  node_ip: 172.17.8.52
  num_metric_batches_dropped: 0
  pid: 12141
  policy_reward_mean: {}
  time_since_restore: 1695.6499252319336
  time_this_iter_s: 13.980016708374023
  time_total_s: 1695.6499252319336
  timestamp: 1594139314
  timesteps_since_restore: 600000
  timesteps_this_iter: 5000
  timesteps_total: 600000
  training_iteration: 120
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 33.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=12141], 1695 s, 120 iter, 600000 ts, 1.66e+03 rew

agent-1: 363.0
agent-2: 364.0
agent-3: 359.0
agent-4: 369.0
agent-5: 365.0
Sum Reward: 1820.0
Avg Reward: 364.0
Min Reward: 359.0
Max Reward: 369.0
Gini Coefficient: 0.004835164835164835
20:20 Ratio: 1.0278551532033426
Max-min Ratio: 1.0278551532033426
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_12-28-47
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1992.0
  episode_reward_mean: 1666.02
  episode_reward_min: 1302.0
  episodes_this_iter: 1
  episodes_total: 120
  experiment_id: ebedc1946062457bb682d57fae83bd74
  hostname: gpu052
  info:
    apply_time_ms: 3.523
    dispatch_time_ms: 23.738
    learner:
      cur_lr: 0.001320039969868958
      grad_gnorm: 39.99999237060547
      policy_entropy: 15.729267120361328
      policy_loss: -0.9031744599342346
      var_gnorm: 31.049259185791016
      vf_explained_var: 0.1704651117324829
      vf_loss: 32.58808898925781
    num_steps_sampled: 605000
    num_steps_trained: 605000
    wait_time_ms: 117.365
  iterations_since_restore: 121
  node_ip: 172.17.8.52
  num_metric_batches_dropped: 0
  pid: 12141
  policy_reward_mean: {}
  time_since_restore: 1708.5999991893768
  time_this_iter_s: 12.950073957443237
  time_total_s: 1708.5999991893768
  timestamp: 1594139327
  timesteps_since_restore: 605000
  timesteps_this_iter: 5000
  timesteps_total: 605000
  training_iteration: 121
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 33.3/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=12141], 1708 s, 121 iter, 605000 ts, 1.67e+03 rew

agent-1: 389.0
agent-2: 388.0
agent-3: 372.0
agent-4: 355.0
agent-5: 386.0
Sum Reward: 1890.0
Avg Reward: 378.0
Min Reward: 355.0
Max Reward: 389.0
Gini Coefficient: 0.017777777777777778
20:20 Ratio: 1.095774647887324
Max-min Ratio: 1.095774647887324
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_12-29-03
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1992.0
  episode_reward_mean: 1668.44
  episode_reward_min: 1302.0
  episodes_this_iter: 1
  episodes_total: 121
  experiment_id: ebedc1946062457bb682d57fae83bd74
  hostname: gpu052
  info:
    apply_time_ms: 2.86
    dispatch_time_ms: 20.903
    learner:
      cur_lr: 0.001319707022048533
      grad_gnorm: 40.00001525878906
      policy_entropy: 19.270967483520508
      policy_loss: -5.4272074699401855
      var_gnorm: 31.04997444152832
      vf_explained_var: 0.5905052423477173
      vf_loss: 25.14703369140625
    num_steps_sampled: 610000
    num_steps_trained: 610000
    wait_time_ms: 114.56
  iterations_since_restore: 122
  node_ip: 172.17.8.52
  num_metric_batches_dropped: 0
  pid: 12141
  policy_reward_mean: {}
  time_since_restore: 1723.757010936737
  time_this_iter_s: 15.15701174736023
  time_total_s: 1723.757010936737
  timestamp: 1594139343
  timesteps_since_restore: 610000
  timesteps_this_iter: 5000
  timesteps_total: 610000
  training_iteration: 122
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 33.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=12141], 1723 s, 122 iter, 610000 ts, 1.67e+03 rew

agent-1: 358.0
agent-2: 349.0
agent-3: 338.0
agent-4: 359.0
agent-5: 382.0
Sum Reward: 1786.0
Avg Reward: 357.2
Min Reward: 338.0
Max Reward: 382.0
Gini Coefficient: 0.0219484882418813
20:20 Ratio: 1.1301775147928994
Max-min Ratio: 1.1301775147928994
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_12-29-16
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1992.0
  episode_reward_mean: 1670.71
  episode_reward_min: 1302.0
  episodes_this_iter: 1
  episodes_total: 122
  experiment_id: ebedc1946062457bb682d57fae83bd74
  hostname: gpu052
  info:
    apply_time_ms: 3.392
    dispatch_time_ms: 23.497
    learner:
      cur_lr: 0.001319373957812786
      grad_gnorm: 39.999996185302734
      policy_entropy: 27.665733337402344
      policy_loss: -24.519527435302734
      var_gnorm: 31.112539291381836
      vf_explained_var: 0.6353845596313477
      vf_loss: 37.72088623046875
    num_steps_sampled: 615000
    num_steps_trained: 615000
    wait_time_ms: 117.269
  iterations_since_restore: 123
  node_ip: 172.17.8.52
  num_metric_batches_dropped: 0
  pid: 12141
  policy_reward_mean: {}
  time_since_restore: 1737.1109383106232
  time_this_iter_s: 13.353927373886108
  time_total_s: 1737.1109383106232
  timestamp: 1594139356
  timesteps_since_restore: 615000
  timesteps_this_iter: 5000
  timesteps_total: 615000
  training_iteration: 123
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 33.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=12141], 1737 s, 123 iter, 615000 ts, 1.67e+03 rew

agent-1: 273.0
agent-2: 366.0
agent-3: 294.0
agent-4: 281.0
agent-5: 309.0
Sum Reward: 1523.0
Avg Reward: 304.6
Min Reward: 273.0
Max Reward: 366.0
Gini Coefficient: 0.056204858831254104
20:20 Ratio: 1.3406593406593406
Max-min Ratio: 1.3406593406593406
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_12-29-32
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1992.0
  episode_reward_mean: 1669.17
  episode_reward_min: 1302.0
  episodes_this_iter: 1
  episodes_total: 123
  experiment_id: ebedc1946062457bb682d57fae83bd74
  hostname: gpu052
  info:
    apply_time_ms: 2.984
    dispatch_time_ms: 28.673
    learner:
      cur_lr: 0.001319041009992361
      grad_gnorm: 40.000003814697266
      policy_entropy: 20.286964416503906
      policy_loss: 7.428504467010498
      var_gnorm: 31.180034637451172
      vf_explained_var: 0.29660940170288086
      vf_loss: 111.82423400878906
    num_steps_sampled: 620000
    num_steps_trained: 620000
    wait_time_ms: 85.804
  iterations_since_restore: 124
  node_ip: 172.17.8.52
  num_metric_batches_dropped: 0
  pid: 12141
  policy_reward_mean: {}
  time_since_restore: 1752.6135828495026
  time_this_iter_s: 15.502644538879395
  time_total_s: 1752.6135828495026
  timestamp: 1594139372
  timesteps_since_restore: 620000
  timesteps_this_iter: 5000
  timesteps_total: 620000
  training_iteration: 124
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 33.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=12141], 1752 s, 124 iter, 620000 ts, 1.67e+03 rew

agent-1: 271.0
agent-2: 340.0
agent-3: 263.0
agent-4: 304.0
agent-5: 314.0
Sum Reward: 1492.0
Avg Reward: 298.4
Min Reward: 263.0
Max Reward: 340.0
Gini Coefficient: 0.052815013404825736
20:20 Ratio: 1.2927756653992395
Max-min Ratio: 1.2927756653992395
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_12-29-44
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1992.0
  episode_reward_mean: 1669.21
  episode_reward_min: 1302.0
  episodes_this_iter: 1
  episodes_total: 124
  experiment_id: ebedc1946062457bb682d57fae83bd74
  hostname: gpu052
  info:
    apply_time_ms: 2.831
    dispatch_time_ms: 18.705
    learner:
      cur_lr: 0.0013187079457566142
      grad_gnorm: 40.0
      policy_entropy: 23.694124221801758
      policy_loss: 2.3409359455108643
      var_gnorm: 31.236799240112305
      vf_explained_var: 0.8475489616394043
      vf_loss: 55.15925598144531
    num_steps_sampled: 625000
    num_steps_trained: 625000
    wait_time_ms: 116.826
  iterations_since_restore: 125
  node_ip: 172.17.8.52
  num_metric_batches_dropped: 0
  pid: 12141
  policy_reward_mean: {}
  time_since_restore: 1765.1783375740051
  time_this_iter_s: 12.564754724502563
  time_total_s: 1765.1783375740051
  timestamp: 1594139384
  timesteps_since_restore: 625000
  timesteps_this_iter: 5000
  timesteps_total: 625000
  training_iteration: 125
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 33.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=12141], 1765 s, 125 iter, 625000 ts, 1.67e+03 rew

agent-1: 251.0
agent-2: 354.0
agent-3: 268.0
agent-4: 358.0
agent-5: 299.0
Sum Reward: 1530.0
Avg Reward: 306.0
Min Reward: 251.0
Max Reward: 358.0
Gini Coefficient: 0.0784313725490196
20:20 Ratio: 1.4262948207171315
Max-min Ratio: 1.4262948207171315
Result for A3C_harvest_env_0:
agent-1: 276.0
agent-2: 349.0
agent-3: 326.0
agent-4: 262.0
agent-5: 319.0
Sum Reward: 1532.0
Avg Reward: 306.4
Min Reward: 262.0
Max Reward: 349.0
Gini Coefficient: 0.05848563968668407
20:20 Ratio: 1.33206106870229
Max-min Ratio: 1.33206106870229
  custom_metrics: {}
  date: 2020-07-07_12-30-02
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1992.0
  episode_reward_mean: 1669.9
  episode_reward_min: 1302.0
  episodes_this_iter: 1
  episodes_total: 125
  experiment_id: ebedc1946062457bb682d57fae83bd74
  hostname: gpu052
  info:
    apply_time_ms: 3.181
    dispatch_time_ms: 48.515
    learner:
      cur_lr: 0.0013183749979361892
      grad_gnorm: 40.0
      policy_entropy: 28.19289779663086
      policy_loss: -32.72074890136719
      var_gnorm: 31.28519058227539
      vf_explained_var: 0.603750467300415
      vf_loss: 47.03450012207031
    num_steps_sampled: 630000
    num_steps_trained: 630000
    wait_time_ms: 40.672
  iterations_since_restore: 126
  node_ip: 172.17.8.52
  num_metric_batches_dropped: 0
  pid: 12141
  policy_reward_mean: {}
  time_since_restore: 1783.1548285484314
  time_this_iter_s: 17.97649097442627
  time_total_s: 1783.1548285484314
  timestamp: 1594139402
  timesteps_since_restore: 630000
  timesteps_this_iter: 5000
  timesteps_total: 630000
  training_iteration: 126
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 33.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=12141], 1783 s, 126 iter, 630000 ts, 1.67e+03 rew

Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_12-30-15
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1992.0
  episode_reward_mean: 1669.86
  episode_reward_min: 1302.0
  episodes_this_iter: 1
  episodes_total: 126
  experiment_id: ebedc1946062457bb682d57fae83bd74
  hostname: gpu052
  info:
    apply_time_ms: 2.973
    dispatch_time_ms: 13.212
    learner:
      cur_lr: 0.0013180420501157641
      grad_gnorm: 39.999996185302734
      policy_entropy: 26.258872985839844
      policy_loss: 19.664155960083008
      var_gnorm: 31.369264602661133
      vf_explained_var: 0.5929980278015137
      vf_loss: 35.54563522338867
    num_steps_sampled: 635000
    num_steps_trained: 635000
    wait_time_ms: 124.107
  iterations_since_restore: 127
  node_ip: 172.17.8.52
  num_metric_batches_dropped: 0
  pid: 12141
  policy_reward_mean: {}
  time_since_restore: 1795.249567270279
  time_this_iter_s: 12.094738721847534
  time_total_s: 1795.249567270279
  timestamp: 1594139415
  timesteps_since_restore: 635000
  timesteps_this_iter: 5000
  timesteps_total: 635000
  training_iteration: 127
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 33.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=12141], 1795 s, 127 iter, 635000 ts, 1.67e+03 rew

agent-1: 349.0
agent-2: 385.0
agent-3: 329.0
agent-4: 346.0
agent-5: 324.0
Sum Reward: 1733.0
Avg Reward: 346.6
Min Reward: 324.0
Max Reward: 385.0
Gini Coefficient: 0.032775533756491636
20:20 Ratio: 1.1882716049382716
Max-min Ratio: 1.1882716049382716
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_12-30-30
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1992.0
  episode_reward_mean: 1671.7
  episode_reward_min: 1302.0
  episodes_this_iter: 1
  episodes_total: 127
  experiment_id: ebedc1946062457bb682d57fae83bd74
  hostname: gpu052
  info:
    apply_time_ms: 2.763
    dispatch_time_ms: 19.919
    learner:
      cur_lr: 0.0013177089858800173
      grad_gnorm: 40.000003814697266
      policy_entropy: 25.576372146606445
      policy_loss: 5.893718719482422
      var_gnorm: 31.371047973632812
      vf_explained_var: 0.24360406398773193
      vf_loss: 38.163818359375
    num_steps_sampled: 640000
    num_steps_trained: 640000
    wait_time_ms: 119.382
  iterations_since_restore: 128
  node_ip: 172.17.8.52
  num_metric_batches_dropped: 0
  pid: 12141
  policy_reward_mean: {}
  time_since_restore: 1809.312281370163
  time_this_iter_s: 14.062714099884033
  time_total_s: 1809.312281370163
  timestamp: 1594139430
  timesteps_since_restore: 640000
  timesteps_this_iter: 5000
  timesteps_total: 640000
  training_iteration: 128
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 33.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=12141], 1809 s, 128 iter, 640000 ts, 1.67e+03 rew

agent-1: 343.0
agent-2: 365.0
agent-3: 327.0
agent-4: 324.0
agent-5: 317.0
Sum Reward: 1676.0
Avg Reward: 335.2
Min Reward: 317.0
Max Reward: 365.0
Gini Coefficient: 0.027446300715990454
20:20 Ratio: 1.1514195583596214
Max-min Ratio: 1.1514195583596214
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_12-30-43
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1992.0
  episode_reward_mean: 1672.47
  episode_reward_min: 1302.0
  episodes_this_iter: 1
  episodes_total: 128
  experiment_id: ebedc1946062457bb682d57fae83bd74
  hostname: gpu052
  info:
    apply_time_ms: 3.502
    dispatch_time_ms: 20.065
    learner:
      cur_lr: 0.0013173760380595922
      grad_gnorm: 39.999996185302734
      policy_entropy: 6.84300422668457
      policy_loss: -9.214919090270996
      var_gnorm: 31.404991149902344
      vf_explained_var: 0.5367597341537476
      vf_loss: 40.54833984375
    num_steps_sampled: 645000
    num_steps_trained: 645000
    wait_time_ms: 103.5
  iterations_since_restore: 129
  node_ip: 172.17.8.52
  num_metric_batches_dropped: 0
  pid: 12141
  policy_reward_mean: {}
  time_since_restore: 1822.28298330307
  time_this_iter_s: 12.970701932907104
  time_total_s: 1822.28298330307
  timestamp: 1594139443
  timesteps_since_restore: 645000
  timesteps_this_iter: 5000
  timesteps_total: 645000
  training_iteration: 129
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 33.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=12141], 1822 s, 129 iter, 645000 ts, 1.67e+03 rew

agent-1: 377.0
agent-2: 392.0
agent-3: 396.0
agent-4: 378.0
agent-5: 407.0
Sum Reward: 1950.0
Avg Reward: 390.0
Min Reward: 377.0
Max Reward: 407.0
Gini Coefficient: 0.016
20:20 Ratio: 1.0795755968169762
Max-min Ratio: 1.0795755968169762
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_12-30-56
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1992.0
  episode_reward_mean: 1675.62
  episode_reward_min: 1302.0
  episodes_this_iter: 1
  episodes_total: 129
  experiment_id: ebedc1946062457bb682d57fae83bd74
  hostname: gpu052
  info:
    apply_time_ms: 3.011
    dispatch_time_ms: 32.681
    learner:
      cur_lr: 0.0013170429738238454
      grad_gnorm: 40.0
      policy_entropy: 10.610562324523926
      policy_loss: 1.2419919967651367
      var_gnorm: 31.393760681152344
      vf_explained_var: 0.4228619933128357
      vf_loss: 62.55215835571289
    num_steps_sampled: 650000
    num_steps_trained: 650000
    wait_time_ms: 80.972
  iterations_since_restore: 130
  node_ip: 172.17.8.52
  num_metric_batches_dropped: 0
  pid: 12141
  policy_reward_mean: {}
  time_since_restore: 1835.7247500419617
  time_this_iter_s: 13.441766738891602
  time_total_s: 1835.7247500419617
  timestamp: 1594139456
  timesteps_since_restore: 650000
  timesteps_this_iter: 5000
  timesteps_total: 650000
  training_iteration: 130
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 33.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=12141], 1835 s, 130 iter, 650000 ts, 1.68e+03 rew

agent-1: 377.0
agent-2: 390.0
agent-3: 372.0
agent-4: 357.0
agent-5: 390.0
Sum Reward: 1886.0
Avg Reward: 377.2
Min Reward: 357.0
Max Reward: 390.0
Gini Coefficient: 0.017815482502651112
20:20 Ratio: 1.0924369747899159
Max-min Ratio: 1.0924369747899159
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_12-31-10
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1992.0
  episode_reward_mean: 1677.92
  episode_reward_min: 1302.0
  episodes_this_iter: 1
  episodes_total: 130
  experiment_id: ebedc1946062457bb682d57fae83bd74
  hostname: gpu052
  info:
    apply_time_ms: 3.09
    dispatch_time_ms: 32.618
    learner:
      cur_lr: 0.0013167100260034204
      grad_gnorm: 39.999996185302734
      policy_entropy: 6.958944797515869
      policy_loss: -0.02518051117658615
      var_gnorm: 31.519609451293945
      vf_explained_var: 0.0631597638130188
      vf_loss: 34.85346603393555
    num_steps_sampled: 655000
    num_steps_trained: 655000
    wait_time_ms: 112.502
  iterations_since_restore: 131
  node_ip: 172.17.8.52
  num_metric_batches_dropped: 0
  pid: 12141
  policy_reward_mean: {}
  time_since_restore: 1849.22789478302
  time_this_iter_s: 13.50314474105835
  time_total_s: 1849.22789478302
  timestamp: 1594139470
  timesteps_since_restore: 655000
  timesteps_this_iter: 5000
  timesteps_total: 655000
  training_iteration: 131
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 33.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=12141], 1849 s, 131 iter, 655000 ts, 1.68e+03 rew

agent-1: 383.0
agent-2: 366.0
agent-3: 358.0
agent-4: 354.0
agent-5: 354.0
Sum Reward: 1815.0
Avg Reward: 363.0
Min Reward: 354.0
Max Reward: 383.0
Gini Coefficient: 0.015426997245179064
20:20 Ratio: 1.0819209039548023
Max-min Ratio: 1.0819209039548023
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_12-31-24
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1992.0
  episode_reward_mean: 1678.82
  episode_reward_min: 1302.0
  episodes_this_iter: 1
  episodes_total: 131
  experiment_id: ebedc1946062457bb682d57fae83bd74
  hostname: gpu052
  info:
    apply_time_ms: 2.885
    dispatch_time_ms: 27.793
    learner:
      cur_lr: 0.0013163769617676735
      grad_gnorm: 39.99999237060547
      policy_entropy: 14.998373031616211
      policy_loss: 14.789701461791992
      var_gnorm: 31.606136322021484
      vf_explained_var: 0.2431679368019104
      vf_loss: 49.53656005859375
    num_steps_sampled: 660000
    num_steps_trained: 660000
    wait_time_ms: 89.802
  iterations_since_restore: 132
  node_ip: 172.17.8.52
  num_metric_batches_dropped: 0
  pid: 12141
  policy_reward_mean: {}
  time_since_restore: 1863.372486114502
  time_this_iter_s: 14.144591331481934
  time_total_s: 1863.372486114502
  timestamp: 1594139484
  timesteps_since_restore: 660000
  timesteps_this_iter: 5000
  timesteps_total: 660000
  training_iteration: 132
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 33.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=12141], 1863 s, 132 iter, 660000 ts, 1.68e+03 rew

agent-1: 372.0
agent-2: 373.0
agent-3: 318.0
agent-4: 389.0
agent-5: 298.0
Sum Reward: 1750.0
Avg Reward: 350.0
Min Reward: 298.0
Max Reward: 389.0
Gini Coefficient: 0.05417142857142857
20:20 Ratio: 1.3053691275167785
Max-min Ratio: 1.3053691275167785
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_12-31-37
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1992.0
  episode_reward_mean: 1677.87
  episode_reward_min: 1302.0
  episodes_this_iter: 1
  episodes_total: 132
  experiment_id: ebedc1946062457bb682d57fae83bd74
  hostname: gpu052
  info:
    apply_time_ms: 2.76
    dispatch_time_ms: 24.612
    learner:
      cur_lr: 0.0013160440139472485
      grad_gnorm: 40.0
      policy_entropy: 11.169822692871094
      policy_loss: 5.971337795257568
      var_gnorm: 31.630983352661133
      vf_explained_var: 0.5946599245071411
      vf_loss: 25.680919647216797
    num_steps_sampled: 665000
    num_steps_trained: 665000
    wait_time_ms: 101.005
  iterations_since_restore: 133
  node_ip: 172.17.8.52
  num_metric_batches_dropped: 0
  pid: 12141
  policy_reward_mean: {}
  time_since_restore: 1876.4138915538788
  time_this_iter_s: 13.041405439376831
  time_total_s: 1876.4138915538788
  timestamp: 1594139497
  timesteps_since_restore: 665000
  timesteps_this_iter: 5000
  timesteps_total: 665000
  training_iteration: 133
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 33.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=12141], 1876 s, 133 iter, 665000 ts, 1.68e+03 rew

agent-1: 389.0
agent-2: 389.0
agent-3: 362.0
agent-4: 375.0
agent-5: 357.0
Sum Reward: 1872.0
Avg Reward: 374.4
Min Reward: 357.0
Max Reward: 389.0
Gini Coefficient: 0.019444444444444445
20:20 Ratio: 1.0896358543417366
Max-min Ratio: 1.0896358543417366
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_12-31-51
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1992.0
  episode_reward_mean: 1681.29
  episode_reward_min: 1302.0
  episodes_this_iter: 1
  episodes_total: 133
  experiment_id: ebedc1946062457bb682d57fae83bd74
  hostname: gpu052
  info:
    apply_time_ms: 4.126
    dispatch_time_ms: 25.166
    learner:
      cur_lr: 0.0013157109497115016
      grad_gnorm: 40.0
      policy_entropy: 17.181987762451172
      policy_loss: -13.19979476928711
      var_gnorm: 31.631086349487305
      vf_explained_var: 0.16739672422409058
      vf_loss: 83.17141723632812
    num_steps_sampled: 670000
    num_steps_trained: 670000
    wait_time_ms: 112.878
  iterations_since_restore: 134
  node_ip: 172.17.8.52
  num_metric_batches_dropped: 0
  pid: 12141
  policy_reward_mean: {}
  time_since_restore: 1890.8649446964264
  time_this_iter_s: 14.451053142547607
  time_total_s: 1890.8649446964264
  timestamp: 1594139511
  timesteps_since_restore: 670000
  timesteps_this_iter: 5000
  timesteps_total: 670000
  training_iteration: 134
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 34.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=12141], 1890 s, 134 iter, 670000 ts, 1.68e+03 rew

agent-1: 369.0
agent-2: 401.0
agent-3: 356.0
agent-4: 345.0
agent-5: 383.0
Sum Reward: 1854.0
Avg Reward: 370.8
Min Reward: 345.0
Max Reward: 401.0
Gini Coefficient: 0.029989212513484357
20:20 Ratio: 1.1623188405797102
Max-min Ratio: 1.1623188405797102
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_12-32-05
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1992.0
  episode_reward_mean: 1683.12
  episode_reward_min: 1302.0
  episodes_this_iter: 1
  episodes_total: 134
  experiment_id: ebedc1946062457bb682d57fae83bd74
  hostname: gpu052
  info:
    apply_time_ms: 2.643
    dispatch_time_ms: 19.281
    learner:
      cur_lr: 0.0013153780018910766
      grad_gnorm: 39.99999237060547
      policy_entropy: 13.095431327819824
      policy_loss: 3.8590176105499268
      var_gnorm: 31.64933967590332
      vf_explained_var: -0.31940150260925293
      vf_loss: 40.87566375732422
    num_steps_sampled: 675000
    num_steps_trained: 675000
    wait_time_ms: 138.919
  iterations_since_restore: 135
  node_ip: 172.17.8.52
  num_metric_batches_dropped: 0
  pid: 12141
  policy_reward_mean: {}
  time_since_restore: 1904.560804605484
  time_this_iter_s: 13.695859909057617
  time_total_s: 1904.560804605484
  timestamp: 1594139525
  timesteps_since_restore: 675000
  timesteps_this_iter: 5000
  timesteps_total: 675000
  training_iteration: 135
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 34.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=12141], 1904 s, 135 iter, 675000 ts, 1.68e+03 rew

agent-1: 349.0
agent-2: 364.0
agent-3: 312.0
agent-4: 339.0
agent-5: 389.0
Sum Reward: 1753.0
Avg Reward: 350.6
Min Reward: 312.0
Max Reward: 389.0
Gini Coefficient: 0.04084426697090702
20:20 Ratio: 1.2467948717948718
Max-min Ratio: 1.2467948717948718
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_12-32-20
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1992.0
  episode_reward_mean: 1683.72
  episode_reward_min: 1302.0
  episodes_this_iter: 1
  episodes_total: 135
  experiment_id: ebedc1946062457bb682d57fae83bd74
  hostname: gpu052
  info:
    apply_time_ms: 3.409
    dispatch_time_ms: 25.95
    learner:
      cur_lr: 0.0013150450540706515
      grad_gnorm: 40.000003814697266
      policy_entropy: 21.015377044677734
      policy_loss: -0.9326404333114624
      var_gnorm: 31.760412216186523
      vf_explained_var: -0.2704659700393677
      vf_loss: 71.23590850830078
    num_steps_sampled: 680000
    num_steps_trained: 680000
    wait_time_ms: 113.548
  iterations_since_restore: 136
  node_ip: 172.17.8.52
  num_metric_batches_dropped: 0
  pid: 12141
  policy_reward_mean: {}
  time_since_restore: 1919.8669550418854
  time_this_iter_s: 15.306150436401367
  time_total_s: 1919.8669550418854
  timestamp: 1594139540
  timesteps_since_restore: 680000
  timesteps_this_iter: 5000
  timesteps_total: 680000
  training_iteration: 136
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 34.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=12141], 1919 s, 136 iter, 680000 ts, 1.68e+03 rew

agent-1: 281.0
agent-2: 345.0
agent-3: 322.0
agent-4: 316.0
agent-5: 348.0
Sum Reward: 1612.0
Avg Reward: 322.4
Min Reward: 281.0
Max Reward: 348.0
Gini Coefficient: 0.04044665012406948
20:20 Ratio: 1.2384341637010676
Max-min Ratio: 1.2384341637010676
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_12-32-33
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1992.0
  episode_reward_mean: 1682.9
  episode_reward_min: 1302.0
  episodes_this_iter: 1
  episodes_total: 136
  experiment_id: ebedc1946062457bb682d57fae83bd74
  hostname: gpu052
  info:
    apply_time_ms: 2.897
    dispatch_time_ms: 30.296
    learner:
      cur_lr: 0.0013147119898349047
      grad_gnorm: 40.00000762939453
      policy_entropy: 20.396312713623047
      policy_loss: -17.40664291381836
      var_gnorm: 31.86131477355957
      vf_explained_var: 0.4921637773513794
      vf_loss: 95.11640930175781
    num_steps_sampled: 685000
    num_steps_trained: 685000
    wait_time_ms: 97.271
  iterations_since_restore: 137
  node_ip: 172.17.8.52
  num_metric_batches_dropped: 0
  pid: 12141
  policy_reward_mean: {}
  time_since_restore: 1932.7635340690613
  time_this_iter_s: 12.896579027175903
  time_total_s: 1932.7635340690613
  timestamp: 1594139553
  timesteps_since_restore: 685000
  timesteps_this_iter: 5000
  timesteps_total: 685000
  training_iteration: 137
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 34.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=12141], 1932 s, 137 iter, 685000 ts, 1.68e+03 rew

agent-1: 369.0
agent-2: 374.0
agent-3: 253.0
agent-4: 227.0
agent-5: 310.0
Sum Reward: 1533.0
Avg Reward: 306.6
Min Reward: 227.0
Max Reward: 374.0
Gini Coefficient: 0.10697977821265492
20:20 Ratio: 1.6475770925110131
Max-min Ratio: 1.6475770925110131
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_12-32-47
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1992.0
  episode_reward_mean: 1680.72
  episode_reward_min: 1302.0
  episodes_this_iter: 1
  episodes_total: 137
  experiment_id: ebedc1946062457bb682d57fae83bd74
  hostname: gpu052
  info:
    apply_time_ms: 2.805
    dispatch_time_ms: 27.725
    learner:
      cur_lr: 0.0013143790420144796
      grad_gnorm: 40.00000762939453
      policy_entropy: 22.36792755126953
      policy_loss: -1.9732290506362915
      var_gnorm: 31.86598777770996
      vf_explained_var: 0.8323286771774292
      vf_loss: 70.7269287109375
    num_steps_sampled: 690000
    num_steps_trained: 690000
    wait_time_ms: 108.345
  iterations_since_restore: 138
  node_ip: 172.17.8.52
  num_metric_batches_dropped: 0
  pid: 12141
  policy_reward_mean: {}
  time_since_restore: 1946.046701669693
  time_this_iter_s: 13.283167600631714
  time_total_s: 1946.046701669693
  timestamp: 1594139567
  timesteps_since_restore: 690000
  timesteps_this_iter: 5000
  timesteps_total: 690000
  training_iteration: 138
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 34.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=12141], 1946 s, 138 iter, 690000 ts, 1.68e+03 rew

agent-1: 249.0
agent-2: 388.0
agent-3: 292.0
agent-4: 317.0
agent-5: 310.0
Sum Reward: 1556.0
Avg Reward: 311.2
Min Reward: 249.0
Max Reward: 388.0
Gini Coefficient: 0.07789203084832905
20:20 Ratio: 1.5582329317269077
Max-min Ratio: 1.5582329317269077
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_12-33-00
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1992.0
  episode_reward_mean: 1678.86
  episode_reward_min: 1302.0
  episodes_this_iter: 1
  episodes_total: 138
  experiment_id: ebedc1946062457bb682d57fae83bd74
  hostname: gpu052
  info:
    apply_time_ms: 3.293
    dispatch_time_ms: 23.4
    learner:
      cur_lr: 0.0013140459777787328
      grad_gnorm: 40.00000762939453
      policy_entropy: 13.78345775604248
      policy_loss: 16.83262062072754
      var_gnorm: 31.923067092895508
      vf_explained_var: 0.2464909553527832
      vf_loss: 49.16691970825195
    num_steps_sampled: 695000
    num_steps_trained: 695000
    wait_time_ms: 121.013
  iterations_since_restore: 139
  node_ip: 172.17.8.52
  num_metric_batches_dropped: 0
  pid: 12141
  policy_reward_mean: {}
  time_since_restore: 1959.2205049991608
  time_this_iter_s: 13.173803329467773
  time_total_s: 1959.2205049991608
  timestamp: 1594139580
  timesteps_since_restore: 695000
  timesteps_this_iter: 5000
  timesteps_total: 695000
  training_iteration: 139
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 34.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=12141], 1959 s, 139 iter, 695000 ts, 1.68e+03 rew

agent-1: 400.0
agent-2: 307.0
agent-3: 346.0
agent-4: 302.0
agent-5: 362.0
Sum Reward: 1717.0
Avg Reward: 343.4
Min Reward: 302.0
Max Reward: 400.0
Gini Coefficient: 0.05847408270238789
20:20 Ratio: 1.3245033112582782
Max-min Ratio: 1.3245033112582782
agent-1: 360.0
agent-2: 356.0
agent-3: 369.0
agent-4: 371.0
agent-5: 388.0
Sum Reward: 1844.0
Avg Reward: 368.8
Min Reward: 356.0
Max Reward: 388.0
Gini Coefficient: 0.016268980477223426
20:20 Ratio: 1.0898876404494382
Max-min Ratio: 1.0898876404494382
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_12-33-15
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1992.0
  episode_reward_mean: 1681.35
  episode_reward_min: 1302.0
  episodes_this_iter: 2
  episodes_total: 140
  experiment_id: ebedc1946062457bb682d57fae83bd74
  hostname: gpu052
  info:
    apply_time_ms: 3.305
    dispatch_time_ms: 20.673
    learner:
      cur_lr: 0.0013137130299583077
      grad_gnorm: 39.999996185302734
      policy_entropy: 22.31477165222168
      policy_loss: -989.0047607421875
      var_gnorm: 31.93243408203125
      vf_explained_var: 0.11815571784973145
      vf_loss: 23545.765625
    num_steps_sampled: 700000
    num_steps_trained: 700000
    wait_time_ms: 144.41
  iterations_since_restore: 140
  node_ip: 172.17.8.52
  num_metric_batches_dropped: 0
  pid: 12141
  policy_reward_mean: {}
  time_since_restore: 1974.3628380298615
  time_this_iter_s: 15.142333030700684
  time_total_s: 1974.3628380298615
  timestamp: 1594139595
  timesteps_since_restore: 700000
  timesteps_this_iter: 5000
  timesteps_total: 700000
  training_iteration: 140
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 34.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=12141], 1974 s, 140 iter, 700000 ts, 1.68e+03 rew

Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_12-33-28
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1992.0
  episode_reward_mean: 1681.35
  episode_reward_min: 1302.0
  episodes_this_iter: 0
  episodes_total: 140
  experiment_id: ebedc1946062457bb682d57fae83bd74
  hostname: gpu052
  info:
    apply_time_ms: 2.615
    dispatch_time_ms: 28.632
    learner:
      cur_lr: 0.0013133799657225609
      grad_gnorm: 40.000003814697266
      policy_entropy: 12.539722442626953
      policy_loss: -3.957967519760132
      var_gnorm: 32.00373458862305
      vf_explained_var: 0.7182003259658813
      vf_loss: 27.572277069091797
    num_steps_sampled: 705000
    num_steps_trained: 705000
    wait_time_ms: 112.985
  iterations_since_restore: 141
  node_ip: 172.17.8.52
  num_metric_batches_dropped: 0
  pid: 12141
  policy_reward_mean: {}
  time_since_restore: 1987.7070245742798
  time_this_iter_s: 13.344186544418335
  time_total_s: 1987.7070245742798
  timestamp: 1594139608
  timesteps_since_restore: 705000
  timesteps_this_iter: 5000
  timesteps_total: 705000
  training_iteration: 141
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 34.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=12141], 1987 s, 141 iter, 705000 ts, 1.68e+03 rew

agent-1: 366.0
agent-2: 402.0
agent-3: 417.0
agent-4: 377.0
agent-5: 413.0
Sum Reward: 1975.0
Avg Reward: 395.0
Min Reward: 366.0
Max Reward: 417.0
Gini Coefficient: 0.027949367088607596
20:20 Ratio: 1.139344262295082
Max-min Ratio: 1.139344262295082
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_12-33-44
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1992.0
  episode_reward_mean: 1685.1
  episode_reward_min: 1302.0
  episodes_this_iter: 1
  episodes_total: 141
  experiment_id: ebedc1946062457bb682d57fae83bd74
  hostname: gpu052
  info:
    apply_time_ms: 2.583
    dispatch_time_ms: 27.462
    learner:
      cur_lr: 0.0013130470179021358
      grad_gnorm: 40.00000762939453
      policy_entropy: 19.33233642578125
      policy_loss: 23.334861755371094
      var_gnorm: 32.111915588378906
      vf_explained_var: -1.0
      vf_loss: 135.97250366210938
    num_steps_sampled: 710000
    num_steps_trained: 710000
    wait_time_ms: 95.424
  iterations_since_restore: 142
  node_ip: 172.17.8.52
  num_metric_batches_dropped: 0
  pid: 12141
  policy_reward_mean: {}
  time_since_restore: 2002.7032556533813
  time_this_iter_s: 14.996231079101562
  time_total_s: 2002.7032556533813
  timestamp: 1594139624
  timesteps_since_restore: 710000
  timesteps_this_iter: 5000
  timesteps_total: 710000
  training_iteration: 142
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 34.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=12141], 2002 s, 142 iter, 710000 ts, 1.69e+03 rew

agent-1: 341.0
agent-2: 363.0
agent-3: 291.0
agent-4: 372.0
agent-5: 367.0
Sum Reward: 1734.0
Avg Reward: 346.8
Min Reward: 291.0
Max Reward: 372.0
Gini Coefficient: 0.0433679354094579
20:20 Ratio: 1.2783505154639174
Max-min Ratio: 1.2783505154639174
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_12-33-57
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1992.0
  episode_reward_mean: 1685.22
  episode_reward_min: 1302.0
  episodes_this_iter: 1
  episodes_total: 142
  experiment_id: ebedc1946062457bb682d57fae83bd74
  hostname: gpu052
  info:
    apply_time_ms: 2.464
    dispatch_time_ms: 24.268
    learner:
      cur_lr: 0.001312713953666389
      grad_gnorm: 39.99999237060547
      policy_entropy: 27.170166015625
      policy_loss: -44.35129165649414
      var_gnorm: 32.189369201660156
      vf_explained_var: 0.6593689918518066
      vf_loss: 193.49514770507812
    num_steps_sampled: 715000
    num_steps_trained: 715000
    wait_time_ms: 117.272
  iterations_since_restore: 143
  node_ip: 172.17.8.52
  num_metric_batches_dropped: 0
  pid: 12141
  policy_reward_mean: {}
  time_since_restore: 2016.143056154251
  time_this_iter_s: 13.439800500869751
  time_total_s: 2016.143056154251
  timestamp: 1594139637
  timesteps_since_restore: 715000
  timesteps_this_iter: 5000
  timesteps_total: 715000
  training_iteration: 143
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 34.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=12141], 2016 s, 143 iter, 715000 ts, 1.69e+03 rew

agent-1: 310.0
agent-2: 372.0
agent-3: 273.0
agent-4: 354.0
agent-5: 316.0
Sum Reward: 1625.0
Avg Reward: 325.0
Min Reward: 273.0
Max Reward: 372.0
Gini Coefficient: 0.05956923076923077
20:20 Ratio: 1.3626373626373627
Max-min Ratio: 1.3626373626373627
agent-1: 284.0
agent-2: 347.0
agent-3: 323.0
agent-4: 345.0
agent-5: 342.0
Sum Reward: 1641.0
Avg Reward: 328.2
Min Reward: 284.0
Max Reward: 347.0
Gini Coefficient: 0.03607556368068251
20:20 Ratio: 1.221830985915493
Max-min Ratio: 1.221830985915493
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_12-34-12
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1992.0
  episode_reward_mean: 1686.97
  episode_reward_min: 1302.0
  episodes_this_iter: 2
  episodes_total: 144
  experiment_id: ebedc1946062457bb682d57fae83bd74
  hostname: gpu052
  info:
    apply_time_ms: 2.545
    dispatch_time_ms: 25.945
    learner:
      cur_lr: 0.001312381005845964
      grad_gnorm: 40.0
      policy_entropy: 47.92570495605469
      policy_loss: -1319.8956298828125
      var_gnorm: 32.216796875
      vf_explained_var: -1.0
      vf_loss: 19181.650390625
    num_steps_sampled: 720000
    num_steps_trained: 720000
    wait_time_ms: 117.129
  iterations_since_restore: 144
  node_ip: 172.17.8.52
  num_metric_batches_dropped: 0
  pid: 12141
  policy_reward_mean: {}
  time_since_restore: 2031.3641273975372
  time_this_iter_s: 15.221071243286133
  time_total_s: 2031.3641273975372
  timestamp: 1594139652
  timesteps_since_restore: 720000
  timesteps_this_iter: 5000
  timesteps_total: 720000
  training_iteration: 144
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 33.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=12141], 2031 s, 144 iter, 720000 ts, 1.69e+03 rew

Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_12-34-25
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1992.0
  episode_reward_mean: 1686.97
  episode_reward_min: 1302.0
  episodes_this_iter: 0
  episodes_total: 144
  experiment_id: ebedc1946062457bb682d57fae83bd74
  hostname: gpu052
  info:
    apply_time_ms: 3.639
    dispatch_time_ms: 31.948
    learner:
      cur_lr: 0.001312048058025539
      grad_gnorm: 40.000003814697266
      policy_entropy: 22.00589370727539
      policy_loss: 19.147476196289062
      var_gnorm: 32.274723052978516
      vf_explained_var: 0.8285162448883057
      vf_loss: 86.46881103515625
    num_steps_sampled: 725000
    num_steps_trained: 725000
    wait_time_ms: 91.039
  iterations_since_restore: 145
  node_ip: 172.17.8.52
  num_metric_batches_dropped: 0
  pid: 12141
  policy_reward_mean: {}
  time_since_restore: 2043.842957496643
  time_this_iter_s: 12.478830099105835
  time_total_s: 2043.842957496643
  timestamp: 1594139665
  timesteps_since_restore: 725000
  timesteps_this_iter: 5000
  timesteps_total: 725000
  training_iteration: 145
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 33.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=12141], 2043 s, 145 iter, 725000 ts, 1.69e+03 rew

agent-1: 258.0
agent-2: 393.0
agent-3: 250.0
agent-4: 304.0
agent-5: 375.0
Sum Reward: 1580.0
Avg Reward: 316.0
Min Reward: 250.0
Max Reward: 393.0
Gini Coefficient: 0.10202531645569621
20:20 Ratio: 1.572
Max-min Ratio: 1.572
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_12-34-39
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1992.0
  episode_reward_mean: 1685.61
  episode_reward_min: 1302.0
  episodes_this_iter: 1
  episodes_total: 145
  experiment_id: ebedc1946062457bb682d57fae83bd74
  hostname: gpu052
  info:
    apply_time_ms: 4.026
    dispatch_time_ms: 23.895
    learner:
      cur_lr: 0.001311714993789792
      grad_gnorm: 40.0
      policy_entropy: 8.827754020690918
      policy_loss: 22.339479446411133
      var_gnorm: 32.30927658081055
      vf_explained_var: -0.5675075054168701
      vf_loss: 161.2179718017578
    num_steps_sampled: 730000
    num_steps_trained: 730000
    wait_time_ms: 90.23
  iterations_since_restore: 146
  node_ip: 172.17.8.52
  num_metric_batches_dropped: 0
  pid: 12141
  policy_reward_mean: {}
  time_since_restore: 2057.561096906662
  time_this_iter_s: 13.718139410018921
  time_total_s: 2057.561096906662
  timestamp: 1594139679
  timesteps_since_restore: 730000
  timesteps_this_iter: 5000
  timesteps_total: 730000
  training_iteration: 146
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 33.3/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=12141], 2057 s, 146 iter, 730000 ts, 1.69e+03 rew

agent-1: 343.0
agent-2: 408.0
agent-3: 246.0
agent-4: 332.0
agent-5: 321.0
Sum Reward: 1650.0
Avg Reward: 330.0
Min Reward: 246.0
Max Reward: 408.0
Gini Coefficient: 0.08387878787878787
20:20 Ratio: 1.6585365853658536
Max-min Ratio: 1.6585365853658536
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_12-34-52
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1992.0
  episode_reward_mean: 1684.27
  episode_reward_min: 1302.0
  episodes_this_iter: 1
  episodes_total: 146
  experiment_id: ebedc1946062457bb682d57fae83bd74
  hostname: gpu052
  info:
    apply_time_ms: 3.997
    dispatch_time_ms: 28.096
    learner:
      cur_lr: 0.001311382045969367
      grad_gnorm: 39.99999237060547
      policy_entropy: 17.15641212463379
      policy_loss: -20.269420623779297
      var_gnorm: 32.3878173828125
      vf_explained_var: 0.8444480299949646
      vf_loss: 57.12919998168945
    num_steps_sampled: 735000
    num_steps_trained: 735000
    wait_time_ms: 114.772
  iterations_since_restore: 147
  node_ip: 172.17.8.52
  num_metric_batches_dropped: 0
  pid: 12141
  policy_reward_mean: {}
  time_since_restore: 2070.7780210971832
  time_this_iter_s: 13.21692419052124
  time_total_s: 2070.7780210971832
  timestamp: 1594139692
  timesteps_since_restore: 735000
  timesteps_this_iter: 5000
  timesteps_total: 735000
  training_iteration: 147
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 33.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=12141], 2070 s, 147 iter, 735000 ts, 1.68e+03 rew

agent-1: 403.0
agent-2: 366.0
agent-3: 356.0
agent-4: 346.0
agent-5: 359.0
Sum Reward: 1830.0
Avg Reward: 366.0
Min Reward: 346.0
Max Reward: 403.0
Gini Coefficient: 0.027103825136612022
20:20 Ratio: 1.1647398843930636
Max-min Ratio: 1.1647398843930636
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_12-35-07
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1992.0
  episode_reward_mean: 1686.59
  episode_reward_min: 1302.0
  episodes_this_iter: 1
  episodes_total: 147
  experiment_id: ebedc1946062457bb682d57fae83bd74
  hostname: gpu052
  info:
    apply_time_ms: 4.068
    dispatch_time_ms: 41.804
    learner:
      cur_lr: 0.0013110489817336202
      grad_gnorm: 40.000003814697266
      policy_entropy: 19.816837310791016
      policy_loss: -4.570717811584473
      var_gnorm: 32.41975402832031
      vf_explained_var: 0.5834380388259888
      vf_loss: 23.42332649230957
    num_steps_sampled: 740000
    num_steps_trained: 740000
    wait_time_ms: 100.742
  iterations_since_restore: 148
  node_ip: 172.17.8.52
  num_metric_batches_dropped: 0
  pid: 12141
  policy_reward_mean: {}
  time_since_restore: 2085.793882369995
  time_this_iter_s: 15.01586127281189
  time_total_s: 2085.793882369995
  timestamp: 1594139707
  timesteps_since_restore: 740000
  timesteps_this_iter: 5000
  timesteps_total: 740000
  training_iteration: 148
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 34.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=12141], 2085 s, 148 iter, 740000 ts, 1.69e+03 rew

agent-1: 328.0
agent-2: 337.0
agent-3: 239.0
agent-4: 258.0
agent-5: 316.0
Sum Reward: 1478.0
Avg Reward: 295.6
Min Reward: 239.0
Max Reward: 337.0
Gini Coefficient: 0.07198917456021652
20:20 Ratio: 1.4100418410041842
Max-min Ratio: 1.4100418410041842
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_12-35-20
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1992.0
  episode_reward_mean: 1683.25
  episode_reward_min: 1302.0
  episodes_this_iter: 1
  episodes_total: 148
  experiment_id: ebedc1946062457bb682d57fae83bd74
  hostname: gpu052
  info:
    apply_time_ms: 3.77
    dispatch_time_ms: 16.711
    learner:
      cur_lr: 0.0013107160339131951
      grad_gnorm: 40.0
      policy_entropy: 7.9106855392456055
      policy_loss: -2.8299102783203125
      var_gnorm: 32.4368782043457
      vf_explained_var: 0.7843964695930481
      vf_loss: 87.62201690673828
    num_steps_sampled: 745000
    num_steps_trained: 745000
    wait_time_ms: 119.709
  iterations_since_restore: 149
  node_ip: 172.17.8.52
  num_metric_batches_dropped: 0
  pid: 12141
  policy_reward_mean: {}
  time_since_restore: 2099.1584441661835
  time_this_iter_s: 13.364561796188354
  time_total_s: 2099.1584441661835
  timestamp: 1594139720
  timesteps_since_restore: 745000
  timesteps_this_iter: 5000
  timesteps_total: 745000
  training_iteration: 149
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 33.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=12141], 2099 s, 149 iter, 745000 ts, 1.68e+03 rew

agent-1: 377.0
agent-2: 400.0
agent-3: 371.0
agent-4: 372.0
agent-5: 381.0
Sum Reward: 1901.0
Avg Reward: 380.2
Min Reward: 371.0
Max Reward: 400.0
Gini Coefficient: 0.01409784324039979
20:20 Ratio: 1.0781671159029649
Max-min Ratio: 1.0781671159029649
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_12-35-38
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1992.0
  episode_reward_mean: 1683.21
  episode_reward_min: 1302.0
  episodes_this_iter: 1
  episodes_total: 149
  experiment_id: ebedc1946062457bb682d57fae83bd74
  hostname: gpu052
  info:
    apply_time_ms: 3.33
    dispatch_time_ms: 36.458
    learner:
      cur_lr: 0.0013103829696774483
      grad_gnorm: 40.00000762939453
      policy_entropy: 14.435890197753906
      policy_loss: 5.73535680770874
      var_gnorm: 32.49887466430664
      vf_explained_var: 0.5123757123947144
      vf_loss: 118.47687530517578
    num_steps_sampled: 750000
    num_steps_trained: 750000
    wait_time_ms: 86.104
  iterations_since_restore: 150
  node_ip: 172.17.8.52
  num_metric_batches_dropped: 0
  pid: 12141
  policy_reward_mean: {}
  time_since_restore: 2116.8981688022614
  time_this_iter_s: 17.73972463607788
  time_total_s: 2116.8981688022614
  timestamp: 1594139738
  timesteps_since_restore: 750000
  timesteps_this_iter: 5000
  timesteps_total: 750000
  training_iteration: 150
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 33.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=12141], 2116 s, 150 iter, 750000 ts, 1.68e+03 rew

agent-1: 322.0
agent-2: 328.0
agent-3: 360.0
agent-4: 303.0
agent-5: 372.0
Sum Reward: 1685.0
Avg Reward: 337.0
Min Reward: 303.0
Max Reward: 372.0
Gini Coefficient: 0.04178041543026706
20:20 Ratio: 1.2277227722772277
Max-min Ratio: 1.2277227722772277
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_12-35-52
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1992.0
  episode_reward_mean: 1682.47
  episode_reward_min: 1302.0
  episodes_this_iter: 1
  episodes_total: 150
  experiment_id: ebedc1946062457bb682d57fae83bd74
  hostname: gpu052
  info:
    apply_time_ms: 2.745
    dispatch_time_ms: 26.772
    learner:
      cur_lr: 0.0013100500218570232
      grad_gnorm: 39.999996185302734
      policy_entropy: 7.996952533721924
      policy_loss: 4.699617862701416
      var_gnorm: 32.55134201049805
      vf_explained_var: 0.640920102596283
      vf_loss: 16.175302505493164
    num_steps_sampled: 755000
    num_steps_trained: 755000
    wait_time_ms: 115.757
  iterations_since_restore: 151
  node_ip: 172.17.8.52
  num_metric_batches_dropped: 0
  pid: 12141
  policy_reward_mean: {}
  time_since_restore: 2130.4645445346832
  time_this_iter_s: 13.566375732421875
  time_total_s: 2130.4645445346832
  timestamp: 1594139752
  timesteps_since_restore: 755000
  timesteps_this_iter: 5000
  timesteps_total: 755000
  training_iteration: 151
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 33.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=12141], 2130 s, 151 iter, 755000 ts, 1.68e+03 rew

agent-1: 334.0
agent-2: 425.0
agent-3: 328.0
agent-4: 360.0
agent-5: 402.0
Sum Reward: 1849.0
Avg Reward: 369.8
Min Reward: 328.0
Max Reward: 425.0
Gini Coefficient: 0.05667928610059492
20:20 Ratio: 1.295731707317073
Max-min Ratio: 1.295731707317073
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_12-36-07
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1992.0
  episode_reward_mean: 1686.19
  episode_reward_min: 1302.0
  episodes_this_iter: 1
  episodes_total: 151
  experiment_id: ebedc1946062457bb682d57fae83bd74
  hostname: gpu052
  info:
    apply_time_ms: 2.824
    dispatch_time_ms: 17.453
    learner:
      cur_lr: 0.0013097169576212764
      grad_gnorm: 39.99999237060547
      policy_entropy: 14.749395370483398
      policy_loss: -70.69922637939453
      var_gnorm: 32.62948989868164
      vf_explained_var: 0.19451671838760376
      vf_loss: 175.54367065429688
    num_steps_sampled: 760000
    num_steps_trained: 760000
    wait_time_ms: 123.517
  iterations_since_restore: 152
  node_ip: 172.17.8.52
  num_metric_batches_dropped: 0
  pid: 12141
  policy_reward_mean: {}
  time_since_restore: 2145.3679459095
  time_this_iter_s: 14.903401374816895
  time_total_s: 2145.3679459095
  timestamp: 1594139767
  timesteps_since_restore: 760000
  timesteps_this_iter: 5000
  timesteps_total: 760000
  training_iteration: 152
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 33.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=12141], 2145 s, 152 iter, 760000 ts, 1.69e+03 rew

agent-1: 366.0
agent-2: 351.0
agent-3: 352.0
agent-4: 350.0
agent-5: 352.0
Sum Reward: 1771.0
Avg Reward: 354.2
Min Reward: 350.0
Max Reward: 366.0
Gini Coefficient: 0.007453416149068323
20:20 Ratio: 1.0457142857142858
Max-min Ratio: 1.0457142857142858
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_12-36-20
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1992.0
  episode_reward_mean: 1685.99
  episode_reward_min: 1302.0
  episodes_this_iter: 1
  episodes_total: 152
  experiment_id: ebedc1946062457bb682d57fae83bd74
  hostname: gpu052
  info:
    apply_time_ms: 3.349
    dispatch_time_ms: 30.836
    learner:
      cur_lr: 0.0013093840098008513
      grad_gnorm: 40.00000762939453
      policy_entropy: 20.224157333374023
      policy_loss: -33.63391876220703
      var_gnorm: 32.71982955932617
      vf_explained_var: 0.7513889074325562
      vf_loss: 91.16732788085938
    num_steps_sampled: 765000
    num_steps_trained: 765000
    wait_time_ms: 118.436
  iterations_since_restore: 153
  node_ip: 172.17.8.52
  num_metric_batches_dropped: 0
  pid: 12141
  policy_reward_mean: {}
  time_since_restore: 2159.152116060257
  time_this_iter_s: 13.784170150756836
  time_total_s: 2159.152116060257
  timestamp: 1594139780
  timesteps_since_restore: 765000
  timesteps_this_iter: 5000
  timesteps_total: 765000
  training_iteration: 153
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 34.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=12141], 2159 s, 153 iter, 765000 ts, 1.69e+03 rew

agent-1: 356.0
agent-2: 376.0
agent-3: 289.0
agent-4: 347.0
agent-5: 280.0
Sum Reward: 1648.0
Avg Reward: 329.6
Min Reward: 280.0
Max Reward: 376.0
Gini Coefficient: 0.06286407766990292
20:20 Ratio: 1.3428571428571427
Max-min Ratio: 1.3428571428571427
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_12-36-34
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1992.0
  episode_reward_mean: 1685.65
  episode_reward_min: 1302.0
  episodes_this_iter: 1
  episodes_total: 153
  experiment_id: ebedc1946062457bb682d57fae83bd74
  hostname: gpu052
  info:
    apply_time_ms: 2.676
    dispatch_time_ms: 21.14
    learner:
      cur_lr: 0.0013090509455651045
      grad_gnorm: 39.999996185302734
      policy_entropy: 5.665982246398926
      policy_loss: 12.948878288269043
      var_gnorm: 32.75661087036133
      vf_explained_var: 0.8398851156234741
      vf_loss: 179.69717407226562
    num_steps_sampled: 770000
    num_steps_trained: 770000
    wait_time_ms: 103.39
  iterations_since_restore: 154
  node_ip: 172.17.8.52
  num_metric_batches_dropped: 0
  pid: 12141
  policy_reward_mean: {}
  time_since_restore: 2173.170093536377
  time_this_iter_s: 14.017977476119995
  time_total_s: 2173.170093536377
  timestamp: 1594139794
  timesteps_since_restore: 770000
  timesteps_this_iter: 5000
  timesteps_total: 770000
  training_iteration: 154
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 34.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=12141], 2173 s, 154 iter, 770000 ts, 1.69e+03 rew

agent-1: 376.0
agent-2: 390.0
agent-3: 232.0
agent-4: 285.0
agent-5: 328.0
Sum Reward: 1611.0
Avg Reward: 322.2
Min Reward: 232.0
Max Reward: 390.0
Gini Coefficient: 0.1010552451893234
20:20 Ratio: 1.6810344827586208
Max-min Ratio: 1.6810344827586208
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_12-36-47
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1992.0
  episode_reward_mean: 1686.08
  episode_reward_min: 1302.0
  episodes_this_iter: 1
  episodes_total: 154
  experiment_id: ebedc1946062457bb682d57fae83bd74
  hostname: gpu052
  info:
    apply_time_ms: 2.961
    dispatch_time_ms: 28.94
    learner:
      cur_lr: 0.0013087179977446795
      grad_gnorm: 39.99999237060547
      policy_entropy: 7.764725685119629
      policy_loss: -2.6218559741973877
      var_gnorm: 32.78025817871094
      vf_explained_var: 0.9856266975402832
      vf_loss: 31.158689498901367
    num_steps_sampled: 775000
    num_steps_trained: 775000
    wait_time_ms: 87.511
  iterations_since_restore: 155
  node_ip: 172.17.8.52
  num_metric_batches_dropped: 0
  pid: 12141
  policy_reward_mean: {}
  time_since_restore: 2185.270303964615
  time_this_iter_s: 12.100210428237915
  time_total_s: 2185.270303964615
  timestamp: 1594139807
  timesteps_since_restore: 775000
  timesteps_this_iter: 5000
  timesteps_total: 775000
  training_iteration: 155
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 34.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=12141], 2185 s, 155 iter, 775000 ts, 1.69e+03 rew

agent-1: 200.0
agent-2: 386.0
agent-3: 390.0
agent-4: 373.0
agent-5: 430.0
Sum Reward: 1779.0
Avg Reward: 355.8
Min Reward: 200.0
Max Reward: 430.0
Gini Coefficient: 0.10725126475548061
20:20 Ratio: 2.15
Max-min Ratio: 2.15
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_12-36-59
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1992.0
  episode_reward_mean: 1688.37
  episode_reward_min: 1302.0
  episodes_this_iter: 1
  episodes_total: 155
  experiment_id: ebedc1946062457bb682d57fae83bd74
  hostname: gpu052
  info:
    apply_time_ms: 2.467
    dispatch_time_ms: 22.837
    learner:
      cur_lr: 0.0013083850499242544
      grad_gnorm: 40.000003814697266
      policy_entropy: 13.070965766906738
      policy_loss: -10.494379043579102
      var_gnorm: 32.872581481933594
      vf_explained_var: -0.030846714973449707
      vf_loss: 23.12067413330078
    num_steps_sampled: 780000
    num_steps_trained: 780000
    wait_time_ms: 106.091
  iterations_since_restore: 156
  node_ip: 172.17.8.52
  num_metric_batches_dropped: 0
  pid: 12141
  policy_reward_mean: {}
  time_since_restore: 2197.8108916282654
  time_this_iter_s: 12.540587663650513
  time_total_s: 2197.8108916282654
  timestamp: 1594139819
  timesteps_since_restore: 780000
  timesteps_this_iter: 5000
  timesteps_total: 780000
  training_iteration: 156
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 33.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=12141], 2197 s, 156 iter, 780000 ts, 1.69e+03 rew

agent-1: 366.0
agent-2: 447.0
agent-3: 236.0
agent-4: 8.0
agent-5: 434.0
Sum Reward: 1491.0
Avg Reward: 298.2
Min Reward: 8.0
Max Reward: 447.0
Gini Coefficient: 0.2886653252850436
20:20 Ratio: 55.875
Max-min Ratio: 55.875
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_12-37-13
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1992.0
  episode_reward_mean: 1685.2
  episode_reward_min: 1302.0
  episodes_this_iter: 1
  episodes_total: 156
  experiment_id: ebedc1946062457bb682d57fae83bd74
  hostname: gpu052
  info:
    apply_time_ms: 2.775
    dispatch_time_ms: 46.76
    learner:
      cur_lr: 0.0013080519856885076
      grad_gnorm: 27.37989616394043
      policy_entropy: 7.216461181640625
      policy_loss: 1.6037925481796265
      var_gnorm: 32.9399528503418
      vf_explained_var: 0.9121144413948059
      vf_loss: 68.5289077758789
    num_steps_sampled: 785000
    num_steps_trained: 785000
    wait_time_ms: 85.559
  iterations_since_restore: 157
  node_ip: 172.17.8.52
  num_metric_batches_dropped: 0
  pid: 12141
  policy_reward_mean: {}
  time_since_restore: 2211.102965593338
  time_this_iter_s: 13.292073965072632
  time_total_s: 2211.102965593338
  timestamp: 1594139833
  timesteps_since_restore: 785000
  timesteps_this_iter: 5000
  timesteps_total: 785000
  training_iteration: 157
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 33.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=12141], 2211 s, 157 iter, 785000 ts, 1.69e+03 rew

agent-1: 390.0
agent-2: 352.0
agent-3: 320.0
agent-4: 248.0
agent-5: 381.0
Sum Reward: 1691.0
Avg Reward: 338.2
Min Reward: 248.0
Max Reward: 390.0
Gini Coefficient: 0.08160851567120048
20:20 Ratio: 1.5725806451612903
Max-min Ratio: 1.5725806451612903
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_12-37-26
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1992.0
  episode_reward_mean: 1686.43
  episode_reward_min: 1302.0
  episodes_this_iter: 1
  episodes_total: 157
  experiment_id: ebedc1946062457bb682d57fae83bd74
  hostname: gpu052
  info:
    apply_time_ms: 3.163
    dispatch_time_ms: 22.437
    learner:
      cur_lr: 0.0013077190378680825
      grad_gnorm: 40.0
      policy_entropy: 22.462993621826172
      policy_loss: 19.02712059020996
      var_gnorm: 32.960205078125
      vf_explained_var: 0.9709159731864929
      vf_loss: 32.5852165222168
    num_steps_sampled: 790000
    num_steps_trained: 790000
    wait_time_ms: 91.445
  iterations_since_restore: 158
  node_ip: 172.17.8.52
  num_metric_batches_dropped: 0
  pid: 12141
  policy_reward_mean: {}
  time_since_restore: 2223.9993443489075
  time_this_iter_s: 12.896378755569458
  time_total_s: 2223.9993443489075
  timestamp: 1594139846
  timesteps_since_restore: 790000
  timesteps_this_iter: 5000
  timesteps_total: 790000
  training_iteration: 158
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 33.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=12141], 2223 s, 158 iter, 790000 ts, 1.69e+03 rew

agent-1: 364.0
agent-2: 368.0
agent-3: 347.0
agent-4: 339.0
agent-5: 270.0
Sum Reward: 1688.0
Avg Reward: 337.6
Min Reward: 270.0
Max Reward: 368.0
Gini Coefficient: 0.0523696682464455
20:20 Ratio: 1.362962962962963
Max-min Ratio: 1.362962962962963
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_12-37-38
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1992.0
  episode_reward_mean: 1688.93
  episode_reward_min: 1302.0
  episodes_this_iter: 1
  episodes_total: 158
  experiment_id: ebedc1946062457bb682d57fae83bd74
  hostname: gpu052
  info:
    apply_time_ms: 2.89
    dispatch_time_ms: 34.229
    learner:
      cur_lr: 0.0013073859736323357
      grad_gnorm: 40.0
      policy_entropy: 13.757416725158691
      policy_loss: 25.236738204956055
      var_gnorm: 33.015220642089844
      vf_explained_var: 0.9398289918899536
      vf_loss: 84.79190826416016
    num_steps_sampled: 795000
    num_steps_trained: 795000
    wait_time_ms: 85.876
  iterations_since_restore: 159
  node_ip: 172.17.8.52
  num_metric_batches_dropped: 0
  pid: 12141
  policy_reward_mean: {}
  time_since_restore: 2236.273472070694
  time_this_iter_s: 12.274127721786499
  time_total_s: 2236.273472070694
  timestamp: 1594139858
  timesteps_since_restore: 795000
  timesteps_this_iter: 5000
  timesteps_total: 795000
  training_iteration: 159
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 33.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=12141], 2236 s, 159 iter, 795000 ts, 1.69e+03 rew

agent-1: 359.0
agent-2: 439.0
agent-3: 398.0
agent-4: -6.0
agent-5: 342.0
Sum Reward: 1532.0
Avg Reward: 306.4
Min Reward: -6.0
Max Reward: 439.0
Gini Coefficient: 0.24699738903394255
20:20 Ratio: -73.16666666666667
Max-min Ratio: -73.16666666666667
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_12-37-50
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1992.0
  episode_reward_mean: 1691.2
  episode_reward_min: 1302.0
  episodes_this_iter: 1
  episodes_total: 159
  experiment_id: ebedc1946062457bb682d57fae83bd74
  hostname: gpu052
  info:
    apply_time_ms: 3.364
    dispatch_time_ms: 28.271
    learner:
      cur_lr: 0.0013070530258119106
      grad_gnorm: 40.0
      policy_entropy: 22.523103713989258
      policy_loss: -46.93671798706055
      var_gnorm: 33.085235595703125
      vf_explained_var: 0.9305433034896851
      vf_loss: 331.9605407714844
    num_steps_sampled: 800000
    num_steps_trained: 800000
    wait_time_ms: 76.82
  iterations_since_restore: 160
  node_ip: 172.17.8.52
  num_metric_batches_dropped: 0
  pid: 12141
  policy_reward_mean: {}
  time_since_restore: 2248.4983315467834
  time_this_iter_s: 12.224859476089478
  time_total_s: 2248.4983315467834
  timestamp: 1594139870
  timesteps_since_restore: 800000
  timesteps_this_iter: 5000
  timesteps_total: 800000
  training_iteration: 160
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 33.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=12141], 2248 s, 160 iter, 800000 ts, 1.69e+03 rew

agent-1: 383.0
agent-2: 393.0
agent-3: -9237.0
agent-4: -9532.0
agent-5: 436.0
Sum Reward: -17557.0
Avg Reward: -3511.4
Min Reward: -9532.0
Max Reward: 436.0
Gini Coefficient: -0.673600273395227
20:20 Ratio: -0.045740663029794376
Max-min Ratio: -0.045740663029794376
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_12-38-02
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1992.0
  episode_reward_mean: 1499.15
  episode_reward_min: -17557.0
  episodes_this_iter: 1
  episodes_total: 160
  experiment_id: ebedc1946062457bb682d57fae83bd74
  hostname: gpu052
  info:
    apply_time_ms: 3.013
    dispatch_time_ms: 24.992
    learner:
      cur_lr: 0.0013067199615761638
      grad_gnorm: 40.0
      policy_entropy: 27.29544448852539
      policy_loss: 22.99709701538086
      var_gnorm: 33.12308120727539
      vf_explained_var: 0.01769334077835083
      vf_loss: 150.54708862304688
    num_steps_sampled: 805000
    num_steps_trained: 805000
    wait_time_ms: 91.415
  iterations_since_restore: 161
  node_ip: 172.17.8.52
  num_metric_batches_dropped: 0
  pid: 12141
  policy_reward_mean: {}
  time_since_restore: 2260.286941051483
  time_this_iter_s: 11.788609504699707
  time_total_s: 2260.286941051483
  timestamp: 1594139882
  timesteps_since_restore: 805000
  timesteps_this_iter: 5000
  timesteps_total: 805000
  training_iteration: 161
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 33.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=12141], 2260 s, 161 iter, 805000 ts, 1.5e+03 rew

agent-1: -428.0
agent-2: -420.0
agent-3: -91.0
agent-4: 9.0
agent-5: -447.0
Sum Reward: -1377.0
Avg Reward: -275.4
Min Reward: -447.0
Max Reward: 9.0
Gini Coefficient: -0.3628177196804648
20:20 Ratio: -0.020134228187919462
Max-min Ratio: -0.020134228187919462
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_12-38-15
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1992.0
  episode_reward_mean: 1471.35
  episode_reward_min: -17557.0
  episodes_this_iter: 1
  episodes_total: 161
  experiment_id: ebedc1946062457bb682d57fae83bd74
  hostname: gpu052
  info:
    apply_time_ms: 2.808
    dispatch_time_ms: 20.866
    learner:
      cur_lr: 0.0013063870137557387
      grad_gnorm: 40.0
      policy_entropy: 28.911718368530273
      policy_loss: 46.63617706298828
      var_gnorm: 33.10842514038086
      vf_explained_var: -0.7864968776702881
      vf_loss: 179.53016662597656
    num_steps_sampled: 810000
    num_steps_trained: 810000
    wait_time_ms: 97.492
  iterations_since_restore: 162
  node_ip: 172.17.8.52
  num_metric_batches_dropped: 0
  pid: 12141
  policy_reward_mean: {}
  time_since_restore: 2272.8183274269104
  time_this_iter_s: 12.531386375427246
  time_total_s: 2272.8183274269104
  timestamp: 1594139895
  timesteps_since_restore: 810000
  timesteps_this_iter: 5000
  timesteps_total: 810000
  training_iteration: 162
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 34.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=12141], 2272 s, 162 iter, 810000 ts, 1.47e+03 rew

agent-1: 208.0
agent-2: 320.0
agent-3: 198.0
agent-4: -13.0
agent-5: 283.0
Sum Reward: 996.0
Avg Reward: 199.2
Min Reward: -13.0
Max Reward: 320.0
Gini Coefficient: 0.30160642570281126
20:20 Ratio: -24.615384615384617
Max-min Ratio: -24.615384615384617
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_12-38-27
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1992.0
  episode_reward_mean: 1463.8
  episode_reward_min: -17557.0
  episodes_this_iter: 1
  episodes_total: 162
  experiment_id: ebedc1946062457bb682d57fae83bd74
  hostname: gpu052
  info:
    apply_time_ms: 3.605
    dispatch_time_ms: 22.855
    learner:
      cur_lr: 0.0013060539495199919
      grad_gnorm: 40.0
      policy_entropy: 29.150232315063477
      policy_loss: 21.054811477661133
      var_gnorm: 33.16908264160156
      vf_explained_var: 0.49870067834854126
      vf_loss: 51.88557434082031
    num_steps_sampled: 815000
    num_steps_trained: 815000
    wait_time_ms: 113.693
  iterations_since_restore: 163
  node_ip: 172.17.8.52
  num_metric_batches_dropped: 0
  pid: 12141
  policy_reward_mean: {}
  time_since_restore: 2285.696813106537
  time_this_iter_s: 12.878485679626465
  time_total_s: 2285.696813106537
  timestamp: 1594139907
  timesteps_since_restore: 815000
  timesteps_this_iter: 5000
  timesteps_total: 815000
  training_iteration: 163
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 34.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=12141], 2285 s, 163 iter, 815000 ts, 1.46e+03 rew

agent-1: 329.0
agent-2: 410.0
agent-3: 217.0
agent-4: 304.0
agent-5: 346.0
Sum Reward: 1606.0
Avg Reward: 321.2
Min Reward: 217.0
Max Reward: 410.0
Gini Coefficient: 0.10660024906600249
20:20 Ratio: 1.8894009216589862
Max-min Ratio: 1.8894009216589862
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_12-38-42
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1992.0
  episode_reward_mean: 1461.04
  episode_reward_min: -17557.0
  episodes_this_iter: 1
  episodes_total: 163
  experiment_id: ebedc1946062457bb682d57fae83bd74
  hostname: gpu052
  info:
    apply_time_ms: 2.996
    dispatch_time_ms: 27.581
    learner:
      cur_lr: 0.0013057210016995668
      grad_gnorm: 40.000003814697266
      policy_entropy: 27.82862663269043
      policy_loss: -6.425199508666992
      var_gnorm: 33.24549102783203
      vf_explained_var: 0.25874972343444824
      vf_loss: 41.572723388671875
    num_steps_sampled: 820000
    num_steps_trained: 820000
    wait_time_ms: 113.84
  iterations_since_restore: 164
  node_ip: 172.17.8.52
  num_metric_batches_dropped: 0
  pid: 12141
  policy_reward_mean: {}
  time_since_restore: 2299.9058544635773
  time_this_iter_s: 14.209041357040405
  time_total_s: 2299.9058544635773
  timestamp: 1594139922
  timesteps_since_restore: 820000
  timesteps_this_iter: 5000
  timesteps_total: 820000
  training_iteration: 164
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 34.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=12141], 2299 s, 164 iter, 820000 ts, 1.46e+03 rew

agent-1: 261.0
agent-2: 357.0
agent-3: 344.0
agent-4: 290.0
agent-5: 303.0
Sum Reward: 1555.0
Avg Reward: 311.0
Min Reward: 261.0
Max Reward: 357.0
Gini Coefficient: 0.06327974276527332
20:20 Ratio: 1.367816091954023
Max-min Ratio: 1.367816091954023
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_12-38-55
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1992.0
  episode_reward_mean: 1457.95
  episode_reward_min: -17557.0
  episodes_this_iter: 1
  episodes_total: 164
  experiment_id: ebedc1946062457bb682d57fae83bd74
  hostname: gpu052
  info:
    apply_time_ms: 2.798
    dispatch_time_ms: 43.111
    learner:
      cur_lr: 0.0013053880538791418
      grad_gnorm: 39.999996185302734
      policy_entropy: 21.875106811523438
      policy_loss: -2.3803658485412598
      var_gnorm: 33.27909851074219
      vf_explained_var: -0.015581250190734863
      vf_loss: 61.822540283203125
    num_steps_sampled: 825000
    num_steps_trained: 825000
    wait_time_ms: 93.16
  iterations_since_restore: 165
  node_ip: 172.17.8.52
  num_metric_batches_dropped: 0
  pid: 12141
  policy_reward_mean: {}
  time_since_restore: 2313.52703332901
  time_this_iter_s: 13.62117886543274
  time_total_s: 2313.52703332901
  timestamp: 1594139935
  timesteps_since_restore: 825000
  timesteps_this_iter: 5000
  timesteps_total: 825000
  training_iteration: 165
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 34.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=12141], 2313 s, 165 iter, 825000 ts, 1.46e+03 rew

agent-1: 342.0
agent-2: 390.0
agent-3: 338.0
agent-4: 368.0
agent-5: 326.0
Sum Reward: 1764.0
Avg Reward: 352.8
Min Reward: 326.0
Max Reward: 390.0
Gini Coefficient: 0.03582766439909297
20:20 Ratio: 1.196319018404908
Max-min Ratio: 1.196319018404908
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_12-39-09
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1992.0
  episode_reward_mean: 1462.57
  episode_reward_min: -17557.0
  episodes_this_iter: 1
  episodes_total: 165
  experiment_id: ebedc1946062457bb682d57fae83bd74
  hostname: gpu052
  info:
    apply_time_ms: 3.902
    dispatch_time_ms: 36.419
    learner:
      cur_lr: 0.001305054989643395
      grad_gnorm: 39.999996185302734
      policy_entropy: 28.78399085998535
      policy_loss: 13.60147762298584
      var_gnorm: 33.35031509399414
      vf_explained_var: 0.19934380054473877
      vf_loss: 48.21031188964844
    num_steps_sampled: 830000
    num_steps_trained: 830000
    wait_time_ms: 85.58
  iterations_since_restore: 166
  node_ip: 172.17.8.52
  num_metric_batches_dropped: 0
  pid: 12141
  policy_reward_mean: {}
  time_since_restore: 2327.247416496277
  time_this_iter_s: 13.720383167266846
  time_total_s: 2327.247416496277
  timestamp: 1594139949
  timesteps_since_restore: 830000
  timesteps_this_iter: 5000
  timesteps_total: 830000
  training_iteration: 166
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 34.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=12141], 2327 s, 166 iter, 830000 ts, 1.46e+03 rew

agent-1: 336.0
agent-2: 369.0
agent-3: 324.0
agent-4: 344.0
agent-5: 360.0
Sum Reward: 1733.0
Avg Reward: 346.6
Min Reward: 324.0
Max Reward: 369.0
Gini Coefficient: 0.026312752452394693
20:20 Ratio: 1.1388888888888888
Max-min Ratio: 1.1388888888888888
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_12-39-23
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1992.0
  episode_reward_mean: 1464.56
  episode_reward_min: -17557.0
  episodes_this_iter: 1
  episodes_total: 166
  experiment_id: ebedc1946062457bb682d57fae83bd74
  hostname: gpu052
  info:
    apply_time_ms: 2.826
    dispatch_time_ms: 25.71
    learner:
      cur_lr: 0.00130472204182297
      grad_gnorm: 39.999996185302734
      policy_entropy: 17.74503517150879
      policy_loss: 1.3745025396347046
      var_gnorm: 33.36840057373047
      vf_explained_var: 0.02952629327774048
      vf_loss: 44.031044006347656
    num_steps_sampled: 835000
    num_steps_trained: 835000
    wait_time_ms: 118.35
  iterations_since_restore: 167
  node_ip: 172.17.8.52
  num_metric_batches_dropped: 0
  pid: 12141
  policy_reward_mean: {}
  time_since_restore: 2340.8653795719147
  time_this_iter_s: 13.617963075637817
  time_total_s: 2340.8653795719147
  timestamp: 1594139963
  timesteps_since_restore: 835000
  timesteps_this_iter: 5000
  timesteps_total: 835000
  training_iteration: 167
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 34.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=12141], 2340 s, 167 iter, 835000 ts, 1.46e+03 rew

agent-1: 358.0
agent-2: 315.0
agent-3: 340.0
agent-4: 340.0
agent-5: 358.0
Sum Reward: 1711.0
Avg Reward: 342.2
Min Reward: 315.0
Max Reward: 358.0
Gini Coefficient: 0.024313267095265927
20:20 Ratio: 1.1365079365079365
Max-min Ratio: 1.1365079365079365
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_12-39-37
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1992.0
  episode_reward_mean: 1465.35
  episode_reward_min: -17557.0
  episodes_this_iter: 1
  episodes_total: 167
  experiment_id: ebedc1946062457bb682d57fae83bd74
  hostname: gpu052
  info:
    apply_time_ms: 2.987
    dispatch_time_ms: 34.036
    learner:
      cur_lr: 0.001304388977587223
      grad_gnorm: 40.0
      policy_entropy: 7.707746505737305
      policy_loss: 7.493528366088867
      var_gnorm: 33.39461898803711
      vf_explained_var: 0.054975271224975586
      vf_loss: 58.946834564208984
    num_steps_sampled: 840000
    num_steps_trained: 840000
    wait_time_ms: 102.384
  iterations_since_restore: 168
  node_ip: 172.17.8.52
  num_metric_batches_dropped: 0
  pid: 12141
  policy_reward_mean: {}
  time_since_restore: 2355.0978784561157
  time_this_iter_s: 14.23249888420105
  time_total_s: 2355.0978784561157
  timestamp: 1594139977
  timesteps_since_restore: 840000
  timesteps_this_iter: 5000
  timesteps_total: 840000
  training_iteration: 168
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 34.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=12141], 2355 s, 168 iter, 840000 ts, 1.47e+03 rew

agent-1: 350.0
agent-2: 374.0
agent-3: 342.0
agent-4: 339.0
agent-5: 344.0
Sum Reward: 1749.0
Avg Reward: 349.8
Min Reward: 339.0
Max Reward: 374.0
Gini Coefficient: 0.01783876500857633
20:20 Ratio: 1.103244837758112
Max-min Ratio: 1.103244837758112
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_12-39-50
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1992.0
  episode_reward_mean: 1468.03
  episode_reward_min: -17557.0
  episodes_this_iter: 1
  episodes_total: 168
  experiment_id: ebedc1946062457bb682d57fae83bd74
  hostname: gpu052
  info:
    apply_time_ms: 2.957
    dispatch_time_ms: 18.298
    learner:
      cur_lr: 0.001304056029766798
      grad_gnorm: 40.000003814697266
      policy_entropy: 9.996233940124512
      policy_loss: 8.830270767211914
      var_gnorm: 33.40742111206055
      vf_explained_var: 0.12213289737701416
      vf_loss: 28.984460830688477
    num_steps_sampled: 845000
    num_steps_trained: 845000
    wait_time_ms: 119.142
  iterations_since_restore: 169
  node_ip: 172.17.8.52
  num_metric_batches_dropped: 0
  pid: 12141
  policy_reward_mean: {}
  time_since_restore: 2368.2771894931793
  time_this_iter_s: 13.179311037063599
  time_total_s: 2368.2771894931793
  timestamp: 1594139990
  timesteps_since_restore: 845000
  timesteps_this_iter: 5000
  timesteps_total: 845000
  training_iteration: 169
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 34.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=12141], 2368 s, 169 iter, 845000 ts, 1.47e+03 rew

agent-1: 358.0
agent-2: 363.0
agent-3: 363.0
agent-4: 396.0
agent-5: 398.0
Sum Reward: 1878.0
Avg Reward: 375.6
Min Reward: 358.0
Max Reward: 398.0
Gini Coefficient: 0.02406815761448349
20:20 Ratio: 1.111731843575419
Max-min Ratio: 1.111731843575419
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_12-40-04
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1992.0
  episode_reward_mean: 1468.68
  episode_reward_min: -17557.0
  episodes_this_iter: 1
  episodes_total: 169
  experiment_id: ebedc1946062457bb682d57fae83bd74
  hostname: gpu052
  info:
    apply_time_ms: 3.074
    dispatch_time_ms: 31.047
    learner:
      cur_lr: 0.0013037229655310512
      grad_gnorm: 39.999996185302734
      policy_entropy: 11.404033660888672
      policy_loss: -4.715218544006348
      var_gnorm: 33.413307189941406
      vf_explained_var: -0.1301959753036499
      vf_loss: 21.330900192260742
    num_steps_sampled: 850000
    num_steps_trained: 850000
    wait_time_ms: 107.205
  iterations_since_restore: 170
  node_ip: 172.17.8.52
  num_metric_batches_dropped: 0
  pid: 12141
  policy_reward_mean: {}
  time_since_restore: 2381.817057132721
  time_this_iter_s: 13.539867639541626
  time_total_s: 2381.817057132721
  timestamp: 1594140004
  timesteps_since_restore: 850000
  timesteps_this_iter: 5000
  timesteps_total: 850000
  training_iteration: 170
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 34.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=12141], 2381 s, 170 iter, 850000 ts, 1.47e+03 rew

agent-1: 353.0
agent-2: 324.0
agent-3: 356.0
agent-4: 376.0
agent-5: 362.0
Sum Reward: 1771.0
Avg Reward: 354.2
Min Reward: 324.0
Max Reward: 376.0
Gini Coefficient: 0.02552230378317335
20:20 Ratio: 1.1604938271604939
Max-min Ratio: 1.1604938271604939
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_12-40-18
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1992.0
  episode_reward_mean: 1469.02
  episode_reward_min: -17557.0
  episodes_this_iter: 1
  episodes_total: 170
  experiment_id: ebedc1946062457bb682d57fae83bd74
  hostname: gpu052
  info:
    apply_time_ms: 3.699
    dispatch_time_ms: 35.891
    learner:
      cur_lr: 0.0013033900177106261
      grad_gnorm: 40.0
      policy_entropy: 18.707754135131836
      policy_loss: 15.480438232421875
      var_gnorm: 33.457847595214844
      vf_explained_var: -0.3540818691253662
      vf_loss: 40.70749282836914
    num_steps_sampled: 855000
    num_steps_trained: 855000
    wait_time_ms: 98.771
  iterations_since_restore: 171
  node_ip: 172.17.8.52
  num_metric_batches_dropped: 0
  pid: 12141
  policy_reward_mean: {}
  time_since_restore: 2395.515676021576
  time_this_iter_s: 13.69861888885498
  time_total_s: 2395.515676021576
  timestamp: 1594140018
  timesteps_since_restore: 855000
  timesteps_this_iter: 5000
  timesteps_total: 855000
  training_iteration: 171
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 34.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=12141], 2395 s, 171 iter, 855000 ts, 1.47e+03 rew

agent-1: 374.0
agent-2: 373.0
agent-3: 399.0
agent-4: 378.0
agent-5: 340.0
Sum Reward: 1864.0
Avg Reward: 372.8
Min Reward: 340.0
Max Reward: 399.0
Gini Coefficient: 0.026394849785407726
20:20 Ratio: 1.173529411764706
Max-min Ratio: 1.173529411764706
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_12-40-31
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1992.0
  episode_reward_mean: 1471.21
  episode_reward_min: -17557.0
  episodes_this_iter: 1
  episodes_total: 171
  experiment_id: ebedc1946062457bb682d57fae83bd74
  hostname: gpu052
  info:
    apply_time_ms: 2.889
    dispatch_time_ms: 25.148
    learner:
      cur_lr: 0.0013030569534748793
      grad_gnorm: 40.0
      policy_entropy: 27.067659378051758
      policy_loss: -23.297449111938477
      var_gnorm: 33.52128982543945
      vf_explained_var: 0.24250423908233643
      vf_loss: 57.92529296875
    num_steps_sampled: 860000
    num_steps_trained: 860000
    wait_time_ms: 107.966
  iterations_since_restore: 172
  node_ip: 172.17.8.52
  num_metric_batches_dropped: 0
  pid: 12141
  policy_reward_mean: {}
  time_since_restore: 2408.9968523979187
  time_this_iter_s: 13.481176376342773
  time_total_s: 2408.9968523979187
  timestamp: 1594140031
  timesteps_since_restore: 860000
  timesteps_this_iter: 5000
  timesteps_total: 860000
  training_iteration: 172
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 34.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=12141], 2408 s, 172 iter, 860000 ts, 1.47e+03 rew

agent-1: 317.0
agent-2: 346.0
agent-3: 294.0
agent-4: 304.0
agent-5: 315.0
Sum Reward: 1576.0
Avg Reward: 315.2
Min Reward: 294.0
Max Reward: 346.0
Gini Coefficient: 0.02969543147208122
20:20 Ratio: 1.1768707482993197
Max-min Ratio: 1.1768707482993197
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_12-40-45
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1992.0
  episode_reward_mean: 1472.34
  episode_reward_min: -17557.0
  episodes_this_iter: 1
  episodes_total: 172
  experiment_id: ebedc1946062457bb682d57fae83bd74
  hostname: gpu052
  info:
    apply_time_ms: 3.044
    dispatch_time_ms: 30.49
    learner:
      cur_lr: 0.0013027240056544542
      grad_gnorm: 40.0
      policy_entropy: 31.414216995239258
      policy_loss: -42.9332160949707
      var_gnorm: 33.59547424316406
      vf_explained_var: 0.24348562955856323
      vf_loss: 71.1659164428711
    num_steps_sampled: 865000
    num_steps_trained: 865000
    wait_time_ms: 107.224
  iterations_since_restore: 173
  node_ip: 172.17.8.52
  num_metric_batches_dropped: 0
  pid: 12141
  policy_reward_mean: {}
  time_since_restore: 2422.5397601127625
  time_this_iter_s: 13.54290771484375
  time_total_s: 2422.5397601127625
  timestamp: 1594140045
  timesteps_since_restore: 865000
  timesteps_this_iter: 5000
  timesteps_total: 865000
  training_iteration: 173
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 34.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=12141], 2422 s, 173 iter, 865000 ts, 1.47e+03 rew

agent-1: 314.0
agent-2: 361.0
agent-3: 301.0
agent-4: 291.0
agent-5: 296.0
Sum Reward: 1563.0
Avg Reward: 312.6
Min Reward: 291.0
Max Reward: 361.0
Gini Coefficient: 0.040435060780550224
20:20 Ratio: 1.2405498281786942
Max-min Ratio: 1.2405498281786942
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_12-41-02
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1992.0
  episode_reward_mean: 1469.83
  episode_reward_min: -17557.0
  episodes_this_iter: 1
  episodes_total: 173
  experiment_id: ebedc1946062457bb682d57fae83bd74
  hostname: gpu052
  info:
    apply_time_ms: 2.906
    dispatch_time_ms: 25.48
    learner:
      cur_lr: 0.0013023910578340292
      grad_gnorm: 40.0
      policy_entropy: 26.15862274169922
      policy_loss: 13.757692337036133
      var_gnorm: 33.65377426147461
      vf_explained_var: 0.6142928600311279
      vf_loss: 37.76114273071289
    num_steps_sampled: 870000
    num_steps_trained: 870000
    wait_time_ms: 113.198
  iterations_since_restore: 174
  node_ip: 172.17.8.52
  num_metric_batches_dropped: 0
  pid: 12141
  policy_reward_mean: {}
  time_since_restore: 2439.9922392368317
  time_this_iter_s: 17.452479124069214
  time_total_s: 2439.9922392368317
  timestamp: 1594140062
  timesteps_since_restore: 870000
  timesteps_this_iter: 5000
  timesteps_total: 870000
  training_iteration: 174
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 34.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=12141], 2439 s, 174 iter, 870000 ts, 1.47e+03 rew

agent-1: 344.0
agent-2: 391.0
agent-3: 291.0
agent-4: 339.0
agent-5: 357.0
Sum Reward: 1722.0
Avg Reward: 344.4
Min Reward: 291.0
Max Reward: 391.0
Gini Coefficient: 0.05063879210220674
20:20 Ratio: 1.3436426116838487
Max-min Ratio: 1.3436426116838487
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_12-41-16
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1992.0
  episode_reward_mean: 1471.53
  episode_reward_min: -17557.0
  episodes_this_iter: 1
  episodes_total: 174
  experiment_id: ebedc1946062457bb682d57fae83bd74
  hostname: gpu052
  info:
    apply_time_ms: 2.577
    dispatch_time_ms: 22.802
    learner:
      cur_lr: 0.0013020579935982823
      grad_gnorm: 39.999969482421875
      policy_entropy: 29.346799850463867
      policy_loss: -2.8260154724121094
      var_gnorm: 33.667930603027344
      vf_explained_var: 0.6772418022155762
      vf_loss: 23.59644317626953
    num_steps_sampled: 875000
    num_steps_trained: 875000
    wait_time_ms: 116.614
  iterations_since_restore: 175
  node_ip: 172.17.8.52
  num_metric_batches_dropped: 0
  pid: 12141
  policy_reward_mean: {}
  time_since_restore: 2453.4264278411865
  time_this_iter_s: 13.434188604354858
  time_total_s: 2453.4264278411865
  timestamp: 1594140076
  timesteps_since_restore: 875000
  timesteps_this_iter: 5000
  timesteps_total: 875000
  training_iteration: 175
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 34.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=12141], 2453 s, 175 iter, 875000 ts, 1.47e+03 rew

agent-1: 324.0
agent-2: 335.0
agent-3: 297.0
agent-4: 307.0
agent-5: 294.0
Sum Reward: 1557.0
Avg Reward: 311.4
Min Reward: 294.0
Max Reward: 335.0
Gini Coefficient: 0.028002569043031472
20:20 Ratio: 1.1394557823129252
Max-min Ratio: 1.1394557823129252
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_12-41-29
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1992.0
  episode_reward_mean: 1470.87
  episode_reward_min: -17557.0
  episodes_this_iter: 1
  episodes_total: 175
  experiment_id: ebedc1946062457bb682d57fae83bd74
  hostname: gpu052
  info:
    apply_time_ms: 2.867
    dispatch_time_ms: 27.281
    learner:
      cur_lr: 0.0013017250457778573
      grad_gnorm: 40.0000114440918
      policy_entropy: 24.06363868713379
      policy_loss: 15.409475326538086
      var_gnorm: 33.741031646728516
      vf_explained_var: 0.6752625703811646
      vf_loss: 25.545928955078125
    num_steps_sampled: 880000
    num_steps_trained: 880000
    wait_time_ms: 101.82
  iterations_since_restore: 176
  node_ip: 172.17.8.52
  num_metric_batches_dropped: 0
  pid: 12141
  policy_reward_mean: {}
  time_since_restore: 2466.6651685237885
  time_this_iter_s: 13.238740682601929
  time_total_s: 2466.6651685237885
  timestamp: 1594140089
  timesteps_since_restore: 880000
  timesteps_this_iter: 5000
  timesteps_total: 880000
  training_iteration: 176
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 34.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=12141], 2466 s, 176 iter, 880000 ts, 1.47e+03 rew

agent-1: 355.0
agent-2: 393.0
agent-3: 331.0
agent-4: 386.0
agent-5: 360.0
Sum Reward: 1825.0
Avg Reward: 365.0
Min Reward: 331.0
Max Reward: 393.0
Gini Coefficient: 0.03397260273972603
20:20 Ratio: 1.1873111782477341
Max-min Ratio: 1.1873111782477341
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_12-41-42
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1992.0
  episode_reward_mean: 1471.78
  episode_reward_min: -17557.0
  episodes_this_iter: 1
  episodes_total: 176
  experiment_id: ebedc1946062457bb682d57fae83bd74
  hostname: gpu052
  info:
    apply_time_ms: 2.715
    dispatch_time_ms: 22.27
    learner:
      cur_lr: 0.0013013919815421104
      grad_gnorm: 39.3375244140625
      policy_entropy: 15.941926956176758
      policy_loss: 6.121702194213867
      var_gnorm: 33.747894287109375
      vf_explained_var: 0.17281806468963623
      vf_loss: 22.287574768066406
    num_steps_sampled: 885000
    num_steps_trained: 885000
    wait_time_ms: 115.411
  iterations_since_restore: 177
  node_ip: 172.17.8.52
  num_metric_batches_dropped: 0
  pid: 12141
  policy_reward_mean: {}
  time_since_restore: 2480.0063803195953
  time_this_iter_s: 13.341211795806885
  time_total_s: 2480.0063803195953
  timestamp: 1594140102
  timesteps_since_restore: 885000
  timesteps_this_iter: 5000
  timesteps_total: 885000
  training_iteration: 177
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 34.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=12141], 2480 s, 177 iter, 885000 ts, 1.47e+03 rew

agent-1: 350.0
agent-2: 407.0
agent-3: 374.0
agent-4: 397.0
agent-5: 376.0
Sum Reward: 1904.0
Avg Reward: 380.8
Min Reward: 350.0
Max Reward: 407.0
Gini Coefficient: 0.028781512605042015
20:20 Ratio: 1.1628571428571428
Max-min Ratio: 1.1628571428571428
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_12-41-56
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1975.0
  episode_reward_mean: 1470.9
  episode_reward_min: -17557.0
  episodes_this_iter: 1
  episodes_total: 177
  experiment_id: ebedc1946062457bb682d57fae83bd74
  hostname: gpu052
  info:
    apply_time_ms: 2.442
    dispatch_time_ms: 22.687
    learner:
      cur_lr: 0.0013010590337216854
      grad_gnorm: 40.0000114440918
      policy_entropy: 17.50385284423828
      policy_loss: -5.920588970184326
      var_gnorm: 33.806427001953125
      vf_explained_var: -0.14372503757476807
      vf_loss: 64.118896484375
    num_steps_sampled: 890000
    num_steps_trained: 890000
    wait_time_ms: 122.931
  iterations_since_restore: 178
  node_ip: 172.17.8.52
  num_metric_batches_dropped: 0
  pid: 12141
  policy_reward_mean: {}
  time_since_restore: 2493.610870361328
  time_this_iter_s: 13.604490041732788
  time_total_s: 2493.610870361328
  timestamp: 1594140116
  timesteps_since_restore: 890000
  timesteps_this_iter: 5000
  timesteps_total: 890000
  training_iteration: 178
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 34.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=12141], 2493 s, 178 iter, 890000 ts, 1.47e+03 rew

agent-1: 326.0
agent-2: 398.0
agent-3: 359.0
agent-4: 343.0
agent-5: 365.0
Sum Reward: 1791.0
Avg Reward: 358.2
Min Reward: 326.0
Max Reward: 398.0
Gini Coefficient: 0.03707426018983808
20:20 Ratio: 1.2208588957055215
Max-min Ratio: 1.2208588957055215
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_12-42-10
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1975.0
  episode_reward_mean: 1471.44
  episode_reward_min: -17557.0
  episodes_this_iter: 1
  episodes_total: 178
  experiment_id: ebedc1946062457bb682d57fae83bd74
  hostname: gpu052
  info:
    apply_time_ms: 3.232
    dispatch_time_ms: 24.86
    learner:
      cur_lr: 0.0013007259694859385
      grad_gnorm: 40.00000762939453
      policy_entropy: 15.674315452575684
      policy_loss: -7.663512229919434
      var_gnorm: 33.87772750854492
      vf_explained_var: -0.4212496280670166
      vf_loss: 22.497940063476562
    num_steps_sampled: 895000
    num_steps_trained: 895000
    wait_time_ms: 99.12
  iterations_since_restore: 179
  node_ip: 172.17.8.52
  num_metric_batches_dropped: 0
  pid: 12141
  policy_reward_mean: {}
  time_since_restore: 2507.217431306839
  time_this_iter_s: 13.606560945510864
  time_total_s: 2507.217431306839
  timestamp: 1594140130
  timesteps_since_restore: 895000
  timesteps_this_iter: 5000
  timesteps_total: 895000
  training_iteration: 179
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 34.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=12141], 2507 s, 179 iter, 895000 ts, 1.47e+03 rew

agent-1: 377.0
agent-2: 368.0
agent-3: 366.0
agent-4: 302.0
agent-5: 356.0
Sum Reward: 1769.0
Avg Reward: 353.8
Min Reward: 302.0
Max Reward: 377.0
Gini Coefficient: 0.03663086489542114
20:20 Ratio: 1.2483443708609272
Max-min Ratio: 1.2483443708609272
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_12-42-23
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1975.0
  episode_reward_mean: 1471.56
  episode_reward_min: -17557.0
  episodes_this_iter: 1
  episodes_total: 179
  experiment_id: ebedc1946062457bb682d57fae83bd74
  hostname: gpu052
  info:
    apply_time_ms: 2.713
    dispatch_time_ms: 26.131
    learner:
      cur_lr: 0.0013003930216655135
      grad_gnorm: 39.999996185302734
      policy_entropy: 13.568509101867676
      policy_loss: 5.600966930389404
      var_gnorm: 33.944515228271484
      vf_explained_var: 0.3366684317588806
      vf_loss: 76.6363525390625
    num_steps_sampled: 900000
    num_steps_trained: 900000
    wait_time_ms: 92.268
  iterations_since_restore: 180
  node_ip: 172.17.8.52
  num_metric_batches_dropped: 0
  pid: 12141
  policy_reward_mean: {}
  time_since_restore: 2520.294612646103
  time_this_iter_s: 13.077181339263916
  time_total_s: 2520.294612646103
  timestamp: 1594140143
  timesteps_since_restore: 900000
  timesteps_this_iter: 5000
  timesteps_total: 900000
  training_iteration: 180
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 34.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=12141], 2520 s, 180 iter, 900000 ts, 1.47e+03 rew

agent-1: 329.0
agent-2: 409.0
agent-3: 343.0
agent-4: 359.0
agent-5: 338.0
Sum Reward: 1778.0
Avg Reward: 355.6
Min Reward: 329.0
Max Reward: 409.0
Gini Coefficient: 0.0407199100112486
20:20 Ratio: 1.243161094224924
Max-min Ratio: 1.243161094224924
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_12-42-36
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1975.0
  episode_reward_mean: 1472.34
  episode_reward_min: -17557.0
  episodes_this_iter: 1
  episodes_total: 180
  experiment_id: ebedc1946062457bb682d57fae83bd74
  hostname: gpu052
  info:
    apply_time_ms: 2.988
    dispatch_time_ms: 28.796
    learner:
      cur_lr: 0.0013000599574297667
      grad_gnorm: 39.99999237060547
      policy_entropy: 18.0479793548584
      policy_loss: -19.19121551513672
      var_gnorm: 34.01138687133789
      vf_explained_var: -0.010926365852355957
      vf_loss: 91.58946228027344
    num_steps_sampled: 905000
    num_steps_trained: 905000
    wait_time_ms: 107.352
  iterations_since_restore: 181
  node_ip: 172.17.8.52
  num_metric_batches_dropped: 0
  pid: 12141
  policy_reward_mean: {}
  time_since_restore: 2533.607108592987
  time_this_iter_s: 13.312495946884155
  time_total_s: 2533.607108592987
  timestamp: 1594140156
  timesteps_since_restore: 905000
  timesteps_this_iter: 5000
  timesteps_total: 905000
  training_iteration: 181
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 34.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=12141], 2533 s, 181 iter, 905000 ts, 1.47e+03 rew

agent-1: 358.0
agent-2: 349.0
agent-3: 350.0
agent-4: 342.0
agent-5: 353.0
Sum Reward: 1752.0
Avg Reward: 350.4
Min Reward: 342.0
Max Reward: 358.0
Gini Coefficient: 0.00821917808219178
20:20 Ratio: 1.0467836257309941
Max-min Ratio: 1.0467836257309941
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_12-43-12
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1975.0
  episode_reward_mean: 1473.13
  episode_reward_min: -17557.0
  episodes_this_iter: 1
  episodes_total: 181
  experiment_id: ebedc1946062457bb682d57fae83bd74
  hostname: gpu052
  info:
    apply_time_ms: 2.75
    dispatch_time_ms: 22.897
    learner:
      cur_lr: 0.0012997270096093416
      grad_gnorm: 40.000003814697266
      policy_entropy: 10.98928451538086
      policy_loss: -7.0162248611450195
      var_gnorm: 34.071231842041016
      vf_explained_var: -0.6466795206069946
      vf_loss: 75.15338134765625
    num_steps_sampled: 910000
    num_steps_trained: 910000
    wait_time_ms: 98.181
  iterations_since_restore: 182
  node_ip: 172.17.8.52
  num_metric_batches_dropped: 0
  pid: 12141
  policy_reward_mean: {}
  time_since_restore: 2569.8250863552094
  time_this_iter_s: 36.21797776222229
  time_total_s: 2569.8250863552094
  timestamp: 1594140192
  timesteps_since_restore: 910000
  timesteps_this_iter: 5000
  timesteps_total: 910000
  training_iteration: 182
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 34.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=12141], 2569 s, 182 iter, 910000 ts, 1.47e+03 rew

agent-1: 374.0
agent-2: 374.0
agent-3: 372.0
agent-4: 353.0
agent-5: 374.0
Sum Reward: 1847.0
Avg Reward: 369.4
Min Reward: 353.0
Max Reward: 374.0
Gini Coefficient: 0.00952896589063346
20:20 Ratio: 1.0594900849858357
Max-min Ratio: 1.0594900849858357
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_12-43-26
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1975.0
  episode_reward_mean: 1474.33
  episode_reward_min: -17557.0
  episodes_this_iter: 1
  episodes_total: 182
  experiment_id: ebedc1946062457bb682d57fae83bd74
  hostname: gpu052
  info:
    apply_time_ms: 2.569
    dispatch_time_ms: 18.816
    learner:
      cur_lr: 0.0012993939453735948
      grad_gnorm: 39.999996185302734
      policy_entropy: 14.211003303527832
      policy_loss: -4.318818092346191
      var_gnorm: 34.07776641845703
      vf_explained_var: 0.28791743516921997
      vf_loss: 33.7662353515625
    num_steps_sampled: 915000
    num_steps_trained: 915000
    wait_time_ms: 104.552
  iterations_since_restore: 183
  node_ip: 172.17.8.52
  num_metric_batches_dropped: 0
  pid: 12141
  policy_reward_mean: {}
  time_since_restore: 2583.0176260471344
  time_this_iter_s: 13.192539691925049
  time_total_s: 2583.0176260471344
  timestamp: 1594140206
  timesteps_since_restore: 915000
  timesteps_this_iter: 5000
  timesteps_total: 915000
  training_iteration: 183
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 34.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=12141], 2583 s, 183 iter, 915000 ts, 1.47e+03 rew

agent-1: 373.0
agent-2: 374.0
agent-3: 387.0
agent-4: 365.0
agent-5: 380.0
Sum Reward: 1879.0
Avg Reward: 375.8
Min Reward: 365.0
Max Reward: 387.0
Gini Coefficient: 0.010856838744012772
20:20 Ratio: 1.0602739726027397
Max-min Ratio: 1.0602739726027397
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_12-43-39
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1975.0
  episode_reward_mean: 1476.3
  episode_reward_min: -17557.0
  episodes_this_iter: 1
  episodes_total: 183
  experiment_id: ebedc1946062457bb682d57fae83bd74
  hostname: gpu052
  info:
    apply_time_ms: 3.132
    dispatch_time_ms: 15.087
    learner:
      cur_lr: 0.0012990609975531697
      grad_gnorm: 40.0
      policy_entropy: 15.854226112365723
      policy_loss: -13.734946250915527
      var_gnorm: 34.10736846923828
      vf_explained_var: 0.7413781881332397
      vf_loss: 36.92328643798828
    num_steps_sampled: 920000
    num_steps_trained: 920000
    wait_time_ms: 111.076
  iterations_since_restore: 184
  node_ip: 172.17.8.52
  num_metric_batches_dropped: 0
  pid: 12141
  policy_reward_mean: {}
  time_since_restore: 2596.2499284744263
  time_this_iter_s: 13.23230242729187
  time_total_s: 2596.2499284744263
  timestamp: 1594140219
  timesteps_since_restore: 920000
  timesteps_this_iter: 5000
  timesteps_total: 920000
  training_iteration: 184
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 34.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=12141], 2596 s, 184 iter, 920000 ts, 1.48e+03 rew

agent-1: 365.0
agent-2: 381.0
agent-3: 351.0
agent-4: 387.0
agent-5: 379.0
Sum Reward: 1863.0
Avg Reward: 372.6
Min Reward: 351.0
Max Reward: 387.0
Gini Coefficient: 0.018894256575415994
20:20 Ratio: 1.1025641025641026
Max-min Ratio: 1.1025641025641026
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_12-43-53
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1975.0
  episode_reward_mean: 1476.76
  episode_reward_min: -17557.0
  episodes_this_iter: 1
  episodes_total: 184
  experiment_id: ebedc1946062457bb682d57fae83bd74
  hostname: gpu052
  info:
    apply_time_ms: 2.985
    dispatch_time_ms: 17.866
    learner:
      cur_lr: 0.0012987280497327447
      grad_gnorm: 39.999996185302734
      policy_entropy: 25.357254028320312
      policy_loss: -14.9747314453125
      var_gnorm: 34.11561584472656
      vf_explained_var: 0.22308140993118286
      vf_loss: 38.60725402832031
    num_steps_sampled: 925000
    num_steps_trained: 925000
    wait_time_ms: 101.2
  iterations_since_restore: 185
  node_ip: 172.17.8.52
  num_metric_batches_dropped: 0
  pid: 12141
  policy_reward_mean: {}
  time_since_restore: 2609.9425060749054
  time_this_iter_s: 13.692577600479126
  time_total_s: 2609.9425060749054
  timestamp: 1594140233
  timesteps_since_restore: 925000
  timesteps_this_iter: 5000
  timesteps_total: 925000
  training_iteration: 185
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 34.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=12141], 2609 s, 185 iter, 925000 ts, 1.48e+03 rew

agent-1: 365.0
agent-2: 329.0
agent-3: 359.0
agent-4: 347.0
agent-5: 365.0
Sum Reward: 1765.0
Avg Reward: 353.0
Min Reward: 329.0
Max Reward: 365.0
Gini Coefficient: 0.020396600566572238
20:20 Ratio: 1.1094224924012157
Max-min Ratio: 1.1094224924012157
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_12-44-06
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1975.0
  episode_reward_mean: 1476.18
  episode_reward_min: -17557.0
  episodes_this_iter: 1
  episodes_total: 185
  experiment_id: ebedc1946062457bb682d57fae83bd74
  hostname: gpu052
  info:
    apply_time_ms: 2.637
    dispatch_time_ms: 22.751
    learner:
      cur_lr: 0.0012983949854969978
      grad_gnorm: 40.0
      policy_entropy: 18.472183227539062
      policy_loss: 4.6245856285095215
      var_gnorm: 34.12850570678711
      vf_explained_var: 0.3527640700340271
      vf_loss: 47.212364196777344
    num_steps_sampled: 930000
    num_steps_trained: 930000
    wait_time_ms: 113.335
  iterations_since_restore: 186
  node_ip: 172.17.8.52
  num_metric_batches_dropped: 0
  pid: 12141
  policy_reward_mean: {}
  time_since_restore: 2623.492517709732
  time_this_iter_s: 13.55001163482666
  time_total_s: 2623.492517709732
  timestamp: 1594140246
  timesteps_since_restore: 930000
  timesteps_this_iter: 5000
  timesteps_total: 930000
  training_iteration: 186
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 34.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=12141], 2623 s, 186 iter, 930000 ts, 1.48e+03 rew

agent-1: 365.0
agent-2: 394.0
agent-3: 361.0
agent-4: 371.0
agent-5: 389.0
Sum Reward: 1880.0
Avg Reward: 376.0
Min Reward: 361.0
Max Reward: 394.0
Gini Coefficient: 0.019148936170212766
20:20 Ratio: 1.0914127423822715
Max-min Ratio: 1.0914127423822715
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_12-44-20
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1975.0
  episode_reward_mean: 1477.59
  episode_reward_min: -17557.0
  episodes_this_iter: 1
  episodes_total: 186
  experiment_id: ebedc1946062457bb682d57fae83bd74
  hostname: gpu052
  info:
    apply_time_ms: 3.091
    dispatch_time_ms: 19.168
    learner:
      cur_lr: 0.0012980620376765728
      grad_gnorm: 40.00000762939453
      policy_entropy: 15.721104621887207
      policy_loss: -12.965250015258789
      var_gnorm: 34.12216567993164
      vf_explained_var: 0.4274482727050781
      vf_loss: 43.174072265625
    num_steps_sampled: 935000
    num_steps_trained: 935000
    wait_time_ms: 121.729
  iterations_since_restore: 187
  node_ip: 172.17.8.52
  num_metric_batches_dropped: 0
  pid: 12141
  policy_reward_mean: {}
  time_since_restore: 2637.3663992881775
  time_this_iter_s: 13.873881578445435
  time_total_s: 2637.3663992881775
  timestamp: 1594140260
  timesteps_since_restore: 935000
  timesteps_this_iter: 5000
  timesteps_total: 935000
  training_iteration: 187
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 34.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=12141], 2637 s, 187 iter, 935000 ts, 1.48e+03 rew

agent-1: 380.0
agent-2: 358.0
agent-3: 371.0
agent-4: 393.0
agent-5: 369.0
Sum Reward: 1871.0
Avg Reward: 374.2
Min Reward: 358.0
Max Reward: 393.0
Gini Coefficient: 0.017316942811330838
20:20 Ratio: 1.0977653631284916
Max-min Ratio: 1.0977653631284916
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_12-44-34
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1975.0
  episode_reward_mean: 1478.78
  episode_reward_min: -17557.0
  episodes_this_iter: 1
  episodes_total: 187
  experiment_id: ebedc1946062457bb682d57fae83bd74
  hostname: gpu052
  info:
    apply_time_ms: 3.849
    dispatch_time_ms: 28.866
    learner:
      cur_lr: 0.001297728973440826
      grad_gnorm: 40.000003814697266
      policy_entropy: 17.678396224975586
      policy_loss: -4.316305637359619
      var_gnorm: 34.095558166503906
      vf_explained_var: 0.3621188998222351
      vf_loss: 50.26365280151367
    num_steps_sampled: 940000
    num_steps_trained: 940000
    wait_time_ms: 93.863
  iterations_since_restore: 188
  node_ip: 172.17.8.52
  num_metric_batches_dropped: 0
  pid: 12141
  policy_reward_mean: {}
  time_since_restore: 2650.987732410431
  time_this_iter_s: 13.621333122253418
  time_total_s: 2650.987732410431
  timestamp: 1594140274
  timesteps_since_restore: 940000
  timesteps_this_iter: 5000
  timesteps_total: 940000
  training_iteration: 188
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 34.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=12141], 2650 s, 188 iter, 940000 ts, 1.48e+03 rew

agent-1: 369.0
agent-2: 353.0
agent-3: 341.0
agent-4: 356.0
agent-5: 395.0
Sum Reward: 1814.0
Avg Reward: 362.8
Min Reward: 341.0
Max Reward: 395.0
Gini Coefficient: 0.027342888643880927
20:20 Ratio: 1.1583577712609971
Max-min Ratio: 1.1583577712609971
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_12-44-48
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1975.0
  episode_reward_mean: 1480.98
  episode_reward_min: -17557.0
  episodes_this_iter: 1
  episodes_total: 188
  experiment_id: ebedc1946062457bb682d57fae83bd74
  hostname: gpu052
  info:
    apply_time_ms: 2.535
    dispatch_time_ms: 13.385
    learner:
      cur_lr: 0.001297396025620401
      grad_gnorm: 39.99999237060547
      policy_entropy: 14.603415489196777
      policy_loss: 12.881354331970215
      var_gnorm: 34.11023712158203
      vf_explained_var: 0.4652429223060608
      vf_loss: 63.3714714050293
    num_steps_sampled: 945000
    num_steps_trained: 945000
    wait_time_ms: 122.891
  iterations_since_restore: 189
  node_ip: 172.17.8.52
  num_metric_batches_dropped: 0
  pid: 12141
  policy_reward_mean: {}
  time_since_restore: 2664.8836081027985
  time_this_iter_s: 13.895875692367554
  time_total_s: 2664.8836081027985
  timestamp: 1594140288
  timesteps_since_restore: 945000
  timesteps_this_iter: 5000
  timesteps_total: 945000
  training_iteration: 189
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 34.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=12141], 2664 s, 189 iter, 945000 ts, 1.48e+03 rew

agent-1: 371.0
agent-2: 368.0
agent-3: 371.0
agent-4: 337.0
agent-5: 378.0
Sum Reward: 1825.0
Avg Reward: 365.0
Min Reward: 337.0
Max Reward: 378.0
Gini Coefficient: 0.01863013698630137
20:20 Ratio: 1.1216617210682494
Max-min Ratio: 1.1216617210682494
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_12-45-02
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1975.0
  episode_reward_mean: 1485.09
  episode_reward_min: -17557.0
  episodes_this_iter: 1
  episodes_total: 189
  experiment_id: ebedc1946062457bb682d57fae83bd74
  hostname: gpu052
  info:
    apply_time_ms: 3.039
    dispatch_time_ms: 25.641
    learner:
      cur_lr: 0.001297062961384654
      grad_gnorm: 40.0
      policy_entropy: 15.619828224182129
      policy_loss: 3.347750663757324
      var_gnorm: 34.191436767578125
      vf_explained_var: 0.07277703285217285
      vf_loss: 60.11044692993164
    num_steps_sampled: 950000
    num_steps_trained: 950000
    wait_time_ms: 128.182
  iterations_since_restore: 190
  node_ip: 172.17.8.52
  num_metric_batches_dropped: 0
  pid: 12141
  policy_reward_mean: {}
  time_since_restore: 2678.929399728775
  time_this_iter_s: 14.045791625976562
  time_total_s: 2678.929399728775
  timestamp: 1594140302
  timesteps_since_restore: 950000
  timesteps_this_iter: 5000
  timesteps_total: 950000
  training_iteration: 190
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 34.3/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=12141], 2678 s, 190 iter, 950000 ts, 1.49e+03 rew

agent-1: 379.0
agent-2: 367.0
agent-3: 365.0
agent-4: 363.0
agent-5: 365.0
Sum Reward: 1839.0
Avg Reward: 367.8
Min Reward: 363.0
Max Reward: 379.0
Gini Coefficient: 0.007395323545405111
20:20 Ratio: 1.044077134986226
Max-min Ratio: 1.044077134986226
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_12-45-15
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1975.0
  episode_reward_mean: 1487.78
  episode_reward_min: -17557.0
  episodes_this_iter: 1
  episodes_total: 190
  experiment_id: ebedc1946062457bb682d57fae83bd74
  hostname: gpu052
  info:
    apply_time_ms: 3.208
    dispatch_time_ms: 19.883
    learner:
      cur_lr: 0.001296730013564229
      grad_gnorm: 39.999996185302734
      policy_entropy: 21.42111587524414
      policy_loss: 10.0474853515625
      var_gnorm: 34.246002197265625
      vf_explained_var: 0.8547565937042236
      vf_loss: 44.22355270385742
    num_steps_sampled: 955000
    num_steps_trained: 955000
    wait_time_ms: 119.852
  iterations_since_restore: 191
  node_ip: 172.17.8.52
  num_metric_batches_dropped: 0
  pid: 12141
  policy_reward_mean: {}
  time_since_restore: 2692.457762002945
  time_this_iter_s: 13.528362274169922
  time_total_s: 2692.457762002945
  timestamp: 1594140315
  timesteps_since_restore: 955000
  timesteps_this_iter: 5000
  timesteps_total: 955000
  training_iteration: 191
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 35.3/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=12141], 2692 s, 191 iter, 955000 ts, 1.49e+03 rew

agent-1: 385.0
agent-2: 387.0
agent-3: 366.0
agent-4: 347.0
agent-5: 332.0
Sum Reward: 1817.0
Avg Reward: 363.4
Min Reward: 332.0
Max Reward: 387.0
Gini Coefficient: 0.03258117776554761
20:20 Ratio: 1.1656626506024097
Max-min Ratio: 1.1656626506024097
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_12-45-29
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1975.0
  episode_reward_mean: 1487.94
  episode_reward_min: -17557.0
  episodes_this_iter: 1
  episodes_total: 191
  experiment_id: ebedc1946062457bb682d57fae83bd74
  hostname: gpu052
  info:
    apply_time_ms: 2.524
    dispatch_time_ms: 17.038
    learner:
      cur_lr: 0.0012963969493284822
      grad_gnorm: 40.00000762939453
      policy_entropy: 11.366897583007812
      policy_loss: -1.7864149808883667
      var_gnorm: 34.29594039916992
      vf_explained_var: 0.6208277344703674
      vf_loss: 14.8584566116333
    num_steps_sampled: 960000
    num_steps_trained: 960000
    wait_time_ms: 114.402
  iterations_since_restore: 192
  node_ip: 172.17.8.52
  num_metric_batches_dropped: 0
  pid: 12141
  policy_reward_mean: {}
  time_since_restore: 2705.687885284424
  time_this_iter_s: 13.230123281478882
  time_total_s: 2705.687885284424
  timestamp: 1594140329
  timesteps_since_restore: 960000
  timesteps_this_iter: 5000
  timesteps_total: 960000
  training_iteration: 192
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 35.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=12141], 2705 s, 192 iter, 960000 ts, 1.49e+03 rew

agent-1: 334.0
agent-2: 350.0
agent-3: 356.0
agent-4: 348.0
agent-5: 387.0
Sum Reward: 1775.0
Avg Reward: 355.0
Min Reward: 334.0
Max Reward: 387.0
Gini Coefficient: 0.025690140845070424
20:20 Ratio: 1.158682634730539
Max-min Ratio: 1.158682634730539
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_12-45-42
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1975.0
  episode_reward_mean: 1487.35
  episode_reward_min: -17557.0
  episodes_this_iter: 1
  episodes_total: 192
  experiment_id: ebedc1946062457bb682d57fae83bd74
  hostname: gpu052
  info:
    apply_time_ms: 2.856
    dispatch_time_ms: 31.09
    learner:
      cur_lr: 0.0012960640015080571
      grad_gnorm: 39.999996185302734
      policy_entropy: 9.853729248046875
      policy_loss: 4.089850425720215
      var_gnorm: 34.36152267456055
      vf_explained_var: 0.2973233461380005
      vf_loss: 67.91337585449219
    num_steps_sampled: 965000
    num_steps_trained: 965000
    wait_time_ms: 106.88
  iterations_since_restore: 193
  node_ip: 172.17.8.52
  num_metric_batches_dropped: 0
  pid: 12141
  policy_reward_mean: {}
  time_since_restore: 2719.2763407230377
  time_this_iter_s: 13.588455438613892
  time_total_s: 2719.2763407230377
  timestamp: 1594140342
  timesteps_since_restore: 965000
  timesteps_this_iter: 5000
  timesteps_total: 965000
  training_iteration: 193
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 35.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=12141], 2719 s, 193 iter, 965000 ts, 1.49e+03 rew

agent-1: 395.0
agent-2: 397.0
agent-3: 377.0
agent-4: 390.0
agent-5: 359.0
Sum Reward: 1918.0
Avg Reward: 383.6
Min Reward: 359.0
Max Reward: 397.0
Gini Coefficient: 0.019603753910323252
20:20 Ratio: 1.105849582172702
Max-min Ratio: 1.105849582172702
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_12-45-56
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1975.0
  episode_reward_mean: 1490.22
  episode_reward_min: -17557.0
  episodes_this_iter: 1
  episodes_total: 193
  experiment_id: ebedc1946062457bb682d57fae83bd74
  hostname: gpu052
  info:
    apply_time_ms: 2.818
    dispatch_time_ms: 20.949
    learner:
      cur_lr: 0.001295731053687632
      grad_gnorm: 40.000003814697266
      policy_entropy: 8.473780632019043
      policy_loss: -19.83765411376953
      var_gnorm: 34.429080963134766
      vf_explained_var: 0.18528342247009277
      vf_loss: 129.45040893554688
    num_steps_sampled: 970000
    num_steps_trained: 970000
    wait_time_ms: 117.979
  iterations_since_restore: 194
  node_ip: 172.17.8.52
  num_metric_batches_dropped: 0
  pid: 12141
  policy_reward_mean: {}
  time_since_restore: 2732.4955530166626
  time_this_iter_s: 13.219212293624878
  time_total_s: 2732.4955530166626
  timestamp: 1594140356
  timesteps_since_restore: 970000
  timesteps_this_iter: 5000
  timesteps_total: 970000
  training_iteration: 194
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 35.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=12141], 2732 s, 194 iter, 970000 ts, 1.49e+03 rew

agent-1: 369.0
agent-2: 368.0
agent-3: 351.0
agent-4: 347.0
agent-5: 335.0
Sum Reward: 1770.0
Avg Reward: 354.0
Min Reward: 335.0
Max Reward: 369.0
Gini Coefficient: 0.020112994350282486
20:20 Ratio: 1.1014925373134328
Max-min Ratio: 1.1014925373134328
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_12-46-09
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1975.0
  episode_reward_mean: 1489.13
  episode_reward_min: -17557.0
  episodes_this_iter: 1
  episodes_total: 194
  experiment_id: ebedc1946062457bb682d57fae83bd74
  hostname: gpu052
  info:
    apply_time_ms: 2.928
    dispatch_time_ms: 20.199
    learner:
      cur_lr: 0.0012953979894518852
      grad_gnorm: 39.999996185302734
      policy_entropy: 4.912677764892578
      policy_loss: -0.3368169963359833
      var_gnorm: 34.44960403442383
      vf_explained_var: 0.7024458646774292
      vf_loss: 18.874290466308594
    num_steps_sampled: 975000
    num_steps_trained: 975000
    wait_time_ms: 101.741
  iterations_since_restore: 195
  node_ip: 172.17.8.52
  num_metric_batches_dropped: 0
  pid: 12141
  policy_reward_mean: {}
  time_since_restore: 2745.846129179001
  time_this_iter_s: 13.350576162338257
  time_total_s: 2745.846129179001
  timestamp: 1594140369
  timesteps_since_restore: 975000
  timesteps_this_iter: 5000
  timesteps_total: 975000
  training_iteration: 195
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 35.3/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=12141], 2745 s, 195 iter, 975000 ts, 1.49e+03 rew

agent-1: 321.0
agent-2: 373.0
agent-3: 354.0
agent-4: 357.0
agent-5: 352.0
Sum Reward: 1757.0
Avg Reward: 351.4
Min Reward: 321.0
Max Reward: 373.0
Gini Coefficient: 0.024815025611838362
20:20 Ratio: 1.161993769470405
Max-min Ratio: 1.161993769470405
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_12-46-22
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1975.0
  episode_reward_mean: 1490.52
  episode_reward_min: -17557.0
  episodes_this_iter: 1
  episodes_total: 195
  experiment_id: ebedc1946062457bb682d57fae83bd74
  hostname: gpu052
  info:
    apply_time_ms: 5.245
    dispatch_time_ms: 30.982
    learner:
      cur_lr: 0.0012950650416314602
      grad_gnorm: 39.999996185302734
      policy_entropy: 9.645963668823242
      policy_loss: -6.906459331512451
      var_gnorm: 34.507171630859375
      vf_explained_var: 0.6513217091560364
      vf_loss: 51.752174377441406
    num_steps_sampled: 980000
    num_steps_trained: 980000
    wait_time_ms: 99.805
  iterations_since_restore: 196
  node_ip: 172.17.8.52
  num_metric_batches_dropped: 0
  pid: 12141
  policy_reward_mean: {}
  time_since_restore: 2758.861637353897
  time_this_iter_s: 13.01550817489624
  time_total_s: 2758.861637353897
  timestamp: 1594140382
  timesteps_since_restore: 980000
  timesteps_this_iter: 5000
  timesteps_total: 980000
  training_iteration: 196
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 35.3/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=12141], 2758 s, 196 iter, 980000 ts, 1.49e+03 rew

agent-1: 333.0
agent-2: 345.0
agent-3: 296.0
agent-4: 336.0
agent-5: 374.0
Sum Reward: 1684.0
Avg Reward: 336.8
Min Reward: 296.0
Max Reward: 374.0
Gini Coefficient: 0.039904988123515436
20:20 Ratio: 1.2635135135135136
Max-min Ratio: 1.2635135135135136
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_12-46-35
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1975.0
  episode_reward_mean: 1488.69
  episode_reward_min: -17557.0
  episodes_this_iter: 1
  episodes_total: 196
  experiment_id: ebedc1946062457bb682d57fae83bd74
  hostname: gpu052
  info:
    apply_time_ms: 2.534
    dispatch_time_ms: 29.543
    learner:
      cur_lr: 0.0012947319773957133
      grad_gnorm: 40.0
      policy_entropy: 4.6721062660217285
      policy_loss: 2.2963902950286865
      var_gnorm: 34.532997131347656
      vf_explained_var: -0.1029365062713623
      vf_loss: 29.064697265625
    num_steps_sampled: 985000
    num_steps_trained: 985000
    wait_time_ms: 99.151
  iterations_since_restore: 197
  node_ip: 172.17.8.52
  num_metric_batches_dropped: 0
  pid: 12141
  policy_reward_mean: {}
  time_since_restore: 2771.9824283123016
  time_this_iter_s: 13.120790958404541
  time_total_s: 2771.9824283123016
  timestamp: 1594140395
  timesteps_since_restore: 985000
  timesteps_this_iter: 5000
  timesteps_total: 985000
  training_iteration: 197
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 35.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=12141], 2771 s, 197 iter, 985000 ts, 1.49e+03 rew

agent-1: 333.0
agent-2: 351.0
agent-3: 332.0
agent-4: 369.0
agent-5: 375.0
Sum Reward: 1760.0
Avg Reward: 352.0
Min Reward: 332.0
Max Reward: 375.0
Gini Coefficient: 0.02772727272727273
20:20 Ratio: 1.1295180722891567
Max-min Ratio: 1.1295180722891567
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_12-46-53
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1975.0
  episode_reward_mean: 1491.3
  episode_reward_min: -17557.0
  episodes_this_iter: 1
  episodes_total: 197
  experiment_id: ebedc1946062457bb682d57fae83bd74
  hostname: gpu052
  info:
    apply_time_ms: 2.761
    dispatch_time_ms: 5.888
    learner:
      cur_lr: 0.0012943990295752883
      grad_gnorm: 39.999996185302734
      policy_entropy: 3.9626822471618652
      policy_loss: 1.772521734237671
      var_gnorm: 34.58657455444336
      vf_explained_var: 0.641292929649353
      vf_loss: 23.541513442993164
    num_steps_sampled: 990000
    num_steps_trained: 990000
    wait_time_ms: 126.097
  iterations_since_restore: 198
  node_ip: 172.17.8.52
  num_metric_batches_dropped: 0
  pid: 12141
  policy_reward_mean: {}
  time_since_restore: 2789.6831119060516
  time_this_iter_s: 17.70068359375
  time_total_s: 2789.6831119060516
  timestamp: 1594140413
  timesteps_since_restore: 990000
  timesteps_this_iter: 5000
  timesteps_total: 990000
  training_iteration: 198
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 35.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=12141], 2789 s, 198 iter, 990000 ts, 1.49e+03 rew

agent-1: 347.0
agent-2: 356.0
agent-3: 394.0
agent-4: 327.0
agent-5: 357.0
Sum Reward: 1781.0
Avg Reward: 356.2
Min Reward: 327.0
Max Reward: 394.0
Gini Coefficient: 0.03234138124649073
20:20 Ratio: 1.2048929663608563
Max-min Ratio: 1.2048929663608563
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_12-47-06
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1975.0
  episode_reward_mean: 1494.11
  episode_reward_min: -17557.0
  episodes_this_iter: 1
  episodes_total: 198
  experiment_id: ebedc1946062457bb682d57fae83bd74
  hostname: gpu052
  info:
    apply_time_ms: 2.937
    dispatch_time_ms: 7.017
    learner:
      cur_lr: 0.0012940659653395414
      grad_gnorm: 40.0
      policy_entropy: 4.540778636932373
      policy_loss: 0.5863829851150513
      var_gnorm: 34.586124420166016
      vf_explained_var: 0.46457451581954956
      vf_loss: 20.206371307373047
    num_steps_sampled: 995000
    num_steps_trained: 995000
    wait_time_ms: 109.527
  iterations_since_restore: 199
  node_ip: 172.17.8.52
  num_metric_batches_dropped: 0
  pid: 12141
  policy_reward_mean: {}
  time_since_restore: 2802.634190797806
  time_this_iter_s: 12.95107889175415
  time_total_s: 2802.634190797806
  timestamp: 1594140426
  timesteps_since_restore: 995000
  timesteps_this_iter: 5000
  timesteps_total: 995000
  training_iteration: 199
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 35.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=12141], 2802 s, 199 iter, 995000 ts, 1.49e+03 rew

agent-1: 366.0
agent-2: 341.0
agent-3: 340.0
agent-4: 380.0
agent-5: 383.0
Sum Reward: 1810.0
Avg Reward: 362.0
Min Reward: 340.0
Max Reward: 383.0
Gini Coefficient: 0.027624309392265192
20:20 Ratio: 1.1264705882352941
Max-min Ratio: 1.1264705882352941
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_12-47-18
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1975.0
  episode_reward_mean: 1495.03
  episode_reward_min: -17557.0
  episodes_this_iter: 1
  episodes_total: 199
  experiment_id: ebedc1946062457bb682d57fae83bd74
  hostname: gpu052
  info:
    apply_time_ms: 3.22
    dispatch_time_ms: 7.781
    learner:
      cur_lr: 0.0012937330175191164
      grad_gnorm: 40.000003814697266
      policy_entropy: 14.036299705505371
      policy_loss: -9.440946578979492
      var_gnorm: 34.6755485534668
      vf_explained_var: 0.7811771035194397
      vf_loss: 59.00171661376953
    num_steps_sampled: 1000000
    num_steps_trained: 1000000
    wait_time_ms: 122.832
  iterations_since_restore: 200
  node_ip: 172.17.8.52
  num_metric_batches_dropped: 0
  pid: 12141
  policy_reward_mean: {}
  time_since_restore: 2814.8365676403046
  time_this_iter_s: 12.20237684249878
  time_total_s: 2814.8365676403046
  timestamp: 1594140438
  timesteps_since_restore: 1000000
  timesteps_this_iter: 5000
  timesteps_total: 1000000
  training_iteration: 200
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 35.3/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=12141], 2814 s, 200 iter, 1000000 ts, 1.5e+03 rew

agent-1: 322.0
agent-2: 353.0
agent-3: 330.0
agent-4: 329.0
agent-5: 325.0
Sum Reward: 1659.0
Avg Reward: 331.8
Min Reward: 322.0
Max Reward: 353.0
Gini Coefficient: 0.0161543098251959
20:20 Ratio: 1.0962732919254659
Max-min Ratio: 1.0962732919254659
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_12-47-31
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1975.0
  episode_reward_mean: 1493.27
  episode_reward_min: -17557.0
  episodes_this_iter: 1
  episodes_total: 200
  experiment_id: ebedc1946062457bb682d57fae83bd74
  hostname: gpu052
  info:
    apply_time_ms: 2.744
    dispatch_time_ms: 6.122
    learner:
      cur_lr: 0.0012933999532833695
      grad_gnorm: 37.153160095214844
      policy_entropy: 9.054638862609863
      policy_loss: -4.25865364074707
      var_gnorm: 34.668670654296875
      vf_explained_var: 0.913785994052887
      vf_loss: 40.568145751953125
    num_steps_sampled: 1005000
    num_steps_trained: 1005000
    wait_time_ms: 110.478
  iterations_since_restore: 201
  node_ip: 172.17.8.52
  num_metric_batches_dropped: 0
  pid: 12141
  policy_reward_mean: {}
  time_since_restore: 2827.292373895645
  time_this_iter_s: 12.455806255340576
  time_total_s: 2827.292373895645
  timestamp: 1594140451
  timesteps_since_restore: 1005000
  timesteps_this_iter: 5000
  timesteps_total: 1005000
  training_iteration: 201
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 35.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=12141], 2827 s, 201 iter, 1005000 ts, 1.49e+03 rew

agent-1: 366.0
agent-2: 313.0
agent-3: 177.0
agent-4: 337.0
agent-5: 298.0
Sum Reward: 1491.0
Avg Reward: 298.2
Min Reward: 177.0
Max Reward: 366.0
Gini Coefficient: 0.11187122736418512
20:20 Ratio: 2.0677966101694913
Max-min Ratio: 2.0677966101694913
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_12-47-43
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1975.0
  episode_reward_mean: 1494.07
  episode_reward_min: -17557.0
  episodes_this_iter: 1
  episodes_total: 201
  experiment_id: ebedc1946062457bb682d57fae83bd74
  hostname: gpu052
  info:
    apply_time_ms: 2.766
    dispatch_time_ms: 8.521
    learner:
      cur_lr: 0.0012930670054629445
      grad_gnorm: 40.0
      policy_entropy: 6.820505142211914
      policy_loss: 7.685399055480957
      var_gnorm: 34.74769592285156
      vf_explained_var: 0.4647659659385681
      vf_loss: 28.05592918395996
    num_steps_sampled: 1010000
    num_steps_trained: 1010000
    wait_time_ms: 114.734
  iterations_since_restore: 202
  node_ip: 172.17.8.52
  num_metric_batches_dropped: 0
  pid: 12141
  policy_reward_mean: {}
  time_since_restore: 2839.2351076602936
  time_this_iter_s: 11.942733764648438
  time_total_s: 2839.2351076602936
  timestamp: 1594140463
  timesteps_since_restore: 1010000
  timesteps_this_iter: 5000
  timesteps_total: 1010000
  training_iteration: 202
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 35.3/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=12141], 2839 s, 202 iter, 1010000 ts, 1.49e+03 rew

agent-1: 322.0
agent-2: 327.0
agent-3: 374.0
agent-4: 304.0
agent-5: 323.0
Sum Reward: 1650.0
Avg Reward: 330.0
Min Reward: 304.0
Max Reward: 374.0
Gini Coefficient: 0.03515151515151515
20:20 Ratio: 1.230263157894737
Max-min Ratio: 1.230263157894737
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_12-47-55
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1975.0
  episode_reward_mean: 1494.77
  episode_reward_min: -17557.0
  episodes_this_iter: 1
  episodes_total: 202
  experiment_id: ebedc1946062457bb682d57fae83bd74
  hostname: gpu052
  info:
    apply_time_ms: 3.413
    dispatch_time_ms: 5.722
    learner:
      cur_lr: 0.0012927340576425195
      grad_gnorm: 40.0
      policy_entropy: 3.6518242359161377
      policy_loss: -22.855587005615234
      var_gnorm: 34.81504440307617
      vf_explained_var: 0.5633147954940796
      vf_loss: 106.13038635253906
    num_steps_sampled: 1015000
    num_steps_trained: 1015000
    wait_time_ms: 104.886
  iterations_since_restore: 203
  node_ip: 172.17.8.52
  num_metric_batches_dropped: 0
  pid: 12141
  policy_reward_mean: {}
  time_since_restore: 2851.967727661133
  time_this_iter_s: 12.732620000839233
  time_total_s: 2851.967727661133
  timestamp: 1594140475
  timesteps_since_restore: 1015000
  timesteps_this_iter: 5000
  timesteps_total: 1015000
  training_iteration: 203
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 35.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=12141], 2851 s, 203 iter, 1015000 ts, 1.49e+03 rew

agent-1: 368.0
agent-2: 318.0
agent-3: 338.0
agent-4: 310.0
agent-5: 370.0
Sum Reward: 1704.0
Avg Reward: 340.8
Min Reward: 310.0
Max Reward: 370.0
Gini Coefficient: 0.03990610328638498
20:20 Ratio: 1.1935483870967742
Max-min Ratio: 1.1935483870967742
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_12-48-07
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1975.0
  episode_reward_mean: 1496.08
  episode_reward_min: -17557.0
  episodes_this_iter: 1
  episodes_total: 203
  experiment_id: ebedc1946062457bb682d57fae83bd74
  hostname: gpu052
  info:
    apply_time_ms: 3.476
    dispatch_time_ms: 9.027
    learner:
      cur_lr: 0.0012924009934067726
      grad_gnorm: 40.0
      policy_entropy: 4.722397327423096
      policy_loss: -1.5757381916046143
      var_gnorm: 34.794921875
      vf_explained_var: 0.3638541102409363
      vf_loss: 51.15362548828125
    num_steps_sampled: 1020000
    num_steps_trained: 1020000
    wait_time_ms: 111.712
  iterations_since_restore: 204
  node_ip: 172.17.8.52
  num_metric_batches_dropped: 0
  pid: 12141
  policy_reward_mean: {}
  time_since_restore: 2863.837986946106
  time_this_iter_s: 11.870259284973145
  time_total_s: 2863.837986946106
  timestamp: 1594140487
  timesteps_since_restore: 1020000
  timesteps_this_iter: 5000
  timesteps_total: 1020000
  training_iteration: 204
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 35.3/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=12141], 2863 s, 204 iter, 1020000 ts, 1.5e+03 rew

agent-1: 308.0
agent-2: 375.0
agent-3: 369.0
agent-4: 354.0
agent-5: 291.0
Sum Reward: 1697.0
Avg Reward: 339.4
Min Reward: 291.0
Max Reward: 375.0
Gini Coefficient: 0.053977607542722454
20:20 Ratio: 1.288659793814433
Max-min Ratio: 1.288659793814433
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_12-48-20
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1975.0
  episode_reward_mean: 1496.3
  episode_reward_min: -17557.0
  episodes_this_iter: 1
  episodes_total: 204
  experiment_id: ebedc1946062457bb682d57fae83bd74
  hostname: gpu052
  info:
    apply_time_ms: 3.554
    dispatch_time_ms: 7.193
    learner:
      cur_lr: 0.0012920680455863476
      grad_gnorm: 40.000003814697266
      policy_entropy: 2.3013899326324463
      policy_loss: -0.0344076007604599
      var_gnorm: 34.812355041503906
      vf_explained_var: 0.32229453325271606
      vf_loss: 42.70264434814453
    num_steps_sampled: 1025000
    num_steps_trained: 1025000
    wait_time_ms: 113.035
  iterations_since_restore: 205
  node_ip: 172.17.8.52
  num_metric_batches_dropped: 0
  pid: 12141
  policy_reward_mean: {}
  time_since_restore: 2876.2982285022736
  time_this_iter_s: 12.460241556167603
  time_total_s: 2876.2982285022736
  timestamp: 1594140500
  timesteps_since_restore: 1025000
  timesteps_this_iter: 5000
  timesteps_total: 1025000
  training_iteration: 205
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 35.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=12141], 2876 s, 205 iter, 1025000 ts, 1.5e+03 rew

agent-1: 287.0
agent-2: 293.0
agent-3: 372.0
agent-4: 343.0
agent-5: 352.0
Sum Reward: 1647.0
Avg Reward: 329.4
Min Reward: 287.0
Max Reward: 372.0
Gini Coefficient: 0.05561627200971463
20:20 Ratio: 1.2961672473867596
Max-min Ratio: 1.2961672473867596
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_12-48-32
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1975.0
  episode_reward_mean: 1493.84
  episode_reward_min: -17557.0
  episodes_this_iter: 1
  episodes_total: 205
  experiment_id: ebedc1946062457bb682d57fae83bd74
  hostname: gpu052
  info:
    apply_time_ms: 3.539
    dispatch_time_ms: 7.501
    learner:
      cur_lr: 0.0012917349813506007
      grad_gnorm: 40.000003814697266
      policy_entropy: 9.708449363708496
      policy_loss: -7.539858341217041
      var_gnorm: 34.836883544921875
      vf_explained_var: 0.48398923873901367
      vf_loss: 42.22496795654297
    num_steps_sampled: 1030000
    num_steps_trained: 1030000
    wait_time_ms: 116.846
  iterations_since_restore: 206
  node_ip: 172.17.8.52
  num_metric_batches_dropped: 0
  pid: 12141
  policy_reward_mean: {}
  time_since_restore: 2888.6627435684204
  time_this_iter_s: 12.36451506614685
  time_total_s: 2888.6627435684204
  timestamp: 1594140512
  timesteps_since_restore: 1030000
  timesteps_this_iter: 5000
  timesteps_total: 1030000
  training_iteration: 206
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 35.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=12141], 2888 s, 206 iter, 1030000 ts, 1.49e+03 rew

agent-1: 342.0
agent-2: 293.0
agent-3: 348.0
agent-4: 356.0
agent-5: 283.0
Sum Reward: 1622.0
Avg Reward: 324.4
Min Reward: 283.0
Max Reward: 356.0
Gini Coefficient: 0.04956843403205918
20:20 Ratio: 1.2579505300353357
Max-min Ratio: 1.2579505300353357
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_12-48-45
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1975.0
  episode_reward_mean: 1493.3
  episode_reward_min: -17557.0
  episodes_this_iter: 1
  episodes_total: 206
  experiment_id: ebedc1946062457bb682d57fae83bd74
  hostname: gpu052
  info:
    apply_time_ms: 3.293
    dispatch_time_ms: 6.736
    learner:
      cur_lr: 0.0012914020335301757
      grad_gnorm: 40.0
      policy_entropy: 3.8934526443481445
      policy_loss: 0.5157476663589478
      var_gnorm: 34.86989974975586
      vf_explained_var: -1.0
      vf_loss: 44.57363510131836
    num_steps_sampled: 1035000
    num_steps_trained: 1035000
    wait_time_ms: 112.937
  iterations_since_restore: 207
  node_ip: 172.17.8.52
  num_metric_batches_dropped: 0
  pid: 12141
  policy_reward_mean: {}
  time_since_restore: 2901.8528904914856
  time_this_iter_s: 13.190146923065186
  time_total_s: 2901.8528904914856
  timestamp: 1594140525
  timesteps_since_restore: 1035000
  timesteps_this_iter: 5000
  timesteps_total: 1035000
  training_iteration: 207
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 35.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=12141], 2901 s, 207 iter, 1035000 ts, 1.49e+03 rew

agent-1: 292.0
agent-2: 283.0
agent-3: 296.0
agent-4: 328.0
agent-5: 322.0
Sum Reward: 1521.0
Avg Reward: 304.2
Min Reward: 283.0
Max Reward: 328.0
Gini Coefficient: 0.03155818540433925
20:20 Ratio: 1.1590106007067138
Max-min Ratio: 1.1590106007067138
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_12-48-58
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1975.0
  episode_reward_mean: 1492.76
  episode_reward_min: -17557.0
  episodes_this_iter: 1
  episodes_total: 207
  experiment_id: ebedc1946062457bb682d57fae83bd74
  hostname: gpu052
  info:
    apply_time_ms: 3.99
    dispatch_time_ms: 8.013
    learner:
      cur_lr: 0.0012910689692944288
      grad_gnorm: 40.0
      policy_entropy: 7.472907066345215
      policy_loss: -21.561771392822266
      var_gnorm: 34.923248291015625
      vf_explained_var: 0.4714984893798828
      vf_loss: 85.91830444335938
    num_steps_sampled: 1040000
    num_steps_trained: 1040000
    wait_time_ms: 121.615
  iterations_since_restore: 208
  node_ip: 172.17.8.52
  num_metric_batches_dropped: 0
  pid: 12141
  policy_reward_mean: {}
  time_since_restore: 2914.0415618419647
  time_this_iter_s: 12.188671350479126
  time_total_s: 2914.0415618419647
  timestamp: 1594140538
  timesteps_since_restore: 1040000
  timesteps_this_iter: 5000
  timesteps_total: 1040000
  training_iteration: 208
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 35.3/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=12141], 2914 s, 208 iter, 1040000 ts, 1.49e+03 rew

agent-1: 341.0
agent-2: 250.0
agent-3: 254.0
agent-4: 326.0
agent-5: 334.0
Sum Reward: 1505.0
Avg Reward: 301.0
Min Reward: 250.0
Max Reward: 341.0
Gini Coefficient: 0.06963455149501661
20:20 Ratio: 1.364
Max-min Ratio: 1.364
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_12-49-11
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1975.0
  episode_reward_mean: 1491.42
  episode_reward_min: -17557.0
  episodes_this_iter: 1
  episodes_total: 208
  experiment_id: ebedc1946062457bb682d57fae83bd74
  hostname: gpu052
  info:
    apply_time_ms: 3.245
    dispatch_time_ms: 7.886
    learner:
      cur_lr: 0.0012907360214740038
      grad_gnorm: 40.00000762939453
      policy_entropy: 6.448851108551025
      policy_loss: -0.3645259141921997
      var_gnorm: 34.95975112915039
      vf_explained_var: 0.4007388949394226
      vf_loss: 80.8105697631836
    num_steps_sampled: 1045000
    num_steps_trained: 1045000
    wait_time_ms: 120.297
  iterations_since_restore: 209
  node_ip: 172.17.8.52
  num_metric_batches_dropped: 0
  pid: 12141
  policy_reward_mean: {}
  time_since_restore: 2927.323016166687
  time_this_iter_s: 13.28145432472229
  time_total_s: 2927.323016166687
  timestamp: 1594140551
  timesteps_since_restore: 1045000
  timesteps_this_iter: 5000
  timesteps_total: 1045000
  training_iteration: 209
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 35.3/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=12141], 2927 s, 209 iter, 1045000 ts, 1.49e+03 rew

agent-1: 350.0
agent-2: 359.0
agent-3: 313.0
agent-4: 324.0
agent-5: 318.0
Sum Reward: 1664.0
Avg Reward: 332.8
Min Reward: 313.0
Max Reward: 359.0
Gini Coefficient: 0.02980769230769231
20:20 Ratio: 1.1469648562300319
Max-min Ratio: 1.1469648562300319
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_12-49-23
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1975.0
  episode_reward_mean: 1490.26
  episode_reward_min: -17557.0
  episodes_this_iter: 1
  episodes_total: 209
  experiment_id: ebedc1946062457bb682d57fae83bd74
  hostname: gpu052
  info:
    apply_time_ms: 3.79
    dispatch_time_ms: 9.046
    learner:
      cur_lr: 0.001290402957238257
      grad_gnorm: 39.999996185302734
      policy_entropy: 4.090489864349365
      policy_loss: 0.6060428619384766
      var_gnorm: 34.95426940917969
      vf_explained_var: 0.3750951886177063
      vf_loss: 34.97186279296875
    num_steps_sampled: 1050000
    num_steps_trained: 1050000
    wait_time_ms: 108.412
  iterations_since_restore: 210
  node_ip: 172.17.8.52
  num_metric_batches_dropped: 0
  pid: 12141
  policy_reward_mean: {}
  time_since_restore: 2939.2332270145416
  time_this_iter_s: 11.910210847854614
  time_total_s: 2939.2332270145416
  timestamp: 1594140563
  timesteps_since_restore: 1050000
  timesteps_this_iter: 5000
  timesteps_total: 1050000
  training_iteration: 210
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 35.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=12141], 2939 s, 210 iter, 1050000 ts, 1.49e+03 rew

agent-1: 364.0
agent-2: 334.0
agent-3: 304.0
agent-4: 298.0
agent-5: 359.0
Sum Reward: 1659.0
Avg Reward: 331.8
Min Reward: 298.0
Max Reward: 364.0
Gini Coefficient: 0.045087402049427364
20:20 Ratio: 1.221476510067114
Max-min Ratio: 1.221476510067114
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_12-49-36
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1975.0
  episode_reward_mean: 1490.38
  episode_reward_min: -17557.0
  episodes_this_iter: 1
  episodes_total: 210
  experiment_id: ebedc1946062457bb682d57fae83bd74
  hostname: gpu052
  info:
    apply_time_ms: 3.822
    dispatch_time_ms: 6.992
    learner:
      cur_lr: 0.001290070009417832
      grad_gnorm: 40.000003814697266
      policy_entropy: 3.496856451034546
      policy_loss: 5.55717658996582
      var_gnorm: 34.97974395751953
      vf_explained_var: 0.006978452205657959
      vf_loss: 75.07825469970703
    num_steps_sampled: 1055000
    num_steps_trained: 1055000
    wait_time_ms: 103.11
  iterations_since_restore: 211
  node_ip: 172.17.8.52
  num_metric_batches_dropped: 0
  pid: 12141
  policy_reward_mean: {}
  time_since_restore: 2952.153744459152
  time_this_iter_s: 12.920517444610596
  time_total_s: 2952.153744459152
  timestamp: 1594140576
  timesteps_since_restore: 1055000
  timesteps_this_iter: 5000
  timesteps_total: 1055000
  training_iteration: 211
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 35.3/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=12141], 2952 s, 211 iter, 1055000 ts, 1.49e+03 rew

agent-1: 352.0
agent-2: 308.0
agent-3: 321.0
agent-4: 312.0
agent-5: 288.0
Sum Reward: 1581.0
Avg Reward: 316.2
Min Reward: 288.0
Max Reward: 352.0
Gini Coefficient: 0.03567362428842505
20:20 Ratio: 1.2222222222222223
Max-min Ratio: 1.2222222222222223
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_12-49-49
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1975.0
  episode_reward_mean: 1489.45
  episode_reward_min: -17557.0
  episodes_this_iter: 1
  episodes_total: 211
  experiment_id: ebedc1946062457bb682d57fae83bd74
  hostname: gpu052
  info:
    apply_time_ms: 2.65
    dispatch_time_ms: 5.992
    learner:
      cur_lr: 0.001289736945182085
      grad_gnorm: 39.999996185302734
      policy_entropy: 6.5203986167907715
      policy_loss: -5.336579322814941
      var_gnorm: 35.02093505859375
      vf_explained_var: 0.6291339993476868
      vf_loss: 37.042476654052734
    num_steps_sampled: 1060000
    num_steps_trained: 1060000
    wait_time_ms: 135.561
  iterations_since_restore: 212
  node_ip: 172.17.8.52
  num_metric_batches_dropped: 0
  pid: 12141
  policy_reward_mean: {}
  time_since_restore: 2965.031236410141
  time_this_iter_s: 12.87749195098877
  time_total_s: 2965.031236410141
  timestamp: 1594140589
  timesteps_since_restore: 1060000
  timesteps_this_iter: 5000
  timesteps_total: 1060000
  training_iteration: 212
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 35.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=12141], 2965 s, 212 iter, 1060000 ts, 1.49e+03 rew

agent-1: 350.0
agent-2: 327.0
agent-3: 323.0
agent-4: 352.0
agent-5: 357.0
Sum Reward: 1709.0
Avg Reward: 341.8
Min Reward: 323.0
Max Reward: 357.0
Gini Coefficient: 0.02176711527208894
20:20 Ratio: 1.105263157894737
Max-min Ratio: 1.105263157894737
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_12-50-02
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1975.0
  episode_reward_mean: 1489.59
  episode_reward_min: -17557.0
  episodes_this_iter: 1
  episodes_total: 212
  experiment_id: ebedc1946062457bb682d57fae83bd74
  hostname: gpu052
  info:
    apply_time_ms: 3.359
    dispatch_time_ms: 7.06
    learner:
      cur_lr: 0.00128940399736166
      grad_gnorm: 40.00000762939453
      policy_entropy: 7.525862693786621
      policy_loss: 0.7433596253395081
      var_gnorm: 35.07839584350586
      vf_explained_var: 0.4960482120513916
      vf_loss: 38.33113098144531
    num_steps_sampled: 1065000
    num_steps_trained: 1065000
    wait_time_ms: 116.418
  iterations_since_restore: 213
  node_ip: 172.17.8.52
  num_metric_batches_dropped: 0
  pid: 12141
  policy_reward_mean: {}
  time_since_restore: 2978.1654646396637
  time_this_iter_s: 13.134228229522705
  time_total_s: 2978.1654646396637
  timestamp: 1594140602
  timesteps_since_restore: 1065000
  timesteps_this_iter: 5000
  timesteps_total: 1065000
  training_iteration: 213
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 35.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=12141], 2978 s, 213 iter, 1065000 ts, 1.49e+03 rew

agent-1: 349.0
agent-2: 330.0
agent-3: 364.0
agent-4: 361.0
agent-5: 342.0
Sum Reward: 1746.0
Avg Reward: 349.2
Min Reward: 330.0
Max Reward: 364.0
Gini Coefficient: 0.01993127147766323
20:20 Ratio: 1.103030303030303
Max-min Ratio: 1.103030303030303
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_12-50-14
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1975.0
  episode_reward_mean: 1489.41
  episode_reward_min: -17557.0
  episodes_this_iter: 1
  episodes_total: 213
  experiment_id: ebedc1946062457bb682d57fae83bd74
  hostname: gpu052
  info:
    apply_time_ms: 2.719
    dispatch_time_ms: 11.143
    learner:
      cur_lr: 0.001289071049541235
      grad_gnorm: 40.0
      policy_entropy: 3.4516427516937256
      policy_loss: 4.181624889373779
      var_gnorm: 35.170406341552734
      vf_explained_var: 0.4442816376686096
      vf_loss: 30.10045051574707
    num_steps_sampled: 1070000
    num_steps_trained: 1070000
    wait_time_ms: 131.362
  iterations_since_restore: 214
  node_ip: 172.17.8.52
  num_metric_batches_dropped: 0
  pid: 12141
  policy_reward_mean: {}
  time_since_restore: 2990.504250049591
  time_this_iter_s: 12.338785409927368
  time_total_s: 2990.504250049591
  timestamp: 1594140614
  timesteps_since_restore: 1070000
  timesteps_this_iter: 5000
  timesteps_total: 1070000
  training_iteration: 214
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 35.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=12141], 2990 s, 214 iter, 1070000 ts, 1.49e+03 rew

agent-1: 347.0
agent-2: 373.0
agent-3: 357.0
agent-4: 407.0
agent-5: 377.0
Sum Reward: 1861.0
Avg Reward: 372.2
Min Reward: 347.0
Max Reward: 407.0
Gini Coefficient: 0.030091348737238045
20:20 Ratio: 1.1729106628242074
Max-min Ratio: 1.1729106628242074
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_12-50-28
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1975.0
  episode_reward_mean: 1492.14
  episode_reward_min: -17557.0
  episodes_this_iter: 1
  episodes_total: 214
  experiment_id: ebedc1946062457bb682d57fae83bd74
  hostname: gpu052
  info:
    apply_time_ms: 2.96
    dispatch_time_ms: 32.932
    learner:
      cur_lr: 0.0012887379853054881
      grad_gnorm: 39.999996185302734
      policy_entropy: 3.9595084190368652
      policy_loss: -11.42166519165039
      var_gnorm: 35.20406723022461
      vf_explained_var: -0.11311376094818115
      vf_loss: 25.05855369567871
    num_steps_sampled: 1075000
    num_steps_trained: 1075000
    wait_time_ms: 97.902
  iterations_since_restore: 215
  node_ip: 172.17.8.52
  num_metric_batches_dropped: 0
  pid: 12141
  policy_reward_mean: {}
  time_since_restore: 3004.486360311508
  time_this_iter_s: 13.982110261917114
  time_total_s: 3004.486360311508
  timestamp: 1594140628
  timesteps_since_restore: 1075000
  timesteps_this_iter: 5000
  timesteps_total: 1075000
  training_iteration: 215
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 35.3/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=12141], 3004 s, 215 iter, 1075000 ts, 1.49e+03 rew

agent-1: 383.0
agent-2: 353.0
agent-3: 333.0
agent-4: 363.0
agent-5: 360.0
Sum Reward: 1792.0
Avg Reward: 358.4
Min Reward: 333.0
Max Reward: 383.0
Gini Coefficient: 0.024553571428571428
20:20 Ratio: 1.15015015015015
Max-min Ratio: 1.15015015015015
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_12-50-41
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1975.0
  episode_reward_mean: 1492.23
  episode_reward_min: -17557.0
  episodes_this_iter: 1
  episodes_total: 215
  experiment_id: ebedc1946062457bb682d57fae83bd74
  hostname: gpu052
  info:
    apply_time_ms: 4.073
    dispatch_time_ms: 17.379
    learner:
      cur_lr: 0.001288405037485063
      grad_gnorm: 40.00001525878906
      policy_entropy: 4.916417121887207
      policy_loss: -5.731225967407227
      var_gnorm: 35.29104232788086
      vf_explained_var: 0.49942779541015625
      vf_loss: 46.05280303955078
    num_steps_sampled: 1080000
    num_steps_trained: 1080000
    wait_time_ms: 116.754
  iterations_since_restore: 216
  node_ip: 172.17.8.52
  num_metric_batches_dropped: 0
  pid: 12141
  policy_reward_mean: {}
  time_since_restore: 3017.528933286667
  time_this_iter_s: 13.042572975158691
  time_total_s: 3017.528933286667
  timestamp: 1594140641
  timesteps_since_restore: 1080000
  timesteps_this_iter: 5000
  timesteps_total: 1080000
  training_iteration: 216
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 35.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=12141], 3017 s, 216 iter, 1080000 ts, 1.49e+03 rew

agent-1: 344.0
agent-2: 337.0
agent-3: 352.0
agent-4: 341.0
agent-5: 295.0
Sum Reward: 1669.0
Avg Reward: 333.8
Min Reward: 295.0
Max Reward: 352.0
Gini Coefficient: 0.028999400838825642
20:20 Ratio: 1.193220338983051
Max-min Ratio: 1.193220338983051
agent-1: 350.0
agent-2: 374.0
agent-3: 369.0
agent-4: 370.0
agent-5: 362.0
Sum Reward: 1825.0
Avg Reward: 365.0
Min Reward: 350.0
Max Reward: 374.0
Gini Coefficient: 0.012273972602739725
20:20 Ratio: 1.0685714285714285
Max-min Ratio: 1.0685714285714285
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_12-50-55
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1975.0
  episode_reward_mean: 1494.51
  episode_reward_min: -17557.0
  episodes_this_iter: 2
  episodes_total: 217
  experiment_id: ebedc1946062457bb682d57fae83bd74
  hostname: gpu052
  info:
    apply_time_ms: 2.604
    dispatch_time_ms: 22.986
    learner:
      cur_lr: 0.0012880719732493162
      grad_gnorm: 40.000003814697266
      policy_entropy: 4.4636688232421875
      policy_loss: -225.76806640625
      var_gnorm: 35.32274627685547
      vf_explained_var: 0.15612351894378662
      vf_loss: 24657.408203125
    num_steps_sampled: 1085000
    num_steps_trained: 1085000
    wait_time_ms: 109.486
  iterations_since_restore: 217
  node_ip: 172.17.8.52
  num_metric_batches_dropped: 0
  pid: 12141
  policy_reward_mean: {}
  time_since_restore: 3031.503638982773
  time_this_iter_s: 13.974705696105957
  time_total_s: 3031.503638982773
  timestamp: 1594140655
  timesteps_since_restore: 1085000
  timesteps_this_iter: 5000
  timesteps_total: 1085000
  training_iteration: 217
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 35.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=12141], 3031 s, 217 iter, 1085000 ts, 1.49e+03 rew

Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_12-51-08
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1975.0
  episode_reward_mean: 1494.51
  episode_reward_min: -17557.0
  episodes_this_iter: 0
  episodes_total: 217
  experiment_id: ebedc1946062457bb682d57fae83bd74
  hostname: gpu052
  info:
    apply_time_ms: 2.713
    dispatch_time_ms: 26.309
    learner:
      cur_lr: 0.0012877390254288912
      grad_gnorm: 39.999996185302734
      policy_entropy: 3.6268231868743896
      policy_loss: -0.270946741104126
      var_gnorm: 35.370384216308594
      vf_explained_var: 0.46740978956222534
      vf_loss: 42.6424560546875
    num_steps_sampled: 1090000
    num_steps_trained: 1090000
    wait_time_ms: 111.957
  iterations_since_restore: 218
  node_ip: 172.17.8.52
  num_metric_batches_dropped: 0
  pid: 12141
  policy_reward_mean: {}
  time_since_restore: 3044.251686811447
  time_this_iter_s: 12.748047828674316
  time_total_s: 3044.251686811447
  timestamp: 1594140668
  timesteps_since_restore: 1090000
  timesteps_this_iter: 5000
  timesteps_total: 1090000
  training_iteration: 218
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 35.3/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=12141], 3044 s, 218 iter, 1090000 ts, 1.49e+03 rew

agent-1: 375.0
agent-2: 378.0
agent-3: 403.0
agent-4: 366.0
agent-5: 409.0
Sum Reward: 1931.0
Avg Reward: 386.2
Min Reward: 366.0
Max Reward: 409.0
Gini Coefficient: 0.023614707405489384
20:20 Ratio: 1.1174863387978142
Max-min Ratio: 1.1174863387978142
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_12-51-22
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1975.0
  episode_reward_mean: 1496.4
  episode_reward_min: -17557.0
  episodes_this_iter: 1
  episodes_total: 218
  experiment_id: ebedc1946062457bb682d57fae83bd74
  hostname: gpu052
  info:
    apply_time_ms: 3.065
    dispatch_time_ms: 15.487
    learner:
      cur_lr: 0.0012874059611931443
      grad_gnorm: 39.999996185302734
      policy_entropy: 4.429527759552002
      policy_loss: 13.904736518859863
      var_gnorm: 35.3885612487793
      vf_explained_var: -0.05068635940551758
      vf_loss: 87.01321411132812
    num_steps_sampled: 1095000
    num_steps_trained: 1095000
    wait_time_ms: 106.006
  iterations_since_restore: 219
  node_ip: 172.17.8.52
  num_metric_batches_dropped: 0
  pid: 12141
  policy_reward_mean: {}
  time_since_restore: 3058.345331430435
  time_this_iter_s: 14.093644618988037
  time_total_s: 3058.345331430435
  timestamp: 1594140682
  timesteps_since_restore: 1095000
  timesteps_this_iter: 5000
  timesteps_total: 1095000
  training_iteration: 219
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 35.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=12141], 3058 s, 219 iter, 1095000 ts, 1.5e+03 rew

agent-1: 314.0
agent-2: 404.0
agent-3: 329.0
agent-4: 335.0
agent-5: 309.0
Sum Reward: 1691.0
Avg Reward: 338.2
Min Reward: 309.0
Max Reward: 404.0
Gini Coefficient: 0.04991129509166174
20:20 Ratio: 1.307443365695793
Max-min Ratio: 1.307443365695793
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_12-51-35
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1975.0
  episode_reward_mean: 1494.92
  episode_reward_min: -17557.0
  episodes_this_iter: 1
  episodes_total: 219
  experiment_id: ebedc1946062457bb682d57fae83bd74
  hostname: gpu052
  info:
    apply_time_ms: 2.564
    dispatch_time_ms: 45.357
    learner:
      cur_lr: 0.0012870730133727193
      grad_gnorm: 39.99999237060547
      policy_entropy: 10.70461368560791
      policy_loss: -7.679563999176025
      var_gnorm: 35.41299057006836
      vf_explained_var: 0.547622799873352
      vf_loss: 38.34502029418945
    num_steps_sampled: 1100000
    num_steps_trained: 1100000
    wait_time_ms: 99.673
  iterations_since_restore: 220
  node_ip: 172.17.8.52
  num_metric_batches_dropped: 0
  pid: 12141
  policy_reward_mean: {}
  time_since_restore: 3071.3125710487366
  time_this_iter_s: 12.967239618301392
  time_total_s: 3071.3125710487366
  timestamp: 1594140695
  timesteps_since_restore: 1100000
  timesteps_this_iter: 5000
  timesteps_total: 1100000
  training_iteration: 220
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 35.3/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=12141], 3071 s, 220 iter, 1100000 ts, 1.49e+03 rew

agent-1: 356.0
agent-2: 336.0
agent-3: 337.0
agent-4: 338.0
agent-5: 370.0
Sum Reward: 1737.0
Avg Reward: 347.4
Min Reward: 336.0
Max Reward: 370.0
Gini Coefficient: 0.02003454231433506
20:20 Ratio: 1.1011904761904763
Max-min Ratio: 1.1011904761904763
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_12-51-50
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1975.0
  episode_reward_mean: 1494.09
  episode_reward_min: -17557.0
  episodes_this_iter: 1
  episodes_total: 220
  experiment_id: ebedc1946062457bb682d57fae83bd74
  hostname: gpu052
  info:
    apply_time_ms: 2.824
    dispatch_time_ms: 26.459
    learner:
      cur_lr: 0.0012867399491369724
      grad_gnorm: 40.0
      policy_entropy: 10.134260177612305
      policy_loss: 3.8548407554626465
      var_gnorm: 35.40993118286133
      vf_explained_var: 0.5312891006469727
      vf_loss: 35.12983322143555
    num_steps_sampled: 1105000
    num_steps_trained: 1105000
    wait_time_ms: 157.83
  iterations_since_restore: 221
  node_ip: 172.17.8.52
  num_metric_batches_dropped: 0
  pid: 12141
  policy_reward_mean: {}
  time_since_restore: 3085.879585504532
  time_this_iter_s: 14.567014455795288
  time_total_s: 3085.879585504532
  timestamp: 1594140710
  timesteps_since_restore: 1105000
  timesteps_this_iter: 5000
  timesteps_total: 1105000
  training_iteration: 221
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 35.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=12141], 3085 s, 221 iter, 1105000 ts, 1.49e+03 rew

agent-1: 369.0
agent-2: 370.0
agent-3: 388.0
agent-4: 366.0
agent-5: 278.0
Sum Reward: 1771.0
Avg Reward: 354.2
Min Reward: 278.0
Max Reward: 388.0
Gini Coefficient: 0.05059288537549407
20:20 Ratio: 1.39568345323741
Max-min Ratio: 1.39568345323741
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_12-52-02
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1975.0
  episode_reward_mean: 1492.9
  episode_reward_min: -17557.0
  episodes_this_iter: 1
  episodes_total: 221
  experiment_id: ebedc1946062457bb682d57fae83bd74
  hostname: gpu052
  info:
    apply_time_ms: 2.738
    dispatch_time_ms: 9.237
    learner:
      cur_lr: 0.0012864070013165474
      grad_gnorm: 22.606008529663086
      policy_entropy: 11.27172565460205
      policy_loss: 0.7131646275520325
      var_gnorm: 35.47988510131836
      vf_explained_var: 0.5948927998542786
      vf_loss: 18.931909561157227
    num_steps_sampled: 1110000
    num_steps_trained: 1110000
    wait_time_ms: 122.659
  iterations_since_restore: 222
  node_ip: 172.17.8.52
  num_metric_batches_dropped: 0
  pid: 12141
  policy_reward_mean: {}
  time_since_restore: 3098.245623111725
  time_this_iter_s: 12.366037607192993
  time_total_s: 3098.245623111725
  timestamp: 1594140722
  timesteps_since_restore: 1110000
  timesteps_this_iter: 5000
  timesteps_total: 1110000
  training_iteration: 222
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=12141], 3098 s, 222 iter, 1110000 ts, 1.49e+03 rew

agent-1: 376.0
agent-2: 349.0
agent-3: 331.0
agent-4: 380.0
agent-5: 410.0
Sum Reward: 1846.0
Avg Reward: 369.2
Min Reward: 331.0
Max Reward: 410.0
Gini Coefficient: 0.0409534127843987
20:20 Ratio: 1.2386706948640482
Max-min Ratio: 1.2386706948640482
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_12-52-16
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1975.0
  episode_reward_mean: 1493.5
  episode_reward_min: -17557.0
  episodes_this_iter: 1
  episodes_total: 222
  experiment_id: ebedc1946062457bb682d57fae83bd74
  hostname: gpu052
  info:
    apply_time_ms: 3.57
    dispatch_time_ms: 6.095
    learner:
      cur_lr: 0.0012860740534961224
      grad_gnorm: 39.616172790527344
      policy_entropy: 8.458810806274414
      policy_loss: 25.57285499572754
      var_gnorm: 35.564659118652344
      vf_explained_var: 0.3967130184173584
      vf_loss: 79.76856994628906
    num_steps_sampled: 1115000
    num_steps_trained: 1115000
    wait_time_ms: 124.674
  iterations_since_restore: 223
  node_ip: 172.17.8.52
  num_metric_batches_dropped: 0
  pid: 12141
  policy_reward_mean: {}
  time_since_restore: 3112.1868708133698
  time_this_iter_s: 13.941247701644897
  time_total_s: 3112.1868708133698
  timestamp: 1594140736
  timesteps_since_restore: 1115000
  timesteps_this_iter: 5000
  timesteps_total: 1115000
  training_iteration: 223
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 33.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=12141], 3112 s, 223 iter, 1115000 ts, 1.49e+03 rew

agent-1: 327.0
agent-2: 368.0
agent-3: 307.0
agent-4: 347.0
agent-5: 326.0
Sum Reward: 1675.0
Avg Reward: 335.0
Min Reward: 307.0
Max Reward: 368.0
Gini Coefficient: 0.03414925373134328
20:20 Ratio: 1.1986970684039089
Max-min Ratio: 1.1986970684039089
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_12-52-29
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1975.0
  episode_reward_mean: 1495.02
  episode_reward_min: -17557.0
  episodes_this_iter: 1
  episodes_total: 223
  experiment_id: ebedc1946062457bb682d57fae83bd74
  hostname: gpu052
  info:
    apply_time_ms: 3.518
    dispatch_time_ms: 7.699
    learner:
      cur_lr: 0.0012857409892603755
      grad_gnorm: 40.0
      policy_entropy: 15.518012046813965
      policy_loss: 16.629453659057617
      var_gnorm: 35.68270492553711
      vf_explained_var: -0.2520815134048462
      vf_loss: 53.992652893066406
    num_steps_sampled: 1120000
    num_steps_trained: 1120000
    wait_time_ms: 124.603
  iterations_since_restore: 224
  node_ip: 172.17.8.52
  num_metric_batches_dropped: 0
  pid: 12141
  policy_reward_mean: {}
  time_since_restore: 3125.110431432724
  time_this_iter_s: 12.923560619354248
  time_total_s: 3125.110431432724
  timestamp: 1594140749
  timesteps_since_restore: 1120000
  timesteps_this_iter: 5000
  timesteps_total: 1120000
  training_iteration: 224
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 33.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=12141], 3125 s, 224 iter, 1120000 ts, 1.5e+03 rew

agent-1: 254.0
agent-2: 359.0
agent-3: 361.0
agent-4: 366.0
agent-5: 357.0
Sum Reward: 1697.0
Avg Reward: 339.4
Min Reward: 254.0
Max Reward: 366.0
Gini Coefficient: 0.05374189746611668
20:20 Ratio: 1.4409448818897639
Max-min Ratio: 1.4409448818897639
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_12-52-44
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1975.0
  episode_reward_mean: 1497.07
  episode_reward_min: -17557.0
  episodes_this_iter: 1
  episodes_total: 224
  experiment_id: ebedc1946062457bb682d57fae83bd74
  hostname: gpu052
  info:
    apply_time_ms: 3.755
    dispatch_time_ms: 7.228
    learner:
      cur_lr: 0.0012854080414399505
      grad_gnorm: 26.360605239868164
      policy_entropy: 17.45128631591797
      policy_loss: -9.370542526245117
      var_gnorm: 35.72277069091797
      vf_explained_var: 0.5197417736053467
      vf_loss: 41.03975296020508
    num_steps_sampled: 1125000
    num_steps_trained: 1125000
    wait_time_ms: 117.884
  iterations_since_restore: 225
  node_ip: 172.17.8.52
  num_metric_batches_dropped: 0
  pid: 12141
  policy_reward_mean: {}
  time_since_restore: 3139.5302591323853
  time_this_iter_s: 14.419827699661255
  time_total_s: 3139.5302591323853
  timestamp: 1594140764
  timesteps_since_restore: 1125000
  timesteps_this_iter: 5000
  timesteps_total: 1125000
  training_iteration: 225
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 33.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=12141], 3139 s, 225 iter, 1125000 ts, 1.5e+03 rew

agent-1: 328.0
agent-2: 313.0
agent-3: 378.0
agent-4: 391.0
agent-5: 389.0
Sum Reward: 1799.0
Avg Reward: 359.8
Min Reward: 313.0
Max Reward: 391.0
Gini Coefficient: 0.04824902723735409
20:20 Ratio: 1.2492012779552715
Max-min Ratio: 1.2492012779552715
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_12-52-57
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1975.0
  episode_reward_mean: 1499.76
  episode_reward_min: -17557.0
  episodes_this_iter: 1
  episodes_total: 225
  experiment_id: ebedc1946062457bb682d57fae83bd74
  hostname: gpu052
  info:
    apply_time_ms: 4.088
    dispatch_time_ms: 7.215
    learner:
      cur_lr: 0.0012850749772042036
      grad_gnorm: 40.00000762939453
      policy_entropy: 13.999931335449219
      policy_loss: 0.4685712456703186
      var_gnorm: 35.726158142089844
      vf_explained_var: 0.6082180738449097
      vf_loss: 60.60060501098633
    num_steps_sampled: 1130000
    num_steps_trained: 1130000
    wait_time_ms: 132.354
  iterations_since_restore: 226
  node_ip: 172.17.8.52
  num_metric_batches_dropped: 0
  pid: 12141
  policy_reward_mean: {}
  time_since_restore: 3152.9119250774384
  time_this_iter_s: 13.3816659450531
  time_total_s: 3152.9119250774384
  timestamp: 1594140777
  timesteps_since_restore: 1130000
  timesteps_this_iter: 5000
  timesteps_total: 1130000
  training_iteration: 226
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 33.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=12141], 3152 s, 226 iter, 1130000 ts, 1.5e+03 rew

agent-1: 311.0
agent-2: 293.0
agent-3: 348.0
agent-4: 386.0
agent-5: 346.0
Sum Reward: 1684.0
Avg Reward: 336.8
Min Reward: 293.0
Max Reward: 386.0
Gini Coefficient: 0.05296912114014252
20:20 Ratio: 1.31740614334471
Max-min Ratio: 1.31740614334471
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_12-53-12
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1975.0
  episode_reward_mean: 1501.28
  episode_reward_min: -17557.0
  episodes_this_iter: 1
  episodes_total: 226
  experiment_id: ebedc1946062457bb682d57fae83bd74
  hostname: gpu052
  info:
    apply_time_ms: 2.595
    dispatch_time_ms: 6.925
    learner:
      cur_lr: 0.0012847420293837786
      grad_gnorm: 39.99999237060547
      policy_entropy: 14.079984664916992
      policy_loss: -5.022672176361084
      var_gnorm: 35.78253936767578
      vf_explained_var: 0.5736258625984192
      vf_loss: 15.06889820098877
    num_steps_sampled: 1135000
    num_steps_trained: 1135000
    wait_time_ms: 135.345
  iterations_since_restore: 227
  node_ip: 172.17.8.52
  num_metric_batches_dropped: 0
  pid: 12141
  policy_reward_mean: {}
  time_since_restore: 3167.8852303028107
  time_this_iter_s: 14.973305225372314
  time_total_s: 3167.8852303028107
  timestamp: 1594140792
  timesteps_since_restore: 1135000
  timesteps_this_iter: 5000
  timesteps_total: 1135000
  training_iteration: 227
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 33.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=12141], 3167 s, 227 iter, 1135000 ts, 1.5e+03 rew

agent-1: 338.0
agent-2: 339.0
agent-3: 292.0
agent-4: 324.0
agent-5: 334.0
Sum Reward: 1627.0
Avg Reward: 325.4
Min Reward: 292.0
Max Reward: 339.0
Gini Coefficient: 0.026551936078672404
20:20 Ratio: 1.1609589041095891
Max-min Ratio: 1.1609589041095891
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_12-53-26
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1975.0
  episode_reward_mean: 1500.22
  episode_reward_min: -17557.0
  episodes_this_iter: 1
  episodes_total: 227
  experiment_id: ebedc1946062457bb682d57fae83bd74
  hostname: gpu052
  info:
    apply_time_ms: 2.651
    dispatch_time_ms: 7.964
    learner:
      cur_lr: 0.0012844089651480317
      grad_gnorm: 39.999977111816406
      policy_entropy: 24.8595027923584
      policy_loss: 28.770639419555664
      var_gnorm: 35.87810134887695
      vf_explained_var: 0.18377405405044556
      vf_loss: 55.43955612182617
    num_steps_sampled: 1140000
    num_steps_trained: 1140000
    wait_time_ms: 127.315
  iterations_since_restore: 228
  node_ip: 172.17.8.52
  num_metric_batches_dropped: 0
  pid: 12141
  policy_reward_mean: {}
  time_since_restore: 3181.7420012950897
  time_this_iter_s: 13.856770992279053
  time_total_s: 3181.7420012950897
  timestamp: 1594140806
  timesteps_since_restore: 1140000
  timesteps_this_iter: 5000
  timesteps_total: 1140000
  training_iteration: 228
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 34.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=12141], 3181 s, 228 iter, 1140000 ts, 1.5e+03 rew

agent-1: 273.0
agent-2: 336.0
agent-3: 318.0
agent-4: 309.0
agent-5: 320.0
Sum Reward: 1556.0
Avg Reward: 311.2
Min Reward: 273.0
Max Reward: 336.0
Gini Coefficient: 0.03521850899742931
20:20 Ratio: 1.2307692307692308
Max-min Ratio: 1.2307692307692308
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_12-53-41
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1975.0
  episode_reward_mean: 1499.02
  episode_reward_min: -17557.0
  episodes_this_iter: 1
  episodes_total: 228
  experiment_id: ebedc1946062457bb682d57fae83bd74
  hostname: gpu052
  info:
    apply_time_ms: 3.461
    dispatch_time_ms: 6.686
    learner:
      cur_lr: 0.0012840760173276067
      grad_gnorm: 40.0
      policy_entropy: 25.21752166748047
      policy_loss: 4.574192523956299
      var_gnorm: 35.871734619140625
      vf_explained_var: 0.28052473068237305
      vf_loss: 30.854782104492188
    num_steps_sampled: 1145000
    num_steps_trained: 1145000
    wait_time_ms: 124.981
  iterations_since_restore: 229
  node_ip: 172.17.8.52
  num_metric_batches_dropped: 0
  pid: 12141
  policy_reward_mean: {}
  time_since_restore: 3196.4138371944427
  time_this_iter_s: 14.671835899353027
  time_total_s: 3196.4138371944427
  timestamp: 1594140821
  timesteps_since_restore: 1145000
  timesteps_this_iter: 5000
  timesteps_total: 1145000
  training_iteration: 229
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 33.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=12141], 3196 s, 229 iter, 1145000 ts, 1.5e+03 rew

agent-1: 330.0
agent-2: 373.0
agent-3: 361.0
agent-4: 383.0
agent-5: 407.0
Sum Reward: 1854.0
Avg Reward: 370.8
Min Reward: 330.0
Max Reward: 407.0
Gini Coefficient: 0.03797195253505933
20:20 Ratio: 1.2333333333333334
Max-min Ratio: 1.2333333333333334
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_12-53-54
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1975.0
  episode_reward_mean: 1498.06
  episode_reward_min: -17557.0
  episodes_this_iter: 1
  episodes_total: 229
  experiment_id: ebedc1946062457bb682d57fae83bd74
  hostname: gpu052
  info:
    apply_time_ms: 3.073
    dispatch_time_ms: 7.591
    learner:
      cur_lr: 0.0012837429530918598
      grad_gnorm: 40.0
      policy_entropy: 12.096205711364746
      policy_loss: -5.128097057342529
      var_gnorm: 35.94906997680664
      vf_explained_var: 0.10445117950439453
      vf_loss: 30.63226890563965
    num_steps_sampled: 1150000
    num_steps_trained: 1150000
    wait_time_ms: 129.911
  iterations_since_restore: 230
  node_ip: 172.17.8.52
  num_metric_batches_dropped: 0
  pid: 12141
  policy_reward_mean: {}
  time_since_restore: 3209.846352815628
  time_this_iter_s: 13.432515621185303
  time_total_s: 3209.846352815628
  timestamp: 1594140834
  timesteps_since_restore: 1150000
  timesteps_this_iter: 5000
  timesteps_total: 1150000
  training_iteration: 230
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 33.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=12141], 3209 s, 230 iter, 1150000 ts, 1.5e+03 rew

agent-1: 344.0
agent-2: 338.0
agent-3: 374.0
agent-4: 360.0
agent-5: 317.0
Sum Reward: 1733.0
Avg Reward: 346.6
Min Reward: 317.0
Max Reward: 374.0
Gini Coefficient: 0.03139065204847086
20:20 Ratio: 1.1798107255520505
Max-min Ratio: 1.1798107255520505
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_12-54-08
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1975.0
  episode_reward_mean: 1496.53
  episode_reward_min: -17557.0
  episodes_this_iter: 1
  episodes_total: 230
  experiment_id: ebedc1946062457bb682d57fae83bd74
  hostname: gpu052
  info:
    apply_time_ms: 2.885
    dispatch_time_ms: 7.671
    learner:
      cur_lr: 0.0012834100052714348
      grad_gnorm: 40.00000762939453
      policy_entropy: 17.38135528564453
      policy_loss: -3.43782377243042
      var_gnorm: 36.0366325378418
      vf_explained_var: 0.8997530341148376
      vf_loss: 29.22318458557129
    num_steps_sampled: 1155000
    num_steps_trained: 1155000
    wait_time_ms: 112.809
  iterations_since_restore: 231
  node_ip: 172.17.8.52
  num_metric_batches_dropped: 0
  pid: 12141
  policy_reward_mean: {}
  time_since_restore: 3223.774474620819
  time_this_iter_s: 13.92812180519104
  time_total_s: 3223.774474620819
  timestamp: 1594140848
  timesteps_since_restore: 1155000
  timesteps_this_iter: 5000
  timesteps_total: 1155000
  training_iteration: 231
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 33.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=12141], 3223 s, 231 iter, 1155000 ts, 1.5e+03 rew

agent-1: 389.0
agent-2: 365.0
agent-3: 327.0
agent-4: 371.0
agent-5: 395.0
Sum Reward: 1847.0
Avg Reward: 369.4
Min Reward: 327.0
Max Reward: 395.0
Gini Coefficient: 0.034650785056848946
20:20 Ratio: 1.2079510703363914
Max-min Ratio: 1.2079510703363914
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_12-54-22
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1975.0
  episode_reward_mean: 1496.85
  episode_reward_min: -17557.0
  episodes_this_iter: 1
  episodes_total: 231
  experiment_id: ebedc1946062457bb682d57fae83bd74
  hostname: gpu052
  info:
    apply_time_ms: 3.046
    dispatch_time_ms: 6.345
    learner:
      cur_lr: 0.0012830770574510098
      grad_gnorm: 40.0
      policy_entropy: 18.29203224182129
      policy_loss: 2.2820565700531006
      var_gnorm: 36.1065673828125
      vf_explained_var: -1.0
      vf_loss: 58.1016845703125
    num_steps_sampled: 1160000
    num_steps_trained: 1160000
    wait_time_ms: 136.098
  iterations_since_restore: 232
  node_ip: 172.17.8.52
  num_metric_batches_dropped: 0
  pid: 12141
  policy_reward_mean: {}
  time_since_restore: 3237.227100610733
  time_this_iter_s: 13.45262598991394
  time_total_s: 3237.227100610733
  timestamp: 1594140862
  timesteps_since_restore: 1160000
  timesteps_this_iter: 5000
  timesteps_total: 1160000
  training_iteration: 232
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 33.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=12141], 3237 s, 232 iter, 1160000 ts, 1.5e+03 rew

agent-1: 376.0
agent-2: 335.0
agent-3: 370.0
agent-4: 372.0
agent-5: 356.0
Sum Reward: 1809.0
Avg Reward: 361.8
Min Reward: 335.0
Max Reward: 376.0
Gini Coefficient: 0.021669430624654505
20:20 Ratio: 1.1223880597014926
Max-min Ratio: 1.1223880597014926
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_12-54-36
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1975.0
  episode_reward_mean: 1497.44
  episode_reward_min: -17557.0
  episodes_this_iter: 1
  episodes_total: 232
  experiment_id: ebedc1946062457bb682d57fae83bd74
  hostname: gpu052
  info:
    apply_time_ms: 2.659
    dispatch_time_ms: 7.808
    learner:
      cur_lr: 0.0012827439932152629
      grad_gnorm: 40.0
      policy_entropy: 14.167013168334961
      policy_loss: 8.210305213928223
      var_gnorm: 36.14268493652344
      vf_explained_var: 0.333327054977417
      vf_loss: 35.86940002441406
    num_steps_sampled: 1165000
    num_steps_trained: 1165000
    wait_time_ms: 129.985
  iterations_since_restore: 233
  node_ip: 172.17.8.52
  num_metric_batches_dropped: 0
  pid: 12141
  policy_reward_mean: {}
  time_since_restore: 3251.6797857284546
  time_this_iter_s: 14.452685117721558
  time_total_s: 3251.6797857284546
  timestamp: 1594140876
  timesteps_since_restore: 1165000
  timesteps_this_iter: 5000
  timesteps_total: 1165000
  training_iteration: 233
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 33.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=12141], 3251 s, 233 iter, 1165000 ts, 1.5e+03 rew

agent-1: 357.0
agent-2: 340.0
agent-3: 372.0
agent-4: 341.0
agent-5: 371.0
Sum Reward: 1781.0
Avg Reward: 356.2
Min Reward: 340.0
Max Reward: 372.0
Gini Coefficient: 0.02111173498034812
20:20 Ratio: 1.0941176470588236
Max-min Ratio: 1.0941176470588236
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_12-54-50
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1975.0
  episode_reward_mean: 1496.53
  episode_reward_min: -17557.0
  episodes_this_iter: 1
  episodes_total: 233
  experiment_id: ebedc1946062457bb682d57fae83bd74
  hostname: gpu052
  info:
    apply_time_ms: 3.323
    dispatch_time_ms: 6.075
    learner:
      cur_lr: 0.0012824110453948379
      grad_gnorm: 40.0000114440918
      policy_entropy: 21.493118286132812
      policy_loss: -10.966489791870117
      var_gnorm: 36.19462585449219
      vf_explained_var: 0.045174479484558105
      vf_loss: 26.136980056762695
    num_steps_sampled: 1170000
    num_steps_trained: 1170000
    wait_time_ms: 137.645
  iterations_since_restore: 234
  node_ip: 172.17.8.52
  num_metric_batches_dropped: 0
  pid: 12141
  policy_reward_mean: {}
  time_since_restore: 3265.344123840332
  time_this_iter_s: 13.664338111877441
  time_total_s: 3265.344123840332
  timestamp: 1594140890
  timesteps_since_restore: 1170000
  timesteps_this_iter: 5000
  timesteps_total: 1170000
  training_iteration: 234
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 33.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=12141], 3265 s, 234 iter, 1170000 ts, 1.5e+03 rew

agent-1: 328.0
agent-2: 303.0
agent-3: 288.0
agent-4: 343.0
agent-5: 339.0
Sum Reward: 1601.0
Avg Reward: 320.2
Min Reward: 288.0
Max Reward: 343.0
Gini Coefficient: 0.03647720174890693
20:20 Ratio: 1.1909722222222223
Max-min Ratio: 1.1909722222222223
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_12-55-05
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1975.0
  episode_reward_mean: 1494.0
  episode_reward_min: -17557.0
  episodes_this_iter: 1
  episodes_total: 234
  experiment_id: ebedc1946062457bb682d57fae83bd74
  hostname: gpu052
  info:
    apply_time_ms: 2.955
    dispatch_time_ms: 6.71
    learner:
      cur_lr: 0.001282077981159091
      grad_gnorm: 40.000003814697266
      policy_entropy: 17.278034210205078
      policy_loss: -6.318378448486328
      var_gnorm: 36.22864532470703
      vf_explained_var: 0.40991640090942383
      vf_loss: 57.50655746459961
    num_steps_sampled: 1175000
    num_steps_trained: 1175000
    wait_time_ms: 124.05
  iterations_since_restore: 235
  node_ip: 172.17.8.52
  num_metric_batches_dropped: 0
  pid: 12141
  policy_reward_mean: {}
  time_since_restore: 3280.0297729969025
  time_this_iter_s: 14.685649156570435
  time_total_s: 3280.0297729969025
  timestamp: 1594140905
  timesteps_since_restore: 1175000
  timesteps_this_iter: 5000
  timesteps_total: 1175000
  training_iteration: 235
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 34.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=12141], 3280 s, 235 iter, 1175000 ts, 1.49e+03 rew

agent-1: 377.0
agent-2: 369.0
agent-3: 336.0
agent-4: 364.0
agent-5: 322.0
Sum Reward: 1768.0
Avg Reward: 353.6
Min Reward: 322.0
Max Reward: 377.0
Gini Coefficient: 0.03235294117647059
20:20 Ratio: 1.170807453416149
Max-min Ratio: 1.170807453416149
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_12-55-18
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1975.0
  episode_reward_mean: 1494.15
  episode_reward_min: -17557.0
  episodes_this_iter: 1
  episodes_total: 235
  experiment_id: ebedc1946062457bb682d57fae83bd74
  hostname: gpu052
  info:
    apply_time_ms: 2.984
    dispatch_time_ms: 7.055
    learner:
      cur_lr: 0.001281745033338666
      grad_gnorm: 40.0
      policy_entropy: 20.736309051513672
      policy_loss: -0.3199501037597656
      var_gnorm: 36.30413818359375
      vf_explained_var: 0.16858577728271484
      vf_loss: 60.352718353271484
    num_steps_sampled: 1180000
    num_steps_trained: 1180000
    wait_time_ms: 136.037
  iterations_since_restore: 236
  node_ip: 172.17.8.52
  num_metric_batches_dropped: 0
  pid: 12141
  policy_reward_mean: {}
  time_since_restore: 3293.425764799118
  time_this_iter_s: 13.395991802215576
  time_total_s: 3293.425764799118
  timestamp: 1594140918
  timesteps_since_restore: 1180000
  timesteps_this_iter: 5000
  timesteps_total: 1180000
  training_iteration: 236
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 33.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=12141], 3293 s, 236 iter, 1180000 ts, 1.49e+03 rew

agent-1: 357.0
agent-2: 367.0
agent-3: 313.0
agent-4: 313.0
agent-5: 349.0
Sum Reward: 1699.0
Avg Reward: 339.8
Min Reward: 313.0
Max Reward: 367.0
Gini Coefficient: 0.035785756327251325
20:20 Ratio: 1.1725239616613419
Max-min Ratio: 1.1725239616613419
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_12-55-33
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1975.0
  episode_reward_mean: 1495.02
  episode_reward_min: -17557.0
  episodes_this_iter: 1
  episodes_total: 236
  experiment_id: ebedc1946062457bb682d57fae83bd74
  hostname: gpu052
  info:
    apply_time_ms: 2.716
    dispatch_time_ms: 8.0
    learner:
      cur_lr: 0.001281411969102919
      grad_gnorm: 40.0
      policy_entropy: 26.90497398376465
      policy_loss: -15.968343734741211
      var_gnorm: 36.37730026245117
      vf_explained_var: 0.7418547868728638
      vf_loss: 115.57344055175781
    num_steps_sampled: 1185000
    num_steps_trained: 1185000
    wait_time_ms: 136.916
  iterations_since_restore: 237
  node_ip: 172.17.8.52
  num_metric_batches_dropped: 0
  pid: 12141
  policy_reward_mean: {}
  time_since_restore: 3308.1661717891693
  time_this_iter_s: 14.74040699005127
  time_total_s: 3308.1661717891693
  timestamp: 1594140933
  timesteps_since_restore: 1185000
  timesteps_this_iter: 5000
  timesteps_total: 1185000
  training_iteration: 237
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 33.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=12141], 3308 s, 237 iter, 1185000 ts, 1.5e+03 rew

agent-1: 392.0
agent-2: 344.0
agent-3: 302.0
agent-4: 366.0
agent-5: 301.0
Sum Reward: 1705.0
Avg Reward: 341.0
Min Reward: 301.0
Max Reward: 392.0
Gini Coefficient: 0.05771260997067449
20:20 Ratio: 1.302325581395349
Max-min Ratio: 1.302325581395349
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_12-55-46
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1975.0
  episode_reward_mean: 1496.74
  episode_reward_min: -17557.0
  episodes_this_iter: 1
  episodes_total: 237
  experiment_id: ebedc1946062457bb682d57fae83bd74
  hostname: gpu052
  info:
    apply_time_ms: 2.907
    dispatch_time_ms: 6.104
    learner:
      cur_lr: 0.001281079021282494
      grad_gnorm: 40.00000762939453
      policy_entropy: 19.9942684173584
      policy_loss: -4.46070671081543
      var_gnorm: 36.41709899902344
      vf_explained_var: 0.8099459409713745
      vf_loss: 23.888154983520508
    num_steps_sampled: 1190000
    num_steps_trained: 1190000
    wait_time_ms: 137.943
  iterations_since_restore: 238
  node_ip: 172.17.8.52
  num_metric_batches_dropped: 0
  pid: 12141
  policy_reward_mean: {}
  time_since_restore: 3321.55850481987
  time_this_iter_s: 13.392333030700684
  time_total_s: 3321.55850481987
  timestamp: 1594140946
  timesteps_since_restore: 1190000
  timesteps_this_iter: 5000
  timesteps_total: 1190000
  training_iteration: 238
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 34.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=12141], 3321 s, 238 iter, 1190000 ts, 1.5e+03 rew

agent-1: 325.0
agent-2: 391.0
agent-3: 282.0
agent-4: 330.0
agent-5: 287.0
Sum Reward: 1615.0
Avg Reward: 323.0
Min Reward: 282.0
Max Reward: 391.0
Gini Coefficient: 0.06464396284829721
20:20 Ratio: 1.3865248226950355
Max-min Ratio: 1.3865248226950355
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_12-56-00
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1975.0
  episode_reward_mean: 1497.33
  episode_reward_min: -17557.0
  episodes_this_iter: 1
  episodes_total: 238
  experiment_id: ebedc1946062457bb682d57fae83bd74
  hostname: gpu052
  info:
    apply_time_ms: 3.126
    dispatch_time_ms: 7.07
    learner:
      cur_lr: 0.0012807459570467472
      grad_gnorm: 40.0000114440918
      policy_entropy: 20.87625503540039
      policy_loss: 3.7204360961914062
      var_gnorm: 36.44064712524414
      vf_explained_var: 0.18629127740859985
      vf_loss: 82.41766357421875
    num_steps_sampled: 1195000
    num_steps_trained: 1195000
    wait_time_ms: 124.149
  iterations_since_restore: 239
  node_ip: 172.17.8.52
  num_metric_batches_dropped: 0
  pid: 12141
  policy_reward_mean: {}
  time_since_restore: 3335.639932870865
  time_this_iter_s: 14.081428050994873
  time_total_s: 3335.639932870865
  timestamp: 1594140960
  timesteps_since_restore: 1195000
  timesteps_this_iter: 5000
  timesteps_total: 1195000
  training_iteration: 239
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 34.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=12141], 3335 s, 239 iter, 1195000 ts, 1.5e+03 rew

agent-1: 297.0
agent-2: 359.0
agent-3: 333.0
agent-4: 327.0
agent-5: 361.0
Sum Reward: 1677.0
Avg Reward: 335.4
Min Reward: 297.0
Max Reward: 361.0
Gini Coefficient: 0.0381633870005963
20:20 Ratio: 1.2154882154882154
Max-min Ratio: 1.2154882154882154
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_12-56-14
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1975.0
  episode_reward_mean: 1495.66
  episode_reward_min: -17557.0
  episodes_this_iter: 1
  episodes_total: 239
  experiment_id: ebedc1946062457bb682d57fae83bd74
  hostname: gpu052
  info:
    apply_time_ms: 2.564
    dispatch_time_ms: 5.546
    learner:
      cur_lr: 0.0012804130092263222
      grad_gnorm: 40.00000762939453
      policy_entropy: 17.554214477539062
      policy_loss: -21.43547248840332
      var_gnorm: 36.44889450073242
      vf_explained_var: -0.3631470203399658
      vf_loss: 96.22576141357422
    num_steps_sampled: 1200000
    num_steps_trained: 1200000
    wait_time_ms: 140.42
  iterations_since_restore: 240
  node_ip: 172.17.8.52
  num_metric_batches_dropped: 0
  pid: 12141
  policy_reward_mean: {}
  time_since_restore: 3348.9878549575806
  time_this_iter_s: 13.347922086715698
  time_total_s: 3348.9878549575806
  timestamp: 1594140974
  timesteps_since_restore: 1200000
  timesteps_this_iter: 5000
  timesteps_total: 1200000
  training_iteration: 240
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 34.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=12141], 3348 s, 240 iter, 1200000 ts, 1.5e+03 rew

agent-1: 325.0
agent-2: 305.0
agent-3: 286.0
agent-4: 273.0
agent-5: 315.0
Sum Reward: 1504.0
Avg Reward: 300.8
Min Reward: 273.0
Max Reward: 325.0
Gini Coefficient: 0.03537234042553192
20:20 Ratio: 1.1904761904761905
Max-min Ratio: 1.1904761904761905
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_12-56-29
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1975.0
  episode_reward_mean: 1493.53
  episode_reward_min: -17557.0
  episodes_this_iter: 1
  episodes_total: 240
  experiment_id: ebedc1946062457bb682d57fae83bd74
  hostname: gpu052
  info:
    apply_time_ms: 4.683
    dispatch_time_ms: 6.918
    learner:
      cur_lr: 0.0012800799449905753
      grad_gnorm: 40.0
      policy_entropy: 22.52406120300293
      policy_loss: -2.0747790336608887
      var_gnorm: 36.45234298706055
      vf_explained_var: -0.01245415210723877
      vf_loss: 23.22271156311035
    num_steps_sampled: 1205000
    num_steps_trained: 1205000
    wait_time_ms: 118.343
  iterations_since_restore: 241
  node_ip: 172.17.8.52
  num_metric_batches_dropped: 0
  pid: 12141
  policy_reward_mean: {}
  time_since_restore: 3363.7329502105713
  time_this_iter_s: 14.745095252990723
  time_total_s: 3363.7329502105713
  timestamp: 1594140989
  timesteps_since_restore: 1205000
  timesteps_this_iter: 5000
  timesteps_total: 1205000
  training_iteration: 241
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 34.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=12141], 3363 s, 241 iter, 1205000 ts, 1.49e+03 rew

agent-1: 309.0
agent-2: 257.0
agent-3: 341.0
agent-4: 343.0
agent-5: 294.0
Sum Reward: 1544.0
Avg Reward: 308.8
Min Reward: 257.0
Max Reward: 343.0
Gini Coefficient: 0.05673575129533679
20:20 Ratio: 1.3346303501945525
Max-min Ratio: 1.3346303501945525
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_12-56-42
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1931.0
  episode_reward_mean: 1489.22
  episode_reward_min: -17557.0
  episodes_this_iter: 1
  episodes_total: 241
  experiment_id: ebedc1946062457bb682d57fae83bd74
  hostname: gpu052
  info:
    apply_time_ms: 3.821
    dispatch_time_ms: 7.461
    learner:
      cur_lr: 0.0012797469971701503
      grad_gnorm: 39.999996185302734
      policy_entropy: 12.384368896484375
      policy_loss: -11.08378791809082
      var_gnorm: 36.4825439453125
      vf_explained_var: 0.4782096743583679
      vf_loss: 77.1365966796875
    num_steps_sampled: 1210000
    num_steps_trained: 1210000
    wait_time_ms: 130.571
  iterations_since_restore: 242
  node_ip: 172.17.8.52
  num_metric_batches_dropped: 0
  pid: 12141
  policy_reward_mean: {}
  time_since_restore: 3376.7351949214935
  time_this_iter_s: 13.002244710922241
  time_total_s: 3376.7351949214935
  timestamp: 1594141002
  timesteps_since_restore: 1210000
  timesteps_this_iter: 5000
  timesteps_total: 1210000
  training_iteration: 242
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 34.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=12141], 3376 s, 242 iter, 1210000 ts, 1.49e+03 rew

agent-1: 330.0
agent-2: 301.0
agent-3: 248.0
agent-4: 340.0
agent-5: 336.0
Sum Reward: 1555.0
Avg Reward: 311.0
Min Reward: 248.0
Max Reward: 340.0
Gini Coefficient: 0.05633440514469453
20:20 Ratio: 1.3709677419354838
Max-min Ratio: 1.3709677419354838
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_12-56-56
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1931.0
  episode_reward_mean: 1487.43
  episode_reward_min: -17557.0
  episodes_this_iter: 1
  episodes_total: 242
  experiment_id: ebedc1946062457bb682d57fae83bd74
  hostname: gpu052
  info:
    apply_time_ms: 3.19
    dispatch_time_ms: 6.939
    learner:
      cur_lr: 0.0012794140493497252
      grad_gnorm: 40.00000762939453
      policy_entropy: 18.132904052734375
      policy_loss: 24.13300132751465
      var_gnorm: 36.54792785644531
      vf_explained_var: -0.13923954963684082
      vf_loss: 74.77125549316406
    num_steps_sampled: 1215000
    num_steps_trained: 1215000
    wait_time_ms: 117.287
  iterations_since_restore: 243
  node_ip: 172.17.8.52
  num_metric_batches_dropped: 0
  pid: 12141
  policy_reward_mean: {}
  time_since_restore: 3391.2843556404114
  time_this_iter_s: 14.549160718917847
  time_total_s: 3391.2843556404114
  timestamp: 1594141016
  timesteps_since_restore: 1215000
  timesteps_this_iter: 5000
  timesteps_total: 1215000
  training_iteration: 243
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 34.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=12141], 3391 s, 243 iter, 1215000 ts, 1.49e+03 rew

agent-1: 300.0
agent-2: 384.0
agent-3: 362.0
agent-4: 334.0
agent-5: 341.0
Sum Reward: 1721.0
Avg Reward: 344.2
Min Reward: 300.0
Max Reward: 384.0
Gini Coefficient: 0.04555490993608367
20:20 Ratio: 1.28
Max-min Ratio: 1.28
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_12-57-10
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1931.0
  episode_reward_mean: 1488.39
  episode_reward_min: -17557.0
  episodes_this_iter: 1
  episodes_total: 243
  experiment_id: ebedc1946062457bb682d57fae83bd74
  hostname: gpu052
  info:
    apply_time_ms: 2.543
    dispatch_time_ms: 8.493
    learner:
      cur_lr: 0.0012790809851139784
      grad_gnorm: 40.0
      policy_entropy: 11.403650283813477
      policy_loss: 5.230191707611084
      var_gnorm: 36.61275100708008
      vf_explained_var: 0.6126576662063599
      vf_loss: 54.4605598449707
    num_steps_sampled: 1220000
    num_steps_trained: 1220000
    wait_time_ms: 128.801
  iterations_since_restore: 244
  node_ip: 172.17.8.52
  num_metric_batches_dropped: 0
  pid: 12141
  policy_reward_mean: {}
  time_since_restore: 3404.8580746650696
  time_this_iter_s: 13.573719024658203
  time_total_s: 3404.8580746650696
  timestamp: 1594141030
  timesteps_since_restore: 1220000
  timesteps_this_iter: 5000
  timesteps_total: 1220000
  training_iteration: 244
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 34.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=12141], 3404 s, 244 iter, 1220000 ts, 1.49e+03 rew

agent-1: 343.0
agent-2: 302.0
agent-3: 317.0
agent-4: 341.0
agent-5: 371.0
Sum Reward: 1674.0
Avg Reward: 334.8
Min Reward: 302.0
Max Reward: 371.0
Gini Coefficient: 0.03918757467144564
20:20 Ratio: 1.228476821192053
Max-min Ratio: 1.228476821192053
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_12-57-24
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1931.0
  episode_reward_mean: 1488.72
  episode_reward_min: -17557.0
  episodes_this_iter: 1
  episodes_total: 244
  experiment_id: ebedc1946062457bb682d57fae83bd74
  hostname: gpu052
  info:
    apply_time_ms: 2.884
    dispatch_time_ms: 6.986
    learner:
      cur_lr: 0.0012787480372935534
      grad_gnorm: 40.00000762939453
      policy_entropy: 11.160460472106934
      policy_loss: 1.6182175874710083
      var_gnorm: 36.67378234863281
      vf_explained_var: -0.012105464935302734
      vf_loss: 48.28638458251953
    num_steps_sampled: 1225000
    num_steps_trained: 1225000
    wait_time_ms: 115.302
  iterations_since_restore: 245
  node_ip: 172.17.8.52
  num_metric_batches_dropped: 0
  pid: 12141
  policy_reward_mean: {}
  time_since_restore: 3419.4846136569977
  time_this_iter_s: 14.6265389919281
  time_total_s: 3419.4846136569977
  timestamp: 1594141044
  timesteps_since_restore: 1225000
  timesteps_this_iter: 5000
  timesteps_total: 1225000
  training_iteration: 245
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 33.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=12141], 3419 s, 245 iter, 1225000 ts, 1.49e+03 rew

agent-1: 360.0
agent-2: 381.0
agent-3: 367.0
agent-4: 383.0
agent-5: 389.0
Sum Reward: 1880.0
Avg Reward: 376.0
Min Reward: 360.0
Max Reward: 389.0
Gini Coefficient: 0.01574468085106383
20:20 Ratio: 1.0805555555555555
Max-min Ratio: 1.0805555555555555
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_12-57-37
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1931.0
  episode_reward_mean: 1491.72
  episode_reward_min: -17557.0
  episodes_this_iter: 1
  episodes_total: 245
  experiment_id: ebedc1946062457bb682d57fae83bd74
  hostname: gpu052
  info:
    apply_time_ms: 2.679
    dispatch_time_ms: 7.483
    learner:
      cur_lr: 0.0012784149730578065
      grad_gnorm: 24.651391983032227
      policy_entropy: 7.122862339019775
      policy_loss: 2.487661361694336
      var_gnorm: 36.751609802246094
      vf_explained_var: 0.40554219484329224
      vf_loss: 75.45516204833984
    num_steps_sampled: 1230000
    num_steps_trained: 1230000
    wait_time_ms: 124.523
  iterations_since_restore: 246
  node_ip: 172.17.8.52
  num_metric_batches_dropped: 0
  pid: 12141
  policy_reward_mean: {}
  time_since_restore: 3432.4129939079285
  time_this_iter_s: 12.928380250930786
  time_total_s: 3432.4129939079285
  timestamp: 1594141057
  timesteps_since_restore: 1230000
  timesteps_this_iter: 5000
  timesteps_total: 1230000
  training_iteration: 246
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 34.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=12141], 3432 s, 246 iter, 1230000 ts, 1.49e+03 rew

agent-1: 354.0
agent-2: 338.0
agent-3: 338.0
agent-4: 429.0
agent-5: 327.0
Sum Reward: 1786.0
Avg Reward: 357.2
Min Reward: 327.0
Max Reward: 429.0
Gini Coefficient: 0.04927211646136618
20:20 Ratio: 1.311926605504587
Max-min Ratio: 1.311926605504587
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_12-57-51
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1931.0
  episode_reward_mean: 1493.08
  episode_reward_min: -17557.0
  episodes_this_iter: 1
  episodes_total: 246
  experiment_id: ebedc1946062457bb682d57fae83bd74
  hostname: gpu052
  info:
    apply_time_ms: 3.549
    dispatch_time_ms: 6.508
    learner:
      cur_lr: 0.0012780820252373815
      grad_gnorm: 39.999996185302734
      policy_entropy: 8.807794570922852
      policy_loss: 7.272671699523926
      var_gnorm: 36.74740219116211
      vf_explained_var: 0.5302931666374207
      vf_loss: 46.93058776855469
    num_steps_sampled: 1235000
    num_steps_trained: 1235000
    wait_time_ms: 125.114
  iterations_since_restore: 247
  node_ip: 172.17.8.52
  num_metric_batches_dropped: 0
  pid: 12141
  policy_reward_mean: {}
  time_since_restore: 3445.7146723270416
  time_this_iter_s: 13.30167841911316
  time_total_s: 3445.7146723270416
  timestamp: 1594141071
  timesteps_since_restore: 1235000
  timesteps_this_iter: 5000
  timesteps_total: 1235000
  training_iteration: 247
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 33.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=12141], 3445 s, 247 iter, 1235000 ts, 1.49e+03 rew

agent-1: 391.0
agent-2: 355.0
agent-3: 344.0
agent-4: 330.0
agent-5: 356.0
Sum Reward: 1776.0
Avg Reward: 355.2
Min Reward: 330.0
Max Reward: 391.0
Gini Coefficient: 0.03018018018018018
20:20 Ratio: 1.1848484848484848
Max-min Ratio: 1.1848484848484848
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_12-58-04
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1931.0
  episode_reward_mean: 1492.54
  episode_reward_min: -17557.0
  episodes_this_iter: 1
  episodes_total: 247
  experiment_id: ebedc1946062457bb682d57fae83bd74
  hostname: gpu052
  info:
    apply_time_ms: 2.668
    dispatch_time_ms: 5.775
    learner:
      cur_lr: 0.0012777489610016346
      grad_gnorm: 40.000003814697266
      policy_entropy: 28.475759506225586
      policy_loss: -20.480316162109375
      var_gnorm: 36.85417556762695
      vf_explained_var: 0.3693627119064331
      vf_loss: 84.56194305419922
    num_steps_sampled: 1240000
    num_steps_trained: 1240000
    wait_time_ms: 116.14
  iterations_since_restore: 248
  node_ip: 172.17.8.52
  num_metric_batches_dropped: 0
  pid: 12141
  policy_reward_mean: {}
  time_since_restore: 3458.7488131523132
  time_this_iter_s: 13.034140825271606
  time_total_s: 3458.7488131523132
  timestamp: 1594141084
  timesteps_since_restore: 1240000
  timesteps_this_iter: 5000
  timesteps_total: 1240000
  training_iteration: 248
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 34.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=12141], 3458 s, 248 iter, 1240000 ts, 1.49e+03 rew

agent-1: 127.0
agent-2: 172.0
agent-3: 249.0
agent-4: 355.0
agent-5: 346.0
Sum Reward: 1249.0
Avg Reward: 249.8
Min Reward: 127.0
Max Reward: 355.0
Gini Coefficient: 0.20176140912730184
20:20 Ratio: 2.795275590551181
Max-min Ratio: 2.795275590551181
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_12-58-16
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1931.0
  episode_reward_mean: 1490.25
  episode_reward_min: -17557.0
  episodes_this_iter: 1
  episodes_total: 248
  experiment_id: ebedc1946062457bb682d57fae83bd74
  hostname: gpu052
  info:
    apply_time_ms: 2.741
    dispatch_time_ms: 6.742
    learner:
      cur_lr: 0.0012774160131812096
      grad_gnorm: 40.00000762939453
      policy_entropy: 31.204139709472656
      policy_loss: 22.036815643310547
      var_gnorm: 36.894351959228516
      vf_explained_var: -0.018702983856201172
      vf_loss: 112.54214477539062
    num_steps_sampled: 1245000
    num_steps_trained: 1245000
    wait_time_ms: 106.944
  iterations_since_restore: 249
  node_ip: 172.17.8.52
  num_metric_batches_dropped: 0
  pid: 12141
  policy_reward_mean: {}
  time_since_restore: 3470.891117334366
  time_this_iter_s: 12.142304182052612
  time_total_s: 3470.891117334366
  timestamp: 1594141096
  timesteps_since_restore: 1245000
  timesteps_this_iter: 5000
  timesteps_total: 1245000
  training_iteration: 249
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 34.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=12141], 3470 s, 249 iter, 1245000 ts, 1.49e+03 rew

agent-1: 244.0
agent-2: 342.0
agent-3: 282.0
agent-4: 310.0
agent-5: 270.0
Sum Reward: 1448.0
Avg Reward: 289.6
Min Reward: 244.0
Max Reward: 342.0
Gini Coefficient: 0.06519337016574586
20:20 Ratio: 1.401639344262295
Max-min Ratio: 1.401639344262295
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_12-58-29
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1931.0
  episode_reward_mean: 1485.72
  episode_reward_min: -17557.0
  episodes_this_iter: 1
  episodes_total: 249
  experiment_id: ebedc1946062457bb682d57fae83bd74
  hostname: gpu052
  info:
    apply_time_ms: 2.599
    dispatch_time_ms: 5.418
    learner:
      cur_lr: 0.0012770829489454627
      grad_gnorm: 40.0
      policy_entropy: 21.441795349121094
      policy_loss: 16.432327270507812
      var_gnorm: 36.923797607421875
      vf_explained_var: 0.29605287313461304
      vf_loss: 33.875885009765625
    num_steps_sampled: 1250000
    num_steps_trained: 1250000
    wait_time_ms: 123.666
  iterations_since_restore: 250
  node_ip: 172.17.8.52
  num_metric_batches_dropped: 0
  pid: 12141
  policy_reward_mean: {}
  time_since_restore: 3483.404316663742
  time_this_iter_s: 12.51319932937622
  time_total_s: 3483.404316663742
  timestamp: 1594141109
  timesteps_since_restore: 1250000
  timesteps_this_iter: 5000
  timesteps_total: 1250000
  training_iteration: 250
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 33.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=12141], 3483 s, 250 iter, 1250000 ts, 1.49e+03 rew

agent-1: 319.0
agent-2: 339.0
agent-3: 294.0
agent-4: 377.0
agent-5: 357.0
Sum Reward: 1686.0
Avg Reward: 337.2
Min Reward: 294.0
Max Reward: 377.0
Gini Coefficient: 0.048398576512455514
20:20 Ratio: 1.282312925170068
Max-min Ratio: 1.282312925170068
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_12-58-42
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1931.0
  episode_reward_mean: 1485.73
  episode_reward_min: -17557.0
  episodes_this_iter: 1
  episodes_total: 250
  experiment_id: ebedc1946062457bb682d57fae83bd74
  hostname: gpu052
  info:
    apply_time_ms: 2.844
    dispatch_time_ms: 6.656
    learner:
      cur_lr: 0.0012767500011250377
      grad_gnorm: 40.0
      policy_entropy: 16.58391571044922
      policy_loss: 9.730924606323242
      var_gnorm: 36.951480865478516
      vf_explained_var: 0.014289617538452148
      vf_loss: 47.333030700683594
    num_steps_sampled: 1255000
    num_steps_trained: 1255000
    wait_time_ms: 127.497
  iterations_since_restore: 251
  node_ip: 172.17.8.52
  num_metric_batches_dropped: 0
  pid: 12141
  policy_reward_mean: {}
  time_since_restore: 3496.9951758384705
  time_this_iter_s: 13.590859174728394
  time_total_s: 3496.9951758384705
  timestamp: 1594141122
  timesteps_since_restore: 1255000
  timesteps_this_iter: 5000
  timesteps_total: 1255000
  training_iteration: 251
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 34.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=12141], 3496 s, 251 iter, 1255000 ts, 1.49e+03 rew

agent-1: 315.0
agent-2: 379.0
agent-3: 369.0
agent-4: 332.0
agent-5: 365.0
Sum Reward: 1760.0
Avg Reward: 352.0
Min Reward: 315.0
Max Reward: 379.0
Gini Coefficient: 0.0375
20:20 Ratio: 1.2031746031746031
Max-min Ratio: 1.2031746031746031
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_12-58-56
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1931.0
  episode_reward_mean: 1484.84
  episode_reward_min: -17557.0
  episodes_this_iter: 1
  episodes_total: 251
  experiment_id: ebedc1946062457bb682d57fae83bd74
  hostname: gpu052
  info:
    apply_time_ms: 2.897
    dispatch_time_ms: 10.338
    learner:
      cur_lr: 0.0012764170533046126
      grad_gnorm: 39.99999237060547
      policy_entropy: 17.3060359954834
      policy_loss: -8.831992149353027
      var_gnorm: 37.05025863647461
      vf_explained_var: 0.637541651725769
      vf_loss: 54.95576477050781
    num_steps_sampled: 1260000
    num_steps_trained: 1260000
    wait_time_ms: 123.621
  iterations_since_restore: 252
  node_ip: 172.17.8.52
  num_metric_batches_dropped: 0
  pid: 12141
  policy_reward_mean: {}
  time_since_restore: 3510.372641801834
  time_this_iter_s: 13.377465963363647
  time_total_s: 3510.372641801834
  timestamp: 1594141136
  timesteps_since_restore: 1260000
  timesteps_this_iter: 5000
  timesteps_total: 1260000
  training_iteration: 252
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 33.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=12141], 3510 s, 252 iter, 1260000 ts, 1.48e+03 rew

agent-1: 382.0
agent-2: 399.0
agent-3: 312.0
agent-4: 338.0
agent-5: 358.0
Sum Reward: 1789.0
Avg Reward: 357.8
Min Reward: 312.0
Max Reward: 399.0
Gini Coefficient: 0.04874231414197876
20:20 Ratio: 1.2788461538461537
Max-min Ratio: 1.2788461538461537
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_12-59-09
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1931.0
  episode_reward_mean: 1485.02
  episode_reward_min: -17557.0
  episodes_this_iter: 1
  episodes_total: 252
  experiment_id: ebedc1946062457bb682d57fae83bd74
  hostname: gpu052
  info:
    apply_time_ms: 3.331
    dispatch_time_ms: 7.441
    learner:
      cur_lr: 0.0012760839890688658
      grad_gnorm: 39.999996185302734
      policy_entropy: 25.26767349243164
      policy_loss: -9.401763916015625
      var_gnorm: 37.12266540527344
      vf_explained_var: 0.4472230076789856
      vf_loss: 95.42764282226562
    num_steps_sampled: 1265000
    num_steps_trained: 1265000
    wait_time_ms: 121.764
  iterations_since_restore: 253
  node_ip: 172.17.8.52
  num_metric_batches_dropped: 0
  pid: 12141
  policy_reward_mean: {}
  time_since_restore: 3523.927684545517
  time_this_iter_s: 13.555042743682861
  time_total_s: 3523.927684545517
  timestamp: 1594141149
  timesteps_since_restore: 1265000
  timesteps_this_iter: 5000
  timesteps_total: 1265000
  training_iteration: 253
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 34.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=12141], 3523 s, 253 iter, 1265000 ts, 1.49e+03 rew

agent-1: 323.0
agent-2: 391.0
agent-3: 365.0
agent-4: 328.0
agent-5: 322.0
Sum Reward: 1729.0
Avg Reward: 345.8
Min Reward: 322.0
Max Reward: 391.0
Gini Coefficient: 0.04164256795835743
20:20 Ratio: 1.2142857142857142
Max-min Ratio: 1.2142857142857142
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_12-59-22
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1931.0
  episode_reward_mean: 1485.83
  episode_reward_min: -17557.0
  episodes_this_iter: 1
  episodes_total: 253
  experiment_id: ebedc1946062457bb682d57fae83bd74
  hostname: gpu052
  info:
    apply_time_ms: 3.52
    dispatch_time_ms: 6.587
    learner:
      cur_lr: 0.0012757510412484407
      grad_gnorm: 40.0
      policy_entropy: 14.135332107543945
      policy_loss: 1.490436315536499
      var_gnorm: 37.1812744140625
      vf_explained_var: 0.554408609867096
      vf_loss: 22.991714477539062
    num_steps_sampled: 1270000
    num_steps_trained: 1270000
    wait_time_ms: 126.609
  iterations_since_restore: 254
  node_ip: 172.17.8.52
  num_metric_batches_dropped: 0
  pid: 12141
  policy_reward_mean: {}
  time_since_restore: 3536.816586971283
  time_this_iter_s: 12.888902425765991
  time_total_s: 3536.816586971283
  timestamp: 1594141162
  timesteps_since_restore: 1270000
  timesteps_this_iter: 5000
  timesteps_total: 1270000
  training_iteration: 254
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 34.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=12141], 3536 s, 254 iter, 1270000 ts, 1.49e+03 rew

agent-1: 338.0
agent-2: 370.0
agent-3: 302.0
agent-4: 337.0
agent-5: 347.0
Sum Reward: 1694.0
Avg Reward: 338.8
Min Reward: 302.0
Max Reward: 370.0
Gini Coefficient: 0.03447461629279811
20:20 Ratio: 1.2251655629139073
Max-min Ratio: 1.2251655629139073
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_12-59-35
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1931.0
  episode_reward_mean: 1486.66
  episode_reward_min: -17557.0
  episodes_this_iter: 1
  episodes_total: 254
  experiment_id: ebedc1946062457bb682d57fae83bd74
  hostname: gpu052
  info:
    apply_time_ms: 4.078
    dispatch_time_ms: 6.43
    learner:
      cur_lr: 0.0012754179770126939
      grad_gnorm: 39.999996185302734
      policy_entropy: 24.79259490966797
      policy_loss: -25.734474182128906
      var_gnorm: 37.22256088256836
      vf_explained_var: 0.42988061904907227
      vf_loss: 68.26493072509766
    num_steps_sampled: 1275000
    num_steps_trained: 1275000
    wait_time_ms: 119.371
  iterations_since_restore: 255
  node_ip: 172.17.8.52
  num_metric_batches_dropped: 0
  pid: 12141
  policy_reward_mean: {}
  time_since_restore: 3549.692180633545
  time_this_iter_s: 12.875593662261963
  time_total_s: 3549.692180633545
  timestamp: 1594141175
  timesteps_since_restore: 1275000
  timesteps_this_iter: 5000
  timesteps_total: 1275000
  training_iteration: 255
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 34.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=12141], 3549 s, 255 iter, 1275000 ts, 1.49e+03 rew

agent-1: 360.0
agent-2: 374.0
agent-3: 323.0
agent-4: 294.0
agent-5: 321.0
Sum Reward: 1672.0
Avg Reward: 334.4
Min Reward: 294.0
Max Reward: 374.0
Gini Coefficient: 0.04760765550239234
20:20 Ratio: 1.272108843537415
Max-min Ratio: 1.272108843537415
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_12-59-47
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1931.0
  episode_reward_mean: 1485.59
  episode_reward_min: -17557.0
  episodes_this_iter: 1
  episodes_total: 255
  experiment_id: ebedc1946062457bb682d57fae83bd74
  hostname: gpu052
  info:
    apply_time_ms: 3.001
    dispatch_time_ms: 8.297
    learner:
      cur_lr: 0.0012750850291922688
      grad_gnorm: 40.0
      policy_entropy: 34.16699981689453
      policy_loss: -18.544559478759766
      var_gnorm: 37.245994567871094
      vf_explained_var: 0.5801880359649658
      vf_loss: 87.37152862548828
    num_steps_sampled: 1280000
    num_steps_trained: 1280000
    wait_time_ms: 114.531
  iterations_since_restore: 256
  node_ip: 172.17.8.52
  num_metric_batches_dropped: 0
  pid: 12141
  policy_reward_mean: {}
  time_since_restore: 3561.7591421604156
  time_this_iter_s: 12.066961526870728
  time_total_s: 3561.7591421604156
  timestamp: 1594141187
  timesteps_since_restore: 1280000
  timesteps_this_iter: 5000
  timesteps_total: 1280000
  training_iteration: 256
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 34.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=12141], 3561 s, 256 iter, 1280000 ts, 1.49e+03 rew

agent-1: 305.0
agent-2: 356.0
agent-3: 300.0
agent-4: 322.0
agent-5: 312.0
Sum Reward: 1595.0
Avg Reward: 319.0
Min Reward: 300.0
Max Reward: 356.0
Gini Coefficient: 0.03235109717868338
20:20 Ratio: 1.1866666666666668
Max-min Ratio: 1.1866666666666668
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_13-00-00
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1931.0
  episode_reward_mean: 1486.63
  episode_reward_min: -17557.0
  episodes_this_iter: 1
  episodes_total: 256
  experiment_id: ebedc1946062457bb682d57fae83bd74
  hostname: gpu052
  info:
    apply_time_ms: 2.822
    dispatch_time_ms: 6.828
    learner:
      cur_lr: 0.001274751964956522
      grad_gnorm: 40.00001907348633
      policy_entropy: 26.776826858520508
      policy_loss: 11.02898120880127
      var_gnorm: 37.22760772705078
      vf_explained_var: 0.46880054473876953
      vf_loss: 74.04603576660156
    num_steps_sampled: 1285000
    num_steps_trained: 1285000
    wait_time_ms: 122.266
  iterations_since_restore: 257
  node_ip: 172.17.8.52
  num_metric_batches_dropped: 0
  pid: 12141
  policy_reward_mean: {}
  time_since_restore: 3574.6788725852966
  time_this_iter_s: 12.919730424880981
  time_total_s: 3574.6788725852966
  timestamp: 1594141200
  timesteps_since_restore: 1285000
  timesteps_this_iter: 5000
  timesteps_total: 1285000
  training_iteration: 257
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 34.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=12141], 3574 s, 257 iter, 1285000 ts, 1.49e+03 rew

agent-1: 336.0
agent-2: 380.0
agent-3: 256.0
agent-4: 329.0
agent-5: 340.0
Sum Reward: 1641.0
Avg Reward: 328.2
Min Reward: 256.0
Max Reward: 380.0
Gini Coefficient: 0.0631322364411944
20:20 Ratio: 1.484375
Max-min Ratio: 1.484375
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_13-00-13
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1931.0
  episode_reward_mean: 1486.13
  episode_reward_min: -17557.0
  episodes_this_iter: 1
  episodes_total: 257
  experiment_id: ebedc1946062457bb682d57fae83bd74
  hostname: gpu052
  info:
    apply_time_ms: 3.439
    dispatch_time_ms: 6.443
    learner:
      cur_lr: 0.001274419017136097
      grad_gnorm: 40.0
      policy_entropy: 24.408275604248047
      policy_loss: -25.6294002532959
      var_gnorm: 37.29006576538086
      vf_explained_var: 0.4859018325805664
      vf_loss: 44.652809143066406
    num_steps_sampled: 1290000
    num_steps_trained: 1290000
    wait_time_ms: 135.085
  iterations_since_restore: 258
  node_ip: 172.17.8.52
  num_metric_batches_dropped: 0
  pid: 12141
  policy_reward_mean: {}
  time_since_restore: 3587.9409539699554
  time_this_iter_s: 13.262081384658813
  time_total_s: 3587.9409539699554
  timestamp: 1594141213
  timesteps_since_restore: 1290000
  timesteps_this_iter: 5000
  timesteps_total: 1290000
  training_iteration: 258
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 34.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=12141], 3587 s, 258 iter, 1290000 ts, 1.49e+03 rew

agent-1: 303.0
agent-2: 339.0
agent-3: 290.0
agent-4: 354.0
agent-5: 329.0
Sum Reward: 1615.0
Avg Reward: 323.0
Min Reward: 290.0
Max Reward: 354.0
Gini Coefficient: 0.04061919504643963
20:20 Ratio: 1.2206896551724138
Max-min Ratio: 1.2206896551724138
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_13-00-27
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1931.0
  episode_reward_mean: 1485.4
  episode_reward_min: -17557.0
  episodes_this_iter: 1
  episodes_total: 258
  experiment_id: ebedc1946062457bb682d57fae83bd74
  hostname: gpu052
  info:
    apply_time_ms: 3.61
    dispatch_time_ms: 6.641
    learner:
      cur_lr: 0.00127408595290035
      grad_gnorm: 40.00000762939453
      policy_entropy: 17.989999771118164
      policy_loss: -2.5019333362579346
      var_gnorm: 37.35710906982422
      vf_explained_var: 0.3738771080970764
      vf_loss: 33.3143310546875
    num_steps_sampled: 1295000
    num_steps_trained: 1295000
    wait_time_ms: 119.24
  iterations_since_restore: 259
  node_ip: 172.17.8.52
  num_metric_batches_dropped: 0
  pid: 12141
  policy_reward_mean: {}
  time_since_restore: 3601.3692111968994
  time_this_iter_s: 13.42825722694397
  time_total_s: 3601.3692111968994
  timestamp: 1594141227
  timesteps_since_restore: 1295000
  timesteps_this_iter: 5000
  timesteps_total: 1295000
  training_iteration: 259
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 34.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=12141], 3601 s, 259 iter, 1295000 ts, 1.49e+03 rew

agent-1: 352.0
agent-2: 338.0
agent-3: 347.0
agent-4: 376.0
agent-5: 351.0
Sum Reward: 1764.0
Avg Reward: 352.8
Min Reward: 338.0
Max Reward: 376.0
Gini Coefficient: 0.018367346938775512
20:20 Ratio: 1.1124260355029585
Max-min Ratio: 1.1124260355029585
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_13-00-40
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1931.0
  episode_reward_mean: 1487.72
  episode_reward_min: -17557.0
  episodes_this_iter: 1
  episodes_total: 259
  experiment_id: ebedc1946062457bb682d57fae83bd74
  hostname: gpu052
  info:
    apply_time_ms: 2.585
    dispatch_time_ms: 7.035
    learner:
      cur_lr: 0.001273753005079925
      grad_gnorm: 39.999996185302734
      policy_entropy: 20.23069953918457
      policy_loss: 8.86466121673584
      var_gnorm: 37.357139587402344
      vf_explained_var: -0.03722536563873291
      vf_loss: 33.70805740356445
    num_steps_sampled: 1300000
    num_steps_trained: 1300000
    wait_time_ms: 124.586
  iterations_since_restore: 260
  node_ip: 172.17.8.52
  num_metric_batches_dropped: 0
  pid: 12141
  policy_reward_mean: {}
  time_since_restore: 3614.1888389587402
  time_this_iter_s: 12.81962776184082
  time_total_s: 3614.1888389587402
  timestamp: 1594141240
  timesteps_since_restore: 1300000
  timesteps_this_iter: 5000
  timesteps_total: 1300000
  training_iteration: 260
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 34.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=12141], 3614 s, 260 iter, 1300000 ts, 1.49e+03 rew

agent-1: 362.0
agent-2: 301.0
agent-3: 344.0
agent-4: 301.0
agent-5: 395.0
Sum Reward: 1703.0
Avg Reward: 340.6
Min Reward: 301.0
Max Reward: 395.0
Gini Coefficient: 0.05848502642395772
20:20 Ratio: 1.3122923588039868
Max-min Ratio: 1.3122923588039868
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_13-00-53
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1931.0
  episode_reward_mean: 1680.32
  episode_reward_min: -1377.0
  episodes_this_iter: 1
  episodes_total: 260
  experiment_id: ebedc1946062457bb682d57fae83bd74
  hostname: gpu052
  info:
    apply_time_ms: 3.074
    dispatch_time_ms: 8.324
    learner:
      cur_lr: 0.0012734200572595
      grad_gnorm: 40.0
      policy_entropy: 22.091697692871094
      policy_loss: 6.734529495239258
      var_gnorm: 37.3355827331543
      vf_explained_var: 0.714252233505249
      vf_loss: 74.90071105957031
    num_steps_sampled: 1305000
    num_steps_trained: 1305000
    wait_time_ms: 113.403
  iterations_since_restore: 261
  node_ip: 172.17.8.52
  num_metric_batches_dropped: 0
  pid: 12141
  policy_reward_mean: {}
  time_since_restore: 3627.9120337963104
  time_this_iter_s: 13.72319483757019
  time_total_s: 3627.9120337963104
  timestamp: 1594141253
  timesteps_since_restore: 1305000
  timesteps_this_iter: 5000
  timesteps_total: 1305000
  training_iteration: 261
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 34.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=12141], 3627 s, 261 iter, 1305000 ts, 1.68e+03 rew

agent-1: 265.0
agent-2: 324.0
agent-3: 234.0
agent-4: 309.0
agent-5: 296.0
Sum Reward: 1428.0
Avg Reward: 285.6
Min Reward: 234.0
Max Reward: 324.0
Gini Coefficient: 0.06274509803921569
20:20 Ratio: 1.3846153846153846
Max-min Ratio: 1.3846153846153846
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_13-01-07
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1931.0
  episode_reward_mean: 1708.37
  episode_reward_min: 996.0
  episodes_this_iter: 1
  episodes_total: 261
  experiment_id: ebedc1946062457bb682d57fae83bd74
  hostname: gpu052
  info:
    apply_time_ms: 3.381
    dispatch_time_ms: 6.11
    learner:
      cur_lr: 0.0012730869930237532
      grad_gnorm: 20.907094955444336
      policy_entropy: 12.199568748474121
      policy_loss: 2.997814178466797
      var_gnorm: 37.375038146972656
      vf_explained_var: 0.18632686138153076
      vf_loss: 49.379451751708984
    num_steps_sampled: 1310000
    num_steps_trained: 1310000
    wait_time_ms: 131.392
  iterations_since_restore: 262
  node_ip: 172.17.8.52
  num_metric_batches_dropped: 0
  pid: 12141
  policy_reward_mean: {}
  time_since_restore: 3641.1133286952972
  time_this_iter_s: 13.201294898986816
  time_total_s: 3641.1133286952972
  timestamp: 1594141267
  timesteps_since_restore: 1310000
  timesteps_this_iter: 5000
  timesteps_total: 1310000
  training_iteration: 262
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 34.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=12141], 3641 s, 262 iter, 1310000 ts, 1.71e+03 rew

agent-1: 348.0
agent-2: 277.0
agent-3: 311.0
agent-4: 351.0
agent-5: 340.0
Sum Reward: 1627.0
Avg Reward: 325.4
Min Reward: 277.0
Max Reward: 351.0
Gini Coefficient: 0.04548248309772587
20:20 Ratio: 1.2671480144404332
Max-min Ratio: 1.2671480144404332
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_13-01-20
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1931.0
  episode_reward_mean: 1714.68
  episode_reward_min: 1249.0
  episodes_this_iter: 1
  episodes_total: 262
  experiment_id: ebedc1946062457bb682d57fae83bd74
  hostname: gpu052
  info:
    apply_time_ms: 2.684
    dispatch_time_ms: 6.18
    learner:
      cur_lr: 0.0012727540452033281
      grad_gnorm: 40.00002670288086
      policy_entropy: 13.442675590515137
      policy_loss: -5.739252090454102
      var_gnorm: 37.42993927001953
      vf_explained_var: 0.9182968735694885
      vf_loss: 47.580265045166016
    num_steps_sampled: 1315000
    num_steps_trained: 1315000
    wait_time_ms: 132.572
  iterations_since_restore: 263
  node_ip: 172.17.8.52
  num_metric_batches_dropped: 0
  pid: 12141
  policy_reward_mean: {}
  time_since_restore: 3654.421446800232
  time_this_iter_s: 13.308118104934692
  time_total_s: 3654.421446800232
  timestamp: 1594141280
  timesteps_since_restore: 1315000
  timesteps_this_iter: 5000
  timesteps_total: 1315000
  training_iteration: 263
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 34.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=12141], 3654 s, 263 iter, 1315000 ts, 1.71e+03 rew

agent-1: 333.0
agent-2: 220.0
agent-3: 319.0
agent-4: 361.0
agent-5: 319.0
Sum Reward: 1552.0
Avg Reward: 310.4
Min Reward: 220.0
Max Reward: 361.0
Gini Coefficient: 0.07628865979381444
20:20 Ratio: 1.6409090909090909
Max-min Ratio: 1.6409090909090909
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_13-01-34
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1931.0
  episode_reward_mean: 1714.14
  episode_reward_min: 1249.0
  episodes_this_iter: 1
  episodes_total: 263
  experiment_id: ebedc1946062457bb682d57fae83bd74
  hostname: gpu052
  info:
    apply_time_ms: 2.94
    dispatch_time_ms: 6.451
    learner:
      cur_lr: 0.0012724209809675813
      grad_gnorm: 40.000003814697266
      policy_entropy: 12.584068298339844
      policy_loss: -1.0966604948043823
      var_gnorm: 37.513275146484375
      vf_explained_var: 0.47609394788742065
      vf_loss: 7.942528247833252
    num_steps_sampled: 1320000
    num_steps_trained: 1320000
    wait_time_ms: 135.704
  iterations_since_restore: 264
  node_ip: 172.17.8.52
  num_metric_batches_dropped: 0
  pid: 12141
  policy_reward_mean: {}
  time_since_restore: 3667.973217010498
  time_this_iter_s: 13.551770210266113
  time_total_s: 3667.973217010498
  timestamp: 1594141294
  timesteps_since_restore: 1320000
  timesteps_this_iter: 5000
  timesteps_total: 1320000
  training_iteration: 264
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 34.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=12141], 3667 s, 264 iter, 1320000 ts, 1.71e+03 rew

agent-1: 334.0
agent-2: 304.0
agent-3: 328.0
agent-4: 339.0
agent-5: 347.0
Sum Reward: 1652.0
Avg Reward: 330.4
Min Reward: 304.0
Max Reward: 347.0
Gini Coefficient: 0.023486682808716706
20:20 Ratio: 1.1414473684210527
Max-min Ratio: 1.1414473684210527
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_13-01-47
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1931.0
  episode_reward_mean: 1715.11
  episode_reward_min: 1249.0
  episodes_this_iter: 1
  episodes_total: 264
  experiment_id: ebedc1946062457bb682d57fae83bd74
  hostname: gpu052
  info:
    apply_time_ms: 2.964
    dispatch_time_ms: 6.552
    learner:
      cur_lr: 0.0012720880331471562
      grad_gnorm: 40.000003814697266
      policy_entropy: 16.739866256713867
      policy_loss: 7.843652725219727
      var_gnorm: 37.57453536987305
      vf_explained_var: 0.5034470558166504
      vf_loss: 71.12666320800781
    num_steps_sampled: 1325000
    num_steps_trained: 1325000
    wait_time_ms: 120.793
  iterations_since_restore: 265
  node_ip: 172.17.8.52
  num_metric_batches_dropped: 0
  pid: 12141
  policy_reward_mean: {}
  time_since_restore: 3681.7418150901794
  time_this_iter_s: 13.768598079681396
  time_total_s: 3681.7418150901794
  timestamp: 1594141307
  timesteps_since_restore: 1325000
  timesteps_this_iter: 5000
  timesteps_total: 1325000
  training_iteration: 265
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 34.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=12141], 3681 s, 265 iter, 1325000 ts, 1.72e+03 rew

agent-1: 292.0
agent-2: 360.0
agent-3: 314.0
agent-4: 369.0
agent-5: 370.0
Sum Reward: 1705.0
Avg Reward: 341.0
Min Reward: 292.0
Max Reward: 370.0
Gini Coefficient: 0.04950146627565982
20:20 Ratio: 1.2671232876712328
Max-min Ratio: 1.2671232876712328
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_13-02-01
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1931.0
  episode_reward_mean: 1714.52
  episode_reward_min: 1249.0
  episodes_this_iter: 1
  episodes_total: 265
  experiment_id: ebedc1946062457bb682d57fae83bd74
  hostname: gpu052
  info:
    apply_time_ms: 3.022
    dispatch_time_ms: 6.429
    learner:
      cur_lr: 0.0012717549689114094
      grad_gnorm: 39.99999237060547
      policy_entropy: 9.314077377319336
      policy_loss: -10.342971801757812
      var_gnorm: 37.61317443847656
      vf_explained_var: 0.4744713306427002
      vf_loss: 44.62868881225586
    num_steps_sampled: 1330000
    num_steps_trained: 1330000
    wait_time_ms: 129.421
  iterations_since_restore: 266
  node_ip: 172.17.8.52
  num_metric_batches_dropped: 0
  pid: 12141
  policy_reward_mean: {}
  time_since_restore: 3695.2472262382507
  time_this_iter_s: 13.505411148071289
  time_total_s: 3695.2472262382507
  timestamp: 1594141321
  timesteps_since_restore: 1330000
  timesteps_this_iter: 5000
  timesteps_total: 1330000
  training_iteration: 266
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 34.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=12141], 3695 s, 266 iter, 1330000 ts, 1.71e+03 rew

agent-1: 339.0
agent-2: 375.0
agent-3: 364.0
agent-4: 340.0
agent-5: 383.0
Sum Reward: 1801.0
Avg Reward: 360.2
Min Reward: 339.0
Max Reward: 383.0
Gini Coefficient: 0.027318156579677958
20:20 Ratio: 1.1297935103244838
Max-min Ratio: 1.1297935103244838
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_13-02-15
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1931.0
  episode_reward_mean: 1715.2
  episode_reward_min: 1249.0
  episodes_this_iter: 1
  episodes_total: 266
  experiment_id: ebedc1946062457bb682d57fae83bd74
  hostname: gpu052
  info:
    apply_time_ms: 3.43
    dispatch_time_ms: 6.026
    learner:
      cur_lr: 0.0012714220210909843
      grad_gnorm: 39.9999885559082
      policy_entropy: 20.9143123626709
      policy_loss: -4.768258094787598
      var_gnorm: 37.58263397216797
      vf_explained_var: 0.23262429237365723
      vf_loss: 59.397735595703125
    num_steps_sampled: 1335000
    num_steps_trained: 1335000
    wait_time_ms: 133.687
  iterations_since_restore: 267
  node_ip: 172.17.8.52
  num_metric_batches_dropped: 0
  pid: 12141
  policy_reward_mean: {}
  time_since_restore: 3708.7922282218933
  time_this_iter_s: 13.545001983642578
  time_total_s: 3708.7922282218933
  timestamp: 1594141335
  timesteps_since_restore: 1335000
  timesteps_this_iter: 5000
  timesteps_total: 1335000
  training_iteration: 267
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 34.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=12141], 3708 s, 267 iter, 1335000 ts, 1.72e+03 rew

agent-1: 344.0
agent-2: 316.0
agent-3: 262.0
agent-4: 325.0
agent-5: 349.0
Sum Reward: 1596.0
Avg Reward: 319.2
Min Reward: 262.0
Max Reward: 349.0
Gini Coefficient: 0.0506265664160401
20:20 Ratio: 1.33206106870229
Max-min Ratio: 1.33206106870229
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_13-02-29
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1931.0
  episode_reward_mean: 1714.05
  episode_reward_min: 1249.0
  episodes_this_iter: 1
  episodes_total: 267
  experiment_id: ebedc1946062457bb682d57fae83bd74
  hostname: gpu052
  info:
    apply_time_ms: 2.966
    dispatch_time_ms: 7.082
    learner:
      cur_lr: 0.0012710889568552375
      grad_gnorm: 40.0
      policy_entropy: 12.669238090515137
      policy_loss: -2.364678144454956
      var_gnorm: 37.62710189819336
      vf_explained_var: 0.568540096282959
      vf_loss: 98.1046371459961
    num_steps_sampled: 1340000
    num_steps_trained: 1340000
    wait_time_ms: 132.187
  iterations_since_restore: 268
  node_ip: 172.17.8.52
  num_metric_batches_dropped: 0
  pid: 12141
  policy_reward_mean: {}
  time_since_restore: 3722.9195005893707
  time_this_iter_s: 14.127272367477417
  time_total_s: 3722.9195005893707
  timestamp: 1594141349
  timesteps_since_restore: 1340000
  timesteps_this_iter: 5000
  timesteps_total: 1340000
  training_iteration: 268
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 34.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=12141], 3722 s, 268 iter, 1340000 ts, 1.71e+03 rew

agent-1: 311.0
agent-2: 339.0
agent-3: 347.0
agent-4: 384.0
agent-5: 335.0
Sum Reward: 1716.0
Avg Reward: 343.2
Min Reward: 311.0
Max Reward: 384.0
Gini Coefficient: 0.03682983682983683
20:20 Ratio: 1.234726688102894
Max-min Ratio: 1.234726688102894
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_13-02-43
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1931.0
  episode_reward_mean: 1713.72
  episode_reward_min: 1249.0
  episodes_this_iter: 1
  episodes_total: 268
  experiment_id: ebedc1946062457bb682d57fae83bd74
  hostname: gpu052
  info:
    apply_time_ms: 3.289
    dispatch_time_ms: 6.574
    learner:
      cur_lr: 0.0012707560090348125
      grad_gnorm: 40.0000114440918
      policy_entropy: 16.6009578704834
      policy_loss: 18.239038467407227
      var_gnorm: 37.6716194152832
      vf_explained_var: 0.8350456953048706
      vf_loss: 41.7630729675293
    num_steps_sampled: 1345000
    num_steps_trained: 1345000
    wait_time_ms: 128.393
  iterations_since_restore: 269
  node_ip: 172.17.8.52
  num_metric_batches_dropped: 0
  pid: 12141
  policy_reward_mean: {}
  time_since_restore: 3737.0115554332733
  time_this_iter_s: 14.092054843902588
  time_total_s: 3737.0115554332733
  timestamp: 1594141363
  timesteps_since_restore: 1345000
  timesteps_this_iter: 5000
  timesteps_total: 1345000
  training_iteration: 269
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 34.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=12141], 3737 s, 269 iter, 1345000 ts, 1.71e+03 rew

agent-1: 360.0
agent-2: 343.0
agent-3: 275.0
agent-4: 331.0
agent-5: 372.0
Sum Reward: 1681.0
Avg Reward: 336.2
Min Reward: 275.0
Max Reward: 372.0
Gini Coefficient: 0.05306365258774539
20:20 Ratio: 1.3527272727272728
Max-min Ratio: 1.3527272727272728
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_13-02-57
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1931.0
  episode_reward_mean: 1711.75
  episode_reward_min: 1249.0
  episodes_this_iter: 1
  episodes_total: 269
  experiment_id: ebedc1946062457bb682d57fae83bd74
  hostname: gpu052
  info:
    apply_time_ms: 2.749
    dispatch_time_ms: 6.179
    learner:
      cur_lr: 0.0012704229447990656
      grad_gnorm: 24.99366569519043
      policy_entropy: 16.143869400024414
      policy_loss: -2.8147668838500977
      var_gnorm: 37.71728515625
      vf_explained_var: 0.7817403078079224
      vf_loss: 48.33566665649414
    num_steps_sampled: 1350000
    num_steps_trained: 1350000
    wait_time_ms: 146.947
  iterations_since_restore: 270
  node_ip: 172.17.8.52
  num_metric_batches_dropped: 0
  pid: 12141
  policy_reward_mean: {}
  time_since_restore: 3751.048364639282
  time_this_iter_s: 14.036809206008911
  time_total_s: 3751.048364639282
  timestamp: 1594141377
  timesteps_since_restore: 1350000
  timesteps_this_iter: 5000
  timesteps_total: 1350000
  training_iteration: 270
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 34.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=12141], 3751 s, 270 iter, 1350000 ts, 1.71e+03 rew

agent-1: 354.0
agent-2: 346.0
agent-3: 313.0
agent-4: 345.0
agent-5: 346.0
Sum Reward: 1704.0
Avg Reward: 340.8
Min Reward: 313.0
Max Reward: 354.0
Gini Coefficient: 0.01948356807511737
20:20 Ratio: 1.1309904153354633
Max-min Ratio: 1.1309904153354633
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_13-03-11
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1931.0
  episode_reward_mean: 1711.08
  episode_reward_min: 1249.0
  episodes_this_iter: 1
  episodes_total: 270
  experiment_id: ebedc1946062457bb682d57fae83bd74
  hostname: gpu052
  info:
    apply_time_ms: 2.812
    dispatch_time_ms: 6.513
    learner:
      cur_lr: 0.0012700899969786406
      grad_gnorm: 40.0
      policy_entropy: 16.385032653808594
      policy_loss: 4.618975639343262
      var_gnorm: 37.81027603149414
      vf_explained_var: 0.6700032949447632
      vf_loss: 24.46961212158203
    num_steps_sampled: 1355000
    num_steps_trained: 1355000
    wait_time_ms: 134.215
  iterations_since_restore: 271
  node_ip: 172.17.8.52
  num_metric_batches_dropped: 0
  pid: 12141
  policy_reward_mean: {}
  time_since_restore: 3764.872848033905
  time_this_iter_s: 13.824483394622803
  time_total_s: 3764.872848033905
  timestamp: 1594141391
  timesteps_since_restore: 1355000
  timesteps_this_iter: 5000
  timesteps_total: 1355000
  training_iteration: 271
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 34.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=12141], 3764 s, 271 iter, 1355000 ts, 1.71e+03 rew

agent-1: 209.0
agent-2: 397.0
agent-3: 401.0
agent-4: 354.0
agent-5: 337.0
Sum Reward: 1698.0
Avg Reward: 339.6
Min Reward: 209.0
Max Reward: 401.0
Gini Coefficient: 0.10459363957597173
20:20 Ratio: 1.9186602870813396
Max-min Ratio: 1.9186602870813396
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_13-03-25
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1931.0
  episode_reward_mean: 1709.42
  episode_reward_min: 1249.0
  episodes_this_iter: 1
  episodes_total: 271
  experiment_id: ebedc1946062457bb682d57fae83bd74
  hostname: gpu052
  info:
    apply_time_ms: 3.914
    dispatch_time_ms: 7.992
    learner:
      cur_lr: 0.0012697570491582155
      grad_gnorm: 39.999996185302734
      policy_entropy: 15.330764770507812
      policy_loss: -7.885198593139648
      var_gnorm: 37.930484771728516
      vf_explained_var: 0.6371169090270996
      vf_loss: 71.76947021484375
    num_steps_sampled: 1360000
    num_steps_trained: 1360000
    wait_time_ms: 116.187
  iterations_since_restore: 272
  node_ip: 172.17.8.52
  num_metric_batches_dropped: 0
  pid: 12141
  policy_reward_mean: {}
  time_since_restore: 3778.6701641082764
  time_this_iter_s: 13.797316074371338
  time_total_s: 3778.6701641082764
  timestamp: 1594141405
  timesteps_since_restore: 1360000
  timesteps_this_iter: 5000
  timesteps_total: 1360000
  training_iteration: 272
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 34.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=12141], 3778 s, 272 iter, 1360000 ts, 1.71e+03 rew

agent-1: 336.0
agent-2: 300.0
agent-3: 247.0
agent-4: 350.0
agent-5: 278.0
Sum Reward: 1511.0
Avg Reward: 302.2
Min Reward: 247.0
Max Reward: 350.0
Gini Coefficient: 0.0698874917273329
20:20 Ratio: 1.417004048582996
Max-min Ratio: 1.417004048582996
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_13-03-38
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1931.0
  episode_reward_mean: 1708.77
  episode_reward_min: 1249.0
  episodes_this_iter: 1
  episodes_total: 272
  experiment_id: ebedc1946062457bb682d57fae83bd74
  hostname: gpu052
  info:
    apply_time_ms: 2.655
    dispatch_time_ms: 6.705
    learner:
      cur_lr: 0.0012694239849224687
      grad_gnorm: 40.0
      policy_entropy: 28.679033279418945
      policy_loss: -0.8228762745857239
      var_gnorm: 37.997249603271484
      vf_explained_var: 0.7441909313201904
      vf_loss: 120.63867950439453
    num_steps_sampled: 1365000
    num_steps_trained: 1365000
    wait_time_ms: 125.508
  iterations_since_restore: 273
  node_ip: 172.17.8.52
  num_metric_batches_dropped: 0
  pid: 12141
  policy_reward_mean: {}
  time_since_restore: 3791.553725004196
  time_this_iter_s: 12.8835608959198
  time_total_s: 3791.553725004196
  timestamp: 1594141418
  timesteps_since_restore: 1365000
  timesteps_this_iter: 5000
  timesteps_total: 1365000
  training_iteration: 273
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 34.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=12141], 3791 s, 273 iter, 1365000 ts, 1.71e+03 rew

agent-1: 323.0
agent-2: 383.0
agent-3: 210.0
agent-4: 323.0
agent-5: 341.0
Sum Reward: 1580.0
Avg Reward: 316.0
Min Reward: 210.0
Max Reward: 383.0
Gini Coefficient: 0.09215189873417722
20:20 Ratio: 1.8238095238095238
Max-min Ratio: 1.8238095238095238
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_13-03-51
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1931.0
  episode_reward_mean: 1708.94
  episode_reward_min: 1249.0
  episodes_this_iter: 1
  episodes_total: 273
  experiment_id: ebedc1946062457bb682d57fae83bd74
  hostname: gpu052
  info:
    apply_time_ms: 2.659
    dispatch_time_ms: 7.311
    learner:
      cur_lr: 0.0012690910371020436
      grad_gnorm: 40.000003814697266
      policy_entropy: 17.35860824584961
      policy_loss: 14.77260684967041
      var_gnorm: 38.0647087097168
      vf_explained_var: 0.636152982711792
      vf_loss: 95.73049926757812
    num_steps_sampled: 1370000
    num_steps_trained: 1370000
    wait_time_ms: 140.741
  iterations_since_restore: 274
  node_ip: 172.17.8.52
  num_metric_batches_dropped: 0
  pid: 12141
  policy_reward_mean: {}
  time_since_restore: 3804.9408226013184
  time_this_iter_s: 13.387097597122192
  time_total_s: 3804.9408226013184
  timestamp: 1594141431
  timesteps_since_restore: 1370000
  timesteps_this_iter: 5000
  timesteps_total: 1370000
  training_iteration: 274
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 34.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=12141], 3804 s, 274 iter, 1370000 ts, 1.71e+03 rew

agent-1: 359.0
agent-2: 335.0
agent-3: 358.0
agent-4: 277.0
agent-5: 408.0
Sum Reward: 1737.0
Avg Reward: 347.4
Min Reward: 277.0
Max Reward: 408.0
Gini Coefficient: 0.06586067933218193
20:20 Ratio: 1.4729241877256318
Max-min Ratio: 1.4729241877256318
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_13-04-05
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1931.0
  episode_reward_mean: 1709.09
  episode_reward_min: 1249.0
  episodes_this_iter: 1
  episodes_total: 274
  experiment_id: ebedc1946062457bb682d57fae83bd74
  hostname: gpu052
  info:
    apply_time_ms: 3.636
    dispatch_time_ms: 6.866
    learner:
      cur_lr: 0.0012687579728662968
      grad_gnorm: 40.0
      policy_entropy: 18.921110153198242
      policy_loss: -9.30063247680664
      var_gnorm: 38.132225036621094
      vf_explained_var: 0.5877349376678467
      vf_loss: 72.7845230102539
    num_steps_sampled: 1375000
    num_steps_trained: 1375000
    wait_time_ms: 129.198
  iterations_since_restore: 275
  node_ip: 172.17.8.52
  num_metric_batches_dropped: 0
  pid: 12141
  policy_reward_mean: {}
  time_since_restore: 3818.6760222911835
  time_this_iter_s: 13.735199689865112
  time_total_s: 3818.6760222911835
  timestamp: 1594141445
  timesteps_since_restore: 1375000
  timesteps_this_iter: 5000
  timesteps_total: 1375000
  training_iteration: 275
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 34.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=12141], 3818 s, 275 iter, 1375000 ts, 1.71e+03 rew

agent-1: 387.0
agent-2: 316.0
agent-3: 307.0
agent-4: 254.0
agent-5: 340.0
Sum Reward: 1604.0
Avg Reward: 320.8
Min Reward: 254.0
Max Reward: 387.0
Gini Coefficient: 0.07456359102244389
20:20 Ratio: 1.5236220472440944
Max-min Ratio: 1.5236220472440944
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_13-04-18
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1931.0
  episode_reward_mean: 1709.56
  episode_reward_min: 1249.0
  episodes_this_iter: 1
  episodes_total: 275
  experiment_id: ebedc1946062457bb682d57fae83bd74
  hostname: gpu052
  info:
    apply_time_ms: 2.749
    dispatch_time_ms: 5.879
    learner:
      cur_lr: 0.0012684250250458717
      grad_gnorm: 40.0
      policy_entropy: 10.687816619873047
      policy_loss: 1.0275683403015137
      var_gnorm: 38.2098274230957
      vf_explained_var: 0.6603440046310425
      vf_loss: 23.471908569335938
    num_steps_sampled: 1380000
    num_steps_trained: 1380000
    wait_time_ms: 122.592
  iterations_since_restore: 276
  node_ip: 172.17.8.52
  num_metric_batches_dropped: 0
  pid: 12141
  policy_reward_mean: {}
  time_since_restore: 3832.1419880390167
  time_this_iter_s: 13.465965747833252
  time_total_s: 3832.1419880390167
  timestamp: 1594141458
  timesteps_since_restore: 1380000
  timesteps_this_iter: 5000
  timesteps_total: 1380000
  training_iteration: 276
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 34.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=12141], 3832 s, 276 iter, 1380000 ts, 1.71e+03 rew

agent-1: 310.0
agent-2: 337.0
agent-3: 277.0
agent-4: 351.0
agent-5: 336.0
Sum Reward: 1611.0
Avg Reward: 322.2
Min Reward: 277.0
Max Reward: 351.0
Gini Coefficient: 0.043451272501551834
20:20 Ratio: 1.2671480144404332
Max-min Ratio: 1.2671480144404332
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_13-04-31
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1931.0
  episode_reward_mean: 1707.42
  episode_reward_min: 1249.0
  episodes_this_iter: 1
  episodes_total: 276
  experiment_id: ebedc1946062457bb682d57fae83bd74
  hostname: gpu052
  info:
    apply_time_ms: 3.828
    dispatch_time_ms: 7.667
    learner:
      cur_lr: 0.0012680919608101249
      grad_gnorm: 39.999996185302734
      policy_entropy: 27.74721908569336
      policy_loss: -34.71223831176758
      var_gnorm: 38.24998092651367
      vf_explained_var: 0.6782987117767334
      vf_loss: 85.05659484863281
    num_steps_sampled: 1385000
    num_steps_trained: 1385000
    wait_time_ms: 128.548
  iterations_since_restore: 277
  node_ip: 172.17.8.52
  num_metric_batches_dropped: 0
  pid: 12141
  policy_reward_mean: {}
  time_since_restore: 3845.1303222179413
  time_this_iter_s: 12.98833417892456
  time_total_s: 3845.1303222179413
  timestamp: 1594141471
  timesteps_since_restore: 1385000
  timesteps_this_iter: 5000
  timesteps_total: 1385000
  training_iteration: 277
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 34.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=12141], 3845 s, 277 iter, 1385000 ts, 1.71e+03 rew

agent-1: 353.0
agent-2: 389.0
agent-3: 241.0
agent-4: 350.0
agent-5: 338.0
Sum Reward: 1671.0
Avg Reward: 334.2
Min Reward: 241.0
Max Reward: 389.0
Gini Coefficient: 0.07444643925792939
20:20 Ratio: 1.6141078838174274
Max-min Ratio: 1.6141078838174274
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_13-04-45
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1931.0
  episode_reward_mean: 1705.09
  episode_reward_min: 1249.0
  episodes_this_iter: 1
  episodes_total: 277
  experiment_id: ebedc1946062457bb682d57fae83bd74
  hostname: gpu052
  info:
    apply_time_ms: 3.344
    dispatch_time_ms: 7.677
    learner:
      cur_lr: 0.0012677590129896998
      grad_gnorm: 39.99998474121094
      policy_entropy: 19.021324157714844
      policy_loss: -15.445770263671875
      var_gnorm: 38.27924346923828
      vf_explained_var: 0.4984845519065857
      vf_loss: 50.62110900878906
    num_steps_sampled: 1390000
    num_steps_trained: 1390000
    wait_time_ms: 130.866
  iterations_since_restore: 278
  node_ip: 172.17.8.52
  num_metric_batches_dropped: 0
  pid: 12141
  policy_reward_mean: {}
  time_since_restore: 3858.5028235912323
  time_this_iter_s: 13.372501373291016
  time_total_s: 3858.5028235912323
  timestamp: 1594141485
  timesteps_since_restore: 1390000
  timesteps_this_iter: 5000
  timesteps_total: 1390000
  training_iteration: 278
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 34.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=12141], 3858 s, 278 iter, 1390000 ts, 1.71e+03 rew

agent-1: 343.0
agent-2: 372.0
agent-3: 271.0
agent-4: 355.0
agent-5: 337.0
Sum Reward: 1678.0
Avg Reward: 335.6
Min Reward: 271.0
Max Reward: 372.0
Gini Coefficient: 0.052443384982121574
20:20 Ratio: 1.3726937269372694
Max-min Ratio: 1.3726937269372694
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_13-04-58
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1931.0
  episode_reward_mean: 1703.96
  episode_reward_min: 1249.0
  episodes_this_iter: 1
  episodes_total: 278
  experiment_id: ebedc1946062457bb682d57fae83bd74
  hostname: gpu052
  info:
    apply_time_ms: 4.228
    dispatch_time_ms: 5.311
    learner:
      cur_lr: 0.001267425948753953
      grad_gnorm: 39.999996185302734
      policy_entropy: 11.026174545288086
      policy_loss: 4.916650295257568
      var_gnorm: 38.34795379638672
      vf_explained_var: 0.3251718282699585
      vf_loss: 51.400691986083984
    num_steps_sampled: 1395000
    num_steps_trained: 1395000
    wait_time_ms: 120.0
  iterations_since_restore: 279
  node_ip: 172.17.8.52
  num_metric_batches_dropped: 0
  pid: 12141
  policy_reward_mean: {}
  time_since_restore: 3871.8431990146637
  time_this_iter_s: 13.340375423431396
  time_total_s: 3871.8431990146637
  timestamp: 1594141498
  timesteps_since_restore: 1395000
  timesteps_this_iter: 5000
  timesteps_total: 1395000
  training_iteration: 279
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 34.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=12141], 3871 s, 279 iter, 1395000 ts, 1.7e+03 rew

agent-1: 394.0
agent-2: 349.0
agent-3: 355.0
agent-4: 319.0
agent-5: 345.0
Sum Reward: 1762.0
Avg Reward: 352.4
Min Reward: 319.0
Max Reward: 394.0
Gini Coefficient: 0.036322360953461974
20:20 Ratio: 1.2351097178683386
Max-min Ratio: 1.2351097178683386
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_13-05-11
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1931.0
  episode_reward_mean: 1703.89
  episode_reward_min: 1249.0
  episodes_this_iter: 1
  episodes_total: 279
  experiment_id: ebedc1946062457bb682d57fae83bd74
  hostname: gpu052
  info:
    apply_time_ms: 3.416
    dispatch_time_ms: 6.258
    learner:
      cur_lr: 0.001267093000933528
      grad_gnorm: 40.0
      policy_entropy: 12.938077926635742
      policy_loss: -8.461566925048828
      var_gnorm: 38.394493103027344
      vf_explained_var: 0.753298819065094
      vf_loss: 126.5427017211914
    num_steps_sampled: 1400000
    num_steps_trained: 1400000
    wait_time_ms: 125.072
  iterations_since_restore: 280
  node_ip: 172.17.8.52
  num_metric_batches_dropped: 0
  pid: 12141
  policy_reward_mean: {}
  time_since_restore: 3884.6914608478546
  time_this_iter_s: 12.848261833190918
  time_total_s: 3884.6914608478546
  timestamp: 1594141511
  timesteps_since_restore: 1400000
  timesteps_this_iter: 5000
  timesteps_total: 1400000
  training_iteration: 280
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 34.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=12141], 3884 s, 280 iter, 1400000 ts, 1.7e+03 rew

agent-1: 386.0
agent-2: 388.0
agent-3: 386.0
agent-4: 349.0
agent-5: 279.0
Sum Reward: 1788.0
Avg Reward: 357.6
Min Reward: 279.0
Max Reward: 388.0
Gini Coefficient: 0.05704697986577181
20:20 Ratio: 1.3906810035842294
Max-min Ratio: 1.3906810035842294
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_13-05-24
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1931.0
  episode_reward_mean: 1703.99
  episode_reward_min: 1249.0
  episodes_this_iter: 1
  episodes_total: 280
  experiment_id: ebedc1946062457bb682d57fae83bd74
  hostname: gpu052
  info:
    apply_time_ms: 2.785
    dispatch_time_ms: 8.208
    learner:
      cur_lr: 0.001266760053113103
      grad_gnorm: 39.999996185302734
      policy_entropy: 18.11328887939453
      policy_loss: -27.08793067932129
      var_gnorm: 38.451175689697266
      vf_explained_var: 0.7504397034645081
      vf_loss: 224.57359313964844
    num_steps_sampled: 1405000
    num_steps_trained: 1405000
    wait_time_ms: 116.978
  iterations_since_restore: 281
  node_ip: 172.17.8.52
  num_metric_batches_dropped: 0
  pid: 12141
  policy_reward_mean: {}
  time_since_restore: 3897.4529252052307
  time_this_iter_s: 12.761464357376099
  time_total_s: 3897.4529252052307
  timestamp: 1594141524
  timesteps_since_restore: 1405000
  timesteps_this_iter: 5000
  timesteps_total: 1405000
  training_iteration: 281
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 34.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=12141], 3897 s, 281 iter, 1405000 ts, 1.7e+03 rew

agent-1: 396.0
agent-2: 366.0
agent-3: 345.0
agent-4: 357.0
agent-5: 406.0
Sum Reward: 1870.0
Avg Reward: 374.0
Min Reward: 345.0
Max Reward: 406.0
Gini Coefficient: 0.03443850267379679
20:20 Ratio: 1.1768115942028985
Max-min Ratio: 1.1768115942028985
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_13-05-37
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1931.0
  episode_reward_mean: 1705.17
  episode_reward_min: 1249.0
  episodes_this_iter: 1
  episodes_total: 281
  experiment_id: ebedc1946062457bb682d57fae83bd74
  hostname: gpu052
  info:
    apply_time_ms: 3.903
    dispatch_time_ms: 6.216
    learner:
      cur_lr: 0.001266426988877356
      grad_gnorm: 40.0
      policy_entropy: 6.973543167114258
      policy_loss: -4.042107105255127
      var_gnorm: 38.46030044555664
      vf_explained_var: 0.7401570081710815
      vf_loss: 14.4521484375
    num_steps_sampled: 1410000
    num_steps_trained: 1410000
    wait_time_ms: 117.076
  iterations_since_restore: 282
  node_ip: 172.17.8.52
  num_metric_batches_dropped: 0
  pid: 12141
  policy_reward_mean: {}
  time_since_restore: 3910.3385910987854
  time_this_iter_s: 12.885665893554688
  time_total_s: 3910.3385910987854
  timestamp: 1594141537
  timesteps_since_restore: 1410000
  timesteps_this_iter: 5000
  timesteps_total: 1410000
  training_iteration: 282
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 34.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=12141], 3910 s, 282 iter, 1410000 ts, 1.71e+03 rew

agent-1: 332.0
agent-2: 390.0
agent-3: 407.0
agent-4: 307.0
agent-5: 272.0
Sum Reward: 1708.0
Avg Reward: 341.6
Min Reward: 272.0
Max Reward: 407.0
Gini Coefficient: 0.08266978922716628
20:20 Ratio: 1.4963235294117647
Max-min Ratio: 1.4963235294117647
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_13-05-50
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1931.0
  episode_reward_mean: 1703.78
  episode_reward_min: 1249.0
  episodes_this_iter: 1
  episodes_total: 282
  experiment_id: ebedc1946062457bb682d57fae83bd74
  hostname: gpu052
  info:
    apply_time_ms: 3.216
    dispatch_time_ms: 5.398
    learner:
      cur_lr: 0.001266094041056931
      grad_gnorm: 39.99999237060547
      policy_entropy: 10.591495513916016
      policy_loss: 3.4893980026245117
      var_gnorm: 38.467838287353516
      vf_explained_var: 0.4023205637931824
      vf_loss: 26.22506332397461
    num_steps_sampled: 1415000
    num_steps_trained: 1415000
    wait_time_ms: 122.995
  iterations_since_restore: 283
  node_ip: 172.17.8.52
  num_metric_batches_dropped: 0
  pid: 12141
  policy_reward_mean: {}
  time_since_restore: 3923.2067761421204
  time_this_iter_s: 12.868185043334961
  time_total_s: 3923.2067761421204
  timestamp: 1594141550
  timesteps_since_restore: 1415000
  timesteps_this_iter: 5000
  timesteps_total: 1415000
  training_iteration: 283
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 34.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=12141], 3923 s, 283 iter, 1415000 ts, 1.7e+03 rew

agent-1: 386.0
agent-2: 372.0
agent-3: 327.0
agent-4: 353.0
agent-5: 334.0
Sum Reward: 1772.0
Avg Reward: 354.4
Min Reward: 327.0
Max Reward: 386.0
Gini Coefficient: 0.035214446952595936
20:20 Ratio: 1.180428134556575
Max-min Ratio: 1.180428134556575
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_13-06-02
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1931.0
  episode_reward_mean: 1702.71
  episode_reward_min: 1249.0
  episodes_this_iter: 1
  episodes_total: 283
  experiment_id: ebedc1946062457bb682d57fae83bd74
  hostname: gpu052
  info:
    apply_time_ms: 3.895
    dispatch_time_ms: 6.344
    learner:
      cur_lr: 0.0012657609768211842
      grad_gnorm: 39.999996185302734
      policy_entropy: 6.624009132385254
      policy_loss: 1.8959417343139648
      var_gnorm: 38.51433181762695
      vf_explained_var: -0.44058847427368164
      vf_loss: 34.39655303955078
    num_steps_sampled: 1420000
    num_steps_trained: 1420000
    wait_time_ms: 116.409
  iterations_since_restore: 284
  node_ip: 172.17.8.52
  num_metric_batches_dropped: 0
  pid: 12141
  policy_reward_mean: {}
  time_since_restore: 3935.6218144893646
  time_this_iter_s: 12.415038347244263
  time_total_s: 3935.6218144893646
  timestamp: 1594141562
  timesteps_since_restore: 1420000
  timesteps_this_iter: 5000
  timesteps_total: 1420000
  training_iteration: 284
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 34.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=12141], 3935 s, 284 iter, 1420000 ts, 1.7e+03 rew

agent-1: 387.0
agent-2: 274.0
agent-3: 332.0
agent-4: 346.0
agent-5: 352.0
Sum Reward: 1691.0
Avg Reward: 338.2
Min Reward: 274.0
Max Reward: 387.0
Gini Coefficient: 0.058190419869899465
20:20 Ratio: 1.4124087591240877
Max-min Ratio: 1.4124087591240877
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_13-06-15
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1931.0
  episode_reward_mean: 1700.99
  episode_reward_min: 1249.0
  episodes_this_iter: 1
  episodes_total: 284
  experiment_id: ebedc1946062457bb682d57fae83bd74
  hostname: gpu052
  info:
    apply_time_ms: 2.713
    dispatch_time_ms: 6.086
    learner:
      cur_lr: 0.0012654280290007591
      grad_gnorm: 39.999996185302734
      policy_entropy: 6.30902099609375
      policy_loss: -17.718488693237305
      var_gnorm: 38.569435119628906
      vf_explained_var: -0.057076454162597656
      vf_loss: 33.884361267089844
    num_steps_sampled: 1425000
    num_steps_trained: 1425000
    wait_time_ms: 124.9
  iterations_since_restore: 285
  node_ip: 172.17.8.52
  num_metric_batches_dropped: 0
  pid: 12141
  policy_reward_mean: {}
  time_since_restore: 3948.6478848457336
  time_this_iter_s: 13.026070356369019
  time_total_s: 3948.6478848457336
  timestamp: 1594141575
  timesteps_since_restore: 1425000
  timesteps_this_iter: 5000
  timesteps_total: 1425000
  training_iteration: 285
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 35.3/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=12141], 3948 s, 285 iter, 1425000 ts, 1.7e+03 rew

agent-1: 312.0
agent-2: 388.0
agent-3: 308.0
agent-4: 327.0
agent-5: 404.0
Sum Reward: 1739.0
Avg Reward: 347.8
Min Reward: 308.0
Max Reward: 404.0
Gini Coefficient: 0.061644623346751005
20:20 Ratio: 1.3116883116883118
Max-min Ratio: 1.3116883116883118
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_13-06-28
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1931.0
  episode_reward_mean: 1700.73
  episode_reward_min: 1249.0
  episodes_this_iter: 1
  episodes_total: 285
  experiment_id: ebedc1946062457bb682d57fae83bd74
  hostname: gpu052
  info:
    apply_time_ms: 2.612
    dispatch_time_ms: 7.691
    learner:
      cur_lr: 0.0012650949647650123
      grad_gnorm: 30.907482147216797
      policy_entropy: 8.439258575439453
      policy_loss: -3.0587525367736816
      var_gnorm: 38.626190185546875
      vf_explained_var: 0.5469099283218384
      vf_loss: 14.066922187805176
    num_steps_sampled: 1430000
    num_steps_trained: 1430000
    wait_time_ms: 116.001
  iterations_since_restore: 286
  node_ip: 172.17.8.52
  num_metric_batches_dropped: 0
  pid: 12141
  policy_reward_mean: {}
  time_since_restore: 3961.7407999038696
  time_this_iter_s: 13.092915058135986
  time_total_s: 3961.7407999038696
  timestamp: 1594141588
  timesteps_since_restore: 1430000
  timesteps_this_iter: 5000
  timesteps_total: 1430000
  training_iteration: 286
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 35.3/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=12141], 3961 s, 286 iter, 1430000 ts, 1.7e+03 rew

agent-1: 313.0
agent-2: 351.0
agent-3: 331.0
agent-4: 367.0
agent-5: 363.0
Sum Reward: 1725.0
Avg Reward: 345.0
Min Reward: 313.0
Max Reward: 367.0
Gini Coefficient: 0.03246376811594203
20:20 Ratio: 1.1725239616613419
Max-min Ratio: 1.1725239616613419
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_13-06-41
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1931.0
  episode_reward_mean: 1699.18
  episode_reward_min: 1249.0
  episodes_this_iter: 1
  episodes_total: 286
  experiment_id: ebedc1946062457bb682d57fae83bd74
  hostname: gpu052
  info:
    apply_time_ms: 3.238
    dispatch_time_ms: 6.394
    learner:
      cur_lr: 0.0012647620169445872
      grad_gnorm: 7.83268404006958
      policy_entropy: 6.940099716186523
      policy_loss: -1.1991331577301025
      var_gnorm: 38.671775817871094
      vf_explained_var: 0.13176405429840088
      vf_loss: 13.832175254821777
    num_steps_sampled: 1435000
    num_steps_trained: 1435000
    wait_time_ms: 109.494
  iterations_since_restore: 287
  node_ip: 172.17.8.52
  num_metric_batches_dropped: 0
  pid: 12141
  policy_reward_mean: {}
  time_since_restore: 3974.161863088608
  time_this_iter_s: 12.42106318473816
  time_total_s: 3974.161863088608
  timestamp: 1594141601
  timesteps_since_restore: 1435000
  timesteps_this_iter: 5000
  timesteps_total: 1435000
  training_iteration: 287
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 35.3/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=12141], 3974 s, 287 iter, 1435000 ts, 1.7e+03 rew

agent-1: 324.0
agent-2: 401.0
agent-3: 327.0
agent-4: 325.0
agent-5: 347.0
Sum Reward: 1724.0
Avg Reward: 344.8
Min Reward: 324.0
Max Reward: 401.0
Gini Coefficient: 0.04083526682134571
20:20 Ratio: 1.2376543209876543
Max-min Ratio: 1.2376543209876543
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_13-06-53
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1931.0
  episode_reward_mean: 1697.71
  episode_reward_min: 1249.0
  episodes_this_iter: 1
  episodes_total: 287
  experiment_id: ebedc1946062457bb682d57fae83bd74
  hostname: gpu052
  info:
    apply_time_ms: 4.675
    dispatch_time_ms: 9.641
    learner:
      cur_lr: 0.0012644289527088404
      grad_gnorm: 40.00000762939453
      policy_entropy: 13.112028121948242
      policy_loss: -8.972240447998047
      var_gnorm: 38.6672248840332
      vf_explained_var: 0.924860954284668
      vf_loss: 36.61168670654297
    num_steps_sampled: 1440000
    num_steps_trained: 1440000
    wait_time_ms: 117.517
  iterations_since_restore: 288
  node_ip: 172.17.8.52
  num_metric_batches_dropped: 0
  pid: 12141
  policy_reward_mean: {}
  time_since_restore: 3986.8532848358154
  time_this_iter_s: 12.691421747207642
  time_total_s: 3986.8532848358154
  timestamp: 1594141613
  timesteps_since_restore: 1440000
  timesteps_this_iter: 5000
  timesteps_total: 1440000
  training_iteration: 288
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 35.3/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=12141], 3986 s, 288 iter, 1440000 ts, 1.7e+03 rew

agent-1: 318.0
agent-2: 376.0
agent-3: 310.0
agent-4: 275.0
agent-5: 342.0
Sum Reward: 1621.0
Avg Reward: 324.2
Min Reward: 275.0
Max Reward: 376.0
Gini Coefficient: 0.057742134484885875
20:20 Ratio: 1.3672727272727272
Max-min Ratio: 1.3672727272727272
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_13-07-06
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1931.0
  episode_reward_mean: 1695.78
  episode_reward_min: 1249.0
  episodes_this_iter: 1
  episodes_total: 288
  experiment_id: ebedc1946062457bb682d57fae83bd74
  hostname: gpu052
  info:
    apply_time_ms: 4.151
    dispatch_time_ms: 5.73
    learner:
      cur_lr: 0.0012640960048884153
      grad_gnorm: 40.0000114440918
      policy_entropy: 9.091658592224121
      policy_loss: 0.7459253072738647
      var_gnorm: 38.70273208618164
      vf_explained_var: -0.34080934524536133
      vf_loss: 20.693702697753906
    num_steps_sampled: 1445000
    num_steps_trained: 1445000
    wait_time_ms: 121.316
  iterations_since_restore: 289
  node_ip: 172.17.8.52
  num_metric_batches_dropped: 0
  pid: 12141
  policy_reward_mean: {}
  time_since_restore: 3999.728043317795
  time_this_iter_s: 12.87475848197937
  time_total_s: 3999.728043317795
  timestamp: 1594141626
  timesteps_since_restore: 1445000
  timesteps_this_iter: 5000
  timesteps_total: 1445000
  training_iteration: 289
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 35.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=12141], 3999 s, 289 iter, 1445000 ts, 1.7e+03 rew

agent-1: 347.0
agent-2: 300.0
agent-3: 169.0
agent-4: 359.0
agent-5: 364.0
Sum Reward: 1539.0
Avg Reward: 307.8
Min Reward: 169.0
Max Reward: 364.0
Gini Coefficient: 0.11669915529564652
20:20 Ratio: 2.1538461538461537
Max-min Ratio: 2.1538461538461537
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_13-07-19
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1931.0
  episode_reward_mean: 1692.92
  episode_reward_min: 1249.0
  episodes_this_iter: 1
  episodes_total: 289
  experiment_id: ebedc1946062457bb682d57fae83bd74
  hostname: gpu052
  info:
    apply_time_ms: 2.73
    dispatch_time_ms: 7.265
    learner:
      cur_lr: 0.0012637630570679903
      grad_gnorm: 40.0
      policy_entropy: 9.855091094970703
      policy_loss: -9.313157081604004
      var_gnorm: 38.70764923095703
      vf_explained_var: 0.5358939170837402
      vf_loss: 94.9869613647461
    num_steps_sampled: 1450000
    num_steps_trained: 1450000
    wait_time_ms: 118.443
  iterations_since_restore: 290
  node_ip: 172.17.8.52
  num_metric_batches_dropped: 0
  pid: 12141
  policy_reward_mean: {}
  time_since_restore: 4012.761135339737
  time_this_iter_s: 13.033092021942139
  time_total_s: 4012.761135339737
  timestamp: 1594141639
  timesteps_since_restore: 1450000
  timesteps_this_iter: 5000
  timesteps_total: 1450000
  training_iteration: 290
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 35.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=12141], 4012 s, 290 iter, 1450000 ts, 1.69e+03 rew

agent-1: 320.0
agent-2: 376.0
agent-3: 283.0
agent-4: 369.0
agent-5: 389.0
Sum Reward: 1737.0
Avg Reward: 347.4
Min Reward: 283.0
Max Reward: 389.0
Gini Coefficient: 0.06171560161197467
20:20 Ratio: 1.3745583038869258
Max-min Ratio: 1.3745583038869258
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_13-07-32
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1931.0
  episode_reward_mean: 1691.9
  episode_reward_min: 1249.0
  episodes_this_iter: 1
  episodes_total: 290
  experiment_id: ebedc1946062457bb682d57fae83bd74
  hostname: gpu052
  info:
    apply_time_ms: 2.7
    dispatch_time_ms: 6.543
    learner:
      cur_lr: 0.0012634299928322434
      grad_gnorm: 40.0
      policy_entropy: 15.233323097229004
      policy_loss: 10.94333553314209
      var_gnorm: 38.77779769897461
      vf_explained_var: 0.3062315583229065
      vf_loss: 428.7837829589844
    num_steps_sampled: 1455000
    num_steps_trained: 1455000
    wait_time_ms: 126.229
  iterations_since_restore: 291
  node_ip: 172.17.8.52
  num_metric_batches_dropped: 0
  pid: 12141
  policy_reward_mean: {}
  time_since_restore: 4025.6758601665497
  time_this_iter_s: 12.914724826812744
  time_total_s: 4025.6758601665497
  timestamp: 1594141652
  timesteps_since_restore: 1455000
  timesteps_this_iter: 5000
  timesteps_total: 1455000
  training_iteration: 291
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 35.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=12141], 4025 s, 291 iter, 1455000 ts, 1.69e+03 rew

agent-1: 317.0
agent-2: 352.0
agent-3: 320.0
agent-4: 341.0
agent-5: 404.0
Sum Reward: 1734.0
Avg Reward: 346.8
Min Reward: 317.0
Max Reward: 404.0
Gini Coefficient: 0.047520184544406
20:20 Ratio: 1.274447949526814
Max-min Ratio: 1.274447949526814
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_13-07-45
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1931.0
  episode_reward_mean: 1691.07
  episode_reward_min: 1249.0
  episodes_this_iter: 1
  episodes_total: 291
  experiment_id: ebedc1946062457bb682d57fae83bd74
  hostname: gpu052
  info:
    apply_time_ms: 2.646
    dispatch_time_ms: 6.723
    learner:
      cur_lr: 0.0012630970450118184
      grad_gnorm: 39.99999237060547
      policy_entropy: 14.19953441619873
      policy_loss: 5.74847412109375
      var_gnorm: 38.79136657714844
      vf_explained_var: 0.9486238956451416
      vf_loss: 70.9374771118164
    num_steps_sampled: 1460000
    num_steps_trained: 1460000
    wait_time_ms: 122.948
  iterations_since_restore: 292
  node_ip: 172.17.8.52
  num_metric_batches_dropped: 0
  pid: 12141
  policy_reward_mean: {}
  time_since_restore: 4038.5499923229218
  time_this_iter_s: 12.87413215637207
  time_total_s: 4038.5499923229218
  timestamp: 1594141665
  timesteps_since_restore: 1460000
  timesteps_this_iter: 5000
  timesteps_total: 1460000
  training_iteration: 292
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 35.3/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=12141], 4038 s, 292 iter, 1460000 ts, 1.69e+03 rew

agent-1: 335.0
agent-2: 417.0
agent-3: 87.0
agent-4: 390.0
agent-5: 319.0
Sum Reward: 1548.0
Avg Reward: 309.6
Min Reward: 87.0
Max Reward: 417.0
Gini Coefficient: 0.18888888888888888
20:20 Ratio: 4.793103448275862
Max-min Ratio: 4.793103448275862
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_13-08-02
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1931.0
  episode_reward_mean: 1688.8
  episode_reward_min: 1249.0
  episodes_this_iter: 1
  episodes_total: 292
  experiment_id: ebedc1946062457bb682d57fae83bd74
  hostname: gpu052
  info:
    apply_time_ms: 2.869
    dispatch_time_ms: 26.994
    learner:
      cur_lr: 0.0012627639807760715
      grad_gnorm: 40.0
      policy_entropy: 28.522735595703125
      policy_loss: 16.629480361938477
      var_gnorm: 38.83819580078125
      vf_explained_var: -0.17356204986572266
      vf_loss: 347.13665771484375
    num_steps_sampled: 1465000
    num_steps_trained: 1465000
    wait_time_ms: 117.258
  iterations_since_restore: 293
  node_ip: 172.17.8.52
  num_metric_batches_dropped: 0
  pid: 12141
  policy_reward_mean: {}
  time_since_restore: 4055.5220909118652
  time_this_iter_s: 16.97209858894348
  time_total_s: 4055.5220909118652
  timestamp: 1594141682
  timesteps_since_restore: 1465000
  timesteps_this_iter: 5000
  timesteps_total: 1465000
  training_iteration: 293
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 35.3/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=12141], 4055 s, 293 iter, 1465000 ts, 1.69e+03 rew

agent-1: 288.0
agent-2: 319.0
agent-3: 301.0
agent-4: 346.0
agent-5: 324.0
Sum Reward: 1578.0
Avg Reward: 315.6
Min Reward: 288.0
Max Reward: 346.0
Gini Coefficient: 0.03523447401774398
20:20 Ratio: 1.2013888888888888
Max-min Ratio: 1.2013888888888888
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_13-08-17
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1931.0
  episode_reward_mean: 1685.4
  episode_reward_min: 1249.0
  episodes_this_iter: 1
  episodes_total: 293
  experiment_id: ebedc1946062457bb682d57fae83bd74
  hostname: gpu052
  info:
    apply_time_ms: 3.489
    dispatch_time_ms: 8.018
    learner:
      cur_lr: 0.0012624310329556465
      grad_gnorm: 40.000003814697266
      policy_entropy: 30.116863250732422
      policy_loss: -9.776700019836426
      var_gnorm: 38.871891021728516
      vf_explained_var: 0.3597347140312195
      vf_loss: 81.17091369628906
    num_steps_sampled: 1470000
    num_steps_trained: 1470000
    wait_time_ms: 119.807
  iterations_since_restore: 294
  node_ip: 172.17.8.52
  num_metric_batches_dropped: 0
  pid: 12141
  policy_reward_mean: {}
  time_since_restore: 4069.976819753647
  time_this_iter_s: 14.454728841781616
  time_total_s: 4069.976819753647
  timestamp: 1594141697
  timesteps_since_restore: 1470000
  timesteps_this_iter: 5000
  timesteps_total: 1470000
  training_iteration: 294
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 35.3/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=12141], 4069 s, 294 iter, 1470000 ts, 1.69e+03 rew

agent-1: 326.0
agent-2: 334.0
agent-3: 296.0
agent-4: 306.0
agent-5: 316.0
Sum Reward: 1578.0
Avg Reward: 315.6
Min Reward: 296.0
Max Reward: 334.0
Gini Coefficient: 0.024334600760456272
20:20 Ratio: 1.1283783783783783
Max-min Ratio: 1.1283783783783783
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_13-08-30
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1931.0
  episode_reward_mean: 1683.48
  episode_reward_min: 1249.0
  episodes_this_iter: 1
  episodes_total: 294
  experiment_id: ebedc1946062457bb682d57fae83bd74
  hostname: gpu052
  info:
    apply_time_ms: 2.621
    dispatch_time_ms: 5.741
    learner:
      cur_lr: 0.0012620979687198997
      grad_gnorm: 40.0
      policy_entropy: 21.2554931640625
      policy_loss: 1.8399686813354492
      var_gnorm: 38.8668327331543
      vf_explained_var: 0.5183218717575073
      vf_loss: 34.488101959228516
    num_steps_sampled: 1475000
    num_steps_trained: 1475000
    wait_time_ms: 126.128
  iterations_since_restore: 295
  node_ip: 172.17.8.52
  num_metric_batches_dropped: 0
  pid: 12141
  policy_reward_mean: {}
  time_since_restore: 4082.8066210746765
  time_this_iter_s: 12.829801321029663
  time_total_s: 4082.8066210746765
  timestamp: 1594141710
  timesteps_since_restore: 1475000
  timesteps_this_iter: 5000
  timesteps_total: 1475000
  training_iteration: 295
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 35.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=12141], 4082 s, 295 iter, 1475000 ts, 1.68e+03 rew

agent-1: 289.0
agent-2: 317.0
agent-3: 279.0
agent-4: 308.0
agent-5: 227.0
Sum Reward: 1420.0
Avg Reward: 284.0
Min Reward: 227.0
Max Reward: 317.0
Gini Coefficient: 0.05887323943661972
20:20 Ratio: 1.39647577092511
Max-min Ratio: 1.39647577092511
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_13-08-43
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1931.0
  episode_reward_mean: 1680.11
  episode_reward_min: 1249.0
  episodes_this_iter: 1
  episodes_total: 295
  experiment_id: ebedc1946062457bb682d57fae83bd74
  hostname: gpu052
  info:
    apply_time_ms: 2.908
    dispatch_time_ms: 27.18
    learner:
      cur_lr: 0.0012617650208994746
      grad_gnorm: 39.99998092651367
      policy_entropy: 31.871599197387695
      policy_loss: 27.864240646362305
      var_gnorm: 38.82810592651367
      vf_explained_var: 0.4040032625198364
      vf_loss: 54.221343994140625
    num_steps_sampled: 1480000
    num_steps_trained: 1480000
    wait_time_ms: 100.729
  iterations_since_restore: 296
  node_ip: 172.17.8.52
  num_metric_batches_dropped: 0
  pid: 12141
  policy_reward_mean: {}
  time_since_restore: 4096.108426809311
  time_this_iter_s: 13.3018057346344
  time_total_s: 4096.108426809311
  timestamp: 1594141723
  timesteps_since_restore: 1480000
  timesteps_this_iter: 5000
  timesteps_total: 1480000
  training_iteration: 296
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 35.3/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=12141], 4096 s, 296 iter, 1480000 ts, 1.68e+03 rew

agent-1: 252.0
agent-2: 273.0
agent-3: 228.0
agent-4: 305.0
agent-5: 265.0
Sum Reward: 1323.0
Avg Reward: 264.6
Min Reward: 228.0
Max Reward: 305.0
Gini Coefficient: 0.05291005291005291
20:20 Ratio: 1.337719298245614
Max-min Ratio: 1.337719298245614
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_13-08-56
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1931.0
  episode_reward_mean: 1676.5
  episode_reward_min: 1249.0
  episodes_this_iter: 1
  episodes_total: 296
  experiment_id: ebedc1946062457bb682d57fae83bd74
  hostname: gpu052
  info:
    apply_time_ms: 2.589
    dispatch_time_ms: 21.712
    learner:
      cur_lr: 0.0012614319566637278
      grad_gnorm: 38.288841247558594
      policy_entropy: 24.435476303100586
      policy_loss: 6.978857040405273
      var_gnorm: 38.85741424560547
      vf_explained_var: -0.010622262954711914
      vf_loss: 24.4958553314209
    num_steps_sampled: 1485000
    num_steps_trained: 1485000
    wait_time_ms: 113.652
  iterations_since_restore: 297
  node_ip: 172.17.8.52
  num_metric_batches_dropped: 0
  pid: 12141
  policy_reward_mean: {}
  time_since_restore: 4108.952152013779
  time_this_iter_s: 12.843725204467773
  time_total_s: 4108.952152013779
  timestamp: 1594141736
  timesteps_since_restore: 1485000
  timesteps_this_iter: 5000
  timesteps_total: 1485000
  training_iteration: 297
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 35.3/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=12141], 4108 s, 297 iter, 1485000 ts, 1.68e+03 rew

agent-1: 322.0
agent-2: 287.0
agent-3: 258.0
agent-4: 270.0
agent-5: 334.0
Sum Reward: 1471.0
Avg Reward: 294.2
Min Reward: 258.0
Max Reward: 334.0
Gini Coefficient: 0.05547246770904147
20:20 Ratio: 1.2945736434108528
Max-min Ratio: 1.2945736434108528
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_13-09-09
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1931.0
  episode_reward_mean: 1673.61
  episode_reward_min: 1249.0
  episodes_this_iter: 1
  episodes_total: 297
  experiment_id: ebedc1946062457bb682d57fae83bd74
  hostname: gpu052
  info:
    apply_time_ms: 3.989
    dispatch_time_ms: 19.184
    learner:
      cur_lr: 0.0012610990088433027
      grad_gnorm: 39.999996185302734
      policy_entropy: 9.974468231201172
      policy_loss: 22.205015182495117
      var_gnorm: 38.81246566772461
      vf_explained_var: 0.24714910984039307
      vf_loss: 56.52450180053711
    num_steps_sampled: 1490000
    num_steps_trained: 1490000
    wait_time_ms: 103.352
  iterations_since_restore: 298
  node_ip: 172.17.8.52
  num_metric_batches_dropped: 0
  pid: 12141
  policy_reward_mean: {}
  time_since_restore: 4122.237603902817
  time_this_iter_s: 13.285451889038086
  time_total_s: 4122.237603902817
  timestamp: 1594141749
  timesteps_since_restore: 1490000
  timesteps_this_iter: 5000
  timesteps_total: 1490000
  training_iteration: 298
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 35.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=12141], 4122 s, 298 iter, 1490000 ts, 1.67e+03 rew

agent-1: 266.0
agent-2: 308.0
agent-3: 272.0
agent-4: 299.0
agent-5: 307.0
Sum Reward: 1452.0
Avg Reward: 290.4
Min Reward: 266.0
Max Reward: 308.0
Gini Coefficient: 0.03278236914600551
20:20 Ratio: 1.1578947368421053
Max-min Ratio: 1.1578947368421053
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_13-09-22
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1931.0
  episode_reward_mean: 1670.32
  episode_reward_min: 1249.0
  episodes_this_iter: 1
  episodes_total: 298
  experiment_id: ebedc1946062457bb682d57fae83bd74
  hostname: gpu052
  info:
    apply_time_ms: 2.961
    dispatch_time_ms: 7.981
    learner:
      cur_lr: 0.0012607659446075559
      grad_gnorm: 40.000003814697266
      policy_entropy: 27.545377731323242
      policy_loss: -5.259185314178467
      var_gnorm: 38.904296875
      vf_explained_var: 0.3361802101135254
      vf_loss: 48.659454345703125
    num_steps_sampled: 1495000
    num_steps_trained: 1495000
    wait_time_ms: 124.415
  iterations_since_restore: 299
  node_ip: 172.17.8.52
  num_metric_batches_dropped: 0
  pid: 12141
  policy_reward_mean: {}
  time_since_restore: 4135.204883813858
  time_this_iter_s: 12.96727991104126
  time_total_s: 4135.204883813858
  timestamp: 1594141762
  timesteps_since_restore: 1495000
  timesteps_this_iter: 5000
  timesteps_total: 1495000
  training_iteration: 299
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 35.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=12141], 4135 s, 299 iter, 1495000 ts, 1.67e+03 rew

agent-1: 312.0
agent-2: 332.0
agent-3: 332.0
agent-4: 318.0
agent-5: 316.0
Sum Reward: 1610.0
Avg Reward: 322.0
Min Reward: 312.0
Max Reward: 332.0
Gini Coefficient: 0.01391304347826087
20:20 Ratio: 1.064102564102564
Max-min Ratio: 1.064102564102564
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_13-09-35
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1931.0
  episode_reward_mean: 1668.32
  episode_reward_min: 1249.0
  episodes_this_iter: 1
  episodes_total: 299
  experiment_id: ebedc1946062457bb682d57fae83bd74
  hostname: gpu052
  info:
    apply_time_ms: 2.632
    dispatch_time_ms: 8.249
    learner:
      cur_lr: 0.0012604329967871308
      grad_gnorm: 40.0
      policy_entropy: 23.486347198486328
      policy_loss: 32.4918212890625
      var_gnorm: 38.927738189697266
      vf_explained_var: -0.07854413986206055
      vf_loss: 84.64716339111328
    num_steps_sampled: 1500000
    num_steps_trained: 1500000
    wait_time_ms: 113.617
  iterations_since_restore: 300
  node_ip: 172.17.8.52
  num_metric_batches_dropped: 0
  pid: 12141
  policy_reward_mean: {}
  time_since_restore: 4148.020901918411
  time_this_iter_s: 12.816018104553223
  time_total_s: 4148.020901918411
  timestamp: 1594141775
  timesteps_since_restore: 1500000
  timesteps_this_iter: 5000
  timesteps_total: 1500000
  training_iteration: 300
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 35.3/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=12141], 4148 s, 300 iter, 1500000 ts, 1.67e+03 rew

agent-1: 294.0
agent-2: 306.0
agent-3: 312.0
agent-4: 334.0
agent-5: 287.0
Sum Reward: 1533.0
Avg Reward: 306.6
Min Reward: 287.0
Max Reward: 334.0
Gini Coefficient: 0.029223744292237442
20:20 Ratio: 1.1637630662020906
Max-min Ratio: 1.1637630662020906
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_13-09-48
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1931.0
  episode_reward_mean: 1667.06
  episode_reward_min: 1249.0
  episodes_this_iter: 1
  episodes_total: 300
  experiment_id: ebedc1946062457bb682d57fae83bd74
  hostname: gpu052
  info:
    apply_time_ms: 4.277
    dispatch_time_ms: 8.307
    learner:
      cur_lr: 0.0012601000489667058
      grad_gnorm: 40.0
      policy_entropy: 22.318920135498047
      policy_loss: 4.084167957305908
      var_gnorm: 38.9581298828125
      vf_explained_var: 0.6668204069137573
      vf_loss: 34.93288803100586
    num_steps_sampled: 1505000
    num_steps_trained: 1505000
    wait_time_ms: 125.832
  iterations_since_restore: 301
  node_ip: 172.17.8.52
  num_metric_batches_dropped: 0
  pid: 12141
  policy_reward_mean: {}
  time_since_restore: 4160.588383674622
  time_this_iter_s: 12.567481756210327
  time_total_s: 4160.588383674622
  timestamp: 1594141788
  timesteps_since_restore: 1505000
  timesteps_this_iter: 5000
  timesteps_total: 1505000
  training_iteration: 301
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 35.3/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=12141], 4160 s, 301 iter, 1505000 ts, 1.67e+03 rew

agent-1: 252.0
agent-2: 354.0
agent-3: 340.0
agent-4: 298.0
agent-5: 279.0
Sum Reward: 1523.0
Avg Reward: 304.6
Min Reward: 252.0
Max Reward: 354.0
Gini Coefficient: 0.0695994747209455
20:20 Ratio: 1.4047619047619047
Max-min Ratio: 1.4047619047619047
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_13-10-02
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1931.0
  episode_reward_mean: 1667.38
  episode_reward_min: 1249.0
  episodes_this_iter: 1
  episodes_total: 301
  experiment_id: ebedc1946062457bb682d57fae83bd74
  hostname: gpu052
  info:
    apply_time_ms: 4.369
    dispatch_time_ms: 6.787
    learner:
      cur_lr: 0.001259766984730959
      grad_gnorm: 40.000003814697266
      policy_entropy: 16.525920867919922
      policy_loss: 14.55694580078125
      var_gnorm: 38.936363220214844
      vf_explained_var: 0.5872238278388977
      vf_loss: 67.53214263916016
    num_steps_sampled: 1510000
    num_steps_trained: 1510000
    wait_time_ms: 116.151
  iterations_since_restore: 302
  node_ip: 172.17.8.52
  num_metric_batches_dropped: 0
  pid: 12141
  policy_reward_mean: {}
  time_since_restore: 4174.5615248680115
  time_this_iter_s: 13.973141193389893
  time_total_s: 4174.5615248680115
  timestamp: 1594141802
  timesteps_since_restore: 1510000
  timesteps_this_iter: 5000
  timesteps_total: 1510000
  training_iteration: 302
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 35.3/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=12141], 4174 s, 302 iter, 1510000 ts, 1.67e+03 rew

agent-1: 305.0
agent-2: 359.0
agent-3: 302.0
agent-4: 326.0
agent-5: 334.0
Sum Reward: 1626.0
Avg Reward: 325.2
Min Reward: 302.0
Max Reward: 359.0
Gini Coefficient: 0.03517835178351784
20:20 Ratio: 1.1887417218543046
Max-min Ratio: 1.1887417218543046
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_13-10-15
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1931.0
  episode_reward_mean: 1667.14
  episode_reward_min: 1249.0
  episodes_this_iter: 1
  episodes_total: 302
  experiment_id: ebedc1946062457bb682d57fae83bd74
  hostname: gpu052
  info:
    apply_time_ms: 3.067
    dispatch_time_ms: 26.076
    learner:
      cur_lr: 0.001259434036910534
      grad_gnorm: 40.000022888183594
      policy_entropy: 26.85042381286621
      policy_loss: -22.51664924621582
      var_gnorm: 38.99294662475586
      vf_explained_var: 0.11326903104782104
      vf_loss: 51.64239501953125
    num_steps_sampled: 1515000
    num_steps_trained: 1515000
    wait_time_ms: 107.66
  iterations_since_restore: 303
  node_ip: 172.17.8.52
  num_metric_batches_dropped: 0
  pid: 12141
  policy_reward_mean: {}
  time_since_restore: 4188.077620267868
  time_this_iter_s: 13.516095399856567
  time_total_s: 4188.077620267868
  timestamp: 1594141815
  timesteps_since_restore: 1515000
  timesteps_this_iter: 5000
  timesteps_total: 1515000
  training_iteration: 303
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 35.3/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=12141], 4188 s, 303 iter, 1515000 ts, 1.67e+03 rew

agent-1: 320.0
agent-2: 277.0
agent-3: 289.0
agent-4: 306.0
agent-5: 315.0
Sum Reward: 1507.0
Avg Reward: 301.4
Min Reward: 277.0
Max Reward: 320.0
Gini Coefficient: 0.029727936297279364
20:20 Ratio: 1.1552346570397112
Max-min Ratio: 1.1552346570397112
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_13-10-29
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1931.0
  episode_reward_mean: 1665.17
  episode_reward_min: 1249.0
  episodes_this_iter: 1
  episodes_total: 303
  experiment_id: ebedc1946062457bb682d57fae83bd74
  hostname: gpu052
  info:
    apply_time_ms: 2.814
    dispatch_time_ms: 31.688
    learner:
      cur_lr: 0.001259100972674787
      grad_gnorm: 39.87994384765625
      policy_entropy: 27.083097457885742
      policy_loss: 2.2524454593658447
      var_gnorm: 39.0438117980957
      vf_explained_var: 0.20720863342285156
      vf_loss: 21.567481994628906
    num_steps_sampled: 1520000
    num_steps_trained: 1520000
    wait_time_ms: 85.002
  iterations_since_restore: 304
  node_ip: 172.17.8.52
  num_metric_batches_dropped: 0
  pid: 12141
  policy_reward_mean: {}
  time_since_restore: 4202.184364080429
  time_this_iter_s: 14.106743812561035
  time_total_s: 4202.184364080429
  timestamp: 1594141829
  timesteps_since_restore: 1520000
  timesteps_this_iter: 5000
  timesteps_total: 1520000
  training_iteration: 304
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 35.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=12141], 4202 s, 304 iter, 1520000 ts, 1.67e+03 rew

agent-1: 270.0
agent-2: 349.0
agent-3: 242.0
agent-4: 342.0
agent-5: 311.0
Sum Reward: 1514.0
Avg Reward: 302.8
Min Reward: 242.0
Max Reward: 349.0
Gini Coefficient: 0.07556142668428005
20:20 Ratio: 1.4421487603305785
Max-min Ratio: 1.4421487603305785
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_13-10-43
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1931.0
  episode_reward_mean: 1663.34
  episode_reward_min: 1249.0
  episodes_this_iter: 1
  episodes_total: 304
  experiment_id: ebedc1946062457bb682d57fae83bd74
  hostname: gpu052
  info:
    apply_time_ms: 3.098
    dispatch_time_ms: 15.957
    learner:
      cur_lr: 0.001258768024854362
      grad_gnorm: 40.0
      policy_entropy: 23.911197662353516
      policy_loss: 7.660748481750488
      var_gnorm: 39.091400146484375
      vf_explained_var: -0.08992016315460205
      vf_loss: 15.52294921875
    num_steps_sampled: 1525000
    num_steps_trained: 1525000
    wait_time_ms: 125.942
  iterations_since_restore: 305
  node_ip: 172.17.8.52
  num_metric_batches_dropped: 0
  pid: 12141
  policy_reward_mean: {}
  time_since_restore: 4216.116811752319
  time_this_iter_s: 13.932447671890259
  time_total_s: 4216.116811752319
  timestamp: 1594141843
  timesteps_since_restore: 1525000
  timesteps_this_iter: 5000
  timesteps_total: 1525000
  training_iteration: 305
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 35.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=12141], 4216 s, 305 iter, 1525000 ts, 1.66e+03 rew

agent-1: 323.0
agent-2: 347.0
agent-3: 243.0
agent-4: 363.0
agent-5: 312.0
Sum Reward: 1588.0
Avg Reward: 317.6
Min Reward: 243.0
Max Reward: 363.0
Gini Coefficient: 0.06926952141057935
20:20 Ratio: 1.4938271604938271
Max-min Ratio: 1.4938271604938271
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_13-10-58
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1931.0
  episode_reward_mean: 1662.75
  episode_reward_min: 1249.0
  episodes_this_iter: 1
  episodes_total: 305
  experiment_id: ebedc1946062457bb682d57fae83bd74
  hostname: gpu052
  info:
    apply_time_ms: 3.239
    dispatch_time_ms: 27.478
    learner:
      cur_lr: 0.0012584349606186152
      grad_gnorm: 40.0
      policy_entropy: 9.733343124389648
      policy_loss: 3.710653305053711
      var_gnorm: 39.12880325317383
      vf_explained_var: 0.5665371417999268
      vf_loss: 48.74506378173828
    num_steps_sampled: 1530000
    num_steps_trained: 1530000
    wait_time_ms: 106.573
  iterations_since_restore: 306
  node_ip: 172.17.8.52
  num_metric_batches_dropped: 0
  pid: 12141
  policy_reward_mean: {}
  time_since_restore: 4231.168510198593
  time_this_iter_s: 15.051698446273804
  time_total_s: 4231.168510198593
  timestamp: 1594141858
  timesteps_since_restore: 1530000
  timesteps_this_iter: 5000
  timesteps_total: 1530000
  training_iteration: 306
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 35.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=12141], 4231 s, 306 iter, 1530000 ts, 1.66e+03 rew

agent-1: 309.0
agent-2: 377.0
agent-3: 323.0
agent-4: 328.0
agent-5: 361.0
Sum Reward: 1698.0
Avg Reward: 339.6
Min Reward: 309.0
Max Reward: 377.0
Gini Coefficient: 0.04098939929328622
20:20 Ratio: 1.220064724919094
Max-min Ratio: 1.220064724919094
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_13-11-12
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1931.0
  episode_reward_mean: 1663.51
  episode_reward_min: 1249.0
  episodes_this_iter: 1
  episodes_total: 306
  experiment_id: ebedc1946062457bb682d57fae83bd74
  hostname: gpu052
  info:
    apply_time_ms: 3.358
    dispatch_time_ms: 30.977
    learner:
      cur_lr: 0.0012581020127981901
      grad_gnorm: 40.0
      policy_entropy: 11.889593124389648
      policy_loss: 3.0946996212005615
      var_gnorm: 39.15230178833008
      vf_explained_var: 0.47681891918182373
      vf_loss: 66.222900390625
    num_steps_sampled: 1535000
    num_steps_trained: 1535000
    wait_time_ms: 113.944
  iterations_since_restore: 307
  node_ip: 172.17.8.52
  num_metric_batches_dropped: 0
  pid: 12141
  policy_reward_mean: {}
  time_since_restore: 4244.811205625534
  time_this_iter_s: 13.642695426940918
  time_total_s: 4244.811205625534
  timestamp: 1594141872
  timesteps_since_restore: 1535000
  timesteps_this_iter: 5000
  timesteps_total: 1535000
  training_iteration: 307
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 35.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=12141], 4244 s, 307 iter, 1535000 ts, 1.66e+03 rew

agent-1: 342.0
agent-2: 355.0
agent-3: 359.0
agent-4: 366.0
agent-5: 350.0
Sum Reward: 1772.0
Avg Reward: 354.4
Min Reward: 342.0
Max Reward: 366.0
Gini Coefficient: 0.012866817155756207
20:20 Ratio: 1.0701754385964912
Max-min Ratio: 1.0701754385964912
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_13-11-27
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1931.0
  episode_reward_mean: 1666.02
  episode_reward_min: 1249.0
  episodes_this_iter: 1
  episodes_total: 307
  experiment_id: ebedc1946062457bb682d57fae83bd74
  hostname: gpu052
  info:
    apply_time_ms: 2.62
    dispatch_time_ms: 24.018
    learner:
      cur_lr: 0.0012577689485624433
      grad_gnorm: 40.0
      policy_entropy: 13.005033493041992
      policy_loss: 15.340898513793945
      var_gnorm: 39.30609893798828
      vf_explained_var: 0.7249776124954224
      vf_loss: 52.15485382080078
    num_steps_sampled: 1540000
    num_steps_trained: 1540000
    wait_time_ms: 106.585
  iterations_since_restore: 308
  node_ip: 172.17.8.52
  num_metric_batches_dropped: 0
  pid: 12141
  policy_reward_mean: {}
  time_since_restore: 4259.910928964615
  time_this_iter_s: 15.09972333908081
  time_total_s: 4259.910928964615
  timestamp: 1594141887
  timesteps_since_restore: 1540000
  timesteps_this_iter: 5000
  timesteps_total: 1540000
  training_iteration: 308
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 34.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=12141], 4259 s, 308 iter, 1540000 ts, 1.67e+03 rew

agent-1: 368.0
agent-2: 268.0
agent-3: 219.0
agent-4: 353.0
agent-5: 384.0
Sum Reward: 1592.0
Avg Reward: 318.4
Min Reward: 219.0
Max Reward: 384.0
Gini Coefficient: 0.10804020100502512
20:20 Ratio: 1.7534246575342465
Max-min Ratio: 1.7534246575342465
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_13-11-41
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1931.0
  episode_reward_mean: 1666.89
  episode_reward_min: 1249.0
  episodes_this_iter: 1
  episodes_total: 308
  experiment_id: ebedc1946062457bb682d57fae83bd74
  hostname: gpu052
  info:
    apply_time_ms: 3.719
    dispatch_time_ms: 29.85
    learner:
      cur_lr: 0.0012574360007420182
      grad_gnorm: 40.0
      policy_entropy: 15.58553695678711
      policy_loss: 20.520784378051758
      var_gnorm: 39.40437698364258
      vf_explained_var: 0.31090813875198364
      vf_loss: 81.12398529052734
    num_steps_sampled: 1545000
    num_steps_trained: 1545000
    wait_time_ms: 116.932
  iterations_since_restore: 309
  node_ip: 172.17.8.52
  num_metric_batches_dropped: 0
  pid: 12141
  policy_reward_mean: {}
  time_since_restore: 4273.273497581482
  time_this_iter_s: 13.362568616867065
  time_total_s: 4273.273497581482
  timestamp: 1594141901
  timesteps_since_restore: 1545000
  timesteps_this_iter: 5000
  timesteps_total: 1545000
  training_iteration: 309
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 35.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=12141], 4273 s, 309 iter, 1545000 ts, 1.67e+03 rew

agent-1: 346.0
agent-2: 328.0
agent-3: 375.0
agent-4: 257.0
agent-5: 277.0
Sum Reward: 1583.0
Avg Reward: 316.6
Min Reward: 257.0
Max Reward: 375.0
Gini Coefficient: 0.07706885660138976
20:20 Ratio: 1.4591439688715953
Max-min Ratio: 1.4591439688715953
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_13-11-55
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1931.0
  episode_reward_mean: 1666.08
  episode_reward_min: 1249.0
  episodes_this_iter: 1
  episodes_total: 309
  experiment_id: ebedc1946062457bb682d57fae83bd74
  hostname: gpu052
  info:
    apply_time_ms: 3.22
    dispatch_time_ms: 6.021
    learner:
      cur_lr: 0.0012571030529215932
      grad_gnorm: 40.0
      policy_entropy: 13.389752388000488
      policy_loss: -3.418617010116577
      var_gnorm: 39.430450439453125
      vf_explained_var: -0.2491854429244995
      vf_loss: 81.1436767578125
    num_steps_sampled: 1550000
    num_steps_trained: 1550000
    wait_time_ms: 119.483
  iterations_since_restore: 310
  node_ip: 172.17.8.52
  num_metric_batches_dropped: 0
  pid: 12141
  policy_reward_mean: {}
  time_since_restore: 4287.260085105896
  time_this_iter_s: 13.986587524414062
  time_total_s: 4287.260085105896
  timestamp: 1594141915
  timesteps_since_restore: 1550000
  timesteps_this_iter: 5000
  timesteps_total: 1550000
  training_iteration: 310
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 35.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=12141], 4287 s, 310 iter, 1550000 ts, 1.67e+03 rew

agent-1: 322.0
agent-2: 358.0
agent-3: 353.0
agent-4: 377.0
agent-5: 299.0
Sum Reward: 1709.0
Avg Reward: 341.8
Min Reward: 299.0
Max Reward: 377.0
Gini Coefficient: 0.044938560561732004
20:20 Ratio: 1.2608695652173914
Max-min Ratio: 1.2608695652173914
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_13-12-07
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1931.0
  episode_reward_mean: 1666.58
  episode_reward_min: 1249.0
  episodes_this_iter: 1
  episodes_total: 310
  experiment_id: ebedc1946062457bb682d57fae83bd74
  hostname: gpu052
  info:
    apply_time_ms: 3.53
    dispatch_time_ms: 6.228
    learner:
      cur_lr: 0.0012567699886858463
      grad_gnorm: 39.9999885559082
      policy_entropy: 12.1777982711792
      policy_loss: -2.1742236614227295
      var_gnorm: 39.472190856933594
      vf_explained_var: 0.45883679389953613
      vf_loss: 67.92289733886719
    num_steps_sampled: 1555000
    num_steps_trained: 1555000
    wait_time_ms: 124.831
  iterations_since_restore: 311
  node_ip: 172.17.8.52
  num_metric_batches_dropped: 0
  pid: 12141
  policy_reward_mean: {}
  time_since_restore: 4299.995794296265
  time_this_iter_s: 12.735709190368652
  time_total_s: 4299.995794296265
  timestamp: 1594141927
  timesteps_since_restore: 1555000
  timesteps_this_iter: 5000
  timesteps_total: 1555000
  training_iteration: 311
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 35.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=12141], 4299 s, 311 iter, 1555000 ts, 1.67e+03 rew

agent-1: 356.0
agent-2: 382.0
agent-3: 343.0
agent-4: 356.0
agent-5: 357.0
Sum Reward: 1794.0
Avg Reward: 358.8
Min Reward: 343.0
Max Reward: 382.0
Gini Coefficient: 0.017614269788182833
20:20 Ratio: 1.1137026239067056
Max-min Ratio: 1.1137026239067056
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_13-12-21
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1931.0
  episode_reward_mean: 1668.71
  episode_reward_min: 1249.0
  episodes_this_iter: 1
  episodes_total: 311
  experiment_id: ebedc1946062457bb682d57fae83bd74
  hostname: gpu052
  info:
    apply_time_ms: 4.04
    dispatch_time_ms: 7.659
    learner:
      cur_lr: 0.0012564370408654213
      grad_gnorm: 39.999996185302734
      policy_entropy: 9.864911079406738
      policy_loss: -1.4173413515090942
      var_gnorm: 39.49073028564453
      vf_explained_var: -0.11068129539489746
      vf_loss: 27.363439559936523
    num_steps_sampled: 1560000
    num_steps_trained: 1560000
    wait_time_ms: 126.219
  iterations_since_restore: 312
  node_ip: 172.17.8.52
  num_metric_batches_dropped: 0
  pid: 12141
  policy_reward_mean: {}
  time_since_restore: 4314.033364534378
  time_this_iter_s: 14.037570238113403
  time_total_s: 4314.033364534378
  timestamp: 1594141941
  timesteps_since_restore: 1560000
  timesteps_this_iter: 5000
  timesteps_total: 1560000
  training_iteration: 312
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 35.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=12141], 4314 s, 312 iter, 1560000 ts, 1.67e+03 rew

agent-1: 393.0
agent-2: 366.0
agent-3: 357.0
agent-4: 355.0
agent-5: 354.0
Sum Reward: 1825.0
Avg Reward: 365.0
Min Reward: 354.0
Max Reward: 393.0
Gini Coefficient: 0.019506849315068492
20:20 Ratio: 1.1101694915254237
Max-min Ratio: 1.1101694915254237
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_13-12-34
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1931.0
  episode_reward_mean: 1669.87
  episode_reward_min: 1249.0
  episodes_this_iter: 1
  episodes_total: 312
  experiment_id: ebedc1946062457bb682d57fae83bd74
  hostname: gpu052
  info:
    apply_time_ms: 2.929
    dispatch_time_ms: 6.255
    learner:
      cur_lr: 0.0012561039766296744
      grad_gnorm: 40.0
      policy_entropy: 11.45859432220459
      policy_loss: -7.247214317321777
      var_gnorm: 39.524681091308594
      vf_explained_var: 0.00581592321395874
      vf_loss: 38.06523895263672
    num_steps_sampled: 1565000
    num_steps_trained: 1565000
    wait_time_ms: 126.628
  iterations_since_restore: 313
  node_ip: 172.17.8.52
  num_metric_batches_dropped: 0
  pid: 12141
  policy_reward_mean: {}
  time_since_restore: 4327.007612705231
  time_this_iter_s: 12.974248170852661
  time_total_s: 4327.007612705231
  timestamp: 1594141954
  timesteps_since_restore: 1565000
  timesteps_this_iter: 5000
  timesteps_total: 1565000
  training_iteration: 313
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 35.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=12141], 4327 s, 313 iter, 1565000 ts, 1.67e+03 rew

agent-1: 368.0
agent-2: 363.0
agent-3: 328.0
agent-4: 371.0
agent-5: 347.0
Sum Reward: 1777.0
Avg Reward: 355.4
Min Reward: 328.0
Max Reward: 371.0
Gini Coefficient: 0.024085537422622396
20:20 Ratio: 1.1310975609756098
Max-min Ratio: 1.1310975609756098
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_13-12-49
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1931.0
  episode_reward_mean: 1670.18
  episode_reward_min: 1249.0
  episodes_this_iter: 1
  episodes_total: 313
  experiment_id: ebedc1946062457bb682d57fae83bd74
  hostname: gpu052
  info:
    apply_time_ms: 2.634
    dispatch_time_ms: 7.42
    learner:
      cur_lr: 0.0012557710288092494
      grad_gnorm: 40.000003814697266
      policy_entropy: 12.964890480041504
      policy_loss: 3.352663993835449
      var_gnorm: 39.5670280456543
      vf_explained_var: 0.2928096652030945
      vf_loss: 115.63047790527344
    num_steps_sampled: 1570000
    num_steps_trained: 1570000
    wait_time_ms: 115.393
  iterations_since_restore: 314
  node_ip: 172.17.8.52
  num_metric_batches_dropped: 0
  pid: 12141
  policy_reward_mean: {}
  time_since_restore: 4341.45765209198
  time_this_iter_s: 14.450039386749268
  time_total_s: 4341.45765209198
  timestamp: 1594141969
  timesteps_since_restore: 1570000
  timesteps_this_iter: 5000
  timesteps_total: 1570000
  training_iteration: 314
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 35.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=12141], 4341 s, 314 iter, 1570000 ts, 1.67e+03 rew

agent-1: 317.0
agent-2: 328.0
agent-3: 357.0
agent-4: 322.0
agent-5: 341.0
Sum Reward: 1665.0
Avg Reward: 333.0
Min Reward: 317.0
Max Reward: 357.0
Gini Coefficient: 0.023783783783783784
20:20 Ratio: 1.1261829652996846
Max-min Ratio: 1.1261829652996846
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_13-13-02
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1931.0
  episode_reward_mean: 1668.22
  episode_reward_min: 1249.0
  episodes_this_iter: 1
  episodes_total: 314
  experiment_id: ebedc1946062457bb682d57fae83bd74
  hostname: gpu052
  info:
    apply_time_ms: 3.059
    dispatch_time_ms: 9.416
    learner:
      cur_lr: 0.0012554379645735025
      grad_gnorm: 40.0
      policy_entropy: 9.20064640045166
      policy_loss: 3.200363874435425
      var_gnorm: 39.600196838378906
      vf_explained_var: 0.576972246170044
      vf_loss: 60.205787658691406
    num_steps_sampled: 1575000
    num_steps_trained: 1575000
    wait_time_ms: 121.705
  iterations_since_restore: 315
  node_ip: 172.17.8.52
  num_metric_batches_dropped: 0
  pid: 12141
  policy_reward_mean: {}
  time_since_restore: 4354.184217214584
  time_this_iter_s: 12.72656512260437
  time_total_s: 4354.184217214584
  timestamp: 1594141982
  timesteps_since_restore: 1575000
  timesteps_this_iter: 5000
  timesteps_total: 1575000
  training_iteration: 315
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 35.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=12141], 4354 s, 315 iter, 1575000 ts, 1.67e+03 rew

agent-1: 318.0
agent-2: 333.0
agent-3: 310.0
agent-4: 384.0
agent-5: 376.0
Sum Reward: 1721.0
Avg Reward: 344.2
Min Reward: 310.0
Max Reward: 384.0
Gini Coefficient: 0.04787914003486345
20:20 Ratio: 1.238709677419355
Max-min Ratio: 1.238709677419355
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_13-13-16
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1931.0
  episode_reward_mean: 1667.51
  episode_reward_min: 1249.0
  episodes_this_iter: 1
  episodes_total: 315
  experiment_id: ebedc1946062457bb682d57fae83bd74
  hostname: gpu052
  info:
    apply_time_ms: 2.837
    dispatch_time_ms: 6.523
    learner:
      cur_lr: 0.0012551050167530775
      grad_gnorm: 40.0
      policy_entropy: 8.053130149841309
      policy_loss: 15.416877746582031
      var_gnorm: 39.641414642333984
      vf_explained_var: 0.15222376585006714
      vf_loss: 29.610427856445312
    num_steps_sampled: 1580000
    num_steps_trained: 1580000
    wait_time_ms: 113.803
  iterations_since_restore: 316
  node_ip: 172.17.8.52
  num_metric_batches_dropped: 0
  pid: 12141
  policy_reward_mean: {}
  time_since_restore: 4368.034883260727
  time_this_iter_s: 13.850666046142578
  time_total_s: 4368.034883260727
  timestamp: 1594141996
  timesteps_since_restore: 1580000
  timesteps_this_iter: 5000
  timesteps_total: 1580000
  training_iteration: 316
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 33.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=12141], 4368 s, 316 iter, 1580000 ts, 1.67e+03 rew

agent-1: 320.0
agent-2: 361.0
agent-3: 361.0
agent-4: 304.0
agent-5: 359.0
Sum Reward: 1705.0
Avg Reward: 341.0
Min Reward: 304.0
Max Reward: 361.0
Gini Coefficient: 0.03636363636363636
20:20 Ratio: 1.1875
Max-min Ratio: 1.1875
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_13-13-32
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1931.0
  episode_reward_mean: 1667.87
  episode_reward_min: 1249.0
  episodes_this_iter: 1
  episodes_total: 316
  experiment_id: ebedc1946062457bb682d57fae83bd74
  hostname: gpu052
  info:
    apply_time_ms: 2.926
    dispatch_time_ms: 6.534
    learner:
      cur_lr: 0.0012547719525173306
      grad_gnorm: 40.0000114440918
      policy_entropy: 3.7588701248168945
      policy_loss: -4.8341546058654785
      var_gnorm: 39.686832427978516
      vf_explained_var: 0.34699445962905884
      vf_loss: 100.98804473876953
    num_steps_sampled: 1585000
    num_steps_trained: 1585000
    wait_time_ms: 120.208
  iterations_since_restore: 317
  node_ip: 172.17.8.52
  num_metric_batches_dropped: 0
  pid: 12141
  policy_reward_mean: {}
  time_since_restore: 4384.594965934753
  time_this_iter_s: 16.56008267402649
  time_total_s: 4384.594965934753
  timestamp: 1594142012
  timesteps_since_restore: 1585000
  timesteps_this_iter: 5000
  timesteps_total: 1585000
  training_iteration: 317
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 33.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=12141], 4384 s, 317 iter, 1585000 ts, 1.67e+03 rew

agent-1: 368.0
agent-2: 400.0
agent-3: 347.0
agent-4: 367.0
agent-5: 346.0
Sum Reward: 1828.0
Avg Reward: 365.6
Min Reward: 346.0
Max Reward: 400.0
Gini Coefficient: 0.02822757111597374
20:20 Ratio: 1.1560693641618498
Max-min Ratio: 1.1560693641618498
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_13-13-45
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1931.0
  episode_reward_mean: 1667.9
  episode_reward_min: 1249.0
  episodes_this_iter: 1
  episodes_total: 317
  experiment_id: ebedc1946062457bb682d57fae83bd74
  hostname: gpu052
  info:
    apply_time_ms: 2.661
    dispatch_time_ms: 37.475
    learner:
      cur_lr: 0.0012544390046969056
      grad_gnorm: 40.000003814697266
      policy_entropy: 12.141775131225586
      policy_loss: 7.964666366577148
      var_gnorm: 39.70991134643555
      vf_explained_var: -0.3022172451019287
      vf_loss: 48.63043975830078
    num_steps_sampled: 1590000
    num_steps_trained: 1590000
    wait_time_ms: 75.646
  iterations_since_restore: 318
  node_ip: 172.17.8.52
  num_metric_batches_dropped: 0
  pid: 12141
  policy_reward_mean: {}
  time_since_restore: 4397.560481309891
  time_this_iter_s: 12.965515375137329
  time_total_s: 4397.560481309891
  timestamp: 1594142025
  timesteps_since_restore: 1590000
  timesteps_this_iter: 5000
  timesteps_total: 1590000
  training_iteration: 318
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 33.3/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=12141], 4397 s, 318 iter, 1590000 ts, 1.67e+03 rew

agent-1: 348.0
agent-2: 359.0
agent-3: 362.0
agent-4: 362.0
agent-5: 362.0
Sum Reward: 1793.0
Avg Reward: 358.6
Min Reward: 348.0
Max Reward: 362.0
Gini Coefficient: 0.006915783602900167
20:20 Ratio: 1.0402298850574712
Max-min Ratio: 1.0402298850574712
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_13-13-58
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1880.0
  episode_reward_mean: 1666.52
  episode_reward_min: 1249.0
  episodes_this_iter: 1
  episodes_total: 318
  experiment_id: ebedc1946062457bb682d57fae83bd74
  hostname: gpu052
  info:
    apply_time_ms: 3.891
    dispatch_time_ms: 16.415
    learner:
      cur_lr: 0.0012541060568764806
      grad_gnorm: 40.0
      policy_entropy: 10.455162048339844
      policy_loss: -11.60335922241211
      var_gnorm: 39.70336151123047
      vf_explained_var: -0.10955965518951416
      vf_loss: 68.7292709350586
    num_steps_sampled: 1595000
    num_steps_trained: 1595000
    wait_time_ms: 113.777
  iterations_since_restore: 319
  node_ip: 172.17.8.52
  num_metric_batches_dropped: 0
  pid: 12141
  policy_reward_mean: {}
  time_since_restore: 4410.424576997757
  time_this_iter_s: 12.864095687866211
  time_total_s: 4410.424576997757
  timestamp: 1594142038
  timesteps_since_restore: 1595000
  timesteps_this_iter: 5000
  timesteps_total: 1595000
  training_iteration: 319
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 33.3/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=12141], 4410 s, 319 iter, 1595000 ts, 1.67e+03 rew

agent-1: 356.0
agent-2: 367.0
agent-3: 310.0
agent-4: 342.0
agent-5: 338.0
Sum Reward: 1713.0
Avg Reward: 342.6
Min Reward: 310.0
Max Reward: 367.0
Gini Coefficient: 0.030823117338003504
20:20 Ratio: 1.1838709677419355
Max-min Ratio: 1.1838709677419355
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_13-14-12
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1880.0
  episode_reward_mean: 1666.74
  episode_reward_min: 1249.0
  episodes_this_iter: 1
  episodes_total: 319
  experiment_id: ebedc1946062457bb682d57fae83bd74
  hostname: gpu052
  info:
    apply_time_ms: 2.904
    dispatch_time_ms: 37.81
    learner:
      cur_lr: 0.0012537729926407337
      grad_gnorm: 40.0
      policy_entropy: 15.177724838256836
      policy_loss: 11.590831756591797
      var_gnorm: 39.669525146484375
      vf_explained_var: 0.30687761306762695
      vf_loss: 98.23812866210938
    num_steps_sampled: 1600000
    num_steps_trained: 1600000
    wait_time_ms: 88.061
  iterations_since_restore: 320
  node_ip: 172.17.8.52
  num_metric_batches_dropped: 0
  pid: 12141
  policy_reward_mean: {}
  time_since_restore: 4424.42169713974
  time_this_iter_s: 13.997120141983032
  time_total_s: 4424.42169713974
  timestamp: 1594142052
  timesteps_since_restore: 1600000
  timesteps_this_iter: 5000
  timesteps_total: 1600000
  training_iteration: 320
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 33.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=12141], 4424 s, 320 iter, 1600000 ts, 1.67e+03 rew

agent-1: 331.0
agent-2: 362.0
agent-3: 350.0
agent-4: 342.0
agent-5: 340.0
Sum Reward: 1725.0
Avg Reward: 345.0
Min Reward: 331.0
Max Reward: 362.0
Gini Coefficient: 0.016695652173913042
20:20 Ratio: 1.093655589123867
Max-min Ratio: 1.093655589123867
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_13-14-25
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1880.0
  episode_reward_mean: 1666.62
  episode_reward_min: 1249.0
  episodes_this_iter: 1
  episodes_total: 320
  experiment_id: ebedc1946062457bb682d57fae83bd74
  hostname: gpu052
  info:
    apply_time_ms: 3.988
    dispatch_time_ms: 19.366
    learner:
      cur_lr: 0.0012534400448203087
      grad_gnorm: 40.00000762939453
      policy_entropy: 6.739914894104004
      policy_loss: 0.9704496264457703
      var_gnorm: 39.763336181640625
      vf_explained_var: 0.1641286015510559
      vf_loss: 32.49946594238281
    num_steps_sampled: 1605000
    num_steps_trained: 1605000
    wait_time_ms: 118.857
  iterations_since_restore: 321
  node_ip: 172.17.8.52
  num_metric_batches_dropped: 0
  pid: 12141
  policy_reward_mean: {}
  time_since_restore: 4437.383515357971
  time_this_iter_s: 12.961818218231201
  time_total_s: 4437.383515357971
  timestamp: 1594142065
  timesteps_since_restore: 1605000
  timesteps_this_iter: 5000
  timesteps_total: 1605000
  training_iteration: 321
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 33.3/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=12141], 4437 s, 321 iter, 1605000 ts, 1.67e+03 rew

agent-1: 365.0
agent-2: 305.0
agent-3: 356.0
agent-4: 355.0
agent-5: 338.0
Sum Reward: 1719.0
Avg Reward: 343.8
Min Reward: 305.0
Max Reward: 365.0
Gini Coefficient: 0.03211169284467714
20:20 Ratio: 1.1967213114754098
Max-min Ratio: 1.1967213114754098
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_13-14-39
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1880.0
  episode_reward_mean: 1666.1
  episode_reward_min: 1249.0
  episodes_this_iter: 1
  episodes_total: 321
  experiment_id: ebedc1946062457bb682d57fae83bd74
  hostname: gpu052
  info:
    apply_time_ms: 2.9
    dispatch_time_ms: 29.928
    learner:
      cur_lr: 0.0012531069805845618
      grad_gnorm: 39.99998092651367
      policy_entropy: 6.841413974761963
      policy_loss: 7.650093078613281
      var_gnorm: 39.77085494995117
      vf_explained_var: 0.5033137798309326
      vf_loss: 38.901737213134766
    num_steps_sampled: 1610000
    num_steps_trained: 1610000
    wait_time_ms: 104.972
  iterations_since_restore: 322
  node_ip: 172.17.8.52
  num_metric_batches_dropped: 0
  pid: 12141
  policy_reward_mean: {}
  time_since_restore: 4451.1531457901
  time_this_iter_s: 13.769630432128906
  time_total_s: 4451.1531457901
  timestamp: 1594142079
  timesteps_since_restore: 1610000
  timesteps_this_iter: 5000
  timesteps_total: 1610000
  training_iteration: 322
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 33.3/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=12141], 4451 s, 322 iter, 1610000 ts, 1.67e+03 rew

agent-1: 343.0
agent-2: 339.0
agent-3: 339.0
agent-4: 356.0
agent-5: 391.0
Sum Reward: 1768.0
Avg Reward: 353.6
Min Reward: 339.0
Max Reward: 391.0
Gini Coefficient: 0.02737556561085973
20:20 Ratio: 1.1533923303834808
Max-min Ratio: 1.1533923303834808
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_13-14-52
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1880.0
  episode_reward_mean: 1665.32
  episode_reward_min: 1249.0
  episodes_this_iter: 1
  episodes_total: 322
  experiment_id: ebedc1946062457bb682d57fae83bd74
  hostname: gpu052
  info:
    apply_time_ms: 4.292
    dispatch_time_ms: 20.896
    learner:
      cur_lr: 0.0012527740327641368
      grad_gnorm: 23.259765625
      policy_entropy: 8.500783920288086
      policy_loss: -2.1895341873168945
      var_gnorm: 39.79987335205078
      vf_explained_var: 0.753420889377594
      vf_loss: 37.67429733276367
    num_steps_sampled: 1615000
    num_steps_trained: 1615000
    wait_time_ms: 126.54
  iterations_since_restore: 323
  node_ip: 172.17.8.52
  num_metric_batches_dropped: 0
  pid: 12141
  policy_reward_mean: {}
  time_since_restore: 4464.151128292084
  time_this_iter_s: 12.997982501983643
  time_total_s: 4464.151128292084
  timestamp: 1594142092
  timesteps_since_restore: 1615000
  timesteps_this_iter: 5000
  timesteps_total: 1615000
  training_iteration: 323
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 33.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=12141], 4464 s, 323 iter, 1615000 ts, 1.67e+03 rew

agent-1: 338.0
agent-2: 355.0
agent-3: 320.0
agent-4: 374.0
agent-5: 327.0
Sum Reward: 1714.0
Avg Reward: 342.8
Min Reward: 320.0
Max Reward: 374.0
Gini Coefficient: 0.031738623103850644
20:20 Ratio: 1.16875
Max-min Ratio: 1.16875
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_13-15-06
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1880.0
  episode_reward_mean: 1665.71
  episode_reward_min: 1249.0
  episodes_this_iter: 1
  episodes_total: 323
  experiment_id: ebedc1946062457bb682d57fae83bd74
  hostname: gpu052
  info:
    apply_time_ms: 3.486
    dispatch_time_ms: 21.854
    learner:
      cur_lr: 0.00125244096852839
      grad_gnorm: 40.000022888183594
      policy_entropy: 8.594930648803711
      policy_loss: -3.287104606628418
      var_gnorm: 39.82352066040039
      vf_explained_var: 0.5723491907119751
      vf_loss: 26.461978912353516
    num_steps_sampled: 1620000
    num_steps_trained: 1620000
    wait_time_ms: 117.66
  iterations_since_restore: 324
  node_ip: 172.17.8.52
  num_metric_batches_dropped: 0
  pid: 12141
  policy_reward_mean: {}
  time_since_restore: 4478.292419910431
  time_this_iter_s: 14.141291618347168
  time_total_s: 4478.292419910431
  timestamp: 1594142106
  timesteps_since_restore: 1620000
  timesteps_this_iter: 5000
  timesteps_total: 1620000
  training_iteration: 324
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 33.3/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=12141], 4478 s, 324 iter, 1620000 ts, 1.67e+03 rew

agent-1: 354.0
agent-2: 349.0
agent-3: 345.0
agent-4: 318.0
agent-5: 387.0
Sum Reward: 1753.0
Avg Reward: 350.6
Min Reward: 318.0
Max Reward: 387.0
Gini Coefficient: 0.03354249857387336
20:20 Ratio: 1.2169811320754718
Max-min Ratio: 1.2169811320754718
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_13-15-19
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1880.0
  episode_reward_mean: 1666.27
  episode_reward_min: 1249.0
  episodes_this_iter: 1
  episodes_total: 324
  experiment_id: ebedc1946062457bb682d57fae83bd74
  hostname: gpu052
  info:
    apply_time_ms: 3.049
    dispatch_time_ms: 8.35
    learner:
      cur_lr: 0.001252108020707965
      grad_gnorm: 39.999996185302734
      policy_entropy: 9.852478981018066
      policy_loss: -17.518877029418945
      var_gnorm: 39.839996337890625
      vf_explained_var: 0.2642006278038025
      vf_loss: 83.56057739257812
    num_steps_sampled: 1625000
    num_steps_trained: 1625000
    wait_time_ms: 122.279
  iterations_since_restore: 325
  node_ip: 172.17.8.52
  num_metric_batches_dropped: 0
  pid: 12141
  policy_reward_mean: {}
  time_since_restore: 4491.082866191864
  time_this_iter_s: 12.790446281433105
  time_total_s: 4491.082866191864
  timestamp: 1594142119
  timesteps_since_restore: 1625000
  timesteps_this_iter: 5000
  timesteps_total: 1625000
  training_iteration: 325
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 33.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=12141], 4491 s, 325 iter, 1625000 ts, 1.67e+03 rew

agent-1: 384.0
agent-2: 370.0
agent-3: 300.0
agent-4: 344.0
agent-5: 369.0
Sum Reward: 1767.0
Avg Reward: 353.4
Min Reward: 300.0
Max Reward: 384.0
Gini Coefficient: 0.04391624221844935
20:20 Ratio: 1.28
Max-min Ratio: 1.28
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_13-15-33
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1880.0
  episode_reward_mean: 1665.95
  episode_reward_min: 1249.0
  episodes_this_iter: 1
  episodes_total: 325
  experiment_id: ebedc1946062457bb682d57fae83bd74
  hostname: gpu052
  info:
    apply_time_ms: 3.728
    dispatch_time_ms: 7.048
    learner:
      cur_lr: 0.001251774956472218
      grad_gnorm: 39.999996185302734
      policy_entropy: 19.211170196533203
      policy_loss: -20.55588150024414
      var_gnorm: 39.829837799072266
      vf_explained_var: 0.6028435230255127
      vf_loss: 40.14358901977539
    num_steps_sampled: 1630000
    num_steps_trained: 1630000
    wait_time_ms: 122.316
  iterations_since_restore: 326
  node_ip: 172.17.8.52
  num_metric_batches_dropped: 0
  pid: 12141
  policy_reward_mean: {}
  time_since_restore: 4504.758640766144
  time_this_iter_s: 13.675774574279785
  time_total_s: 4504.758640766144
  timestamp: 1594142133
  timesteps_since_restore: 1630000
  timesteps_this_iter: 5000
  timesteps_total: 1630000
  training_iteration: 326
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 33.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=12141], 4504 s, 326 iter, 1630000 ts, 1.67e+03 rew

agent-1: 338.0
agent-2: 332.0
agent-3: 362.0
agent-4: 336.0
agent-5: 313.0
Sum Reward: 1681.0
Avg Reward: 336.2
Min Reward: 313.0
Max Reward: 362.0
Gini Coefficient: 0.024747174301011303
20:20 Ratio: 1.156549520766773
Max-min Ratio: 1.156549520766773
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_13-15-46
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1880.0
  episode_reward_mean: 1665.92
  episode_reward_min: 1249.0
  episodes_this_iter: 1
  episodes_total: 326
  experiment_id: ebedc1946062457bb682d57fae83bd74
  hostname: gpu052
  info:
    apply_time_ms: 2.734
    dispatch_time_ms: 10.53
    learner:
      cur_lr: 0.001251442008651793
      grad_gnorm: 40.0
      policy_entropy: 8.947098731994629
      policy_loss: -3.9296364784240723
      var_gnorm: 39.96608352661133
      vf_explained_var: 0.26959657669067383
      vf_loss: 32.138816833496094
    num_steps_sampled: 1635000
    num_steps_trained: 1635000
    wait_time_ms: 123.827
  iterations_since_restore: 327
  node_ip: 172.17.8.52
  num_metric_batches_dropped: 0
  pid: 12141
  policy_reward_mean: {}
  time_since_restore: 4517.470336198807
  time_this_iter_s: 12.711695432662964
  time_total_s: 4517.470336198807
  timestamp: 1594142146
  timesteps_since_restore: 1635000
  timesteps_this_iter: 5000
  timesteps_total: 1635000
  training_iteration: 327
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 33.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=12141], 4517 s, 327 iter, 1635000 ts, 1.67e+03 rew

agent-1: 347.0
agent-2: 332.0
agent-3: 318.0
agent-4: 366.0
agent-5: 348.0
Sum Reward: 1711.0
Avg Reward: 342.2
Min Reward: 318.0
Max Reward: 366.0
Gini Coefficient: 0.02618351841028638
20:20 Ratio: 1.150943396226415
Max-min Ratio: 1.150943396226415
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_13-15-59
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1880.0
  episode_reward_mean: 1666.76
  episode_reward_min: 1249.0
  episodes_this_iter: 1
  episodes_total: 327
  experiment_id: ebedc1946062457bb682d57fae83bd74
  hostname: gpu052
  info:
    apply_time_ms: 3.297
    dispatch_time_ms: 6.635
    learner:
      cur_lr: 0.0012511089444160461
      grad_gnorm: 40.0
      policy_entropy: 11.17694091796875
      policy_loss: 22.6347599029541
      var_gnorm: 40.00383377075195
      vf_explained_var: -0.20965325832366943
      vf_loss: 79.3624496459961
    num_steps_sampled: 1640000
    num_steps_trained: 1640000
    wait_time_ms: 118.575
  iterations_since_restore: 328
  node_ip: 172.17.8.52
  num_metric_batches_dropped: 0
  pid: 12141
  policy_reward_mean: {}
  time_since_restore: 4531.027455329895
  time_this_iter_s: 13.557119131088257
  time_total_s: 4531.027455329895
  timestamp: 1594142159
  timesteps_since_restore: 1640000
  timesteps_this_iter: 5000
  timesteps_total: 1640000
  training_iteration: 328
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 33.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=12141], 4531 s, 328 iter, 1640000 ts, 1.67e+03 rew

agent-1: 269.0
agent-2: 340.0
agent-3: 320.0
agent-4: 288.0
agent-5: 325.0
Sum Reward: 1542.0
Avg Reward: 308.4
Min Reward: 269.0
Max Reward: 340.0
Gini Coefficient: 0.04643320363164721
20:20 Ratio: 1.2639405204460967
Max-min Ratio: 1.2639405204460967
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_13-16-12
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1880.0
  episode_reward_mean: 1666.62
  episode_reward_min: 1249.0
  episodes_this_iter: 1
  episodes_total: 328
  experiment_id: ebedc1946062457bb682d57fae83bd74
  hostname: gpu052
  info:
    apply_time_ms: 2.996
    dispatch_time_ms: 12.061
    learner:
      cur_lr: 0.0012507759965956211
      grad_gnorm: 39.999996185302734
      policy_entropy: 7.642884731292725
      policy_loss: -10.56998062133789
      var_gnorm: 40.01894760131836
      vf_explained_var: -0.5674608945846558
      vf_loss: 30.066904067993164
    num_steps_sampled: 1645000
    num_steps_trained: 1645000
    wait_time_ms: 127.075
  iterations_since_restore: 329
  node_ip: 172.17.8.52
  num_metric_batches_dropped: 0
  pid: 12141
  policy_reward_mean: {}
  time_since_restore: 4544.234915494919
  time_this_iter_s: 13.207460165023804
  time_total_s: 4544.234915494919
  timestamp: 1594142172
  timesteps_since_restore: 1645000
  timesteps_this_iter: 5000
  timesteps_total: 1645000
  training_iteration: 329
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 33.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=12141], 4544 s, 329 iter, 1645000 ts, 1.67e+03 rew

agent-1: 362.0
agent-2: 330.0
agent-3: 370.0
agent-4: 278.0
agent-5: 322.0
Sum Reward: 1662.0
Avg Reward: 332.4
Min Reward: 278.0
Max Reward: 370.0
Gini Coefficient: 0.05391095066185319
20:20 Ratio: 1.330935251798561
Max-min Ratio: 1.330935251798561
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_13-16-27
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1880.0
  episode_reward_mean: 1664.7
  episode_reward_min: 1249.0
  episodes_this_iter: 1
  episodes_total: 329
  experiment_id: ebedc1946062457bb682d57fae83bd74
  hostname: gpu052
  info:
    apply_time_ms: 3.131
    dispatch_time_ms: 6.185
    learner:
      cur_lr: 0.001250443048775196
      grad_gnorm: 39.99999237060547
      policy_entropy: 22.14673614501953
      policy_loss: -11.744192123413086
      var_gnorm: 40.085384368896484
      vf_explained_var: 0.7904006242752075
      vf_loss: 23.083547592163086
    num_steps_sampled: 1650000
    num_steps_trained: 1650000
    wait_time_ms: 122.589
  iterations_since_restore: 330
  node_ip: 172.17.8.52
  num_metric_batches_dropped: 0
  pid: 12141
  policy_reward_mean: {}
  time_since_restore: 4558.3534779548645
  time_this_iter_s: 14.118562459945679
  time_total_s: 4558.3534779548645
  timestamp: 1594142187
  timesteps_since_restore: 1650000
  timesteps_this_iter: 5000
  timesteps_total: 1650000
  training_iteration: 330
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 33.3/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=12141], 4558 s, 330 iter, 1650000 ts, 1.66e+03 rew

agent-1: 335.0
agent-2: 374.0
agent-3: 345.0
agent-4: 346.0
agent-5: 362.0
Sum Reward: 1762.0
Avg Reward: 352.4
Min Reward: 335.0
Max Reward: 374.0
Gini Coefficient: 0.021566401816118047
20:20 Ratio: 1.1164179104477612
Max-min Ratio: 1.1164179104477612
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_13-16-40
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1880.0
  episode_reward_mean: 1664.99
  episode_reward_min: 1249.0
  episodes_this_iter: 1
  episodes_total: 330
  experiment_id: ebedc1946062457bb682d57fae83bd74
  hostname: gpu052
  info:
    apply_time_ms: 3.099
    dispatch_time_ms: 7.599
    learner:
      cur_lr: 0.0012501099845394492
      grad_gnorm: 40.0
      policy_entropy: 15.258048057556152
      policy_loss: 1.9656931161880493
      var_gnorm: 40.089603424072266
      vf_explained_var: 0.33525168895721436
      vf_loss: 27.312782287597656
    num_steps_sampled: 1655000
    num_steps_trained: 1655000
    wait_time_ms: 123.303
  iterations_since_restore: 331
  node_ip: 172.17.8.52
  num_metric_batches_dropped: 0
  pid: 12141
  policy_reward_mean: {}
  time_since_restore: 4571.29922246933
  time_this_iter_s: 12.945744514465332
  time_total_s: 4571.29922246933
  timestamp: 1594142200
  timesteps_since_restore: 1655000
  timesteps_this_iter: 5000
  timesteps_total: 1655000
  training_iteration: 331
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 33.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=12141], 4571 s, 331 iter, 1655000 ts, 1.66e+03 rew

agent-1: 237.0
agent-2: 366.0
agent-3: 359.0
agent-4: 311.0
agent-5: 302.0
Sum Reward: 1575.0
Avg Reward: 315.0
Min Reward: 237.0
Max Reward: 366.0
Gini Coefficient: 0.08
20:20 Ratio: 1.5443037974683544
Max-min Ratio: 1.5443037974683544
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_13-16-54
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1880.0
  episode_reward_mean: 1662.27
  episode_reward_min: 1249.0
  episodes_this_iter: 1
  episodes_total: 331
  experiment_id: ebedc1946062457bb682d57fae83bd74
  hostname: gpu052
  info:
    apply_time_ms: 3.754
    dispatch_time_ms: 29.067
    learner:
      cur_lr: 0.0012497770367190242
      grad_gnorm: 40.000003814697266
      policy_entropy: 5.492202281951904
      policy_loss: 18.29617691040039
      var_gnorm: 40.086029052734375
      vf_explained_var: -0.663503885269165
      vf_loss: 101.20746612548828
    num_steps_sampled: 1660000
    num_steps_trained: 1660000
    wait_time_ms: 95.832
  iterations_since_restore: 332
  node_ip: 172.17.8.52
  num_metric_batches_dropped: 0
  pid: 12141
  policy_reward_mean: {}
  time_since_restore: 4585.7744019031525
  time_this_iter_s: 14.475179433822632
  time_total_s: 4585.7744019031525
  timestamp: 1594142214
  timesteps_since_restore: 1660000
  timesteps_this_iter: 5000
  timesteps_total: 1660000
  training_iteration: 332
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 33.3/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=12141], 4585 s, 332 iter, 1660000 ts, 1.66e+03 rew

agent-1: 341.0
agent-2: 391.0
agent-3: 281.0
agent-4: 351.0
agent-5: 343.0
Sum Reward: 1707.0
Avg Reward: 341.4
Min Reward: 281.0
Max Reward: 391.0
Gini Coefficient: 0.053895723491505565
20:20 Ratio: 1.3914590747330962
Max-min Ratio: 1.3914590747330962
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_13-17-07
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1880.0
  episode_reward_mean: 1661.25
  episode_reward_min: 1249.0
  episodes_this_iter: 1
  episodes_total: 332
  experiment_id: ebedc1946062457bb682d57fae83bd74
  hostname: gpu052
  info:
    apply_time_ms: 3.449
    dispatch_time_ms: 26.477
    learner:
      cur_lr: 0.0012494439724832773
      grad_gnorm: 40.0
      policy_entropy: 13.040050506591797
      policy_loss: 29.267902374267578
      var_gnorm: 40.19221496582031
      vf_explained_var: 0.007752954959869385
      vf_loss: 62.13298034667969
    num_steps_sampled: 1665000
    num_steps_trained: 1665000
    wait_time_ms: 105.144
  iterations_since_restore: 333
  node_ip: 172.17.8.52
  num_metric_batches_dropped: 0
  pid: 12141
  policy_reward_mean: {}
  time_since_restore: 4599.173473358154
  time_this_iter_s: 13.399071455001831
  time_total_s: 4599.173473358154
  timestamp: 1594142227
  timesteps_since_restore: 1665000
  timesteps_this_iter: 5000
  timesteps_total: 1665000
  training_iteration: 333
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 33.3/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=12141], 4599 s, 333 iter, 1665000 ts, 1.66e+03 rew

agent-1: 367.0
agent-2: 351.0
agent-3: 344.0
agent-4: 355.0
agent-5: 354.0
Sum Reward: 1771.0
Avg Reward: 354.2
Min Reward: 344.0
Max Reward: 367.0
Gini Coefficient: 0.01129305477131564
20:20 Ratio: 1.066860465116279
Max-min Ratio: 1.066860465116279
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_13-17-22
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1880.0
  episode_reward_mean: 1661.15
  episode_reward_min: 1249.0
  episodes_this_iter: 1
  episodes_total: 333
  experiment_id: ebedc1946062457bb682d57fae83bd74
  hostname: gpu052
  info:
    apply_time_ms: 2.426
    dispatch_time_ms: 30.856
    learner:
      cur_lr: 0.0012491110246628523
      grad_gnorm: 40.0
      policy_entropy: 8.507720947265625
      policy_loss: -0.987892746925354
      var_gnorm: 40.215824127197266
      vf_explained_var: 0.3732207417488098
      vf_loss: 24.453508377075195
    num_steps_sampled: 1670000
    num_steps_trained: 1670000
    wait_time_ms: 94.771
  iterations_since_restore: 334
  node_ip: 172.17.8.52
  num_metric_batches_dropped: 0
  pid: 12141
  policy_reward_mean: {}
  time_since_restore: 4613.322544336319
  time_this_iter_s: 14.149070978164673
  time_total_s: 4613.322544336319
  timestamp: 1594142242
  timesteps_since_restore: 1670000
  timesteps_this_iter: 5000
  timesteps_total: 1670000
  training_iteration: 334
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 33.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=12141], 4613 s, 334 iter, 1670000 ts, 1.66e+03 rew

agent-1: 306.0
agent-2: 364.0
agent-3: 309.0
agent-4: 363.0
agent-5: 364.0
Sum Reward: 1706.0
Avg Reward: 341.2
Min Reward: 306.0
Max Reward: 364.0
Gini Coefficient: 0.04009378663540446
20:20 Ratio: 1.1895424836601307
Max-min Ratio: 1.1895424836601307
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_13-17-35
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1880.0
  episode_reward_mean: 1662.2
  episode_reward_min: 1249.0
  episodes_this_iter: 1
  episodes_total: 334
  experiment_id: ebedc1946062457bb682d57fae83bd74
  hostname: gpu052
  info:
    apply_time_ms: 3.348
    dispatch_time_ms: 28.604
    learner:
      cur_lr: 0.0012487779604271054
      grad_gnorm: 39.99999237060547
      policy_entropy: 15.658889770507812
      policy_loss: 11.157806396484375
      var_gnorm: 40.2420539855957
      vf_explained_var: 0.5280665755271912
      vf_loss: 22.81412696838379
    num_steps_sampled: 1675000
    num_steps_trained: 1675000
    wait_time_ms: 117.362
  iterations_since_restore: 335
  node_ip: 172.17.8.52
  num_metric_batches_dropped: 0
  pid: 12141
  policy_reward_mean: {}
  time_since_restore: 4626.889508485794
  time_this_iter_s: 13.566964149475098
  time_total_s: 4626.889508485794
  timestamp: 1594142255
  timesteps_since_restore: 1675000
  timesteps_this_iter: 5000
  timesteps_total: 1675000
  training_iteration: 335
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 33.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=12141], 4626 s, 335 iter, 1675000 ts, 1.66e+03 rew

agent-1: 351.0
agent-2: 350.0
agent-3: 327.0
agent-4: 355.0
agent-5: 350.0
Sum Reward: 1733.0
Avg Reward: 346.6
Min Reward: 327.0
Max Reward: 355.0
Gini Coefficient: 0.013156376226197346
20:20 Ratio: 1.0856269113149848
Max-min Ratio: 1.0856269113149848
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_13-17-50
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1880.0
  episode_reward_mean: 1661.85
  episode_reward_min: 1249.0
  episodes_this_iter: 1
  episodes_total: 335
  experiment_id: ebedc1946062457bb682d57fae83bd74
  hostname: gpu052
  info:
    apply_time_ms: 3.203
    dispatch_time_ms: 23.488
    learner:
      cur_lr: 0.0012484450126066804
      grad_gnorm: 39.999996185302734
      policy_entropy: 6.789680004119873
      policy_loss: -1.7649407386779785
      var_gnorm: 40.243927001953125
      vf_explained_var: 0.6759684085845947
      vf_loss: 94.38626861572266
    num_steps_sampled: 1680000
    num_steps_trained: 1680000
    wait_time_ms: 112.906
  iterations_since_restore: 336
  node_ip: 172.17.8.52
  num_metric_batches_dropped: 0
  pid: 12141
  policy_reward_mean: {}
  time_since_restore: 4641.568145751953
  time_this_iter_s: 14.678637266159058
  time_total_s: 4641.568145751953
  timestamp: 1594142270
  timesteps_since_restore: 1680000
  timesteps_this_iter: 5000
  timesteps_total: 1680000
  training_iteration: 336
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 33.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=12141], 4641 s, 336 iter, 1680000 ts, 1.66e+03 rew

agent-1: 346.0
agent-2: 237.0
agent-3: 349.0
agent-4: 379.0
agent-5: 338.0
Sum Reward: 1649.0
Avg Reward: 329.8
Min Reward: 237.0
Max Reward: 379.0
Gini Coefficient: 0.07155852031534263
20:20 Ratio: 1.59915611814346
Max-min Ratio: 1.59915611814346
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_13-18-03
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1880.0
  episode_reward_mean: 1661.35
  episode_reward_min: 1249.0
  episodes_this_iter: 1
  episodes_total: 336
  experiment_id: ebedc1946062457bb682d57fae83bd74
  hostname: gpu052
  info:
    apply_time_ms: 3.992
    dispatch_time_ms: 19.643
    learner:
      cur_lr: 0.0012481119483709335
      grad_gnorm: 40.0
      policy_entropy: 7.434934616088867
      policy_loss: -3.048577308654785
      var_gnorm: 40.266475677490234
      vf_explained_var: 0.5420209169387817
      vf_loss: 31.152301788330078
    num_steps_sampled: 1685000
    num_steps_trained: 1685000
    wait_time_ms: 116.291
  iterations_since_restore: 337
  node_ip: 172.17.8.52
  num_metric_batches_dropped: 0
  pid: 12141
  policy_reward_mean: {}
  time_since_restore: 4654.951102972031
  time_this_iter_s: 13.382957220077515
  time_total_s: 4654.951102972031
  timestamp: 1594142283
  timesteps_since_restore: 1685000
  timesteps_this_iter: 5000
  timesteps_total: 1685000
  training_iteration: 337
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 33.3/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=12141], 4654 s, 337 iter, 1685000 ts, 1.66e+03 rew

agent-1: 315.0
agent-2: 367.0
agent-3: 325.0
agent-4: 350.0
agent-5: 356.0
Sum Reward: 1713.0
Avg Reward: 342.6
Min Reward: 315.0
Max Reward: 367.0
Gini Coefficient: 0.03152364273204904
20:20 Ratio: 1.1650793650793652
Max-min Ratio: 1.1650793650793652
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_13-18-18
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1880.0
  episode_reward_mean: 1661.43
  episode_reward_min: 1249.0
  episodes_this_iter: 1
  episodes_total: 337
  experiment_id: ebedc1946062457bb682d57fae83bd74
  hostname: gpu052
  info:
    apply_time_ms: 2.946
    dispatch_time_ms: 26.893
    learner:
      cur_lr: 0.0012477790005505085
      grad_gnorm: 40.0
      policy_entropy: 13.313370704650879
      policy_loss: -1.0564219951629639
      var_gnorm: 40.29931640625
      vf_explained_var: 0.2416556477546692
      vf_loss: 16.283546447753906
    num_steps_sampled: 1690000
    num_steps_trained: 1690000
    wait_time_ms: 105.763
  iterations_since_restore: 338
  node_ip: 172.17.8.52
  num_metric_batches_dropped: 0
  pid: 12141
  policy_reward_mean: {}
  time_since_restore: 4669.310575008392
  time_this_iter_s: 14.359472036361694
  time_total_s: 4669.310575008392
  timestamp: 1594142298
  timesteps_since_restore: 1690000
  timesteps_this_iter: 5000
  timesteps_total: 1690000
  training_iteration: 338
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 33.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=12141], 4669 s, 338 iter, 1690000 ts, 1.66e+03 rew

agent-1: 344.0
agent-2: 365.0
agent-3: 356.0
agent-4: 322.0
agent-5: 379.0
Sum Reward: 1766.0
Avg Reward: 353.2
Min Reward: 322.0
Max Reward: 379.0
Gini Coefficient: 0.030577576443941108
20:20 Ratio: 1.1770186335403727
Max-min Ratio: 1.1770186335403727
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_13-18-32
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1880.0
  episode_reward_mean: 1662.94
  episode_reward_min: 1249.0
  episodes_this_iter: 1
  episodes_total: 338
  experiment_id: ebedc1946062457bb682d57fae83bd74
  hostname: gpu052
  info:
    apply_time_ms: 4.114
    dispatch_time_ms: 31.542
    learner:
      cur_lr: 0.0012474460527300835
      grad_gnorm: 40.0
      policy_entropy: 7.478215217590332
      policy_loss: 1.865311622619629
      var_gnorm: 40.3670539855957
      vf_explained_var: 0.4372768998146057
      vf_loss: 54.04922866821289
    num_steps_sampled: 1695000
    num_steps_trained: 1695000
    wait_time_ms: 103.745
  iterations_since_restore: 339
  node_ip: 172.17.8.52
  num_metric_batches_dropped: 0
  pid: 12141
  policy_reward_mean: {}
  time_since_restore: 4683.084529399872
  time_this_iter_s: 13.773954391479492
  time_total_s: 4683.084529399872
  timestamp: 1594142312
  timesteps_since_restore: 1695000
  timesteps_this_iter: 5000
  timesteps_total: 1695000
  training_iteration: 339
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 33.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=12141], 4683 s, 339 iter, 1695000 ts, 1.66e+03 rew

agent-1: 336.0
agent-2: 363.0
agent-3: 255.0
agent-4: 306.0
agent-5: 396.0
Sum Reward: 1656.0
Avg Reward: 331.2
Min Reward: 255.0
Max Reward: 396.0
Gini Coefficient: 0.08188405797101449
20:20 Ratio: 1.5529411764705883
Max-min Ratio: 1.5529411764705883
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_13-18-47
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1880.0
  episode_reward_mean: 1662.73
  episode_reward_min: 1249.0
  episodes_this_iter: 1
  episodes_total: 339
  experiment_id: ebedc1946062457bb682d57fae83bd74
  hostname: gpu052
  info:
    apply_time_ms: 3.727
    dispatch_time_ms: 9.351
    learner:
      cur_lr: 0.0012471129884943366
      grad_gnorm: 38.57958984375
      policy_entropy: 4.530869960784912
      policy_loss: -2.2303714752197266
      var_gnorm: 40.362892150878906
      vf_explained_var: 0.006281912326812744
      vf_loss: 32.864402770996094
    num_steps_sampled: 1700000
    num_steps_trained: 1700000
    wait_time_ms: 43.53
  iterations_since_restore: 340
  node_ip: 172.17.8.52
  num_metric_batches_dropped: 0
  pid: 12141
  policy_reward_mean: {}
  time_since_restore: 4698.859993696213
  time_this_iter_s: 15.775464296340942
  time_total_s: 4698.859993696213
  timestamp: 1594142327
  timesteps_since_restore: 1700000
  timesteps_this_iter: 5000
  timesteps_total: 1700000
  training_iteration: 340
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 33.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=12141], 4698 s, 340 iter, 1700000 ts, 1.66e+03 rew

agent-1: 290.0
agent-2: 364.0
agent-3: 377.0
agent-4: 302.0
agent-5: 378.0
Sum Reward: 1711.0
Avg Reward: 342.2
Min Reward: 290.0
Max Reward: 378.0
Gini Coefficient: 0.0586791350087668
20:20 Ratio: 1.303448275862069
Max-min Ratio: 1.303448275862069
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_13-19-01
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1880.0
  episode_reward_mean: 1664.8
  episode_reward_min: 1249.0
  episodes_this_iter: 1
  episodes_total: 340
  experiment_id: ebedc1946062457bb682d57fae83bd74
  hostname: gpu052
  info:
    apply_time_ms: 3.9
    dispatch_time_ms: 6.526
    learner:
      cur_lr: 0.0012467800406739116
      grad_gnorm: 39.999996185302734
      policy_entropy: 8.216696739196777
      policy_loss: 0.14052675664424896
      var_gnorm: 40.413665771484375
      vf_explained_var: 0.13479161262512207
      vf_loss: 59.62264633178711
    num_steps_sampled: 1705000
    num_steps_trained: 1705000
    wait_time_ms: 132.486
  iterations_since_restore: 341
  node_ip: 172.17.8.52
  num_metric_batches_dropped: 0
  pid: 12141
  policy_reward_mean: {}
  time_since_restore: 4712.00948882103
  time_this_iter_s: 13.149495124816895
  time_total_s: 4712.00948882103
  timestamp: 1594142341
  timesteps_since_restore: 1705000
  timesteps_this_iter: 5000
  timesteps_total: 1705000
  training_iteration: 341
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 33.3/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=12141], 4712 s, 341 iter, 1705000 ts, 1.66e+03 rew

agent-1: 363.0
agent-2: 330.0
agent-3: 311.0
agent-4: 367.0
agent-5: 366.0
Sum Reward: 1737.0
Avg Reward: 347.4
Min Reward: 311.0
Max Reward: 367.0
Gini Coefficient: 0.03408175014392631
20:20 Ratio: 1.180064308681672
Max-min Ratio: 1.180064308681672
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_13-19-15
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1880.0
  episode_reward_mean: 1666.73
  episode_reward_min: 1249.0
  episodes_this_iter: 1
  episodes_total: 341
  experiment_id: ebedc1946062457bb682d57fae83bd74
  hostname: gpu052
  info:
    apply_time_ms: 3.143
    dispatch_time_ms: 6.986
    learner:
      cur_lr: 0.0012464469764381647
      grad_gnorm: 40.000003814697266
      policy_entropy: 11.38644027709961
      policy_loss: 9.163298606872559
      var_gnorm: 40.42251205444336
      vf_explained_var: -0.3591935634613037
      vf_loss: 25.944149017333984
    num_steps_sampled: 1710000
    num_steps_trained: 1710000
    wait_time_ms: 114.354
  iterations_since_restore: 342
  node_ip: 172.17.8.52
  num_metric_batches_dropped: 0
  pid: 12141
  policy_reward_mean: {}
  time_since_restore: 4725.817754983902
  time_this_iter_s: 13.808266162872314
  time_total_s: 4725.817754983902
  timestamp: 1594142355
  timesteps_since_restore: 1710000
  timesteps_this_iter: 5000
  timesteps_total: 1710000
  training_iteration: 342
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 33.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=12141], 4725 s, 342 iter, 1710000 ts, 1.67e+03 rew

agent-1: 319.0
agent-2: 322.0
agent-3: 367.0
agent-4: 385.0
agent-5: 344.0
Sum Reward: 1737.0
Avg Reward: 347.4
Min Reward: 319.0
Max Reward: 385.0
Gini Coefficient: 0.04075993091537133
20:20 Ratio: 1.206896551724138
Max-min Ratio: 1.206896551724138
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_13-19-28
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1880.0
  episode_reward_mean: 1668.55
  episode_reward_min: 1249.0
  episodes_this_iter: 1
  episodes_total: 342
  experiment_id: ebedc1946062457bb682d57fae83bd74
  hostname: gpu052
  info:
    apply_time_ms: 2.753
    dispatch_time_ms: 7.367
    learner:
      cur_lr: 0.0012461140286177397
      grad_gnorm: 40.00000762939453
      policy_entropy: 13.510300636291504
      policy_loss: -10.186586380004883
      var_gnorm: 40.47262954711914
      vf_explained_var: 0.2990676164627075
      vf_loss: 23.075212478637695
    num_steps_sampled: 1715000
    num_steps_trained: 1715000
    wait_time_ms: 121.169
  iterations_since_restore: 343
  node_ip: 172.17.8.52
  num_metric_batches_dropped: 0
  pid: 12141
  policy_reward_mean: {}
  time_since_restore: 4738.853531599045
  time_this_iter_s: 13.035776615142822
  time_total_s: 4738.853531599045
  timestamp: 1594142368
  timesteps_since_restore: 1715000
  timesteps_this_iter: 5000
  timesteps_total: 1715000
  training_iteration: 343
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 33.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=12141], 4738 s, 343 iter, 1715000 ts, 1.67e+03 rew

agent-1: 342.0
agent-2: 370.0
agent-3: 308.0
agent-4: 393.0
agent-5: 339.0
Sum Reward: 1752.0
Avg Reward: 350.4
Min Reward: 308.0
Max Reward: 393.0
Gini Coefficient: 0.04589041095890411
20:20 Ratio: 1.275974025974026
Max-min Ratio: 1.275974025974026
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_13-19-41
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1880.0
  episode_reward_mean: 1668.86
  episode_reward_min: 1249.0
  episodes_this_iter: 1
  episodes_total: 343
  experiment_id: ebedc1946062457bb682d57fae83bd74
  hostname: gpu052
  info:
    apply_time_ms: 2.674
    dispatch_time_ms: 5.854
    learner:
      cur_lr: 0.0012457809643819928
      grad_gnorm: 39.999996185302734
      policy_entropy: 13.005311012268066
      policy_loss: 10.023377418518066
      var_gnorm: 40.565250396728516
      vf_explained_var: -0.8089178800582886
      vf_loss: 30.735183715820312
    num_steps_sampled: 1720000
    num_steps_trained: 1720000
    wait_time_ms: 118.088
  iterations_since_restore: 344
  node_ip: 172.17.8.52
  num_metric_batches_dropped: 0
  pid: 12141
  policy_reward_mean: {}
  time_since_restore: 4752.431751489639
  time_this_iter_s: 13.578219890594482
  time_total_s: 4752.431751489639
  timestamp: 1594142381
  timesteps_since_restore: 1720000
  timesteps_this_iter: 5000
  timesteps_total: 1720000
  training_iteration: 344
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 33.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=12141], 4752 s, 344 iter, 1720000 ts, 1.67e+03 rew

agent-1: 313.0
agent-2: 400.0
agent-3: 367.0
agent-4: 329.0
agent-5: 335.0
Sum Reward: 1744.0
Avg Reward: 348.8
Min Reward: 313.0
Max Reward: 400.0
Gini Coefficient: 0.04862385321100918
20:20 Ratio: 1.2779552715654952
Max-min Ratio: 1.2779552715654952
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_13-19-55
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1880.0
  episode_reward_mean: 1669.56
  episode_reward_min: 1249.0
  episodes_this_iter: 1
  episodes_total: 344
  experiment_id: ebedc1946062457bb682d57fae83bd74
  hostname: gpu052
  info:
    apply_time_ms: 2.848
    dispatch_time_ms: 6.606
    learner:
      cur_lr: 0.0012454480165615678
      grad_gnorm: 40.0
      policy_entropy: 12.503180503845215
      policy_loss: -0.7761757373809814
      var_gnorm: 40.60813522338867
      vf_explained_var: 0.19993466138839722
      vf_loss: 26.285114288330078
    num_steps_sampled: 1725000
    num_steps_trained: 1725000
    wait_time_ms: 126.937
  iterations_since_restore: 345
  node_ip: 172.17.8.52
  num_metric_batches_dropped: 0
  pid: 12141
  policy_reward_mean: {}
  time_since_restore: 4765.80362200737
  time_this_iter_s: 13.371870517730713
  time_total_s: 4765.80362200737
  timestamp: 1594142395
  timesteps_since_restore: 1725000
  timesteps_this_iter: 5000
  timesteps_total: 1725000
  training_iteration: 345
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 33.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=12141], 4765 s, 345 iter, 1725000 ts, 1.67e+03 rew

agent-1: 345.0
agent-2: 374.0
agent-3: 321.0
agent-4: 305.0
agent-5: 339.0
Sum Reward: 1684.0
Avg Reward: 336.8
Min Reward: 305.0
Max Reward: 374.0
Gini Coefficient: 0.03847980997624703
20:20 Ratio: 1.2262295081967214
Max-min Ratio: 1.2262295081967214
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_13-20-08
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1870.0
  episode_reward_mean: 1667.6
  episode_reward_min: 1249.0
  episodes_this_iter: 1
  episodes_total: 345
  experiment_id: ebedc1946062457bb682d57fae83bd74
  hostname: gpu052
  info:
    apply_time_ms: 3.844
    dispatch_time_ms: 8.183
    learner:
      cur_lr: 0.001245114952325821
      grad_gnorm: 40.0
      policy_entropy: 15.967913627624512
      policy_loss: 9.23884391784668
      var_gnorm: 40.733970642089844
      vf_explained_var: -0.0005953311920166016
      vf_loss: 51.5338020324707
    num_steps_sampled: 1730000
    num_steps_trained: 1730000
    wait_time_ms: 119.626
  iterations_since_restore: 346
  node_ip: 172.17.8.52
  num_metric_batches_dropped: 0
  pid: 12141
  policy_reward_mean: {}
  time_since_restore: 4779.356071233749
  time_this_iter_s: 13.552449226379395
  time_total_s: 4779.356071233749
  timestamp: 1594142408
  timesteps_since_restore: 1730000
  timesteps_this_iter: 5000
  timesteps_total: 1730000
  training_iteration: 346
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 33.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=12141], 4779 s, 346 iter, 1730000 ts, 1.67e+03 rew

agent-1: 287.0
agent-2: 291.0
agent-3: 355.0
agent-4: 270.0
agent-5: 380.0
Sum Reward: 1583.0
Avg Reward: 316.6
Min Reward: 270.0
Max Reward: 380.0
Gini Coefficient: 0.07277321541377132
20:20 Ratio: 1.4074074074074074
Max-min Ratio: 1.4074074074074074
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_13-20-21
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1870.0
  episode_reward_mean: 1665.57
  episode_reward_min: 1249.0
  episodes_this_iter: 1
  episodes_total: 346
  experiment_id: ebedc1946062457bb682d57fae83bd74
  hostname: gpu052
  info:
    apply_time_ms: 3.791
    dispatch_time_ms: 6.701
    learner:
      cur_lr: 0.0012447820045053959
      grad_gnorm: 40.00000762939453
      policy_entropy: 21.389034271240234
      policy_loss: 7.973161220550537
      var_gnorm: 40.77446365356445
      vf_explained_var: 0.17847001552581787
      vf_loss: 73.52944946289062
    num_steps_sampled: 1735000
    num_steps_trained: 1735000
    wait_time_ms: 135.023
  iterations_since_restore: 347
  node_ip: 172.17.8.52
  num_metric_batches_dropped: 0
  pid: 12141
  policy_reward_mean: {}
  time_since_restore: 4792.622017860413
  time_this_iter_s: 13.265946626663208
  time_total_s: 4792.622017860413
  timestamp: 1594142421
  timesteps_since_restore: 1735000
  timesteps_this_iter: 5000
  timesteps_total: 1735000
  training_iteration: 347
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 33.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=12141], 4792 s, 347 iter, 1735000 ts, 1.67e+03 rew

agent-1: 339.0
agent-2: 367.0
agent-3: 314.0
agent-4: 353.0
agent-5: 286.0
Sum Reward: 1659.0
Avg Reward: 331.8
Min Reward: 286.0
Max Reward: 367.0
Gini Coefficient: 0.0484629294755877
20:20 Ratio: 1.2832167832167831
Max-min Ratio: 1.2832167832167831
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_13-20-35
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1870.0
  episode_reward_mean: 1664.4
  episode_reward_min: 1249.0
  episodes_this_iter: 1
  episodes_total: 347
  experiment_id: ebedc1946062457bb682d57fae83bd74
  hostname: gpu052
  info:
    apply_time_ms: 2.59
    dispatch_time_ms: 8.232
    learner:
      cur_lr: 0.0012444490566849709
      grad_gnorm: 40.0
      policy_entropy: 20.786527633666992
      policy_loss: 15.252706527709961
      var_gnorm: 40.873836517333984
      vf_explained_var: 0.7729855179786682
      vf_loss: 54.695518493652344
    num_steps_sampled: 1740000
    num_steps_trained: 1740000
    wait_time_ms: 121.471
  iterations_since_restore: 348
  node_ip: 172.17.8.52
  num_metric_batches_dropped: 0
  pid: 12141
  policy_reward_mean: {}
  time_since_restore: 4806.423651456833
  time_this_iter_s: 13.801633596420288
  time_total_s: 4806.423651456833
  timestamp: 1594142435
  timesteps_since_restore: 1740000
  timesteps_this_iter: 5000
  timesteps_total: 1740000
  training_iteration: 348
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 33.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=12141], 4806 s, 348 iter, 1740000 ts, 1.66e+03 rew

agent-1: 286.0
agent-2: 277.0
agent-3: 396.0
agent-4: 334.0
agent-5: 337.0
Sum Reward: 1630.0
Avg Reward: 326.0
Min Reward: 277.0
Max Reward: 396.0
Gini Coefficient: 0.07092024539877301
20:20 Ratio: 1.4296028880866427
Max-min Ratio: 1.4296028880866427
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_13-20-48
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1870.0
  episode_reward_mean: 1668.21
  episode_reward_min: 1323.0
  episodes_this_iter: 1
  episodes_total: 348
  experiment_id: ebedc1946062457bb682d57fae83bd74
  hostname: gpu052
  info:
    apply_time_ms: 3.725
    dispatch_time_ms: 8.503
    learner:
      cur_lr: 0.001244115992449224
      grad_gnorm: 39.99999237060547
      policy_entropy: 24.638778686523438
      policy_loss: 42.14775466918945
      var_gnorm: 40.908477783203125
      vf_explained_var: 0.4162209630012512
      vf_loss: 71.01657104492188
    num_steps_sampled: 1745000
    num_steps_trained: 1745000
    wait_time_ms: 124.195
  iterations_since_restore: 349
  node_ip: 172.17.8.52
  num_metric_batches_dropped: 0
  pid: 12141
  policy_reward_mean: {}
  time_since_restore: 4819.341101646423
  time_this_iter_s: 12.917450189590454
  time_total_s: 4819.341101646423
  timestamp: 1594142448
  timesteps_since_restore: 1745000
  timesteps_this_iter: 5000
  timesteps_total: 1745000
  training_iteration: 349
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 33.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=12141], 4819 s, 349 iter, 1745000 ts, 1.67e+03 rew

agent-1: 178.0
agent-2: 299.0
agent-3: 240.0
agent-4: 237.0
agent-5: 365.0
Sum Reward: 1319.0
Avg Reward: 263.8
Min Reward: 178.0
Max Reward: 365.0
Gini Coefficient: 0.13222137983320698
20:20 Ratio: 2.050561797752809
Max-min Ratio: 2.050561797752809
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_13-21-01
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1870.0
  episode_reward_mean: 1666.92
  episode_reward_min: 1319.0
  episodes_this_iter: 1
  episodes_total: 349
  experiment_id: ebedc1946062457bb682d57fae83bd74
  hostname: gpu052
  info:
    apply_time_ms: 3.725
    dispatch_time_ms: 29.172
    learner:
      cur_lr: 0.001243783044628799
      grad_gnorm: 39.999996185302734
      policy_entropy: 22.555627822875977
      policy_loss: -22.772594451904297
      var_gnorm: 40.93238830566406
      vf_explained_var: -0.23247909545898438
      vf_loss: 91.92130279541016
    num_steps_sampled: 1750000
    num_steps_trained: 1750000
    wait_time_ms: 82.664
  iterations_since_restore: 350
  node_ip: 172.17.8.52
  num_metric_batches_dropped: 0
  pid: 12141
  policy_reward_mean: {}
  time_since_restore: 4832.002374410629
  time_this_iter_s: 12.661272764205933
  time_total_s: 4832.002374410629
  timestamp: 1594142461
  timesteps_since_restore: 1750000
  timesteps_this_iter: 5000
  timesteps_total: 1750000
  training_iteration: 350
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 33.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=12141], 4832 s, 350 iter, 1750000 ts, 1.67e+03 rew

agent-1: 285.0
agent-2: 359.0
agent-3: 274.0
agent-4: 305.0
agent-5: 262.0
Sum Reward: 1485.0
Avg Reward: 297.0
Min Reward: 262.0
Max Reward: 359.0
Gini Coefficient: 0.06060606060606061
20:20 Ratio: 1.3702290076335877
Max-min Ratio: 1.3702290076335877
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_13-21-13
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1870.0
  episode_reward_mean: 1664.91
  episode_reward_min: 1319.0
  episodes_this_iter: 1
  episodes_total: 350
  experiment_id: ebedc1946062457bb682d57fae83bd74
  hostname: gpu052
  info:
    apply_time_ms: 2.769
    dispatch_time_ms: 31.432
    learner:
      cur_lr: 0.001243449980393052
      grad_gnorm: 40.0
      policy_entropy: 25.45534896850586
      policy_loss: -5.654719352722168
      var_gnorm: 40.98676300048828
      vf_explained_var: 0.7642380595207214
      vf_loss: 31.903568267822266
    num_steps_sampled: 1755000
    num_steps_trained: 1755000
    wait_time_ms: 95.126
  iterations_since_restore: 351
  node_ip: 172.17.8.52
  num_metric_batches_dropped: 0
  pid: 12141
  policy_reward_mean: {}
  time_since_restore: 4844.436887741089
  time_this_iter_s: 12.434513330459595
  time_total_s: 4844.436887741089
  timestamp: 1594142473
  timesteps_since_restore: 1755000
  timesteps_this_iter: 5000
  timesteps_total: 1755000
  training_iteration: 351
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 34.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=12141], 4844 s, 351 iter, 1755000 ts, 1.66e+03 rew

agent-1: 205.0
agent-2: 244.0
agent-3: 298.0
agent-4: 246.0
agent-5: 289.0
Sum Reward: 1282.0
Avg Reward: 256.4
Min Reward: 205.0
Max Reward: 298.0
Gini Coefficient: 0.07207488299531982
20:20 Ratio: 1.4536585365853658
Max-min Ratio: 1.4536585365853658
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_13-21-26
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1870.0
  episode_reward_mean: 1660.13
  episode_reward_min: 1282.0
  episodes_this_iter: 1
  episodes_total: 351
  experiment_id: ebedc1946062457bb682d57fae83bd74
  hostname: gpu052
  info:
    apply_time_ms: 2.637
    dispatch_time_ms: 14.003
    learner:
      cur_lr: 0.001243117032572627
      grad_gnorm: 40.00000762939453
      policy_entropy: 18.812990188598633
      policy_loss: -21.8082275390625
      var_gnorm: 41.036163330078125
      vf_explained_var: 0.5436456203460693
      vf_loss: 73.55054473876953
    num_steps_sampled: 1760000
    num_steps_trained: 1760000
    wait_time_ms: 96.995
  iterations_since_restore: 352
  node_ip: 172.17.8.52
  num_metric_batches_dropped: 0
  pid: 12141
  policy_reward_mean: {}
  time_since_restore: 4856.493702173233
  time_this_iter_s: 12.056814432144165
  time_total_s: 4856.493702173233
  timestamp: 1594142486
  timesteps_since_restore: 1760000
  timesteps_this_iter: 5000
  timesteps_total: 1760000
  training_iteration: 352
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 34.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=12141], 4856 s, 352 iter, 1760000 ts, 1.66e+03 rew

agent-1: 188.0
agent-2: 303.0
agent-3: 189.0
agent-4: 271.0
agent-5: 287.0
Sum Reward: 1238.0
Avg Reward: 247.6
Min Reward: 188.0
Max Reward: 303.0
Gini Coefficient: 0.10597738287560582
20:20 Ratio: 1.6117021276595744
Max-min Ratio: 1.6117021276595744
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_13-21-38
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1870.0
  episode_reward_mean: 1654.62
  episode_reward_min: 1238.0
  episodes_this_iter: 1
  episodes_total: 352
  experiment_id: ebedc1946062457bb682d57fae83bd74
  hostname: gpu052
  info:
    apply_time_ms: 3.092
    dispatch_time_ms: 30.32
    learner:
      cur_lr: 0.0012427839683368802
      grad_gnorm: 40.0
      policy_entropy: 24.42970085144043
      policy_loss: 30.29585075378418
      var_gnorm: 41.04676055908203
      vf_explained_var: 0.32935184240341187
      vf_loss: 57.15097427368164
    num_steps_sampled: 1765000
    num_steps_trained: 1765000
    wait_time_ms: 89.122
  iterations_since_restore: 353
  node_ip: 172.17.8.52
  num_metric_batches_dropped: 0
  pid: 12141
  policy_reward_mean: {}
  time_since_restore: 4868.764747619629
  time_this_iter_s: 12.271045446395874
  time_total_s: 4868.764747619629
  timestamp: 1594142498
  timesteps_since_restore: 1765000
  timesteps_this_iter: 5000
  timesteps_total: 1765000
  training_iteration: 353
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 34.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=12141], 4868 s, 353 iter, 1765000 ts, 1.65e+03 rew

agent-1: 208.0
agent-2: 295.0
agent-3: 251.0
agent-4: 259.0
agent-5: 238.0
Sum Reward: 1251.0
Avg Reward: 250.2
Min Reward: 208.0
Max Reward: 295.0
Gini Coefficient: 0.06235011990407674
20:20 Ratio: 1.4182692307692308
Max-min Ratio: 1.4182692307692308
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_13-21-50
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1870.0
  episode_reward_mean: 1649.84
  episode_reward_min: 1238.0
  episodes_this_iter: 1
  episodes_total: 353
  experiment_id: ebedc1946062457bb682d57fae83bd74
  hostname: gpu052
  info:
    apply_time_ms: 3.029
    dispatch_time_ms: 22.541
    learner:
      cur_lr: 0.0012424510205164552
      grad_gnorm: 40.0
      policy_entropy: 27.464635848999023
      policy_loss: -26.559642791748047
      var_gnorm: 41.07040023803711
      vf_explained_var: 0.7898286581039429
      vf_loss: 23.67148208618164
    num_steps_sampled: 1770000
    num_steps_trained: 1770000
    wait_time_ms: 100.654
  iterations_since_restore: 354
  node_ip: 172.17.8.52
  num_metric_batches_dropped: 0
  pid: 12141
  policy_reward_mean: {}
  time_since_restore: 4881.315208911896
  time_this_iter_s: 12.550461292266846
  time_total_s: 4881.315208911896
  timestamp: 1594142510
  timesteps_since_restore: 1770000
  timesteps_this_iter: 5000
  timesteps_total: 1770000
  training_iteration: 354
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 34.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=12141], 4881 s, 354 iter, 1770000 ts, 1.65e+03 rew

agent-1: 236.0
agent-2: 320.0
agent-3: 187.0
agent-4: 269.0
agent-5: 214.0
Sum Reward: 1226.0
Avg Reward: 245.2
Min Reward: 187.0
Max Reward: 320.0
Gini Coefficient: 0.10473083197389886
20:20 Ratio: 1.7112299465240641
Max-min Ratio: 1.7112299465240641
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_13-22-02
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1870.0
  episode_reward_mean: 1645.16
  episode_reward_min: 1226.0
  episodes_this_iter: 1
  episodes_total: 354
  experiment_id: ebedc1946062457bb682d57fae83bd74
  hostname: gpu052
  info:
    apply_time_ms: 2.777
    dispatch_time_ms: 42.338
    learner:
      cur_lr: 0.0012421179562807083
      grad_gnorm: 40.0
      policy_entropy: 26.518795013427734
      policy_loss: -7.112938404083252
      var_gnorm: 41.082733154296875
      vf_explained_var: 0.30736464262008667
      vf_loss: 36.449798583984375
    num_steps_sampled: 1775000
    num_steps_trained: 1775000
    wait_time_ms: 83.16
  iterations_since_restore: 355
  node_ip: 172.17.8.52
  num_metric_batches_dropped: 0
  pid: 12141
  policy_reward_mean: {}
  time_since_restore: 4893.299966096878
  time_this_iter_s: 11.9847571849823
  time_total_s: 4893.299966096878
  timestamp: 1594142522
  timesteps_since_restore: 1775000
  timesteps_this_iter: 5000
  timesteps_total: 1775000
  training_iteration: 355
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 34.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=12141], 4893 s, 355 iter, 1775000 ts, 1.65e+03 rew

agent-1: 202.0
agent-2: 274.0
agent-3: 208.0
agent-4: 207.0
agent-5: 211.0
Sum Reward: 1102.0
Avg Reward: 220.4
Min Reward: 202.0
Max Reward: 274.0
Gini Coefficient: 0.05372050816696915
20:20 Ratio: 1.3564356435643565
Max-min Ratio: 1.3564356435643565
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_13-22-14
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1870.0
  episode_reward_mean: 1639.46
  episode_reward_min: 1102.0
  episodes_this_iter: 1
  episodes_total: 355
  experiment_id: ebedc1946062457bb682d57fae83bd74
  hostname: gpu052
  info:
    apply_time_ms: 2.788
    dispatch_time_ms: 17.735
    learner:
      cur_lr: 0.0012417850084602833
      grad_gnorm: 40.0
      policy_entropy: 20.561614990234375
      policy_loss: 25.9835205078125
      var_gnorm: 41.086490631103516
      vf_explained_var: 0.8332215547561646
      vf_loss: 73.65621185302734
    num_steps_sampled: 1780000
    num_steps_trained: 1780000
    wait_time_ms: 103.224
  iterations_since_restore: 356
  node_ip: 172.17.8.52
  num_metric_batches_dropped: 0
  pid: 12141
  policy_reward_mean: {}
  time_since_restore: 4905.00806593895
  time_this_iter_s: 11.708099842071533
  time_total_s: 4905.00806593895
  timestamp: 1594142534
  timesteps_since_restore: 1780000
  timesteps_this_iter: 5000
  timesteps_total: 1780000
  training_iteration: 356
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 33.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=12141], 4905 s, 356 iter, 1780000 ts, 1.64e+03 rew

agent-1: 193.0
agent-2: 273.0
agent-3: 209.0
agent-4: 246.0
agent-5: 251.0
Sum Reward: 1172.0
Avg Reward: 234.4
Min Reward: 193.0
Max Reward: 273.0
Gini Coefficient: 0.0689419795221843
20:20 Ratio: 1.4145077720207253
Max-min Ratio: 1.4145077720207253
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_13-22-26
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1870.0
  episode_reward_mean: 1635.23
  episode_reward_min: 1102.0
  episodes_this_iter: 1
  episodes_total: 356
  experiment_id: ebedc1946062457bb682d57fae83bd74
  hostname: gpu052
  info:
    apply_time_ms: 2.548
    dispatch_time_ms: 31.337
    learner:
      cur_lr: 0.0012414519442245364
      grad_gnorm: 39.999996185302734
      policy_entropy: 20.106700897216797
      policy_loss: 4.520310878753662
      var_gnorm: 41.07561111450195
      vf_explained_var: 0.7670705318450928
      vf_loss: 64.81391906738281
    num_steps_sampled: 1785000
    num_steps_trained: 1785000
    wait_time_ms: 89.711
  iterations_since_restore: 357
  node_ip: 172.17.8.52
  num_metric_batches_dropped: 0
  pid: 12141
  policy_reward_mean: {}
  time_since_restore: 4917.192849159241
  time_this_iter_s: 12.184783220291138
  time_total_s: 4917.192849159241
  timestamp: 1594142546
  timesteps_since_restore: 1785000
  timesteps_this_iter: 5000
  timesteps_total: 1785000
  training_iteration: 357
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 33.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=12141], 4917 s, 357 iter, 1785000 ts, 1.64e+03 rew

agent-1: 235.0
agent-2: 237.0
agent-3: 245.0
agent-4: 246.0
agent-5: 310.0
Sum Reward: 1273.0
Avg Reward: 254.6
Min Reward: 235.0
Max Reward: 310.0
Gini Coefficient: 0.04996072270227808
20:20 Ratio: 1.3191489361702127
Max-min Ratio: 1.3191489361702127
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_13-22-40
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1870.0
  episode_reward_mean: 1631.55
  episode_reward_min: 1102.0
  episodes_this_iter: 1
  episodes_total: 357
  experiment_id: ebedc1946062457bb682d57fae83bd74
  hostname: gpu052
  info:
    apply_time_ms: 3.635
    dispatch_time_ms: 16.606
    learner:
      cur_lr: 0.0012411189964041114
      grad_gnorm: 40.000003814697266
      policy_entropy: 23.11527442932129
      policy_loss: 26.660676956176758
      var_gnorm: 41.06878662109375
      vf_explained_var: 0.2203846573829651
      vf_loss: 67.72686767578125
    num_steps_sampled: 1790000
    num_steps_trained: 1790000
    wait_time_ms: 119.346
  iterations_since_restore: 358
  node_ip: 172.17.8.52
  num_metric_batches_dropped: 0
  pid: 12141
  policy_reward_mean: {}
  time_since_restore: 4930.3717296123505
  time_this_iter_s: 13.178880453109741
  time_total_s: 4930.3717296123505
  timestamp: 1594142560
  timesteps_since_restore: 1790000
  timesteps_this_iter: 5000
  timesteps_total: 1790000
  training_iteration: 358
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 33.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=12141], 4930 s, 358 iter, 1790000 ts, 1.63e+03 rew

agent-1: 321.0
agent-2: 364.0
agent-3: 281.0
agent-4: 316.0
agent-5: 302.0
Sum Reward: 1584.0
Avg Reward: 316.8
Min Reward: 281.0
Max Reward: 364.0
Gini Coefficient: 0.04671717171717172
20:20 Ratio: 1.295373665480427
Max-min Ratio: 1.295373665480427
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_13-22-54
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1870.0
  episode_reward_mean: 1631.24
  episode_reward_min: 1102.0
  episodes_this_iter: 1
  episodes_total: 358
  experiment_id: ebedc1946062457bb682d57fae83bd74
  hostname: gpu052
  info:
    apply_time_ms: 3.996
    dispatch_time_ms: 19.197
    learner:
      cur_lr: 0.0012407860485836864
      grad_gnorm: 40.0
      policy_entropy: 15.087409973144531
      policy_loss: 8.35401725769043
      var_gnorm: 41.1009635925293
      vf_explained_var: 0.287516713142395
      vf_loss: 140.77890014648438
    num_steps_sampled: 1795000
    num_steps_trained: 1795000
    wait_time_ms: 129.704
  iterations_since_restore: 359
  node_ip: 172.17.8.52
  num_metric_batches_dropped: 0
  pid: 12141
  policy_reward_mean: {}
  time_since_restore: 4944.409050226212
  time_this_iter_s: 14.037320613861084
  time_total_s: 4944.409050226212
  timestamp: 1594142574
  timesteps_since_restore: 1795000
  timesteps_this_iter: 5000
  timesteps_total: 1795000
  training_iteration: 359
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 33.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=12141], 4944 s, 359 iter, 1795000 ts, 1.63e+03 rew

agent-1: 338.0
agent-2: 302.0
agent-3: 318.0
agent-4: 238.0
agent-5: 380.0
Sum Reward: 1576.0
Avg Reward: 315.2
Min Reward: 238.0
Max Reward: 380.0
Gini Coefficient: 0.08121827411167512
20:20 Ratio: 1.596638655462185
Max-min Ratio: 1.596638655462185
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_13-23-08
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1870.0
  episode_reward_mean: 1629.36
  episode_reward_min: 1102.0
  episodes_this_iter: 1
  episodes_total: 359
  experiment_id: ebedc1946062457bb682d57fae83bd74
  hostname: gpu052
  info:
    apply_time_ms: 3.15
    dispatch_time_ms: 19.0
    learner:
      cur_lr: 0.0012404529843479395
      grad_gnorm: 39.999996185302734
      policy_entropy: 8.244653701782227
      policy_loss: -8.941226959228516
      var_gnorm: 41.151763916015625
      vf_explained_var: 0.41597235202789307
      vf_loss: 34.601707458496094
    num_steps_sampled: 1800000
    num_steps_trained: 1800000
    wait_time_ms: 122.839
  iterations_since_restore: 360
  node_ip: 172.17.8.52
  num_metric_batches_dropped: 0
  pid: 12141
  policy_reward_mean: {}
  time_since_restore: 4958.191707134247
  time_this_iter_s: 13.782656908035278
  time_total_s: 4958.191707134247
  timestamp: 1594142588
  timesteps_since_restore: 1800000
  timesteps_this_iter: 5000
  timesteps_total: 1800000
  training_iteration: 360
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 33.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=12141], 4958 s, 360 iter, 1800000 ts, 1.63e+03 rew

agent-1: 316.0
agent-2: 364.0
agent-3: 340.0
agent-4: 379.0
agent-5: 390.0
Sum Reward: 1789.0
Avg Reward: 357.8
Min Reward: 316.0
Max Reward: 390.0
Gini Coefficient: 0.041811067635550585
20:20 Ratio: 1.2341772151898733
Max-min Ratio: 1.2341772151898733
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_13-23-22
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1870.0
  episode_reward_mean: 1630.22
  episode_reward_min: 1102.0
  episodes_this_iter: 1
  episodes_total: 360
  experiment_id: ebedc1946062457bb682d57fae83bd74
  hostname: gpu052
  info:
    apply_time_ms: 5.028
    dispatch_time_ms: 39.622
    learner:
      cur_lr: 0.0012401200365275145
      grad_gnorm: 40.000003814697266
      policy_entropy: 30.372886657714844
      policy_loss: -54.71772384643555
      var_gnorm: 41.15947723388672
      vf_explained_var: 0.4827688932418823
      vf_loss: 149.5557403564453
    num_steps_sampled: 1805000
    num_steps_trained: 1805000
    wait_time_ms: 103.474
  iterations_since_restore: 361
  node_ip: 172.17.8.52
  num_metric_batches_dropped: 0
  pid: 12141
  policy_reward_mean: {}
  time_since_restore: 4972.30158495903
  time_this_iter_s: 14.109877824783325
  time_total_s: 4972.30158495903
  timestamp: 1594142602
  timesteps_since_restore: 1805000
  timesteps_this_iter: 5000
  timesteps_total: 1805000
  training_iteration: 361
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 33.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=12141], 4972 s, 361 iter, 1805000 ts, 1.63e+03 rew

agent-1: 349.0
agent-2: 316.0
agent-3: 307.0
agent-4: 339.0
agent-5: 320.0
Sum Reward: 1631.0
Avg Reward: 326.2
Min Reward: 307.0
Max Reward: 349.0
Gini Coefficient: 0.026241569589209073
20:20 Ratio: 1.1368078175895766
Max-min Ratio: 1.1368078175895766
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_13-23-35
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1870.0
  episode_reward_mean: 1632.25
  episode_reward_min: 1102.0
  episodes_this_iter: 1
  episodes_total: 361
  experiment_id: ebedc1946062457bb682d57fae83bd74
  hostname: gpu052
  info:
    apply_time_ms: 3.058
    dispatch_time_ms: 39.265
    learner:
      cur_lr: 0.0012397869722917676
      grad_gnorm: 40.0
      policy_entropy: 28.873342514038086
      policy_loss: -7.868564605712891
      var_gnorm: 41.20975112915039
      vf_explained_var: 0.07400208711624146
      vf_loss: 14.76738452911377
    num_steps_sampled: 1810000
    num_steps_trained: 1810000
    wait_time_ms: 82.478
  iterations_since_restore: 362
  node_ip: 172.17.8.52
  num_metric_batches_dropped: 0
  pid: 12141
  policy_reward_mean: {}
  time_since_restore: 4985.729679584503
  time_this_iter_s: 13.428094625473022
  time_total_s: 4985.729679584503
  timestamp: 1594142615
  timesteps_since_restore: 1810000
  timesteps_this_iter: 5000
  timesteps_total: 1810000
  training_iteration: 362
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 33.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=12141], 4985 s, 362 iter, 1810000 ts, 1.63e+03 rew

agent-1: 340.0
agent-2: 358.0
agent-3: 351.0
agent-4: 335.0
agent-5: 297.0
Sum Reward: 1681.0
Avg Reward: 336.2
Min Reward: 297.0
Max Reward: 358.0
Gini Coefficient: 0.03283759666864961
20:20 Ratio: 1.2053872053872055
Max-min Ratio: 1.2053872053872055
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_13-23-49
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1870.0
  episode_reward_mean: 1632.79
  episode_reward_min: 1102.0
  episodes_this_iter: 1
  episodes_total: 362
  experiment_id: ebedc1946062457bb682d57fae83bd74
  hostname: gpu052
  info:
    apply_time_ms: 3.113
    dispatch_time_ms: 22.506
    learner:
      cur_lr: 0.0012394540244713426
      grad_gnorm: 38.0871467590332
      policy_entropy: 14.321176528930664
      policy_loss: 0.8380439877510071
      var_gnorm: 41.227745056152344
      vf_explained_var: 0.7107337713241577
      vf_loss: 41.13364791870117
    num_steps_sampled: 1815000
    num_steps_trained: 1815000
    wait_time_ms: 119.008
  iterations_since_restore: 363
  node_ip: 172.17.8.52
  num_metric_batches_dropped: 0
  pid: 12141
  policy_reward_mean: {}
  time_since_restore: 4999.234487295151
  time_this_iter_s: 13.504807710647583
  time_total_s: 4999.234487295151
  timestamp: 1594142629
  timesteps_since_restore: 1815000
  timesteps_this_iter: 5000
  timesteps_total: 1815000
  training_iteration: 363
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 33.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=12141], 4999 s, 363 iter, 1815000 ts, 1.63e+03 rew

agent-1: 353.0
agent-2: 332.0
agent-3: 307.0
agent-4: 356.0
agent-5: 344.0
Sum Reward: 1692.0
Avg Reward: 338.4
Min Reward: 307.0
Max Reward: 356.0
Gini Coefficient: 0.02813238770685579
20:20 Ratio: 1.1596091205211727
Max-min Ratio: 1.1596091205211727
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_13-24-03
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1870.0
  episode_reward_mean: 1634.19
  episode_reward_min: 1102.0
  episodes_this_iter: 1
  episodes_total: 363
  experiment_id: ebedc1946062457bb682d57fae83bd74
  hostname: gpu052
  info:
    apply_time_ms: 3.329
    dispatch_time_ms: 7.004
    learner:
      cur_lr: 0.0012391209602355957
      grad_gnorm: 40.0
      policy_entropy: 12.553990364074707
      policy_loss: -4.247212886810303
      var_gnorm: 41.271305084228516
      vf_explained_var: 0.09975409507751465
      vf_loss: 34.138389587402344
    num_steps_sampled: 1820000
    num_steps_trained: 1820000
    wait_time_ms: 130.208
  iterations_since_restore: 364
  node_ip: 172.17.8.52
  num_metric_batches_dropped: 0
  pid: 12141
  policy_reward_mean: {}
  time_since_restore: 5012.999572515488
  time_this_iter_s: 13.765085220336914
  time_total_s: 5012.999572515488
  timestamp: 1594142643
  timesteps_since_restore: 1820000
  timesteps_this_iter: 5000
  timesteps_total: 1820000
  training_iteration: 364
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 33.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=12141], 5012 s, 364 iter, 1820000 ts, 1.63e+03 rew

agent-1: 346.0
agent-2: 304.0
agent-3: 356.0
agent-4: 326.0
agent-5: 349.0
Sum Reward: 1681.0
Avg Reward: 336.2
Min Reward: 304.0
Max Reward: 356.0
Gini Coefficient: 0.03022010707911957
20:20 Ratio: 1.1710526315789473
Max-min Ratio: 1.1710526315789473
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_13-24-16
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1870.0
  episode_reward_mean: 1634.48
  episode_reward_min: 1102.0
  episodes_this_iter: 1
  episodes_total: 364
  experiment_id: ebedc1946062457bb682d57fae83bd74
  hostname: gpu052
  info:
    apply_time_ms: 2.645
    dispatch_time_ms: 6.968
    learner:
      cur_lr: 0.0012387880124151707
      grad_gnorm: 40.0
      policy_entropy: 20.983070373535156
      policy_loss: -7.963876247406006
      var_gnorm: 41.271636962890625
      vf_explained_var: 0.3369722366333008
      vf_loss: 50.550804138183594
    num_steps_sampled: 1825000
    num_steps_trained: 1825000
    wait_time_ms: 122.295
  iterations_since_restore: 365
  node_ip: 172.17.8.52
  num_metric_batches_dropped: 0
  pid: 12141
  policy_reward_mean: {}
  time_since_restore: 5026.08487701416
  time_this_iter_s: 13.085304498672485
  time_total_s: 5026.08487701416
  timestamp: 1594142656
  timesteps_since_restore: 1825000
  timesteps_this_iter: 5000
  timesteps_total: 1825000
  training_iteration: 365
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 33.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=12141], 5026 s, 365 iter, 1825000 ts, 1.63e+03 rew

agent-1: 345.0
agent-2: 351.0
agent-3: 350.0
agent-4: 353.0
agent-5: 330.0
Sum Reward: 1729.0
Avg Reward: 345.8
Min Reward: 330.0
Max Reward: 353.0
Gini Coefficient: 0.012030075187969926
20:20 Ratio: 1.0696969696969696
Max-min Ratio: 1.0696969696969696
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_13-24-29
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1870.0
  episode_reward_mean: 1634.72
  episode_reward_min: 1102.0
  episodes_this_iter: 1
  episodes_total: 365
  experiment_id: ebedc1946062457bb682d57fae83bd74
  hostname: gpu052
  info:
    apply_time_ms: 2.827
    dispatch_time_ms: 8.037
    learner:
      cur_lr: 0.0012384549481794238
      grad_gnorm: 40.0
      policy_entropy: 15.10675048828125
      policy_loss: -1.0887584686279297
      var_gnorm: 41.38656234741211
      vf_explained_var: 0.7088413834571838
      vf_loss: 19.81096839904785
    num_steps_sampled: 1830000
    num_steps_trained: 1830000
    wait_time_ms: 125.358
  iterations_since_restore: 366
  node_ip: 172.17.8.52
  num_metric_batches_dropped: 0
  pid: 12141
  policy_reward_mean: {}
  time_since_restore: 5039.696296930313
  time_this_iter_s: 13.611419916152954
  time_total_s: 5039.696296930313
  timestamp: 1594142669
  timesteps_since_restore: 1830000
  timesteps_this_iter: 5000
  timesteps_total: 1830000
  training_iteration: 366
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 33.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=12141], 5039 s, 366 iter, 1830000 ts, 1.63e+03 rew

agent-1: 315.0
agent-2: 362.0
agent-3: 350.0
agent-4: 334.0
agent-5: 305.0
Sum Reward: 1666.0
Avg Reward: 333.2
Min Reward: 305.0
Max Reward: 362.0
Gini Coefficient: 0.03577430972388956
20:20 Ratio: 1.1868852459016392
Max-min Ratio: 1.1868852459016392
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_13-24-43
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1870.0
  episode_reward_mean: 1633.37
  episode_reward_min: 1102.0
  episodes_this_iter: 1
  episodes_total: 366
  experiment_id: ebedc1946062457bb682d57fae83bd74
  hostname: gpu052
  info:
    apply_time_ms: 2.711
    dispatch_time_ms: 6.757
    learner:
      cur_lr: 0.0012381220003589988
      grad_gnorm: 40.0
      policy_entropy: 27.7380313873291
      policy_loss: -0.28668683767318726
      var_gnorm: 41.47422409057617
      vf_explained_var: 0.7389674186706543
      vf_loss: 65.29608154296875
    num_steps_sampled: 1835000
    num_steps_trained: 1835000
    wait_time_ms: 127.232
  iterations_since_restore: 367
  node_ip: 172.17.8.52
  num_metric_batches_dropped: 0
  pid: 12141
  policy_reward_mean: {}
  time_since_restore: 5053.028285264969
  time_this_iter_s: 13.331988334655762
  time_total_s: 5053.028285264969
  timestamp: 1594142683
  timesteps_since_restore: 1835000
  timesteps_this_iter: 5000
  timesteps_total: 1835000
  training_iteration: 367
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 33.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=12141], 5053 s, 367 iter, 1835000 ts, 1.63e+03 rew

agent-1: 302.0
agent-2: 354.0
agent-3: 305.0
agent-4: 352.0
agent-5: 299.0
Sum Reward: 1612.0
Avg Reward: 322.4
Min Reward: 299.0
Max Reward: 354.0
Gini Coefficient: 0.03970223325062035
20:20 Ratio: 1.1839464882943145
Max-min Ratio: 1.1839464882943145
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_13-24-56
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1870.0
  episode_reward_mean: 1633.53
  episode_reward_min: 1102.0
  episodes_this_iter: 1
  episodes_total: 367
  experiment_id: ebedc1946062457bb682d57fae83bd74
  hostname: gpu052
  info:
    apply_time_ms: 3.757
    dispatch_time_ms: 6.049
    learner:
      cur_lr: 0.0012377890525385737
      grad_gnorm: 40.000003814697266
      policy_entropy: 41.8741340637207
      policy_loss: -22.561931610107422
      var_gnorm: 41.52439498901367
      vf_explained_var: 0.6215584874153137
      vf_loss: 116.42679595947266
    num_steps_sampled: 1840000
    num_steps_trained: 1840000
    wait_time_ms: 117.674
  iterations_since_restore: 368
  node_ip: 172.17.8.52
  num_metric_batches_dropped: 0
  pid: 12141
  policy_reward_mean: {}
  time_since_restore: 5066.169018745422
  time_this_iter_s: 13.140733480453491
  time_total_s: 5066.169018745422
  timestamp: 1594142696
  timesteps_since_restore: 1840000
  timesteps_this_iter: 5000
  timesteps_total: 1840000
  training_iteration: 368
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 34.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=12141], 5066 s, 368 iter, 1840000 ts, 1.63e+03 rew

agent-1: 263.0
agent-2: 353.0
agent-3: 275.0
agent-4: 331.0
agent-5: 349.0
Sum Reward: 1571.0
Avg Reward: 314.2
Min Reward: 263.0
Max Reward: 353.0
Gini Coefficient: 0.06467218332272438
20:20 Ratio: 1.3422053231939164
Max-min Ratio: 1.3422053231939164
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_13-25-09
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1870.0
  episode_reward_mean: 1632.08
  episode_reward_min: 1102.0
  episodes_this_iter: 1
  episodes_total: 368
  experiment_id: ebedc1946062457bb682d57fae83bd74
  hostname: gpu052
  info:
    apply_time_ms: 3.068
    dispatch_time_ms: 11.211
    learner:
      cur_lr: 0.0012374559883028269
      grad_gnorm: 40.0
      policy_entropy: 40.311038970947266
      policy_loss: 7.6075439453125
      var_gnorm: 41.637168884277344
      vf_explained_var: 0.6035692691802979
      vf_loss: 105.33441162109375
    num_steps_sampled: 1845000
    num_steps_trained: 1845000
    wait_time_ms: 115.516
  iterations_since_restore: 369
  node_ip: 172.17.8.52
  num_metric_batches_dropped: 0
  pid: 12141
  policy_reward_mean: {}
  time_since_restore: 5079.481259346008
  time_this_iter_s: 13.312240600585938
  time_total_s: 5079.481259346008
  timestamp: 1594142709
  timesteps_since_restore: 1845000
  timesteps_this_iter: 5000
  timesteps_total: 1845000
  training_iteration: 369
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 34.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=12141], 5079 s, 369 iter, 1845000 ts, 1.63e+03 rew

agent-1: 249.0
agent-2: 330.0
agent-3: 312.0
agent-4: 317.0
agent-5: 345.0
Sum Reward: 1553.0
Avg Reward: 310.6
Min Reward: 249.0
Max Reward: 345.0
Gini Coefficient: 0.0540888602704443
20:20 Ratio: 1.3855421686746987
Max-min Ratio: 1.3855421686746987
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_13-25-22
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1870.0
  episode_reward_mean: 1630.8
  episode_reward_min: 1102.0
  episodes_this_iter: 1
  episodes_total: 369
  experiment_id: ebedc1946062457bb682d57fae83bd74
  hostname: gpu052
  info:
    apply_time_ms: 3.224
    dispatch_time_ms: 6.302
    learner:
      cur_lr: 0.0012371230404824018
      grad_gnorm: 40.00000762939453
      policy_entropy: 38.68949890136719
      policy_loss: -6.177475452423096
      var_gnorm: 41.69456481933594
      vf_explained_var: -0.07535195350646973
      vf_loss: 59.86946487426758
    num_steps_sampled: 1850000
    num_steps_trained: 1850000
    wait_time_ms: 118.17
  iterations_since_restore: 370
  node_ip: 172.17.8.52
  num_metric_batches_dropped: 0
  pid: 12141
  policy_reward_mean: {}
  time_since_restore: 5092.265037536621
  time_this_iter_s: 12.783778190612793
  time_total_s: 5092.265037536621
  timestamp: 1594142722
  timesteps_since_restore: 1850000
  timesteps_this_iter: 5000
  timesteps_total: 1850000
  training_iteration: 370
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 34.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=12141], 5092 s, 370 iter, 1850000 ts, 1.63e+03 rew

agent-1: 344.0
agent-2: 355.0
agent-3: 244.0
agent-4: 343.0
agent-5: 388.0
Sum Reward: 1674.0
Avg Reward: 334.8
Min Reward: 244.0
Max Reward: 388.0
Gini Coefficient: 0.07168458781362007
20:20 Ratio: 1.5901639344262295
Max-min Ratio: 1.5901639344262295
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_13-25-35
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1870.0
  episode_reward_mean: 1630.5
  episode_reward_min: 1102.0
  episodes_this_iter: 1
  episodes_total: 370
  experiment_id: ebedc1946062457bb682d57fae83bd74
  hostname: gpu052
  info:
    apply_time_ms: 2.41
    dispatch_time_ms: 5.287
    learner:
      cur_lr: 0.001236789976246655
      grad_gnorm: 40.000003814697266
      policy_entropy: 26.14665985107422
      policy_loss: -27.47224998474121
      var_gnorm: 41.71461486816406
      vf_explained_var: 0.6058893203735352
      vf_loss: 119.35995483398438
    num_steps_sampled: 1855000
    num_steps_trained: 1855000
    wait_time_ms: 125.506
  iterations_since_restore: 371
  node_ip: 172.17.8.52
  num_metric_batches_dropped: 0
  pid: 12141
  policy_reward_mean: {}
  time_since_restore: 5105.171958446503
  time_this_iter_s: 12.906920909881592
  time_total_s: 5105.171958446503
  timestamp: 1594142735
  timesteps_since_restore: 1855000
  timesteps_this_iter: 5000
  timesteps_total: 1855000
  training_iteration: 371
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 33.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=12141], 5105 s, 371 iter, 1855000 ts, 1.63e+03 rew

agent-1: 371.0
agent-2: 318.0
agent-3: 274.0
agent-4: 336.0
agent-5: 365.0
Sum Reward: 1664.0
Avg Reward: 332.8
Min Reward: 274.0
Max Reward: 371.0
Gini Coefficient: 0.05793269230769231
20:20 Ratio: 1.354014598540146
Max-min Ratio: 1.354014598540146
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_13-25-48
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1870.0
  episode_reward_mean: 1630.16
  episode_reward_min: 1102.0
  episodes_this_iter: 1
  episodes_total: 371
  experiment_id: ebedc1946062457bb682d57fae83bd74
  hostname: gpu052
  info:
    apply_time_ms: 3.113
    dispatch_time_ms: 6.434
    learner:
      cur_lr: 0.00123645702842623
      grad_gnorm: 40.00000762939453
      policy_entropy: 40.96936798095703
      policy_loss: -28.279857635498047
      var_gnorm: 41.7943000793457
      vf_explained_var: -0.3447377681732178
      vf_loss: 125.41441345214844
    num_steps_sampled: 1860000
    num_steps_trained: 1860000
    wait_time_ms: 138.448
  iterations_since_restore: 372
  node_ip: 172.17.8.52
  num_metric_batches_dropped: 0
  pid: 12141
  policy_reward_mean: {}
  time_since_restore: 5118.529541730881
  time_this_iter_s: 13.357583284378052
  time_total_s: 5118.529541730881
  timestamp: 1594142748
  timesteps_since_restore: 1860000
  timesteps_this_iter: 5000
  timesteps_total: 1860000
  training_iteration: 372
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 33.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=12141], 5118 s, 372 iter, 1860000 ts, 1.63e+03 rew

agent-1: 314.0
agent-2: 351.0
agent-3: 292.0
agent-4: 325.0
agent-5: 363.0
Sum Reward: 1645.0
Avg Reward: 329.0
Min Reward: 292.0
Max Reward: 363.0
Gini Coefficient: 0.043525835866261395
20:20 Ratio: 1.2431506849315068
Max-min Ratio: 1.2431506849315068
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_13-26-02
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1870.0
  episode_reward_mean: 1631.5
  episode_reward_min: 1102.0
  episodes_this_iter: 1
  episodes_total: 372
  experiment_id: ebedc1946062457bb682d57fae83bd74
  hostname: gpu052
  info:
    apply_time_ms: 3.271
    dispatch_time_ms: 8.109
    learner:
      cur_lr: 0.001236123964190483
      grad_gnorm: 39.9999885559082
      policy_entropy: 29.433847427368164
      policy_loss: -9.886007308959961
      var_gnorm: 41.82221603393555
      vf_explained_var: 0.5614270567893982
      vf_loss: 81.51018524169922
    num_steps_sampled: 1865000
    num_steps_trained: 1865000
    wait_time_ms: 126.707
  iterations_since_restore: 373
  node_ip: 172.17.8.52
  num_metric_batches_dropped: 0
  pid: 12141
  policy_reward_mean: {}
  time_since_restore: 5131.625244855881
  time_this_iter_s: 13.095703125
  time_total_s: 5131.625244855881
  timestamp: 1594142762
  timesteps_since_restore: 1865000
  timesteps_this_iter: 5000
  timesteps_total: 1865000
  training_iteration: 373
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 33.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=12141], 5131 s, 373 iter, 1865000 ts, 1.63e+03 rew

agent-1: 266.0
agent-2: 352.0
agent-3: 332.0
agent-4: 308.0
agent-5: 391.0
Sum Reward: 1649.0
Avg Reward: 329.8
Min Reward: 266.0
Max Reward: 391.0
Gini Coefficient: 0.07131594906003638
20:20 Ratio: 1.4699248120300752
Max-min Ratio: 1.4699248120300752
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_13-26-15
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1870.0
  episode_reward_mean: 1632.19
  episode_reward_min: 1102.0
  episodes_this_iter: 1
  episodes_total: 373
  experiment_id: ebedc1946062457bb682d57fae83bd74
  hostname: gpu052
  info:
    apply_time_ms: 2.823
    dispatch_time_ms: 8.495
    learner:
      cur_lr: 0.001235791016370058
      grad_gnorm: 40.000003814697266
      policy_entropy: 25.649639129638672
      policy_loss: -30.68923568725586
      var_gnorm: 41.827457427978516
      vf_explained_var: 0.47890156507492065
      vf_loss: 40.24970626831055
    num_steps_sampled: 1870000
    num_steps_trained: 1870000
    wait_time_ms: 125.338
  iterations_since_restore: 374
  node_ip: 172.17.8.52
  num_metric_batches_dropped: 0
  pid: 12141
  policy_reward_mean: {}
  time_since_restore: 5144.970442056656
  time_this_iter_s: 13.345197200775146
  time_total_s: 5144.970442056656
  timestamp: 1594142775
  timesteps_since_restore: 1870000
  timesteps_this_iter: 5000
  timesteps_total: 1870000
  training_iteration: 374
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 33.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=12141], 5144 s, 374 iter, 1870000 ts, 1.63e+03 rew

agent-1: 297.0
agent-2: 351.0
agent-3: 355.0
agent-4: 324.0
agent-5: 385.0
Sum Reward: 1712.0
Avg Reward: 342.4
Min Reward: 297.0
Max Reward: 385.0
Gini Coefficient: 0.04836448598130841
20:20 Ratio: 1.2962962962962963
Max-min Ratio: 1.2962962962962963
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_13-26-28
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1870.0
  episode_reward_mean: 1631.94
  episode_reward_min: 1102.0
  episodes_this_iter: 1
  episodes_total: 374
  experiment_id: ebedc1946062457bb682d57fae83bd74
  hostname: gpu052
  info:
    apply_time_ms: 2.657
    dispatch_time_ms: 6.596
    learner:
      cur_lr: 0.0012354579521343112
      grad_gnorm: 40.00000762939453
      policy_entropy: 28.86321258544922
      policy_loss: 0.7629976272583008
      var_gnorm: 41.87720489501953
      vf_explained_var: 0.6559828519821167
      vf_loss: 131.7390594482422
    num_steps_sampled: 1875000
    num_steps_trained: 1875000
    wait_time_ms: 121.433
  iterations_since_restore: 375
  node_ip: 172.17.8.52
  num_metric_batches_dropped: 0
  pid: 12141
  policy_reward_mean: {}
  time_since_restore: 5158.145030260086
  time_this_iter_s: 13.174588203430176
  time_total_s: 5158.145030260086
  timestamp: 1594142788
  timesteps_since_restore: 1875000
  timesteps_this_iter: 5000
  timesteps_total: 1875000
  training_iteration: 375
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 34.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=12141], 5158 s, 375 iter, 1875000 ts, 1.63e+03 rew

agent-1: 367.0
agent-2: 388.0
agent-3: 242.0
agent-4: 212.0
agent-5: 336.0
Sum Reward: 1545.0
Avg Reward: 309.0
Min Reward: 212.0
Max Reward: 388.0
Gini Coefficient: 0.12349514563106796
20:20 Ratio: 1.830188679245283
Max-min Ratio: 1.830188679245283
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_13-26-41
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1870.0
  episode_reward_mean: 1631.35
  episode_reward_min: 1102.0
  episodes_this_iter: 1
  episodes_total: 375
  experiment_id: ebedc1946062457bb682d57fae83bd74
  hostname: gpu052
  info:
    apply_time_ms: 3.748
    dispatch_time_ms: 11.435
    learner:
      cur_lr: 0.0012351250043138862
      grad_gnorm: 40.0
      policy_entropy: 21.950345993041992
      policy_loss: 8.485758781433105
      var_gnorm: 41.919677734375
      vf_explained_var: 0.24568629264831543
      vf_loss: 102.42857360839844
    num_steps_sampled: 1880000
    num_steps_trained: 1880000
    wait_time_ms: 111.579
  iterations_since_restore: 376
  node_ip: 172.17.8.52
  num_metric_batches_dropped: 0
  pid: 12141
  policy_reward_mean: {}
  time_since_restore: 5170.58873295784
  time_this_iter_s: 12.443702697753906
  time_total_s: 5170.58873295784
  timestamp: 1594142801
  timesteps_since_restore: 1880000
  timesteps_this_iter: 5000
  timesteps_total: 1880000
  training_iteration: 376
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 34.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=12141], 5170 s, 376 iter, 1880000 ts, 1.63e+03 rew

agent-1: 304.0
agent-2: 345.0
agent-3: 254.0
agent-4: 267.0
agent-5: 347.0
Sum Reward: 1517.0
Avg Reward: 303.4
Min Reward: 254.0
Max Reward: 347.0
Gini Coefficient: 0.06961107448912326
20:20 Ratio: 1.3661417322834646
Max-min Ratio: 1.3661417322834646
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_13-26-53
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1870.0
  episode_reward_mean: 1630.41
  episode_reward_min: 1102.0
  episodes_this_iter: 1
  episodes_total: 376
  experiment_id: ebedc1946062457bb682d57fae83bd74
  hostname: gpu052
  info:
    apply_time_ms: 3.312
    dispatch_time_ms: 10.913
    learner:
      cur_lr: 0.0012347920564934611
      grad_gnorm: 39.999996185302734
      policy_entropy: 33.465293884277344
      policy_loss: 6.482099533081055
      var_gnorm: 41.992515563964844
      vf_explained_var: -0.355165958404541
      vf_loss: 142.64971923828125
    num_steps_sampled: 1885000
    num_steps_trained: 1885000
    wait_time_ms: 108.99
  iterations_since_restore: 377
  node_ip: 172.17.8.52
  num_metric_batches_dropped: 0
  pid: 12141
  policy_reward_mean: {}
  time_since_restore: 5183.124361515045
  time_this_iter_s: 12.5356285572052
  time_total_s: 5183.124361515045
  timestamp: 1594142813
  timesteps_since_restore: 1885000
  timesteps_this_iter: 5000
  timesteps_total: 1885000
  training_iteration: 377
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 34.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=12141], 5183 s, 377 iter, 1885000 ts, 1.63e+03 rew

agent-1: 216.0
agent-2: 317.0
agent-3: 185.0
agent-4: 263.0
agent-5: 322.0
Sum Reward: 1303.0
Avg Reward: 260.6
Min Reward: 185.0
Max Reward: 322.0
Gini Coefficient: 0.11511895625479662
20:20 Ratio: 1.7405405405405405
Max-min Ratio: 1.7405405405405405
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_13-27-04
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1870.0
  episode_reward_mean: 1626.73
  episode_reward_min: 1102.0
  episodes_this_iter: 1
  episodes_total: 377
  experiment_id: ebedc1946062457bb682d57fae83bd74
  hostname: gpu052
  info:
    apply_time_ms: 3.043
    dispatch_time_ms: 9.95
    learner:
      cur_lr: 0.0012344589922577143
      grad_gnorm: 40.0
      policy_entropy: 19.873136520385742
      policy_loss: -13.313471794128418
      var_gnorm: 42.08557891845703
      vf_explained_var: 0.21739274263381958
      vf_loss: 27.67113494873047
    num_steps_sampled: 1890000
    num_steps_trained: 1890000
    wait_time_ms: 96.685
  iterations_since_restore: 378
  node_ip: 172.17.8.52
  num_metric_batches_dropped: 0
  pid: 12141
  policy_reward_mean: {}
  time_since_restore: 5194.132467508316
  time_this_iter_s: 11.008105993270874
  time_total_s: 5194.132467508316
  timestamp: 1594142824
  timesteps_since_restore: 1890000
  timesteps_this_iter: 5000
  timesteps_total: 1890000
  training_iteration: 378
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 35.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=12141], 5194 s, 378 iter, 1890000 ts, 1.63e+03 rew

agent-1: 170.0
agent-2: 198.0
agent-3: 167.0
agent-4: 207.0
agent-5: 211.0
Sum Reward: 953.0
Avg Reward: 190.6
Min Reward: 167.0
Max Reward: 211.0
Gini Coefficient: 0.05246589716684155
20:20 Ratio: 1.2634730538922156
Max-min Ratio: 1.2634730538922156
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_13-27-15
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1870.0
  episode_reward_mean: 1619.48
  episode_reward_min: 953.0
  episodes_this_iter: 1
  episodes_total: 378
  experiment_id: ebedc1946062457bb682d57fae83bd74
  hostname: gpu052
  info:
    apply_time_ms: 3.613
    dispatch_time_ms: 10.08
    learner:
      cur_lr: 0.0012341260444372892
      grad_gnorm: 40.0
      policy_entropy: 33.43976974487305
      policy_loss: 20.91063690185547
      var_gnorm: 41.9969596862793
      vf_explained_var: 0.12485545873641968
      vf_loss: 124.65603637695312
    num_steps_sampled: 1895000
    num_steps_trained: 1895000
    wait_time_ms: 90.153
  iterations_since_restore: 379
  node_ip: 172.17.8.52
  num_metric_batches_dropped: 0
  pid: 12141
  policy_reward_mean: {}
  time_since_restore: 5204.659224510193
  time_this_iter_s: 10.526757001876831
  time_total_s: 5204.659224510193
  timestamp: 1594142835
  timesteps_since_restore: 1895000
  timesteps_this_iter: 5000
  timesteps_total: 1895000
  training_iteration: 379
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 34.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=12141], 5204 s, 379 iter, 1895000 ts, 1.62e+03 rew

agent-1: 108.0
agent-2: 161.0
agent-3: 97.0
agent-4: 116.0
agent-5: 89.0
Sum Reward: 571.0
Avg Reward: 114.2
Min Reward: 89.0
Max Reward: 161.0
Gini Coefficient: 0.11418563922942207
20:20 Ratio: 1.8089887640449438
Max-min Ratio: 1.8089887640449438
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_13-27-25
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1870.0
  episode_reward_mean: 1607.57
  episode_reward_min: 571.0
  episodes_this_iter: 1
  episodes_total: 379
  experiment_id: ebedc1946062457bb682d57fae83bd74
  hostname: gpu052
  info:
    apply_time_ms: 3.727
    dispatch_time_ms: 8.681
    learner:
      cur_lr: 0.0012337929802015424
      grad_gnorm: 40.0
      policy_entropy: 32.240936279296875
      policy_loss: 19.19155502319336
      var_gnorm: 41.96382141113281
      vf_explained_var: 0.37838661670684814
      vf_loss: 73.84115600585938
    num_steps_sampled: 1900000
    num_steps_trained: 1900000
    wait_time_ms: 90.415
  iterations_since_restore: 380
  node_ip: 172.17.8.52
  num_metric_batches_dropped: 0
  pid: 12141
  policy_reward_mean: {}
  time_since_restore: 5214.821323633194
  time_this_iter_s: 10.162099123001099
  time_total_s: 5214.821323633194
  timestamp: 1594142845
  timesteps_since_restore: 1900000
  timesteps_this_iter: 5000
  timesteps_total: 1900000
  training_iteration: 380
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 34.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=12141], 5214 s, 380 iter, 1900000 ts, 1.61e+03 rew

agent-1: 112.0
agent-2: 153.0
agent-3: 59.0
agent-4: 107.0
agent-5: 185.0
Sum Reward: 616.0
Avg Reward: 123.2
Min Reward: 59.0
Max Reward: 185.0
Gini Coefficient: 0.19350649350649352
20:20 Ratio: 3.135593220338983
Max-min Ratio: 3.135593220338983
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_13-27-37
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1870.0
  episode_reward_mean: 1595.85
  episode_reward_min: 571.0
  episodes_this_iter: 1
  episodes_total: 380
  experiment_id: ebedc1946062457bb682d57fae83bd74
  hostname: gpu052
  info:
    apply_time_ms: 2.96
    dispatch_time_ms: 9.794
    learner:
      cur_lr: 0.0012334600323811173
      grad_gnorm: 40.0
      policy_entropy: 35.00731658935547
      policy_loss: 9.270591735839844
      var_gnorm: 41.95906448364258
      vf_explained_var: 0.32952797412872314
      vf_loss: 56.85145568847656
    num_steps_sampled: 1905000
    num_steps_trained: 1905000
    wait_time_ms: 101.83
  iterations_since_restore: 381
  node_ip: 172.17.8.52
  num_metric_batches_dropped: 0
  pid: 12141
  policy_reward_mean: {}
  time_since_restore: 5225.029227972031
  time_this_iter_s: 10.20790433883667
  time_total_s: 5225.029227972031
  timestamp: 1594142857
  timesteps_since_restore: 1905000
  timesteps_this_iter: 5000
  timesteps_total: 1905000
  training_iteration: 381
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 34.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=12141], 5225 s, 381 iter, 1905000 ts, 1.6e+03 rew

agent-1: 177.0
agent-2: 185.0
agent-3: 183.0
agent-4: 260.0
agent-5: 219.0
Sum Reward: 1024.0
Avg Reward: 204.8
Min Reward: 177.0
Max Reward: 260.0
Gini Coefficient: 0.07890625
20:20 Ratio: 1.4689265536723164
Max-min Ratio: 1.4689265536723164
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_13-27-49
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1828.0
  episode_reward_mean: 1587.39
  episode_reward_min: 571.0
  episodes_this_iter: 1
  episodes_total: 381
  experiment_id: ebedc1946062457bb682d57fae83bd74
  hostname: gpu052
  info:
    apply_time_ms: 2.571
    dispatch_time_ms: 7.123
    learner:
      cur_lr: 0.0012331269681453705
      grad_gnorm: 40.000003814697266
      policy_entropy: 15.594462394714355
      policy_loss: 2.363325357437134
      var_gnorm: 41.97093200683594
      vf_explained_var: 0.518494725227356
      vf_loss: 149.85858154296875
    num_steps_sampled: 1910000
    num_steps_trained: 1910000
    wait_time_ms: 119.771
  iterations_since_restore: 382
  node_ip: 172.17.8.52
  num_metric_batches_dropped: 0
  pid: 12141
  policy_reward_mean: {}
  time_since_restore: 5236.768520832062
  time_this_iter_s: 11.739292860031128
  time_total_s: 5236.768520832062
  timestamp: 1594142869
  timesteps_since_restore: 1910000
  timesteps_this_iter: 5000
  timesteps_total: 1910000
  training_iteration: 382
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 34.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=12141], 5236 s, 382 iter, 1910000 ts, 1.59e+03 rew

agent-1: 224.0
agent-2: 273.0
agent-3: 230.0
agent-4: 283.0
agent-5: 318.0
Sum Reward: 1328.0
Avg Reward: 265.6
Min Reward: 224.0
Max Reward: 318.0
Gini Coefficient: 0.07259036144578314
20:20 Ratio: 1.4196428571428572
Max-min Ratio: 1.4196428571428572
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_13-28-01
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1828.0
  episode_reward_mean: 1583.59
  episode_reward_min: 571.0
  episodes_this_iter: 1
  episodes_total: 382
  experiment_id: ebedc1946062457bb682d57fae83bd74
  hostname: gpu052
  info:
    apply_time_ms: 2.446
    dispatch_time_ms: 6.128
    learner:
      cur_lr: 0.0012327940203249454
      grad_gnorm: 40.000003814697266
      policy_entropy: 14.873581886291504
      policy_loss: 32.18656921386719
      var_gnorm: 42.03832244873047
      vf_explained_var: 0.7128869295120239
      vf_loss: 123.33062744140625
    num_steps_sampled: 1915000
    num_steps_trained: 1915000
    wait_time_ms: 113.345
  iterations_since_restore: 383
  node_ip: 172.17.8.52
  num_metric_batches_dropped: 0
  pid: 12141
  policy_reward_mean: {}
  time_since_restore: 5249.0131759643555
  time_this_iter_s: 12.244655132293701
  time_total_s: 5249.0131759643555
  timestamp: 1594142881
  timesteps_since_restore: 1915000
  timesteps_this_iter: 5000
  timesteps_total: 1915000
  training_iteration: 383
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 34.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=12141], 5249 s, 383 iter, 1915000 ts, 1.58e+03 rew

agent-1: 302.0
agent-2: 305.0
agent-3: 121.0
agent-4: 329.0
agent-5: 300.0
Sum Reward: 1357.0
Avg Reward: 271.4
Min Reward: 121.0
Max Reward: 329.0
Gini Coefficient: 0.12409727339719971
20:20 Ratio: 2.71900826446281
Max-min Ratio: 2.71900826446281
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_13-28-13
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1828.0
  episode_reward_mean: 1579.44
  episode_reward_min: 571.0
  episodes_this_iter: 1
  episodes_total: 383
  experiment_id: ebedc1946062457bb682d57fae83bd74
  hostname: gpu052
  info:
    apply_time_ms: 2.457
    dispatch_time_ms: 5.848
    learner:
      cur_lr: 0.0012324609560891986
      grad_gnorm: 39.999996185302734
      policy_entropy: 25.651851654052734
      policy_loss: 17.59466552734375
      var_gnorm: 41.96925735473633
      vf_explained_var: 0.5966292023658752
      vf_loss: 243.8945770263672
    num_steps_sampled: 1920000
    num_steps_trained: 1920000
    wait_time_ms: 123.054
  iterations_since_restore: 384
  node_ip: 172.17.8.52
  num_metric_batches_dropped: 0
  pid: 12141
  policy_reward_mean: {}
  time_since_restore: 5261.124156475067
  time_this_iter_s: 12.11098051071167
  time_total_s: 5261.124156475067
  timestamp: 1594142893
  timesteps_since_restore: 1920000
  timesteps_this_iter: 5000
  timesteps_total: 1920000
  training_iteration: 384
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 34.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=12141], 5261 s, 384 iter, 1920000 ts, 1.58e+03 rew

agent-1: 342.0
agent-2: 252.0
agent-3: 266.0
agent-4: 295.0
agent-5: 341.0
Sum Reward: 1496.0
Avg Reward: 299.2
Min Reward: 252.0
Max Reward: 342.0
Gini Coefficient: 0.06818181818181818
20:20 Ratio: 1.3571428571428572
Max-min Ratio: 1.3571428571428572
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_13-28-26
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1828.0
  episode_reward_mean: 1577.49
  episode_reward_min: 571.0
  episodes_this_iter: 1
  episodes_total: 384
  experiment_id: ebedc1946062457bb682d57fae83bd74
  hostname: gpu052
  info:
    apply_time_ms: 2.607
    dispatch_time_ms: 5.888
    learner:
      cur_lr: 0.0012321280082687736
      grad_gnorm: 40.0
      policy_entropy: 19.197925567626953
      policy_loss: 3.8992748260498047
      var_gnorm: 41.92792892456055
      vf_explained_var: -0.5688270330429077
      vf_loss: 126.34197998046875
    num_steps_sampled: 1925000
    num_steps_trained: 1925000
    wait_time_ms: 135.421
  iterations_since_restore: 385
  node_ip: 172.17.8.52
  num_metric_batches_dropped: 0
  pid: 12141
  policy_reward_mean: {}
  time_since_restore: 5274.402157306671
  time_this_iter_s: 13.278000831604004
  time_total_s: 5274.402157306671
  timestamp: 1594142906
  timesteps_since_restore: 1925000
  timesteps_this_iter: 5000
  timesteps_total: 1925000
  training_iteration: 385
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 34.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=12141], 5274 s, 385 iter, 1925000 ts, 1.58e+03 rew

agent-1: 341.0
agent-2: 301.0
agent-3: 282.0
agent-4: 326.0
agent-5: 338.0
Sum Reward: 1588.0
Avg Reward: 317.6
Min Reward: 282.0
Max Reward: 341.0
Gini Coefficient: 0.03904282115869018
20:20 Ratio: 1.2092198581560283
Max-min Ratio: 1.2092198581560283
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_13-28-39
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1828.0
  episode_reward_mean: 1575.98
  episode_reward_min: 571.0
  episodes_this_iter: 1
  episodes_total: 385
  experiment_id: ebedc1946062457bb682d57fae83bd74
  hostname: gpu052
  info:
    apply_time_ms: 3.061
    dispatch_time_ms: 8.213
    learner:
      cur_lr: 0.0012317949440330267
      grad_gnorm: 39.999996185302734
      policy_entropy: 7.976691722869873
      policy_loss: -6.012318134307861
      var_gnorm: 41.97097396850586
      vf_explained_var: -0.5136842727661133
      vf_loss: 32.39106369018555
    num_steps_sampled: 1930000
    num_steps_trained: 1930000
    wait_time_ms: 120.384
  iterations_since_restore: 386
  node_ip: 172.17.8.52
  num_metric_batches_dropped: 0
  pid: 12141
  policy_reward_mean: {}
  time_since_restore: 5287.476076126099
  time_this_iter_s: 13.07391881942749
  time_total_s: 5287.476076126099
  timestamp: 1594142919
  timesteps_since_restore: 1930000
  timesteps_this_iter: 5000
  timesteps_total: 1930000
  training_iteration: 386
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 34.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=12141], 5287 s, 386 iter, 1930000 ts, 1.58e+03 rew

agent-1: 344.0
agent-2: 361.0
agent-3: 366.0
agent-4: 363.0
agent-5: 327.0
Sum Reward: 1761.0
Avg Reward: 352.2
Min Reward: 327.0
Max Reward: 366.0
Gini Coefficient: 0.022032935831913684
20:20 Ratio: 1.1192660550458715
Max-min Ratio: 1.1192660550458715
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_13-28-52
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1828.0
  episode_reward_mean: 1576.34
  episode_reward_min: 571.0
  episodes_this_iter: 1
  episodes_total: 386
  experiment_id: ebedc1946062457bb682d57fae83bd74
  hostname: gpu052
  info:
    apply_time_ms: 3.135
    dispatch_time_ms: 5.687
    learner:
      cur_lr: 0.0012314619962126017
      grad_gnorm: 40.0
      policy_entropy: 12.935534477233887
      policy_loss: -7.626898765563965
      var_gnorm: 41.96284866333008
      vf_explained_var: 0.10817044973373413
      vf_loss: 35.05636978149414
    num_steps_sampled: 1935000
    num_steps_trained: 1935000
    wait_time_ms: 119.703
  iterations_since_restore: 387
  node_ip: 172.17.8.52
  num_metric_batches_dropped: 0
  pid: 12141
  policy_reward_mean: {}
  time_since_restore: 5300.455015659332
  time_this_iter_s: 12.978939533233643
  time_total_s: 5300.455015659332
  timestamp: 1594142932
  timesteps_since_restore: 1935000
  timesteps_this_iter: 5000
  timesteps_total: 1935000
  training_iteration: 387
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 34.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=12141], 5300 s, 387 iter, 1935000 ts, 1.58e+03 rew

agent-1: 374.0
agent-2: 376.0
agent-3: 340.0
agent-4: 375.0
agent-5: 368.0
Sum Reward: 1833.0
Avg Reward: 366.6
Min Reward: 340.0
Max Reward: 376.0
Gini Coefficient: 0.01723949809056192
20:20 Ratio: 1.1058823529411765
Max-min Ratio: 1.1058823529411765
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_13-29-06
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1833.0
  episode_reward_mean: 1577.43
  episode_reward_min: 571.0
  episodes_this_iter: 1
  episodes_total: 387
  experiment_id: ebedc1946062457bb682d57fae83bd74
  hostname: gpu052
  info:
    apply_time_ms: 2.876
    dispatch_time_ms: 6.178
    learner:
      cur_lr: 0.0012311290483921766
      grad_gnorm: 40.0
      policy_entropy: 6.581590175628662
      policy_loss: 3.6422181129455566
      var_gnorm: 41.96641540527344
      vf_explained_var: 0.4210638999938965
      vf_loss: 26.865554809570312
    num_steps_sampled: 1940000
    num_steps_trained: 1940000
    wait_time_ms: 125.189
  iterations_since_restore: 388
  node_ip: 172.17.8.52
  num_metric_batches_dropped: 0
  pid: 12141
  policy_reward_mean: {}
  time_since_restore: 5313.857060432434
  time_this_iter_s: 13.402044773101807
  time_total_s: 5313.857060432434
  timestamp: 1594142946
  timesteps_since_restore: 1940000
  timesteps_this_iter: 5000
  timesteps_total: 1940000
  training_iteration: 388
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 34.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=12141], 5313 s, 388 iter, 1940000 ts, 1.58e+03 rew

agent-1: 306.0
agent-2: 353.0
agent-3: 322.0
agent-4: 309.0
agent-5: 376.0
Sum Reward: 1666.0
Avg Reward: 333.2
Min Reward: 306.0
Max Reward: 376.0
Gini Coefficient: 0.04417767106842737
20:20 Ratio: 1.2287581699346406
Max-min Ratio: 1.2287581699346406
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_13-29-19
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1833.0
  episode_reward_mean: 1577.88
  episode_reward_min: 571.0
  episodes_this_iter: 1
  episodes_total: 388
  experiment_id: ebedc1946062457bb682d57fae83bd74
  hostname: gpu052
  info:
    apply_time_ms: 3.389
    dispatch_time_ms: 8.162
    learner:
      cur_lr: 0.0012307959841564298
      grad_gnorm: 24.461566925048828
      policy_entropy: 13.352652549743652
      policy_loss: -4.232706546783447
      var_gnorm: 42.00901412963867
      vf_explained_var: 0.4120616316795349
      vf_loss: 9.130032539367676
    num_steps_sampled: 1945000
    num_steps_trained: 1945000
    wait_time_ms: 127.533
  iterations_since_restore: 389
  node_ip: 172.17.8.52
  num_metric_batches_dropped: 0
  pid: 12141
  policy_reward_mean: {}
  time_since_restore: 5327.255173921585
  time_this_iter_s: 13.398113489151001
  time_total_s: 5327.255173921585
  timestamp: 1594142959
  timesteps_since_restore: 1945000
  timesteps_this_iter: 5000
  timesteps_total: 1945000
  training_iteration: 389
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 34.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=12141], 5327 s, 389 iter, 1945000 ts, 1.58e+03 rew

agent-1: 344.0
agent-2: 354.0
agent-3: 310.0
agent-4: 289.0
agent-5: 337.0
Sum Reward: 1634.0
Avg Reward: 326.8
Min Reward: 289.0
Max Reward: 354.0
Gini Coefficient: 0.0401468788249694
20:20 Ratio: 1.2249134948096885
Max-min Ratio: 1.2249134948096885
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_13-29-32
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1833.0
  episode_reward_mean: 1578.83
  episode_reward_min: 571.0
  episodes_this_iter: 1
  episodes_total: 389
  experiment_id: ebedc1946062457bb682d57fae83bd74
  hostname: gpu052
  info:
    apply_time_ms: 2.874
    dispatch_time_ms: 5.902
    learner:
      cur_lr: 0.0012304630363360047
      grad_gnorm: 40.0
      policy_entropy: 14.239038467407227
      policy_loss: 12.364276885986328
      var_gnorm: 42.01971435546875
      vf_explained_var: 0.05720013380050659
      vf_loss: 32.12128448486328
    num_steps_sampled: 1950000
    num_steps_trained: 1950000
    wait_time_ms: 126.029
  iterations_since_restore: 390
  node_ip: 172.17.8.52
  num_metric_batches_dropped: 0
  pid: 12141
  policy_reward_mean: {}
  time_since_restore: 5340.137796163559
  time_this_iter_s: 12.882622241973877
  time_total_s: 5340.137796163559
  timestamp: 1594142972
  timesteps_since_restore: 1950000
  timesteps_this_iter: 5000
  timesteps_total: 1950000
  training_iteration: 390
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 34.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=12141], 5340 s, 390 iter, 1950000 ts, 1.58e+03 rew

agent-1: 367.0
agent-2: 342.0
agent-3: 386.0
agent-4: 343.0
agent-5: 396.0
Sum Reward: 1834.0
Avg Reward: 366.8
Min Reward: 342.0
Max Reward: 396.0
Gini Coefficient: 0.032933478735005454
20:20 Ratio: 1.1578947368421053
Max-min Ratio: 1.1578947368421053
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_13-29-46
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1834.0
  episode_reward_mean: 1579.8
  episode_reward_min: 571.0
  episodes_this_iter: 1
  episodes_total: 390
  experiment_id: ebedc1946062457bb682d57fae83bd74
  hostname: gpu052
  info:
    apply_time_ms: 3.64
    dispatch_time_ms: 7.668
    learner:
      cur_lr: 0.0012301299721002579
      grad_gnorm: 23.5841121673584
      policy_entropy: 6.770905494689941
      policy_loss: -7.66825008392334
      var_gnorm: 42.07151412963867
      vf_explained_var: -0.06977081298828125
      vf_loss: 32.749149322509766
    num_steps_sampled: 1955000
    num_steps_trained: 1955000
    wait_time_ms: 115.178
  iterations_since_restore: 391
  node_ip: 172.17.8.52
  num_metric_batches_dropped: 0
  pid: 12141
  policy_reward_mean: {}
  time_since_restore: 5353.626836776733
  time_this_iter_s: 13.489040613174438
  time_total_s: 5353.626836776733
  timestamp: 1594142986
  timesteps_since_restore: 1955000
  timesteps_this_iter: 5000
  timesteps_total: 1955000
  training_iteration: 391
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 33.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=12141], 5353 s, 391 iter, 1955000 ts, 1.58e+03 rew

agent-1: 348.0
agent-2: 328.0
agent-3: 321.0
agent-4: 327.0
agent-5: 337.0
Sum Reward: 1661.0
Avg Reward: 332.2
Min Reward: 321.0
Max Reward: 348.0
Gini Coefficient: 0.015412402167369055
20:20 Ratio: 1.0841121495327102
Max-min Ratio: 1.0841121495327102
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_13-29-59
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1834.0
  episode_reward_mean: 1579.07
  episode_reward_min: 571.0
  episodes_this_iter: 1
  episodes_total: 391
  experiment_id: ebedc1946062457bb682d57fae83bd74
  hostname: gpu052
  info:
    apply_time_ms: 3.175
    dispatch_time_ms: 10.193
    learner:
      cur_lr: 0.0012297970242798328
      grad_gnorm: 40.0
      policy_entropy: 13.161857604980469
      policy_loss: 4.678377151489258
      var_gnorm: 42.10540008544922
      vf_explained_var: 0.3400144577026367
      vf_loss: 24.66550064086914
    num_steps_sampled: 1960000
    num_steps_trained: 1960000
    wait_time_ms: 117.799
  iterations_since_restore: 392
  node_ip: 172.17.8.52
  num_metric_batches_dropped: 0
  pid: 12141
  policy_reward_mean: {}
  time_since_restore: 5366.5818428993225
  time_this_iter_s: 12.955006122589111
  time_total_s: 5366.5818428993225
  timestamp: 1594142999
  timesteps_since_restore: 1960000
  timesteps_this_iter: 5000
  timesteps_total: 1960000
  training_iteration: 392
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 34.3/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=12141], 5366 s, 392 iter, 1960000 ts, 1.58e+03 rew

agent-1: 321.0
agent-2: 386.0
agent-3: 375.0
agent-4: 392.0
agent-5: 373.0
Sum Reward: 1847.0
Avg Reward: 369.4
Min Reward: 321.0
Max Reward: 392.0
Gini Coefficient: 0.033567948023822416
20:20 Ratio: 1.2211838006230529
Max-min Ratio: 1.2211838006230529
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_13-30-12
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1847.0
  episode_reward_mean: 1582.06
  episode_reward_min: 571.0
  episodes_this_iter: 1
  episodes_total: 392
  experiment_id: ebedc1946062457bb682d57fae83bd74
  hostname: gpu052
  info:
    apply_time_ms: 3.113
    dispatch_time_ms: 8.029
    learner:
      cur_lr: 0.001229463960044086
      grad_gnorm: 40.0
      policy_entropy: 17.401718139648438
      policy_loss: 10.423985481262207
      var_gnorm: 42.107791900634766
      vf_explained_var: 0.6301633715629578
      vf_loss: 62.87968444824219
    num_steps_sampled: 1965000
    num_steps_trained: 1965000
    wait_time_ms: 122.127
  iterations_since_restore: 393
  node_ip: 172.17.8.52
  num_metric_batches_dropped: 0
  pid: 12141
  policy_reward_mean: {}
  time_since_restore: 5380.090490579605
  time_this_iter_s: 13.508647680282593
  time_total_s: 5380.090490579605
  timestamp: 1594143012
  timesteps_since_restore: 1965000
  timesteps_this_iter: 5000
  timesteps_total: 1965000
  training_iteration: 393
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 34.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=12141], 5380 s, 393 iter, 1965000 ts, 1.58e+03 rew

agent-1: 393.0
agent-2: 408.0
agent-3: 340.0
agent-4: 343.0
agent-5: 355.0
Sum Reward: 1839.0
Avg Reward: 367.8
Min Reward: 340.0
Max Reward: 408.0
Gini Coefficient: 0.04045676998368679
20:20 Ratio: 1.2
Max-min Ratio: 1.2
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_13-30-26
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1847.0
  episode_reward_mean: 1584.67
  episode_reward_min: 571.0
  episodes_this_iter: 1
  episodes_total: 393
  experiment_id: ebedc1946062457bb682d57fae83bd74
  hostname: gpu052
  info:
    apply_time_ms: 2.594
    dispatch_time_ms: 6.956
    learner:
      cur_lr: 0.001229131012223661
      grad_gnorm: 40.0
      policy_entropy: 14.428032875061035
      policy_loss: -0.4194861054420471
      var_gnorm: 42.1699333190918
      vf_explained_var: 0.5181326866149902
      vf_loss: 21.312768936157227
    num_steps_sampled: 1970000
    num_steps_trained: 1970000
    wait_time_ms: 128.269
  iterations_since_restore: 394
  node_ip: 172.17.8.52
  num_metric_batches_dropped: 0
  pid: 12141
  policy_reward_mean: {}
  time_since_restore: 5393.536148309708
  time_this_iter_s: 13.445657730102539
  time_total_s: 5393.536148309708
  timestamp: 1594143026
  timesteps_since_restore: 1970000
  timesteps_this_iter: 5000
  timesteps_total: 1970000
  training_iteration: 394
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 34.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=12141], 5393 s, 394 iter, 1970000 ts, 1.58e+03 rew

agent-1: 353.0
agent-2: 350.0
agent-3: 352.0
agent-4: 344.0
agent-5: 361.0
Sum Reward: 1760.0
Avg Reward: 352.0
Min Reward: 344.0
Max Reward: 361.0
Gini Coefficient: 0.00840909090909091
20:20 Ratio: 1.0494186046511629
Max-min Ratio: 1.0494186046511629
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_13-30-39
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1847.0
  episode_reward_mean: 1586.49
  episode_reward_min: 571.0
  episodes_this_iter: 1
  episodes_total: 394
  experiment_id: ebedc1946062457bb682d57fae83bd74
  hostname: gpu052
  info:
    apply_time_ms: 2.772
    dispatch_time_ms: 5.851
    learner:
      cur_lr: 0.001228797947987914
      grad_gnorm: 40.0
      policy_entropy: 11.222442626953125
      policy_loss: -17.516204833984375
      var_gnorm: 42.208518981933594
      vf_explained_var: -0.4966663122177124
      vf_loss: 39.97792053222656
    num_steps_sampled: 1975000
    num_steps_trained: 1975000
    wait_time_ms: 115.821
  iterations_since_restore: 395
  node_ip: 172.17.8.52
  num_metric_batches_dropped: 0
  pid: 12141
  policy_reward_mean: {}
  time_since_restore: 5407.222728729248
  time_this_iter_s: 13.686580419540405
  time_total_s: 5407.222728729248
  timestamp: 1594143039
  timesteps_since_restore: 1975000
  timesteps_this_iter: 5000
  timesteps_total: 1975000
  training_iteration: 395
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 34.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=12141], 5407 s, 395 iter, 1975000 ts, 1.59e+03 rew

agent-1: 316.0
agent-2: 351.0
agent-3: 364.0
agent-4: 384.0
agent-5: 360.0
Sum Reward: 1775.0
Avg Reward: 355.0
Min Reward: 316.0
Max Reward: 384.0
Gini Coefficient: 0.03357746478873239
20:20 Ratio: 1.2151898734177216
Max-min Ratio: 1.2151898734177216
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_13-30-53
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1847.0
  episode_reward_mean: 1590.04
  episode_reward_min: 571.0
  episodes_this_iter: 1
  episodes_total: 395
  experiment_id: ebedc1946062457bb682d57fae83bd74
  hostname: gpu052
  info:
    apply_time_ms: 3.38
    dispatch_time_ms: 5.936
    learner:
      cur_lr: 0.001228465000167489
      grad_gnorm: 40.0
      policy_entropy: 16.510759353637695
      policy_loss: 9.201189994812012
      var_gnorm: 42.2899284362793
      vf_explained_var: 0.2533475160598755
      vf_loss: 20.971782684326172
    num_steps_sampled: 1980000
    num_steps_trained: 1980000
    wait_time_ms: 119.072
  iterations_since_restore: 396
  node_ip: 172.17.8.52
  num_metric_batches_dropped: 0
  pid: 12141
  policy_reward_mean: {}
  time_since_restore: 5420.42095541954
  time_this_iter_s: 13.198226690292358
  time_total_s: 5420.42095541954
  timestamp: 1594143053
  timesteps_since_restore: 1980000
  timesteps_this_iter: 5000
  timesteps_total: 1980000
  training_iteration: 396
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 34.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=12141], 5420 s, 396 iter, 1980000 ts, 1.59e+03 rew

agent-1: 344.0
agent-2: 303.0
agent-3: 340.0
agent-4: 393.0
agent-5: 322.0
Sum Reward: 1702.0
Avg Reward: 340.4
Min Reward: 303.0
Max Reward: 393.0
Gini Coefficient: 0.04747356051703878
20:20 Ratio: 1.297029702970297
Max-min Ratio: 1.297029702970297
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_13-31-07
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1847.0
  episode_reward_mean: 1593.83
  episode_reward_min: 571.0
  episodes_this_iter: 1
  episodes_total: 396
  experiment_id: ebedc1946062457bb682d57fae83bd74
  hostname: gpu052
  info:
    apply_time_ms: 3.105
    dispatch_time_ms: 21.941
    learner:
      cur_lr: 0.001228132052347064
      grad_gnorm: 40.0
      policy_entropy: 14.225894927978516
      policy_loss: -2.4438459873199463
      var_gnorm: 42.32826232910156
      vf_explained_var: 0.2260444164276123
      vf_loss: 56.229042053222656
    num_steps_sampled: 1985000
    num_steps_trained: 1985000
    wait_time_ms: 106.946
  iterations_since_restore: 397
  node_ip: 172.17.8.52
  num_metric_batches_dropped: 0
  pid: 12141
  policy_reward_mean: {}
  time_since_restore: 5434.464011669159
  time_this_iter_s: 14.04305624961853
  time_total_s: 5434.464011669159
  timestamp: 1594143067
  timesteps_since_restore: 1985000
  timesteps_this_iter: 5000
  timesteps_total: 1985000
  training_iteration: 397
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 34.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=12141], 5434 s, 397 iter, 1985000 ts, 1.59e+03 rew

agent-1: 338.0
agent-2: 315.0
agent-3: 345.0
agent-4: 323.0
agent-5: 341.0
Sum Reward: 1662.0
Avg Reward: 332.4
Min Reward: 315.0
Max Reward: 345.0
Gini Coefficient: 0.018772563176895306
20:20 Ratio: 1.0952380952380953
Max-min Ratio: 1.0952380952380953
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_13-31-21
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1847.0
  episode_reward_mean: 1595.74
  episode_reward_min: 571.0
  episodes_this_iter: 1
  episodes_total: 397
  experiment_id: ebedc1946062457bb682d57fae83bd74
  hostname: gpu052
  info:
    apply_time_ms: 2.561
    dispatch_time_ms: 6.053
    learner:
      cur_lr: 0.0012277989881113172
      grad_gnorm: 39.99999237060547
      policy_entropy: 8.32142162322998
      policy_loss: -14.705218315124512
      var_gnorm: 42.36345291137695
      vf_explained_var: 0.5180429816246033
      vf_loss: 18.27113151550293
    num_steps_sampled: 1990000
    num_steps_trained: 1990000
    wait_time_ms: 136.263
  iterations_since_restore: 398
  node_ip: 172.17.8.52
  num_metric_batches_dropped: 0
  pid: 12141
  policy_reward_mean: {}
  time_since_restore: 5448.326522111893
  time_this_iter_s: 13.862510442733765
  time_total_s: 5448.326522111893
  timestamp: 1594143081
  timesteps_since_restore: 1990000
  timesteps_this_iter: 5000
  timesteps_total: 1990000
  training_iteration: 398
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 34.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=12141], 5448 s, 398 iter, 1990000 ts, 1.6e+03 rew

agent-1: 350.0
agent-2: 332.0
agent-3: 351.0
agent-4: 378.0
agent-5: 352.0
Sum Reward: 1763.0
Avg Reward: 352.6
Min Reward: 332.0
Max Reward: 378.0
Gini Coefficient: 0.021327283040272264
20:20 Ratio: 1.1385542168674698
Max-min Ratio: 1.1385542168674698
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_13-31-34
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1847.0
  episode_reward_mean: 1598.85
  episode_reward_min: 571.0
  episodes_this_iter: 1
  episodes_total: 398
  experiment_id: ebedc1946062457bb682d57fae83bd74
  hostname: gpu052
  info:
    apply_time_ms: 3.143
    dispatch_time_ms: 6.518
    learner:
      cur_lr: 0.0012274660402908921
      grad_gnorm: 39.99999237060547
      policy_entropy: 10.956216812133789
      policy_loss: 5.087681293487549
      var_gnorm: 42.38026809692383
      vf_explained_var: 0.8632935881614685
      vf_loss: 18.435958862304688
    num_steps_sampled: 1995000
    num_steps_trained: 1995000
    wait_time_ms: 114.481
  iterations_since_restore: 399
  node_ip: 172.17.8.52
  num_metric_batches_dropped: 0
  pid: 12141
  policy_reward_mean: {}
  time_since_restore: 5462.064806222916
  time_this_iter_s: 13.73828411102295
  time_total_s: 5462.064806222916
  timestamp: 1594143094
  timesteps_since_restore: 1995000
  timesteps_this_iter: 5000
  timesteps_total: 1995000
  training_iteration: 399
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 34.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=12141], 5462 s, 399 iter, 1995000 ts, 1.6e+03 rew

agent-1: 314.0
agent-2: 356.0
agent-3: 223.0
agent-4: 349.0
agent-5: 324.0
Sum Reward: 1566.0
Avg Reward: 313.2
Min Reward: 223.0
Max Reward: 356.0
Gini Coefficient: 0.0768837803320562
20:20 Ratio: 1.5964125560538116
Max-min Ratio: 1.5964125560538116
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_13-31-48
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1847.0
  episode_reward_mean: 1598.41
  episode_reward_min: 571.0
  episodes_this_iter: 1
  episodes_total: 399
  experiment_id: ebedc1946062457bb682d57fae83bd74
  hostname: gpu052
  info:
    apply_time_ms: 2.457
    dispatch_time_ms: 5.877
    learner:
      cur_lr: 0.0012271329760551453
      grad_gnorm: 40.0
      policy_entropy: 11.898017883300781
      policy_loss: -15.200968742370605
      var_gnorm: 42.423641204833984
      vf_explained_var: 0.7899082899093628
      vf_loss: 63.24052429199219
    num_steps_sampled: 2000000
    num_steps_trained: 2000000
    wait_time_ms: 135.377
  iterations_since_restore: 400
  node_ip: 172.17.8.52
  num_metric_batches_dropped: 0
  pid: 12141
  policy_reward_mean: {}
  time_since_restore: 5475.409567117691
  time_this_iter_s: 13.34476089477539
  time_total_s: 5475.409567117691
  timestamp: 1594143108
  timesteps_since_restore: 2000000
  timesteps_this_iter: 5000
  timesteps_total: 2000000
  training_iteration: 400
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 34.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=12141], 5475 s, 400 iter, 2000000 ts, 1.6e+03 rew

agent-1: 336.0
agent-2: 352.0
agent-3: 348.0
agent-4: 414.0
agent-5: 353.0
Sum Reward: 1803.0
Avg Reward: 360.6
Min Reward: 336.0
Max Reward: 414.0
Gini Coefficient: 0.03571824736550194
20:20 Ratio: 1.2321428571428572
Max-min Ratio: 1.2321428571428572
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_13-32-02
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1847.0
  episode_reward_mean: 1601.11
  episode_reward_min: 571.0
  episodes_this_iter: 1
  episodes_total: 400
  experiment_id: ebedc1946062457bb682d57fae83bd74
  hostname: gpu052
  info:
    apply_time_ms: 2.51
    dispatch_time_ms: 5.577
    learner:
      cur_lr: 0.0012268000282347202
      grad_gnorm: 40.0
      policy_entropy: 9.980555534362793
      policy_loss: -1.0232187509536743
      var_gnorm: 42.43415451049805
      vf_explained_var: 0.40920138359069824
      vf_loss: 70.32662200927734
    num_steps_sampled: 2005000
    num_steps_trained: 2005000
    wait_time_ms: 138.199
  iterations_since_restore: 401
  node_ip: 172.17.8.52
  num_metric_batches_dropped: 0
  pid: 12141
  policy_reward_mean: {}
  time_since_restore: 5489.384961843491
  time_this_iter_s: 13.97539472579956
  time_total_s: 5489.384961843491
  timestamp: 1594143122
  timesteps_since_restore: 2005000
  timesteps_this_iter: 5000
  timesteps_total: 2005000
  training_iteration: 401
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 34.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=12141], 5489 s, 401 iter, 2005000 ts, 1.6e+03 rew

agent-1: 347.0
agent-2: 368.0
agent-3: 298.0
agent-4: 351.0
agent-5: 372.0
Sum Reward: 1736.0
Avg Reward: 347.2
Min Reward: 298.0
Max Reward: 372.0
Gini Coefficient: 0.03894009216589862
20:20 Ratio: 1.2483221476510067
Max-min Ratio: 1.2483221476510067
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_13-32-16
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1847.0
  episode_reward_mean: 1603.24
  episode_reward_min: 571.0
  episodes_this_iter: 1
  episodes_total: 401
  experiment_id: ebedc1946062457bb682d57fae83bd74
  hostname: gpu052
  info:
    apply_time_ms: 3.708
    dispatch_time_ms: 7.166
    learner:
      cur_lr: 0.0012264669639989734
      grad_gnorm: 39.999996185302734
      policy_entropy: 19.739097595214844
      policy_loss: -1.9948025941848755
      var_gnorm: 42.48325729370117
      vf_explained_var: 0.8966808319091797
      vf_loss: 54.99795150756836
    num_steps_sampled: 2010000
    num_steps_trained: 2010000
    wait_time_ms: 127.63
  iterations_since_restore: 402
  node_ip: 172.17.8.52
  num_metric_batches_dropped: 0
  pid: 12141
  policy_reward_mean: {}
  time_since_restore: 5502.956923484802
  time_this_iter_s: 13.571961641311646
  time_total_s: 5502.956923484802
  timestamp: 1594143136
  timesteps_since_restore: 2010000
  timesteps_this_iter: 5000
  timesteps_total: 2010000
  training_iteration: 402
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 34.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=12141], 5502 s, 402 iter, 2010000 ts, 1.6e+03 rew

agent-1: 286.0
agent-2: 317.0
agent-3: 291.0
agent-4: 325.0
agent-5: 312.0
Sum Reward: 1531.0
Avg Reward: 306.2
Min Reward: 286.0
Max Reward: 325.0
Gini Coefficient: 0.027171783148269107
20:20 Ratio: 1.1363636363636365
Max-min Ratio: 1.1363636363636365
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_13-32-29
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1847.0
  episode_reward_mean: 1602.29
  episode_reward_min: 571.0
  episodes_this_iter: 1
  episodes_total: 402
  experiment_id: ebedc1946062457bb682d57fae83bd74
  hostname: gpu052
  info:
    apply_time_ms: 3.322
    dispatch_time_ms: 7.366
    learner:
      cur_lr: 0.0012261340161785483
      grad_gnorm: 40.0
      policy_entropy: 30.87178611755371
      policy_loss: 22.65597915649414
      var_gnorm: 42.556793212890625
      vf_explained_var: 0.2836565375328064
      vf_loss: 75.57623291015625
    num_steps_sampled: 2015000
    num_steps_trained: 2015000
    wait_time_ms: 122.655
  iterations_since_restore: 403
  node_ip: 172.17.8.52
  num_metric_batches_dropped: 0
  pid: 12141
  policy_reward_mean: {}
  time_since_restore: 5516.9202671051025
  time_this_iter_s: 13.963343620300293
  time_total_s: 5516.9202671051025
  timestamp: 1594143149
  timesteps_since_restore: 2015000
  timesteps_this_iter: 5000
  timesteps_total: 2015000
  training_iteration: 403
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 34.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=12141], 5516 s, 403 iter, 2015000 ts, 1.6e+03 rew

agent-1: 322.0
agent-2: 318.0
agent-3: 227.0
agent-4: 347.0
agent-5: 321.0
Sum Reward: 1535.0
Avg Reward: 307.0
Min Reward: 227.0
Max Reward: 347.0
Gini Coefficient: 0.06358306188925081
20:20 Ratio: 1.52863436123348
Max-min Ratio: 1.52863436123348
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_13-32-43
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1847.0
  episode_reward_mean: 1602.57
  episode_reward_min: 571.0
  episodes_this_iter: 1
  episodes_total: 403
  experiment_id: ebedc1946062457bb682d57fae83bd74
  hostname: gpu052
  info:
    apply_time_ms: 2.986
    dispatch_time_ms: 5.557
    learner:
      cur_lr: 0.0012258009519428015
      grad_gnorm: 40.0
      policy_entropy: 13.245580673217773
      policy_loss: -13.062406539916992
      var_gnorm: 42.5762939453125
      vf_explained_var: 0.5922685265541077
      vf_loss: 44.21820068359375
    num_steps_sampled: 2020000
    num_steps_trained: 2020000
    wait_time_ms: 140.141
  iterations_since_restore: 404
  node_ip: 172.17.8.52
  num_metric_batches_dropped: 0
  pid: 12141
  policy_reward_mean: {}
  time_since_restore: 5530.649725675583
  time_this_iter_s: 13.729458570480347
  time_total_s: 5530.649725675583
  timestamp: 1594143163
  timesteps_since_restore: 2020000
  timesteps_this_iter: 5000
  timesteps_total: 2020000
  training_iteration: 404
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 34.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=12141], 5530 s, 404 iter, 2020000 ts, 1.6e+03 rew

agent-1: 333.0
agent-2: 309.0
agent-3: 265.0
agent-4: 279.0
agent-5: 240.0
Sum Reward: 1426.0
Avg Reward: 285.2
Min Reward: 240.0
Max Reward: 333.0
Gini Coefficient: 0.06451612903225806
20:20 Ratio: 1.3875
Max-min Ratio: 1.3875
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_13-32-58
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1847.0
  episode_reward_mean: 1601.69
  episode_reward_min: 571.0
  episodes_this_iter: 1
  episodes_total: 404
  experiment_id: ebedc1946062457bb682d57fae83bd74
  hostname: gpu052
  info:
    apply_time_ms: 3.12
    dispatch_time_ms: 5.872
    learner:
      cur_lr: 0.0012254680041223764
      grad_gnorm: 40.0
      policy_entropy: 14.907184600830078
      policy_loss: -8.477311134338379
      var_gnorm: 42.66081237792969
      vf_explained_var: 0.8635832071304321
      vf_loss: 50.71827697753906
    num_steps_sampled: 2025000
    num_steps_trained: 2025000
    wait_time_ms: 120.884
  iterations_since_restore: 405
  node_ip: 172.17.8.52
  num_metric_batches_dropped: 0
  pid: 12141
  policy_reward_mean: {}
  time_since_restore: 5545.831505537033
  time_this_iter_s: 15.181779861450195
  time_total_s: 5545.831505537033
  timestamp: 1594143178
  timesteps_since_restore: 2025000
  timesteps_this_iter: 5000
  timesteps_total: 2025000
  training_iteration: 405
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 34.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=12141], 5545 s, 405 iter, 2025000 ts, 1.6e+03 rew

agent-1: 298.0
agent-2: 274.0
agent-3: 312.0
agent-4: 308.0
agent-5: 317.0
Sum Reward: 1509.0
Avg Reward: 301.8
Min Reward: 274.0
Max Reward: 317.0
Gini Coefficient: 0.026507620941020542
20:20 Ratio: 1.1569343065693432
Max-min Ratio: 1.1569343065693432
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_13-33-12
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1847.0
  episode_reward_mean: 1600.9
  episode_reward_min: 571.0
  episodes_this_iter: 1
  episodes_total: 405
  experiment_id: ebedc1946062457bb682d57fae83bd74
  hostname: gpu052
  info:
    apply_time_ms: 3.437
    dispatch_time_ms: 10.335
    learner:
      cur_lr: 0.0012251350563019514
      grad_gnorm: 37.634437561035156
      policy_entropy: 18.631025314331055
      policy_loss: -0.5075575709342957
      var_gnorm: 42.82139205932617
      vf_explained_var: 0.8122580647468567
      vf_loss: 23.83060073852539
    num_steps_sampled: 2030000
    num_steps_trained: 2030000
    wait_time_ms: 121.724
  iterations_since_restore: 406
  node_ip: 172.17.8.52
  num_metric_batches_dropped: 0
  pid: 12141
  policy_reward_mean: {}
  time_since_restore: 5558.994817733765
  time_this_iter_s: 13.163312196731567
  time_total_s: 5558.994817733765
  timestamp: 1594143192
  timesteps_since_restore: 2030000
  timesteps_this_iter: 5000
  timesteps_total: 2030000
  training_iteration: 406
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 34.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=12141], 5558 s, 406 iter, 2030000 ts, 1.6e+03 rew

agent-1: 349.0
agent-2: 326.0
agent-3: 276.0
agent-4: 353.0
agent-5: 261.0
Sum Reward: 1565.0
Avg Reward: 313.0
Min Reward: 261.0
Max Reward: 353.0
Gini Coefficient: 0.06568690095846645
20:20 Ratio: 1.3524904214559388
Max-min Ratio: 1.3524904214559388
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_13-33-25
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1847.0
  episode_reward_mean: 1599.57
  episode_reward_min: 571.0
  episodes_this_iter: 1
  episodes_total: 406
  experiment_id: ebedc1946062457bb682d57fae83bd74
  hostname: gpu052
  info:
    apply_time_ms: 3.131
    dispatch_time_ms: 6.117
    learner:
      cur_lr: 0.0012248019920662045
      grad_gnorm: 40.0
      policy_entropy: 17.4686222076416
      policy_loss: 9.498257637023926
      var_gnorm: 42.860557556152344
      vf_explained_var: 0.7183053493499756
      vf_loss: 56.231319427490234
    num_steps_sampled: 2035000
    num_steps_trained: 2035000
    wait_time_ms: 113.055
  iterations_since_restore: 407
  node_ip: 172.17.8.52
  num_metric_batches_dropped: 0
  pid: 12141
  policy_reward_mean: {}
  time_since_restore: 5572.521171808243
  time_this_iter_s: 13.52635407447815
  time_total_s: 5572.521171808243
  timestamp: 1594143205
  timesteps_since_restore: 2035000
  timesteps_this_iter: 5000
  timesteps_total: 2035000
  training_iteration: 407
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 34.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=12141], 5572 s, 407 iter, 2035000 ts, 1.6e+03 rew

agent-1: 251.0
agent-2: 331.0
agent-3: 274.0
agent-4: 327.0
agent-5: 261.0
Sum Reward: 1444.0
Avg Reward: 288.8
Min Reward: 251.0
Max Reward: 331.0
Gini Coefficient: 0.06260387811634349
20:20 Ratio: 1.3187250996015936
Max-min Ratio: 1.3187250996015936
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_13-33-39
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1847.0
  episode_reward_mean: 1596.29
  episode_reward_min: 571.0
  episodes_this_iter: 1
  episodes_total: 407
  experiment_id: ebedc1946062457bb682d57fae83bd74
  hostname: gpu052
  info:
    apply_time_ms: 2.802
    dispatch_time_ms: 7.07
    learner:
      cur_lr: 0.0012244690442457795
      grad_gnorm: 40.000003814697266
      policy_entropy: 19.078031539916992
      policy_loss: -29.310285568237305
      var_gnorm: 42.8912467956543
      vf_explained_var: 0.09628468751907349
      vf_loss: 183.7687530517578
    num_steps_sampled: 2040000
    num_steps_trained: 2040000
    wait_time_ms: 130.655
  iterations_since_restore: 408
  node_ip: 172.17.8.52
  num_metric_batches_dropped: 0
  pid: 12141
  policy_reward_mean: {}
  time_since_restore: 5585.802855968475
  time_this_iter_s: 13.281684160232544
  time_total_s: 5585.802855968475
  timestamp: 1594143219
  timesteps_since_restore: 2040000
  timesteps_this_iter: 5000
  timesteps_total: 2040000
  training_iteration: 408
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 34.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=12141], 5585 s, 408 iter, 2040000 ts, 1.6e+03 rew

agent-1: 299.0
agent-2: 377.0
agent-3: 343.0
agent-4: 357.0
agent-5: 352.0
Sum Reward: 1728.0
Avg Reward: 345.6
Min Reward: 299.0
Max Reward: 377.0
Gini Coefficient: 0.03935185185185185
20:20 Ratio: 1.2608695652173914
Max-min Ratio: 1.2608695652173914
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_13-33-52
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1847.0
  episode_reward_mean: 1597.65
  episode_reward_min: 571.0
  episodes_this_iter: 1
  episodes_total: 408
  experiment_id: ebedc1946062457bb682d57fae83bd74
  hostname: gpu052
  info:
    apply_time_ms: 3.22
    dispatch_time_ms: 6.601
    learner:
      cur_lr: 0.0012241359800100327
      grad_gnorm: 40.000003814697266
      policy_entropy: 21.350847244262695
      policy_loss: -15.152385711669922
      var_gnorm: 42.890071868896484
      vf_explained_var: 0.2448546290397644
      vf_loss: 43.948490142822266
    num_steps_sampled: 2045000
    num_steps_trained: 2045000
    wait_time_ms: 125.92
  iterations_since_restore: 409
  node_ip: 172.17.8.52
  num_metric_batches_dropped: 0
  pid: 12141
  policy_reward_mean: {}
  time_since_restore: 5599.608765363693
  time_this_iter_s: 13.805909395217896
  time_total_s: 5599.608765363693
  timestamp: 1594143232
  timesteps_since_restore: 2045000
  timesteps_this_iter: 5000
  timesteps_total: 2045000
  training_iteration: 409
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 34.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=12141], 5599 s, 409 iter, 2045000 ts, 1.6e+03 rew

agent-1: 313.0
agent-2: 322.0
agent-3: 299.0
agent-4: 306.0
agent-5: 353.0
Sum Reward: 1593.0
Avg Reward: 318.6
Min Reward: 299.0
Max Reward: 353.0
Gini Coefficient: 0.031136220966729442
20:20 Ratio: 1.1806020066889633
Max-min Ratio: 1.1806020066889633
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_13-34-05
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1847.0
  episode_reward_mean: 1597.75
  episode_reward_min: 571.0
  episodes_this_iter: 1
  episodes_total: 409
  experiment_id: ebedc1946062457bb682d57fae83bd74
  hostname: gpu052
  info:
    apply_time_ms: 2.831
    dispatch_time_ms: 5.991
    learner:
      cur_lr: 0.0012238030321896076
      grad_gnorm: 40.0
      policy_entropy: 27.39630699157715
      policy_loss: -9.229283332824707
      var_gnorm: 42.85269546508789
      vf_explained_var: -0.008220672607421875
      vf_loss: 52.79996109008789
    num_steps_sampled: 2050000
    num_steps_trained: 2050000
    wait_time_ms: 118.777
  iterations_since_restore: 410
  node_ip: 172.17.8.52
  num_metric_batches_dropped: 0
  pid: 12141
  policy_reward_mean: {}
  time_since_restore: 5612.299497127533
  time_this_iter_s: 12.690731763839722
  time_total_s: 5612.299497127533
  timestamp: 1594143245
  timesteps_since_restore: 2050000
  timesteps_this_iter: 5000
  timesteps_total: 2050000
  training_iteration: 410
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 35.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=12141], 5612 s, 410 iter, 2050000 ts, 1.6e+03 rew

agent-1: 291.0
agent-2: 324.0
agent-3: 298.0
agent-4: 315.0
agent-5: 312.0
Sum Reward: 1540.0
Avg Reward: 308.0
Min Reward: 291.0
Max Reward: 324.0
Gini Coefficient: 0.021558441558441558
20:20 Ratio: 1.1134020618556701
Max-min Ratio: 1.1134020618556701
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_13-34-18
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1847.0
  episode_reward_mean: 1596.06
  episode_reward_min: 571.0
  episodes_this_iter: 1
  episodes_total: 410
  experiment_id: ebedc1946062457bb682d57fae83bd74
  hostname: gpu052
  info:
    apply_time_ms: 3.87
    dispatch_time_ms: 10.563
    learner:
      cur_lr: 0.0012234699679538608
      grad_gnorm: 40.0
      policy_entropy: 31.116559982299805
      policy_loss: 1.8614776134490967
      var_gnorm: 42.87596130371094
      vf_explained_var: 0.08732181787490845
      vf_loss: 101.07611083984375
    num_steps_sampled: 2055000
    num_steps_trained: 2055000
    wait_time_ms: 108.748
  iterations_since_restore: 411
  node_ip: 172.17.8.52
  num_metric_batches_dropped: 0
  pid: 12141
  policy_reward_mean: {}
  time_since_restore: 5625.2056040763855
  time_this_iter_s: 12.906106948852539
  time_total_s: 5625.2056040763855
  timestamp: 1594143258
  timesteps_since_restore: 2055000
  timesteps_this_iter: 5000
  timesteps_total: 2055000
  training_iteration: 411
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 35.3/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=12141], 5625 s, 411 iter, 2055000 ts, 1.6e+03 rew

agent-1: 323.0
agent-2: 331.0
agent-3: 304.0
agent-4: 338.0
agent-5: 357.0
Sum Reward: 1653.0
Avg Reward: 330.6
Min Reward: 304.0
Max Reward: 357.0
Gini Coefficient: 0.02928009679370841
20:20 Ratio: 1.174342105263158
Max-min Ratio: 1.174342105263158
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_13-34-32
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1847.0
  episode_reward_mean: 1594.65
  episode_reward_min: 571.0
  episodes_this_iter: 1
  episodes_total: 411
  experiment_id: ebedc1946062457bb682d57fae83bd74
  hostname: gpu052
  info:
    apply_time_ms: 2.815
    dispatch_time_ms: 6.197
    learner:
      cur_lr: 0.0012231370201334357
      grad_gnorm: 40.0
      policy_entropy: 19.863508224487305
      policy_loss: -16.05617332458496
      var_gnorm: 42.947731018066406
      vf_explained_var: 0.8492697477340698
      vf_loss: 72.12440490722656
    num_steps_sampled: 2060000
    num_steps_trained: 2060000
    wait_time_ms: 123.237
  iterations_since_restore: 412
  node_ip: 172.17.8.52
  num_metric_batches_dropped: 0
  pid: 12141
  policy_reward_mean: {}
  time_since_restore: 5639.600665807724
  time_this_iter_s: 14.395061731338501
  time_total_s: 5639.600665807724
  timestamp: 1594143272
  timesteps_since_restore: 2060000
  timesteps_this_iter: 5000
  timesteps_total: 2060000
  training_iteration: 412
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 35.3/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=12141], 5639 s, 412 iter, 2060000 ts, 1.59e+03 rew

agent-1: 345.0
agent-2: 369.0
agent-3: 327.0
agent-4: 355.0
agent-5: 361.0
Sum Reward: 1757.0
Avg Reward: 351.4
Min Reward: 327.0
Max Reward: 369.0
Gini Coefficient: 0.022766078542970972
20:20 Ratio: 1.128440366972477
Max-min Ratio: 1.128440366972477
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_13-34-46
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1847.0
  episode_reward_mean: 1593.97
  episode_reward_min: 571.0
  episodes_this_iter: 1
  episodes_total: 412
  experiment_id: ebedc1946062457bb682d57fae83bd74
  hostname: gpu052
  info:
    apply_time_ms: 2.685
    dispatch_time_ms: 18.881
    learner:
      cur_lr: 0.0012228039558976889
      grad_gnorm: 40.0
      policy_entropy: 16.76160430908203
      policy_loss: -14.279489517211914
      var_gnorm: 42.960182189941406
      vf_explained_var: 0.4613136649131775
      vf_loss: 95.2174072265625
    num_steps_sampled: 2065000
    num_steps_trained: 2065000
    wait_time_ms: 106.23
  iterations_since_restore: 413
  node_ip: 172.17.8.52
  num_metric_batches_dropped: 0
  pid: 12141
  policy_reward_mean: {}
  time_since_restore: 5653.452941417694
  time_this_iter_s: 13.852275609970093
  time_total_s: 5653.452941417694
  timestamp: 1594143286
  timesteps_since_restore: 2065000
  timesteps_this_iter: 5000
  timesteps_total: 2065000
  training_iteration: 413
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 35.3/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=12141], 5653 s, 413 iter, 2065000 ts, 1.59e+03 rew

agent-1: 365.0
agent-2: 387.0
agent-3: 321.0
agent-4: 354.0
agent-5: 375.0
Sum Reward: 1802.0
Avg Reward: 360.4
Min Reward: 321.0
Max Reward: 387.0
Gini Coefficient: 0.033962264150943396
20:20 Ratio: 1.205607476635514
Max-min Ratio: 1.205607476635514
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_13-35-00
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1847.0
  episode_reward_mean: 1594.22
  episode_reward_min: 571.0
  episodes_this_iter: 1
  episodes_total: 413
  experiment_id: ebedc1946062457bb682d57fae83bd74
  hostname: gpu052
  info:
    apply_time_ms: 2.703
    dispatch_time_ms: 25.061
    learner:
      cur_lr: 0.0012224710080772638
      grad_gnorm: 40.0
      policy_entropy: 23.2989444732666
      policy_loss: -29.870187759399414
      var_gnorm: 43.02752685546875
      vf_explained_var: 0.728135347366333
      vf_loss: 44.761138916015625
    num_steps_sampled: 2070000
    num_steps_trained: 2070000
    wait_time_ms: 123.107
  iterations_since_restore: 414
  node_ip: 172.17.8.52
  num_metric_batches_dropped: 0
  pid: 12141
  policy_reward_mean: {}
  time_since_restore: 5667.155234098434
  time_this_iter_s: 13.702292680740356
  time_total_s: 5667.155234098434
  timestamp: 1594143300
  timesteps_since_restore: 2070000
  timesteps_this_iter: 5000
  timesteps_total: 2070000
  training_iteration: 414
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 35.3/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=12141], 5667 s, 414 iter, 2070000 ts, 1.59e+03 rew

agent-1: 314.0
agent-2: 342.0
agent-3: 309.0
agent-4: 376.0
agent-5: 322.0
Sum Reward: 1663.0
Avg Reward: 332.6
Min Reward: 309.0
Max Reward: 376.0
Gini Coefficient: 0.038965724594107035
20:20 Ratio: 1.2168284789644013
Max-min Ratio: 1.2168284789644013
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_13-35-15
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1847.0
  episode_reward_mean: 1594.2
  episode_reward_min: 571.0
  episodes_this_iter: 1
  episodes_total: 414
  experiment_id: ebedc1946062457bb682d57fae83bd74
  hostname: gpu052
  info:
    apply_time_ms: 2.903
    dispatch_time_ms: 9.983
    learner:
      cur_lr: 0.001222137943841517
      grad_gnorm: 40.0
      policy_entropy: 21.994089126586914
      policy_loss: -28.73595428466797
      var_gnorm: 43.01845932006836
      vf_explained_var: -0.06949079036712646
      vf_loss: 80.6883316040039
    num_steps_sampled: 2075000
    num_steps_trained: 2075000
    wait_time_ms: 125.41
  iterations_since_restore: 415
  node_ip: 172.17.8.52
  num_metric_batches_dropped: 0
  pid: 12141
  policy_reward_mean: {}
  time_since_restore: 5681.671027898788
  time_this_iter_s: 14.515793800354004
  time_total_s: 5681.671027898788
  timestamp: 1594143315
  timesteps_since_restore: 2075000
  timesteps_this_iter: 5000
  timesteps_total: 2075000
  training_iteration: 415
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 35.3/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=12141], 5681 s, 415 iter, 2075000 ts, 1.59e+03 rew

agent-1: 391.0
agent-2: 299.0
agent-3: 395.0
agent-4: 287.0
agent-5: 367.0
Sum Reward: 1739.0
Avg Reward: 347.8
Min Reward: 287.0
Max Reward: 395.0
Gini Coefficient: 0.07084531339850489
20:20 Ratio: 1.3763066202090593
Max-min Ratio: 1.3763066202090593
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_13-35-28
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1847.0
  episode_reward_mean: 1594.38
  episode_reward_min: 571.0
  episodes_this_iter: 1
  episodes_total: 415
  experiment_id: ebedc1946062457bb682d57fae83bd74
  hostname: gpu052
  info:
    apply_time_ms: 2.716
    dispatch_time_ms: 5.486
    learner:
      cur_lr: 0.001221804996021092
      grad_gnorm: 39.999996185302734
      policy_entropy: 11.938658714294434
      policy_loss: 3.36605167388916
      var_gnorm: 43.043548583984375
      vf_explained_var: 0.692546010017395
      vf_loss: 54.072269439697266
    num_steps_sampled: 2080000
    num_steps_trained: 2080000
    wait_time_ms: 123.062
  iterations_since_restore: 416
  node_ip: 172.17.8.52
  num_metric_batches_dropped: 0
  pid: 12141
  policy_reward_mean: {}
  time_since_restore: 5694.552371740341
  time_this_iter_s: 12.881343841552734
  time_total_s: 5694.552371740341
  timestamp: 1594143328
  timesteps_since_restore: 2080000
  timesteps_this_iter: 5000
  timesteps_total: 2080000
  training_iteration: 416
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 35.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=12141], 5694 s, 416 iter, 2080000 ts, 1.59e+03 rew

agent-1: 335.0
agent-2: 369.0
agent-3: 363.0
agent-4: 383.0
agent-5: 372.0
Sum Reward: 1822.0
Avg Reward: 364.4
Min Reward: 335.0
Max Reward: 383.0
Gini Coefficient: 0.02305159165751921
20:20 Ratio: 1.1432835820895522
Max-min Ratio: 1.1432835820895522
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_13-35-41
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1847.0
  episode_reward_mean: 1595.55
  episode_reward_min: 571.0
  episodes_this_iter: 1
  episodes_total: 416
  experiment_id: ebedc1946062457bb682d57fae83bd74
  hostname: gpu052
  info:
    apply_time_ms: 2.629
    dispatch_time_ms: 6.792
    learner:
      cur_lr: 0.001221472048200667
      grad_gnorm: 40.0
      policy_entropy: 18.993270874023438
      policy_loss: -1.4088690280914307
      var_gnorm: 43.083370208740234
      vf_explained_var: 0.42574983835220337
      vf_loss: 34.67731857299805
    num_steps_sampled: 2085000
    num_steps_trained: 2085000
    wait_time_ms: 111.913
  iterations_since_restore: 417
  node_ip: 172.17.8.52
  num_metric_batches_dropped: 0
  pid: 12141
  policy_reward_mean: {}
  time_since_restore: 5708.365957021713
  time_this_iter_s: 13.81358528137207
  time_total_s: 5708.365957021713
  timestamp: 1594143341
  timesteps_since_restore: 2085000
  timesteps_this_iter: 5000
  timesteps_total: 2085000
  training_iteration: 417
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 35.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=12141], 5708 s, 417 iter, 2085000 ts, 1.6e+03 rew

agent-1: 331.0
agent-2: 379.0
agent-3: 320.0
agent-4: 323.0
agent-5: 301.0
Sum Reward: 1654.0
Avg Reward: 330.8
Min Reward: 301.0
Max Reward: 379.0
Gini Coefficient: 0.0403869407496977
20:20 Ratio: 1.2591362126245846
Max-min Ratio: 1.2591362126245846
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_13-35-55
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1847.0
  episode_reward_mean: 1593.81
  episode_reward_min: 571.0
  episodes_this_iter: 1
  episodes_total: 417
  experiment_id: ebedc1946062457bb682d57fae83bd74
  hostname: gpu052
  info:
    apply_time_ms: 2.926
    dispatch_time_ms: 6.108
    learner:
      cur_lr: 0.00122113898396492
      grad_gnorm: 40.000003814697266
      policy_entropy: 9.954092025756836
      policy_loss: -14.036677360534668
      var_gnorm: 43.077056884765625
      vf_explained_var: 0.8127368092536926
      vf_loss: 25.31460952758789
    num_steps_sampled: 2090000
    num_steps_trained: 2090000
    wait_time_ms: 138.711
  iterations_since_restore: 418
  node_ip: 172.17.8.52
  num_metric_batches_dropped: 0
  pid: 12141
  policy_reward_mean: {}
  time_since_restore: 5721.799005508423
  time_this_iter_s: 13.433048486709595
  time_total_s: 5721.799005508423
  timestamp: 1594143355
  timesteps_since_restore: 2090000
  timesteps_this_iter: 5000
  timesteps_total: 2090000
  training_iteration: 418
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 35.3/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=12141], 5721 s, 418 iter, 2090000 ts, 1.59e+03 rew

agent-1: 327.0
agent-2: 354.0
agent-3: 312.0
agent-4: 345.0
agent-5: 330.0
Sum Reward: 1668.0
Avg Reward: 333.6
Min Reward: 312.0
Max Reward: 354.0
Gini Coefficient: 0.02446043165467626
20:20 Ratio: 1.1346153846153846
Max-min Ratio: 1.1346153846153846
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_13-36-09
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1847.0
  episode_reward_mean: 1592.56
  episode_reward_min: 571.0
  episodes_this_iter: 1
  episodes_total: 418
  experiment_id: ebedc1946062457bb682d57fae83bd74
  hostname: gpu052
  info:
    apply_time_ms: 4.123
    dispatch_time_ms: 6.72
    learner:
      cur_lr: 0.001220806036144495
      grad_gnorm: 40.0
      policy_entropy: 5.998049736022949
      policy_loss: 4.410091400146484
      var_gnorm: 43.126564025878906
      vf_explained_var: 0.5461433529853821
      vf_loss: 51.13417053222656
    num_steps_sampled: 2095000
    num_steps_trained: 2095000
    wait_time_ms: 98.154
  iterations_since_restore: 419
  node_ip: 172.17.8.52
  num_metric_batches_dropped: 0
  pid: 12141
  policy_reward_mean: {}
  time_since_restore: 5735.410646438599
  time_this_iter_s: 13.611640930175781
  time_total_s: 5735.410646438599
  timestamp: 1594143369
  timesteps_since_restore: 2095000
  timesteps_this_iter: 5000
  timesteps_total: 2095000
  training_iteration: 419
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 35.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=12141], 5735 s, 419 iter, 2095000 ts, 1.59e+03 rew

agent-1: 243.0
agent-2: 228.0
agent-3: 366.0
agent-4: 361.0
agent-5: 369.0
Sum Reward: 1567.0
Avg Reward: 313.4
Min Reward: 228.0
Max Reward: 369.0
Gini Coefficient: 0.10338225909380983
20:20 Ratio: 1.618421052631579
Max-min Ratio: 1.618421052631579
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_13-36-21
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1847.0
  episode_reward_mean: 1591.1
  episode_reward_min: 571.0
  episodes_this_iter: 1
  episodes_total: 419
  experiment_id: ebedc1946062457bb682d57fae83bd74
  hostname: gpu052
  info:
    apply_time_ms: 3.65
    dispatch_time_ms: 6.195
    learner:
      cur_lr: 0.0012204729719087481
      grad_gnorm: 39.999996185302734
      policy_entropy: 9.894224166870117
      policy_loss: -8.567815780639648
      var_gnorm: 43.227596282958984
      vf_explained_var: 0.871199905872345
      vf_loss: 40.42185592651367
    num_steps_sampled: 2100000
    num_steps_trained: 2100000
    wait_time_ms: 125.319
  iterations_since_restore: 420
  node_ip: 172.17.8.52
  num_metric_batches_dropped: 0
  pid: 12141
  policy_reward_mean: {}
  time_since_restore: 5747.825122117996
  time_this_iter_s: 12.414475679397583
  time_total_s: 5747.825122117996
  timestamp: 1594143381
  timesteps_since_restore: 2100000
  timesteps_this_iter: 5000
  timesteps_total: 2100000
  training_iteration: 420
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 35.3/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=12141], 5747 s, 420 iter, 2100000 ts, 1.59e+03 rew

agent-1: 321.0
agent-2: 318.0
agent-3: 318.0
agent-4: 354.0
agent-5: 358.0
Sum Reward: 1669.0
Avg Reward: 333.8
Min Reward: 318.0
Max Reward: 358.0
Gini Coefficient: 0.027801078490113842
20:20 Ratio: 1.1257861635220126
Max-min Ratio: 1.1257861635220126
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_13-36-34
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1847.0
  episode_reward_mean: 1590.54
  episode_reward_min: 571.0
  episodes_this_iter: 1
  episodes_total: 420
  experiment_id: ebedc1946062457bb682d57fae83bd74
  hostname: gpu052
  info:
    apply_time_ms: 2.82
    dispatch_time_ms: 6.486
    learner:
      cur_lr: 0.0012201400240883231
      grad_gnorm: 40.000003814697266
      policy_entropy: 9.17585563659668
      policy_loss: -12.391051292419434
      var_gnorm: 43.21281433105469
      vf_explained_var: 0.5908606052398682
      vf_loss: 71.63328552246094
    num_steps_sampled: 2105000
    num_steps_trained: 2105000
    wait_time_ms: 111.227
  iterations_since_restore: 421
  node_ip: 172.17.8.52
  num_metric_batches_dropped: 0
  pid: 12141
  policy_reward_mean: {}
  time_since_restore: 5761.117555141449
  time_this_iter_s: 13.292433023452759
  time_total_s: 5761.117555141449
  timestamp: 1594143394
  timesteps_since_restore: 2105000
  timesteps_this_iter: 5000
  timesteps_total: 2105000
  training_iteration: 421
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 35.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=12141], 5761 s, 421 iter, 2105000 ts, 1.59e+03 rew

agent-1: 337.0
agent-2: 334.0
agent-3: 323.0
agent-4: 357.0
agent-5: 359.0
Sum Reward: 1710.0
Avg Reward: 342.0
Min Reward: 323.0
Max Reward: 359.0
Gini Coefficient: 0.022222222222222223
20:20 Ratio: 1.111455108359133
Max-min Ratio: 1.111455108359133
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_13-36-47
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1847.0
  episode_reward_mean: 1590.45
  episode_reward_min: 571.0
  episodes_this_iter: 1
  episodes_total: 421
  experiment_id: ebedc1946062457bb682d57fae83bd74
  hostname: gpu052
  info:
    apply_time_ms: 2.729
    dispatch_time_ms: 9.612
    learner:
      cur_lr: 0.0012198069598525763
      grad_gnorm: 39.999996185302734
      policy_entropy: 5.947762489318848
      policy_loss: 2.8486626148223877
      var_gnorm: 43.228206634521484
      vf_explained_var: 0.3350332975387573
      vf_loss: 60.47993850708008
    num_steps_sampled: 2110000
    num_steps_trained: 2110000
    wait_time_ms: 123.56
  iterations_since_restore: 422
  node_ip: 172.17.8.52
  num_metric_batches_dropped: 0
  pid: 12141
  policy_reward_mean: {}
  time_since_restore: 5773.623394489288
  time_this_iter_s: 12.505839347839355
  time_total_s: 5773.623394489288
  timestamp: 1594143407
  timesteps_since_restore: 2110000
  timesteps_this_iter: 5000
  timesteps_total: 2110000
  training_iteration: 422
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 35.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=12141], 5773 s, 422 iter, 2110000 ts, 1.59e+03 rew

agent-1: 268.0
agent-2: 317.0
agent-3: 336.0
agent-4: 409.0
agent-5: 314.0
Sum Reward: 1644.0
Avg Reward: 328.8
Min Reward: 268.0
Max Reward: 409.0
Gini Coefficient: 0.07396593673965937
20:20 Ratio: 1.5261194029850746
Max-min Ratio: 1.5261194029850746
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_13-37-01
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1847.0
  episode_reward_mean: 1589.21
  episode_reward_min: 571.0
  episodes_this_iter: 1
  episodes_total: 422
  experiment_id: ebedc1946062457bb682d57fae83bd74
  hostname: gpu052
  info:
    apply_time_ms: 2.921
    dispatch_time_ms: 6.427
    learner:
      cur_lr: 0.0012194740120321512
      grad_gnorm: 40.0
      policy_entropy: 16.461986541748047
      policy_loss: -16.794261932373047
      var_gnorm: 43.248268127441406
      vf_explained_var: 0.07296723127365112
      vf_loss: 40.36902618408203
    num_steps_sampled: 2115000
    num_steps_trained: 2115000
    wait_time_ms: 113.527
  iterations_since_restore: 423
  node_ip: 172.17.8.52
  num_metric_batches_dropped: 0
  pid: 12141
  policy_reward_mean: {}
  time_since_restore: 5787.362675905228
  time_this_iter_s: 13.739281415939331
  time_total_s: 5787.362675905228
  timestamp: 1594143421
  timesteps_since_restore: 2115000
  timesteps_this_iter: 5000
  timesteps_total: 2115000
  training_iteration: 423
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 35.3/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=12141], 5787 s, 423 iter, 2115000 ts, 1.59e+03 rew

agent-1: 366.0
agent-2: 305.0
agent-3: 373.0
agent-4: 352.0
agent-5: 292.0
Sum Reward: 1688.0
Avg Reward: 337.6
Min Reward: 292.0
Max Reward: 373.0
Gini Coefficient: 0.052843601895734595
20:20 Ratio: 1.2773972602739727
Max-min Ratio: 1.2773972602739727
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_13-37-14
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1847.0
  episode_reward_mean: 1588.95
  episode_reward_min: 571.0
  episodes_this_iter: 1
  episodes_total: 423
  experiment_id: ebedc1946062457bb682d57fae83bd74
  hostname: gpu052
  info:
    apply_time_ms: 4.408
    dispatch_time_ms: 7.693
    learner:
      cur_lr: 0.0012191409477964044
      grad_gnorm: 39.999996185302734
      policy_entropy: 18.411462783813477
      policy_loss: 0.12420909106731415
      var_gnorm: 43.35955810546875
      vf_explained_var: 0.48528724908828735
      vf_loss: 47.74892044067383
    num_steps_sampled: 2120000
    num_steps_trained: 2120000
    wait_time_ms: 123.165
  iterations_since_restore: 424
  node_ip: 172.17.8.52
  num_metric_batches_dropped: 0
  pid: 12141
  policy_reward_mean: {}
  time_since_restore: 5800.675353765488
  time_this_iter_s: 13.31267786026001
  time_total_s: 5800.675353765488
  timestamp: 1594143434
  timesteps_since_restore: 2120000
  timesteps_this_iter: 5000
  timesteps_total: 2120000
  training_iteration: 424
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 35.3/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=12141], 5800 s, 424 iter, 2120000 ts, 1.59e+03 rew

agent-1: 363.0
agent-2: 350.0
agent-3: 306.0
agent-4: 362.0
agent-5: 359.0
Sum Reward: 1740.0
Avg Reward: 348.0
Min Reward: 306.0
Max Reward: 363.0
Gini Coefficient: 0.028965517241379312
20:20 Ratio: 1.1862745098039216
Max-min Ratio: 1.1862745098039216
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_13-37-28
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1847.0
  episode_reward_mean: 1588.82
  episode_reward_min: 571.0
  episodes_this_iter: 1
  episodes_total: 424
  experiment_id: ebedc1946062457bb682d57fae83bd74
  hostname: gpu052
  info:
    apply_time_ms: 3.622
    dispatch_time_ms: 10.115
    learner:
      cur_lr: 0.0012188079999759793
      grad_gnorm: 40.00000762939453
      policy_entropy: 27.807523727416992
      policy_loss: -8.321070671081543
      var_gnorm: 43.35798263549805
      vf_explained_var: 0.7733932137489319
      vf_loss: 51.29127883911133
    num_steps_sampled: 2125000
    num_steps_trained: 2125000
    wait_time_ms: 129.669
  iterations_since_restore: 425
  node_ip: 172.17.8.52
  num_metric_batches_dropped: 0
  pid: 12141
  policy_reward_mean: {}
  time_since_restore: 5814.476229429245
  time_this_iter_s: 13.800875663757324
  time_total_s: 5814.476229429245
  timestamp: 1594143448
  timesteps_since_restore: 2125000
  timesteps_this_iter: 5000
  timesteps_total: 2125000
  training_iteration: 425
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 35.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=12141], 5814 s, 425 iter, 2125000 ts, 1.59e+03 rew

agent-1: 300.0
agent-2: 311.0
agent-3: 316.0
agent-4: 332.0
agent-5: 298.0
Sum Reward: 1557.0
Avg Reward: 311.4
Min Reward: 298.0
Max Reward: 332.0
Gini Coefficient: 0.02157996146435453
20:20 Ratio: 1.1140939597315436
Max-min Ratio: 1.1140939597315436
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_13-37-41
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1847.0
  episode_reward_mean: 1586.72
  episode_reward_min: 571.0
  episodes_this_iter: 1
  episodes_total: 425
  experiment_id: ebedc1946062457bb682d57fae83bd74
  hostname: gpu052
  info:
    apply_time_ms: 3.234
    dispatch_time_ms: 8.167
    learner:
      cur_lr: 0.0012184750521555543
      grad_gnorm: 40.00000762939453
      policy_entropy: 14.791604042053223
      policy_loss: 7.978346824645996
      var_gnorm: 43.40960693359375
      vf_explained_var: 0.888384997844696
      vf_loss: 28.941783905029297
    num_steps_sampled: 2130000
    num_steps_trained: 2130000
    wait_time_ms: 129.948
  iterations_since_restore: 426
  node_ip: 172.17.8.52
  num_metric_batches_dropped: 0
  pid: 12141
  policy_reward_mean: {}
  time_since_restore: 5827.687537431717
  time_this_iter_s: 13.211308002471924
  time_total_s: 5827.687537431717
  timestamp: 1594143461
  timesteps_since_restore: 2130000
  timesteps_this_iter: 5000
  timesteps_total: 2130000
  training_iteration: 426
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 35.3/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=12141], 5827 s, 426 iter, 2130000 ts, 1.59e+03 rew

agent-1: 318.0
agent-2: 359.0
agent-3: 280.0
agent-4: 331.0
agent-5: 282.0
Sum Reward: 1570.0
Avg Reward: 314.0
Min Reward: 280.0
Max Reward: 359.0
Gini Coefficient: 0.05273885350318471
20:20 Ratio: 1.2821428571428573
Max-min Ratio: 1.2821428571428573
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_13-37-55
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1847.0
  episode_reward_mean: 1585.61
  episode_reward_min: 571.0
  episodes_this_iter: 1
  episodes_total: 426
  experiment_id: ebedc1946062457bb682d57fae83bd74
  hostname: gpu052
  info:
    apply_time_ms: 2.542
    dispatch_time_ms: 5.76
    learner:
      cur_lr: 0.0012181419879198074
      grad_gnorm: 39.999996185302734
      policy_entropy: 17.32636070251465
      policy_loss: 15.878630638122559
      var_gnorm: 43.47627258300781
      vf_explained_var: 0.9524188041687012
      vf_loss: 34.64094161987305
    num_steps_sampled: 2135000
    num_steps_trained: 2135000
    wait_time_ms: 110.752
  iterations_since_restore: 427
  node_ip: 172.17.8.52
  num_metric_batches_dropped: 0
  pid: 12141
  policy_reward_mean: {}
  time_since_restore: 5841.553278923035
  time_this_iter_s: 13.865741491317749
  time_total_s: 5841.553278923035
  timestamp: 1594143475
  timesteps_since_restore: 2135000
  timesteps_this_iter: 5000
  timesteps_total: 2135000
  training_iteration: 427
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 35.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=12141], 5841 s, 427 iter, 2135000 ts, 1.59e+03 rew

agent-1: 292.0
agent-2: 375.0
agent-3: 266.0
agent-4: 278.0
agent-5: 380.0
Sum Reward: 1591.0
Avg Reward: 318.2
Min Reward: 266.0
Max Reward: 380.0
Gini Coefficient: 0.08170961659333752
20:20 Ratio: 1.4285714285714286
Max-min Ratio: 1.4285714285714286
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_13-38-08
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1847.0
  episode_reward_mean: 1584.41
  episode_reward_min: 571.0
  episodes_this_iter: 1
  episodes_total: 427
  experiment_id: ebedc1946062457bb682d57fae83bd74
  hostname: gpu052
  info:
    apply_time_ms: 2.558
    dispatch_time_ms: 5.843
    learner:
      cur_lr: 0.0012178090400993824
      grad_gnorm: 40.0
      policy_entropy: 17.344005584716797
      policy_loss: -8.256023406982422
      var_gnorm: 43.469398498535156
      vf_explained_var: 0.9131295084953308
      vf_loss: 48.60686111450195
    num_steps_sampled: 2140000
    num_steps_trained: 2140000
    wait_time_ms: 131.095
  iterations_since_restore: 428
  node_ip: 172.17.8.52
  num_metric_batches_dropped: 0
  pid: 12141
  policy_reward_mean: {}
  time_since_restore: 5854.434517145157
  time_this_iter_s: 12.881238222122192
  time_total_s: 5854.434517145157
  timestamp: 1594143488
  timesteps_since_restore: 2140000
  timesteps_this_iter: 5000
  timesteps_total: 2140000
  training_iteration: 428
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 35.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=12141], 5854 s, 428 iter, 2140000 ts, 1.58e+03 rew

agent-1: 110.0
agent-2: 372.0
agent-3: 362.0
agent-4: 328.0
agent-5: 351.0
Sum Reward: 1523.0
Avg Reward: 304.6
Min Reward: 110.0
Max Reward: 372.0
Gini Coefficient: 0.14655285620485883
20:20 Ratio: 3.381818181818182
Max-min Ratio: 3.381818181818182
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_13-38-22
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1847.0
  episode_reward_mean: 1584.22
  episode_reward_min: 571.0
  episodes_this_iter: 1
  episodes_total: 428
  experiment_id: ebedc1946062457bb682d57fae83bd74
  hostname: gpu052
  info:
    apply_time_ms: 3.686
    dispatch_time_ms: 6.294
    learner:
      cur_lr: 0.0012174759758636355
      grad_gnorm: 39.99998474121094
      policy_entropy: 19.061294555664062
      policy_loss: 12.626852035522461
      var_gnorm: 43.52028274536133
      vf_explained_var: -0.5629274845123291
      vf_loss: 65.46881866455078
    num_steps_sampled: 2145000
    num_steps_trained: 2145000
    wait_time_ms: 130.353
  iterations_since_restore: 429
  node_ip: 172.17.8.52
  num_metric_batches_dropped: 0
  pid: 12141
  policy_reward_mean: {}
  time_since_restore: 5868.515181779861
  time_this_iter_s: 14.08066463470459
  time_total_s: 5868.515181779861
  timestamp: 1594143502
  timesteps_since_restore: 2145000
  timesteps_this_iter: 5000
  timesteps_total: 2145000
  training_iteration: 429
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 35.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=12141], 5868 s, 429 iter, 2145000 ts, 1.58e+03 rew

agent-1: 302.0
agent-2: 339.0
agent-3: 310.0
agent-4: 319.0
agent-5: 245.0
Sum Reward: 1515.0
Avg Reward: 303.0
Min Reward: 245.0
Max Reward: 339.0
Gini Coefficient: 0.05412541254125412
20:20 Ratio: 1.383673469387755
Max-min Ratio: 1.383673469387755
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_13-38-35
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1847.0
  episode_reward_mean: 1582.75
  episode_reward_min: 571.0
  episodes_this_iter: 1
  episodes_total: 429
  experiment_id: ebedc1946062457bb682d57fae83bd74
  hostname: gpu052
  info:
    apply_time_ms: 3.579
    dispatch_time_ms: 8.15
    learner:
      cur_lr: 0.0012171430280432105
      grad_gnorm: 40.0
      policy_entropy: 12.746634483337402
      policy_loss: 12.386428833007812
      var_gnorm: 43.5102653503418
      vf_explained_var: 0.09548813104629517
      vf_loss: 111.97028350830078
    num_steps_sampled: 2150000
    num_steps_trained: 2150000
    wait_time_ms: 130.389
  iterations_since_restore: 430
  node_ip: 172.17.8.52
  num_metric_batches_dropped: 0
  pid: 12141
  policy_reward_mean: {}
  time_since_restore: 5881.638321876526
  time_this_iter_s: 13.123140096664429
  time_total_s: 5881.638321876526
  timestamp: 1594143515
  timesteps_since_restore: 2150000
  timesteps_this_iter: 5000
  timesteps_total: 2150000
  training_iteration: 430
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 35.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=12141], 5881 s, 430 iter, 2150000 ts, 1.58e+03 rew

agent-1: 323.0
agent-2: 315.0
agent-3: 327.0
agent-4: 329.0
agent-5: 360.0
Sum Reward: 1654.0
Avg Reward: 330.8
Min Reward: 315.0
Max Reward: 360.0
Gini Coefficient: 0.023216444981862153
20:20 Ratio: 1.1428571428571428
Max-min Ratio: 1.1428571428571428
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_13-38-50
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1847.0
  episode_reward_mean: 1581.67
  episode_reward_min: 571.0
  episodes_this_iter: 1
  episodes_total: 430
  experiment_id: ebedc1946062457bb682d57fae83bd74
  hostname: gpu052
  info:
    apply_time_ms: 3.693
    dispatch_time_ms: 8.51
    learner:
      cur_lr: 0.0012168099638074636
      grad_gnorm: 40.0
      policy_entropy: 19.4092960357666
      policy_loss: 16.186573028564453
      var_gnorm: 43.61536407470703
      vf_explained_var: 0.9521188735961914
      vf_loss: 37.31770324707031
    num_steps_sampled: 2155000
    num_steps_trained: 2155000
    wait_time_ms: 120.999
  iterations_since_restore: 431
  node_ip: 172.17.8.52
  num_metric_batches_dropped: 0
  pid: 12141
  policy_reward_mean: {}
  time_since_restore: 5896.454802751541
  time_this_iter_s: 14.816480875015259
  time_total_s: 5896.454802751541
  timestamp: 1594143530
  timesteps_since_restore: 2155000
  timesteps_this_iter: 5000
  timesteps_total: 2155000
  training_iteration: 431
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 35.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=12141], 5896 s, 431 iter, 2155000 ts, 1.58e+03 rew

agent-1: 298.0
agent-2: 331.0
agent-3: 215.0
agent-4: 318.0
agent-5: 290.0
Sum Reward: 1452.0
Avg Reward: 290.4
Min Reward: 215.0
Max Reward: 331.0
Gini Coefficient: 0.07162534435261708
20:20 Ratio: 1.5395348837209302
Max-min Ratio: 1.5395348837209302
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_13-39-03
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1847.0
  episode_reward_mean: 1580.44
  episode_reward_min: 571.0
  episodes_this_iter: 1
  episodes_total: 431
  experiment_id: ebedc1946062457bb682d57fae83bd74
  hostname: gpu052
  info:
    apply_time_ms: 2.81
    dispatch_time_ms: 8.083
    learner:
      cur_lr: 0.0012164770159870386
      grad_gnorm: 31.72168731689453
      policy_entropy: 13.402976036071777
      policy_loss: -4.622159957885742
      var_gnorm: 43.61257553100586
      vf_explained_var: 0.423542320728302
      vf_loss: 44.67064666748047
    num_steps_sampled: 2160000
    num_steps_trained: 2160000
    wait_time_ms: 121.31
  iterations_since_restore: 432
  node_ip: 172.17.8.52
  num_metric_batches_dropped: 0
  pid: 12141
  policy_reward_mean: {}
  time_since_restore: 5909.463441133499
  time_this_iter_s: 13.008638381958008
  time_total_s: 5909.463441133499
  timestamp: 1594143543
  timesteps_since_restore: 2160000
  timesteps_this_iter: 5000
  timesteps_total: 2160000
  training_iteration: 432
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 35.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=12141], 5909 s, 432 iter, 2160000 ts, 1.58e+03 rew

agent-1: 391.0
agent-2: 391.0
agent-3: 0.0
agent-4: 398.0
agent-5: 413.0
Sum Reward: 1593.0
Avg Reward: 318.6
Min Reward: 0.0
Max Reward: 413.0
Gini Coefficient: 0.20916509730069052
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_13-39-17
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1847.0
  episode_reward_mean: 1579.3
  episode_reward_min: 571.0
  episodes_this_iter: 1
  episodes_total: 432
  experiment_id: ebedc1946062457bb682d57fae83bd74
  hostname: gpu052
  info:
    apply_time_ms: 3.479
    dispatch_time_ms: 7.026
    learner:
      cur_lr: 0.0012161439517512918
      grad_gnorm: 37.26930236816406
      policy_entropy: 21.824459075927734
      policy_loss: 12.343429565429688
      var_gnorm: 43.64604187011719
      vf_explained_var: 0.20750927925109863
      vf_loss: 53.93319320678711
    num_steps_sampled: 2165000
    num_steps_trained: 2165000
    wait_time_ms: 114.568
  iterations_since_restore: 433
  node_ip: 172.17.8.52
  num_metric_batches_dropped: 0
  pid: 12141
  policy_reward_mean: {}
  time_since_restore: 5922.777719497681
  time_this_iter_s: 13.314278364181519
  time_total_s: 5922.777719497681
  timestamp: 1594143557
  timesteps_since_restore: 2165000
  timesteps_this_iter: 5000
  timesteps_total: 2165000
  training_iteration: 433
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 35.3/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=12141], 5922 s, 433 iter, 2165000 ts, 1.58e+03 rew

agent-1: 269.0
agent-2: 364.0
agent-3: 292.0
agent-4: 356.0
agent-5: 317.0
Sum Reward: 1598.0
Avg Reward: 319.6
Min Reward: 269.0
Max Reward: 364.0
Gini Coefficient: 0.06357947434292865
20:20 Ratio: 1.3531598513011152
Max-min Ratio: 1.3531598513011152
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_13-39-29
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1847.0
  episode_reward_mean: 1577.57
  episode_reward_min: 571.0
  episodes_this_iter: 1
  episodes_total: 433
  experiment_id: ebedc1946062457bb682d57fae83bd74
  hostname: gpu052
  info:
    apply_time_ms: 3.906
    dispatch_time_ms: 6.63
    learner:
      cur_lr: 0.0012158110039308667
      grad_gnorm: 40.0
      policy_entropy: 16.931671142578125
      policy_loss: -1.719920039176941
      var_gnorm: 43.705345153808594
      vf_explained_var: 0.6230099201202393
      vf_loss: 39.47834396362305
    num_steps_sampled: 2170000
    num_steps_trained: 2170000
    wait_time_ms: 131.378
  iterations_since_restore: 434
  node_ip: 172.17.8.52
  num_metric_batches_dropped: 0
  pid: 12141
  policy_reward_mean: {}
  time_since_restore: 5935.673038721085
  time_this_iter_s: 12.89531922340393
  time_total_s: 5935.673038721085
  timestamp: 1594143569
  timesteps_since_restore: 2170000
  timesteps_this_iter: 5000
  timesteps_total: 2170000
  training_iteration: 434
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 35.3/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=12141], 5935 s, 434 iter, 2170000 ts, 1.58e+03 rew

agent-1: 300.0
agent-2: 366.0
agent-3: 290.0
agent-4: 296.0
agent-5: 305.0
Sum Reward: 1557.0
Avg Reward: 311.4
Min Reward: 290.0
Max Reward: 366.0
Gini Coefficient: 0.04136159280667951
20:20 Ratio: 1.2620689655172415
Max-min Ratio: 1.2620689655172415
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_13-39-50
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1847.0
  episode_reward_mean: 1576.08
  episode_reward_min: 571.0
  episodes_this_iter: 1
  episodes_total: 434
  experiment_id: ebedc1946062457bb682d57fae83bd74
  hostname: gpu052
  info:
    apply_time_ms: 3.213
    dispatch_time_ms: 688.966
    learner:
      cur_lr: 0.0012154780561104417
      grad_gnorm: 39.999996185302734
      policy_entropy: 14.998421669006348
      policy_loss: -6.180859565734863
      var_gnorm: 43.7346076965332
      vf_explained_var: 0.9658118486404419
      vf_loss: 31.768138885498047
    num_steps_sampled: 2175000
    num_steps_trained: 2175000
    wait_time_ms: 86.525
  iterations_since_restore: 435
  node_ip: 172.17.8.52
  num_metric_batches_dropped: 0
  pid: 12141
  policy_reward_mean: {}
  time_since_restore: 5955.818055868149
  time_this_iter_s: 20.14501714706421
  time_total_s: 5955.818055868149
  timestamp: 1594143590
  timesteps_since_restore: 2175000
  timesteps_this_iter: 5000
  timesteps_total: 2175000
  training_iteration: 435
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 35.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=12141], 5955 s, 435 iter, 2175000 ts, 1.58e+03 rew

agent-1: 376.0
agent-2: 352.0
agent-3: 21.0
agent-4: 369.0
agent-5: 355.0
Sum Reward: 1473.0
Avg Reward: 294.6
Min Reward: 21.0
Max Reward: 376.0
Gini Coefficient: 0.19742023082145282
20:20 Ratio: 17.904761904761905
Max-min Ratio: 17.904761904761905
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_13-40-02
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1847.0
  episode_reward_mean: 1573.48
  episode_reward_min: 571.0
  episodes_this_iter: 1
  episodes_total: 435
  experiment_id: ebedc1946062457bb682d57fae83bd74
  hostname: gpu052
  info:
    apply_time_ms: 2.731
    dispatch_time_ms: 38.492
    learner:
      cur_lr: 0.0012151449918746948
      grad_gnorm: 40.0
      policy_entropy: 13.89208698272705
      policy_loss: -13.674939155578613
      var_gnorm: 43.77783203125
      vf_explained_var: 0.8907977342605591
      vf_loss: 88.45736694335938
    num_steps_sampled: 2180000
    num_steps_trained: 2180000
    wait_time_ms: 93.567
  iterations_since_restore: 436
  node_ip: 172.17.8.52
  num_metric_batches_dropped: 0
  pid: 12141
  policy_reward_mean: {}
  time_since_restore: 5968.304343700409
  time_this_iter_s: 12.486287832260132
  time_total_s: 5968.304343700409
  timestamp: 1594143602
  timesteps_since_restore: 2180000
  timesteps_this_iter: 5000
  timesteps_total: 2180000
  training_iteration: 436
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 35.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=12141], 5968 s, 436 iter, 2180000 ts, 1.57e+03 rew

agent-1: 0.0
agent-2: 405.0
agent-3: 362.0
agent-4: 381.0
agent-5: 404.0
Sum Reward: 1552.0
Avg Reward: 310.4
Min Reward: 0.0
Max Reward: 405.0
Gini Coefficient: 0.21958762886597938
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_13-40-16
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1847.0
  episode_reward_mean: 1572.51
  episode_reward_min: 571.0
  episodes_this_iter: 1
  episodes_total: 436
  experiment_id: ebedc1946062457bb682d57fae83bd74
  hostname: gpu052
  info:
    apply_time_ms: 2.77
    dispatch_time_ms: 31.586
    learner:
      cur_lr: 0.0012148120440542698
      grad_gnorm: 40.0
      policy_entropy: 22.5074462890625
      policy_loss: 25.811552047729492
      var_gnorm: 43.790687561035156
      vf_explained_var: 0.28685832023620605
      vf_loss: 103.05537414550781
    num_steps_sampled: 2185000
    num_steps_trained: 2185000
    wait_time_ms: 94.823
  iterations_since_restore: 437
  node_ip: 172.17.8.52
  num_metric_batches_dropped: 0
  pid: 12141
  policy_reward_mean: {}
  time_since_restore: 5981.870761394501
  time_this_iter_s: 13.566417694091797
  time_total_s: 5981.870761394501
  timestamp: 1594143616
  timesteps_since_restore: 2185000
  timesteps_this_iter: 5000
  timesteps_total: 2185000
  training_iteration: 437
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 35.3/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=12141], 5981 s, 437 iter, 2185000 ts, 1.57e+03 rew

agent-1: 251.0
agent-2: 364.0
agent-3: 294.0
agent-4: 319.0
agent-5: 333.0
Sum Reward: 1561.0
Avg Reward: 312.2
Min Reward: 251.0
Max Reward: 364.0
Gini Coefficient: 0.06790518898142217
20:20 Ratio: 1.450199203187251
Max-min Ratio: 1.450199203187251
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_13-40-30
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1847.0
  episode_reward_mean: 1570.99
  episode_reward_min: 571.0
  episodes_this_iter: 1
  episodes_total: 437
  experiment_id: ebedc1946062457bb682d57fae83bd74
  hostname: gpu052
  info:
    apply_time_ms: 2.417
    dispatch_time_ms: 17.053
    learner:
      cur_lr: 0.001214478979818523
      grad_gnorm: 40.0000114440918
      policy_entropy: 4.279934406280518
      policy_loss: 0.14148807525634766
      var_gnorm: 43.857948303222656
      vf_explained_var: 0.8563405275344849
      vf_loss: 63.4608039855957
    num_steps_sampled: 2190000
    num_steps_trained: 2190000
    wait_time_ms: 131.821
  iterations_since_restore: 438
  node_ip: 172.17.8.52
  num_metric_batches_dropped: 0
  pid: 12141
  policy_reward_mean: {}
  time_since_restore: 5995.657347679138
  time_this_iter_s: 13.786586284637451
  time_total_s: 5995.657347679138
  timestamp: 1594143630
  timesteps_since_restore: 2190000
  timesteps_this_iter: 5000
  timesteps_total: 2190000
  training_iteration: 438
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 35.3/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=12141], 5995 s, 438 iter, 2190000 ts, 1.57e+03 rew

agent-1: 276.0
agent-2: 334.0
agent-3: 332.0
agent-4: 190.0
agent-5: 367.0
Sum Reward: 1499.0
Avg Reward: 299.8
Min Reward: 190.0
Max Reward: 367.0
Gini Coefficient: 0.10993995997331554
20:20 Ratio: 1.931578947368421
Max-min Ratio: 1.931578947368421
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_13-40-43
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1847.0
  episode_reward_mean: 1568.32
  episode_reward_min: 571.0
  episodes_this_iter: 1
  episodes_total: 438
  experiment_id: ebedc1946062457bb682d57fae83bd74
  hostname: gpu052
  info:
    apply_time_ms: 3.27
    dispatch_time_ms: 15.838
    learner:
      cur_lr: 0.001214146031998098
      grad_gnorm: 40.0
      policy_entropy: 11.328264236450195
      policy_loss: -1.5512523651123047
      var_gnorm: 43.90901184082031
      vf_explained_var: 0.7910765409469604
      vf_loss: 128.26654052734375
    num_steps_sampled: 2195000
    num_steps_trained: 2195000
    wait_time_ms: 122.673
  iterations_since_restore: 439
  node_ip: 172.17.8.52
  num_metric_batches_dropped: 0
  pid: 12141
  policy_reward_mean: {}
  time_since_restore: 6009.439653873444
  time_this_iter_s: 13.78230619430542
  time_total_s: 6009.439653873444
  timestamp: 1594143643
  timesteps_since_restore: 2195000
  timesteps_this_iter: 5000
  timesteps_total: 2195000
  training_iteration: 439
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 35.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=12141], 6009 s, 439 iter, 2195000 ts, 1.57e+03 rew

agent-1: 338.0
agent-2: 358.0
agent-3: 350.0
agent-4: 381.0
agent-5: 385.0
Sum Reward: 1812.0
Avg Reward: 362.4
Min Reward: 338.0
Max Reward: 385.0
Gini Coefficient: 0.02759381898454746
20:20 Ratio: 1.1390532544378698
Max-min Ratio: 1.1390532544378698
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_13-40-57
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1847.0
  episode_reward_mean: 1569.88
  episode_reward_min: 571.0
  episodes_this_iter: 1
  episodes_total: 439
  experiment_id: ebedc1946062457bb682d57fae83bd74
  hostname: gpu052
  info:
    apply_time_ms: 3.131
    dispatch_time_ms: 24.551
    learner:
      cur_lr: 0.001213812967762351
      grad_gnorm: 40.0
      policy_entropy: 19.172866821289062
      policy_loss: -77.35903930664062
      var_gnorm: 43.90303421020508
      vf_explained_var: 0.8992749452590942
      vf_loss: 75.89218139648438
    num_steps_sampled: 2200000
    num_steps_trained: 2200000
    wait_time_ms: 136.364
  iterations_since_restore: 440
  node_ip: 172.17.8.52
  num_metric_batches_dropped: 0
  pid: 12141
  policy_reward_mean: {}
  time_since_restore: 6022.97477722168
  time_this_iter_s: 13.535123348236084
  time_total_s: 6022.97477722168
  timestamp: 1594143657
  timesteps_since_restore: 2200000
  timesteps_this_iter: 5000
  timesteps_total: 2200000
  training_iteration: 440
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 35.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=12141], 6022 s, 440 iter, 2200000 ts, 1.57e+03 rew

agent-1: 382.0
agent-2: 364.0
agent-3: 221.0
agent-4: 356.0
agent-5: 373.0
Sum Reward: 1696.0
Avg Reward: 339.2
Min Reward: 221.0
Max Reward: 382.0
Gini Coefficient: 0.07995283018867924
20:20 Ratio: 1.7285067873303168
Max-min Ratio: 1.7285067873303168
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_13-41-11
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1847.0
  episode_reward_mean: 1569.73
  episode_reward_min: 571.0
  episodes_this_iter: 1
  episodes_total: 440
  experiment_id: ebedc1946062457bb682d57fae83bd74
  hostname: gpu052
  info:
    apply_time_ms: 3.488
    dispatch_time_ms: 28.482
    learner:
      cur_lr: 0.001213480019941926
      grad_gnorm: 40.0
      policy_entropy: 24.107833862304688
      policy_loss: -39.25302505493164
      var_gnorm: 43.927459716796875
      vf_explained_var: 0.6276258230209351
      vf_loss: 116.61123657226562
    num_steps_sampled: 2205000
    num_steps_trained: 2205000
    wait_time_ms: 87.466
  iterations_since_restore: 441
  node_ip: 172.17.8.52
  num_metric_batches_dropped: 0
  pid: 12141
  policy_reward_mean: {}
  time_since_restore: 6036.61878824234
  time_this_iter_s: 13.6440110206604
  time_total_s: 6036.61878824234
  timestamp: 1594143671
  timesteps_since_restore: 2205000
  timesteps_this_iter: 5000
  timesteps_total: 2205000
  training_iteration: 441
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 33.3/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=12141], 6036 s, 441 iter, 2205000 ts, 1.57e+03 rew

agent-1: 365.0
agent-2: 367.0
agent-3: 317.0
agent-4: 304.0
agent-5: 321.0
Sum Reward: 1674.0
Avg Reward: 334.8
Min Reward: 304.0
Max Reward: 367.0
Gini Coefficient: 0.04157706093189964
20:20 Ratio: 1.207236842105263
Max-min Ratio: 1.207236842105263
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_13-41-24
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1847.0
  episode_reward_mean: 1569.1
  episode_reward_min: 571.0
  episodes_this_iter: 1
  episodes_total: 441
  experiment_id: ebedc1946062457bb682d57fae83bd74
  hostname: gpu052
  info:
    apply_time_ms: 2.581
    dispatch_time_ms: 14.742
    learner:
      cur_lr: 0.0012131469557061791
      grad_gnorm: 34.480220794677734
      policy_entropy: 16.205955505371094
      policy_loss: 4.8640031814575195
      var_gnorm: 43.949886322021484
      vf_explained_var: 0.964478611946106
      vf_loss: 41.805870056152344
    num_steps_sampled: 2210000
    num_steps_trained: 2210000
    wait_time_ms: 117.987
  iterations_since_restore: 442
  node_ip: 172.17.8.52
  num_metric_batches_dropped: 0
  pid: 12141
  policy_reward_mean: {}
  time_since_restore: 6049.585968017578
  time_this_iter_s: 12.967179775238037
  time_total_s: 6049.585968017578
  timestamp: 1594143684
  timesteps_since_restore: 2210000
  timesteps_this_iter: 5000
  timesteps_total: 2210000
  training_iteration: 442
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 33.3/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=12141], 6049 s, 442 iter, 2210000 ts, 1.57e+03 rew

agent-1: 302.0
agent-2: 243.0
agent-3: 169.0
agent-4: 398.0
agent-5: 414.0
Sum Reward: 1526.0
Avg Reward: 305.2
Min Reward: 169.0
Max Reward: 414.0
Gini Coefficient: 0.1690694626474443
20:20 Ratio: 2.4497041420118344
Max-min Ratio: 2.4497041420118344
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_13-41-37
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1847.0
  episode_reward_mean: 1566.99
  episode_reward_min: 571.0
  episodes_this_iter: 1
  episodes_total: 442
  experiment_id: ebedc1946062457bb682d57fae83bd74
  hostname: gpu052
  info:
    apply_time_ms: 2.867
    dispatch_time_ms: 35.776
    learner:
      cur_lr: 0.0012128140078857541
      grad_gnorm: 40.0
      policy_entropy: 17.232025146484375
      policy_loss: 8.415323257446289
      var_gnorm: 43.909400939941406
      vf_explained_var: 0.4945371747016907
      vf_loss: 79.60891723632812
    num_steps_sampled: 2215000
    num_steps_trained: 2215000
    wait_time_ms: 88.206
  iterations_since_restore: 443
  node_ip: 172.17.8.52
  num_metric_batches_dropped: 0
  pid: 12141
  policy_reward_mean: {}
  time_since_restore: 6063.027580738068
  time_this_iter_s: 13.441612720489502
  time_total_s: 6063.027580738068
  timestamp: 1594143697
  timesteps_since_restore: 2215000
  timesteps_this_iter: 5000
  timesteps_total: 2215000
  training_iteration: 443
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 33.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=12141], 6063 s, 443 iter, 2215000 ts, 1.57e+03 rew

agent-1: 368.0
agent-2: 377.0
agent-3: 398.0
agent-4: 364.0
agent-5: 176.0
Sum Reward: 1683.0
Avg Reward: 336.6
Min Reward: 176.0
Max Reward: 398.0
Gini Coefficient: 0.10861556743909685
20:20 Ratio: 2.2613636363636362
Max-min Ratio: 2.2613636363636362
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_13-41-51
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1847.0
  episode_reward_mean: 1566.3
  episode_reward_min: 571.0
  episodes_this_iter: 1
  episodes_total: 443
  experiment_id: ebedc1946062457bb682d57fae83bd74
  hostname: gpu052
  info:
    apply_time_ms: 2.692
    dispatch_time_ms: 17.855
    learner:
      cur_lr: 0.0012124809436500072
      grad_gnorm: 39.99999237060547
      policy_entropy: 13.101236343383789
      policy_loss: 2.538607120513916
      var_gnorm: 43.91761016845703
      vf_explained_var: 0.28727251291275024
      vf_loss: 51.42522430419922
    num_steps_sampled: 2220000
    num_steps_trained: 2220000
    wait_time_ms: 124.734
  iterations_since_restore: 444
  node_ip: 172.17.8.52
  num_metric_batches_dropped: 0
  pid: 12141
  policy_reward_mean: {}
  time_since_restore: 6076.693016767502
  time_this_iter_s: 13.665436029434204
  time_total_s: 6076.693016767502
  timestamp: 1594143711
  timesteps_since_restore: 2220000
  timesteps_this_iter: 5000
  timesteps_total: 2220000
  training_iteration: 444
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 33.3/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=12141], 6076 s, 444 iter, 2220000 ts, 1.57e+03 rew

agent-1: 364.0
agent-2: 326.0
agent-3: 372.0
agent-4: 368.0
agent-5: 371.0
Sum Reward: 1801.0
Avg Reward: 360.2
Min Reward: 326.0
Max Reward: 372.0
Gini Coefficient: 0.021987784564131037
20:20 Ratio: 1.1411042944785277
Max-min Ratio: 1.1411042944785277
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_13-42-05
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1847.0
  episode_reward_mean: 1566.87
  episode_reward_min: 571.0
  episodes_this_iter: 1
  episodes_total: 444
  experiment_id: ebedc1946062457bb682d57fae83bd74
  hostname: gpu052
  info:
    apply_time_ms: 3.045
    dispatch_time_ms: 8.224
    learner:
      cur_lr: 0.0012121479958295822
      grad_gnorm: 39.999996185302734
      policy_entropy: 12.148444175720215
      policy_loss: -0.07629820704460144
      var_gnorm: 43.965572357177734
      vf_explained_var: 0.15117794275283813
      vf_loss: 76.15675354003906
    num_steps_sampled: 2225000
    num_steps_trained: 2225000
    wait_time_ms: 122.848
  iterations_since_restore: 445
  node_ip: 172.17.8.52
  num_metric_batches_dropped: 0
  pid: 12141
  policy_reward_mean: {}
  time_since_restore: 6090.854304790497
  time_this_iter_s: 14.161288022994995
  time_total_s: 6090.854304790497
  timestamp: 1594143725
  timesteps_since_restore: 2225000
  timesteps_this_iter: 5000
  timesteps_total: 2225000
  training_iteration: 445
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 33.3/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=12141], 6090 s, 445 iter, 2225000 ts, 1.57e+03 rew

agent-1: 319.0
agent-2: 333.0
agent-3: 344.0
agent-4: 247.0
agent-5: 317.0
Sum Reward: 1560.0
Avg Reward: 312.0
Min Reward: 247.0
Max Reward: 344.0
Gini Coefficient: 0.05384615384615385
20:20 Ratio: 1.3927125506072875
Max-min Ratio: 1.3927125506072875
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_13-42-19
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1847.0
  episode_reward_mean: 1565.63
  episode_reward_min: 571.0
  episodes_this_iter: 1
  episodes_total: 445
  experiment_id: ebedc1946062457bb682d57fae83bd74
  hostname: gpu052
  info:
    apply_time_ms: 2.701
    dispatch_time_ms: 5.716
    learner:
      cur_lr: 0.0012118150480091572
      grad_gnorm: 39.999996185302734
      policy_entropy: 10.187385559082031
      policy_loss: 2.0814332962036133
      var_gnorm: 44.01089859008789
      vf_explained_var: -0.1212691068649292
      vf_loss: 177.3962860107422
    num_steps_sampled: 2230000
    num_steps_trained: 2230000
    wait_time_ms: 128.564
  iterations_since_restore: 446
  node_ip: 172.17.8.52
  num_metric_batches_dropped: 0
  pid: 12141
  policy_reward_mean: {}
  time_since_restore: 6104.381477832794
  time_this_iter_s: 13.527173042297363
  time_total_s: 6104.381477832794
  timestamp: 1594143739
  timesteps_since_restore: 2230000
  timesteps_this_iter: 5000
  timesteps_total: 2230000
  training_iteration: 446
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 33.3/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=12141], 6104 s, 446 iter, 2230000 ts, 1.57e+03 rew

agent-1: 380.0
agent-2: 376.0
agent-3: 327.0
agent-4: 351.0
agent-5: 334.0
Sum Reward: 1768.0
Avg Reward: 353.6
Min Reward: 327.0
Max Reward: 380.0
Gini Coefficient: 0.0334841628959276
20:20 Ratio: 1.162079510703364
Max-min Ratio: 1.162079510703364
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_13-42-33
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1847.0
  episode_reward_mean: 1567.48
  episode_reward_min: 571.0
  episodes_this_iter: 1
  episodes_total: 446
  experiment_id: ebedc1946062457bb682d57fae83bd74
  hostname: gpu052
  info:
    apply_time_ms: 3.018
    dispatch_time_ms: 5.781
    learner:
      cur_lr: 0.0012114819837734103
      grad_gnorm: 40.0
      policy_entropy: 16.02223777770996
      policy_loss: -4.527235507965088
      var_gnorm: 44.08628463745117
      vf_explained_var: 0.03362327814102173
      vf_loss: 18.461139678955078
    num_steps_sampled: 2235000
    num_steps_trained: 2235000
    wait_time_ms: 123.629
  iterations_since_restore: 447
  node_ip: 172.17.8.52
  num_metric_batches_dropped: 0
  pid: 12141
  policy_reward_mean: {}
  time_since_restore: 6118.528007745743
  time_this_iter_s: 14.146529912948608
  time_total_s: 6118.528007745743
  timestamp: 1594143753
  timesteps_since_restore: 2235000
  timesteps_this_iter: 5000
  timesteps_total: 2235000
  training_iteration: 447
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 33.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=12141], 6118 s, 447 iter, 2235000 ts, 1.57e+03 rew

agent-1: 317.0
agent-2: 346.0
agent-3: 341.0
agent-4: 288.0
agent-5: 373.0
Sum Reward: 1665.0
Avg Reward: 333.0
Min Reward: 288.0
Max Reward: 373.0
Gini Coefficient: 0.04780780780780781
20:20 Ratio: 1.2951388888888888
Max-min Ratio: 1.2951388888888888
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_13-42-47
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1847.0
  episode_reward_mean: 1567.54
  episode_reward_min: 571.0
  episodes_this_iter: 1
  episodes_total: 447
  experiment_id: ebedc1946062457bb682d57fae83bd74
  hostname: gpu052
  info:
    apply_time_ms: 3.971
    dispatch_time_ms: 6.214
    learner:
      cur_lr: 0.0012111490359529853
      grad_gnorm: 27.80353355407715
      policy_entropy: 10.147924423217773
      policy_loss: 2.514516592025757
      var_gnorm: 44.079124450683594
      vf_explained_var: 0.9431269764900208
      vf_loss: 37.86478805541992
    num_steps_sampled: 2240000
    num_steps_trained: 2240000
    wait_time_ms: 132.15
  iterations_since_restore: 448
  node_ip: 172.17.8.52
  num_metric_batches_dropped: 0
  pid: 12141
  policy_reward_mean: {}
  time_since_restore: 6132.216421365738
  time_this_iter_s: 13.688413619995117
  time_total_s: 6132.216421365738
  timestamp: 1594143767
  timesteps_since_restore: 2240000
  timesteps_this_iter: 5000
  timesteps_total: 2240000
  training_iteration: 448
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 33.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=12141], 6132 s, 448 iter, 2240000 ts, 1.57e+03 rew

agent-1: 297.0
agent-2: 359.0
agent-3: 344.0
agent-4: 337.0
agent-5: 316.0
Sum Reward: 1653.0
Avg Reward: 330.6
Min Reward: 297.0
Max Reward: 359.0
Gini Coefficient: 0.0367816091954023
20:20 Ratio: 1.2087542087542087
Max-min Ratio: 1.2087542087542087
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_13-43-01
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1847.0
  episode_reward_mean: 1567.77
  episode_reward_min: 571.0
  episodes_this_iter: 1
  episodes_total: 448
  experiment_id: ebedc1946062457bb682d57fae83bd74
  hostname: gpu052
  info:
    apply_time_ms: 2.961
    dispatch_time_ms: 6.983
    learner:
      cur_lr: 0.0012108159717172384
      grad_gnorm: 40.000003814697266
      policy_entropy: 15.299360275268555
      policy_loss: 58.45951461791992
      var_gnorm: 44.12735366821289
      vf_explained_var: -0.49146831035614014
      vf_loss: 164.5688934326172
    num_steps_sampled: 2245000
    num_steps_trained: 2245000
    wait_time_ms: 113.622
  iterations_since_restore: 449
  node_ip: 172.17.8.52
  num_metric_batches_dropped: 0
  pid: 12141
  policy_reward_mean: {}
  time_since_restore: 6146.424065589905
  time_this_iter_s: 14.20764422416687
  time_total_s: 6146.424065589905
  timestamp: 1594143781
  timesteps_since_restore: 2245000
  timesteps_this_iter: 5000
  timesteps_total: 2245000
  training_iteration: 449
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 33.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=12141], 6146 s, 449 iter, 2245000 ts, 1.57e+03 rew

agent-1: 285.0
agent-2: 328.0
agent-3: 381.0
agent-4: 309.0
agent-5: 311.0
Sum Reward: 1614.0
Avg Reward: 322.8
Min Reward: 285.0
Max Reward: 381.0
Gini Coefficient: 0.052292441140024785
20:20 Ratio: 1.3368421052631578
Max-min Ratio: 1.3368421052631578
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_13-43-14
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1847.0
  episode_reward_mean: 1570.72
  episode_reward_min: 571.0
  episodes_this_iter: 1
  episodes_total: 449
  experiment_id: ebedc1946062457bb682d57fae83bd74
  hostname: gpu052
  info:
    apply_time_ms: 4.623
    dispatch_time_ms: 5.613
    learner:
      cur_lr: 0.0012104830238968134
      grad_gnorm: 40.000003814697266
      policy_entropy: 24.587848663330078
      policy_loss: 12.406656265258789
      var_gnorm: 44.12133026123047
      vf_explained_var: 0.16525781154632568
      vf_loss: 35.94923400878906
    num_steps_sampled: 2250000
    num_steps_trained: 2250000
    wait_time_ms: 117.834
  iterations_since_restore: 450
  node_ip: 172.17.8.52
  num_metric_batches_dropped: 0
  pid: 12141
  policy_reward_mean: {}
  time_since_restore: 6159.588444948196
  time_this_iter_s: 13.164379358291626
  time_total_s: 6159.588444948196
  timestamp: 1594143794
  timesteps_since_restore: 2250000
  timesteps_this_iter: 5000
  timesteps_total: 2250000
  training_iteration: 450
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 33.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=12141], 6159 s, 450 iter, 2250000 ts, 1.57e+03 rew

agent-1: 217.0
agent-2: 306.0
agent-3: 308.0
agent-4: 320.0
agent-5: 349.0
Sum Reward: 1500.0
Avg Reward: 300.0
Min Reward: 217.0
Max Reward: 349.0
Gini Coefficient: 0.07413333333333333
20:20 Ratio: 1.608294930875576
Max-min Ratio: 1.608294930875576
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_13-43-28
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1847.0
  episode_reward_mean: 1570.87
  episode_reward_min: 571.0
  episodes_this_iter: 1
  episodes_total: 450
  experiment_id: ebedc1946062457bb682d57fae83bd74
  hostname: gpu052
  info:
    apply_time_ms: 2.706
    dispatch_time_ms: 5.849
    learner:
      cur_lr: 0.0012101499596610665
      grad_gnorm: 39.999996185302734
      policy_entropy: 18.32601547241211
      policy_loss: 4.394076824188232
      var_gnorm: 44.11555099487305
      vf_explained_var: 0.21692389249801636
      vf_loss: 41.23094177246094
    num_steps_sampled: 2255000
    num_steps_trained: 2255000
    wait_time_ms: 118.106
  iterations_since_restore: 451
  node_ip: 172.17.8.52
  num_metric_batches_dropped: 0
  pid: 12141
  policy_reward_mean: {}
  time_since_restore: 6173.288261175156
  time_this_iter_s: 13.699816226959229
  time_total_s: 6173.288261175156
  timestamp: 1594143808
  timesteps_since_restore: 2255000
  timesteps_this_iter: 5000
  timesteps_total: 2255000
  training_iteration: 451
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 33.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=12141], 6173 s, 451 iter, 2255000 ts, 1.57e+03 rew

agent-1: 319.0
agent-2: 318.0
agent-3: 316.0
agent-4: 316.0
agent-5: 241.0
Sum Reward: 1510.0
Avg Reward: 302.0
Min Reward: 241.0
Max Reward: 319.0
Gini Coefficient: 0.04185430463576159
20:20 Ratio: 1.3236514522821576
Max-min Ratio: 1.3236514522821576
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_13-43-41
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1847.0
  episode_reward_mean: 1573.15
  episode_reward_min: 571.0
  episodes_this_iter: 1
  episodes_total: 451
  experiment_id: ebedc1946062457bb682d57fae83bd74
  hostname: gpu052
  info:
    apply_time_ms: 2.854
    dispatch_time_ms: 5.977
    learner:
      cur_lr: 0.0012098170118406415
      grad_gnorm: 40.0
      policy_entropy: 27.727502822875977
      policy_loss: -15.776473045349121
      var_gnorm: 44.13605880737305
      vf_explained_var: 0.5500411987304688
      vf_loss: 29.906387329101562
    num_steps_sampled: 2260000
    num_steps_trained: 2260000
    wait_time_ms: 121.813
  iterations_since_restore: 452
  node_ip: 172.17.8.52
  num_metric_batches_dropped: 0
  pid: 12141
  policy_reward_mean: {}
  time_since_restore: 6186.233554363251
  time_this_iter_s: 12.945293188095093
  time_total_s: 6186.233554363251
  timestamp: 1594143821
  timesteps_since_restore: 2260000
  timesteps_this_iter: 5000
  timesteps_total: 2260000
  training_iteration: 452
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 33.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=12141], 6186 s, 452 iter, 2260000 ts, 1.57e+03 rew

agent-1: 350.0
agent-2: 350.0
agent-3: 283.0
agent-4: 337.0
agent-5: 324.0
Sum Reward: 1644.0
Avg Reward: 328.8
Min Reward: 283.0
Max Reward: 350.0
Gini Coefficient: 0.038929440389294405
20:20 Ratio: 1.2367491166077738
Max-min Ratio: 1.2367491166077738
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_13-43-54
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1847.0
  episode_reward_mean: 1577.21
  episode_reward_min: 571.0
  episodes_this_iter: 1
  episodes_total: 452
  experiment_id: ebedc1946062457bb682d57fae83bd74
  hostname: gpu052
  info:
    apply_time_ms: 2.915
    dispatch_time_ms: 6.405
    learner:
      cur_lr: 0.0012094839476048946
      grad_gnorm: 40.0
      policy_entropy: 12.461267471313477
      policy_loss: 5.498752593994141
      var_gnorm: 44.08308792114258
      vf_explained_var: 0.12912017107009888
      vf_loss: 31.488239288330078
    num_steps_sampled: 2265000
    num_steps_trained: 2265000
    wait_time_ms: 111.67
  iterations_since_restore: 453
  node_ip: 172.17.8.52
  num_metric_batches_dropped: 0
  pid: 12141
  policy_reward_mean: {}
  time_since_restore: 6199.924980401993
  time_this_iter_s: 13.691426038742065
  time_total_s: 6199.924980401993
  timestamp: 1594143834
  timesteps_since_restore: 2265000
  timesteps_this_iter: 5000
  timesteps_total: 2265000
  training_iteration: 453
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 33.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=12141], 6199 s, 453 iter, 2265000 ts, 1.58e+03 rew

agent-1: 260.0
agent-2: 330.0
agent-3: 346.0
agent-4: 284.0
agent-5: 328.0
Sum Reward: 1548.0
Avg Reward: 309.6
Min Reward: 260.0
Max Reward: 346.0
Gini Coefficient: 0.056330749354005165
20:20 Ratio: 1.3307692307692307
Max-min Ratio: 1.3307692307692307
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_13-44-07
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1847.0
  episode_reward_mean: 1580.18
  episode_reward_min: 571.0
  episodes_this_iter: 1
  episodes_total: 453
  experiment_id: ebedc1946062457bb682d57fae83bd74
  hostname: gpu052
  info:
    apply_time_ms: 2.724
    dispatch_time_ms: 5.672
    learner:
      cur_lr: 0.0012091509997844696
      grad_gnorm: 40.0
      policy_entropy: 32.02035903930664
      policy_loss: 14.830283164978027
      var_gnorm: 44.07356643676758
      vf_explained_var: 0.15666919946670532
      vf_loss: 46.005706787109375
    num_steps_sampled: 2270000
    num_steps_trained: 2270000
    wait_time_ms: 121.958
  iterations_since_restore: 454
  node_ip: 172.17.8.52
  num_metric_batches_dropped: 0
  pid: 12141
  policy_reward_mean: {}
  time_since_restore: 6212.41765666008
  time_this_iter_s: 12.492676258087158
  time_total_s: 6212.41765666008
  timestamp: 1594143847
  timesteps_since_restore: 2270000
  timesteps_this_iter: 5000
  timesteps_total: 2270000
  training_iteration: 454
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 33.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=12141], 6212 s, 454 iter, 2270000 ts, 1.58e+03 rew

agent-1: 305.0
agent-2: 323.0
agent-3: 328.0
agent-4: 307.0
agent-5: 348.0
Sum Reward: 1611.0
Avg Reward: 322.2
Min Reward: 305.0
Max Reward: 348.0
Gini Coefficient: 0.026567349472377405
20:20 Ratio: 1.140983606557377
Max-min Ratio: 1.140983606557377
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_13-44-21
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1847.0
  episode_reward_mean: 1584.03
  episode_reward_min: 571.0
  episodes_this_iter: 1
  episodes_total: 454
  experiment_id: ebedc1946062457bb682d57fae83bd74
  hostname: gpu052
  info:
    apply_time_ms: 2.743
    dispatch_time_ms: 6.606
    learner:
      cur_lr: 0.0012088180519640446
      grad_gnorm: 39.99997329711914
      policy_entropy: 12.844596862792969
      policy_loss: 6.8405046463012695
      var_gnorm: 44.09938049316406
      vf_explained_var: 0.34293097257614136
      vf_loss: 157.19676208496094
    num_steps_sampled: 2275000
    num_steps_trained: 2275000
    wait_time_ms: 127.997
  iterations_since_restore: 455
  node_ip: 172.17.8.52
  num_metric_batches_dropped: 0
  pid: 12141
  policy_reward_mean: {}
  time_since_restore: 6226.058802127838
  time_this_iter_s: 13.641145467758179
  time_total_s: 6226.058802127838
  timestamp: 1594143861
  timesteps_since_restore: 2275000
  timesteps_this_iter: 5000
  timesteps_total: 2275000
  training_iteration: 455
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 33.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=12141], 6226 s, 455 iter, 2275000 ts, 1.58e+03 rew

agent-1: 311.0
agent-2: 363.0
agent-3: 315.0
agent-4: 328.0
agent-5: 341.0
Sum Reward: 1658.0
Avg Reward: 331.6
Min Reward: 311.0
Max Reward: 363.0
Gini Coefficient: 0.031363088057901084
20:20 Ratio: 1.167202572347267
Max-min Ratio: 1.167202572347267
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_13-44-33
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1847.0
  episode_reward_mean: 1589.59
  episode_reward_min: 571.0
  episodes_this_iter: 1
  episodes_total: 455
  experiment_id: ebedc1946062457bb682d57fae83bd74
  hostname: gpu052
  info:
    apply_time_ms: 3.489
    dispatch_time_ms: 5.922
    learner:
      cur_lr: 0.0012084849877282977
      grad_gnorm: 40.0
      policy_entropy: 16.673542022705078
      policy_loss: 7.154423713684082
      var_gnorm: 44.20404815673828
      vf_explained_var: 0.2398729920387268
      vf_loss: 9.272760391235352
    num_steps_sampled: 2280000
    num_steps_trained: 2280000
    wait_time_ms: 123.499
  iterations_since_restore: 456
  node_ip: 172.17.8.52
  num_metric_batches_dropped: 0
  pid: 12141
  policy_reward_mean: {}
  time_since_restore: 6238.690041065216
  time_this_iter_s: 12.63123893737793
  time_total_s: 6238.690041065216
  timestamp: 1594143873
  timesteps_since_restore: 2280000
  timesteps_this_iter: 5000
  timesteps_total: 2280000
  training_iteration: 456
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 33.3/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=12141], 6238 s, 456 iter, 2280000 ts, 1.59e+03 rew

agent-1: 199.0
agent-2: 280.0
agent-3: 384.0
agent-4: 346.0
agent-5: 305.0
Sum Reward: 1514.0
Avg Reward: 302.8
Min Reward: 199.0
Max Reward: 384.0
Gini Coefficient: 0.11519154557463672
20:20 Ratio: 1.92964824120603
Max-min Ratio: 1.92964824120603
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_13-44-47
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1847.0
  episode_reward_mean: 1593.01
  episode_reward_min: 571.0
  episodes_this_iter: 1
  episodes_total: 456
  experiment_id: ebedc1946062457bb682d57fae83bd74
  hostname: gpu052
  info:
    apply_time_ms: 3.136
    dispatch_time_ms: 7.036
    learner:
      cur_lr: 0.0012081520399078727
      grad_gnorm: 40.0
      policy_entropy: 16.06501579284668
      policy_loss: 12.74000072479248
      var_gnorm: 44.19451141357422
      vf_explained_var: 0.050840675830841064
      vf_loss: 59.795509338378906
    num_steps_sampled: 2285000
    num_steps_trained: 2285000
    wait_time_ms: 110.679
  iterations_since_restore: 457
  node_ip: 172.17.8.52
  num_metric_batches_dropped: 0
  pid: 12141
  policy_reward_mean: {}
  time_since_restore: 6252.213226079941
  time_this_iter_s: 13.523185014724731
  time_total_s: 6252.213226079941
  timestamp: 1594143887
  timesteps_since_restore: 2285000
  timesteps_this_iter: 5000
  timesteps_total: 2285000
  training_iteration: 457
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 33.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=12141], 6252 s, 457 iter, 2285000 ts, 1.59e+03 rew

agent-1: 362.0
agent-2: 389.0
agent-3: 359.0
agent-4: 324.0
agent-5: 339.0
Sum Reward: 1773.0
Avg Reward: 354.6
Min Reward: 324.0
Max Reward: 389.0
Gini Coefficient: 0.03451776649746193
20:20 Ratio: 1.2006172839506173
Max-min Ratio: 1.2006172839506173
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_13-45-00
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1847.0
  episode_reward_mean: 1598.01
  episode_reward_min: 571.0
  episodes_this_iter: 1
  episodes_total: 457
  experiment_id: ebedc1946062457bb682d57fae83bd74
  hostname: gpu052
  info:
    apply_time_ms: 4.371
    dispatch_time_ms: 7.664
    learner:
      cur_lr: 0.0012078189756721258
      grad_gnorm: 32.64910125732422
      policy_entropy: 20.753829956054688
      policy_loss: 10.533907890319824
      var_gnorm: 44.229148864746094
      vf_explained_var: -0.335646390914917
      vf_loss: 29.58922576904297
    num_steps_sampled: 2290000
    num_steps_trained: 2290000
    wait_time_ms: 125.983
  iterations_since_restore: 458
  node_ip: 172.17.8.52
  num_metric_batches_dropped: 0
  pid: 12141
  policy_reward_mean: {}
  time_since_restore: 6265.1249005794525
  time_this_iter_s: 12.911674499511719
  time_total_s: 6265.1249005794525
  timestamp: 1594143900
  timesteps_since_restore: 2290000
  timesteps_this_iter: 5000
  timesteps_total: 2290000
  training_iteration: 458
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 33.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=12141], 6265 s, 458 iter, 2290000 ts, 1.6e+03 rew

agent-1: 356.0
agent-2: 329.0
agent-3: 371.0
agent-4: 364.0
agent-5: 369.0
Sum Reward: 1789.0
Avg Reward: 357.8
Min Reward: 329.0
Max Reward: 371.0
Gini Coefficient: 0.021688093907210732
20:20 Ratio: 1.127659574468085
Max-min Ratio: 1.127659574468085
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_13-45-20
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1847.0
  episode_reward_mean: 1600.06
  episode_reward_min: 571.0
  episodes_this_iter: 1
  episodes_total: 458
  experiment_id: ebedc1946062457bb682d57fae83bd74
  hostname: gpu052
  info:
    apply_time_ms: 3.764
    dispatch_time_ms: 30.476
    learner:
      cur_lr: 0.0012074860278517008
      grad_gnorm: 40.0
      policy_entropy: 19.189058303833008
      policy_loss: -4.238124847412109
      var_gnorm: 44.22540283203125
      vf_explained_var: 0.22379612922668457
      vf_loss: 17.947463989257812
    num_steps_sampled: 2295000
    num_steps_trained: 2295000
    wait_time_ms: 76.185
  iterations_since_restore: 459
  node_ip: 172.17.8.52
  num_metric_batches_dropped: 0
  pid: 12141
  policy_reward_mean: {}
  time_since_restore: 6285.443287611008
  time_this_iter_s: 20.318387031555176
  time_total_s: 6285.443287611008
  timestamp: 1594143920
  timesteps_since_restore: 2295000
  timesteps_this_iter: 5000
  timesteps_total: 2295000
  training_iteration: 459
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 33.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=12141], 6285 s, 459 iter, 2295000 ts, 1.6e+03 rew

agent-1: 356.0
agent-2: 358.0
agent-3: 345.0
agent-4: 358.0
agent-5: 356.0
Sum Reward: 1773.0
Avg Reward: 354.6
Min Reward: 345.0
Max Reward: 358.0
Gini Coefficient: 0.00631697687535251
20:20 Ratio: 1.03768115942029
Max-min Ratio: 1.03768115942029
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_13-45-34
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1847.0
  episode_reward_mean: 1602.03
  episode_reward_min: 571.0
  episodes_this_iter: 1
  episodes_total: 459
  experiment_id: ebedc1946062457bb682d57fae83bd74
  hostname: gpu052
  info:
    apply_time_ms: 2.651
    dispatch_time_ms: 24.627
    learner:
      cur_lr: 0.001207152963615954
      grad_gnorm: 40.0
      policy_entropy: 28.58138656616211
      policy_loss: -17.22586441040039
      var_gnorm: 44.26756286621094
      vf_explained_var: 0.12776732444763184
      vf_loss: 20.291427612304688
    num_steps_sampled: 2300000
    num_steps_trained: 2300000
    wait_time_ms: 113.617
  iterations_since_restore: 460
  node_ip: 172.17.8.52
  num_metric_batches_dropped: 0
  pid: 12141
  policy_reward_mean: {}
  time_since_restore: 6298.754913568497
  time_this_iter_s: 13.311625957489014
  time_total_s: 6298.754913568497
  timestamp: 1594143934
  timesteps_since_restore: 2300000
  timesteps_this_iter: 5000
  timesteps_total: 2300000
  training_iteration: 460
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 33.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=12141], 6298 s, 460 iter, 2300000 ts, 1.6e+03 rew

agent-1: 368.0
agent-2: 341.0
agent-3: 344.0
agent-4: 354.0
agent-5: 335.0
Sum Reward: 1742.0
Avg Reward: 348.4
Min Reward: 335.0
Max Reward: 368.0
Gini Coefficient: 0.018140068886337544
20:20 Ratio: 1.0985074626865672
Max-min Ratio: 1.0985074626865672
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_13-45-49
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1847.0
  episode_reward_mean: 1601.56
  episode_reward_min: 571.0
  episodes_this_iter: 1
  episodes_total: 460
  experiment_id: ebedc1946062457bb682d57fae83bd74
  hostname: gpu052
  info:
    apply_time_ms: 182.418
    dispatch_time_ms: 35.689
    learner:
      cur_lr: 0.0012068200157955289
      grad_gnorm: 39.999996185302734
      policy_entropy: 19.236661911010742
      policy_loss: 3.1776421070098877
      var_gnorm: 44.315921783447266
      vf_explained_var: 0.29104888439178467
      vf_loss: 52.85539627075195
    num_steps_sampled: 2305000
    num_steps_trained: 2305000
    wait_time_ms: 55.779
  iterations_since_restore: 461
  node_ip: 172.17.8.52
  num_metric_batches_dropped: 0
  pid: 12141
  policy_reward_mean: {}
  time_since_restore: 6314.678960561752
  time_this_iter_s: 15.924046993255615
  time_total_s: 6314.678960561752
  timestamp: 1594143949
  timesteps_since_restore: 2305000
  timesteps_this_iter: 5000
  timesteps_total: 2305000
  training_iteration: 461
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 33.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=12141], 6314 s, 461 iter, 2305000 ts, 1.6e+03 rew

agent-1: 330.0
agent-2: 357.0
agent-3: 310.0
agent-4: 342.0
agent-5: 328.0
Sum Reward: 1667.0
Avg Reward: 333.4
Min Reward: 310.0
Max Reward: 357.0
Gini Coefficient: 0.02591481703659268
20:20 Ratio: 1.1516129032258065
Max-min Ratio: 1.1516129032258065
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_13-46-02
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1847.0
  episode_reward_mean: 1601.92
  episode_reward_min: 571.0
  episodes_this_iter: 1
  episodes_total: 461
  experiment_id: ebedc1946062457bb682d57fae83bd74
  hostname: gpu052
  info:
    apply_time_ms: 3.46
    dispatch_time_ms: 24.444
    learner:
      cur_lr: 0.001206486951559782
      grad_gnorm: 35.89542007446289
      policy_entropy: 10.352130889892578
      policy_loss: -5.32613468170166
      var_gnorm: 44.33620834350586
      vf_explained_var: 0.6504131555557251
      vf_loss: 18.680477142333984
    num_steps_sampled: 2310000
    num_steps_trained: 2310000
    wait_time_ms: 116.685
  iterations_since_restore: 462
  node_ip: 172.17.8.52
  num_metric_batches_dropped: 0
  pid: 12141
  policy_reward_mean: {}
  time_since_restore: 6327.201449632645
  time_this_iter_s: 12.522489070892334
  time_total_s: 6327.201449632645
  timestamp: 1594143962
  timesteps_since_restore: 2310000
  timesteps_this_iter: 5000
  timesteps_total: 2310000
  training_iteration: 462
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 33.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=12141], 6327 s, 462 iter, 2310000 ts, 1.6e+03 rew

agent-1: 243.0
agent-2: 309.0
agent-3: 330.0
agent-4: 280.0
agent-5: 332.0
Sum Reward: 1494.0
Avg Reward: 298.8
Min Reward: 243.0
Max Reward: 332.0
Gini Coefficient: 0.06104417670682731
20:20 Ratio: 1.3662551440329218
Max-min Ratio: 1.3662551440329218
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_13-46-17
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1847.0
  episode_reward_mean: 1600.05
  episode_reward_min: 571.0
  episodes_this_iter: 1
  episodes_total: 462
  experiment_id: ebedc1946062457bb682d57fae83bd74
  hostname: gpu052
  info:
    apply_time_ms: 2.936
    dispatch_time_ms: 21.137
    learner:
      cur_lr: 0.001206154003739357
      grad_gnorm: 40.0
      policy_entropy: 19.129302978515625
      policy_loss: 7.457234859466553
      var_gnorm: 44.3492317199707
      vf_explained_var: 0.7750368118286133
      vf_loss: 13.0967378616333
    num_steps_sampled: 2315000
    num_steps_trained: 2315000
    wait_time_ms: 100.696
  iterations_since_restore: 463
  node_ip: 172.17.8.52
  num_metric_batches_dropped: 0
  pid: 12141
  policy_reward_mean: {}
  time_since_restore: 6342.078489303589
  time_this_iter_s: 14.877039670944214
  time_total_s: 6342.078489303589
  timestamp: 1594143977
  timesteps_since_restore: 2315000
  timesteps_this_iter: 5000
  timesteps_total: 2315000
  training_iteration: 463
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 33.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=12141], 6342 s, 463 iter, 2315000 ts, 1.6e+03 rew

agent-1: 303.0
agent-2: 360.0
agent-3: 288.0
agent-4: 354.0
agent-5: 346.0
Sum Reward: 1651.0
Avg Reward: 330.2
Min Reward: 288.0
Max Reward: 360.0
Gini Coefficient: 0.047244094488188976
20:20 Ratio: 1.25
Max-min Ratio: 1.25
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_13-46-31
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1847.0
  episode_reward_mean: 1599.64
  episode_reward_min: 571.0
  episodes_this_iter: 1
  episodes_total: 463
  experiment_id: ebedc1946062457bb682d57fae83bd74
  hostname: gpu052
  info:
    apply_time_ms: 4.166
    dispatch_time_ms: 29.09
    learner:
      cur_lr: 0.001205821055918932
      grad_gnorm: 40.0000114440918
      policy_entropy: 15.887175559997559
      policy_loss: -6.604054927825928
      var_gnorm: 44.4254035949707
      vf_explained_var: 0.33026576042175293
      vf_loss: 38.579551696777344
    num_steps_sampled: 2320000
    num_steps_trained: 2320000
    wait_time_ms: 123.716
  iterations_since_restore: 464
  node_ip: 172.17.8.52
  num_metric_batches_dropped: 0
  pid: 12141
  policy_reward_mean: {}
  time_since_restore: 6355.902572393417
  time_this_iter_s: 13.824083089828491
  time_total_s: 6355.902572393417
  timestamp: 1594143991
  timesteps_since_restore: 2320000
  timesteps_this_iter: 5000
  timesteps_total: 2320000
  training_iteration: 464
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 33.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=12141], 6355 s, 464 iter, 2320000 ts, 1.6e+03 rew

agent-1: 299.0
agent-2: 313.0
agent-3: 292.0
agent-4: 299.0
agent-5: 293.0
Sum Reward: 1496.0
Avg Reward: 299.2
Min Reward: 292.0
Max Reward: 313.0
Gini Coefficient: 0.012834224598930482
20:20 Ratio: 1.071917808219178
Max-min Ratio: 1.071917808219178
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_13-46-46
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1847.0
  episode_reward_mean: 1597.79
  episode_reward_min: 571.0
  episodes_this_iter: 1
  episodes_total: 464
  experiment_id: ebedc1946062457bb682d57fae83bd74
  hostname: gpu052
  info:
    apply_time_ms: 3.208
    dispatch_time_ms: 24.897
    learner:
      cur_lr: 0.001205487991683185
      grad_gnorm: 40.000003814697266
      policy_entropy: 7.232819557189941
      policy_loss: 16.437589645385742
      var_gnorm: 44.38896942138672
      vf_explained_var: -0.7266682386398315
      vf_loss: 233.24462890625
    num_steps_sampled: 2325000
    num_steps_trained: 2325000
    wait_time_ms: 125.344
  iterations_since_restore: 465
  node_ip: 172.17.8.52
  num_metric_batches_dropped: 0
  pid: 12141
  policy_reward_mean: {}
  time_since_restore: 6371.39904999733
  time_this_iter_s: 15.496477603912354
  time_total_s: 6371.39904999733
  timestamp: 1594144006
  timesteps_since_restore: 2325000
  timesteps_this_iter: 5000
  timesteps_total: 2325000
  training_iteration: 465
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 33.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=12141], 6371 s, 465 iter, 2325000 ts, 1.6e+03 rew

agent-1: 376.0
agent-2: 326.0
agent-3: 335.0
agent-4: 298.0
agent-5: 280.0
Sum Reward: 1615.0
Avg Reward: 323.0
Min Reward: 280.0
Max Reward: 376.0
Gini Coefficient: 0.05671826625386997
20:20 Ratio: 1.3428571428571427
Max-min Ratio: 1.3428571428571427
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_13-46-59
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1847.0
  episode_reward_mean: 1596.65
  episode_reward_min: 571.0
  episodes_this_iter: 1
  episodes_total: 465
  experiment_id: ebedc1946062457bb682d57fae83bd74
  hostname: gpu052
  info:
    apply_time_ms: 4.196
    dispatch_time_ms: 6.889
    learner:
      cur_lr: 0.00120515504386276
      grad_gnorm: 40.0
      policy_entropy: 16.892189025878906
      policy_loss: 2.4244682788848877
      var_gnorm: 44.37638473510742
      vf_explained_var: 0.3621927499771118
      vf_loss: 104.7140121459961
    num_steps_sampled: 2330000
    num_steps_trained: 2330000
    wait_time_ms: 122.647
  iterations_since_restore: 466
  node_ip: 172.17.8.52
  num_metric_batches_dropped: 0
  pid: 12141
  policy_reward_mean: {}
  time_since_restore: 6383.944470405579
  time_this_iter_s: 12.545420408248901
  time_total_s: 6383.944470405579
  timestamp: 1594144019
  timesteps_since_restore: 2330000
  timesteps_this_iter: 5000
  timesteps_total: 2330000
  training_iteration: 466
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 33.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=12141], 6383 s, 466 iter, 2330000 ts, 1.6e+03 rew

agent-1: 322.0
agent-2: 282.0
agent-3: 326.0
agent-4: 339.0
agent-5: 331.0
Sum Reward: 1600.0
Avg Reward: 320.0
Min Reward: 282.0
Max Reward: 339.0
Gini Coefficient: 0.03075
20:20 Ratio: 1.202127659574468
Max-min Ratio: 1.202127659574468
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_13-47-13
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1847.0
  episode_reward_mean: 1595.99
  episode_reward_min: 571.0
  episodes_this_iter: 1
  episodes_total: 466
  experiment_id: ebedc1946062457bb682d57fae83bd74
  hostname: gpu052
  info:
    apply_time_ms: 2.858
    dispatch_time_ms: 6.119
    learner:
      cur_lr: 0.0012048219796270132
      grad_gnorm: 40.0
      policy_entropy: 20.76152992248535
      policy_loss: 62.38458251953125
      var_gnorm: 44.424678802490234
      vf_explained_var: -1.0
      vf_loss: 203.6831817626953
    num_steps_sampled: 2335000
    num_steps_trained: 2335000
    wait_time_ms: 134.955
  iterations_since_restore: 467
  node_ip: 172.17.8.52
  num_metric_batches_dropped: 0
  pid: 12141
  policy_reward_mean: {}
  time_since_restore: 6398.106995820999
  time_this_iter_s: 14.162525415420532
  time_total_s: 6398.106995820999
  timestamp: 1594144033
  timesteps_since_restore: 2335000
  timesteps_this_iter: 5000
  timesteps_total: 2335000
  training_iteration: 467
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 33.3/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=12141], 6398 s, 467 iter, 2335000 ts, 1.6e+03 rew

agent-1: 345.0
agent-2: 343.0
agent-3: 324.0
agent-4: 321.0
agent-5: 313.0
Sum Reward: 1646.0
Avg Reward: 329.2
Min Reward: 313.0
Max Reward: 345.0
Gini Coefficient: 0.020899149453219926
20:20 Ratio: 1.1022364217252396
Max-min Ratio: 1.1022364217252396
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_13-47-26
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1847.0
  episode_reward_mean: 1596.33
  episode_reward_min: 571.0
  episodes_this_iter: 1
  episodes_total: 467
  experiment_id: ebedc1946062457bb682d57fae83bd74
  hostname: gpu052
  info:
    apply_time_ms: 3.421
    dispatch_time_ms: 6.468
    learner:
      cur_lr: 0.0012044890318065882
      grad_gnorm: 28.952863693237305
      policy_entropy: 15.737696647644043
      policy_loss: 2.7231662273406982
      var_gnorm: 44.49421691894531
      vf_explained_var: -0.20185339450836182
      vf_loss: 9.413106918334961
    num_steps_sampled: 2340000
    num_steps_trained: 2340000
    wait_time_ms: 125.977
  iterations_since_restore: 468
  node_ip: 172.17.8.52
  num_metric_batches_dropped: 0
  pid: 12141
  policy_reward_mean: {}
  time_since_restore: 6410.757657289505
  time_this_iter_s: 12.65066146850586
  time_total_s: 6410.757657289505
  timestamp: 1594144046
  timesteps_since_restore: 2340000
  timesteps_this_iter: 5000
  timesteps_total: 2340000
  training_iteration: 468
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 33.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=12141], 6410 s, 468 iter, 2340000 ts, 1.6e+03 rew

agent-1: 363.0
agent-2: 342.0
agent-3: 355.0
agent-4: 363.0
agent-5: 386.0
Sum Reward: 1809.0
Avg Reward: 361.8
Min Reward: 342.0
Max Reward: 386.0
Gini Coefficient: 0.02122719734660033
20:20 Ratio: 1.128654970760234
Max-min Ratio: 1.128654970760234
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_13-47-40
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1847.0
  episode_reward_mean: 1598.71
  episode_reward_min: 571.0
  episodes_this_iter: 1
  episodes_total: 468
  experiment_id: ebedc1946062457bb682d57fae83bd74
  hostname: gpu052
  info:
    apply_time_ms: 3.524
    dispatch_time_ms: 8.671
    learner:
      cur_lr: 0.0012041559675708413
      grad_gnorm: 40.0
      policy_entropy: 17.729778289794922
      policy_loss: 12.981283187866211
      var_gnorm: 44.50001525878906
      vf_explained_var: 0.2770423889160156
      vf_loss: 54.19476318359375
    num_steps_sampled: 2345000
    num_steps_trained: 2345000
    wait_time_ms: 126.869
  iterations_since_restore: 469
  node_ip: 172.17.8.52
  num_metric_batches_dropped: 0
  pid: 12141
  policy_reward_mean: {}
  time_since_restore: 6425.336181640625
  time_this_iter_s: 14.578524351119995
  time_total_s: 6425.336181640625
  timestamp: 1594144060
  timesteps_since_restore: 2345000
  timesteps_this_iter: 5000
  timesteps_total: 2345000
  training_iteration: 469
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 33.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=12141], 6425 s, 469 iter, 2345000 ts, 1.6e+03 rew

agent-1: 336.0
agent-2: 336.0
agent-3: 329.0
agent-4: 372.0
agent-5: 345.0
Sum Reward: 1718.0
Avg Reward: 343.6
Min Reward: 329.0
Max Reward: 372.0
Gini Coefficient: 0.02211874272409779
20:20 Ratio: 1.1306990881458967
Max-min Ratio: 1.1306990881458967
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_13-47-54
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1847.0
  episode_reward_mean: 1600.36
  episode_reward_min: 571.0
  episodes_this_iter: 1
  episodes_total: 469
  experiment_id: ebedc1946062457bb682d57fae83bd74
  hostname: gpu052
  info:
    apply_time_ms: 3.352
    dispatch_time_ms: 11.648
    learner:
      cur_lr: 0.0012038230197504163
      grad_gnorm: 40.0000114440918
      policy_entropy: 18.12443733215332
      policy_loss: 11.567134857177734
      var_gnorm: 44.51508331298828
      vf_explained_var: 0.5659867525100708
      vf_loss: 84.58930206298828
    num_steps_sampled: 2350000
    num_steps_trained: 2350000
    wait_time_ms: 125.688
  iterations_since_restore: 470
  node_ip: 172.17.8.52
  num_metric_batches_dropped: 0
  pid: 12141
  policy_reward_mean: {}
  time_since_restore: 6438.493429660797
  time_this_iter_s: 13.15724802017212
  time_total_s: 6438.493429660797
  timestamp: 1594144074
  timesteps_since_restore: 2350000
  timesteps_this_iter: 5000
  timesteps_total: 2350000
  training_iteration: 470
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 33.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=12141], 6438 s, 470 iter, 2350000 ts, 1.6e+03 rew

agent-1: 266.0
agent-2: 333.0
agent-3: 269.0
agent-4: 322.0
agent-5: 348.0
Sum Reward: 1538.0
Avg Reward: 307.6
Min Reward: 266.0
Max Reward: 348.0
Gini Coefficient: 0.05929778933680104
20:20 Ratio: 1.3082706766917294
Max-min Ratio: 1.3082706766917294
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_13-48-09
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1847.0
  episode_reward_mean: 1599.0
  episode_reward_min: 571.0
  episodes_this_iter: 1
  episodes_total: 470
  experiment_id: ebedc1946062457bb682d57fae83bd74
  hostname: gpu052
  info:
    apply_time_ms: 3.117
    dispatch_time_ms: 6.59
    learner:
      cur_lr: 0.0012034899555146694
      grad_gnorm: 40.0
      policy_entropy: 20.97083282470703
      policy_loss: 4.597530841827393
      var_gnorm: 44.555030822753906
      vf_explained_var: 0.8552465438842773
      vf_loss: 87.44985961914062
    num_steps_sampled: 2355000
    num_steps_trained: 2355000
    wait_time_ms: 143.43
  iterations_since_restore: 471
  node_ip: 172.17.8.52
  num_metric_batches_dropped: 0
  pid: 12141
  policy_reward_mean: {}
  time_since_restore: 6453.993869781494
  time_this_iter_s: 15.500440120697021
  time_total_s: 6453.993869781494
  timestamp: 1594144089
  timesteps_since_restore: 2355000
  timesteps_this_iter: 5000
  timesteps_total: 2355000
  training_iteration: 471
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 33.3/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=12141], 6453 s, 471 iter, 2355000 ts, 1.6e+03 rew

agent-1: 325.0
agent-2: 327.0
agent-3: 325.0
agent-4: 292.0
agent-5: 313.0
Sum Reward: 1582.0
Avg Reward: 316.4
Min Reward: 292.0
Max Reward: 327.0
Gini Coefficient: 0.020733249051833123
20:20 Ratio: 1.11986301369863
Max-min Ratio: 1.11986301369863
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_13-48-22
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1847.0
  episode_reward_mean: 1598.18
  episode_reward_min: 571.0
  episodes_this_iter: 1
  episodes_total: 471
  experiment_id: ebedc1946062457bb682d57fae83bd74
  hostname: gpu052
  info:
    apply_time_ms: 3.983
    dispatch_time_ms: 10.922
    learner:
      cur_lr: 0.0012031570076942444
      grad_gnorm: 39.999996185302734
      policy_entropy: 29.8408260345459
      policy_loss: 4.870887756347656
      var_gnorm: 44.66050338745117
      vf_explained_var: 0.6039048433303833
      vf_loss: 18.948312759399414
    num_steps_sampled: 2360000
    num_steps_trained: 2360000
    wait_time_ms: 119.305
  iterations_since_restore: 472
  node_ip: 172.17.8.52
  num_metric_batches_dropped: 0
  pid: 12141
  policy_reward_mean: {}
  time_since_restore: 6466.47211432457
  time_this_iter_s: 12.478244543075562
  time_total_s: 6466.47211432457
  timestamp: 1594144102
  timesteps_since_restore: 2360000
  timesteps_this_iter: 5000
  timesteps_total: 2360000
  training_iteration: 472
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 33.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=12141], 6466 s, 472 iter, 2360000 ts, 1.6e+03 rew

agent-1: 320.0
agent-2: 351.0
agent-3: 308.0
agent-4: 345.0
agent-5: 343.0
Sum Reward: 1667.0
Avg Reward: 333.4
Min Reward: 308.0
Max Reward: 351.0
Gini Coefficient: 0.026634673065386923
20:20 Ratio: 1.1396103896103895
Max-min Ratio: 1.1396103896103895
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_13-48-35
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1847.0
  episode_reward_mean: 1598.4
  episode_reward_min: 571.0
  episodes_this_iter: 1
  episodes_total: 472
  experiment_id: ebedc1946062457bb682d57fae83bd74
  hostname: gpu052
  info:
    apply_time_ms: 3.074
    dispatch_time_ms: 5.973
    learner:
      cur_lr: 0.0012028239434584975
      grad_gnorm: 39.99999237060547
      policy_entropy: 35.38081741333008
      policy_loss: 6.967440605163574
      var_gnorm: 44.67366027832031
      vf_explained_var: -0.10080146789550781
      vf_loss: 45.98429870605469
    num_steps_sampled: 2365000
    num_steps_trained: 2365000
    wait_time_ms: 120.573
  iterations_since_restore: 473
  node_ip: 172.17.8.52
  num_metric_batches_dropped: 0
  pid: 12141
  policy_reward_mean: {}
  time_since_restore: 6480.067328214645
  time_this_iter_s: 13.595213890075684
  time_total_s: 6480.067328214645
  timestamp: 1594144115
  timesteps_since_restore: 2365000
  timesteps_this_iter: 5000
  timesteps_total: 2365000
  training_iteration: 473
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 33.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=12141], 6480 s, 473 iter, 2365000 ts, 1.6e+03 rew

agent-1: 286.0
agent-2: 332.0
agent-3: 272.0
agent-4: 297.0
agent-5: 305.0
Sum Reward: 1492.0
Avg Reward: 298.4
Min Reward: 272.0
Max Reward: 332.0
Gini Coefficient: 0.037265415549597856
20:20 Ratio: 1.2205882352941178
Max-min Ratio: 1.2205882352941178
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_13-48-48
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1847.0
  episode_reward_mean: 1596.83
  episode_reward_min: 571.0
  episodes_this_iter: 1
  episodes_total: 473
  experiment_id: ebedc1946062457bb682d57fae83bd74
  hostname: gpu052
  info:
    apply_time_ms: 2.797
    dispatch_time_ms: 6.933
    learner:
      cur_lr: 0.0012024909956380725
      grad_gnorm: 40.000003814697266
      policy_entropy: 40.279212951660156
      policy_loss: -7.770877361297607
      var_gnorm: 44.747947692871094
      vf_explained_var: 0.5391414761543274
      vf_loss: 26.87420082092285
    num_steps_sampled: 2370000
    num_steps_trained: 2370000
    wait_time_ms: 122.896
  iterations_since_restore: 474
  node_ip: 172.17.8.52
  num_metric_batches_dropped: 0
  pid: 12141
  policy_reward_mean: {}
  time_since_restore: 6492.6521990299225
  time_this_iter_s: 12.5848708152771
  time_total_s: 6492.6521990299225
  timestamp: 1594144128
  timesteps_since_restore: 2370000
  timesteps_this_iter: 5000
  timesteps_total: 2370000
  training_iteration: 474
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 33.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=12141], 6492 s, 474 iter, 2370000 ts, 1.6e+03 rew

agent-1: 380.0
agent-2: 334.0
agent-3: 281.0
agent-4: 346.0
agent-5: 323.0
Sum Reward: 1664.0
Avg Reward: 332.8
Min Reward: 281.0
Max Reward: 380.0
Gini Coefficient: 0.053125
20:20 Ratio: 1.3523131672597866
Max-min Ratio: 1.3523131672597866
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_13-49-02
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1847.0
  episode_reward_mean: 1596.35
  episode_reward_min: 571.0
  episodes_this_iter: 1
  episodes_total: 474
  experiment_id: ebedc1946062457bb682d57fae83bd74
  hostname: gpu052
  info:
    apply_time_ms: 2.916
    dispatch_time_ms: 7.031
    learner:
      cur_lr: 0.0012021580478176475
      grad_gnorm: 19.54807472229004
      policy_entropy: 13.219320297241211
      policy_loss: 5.688146591186523
      var_gnorm: 44.7825927734375
      vf_explained_var: 0.9407894611358643
      vf_loss: 27.639158248901367
    num_steps_sampled: 2375000
    num_steps_trained: 2375000
    wait_time_ms: 113.025
  iterations_since_restore: 475
  node_ip: 172.17.8.52
  num_metric_batches_dropped: 0
  pid: 12141
  policy_reward_mean: {}
  time_since_restore: 6506.66215801239
  time_this_iter_s: 14.009958982467651
  time_total_s: 6506.66215801239
  timestamp: 1594144142
  timesteps_since_restore: 2375000
  timesteps_this_iter: 5000
  timesteps_total: 2375000
  training_iteration: 475
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 33.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=12141], 6506 s, 475 iter, 2375000 ts, 1.6e+03 rew

agent-1: 348.0
agent-2: 357.0
agent-3: 319.0
agent-4: 356.0
agent-5: 365.0
Sum Reward: 1745.0
Avg Reward: 349.0
Min Reward: 319.0
Max Reward: 365.0
Gini Coefficient: 0.02315186246418338
20:20 Ratio: 1.1442006269592477
Max-min Ratio: 1.1442006269592477
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_13-49-15
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1847.0
  episode_reward_mean: 1598.35
  episode_reward_min: 571.0
  episodes_this_iter: 1
  episodes_total: 475
  experiment_id: ebedc1946062457bb682d57fae83bd74
  hostname: gpu052
  info:
    apply_time_ms: 2.923
    dispatch_time_ms: 8.648
    learner:
      cur_lr: 0.0012018249835819006
      grad_gnorm: 39.999996185302734
      policy_entropy: 8.682464599609375
      policy_loss: 1.2491751909255981
      var_gnorm: 44.85029602050781
      vf_explained_var: 0.7295621633529663
      vf_loss: 28.85054588317871
    num_steps_sampled: 2380000
    num_steps_trained: 2380000
    wait_time_ms: 127.951
  iterations_since_restore: 476
  node_ip: 172.17.8.52
  num_metric_batches_dropped: 0
  pid: 12141
  policy_reward_mean: {}
  time_since_restore: 6519.638726949692
  time_this_iter_s: 12.976568937301636
  time_total_s: 6519.638726949692
  timestamp: 1594144155
  timesteps_since_restore: 2380000
  timesteps_this_iter: 5000
  timesteps_total: 2380000
  training_iteration: 476
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 33.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=12141], 6519 s, 476 iter, 2380000 ts, 1.6e+03 rew

agent-1: 327.0
agent-2: 363.0
agent-3: 359.0
agent-4: 369.0
agent-5: 377.0
Sum Reward: 1795.0
Avg Reward: 359.0
Min Reward: 327.0
Max Reward: 377.0
Gini Coefficient: 0.024512534818941504
20:20 Ratio: 1.1529051987767585
Max-min Ratio: 1.1529051987767585
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_13-49-29
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1847.0
  episode_reward_mean: 1601.13
  episode_reward_min: 571.0
  episodes_this_iter: 1
  episodes_total: 476
  experiment_id: ebedc1946062457bb682d57fae83bd74
  hostname: gpu052
  info:
    apply_time_ms: 3.08
    dispatch_time_ms: 8.131
    learner:
      cur_lr: 0.0012014920357614756
      grad_gnorm: 39.463356018066406
      policy_entropy: 10.549903869628906
      policy_loss: 4.116964340209961
      var_gnorm: 44.8550910949707
      vf_explained_var: 0.25267142057418823
      vf_loss: 73.42054748535156
    num_steps_sampled: 2385000
    num_steps_trained: 2385000
    wait_time_ms: 116.793
  iterations_since_restore: 477
  node_ip: 172.17.8.52
  num_metric_batches_dropped: 0
  pid: 12141
  policy_reward_mean: {}
  time_since_restore: 6533.704387664795
  time_this_iter_s: 14.06566071510315
  time_total_s: 6533.704387664795
  timestamp: 1594144169
  timesteps_since_restore: 2385000
  timesteps_this_iter: 5000
  timesteps_total: 2385000
  training_iteration: 477
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 33.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=12141], 6533 s, 477 iter, 2385000 ts, 1.6e+03 rew

agent-1: 389.0
agent-2: 388.0
agent-3: 333.0
agent-4: 370.0
agent-5: 306.0
Sum Reward: 1786.0
Avg Reward: 357.2
Min Reward: 306.0
Max Reward: 389.0
Gini Coefficient: 0.04949608062709966
20:20 Ratio: 1.2712418300653594
Max-min Ratio: 1.2712418300653594
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_13-49-42
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1847.0
  episode_reward_mean: 1605.96
  episode_reward_min: 571.0
  episodes_this_iter: 1
  episodes_total: 477
  experiment_id: ebedc1946062457bb682d57fae83bd74
  hostname: gpu052
  info:
    apply_time_ms: 3.508
    dispatch_time_ms: 11.252
    learner:
      cur_lr: 0.0012011589715257287
      grad_gnorm: 40.0
      policy_entropy: 11.084687232971191
      policy_loss: 40.898216247558594
      var_gnorm: 44.915401458740234
      vf_explained_var: -1.0
      vf_loss: 143.8910369873047
    num_steps_sampled: 2390000
    num_steps_trained: 2390000
    wait_time_ms: 131.259
  iterations_since_restore: 478
  node_ip: 172.17.8.52
  num_metric_batches_dropped: 0
  pid: 12141
  policy_reward_mean: {}
  time_since_restore: 6546.879668235779
  time_this_iter_s: 13.175280570983887
  time_total_s: 6546.879668235779
  timestamp: 1594144182
  timesteps_since_restore: 2390000
  timesteps_this_iter: 5000
  timesteps_total: 2390000
  training_iteration: 478
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 33.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=12141], 6546 s, 478 iter, 2390000 ts, 1.61e+03 rew

agent-1: 297.0
agent-2: 321.0
agent-3: 388.0
agent-4: 344.0
agent-5: 389.0
Sum Reward: 1739.0
Avg Reward: 347.8
Min Reward: 297.0
Max Reward: 389.0
Gini Coefficient: 0.057734330074755605
20:20 Ratio: 1.3097643097643097
Max-min Ratio: 1.3097643097643097
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_13-49-57
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1847.0
  episode_reward_mean: 1613.82
  episode_reward_min: 571.0
  episodes_this_iter: 1
  episodes_total: 478
  experiment_id: ebedc1946062457bb682d57fae83bd74
  hostname: gpu052
  info:
    apply_time_ms: 3.79
    dispatch_time_ms: 7.069
    learner:
      cur_lr: 0.0012008260237053037
      grad_gnorm: 40.0
      policy_entropy: 9.221495628356934
      policy_loss: -8.114704132080078
      var_gnorm: 44.93653106689453
      vf_explained_var: 0.8160676956176758
      vf_loss: 117.12142944335938
    num_steps_sampled: 2395000
    num_steps_trained: 2395000
    wait_time_ms: 127.843
  iterations_since_restore: 479
  node_ip: 172.17.8.52
  num_metric_batches_dropped: 0
  pid: 12141
  policy_reward_mean: {}
  time_since_restore: 6561.226735830307
  time_this_iter_s: 14.347067594528198
  time_total_s: 6561.226735830307
  timestamp: 1594144197
  timesteps_since_restore: 2395000
  timesteps_this_iter: 5000
  timesteps_total: 2395000
  training_iteration: 479
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 33.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=12141], 6561 s, 479 iter, 2395000 ts, 1.61e+03 rew

agent-1: 328.0
agent-2: 352.0
agent-3: 262.0
agent-4: 354.0
agent-5: 381.0
Sum Reward: 1677.0
Avg Reward: 335.4
Min Reward: 262.0
Max Reward: 381.0
Gini Coefficient: 0.0629695885509839
20:20 Ratio: 1.4541984732824427
Max-min Ratio: 1.4541984732824427
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_13-50-10
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1847.0
  episode_reward_mean: 1624.88
  episode_reward_min: 616.0
  episodes_this_iter: 1
  episodes_total: 479
  experiment_id: ebedc1946062457bb682d57fae83bd74
  hostname: gpu052
  info:
    apply_time_ms: 2.706
    dispatch_time_ms: 6.448
    learner:
      cur_lr: 0.0012004929594695568
      grad_gnorm: 39.99999237060547
      policy_entropy: 14.129945755004883
      policy_loss: 8.733139038085938
      var_gnorm: 44.97735595703125
      vf_explained_var: 0.532992959022522
      vf_loss: 149.635498046875
    num_steps_sampled: 2400000
    num_steps_trained: 2400000
    wait_time_ms: 141.967
  iterations_since_restore: 480
  node_ip: 172.17.8.52
  num_metric_batches_dropped: 0
  pid: 12141
  policy_reward_mean: {}
  time_since_restore: 6574.960634469986
  time_this_iter_s: 13.733898639678955
  time_total_s: 6574.960634469986
  timestamp: 1594144210
  timesteps_since_restore: 2400000
  timesteps_this_iter: 5000
  timesteps_total: 2400000
  training_iteration: 480
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 33.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=12141], 6574 s, 480 iter, 2400000 ts, 1.62e+03 rew

agent-1: 309.0
agent-2: 343.0
agent-3: 298.0
agent-4: 302.0
agent-5: 332.0
Sum Reward: 1584.0
Avg Reward: 316.8
Min Reward: 298.0
Max Reward: 343.0
Gini Coefficient: 0.030303030303030304
20:20 Ratio: 1.151006711409396
Max-min Ratio: 1.151006711409396
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_13-50-26
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1847.0
  episode_reward_mean: 1634.56
  episode_reward_min: 1024.0
  episodes_this_iter: 1
  episodes_total: 480
  experiment_id: ebedc1946062457bb682d57fae83bd74
  hostname: gpu052
  info:
    apply_time_ms: 3.402
    dispatch_time_ms: 9.026
    learner:
      cur_lr: 0.0012001600116491318
      grad_gnorm: 40.0
      policy_entropy: 14.920440673828125
      policy_loss: 4.612148761749268
      var_gnorm: 45.023399353027344
      vf_explained_var: 0.7703425288200378
      vf_loss: 25.953516006469727
    num_steps_sampled: 2405000
    num_steps_trained: 2405000
    wait_time_ms: 114.214
  iterations_since_restore: 481
  node_ip: 172.17.8.52
  num_metric_batches_dropped: 0
  pid: 12141
  policy_reward_mean: {}
  time_since_restore: 6590.062717199326
  time_this_iter_s: 15.1020827293396
  time_total_s: 6590.062717199326
  timestamp: 1594144226
  timesteps_since_restore: 2405000
  timesteps_this_iter: 5000
  timesteps_total: 2405000
  training_iteration: 481
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 33.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=12141], 6590 s, 481 iter, 2405000 ts, 1.63e+03 rew

agent-1: 390.0
agent-2: 348.0
agent-3: 336.0
agent-4: 387.0
agent-5: 295.0
Sum Reward: 1756.0
Avg Reward: 351.2
Min Reward: 295.0
Max Reward: 390.0
Gini Coefficient: 0.05489749430523918
20:20 Ratio: 1.3220338983050848
Max-min Ratio: 1.3220338983050848
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_13-50-39
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1847.0
  episode_reward_mean: 1641.88
  episode_reward_min: 1328.0
  episodes_this_iter: 1
  episodes_total: 481
  experiment_id: ebedc1946062457bb682d57fae83bd74
  hostname: gpu052
  info:
    apply_time_ms: 3.353
    dispatch_time_ms: 8.732
    learner:
      cur_lr: 0.001199826947413385
      grad_gnorm: 40.0
      policy_entropy: 11.550415992736816
      policy_loss: -4.935793399810791
      var_gnorm: 45.054725646972656
      vf_explained_var: -0.21548891067504883
      vf_loss: 52.971988677978516
    num_steps_sampled: 2410000
    num_steps_trained: 2410000
    wait_time_ms: 133.636
  iterations_since_restore: 482
  node_ip: 172.17.8.52
  num_metric_batches_dropped: 0
  pid: 12141
  policy_reward_mean: {}
  time_since_restore: 6603.72089099884
  time_this_iter_s: 13.65817379951477
  time_total_s: 6603.72089099884
  timestamp: 1594144239
  timesteps_since_restore: 2410000
  timesteps_this_iter: 5000
  timesteps_total: 2410000
  training_iteration: 482
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 33.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=12141], 6603 s, 482 iter, 2410000 ts, 1.64e+03 rew

agent-1: 340.0
agent-2: 326.0
agent-3: 340.0
agent-4: 355.0
agent-5: 361.0
Sum Reward: 1722.0
Avg Reward: 344.4
Min Reward: 326.0
Max Reward: 361.0
Gini Coefficient: 0.019744483159117306
20:20 Ratio: 1.107361963190184
Max-min Ratio: 1.107361963190184
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_13-51-00
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1847.0
  episode_reward_mean: 1645.82
  episode_reward_min: 1357.0
  episodes_this_iter: 1
  episodes_total: 482
  experiment_id: ebedc1946062457bb682d57fae83bd74
  hostname: gpu052
  info:
    apply_time_ms: 2.957
    dispatch_time_ms: 6.956
    learner:
      cur_lr: 0.0011994939995929599
      grad_gnorm: 40.000003814697266
      policy_entropy: 14.396498680114746
      policy_loss: 5.726919651031494
      var_gnorm: 45.13207244873047
      vf_explained_var: 0.4488077759742737
      vf_loss: 34.45922088623047
    num_steps_sampled: 2415000
    num_steps_trained: 2415000
    wait_time_ms: 118.595
  iterations_since_restore: 483
  node_ip: 172.17.8.52
  num_metric_batches_dropped: 0
  pid: 12141
  policy_reward_mean: {}
  time_since_restore: 6624.260000705719
  time_this_iter_s: 20.539109706878662
  time_total_s: 6624.260000705719
  timestamp: 1594144260
  timesteps_since_restore: 2415000
  timesteps_this_iter: 5000
  timesteps_total: 2415000
  training_iteration: 483
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 33.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=12141], 6624 s, 483 iter, 2415000 ts, 1.65e+03 rew

agent-1: 287.0
agent-2: 318.0
agent-3: 385.0
agent-4: 297.0
agent-5: 375.0
Sum Reward: 1662.0
Avg Reward: 332.4
Min Reward: 287.0
Max Reward: 385.0
Gini Coefficient: 0.06594464500601685
20:20 Ratio: 1.3414634146341464
Max-min Ratio: 1.3414634146341464
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_13-51-13
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1847.0
  episode_reward_mean: 1648.87
  episode_reward_min: 1426.0
  episodes_this_iter: 1
  episodes_total: 483
  experiment_id: ebedc1946062457bb682d57fae83bd74
  hostname: gpu052
  info:
    apply_time_ms: 2.826
    dispatch_time_ms: 8.886
    learner:
      cur_lr: 0.0011991610517725348
      grad_gnorm: 25.296131134033203
      policy_entropy: 13.507704734802246
      policy_loss: -3.7921195030212402
      var_gnorm: 45.15943908691406
      vf_explained_var: 0.41434943675994873
      vf_loss: 49.387939453125
    num_steps_sampled: 2420000
    num_steps_trained: 2420000
    wait_time_ms: 127.638
  iterations_since_restore: 484
  node_ip: 172.17.8.52
  num_metric_batches_dropped: 0
  pid: 12141
  policy_reward_mean: {}
  time_since_restore: 6636.884769201279
  time_this_iter_s: 12.624768495559692
  time_total_s: 6636.884769201279
  timestamp: 1594144273
  timesteps_since_restore: 2420000
  timesteps_this_iter: 5000
  timesteps_total: 2420000
  training_iteration: 484
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 34.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=12141], 6636 s, 484 iter, 2420000 ts, 1.65e+03 rew

agent-1: 400.0
agent-2: 358.0
agent-3: 167.0
agent-4: 403.0
agent-5: 414.0
Sum Reward: 1742.0
Avg Reward: 348.4
Min Reward: 167.0
Max Reward: 414.0
Gini Coefficient: 0.12376578645235362
20:20 Ratio: 2.4790419161676644
Max-min Ratio: 2.4790419161676644
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_13-51-27
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1847.0
  episode_reward_mean: 1651.33
  episode_reward_min: 1426.0
  episodes_this_iter: 1
  episodes_total: 484
  experiment_id: ebedc1946062457bb682d57fae83bd74
  hostname: gpu052
  info:
    apply_time_ms: 2.849
    dispatch_time_ms: 6.621
    learner:
      cur_lr: 0.001198827987536788
      grad_gnorm: 12.119566917419434
      policy_entropy: 18.23807144165039
      policy_loss: -6.012179851531982
      var_gnorm: 45.17441940307617
      vf_explained_var: 0.5445022583007812
      vf_loss: 50.21489715576172
    num_steps_sampled: 2425000
    num_steps_trained: 2425000
    wait_time_ms: 137.199
  iterations_since_restore: 485
  node_ip: 172.17.8.52
  num_metric_batches_dropped: 0
  pid: 12141
  policy_reward_mean: {}
  time_since_restore: 6651.223874092102
  time_this_iter_s: 14.339104890823364
  time_total_s: 6651.223874092102
  timestamp: 1594144287
  timesteps_since_restore: 2425000
  timesteps_this_iter: 5000
  timesteps_total: 2425000
  training_iteration: 485
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 34.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=12141], 6651 s, 485 iter, 2425000 ts, 1.65e+03 rew

agent-1: 347.0
agent-2: 356.0
agent-3: 258.0
agent-4: 340.0
agent-5: 334.0
Sum Reward: 1635.0
Avg Reward: 327.0
Min Reward: 258.0
Max Reward: 356.0
Gini Coefficient: 0.051131498470948014
20:20 Ratio: 1.37984496124031
Max-min Ratio: 1.37984496124031
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_13-51-41
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1847.0
  episode_reward_mean: 1651.8
  episode_reward_min: 1426.0
  episodes_this_iter: 1
  episodes_total: 485
  experiment_id: ebedc1946062457bb682d57fae83bd74
  hostname: gpu052
  info:
    apply_time_ms: 2.67
    dispatch_time_ms: 7.803
    learner:
      cur_lr: 0.001198495039716363
      grad_gnorm: 40.0
      policy_entropy: 10.29370403289795
      policy_loss: -15.012531280517578
      var_gnorm: 45.15146255493164
      vf_explained_var: 0.035478949546813965
      vf_loss: 154.81668090820312
    num_steps_sampled: 2430000
    num_steps_trained: 2430000
    wait_time_ms: 132.799
  iterations_since_restore: 486
  node_ip: 172.17.8.52
  num_metric_batches_dropped: 0
  pid: 12141
  policy_reward_mean: {}
  time_since_restore: 6664.838391780853
  time_this_iter_s: 13.61451768875122
  time_total_s: 6664.838391780853
  timestamp: 1594144301
  timesteps_since_restore: 2430000
  timesteps_this_iter: 5000
  timesteps_total: 2430000
  training_iteration: 486
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 34.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=12141], 6664 s, 486 iter, 2430000 ts, 1.65e+03 rew

agent-1: 318.0
agent-2: 377.0
agent-3: 340.0
agent-4: 384.0
agent-5: 359.0
Sum Reward: 1778.0
Avg Reward: 355.6
Min Reward: 318.0
Max Reward: 384.0
Gini Coefficient: 0.03802024746906637
20:20 Ratio: 1.2075471698113207
Max-min Ratio: 1.2075471698113207
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_13-51-56
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1847.0
  episode_reward_mean: 1651.97
  episode_reward_min: 1426.0
  episodes_this_iter: 1
  episodes_total: 486
  experiment_id: ebedc1946062457bb682d57fae83bd74
  hostname: gpu052
  info:
    apply_time_ms: 2.92
    dispatch_time_ms: 7.288
    learner:
      cur_lr: 0.001198161975480616
      grad_gnorm: 40.000003814697266
      policy_entropy: 10.20769214630127
      policy_loss: 16.86866569519043
      var_gnorm: 45.160709381103516
      vf_explained_var: -0.28623437881469727
      vf_loss: 64.08118438720703
    num_steps_sampled: 2435000
    num_steps_trained: 2435000
    wait_time_ms: 136.262
  iterations_since_restore: 487
  node_ip: 172.17.8.52
  num_metric_batches_dropped: 0
  pid: 12141
  policy_reward_mean: {}
  time_since_restore: 6679.8330936431885
  time_this_iter_s: 14.994701862335205
  time_total_s: 6679.8330936431885
  timestamp: 1594144316
  timesteps_since_restore: 2435000
  timesteps_this_iter: 5000
  timesteps_total: 2435000
  training_iteration: 487
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 34.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=12141], 6679 s, 487 iter, 2435000 ts, 1.65e+03 rew

agent-1: 271.0
agent-2: 347.0
agent-3: 264.0
agent-4: 342.0
agent-5: 305.0
Sum Reward: 1529.0
Avg Reward: 305.8
Min Reward: 264.0
Max Reward: 347.0
Gini Coefficient: 0.06200130804447351
20:20 Ratio: 1.3143939393939394
Max-min Ratio: 1.3143939393939394
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_13-52-10
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1847.0
  episode_reward_mean: 1648.93
  episode_reward_min: 1426.0
  episodes_this_iter: 1
  episodes_total: 487
  experiment_id: ebedc1946062457bb682d57fae83bd74
  hostname: gpu052
  info:
    apply_time_ms: 2.72
    dispatch_time_ms: 5.976
    learner:
      cur_lr: 0.001197829027660191
      grad_gnorm: 40.0000114440918
      policy_entropy: 7.683937072753906
      policy_loss: -0.5723172426223755
      var_gnorm: 45.117374420166016
      vf_explained_var: 0.7041277289390564
      vf_loss: 64.22268676757812
    num_steps_sampled: 2440000
    num_steps_trained: 2440000
    wait_time_ms: 133.997
  iterations_since_restore: 488
  node_ip: 172.17.8.52
  num_metric_batches_dropped: 0
  pid: 12141
  policy_reward_mean: {}
  time_since_restore: 6694.097461700439
  time_this_iter_s: 14.264368057250977
  time_total_s: 6694.097461700439
  timestamp: 1594144330
  timesteps_since_restore: 2440000
  timesteps_this_iter: 5000
  timesteps_total: 2440000
  training_iteration: 488
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 33.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=12141], 6694 s, 488 iter, 2440000 ts, 1.65e+03 rew

agent-1: 335.0
agent-2: 270.0
agent-3: 308.0
agent-4: 291.0
agent-5: 284.0
Sum Reward: 1488.0
Avg Reward: 297.6
Min Reward: 270.0
Max Reward: 335.0
Gini Coefficient: 0.04139784946236559
20:20 Ratio: 1.2407407407407407
Max-min Ratio: 1.2407407407407407
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_13-52-25
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1847.0
  episode_reward_mean: 1647.15
  episode_reward_min: 1426.0
  episodes_this_iter: 1
  episodes_total: 488
  experiment_id: ebedc1946062457bb682d57fae83bd74
  hostname: gpu052
  info:
    apply_time_ms: 3.08
    dispatch_time_ms: 7.077
    learner:
      cur_lr: 0.0011974959634244442
      grad_gnorm: 40.0
      policy_entropy: 4.838351249694824
      policy_loss: -5.381235599517822
      var_gnorm: 45.2106819152832
      vf_explained_var: 0.7827014327049255
      vf_loss: 52.84231948852539
    num_steps_sampled: 2445000
    num_steps_trained: 2445000
    wait_time_ms: 112.927
  iterations_since_restore: 489
  node_ip: 172.17.8.52
  num_metric_batches_dropped: 0
  pid: 12141
  policy_reward_mean: {}
  time_since_restore: 6708.771880149841
  time_this_iter_s: 14.674418449401855
  time_total_s: 6708.771880149841
  timestamp: 1594144345
  timesteps_since_restore: 2445000
  timesteps_this_iter: 5000
  timesteps_total: 2445000
  training_iteration: 489
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 34.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=12141], 6708 s, 489 iter, 2445000 ts, 1.65e+03 rew

agent-1: 371.0
agent-2: 326.0
agent-3: 323.0
agent-4: 352.0
agent-5: 334.0
Sum Reward: 1706.0
Avg Reward: 341.2
Min Reward: 323.0
Max Reward: 371.0
Gini Coefficient: 0.028604923798358734
20:20 Ratio: 1.1486068111455108
Max-min Ratio: 1.1486068111455108
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_13-52-38
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1847.0
  episode_reward_mean: 1647.87
  episode_reward_min: 1426.0
  episodes_this_iter: 1
  episodes_total: 489
  experiment_id: ebedc1946062457bb682d57fae83bd74
  hostname: gpu052
  info:
    apply_time_ms: 3.862
    dispatch_time_ms: 7.116
    learner:
      cur_lr: 0.0011971630156040192
      grad_gnorm: 39.999996185302734
      policy_entropy: 6.917330741882324
      policy_loss: 14.999868392944336
      var_gnorm: 45.28628158569336
      vf_explained_var: 0.43596571683883667
      vf_loss: 28.888708114624023
    num_steps_sampled: 2450000
    num_steps_trained: 2450000
    wait_time_ms: 124.47
  iterations_since_restore: 490
  node_ip: 172.17.8.52
  num_metric_batches_dropped: 0
  pid: 12141
  policy_reward_mean: {}
  time_since_restore: 6721.903519868851
  time_this_iter_s: 13.1316397190094
  time_total_s: 6721.903519868851
  timestamp: 1594144358
  timesteps_since_restore: 2450000
  timesteps_this_iter: 5000
  timesteps_total: 2450000
  training_iteration: 490
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 34.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=12141], 6721 s, 490 iter, 2450000 ts, 1.65e+03 rew

agent-1: 372.0
agent-2: 391.0
agent-3: 343.0
agent-4: 352.0
agent-5: 363.0
Sum Reward: 1821.0
Avg Reward: 364.2
Min Reward: 343.0
Max Reward: 391.0
Gini Coefficient: 0.025480505216913783
20:20 Ratio: 1.1399416909620992
Max-min Ratio: 1.1399416909620992
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_13-52-52
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1847.0
  episode_reward_mean: 1647.74
  episode_reward_min: 1426.0
  episodes_this_iter: 1
  episodes_total: 490
  experiment_id: ebedc1946062457bb682d57fae83bd74
  hostname: gpu052
  info:
    apply_time_ms: 2.379
    dispatch_time_ms: 6.373
    learner:
      cur_lr: 0.0011968299513682723
      grad_gnorm: 39.999996185302734
      policy_entropy: 6.476943492889404
      policy_loss: -6.270976543426514
      var_gnorm: 45.356468200683594
      vf_explained_var: 0.19946956634521484
      vf_loss: 25.369401931762695
    num_steps_sampled: 2455000
    num_steps_trained: 2455000
    wait_time_ms: 126.074
  iterations_since_restore: 491
  node_ip: 172.17.8.52
  num_metric_batches_dropped: 0
  pid: 12141
  policy_reward_mean: {}
  time_since_restore: 6736.085263967514
  time_this_iter_s: 14.18174409866333
  time_total_s: 6736.085263967514
  timestamp: 1594144372
  timesteps_since_restore: 2455000
  timesteps_this_iter: 5000
  timesteps_total: 2455000
  training_iteration: 491
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 34.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=12141], 6736 s, 491 iter, 2455000 ts, 1.65e+03 rew

agent-1: 372.0
agent-2: 331.0
agent-3: 327.0
agent-4: 365.0
agent-5: 362.0
Sum Reward: 1757.0
Avg Reward: 351.4
Min Reward: 327.0
Max Reward: 372.0
Gini Coefficient: 0.028229937393284006
20:20 Ratio: 1.1376146788990826
Max-min Ratio: 1.1376146788990826
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_13-53-05
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1847.0
  episode_reward_mean: 1648.7
  episode_reward_min: 1426.0
  episodes_this_iter: 1
  episodes_total: 491
  experiment_id: ebedc1946062457bb682d57fae83bd74
  hostname: gpu052
  info:
    apply_time_ms: 3.399
    dispatch_time_ms: 6.501
    learner:
      cur_lr: 0.0011964970035478473
      grad_gnorm: 39.999996185302734
      policy_entropy: 8.109328269958496
      policy_loss: 8.373295783996582
      var_gnorm: 45.485843658447266
      vf_explained_var: 0.5635361671447754
      vf_loss: 49.72676467895508
    num_steps_sampled: 2460000
    num_steps_trained: 2460000
    wait_time_ms: 122.92
  iterations_since_restore: 492
  node_ip: 172.17.8.52
  num_metric_batches_dropped: 0
  pid: 12141
  policy_reward_mean: {}
  time_since_restore: 6749.388678789139
  time_this_iter_s: 13.303414821624756
  time_total_s: 6749.388678789139
  timestamp: 1594144385
  timesteps_since_restore: 2460000
  timesteps_this_iter: 5000
  timesteps_total: 2460000
  training_iteration: 492
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 34.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=12141], 6749 s, 492 iter, 2460000 ts, 1.65e+03 rew

agent-1: 319.0
agent-2: 322.0
agent-3: 330.0
agent-4: 357.0
agent-5: 392.0
Sum Reward: 1720.0
Avg Reward: 344.0
Min Reward: 319.0
Max Reward: 392.0
Gini Coefficient: 0.042093023255813954
20:20 Ratio: 1.2288401253918495
Max-min Ratio: 1.2288401253918495
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_13-53-19
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1839.0
  episode_reward_mean: 1647.43
  episode_reward_min: 1426.0
  episodes_this_iter: 1
  episodes_total: 492
  experiment_id: ebedc1946062457bb682d57fae83bd74
  hostname: gpu052
  info:
    apply_time_ms: 4.041
    dispatch_time_ms: 7.122
    learner:
      cur_lr: 0.0011961640557274222
      grad_gnorm: 40.0
      policy_entropy: 10.639752388000488
      policy_loss: -8.343475341796875
      var_gnorm: 45.55337905883789
      vf_explained_var: 0.3042227625846863
      vf_loss: 26.234928131103516
    num_steps_sampled: 2465000
    num_steps_trained: 2465000
    wait_time_ms: 112.24
  iterations_since_restore: 493
  node_ip: 172.17.8.52
  num_metric_batches_dropped: 0
  pid: 12141
  policy_reward_mean: {}
  time_since_restore: 6762.95717716217
  time_this_iter_s: 13.568498373031616
  time_total_s: 6762.95717716217
  timestamp: 1594144399
  timesteps_since_restore: 2465000
  timesteps_this_iter: 5000
  timesteps_total: 2465000
  training_iteration: 493
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 34.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=12141], 6762 s, 493 iter, 2465000 ts, 1.65e+03 rew

agent-1: 290.0
agent-2: 341.0
agent-3: 298.0
agent-4: 341.0
agent-5: 355.0
Sum Reward: 1625.0
Avg Reward: 325.0
Min Reward: 290.0
Max Reward: 355.0
Gini Coefficient: 0.04258461538461539
20:20 Ratio: 1.2241379310344827
Max-min Ratio: 1.2241379310344827
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_13-53-31
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1822.0
  episode_reward_mean: 1645.29
  episode_reward_min: 1426.0
  episodes_this_iter: 1
  episodes_total: 493
  experiment_id: ebedc1946062457bb682d57fae83bd74
  hostname: gpu052
  info:
    apply_time_ms: 2.667
    dispatch_time_ms: 6.707
    learner:
      cur_lr: 0.0011958309914916754
      grad_gnorm: 9.86839485168457
      policy_entropy: 9.763928413391113
      policy_loss: 7.198913097381592
      var_gnorm: 45.60295486450195
      vf_explained_var: -0.1027059555053711
      vf_loss: 24.86542320251465
    num_steps_sampled: 2470000
    num_steps_trained: 2470000
    wait_time_ms: 117.022
  iterations_since_restore: 494
  node_ip: 172.17.8.52
  num_metric_batches_dropped: 0
  pid: 12141
  policy_reward_mean: {}
  time_since_restore: 6775.440372943878
  time_this_iter_s: 12.483195781707764
  time_total_s: 6775.440372943878
  timestamp: 1594144411
  timesteps_since_restore: 2470000
  timesteps_this_iter: 5000
  timesteps_total: 2470000
  training_iteration: 494
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 34.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=12141], 6775 s, 494 iter, 2470000 ts, 1.65e+03 rew

agent-1: 298.0
agent-2: 360.0
agent-3: 341.0
agent-4: 337.0
agent-5: 361.0
Sum Reward: 1697.0
Avg Reward: 339.4
Min Reward: 298.0
Max Reward: 361.0
Gini Coefficient: 0.03512080141426046
20:20 Ratio: 1.2114093959731544
Max-min Ratio: 1.2114093959731544
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_13-53-44
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1822.0
  episode_reward_mean: 1644.66
  episode_reward_min: 1426.0
  episodes_this_iter: 1
  episodes_total: 494
  experiment_id: ebedc1946062457bb682d57fae83bd74
  hostname: gpu052
  info:
    apply_time_ms: 2.896
    dispatch_time_ms: 7.367
    learner:
      cur_lr: 0.0011954980436712503
      grad_gnorm: 40.0
      policy_entropy: 6.115683078765869
      policy_loss: -14.021696090698242
      var_gnorm: 45.627967834472656
      vf_explained_var: 0.6420885324478149
      vf_loss: 43.1932258605957
    num_steps_sampled: 2475000
    num_steps_trained: 2475000
    wait_time_ms: 103.636
  iterations_since_restore: 495
  node_ip: 172.17.8.52
  num_metric_batches_dropped: 0
  pid: 12141
  policy_reward_mean: {}
  time_since_restore: 6787.996176242828
  time_this_iter_s: 12.555803298950195
  time_total_s: 6787.996176242828
  timestamp: 1594144424
  timesteps_since_restore: 2475000
  timesteps_this_iter: 5000
  timesteps_total: 2475000
  training_iteration: 495
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 34.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=12141], 6787 s, 495 iter, 2475000 ts, 1.64e+03 rew

agent-1: 320.0
agent-2: 345.0
agent-3: 319.0
agent-4: 374.0
agent-5: 401.0
Sum Reward: 1759.0
Avg Reward: 351.8
Min Reward: 319.0
Max Reward: 401.0
Gini Coefficient: 0.049573621375781696
20:20 Ratio: 1.2570532915360502
Max-min Ratio: 1.2570532915360502
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_13-53-57
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1822.0
  episode_reward_mean: 1644.5
  episode_reward_min: 1426.0
  episodes_this_iter: 1
  episodes_total: 495
  experiment_id: ebedc1946062457bb682d57fae83bd74
  hostname: gpu052
  info:
    apply_time_ms: 2.862
    dispatch_time_ms: 9.057
    learner:
      cur_lr: 0.0011951649794355035
      grad_gnorm: 39.999996185302734
      policy_entropy: 6.9325079917907715
      policy_loss: -9.915595054626465
      var_gnorm: 45.63422775268555
      vf_explained_var: 0.8549519181251526
      vf_loss: 70.5400619506836
    num_steps_sampled: 2480000
    num_steps_trained: 2480000
    wait_time_ms: 124.704
  iterations_since_restore: 496
  node_ip: 172.17.8.52
  num_metric_batches_dropped: 0
  pid: 12141
  policy_reward_mean: {}
  time_since_restore: 6800.802426815033
  time_this_iter_s: 12.80625057220459
  time_total_s: 6800.802426815033
  timestamp: 1594144437
  timesteps_since_restore: 2480000
  timesteps_this_iter: 5000
  timesteps_total: 2480000
  training_iteration: 496
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 34.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=12141], 6800 s, 496 iter, 2480000 ts, 1.64e+03 rew

agent-1: 284.0
agent-2: 342.0
agent-3: 344.0
agent-4: 326.0
agent-5: 355.0
Sum Reward: 1651.0
Avg Reward: 330.2
Min Reward: 284.0
Max Reward: 355.0
Gini Coefficient: 0.03876438522107813
20:20 Ratio: 1.25
Max-min Ratio: 1.25
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_13-54-10
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1822.0
  episode_reward_mean: 1643.99
  episode_reward_min: 1426.0
  episodes_this_iter: 1
  episodes_total: 496
  experiment_id: ebedc1946062457bb682d57fae83bd74
  hostname: gpu052
  info:
    apply_time_ms: 2.914
    dispatch_time_ms: 7.265
    learner:
      cur_lr: 0.0011948320316150784
      grad_gnorm: 40.0
      policy_entropy: 4.852628707885742
      policy_loss: 1.0901401042938232
      var_gnorm: 45.63800811767578
      vf_explained_var: 0.3671274781227112
      vf_loss: 28.599878311157227
    num_steps_sampled: 2485000
    num_steps_trained: 2485000
    wait_time_ms: 104.799
  iterations_since_restore: 497
  node_ip: 172.17.8.52
  num_metric_batches_dropped: 0
  pid: 12141
  policy_reward_mean: {}
  time_since_restore: 6814.073435544968
  time_this_iter_s: 13.271008729934692
  time_total_s: 6814.073435544968
  timestamp: 1594144450
  timesteps_since_restore: 2485000
  timesteps_this_iter: 5000
  timesteps_total: 2485000
  training_iteration: 497
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 33.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=12141], 6814 s, 497 iter, 2485000 ts, 1.64e+03 rew

agent-1: 357.0
agent-2: 353.0
agent-3: 308.0
agent-4: 346.0
agent-5: 358.0
Sum Reward: 1722.0
Avg Reward: 344.4
Min Reward: 308.0
Max Reward: 358.0
Gini Coefficient: 0.02578397212543554
20:20 Ratio: 1.1623376623376624
Max-min Ratio: 1.1623376623376624
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_13-54-23
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1822.0
  episode_reward_mean: 1644.59
  episode_reward_min: 1426.0
  episodes_this_iter: 1
  episodes_total: 497
  experiment_id: ebedc1946062457bb682d57fae83bd74
  hostname: gpu052
  info:
    apply_time_ms: 3.055
    dispatch_time_ms: 7.261
    learner:
      cur_lr: 0.0011944989673793316
      grad_gnorm: 40.0
      policy_entropy: 8.981307983398438
      policy_loss: -9.213013648986816
      var_gnorm: 45.60991668701172
      vf_explained_var: 0.579369068145752
      vf_loss: 51.508419036865234
    num_steps_sampled: 2490000
    num_steps_trained: 2490000
    wait_time_ms: 126.326
  iterations_since_restore: 498
  node_ip: 172.17.8.52
  num_metric_batches_dropped: 0
  pid: 12141
  policy_reward_mean: {}
  time_since_restore: 6826.607180118561
  time_this_iter_s: 12.53374457359314
  time_total_s: 6826.607180118561
  timestamp: 1594144463
  timesteps_since_restore: 2490000
  timesteps_this_iter: 5000
  timesteps_total: 2490000
  training_iteration: 498
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 33.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=12141], 6826 s, 498 iter, 2490000 ts, 1.64e+03 rew

agent-1: 342.0
agent-2: 351.0
agent-3: 375.0
agent-4: 386.0
agent-5: 392.0
Sum Reward: 1846.0
Avg Reward: 369.2
Min Reward: 342.0
Max Reward: 392.0
Gini Coefficient: 0.02925243770314193
20:20 Ratio: 1.1461988304093567
Max-min Ratio: 1.1461988304093567
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_13-54-36
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1846.0
  episode_reward_mean: 1645.42
  episode_reward_min: 1426.0
  episodes_this_iter: 1
  episodes_total: 498
  experiment_id: ebedc1946062457bb682d57fae83bd74
  hostname: gpu052
  info:
    apply_time_ms: 3.119
    dispatch_time_ms: 6.628
    learner:
      cur_lr: 0.0011941660195589066
      grad_gnorm: 40.000003814697266
      policy_entropy: 15.548614501953125
      policy_loss: 8.956419944763184
      var_gnorm: 45.713531494140625
      vf_explained_var: 0.7642907500267029
      vf_loss: 20.536907196044922
    num_steps_sampled: 2495000
    num_steps_trained: 2495000
    wait_time_ms: 112.563
  iterations_since_restore: 499
  node_ip: 172.17.8.52
  num_metric_batches_dropped: 0
  pid: 12141
  policy_reward_mean: {}
  time_since_restore: 6839.961438417435
  time_this_iter_s: 13.354258298873901
  time_total_s: 6839.961438417435
  timestamp: 1594144476
  timesteps_since_restore: 2495000
  timesteps_this_iter: 5000
  timesteps_total: 2495000
  training_iteration: 499
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 34.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=12141], 6839 s, 499 iter, 2495000 ts, 1.65e+03 rew

agent-1: 321.0
agent-2: 376.0
agent-3: 351.0
agent-4: 309.0
agent-5: 397.0
Sum Reward: 1754.0
Avg Reward: 350.8
Min Reward: 309.0
Max Reward: 397.0
Gini Coefficient: 0.052679589509692135
20:20 Ratio: 1.284789644012945
Max-min Ratio: 1.284789644012945
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-07_13-54-50
  done: true
  episode_len_mean: 1000.0
  episode_reward_max: 1846.0
  episode_reward_mean: 1647.3
  episode_reward_min: 1426.0
  episodes_this_iter: 1
  episodes_total: 499
  experiment_id: ebedc1946062457bb682d57fae83bd74
  hostname: gpu052
  info:
    apply_time_ms: 2.889
    dispatch_time_ms: 30.462
    learner:
      cur_lr: 0.0011938329553231597
      grad_gnorm: 40.000003814697266
      policy_entropy: 8.977948188781738
      policy_loss: 5.717729568481445
      var_gnorm: 45.72264862060547
      vf_explained_var: 0.6825388073921204
      vf_loss: 14.780190467834473
    num_steps_sampled: 2500000
    num_steps_trained: 2500000
    wait_time_ms: 110.252
  iterations_since_restore: 500
  node_ip: 172.17.8.52
  num_metric_batches_dropped: 0
  pid: 12141
  policy_reward_mean: {}
  time_since_restore: 6853.317924976349
  time_this_iter_s: 13.356486558914185
  time_total_s: 6853.317924976349
  timestamp: 1594144490
  timesteps_since_restore: 2500000
  timesteps_this_iter: 5000
  timesteps_total: 2500000
  training_iteration: 500
  
/h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/numpy/core/fromnumeric.py:3335: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/numpy/core/_methods.py:161: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)
[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.[0m
WARNING: Logging before InitGoogleLogging() is written to STDERR
WARNING: Logging before InitGoogleLogging() is written to STDERR
E0707 13:54:50.524204 12164 raylet_client.cc:345] IOError: [RayletClient] Connection closed unexpectedly. [RayletClient] Failed to push profile events.
E0707 13:54:50.499526 12166 raylet_client.cc:345] IOError: [RayletClient] Connection closed unexpectedly. [RayletClient] Failed to push profile events.
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 0.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 34.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
TERMINATED trials:
 - A3C_harvest_env_0:	TERMINATED [pid=12141], 6853 s, 500 iter, 2500000 ts, 1.65e+03 rew

== Status ==
Using FIFO scheduling algorithm.
Resources requested: 0.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 34.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
TERMINATED trials:
 - A3C_harvest_env_0:	TERMINATED [pid=12141], 6853 s, 500 iter, 2500000 ts, 1.65e+03 rew

Commencing experiment harvest_A3C
E0707 13:54:51.596951 12166 raylet_client.cc:345] IOError: [RayletClient] Connection closed unexpectedly. [RayletClient] Failed to push profile events.
E0707 13:54:51.745627 12164 raylet_client.cc:345] IOError: [RayletClient] Connection closed unexpectedly. [RayletClient] Failed to push profile events.
